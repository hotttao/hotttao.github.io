[{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-13","objectID":"/posts/program/go/expert/go_export/expert_31/","tags":["go 进阶"],"title":"Go 的常见“陷阱”","uri":"/posts/program/go/expert/go_export/expert_31/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"1. go generate ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/:1:0","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"1.1 简介 项目构建，通常我们会依赖一些构建管理工具，比如shell脚本、make等。通过 make 我们可以在编译和构建 Go 代码之前，完成诸如 protobuf 文件生成等等编译代码所需要的前置动作。不过，Go 1.4 版本的Go工具链中增加了在构建之前驱动执行前置动作的能力，这就是go generate命令。我们看下面这个示例: package main import ( \"fmt\" msg \"github.com/bigwhite/protobuf-demo/msg\" ) // 预先“埋”在代码中的可以被go generate命令识别的指示符（directive），指示符中的命令将被go generate识别并被驱动执行 //go:generate protoc -I ./IDL msg.proto --gofast_out=./msg func main() { var m = msg.Request{ MsgID: \"xxxx\", Field1: \"field1\", Field2: []string{\"field2-1\", \"field2-2\"}, } fmt.Println(m) } 执行 go generate 时: $go generate -x -v main.go protoc -I ./IDL msg.proto --gofast_out=./msg ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/:1:1","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"1.2 原理 go generate命令比较独立，不能指望go build、go run或go test等命令可以在后台调用go generate驱动前置指令的执行，go generate命令需要在go build这类命令之前单独执行以生成后续命令需要的Go源文件等。 go generate并不会按Go语法格式规范去解析Go源码文件，它只是将Go源码文件当成普通文本读取并识别其中可以与下面字符串模式匹配的内容（go generate指示符）： //go:generate command arg... 注意，注释符号//前面没有空格，与go:generate之间亦无任何空格。 上面的go generate指示符可以放在Go源文件中的任意位置，并且一个Go源文件中可以有多个go generate指示符，go generate命令会按其出现的顺序逐个识别和执行： //go:generate echo \"top\" package main import \"fmt\" //go:generate echo \"middle\" func main() { fmt.Println(\"hello, go generate\") } //go:generate echo \"tail\" $go generate multi_go_generate_directive.go top middle tail go generate在处理子路径下的包时，其执行命令时的当前工作路径已经切换到该包的路径，因此在go generate指示符中使用相对路径时首先要明确当前的工作路径。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/:1:2","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"1.3 执行范围控制 go generate可接受的不同参数形式，用于限定 go generate 执行范围: // 传入某个文件 $go generate -x -v main.go // 传入当前module，匹配到module的main package且仅处理该main package的源文件 $go generate -x -v // 传入本地路径，匹配该路径下的包的所有源文件 $go generate -x -v ./subpkg1 // 传入包，由于是module的根路径，因此只处理该module下的main包 $go generate -x -v github.com/bigwhite/generate-args-demo // 传入包，处理subpkg1包下的所有源文件 $go generate -x -v github.com/bigwhite/generate-args-demo/subpkg1 // 传入./...模式，匹配当前路径及其子路径下的所有包 $go generate -x -v ./... go generate还可以通过-run使用正则式去匹配各源文件中go generate指示符中的命令，并仅执行匹配成功的命令： $go generate -x -v -run \"protoc\" ./... ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/:1:3","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"1.4 应用场景 go generate目前主要用在目标构建之前驱动代码生成动作的执行，比如: 基于protobuf定义文件（*.proto）生成Go源码文件 利用stringer工具（go get golang.org/x/tools/cmd/stringer）自动生成枚举类型的String方法 利用go-bindata工具（go get -u github.com/go-bindata/go-bindata/…）将数据文件嵌入Go源码中 自动生成枚举类型的String方法 type Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) //go:generate stringer -type=Weekday func main() { var d Weekday fmt.Println(d) fmt.Println(Weekday(1)) } // 接下来利用go generate驱动生成代码： $go generate main.go $cat weekday_string.go 将从静态资源文件数据到Go源码的转换 在Web开发领域，Gopher希望将一些静态资源文件（比如CSS文件等）嵌入最终的二进制文件中一起发布和部署。而go generate结合go-bindata工具（https://github.com/go-bindata/go-bindata）常被用于实现这一功能。Go 1.16版本内置了静态文件嵌入（embedding）功能，我们可以直接在Go源码中通过跑go:embed指示符将静态资源文件嵌入，无须再使用本方法。 //go:generate go-bindata -o static.go static/img/go-mascot.jpg func main() { // 注意路径 data, err := Asset(\"static/img/go-mascot.jpg\") if err != nil { fmt.Println(\"Asset invoke error:\", err) return } http.HandleFunc(\"/\", func(w http.ResponseWriter, req *http.Request) { w.Write(data) }) http.ListenAndServe(\":8080\", nil) } ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_26/:1:4","tags":["go 进阶"],"title":"Go generate","uri":"/posts/program/go/expert/go_export/expert_26/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"go 原生提供的工具，在 gopath 和 module-ware 两种模式上存在一些行为差异。接下来我们会分别介绍 go 原生工具在这两种模式下的使用。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:0:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1. go get go get 用于获取 Go 包及其依赖包 常用命令如下: // 1. 仅下载源码 go get -d A // 下载 A的特定版本，仅在 module-ware 模式下可用 go get -d A@version // 2. 下载源码并编译安装 go get A // 3. 更新依赖版本 go get -u A // 4. 获取测试代码依赖的包 go get -t A ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1.1 go get -d go get的标准行为是将Go包及依赖包下载到本地，并编译和安装目标Go包。传入-d 选项，go get仅会将源码下载到本地，不会对目标包进行编译和安装。 区别 gopath module-ware 下载位置 $GOPATH/src GOPATH[0]/pkg/mod 依赖判定 只下载目标包及其依赖包的当前最新版本 分析目标module的依赖以决定下载依赖的版本 指定版本 不支持 go get -d A@version ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1.2 go get 标准go get（无命令行标志选项）不仅要下载项目及其依赖的源码，还要对下载的源码进行编译和安装。 区别 gopath module-ware 二进制文件 安装到 $GOBIN或$GOPATH/bin 安装到 $GOBIN或$GOPATH/bin 库文件 以.a文件的形式被安装到$GOPATH/pkg/$GOOS_$GOARCH下 只编译并将编译结果缓存下来（Linux系统下缓存默认在~/.cache/go-build下），而不安装 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:2","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1.3 go get -u 默认情况下 go get 会检查目标包及其依赖包在本地是否存在 不存在才会从远程获取。 如果存在，那么即便远程仓库中的目标包及其依赖包的版本发生了更新，go get 也会直接跳过 如果想要go get更新目标包及其依赖包的版本，需要给它传入-u命令行标志选项。 区别 gopath module-ware 依赖判定 只是单纯地下载包的最新版本，如果包存在不兼容，将导致编译问题 根据 go.mod 的依赖关系，获取满足要求的、依赖module的minor版本或patch版本进行更新 module-aware模式下，存在一个特殊情况: module s的直接依赖 module t中的包t1 并未直接参与module s的构建(即 s 没有 import t/t1)，这时如果采用go get -u更新module s的依赖版本，go get -u仅会将t更新到最新的兼容版本（v1.1.0），而module t中未直接参与构建s包的t1包所依赖的module w并不会被更新。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:3","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1.4 go get -t -t命令行标志选项是一个辅助选项，它通常与-d或-u组合使用，用来指示go get在仅下载源码或构建安装时要考虑测试代码的依赖，将测试代码的依赖包一并获取。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:4","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"1.5 行为对比 gopath模式和module-aware模式下的go get行为对比: ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:1:5","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"2. go install go install 会对包进行编译，并将构建出的可执行文件安装到 $GOBIN 或 $GOPATH/bin下。注意 go get 会拉取代码，然后在执行 go install。 go install 常用的命令如下 // -x -v选项，go install会输出大量日志 $go install -x -v bitbucket.org/bigwhite/p go module之前的gopath模式 go module之后的gopath模式 module-ware 二进制文件被安装到 $GOBIN 或 $GOPATH/bin下 同 同 目标文件（.a）被安装到$GOPATH/pkg/linux_amd64下 不会安装，会复制一份放到$GOCACHE下，需要单独安装，添加 -i 选项 仅会被缓存到$GOCACHE下 go clean可以清理掉当前目录下编译构建得到的 p 同 同 go clean -i会清理掉$GOBIN下的可执行文件 p 同 同 go clean -i bitbucket.org/bigwhite/q 会清理掉目标文件 无 无 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:2:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"3. go list go list 用于列出(检视)关于包/module的各类信息。go list 命令行选项如下: go list --help usage: go list [-f format] [-json] [-m] [list flags] [build flags] [packages] Run 'go help list' for details. ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:3:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"3.1 搜索范围 package 用于确定搜索的范围: 默认: 在当前路径下寻找 go.mod，如果当前路径下没有go.mod文件，go list会报错 ./…: 列出当前路径及其子路径（递归）下的所有包 在module-aware模式下，如果当前目录不是module根目录，使用module根路径+…的方式列举包会导致go list无法匹配到包 main：表示独立可执行程序的顶层包 all： 在gopath模式下，它可以展开为标准库和GOPATH路径下的所有包； 在module-aware模式下，它展开为主module（当前路径下的module）下的所有包及其所有依赖包，包括测试代码的依赖包。 std：代表标准库所有包的集合 cmd：代码Go语言自身项目仓库下的src/cmd下的所有包及internal包。 # 1. 搜索路径 $go list $go list ./... $go list bitbucket.org/bigwhite/... # Go原生保留了几个代表特定包或包集合的路径关键字：main、all、cmd和std # 这些保留的路径关键字不要用于Go包的构建中 $go list all $go list std $go list cmd ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:3:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"3.2 输出内容 go list -m 默认情况下，go list输出的都是包的导入路径信息，如果要列出module信息，可以为list命令传入-m命令行标志选项。 go list -f go list提供了一个 -f 的命令行标志选项，用于定制其输出内容的格式。-f标志选项的值是一个格式字符串，采用的是Go template包的语法。go list的默认输出等价于： $go list -f '{{.ImportPath}}' go list 可以输出内容来自$GOROOT/src/cmd/go/internal/pkg.go文件中的结构体类型PackagePublic，其结构如下： type PackagePublic struct { Dir string `json:\",omitempty\"` // 包含包源码的目录 ImportPath string `json:\",omitempty\"` // dir下包的导入路径 ImportComment string `json:\",omitempty\"` // 包声明语句后面的注释中的路径 Name string `json:\",omitempty\"` // 包名 Doc string `json:\",omitempty\"` // 包文档字符串 Target string `json:\",omitempty\"` // 该软件包的安装目标（可以是可执行的） ... TestGoFiles []string `json:\",omitempty\"` // 包中的_test.go文件 TestImports []string `json:\",omitempty\"` // TestGoFiles导入的包 XTestGoFiles []string `json:\",omitempty\"` // 包外的_test.go XTestImports []string `json:\",omitempty\"` // XTestGoFiles导入的包 } 字段 含义 ImportPath ImportPath表示当前路径下的包的导入路径，该字段唯一标识一个包 Target Target表示包的安装路径，该字段采用绝对路径形式 Root Root表示包所在的GOROOT或GOPATH顶层路径，或者包含该包的module根路径 GoFiles GoFiles表示当前包包含的Go源文件列表，不包含导入“C”的cgo文件、测试代码源文件 CgoFiles CgoFiles表示当前包下导入了“C”的cgo文件 IgnoredGoFiles IgnoredGoFiles表示当前包中在当前构建上下文约束条件下被忽略的Go源文件 Imports Imports表示当前包导入的依赖包的导入路径集合 Deps Deps表示当前包的所有依赖包导入路径集合。和Imports不同的是，Deps是递归查询当前包的所有依赖包 TestGoFiles TestGoFiles表示当前包的包内测试代码的文件集合 XTestGoFiles XTestGoFiles表示当前包的包外测试代码的文件集合 go list -json -f 外，传入 -json 选项，可以将包的全部信息以JSON格式输出。 go list -m -u 通过 -m 标志选项，可以让go list列出module信息，-m就像是一个从包到module的转换开关。基于该开关，我们还可以通过传入其他标志选项来获得更多有关module的信息。比如：通过传入-u标志选项，我们可以获取到可用的module升级版本。 go list 常用命令 # 2. 输出详细信息 $go list -m # 输出导出包的详细信息 $go list -f '{{.ImportPath}}' $ go list -json # 3. 有关module的可用升级版本信息 $ go list -m -u all ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:3:2","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4. go build go build命令用于Go源码构建。go build 还提供了很多命令行标志选项，这些标志选项可用于 对构建过程出现的问题进行辅助诊断 定制构建 向编译器/链接器传递参数 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4.1 go build -x -v -v 用于输出当前正在编译的包，-x 用于输出go build执行的每一个命令。 go build执行命令的顺序大致如下： 创建用于构建的临时目录； 下载构建module s依赖的module t和u； 分别编译module t和u，将编译后的结果存储到临时目录及GOCACHE目录下； 编译module s； 定位和汇总module s的各个依赖包构建后的目标文件（.a文件）的位置，形成importcfg.link文件，供后续链接器使用； 链接成可执行文件； 清理临时构建环境。 go build 过程会调用 go tool compile: $GOROOT/pkg/tool/linux_amd64/compile) 包编译 go tool link: $GOROOT/pkg/tool/linux_amd64/link 最终的链接 编译及链接命令中的每个标志选项都会对最终结果产生影响，比如：-goversion的值会影响Go编译器的行为，而这个值可能来自go.mod中的Go版本指示标记。 4.2 go build -a -a 强制重新构建所有包。传入-a选项后，go build就会忽略掉所有缓存机制，忽略掉已经安装到$GOPATH/pkg下的依赖包库文件（.a）从头构建。 go build 在 gopath 模式下比较常用，在module-aware模式下，go module 支持可重建，并且缓存由 go 工具自动管理，很少有人去改动，所以 go build -a变得很少用。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4.3 go build -race -race命令行选项会在构建的结果中加入竞态检测的代码。在程序运行过程中，如果发现对数据的并发竞态访问，这些代码会给出警告，这些警告信息可以用来辅助后续查找和解决竞态问题。不过由于插入竞态检测的代码这个动作，带有-race的构建过程会比标准构建略慢一些。 Go社区的一个最佳实践是在正式发布到生产环境之前的调试、测试环节使用带有-race构建选项构建出的程序，以便于在正式发布到生产环境之前尽可能多地发现程序中潜在的并发竞态问题并快速将其解决。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:2","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4.4 go build -gcflags go build 实质上是通过调用Go自带的compile工具（以Linux系统为例，该工具对应的是$GOROOT/pkg/tool/linux_amd64/compile）对Go代码进行编译的。 go build可以经由-gcflags向compile工具传递编译所需的命令行标志选项集合。 go build -gcflags[=标志应用的包范围]='空格分隔的标志选项列表' go build -gcflags='-N -l' # 仅将传递的编译选项应用于当前包 go build -gcflags=all='-N -l' # 将传递的编译选项应用于当前包及其所有依赖包 go build -gcflags=std='-N -l' # 仅将传递的编译选项应用于标准库包 # 一些选项还具有级别属性，即支持设定选项的作用级别或输出信息内容的详尽级别 go build -gcflags='-m' go build -gcflags='-m -m' // 输出比上一条命令更为详尽的逃逸分析过程信息 go build -gcflags='-m=2' // 与上一条命令等价 go build -gcflags='-m -m -m' // 输出最为详尽的逃逸分析过程信息 go build -gcflags='-m=3' // 与上一条命令等价 “标志应用的包范围”是可选项 如果不显式填写，那么Go编译器仅将通过gcflags传递的编译选项应用在当前包； 如果显式指定了包范围，则通过gcflags传递的编译选项不仅会应用在当前包的编译上，还会应用于包范围指定的包上。 命令行标志选项是传递给Go编译器的，比较重要的是 -l：关闭内联。 -N：关闭代码优化。 -m：输出逃逸分析（决定哪些对象在栈上分配，哪些对象在堆上分配）的分析决策过程。 -S：输出汇编代码。 编译选项参数集合 执行 go tool compile -help 可以查看所有能传递给编译器的选项集合: $ go tool compile -help usage: compile [options] file.go... -% int debug non-static initializers -+ compiling runtime -B disable bounds checking -C disable printing of columns in error messages -D path set relative path for local imports -E debug symbol export -G accept generic code (default 3) -I directory add directory to import search path -K debug missing line numbers -L show full file names in error messages -N disable optimizations -S print assembly listing -V print version and exit -W debug parse tree after type checking -asan build code compatible with C/C++ address sanitizer -asmhdr file write assembly header to file -bench file append benchmark times to file -blockprofile file write block profile to file -buildid id record id as the build id in the export metadata -c int concurrency during compilation (1 means no concurrency) (default 1) -clobberdead clobber dead stack slots (for debugging) -clobberdeadreg clobber dead registers (for debugging) -complete compiling complete package (no C or assembly) -cpuprofile file write cpu profile to file -d value enable debugging settings; try -d help -dwarf generate DWARF symbols (default true) -dwarfbasentries use base address selection entries in DWARF (default true) -dwarflocationlists add location lists to DWARF in optimized mode (default true) -dynlink support references to Go symbols defined in other shared libraries -e no limit on number of errors reported -embedcfg file read go:embed configuration from file -gendwarfinl int generate DWARF inline info records (default 2) -goversion string required version of the runtime -h halt on error -importcfg file read import configuration from file -importmap definition add definition of the form source=actual to import map -installsuffix suffix set pkg directory suffix -j debug runtime-initialized variables -json string version,file for JSON compiler/optimizer detail output -l disable inlining -lang string Go language version source code expects -linkobj file write linker-specific object to file -linkshared generate code that will be linked against Go shared libraries -live debug liveness analysis -m print optimization decisions -memprofile file write memory profile to file -memprofilerate rate set runtime.MemProfileRate to rate -msan build code compatible with C/C++ memory sanitizer -mutexprofile file write mutex profile to file -nolocalimports reject local (relative) imports -o file write output to file -p path set expected package import path -pack write to file.a instead of file.o -r debug generated wrappers -race enable race detector -shared generate code that can be linked into a shared library -smallframes reduce the size limit for stack allocated objects -spectre list enable spectre mitigations in list (all, index, ret) -std compiling standard library -symabis file read symbol ABIs from file -t enable tracing for debugging the compiler -traceprofile file write an execution trace to file -trimpath prefix remove prefix from recorded source file paths -v increase debug verbosity -w debug type checking -wb enable write barrier (default true) ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:3","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4.5 go build -ldflags go build 也支持通过-ldflags 为链接器（以Linux系统为例，该工具对应的是$GOROOT/pkg/tool/linux_amd64/link）传递链接选项集合。 go build -ldflags='空格分隔的标志选项列表' go build -ldflags \"-X main.version=v0.7.0 -s -w\" -o linker_x_flag_without_symboltable_and_dwarf linker_x_flag.go 其中比较常用的有: -X: 设定包中string类型变量的值（仅支持string类型变量） -s：不生成符号表（symbol table） -w：不生成DWARF（Debugging With Attributed Record Formats）调试信息 默认情况下，go build构建出的可执行二进制文件中都是包含符号表和DWARF格式的调试信息的，这虽然让最终二进制文件的体积增加了，但是符号表和调试信息对于生产环境下程序异常时的现场保存和在线调试都有着重要意义。但如果你不在意这些信息或者对应用的大小十分敏感，那么可以通过-s和-w选项将符号表和调试信息从最终的二进制文件中剔除。 -X 通过-X选项，我们可以在编译链接期间动态地为程序中的字符串变量进行赋值，这个选项的一个典型应用就是在构建脚本中设定程序的版本值。 我们通常会为应用程序添加version命令行标志选项，用来输出当前程序的版本信息，就像Go自身那样： $go version go version go1.14 darwin/amd64 如果将版本信息写死到程序代码中，显然不够灵活，耦合太紧。而将版本信息在程序构建时注入则是一个不错的方案。-X选项就可以用来实现这个方案： var ( version string ) func main() { if os.Args[1] == \"version\" { fmt.Println(\"version:\", version) return } } // 构建这个程序，在构建时为version这个string类型变量动态地注入新值： $go build -ldflags \"-X main.version=v0.7.0\" linker_x_flag.go $./linker_x_flag version version: v0.7.0 链接选项参数集合 执行 go tool link -help 可以查看所有能传递给链接的选项集合: $ go tool link -help usage: link [options] main.o -B note add an ELF NT_GNU_BUILD_ID note when using ELF -E entry set entry symbol name -H type set header type -I linker use linker as ELF dynamic linker -L directory add specified directory to library path -R quantum set address rounding quantum (default -1) -T address set text segment address (default -1) -V print version and exit -X definition add string value definition of the form importpath.name=value -a no-op (deprecated) -asan enable ASan interface -aslr enable ASLR for buildmode=c-shared on windows (default true) -benchmark string set to 'mem' or 'cpu' to enable phase benchmarking -benchmarkprofile base emit phase profiles to base_phase.{cpu,mem}prof -buildid id record id as Go toolchain build id -buildmode mode set build mode -c dump call graph -compressdwarf compress DWARF if possible (default true) -cpuprofile file write cpu profile to file -d disable dynamic executable -debugtextsize int debug text section max size -debugtramp int debug trampolines -dumpdep dump symbol dependency graph -extar string archive program for buildmode=c-archive -extld linker use linker when linking in external mode -extldflags flags pass flags to external linker -f ignore version mismatch -g disable go package data checks -h halt on error -importcfg file read import configuration from file -installsuffix suffix set package directory suffix -k symbol set field tracking symbol -libgcc string compiler support lib for internal linking; use \"none\" to disable -linkmode mode set link mode -linkshared link against installed Go shared libraries -memprofile file write memory profile to file -memprofilerate rate set runtime.MemProfileRate to rate -msan enable MSan interface -n dump symbol table -o file write output to file -pluginpath string full path name for plugin -r path set the ELF dynamic linker search path to dir1:dir2:... -race enable race detector -s disable symbol table -strictdups int sanity check duplicate symbol contents during object file reading (1=warn 2=err). -tmpdir directory use directory for temporary files -v print link trace -w disable DWARF generation ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:4","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"4.5 go build -tags go build 可以通过 -tags 指定构建的约束条件，以决定哪些源文件被包含在包内进行构建。tags的值为一组逗号分隔（老版本为空格分隔）的值： $go build -tags=\"tag1,tag2,...\" ... 与tags值列表中的tag1、tag2等呼应的则是 Go源文件中的build tag（亦称为build constraint），下面是标准库os包的file_unix.go源文件中build tag的格式： // +build aix darwin dragonfly freebsd js,wasm linux netbsd openbsd solaris package os 可以看到Go源文件中的build tag实际上就是某种特殊形式的注释: 它通常放在Go源文件的顶部区域，以一行注释或连续的（中间无空行）多行注释形式存在。 build tag与前后的包注释或包声明语句的中间要有一行空行。 build tag 以+build作为起始标记，与前面的注释符号//中间有一个空格 +build后面就是约束标记字符串，比如上面例子中的aix、darwin等。每一行的build tag实质上会被求值为一个布尔表达式。 下图是 Go 源文件中 build tag 布尔表达式的求值规则 当一个Go源文件带有build tag时()，只有当该组tag被求值为true时，该源文件才会被包含入对应的包中参与构建。如果文件没有带 build tag 不会走这个判断逻辑，默认即包含。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:4:5","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5. 运行与诊断 Go 原生提供了一些环境变量，这些环境变量可以影响Go程序运行时的行为并输出Go运行时的一些信息以辅助在线诊断Go程序的问题。这也可以算作性能剖析（profiling）、调试（debug）手段之外的程序诊断辅助手段。我们来看看其中几个重要的环境变量: ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5.1 GOMAXPROCS 作用: 可用于设置Go程序启动后的逻辑处理器P的数量，如果每个P都绑定一个操作内核线程，那么该值将决定有多少个内核线程一起并行承载该Go程序的业务运行 默认: Go 1.5版本将GOMAXPROCS默认值调整为CPU核数，通常无需调整 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5.2 GOGC 除了显式调用 runtime.GC 强制运行GC，Go还提供了一个可以调节GC触发时机的环境变量：GOGC。 GOGC是一个整数值 默认为100。这个值代表一个比例值，100表示100%。 这个比例值的分子是上一次GC结束后到当前时刻新分配的堆内存大小（设为M） 分母则是上一次GC结束后堆内存上的活动对象内存数据（live data，可达内存）的大小（设为N）。 Go运行时实时监控当前堆内存状态，如果当前堆内存的N/M的值等于GOGC/100，则会再次触发运行GC STW垃圾回收器 在早期版本中，Go使用的是STW垃圾回收器，即每次触发GC后，都要先停止程序（Stop The World），然后GC进行标记（mark）和清除（sweep）操作，GC完成后再恢复程序的运行。每次GC完成后堆上的内存都是标记的活动对象，Go 运行可以准确的计算出 N/M 的比值。 三色标记圾回收器 在1.5版本中，Go抛弃了GC延迟过大且无法扩展的STW垃圾回收器，引入了基于三色标记清除的并发垃圾回收器。并发垃圾回收器与用户程序一起执行带来了GC延迟的大幅下降，但也导致了Go运行时无法精确控制堆内存大小，因为在并发标记过程中，只要没有停止程序，用户程序就可以继续分配内存。 计算新分配内存时不仅要考虑两次GC之间用户程序请求分配的内存，还要考虑新一轮GC开始后的并发标记过程中用户新分配的内存: 于是新一轮GC被提前启动了，而启动的新一轮GC的目标值（goal）为： goal = 上一轮GC后的堆活动内存大小×(GOGC/100+1) 显然一轮GC结束时的堆大小与该轮GC的目标期望值goal越接近说明GC启动的时机越好，对并发标记过程内存分配的估计越准确。那么究竟该提前多久启动新一轮GC呢？这是由Go并发垃圾回收的Pacing算法决定的。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:2","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5.2 GODEBUG=gctrace=1 设置环境变量 GODEBUG=‘gctrace=1’ 可以让 GO 运行时在每次GC执行时输出此次GC相关的跟踪信息。 $go build -o gctrace gctrace.go $GODEBUG='gctrace=1' GOGC=100 ./gctrace gc 1 @0.008s 3%: 0.005+2.7+0.017 ms clock, 0.042+0.056/3.6/3.7+0.14 ms cpu, 5-\u003e5-\u003e4 MB, 6 MB goal, 8 P gc 2 @0.028s 5%: 0.007+8.4+0.024 ms clock, 0.057+0.074/11/11+0.19 ms cpu, 9-\u003e9-\u003e8 MB, 10 MB goal, 8 P gc 3 @0.067s 5%: 0.005+14+0.023 ms clock, 0.040+0.38/19/18+0.18 ms cpu, 19-\u003e19-\u003e16 MB, 20 MB goal, 8 P gc 4 @0.141s 6%: 0.011+25+0.021 ms clock, 0.093+0.26/46/82+0.17 ms cpu, 38-\u003e38-\u003e33 MB, 39 MB goal, 8 P gc 5 @0.256s 6%: 0.003+34+0.016 ms clock, 0.031+0.40/67/61+0.13 ms cpu, 77-\u003e77-\u003e66 MB, 78 MB goal, 8 P gc 6 @0.448s 6%: 0.004+58+0.017 ms clock, 0.033+0.49/113/185+0.14 ms cpu, 154-\u003e154-\u003e133 MB, 155 MB goal, 8 P gc 7 @0.868s 6%: 0.004+116+0.017 ms clock, 0.032+0.64/231/574+0.13 ms cpu, 307-\u003e308-\u003e266 MB, 308 MB goal, 8 P gc 8 @1.793s 7%: 0.003+368+0.016 ms clock, 0.025+0.95/734/1812+0.13 ms cpu, 615-\u003e616-\u003e533 MB, 616 MB goal, 8 P gc 9 @3.715s 7%: 0.003+692+0.021 ms clock, 0.028+34/1384/3436+0.17 ms cpu, 1231-\u003e1232-\u003e1066 MB, 1232 MB goal, 8 P ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:3","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5.3 GODEBUG=schedtrace=1000 Go提供了调度器当前状态的查看方法：使用Go运行时环境变量GODEBUG。 $ GODEBUG=schedtrace=1000 godoc -http=:6060 SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=3 spinningthreads=0 idlethreads=0 runqueue=0 [0 0 0 0] SCHED 1001ms: gomaxprocs=4 idleprocs=0 threads=9 spinningthreads=0 idlethreads=3 runqueue=2 [8 14 5 2] SCHED 2006ms: gomaxprocs=4 idleprocs=0 threads=25 spinningthreads=0 idlethreads=19 runqueue=12 [0 0 4 0] SCHED 3006ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=8 runqueue=2 [0 1 1 0] SCHED 4010ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=20 runqueue=12 [6 3 1 0] GODEBUG 通过给其传入不同的key1=value1, key2=value2, …组合，Go的运行时会输出不同的调试信息，比如在这里我们给GODEBUG传入了\"schedtrace=1000\"，其含义就是每1000ms打印输出一次goroutine调度器的状态，每次一行。以上面例子中最后一行为例，每一行各字段含义如下： SCHED：调试信息输出标志字符串，代表本行是goroutine调度器相关信息的输出。 6016ms：从程序启动到输出这行日志经过的时间。 gomaxprocs：P的数量。 idleprocs：处于空闲状态的P的数量。通过gomaxprocs和idleprocs的差值，我们就可以知道当前正在执行Go代码的P的数量。 threads：操作系统线程的数量，包含调度器使用的M数量，加上运行时自用的类似sysmon这样的线程的数量。 spinningthreads：处于自旋（spin）状态的操作系统数量。 idlethread：处于空闲状态的操作系统线程的数量。 runqueue=1：Go调度器全局运行队列中G的数量。 [3 4 0 10]：分别为4个P的本地运行队列中的G的数量。 还可以输出每个goroutine、M和P的详细调度信息（对于Gopher来说，在大多数情况下这是不必要的）： $ GODEBUG=schedtrace=1000,scheddetail=1 godoc -http=:6060 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:4","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"5.4 GODEBUG=asyncpreemptoff=1 Go长期以来不支持真正的抢占式调度，下面的代码是一个典型例子： func deadloop() { for { } } func main() { runtime.GOMAXPROCS(1) go deadloop() for { time.Sleep(time.Second * 1) fmt.Println(\"I got scheduled!\") } } 在只有一个P（GOMAXPROCS=1）的情况下，上面代码中deadloop函数所在的goroutine将持续占据该P，使得main goroutine中的代码得不到调度，我们无法看到“I got scheduled!”字样输出。这是因为Go 1.13及以前版本的抢占是协作式的，只在有函数调用的地方才能插入抢占代码（埋点），而deadloop没有给编译器插入抢占代码的机会。Go 1.14版本增加了基于系统信号的异步抢占调度，这样上面的deadloop所在的goroutine也可以被抢占了。 由于系统信号可能在代码执行到任意地方发生，在Go运行时能顾及的地方，Go运行时自然会处理好这些系统信号。但如果你是通过syscall包或golang.org/x/sys/unix在Unix/Linux/macOS上直接进行系统调用，那么一旦在系统调用执行过程中进程收到系统中断信号，这些系统调用就会失败，并以EINTR错误返回，尤其是低速系统调用，包括读写特定类型文件（管道、终端设备、网络设备）、进程间通信等。在这样的情况下，我们就需要自己处理EINTR错误。最常见的错误处理方式是重试。对于可重入的系统调用来说，在收到EINTR信号后的重试是安全的。如果你没有自己调用syscall包，那么异步抢占调度对你已有的代码几乎无影响。 相反，当异步抢占调度对你的代码有影响，并且你还没法及时修正时，可以通过GODEBUG= asyncpreemptoff=1关闭这一新增的特性。 $GODEBUG=asyncpreemptoff=1 go run preemption_scheduler.go // 这里不会输出I got scheduled! 随着Go的演进，GODEBUG的取值还在增加和变化中，其最新更新可参见GODEBUG 取值。 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:5:5","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"6. go vet go vet是官方Go工具链提供的静态代码检查工具，相比于编译器关注语法层面的正确性，go vet 在语义层面尝试发现潜在问题。 go vet 内置了多条静态代码检查规则: assign规则：检查代码中是否有无用的赋值操作m，比如 x = x atomic规则：检查代码中是否有对sync.atomic包中函数的误用情况 bools规则：检查代码中是否存在对布尔操作符的误用情况 buildtag规则：检查源文件中+build tag是否正确定义 composites规则：检查源文件中是否有未使用“field:value”格式的复合字面值形式对struct类型变量进行值构造的问题 copylocks规则：检查源文件中是否存在lock类型变量的按值传递问题 loopclosure规则：检查源文件中是否存在循环内的匿名函数引用循环变量的问题。 unmarshal规则：检查源码中是否有将非指针或非接口类型值传给unmarshal的问题 unsafeptr规则：检查源码中是否有非法将uintptr转换为unsafe.Pointer的问题 可以通过go tool vet help查看更多检查规则。默认情况下，go vet内置的所有检查规则均开启： # go tool vet help vet is a tool for static analysis of Go programs. vet examines Go source code and reports suspicious constructs, such as Printf calls whose arguments do not align with the format string. It uses heuristics that do not guarantee all reports are genuine problems, but it can find errors not caught by the compilers. Registered analyzers: asmdecl report mismatches between assembly files and Go declarations assign check for useless assignments atomic check for common mistakes using the sync/atomic package bools check for common mistakes involving boolean operators buildtag check that +build tags are well-formed and correctly located cgocall detect some violations of the cgo pointer passing rules composites check for unkeyed composite literals copylocks check for locks erroneously passed by value errorsas report passing non-pointer or non-error values to errors.As framepointer report assembly that clobbers the frame pointer before saving it httpresponse check for mistakes using HTTP responses ifaceassert detect impossible interface-to-interface type assertions loopclosure check references to loop variables from within nested functions lostcancel check cancel func returned by context.WithCancel is called nilfunc check for useless comparisons between functions and nil printf check consistency of Printf format strings and arguments shift check for shifts that equal or exceed the width of the integer sigchanyzer check for unbuffered channel of os.Signal stdmethods check signature of methods of well-known interfaces stringintconv check for string(int) conversions structtag check that struct field tags conform to reflect.StructTag.Get testinggoroutine report calls to (*testing.T).Fatal from goroutines started by a test. tests check for common mistaken usages of tests and examples unmarshal report passing non-pointer or non-interface values to unmarshal unreachable check for unreachable code unsafeptr check for invalid conversions of uintptr to unsafe.Pointer unusedresult check for unused results of calls to some functions # 手动关闭其中一个或几个规则 $go vet -printf=false -buildtag=false vet_printf.go # 如果显式开启某些检查，则其他检查规则将不生效 # 仅开启 buildtag 检查，其他检查均不开启 $go vet -buildtag=true vet_printf.go ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:6:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"6.1 第三方linter聚合：golangci-lint 第三方lint工具是对官方go vet工具的一个很好的补充。golangci-lint聚合了几十种Go lint工具，但默认仅开启如下几种。 deadcode：查找代码中的未用代码。 errcheck：检查代码中是否存在未处理的错误。 gosimple：专注于发现可以进一步简化的代码的lint工具。 govet：go官方工具链中的vet工具。 ineffassign：检查源码中是否存在无效赋值的情况（赋值了，但没有使用）。 staticcheck：通用型lint工具，增强的“go vet”，对代码进行很多go vet尚未进行的静态检查。 structcheck：查找未使用的结构体字段。 typecheck：像Go编译器前端那样去解析Go代码并进行类型检查。 unused：检查源码中是否存在未使用的常量、变量、函数和类型。 varcheck：检查源码中是否存在未使用的全局变量和常量。 除了上述默认开启的lint工具，我们还可以通过golangci-lint linters命令查看所有内置lint工具列表，包括默认不开启的。 # 1. 安装 go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest # 2. 开启或关闭特定检查 # 仅开启staticcheck $golangci-lint linters --disable-all -E staticcheck # 在默认开启的lint工具集合的基础上，再额外开启bodyclose和dupl $golangci-lint linters -E bodyclose,dupl # 关闭unused和varcheck $golangci-lint linters -D unused,varcheck # 3. 执行检查 # 仅对当前目录下的vet_assign.go源文件进行staticcheck检查 $golangci-lint run --disable-all -E staticcheck vet_assign.go # 对当前路径下的Go包进行默认lint工具集合的检查 $golangci-lint run # 对当前路径及其子路径（递归）下的所有Go包进行默认开启的lint工具集合检查以及额外的dupl工具检查 $golangci-lint run -E dupl ./... ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:6:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"7. 重构 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:7:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"8. go doc ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:8:0","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"8.1 go doc 命令 go doc在命令行上接受的参数使用了Go语法的格式: go doc \u003cpkg\u003e go doc \u003csym\u003e[.\u003cmethodOrField\u003e] go doc [\u003cpkg\u003e.]\u003csym\u003e[.\u003cmethodOrField\u003e] go doc [\u003cpkg\u003e.][\u003csym\u003e.]\u003cmethodOrField\u003e // 查看标准库文档 go doc net/http go doc net/http.Request.Form // 查看当前路径下的包的文档： $go doc // 查看当前路径下包的导出元素的文档： $go doc CmppActiveTestReqPktLen // 通过-u选项，我们也可以查看当前路径下包的非导出元素的文档： $go doc -u newPacketWriter // 查看源码 go doc -src fmt.Printf ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:8:1","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"6.1 godoc 的Web化的文档中心 // 查看当前版本文档 $godoc -http=localhost:6060 // 查看旧版本 go 文档 $godoc -goroot /Users/tonybai/.bin/go1.9 -http=localhost:6060 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:8:2","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"8.3 查看 go 官方博客 $go get golang.org/x/blog // Go官方博客单独存放在github.com/golang/blog仓库下，需要先将该仓库下载到本地，再切换到该路径下来启动blog服务程序 $git clone https://github.com/golang/blog.git $cd blog $blog 2020/10/31 05:14:47 Listening on addr localhost:8080 ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:8:3","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"8.4 查看present格式文档 go get golang.org/x/tools/cmd/present $git clone https://github.com/golang/talks.git $cd talks $present ","date":"2023-01-12","objectID":"/posts/program/go/expert/go_export/expert_27/:8:4","tags":["go 进阶"],"title":"Go 常用工具","uri":"/posts/program/go/expert/go_export/expert_27/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-11","objectID":"/posts/program/go/expert/go_export/expert_19/","tags":["go 进阶"],"title":"Go cgo","uri":"/posts/program/go/expert/go_export/expert_19/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"1. 反射 Go在标准库中提供的reflect包让Go程序具备运行时的反射能力（reflection，又称为自省）。反射是程序在运行时访问、检测和修改它本身状态或行为的一种能力，各种编程语言所实现的反射机制各有不同。Go语言的interface{}类型变量具有析出任意类型变量的类型信息（type）和值信息（value）的能力，Go的反射本质上就是利用interface{}的这种能力在运行时对任意变量的类型和值信息进行检视甚至是对值进行修改的机制。 ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:1:0","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"1.1 go 反射 反射让静态类型语言Go在运行时具备了某种基于类型信息的动态特性。利用这种特性: fmt.Println在无法提前获知传入参数的真正类型的情况下依旧可以对其进行正确的格式化输出； json.Marshal也是通过这种特性对传入的任意结构体类型进行解构并正确生成对应的JSON文本。 下面通过一个简单的构建SQL查询语句的例子来直观感受Go反射的“魔法”： func ConstructQueryStmt(obj interface{}) (stmt string, err error) { // 仅支持struct或struct指针类型 typ := reflect.TypeOf(obj) if typ.Kind() == reflect.Ptr { typ = typ.Elem() } if typ.Kind() != reflect.Struct { err = errors.New(\"only struct is supported\") return } buffer := bytes.NewBufferString(\"\") buffer.WriteString(\"SELECT \") if typ.NumField() == 0 { err = fmt.Errorf(\"the type[%s] has no fields\", typ.Name()) return } for i := 0; i \u003c typ.NumField(); i++ { field := typ.Field(i) if i != 0 { buffer.WriteString(\", \") } column := field.Name if tag := field.Tag.Get(\"orm\"); tag != \"\" { column = tag } buffer.WriteString(column) } stmt = fmt.Sprintf(\"%s FROM %s\", buffer.String(), typ.Name()) return } Go反射十分适合处理这一类问题，它们的典型特点包括： 输入参数的类型无法提前确定； 函数或方法的处理结果因传入参数（的类型信息和值信息）的不同而异。 反射在带来强大功能的同时，也是很多困扰你的问题的根源，比如： 反射让你的代码逻辑看起来不那么清晰，难于理解； 反射让你的代码运行得更慢； 在编译阶段，编译器无法检测到使用反射的代码中的问题 如果必须使用反射，请牢记 Rob Pike还为Go反射的规范使用定义了三大法则: 反射世界的入口：经由接口（interface{}）类型变量值进入反射的世界并获得对应的反射对象（reflect.Value或reflect.Type） 反射世界的出口：反射对象（reflect.Value）通过化身为一个接口（interface{}）类型变量值的形式走出反射世界。 修改反射对象的前提：反射对象对应的reflect.Value必须是可设置的（Settable） ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:1:1","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"2. 反射世界的入口 ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:2:0","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"2.1 reflect 的基本原理 反射世界的入口: reflect.TypeOf 返回一个reflect.Type对象，该对象中包含了被反射的Go变量实例的所有类型信息； reflect.ValueOf 返回一个reflect.Value对象。Value 对象不仅包含了被反射的Go变量实例的值信息，而且通过调用该对象的Type方法，我们还可以得到Go变量实例的类型信息，这与通过reflect.TypeOf获得类型信息是等价的 var i int = 5 val := reflect.ValueOf(i) typ := reflect.TypeOf(i) fmt.Println(reflect.DeepEqual(typ, val.Type())) // true 反射世界入口可以获取Go变量实例的类型信息和值信息的关键在于，它们利用了interface{}类型的形式参数对传入的实际参数（Go变量实例）的析构能力，。两个入口函数分别将得到的值信息和类型信息存储在reflect.Value对象和reflect.Type对象中。 。 // $GOROOT/src/reflect/value.go // emptyInterface用于表示一个interface{}类型的值的头部 type emptyInterface struct { typ *rtype word unsafe.Pointer } func ValueOf(i interface{}) Value { ... return unpackEface(i) } // unpackEface将empty interface变量i转换成一个reflect.Value func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(\u0026i)) ... return Value{t, e.word, f} } // $GOROOT/src/reflect/type.go // TypeOf返回interface{}类型变量i的动态类型信息 func TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026i)) return toType(eface.typ) } ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:2:1","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"2.2 值/类型检视 通过reflect.Value实例和reflect.Type实例就可以进行值信息和类型信息的检视。 简单原生类型 // 简单原生类型 var b = true // 布尔型 val := reflect.ValueOf(b) typ := reflect.TypeOf(b) fmt.Println(typ.Name(), val.Bool()) // bool true fmt.Println(typ.Name(), val.Int()) // int 23 fmt.Println(typ.Name(), val.Float()) // float64 3.14 fmt.Println(typ.Name(), val.String()) //string hello, reflection var fn = func(a, b int) int { // 函数(一等公民) return a + b } val = reflect.ValueOf(fn) typ = reflect.TypeOf(fn) fmt.Println(typ.Kind(), typ.String()) // func func(int, int) int var i = 17 val := reflect.ValueOf(i) fmt.Println(val.Bool()) // panic: reflect: call of reflect.Value.Bool on int Value reflect.Value类型拥有很多方便我们进行值检视的方法，比如Bool、Int、String等，但显然这些方法并非对所有的变量类型都适用。比如：Bool方法仅适用于对布尔型变量进行反射后得到的Value对象。一旦应用的方法与Value对象的值类型不匹配，我们将收到运行时panic。 reflect.Type是一个接口类型，它包含了很多用于检视类型信息的方法，而对于简单原生类型来说，通过Name、String或Kind方法就可以得到我们想要的类型名称或类型类别等信息。 Name方法返回有确定定义的类型的名字（不包括包名前缀），比如int、string。对于上面的函数类型变量，Name方法将返回空 String方法得到类型的描述字符串，比如上面的func(int, int) int。String方法返回的类型描述可能包含包名（一般使用短包名，即仅使用包导入路径的最后一段），比如main.Person。 Kind方法则返回类型的特定类别 var pi = (*int)(nil) var ps = (*string)(nil) typ := reflect.TypeOf(pi) fmt.Println(typ.Kind(), typ.String()) // ptr *int typ = reflect.TypeOf(ps) fmt.Println(typ.Kind(), typ.String()) // ptr *string 原生复合类型 var sl = []int{5, 6} // 切片 val = reflect.ValueOf(sl) typ = reflect.TypeOf(sl) fmt.Printf(\"[%d %d]\\n\", val.Index(0).Int(), val.Index(1).Int()) // [5, 6] fmt.Println(typ.Kind(), typ.String()) // slice []int var arr = [3]int{5, 6} // 数组 val = reflect.ValueOf(arr) typ = reflect.TypeOf(arr) fmt.Printf(\"[%d %d %d]\\n\", val.Index(0).Int(), val.Index(1).Int(), val.Index(2).Int()) // [5 6 0] fmt.Println(typ.Kind(), typ.String()) // array [3]int var m = map[string]int{ // map \"tony\": 1, \"jim\": 2, \"john\": 3, } val = reflect.ValueOf(m) typ = reflect.TypeOf(m) iter := val.MapRange() fmt.Printf(\"{\") for iter.Next() { k := iter.Key() v := iter.Value() fmt.Printf(\"%s:%d,\", k.String(), v.Int()) } fmt.Printf(\"}\\n\") // {tony:1,jim:2,john:3,} fmt.Println(typ.Kind(), typ.String()) // map map[string]int type Person struct { Name string Age int } var p = Person{\"tony\", 23} // 结构体 val = reflect.ValueOf(p) typ = reflect.TypeOf(p) fmt.Printf(\"{%s, %d}\\n\", val.Field(0).String(), val.Field(1).Int()) // {\"tony\", 23} fmt.Println(typ.Kind(), typ.Name(), typ.String()) // struct Person main.Person var ch = make(chan int, 1) // channel val = reflect.ValueOf(ch) typ = reflect.TypeOf(ch) ch \u003c- 17 v, ok := val.TryRecv() if ok { fmt.Println(v.Int()) // 17 } fmt.Println(typ.Kind(), typ.String()) // chan chan int // 其他自定义类型 type MyInt int var mi MyInt = 19 val = reflect.ValueOf(mi) typ = reflect.TypeOf(mi) fmt.Println(typ.Name(), typ.Kind(), typ.String(), val.Int()) // MyInt int main.MyInt 19 从上面的示例可以看到: 通过Value提供的Index方法，可以获取到切片及数组类型元素所对应的Value对象值 通过Value的MapRange、MapIndex等方法，可以获取到map中的key和value对象所对应的Value对象值 对于结构体类型，Value提供了Field系列方法，通过下标的方式（Field方法）获取结构体字段所对应的Value对象 函数对象 通过反射对象，我们还可以调用函数或对象的方法： func Add(i, j int) int { return i + j } type Calculator struct{} func (c Calculator) Add(i, j int) int { return i + j } func main() { // 函数调用 f := reflect.ValueOf(Add) var i = 5 var j = 6 vals := []reflect.Value{reflect.ValueOf(i), reflect.ValueOf(j)} ret := f.Call(vals) fmt.Println(ret[0].Int()) // 11 // 方法调用 c := reflect.ValueOf(Calculator{}) m := c.MethodByName(\"Add\") ret = m.Call(vals) fmt.Println(ret[0].Int()) // 11 } 通过函数类型变量或包含有方法的类型实例反射出的Value对象，可以通过其Call方法调用该函数或类型的方法。函数或方法的参数以reflect.Value类型切片的形式提供，函数或方法的返回值也以reflect.Value类型切片的形式返回。不过务必保证Value参数的类型信息与原函数或方法的参数的类型相匹配，否则会导致运行时panic。 ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:2:2","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"3. 反射世界的出口 reflect.Value.Interface()是reflect.ValueOf()的逆过程，通过Interface方法我们可以将reflect.Value对象恢复成一个interface{}类型的变量值。这个离开反射世界的过程实质是将reflect.Value中的类型信息和值信息重新打包成一个interface{}的内部表示。之后，我们就可以通过类型断言得到一个反射前的类型变量值： func main() { var i = 5 val := reflect.ValueOf(i) r := val.Interface().(int) fmt.Println(r) // 5 r = 6 fmt.Println(i, r) // 5 6 val = reflect.ValueOf(\u0026i) q := val.Interface().(*int) fmt.Printf(\"%p, %p, %d\\n\", \u0026i, q, *q) // 0xc0000b4008, 0xc0000b4008, 5 *q = 7 fmt.Println(i) // 7 } 从上述例子中我们看到: 通过 reflect.Value.Interface() 函数重建后得到的新变量（如例子中的r）与原变量（如例子中的i）是两个不同的变量，它们的唯一联系就是值相同。 如果我们反射的对象是一个指针（如例子中的\u0026i），那么我们通过reflect.Value.Interface()得到的新变量（如例子中的q）也是一个指针，且它所指的内存地址与原指针变量相同。通过新指针变量对所指内存值的修改会反映到原变量上（变量i的值由5变为7） ","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:3:0","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"4. 输出参数、interface{}类型变量及反射对象的可设置性 在学习传统编程语言（如C语言）的函数概念时，我们通常还会学习到输入参数和输出参数的概念，Go语言也支持这些概念，比如下面的例子： func myFunc(in int, out *int) { in = 1 *out = in + 10 } func main() { var n = 17 var m = 23 fmt.Printf(\"n=%d, m=%d\\n\", n, m) // n=17, m=23 myFunc(n, \u0026m) fmt.Printf(\"n=%d, m=%d\\n\", n, m) // n=17, m=11 } 上例中: in是输入参数，函数体内对in的修改不会影响到作为实参传入myFunc的变量n，因为Go函数参数的传递是传值，即值复制； out是输出参数，它的传递也是值复制，但这里复制的却是指针值，即作为实参myFunc的变量m的地址，这样函数体内通过解引用对out所指内存地址上的值的修改就会同步到变量m。 对于以interface{}类型变量i作为形式参数的reflect.ValueOf和reflect.TypeOf函数来说，i自身是被反射对象的“复制品”，就像上面函数的输入参数那样。而新创建的反射对象又复制了i中所包含的值信息，因此当被反射对象以值类型（T）传递给reflect.ValueOf时，在反射世界中对反射对象值信息的修改不会对被反射对象产生影响。Go的设计者们认为这种修改毫无意义，并禁止了这种行为。一旦发生这种行为，将会导致运行时panic： var i = 17 val := reflect.ValueOf(i) val.SetInt(27) // panic: reflect: reflect.flag.mustBeAssignable using unaddressable value reflect.Value提供了CanSet、CanAddr及CanInterface等方法来帮助我们判断反射对象是否可设置（Settable）、可寻址、可恢复为一个interface{}类型变量 package main import ( \"fmt\" \"reflect\" ) type Person struct { Name string age int } func main() { var n = 17 fmt.Println(\"int:\") val := reflect.ValueOf(n) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true fmt.Println(\"\\n*int:\") val = reflect.ValueOf(\u0026n) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val = reflect.ValueOf(\u0026n).Elem() fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // true true true fmt.Println(\"\\nslice:\") var sl = []int{5, 6, 7} val = reflect.ValueOf(sl) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val = val.Index(0) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // true true true fmt.Println(\"\\narray:\") var arr = [3]int{5, 6, 7} val = reflect.ValueOf(arr) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val = val.Index(0) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true fmt.Println(\"\\nptr to array:\") var pArr = \u0026[3]int{5, 6, 7} val = reflect.ValueOf(pArr) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val = val.Elem() fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // true true true val = val.Index(0) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // true true true fmt.Println(\"\\nstruct:\") p := Person{\"tony\", 33} val = reflect.ValueOf(p) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val1 := val.Field(0) // Name fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val1.CanSet(), val1.CanAddr(), val1.CanInterface()) // false false true val2 := val.Field(1) // age fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val2.CanSet(), val2.CanAddr(), val2.CanInterface()) // false false false fmt.Println(\"\\nptr to struct:\") pp := \u0026Person{\"tony\", 33} val = reflect.ValueOf(pp) fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // false false true val = val.Elem() fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val.CanSet(), val.CanAddr(), val.CanInterface()) // true true true val1 = val.Field(0) // Name fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val1.CanSet(), val1.CanAddr(), val1.CanInterface()) // true true true val2 = val.Field(1) // age fmt.Printf(\"Settable = %v, CanAddr = %v, CanInterface = %v\\n\", val2.CanSet(), val2.CanAddr(), val2.CanInterface()) // false true false fmt.Println","date":"2023-01-10","objectID":"/posts/program/go/expert/go_export/expert_18/:4:0","tags":["go 进阶"],"title":"Go reflect","uri":"/posts/program/go/expert/go_export/expert_18/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"1. 类型安全 在Go语言中，我们是无法通过常规语法手段穿透Go在类型系统层面对内存数据的保护的： func main() { a := 0x12345678 fmt.Printf(\"0x%x\\n\", a) var p *byte = (*byte)(\u0026a) // 错误！不允许将\u0026a从*int类型显式转型为*byte类型 *p = 0x23 var b byte = byte(a) // b是一个新变量，有自己所解释的内存空间 b = 0x23 // 即便强制进行类型转换，原变量a所解释的内存空间的数据依然不变 fmt.Printf(\"0x%x\\n\", b) // 0x23 fmt.Printf(\"0x%x\\n\", a) // 0x12345678 } Go在常规操作下是类型安全的（注：并非绝对的类型安全，绝对的类型安全需要在数学上的形式化证明）。所谓类型安全是指一块内存数据一旦被特定的类型所解释（该内存数据与该类型变量建立关联，也就是变量定义），它就不能再被解释为其他类型，不能再与其他类型变量建立关联。 Go语言的类型安全是建立在Go编译器的静态检查以及Go运行时利用类型信息进行的运行时检查之上的。在语法层面，为了实现常规操作下的类型安全，Go对语法做了诸多限制。 不支持隐式类型转换，所有类型转换必须显式进行 只有底层类型（underlying type）相同的两个类型的指针之间才能进行类型转换 不支持指针运算 var i int = 17 var j uint64 = i // 错误：int类型值不能直接赋值给uint64类型变量 var j uint64 = uint64(i) // 没问题 var i int = 11 var p *uint64 = (*uint64)(\u0026i) // 错误：*int类型不能转换为*uint64类型 type MyInt int var p *MyInt = (*MyInt)(\u0026i) // 没问题，MyInt的底层类型为int // 不支持指针运算 var a [100]int var p *int = \u0026a[0] *(p+1) = 10 // 错误：*int类型与int类型无法相加，即不能跨越数组元素的边界 但是为了兼容性能以及如何实现与操作系统、C代码等互操作的低级代码等问题。最终，Go语言的设计者们选择了在类型系统上开一道“后门”的方案，即在标准库中内置一个特殊的Go包——unsafe包。使用unsafe包我们可以实现性能更高、与底层系统交互更容易的低级代码，但unsafe包的存在也让我们有了绕过Go类型安全屏障的“路径”。一旦使用该包不当，便可能会导致引入安全漏洞、引发程序崩溃（panic）等问题。为此，Go设计者们明确了unsafe包的安全使用模式。 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:1:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"2. unsafe 包使用 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:2:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"2.1 unsafe 包接口 unsafe包非常简洁: // $GOROOT/src/unsafe/unsafe.go package unsafe func Alignof(x ArbitraryType) uintptr func Offsetof(x ArbitraryType) uintptr func Sizeof(x ArbitraryType) uintptr type ArbitraryType int type Pointer *ArbitraryType unsafe包定义了一个类型和三个函数: ArbitraryType并不真正属于unsafe包，我们在Go代码中并不能使用ArbitraryType来定义变量，它表示一个任意表达式的类型，仅用于文档目的，Go编译器会对其做特殊处理。 Alignof、Offsetof和Sizeof这三个函数的使用是绝对安全的，这三个函数的有两个共同点: 接受的参数都是一个表达式（x ArbitraryType），而不是一个类型，ArbitraryType表示任意表达式的类型 返回值都是uintptr类型。之所以使用uintptr类型而不用uint64等整型类型，主要是因为这三个函数更多应用于有unsafe.Pointer和uintptr类型参与的指针运算，采用uintptr作为返回值类型可以减少指针运算表达式中的显式类型转换。 Sizeof Sizeof用于获取一个表达式值的大小: var i int = 5 fmt.Println(unsafe.Sizeof(i)) // 8 fmt.Println(unsafe.Sizeof((*int)(nil))) // 8 Sizeof函数不支持直接传入无类型信息的nil值，我们必须显式告知Sizeof传入的nil究竟是什么类型，要么像上面代码那样进行显式转型，要么传入一个值为nil但类型明确的变量，比如var p *int = nil。 Alignof Alignof用于获取一个表达式的内存地址对齐系数。不同的计算机体系结构下，处理器对变量地址都有着对齐要求，即变量的地址必须可被该变量的对齐系数整除。 var x unsafe.ArbitraryType // unsafe.ArbitraryType表示任意类型 b := uintptr(unsafe.Pointer(\u0026x)) % unsafe.Alignof(x) == 0 fmt.Println(b) // true fmt.Println(unsafe.Alignof(i)) // 8 fmt.Println(unsafe.Alignof(struct{}{})) // 1 (注：空结构体的对齐系数为1) fmt.Println(unsafe.Alignof([0]int{})) // 8 (注：长度为0的数组，其对齐系数依然与其元素 // 类型的对齐系数相同) Offsetof Offsetof用于获取结构体中某字段的地址偏移量（相对于结构体变量的地址）。Offsetof函数应用面较窄，仅用于求结构体中某字段的偏移值。 fmt.Println(unsafe.Offsetof(f.b)) // 8 fmt.Println(unsafe.Offsetof(f.d)) // 40 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:2:1","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"2.2 unsafe.Pointer类型 unsafe包之所以被命名为unsafe，主要是因为该包中定义了unsafe.Pointer类型。 unsafe.Pointer可用于表示任意类型的指针，并且它具备下面四条其他指针类型所不具备的性质。 任意类型的指针值都可以被转换为unsafe.Pointer。 unsafe.Pointer也可以被转换为任意类型的指针值。 uintptr类型值可以被转换为一个unsafe.Pointer。 unsafe.Pointer也可以被转换为一个uintptr类型值。 var a int = 5 var b float64= 5.89 var arr [10]string var f Foo // 1. 任意类型的指针值都可以被转换为unsafe.Pointer p1 := (unsafe.Pointer)(\u0026a) // *int -\u003e unsafe.Pointer p2 := (unsafe.Pointer)(\u0026b) // *float64 -\u003e unsafe.Pointer p3 := (unsafe.Pointer)(\u0026arr) // *[10]string -\u003e unsafe.Pointer p4 := (unsafe.Pointer)(\u0026f) // *Foo -\u003e unsafe.Pointer // 2. unsafe.Pointer也可以被转换为任意类型的指针值 var pa = (*int)(p1) // unsafe.Pointer -\u003e *int var pb = (*float64)(p2) // unsafe.Pointer -\u003e *float64 var parr = (*[10]string)(p3) // unsafe.Pointer -\u003e *[10]string var pf = (*Foo)(p4) // unsafe.Pointer -\u003e *Foo // 3. uintptr类型值可以被转换为一个unsafe.Pointer var i uintptr = 0x80010203 p := unsafe.Pointer(i) // 4. unsafe.Pointer也可以被转换为一个uintptr类型值。 p := unsafe.Pointer(\u0026a) var i = uintptr(p) 有了 unsafe.Pointer，可以很容易穿透Go的类型安全保护: func main() { var a uint32 = 0x12345678 fmt.Printf(\"0x%x\\n\", a) // 0x12345678 p := (unsafe.Pointer)(\u0026a) // 利用unsafe.Pointer的性质1 b := (*[4]byte)(p) // 利用unsafe.Pointer的性质2 b[0] = 0x23 b[1] = 0x45 b[2] = 0x67 b[3] = 0x8a fmt.Printf(\"0x%x\\n\", a) // 0x8a674523 (注：在小端字节序系统中输出此值) } 可以看到原本被解释为uint32类型的一段内存（起始地址为\u0026a，长度为4字节），通过unsafe.Pointer被重新解释成了[4]byte并且通过变量b（*[4]byte类型）可以对该段内存进行修改。 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:2:2","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"3. unsafe包的典型应用 Go核心团队也没有将unsafe包列入Go 1兼容性的承诺保护范围内，但unsafe包所具有的独一无二的穿透类型安全保护的能力对开发人员依旧充满了诱惑力。标准库和运行时中，reflect、sync、syscall和runtime包都是unsafe包的重度“用户”，这些包有的需要绕过Go类型保护直接操作内存，有的对性能敏感，还有的与操作系统或C语言低级代码交互频繁。 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:3:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"3.1 标准库中的典型应用 reflect ValueOf和TypeOf函数是reflect包中用得最多的两个API，它们是进入运行时反射层、获取反射层信息的入口。这两个函数均将任意类型变量转换为一个interface{}类型变量，再利用unsafe.Pointer将这个变量绑定的内存区域重新解释为reflect.emptyInterface类型，以获得传入变量的类型和值的信息。 。 // $GOROOT/src/reflect/value.go // emptyInterface用于表示一个interface{}类型的值的头部 type emptyInterface struct { typ *rtype word unsafe.Pointer } func ValueOf(i interface{}) Value { ... return unpackEface(i) } // unpackEface将empty interface变量i转换成一个reflect.Value func unpackEface(i interface{}) Value { e := (*emptyInterface)(unsafe.Pointer(\u0026i)) ... return Value{t, e.word, f} } // $GOROOT/src/reflect/type.go // TypeOf返回interface{}类型变量i的动态类型信息 func TypeOf(i interface{}) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026i)) return toType(eface.typ) } syscall 标准库中的syscall包封装了与操作系统交互的系统调用接口，比如Stat、Listen、Select等： // $GOROOT/src/syscall/zsyscall_linux_amd64.go func Listen(s int, n int) (err error) { _, _, e1 := Syscall(SYS_LISTEN, uintptr(s), uintptr(n), 0) if e1 != 0 { err = errnoErr(e1) } return } func Select(nfd int, r *FdSet, w *FdSet, e *FdSet, timeout *Timeval) (n int, err error) { r0, _, e1 := Syscall6(SYS_SELECT, uintptr(nfd), uintptr(unsafe.Pointer(r)), uintptr(unsafe.Pointer(w)), uintptr(unsafe.Pointer(e)), uintptr(unsafe.Pointer(timeout)), 0) n = int(r0) if e1 != 0 { err = errnoErr(e1) } return } 我们看到，这类封装的高级调用最终都会落到调用下面一系列Syscall和RawSyscall函数上： // $GOROOT/src/syscall/syscall_unix.go func Syscall(trap, a1, a2, a3 uintptr) (r1, r2 uintptr, err Errno) func Syscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2 uintptr, err Errno) func RawSyscall(trap, a1, a2, a3 uintptr) (r1, r2 uintptr, err Errno) func RawSyscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2 uintptr, err Errn 而这些Syscall系列函数接受的参数类型均为uintptr，这样当封装的系统调用的参数为指针类型时（比如上面Select的参数r、w、e等），我们只能通过unsafe.Pointer将这些指针指向的地址值转换为uintptr值 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:3:1","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"3.2 第三方库的典型应用 Go binding项目（与不是用Go实现的项目进行集成，如gocv、gotk3等）、网络领域项目和数据库领域项目是unsafe的重度“用户”。unsafe包在这些项目中主要被用于如下两个场景 与操作系统以及非Go编写的代码的通信 高效类型转换 与操作系统以及非Go编写的代码的通信 与操作系统的通信主要通过系统调用进行，这在之前已提过。而与非Go编写的代码的通信则主要通过cgo方式，如下面的示例： func SetIcon(iconBytes []byte) { // 转换成一个C char类型 cstr := (*C.char)(unsafe.Pointer(\u0026iconBytes[0])) // 调用来自systray.h的函数 C.setIcon(cstr, (C.int)(len(iconBytes))) } 高效类型转换 通过unsafe包实现性能更好的类型转换。最常见的类型转换是string与[]byte类型间的相互转换： func Bytes2String(b []byte) string { return *(*string)(unsafe.Pointer(\u0026b)) } func String2Bytes(s string) []byte { // 必须在一个表达式内，原因见 unsafe 的安全使用模式 sh := (*reflect.StringHeader)(unsafe.Pointer(\u0026s)) bh := reflect.SliceHeader{ Data: sh.Data, Len: sh.Len, Cap: sh.Len, } return *(*[]byte)(unsafe.Pointer(\u0026bh)) } 在上面的转换中: string 类型变量是不可变的（immutable），通过常规方法将一个 string 类型变量转换为[]byte类型，Go会为[]byte类型变量分配一块新内存，并将string类型变量的值复制到这块新内存中 通过上面基于unsafe包实现的String2Bytes函数，这种转换并不需要额外的内存复制：转换后的[]byte变量与输入参数中的string类型变量共享底层存储（但注意，我们依旧无法通过对返回的切片的修改来改变原字符串） 将[]byte 变量转换为string类型则更为简单，因为[]byte的内部表示是一个三元组(ptr, len, cap)，string的内部表示为一个二元组(ptr, len)，通过unsafe.Pointer将[]byte的内部表示重新解释为string的内部表示，这就是Bytes2String的原理 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:3:2","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"4. 正确理解unsafe.Pointer与uintptr Go语言内存管理是基于垃圾回收的，垃圾回收例程会定期执行。如果一块内存没有被任何对象引用，它就会被垃圾回收器回收。而对象引用是通过指针实现的。 unsafe.Pointer 与 uintptr: unsafe.Pointer和其他常规类型指针一样，可以作为对象引用。如果一个对象仍然被某个unsafe.Pointer变量引用着，那么该对象是不会被垃圾回收的。 但是uintptr并不是指针，它仅仅是一个整型值，即便它存储的是某个对象的内存地址，它也不会被算作对该对象的引用。如果认为将对象地址存储在一个uintptr变量中，该对象就不会被垃圾回收器回收，那就是对uintptr的最大误解。 使用uintptr类型变量保存栈上变量的地址同样是有风险的，因为Go使用的是连续栈的栈管理方案，每个goroutine的默认栈大小为2KB（_StackMin = 2048）。当goroutine当前剩余栈空间无法满足函数/方法调用对栈空间的需求时，Go运行时就会新分配一块更大的内存空间作为该goroutine的新栈空间，并将该goroutine的原有栈整体复制过来，这样原栈上分配的变量的地址就会发生变化。unsafe.Pointer 类型变量的值会被 Go 运行时做同步变更；但 uintptr 类型变量只是一个整型值，它的值是不变的。 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:4:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5. unsafe.Pointer的安全使用模式 Go（1.14版本）在unsafe的文档中定义了6条安全使用模式: ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.1 模式 1 使用: *T1 -\u003e unsafe.Pointer -\u003e *T2 作用: 本质就是内存块的重解释：将原本解释为T1类型的内存重新解释为T2类型 注意: 不能忽略内存对齐问题，转换后类型T2的对齐系数不能比转换前类型T1的对齐系数更严格，即Alignof(T1) \u003e= Alignof(T2) // 1. 模式 1 // $GOROOT/src/math/unsafe.go func Float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(\u0026f)) } ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:1","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.2 模式 2 使用: unsafe.Poiner -\u003e uintptr 作用: 就是将unsafe.Pointer显式转换为uintptr，并且转换后的uintptr类型变量不会再转换回unsafe.Pointer，只用于打印输出，并不参与其他操作。 // 1. 模式 2 var x = [10]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 0} var p = uintptr(unsafe.Pointer(\u0026x)) println(p) ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:2","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.3 模式 3 使用: unsafe.Pointer(uintptr(unsafe.Pointer(\u0026b)) + offset) 作用: 模拟指针运算，用于访问结构体内字段或数组中的元素，也常用于实现对某内存对象的步进式检查 注意: 不要越界 unsafe.Pointer -\u003e uintptr -\u003e unsafe.Pointer的转换要在一个表达式中 // 访问数组a的第4个元素 var p = unsafe.Pointer(uintptr(unsafe.Pointer(\u0026a)) + 3*unsafe.Sizeof(a[0])) fmt.Println(*(*int)(p)) // 4 // 访问Foo结构体的字段c p = unsafe.Pointer(uintptr(unsafe.Pointer(\u0026foo)) + unsafe.Offsetof(foo.c)) fmt.Println(*(*float64)(p)) // 3.1415 // 对数组a的第一个元素进行逐字节步进式检查 for i := uintptr(0); i \u003c unsafe.Sizeof((*int)(nil)); i++ { p = unsafe.Pointer(uintptr(unsafe.Pointer(\u0026a)) + i) fmt.Printf(\"0x%x\\n\", *(*byte)(p)) } 下面是一个存在风险的例子： func NewArray() *[10]int { a := [10]int{10, 11, 12, 13, 14, 15, 16, 17, 18, 19} return \u0026a } func main() { a := uintptr(unsafe.Pointer(NewArray())) // 存在风险：这个时间空隙，GC可能随时回收掉NewArray()返回的数组实例 p := unsafe.Pointer(a + unsafe.Sizeof(int(0))) fmt.Printf(\"%d\\n\", *(*int)(p)) // 输出：??? } // 正确做法 func main() { p := unsafe.Pointer(uintptr(unsafe.Pointer(NewArray())) + unsafe.Sizeof(int(0))) fmt.Printf(\"%d\\n\", *(*int)(p)) // 11 } unsafe.Pointer -\u003e uintptr -\u003e unsafe.Pointer的转换不在一个表达式中。NewArray函数返回的数组对象在转换为 uintptr 后已经失去了所有对其的引用，它随时可能被GC回收掉。正确的处理方式是将这两次转换放在一个表达式中，Go编译器会保证两次转换期间NewArray函数返回的数组对象的有效性 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:3","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.4 模式 4 使用: 调用syscall.Syscall系列函数时指针类型到uintptr类型参数的转换 作用: 特定用法 注意: 转换要在一个表达式中 Go标准库的syscall包的Syscall系列函数的参数都是uintptr类型，就像下面这样： // $GOROOT/src/syscall/syscall_unix.go func Syscall(trap, a1, a2, a3 uintptr) (r1, r2 uintptr, err Errno) func Syscall6(trap, a1, a2, a3, a4, a5, a6 uintptr) (r1, r2 uintptr, err Errno) 要传给Syscall系列函数的变量的类型为指针，那么我们就需要将其转换为uintptr类型。下面是不安全的做法： var p *T // 待传给Syscall系列函数的指针变量 ... a := uintptr(unsafe.Pointer(p)) syscall.Syscall(SYS_READ, uintptr(fd), a, uintptr(n)) 不能保证传入的a值所表示的内存地址上对象的有效性，这个内存对象很可能已经在某个时间被GC回收掉或者在栈扩张或收缩时内存对象的地址发生了变更。正确的做法是将转换操作放入Syscall的参数表达式中，Go编译器会识别出这种特殊的使用模式，并保证在这个转换过程中原内存对象（p）的有效性。 var p *T // 待传给Syscall系列函数的指针变量 syscall.Syscall(SYS_READ, uintptr(fd), uintptr(unsafe.Pointer(p)), uintptr(n)) ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:4","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.5 模式 5 将reflect.Value.Pointer或reflect.Value.UnsafeAddr转换为指针 Go标准库的reflect包的Value类型有两个返回uintptr类型值的方法： // $GOROOT/src/reflect/value.go func (v Value) Pointer() uintptr func (v Value) UnsafeAddr() uintptr unsafe包文档中明确了reflect.Value.Pointer或reflect.Value.UnsafeAddr返回值的安全转换方法：和模式3一样，在一个表达式中完成转换，而不要将返回值赋值给一个uintptr类型变量再在后续的语句中进行转换。 // 错误! 在两条语句的执行间隙，T类型对象可能被垃圾回收 u := reflect.ValueOf(new(T)).Pointer() p := (*T)(unsafe.Pointer(u)) // 正确 p := (*T)(unsafe.Pointer(reflect.ValueOf(new(T)).Pointer())) ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:5","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"5.6 模式 6 reflect.SliceHeader和reflect.StringHeader必须通过模式1构建 reflect包的SliceHeader和StringHeader两个结构体分别代表着切片类型和string类型的内存表示。可以通过模式1的内存块重解释来构造这两个结构体类型的实例。 type SliceHeader struct { Data uintptr Len int Cap int } type StringHeader struct { Data uintptr Len int } 下面示例代码中通过 模式1构建的reflect.SliceHeader实例bh对newSlice返回的切片对象具有对象引用作用，这样可以保证newSlice返回的对象不会被垃圾回收掉，后续反向转换成*[]byte依旧有效。 func newSlice() *[]byte { var b = []byte(\"hello, gopher\") return \u0026b } func main() { // 注意虽然 SliceHeader 中的 Data 是 uintptr，但是使用模式 1 的转换，引用依然有效 bh := (*reflect.SliceHeader)(unsafe.Pointer(newSlice())) // 模式1 var p = (*[]byte)(unsafe.Pointer(bh)) fmt.Printf(\"%q\\n\", *p) // \"hello, gopher\" var a = [...]byte{'I', ' ', 'l', 'o', 'v', 'e', ' ', 'G', 'o', '!', '!'} bh.Data = uintptr(unsafe.Pointer(\u0026a)) bh.Len = len(a) bh.Cap = len(a) fmt.Printf(\"%q\\n\", *p) // \"I love Go!!\" } 如果通过常规语法定义一个reflect.SliceHeader类型实例并赋值，那么后续反向转换成*[]T时存在SliceHeader.Data的值对应的地址上的对象已经被回收的风险： func finalizer(p *[11]byte) { fmt.Println(\"数组对象被垃圾回收\") } func newArray() *[11]byte { var a = [...]byte{'I', ' ', 'l', 'o', 'v', 'e', ' ', 'G', 'o', '!', '!'} runtime.SetFinalizer(\u0026a, finalizer) return \u0026a } func main() { var bh reflect.SliceHeader // 这一步转换之后，newArray() 返回的数组就已经没有对象引用了 bh.Data = uintptr(unsafe.Pointer(newArray())) bh.Len = 11 bh.Cap = 11 var p = (*[]byte)(unsafe.Pointer(\u0026bh)) for i := 0; i \u003c 3; i++ { runtime.GC() // 数组对象在此处被垃圾回收 time.Sleep(1 * time.Second) } fmt.Printf(\"%q\\n\", *p) // } 这种错误非常隐蔽，在 Go1.20 起，在 unsafe 标准库新增了 3 个函数来替代前面这两个类型的使用: func String(ptr *byte, len IntegerType) string：根据数据指针和字符长度构造一个新的 string。 func StringData(str string) *byte：返回指向该 string 的字节数组的数据指针。 func SliceData(slice []ArbitraryType) *ArbitraryType：返回该 slice 的数据指针。 func Slice(ptr *ArbitraryType, len IntegerType) []ArbitraryType 新版本的用法将会变成： func StringToBytes(s string) []byte { return unsafe.Slice(unsafe.StringData(s), len(s)) } func BytesToString(b []byte) string { return unsafe.String(\u0026b[0], len(b)) } ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:5:6","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"6. unsafe 包的安全使用检查 Go核心团队一直在完善工具链，加强对代码中unsafe使用安全性的检查。通过go vet可以检查unsafe.Pointer和uintptr之间的转换是否符合上述六种安全模式。 Go 1.14编译器在-race 或 -msan命令行选型开启的情况下，会执行 -d=checkptr 检查，即对unsafe.Pointer进行下面两项合规性检查。 当将*T1类型按模式1通过 unsafe.Pointer 转换为 *T2 时，T2的内存地址对齐系数不能高于T1的对齐系数。 做完指针运算后，转换后的unsafe.Pointer仍应指向原先的内存对象，相当于越界检查。 func main() { var n = 5 b := make([]byte, n) end := unsafe.Pointer(uintptr(unsafe.Pointer(\u0026b[0])) + uintptr(n+10)) _ = end } // 使用-race选项运行的结果如下（Ubuntu 18.04）： $go run -race go_unsafe_compile_checkptr.go fatal error: checkptr: unsafe pointer arithmetic ... exit status 2 ","date":"2023-01-09","objectID":"/posts/program/go/expert/go_export/expert_17/:6:0","tags":["go 进阶"],"title":"Go unsafe包的安全使用模式","uri":"/posts/program/go/expert/go_export/expert_17/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"Go是自带运行时的跨平台编程语言，Go中暴露给语言使用者的TCP Socket接口是建立在操作系统原生TCP Socket接口之上的。由于Go运行时调度的需要，Go设计了一套适合自己的TCP Socket网络编程模型。在本条中我们就来理解一下这个模型，并了解在该模型下Go TCP Socket在各个场景下的使用方法、行为特点及注意事项。 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:0:0","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"1. TCP Socket网络编程模型 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:1:0","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"1.1 常见的网络 I/O 模型 网络I/O模型定义的是应用线程与操作系统内核之间的交互行为模式。我们通常用阻塞（Blocking）和非阻塞（Non-Blocking）来描述网络I/O模型。不同标准对于网络I/O模型的说法有所不同，比如POSIX.1标准还定义了同步（Sync）和异步（Async）这两个术语来描述模型。 阻塞和非阻塞是以内核是否等数据全部就绪才返回（给发起系统调用的应用线程）来区分的。常用的网络I/O模型包括如下几种。 阻塞I/O模型: 在这样的模型下，所有Socket默认都是阻塞的。一个线程仅能处理一个网络连接上的数据通信 非阻塞I/O模型: 在非阻塞模型下，在用户空间线程向操作系统内核发起I/O请求后，如果此刻数据尚未就绪，则会立即将“未就绪”的状态以错误码形式（如EAGAIN/EWOULDBLOCK）返回给此次I/O系统调用的发起者 用户会通过轮询的方式一次次发起I/O请求，直到读到所需的数据 阻塞的Socket默认可以通过fcntl调用转变为非阻塞Socket I/O多路复用模型: 在该模型下，应用线程首先将需要进行I/O操作的Socket都添加到多路复用函数中（这里以select为例），接着阻塞，等待select系统调用返回 当内核发现有数据到达时，对应的Socket具备通信条件，select函数返回。然后用户线程针对该Socket再次发起网络I/O请求（如read）。由于数据已就绪，因此即便Socket是阻塞的，第二次网络I/O操作也非常快。 塞模型一个线程仅能处理一个Socket，而在I/O多路复用模型中，应用线程可以同时处理多个Socket；虽然可同时处理多个Socket，但I/O多路复用模型由内核实现可读/可写事件的通知，避免了非阻塞模型中轮询带来的CPU计算资源的浪费。 异步I/O模型 ，用户应用线程发起异步I/O调用后，内核将启动等待数据的操作并马上返回。之后，用户应用线程可以继续执行其他操作，既无须阻塞，也无须轮询并再次发起I/O调用。 在内核空间数据就绪并被从内核空间复制到用户空间后，内核会主动生成信号以驱动执行用户线程在异步I/O调用时注册的信号处理函数，或主动执行用户线程注册的回调函数，让用户线程完成对数据的处理。 阻塞I/O模型 非阻塞I/O模型 I/O多路复用模型 异步I/O模型 有些标准使用同步和异步来描述网络I/O操作模型。所谓同步I/O指的是能 ** 引起请求线程阻塞 ** ，直到I/O操作完成；而异步I/O则不引起请求线程的阻塞。按照这个说法，前面提到的阻塞I/O、非阻塞I/O、I/O多路复用均可看成同步I/O模型，而只有异步I/O才是名副其实的“异步I/O”模型。 相较于上述几个模型，异步I/O模型受各个平台的支持程度不一，且使用起来复杂度较高，在如何进行内存管理、信号处理/回调函数等逻辑设计上会给开发人员带来不小的心智负担。 目前主流网络服务器采用的多是I/O多路复用模型，有的也结合了多线程。不过I/O多路复用模型在支持更多连接、提升I/O操作效率的同时，也给使用者带来了不低的复杂性，以至于出现了许多高性能的I/O多路复用框架（如libevent、libev、libuv等）以降低开发复杂性，减轻开发者的心智负担。 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:1:1","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"1.2 Go 的网络I/O模型 Go语言的设计者认为I/O多路复用的这种通过 ** 回调割裂控制流的模型 ** 依旧复杂，且有悖于一般顺序的逻辑设计，为此他们结合Go语言的自身特点，将该“复杂性”隐藏在了Go运行时中。这样，在大多数情况下，Go开发者无须关心Socket是不是阻塞的，也无须亲自将Socket文件描述符的回调函数注册到类似select这样的系统调用中，而只需在每个连接对应的goroutine中以最简单、最易用的阻塞I/O模型的方式进行Socket操作即可，这种设计大大减轻了网络应用开发人员的心智负担。 一个典型的Go网络服务端程序大致如下： func handleConn(c net.Conn) { defer c.Close() for { // 从连接上读取数据 // ... // 向连接上写入数据 // ... } } func main() { l, err := net.Listen(\"tcp\", \":8888\") if err != nil { fmt.Println(\"listen error:\", err) return } for { c, err := l.Accept() if err != nil { fmt.Println(\"accept error:\", err) break } // 启动一个新的goroutine处理这个新连接 go handleConn(c) } } 在 ** Go程序的用户层 ** （相对于Go运行时层）看来，goroutine采用了“阻塞I/O模型”进行网络I/O操作，Socket都是“阻塞”的。但实际上，这样的假象是Go运行时中的 ** netpoller（网络轮询器） ** 通过I/O多路复用机制模拟出来的，对应的底层操作系统Socket实际上是非阻塞的： // $GOROOT/src/net/sock_cloexec.go func sysSocket(family, sotype, proto int) (int, error) { ... if err = syscall.SetNonblock(s, true); err != nil { poll.CloseFunc(s) return -1, os.NewSyscallError(\"setnonblock\", err) } ... } ** 运行时拦截了针对底层Socket的系统调用返回的错误码，并通过netpoller和goroutine调度让goroutine“阻塞”在用户层所看到的Socket描述符上。比如：当用户层针对某个Socket描述符发起read操作时，如果该Socket对应的连接上尚无数据，那么Go运行时会将该Socket描述符加入netpoller中监听，直到Go运行时收到该Socket数据可读的通知，Go运行时才会重新唤醒等待在该Socket上准备读数据的那个goroutine。而这个过程从goroutine的视角来看，就像是read操作一直阻塞在那个Socket描述符上似的。 ** Go语言在netpoller中采用了I/O多路复用模型。Go运行时会选择在不同操作系统上使用操作系统各自实现的高性能多路复用函数，比如Linux上的epoll、Windows上的iocp、FreeBSD/macOS上的kqueue、Solaris上的event port等，这样可以最大限度地提高netpoller的调度和执行性能。 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:1:2","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"2. Go Tcp Socket 使用 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:2:0","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"2.1 TCP连接的建立 在连接的建立过程中，服务端是一个标准的Listen+Accept的结构（可参考上面的代码），而在客户端Go语言使用Dial或DialTimeout函数发起连接建立请求。 // Dial在调用后将一直阻塞，直到连接建立成功或失败。 conn, err := net.Dial(\"tcp\", \"taobao.com:80\") if err != nil { // 处理错误 } // DialTimeout是带有超时机制的Dial： conn, err := net.DialTimeout(\"tcp\", \"localhost:8080\", 2 * time.Second) if err != nil { // 处理错误 } // 连接建立成功，可以进行读写操作 对于客户端而言，建立连接时可能会遇到如下几种情形: 络不可达或对方服务未启动: Dial几乎会立即返回错误，报 “getsockopt: connection refused” 错误 对方服务的listen backlog队列满了 Dial调用阻塞 通常，即便服务端不调用accept接收客户端连接，在backlog数量范围之内，客户端的连接操作也都是会成功的，因为新的连接已经加入服务端的内核listen队列中了，accept操作只是从这个队列中取出一个连接而已。 也就是说在服务端 backlog 满时（未及时执行accept操作），客户端将阻塞在Dial调用上，直到服务端执行一次accept操作（从backlog队列中腾出一个槽位）。 backlog 队列的长度与系统设置有关，linux 上这个参数是 net.ipv4.tcp_max_syn_backlog 若网络延迟较大 Dial将阻塞并超时，报“getsockopt: operation timed out”的错误 DialTimeout函数可以设置 Dail 最长阻塞时间: net.DialTimeout(\"tcp\", \"105.236.176.96:80\", 2*time.Second) ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:2:1","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"2.2 Socket读写 Dial连接成功后会返回一个net.Conn接口类型的变量值，TCPConn内嵌了一个非导出类型conn。TCPConn.Read/TCPConn.Write 调用的都是 conn 的Read/Write 方法。 //$GOROOT/src/net/tcpsock_posix.go type TCPConn struct { conn } //$GOROOT/src/net/net.go type conn struct { fd *netFD } func (c *conn) ok() bool { return c != nil \u0026\u0026 c.fd != nil } func (c *conn) Read(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Read(b) if err != nil \u0026\u0026 err != io.EOF { err = \u0026OpError{Op: \"read\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } func (c *conn) Write(b []byte) (int, error) { if !c.ok() { return 0, syscall.EINVAL } n, err := c.fd.Write(b) if err != nil { err = \u0026OpError{Op: \"write\", Net: c.fd.net, Source: c.fd.laddr, Addr: c.fd.raddr, Err: err} } return n, err } conn.Read Socket中无数据: 接建立后，如果客户端未发送数据，服务端会阻塞在Socket的读操作上，Go运行时会监视该Socket，直到其有数据读事件才会重新调度该Socket对应的goroutine完成读操作 Socket中有部分数据: 如果Socket中有部分数据就绪，且数据数量小于一次读操作所期望读出的数据长度，那么读操作将会成功读出这部分数据并返回，而不是等待期望长度数据全部读取后再返回 Socket中有足够多的数据: 如果连接上有数据，且数据长度大于或等于一次Read操作所期望读出的数据长度，那么Read将会成功读出这部分数据并返回 Socket关闭: 如果 Socket中还有服务端尚未读取的数据，Read 会正常读取数据，第二次 Read 操作时返回错误EOF（代表连接断开） 读操作超时: 在返回超时错误时，是否也同时读出了一部分数据 成功写: Write调用返回的n与预期要写入的数据长度相等，且error = nil 写阻塞: TCP通信连接两端的操作系统内核都会为该连接保留数据缓冲区，一端调用Write后，实际上数据是写入操作系统协议栈的数据缓冲区中的。TCP是全双工通信，因此每个方向都有独立的数据缓冲区。当发送方将对方的接收缓冲区及自身的发送缓冲区都写满后，Write调用就会阻塞。 写入部分数据: 写入的部分数据对端可能未接受，需要特殊处理 写入超时: conn.SetWriteDeadline(time.Now().Add(time.Microsecond * 10)) 可以设置写入超时，超时会出现数据部分写入，在调用Read和Write时依旧要结合这两个方法返回的n和err的结果来做出正确处理 conn的读写并发安全性 conn的读写是不是goroutine并发安全的呢？这个问题需要深入研究一下运行时代码。 net.conn只是*netFD的外层包裹结构，最终Write和Read都会落在其中的fd字段上： //$GOROOT/src/net/net.go type conn struct { fd *netFD } netFD在不同平台上有着不同的实现，这里以net/fd_unix.go中的netFD为例： // $GOROOT/src/net/fd_unix.go // 网络文件描述符 type netFD struct { // sysfd的锁，保证读写顺序进行 fdmu fdMutex ... } netFD类型中包含一个运行时实现的fdMutex类型字段，所有对conn的Read和Write操作都是由fdMutex来同步的: // $GOROOT/src/net/fd_unix.go func (fd *netFD) Read(p []byte) (n int, err error) { if err := fd.readLock(); err != nil { return 0, err } defer fd.readUnlock() if err := fd.pd.PrepareRead(); err != nil { return 0, err } for { n, err = syscall.Read(fd.sysfd, p) if err != nil { n = 0 if err == syscall.EAGAIN { if err = fd.pd.WaitRead(); err == nil { continue } } } err = fd.eofError(n, err) break } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"read\", err) } return } func (fd *netFD) Write(p []byte) (nn int, err error) { if err := fd.writeLock(); err != nil { return 0, err } defer fd.writeUnlock() if err := fd.pd.PrepareWrite(); err != nil { return 0, err } for { var n int n, err = syscall.Write(fd.sysfd, p[nn:]) if n \u003e 0 { nn += n } if nn == len(p) { break } if err == syscall.EAGAIN { if err = fd.pd.WaitWrite(); err == nil { continue } } if err != nil { break } if n == 0 { err = io.ErrUnexpectedEOF break } } if _, ok := err.(syscall.Errno); ok { err = os.NewSyscallError(\"write\", err) } return nn, err } ** 每次Write操作都是受锁保护的，直到此次数据全部写完。因此在应用层面，要想保证多个goroutine在一个conn上的Write操作是安全的，需要让每一次Write操作完整地写入一个业务包。 ** Read操作，也是有锁保护的。多个goroutine对同一conn的并发读不会出现读出内容重叠的情况，但内容断点是依运行时调度来随机确定的。存在一个业务包数据三分之一的内容被goroutine-1读走，而另三分之二被goroutine-2读走的情况。 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:2:2","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"2.3 Socket属性 原生Socket API提供了丰富的sockopt设置接口，Go提供的socket options接口也是基于上述模型的必要的属性设置，包括SetKeepAlive、SetKeep-AlivePeriod、SetLinger、SetNoDelay （默认为no delay）、SetWriteBuffer、SetReadBuffer。不过这些方法是TCPConn类型的，而不是Conn类型的。要使用上面的方法，需要进行类型断言（type assertion）操作： tcpConn, ok := c.(*TCPConn) if !ok { // 错误处理 } tcpConn.SetNoDelay(true) 对于listener的监听Socket，Go默认设置了SO_REUSEADDR，这样当你重启服务程序时，不会因为address in use的错误而重启失败。 ","date":"2023-01-08","objectID":"/posts/program/go/expert/go_export/expert_16/:2:3","tags":["go 进阶"],"title":"Go 网络编程","uri":"/posts/program/go/expert/go_export/expert_16/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-06","objectID":"/posts/program/go/expert/go_export/expert_14/","tags":["go 进阶"],"title":"Go 调度器","uri":"/posts/program/go/expert/go_export/expert_14/"},{"categories":["Go"],"content":"今天我们来学习一些 Go 程序的调试技巧。 ","date":"2023-01-06","objectID":"/posts/program/go/expert/go_export/expert_14/:0:0","tags":["go 进阶"],"title":"Go 调度器","uri":"/posts/program/go/expert/go_export/expert_14/"},{"categories":["Go"],"content":"1. 调度器状态的查看方法 Go提供了调度器当前状态的查看方法：使用Go运行时环境变量GODEBUG。 $ GODEBUG=schedtrace=1000 godoc -http=:6060 SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=3 spinningthreads=0 idlethreads=0 runqueue=0 [0 0 0 0] SCHED 1001ms: gomaxprocs=4 idleprocs=0 threads=9 spinningthreads=0 idlethreads=3 runqueue=2 [8 14 5 2] SCHED 2006ms: gomaxprocs=4 idleprocs=0 threads=25 spinningthreads=0 idlethreads=19 runqueue=12 [0 0 4 0] SCHED 3006ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=8 runqueue=2 [0 1 1 0] SCHED 4010ms: gomaxprocs=4 idleprocs=0 threads=26 spinningthreads=0 idlethreads=20 runqueue=12 [6 3 1 0] GODEBUG 通过给其传入不同的key1=value1, key2=value2, …组合，Go的运行时会输出不同的调试信息，比如在这里我们给GODEBUG传入了\"schedtrace=1000\"，其含义就是每1000ms打印输出一次goroutine调度器的状态，每次一行。以上面例子中最后一行为例，每一行各字段含义如下： SCHED：调试信息输出标志字符串，代表本行是goroutine调度器相关信息的输出。 6016ms：从程序启动到输出这行日志经过的时间。 gomaxprocs：P的数量。 idleprocs：处于空闲状态的P的数量。通过gomaxprocs和idleprocs的差值，我们就可以知道当前正在执行Go代码的P的数量。 threads：操作系统线程的数量，包含调度器使用的M数量，加上运行时自用的类似sysmon这样的线程的数量。 spinningthreads：处于自旋（spin）状态的操作系统数量。 idlethread：处于空闲状态的操作系统线程的数量。 runqueue=1：Go调度器全局运行队列中G的数量。 [3 4 0 10]：分别为4个P的本地运行队列中的G的数量。 还可以输出每个goroutine、M和P的详细调度信息（对于Gopher来说，在大多数情况下这是不必要的）： $ GODEBUG=schedtrace=1000,scheddetail=1 godoc -http=:6060 ","date":"2023-01-06","objectID":"/posts/program/go/expert/go_export/expert_14/:1:0","tags":["go 进阶"],"title":"Go 调度器","uri":"/posts/program/go/expert/go_export/expert_14/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-05","objectID":"/posts/program/go/expert/go_export/expert_13/","tags":["go 进阶"],"title":"Go 汇编反汇编","uri":"/posts/program/go/expert/go_export/expert_13/"},{"categories":["Go"],"content":"1. 查看Go程序的汇编代码 查看Go程序的汇编代码有多种方法： 使用objdump工具：objdump -S go二进制文件 使用gdb disassemble 使用go tool工具生成汇编代码文件：go build -gcflags '-S' xx.go \u003e xx.s 2\u003e\u00261 将Go代码编译成汇编代码：go tool compile -S xx.go \u003e xx.s 使用go tool工具反编译Go程序：go tool objdump -S go-binary \u003e xx.s // 编译 GOARCH=386 go tool compile -N -l test.go // 反编译 GOARCH=386 go tool objdump -gnu test.o ","date":"2023-01-05","objectID":"/posts/program/go/expert/go_export/expert_13/:1:0","tags":["go 进阶"],"title":"Go 汇编反汇编","uri":"/posts/program/go/expert/go_export/expert_13/"},{"categories":["Go"],"content":"交叉编译 GOOS=linux GOARCH=amd64 go build // 交叉编译支持的所有架构 $GOROOT/src/go/build/syslist.go ","date":"2023-01-05","objectID":"/posts/program/go/expert/go_export/expert_13/:2:0","tags":["go 进阶"],"title":"Go 汇编反汇编","uri":"/posts/program/go/expert/go_export/expert_13/"},{"categories":["Go"],"content":"参考资料 Debugging Performance Issues in Go Programs go.dev/doc/diagnostics go-perfbook talk-yapc-asia-2015 ","date":"2023-01-05","objectID":"/posts/program/go/expert/go_export/expert_13/:3:0","tags":["go 进阶"],"title":"Go 汇编反汇编","uri":"/posts/program/go/expert/go_export/expert_13/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"1. 专业调试工具 bug是表象，要发现内部原因需要利用更多的表象数据去推理，需要收集足够多的“现场数据”。我们可以通过编程语言内置的输出语句（如Go的print、fmt.Printf等）输出我们需要的信息，而更为专业的方法是通过编程语言提供的专业调试工具（如GDB）设置断点来采集现场数据或重现bug。 尽管使用 print 输出调试信息更加简单快捷、灵活直观且无须对外部有任何依赖。但专业调试器可以运用在“print辅助调试”无法胜任的场景下，比如： 与IDE集成，通过图形化操作可大幅简化专业调试器的调试循环，提供更佳的体验； 事后调查（postmortem） 调试core dump文件； 在生产环境通过挂接（attach）应用进程，深入应用进程内部进行调试。 语言内置的print语句辅助调试与采用专门的调试器调试代码是相辅相成的，并非对立关系。 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:1:0","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"1.1 gccgo Go发行版中，除了标准的Go编译器之外，还有一个名为gccgo的编译器。和标准Go编译器相比，gccgo具有如下特点： gccgo是GCC编译器的新前端； Go语言由Go语言规范定义和驱动演进，gccgo是另一个实现了该语言规范的编译器，但与标准Go编译器实现的侧重点有所不同； gccgo编译速度较慢，但具有更为强大的优化能力； gccgo复用了GCC后端，因此支持的处理器架构更多； gccgo的演进速度与标准Go编译器的速度并不一致，按照最新官方文档，gcc8等价于go 1.10.1的实现，而gcc9等价于Go 1.12.2的实现。 通过gccgo编译而成的Go程序可以得到GCC成熟工具链集合的原生支持，包括使用强大的GDB进行调试。但由于gccgo不是主流，因此我们这里考虑的是基于标准Go编译器编译的代码的调试。 那么GDB调试器是否可以调试通过标准Go编译器编译生成的Go程序呢？答案是肯定的。但GDB对标准Go编译器输出的程序的支持是不完善的，主要体现在GDB并不十分了解Go程序： Go的栈管理、线程模型、运行时等与GDB所了解的执行模型有很大不同，这会导致GDB在调试过程中输出错误的结果，尤其是针对拥有大量并发的Go程序时，GDB并不是一个可靠的调试器； 使用复杂，需加载插件（$GOROOT/src/runtime/runtime-gdb.py）才能更好地理解Go符号； GDB无法理解一些Go类型信息、名称限定等，导致输出的栈信息和打印的变量类型信息难于识别、查看和分析； Go 1.11后，编译后的可执行文件中调试信息默认是压缩的，低版本的GDB无法加载这些压缩的调试信息，除非显式使用go build -ldflags=-compressdwarf=false 设置不执行调试信息压缩。 综上，GDB显然也不是Go调试工具的最佳选择，虽然其适用于调试带有cgo代码的Go程序或事后调查调试。 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:1:1","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"1.2 Delve Delve是另一个Go语言调试器，旨在为Go提供一个简单、功能齐全、易用使用和调用的调试工具。它紧跟Go语言版本演进，是目前Go调试器的事实标准。和GDB相比，Delve的优势在于 它可以更好地理解Go的一切，对并发程序有着很好的支持 支持跨平台（支持Windows、macOS、Linux三大主流平台） 前后端分离的设计使得它可以非常容易地被集成到各种IDE（如GoLand）、编译器插件（vscode go、vim-go等）、图形化调试器前端（如gdlv）中 接下来，我们就来看看如何使用Delve调试Go程序。 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:1:2","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"2. Delve ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:2:0","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"2.1 Delve 使用 下面是一个使用 Delve 调试本地程序的示例: // 1. 安装 $go get github.com/go-delve/delve/cmd/dlv $dlv version Delve Debugger Version: 1.4.1 Build: $Id: bda606147ff48b58bde39e20b9e11378eaa4db4 // 2. 示例代码结构 // delve-demo1/ $tree . . ├── cmd │ └── delve-demo1 │ └── main.go ├── go.mod └── pkg └── foo └── foo.go // 3. 开始调试 $cd delve-demo1 // 执行dlv后，dlv会对被调试Go包进行编译并在当前工作目录下生成一个临时的二进制文件用于调试 $dlv debug github.com/bigwhite/delve-demo1/cmd/delve-demo1 // 3.1 查看代码 (dlv) list main.go:12 (dlv) list foo.Foo // 3.2 设置/查看断点 (dlv) b main.go:12 // 设置匿名断点 (dlv) b b1 main.go:13 // 设置具名断点 (dlv) bp // breakpoints命令（简写为bp）可以查看已设置的断点列表 (dlv) clear b1 // 删除具名断点 (dlv) clear 2 // 删除匿名断点 (dlv) b b1 main.go:12 Breakpoint b1 set at 0x4967aa for main.main() ./main.go:12 (dlv) bp Breakpoint runtime-fatal-throw (enabled) at 0x434cc0 for runtime.throw() /usr/local/go/src/runtime/panic.go:982 (0) Breakpoint unrecovered-panic (enabled) at 0x435080 for runtime.fatalpanic() /usr/local/go/src/runtime/panic.go:1065 (0) print runtime.curg._panic.arg Breakpoint b1 (enabled) at 0x4967aa for main.main() ./main.go:12 (0) // b1 设置的名称 (dlv) clear b1 Breakpoint b1 cleared at 0x4967aa for main.main() ./main.go:12 (dlv) b main.go:12 Breakpoint 2 set at 0x4967aa for main.main() ./main.go:12 (dlv) bp Breakpoint runtime-fatal-throw (enabled) at 0x434cc0 for runtime.throw() /usr/local/go/src/runtime/panic.go:982 (0) Breakpoint unrecovered-panic (enabled) at 0x435080 for runtime.fatalpanic() /usr/local/go/src/runtime/panic.go:1065 (0) print runtime.curg._panic.arg Breakpoint 2 (enabled) at 0x4967aa for main.main() ./main.go:12 (0) // 2 是匿名的断点序号 (dlv) clear 2 Breakpoint 2 cleared at 0x4967aa for main.main() ./main.go:12 // 3.3 条件断点 // 条件断点，指的就是当满足某个条件时，被调试的目标程序才会在该断点处暂停 (dlv) b b2 foo.go:6 (dlv) cond b2 sum \u003e 10 // 3.4 执行和调试 (dlv) bp Breakpoint runtime-fatal-throw (enabled) at 0x434cc0 for runtime.throw() /usr/local/go/src/runtime/panic.go:982 (0) Breakpoint unrecovered-panic (enabled) at 0x435080 for runtime.fatalpanic() /usr/local/go/src/runtime/panic.go:1065 (0) print runtime.curg._panic.arg Breakpoint 1 (enabled) at 0x4967aa for main.main() ./main.go:12 (0) Breakpoint b2 (enabled) at 0x496749 for github.com/bigwhite/delve-demo1/pkg/foo.Foo() /home/tao/code/github/GoProgrammingFromBeginnerToMaster/chapter8/sources/delve-demo1/pkg/foo/foo.go:6 (0) cond sum \u003e 10 (dlv) c // continue命令（简写 c）执行程序，程序会在下一个断点处停下来，没有断点，程序运行到结束 \u003e main.main() ./main.go:12 (hits goroutine(1):1 total:1) (PC: 0x4967aa) 7: ) 8: 9: func main() { 10: a := 3 11: b := 10 =\u003e 12: c := foo.Foo(a, b) 13: fmt.Println(c) 14: } (dlv) s // step 命令（简写 s）单步调试，如果断点处有函数调用，step命令会进入断点所在行调用的函数 \u003e github.com/bigwhite/delve-demo1/pkg/foo.Foo() /home/tao/code/github/GoProgrammingFromBeginnerToMaster/chapter8/sources/delve-demo1/pkg/foo/foo.go:3 (PC: 0x496700) 1: package foo 2: =\u003e 3: func Foo(step, count int) int { 4: sum := 0 5: for i := 0; i \u003c count; i++ { 6: sum += step 7: } 8: return sum (dlv) n // next 命令（简写 n）单步调试，让程序执行到下一行代码 \u003e github.com/bigwhite/delve-demo1/pkg/foo.Foo() /home/tao/code/github/GoProgrammingFromBeginnerToMaster/chapter8/sources/delve-demo1/pkg/foo/foo.go:4 (PC: 0x496720) 1: package foo 2: 3: func Foo(step, count int) int { =\u003e 4: sum := 0 5: for i := 0; i \u003c count; i++ { 6: sum += step 7: } 8: return sum 9: } (dlv) r // restart 命令（简写 r），重启程序 Process restarted with PID 43945 // 3.5 查看变量值 (dlv) c \u003e [b2] github.com/bigwhite/delve-demo1/pkg/foo.Foo() /home/tao/code/github/GoProgrammingFromBeginnerToMaster/chapter8/sources/delve-demo1/pkg/foo/foo.go:6 (hits goroutine(1):1 total:1) (PC: 0x496749) 1: package foo 2: 3: func Foo(step, count int) int { 4: sum := 0 5: for i := 0; i \u003c count; i++ { =\u003e 6: sum += step 7: } 8: return sum 9: } (dlv) args // 当前函数栈参数和返回值列表（包括参数和返回值的值） step = 3 count = 10 ~r0 = 0 (dlv) locals // 当前函数栈本地变量列表（包括变量的值） sum = 12 i = 4 (dlv) regs // 当前寄存器中的值 Rip = 0x0000000000496749 Rsp = 0x000000c000051ee0 Rax = 0x0000000000000003 Rbx = 0x000000000000000a Rcx = 0x0000000000000004 Rdx = 0x00000000004b4f68 Rsi = ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:2:1","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"2.2 Delve 启动方式 Delve 启动方式有多种: # 第一种: 就是上面使用的，调试包 $cd delve-demo1 $dlv debug github.com/bigwhite/delve-demo1/cmd/delve-demo1 # 第二种: 直接调试源码文件的方式启动调试流程，这样的方式与调试包是等价的： $dlv debug cmd/delve-demo1/main.go # 第三种: 通过exec子命令直接调试已经构建完的Go二进制程序文件，比如： $go build github.com/bigwhite/delve-demo1/cmd/delve-demo1 $dlv exec ./delve-demo1 直接调试二进制文件的潜在问题 在直接调试二进制文件时，Delve会根据二进制文件中保存的源文件位置到对应的路径下寻找对应的源文件并展示对应源码。如果把那个路径下的源文件挪走，那么再通过list命令展示源码就会出现错误： $go build github.com/bigwhite/delve-demo1/cmd/delve-demo1 $dlv exec ./delve-demo1 (dlv) list main.go:12 Showing chapter8/sources/delve-demo1/cmd/delve-demo1/main.go:12 (PC: 0x109ced1) Command failed: open chapter8/sources/delve-demo1/cmd/delve-demo1/main.go: no such file or directory 某些时候，通过 Delve 直接调试构建后的二进制文件可能会出现如下错误（下面仅是模拟示例）： (dlv) break main.go:12 Command failed: could not find statement at chapter8/sources/delve-demo1/cmd/delve-demo1/main.go:12, please use a line with a statement main.go的第12行明明是一个函数调用，但Delve就是提示这行没有Go语句。出现这个问题的原因很可能是Go编译器对目标代码做了优化，比如将foo.Foo内联掉了。为了避免这样的问题，我们可以在编译的时候加入关闭优化的标志位，这样Delve就不会因目标代码优化而报出错误的信息了。 $go build -gcflags=all=\"-N -l\" github.com/bigwhite/delve-demo1/cmd/delve-demo1 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:2:2","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"2.3 Delve 架构和原理 为了便于各种调试器前端（命令行、IDE、编辑器插件、图形化前端）与Delve集成，Delve采用了一个前后分离的架构: UI Layer对应的就是我们使用的dlv命令行或Goland/vim-go中的调试器前端，而Service Layer显然用于前后端通信。Delve真正施展的“魔法”是由Symbolic Layer和Target Layer两层合作实现的。 Target Layer通过各个操作系统提供的系统API来控制被调试目标进程，它对被调试目标的源码没有任何了解，实现的功能包括： 挂接（attach）/分离（detach）目标进程； 枚举目标进程中的线程； 启动/停止单个线程（或整个进程）； 接收和处理“调试事件”（线程创建/退出以及线程在断点处暂停）； 读写目标进程的内存； 读写停止线程的CPU寄存器； 读取core dump文件。 真正了解被调试目标源码文件的是Symbolic Layer，这一层通过读取Go编译器（包括链接器）以DWARF格式（一种标准的调试信息格式）写入目标二进制文件中的调试符号信息来了解被调试目标源码，并实现了被调试目标进程中的地址、二进制文件中的调试符号及源码相关信息三者之间的关系映射，如下图所示。 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:2:3","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"3. 并发、Coredump文件与挂接进程调试 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:3:0","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"3.1 Delve 调试并发程序 下面是一个调试并发程序的例子: // delve-demo2的目录结构 $tree . . ├── cmd │ └── delve-demo2 │ └── main.go ├── go.mod └── pkg ├── bar │ └── bar.go └── foo └── foo.go // 1. 调试并发程序 $ dlv debug cmd/delve-demo2/main.go (dlv) list main.go:19 Showing /home/tao/code/github/GoProgrammingFromBeginnerToMaster/chapter8/sources/delve-demo2/cmd/delve-demo2/main.go:19 (PC: 0x4970b7) 14: wg.Add(1) 15: go func() { 16: for { 17: d := 2 18: e := 20 19: f := bar.Bar(d, e) 20: fmt.Println(f) 21: time.Sleep(2 * time.Second) 22: } 23: wg.Done() 24: }() (dlv) b b1 main.go:19 Breakpoint b1 set at 0x4970b7 for main.main.func1() ./cmd/delve-demo2/main.go:19 (dlv) c // main goroutine输出了foo.Foo调用的返回结果30，然后调试程序在main.go的第19行停了下来 30 \u003e [b1] main.main.func1() ./cmd/delve-demo2/main.go:19 (hits goroutine(34):1 total:1) (PC: 0x4970b7) 14: wg.Add(1) 15: go func() { 16: for { 17: d := 2 18: e := 20 =\u003e 19: f := bar.Bar(d, e) 20: fmt.Println(f) 21: time.Sleep(2 * time.Second) 22: } 23: wg.Done() 24: }() // 2. 查看 goroutine (dlv) goroutine // 打印当前 goroutine 信息 Thread 45702 at ./cmd/delve-demo2/main.go:19 Goroutine 34: Runtime: ./cmd/delve-demo2/main.go:19 main.main.func1 (0x4970b7) User: ./cmd/delve-demo2/main.go:19 main.main.func1 (0x4970b7) Go: ./cmd/delve-demo2/main.go:15 main.main (0x496f46) Start: ./cmd/delve-demo2/main.go:15 main.main.func1 (0x497080) (dlv) goroutines // 查看当前程序内的goroutine列表 Goroutine 1 - User: /usr/local/go/src/runtime/sema.go:56 sync.runtime_Semacquire (0x45e225) [semacquire] Goroutine 2 - User: /usr/local/go/src/runtime/proc.go:362 runtime.gopark (0x4377d2) [force gc (idle)] Goroutine 17 - User: /usr/local/go/src/runtime/proc.go:362 runtime.gopark (0x4377d2) [GC sweep wait] Goroutine 18 - User: /usr/local/go/src/runtime/proc.go:362 runtime.gopark (0x4377d2) [GC scavenge wait] Goroutine 33 - User: /usr/local/go/src/runtime/proc.go:362 runtime.gopark (0x4377d2) [finalizer wait] // 星号 表示当前终端所在的 goroutine * Goroutine 34 - User: ./cmd/delve-demo2/main.go:19 main.main.func1 (0x4970b7) (thread 45702) [6 goroutines] (dlv) list \u003e [b1] main.main.func1() ./cmd/delve-demo2/main.go:19 (hits goroutine(34):1 total:1) (PC: 0x4970b7) 14: wg.Add(1) 15: go func() { 16: for { 17: d := 2 18: e := 20 =\u003e 19: f := bar.Bar(d, e) 20: fmt.Println(f) 21: time.Sleep(2 * time.Second) 22: } 23: wg.Done() 24: }() (dlv) n \u003e main.main.func1() ./cmd/delve-demo2/main.go:20 (PC: 0x4970cb) 15: go func() { 16: for { 17: d := 2 18: e := 20 19: f := bar.Bar(d, e) =\u003e 20: fmt.Println(f) 21: time.Sleep(2 * time.Second) 22: } 23: wg.Done() 24: }() 25: a := 3 (dlv) p f 1048576 (dlv) goroutine 1 // 切换到其他goroutine中 Switched from 34 to 1 (thread 45702) (dlv) bt 0 0x00000000004377d2 in runtime.gopark at /usr/local/go/src/runtime/proc.go:362 1 0x000000000043786a in runtime.goparkunlock at /usr/local/go/src/runtime/proc.go:367 2 0x0000000000446392 in runtime.semacquire1 at /usr/local/go/src/runtime/sema.go:144 3 0x000000000045e225 in sync.runtime_Semacquire at /usr/local/go/src/runtime/sema.go:56 4 0x00000000004754fc in sync.(*WaitGroup).Wait at /usr/local/go/src/sync/waitgroup.go:136 5 0x0000000000496ff9 in main.main at ./cmd/delve-demo2/main.go:29 6 0x00000000004373b8 in runtime.main at /usr/local/go/src/runtime/proc.go:250 7 0x00000000004617a1 in runtime.goexit at /usr/local/go/src/runtime/asm_amd64.s:1571 (dlv) threads // thread和threads命令，查看当前启动的线程列表并在各个线程间切换 * Thread 45702 at 0x4970cb ./cmd/delve-demo2/main.go:20 main.main.func1 Thread 45708 at 0x46305d /usr/local/go/src/runtime/sys_linux_amd64.s:149 runtime.usleep Thread 45709 at 0x463643 /usr/local/go/src/runtime/sys_linux_amd64.s:553 runtime.futex Thread 45710 at 0x463643 /usr/local/go/src/runtime/sys_linux_amd64.s:553 runtime.futex Thread 45711 at 0x463643 /usr/local/go/src/runtime/sys_linux_amd64.s:553 runtime.futex Thread 45712 at 0x463643 /usr/local/go/src/runtime/sys_linux_amd64.s:553 runtime.futex ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:3:1","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"3.2 Delve调试core dump文件 core dump文件是在程序异常终止或崩溃时操作系统对程序当时的内存状态进行记录并保存而生成的一个数据文件，该文件以core命名，也被称为核心转储文件。通过对操作系统记录的core文件中的数据的分析诊断，开发人员可以快速定位程序中存在的bug，这尤其适用于生产环境中的调试。 根据Delve官方文档的描述，Delve目前支持对linux/amd64、linux/arm64架构下产生的core文件的调试，以及Windows/amd64架构下产生的minidump小转储文件的调试。在这里我们以linux/amd64架构为例，看看如何使用Delve调试core dump文件。 测试的程序如下: // chapter8/sources/delve-demo3/main.go func main() { var p *int *p = 1 // 空指针解引用而崩溃 fmt.Println(\"program exit\") } 在Linux/amd64下（Ubuntu 18.04，Go 1.14，Delve 1.4.1）进行这次调试。要想在Linux下让Go程序崩溃时产生core文件，我们需要进行一些设置（因为默认情况下Go程序崩溃并不会产生core文件）： $ulimit -c unlimited // 不限制core文件大小 $go build main.go $GOTRACEBACK=crash ./main panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x49142f] ... /root/.bin/go1.14/src/runtime/asm_amd64.s:1373 +0x1 fp=0xc0000307e8 sp=0xc0000307e0 pc=0x45b911 created by runtime.createfing /root/.bin/go1.14/src/runtime/mfinal.go:156 +0x61 Aborted (core dumped) $ls -lh total 103M -rw------- 1 root root 101M May 28 14:55 core -rwxr-xr-x 1 root root 2.0M May 28 14:55 main -rw-r--r-- 1 root root 102 May 28 14:54 main.g0 # 按照上述步骤执行完，发现当前目录下没有核心转储文件，还需要执行下面这一步，设置操作将核心转储文件保存到当前目录下 echo core \u003e /proc/sys/kernel/core_pattern 使用dlv core命令对产生的core文件进行调试： $dlv core ./main ./core Type 'help' for list of commands. (dlv) bt 0 0x000000000045d4a1 in runtime.raise at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:165 1 0x0000000000442acb in runtime.dieFromSignal at /root/.bin/go1.14/src/runtime/signal_unix.go:721 2 0x0000000000442f5e in runtime.sigfwdgo at /root/.bin/go1.14/src/runtime/signal_unix.go:935 3 0x00000000004419d4 in runtime.sigtrampgo at /root/.bin/go1.14/src/runtime/signal_unix.go:404 4 0x000000000045d803 in runtime.sigtramp at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:389 5 0x000000000045d8f0 in runtime.sigreturn at /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:481 6 0x0000000000442c5a in runtime.crash at /root/.bin/go1.14/src/runtime/signal_unix.go:813 7 0x000000000042ee54 in runtime.fatalpanic at /root/.bin/go1.14/src/runtime/panic.go:1212 8 0x000000000042e7f0 in runtime.gopanic at /root/.bin/go1.14/src/runtime/panic.go:1060 9 0x00000000004429ea in runtime.panicmem at /root/.bin/go1.14/src/runtime/panic.go:212 10 0x00000000004429ea in runtime.sigpanic at /root/.bin/go1.14/src/runtime/signal_unix.go:687 11 0x000000000049142f in main.main at ./main.go:8 12 0x0000000000431222 in runtime.main at /root/.bin/go1.14/src/runtime/proc.go:203 13 0x000000000045b911 in runtime.goexit at /root/.bin/go1.14/src/runtime/asm_amd64.s:1373 (dlv) // 通过stack（简写为bt）命令输出的函数调用栈多为Go运行时的函数，我们唯一熟悉的就是main.main，于是，通过frame命令跳到main.main这个函数栈帧中： // 如果代码复杂且涉及函数调用较多，我们还可以继续通过up和down在各层函数栈帧中搜寻问题的原因。 (dlv) frame 11 \u003e runtime.raise() /root/.bin/go1.14/src/runtime/sys_linux_amd64.s:165 (PC: 0x45d4a1) Warning: debugging optimized function Frame 11: ./main.go:8 (PC: 49142f) 3: import \"fmt\" 4: 5: func main() { 6: var p *int 7: p = nil =\u003e 8: *p = 1 9: fmt.Println(\"program exit\") 10: } ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:3:2","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"3.3 使用Delve挂接到正在运行的进程进行调试 在一些特定的情况下，我们可能需要对正在运行的Go应用进程进行调试。不过这类调试是有较大风险的：调试器一旦成功挂接到正在运行的进程中，调试器就掌握了进程执行的指挥权，并且正在运行的goroutine都会暂停，等待调试器的进一步指令。因此，不到万不得已，请不要在生产环境中使用这种调试方法。 使用 dlv attach 挂接到进程进行调试的方法如下: # 1. 找到正在运行的进程 $ps -ef|grep delve-demo2 501 75863 63197 0 3:33下午 ttys011 0:00.02 ./delve-demo2 # 2. 挂载到运行中的进程 $dlv attach 75863 ./delve-demo2 # Delve一旦成功切入delve-demo2进程，delve-demo2进程内的所有goroutine都将暂停运行，等待Delve的进一步指令。 (dlv) goroutines Goroutine 1 - User: $GOROOT/src/runtime/sema.go:56 sync.runtime_Semacquire (0x103f472) Goroutine 2 - User: $GOROOT/src/runtime/proc.go:305 runtime.gopark (0x1030f60) Goroutine 3 - User: $GOROOT/src/runtime/proc.go:305 runtime.gopark (0x1030f60) Goroutine 4 - User: $GOROOT/src/runtime/proc.go:305 runtime.gopark (0x1030f60) Goroutine 17 - User: $GOROOT/src/runtime/proc.go:305 runtime.gopark (0x1030f60) Goroutine 18 - User: $GOROOT/src/runtime/time.go:198 time.Sleep (0x104ba7a) [6 goroutines] (dlv) b b1 main.go:19 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:3:3","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"4. Delve 调试单元测试 ","date":"2023-01-04","objectID":"/posts/program/go/expert/go_export/expert_12/:4:0","tags":["go 进阶"],"title":"Delve 调试Go代码","uri":"/posts/program/go/expert/go_export/expert_12/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"1. expvar 应用运行状态一般以度量数据的形式呈现。通过了解应用关键路径上的度量数据，我们可以确定在某个度量点上应用的性能是符合预期性能指标还是较大偏离预期，这样就可以最大限度地缩小性能瓶颈点的搜索范围，从而快速定位应用中的瓶颈点并进行优化。这些可以反映应用运行状态的数据也被称为应用的内省（introspection）数据。相比于通过查询应用外部特征而获取的探针类（probing）数据（比如查看应用某端口是否有响应并返回正确的数据或状态码），内省数据可以传达更为丰富、更多的有关应用程序状态的上下文信息。这些上下文信息可以是应用对各类资源的占用信息，比如应用运行占用了多少内存空间，也可以是自定义的性能指标信息，比如单位时间处理的外部请求数量、应答延迟、队列积压量等。我们可以轻松地使用Go标准库提供的expvar包按统一接口、统一数据格式、一致的指标定义方法输出自定义的度量数据。 expvar包不仅可用于辅助缩小定位性能瓶颈的范围，还可以用来输出度量数据以对应用的运行状态进行监控，这样当程序出现问题时，我们可以快速发现问题并利用输出的度量数据对程序进行诊断并快速定位问题。 ","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/:1:0","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"1.1 expvar包的工作原理 expvar包提供了一种输出应用内部状态信息的标准化方案，这个方案标准化了以下三方面内容： 数据输出接口形式； 输出数据的编码格式； 用户自定义性能指标的方法。 整个流程如下图所示: expvar 与 net/http/pprof类似，也是向默认“路由器”DefaultServeMux注册一个服务端点/debug/vars，如果没有使用默认路由，可以自行注册: package main import ( \"expvar\" \"fmt\" \"net/http\" ) func main() { mux := http.NewServeMux() mux.Handle(\"/hi\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hi\")) })) // expvar包提供了Handler函数，该函数可用于其内部expvarHandler的注册。 mux.Handle(\"/debug/vars\", expvar.Handler()) fmt.Println(http.ListenAndServe(\"localhost:8080\", mux)) } 这个服务端点就是expvar提供给外部的获取应用内部状态的唯一标准接口，通过 http get 请求，这个接口返回的是标准的JSON格式数据。样例如下： { \"cmdline\": [\"/var/folders/cz/sbj5kg2d3m3c6j650z0qfm800000gn/T/go-build507091832/ b001/exe/expvar_demo2\"], \"memstats\": { \"Alloc\": 223808, \"TotalAlloc\": 223808, \"Sys\": 71387144, \"Lookups\": 0, \"Mallocs\": 743, \"Frees\": 11, ... } } 在默认返回的状态数据中包含了两个字段：cmdline和memstats。这两个输出数据是expvar包在init函数中就已经发布（Publish）了的变量： cmdline字段的含义是输出数据的应用名 memstats输出的数据对应的是runtime.Memstats结构体，反映的是应用在运行期间堆内存分配、栈内存分配及GC的状态。runtime.Memstats结构体的字段可能会随着Go版本的演进而发生变化 func init() { http.HandleFunc(\"/debug/vars\", expvarHandler) Publish(\"cmdline\", Func(cmdline)) Publish(\"memstats\", Func(memstats)) } expvar包为Go应用输出内部状态提供了标准化方案，前面已经提到了其中的两个标准。 标准的接口：通过http get（默认从/debug/vars服务端点获取数据）。 标准的数据编码格式：JSON。 在这一节中，我们来介绍一下第三个标准：自定义输出的度量数据的标准方法。 ","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/:1:1","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"1.2 输出自定义状态数据 前面的内容可以看到 expvar 已经标准化了两个方面: 标准的接口：通过http get（默认从/debug/vars服务端点获取数据）。 标准的数据编码格式：JSON。 接下来我们来看第三个标准：自定义输出的度量数据的标准方法。 expvar包提供了Publish函数，该函数用于发布通过debug/vars服务端点输出的数据: // $GOROOT/src/expvar/expvar.go func Publish(name string, v Var) // $GOROOT/src/expvar/expvar.go type Var interface { String() string } Publish 接收两个参数：name和v。name是对应字段在输出结果中的字段名，而v是字段值。v的类型为Var，是一个接口类型。我们看下面这个示例: type CustomVar struct { value int64 } // 实现 Var 接口 func (v *CustomVar) String() string { return strconv.FormatInt(atomic.LoadInt64(\u0026v.value), 10) } // 业务对自定义状态进行变更 func (v *CustomVar) Add(delta int64) { atomic.AddInt64(\u0026v.value, delta) } func (v *CustomVar) Set(value int64) { atomic.StoreInt64(\u0026v.value, value) } func init() { customVar := \u0026CustomVar{ value: 17, } expvar.Publish(\"customVar\", customVar) } func main() { http.Handle(\"/hi\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\"hi\")) })) fmt.Println(http.ListenAndServe(\"localhost:8080\", nil)) } ","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/:1:2","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"1.3 expvar 内置指标类型 我们在设计能反映Go应用内部状态的自定义指标时，经常会设计下面两类指标: 测量型: 可增减 计数型：只能递增，可以计算速率 针对上述两类常见指标，expvar包提供了对常用指标类型的原生支持，比如整型指标、浮点型指标以及像memstats那样的Map型复合指标等。 整型指标 整型指标的实现如下: // $GOROOT/src/expvar/expvar.go type Int struct { i int64 } func (v *Int) Value() int64 { return atomic.LoadInt64(\u0026v.i) } func (v *Int) String() string { return strconv.FormatInt(atomic.LoadInt64(\u0026v.i), 10) } func (v *Int) Add(delta int64) { atomic.AddInt64(\u0026v.i, delta) } func (v *Int) Set(value int64) { atomic.StoreInt64(\u0026v.i, value) } 针对expvar.Int类型，expvar包还提供了创建即发布的NewInt函数，这样我们就无须再自行调用Publish函数发布指标了： func NewInt(name string) *Int { v := new(Int) Publish(name, v) return v } 所以上面的示例可以改成: var customVar *expvar.Int func init() { customVar = expvar.NewInt(\"customVar\") customVar.Set(17) } // ... Map型复合指标 使用expvar.Map类型可以定义一个像memstats那样的复合指标: var customVar *expvar.Map func init() { customVar = expvar.NewMap(\"customVar\") var field1 expvar.Int var field2 expvar.Float customVar.Set(\"field1\", \u0026field1) customVar.Set(\"field2\", \u0026field2) } // customVar.Add(\"field1\", 1) // customVar.AddFloat(\"field2\", 0.001) 如以上示例所示，定义一个expvar.Map类型变量后，可以向该复合指标变量中添加指标，比如示例中的“field1”。在业务逻辑中，可以通过expvar.Map提供的Add、AddFloat等方法对复合指标内部的单个指标值进行更新。 如果想将一个结构体类型当作一个复合指标直接输出，expvar包也提供了很好的支持。 type CustomVar struct { Field1 int64 `json:\"field1\"` Field2 float64 `json:\"field2\"` } var ( field1 expvar.Int field2 expvar.Float ) func exportStruct() interface{} { return CustomVar{ Field1: field1.Value(), Field2: field2.Value(), } } func init() { expvar.Publish(\"customVar\", expvar.Func(exportStruct)) } 针对结构体类型，通过实现一个返回interface{}类型的函数（这里是exportStruct），并通过Publish函数将该函数发布出去的（expvar.Func(exportStruct)）。注意，这个返回interface{}类型的函数的返回值底层类型必须是一个支持序列化为JSON格式的类型。显然这种方法更加灵活，可以发布任何类型的自定义指标。 ","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/:1:3","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"1.4 输出数据的展示 /debug/vars服务端点输出的 json 数据很容被各种监控工具集成。Go开发者Ivan Daniluk开发了一款名为expvarmon的开源工具，该工具支持将从expvar输出的数据以基于终端的图形化方式展示出来。使用方法如下: $go get github.com/divan/expvarmon $expvarmon -ports=\"8080\" -vars=\"custom:customVar.field1,custom:customVar.field2,mem:memstats.Alloc,mem:memstats.Sys,mem:memstats.HeapAlloc,mem:memstats.HeapInuse,duration:memstats.PauseNs,duration:memstats.PauseTotalNs\" ","date":"2023-01-03","objectID":"/posts/program/go/expert/go_export/expert_11/:1:4","tags":["go 进阶"],"title":"expvar","uri":"/posts/program/go/expert/go_export/expert_11/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"1. 性能基准测试 性能基准测试在Go语言中是和普通的单元测试一样被原生支持的。我们可以像对普通单元测试那样在*_test.go文件中创建性能基准测试，每个以Benchmark前缀开头的函数都会被当作一个独立的性能基准测试： func BenchmarkXxx(b *testing.B) { for n := 0; n \u003c b.N; n++ { //... } } 可以像下面这样执行性能基准测试: $go test -bench . benchmark_intro_test.go # 通过正则表达式选择要执行的性能测试 $go test -bench=ByJoin ./benchmark_intro_test.go # 通过传入-benchmem命令行参数，可以输出内存分配信息 # （与基准测试代码中显式调用b.ReportAllocs的效果是等价的） $go test -bench=Join ./benchmark_intro_test.go -benchmem goos: darwin goarch: amd64 # 执行次数 平均执行时间 每次分配的内存大小 每次循环内存分配的次数 BenchmarkConcatStringByJoin-8 23004709 48.8 ns/op 48 B/op 1 allocs/op PASS ok command-line-arguments 1.183s ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:1:0","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"1.1 顺序/并发执行的基准测试 根据是否并行执行，Go的性能基准测试可以分为两类：顺序执行的性能基准测试和并行执行的性能基准测试。 顺序执行的性能基准测试 // .顺序执行的性能基准测试 func BenchmarkXxx(b *testing.B) { // ... for i := 0; i \u003c b.N; i++ { // 被测对象的执行代码 } } 顺序执行的性能基准测试的执行过程原理，可以通过下面的例子来说明： package bench import ( \"fmt\" \"sync\" \"sync/atomic\" \"testing\" tls \"github.com/huandu/go-tls\" ) var ( m map[int64]struct{} = make(map[int64]struct{}, 10) mu sync.Mutex round int64 = 1 ) func BenchmarkSequential(b *testing.B) { fmt.Printf(\"\\ngoroutine[%d] enter BenchmarkSequential: round[%d], b.N[%d]\\n\", tls.ID(), atomic.LoadInt64(\u0026round), b.N) defer func() { atomic.AddInt64(\u0026round, 1) }() for i := 0; i \u003c b.N; i++ { mu.Lock() _, ok := m[round] if !ok { m[round] = struct{}{} fmt.Printf(\"goroutine[%d] enter loop in BenchmarkSequential: round[%d], b.N[%d]\\n\", tls.ID(), atomic.LoadInt64(\u0026round), b.N) } mu.Unlock() } fmt.Printf(\"goroutine[%d] exit BenchmarkSequential: round[%d], b.N[%d]\\n\", tls.ID(), atomic.LoadInt64(\u0026round), b.N) } 执行测试，通过日志就能看到: BenchmarkSequential被执行了多轮（见输出结果中的round值） 每一轮执行，for循环的b.N值均不相同 除b.N为1的首轮，其余各轮均在一个goroutine（goroutine[2]）中顺序执行 默认情况下，每个性能基准测试函数（如BenchmarkSequential）的执行时间为1秒。如果不足 1s，go test会有序的增加 b.N 的值。基准测试有几个控制测试次数的参数: 要增加迭代次数，可以使用-benchtime命令行选项来增加基准测试执行的时间。 也可以通过-benchtime手动指定b.N的值，go test 会以指定的N值作为最终轮的循环次数。 还可以显式要求go test多次执行以收集多次数据，并将这些数据经过统计学方法处理后的结果作为最终结果。 # 增加基准测试执行的时间 $go test -bench . sequential_test.go -benchtime 2s # 执行 b.N 的次数 $go test -v -benchtime 5x -bench . sequential_test.go # 设置 go test 执行多次 $go test -v -count 2 -bench . benchmark_intro_test.go 并行执行的性能基准测试 并行执行的基准测试主要用于为包含多goroutine同步设施（如互斥锁、读写锁、原子操作等）的被测代码建立性能基准。这样可以反映出被测试代码在同步上性能损耗。 // 并行执行的性能基准测试 func BenchmarkXxx(b *testing.B) { // ... b.RunParallel(func(pb *testing.PB) { for pb.Next() { // 被测对象的执行代码 } } } $go test -v -bench . benchmark_paralell_demo_test.go -cpu 2,4,8 通过-cpu 2,4,8命令行选项告知go test将每个性能基准测试函数分别在GOMAXPROCS等于2、4、8的情况下各运行一次。这样，可以更加明显的观察到随着并发度的增加，发生在同步上的性能损耗。 和顺序执行的性能基准测试不同，并行执行的性能基准测试会启动多个goroutine并行执行基准测试函数中的循环。针对BenchmarkParalell基准测试的每一轮执行，go test都会启动GOMAXPROCS数量的新goroutine，这些goroutine共同执行b.N次循环，每个goroutine会尽量相对均衡地分担循环次数。 ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:1:1","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"1.2 使用性能基准比较工具 Go核心团队先后开发了两款性能基准比较工具：benchcmp 和 benchstat。 benchcmp $go test -run=NONE -bench . strcat_test.go \u003e old.txt $go test -run=NONE -bench . strcat_test.go \u003e new.txt $benchcmp old.txt new.txt benchmark old ns/op new ns/op delta BenchmarkStrcat-8 92.4 49.6 -46.32% // 如果使用 -count 对BenchmarkStrcat执行多次，那么benchcmp给出的结果如下： $go test -run=NONE -count 5 -bench . strcat_test.go \u003e old.txt $go test -run=NONE -count 5 -bench . strcat_test.go \u003e new.txt $benchcmp old.txt new.txt benchmark old ns/op new ns/op delta BenchmarkStrcat-8 92.8 51.4 -44.61% BenchmarkStrcat-8 91.9 55.3 -39.83% BenchmarkStrcat-8 96.1 52.6 -45.27% BenchmarkStrcat-8 89.4 50.2 -43.85% BenchmarkStrcat-8 91.2 51.5 -43.53% // -best命令行选项，benchcmp 将挑选性能最好的一条数据，然后进行比较： $benchcmp -best old.txt new.txt benchmark old ns/op new ns/op delta BenchmarkStrcat-8 89.4 50.2 -43.85% benchcmp 的实现比较简单，它不关心这些结果数据在统计学层面是否有效，只对结果做简单比较。 benchstat benchstat 提高对性能基准数据比较的科学性。 $go test -run=NONE -count 5 -bench . strcat_test.go -benchmem \u003e old_with_mem.txt $go test -run=NONE -count 5 -bench . strcat_test.go -benchmem \u003e new_with_mem.txt $benchstat old_with_mem.txt new_with_mem.txt // 每次的执行时间 name old time/op new time/op delta Strcat-8 90.5ns ± 1% 50.6ns ± 2% -44.14% (p=0.008 n=5+5) // 每次的内存分配大小 name old alloc/op new alloc/op delta Strcat-8 80.0B ± 0% 48.0B ± 0% -40.00% (p=0.008 n=5+5) // 每次的内存分配次数 name old allocs/op new allocs/op delta Strcat-8 2.00 ± 0% 1.00 ± 0% -50.00% (p=0.008 n=5+5) 其中 ±1% 是样本数据中最大值和最小值距样本平均值的最大偏差百分比。如果这个偏差百分比大于5%，则说明样本数据质量不佳，有些样本数据是不可信的。最后一列（delta）为两次基准测试对比的变化量，这个指标后面括号中的 p=0.008 是一个用于衡量两个样本集合的均值是否有显著差异的指标。一般p值小于0.05的结果是可接受的。 ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:1:2","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"1.3 控制基准测试的计时器 testing.B 中提供了多种灵活操控基准测试计时器的方法: func BenchmarkResetTimer(b *testing.B) { expensiveTestContextSetup() b.ResetTimer() for n := 0; n \u003c b.N; n++ { // .... } } func BenchmarkStop(b *testing.B) { b.StopTimer() expensiveTestContextSetup() b.StartTimer() for n := 0; n \u003c b.N; n++ { // .... } } ResetTimer并不停掉计时器（无论计时器是否在工作），而是将已消耗的时间、内存分配计数器等全部清零，这样即便计数器依然在工作，它仍然需要从零开始重新记；而StopTimer只是停掉一次基准测试运行的计时器，在调用StartTimer后，计时器即恢复正常工作。 将ResetTimer或StopTimer用在每个基准测试的For循环中是有副作用的: 在For循环中使用StopTimer，因为会暂停计时，想要真正运行1秒就要等待很长时间； 如果在For循环中使用了ResetTimer，由于其每次执行都会将计数器数据清零，因此这轮基准测试将一直执行下去，无法退出。 因此尽量不要在基准测试的For循环中使用ResetTimer！但可以在限定条件下在For循环中使用StopTimer/StartTimer。就像下面的Go标准库中这样： // $GOROOT/src/runtime/map_test.go func benchmarkMapDeleteInt32(b *testing.B, n int) { a := make(map[int32]int, n) b.ResetTimer() for i := 0; i \u003c b.N; i++ { if len(a) == 0 { b.StopTimer() for j := i; j \u003c i+n; j++ { a[int32(j)] = j } b.StartTimer() } delete(a, int32(i)) } } ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:1:3","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"2. pprof Go 内置了对代码进行性能剖析的工具：pprof。pprof源自Google Perf Tools工具套件，在Go发布早期就被集成到Go工具链中了，并且Go运行时原生支持输出满足pprof需要的性能采样数据。 pprof 的执行分成数据采集和数据剖析两个阶段: ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:2:0","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"2.1 采样数据类型 数据采集阶段，支持的采样数据类型有如下几种: CPU数据(cpu.prof) 作用: 能帮助我们识别出代码关键路径上消耗CPU最多的函数。 频率: 一旦启用CPU数据采样，Go运行时会每隔一段短暂的时间（10ms）就中断一次（由SIGPROF信号引发）并记录当前所有goroutine的函数栈信息（存入cpu.prof） 堆内存分配数据(mem.prof) 作用: 它能帮助我们了解Go程序的当前和历史内存使用情况 频率: 堆内存分配的采样频率可配置，默认每1000次堆内存分配会做一次采样（存入mem.prof） 锁竞争数据(mutex.prof) 作用: 锁竞争采样数据记录了当前Go程序中互斥锁争用导致延迟的操作。如果你认为很大可能是互斥锁争用导致CPU利用率不高，可以尝试此类型的性能剖析 启用: 该类型采样数据在默认情况下是不启用的，启用方式如下: runtime.SetMutexProfileFraction go test -bench . xxx_test.go -mutexprofile mutex.out 阻塞时间数据(block.prof) 作用: 该类型采样数据记录的是goroutine在某共享资源（一般是由同步原语保护）上的阻塞时间，包括从无缓冲channel收发数据、阻塞在一个已经被其他goroutine锁住的互斥锁、向一个满了的channel发送数据或从一个空的channel接收数据等。 启用: 该类型采样数据在默认情况下也是不启用的，启用方式如下: runtime.SetBlockProfileRate go test -bench . xxx_test.go -blockprofile block.out 采样不是免费的，因此一次采样尽量仅采集一种类型的数据，不要同时采样多种类型的数据，避免相互干扰采样结果。 ","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:2:1","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"2.2 数据采集方式 Go目前主要支持两种性能数据采集方式：性能基准测试和独立程序的性能数据采集。 通过性能基准测试进行数据采集 通过性能基准测试进行数据采集，尤其适用于对应用中关键路径上关键函数/方法性能的剖析。我们仅需为go test增加一些命令行选项即可在执行性能基准测试的同时进行性能数据采集: $go test -bench . xxx_test.go -cpuprofile=cpu.prof $ls cpu.prof xxx.test* xxx_test.go $go test -bench . xxx_test.go -memprofile=mem.prof $go test -bench . xxx_test.go -blockprofile=block.prof $go test -bench . xxx_test.go -mutexprofile=mutex.prof 一旦开启性能数据采集（比如传入-cpuprofile），go test的-c命令选项便会自动开启，go test命令执行后会自动编译出一个与该测试对应的可执行文件（这里是xxx.test）。该可执行文件可以在性能数据剖析过程中提供剖析所需的符号信息（如果没有该可执行文件，go tool pprof的disasm命令将无法给出对应符号的汇编代码）。 独立程序的性能数据采集 可以通过标准库runtime/pprof和runtime包提供的低级API对独立程序进行性能数据采集: package main import ( \"flag\" \"fmt\" \"log\" \"os\" \"os/signal\" \"runtime\" \"runtime/pprof\" \"sync\" \"syscall\" \"time\" ) var cpuprofile = flag.String(\"cpuprofile\", \"\", \"write cpu profile to `file`\") var memprofile = flag.String(\"memprofile\", \"\", \"write memory profile to `file`\") var mutexprofile = flag.String(\"mutexprofile\", \"\", \"write mutex profile to `file`\") var blockprofile = flag.String(\"blockprofile\", \"\", \"write block profile to `file`\") func main() { flag.Parse() if *cpuprofile != \"\" { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(\"could not create CPU profile: \", err) } defer f.Close() // 该例子中暂忽略错误处理 if err := pprof.StartCPUProfile(f); err != nil { log.Fatal(\"could not start CPU profile: \", err) } defer pprof.StopCPUProfile() } if *memprofile != \"\" { f, err := os.Create(*memprofile) if err != nil { log.Fatal(\"could not create memory profile: \", err) } defer f.Close() if err := pprof.WriteHeapProfile(f); err != nil { log.Fatal(\"could not write memory profile: \", err) } } if *mutexprofile != \"\" { runtime.SetMutexProfileFraction(1) defer runtime.SetMutexProfileFraction(0) f, err := os.Create(*mutexprofile) if err != nil { log.Fatal(\"could not create mutex profile: \", err) } defer f.Close() if mp := pprof.Lookup(\"mutex\"); mp != nil { mp.WriteTo(f, 0) } } if *blockprofile != \"\" { runtime.SetBlockProfileRate(1) defer runtime.SetBlockProfileRate(0) f, err := os.Create(*blockprofile) if err != nil { log.Fatal(\"could not create block profile: \", err) } defer f.Close() if mp := pprof.Lookup(\"block\"); mp != nil { mp.WriteTo(f, 0) } } var wg sync.WaitGroup c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT, syscall.SIGTERM) wg.Add(1) go func() { for { select { case \u003c-c: wg.Done() return default: s1 := \"hello,\" s2 := \"gopher\" s3 := \"!\" _ = s1 + s2 + s3 } time.Sleep(10 * time.Millisecond) } }() wg.Wait() fmt.Println(\"program exit\") } 独立程序的性能数据采集方式对业务代码侵入较多，还要自己编写一些采集逻辑：定义flag变量、创建输出文件、关闭输出文件等。每次采集都要停止程序才能获取结果。（当然可以重新定义更复杂的控制采集时间窗口的逻辑，实现不停止程序也能获取采集数据结果。） http 服务性能数据采集 Go在net/http/pprof包中还提供了一种更为高级的针对独立程序的性能数据采集方式，这种方式尤其适合那些内置了HTTP服务的独立程序。net/http/pprof包可以直接利用已有的HTTP服务对外提供用于性能数据采集的服务端点（endpoint）。 package main import ( \"context\" \"fmt\" \"net/http\" _ \"net/http/pprof\" \"os\" \"os/signal\" \"syscall\" ) func main() { http.Handle(\"/hello\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { fmt.Println(*r) w.Write([]byte(\"hello\")) })) s := http.Server{ Addr: \"localhost:8080\", } c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT, syscall.SIGTERM) go func() { \u003c-c s.Shutdown(context.Background()) }() fmt.Println(s.ListenAndServe()) } 下面是net/http/pprof包的init函数，init 函数中向 http 的默认路由添加了很多服务端点和处理函数，通过这些服务端点，我们可以在该独立程序运行期间获取各种类型的性能采集数据。 //$GOROOT/src/net/http/pprof/pprof.go func init() { http.HandleFunc(\"/debug/pprof/\", Index) http.HandleFunc(\"/debug/pprof/cmdline\", Cmdline) http.HandleFunc(\"/debug/pprof/profile\", Profile) http.HandleFunc(\"/debug/pprof/symbol\", Symbol) http.HandleFunc(\"/debug/pprof/trace\", Trace) } 访问http://localhost:8080/debug/pprof/，可以看到以下页面: 页面里列出了多种类型的性能采集数据，点击其中任何一个即可完成该种类型性能数据的一次采集。profile是CPU类型数据的服务端点，点击该端点后，该服务默认会发起一次持续30秒的性能采集，得到的数据文件会由浏览器自动下载到本地。如果想自定义采集时长，可以通过为服务端点传递时长参数实现: http://localhost:8080/debug/pprof/profile?seconds=60 如果未使用 http 默认路由，只需要自行注册对应的服务端点即可: func main() { mux := http.NewServeMux() mux.HandleFunc(\"/debug/pprof/\", pprof.Index) mux.HandleFunc(\"/debug/ppro","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:2:2","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"2.3 性能数据的剖析 Go工具链通过pprof子命令提供了两种性能数据剖析方法：命令行交互式和 Web 图形化。 命令行交互式 对应于三种不同的采样方式，有三种进入命令行交互模式的方式: $go tool pprof xxx.test cpu.prof // 剖析通过性能基准测试采集的数据 $go tool pprof standalone_app cpu.prof // 剖析独立程序输出的性能采集数据 // 通过net/http/pprof注册的性能采集数据服务端点获取数据并剖析 $go tool pprof http://localhost:8080/debug/pprof/p 这里以 standalone_app 为例进行说明: CPU 性能剖析 $ go build -o pprof_standalone1 pprof_standalone1.go $ ./pprof_standalone1 -cpuprofile pprof_standalone1_cpu.prof ^Cprogram exit # 通过go tool pprof命令进入命令行交互模式： $ go tool pprof pprof_standalone1 pprof_standalone1_cpu.prof File: pprof_standalone1 Type: cpu Time: ... # 从pprof子命令的输出中我们看到：程序运行16.14s，采样总时间为240ms，占总时间的1.49%。 Duration: 16.14s, Total samples = 240ms ( 1.49%) Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) # 命令行交互方式下最常用的命令是topN (pprof) top Showing nodes accounting for 240ms, 100% of 240ms total Showing top 10 nodes out of 29 flat flat% sum% cum cum% 90ms 37.50% 37.50% 90ms 37.50% runtime.nanotime1 50ms 20.83% 58.33% 50ms 20.83% runtime.pthread_cond_wait 40ms 16.67% 75.00% 40ms 16.67% runtime.usleep 20ms 8.33% 83.33% 20ms 8.33% runtime.asmcgocall 20ms 8.33% 91.67% 20ms 8.33% runtime.kevent 10ms 4.17% 95.83% 10ms 4.17% runtime.pthread_cond_signal 10ms 4.17% 100% 10ms 4.17% runtime.pthread_cond_timedwait_ relative_np 0 0% 100% 10ms 4.17% main.main.func1 0 0% 100% 30ms 12.50% runtime.checkTimers 0 0% 100% 130ms 54.17% runtime.findrunnable 命令行交互方式下最常用的命令是topN，N 默认为 10，topN命令的输出结果默认按flat(flat%)从大到小的顺序输出。 flat列的值表示函数自身代码在数据采样过程中的执行时长。 flat%列的值表示函数自身代码在数据采样过程中的执行时长占总采样执行时长的百分比。 sum%列的值是当前行flat%值与排在该值前面所有行的flat%值的累加和。以第三行的sum%值75.00%为例，该值由前三行flat%累加而得，即16.67% + 20.83% + 37.50% = 75.00%。 cum列的值表示函数自身在数据采样过程中出现的时长，这个时长是其自身代码执行时长及其等待其调用的函数返回所用时长的总和。越是接近函数调用栈底层的代码，其cum列的值越大。 cum%列的值表示该函数cum值占总采样时长的百分比。比如：runtime.findrunnable函数的cum值为130ms，总采样时长为240ms，则其cum%值为两者的比值百分化后的值。 (pprof) list main.main Total: 240ms ROUTINE ======================== main.main.func1 in chapter8/sources/pprof_standalone1.go 0 10ms (flat, cum) 4.17% of Total . . 86: s2 := \"gopher\" . . 87: s3 := \"!\" . . 88: _ = s1 + s2 + s3 . . 89: } . . 90: . 10ms 91: time.Sleep(10 * time.Millisecond) . . 92: } . . 93: }() . . 94: wg.Wait() . . 95: fmt.Println(\"program exit\") . . 96:} (pprof) 通过list命令列出函数对应的源码，在展开源码的同时，pprof还列出了代码中对应行的消耗时长（基于采样数据）。可以选择耗时较长的函数，进一步向下展开，直到找到令我们满意的结果（某个导致性能瓶颈的函数中的某段代码）。 (pprof) png Generating report in profile001.png 在命令行交互模式下，还可以生成CPU采样数据的函数调用图，且可以导出为多种格式，如PDF、PNG、JPG、GIF、SVG等。不过要做到这一点，前提是本地已安装图片生成所依赖的插件graphviz。 我们可以清晰地看到cum%较大的叶子节点（用黑色粗体标出，叶子节点的cum%值与flat%值相等），它们就是我们需要重点关注的优化点。 内存性能剖析 我们在来看看内存性能剖析的常见选项: $go test -v -run=^$ -bench=^BenchmarkHi$ -benchtime=2s -memprofile=mem.prof $go tool pprof step2.test mem.prof File: step2.test Type: alloc_space Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) 在go tool pprof的输出中有一行为Type: alloc_space。Type 表示的是采样类型: alloc_space: 表示当前pprof将呈现程序运行期间所有内存分配的采样数据（即使该分配的内存在最后一次采样时已经被释放） inuse_space: 表示内存数据采样结束时依然在用的内存。 可以在启动pprof工具时指定所使用的内存数据呈现类型： $go tool pprof --alloc_space step2.test mem.prof // 遗留方式 $go tool pprof -sample_index=alloc_space step2.test mem.prof //最新方式 亦可在进入pprof交互模式后，通过sample_index命令实现切换： (pprof) sample_index = inuse_space 现在以alloc_space类型进入pprof命令交互界面并执行top命令： $go tool pprof -sample_index=alloc_space step2.test mem.prof File: step2.test Type: alloc_space Entering interactive mode (type \"help\" for commands, \"o\" for options) (pprof) top -cum Showing nodes accounting for 2084.53MB, 99.45% of 2096.03MB total Showing top 10 nodes out of 11 flat flat% sum% cum cum% 0 0% 0% 2096.03MB 100% chapter8/sources/go-pprof-optimization- demo/step2.BenchmarkHi 840.55MB 40.10% 40.10% 2096.03MB 100% chapter8/sources/go-pprof-optimization- demo/step2.handleHi 0 0% 40.10% 2096.03MB 100% testing.(*B).launch 0 0% 40.10% 2096.03MB 100% testing.(*B).runN 0 0% 40.10% 1148.98MB 54.82% bytes.(*Buffer).Write 0 0% 40.10% 1148.98MB 54.82% bytes.(*Buffer).grow 1148.98MB 54.82% 94.92% 1148.98MB 54.82% bytes.makeSlice 0 0% 94.92% 1148.98MB 54.82% net/ht","date":"2023-01-02","objectID":"/posts/program/go/expert/go_export/expert_10/:2:3","tags":["go 进阶"],"title":"Go 性能优化","uri":"/posts/program/go/expert/go_export/expert_10/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"本部分将详细介绍Go在单元测试、性能测试的最佳实践方案。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:0:0","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1. 单元测试 Go语言在工具链和标准库中提供对测试的原生支持。在Go中测试代码与包代码放在同一个包目录下，并且Go要求所有测试代码都存放在以*_test.go结尾的文件中。go test将所有包目录下的*_test.go文件编译成一个临时二进制文件（可以通过go test -c显式编译出该文件），并执行该文件，后者将执行各个测试源文件中名字格式为TestXxx的函数所代表的测试用例并输出测试执行结果。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:0","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.1 包内测试与包外测试 go 的单元测试主要使用 go test 命令和 testing 包。 testing包的官方文档说: 要编写一个新的测试集（test suite），创建一个包含TestXxx函数的以_test.go为文件名结尾的文件。将这个测试文件放在与被测试包相同的包下面。编译被测试包时，该文件将被排除在外；执行go test时，该文件将被包含在内。 go test命令行工具的官方文档则说: 那些包名中带有_test后缀的测试文件将被编译成一个独立的包，这个包之后会被链接到主测试二进制文件中并运行。 对比这两段官方文档，我们发现了一处“自相矛盾”的地方：testing包文档告诉我们将测试代码放入与被测试包同名的包中，而go test命令行帮助文档则提到会将包名中带有_test后缀的测试文件编译成一个独立的包。如果我们要测试的包为foo，testing包的帮助文档告诉我们把对foo包的测试代码放在包名为foo的测试文件中；而go test命令行帮助文档则告诉我们把foo包的测试代码放在包名为foo_test的测试文件中。 我们把将测试代码放在与被测包同名的包中的测试方法称为“包内测试”。 我们把将测试代码放在名为被测包包名+\"_test\"的包中的测试方法称为“包外测试”。 # 查看哪些测试源文件使用了包内测试 go list -f={{.TestGoFiles}} . # 查看哪些测试源文件使用了包外测试 go list -f={{.XTestGoFiles}} . 包内测试的优势与不足 由于Go构建工具链在编译包时会自动根据文件名是否具有_test.go后缀将包源文件和包的测试源文件分开，测试代码不会进入包正常构建的范畴，因此测试代码使用与被测包名相同的包内测试方法是一个很自然的选择: 包内测试这种方法本质上是一种白盒测试方法。由于测试代码与被测包源码在同一包名下，测试代码可以访问该包下的所有符号，无论是导出符号还是未导出符号； 并且由于包的内部实现逻辑对测试代码是透明的，包内测试可以更为直接地构造测试数据和实施测试逻辑，可以很容易地达到较高的测试覆盖率。因此对于追求高测试覆盖率的项目而言，包内测试是不二之选。 但同样的包内测试也会存在一些问题: 测试代码自身需要经常性的维护: 包内测试的白盒测试本质意味着它是一种面向实现的测试。 硬伤：包循环引用 包c进行测试的代码（c_test.go）采用了包内测试的方法，其测试代码位于包c下面，测试代码导入并引用了包d，而包d本身却导入并引用了包c，这种包循环引用是Go编译器所不允许的。 包外测试（仅针对导出API的测试） 与包内测试本质是面向实现的白盒测试不同，包外测试的本质是一种面向接口的黑盒测试。这里的“接口”指的就是被测试包对外导出的API，这些API是被测包与外部交互的契约。 契约一旦确定就会长期稳定，这一本质让包外测试代码与被测试包充分解耦，使得针对这些导出API进行测试的包外测试代码表现出十分健壮的特性 包外测试将测试代码放入不同于被测试包的独立包的同时，也使得包外测试不再像包内测试那样存在“包循环引用”的硬伤。 包外测试这种纯黑盒的测试还有一个功能域之外的好处，那就是可以更加聚焦地从用户视角验证被测试包导出API的设计的合理性和易用性。 不过包外测试的不足也是显而易见的，那就是存在测试盲区，很容易出现对被测试包的测试覆盖不足的情况。 安插后门 针对包外测试，测试覆盖不足的问题，Go标准库的实现者们提供了一个解决这个问题的惯用法\"安插后门\"：export_test.go。该文件中的代码位于被测包名下，但它既不会被包含在正式产品代码中（因为位于_test.go文件中），又不包含任何测试代码，而仅用于将被测包的内部符号在测试阶段暴露给包外测试代码： // $GOROOT/src/fmt/export_test.go package fmt var IsSpace = isSpace var Parsenum = parsenum 或者定义一些辅助包外测试的代码，比如扩展被测包的方法集合： // $GOROOT/src/strings/export_test.go package strings func (r *Replacer) Replacer() interface{} { r.once.Do(r.buildOnce) return r.r } func (r *Replacer) PrintTrie() string { r.once.Do(r.buildOnce) gen := r.r.(*genericReplacer) return gen.printNode(\u0026gen.root, 0) } export_test.go仅在go test阶段与被测试包（fmt）一并被构建入最终的测试二进制文件中。在这个过程中，包外测试代码（fmt_test）可以通过导入被测试包（fmt）来访问export_test.go中的导出符号（如IsSpace或对fmt包的扩展）。而export_test.go相当于在测试阶段扩展了包外测试代码的视野，让很多本来很难覆盖到的测试路径变得容易了，进而让包外测试覆盖更多被测试包中的执行路径。 总结 个人更倾向于优先选择包外测试，理由如下。包外测试可以： 优先保证被测试包导出API的正确性； 可从用户角度验证导出API的有效性； 保持测试代码的健壮性，尽可能地降低对测试代码维护的投入； 不失灵活！可通过export_test.go这个“后门”来导出我们需要的内部符号，满足窥探包内实现逻辑的需求。 当然go test也完全支持对被测包同时运用包内测试和包外测试两种测试方法，在这种情况下，包外测试由于将测试代码放入独立的包中，它更适合编写偏向集成测试的用例，它可以任意导入外部包，并测试与外部多个组件的交互。而包内测试更聚焦于内部逻辑的测试，通过给函数/方法传入一些特意构造的数据的方式来验证内部逻辑的正确性。 我们还可以通过测试代码的文件名来区分所属测试类别，比如：net/http包就使用transport_internal_test.go这个名字来明确该测试文件采用包内测试的方法，而对应的transport_test.go则是一个采用包外测试的源文件。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:1","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.2 测试代码组织 平铺模式 go test并没有对测试代码的组织提出任何约束条件。最简单就是平铺模式: 测试函数各自独立，测试函数之间没有层级关系，所有测试平铺在顶层。测试函数名称既用来区分测试，又用来关联测试。 // -run提供正则表达式来匹配并选择执行哪些测试函数 go test -run=TestCompare -v . xUnit家族模式 使用了xUnit家族单元测试框架的典型测试代码组织形式如下图所示: 这种测试代码组织形式主要有测试套件（Test Suite）和测试用例（Test Case）两个层级。Go 1.7中加入的对subtest的支持让我们在Go中也可以使用上面这种方式组织Go测试代码。 func testCompare(t *testing.T) { for _, tt := range compareTests { cmp := strings.Compare(tt.a, tt.b) if cmp != tt.i { t.Errorf(`Compare(%q, %q) = %v`, tt.a, tt.b, cmp) } } } func testCompareIdenticalString(t *testing.T) { var s = \"Hello Gophers!\" if strings.Compare(s, s) != 0 { t.Error(\"s != s\") } if strings.Compare(s, s[:1]) != 1 { t.Error(\"s \u003e s[:1] failed\") } } func testCompareStrings(t *testing.T) { } func TestCompare(t *testing.T) { t.Run(\"Compare\", testCompare) t.Run(\"CompareString\", testCompareStrings) t.Run(\"CompareIdenticalString\", testCompareIdenticalString) } 两种测试模式的结构对比如下图所示: 改造后的名字形如TestXxx的测试函数对应着测试套件，一般针对被测包的一个导出函数或方法的所有测试都放入一个测试套件中。平铺模式下的测试函数TestXxx都改名为testXxx，并作为测试套件对应的测试函数内部的子测试（subtest）。这样的一个子测试等价于一个测试用例。通过对比，我们看到，仅通过查看测试套件内的子测试（测试用例）即可全面了解到究竟对被测函数/方法进行了哪些测试。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:2","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.3 测试固件 测试固件(test fixture)是指一个人造的、确定性的环境。我们一般使用setUp和tearDown来代表测试固件的创建/设置与拆除/销毁的动作。 在传统的平铺模式下，由于每个测试函数都是相互独立的，们需要为每个TestXxx测试函数单独创建和销毁测试固件。 // chapter8/sources/classic_testfixture_test.go package demo_test ... func setUp(testName string) func() { fmt.Printf(\"\\tsetUp fixture for %s\\n\", testName) return func() { fmt.Printf(\"\\ttearDown fixture for %s\\n\", testName) } } func TestFunc1(t *testing.T) { defer setUp(t.Name())() fmt.Printf(\"\\tExecute test: %s\\n\", t.Name()) } 在setUp中返回匿名函数来实现tearDown的好处是，可以在setUp中利用闭包特性在两个函数间共享一些变量，避免了包级变量的使用。Go 1.14版本testing包增加了testing.Cleanup方法，为测试固件的销毁提供了包级原生的支持： func setUp() func(){ ... return func() { } } func TestXxx(t *testing.T) { t.Cleanup(setUp()) ... } 有些时候，我们需要将所有测试函数放入一个更大范围的测试固件环境中执行，这就是包级别测试固件。Go 1.4版本引入了TestMain 用于创建和销毁包级别测试固件 // chapter8/sources/classic_package_level_testfixture_test.go package demo_test ... func setUp(testName string) func() { fmt.Printf(\"\\tsetUp fixture for %s\\n\", testName) return func() { fmt.Printf(\"\\ttearDown fixture for %s\\n\", testName) } } func TestFunc3(t *testing.T) { t.Cleanup(setUp(t.Name())) fmt.Printf(\"\\tExecute test: %s\\n\", t.Name()) } func TestFunc2(t *testing.T) { t.Cleanup(suiteSetUp(t.Name())) t.Run(\"testcase1\", func2TestCase1) t.Run(\"testcase2\", func2TestCase2) t.Run(\"testcase3\", func2TestCase3) } func pkgSetUp(pkgName string) func() { fmt.Printf(\"package SetUp fixture for %s\\n\", pkgName) return func() { fmt.Printf(\"package TearDown fixture for %s\\n\", pkgName) } } func TestMain(m *testing.M) { defer pkgSetUp(\"package demo_test\")() m.Run() } 使用 xUnit 模式创建测试固件的方法与平铺模式完全相同，通过组合，就可以形成一种多层次的、更灵活的测试固件设置体系。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:3","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.4 表驱动的测试 Go的测试函数就是一个普通的Go函数，Go仅对测试函数的函数名和函数原型有特定要求，对测试失败与否的判断在于测试代码逻辑是否进入了包含Error/Errorf、Fatal/Fatalf等方法调用的代码分支。一旦进入这些分支，即代表该测试失败。不同的是Error/Errorf并不会立刻终止当前goroutine的执行，还会继续执行该goroutine后续的测试，而Fatal/Fatalf则会立刻停止当前goroutine的测试执行。 表驱动测试十分适合Go代码测试，我们看下面这个示例: // chapter8/sources/table_driven_strings_with_subtest_test.go func TestCompare(t *testing.T) { compareTests := []struct { name, a, b string i int }{ {`compareTwoEmptyString`, \"\", \"\", 0}, {`compareSecondParamIsEmpty`, \"a\", \"\", 1}, {`compareFirstParamIsEmpty`, \"\", \"a\", -1}, } for _, tt := range compareTests { t.Run(tt.name, func(t *testing.T) { cmp := strings.Compare(tt.a, tt.b) if cmp != tt.i { t.Errorf(`want %v, but Compare(%q, %q) = %v`, tt.i, tt.a, tt.b, cmp) } }) } } 在示例中，我们将测试结果的判定逻辑放入一个单独的子测试中，这样可以单独执行表中某项数据的测试: $go test -v -run /TwoEmptyString table_driven_strings_with_subtest_test.go 测试失败的定位 对于非表驱动的测试，在测试失败时，我们往往通过失败点所在的行数即可判定究竟是哪块测试代码未通过，但在表驱动的测试中，由于一般情况下表驱动的测试的测试结果成功与否的判定逻辑是共享的，因此再通过行数来定位问题就不可行了。 为了在表测试驱动的测试中快速从输出的结果中定位导致测试失败的表项，我们需要在测试失败的输出结果中输出数据表项的唯一标识。最简单的方法是通过输出数据表项在数据表中的偏移量来辅助定位“元凶”： // chapter8/sources/table_driven_strings_by_offset_test.go func TestCompare(t *testing.T) { compareTests := []struct { a, b string i int }{ {\"\", \"\", 7}, {\"a\", \"\", 6}, {\"\", \"a\", -1}, } for i, tt := range compareTests { cmp := strings.Compare(tt.a, tt.b) if cmp != tt.i { t.Errorf(`[table offset: %v] want %v, but Compare(%q, %q) = %v`, i+1, tt.i, tt.a, tt.b, cmp) } } } 另一个更直观的方式是使用名字来区分不同的数据项： // chapter8/sources/table_driven_strings_by_name_test.go func TestCompare(t *testing.T) { compareTests := []struct { name, a, b string i int }{ {\"compareTwoEmptyString\", \"\", \"\", 7}, {\"compareSecondStringEmpty\", \"a\", \"\", 6}, {\"compareFirstStringEmpty\", \"\", \"a\", -1}, } for _, tt := range compareTests { cmp := strings.Compare(tt.a, tt.b) if cmp != tt.i { t.Errorf(`[%s] want %v, but Compare(%q, %q) = %v`, tt.name, tt.i, tt.a, tt.b, cmp) } } } 个人推荐这种方式，结合自测试，可以更灵活的执行单元测试，便于排错。 Errorf还是Fatalf 一般而言，如果一个数据项导致的测试失败不会对后续数据项的测试结果造成影响，那么推荐Errorf，这样可以通过执行一次测试看到所有导致测试失败的数据项；否则，如果数据项导致的测试失败会直接影响到后续数据项的测试结果，那么可以使用Fatalf让测试尽快结束，因为继续执行的测试的意义已经不大了。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:4","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.5 testdata Go语言规定：Go工具链将忽略名为testdata的目录。这样开发者在编写测试时，就可以在名为testdata的目录下存放和管理测试代码依赖的数据文件。而go test命令在执行时会将被测试程序包源码所在目录设置为其工作目录，这样如果要使用testdata目录下的某个数据文件，我们无须再处理各种恼人的路径问题，而可以直接在测试代码中像下面这样定位到充当测试固件的数据文件： f, err := os.Open(\"testdata/data-001.txt\") f, err := os.Open(filepath.Join(\"testdata\", \"data-001.txt\")) golden 文件惯用法 我们经常将预期结果数据保存在文件中并放置在testdata下，用于测试结果的比较基准。那我们怎么得到这些 golden 文件，能否把将预期数据采集到文件的过程与测试代码融合到一起呢？Go标准库为我们提供了一种惯用法：golden文件。 var update = flag.Bool(\"update\", false, \"update .golden files\") func TestAttendeeMarshal(t *testing.T) { for _, tt := range tests { got, err := xml.MarshalIndent(\u0026tt.a, \"\", \" \") if err != nil { t.Fatalf(\"want nil, got %v\", err) } // update的变量以及它所控制的golden文件的预期结果数据采集过程 golden := filepath.Join(\"testdata\", tt.fileName) if *update { ioutil.WriteFile(golden, got, 0644) } want, err := ioutil.ReadFile(golden) if err != nil { t.Fatalf(\"open file %s failed: %v\", tt.fileName, err) } if !bytes.Equal(got, want) { t.Errorf(\"want %s, got %s\", string(want), string(got)) } } } 这个测试代码中，有一个名为 update 的变量以及它所控制的golden文件的预期结果数据采集过程。 go test -v . -update 带有-update命令参数的go test命令仅在需要进行预期结果数据采集时才会执行，尤其是在因数据生成逻辑或类型结构定义发生变化，需要重新采集预期结果数据时。采用golden文件惯用法后，要格外注意在每次重新采集预期结果后，对golden文件中的数据进行正确性检查，否则很容易出现预期结果数据不正确，但测试依然通过的情况。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:5","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"1.6 fake/stub/mock 测试过程中，除了对外部文件数据的依赖之外，还会经常面对被测代码对外部业务组件或服务的依赖。我们需要为这些被测代码提供其依赖的外部组件或服务的替身。替身概念出自于测试驱动编程，xUnit家族框架总结出多种替身，比如fake、stub、mock等。这些概念及其应用模式被汇集在xUnit Test Patterns一书中。接下来我们就来看看这些替身在 go 单元测试中的应用。 fake fake 实现的替身不具备在测试前对返回结果进行预设置的能力，我们看下面这个例子: type mailClient struct { mlr mailer.Mailer } type Mailer interface { SendMail(subject, destination, body string) error } mailClient 的实现依赖 mailer.Mailer 接口，生产环境中用于发送邮件，单元测试中不可能真的准备一个邮件服务。我们可以 fake 出 Mailer 接口两个简化版的实现：fakeOkMailer和fakeFailMailer，前者代表发送成功，后者代表发送失败。 type fakeOkMailer struct{} func (m *fakeOkMailer) SendMail(subject string, dest string, body string) error { return nil } func TestComposeAndSendOk(t *testing.T) { m := \u0026fakeOkMailer{} mc := mailclient.New(m) _, err := mc.ComposeAndSend(\"hello, fake test\", []string{\"xxx@example.com\"}, \"the test body\") if err != nil { t.Errorf(\"want nil, got %v\", err) } } type fakeFailMailer struct{} func (m *fakeFailMailer) SendMail(subject string, dest string, body string) error { return fmt.Errorf(\"can not reach the mail server of dest [%s]\", dest) } func TestComposeAndSendFail(t *testing.T) { m := \u0026fakeFailMailer{} mc := mailclient.New(m) _, err := mc.ComposeAndSend(\"hello, fake test\", []string{\"xxx@example.com\"}, \"the test body\") if err == nil { t.Errorf(\"want non-nil, got nil\") } } 使用fake替身进行测试的最常见理由是在测试环境无法构造被测代码所依赖的外部组件或服务，或者这些组件/服务有副作用。但是 fake 替身不具备在测试前对返回结果进行预设置的能力。如果非要说成功和失败也是预设置的，那么fake替身的预设置能力也仅限于设置单一的返回值，即无论调用多少次，传入什么参数，返回值都是一个。 stub stub也是一种替身概念，和fake替身相比，stub替身增强了对替身返回结果的间接控制能力，这种控制可以通过测试前对调用结果预设置来实现。不过，stub替身通常仅针对计划之内的结果进行设置，对计划之外的请求也无能为力。 在GitHub上有一个名为gostub的第三方包可以用于简化stub替身的管理和编写。下面是一个使用的示例: func TestComposeAndSendWithSign(t *testing.T) { sender := \"tonybai@example.com\" timestamp := \"Mon, 04 May 2020 11:46:12 CST\" stubs := gostub.Stub(\u0026getSign, func(sender string) string { selfSignTxt := senderSigns[sender] return selfSignTxt + \"\\n\" + timestamp }) defer stubs.Reset() ... } mock 和fake、stub替身相比，mock替身更为强大：它除了能提供测试前的预设置返回结果能力之外，还可以对mock替身对象在测试过程中的行为进行观察和验证。不过相比于前两种替身形式，mock存在应用局限（尤指在Go中）: 和前两种替身相比，mock的应用范围要窄很多，只用于实现某接口的实现类型的替身。 一般需要通过第三方框架实现mock替身。Go官方维护了一个mock框架——gomock，该框架通过代码生成的方式生成实现某接口的替身类型。 gomock是一个通用的mock框架，社区还有一些专用的mock框架可用于快速创建mock替身，比如：go-sqlmock专门用于创建sql/driver包中的Driver接口实现的mock替身，可以帮助Gopher简单、快速地建立起对数据库操作相关方法的单元测试。 mock 一般实现起来，都需要借助语言本身提供的反射能力，用法比较复杂，常规的单元测试中不建议使用。 总结 我们更多在包内测试应用上述替身概念辅助测试，这就意味着此类测试与被测代码是实现级别耦合的，这样的测试健壮性较差，一旦被测代码内部逻辑有变化，测试极容易失败。通过fake、stub、mock等概念实现的替身参与的测试毕竟是在一个虚拟的“沙箱”环境中，不能代替与真实依赖连接的测试，因此，在集成测试或系统测试等使用真实外部组件或服务的测试阶段，务必包含与真实依赖的联测用例。 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:1:6","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"2. go-fuzz 模糊测试 暂略 ","date":"2023-01-01","objectID":"/posts/program/go/expert/go_export/expert_9/:2:0","tags":["go 进阶"],"title":"Go 测试","uri":"/posts/program/go/expert/go_export/expert_9/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言的并发编程，将详细介绍Go基本执行单元——goroutine的调度原理、Go并发模型以及常见并发模式、Go支持并发的原生类型——channel的惯用使用模式等内容。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:0:0","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1. goroutine的调度原理 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:0","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1.1 goroutine调度模型和演进历史 G-M模型 Go 1.0正式发布。在这个版本中，Go开发团队实现了一个简单的goroutine调度器。在这个调度器中: 每个goroutine对应于运行时中的一个抽象结构——G（goroutine） 被视作“物理CPU”的操作系统线程则被抽象为另一个结构——M（machine） G-M模型存在严重不足：限制了Go并发程序的伸缩性。 G-P-M模型 Go 1.1版本中实现了 G-P-M调度模型和work stealing算法，这个模型一直沿用至今: P是一个“逻辑处理器”，每个G要想真正运行起来，首先需要被分配一个P，即进入P的本地运行队列（local runq）中，这里暂忽略全局运行队列（global runq）那个环节。对于G来说，P就是运行它的“CPU”，可以说在G的眼里只有P。但从goroutine调度器的视角来看，真正的“CPU”是M，只有将P和M绑定才能让P的本地运行队列中的G真正运行起来。这样的P与M的关系就好比Linux操作系统调度层面用户线程（user thread）与内核线程（kernel thread）的对应关系：多对多（N:M）。 抢占式调度 G-P-M模型的实现是goroutine调度器的一大进步，但调度器仍然有一个头疼的问题，那就是不支持抢占式调度，这导致一旦某个G中出现死循环的代码逻辑，那么G将永久占用分配给它的P和M，而位于同一个P中的其他G将得不到调度，出现“饿死”的情况。更为严重的是，当只有一个P（GOMAXPROCS=1）时，整个Go程序中的其他G都将“饿死”。于是Dmitry Vyukov又提出了“Go抢占式调度器设计”（Go Preemptive Scheduler Design），并在Go 1.2版本中实现了抢占式调度。 这个抢占式调度的原理是在每个函数或方法的入口加上一段额外的代码，让运行时有机会检查是否需要执行抢占调度。这种协作式抢占调度的解决方案只是局部解决了“饿死”问题，对于没有函数调用而是纯算法循环计算的G，goroutine调度器依然无法抢占。 其他优化 Go运行时已经实现了netpoller，这使得即便G发起网络I/O操作也不会导致M被阻塞（仅阻塞G），因而不会导致大量线程（M）被创建出来。 但是对于常规文件的I/O操作一旦阻塞，那么线程（M）将进入挂起状态，等待I/O返回后被唤醒。这种情况下P将与挂起的M分离，再选择一个处于空闲状态（idle）的M。如果此时没有空闲的M，则会新创建一个M（线程），这就是大量文件I/O操作会导致大量线程被创建的原因。 Go开发团队的Ian Lance Taylor在Go 1.9版本中增加了一个针对文件I/O的Poller，它可以像netpoller那样，在G操作那些支持监听的（pollable）文件描述符时，仅阻塞G，而不会阻塞M。不过该功能依然对常规文件无效，常规文件是不支持监听的。但对于goroutine调度器而言，这也算是一个不小的进步了。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:1","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1.2 G-P-M模型 关于G、P、M的定义，可以参见$GOROOT/src/runtime/runtime2.go这个源文件: G：代表goroutine，存储了goroutine的执行栈信息、goroutine状态及goroutine的任务函数等。另外G对象是可以重用的。 P：代表逻辑processor，P的数量决定了系统内最大可并行的G的数量（前提：系统的物理CPU核数\u003e=P的数量）。P中最有用的是其拥有的各种G对象队列、链表、一些缓存和状态。 M：M代表着真正的执行计算资源。在绑定有效的P后，进入一个调度循环；而调度循环的机制大致是从各种队列、P的本地运行队列中获取G，切换到G的执行栈上并执行G的函数，调用goexit做清理工作并回到M。如此反复。M并不保留G状态，这是G可以跨M调度的基础。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:2","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1.3 抢占调度 与操作系统按时间片调度线程不同，Go中并没有时间片的概念。如果某个G没有进行系统调用（syscall）、没有进行I/O操作、没有阻塞在一个channel操作上，那么M是如何让G停下来并调度下一个可运行的G的呢？答案是：G是被抢占调度的。前面说过，除非极端的无限循环或死循环，否则只要G调用函数，Go运行时就有了抢占G的机会。 在Go程序启动时，运行时会启动一个名为sysmon的M（一般称为监控线程），该M的特殊之处在于它无须绑定P即可运行（以g0这个G的形式）。该M在整个Go程序的运行过程中至关重要，参见下面代码： //$GOROOT/src/runtime/proc.go // The main goroutine. func main() { ... systemstack(func() { newm(sysmon, nil) }) ... } // 运行无须P参与 // //go:nowritebarrierrec func sysmon() { // 如果一个heap span在垃圾回收后5分钟内没有被使用 // 就把它归还给操作系统 scavengelimit := int64(5 * 60 * 1e9) ... if ... { ... // 夺回被阻塞在系统调用中的P // 抢占长期运行的G if retake(now) != 0 { idle = 0 } else { idle++ } ... } } sysmon每20us~10ms启动一次，主要完成如下工作： 释放闲置超过5分钟的span物理内存； 如果超过2分钟没有垃圾回收，强制执行； 将长时间未处理的netpoll结果添加到任务队列； 向长时间运行的G任务发出抢占调度； 收回因syscall长时间阻塞的P。 sysmon将向长时间运行的G任务发出抢占调度，这由函数retake实施： // $GOROOT/src/runtime/proc.go // forcePreemptNS是在一个G被抢占之前给它的时间片 const forcePreemptNS = 10 * 1000 * 1000 // 10ms func retake(now int64) uint32 { ... // 抢占运行时间过长的G t := int64(_p_.schedtick) if int64(pd.schedtick) != t { pd.schedtick = uint32(t) pd.schedwhen = now continue } if pd.schedwhen+forcePreemptNS \u003e now { continue } preemptone(_p_) ... } 可以看出，如果一个G任务运行超过10ms，sysmon就会认为其运行时间太久而发出抢占式调度的请求。一旦G的抢占标志位被设为true，那么在这个G下一次调用函数或方法时，运行时便可以将G抢占并移出运行状态，放入P的本地运行队列中（如果P的本地运行队列已满，那么将放在全局运行队列中），等待下一次被调度。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:3","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1.4 channel阻塞或网络I/O情况下的调度 如果G被阻塞在某个channel操作或网络I/O操作上，那么G会被放置到某个等待队列中，而M会尝试运行P的下一个可运行的G。如果此时P没有可运行的G供M运行，那么M将解绑P，并进入挂起状态。当I/O操作完成或channel操作完成，在等待队列中的G会被唤醒，标记为runnable（可运行），并被放入某个P的队列中，绑定一个M后继续执行。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:4","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"1.5 系统调用阻塞情况下的调度 如果G被阻塞在某个系统调用上，那么不仅G会阻塞，执行该G的M也会解绑P（实质是被sysmon抢走了），与G一起进入阻塞状态。如果此时有空闲的M，则P会与其绑定并继续执行其他G；如果没有空闲的M，但仍然有其他G要执行，那么就会创建一个新M（线程）。 当系统调用返回后，阻塞在该系统调用上的G会尝试获取一个可用的P，如果有可用P，之前运行该G的M将绑定P继续运行G；如果没有可用的P，那么G与M之间的关联将解除，同时G会被标记为runnable，放入全局的运行队列中，等待调度器的再次调度。 ","date":"2022-12-31","objectID":"/posts/program/go/expert/go_export/expert_8/:1:5","tags":["go 进阶"],"title":"并发编程","uri":"/posts/program/go/expert/go_export/expert_8/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言的函数、方法和接口 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:0:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"1. 函数 Go 语言里函数是\"一等公民\"，简单来讲函数可以像变量值那样被赋值给变量、作为参数传递、作为返回值返回和在函数内部创建等。概念我们就不过介绍，我们把关注在放在 Go 语言函数的一些典型应用上。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:1:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"1.1 函数的显示类型转换 这个示例来自 net/http 的 http.HandlerFunc: ListenAndServe 接收 Handler 接口作为参数 自定义的类型 HandlerFunc 实现了 Handler 接口 通过显示的类型转换 http.HandlerFunc(greeting)，将函数greeting显式转换为HandlerFunc类型，转型后的greeting就满足了ListenAndServe函数第二个参数的要求 func greeting(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Welcome, Gopher!\\n\") } func main() { http.ListenAndServe(\":8080\", http.HandlerFunc(greeting)) } // $GOROOT/src/net/http/server.go func ListenAndServe(addr string, handler Handler) error { server := \u0026Server{Addr: addr, Handler: handler} return server.ListenAndServe() } // $GOROOT/src/net/http/server.go type Handler interface { ServeHTTP(ResponseWriter, *Request) } type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP调用f(w, r) func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:1:1","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"1.2 函子 函子是函数式编程利的概念，函子非常适合用来对容器集合元素进行批量同构处理。我们直接来看示例: // 函子 type IntSliceFunctor interface { Fmap(fn func(int) int) IntSliceFunctor } // 函子的载体，这个载体包含了要处理的数据，并将处理数据的框架暴露通过 Fmap 暴露出去 type intSliceFunctorImpl struct { ints []int } func (isf intSliceFunctorImpl) Fmap(fn func(int) int) IntSliceFunctor { newInts := make([]int, len(isf.ints)) for i, elt := range isf.ints { retInt := fn(elt) newInts[i] = retInt } return intSliceFunctorImpl{ints: newInts} } func NewIntSliceFunctor(slice []int) IntSliceFunctor { return intSliceFunctorImpl{ints: slice} } // 使用 func main() { // 原切片 intSlice := []int{1, 2, 3, 4} f := NewIntSliceFunctor(intSlice) fmt.Printf(\"original functor: %+v\\n\", f) mapperFunc1 := func(i int) int { return i + 10 } mapped1 := f.Fmap(mapperFunc1) fmt.Printf(\"mapped functor1: %+v\\n\", mapped1) mapperFunc2 := func(i int) int { return i * 3 } mapped2 := mapped1.Fmap(mapperFunc2) fmt.Printf(\"mapped functor2: %+v\\n\", mapped2) fmt.Printf(\"original functor: %+v\\n\", f) // 原函子没有改变 fmt.Printf(\"composite functor: %+v\\n\", f.Fmap(mapperFunc1).Fmap(mapperFunc2)) } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:1:2","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"1.2 变长参数函数 变长参数函数就是可以接收任意个参数的函数，比如 fmt.Println: func Println(a ...interface{}) (n int, err error)。 形参a的类型是一个比较奇特的组合：… interface{}。这种接受“…T”类型形式参数的函数就被称为变长参数函数: 一个变长参数函数只能有一个“…T”类型形式参数，并且该形式参数应该为函数参数列表中的最后一个形式参数 变长参数函数的“…T”类型形式参数在函数体内呈现为[]T类型的变量 在函数外部，“…T”类型形式参数可匹配和接受的实参类型有两种 多个T类型变量； t…（t为[]T类型变量） 只能选择上述两种实参类型中的一种 变长参数函数时最容易出现的一个问题是实参与形参不匹配: func dump(args ...interface{}) { for _, v := range args { fmt.Println(v) } } func main() { s := []string{\"Tony\", \"John\", \"Jim\"} dump(s...) } $ go run variadic_function_2.go ./variadic_function_2.go:14:6: cannot use s (type []string) as type []interface {} in argument to dump 编译器给出了“类型不匹配”的错误。dump函数的变长参数类型为“…interface{}”，因此匹配该形参的要么是interface{}类型的变量，要么为“t…”（t类型为[]interface{}）。在例子中给dump传入的实参为“s…”，但s的类型为[]string，并非[]interface{}，导致不匹配。这里要注意的是，虽然string类型变量可以直接赋值给interface{}类型变量，但是[]string类型变量并不能直接赋值给[]interface{}类型变量。 不过有个例外，那就是Go内置的append函数，它支持通过下面的方式将字符串附加到一个字节切片后面： func main() { b := []byte{} b = append(b, \"hello\"...) fmt.Println(string(b)) } $ go run variadic_function_3.go hello string类型本是不满足类型要求的（append本需要[]byte...），这算是Go编译器的一个优化，编译器自动将string隐式转换为了[]byte。如果是我们自定义的函数，那么是无论如何都不能支持这样的用法的。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:1:3","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"2. defer defer的运作离不开函数，这至少有两层含义： 在Go中，只有在函数和方法内部才能使用defer； defer关键字后面只能接函数或方法，这些函数被称为deferred函数。defer将它们注册到其所在goroutine用于存放deferred函数的栈数据结构中，这些deferred函数将在执行defer的函数退出(无论是正常退出，还是 panic)前被按后进先出（LIFO）的顺序调度执行 defer 有一些关键问题需要了解，否则很容掉进一些坑里: 对于有返回值的自定义函数或方法，返回值会在deferred函数被调度执行的时候被自动丢弃。 Go语言中除了有自定义的函数或方法，还有内置函数 支持用在 defer: close、copy、delete、print、recover 不支持用在 defer: append、cap、len、make、new 不能直接作为deferred函数的内置函数，可以使用一个包裹它的匿名函数来间接满足要求 defer关键字后面的表达式是在将deferred函数注册到deferred函数栈的时候进行求值的 // append 不支持在 defer 中使用，可以使用匿名函数包裹 defer func (){ append(sl, 11) }() // defer 的求值时机 func foo1() { for i := 0; i \u003c= 3; i++ { // defer将fmt.Println注册到deferred函数栈的时候，都会对Println后面的参数 i 进行求值 // 在foo1返回后,将输出 3 2 1 defer fmt.Println(i) } } func foo3() { for i := 0; i \u003c= 3; i++ { // 匿名函数以闭包的方式访问外围函数的变量i // foo3返回后，将输出 4 4 4 4 defer func() { fmt.Println(i) }() } } 在上面的示例中: foo1中，defer后面直接接的是fmt.Println函数，每当defer将fmt.Println注册到deferred函数栈的时候，都会对Println后面的参数进行求值。根据上述代码逻辑，依次压入deferred函数栈的函数是： fmt.Println(0) fmt.Println(1) fmt.Println(2) fmt.Println(3) foo3中，defer后面接的是一个不带参数的匿名函数。根据上述代码逻辑，依次压入deferred函数栈的函数是： func() func() func() func() ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:2:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"2.1 defer 常用用法 拦截panic defer + recover 可以从 panic 中恢复: // $GOROOT/src/bytes/buffer.go func makeSlice(n int) []byte { // If the make fails, give a known error. defer func() { if recover() != nil { panic(ErrTooLarge) // 触发一个新panic } }() return make([]byte, n) } deferred函数虽然可以拦截绝大部分的panic，但无法拦截并恢复一些运行时之外的致命问题。 修改函数的具名返回值 // $GOROOT/src/fmt/scan.go func (s *ss) Token(skipSpace bool, f func(rune) bool) (tok []byte, err error) { defer func() { if e := recover(); e != nil { if se, ok := e.(scanError); ok { // 修改了 err 的返回值 err = se.err } else { panic(e) } } }() ... } 输出调试信息 deferred函数被注册及调度执行的时间点使得它十分适合用来输出一些调试信息。 比如 net 包中的hostLookupOrder方法就使用deferred函数在特定日志级别下输出一些日志以便于程序调试和跟踪。 // $GOROOT/src/net/conf.go func (c *conf) hostLookupOrder(r *Resolver, hostname string) (ret hostLookupOrder) { if c.dnsDebugLevel \u003e 1 { defer func() { print(\"go package net: hostLookupOrder(\", hostname, \") = \", ret.String(), \"\\n\") }() } ... } 另一个用法是在在出入函数时打印留痕日志: func trace(s string) string { fmt.Println(\"entering:\", s) return s } func un(s string) { fmt.Println(\"leaving:\", s) } func a() { defer un(trace(\"a\")) fmt.Println(\"in a\") } func b() { defer un(trace(\"b\")) fmt.Println(\"in b\") a() } 还原变量旧值 // $GOROOT/src/syscall/fs_nacl.go func init() { oldFsinit := fsinit defer func() { fsinit = oldFsinit }() fsinit = func() {} .... } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:2:1","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"2. 方法 和函数相比，Go语言中的方法在声明形式上仅仅多了一个参数，Go称之为receiver参数。 func (receiver T/*T) MethodName(参数列表) (返回值列表) { // 方法体 } 上面方法声明中的T称为receiver的基类型。通过receiver，上述方法被绑定到类型T上。Go方法具有如下特点: 方法名的首字母是否大写决定了该方法是不是导出方法 方法定义要与类型定义放在同一个包内。由此我们可以推出： 不能为原生类型（如int、float64、map等）添加方法，只能为自定义类型定义方法 不能横跨Go包为其他包内的自定义类型定义方法 每个方法只能有一个receiver参数，不支持多receiver参数列表或变长receiver参数。一个方法只能绑定一个基类型，Go语言不支持同时绑定多个类型的方法 receiver参数的基类型本身不能是指针类型或接口类型 type MyInt *int func (r MyInt) String() string { // 编译器错误：invalid receiver type MyInt (MyInt is a pointer type) return fmt.Sprintf(\"%d\", *(*int)(r)) } type MyReader io.Reader func (r MyReader) Read(p []byte) (int, error) { // 编译器错误：invalid receiver type MyReader (MyReader is an interface type) return r.Read(p) } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:3:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"2.1 方法的本质 type T struct { a int } func (t T) Get() int { return t.a } func (t *T) Set(a int) int { t.a = a return t.a } } C++的对象在调用方法时，编译器会自动传入指向对象自身的this指针作为方法的第一个参数。而对于Go来说，receiver其实也是同样道理，我们将receiver作为第一个参数传入方法的参数列表。上面示例中类型T的方法可以等价转换为下面的普通函数： func Get(t T) int { return t.a } func Set(t *T, a int) int { t.a = a return t.a } 这种转换后的函数就是方法的原型。只不过在Go语言中，这种等价转换是由Go编译器在编译和生成代码时自动完成的。 方法表达式 Go方法的一般使用方式如下： var t T t.Get() t.Set(1) 我们可以用如下方式等价替换上面的方法调用： var t T T.Get(t) (*T).Set(\u0026t, 1) 这种直接以类型名T调用方法的表达方式被称为方法表达式（Method Expression）。类型T只能调用T的方法集合（Method Set）中的方法，同理，*T只能调用*T的方法集合中的方法。 这种通过方法表达式对方法进行调用的方式与我们之前所做的方法到函数的等价转换如出一辙。这就是Go方法的本质：一个以方法所绑定类型实例为第一个参数的普通函数。Go方法自身的类型就是一个普通函数，甚至可以将其作为右值赋值给函数类型的变量： var t T f1 := (*T).Set // f1的类型，也是T类型Set方法的原型：func (t *T, int)int f2 := T.Get // f2的类型，也是T类型Get方法的原型：func (t T)int f1(\u0026t, 3) fmt.Println(f2(t)) ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:3:1","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"2.2 选择正确的receiver类型 方法和函数的等价变换公式： func (t T) M1() \u003c=\u003e M1(t T) func (t *T) M2() \u003c=\u003e M2(t *T) func (t T) M1() \u003c=\u003e T.M1(t T) func (t *T) M2() \u003c=\u003e (*T).M2(t *T) 可以看到: 当receiver参数的类型为T时，选择值类型的receiver，即: M1函数体中的t是T类型实例的一个副本 当receiver参数的类型为*T时，选择指针类型的receiver，即: 给M2函数的t是T类型实例的地址 无论是T类型实例还是*T类型实例，都既可以调用receiver为T类型的方法，也可以调用receiver为*T类型的方法。这都是Go语法糖，Go编译器在编译和生成代码时为我们自动做了转换: func main() { var t T t.M1() // ok t.M2() // \u003c=\u003e (\u0026t).M2() var pt = \u0026T{} pt.M1() // \u003c=\u003e (*pt).M1() pt.M2() // ok } 到这里，我们可以得出receiver类型选用的初步结论。 如果要对类型实例进行修改，那么为receiver选择*T类型。 如果没有对类型实例修改的需求，那么为receiver选择T类型或*T类型均可 考虑到Go方法调用时，receiver是以值复制的形式传入方法中的，如果类型的size较大，以值形式传入会导致较大损耗，这时选择*T作为receiver类型会更好些 关于receiver类型的选择其实还有一个重要因素，那就是类型是否要实现某个接口 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:3:2","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3. 方法集合 在 Go 中方法集合决定接口实现。要判断一个自定义类型是否实现了某接口类型，我们首先要识别出自定义类型的方法集合和接口类型的方法集合。Go语言规范： 对于非接口类型的自定义类型T，其方法集合由所有receiver为T类型的方法组成； 类型*T的方法集合则包含所有receiver为T和*T类型的方法 不过方法集合的判断有时候并不容器，特别是存在结构体嵌入、接口嵌入和类型别名时。与接口类型和结构体类型相关的类型嵌入有三种组合： 在接口类型中嵌入接口类型 在结构体类型中嵌入接口类型 结构体类型中嵌入结构体类型 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3.1 接口类型中嵌入接口类型 嵌入其他接口类型的新接口类型的方法集合包含了被嵌入接口类型（如io.Reader）的方法集合。不过在Go 1.14之前的版本中这种方式有一个约束，那就是被嵌入的接口类型的方法集合不能有交集，同时被嵌入的接口类型的方法集合中的方法不能与新接口中其他方法同名。 type Interface2 interface { M1() M2() } type Interface3 interface { Interface1 Interface2 // Go 1.14之前版本报错：duplicate method M1 } type Interface4 interface { Interface2 M2() // Go 1.14之前版本报错：duplicate method M2 } 自Go 1.14版本开始，Go语言去除了这个约束。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:1","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3.2 在结构体类型中嵌入接口类型 在结构体类型中嵌入接口类型后，结构体类型的方法集合中将包含被嵌入接口类型的方法集合。 但有些时候结果并非这样，比如当结构体类型中嵌入多个接口类型且这些接口类型的方法集合存在交集时。这里不得不提一下嵌入了其他接口类型的结构体类型的实例在调用方法时，Go选择方法的次序: 优先选择结构体自身实现的方法。 如果结构体自身并未实现，那么将查找结构体中的嵌入接口类型的方法集合中是否有该方法，如果有，则提升（promoted）为结构体的方法 如果结构体嵌入了多个接口类型且这些接口类型的方法集合存在交集，那么Go编译器将报错，除非结构体自己实现了交集中的所有方法 type Interface interface { M1() M2() M3() } type Interface1 interface { M1() M2() M4() } type T struct { Interface Interface1 } func main() { t := T{} t.M1() t.M2() } $ go run method_set_7.go ./method_set_7.go:22:3: ambiguous selector t.M1 ./method_set_7.go:23:3: ambiguous selector t.M2 编译器在结构体类型内部的嵌入接口类型中寻找M1/M2方法时发现两个接口类型Interface和Interface1都包含M1/M2，于是编译器因无法做出选择而报错。 结构体类型在嵌入某接口类型的同时，也实现了这个接口。这一特性在单元测试中尤为有用: type Stmt interface { Close() error NumInput() int Exec(stmt string, args ...string) (Result, error) Query(args []string) (Rows, error) } // 返回男性员工总数 func MaleCount(s Stmt) (int, error) { result, err := s.Exec(\"select count(*) from employee_tab where gender=?\", \"1\") if err != nil { return 0, err } return result.Int(), nil } // 我们要测试 MaleCount import \"testing\" type fakeStmtForMaleCount struct { Stmt } func (fakeStmtForMaleCount) Exec(stmt string, args ...string) (Result, error) { return Result{Count: 5}, nil } func TestEmployeeMaleCount(t *testing.T) { f := fakeStmtForMaleCount{} c, _ := MaleCount(f) if c != 5 { t.Errorf(\"want: %d, actual: %d\", 5, c) return } } 我们为TestEmployeeMaleCount测试用例建立了一个fakeStmtForMaleCount的伪对象，在该结构体类型中嵌入Stmt接口类型，这样fakeStmtForMaleCount就实现了Stmt接口，我们达到了快速建立伪对象的目的。之后，我们仅需为fakeStmtForMaleCount实现MaleCount所需的Exec方法即可。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:2","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3.3 在结构体类型中嵌入结构体类型 在结构体类型中嵌入结构体类型，外部的结构体类型T可以“继承”嵌入的结构体类型的所有方法的实现，并且无论是T类型的变量实例还是*T类型变量实例，都可以调用所有“继承”的方法。 type T1 struct{} func (T1) T1M1() { println(\"T1's M1\") } func (T1) T1M2() { println(\"T1's M2\") } func (*T1) PT1M3() { println(\"PT1's M3\") } type T2 struct{} func (T2) T2M1() { println(\"T2's M1\") } func (T2) T2M2() { println(\"T2's M2\") } func (*T2) PT2M3() { println(\"PT2's M3\") } type T struct { T1 *T2 } 虽然无论通过T类型变量实例还是*T类型变量实例都可以调用所有“继承”的方法（这也是Go语法糖），但是T和*T类型的方法集合是有差别的： T类型的方法集合 = T1的方法集合 + *T2的方法集合； *T类型的方法集合 = *T1的方法集合 + *T2的方法集合 当结构中嵌入的多个结构体的方法集合存在交集时，依旧按照上面所说的 Go选择方法的次序进行处理。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:3","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3.4 defined类型的方法集合 type MyInterface I type Mystruct T 已有的类型（比如上面的I、T）被称为underlying类型，而新类型被称为defined类型。 新定义的defined类型与原underlying类型是完全不同的类型: 基于接口类型创建的defined类型与原接口类型的方法集合是一致 基于自定义非接口类型创建的defined类型则并没有“继承”原类型的方法集合，新的defined类型的方法集合是空的 package main type T struct{} func (T) M1() {} func (*T) M2() {} type Interface interface { M1() M2() } // T 的方法集合为空 type T1 T // Interface 的方法集合与 Interface1 一致 type Interface1 Interface ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:4","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"3.5 类型别名的方法集合 Go在1.9版本中引入了类型别名，支持为已有类型定义别名: type MyInterface = I type Mystruct = T 类型别名与原类型拥有完全相同的方法集合，无论原类型是接口类型还是非接口类型。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:4:5","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"4. 接口 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:5:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"4.1 接口类型变量的内部表示 在看接口的内部表示之前，我们先看一个示例: type MyError struct { error } func returnsError() error { var p *MyError = nil return p } func main() { e := returnsError() // 注意: returnsError 返回值是 error 接口变量 if e != nil { fmt.Printf(\"error: %+v\\n\", e) return } fmt.Println(\"ok\") } $go run interface-internal-1.go error: \u003cnil\u003e returnsError 返回值是 error 接口变量，因此 returnsError 在返回时，存在一个隐式的转换 error(p)。所以虽然 p 是 nil，但是 error(p) != nil。这就涉及到接口类型变量的内部表示了。我们可以在$GOROOT/src/runtime/runtime2.go中找到接口类型变量在运行时的表示： // $GOROOT/src/runtime/runtime2.go type iface struct { tab *itab data unsafe.Pointer } type eface struct { _type *_type data unsafe.Pointer } 我们看到在运行时层面，接口类型变量有两种内部表示——eface和iface，这两种表示分别用于不同接口类型的变量。 eface：用于表示没有方法的空接口（empty interface）类型变量，即interface{}类型的变量。 iface：用于表示其余拥有方法的接口（interface）类型变量。 eface/iface 都有两个指针字段，并且第二个指针字段都指向当前赋值给该接口类型变量的动态类型变量的值。 eface eface 所表示的空接口类型并无方法列表，因此其第一个指针字段指向一个_type类型结构，该结构为该接口类型变量的动态类型的信息： // $GOROOT/src/runtime/type.go type _type struct { size uintptr ptrdata uintptr hash uint32 tflag tflag align uint8 fieldalign uint8 kind uint8 alg *typeAlg gcdata *byte str nameOff ptrToThis typeOff } iface iface除了要存储动态类型信息之外，还要存储接口本身的信息（接口的类型信息、方法列表信息等）以及动态类型所实现的方法的信息，因此iface的第一个字段指向一个itab类型结构： // $GOROOT/src/runtime/runtime2.go type itab struct { inter *interfacetype _type *_type hash uint32 _ [4]byte fun [1]uintptr } itab结构包括: _type: 存储着该接口类型变量的动态类型的信息 fun: 动态类型已实现的接口方法的调用地址数组 inter: 指向的interfacetype结构存储着该接口类型自身的信息 // $GOROOT/src/runtime/type.go type interfacetype struct { typ _type pkgpath name mhdr []imethod } interfacetype结构由三个字段组成: 类型信息（typ） 包路径名（pkgpath） 接口方法集合切片（mhdr） 接口类型内部表示的示例 // interface-internal-4.go type T struct { n int s string } func (T) M1() {} func (T) M2() {} type NonEmptyInterface interface { M1() M2() } func main() { var t = T { n: 17, s: \"hello, interface\", } var ei interface{} = t // Go运行时使用eface结构表示ei var i NonEmptyInterface = t } 首先看一个用eface表示空接口类型变量的例子：var ei interface{} = t iface的表示稍复杂些: var i NonEmptyInterface = t 虽然eface和iface的第一个字段有所差别，但tab和_type可统一看作动态类型的类型信息。Go语言中每种类型都有唯一的_type信息，无论是内置原生类型，还是自定义类型。Go运行时会为程序内的全部类型建立只读的共享_type信息表，因此拥有相同动态类型的同类接口类型变量的_type/tab信息是相同的。 接口类型变量的data部分则指向一个动态分配的内存空间，该内存空间存储的是赋值给接口类型变量的动态类型变量的值。未显式初始化的接口类型变量的值为nil，即该变量的_type/tab和data都为nil。这样，我们要判断两个接口类型变量是否相同，只需判断_type/tab是否相同以及data指针所指向的内存空间所存储的数据值是否相同（注意：不是data指针的值）。 eface和iface是runtime包中的非导出结构体定义，我们不能直接在包外使用，也就无法直接访问两个结构体中的数据。不过Go语言提供了println预定义函数，可以用来输出eface或iface的两个指针字段的值。println在编译阶段会由编译器根据要输出的参数的类型将println替换为特定的函数，这些函数都定义在$GOROOT/src/runtime/print.go文件中，而针对eface和iface类型的打印函数实现如下： // $GOROOT/src/runtime/print.go func printeface(e eface) { print(\"(\", e._type, \",\", e.data, \")\") } func printiface(i iface) { print(\"(\", i.tab, \",\", i.data, \")\") } func printNilInterface() { // nil接口变量 var i interface{} // 空接口类型 var err error // 非空接口类型 println(i) // (0x0,0x0) println(err) // (0x0,0x0) println(\"i = nil:\", i == nil) // true println(\"err = nil:\", err == nil) // true println(\"i = err:\", i == err) // false println(\"\") } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:5:1","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"4.2 接口等值判断 前面已经提到了，接口变量，无论是空接口还是非空接口，只有在tab/_type和data所指数据内容一致的情况下，两个接口类型变量之间才能画等号。 对于 var err1 error= (*T)(nil) err1 接口类型变量的类型信息并不为空，所以 err1 !=nil。上面的 returnsError 就属于这种情况。 空接口类型变量和非空接口类型变量内部表示的结构有所不同（第一个字段：_type vs. tab），似乎一定不能相等。但Go在进行等值比较时，类型比较使用的是eface的_type和iface的tab._type，所以下面的 eif(空接口) err(非空接口) 两个接口类型变量是相等的。 var eif interface{} = T(5) var err error = T(5) println(\"eif = err:\", eif == err) // True ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:5:2","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"4.3 接口类型的赋值原理 在Go语言中，将任意类型赋值给一个接口类型变量都是装箱操作。接口类型的装箱实则就是创建一个eface或iface的过程。我们以上面的 interface-internal-4.go 为例，输出其汇编代码: go tool compile -S interface-internal-4.go \u003e interface-internal-4.s // 对应ei = t一行的汇编如下 ... 0x00b6 00182 (interface-internal-4.go:24) PCDATA $0, $1 0x00b6 00182 (interface-internal-4.go:24) PCDATA $1, $1 0x00b6 00182 (interface-internal-4.go:24) LEAQ \"\"..autotmp_15+408(SP), AX 0x00be 00190 (interface-internal-4.go:24) PCDATA $0, $0 0x00be 00190 (interface-internal-4.go:24) MOVQ AX, 8(SP) 0x00c3 00195 (interface-internal-4.go:24) CALL runtime.convT2E(SB) ... // 对应i = t一行的汇编如下 0x0128 00296 (interface-internal-4.go:27) PCDATA $0, $1 0x0128 00296 (interface-internal-4.go:27) PCDATA $1, $4 0x0128 00296 (interface-internal-4.go:27) LEAQ \"\"..autotmp_15+408(SP), AX 0x0130 00304 (interface-internal-4.go:27) PCDATA $0, $0 0x0130 00304 (interface-internal-4.go:27) MOVQ AX, 8(SP) 0x0135 00309 (interface-internal-4.go:27) CALL runtime.convT2I(SB) 我们看到了convT2E和convT2I两个runtime包的函数。这两个函数的实现位于$GOROOT/src/runtime/iface.go中： // $GOROOT/src/runtime/iface.go func convT2E(t *_type, elem unsafe.Pointer) (e eface) { if raceenabled { raceReadObjectPC(t, elem, getcallerpc(), funcPC(convT2E)) } if msanenabled { msanread(elem, t.size) } x := mallocgc(t.size, t, true) typedmemmove(t, x, elem) e._type = t e.data = x return } func convT2I(tab *itab, elem unsafe.Pointer) (i iface) { t := tab._type if raceenabled { raceReadObjectPC(t, elem, getcallerpc(), funcPC(convT2I)) } if msanenabled { msanread(elem, t.size) } x := mallocgc(t.size, t, true) typedmemmove(t, x, elem) i.tab = tab i.data = x return } convT2E用于将任意类型转换为一个eface，convT2I用于将任意类型转换为一个iface。两个函数的实现逻辑相似，主要思路就是根据传入的类型信息（convT2E的_type和convT2I的tab._type）分配一块内存空间，并将elem指向的数据复制到这块内存空间中，最后传入的类型信息作为返回值结构中的类型信息，返回值结构中的数据指针（data）指向新分配的那块内存空间。 经过装箱后，箱内的数据（存放在新分配的内存空间中）与原变量便无瓜葛了，除非是指针类型。 那么convT2E和convT2I函数的类型信息从何而来？这些都依赖Go编译器的工作。编译器知道每个要转换为接口类型变量（toType）的动态类型变量的类型（fromType），会根据这一类型选择适当的convT2X函数（见下面代码中的convFuncName），并在生成代码时使用选出的convT2X函数参与装箱操作： 装箱是一个有性能损耗的操作，因此Go在不断对装箱操作进行优化，包括对常见类型（如整型、字符串、切片等）提供一系列快速转换函数： / 实现在 $GOROOT/src/runtime/iface.go中 func convT16(val any) unsafe.Pointer // val必须是一个uint-16相关类型的参数 func convT32(val any) unsafe.Pointer // val必须是一个unit-32相关类型的参数 func convT64(val any) unsafe.Pointer // val必须是一个unit-64相关类型的参数 func convTstring(val any) unsafe.Pointer // val必须是一个字符串类型的参数 func convTslice(val any) unsafe.Pointer // val必须是一个切片类型的参数 这些函数去除了typedmemmove操作，增加了零值快速返回等。同时Go建立了staticbytes区域，对byte大小的值进行装箱操作时不再分配新内存，而是利用staticbytes区域的内存空间，如bool类型等。 // $GOROOT/src/runtime/iface.go // staticbytes用来避免对字节大小的值进行convT2E转换 var staticbytes = [...]byte{ 0x00, 0x01, 0x02, 0x03, 0x04, 0x05, 0x06, 0x07, 0x08, 0x09, 0x0a, 0x0b, 0x0c, 0x0d, 0x0e, 0x0f, ... } ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:5:3","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"5. 组合设计哲学 Go语言中主要有两种组合方式: 垂直组合：又称类型组合，Go语言主要通过类型嵌入机制实现垂直组合，进而实现方法实现的复用、接口定义重用等。 水平组合：通常Go程序以接口类型变量作为程序水平组合的连接点。 通过接口进行水平组合的一种常见模式是使用接受接口类型参数的函数或方法：func YourFuncName(param YourInterfaceType) 从图中可以看到，函数/方法参数中的接口类型作为连接点，将位于多个包中的多个类型“编织”到一起，共同形成一幅程序“骨架”。同时接口类型与其实现者之间隐式的关系在不经意间满足了依赖抽象、里氏替换原则、接口隔离等代码设计原则。 ","date":"2022-12-30","objectID":"/posts/program/go/expert/go_export/expert_7/:6:0","tags":["go 进阶"],"title":"Go 函数、方法和接口","uri":"/posts/program/go/expert/go_export/expert_7/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言的包，包括包的构建和导入过程。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:0:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"1. Go程序构建过程 在介绍 Go 包相关的知识之前，我们先来简单了解一下Go程序的构建过程。 首先我们先简单总结一下，Go 包组织上的特点，这也是 Go 编译速度快的原因: Go要求每个源文件在开头处显式地列出所有依赖的包导入，这样Go编译器不必读取和处理整个文件就可以确定其依赖的包列表。 Go要求包之间不能存在循环依赖，这样一个包的依赖关系便形成了一张有向无环图。由于无环，包可以被单独编译，也可以并行编译。 已编译的Go包对应的目标文件（file_name.o或package_name.a）中不仅记录了该包本身的导出符号信息，还记录了其所依赖包的导出符号信息。这样，Go编译器在编译某包P时，针对P依赖的每个包导入（比如导入包Q），只需读取一个目标文件即可（比如：Q包编译成的目标文件中已经包含Q包的依赖包的导出信息），而无须再读取其他文件中的信息。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:1:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"2. 包导入 package main import ( \"fmt\" // 标准库包导入 \"a/b/c\" // 第三方包导入 ) func main() { c.Func1() fmt.Println(\"Hello, Go!\") } go 语言中包定义和导入都很简单。但是我相信不止我一个一开始不理解 import 后面路径中的最后一个分段到底代表的是什么？是包名还是一个路径？今天我们就来学习包导入和构建的知识。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:2:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"2.1 包的搜索路径空间 编译器要找到依赖包的源码文件，就需要知道依赖包的源码路径。这个路径由两部分组成：基础搜索路径和包导入路径。 基础搜索路径是一个全局的设置，下面是其规则描述。 所有包（无论是标准库包还是第三方包）的源码基础搜索路径都包括$GOROOT/src。 在上述基础搜索路径的基础上，不同版本的Go包含的其他基础搜索路径有不同。 Go 1.11版本之前，包的源码基础搜索路径还包括$GOPATH/src。 Go 1.11～Go 1.12版本，包的源码基础搜索路径有三种模式： 经典gopath模式下（GO111MODULE=off）：$GOPATH/src。 module-aware模式下（GO111MODULE=on）：$GOPATH/pkg/mod。 auto模式下（GO111MODULE=auto）：在$GOPATH/src路径下，与gopath模式相同；在$GOPATH/src路径外且包含go.mod，与module-aware模式相同。 Go 1.13版本，包的源码基础搜索路径有两种模式： 经典gopath模式下（GO111MODULE=off）：$GOPATH/src。 module-aware模式下（GO111MODULE=on/auto）：$GOPATH/pkg/mod。 未来的Go版本将只有module-aware模式，即只在module缓存的目录下搜索包的源码。 搜索路径的第二部分就是位于每个包源码文件头部的包导入路径。基础搜索路径与包导入路径结合在一起，Go编译器便可确定一个包的所有依赖包的源码路径的集合，这个集合构成了Go编译器的源码搜索路径空间。 Go 的包导入支持相对路径，比如下面的包导入路径./e/f/g是一个本地相对路径，它的基础搜索路径是$CWD，即执行编译命令时的当前工作目录。Go编译器在编译源码时会使用-D选项设置当前工作目录，该工作目录与“./e/f/g”的本地相对路径结合，便构成了一个源码搜索路径。 import ( \"./e/f/g\" ) 到这里，我们可以确定：源文件头部的包导入语句import后面的部分就是一个路径，路径的最后一个分段也不是包名。不过Go语言有一个惯用法，那就是包导入路径的最后一段目录名最好与包名一致，当包名与包导入路径中的最后一个目录名不同时，最好用下面的语法将包名显式放入包导入语句。 package main // pkg2 路径处的包名就是 mypkg2，这里的 mypkg2 可以省略，但是最好显式指定包名 import ( mypkg2 \"github.com/bigwhite/effective-go-book/chapter3-demo1/pkg/pkg2\" ) func main() { mypkg2.Func1() } ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:2:1","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"3. 包初始化顺序 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:3:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"3.1 init 函数 Go语言中有两个特殊的函数：一个是main包中的main函数，它是所有Go可执行程序的入口函数；另一个就是包的init函数: init函数是一个无参数、无返回值的函数 如果一个包定义了init函数，Go运行时会负责在该包初始化时调用它的init函数 在Go程序中我们不能显式调用init，否则会在编译期间报错 一个Go包可以拥有多个init函数，每个组成Go包的Go源文件中可以定义多个init函数。在初始化Go包时，Go运行时会按照一定的次序逐一调用该包的init函数。 Go运行时不会并发调用init函数，它会等待一个init函数执行完毕并返回后再执行下一个init函数，且每个init函数在整个Go程序生命周期内仅会被执行一次 init函数极其适合做一些包级数据的初始化及初始状态的检查工作。一般来说，先被传递给Go编译器的源文件中的init函数先被执行，同一个源文件中的多个init函数按声明顺序依次执行。但Go语言的惯例告诉我们：不要依赖init函数的执行次序。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:3:1","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"3.2 程序初始化顺序 Go程序由一组包组合而成，程序的初始化就是这些包的初始化。每个Go包都会有自己的依赖包，每个包还包含有常量、变量、init函数等（其中main包有main函数），这些元素在程序初始化过程中的初始化顺序是什么样的呢？我们用图20-1来说明一下。 在程序初始化的过程中: Go运行时遵循“深度优先”原则查看到pkg1依赖pkg2，于是Go运行时去初始化pkg2； 没有依赖包，于是Go运行时在pkg3包中按照常量→变量→init函数的顺序进行初始化； 到这里，我们知道了init函数适合做包级数据的初始化及初始状态检查工作的前提条件是，init函数的执行顺位排在其所在包的包级变量之后。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:3:2","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"3.3 使用init函数检查包级变量的初始状态 init函数就好比Go包真正投入使用之前的唯一“质检员”，负责对包内部以及暴露到外部的包级数据（主要是包级变量）的初始状态进行检查。init 函数有如下几种用法 重置包级变量值 / $GOROOT/src/flag/flag.go func init() { CommandLine.Usage = commandLineUsage } CommandLine的Usage字段在NewFlagSet函数中被初始化为FlagSet实例（也就是CommandLine）的方法值defaultUsage。如果一直保持这样，那么使用Flag默认CommandLine的外部用户就无法自定义usage输出了。于是flag包在init函数中，将ComandLine的Usage字段设置为一个包内未导出函数commandLineUsage，后者则直接使用了flag包的另一个导出包变量Usage。这样就通过init函数将CommandLine与包变量Usage关联在一起了。在用户将自定义usage赋值给Usage后，就相当于改变了CommandLine变量的Usage。 对包级变量进行初始化，保证其后续可用 有些包级变量的初始化过程较为复杂，简单的初始化表达式不能满足要求，而init函数则非常适合完成此项工作。比如标准库http包则在init函数中根据环境变量GODEBUG的值对一些包级开关变量进行赋值: func init() { e := os.Getenv(\"GODEBUG\") if strings.Contains(e, \"http2debug=1\") { http2VerboseLogs = true } if strings.Contains(e, \"http2debug=2\") { http2VerboseLogs = true http2logFrameWrites = true http2logFrameReads = true } } init函数中的注册模式 import ( \"database/sql\" _ \"github.com/lib/pq\" ) func main() { db, err := sql.Open(\"postgres\", \"user=pqgotest dbname=pqgotest sslmode=verify-full\") if err != nil { log.Fatal(err) } } 空别名方式导入lib/pq的副作用就是Go运行时会将lib/pq作为main包的依赖包并会初始化pq包，于是pq包的init函数得以执行 // github.com/lib/pq/conn.go ... func init() { sql.Register(\"postgres\", \u0026Driver{}) } pq包的init函数中，pq包将自己实现的SQL驱动（driver）注册到sql包中。从database/sql的角度来看，这种注册模式实质是一种工厂设计模式的实现。原理也很简单，database/sql 只要维护一个全局的数据库名称 -\u003e Driver的映射。每个具体的数据链接，通过调用sql.Register 将自己的实现添加到这个映射中，后续就可以根据数据库名称完成初始化。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:3:3","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"3.4 init函数中检查失败的处理方法 init 目的是保证其所在包在被正式使用之前的初始状态是有效的。一旦init函数在检查包数据初始状态时遇到失败或错误的情况快速失败是最佳选择。一般建议直接调用panic或者通过log.Fatal等函数记录异常日志，然后让程序快速退出。但是 go get 至少存在以下问题: 依赖包持续演进，导致不同Gopher在不同时间获取和编译包时得到的结果可能是不同的，即不能保证可重现的构建（reproduceable build）； 如果依赖包引入了不兼容代码，你的包/程序将无法通过编译； Gopher希望自己项目所依赖的第三方包能受自己的控制，而不是随意变化，于是godep、gb、glide等一批第三方包管理工具便出现了。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:3:4","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4. 使用 module 管理包依赖 gopath 模式 Go编译器在传统的GOPATH和vendor目录下搜索目标程序依赖的Go包。 go module 模式 go module 引入了一种新的依赖管理工作模式：module-aware模式 一个仓库的顶层目录下会放置一个go.mod文件，每个go.mod文件唯一定义了一个module。 一个module就是由一组相关包组成的一个独立的版本单元。module是有版本的，module下的包也就有了版本属性。 放置go.mod文件的目录被称为module root目录。module root目录及其子目录下的所有Go包均归属于该module，除了那些自身包含go.mod文件的子目录。 虽然Go支持在一个仓库中定义多个module，但通常Go惯用法是一个仓库只定义一个module。 在module-aware模式下，Go编译器将下载的依赖包缓存在 $GOPATH/pkg/mod 下，Go编译器将不会在GOPATH及vendor下搜索目标程序依赖的第三方Go包。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.1 go.mod 文件 下面是一个 go.mod 文件的示例: module hello require ( bitbucket.org/bigwhite/c v0.0.0-20180714063616-861b08fcd24b bitbucket.org/bigwhite/d v0.0.0-20180714005150-3e3f9af80a02 // indirect ) Go编译器分析出了hello module的依赖包，将其写入go.mod的require区域。由于c、d两个包均没有发布版本（建立其他分支或打标签），因此Go编译器使用了包c和d的当前最新版，并以伪版本（pseudo-version）的形式作为这两个包的当前版本号。此外，hello module并没有直接依赖包d，并且bitbucket.org/bigwhite/c下没有建立go.mod、记录包c的依赖，因此在d包的记录后面用注释标记了indirect，即间接依赖。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:1","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.1 go 依赖管理的选择 go module机制在Go 1.11版本中是试验特性。GO111MODULE这个临时的环境变量就是go module特性的试验开关。 GO111MODULE 有三个值——auto、on和off，默认值为auto。GO111MODULE的值会直接影响Go编译器的包依赖管理工作模式的选择：是gopath模式还是module-aware模式。不同版本下，GO111MODULE 值的行为模式是不同的。 Go 1.11版本: GO111MODULE=off: go module关闭，Go编译器会始终使用gopath模式， GO111MODULE=on: go module始终开启，Go编译器会始终使用module-aware模式 GO111MODULE=auto: 默认值，如果构建的源码目录不在以GOPATH/src为根的目录体系下且包含go.mod文件（两个条件缺一不可），将使用module-aware模式；否则使用传统的gopath模式 Go 1.13版本: GO111MODULE=off: 同上 GO111MODULE=on: 同上 GO111MODULE=auto 默认值，只要目录下有go.mod，Go编译器就会使用module-aware模式 Go 1.14版本: GO111MODULE=off: 同上 GO111MODULE=on: go module 开启，但是行为模式有所变化 在module-aware模式下，如果go.mod中go version是Go 1.14及以上，且当前仓库顶层目录下有vendor目录，那么Go工具链将默认使用vendor（-mod=vendor）中的包，而不是module cache中的（$GOPATH/pkg/mod下）。同时在这种模式下，Go工具会校验vendor/modules.txt与go.mod文件以确保它们保持同步；如果一定要使用module cache中的包进行构建，则需要为Go工具链显式传入-mod=mod ，比如go build -mod=mod ./...。 在module-aware模式下，如果没有建立go.mod或Go工具链，无法找到go.mod，那么你必须显式传入要处理的Go源文件列表，否则Go工具链将需要你明确建立go.mod。比如：在一个没有go.mod的目录下，要编译hello.go，我们需要使用go build hello.go，即hello.go需要显式放在命令后面。如果你执行go build .，就会得到类似下面的错误信息： $go build . go: cannot find main module, but found .git/config in /Users/tonybai to create a module there, run: cd .. \u0026\u0026 go mod init 也就是说，在没有go.mod的情况下，Go工具链的功能是受限的。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:2","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.2 go module的依赖包版本的选择 build list和main module go.mod文件一旦创建，它的内容就会被Go工具链全面掌控。Go工具链会在各类命令（比如go get、go build、go mod等）执行时维护go.mod文件。 go list -m输出的信息被称为build list，也就是构建当前module所需的所有相关包信息的列表。 $go list -m -json all { \"Path\": \"hello\", \"Main\": true, \"Dir\": \"chapter10/sources/go-module/hello\", \"GoMod\": \"chapters/chapter10/sources/go-module/hello/go.mod\", \"GoVersion\": \"1.14\" } ... 在输出信息中我们看到\"Main\"：true这一行信息，它标识当前的module为main module。main module 即 go build 命令执行时所在当前目录所归属的那个module。go命令会在当前目录、当前目录的父目录、父目录的父目录等下面寻找go.mod文件，所找到的第一个go.mod文件对应的module即为main module。如果没有找到go.mod，go命令会提示下面的错误信息： $go build test/hello/hello.go go: cannot find main module root; see 'go help modules' 也可以使用下面的命令来简略输出build list： $go list -m all hello bitbucket.org/bigwhite/c v0.0.0-20180714063616-861b08fcd24b go.mod中的 require go clean -modcache 命令可以清除掉$GOPATH/pkg/mod目录下的内容，并将go.mod重新置为初始状态，即只包含module字段。这样就可以重新拉取依赖进行包构建。 如果对使用的c和d版本有特殊的约束，比如使用包c的v1.0.0版本和包d的v1.1.0版本，我们可以通过go mod -require来显式更新go.mod文件中的require段的信息： # c 和 d 的包版本信息 # // 包c v1.0.0 v1.1.0 v1.2.0 # // 包d v1.0.0 v1.1.0 v1.2.0 v1.3.0 $go mod -require=bitbucket.org/bigwhite/c@v1.0.0 $go mod -require=bitbucket.org/bigwhite/d@v1.1.0 $cat go.mod module hello require ( bitbucket.org/bigwhite/c v1.0.0 bitbucket.org/bigwhite/d v1.1.0 // indirect ) go mod还支持query表达式，比如： $go mod -require='bitbucket.org/bigwhite/c@\u003e=v1.1.0' $cat go.mod module hello require ( bitbucket.org/bigwhite/c v1.1.0 bitbucket.org/bigwhite/d v1.1.0 // indirect ) go mod命令会对query表达式进行求值，得出build list使用的包c的版本。go mod命令对query表达式进行求值的算法是，选择最接近于比较目标的版本（tagged version）。以上面的例子为例： query text: \u003e=v1.1.0，满足这一query表达式的最接近于比较目标的版本就是v1.1.0。 query text: \u003cv1.3.0，满足这一query表达式的最接近于比较目标的版本就是v1.2.0。 最小版本选择 每个依赖管理解决方案都必须解决选择依赖项版本的问题。目前有两种选择方案: 最新最大(latest greatest)版本: 其他语言的方案，在语义版本控制（sematic versioning）被正确应用并且得到遵守的情况下，这是有道理的，因为高版本能正确实现向前兼容 最小版本选择(Minimal Version Selection，MVS): go module 模式的方案，Go 核心团队认为如果无法一直做到保持高版本向低版本兼容，MVS 是为Go程序实现持久的和可重现的构建提供了最佳方案 下面是 MVS 算法的解释: 依赖一个包的不同版本 按照语义化版本规范，当代码出现与之前版本的不兼容性变化时，需要升级版本中的major版本号。而Go module允许在包导入路径中带有major版本号，比如：import github.com/user/repo/v2表示所用的包为v2版本下的实现。甚至可以在一个项目中同时依赖同一个包的不同版本。 首先需要为包d建立module文件Go.mod，并标识出当前的module为bitbucket.org/bigwhite/d/v2。（为了保持与v0/v1各自独立演进，可通过建立分支的方式来实现，然后基于该版本打v2.0.0标签。） // bitbucket.org/bigwhite/d $cat go.mod module bitbucket.org/bigwhite/d/v2 改造一下hello module，导入包d的v2版本： // sources/go-module/hello/hello.go package main // 注 c 依赖 d v1.2.0 import \"bitbucket.org/bigwhite/c\" import \"bitbucket.org/bigwhite/d/v2\" 重新拉取依赖包: $go build hello.go go: finding bitbucket.org/bigwhite/c v1.3.0 go: finding bitbucket.org/bigwhite/d v1.2.0 go: downloading bitbucket.org/bigwhite/c v1.3.0 go: downloading bitbucket.org/bigwhite/d v1.2.0 // c 依赖的 d v1.2.0 go: finding bitbucket.org/bigwhite/d/v2 v2.0.0 go: downloading bitbucket.org/bigwhite/d/v2 v2.0.0 // hello 依赖的 d/v2 v2.0.0 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:3","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.3 go mod 命令使用 Go module与vendor go module支持通过下面的命令将某个module的所有依赖复制一份到module根路径下的vendor目录下： $ go mod -vendor $ ls go.mod go.sum hello.go vendor/ $ cd vendor $ ls bitbucket.org/ modules.txt $ cat modules.txt # bitbucket.org/bigwhite/c v1.3.0 bitbucket.org/bigwhite/c # bitbucket.org/bigwhite/d v1.2.0 bitbucket.org/bigwhite/d # bitbucket.org/bigwhite/d/v2 v2.0.0 bitbucket.org/bigwhite/d/v2 这样即便在module-aware模式下，我们也依然可以只用vendor下的包来构建hello module: go build -mode=vendor hello.go。当然生成的vendor目录还可以兼容Go 1.11之前版本的Go编译器。不过由于Go 1.11之前版本的Go编译器不支持在GOPATH之外使用vendor机制，我们需要将hello目录复制到$GOPATH/src下才能成功编译它。 go.sum 执行go build后，hello module的当前目录下多了一个go.sum文件： $cat go.sum bitbucket.org/bigwhite/c v1.3.0 h1:crNI04Bw6lm1yyRjJ+8lJX+3amsxeU72mVQ41kjnESA= bitbucket.org/bigwhite/c v1.3.0/go.mod h1:6p3lkm60SJ7QP5a4oJyLUxbDJeT+w5x5CShTrekjc7o= bitbucket.org/bigwhite/d v1.2.0 h1:QQawlmsVZWwIsr0ockPCSJjN1QoKd4W0KEJrINdIzY0= bitbucket.org/bigwhite/d v1.2.0/go.mod h1:6XJNbysZ+/91fhY6/3TKkMNdV/c0pgaubTQWMigKnlY= go.sum记录每个依赖库的版本和对应内容的校验和。每当增加一个依赖项时，如果go.sum中没有，则会将该依赖项的版本和内容校验和添加到go.sum中。go命令会使用这些校验和与缓存在本地的依赖包副本元信息进行比对校验。如果修改了$GOPATH/pkg/mod/cache/ 中缓存的包的内容，那么当执行verify子命令时，我们会得到报错信息： go mod verify golang.org/x/text v0.3.0: zip has been modified (/root/go/pkg/mod/cache/download/golang.org/x/text/@v/v0.3.0.zip) golang.org/x/text v0.3.0: dir has been modified (/root/go/pkg/mod/golang.org/x/text@v0.3.0) // 如果没有“恶意”修改，则verify会报成功： # go mod verify all modules verified 在将代码提交/推回存储库之前，请运行go mod tidy以确保module文件（go.mod）是最新且准确的。在本地构建、运行或测试代码将随时影响Go对module文件中内容的更新。运行go mod tidy可以确保项目具有所需内容的准确且完整的快照，这对团队中的其他人或持续集成/交付环境大有裨益。 升降级依赖关系 在module-aware模式下，由于go.mod和go.sum都是由Go工具链维护和管理的，不建议手动修改go.mod中require中的包版本号。我们可以通过go get命令来实现升降级依赖: # 我们可以先用go list命令查看一下某个module有哪些版本可用: $go list -m -versions golang.org/x/text golang.org/x/text v0.1.0 v0.2.0 v0.3.0 v0.3.1 v0.3.2 v0.3.3 # 将 golang.org/x/text 从v0.3.0 降级到 v0.1.0 # go get 会自动更新 go.mod 和 go.sum $go get golang.org/x/text@v0.1.0 go: finding golang.org/x/text v0.1.0 go: downloading golang.org/x/text v0.1.0 # go get-u会将当前module的所有依赖的包版本（无论直接依赖还是间接依赖）都升级到最新的兼容版本。 # 后接具体的 module 则只更新对应的 module，省略则更新所有 $ go get -u golang.org/x/text # 如果仅升级patch号，而不升级minor号，可以使用go get -u=patch A。 # 如果 golang.org/x/text 当前版本是 v0.1.0 如果其有 v0.1.1，最新版本是 v0.3.3，加上 -u=patch，升级到的版本则是 v0.1.1 go get -u=patch golang.org/x/text 处于module-aware模式下的go get在更新某个依赖（无论是升版本还是降版本）时，会自动计算并更新其间接依赖的包的版本。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:4","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.4 Go module代理 GOPROXY环境变量 无论是在gopath模式还是module-aware模式下，go get命令默认都是直接从代码托管服务器（如GitHub、GitLab等）下载Go module的。但是在Go 1.11中，我们可以通过设置GOPROXY环境变量让Go命令从其他module代理服务器下载module。比如：export GOPROXY=https://goproxy.cn 通过代码托管站点拉取代码总是比从代理拉取代码慢，所以在Go 1.13中将https://proxy.golang.org设为GOPROXY环境变量的默认值之一，这也是Go提供的官方module代理服务。同样是从Go 1.13版本开始，GOPROXY环境变量支持设置多个代理的列表（多个代理之间采用逗号分隔）。Go编译器会按顺序尝试从列表中的代理服务获取依赖包数据，当有代理服务不可达或者返回的HTTP状态码既不是404也不是410时，Go会终止数据获取，否则会尝试向列表中的下一个代理服务获取数据。在Go 1.13中，GOPROXY的默认值为https://proxy.golang.org,direct。 当官方代理返回404或410时，Go编译器会尝试直接连接依赖module的代码托管站点以获取数据。但是当列表中的代理服务返回其他错误时，Go命令不会向GOPROXY列表中的下一个值所代表的代理服务发起请求。这种行为模式没能让所有Gopher满意，很多Gopher认为Go工具链应该向后面的代理服务请求，直到所有代理服务都返回失败。Go 1.15版本满足了Go社区的需求，新增以管道符“|”为分隔符的代理列表值。如果GOPROXY配置的代理服务列表值以管道符分隔，则无论某个代理服务返回什么错误码，Go命令都会向列表中的下一个代理服务发起新的尝试请求。（Go 1.15版本中GOPROXY环境变量的默认值依旧为https://proxy.golang.org,direct。） 目前世界各地的一些知名module代理服务。 proxy.golang.org：Go官方提供的module代理服务。 mirrors.tencent.com/go：腾讯公司提供的module代理服务。 mirrors.aliyun.com/goproxy：阿里云提供的module代理服务。 goproxy.cn：开源module代理，由七牛云提供主机，是目前中国最为稳定的module代理服务。 goproxy.io：开源module代理，由中国Go社区提供的module代理服务。 Athens：开源module代理，可基于该代理自行搭建module代理服务。 GOSUMDB 每次运行或构建时，Go命令都会通过本地的go.sum检查其本地缓存副本的校验和是否一致。如果校验和不匹配，则Go命令将报告安全错误，并拒绝运行构建或运行。在这种情况下，重要的是找出正确的校验和，确定是go.sum错误还是下载的代码有误。如果go.sum中尚未包含已下载的module，并且该模块是公共module，则go命令将查询Go校验和数据库以获取正确的校验和数据并存入go.sum。 Go 1.13提供了GOSUMDB环境变量来配置Go校验和数据库的服务地址（和公钥），其默认值为 sum.golang.org，这也是Go官方提供的校验和数据库服务（也可以使用 sum.golang.google.cn）。出于安全考虑，建议保持 GOSUMDB 开启。但如果因为某些因素无法访问GOSUMDB，也可以通过下面的命令将其关闭：$go env -w GOSUMDB=off 在GOSUMDB关闭后，Go编译器就仅能使用本地的go.sum进行包的校验和校验了。 获取私有module 如果依赖的 module 是企业内部代码服务器或公共代码托管站点上的私有module，通过公共的 module 显然是无法获取私有的 module 的。对于 github 上私有的 module 需要配置访问 github 的凭证。配置好后，还存在另一个问题: 由于是私有仓库，默认的sum.golang.org站点自然不会有该仓库的校验信息，在使用默认的GOSUMDB（sum.golang.org）校验privatemodule时报了404错误。 Go 1.13提供了GOPRIVATE环境变量用于指示哪些仓库下的module是私有的，不需要通过GOPROXY下载，也不需要通过GOSUMDB验证其校验和。不过要注意的是，GONOPROXY和GONOSUMDB可以覆盖GOPRIVATE变量中的设置，因此设置时要谨慎，比如下面的例子： GOPRIVATE=pkg.tonybai.com/private GONOPROXY=none GONOSUMDB=none GOPRIVATE指示 pkg.tonybai.com/private 下的包无须经过GOPROXY代理下载，不经过GOSUMDB验证。但GONOPROXY和GONOSUMDB均为none，意味着所有module，不管是公共的还是私有的，都要经过GOPROXY下载，经过GOSUMDB验证，这样GOPRIVATE的设置就因被覆盖而不会生效。可以单独设置GOPRIVATE来实现go get不使用GOPROXY下载privatemodule并且无须GOSUMDB校验： $export GOPRIVATE=github.com/bigwhite/privatemodule $go get github.com/bigwhite/privatemodule ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:5","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"4.5 升级module的主版本号 go module的语义导入版本 在“Semantic Import Versioning”一文中，Russ Cox说明了Go import包兼容性的总原则： 如果新旧版本的包使用相同的导入路径，那么新包与旧包是兼容的。 如果新旧两个包不兼容，那么应该采用不同的导入路径 因此，Russ Cox采用了将主版本作为导入路径一部分的设计。这种设计支持在 同一个项目的Go源文件中导入同一个包的不同版本：同一个包虽然包名相同，但是导入路径不同。 vN作为导入路径的一部分将用于区分包的不同版本。同时在同一个源文件中，我们可以使用包别名来区分同一个包的不同版本， 比如： import ( \"github.com/bigwhite/foo/bar\" barV2 \"github.com/bigwhite/foo/v2/bar\" ) go module的这种设计虽然没有给Go包的使用者带来多少额外工作，但却给Go包的维护者带来了一定的复杂性，他们需要考虑在go module机制下如何升级自己的go module的主版本号（major version）。稍有不慎，很可能就会导致自身代码库的混乱或者包使用者侧无法通过编译或执行行为混乱。 总体上有两种方案: major branch 方案 major subdirectory方案 major branch 方案 major branch 方案是一个过渡比较自然的方案，它通过建立 vN 分支并基于vN分支打vN.x.y标签的方式进行主版本号的升级。示例中假设，我们的项目 A 依赖一个 bitbucket.org/bigwhite/modules-major-branch。 // 1. modules-major-branch 发布版本 v1.0.0 // 假设 modules-major-branch 已经发布了版本 pre，现在发布正式的 v1.0.0 版本 git tag v1.0.0 git push --tag origin master // 2. A 升级依赖 // 升级是不会自动进行的，需要开发手动进行 go mod edit -require=bitbucket.org/bigwhite/modules-major-branch@v1.0.0 从pre-v1到v1还算不上主版本升级，接下来看看foo包的作者应该如何对modules-major-branch module进行不兼容的升级：v1→v2。 # 1. v1 分支，进行 v1 版本开发和升级 $ git checkout -b v1 # 2. 在master分支上进行不兼容的修改 $ git checkout master # 进行不兼容开发 .... # 3. modules-major-branch module要有不同的导入路径，因此需要修改modules-major-branch module的module路径 $ cat go.mod module bitbucket.org/bigwhite/modules-major-branch/v2 # 4. v2 发版 $ git tag v2.0.0 $ git push --tag origin master 假设 A 项目需要使用 v2 版本: package main import ( \"bitbucket.org/bigwhite/modules-major-branch/v2/foo\" ) 后续modules-major-branch可以在master分支上持续演进，直到又有不兼容改动时，可以基于master建立v2维护分支，同时master分支将升级为v3版本。 在该方案中，对包的作者而言，升级主版本号需要： 在go.mod中升级module的根路径，增加vN； 建立vN.x.x形式的标签（可选，如果不打标签，Go会在消费者的go.mod中使用伪版本号，比如bitbucket.org/bigwhite/modules-major-branch/v2 v2.0.0-20190603050009-28a5b8da279e）。 如果 modules-major-branch 内部有相互的包引用，那么在升级主版本号的时候，这些包的导入路径也要增加vN，否则就会出现在高版本号的代码中引用低版本号包代码的情况，这也是包作者极容易忽略的事情。 github.com/marwan-at-work/mod 是一个为module作者提供的升降级主版本号的工具，它可以帮助包作者方便地自动修改项目内所有源文件中的导入路径。有Gopher已经提出希望Go官方提供升降级的支持: issue，但目前Go核心团队尚未明确是否增加。 对于包的消费者而言，升级依赖包的主版本号，只需要在导入包时在导入路径中增加vN即可 major subdirectory方案 Go module还提供了一种用起来不那么自然的方案，那就是利用子目录分割不同主版本。在这种方案下，如果某个module目前已经演进到v3版本，那么这个module所在仓库的目录结构应该是这样的： $ tree modules-major-subdir modules-major-subdir ├── bar │ └── bar.go ├── go.mod ├── v2 # v2 就是对应的版本目录 │ ├── bar │ │ └── bar.go │ └── go.mod └── v3 ├── bar │ └── bar.go └── go.mod $ cat v2/go.mod module bitbucket.org/bigwhite/modules-major-subdir/v2 接下来，创建一个新的消费者，让它来分别调用不同版本的modules-major-subdir/bar包 package main import ( \"bitbucket.org/bigwhite/modules-major-subdir/bar\" \"bitbucket.org/bigwhite/modules-major-subdir/v2/bar\" ) Go编译器会自动找到了位于modules-major-subdir仓库下v2子目录下的v2版本bar包。 从上面的示例来看，这种通过子目录方式来实现主版本升级的方式似乎更简单一些，但感觉有点“怪”，尤其是在与分支和标签交叉使用时可能会带来一些困惑，其他主流语言也鲜有使用这种方式进行主版本升级的。一旦使用这种方式，利用Git等工具在各个不同主版本之间自动同步代码变更将变得很困难。另外和major branch方案一样，如果module内部有相互的包引用，那么在升级module的主版本号的时候，这些包的导入路径也要增加vN，否则也会出现在高版本号的代码中引用低版本号包代码的情况。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:4:6","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"5. 自定义包导入 在日常开发中，我们使用最多的Go包的go get导入路径主要是基于一些代码托管站点的域名。以 Go Web 框架beego包为例，它的go get导入路径就是github.com/astaxie/beego。我们还经常看到一些包，它们的导入路径很特殊，比如go get golang.org/x/net，这些包使用了自定义的包导入路径。这种自定义包go get导入路径的实践有诸多好处。 可以作为Go包的权威导入路径，这样可以避免 github 倒闭 go 包迁移之后，Go包导入路径发生变化的情况 便于组织和个人对Go包的管理。组织和个人可以将其分散托管在不同代码管理站点上的Go包统一聚合到组织的官网名下或个人的域名下 Go包的导入路径可以更短、更简洁 下面介绍一个自定义Go包导入路径的方法: govanityurls。 ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:5:0","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"5.1 govanityurls govanityurls，可以帮助Gopher快速实现自定义Go包的go get导入路径。govanityurls仅能运行于Google的App Engine上。白名老师(《Go 语言精进之路》作用)修改了一个可以在裸机上运行的版本: bigwhite/govanityurls。 govanityurls原理 govanityurls的原理十分简单: govanityurls 使用 # 1. 安装 $go get github.com/bigwhite/govanityurls $govanityurls # // govanityurls需要外部传入一个代表自定义包路径基本域名的host参数 govanityurls is a service that allows you to set custom import paths for your go packages Usage: govanityurls -host [HOST_NAME] -host string custom domain name, e.g. tonybai.com # 2. 配置vanity.yaml # // govanityurls 从vanity.yaml配置文件中读取请求包的真实地址返回给go get /gowechat: # 请求包 repo: https://github.com/bigwhite/gowechat # 请求包真实路径 /x/experiments: repo: https://github.com/bigwhite/experiments # 3. nginx 代理配置 cat /etc/nginx/conf.d/govanityurls.conf server { listen 80; listen 443 ssl; server_name tonybai.com; ssl_certificate /etc/nginx/cert.crt; ssl_certificate_key /etc/nginx/cert.key; ssl on; # 之所以加一个 /x 是为了简化 nginx 代理规则的编写 location /x { proxy_pass http://192.168.16.4:8080; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \"upgrade\"; } } ","date":"2022-12-29","objectID":"/posts/program/go/expert/go_export/expert_6/:5:1","tags":["go 进阶"],"title":"Go 包","uri":"/posts/program/go/expert/go_export/expert_6/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言语法的复合数据类型: slice、map、string ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:0:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"1. slice 学习 slice 之前，我们先来一下 Go 语言中的数组。 Go语言数组是一个固定长度的、容纳同构类型元素的连续序列，因此Go数组类型具有两个属性：元素类型和数组长度。这两个属性都相同的数组类型是等价的。所以下面三个数组都属于不同类型 // a、c 类型相同，但是长度不同，属于不同类型的数组 var a [8]int var b [8]byte var c [9]int Go数组是值语义的，数组在内部表示为连续的字节序列，虽然长度是Go数组类型的一部分，但长度并不包含在数组类型在Go运行时的内部表示中，数组长度是由编译器在编译期计算出来。这点与C语言完全不同。在C语言中，数组变量可视为指向数组第一个元素的指针。在Go语言中传递数组是纯粹的值拷贝，大数组在作为参数进行传递会有性能损耗。相比于数组，在 go 语言中更通用的是 slice。 slice 是基于数组的容器类型，可以自动对数组进行扩缩容。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:1:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"1.1 切片的初始化和操作 声明和初始化切片有如下几种方式: // 1. 变量声明 var s []int // s 为 nil 未分配空间 // 2. 字面量 s := []int{} s := []int{1, 2, 3} // 3. make s := make([]int, 2, 100) // 4. 切片 array := [5]int{1, 2, 3, 4, 5} s := array[0:2:5] 内置函数 append() 用于向切片中追加元素: s := make([]int, 9) s = append(s, 1) s = append(s, 2, 3, 4) s = append(s []int{5, 6}...) ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:1:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"1.2 slice 实现 slice 定义在 src/runtime/slice.go 中，由 makeslice 函数创建: type slice struct { array unsafe.Pointer // 指向底层数组 len int cap int } func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { // NOTE: Produce a 'len out of range' error instead of a // 'cap out of range' error when someone does make([]T, bignumber). // 'cap out of range' is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } // slice 扩缩容处理 func growslice(et *_type, old slice, cap int) slice {} // slice copy 操作实现 func slicecopy(toPtr unsafe.Pointer, toLen int, fromPtr unsafe.Pointer, fromLen int, width uintptr) int 每个切片包含以下三个字段。 array：指向下层数组某元素的指针，该元素也是切片的起始元素 len：切片的长度，即切片中当前元素的个数 cap：切片的最大容量，cap \u003e= len slice 的 struct 定义以及底层的数组指针决定了其具有如下的赋值特性: 赋值操作会复制整个 struct 但是共享底层的数组 赋值前后，数组的 len 和 cap 是独立的，但共享的底层数组是可能导致读写冲突的 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:1:2","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"1.3 slice 扩缩容 另外，slice 的扩容和拷贝规则如下: slice 的容量小于 1024 时，新的容量扩大为原来的 2 倍 slice 的容量大于 1024 时，新的容量扩大为原来的 1.25 倍 使用 copy() 内置函数拷贝两个切片是，会将源切片数据逐个拷贝到目的切片指向的数组，拷贝数量取两个切片长度的最小值。 最后 slice 的切片有一个扩展表达式 a[low:high:max] max 用于限定新生成的切片容量，注意 max 表示的是到哪，而不是有多少个，新生成的切片: len=high-low cap=max-low 一旦发生扩容，切片就会和原数组解除绑定，并绑定到扩容后的新数组。最后，虽然数组可以动态扩容，但是如果可以预估出切片底层数组需要承载的元素数量，强烈建议在创建切片时带上cap参数。这样可以减少数组分配和拷贝的次数，提升性能。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:1:3","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"1.4 slice 数据共享问题 由于 append 扩容后与底层数组的解绑行为；共享底层数组的情况，也有可能导致意外的覆盖写。我们看下面这例子: func main() { path := []byte(\"AAAA/BBBBBBBBB\") sepIndex := bytes.IndexByte(path,'/') dir1 := path[:sepIndex] dir2 := path[sepIndex+1:] fmt.Println(\"dir1 =\u003e\",string(dir1)) //prints: dir1 =\u003e AAAA fmt.Println(\"dir2 =\u003e\",string(dir2)) //prints: dir2 =\u003e BBBBBBBBB dir1 = append(dir1,\"suffix\"...) fmt.Println(\"dir1 =\u003e\",string(dir1)) //prints: dir1 =\u003e AAAAsuffix fmt.Println(\"dir2 =\u003e\",string(dir2)) //prints: dir2 =\u003e uffixBBBB } dir1 = append(dir1,\"suffix\"...) 由于 append 操作没有超过 path cap 的容量，导致，对 dir1 的修改覆盖了 dir2 中的数据。如果 dir2/dir1 被传递到程序的不同地方使用。导致的问题将更加隐蔽。解决这个问题的方法有两个，一个是 copy dir1，然后再修改。更好的方法是使用: dir1 := path[:sepIndex:sepIndex] 因为限定了 dir1 的 cap，后续的 append 操作就会重新分配新的数组。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:1:4","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2. map ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.1 map 的初始化和操作 首先 Go 对 map 有些使用上的限制: map对value的类型没有限制，但是对key的类型有严格要求：key的类型应该严格定义了作为“==”和“!=”两个操作符的操作数时的行为，因此函数、map、切片不能作为map的key类型 map类型不支持“零值可用”，未显式赋初值的map类型变量的零值为nil。对处于零值状态的map变量进行操作将会导致运行时panic map 的常见操作如下: var m map[string]int // m = nil m[\"key\"] = 1 // panic: assignment to entry in nil map // 1. 声明和初始化 var statusText = map[int]string{ StatusOK: \"OK\", StatusCreated: \"Created\", StatusAccepted: \"Accepted\", ... } icookies = make(map[string][]*Cookie) // 2. 插入和删除 m := make(map[K]V) m[k1] = v1 m[k2] = v2 m[k3] = v3 fmt.Println(len(m)) // 3 delete(m, \"key2\") // 3. 查找 // 即使 key 不在 map 中，也会返回 value 类型的零值，要判断 key 是否在 map 内，需要使用 comma ok _, ok := m[\"key\"] if !ok { // \"key\"不在map中 } // 4.遍历 // Go运行时在初始化map迭代器时对起始位置做了随机处理，所以元素的遍历次序是不一定的 for k, v := range m { fmt.Printf(\"[%d, %d] \", k, v) } ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.2 map 的底层实现 map 定义在 src/runtime/map.go 中，由 makemap 函数创建，在编译阶段，Go编译器会将语法层面的map操作重写成运行时对应的函数调用: m := make(map[keyType]valType, capacityhint) → m := runtime.makemap(maptype, capacityhint, m) v := m[\"key\"] → v := runtime.mapaccess1(maptype, m, \"key\") v, ok := m[\"key\"] → v, ok := runtime.mapaccess2(maptype, m, \"key\") m[\"key\"] = \"value\" → v := runtime.mapassign(maptype, m, \"key\") // v是用于后续存储value 的空间的地址 delete(m, \"key\") → runtime.mapdelete(maptype, m, \"key\") // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } // mapextra holds fields that are not present on all maps. type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap oldoverflow *[]*bmap // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap } // A bucket for a Go map. type bmap struct { // tophash generally contains the top byte of the hash value // for each key in this bucket. If tophash[0] \u003c minTopHash, // tophash[0] is a bucket evacuation state instead. tophash [bucketCnt]uint8 // Followed by bucketCnt keys and then bucketCnt elems. // NOTE: packing all the keys together and then all the elems together makes the // code a bit more complicated than alternating key/elem/key/elem/... but it allows // us to eliminate padding which would be needed for, e.g., map[int64]int8. // Followed by an overflow pointer. } // makemap implements Go map creation for make(map[k]v, hint). // If the compiler has determined that the map or the first bucket // can be created on the stack, h and/or bucket may be non-nil. // If h != nil, the map can be created directly in h. // If h.buckets != nil, bucket pointed to can be used as the first bucket. func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u003e maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u003c 0 overLoadFactor returns false since hint \u003c bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap){} 通过 makemap 函数，我们可以看到 map 在运行时是一个指向 hmap 的指针，hmap 是 go 语言实现的哈希表，一个哈希表有如下实现要点: 首先哈希表由哈希函数和底层的数组组成 哈希函数用来定位 key 的存储位置，并可能存在哈希冲突 当负载因子高或者低时，哈希表需要动态扩缩容(rehash) 下面是 map","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:2","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.1 底层数组 hmap.buckets 就是 hmap 的底层数组，它由 bmap 定义，注意 bmap 的完整定义如下: type bmap struct { tophash [bucketCnt]uint8 data []byte overflow *bmap } 其中: tophash: 用来存储 Hash 值的高 8 位 这个字段与 hmap 的定位过程有关，后面就会看到它存在的意义 data: 存放的是key-value 数据 内存布局是 key/key/…..value/value 这么存储是为了节省字节对齐带来的空间浪费 overflow: 指向下一个 bucket hmap 使用链表法解决哈希冲突 注意: data 和 overflow 并没有显示的定义在结构体中，运行时在访问 bucket 时直接通过指针的偏移来访问这些虚拟成员。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:3","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.2 key 定位过程 hmap 的增删改查都需要先定位 key 在 buckets 中的位置， hmap 定位过程如下: 计算 key 的 Hash 值 将 Hash 值分为高 8 位和剩余低位 取 Hash 值低位与 hmap.B 取模确定 bucket 的位置 取 Hash 值高 8 位，在 bucket.tophash 数组中查询，如果在索引 i 处查找到，则获取索引 i 对应的 key 进行比较 当前 bucket 中没有找到，则依次从溢出的 bucket 中查找，如果 map 处于扩缩容过程中，优先从 oldbuckets 数组中查找 所以 bmap 的 tophash 的类型为 [bucketCnt]uint8 保存的是存储在当前bucket 的所有key 的Hash 的值高 8 位，目的是加快 key 的索引过程。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:4","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.3 数据存储 运行时在分配bucket时需要知道key/value的大小。那么运行时是如何知道key的大小的呢？当我们声明一个map类型变量时，比如var m map[string]int，Go运行时就会为该变量对应的特定map类型生成一个runtime.maptype实例: // $GOROOT/src/runtime/type.go type maptype struct { typ _type key *_type elem *_type bucket *_type // 表示hash bucket的内部类型 keysize uint8 // key的大小 elemsize uint8 // elem的大小 bucketsize uint16 // bucket的大小 flags uint32 } maptype 包含了我们所需的map类型的所有元信息。前面提到过编译器会将语法层面的map操作重写成运行时对应的函数调用，这些运行时函数有一个共同的特点：第一个参数都是maptype指针类型的参数。Go运行时就是利用maptype参数中的信息确定key的类型和大小的，map所用的hash函数也存放在maptype.key.alg.hash(key, hmap.hash0)中。 另外还有一点要提及的是，如果key或value的数据长度大于一定数值，那么运行时不会在bucket中直接存储数据，而是会存储key或value数据的指针。目前Go运行时定义的最大key和value的长度分别如下： // $GOROOT/src/runtime/map.go const ( maxKeySize = 128 maxElemSize = 128 ) ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:5","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.4 扩缩容 rehash 扩容条件 负载因子 = 键数量/bucket数量，Go 触发 hmap 扩容的条件有两个: 负载因子 \u003e 6.5 overflow 数量大于2^15 扩容过程 hmap 扩容时，会新建一个 bucket 数组，长度为原来的 2 倍，Go 会采用逐步搬迁的策略，每次访问 map 时都会触发一次搬迁，每次搬迁 2 个键值对。因此 hmap 的结构体中包含了 oldbuckets 成员，指向了扩容前的原 buckets 数组。buckets 则指向新分配的数组。带 oldbuckets 数组中所有键值对搬迁完毕后，oldbuckets就会被释放。 如果是因为overflow bucket过多导致的“扩容”，实际上运行时会新建一个和现有规模一样的bucket数组。 缩容过程 缩容过程发生在大量key 被删除之后，过程与扩容类似。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:6","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"2.5 并发 从上面的实现原理来看，充当map描述符角色的hmap实例自身是有状态的（hmap.flags）且对状态的读写是没有并发保护的，因此map实例不是并发写安全的，不支持并发读写。如果对map实例进行并发读写，程序运行时会发生panic。另外考虑到map可以自动扩容，map中数据元素的value位置可能在这一过程中发生变化，因此Go不允许获取map中value的地址，这个约束是在编译期间就生效的。 最后与 slice 类似，最好对map使用规模做出粗略的估算，并使用cap参数对map实例进行初始化。这样可以减少内存分配和数据迁移的次数，提升性能。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:2:7","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"3. string go string类型具有如下功能特点: string类型的数据是不可变的 零值可用 支持通过+/+=操作符进行字符串连接 支持各种比较关系操作符：==、!= 、\u003e=、\u003c=、\u003e和\u003c ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:3:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"3.1 string 实现 string 定义在 src/runtime/string.go 中: type stringStruct struct { str unsafe.Pointer len int } func gostringnocopy(str *byte) string { ss := stringStruct{str: unsafe.Pointer(str), len: findnull(str)} s := *(*string)(unsafe.Pointer(\u0026ss)) return s } stringStruct 中: str: 字符串的首地址 len: 字符串的长度 在 runtime 包中使用 gostringnocopy 函数来生成字符串，gostringnocopy 会先构建 stringStruct 对象，然后在转换成 string，string 定义在 buildin 包中: // string is the set of all strings of 8-bit bytes, conventionally but not // necessarily representing UTF-8-encoded text. A string may be empty, but // not nil. Values of string type are immutable. type string string 从注释中可以看到: string 是 8bit 的集合，通常是 UTF-8 的文本 string 可以为空，但不会是 nil string 对象不可修改 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:3:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"3.2 字符串拼接 Go 中字符串可以直接使用 + 号进行拼接: str := \"str1\" + \"str2\" + \"str3\"，拼接过程在内部则会调用 string 包的 concatstrings() 函数，代码如下: // concatstrings implements a Go string concatenation x+y+z+... // The operands are passed in the slice a. // If buf != nil, the compiler has determined that the result does not // escape the calling function, so the string data can be stored in buf // if small enough. func concatstrings(buf *tmpBuf, a []string) string { idx := 0 l := 0 count := 0 for i, x := range a { n := len(x) if n == 0 { continue } if l+n \u003c l { throw(\"string concatenation too long\") } l += n count++ idx = i } if count == 0 { return \"\" } // If there is just one string and either it is not on the stack // or our result does not escape the calling frame (buf != nil), // then we can return that string directly. if count == 1 \u0026\u0026 (buf != nil || !stringDataOnStack(a[idx])) { return a[idx] } // 返回一个 string 和切片，二者共享内存空间 s, b := rawstringtmp(buf, l) for _, x := range a { copy(b, x) b = b[len(x):] } return s } func rawstringtmp(buf *tmpBuf, l int) (s string, b []byte) { if buf != nil \u0026\u0026 l \u003c= len(buf) { b = buf[:l] s = slicebytetostringtmp(\u0026b[0], len(b)) } else { s, b = rawstring(l) } return } // rawstring allocates storage for a new string. The returned // string and byte slice both refer to the same storage. // The storage is not zeroed. Callers should use // b to set the string contents and then drop b. func rawstring(size int) (s string, b []byte) { p := mallocgc(uintptr(size), nil, false) stringStructOf(\u0026s).str = p stringStructOf(\u0026s).len = size *(*slice)(unsafe.Pointer(\u0026b)) = slice{p, size, size} return } concatstrings 实现中: 所有待拼接字符串都被编译器组织到一个切片中并传入 concatstrings 函数 拼接需要遍历两次切片，第一次遍历获取总的字符串长度，据此申请内存 第二次遍历把字符串逐个拷贝过去 运行时修改字符串的方式是，rawstring 创建一个临时slice，该slice的array指针也指向存储字符串数据的底层内存区域。rawstring调用后，新申请的内存区域还未被写入数据，该slice就是供后续运行时层向其中写入数据用的。写完数据后，该slice就可以被回收掉了， 字符串高效构建 Go 支持通过+/+=操作符来连接多个字符串以构造一个更长的字符串，并且通过+/+=操作符的字符串连接构造是最自然、开发体验最好的一种。但Go还提供了其他一些构造字符串的方法，比如： 使用fmt.Sprintf； 使用strings.Join； 使用strings.Builder； 使用bytes.Buffer。 可以编写一些单元测试来测试不同方法的性能 // 1. 做了预初始化的strings.Builder -- 效率最高 func concatStringByStringsBuilderWithInitSize(sl []string) string { var b strings.Builder b.Grow(64) for _, v := range sl { b.WriteString(v) } return b.String() } // 2. join -- 其次 func concatStringByJoin(sl []string) string { return strings.Join(sl, \"\") } // 3. 带有预初始化的bytes.Buffer -- 与 join 差不多 func concatStringByBytesBufferWithInitSize(sl []string) string { buf := make([]byte, 0, 64) b := bytes.NewBuffer(buf) for _, v := range sl { b.WriteString(v) } return b.String() } // 4. fmt.Sprintf 效率最低 func concatStringBySprintf(sl []string) string { var s string for _, v := range sl { s = fmt.Sprintf(\"%s%s\", s, v) } return s } 这里给一下结论: 在能预估出最终字符串长度的情况下，使用预初始化的strings.Builder连接构建字符串效率最高； strings.Join连接构建字符串的平均性能最稳定，如果输入的多个字符串是以[]string承载的，那么strings.Join也是不错的选择； 使用操作符连接的方式最直观、最自然，在编译器知晓欲连接的字符串个数的情况下，使用此种方式可以得到编译器的优化处理； fmt.Sprintf虽然效率不高，但也不是一无是处，如果是由多种不同类型变量来构建特定格式的字符串，那么这种方式还是最适合的。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:3:2","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"3.3 类型转换 字符串可以与rune slice、byte slice相互转换，转换过程需要一次内存拷贝，转换对应的函数如下： // $GOROOT/src/runtime/string.go slicebytetostring: []byte -\u003e string slicerunetostring: []rune -\u003e string stringtoslicebyte: string -\u003e []byte stringtoslicerune: string -\u003e []rune []byte -\u003e string []byte -\u003e string 调用的是 string 包的 slicebytetostring 函数 // slicebytetostring converts a byte slice to a string. // It is inserted by the compiler into generated code. // ptr is a pointer to the first element of the slice; // n is the length of the slice. // Buf is a fixed-size buffer for the result, // it is not nil if the result does not escape. func slicebytetostring(buf *tmpBuf, ptr *byte, n int) (str string) { if n == 0 { // Turns out to be a relatively common case. // Consider that you want to parse out data between parens in \"foo()bar\", // you find the indices and convert the subslice to string. return \"\" } if raceenabled { racereadrangepc(unsafe.Pointer(ptr), uintptr(n), getcallerpc(), funcPC(slicebytetostring)) } if msanenabled { msanread(unsafe.Pointer(ptr), uintptr(n)) } if n == 1 { p := unsafe.Pointer(\u0026staticuint64s[*ptr]) if sys.BigEndian { p = add(p, 7) } stringStructOf(\u0026str).str = p stringStructOf(\u0026str).len = 1 return } var p unsafe.Pointer if buf != nil \u0026\u0026 n \u003c= len(buf) { // 如果预留 buf 够用，则用预留的 buf p = unsafe.Pointer(buf) } else { // 否则重新申请内存 p = mallocgc(uintptr(n), nil, false) } // 构建字符串 stringStructOf(\u0026str).str = p stringStructOf(\u0026str).len = n // 将切片底层数组中数据拷贝到字符串 memmove(p, unsafe.Pointer(ptr), uintptr(n)) return } func memmove(to, from unsafe.Pointer, n uintptr) func mallocgc(size uintptr, typ *_type, needzero bool) unsafe.Pointer string -\u003e []byte []byte -\u003e string 调用的是 string 包的 slicebytetostring 函数: type tmpBuf [tmpStringBufSize]byte func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil \u0026\u0026 len(s) \u003c= len(buf) { // buf 小直接从栈上分配 *buf = tmpBuf{} b = buf[:len(s)] } else { // 生成新的切片 b = rawbyteslice(len(s)) } copy(b, s) return b } // rawbyteslice allocates a new byte slice. The byte slice is not zeroed. func rawbyteslice(size int) (b []byte) { cap := roundupsize(uintptr(size)) p := mallocgc(cap, nil, false) if cap != uintptr(size) { memclrNoHeapPointers(add(p, uintptr(size)), cap-uintptr(size)) } *(*slice)(unsafe.Pointer(\u0026b)) = slice{p, size, int(cap)} return } type Type int func copy(dst, src []Type) int ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:3:3","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"3.4 编译优化 []byte 和 string 相互转化都会进行一次内存拷贝，而在某些临时场景下，byte 切换在转化成 string 是并不会拷贝内存，而是直接返回一个 string ，string.str 的指针指向切片的内存，这些场景都符合一个特征，即在 string 的存续期间 []byte 肯定不会修改: 使用 map[string(b)] 字符串拼接 \"a\" + string(b) + \"c\" 字符串比较 string(b) == \"foo\" 用在for-range循环中的string到[]byte的转换 func convertWithOptimize() { s := \"中国欢迎您，北京欢迎您\" // range 内的转换不会拷贝内存 for _, v := range []byte(s) { _ = v } } ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:3:4","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"4. struct Go 语言中 struct 的一个特点是允许为字段标记 Tag，如下所示: type TypeMeta struct { Kind string `json:\"kind,omitempty\" protobuf:\"bytes,1,opt,name=kind\"` } ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:4:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"4.1 Tag 的本质 首先 Tag 是 struct 的一部分，用于标识结构体字段的额外属性。在 reflect 包中，使用结构体 StructField 表示结构体的一个字段: // A StructField describes a single field in a struct. type StructField struct { // Name is the field name. Name string // PkgPath is the package path that qualifies a lower case (unexported) // field name. It is empty for upper case (exported) field names. // See https://golang.org/ref/spec#Uniqueness_of_identifiers PkgPath string Type Type // field type Tag StructTag // field tag string Offset uintptr // offset within struct, in bytes Index []int // index sequence for Type.FieldByIndex Anonymous bool // is an embedded field } type StructTag string func (tag StructTag) Get(key string) string { v, _ := tag.Lookup(key) return v } 可以看到，Tag 也是字段的一个组成部分。从类型可以看出 Tag 是一个字符串，它有一个约定的格式，就是由 key:“value” 组成: key: 必须是非空字符串，字符串不能包含控制字符、空格、引号、冒号 value: 以双引号括住的字符串 key 和 value 之间使用冒号相隔，冒号前后不能有空格，多个 key:“value” 由空格分割 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:4:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"4.2 Tag 的获取 通过反射可以获取 Tag 中 key 对应的 value，下面是一个代码示例: func PrintTag(){ t := TypeMeta{} ty := reflect.TypeOf(t) for i := 0; i \u003c ty.NumField(); i++ { fmt.Printf(\"Field: %s, Tag: %s\\n\", ty.Field(i).Name, ty.Field(i).Tag.Get(\"json\")) } } Go 语言的反射特性可以动态的给结构体成员赋值，Tag 就可以给这种赋值提供\"指引\"。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:4:2","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"5. iota Go 中 iota 用于声明连续的整型常量，iota 的取值与其出现的额位置强相关。从编译器的角度看 iota，其取值规则只有一条: iota 代表了 const 声明块的行索引。除此之外，const 声明还有一个特点，如果为常量指定了一个表达式，但后续的常量没有表达式，则继承上面的表达式。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:5:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"5.1 实现原理 在编译器代码中，每个常量或者变量的声明语句使用 ValueSpec 结构表示，ValueSpec 定义在 src/go/ast/ast.go ValueSpec struct { Doc *CommentGroup // associated documentation; or nil Names []*Ident // value names (len(Names) \u003e 0) Type Expr // value type; or nil Values []Expr // initial values; or nil Comment *CommentGroup // line comments; or nil } ValueSpec 仅表示一行声明语句，比如: const ( // 常量块注释 a, b = iota, iota // 常量行注释 ) 上面的常量声明中仅包括一行声明语句，对应一个 ValueSpec 结构: Doc: 表示注释 Name: 常量的名字，使用切片表示当行语句中声明的多个变量 Type: 常量类型 Value: 常量值 Comment: 常量行注释 如果 const 包含多行常量声明，就会对应多个 ValueSpec，编译器在遍历时会使用类似下面的伪代码: for iota, spec := range ValueSpecs { for i, name := range spec.Names }{ obj := NewConst(name, iota) } } 从上面的代码就可以看出，iota 的本质: 仅代表常量声明的索引。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:5:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"6. channel channel 的定义和使用，在 go 语言的第四部分-go 并发中有详细的介绍，内容如下: Channel 使用与实现 Channel 应用 虽然后面有更详细的介绍，但这里不妨我们对它有个基本的认识。 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:6:0","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"6.1 hchan 数据结构 channel 定义在源码包 src/runtime/chan.go 中，对应类型为 *hchan，由 makechan 函数创建。hchan 结构如下，其中比较难理解的是 elementype *_type，这个跟 Go 类型系统的实现有关，我们暂时放一放。 type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G's status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex } type _type struct { size uintptr ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag tflag align uint8 fieldAlign uint8 kind uint8 // function for comparing objects of this type // (ptr to object A, ptr to object B) -\u003e ==? equal func(unsafe.Pointer, unsafe.Pointer) bool // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte str nameOff ptrToThis typeOff } type nameOff int32 type typeOff int32 type tflag uint8 hchan 的结构成员分成了如下几类 环形队列: dataqsiz: 队列的长度 buf: 队列的内存 qcount: 队列中元素个数 sendx: 插入数据的位置索引 recvx: 读取数据的位置索引 等待队列: recvq: 读取等待队列 sendq: 发送等待队列 类型信息: 一个管道只能发送一种类型的值 elemtype: 元素类型 elemsize: 元素类型大小 互斥锁: lock ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:6:1","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"6.2 channel 创建 hchan 由 makechan 函数创建，函数如下: type chantype struct { typ _type elem *_type dir uintptr } func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u003e= 1\u003c\u003c16 { throw(\"makechan: invalid channel element type\") } if hchanSize%maxAlign != 0 || elem.align \u003e maxAlign { throw(\"makechan: bad alignment\") } mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u003e maxAlloc-hchanSize || size \u003c 0 { panic(plainError(\"makechan: size out of range\")) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026c.lock, lockRankHchan) if debugChan { print(\"makechan: chan=\", c, \"; elemsize=\", elem.size, \"; dataqsiz=\", size, \"\\n\") } return c } ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:6:2","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"6.3 channel 的使用 向 channel 收发数据是否会阻塞，与我们理解的环形队列的使用基本无异，只不过里面包含了一些小技巧: 首先环形队列没有空间时，发送数据会阻塞 同样环形队列中没有数据时，读取数据会阻塞 技巧一，当接收队列 recvq 不为空时，说明缓冲区肯定没有数据但有协程在等待，所以会把写入的数据直接传递给 recvq 中的第一个协程，而不必写入 buf 于技巧一类似，当 sendq 不为空时，会直接将 sendq 中第一个协程的数据发送给读取的协程 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:6:3","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"6.4 channel的关闭 关闭管道时，recvq/sendq 中的协程会全部唤醒，但是行为不同: recvq 中的协程会获取对应类型的零值 sendq 中的协程会触发异常，所以 channel 只能发送方关闭，发送方可以确保没有协程阻塞在 sendq 除此之外下面的 channel 操作也会触发 panic: 关闭值为 nil 的管道 关闭已经被关闭的管道 向已经关闭的管道写入数据 ","date":"2022-12-28","objectID":"/posts/program/go/expert/go_export/expert_5/:6:4","tags":["go 进阶"],"title":"Go 语言的复合数据类型","uri":"/posts/program/go/expert/go_export/expert_5/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言语法的基础: 语句、控制结构。 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:0:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"1. 表达式的求值顺序 Go语言支持在同一行声明和初始化多个变量（不同类型也可以），也支持在同一行对多个变量进行赋值 var a, b, c = 5, \"hello\", 3.45 a, b, c = 5, \"hello\", 3.4 但这就牵扯到另一个问题: 表达式求值顺序（evaluation order）。比如 n0, n1 = n0+n1, n0 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:1:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"1.1 包级别变量声明语句中的表达式求值顺序 包级别变量声明语句中的表达式求值顺序由变量的声明顺序和初始化依赖（initialization dependencies）规则决定 初始化依赖规则是: 在Go包中，包级别变量的初始化按照变量声明的先后顺序进行。 如果某个变量（如变量a）的初始化表达式中直接或间接依赖其他变量（如变量b），那么变量a的初始化顺序排在变量b后面。 未初始化的且不含有对应初始化表达式或初始化表达式不依赖任何未初始化变量的变量，我们称之为“ready for initialization”变量。 包级别变量的初始化是逐步进行的，每一步就是按照变量声明顺序找到下一个“ready for initialization”变量并对其进行初始化的过程。反复重复这一步骤，直到没有“ready for initialization”变量为止。 位于同一包内但不同文件中的变量的声明顺序依赖编译器处理文件的顺序：先处理的文件中的变量的声明顺序先于后处理的文件中的所有变量。 我们看下面这个例子，由于初始化的过程就是寻找 “ready for initialization，并对其进行初始化，所以整个初始化会经过如下几轮的查找 第一轮: 按照a -\u003e b -\u003e c -\u003e d的顺序，查找“ready for initialization”变量并对其进行初始化，d 被初始化 第二轮: 继续按照a -\u003e b -\u003e c -\u003e d的顺序，a 依赖 b 和 c，不满足初始化条件，b依赖函数f，函数f依赖d，d 已经初始化，b 具备成为 ready for initialization 的条件，所以次轮初始化 b 第三轮: 初始化 c 第四轮: 初始化 a // chapter3/sources/evaluation_order_1.go var ( a = c + b b = f() // _ = f() // _ 空变量，会得到一视同仁的处理 c = f() d = 3 ) func f() int { d++ return d } func main() { fmt.Println(a, b, c, d) } 还有一种比较特殊的情况，那就是当多个变量在声明语句左侧且右侧为单一表达式时的表达式求值情况。在这种情况下，无论左侧哪个变量被初始化，同一行的其他变量也会被一并初始化。 // chapter3/sources/evaluation_order_3.go var ( a = c b, c = f() d = 3 ) func f() (int, int) { d++ return d, d + 1 } func main() { fmt.Println(a, b, c, d) } 根据包级变量初始化规则，初始化过程将按照a -\u003e b\u0026c -\u003e d顺序进行“ready for initialization”变量的查找: 第一轮: d 初始化 第二轮：变量b和c一起符合条件，以b被选出为例，b被初始化的同时，c也得到了初始化 第三轮：a 初始化 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:1:1","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"1.2 普通求值顺序 普通求值顺序（usual order），用于规定表达式操作数中的函数、方法及channel操作的求值顺序。Go规定表达式操作数中的所有函数、方法以及channel操作按照从左到右的次序进行求值。 我们看这样一个表达式的求值顺序: y[f()], _ = g(h(), i()+x[j()], \u003c-c), k() 按照从左到右的顺序，先对等号左侧表达式操作数中的函数进行调用求值，因此第一个是y[f()]中的f()。 接下来是等号右侧的表达式。第一个函数是g()，但g()依赖其参数的求值，其参数列表依然可以看成是一个多值赋值操作，其涉及的函数调用顺序从左到右依次为h()、i()、j()、\u003c-c，这样该表达式操作数函数的求值顺序即为h() -\u003e i() -\u003e j() -\u003e c取值操作 -\u003e g()。 最后还剩下末尾的k()。 当普通求值顺序与包级变量的初始化依赖顺序一并使用时，后者优先级更高，但每个单独表达式中的操作数求值依旧按照普通求值顺序的规则。 我们看这样一个表达式的求值顺序: var a, b, c = f() + v(), g(), sqr(u()) + v() func f() int { fmt.Println(\"calling f\") return c } 单行的多变量赋值，可以转换为如下等价形式(注意，这里不是右侧为单一表达式) var ( a = f() + v() // f 依赖 c b = g() // g() 不依赖其他变量 c = sqr(u()) + v() ) 根据包级变量初始化规则，初始化过程将按照\"a -\u003e b -\u003e c\"顺序进行“ready for initialization”变量的查找: 第一轮：变量a依赖c，b符合条件，b被选出并初始化。依据普通求值顺序规则，g被调用。 第二轮：变量c符合条件，c被选出并初始化。依据普通求值顺序规则，u、sqr、v先后被调用。 第三轮：变量a符合条件，a被选出并初始化。依据普通求值顺序规则，f、v先后被调用。 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:1:2","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"1.3 赋值语句的求值 Go语言规定，赋值语句求值分为两个阶段： 第一阶段，对于等号左边的下标表达式、指针解引用表达式和等号右边表达式中的操作数，按照普通求值规则从左到右进行求值； 第二阶段，按从左到右的顺序对变量进行赋值。 所以对于 n0, n1 = n0 + n1, n0 假定 n0, n1 = 1, 2 第一阶段：等号两端表达式求值。上述问题中，等号左边没有需要求值的下标表达式、指针解引用表达式等，只有右端有n0+n1和n0两个表达式，但表达式的操作数(n0，n1)都是已初始化了的，因此直接将值代入，得到求值结果。求值后，语句可以看成n0, n1 = 3, 1 第二阶段：从左到右赋值，即n0 =3，n1 = 1 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:2:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"1.4 switch/select语句中的表达式求值 switch 先来看switch-case语句中的表达式求值，这类求值属于“惰性求值”范畴。惰性求值指的就是需要进行求值时才会对表达值进行求值。 func Expr(n int) int { fmt.Println(n) return n } func main() { switch Expr(2) { case Expr(1), Expr(2), Expr(3): fmt.Println(\"enter into case1\") fallthrough case Expr(4): fmt.Println(\"enter into case2\") } } $go run evaluation_order_7.go 2 1 2 enter into case1 enter into case2 从输出可以看出: 对于switch-case语句而言，首先进行求值的是switch后面的表达式Expr(2) 接下来将按照从上到下、从左到右的顺序对case语句中的表达式进行求值。如果某个表达式的结果与switch表达式结果一致，那么求值停止，后面未求值的case表达式将被忽略。 fallthrough 将执行权直接转移到下一个case执行语句中了，略过了case表达式Expr(4)的求值。 select select 的求值顺序，直接看下面这个例子: func getAReadOnlyChannel() \u003c-chan int { fmt.Println(\"invoke getAReadOnlyChannel\") c := make(chan int) go func() { time.Sleep(3 * time.Second) c \u003c- 1 }() return c } func getASlice() *[5]int { fmt.Println(\"invoke getASlice\") var a [5]int return \u0026a } func getAWriteOnlyChannel() chan\u003c- int { fmt.Println(\"invoke getAWriteOnlyChannel\") return make(chan int) } func getANumToChannel() int { fmt.Println(\"invoke getANumToChannel\") return 2 } func main() { select { // 从channel接收数据 case (getASlice())[0] = \u003c-getAReadOnlyChannel(): fmt.Println(\"recv something from a readonly channel\") // 将数据发送到channel case getAWriteOnlyChannel() \u003c- getANumToChannel(): fmt.Println(\"send something to a writeonly channel\") } } $go run evaluation_order_8.go invoke getAReadOnlyChannel invoke getAWriteOnlyChannel invoke getANumToChannel 从上述例子可以看出以下两点： select执行开始时，首先所有case表达式都会被按出现的先后顺序求值一遍 有一个例外，位于case等号左边的从channel接收数据的表达式（RecvStmt）不会被求值，即这里的 getASlice()。如果选择要执行的是一个从channel接收数据的case，那么该case等号左边的表达式在接收前才会被求值。比如在上面的例子中，在getAReadOnlyChannel创建的goroutine在3s后向channel中写入一个int值后，select选择了第一个case执行，此时对等号左侧的表达式(getASlice())[0]进行求值，这也算是一种惰性求值。 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:2:1","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2. 代码块与作用域 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2.1 Go 的代码块与作用域 Go语言中有两类代码块，一类是我们在代码中直观可见的由一堆大括号包裹的显式代码块，比如函数的函数体、for循环的循环体、if语句的某个分支等。 另一类则是没有大括号包裹的隐式代码块。Go规范定义了如下几种隐式代码块: 宇宙（Universe）代码块：所有Go源码都在该隐式代码块中，就相当于所有Go代码的最外层都存在一对大括号 包代码块：每个包都有一个包代码块，其中放置着该包的所有Go源码 文件代码块：每个文件都有一个文件代码块，其中包含着该文件中的所有Go源码 每个if、for和switch语句均被视为位于其自己的隐式代码块中 switch或select语句中的每个子句都被视为一个隐式代码块 Go标识符的作用域是基于代码块定义的，作用域规则描述了标识符在哪些代码块中是有效的。下面是标识符作用域规则。 预定义标识符，make、new、cap、len等的作用域范围是宇宙块。 顶层（任何函数之外）声明的常量、类型、变量或函数（但不是方法）对应的标识符的作用域范围是包代码块。比如：包级变量、包级常量的标识符的作用域都是包代码块。 Go源文件中导入的包名称的作用域范围是文件代码块。 方法接收器（receiver）、函数参数或返回值变量对应的标识符的作用域范围是函数体（显式代码块），虽然它们并没有被函数体的大括号所显式包裹。 在函数内部声明的常量或变量对应的标识符的作用域范围始于常量或变量声明语句的末尾，止于其最里面的那个包含块的末尾 在函数内部声明的类型标识符的作用域范围始于类型定义中的标识符，止于其最里面的那个包含块的末尾 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:1","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2.2 if 语句的代码块 我们先来了解一下 if 条件控制语句的代码块分布规则。 单if型 单if型，即 if SimpleStmt; Expression { ... } 根据代码块规则，if语句自身在一个隐式代码块中，因此单if类型的控制语句中有两个代码块：一个隐式代码块和一个显式代码块。所以上面的 if 语句等价于: { // 隐式代码块开始 SimpleStmt if Expression { // 显式代码块开始 ... } // 显式代码块结束 } // 隐式代码块结束 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:2","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"if { } else { }型 if Simplestmt; Expression { ... } else { ... } 等价于: { // 隐式代码块开始 SimpleStmt if Expression { // 显式代码块1开始 ... // 显式代码块1结束 } else { // 显式代码块2开始 ... } // 显式代码块2结束 } // 隐式代码块结束 所以在SimpleStmt中声明的变量，其作用域范围可以延伸到else后面的显式代码块中。 if {} else if {} else {} 型 if SimpleStmt1; Expression1 { ... } else if SimpleStmt2; Expression2 { ... } else { ... } 等价于: { // 隐式代码块1开始 SimpleStmt1 if Expression1 { // 显式代码块1开始 ... } else { // 显式代码块1结束；显式代码块2开始 { // 隐式代码块2开始 SimpleStmt2 if Expression2 { // 显式代码块3开始 ... } else { // 显式代码块3结束；显式代码块4开始 ... } // 显式代码块4结束 } // 隐式代码块2结束 } // 显式代码块2结束 } // 隐式代码块1结束 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:3","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2.3 for 语句的代码块 第一种 for 语句 for InitStmt; Condition; PostStmt { ... } 等价于: { // 隐式代码块开始 InitStmt for Condition; PostStmt { // for显式代码块 ... } } // 隐式代码块结束 第二种 for 语句 for IndentifierList := range Expression { ... } 等价于: { // 隐式代码块开始 IndentifierList := InitialValueList for IndentifierList = range Expression { // for的显式代码块 ... } } // 隐式代码块结束 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:4","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2.4 switch-case语句的代码块 switch SimpleStmt; Expression { case ExpressionList1: ... case ExpressionList2: ... default: ... } 等价于: { // 隐式代码块1开始 SimpleStmt switch Expression { // 显式代码块1开始 case ExpressionList1: { // 隐式代码块2开始 ... } // 隐式代码块2结束 case ExpressionList2: { // 隐式代码块3开始 ... } // 隐式代码块3结束 default: { // 隐式代码块4开始 ... } // 隐式代码块4结束 } // 显式代码块1结束 } // 隐式代码块1结束 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:5","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"2.5 select-case语句的代码块 和switch-case无法在case子句中声明变量不同的是，select-case可以在case字句中通过短变量声明定义新变量，但该变量依然被纳入case的隐式代码块中。 select { case SendStmt: ... case RecvStmt: ... default: ... } 等价于: select { // 显式代码块开始 case SendStmt: { // 隐式代码块1开始 ... } // 隐式代码块1结束 case RecvStmt: { // 隐式代码块2开始，如果RecvStmt声明了新变量，那么该变量也应包含在隐式代码块2中 // 等同于 RecvStmt 声明在这 ... } // 隐式代码块2结束 default: { // 隐式代码块3开始 ... } // 隐式代码块3结束 } // 显式代码块结束 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:3:6","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"3. 控制语句最佳实践 最后我们来介绍一些 Go 控制语句的惯用法，掌握这些，可以让我们写出更符合 go 思维的代码。 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:4:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"3.1 使用if控制语句时应遵循“快乐路径”原则 func doSomething() error { if errorCondition1 { // 错误逻辑 ... return err1 } // 成功逻辑 ... if errorCondition2 { // 错误逻辑 ... return err2 } // 成功逻辑 ... return nil } 所谓“快乐路径”即成功逻辑的代码执行路径，这个原则要求： 当出现错误时，快速返回； 成功逻辑不要嵌入if-else语句中； “快乐路径”的执行逻辑在代码布局上始终靠左，这样读者可以一眼看到该函数的正常逻辑流程； “快乐路径”的返回值一般在函数最后一行，就像上面伪代码段中的那样 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:4:1","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"3.2 for range的避“坑”指南 迭代变量的重用 for range的惯用法是使用短变量声明方式（:=）在for的initStmt中声明迭代变量（iteration variable）。但需要注意的是，这些迭代变量在for range的每次循环中都会被重用，而不是重新声明。这是因为根据for 语句的代码块作用域的说明: for InitStmt; Condition; PostStmt { ... } 等价于: { // 隐式代码块开始 InitStmt for Condition; PostStmt { // for显式代码块 ... } } // 隐式代码块结束 我们就可以清晰地看到迭代变量的重用。典型的错误，就是像下面这样: func demo1() { var m = [...]int{1, 2, 3, 4, 5} for i, v := range m { go func() { time.Sleep(time.Second * 3) fmt.Println(i, v) }() // }(i, v) 正确的方式是讲 i,v 作为参数传入 } time.Sleep(time.Second * 10) } goroutine执行的闭包函数引用了它的外层包裹函数中的变量i、v，这样变量i、v在主goroutine和新启动的goroutine之间实现了共享。而i、v值在整个循环过程中是重用的，仅有一份。所有的 goroutine 都会输出 4,5。 参与迭代的是range表达式的副本 for range语句中，range后面接受的表达式的类型可以是数组、指向数组的指针、切片、字符串、map和channel（至少需具有读权限）。我们以数组为例，看一个示例: func arrayRangeExpression() { var a = [5]int{1, 2, 3, 4, 5} var r [5]int fmt.Println(\"arrayRangeExpression result:\") fmt.Println(\"a = \", a) for i, v := range a { if i == 0 { a[1] = 12 a[2] = 13 } r[i] = v } fmt.Println(\"r = \", r) fmt.Println(\"a = \", a) } // 实际运行该程序的输出结果 a = [1 2 3 4 5] r = [1 2 3 4 5] a = [1 12 13 4 5] 出现这个结果的原因是：参与循环的是range表达式的副本。 Go中的数组在内部表示为连续的字节序列，虽然长度是Go数组类型的一部分，但长度并不包含在数组类型在Go运行时的内部表示中，数组长度是由编译器在编译期计算出来。这个例子中，对range表达式的复制即对一个数组的复制。因此无论a被如何修改，其参与循环的副本a’依旧保持原值。因为是副本，所以当 for change 迭代的对象是数组，会有性能损耗。 对于其他类型，比如切片，在迭代时修改被迭代对象的效果需要结合被迭代对象的具体实现来看 slice: slice 由(*T, len, cap)三元组组成，虽然是副本，但是底层数据是共享的，但是长度信息是独立，增加长度的修改，不会反应在副本上 string: string 表示为struct {*byte, len}，并且string本身是不可改变的（immutable），因此其行为和消耗与切片作为range表达式时类似 不过 for range对于string来说，每次循环的单位是一个rune，而不是一个byte，返回的第一个值为迭代字符码点的第一字节的位置 如果作为range表达式的字符串s中存在非法UTF8字节序列，那么v将返回0xfffd这个特殊值，并且在下一轮循环中，v将仅前进一字节 map: map在Go运行时内部表示为一个hmap的描述符结构指针，因此 map 的副本也会指向同一个 hmap for range无法保证每次迭代的元素次序是一致的。如果在循环的过程中对map进行修改，那么这样修改的结果是否会影响后续迭代过程也是不确定的 channel: channel在Go运行时内部表示为一个channel描述符的指针，channel的副本也指向原channel 描述符 当channel作为range表达式类型时，for range最终以阻塞读的方式阻塞在channel表达式上，即便是带缓冲的channel亦是如此：当channel中无数据时，for range也会阻塞在channel上，直到channel关闭 ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:4:2","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"3.3 break Go break语法的一个“小坑”，Go语言规范中明确规定 break语句（不接label的情况下）结束执行并跳出的是同一函数内break语句所在的最内层的for、switch或select的执行。 func main() { exit := make(chan interface{}) go func() { loop: for { select { case \u003c-time.After(time.Second): fmt.Println(\"tick\") case \u003c-exit: fmt.Println(\"exiting...\") break loop } } fmt.Println(\"exit!\") }() time.Sleep(3 * time.Second) exit \u003c- struct{}{} // 等待子goroutine退出 time.Sleep(3 * time.Second) } 上面例子中的，如果 break 不加 loop，实际上跳出了的是 select语句，不会跳出 for 循环。程序会一直执行。类似的 continue 也支持标签: outerLoop: for i := 0; i \u003c n; i++ { // ... for j := 0; j \u003c m; j++ { // 当不满足某些条件时，直接终止最外层循环的执行 break outerLoop // 当满足某些条件时，直接跳出内层循环，回到外层循环继续执行 continue outerLoop } } ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:5:0","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"3.4 switch case 的 fallthrough go 提供了 fallthrough 关键字，将执行权直接转移到下一个switch case执行语句中。不过在实际编码过程中，fallthrough的应用依然不多，而且Go的switch-case语句还提供了case表达式列表来支持多个分支表达式处理逻辑相同的情况： switch n { case 1, 3, 5, 7: odd() case 2, 4, 6, 8: even() default: unknown() } ","date":"2022-12-27","objectID":"/posts/program/go/expert/go_export/expert_3/:5:1","tags":["go 进阶"],"title":"Go 语句与控制结构","uri":"/posts/program/go/expert/go_export/expert_3/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"今天我们开始深入学习，Go 语言语法的基础: Go 声明、类型、初始化。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:0:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"1. 变量声明 Go语言沿袭了静态编译型语言的传统：使用变量之前需要先进行变量的声明。Go语言有两类变量。 包级变量（package variable）：在package级别可见的变量。如果是导出变量，则该包级变量也可以被视为全局变量，包级变量只能使用带有var关键字的变量声明形式 局部变量（local variable）：函数或方法体内声明的变量，仅在函数或方法体内可见 Go 为这两种变量提供了两种不同的声明方式: var 关键字和短变量声明的方式。加上 var 声明块，Go 语言就有了多种命名变量的方式: var a int32 var s string = \"hello\" var i = 13 n := 17 var ( crlf = []byte(\"\\r\\n\") colonSpace = []byte(\": \") ) 虽然声明多样，但是我们应尽量保持项目范围内一致。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:1:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"1.1 var 声明 首先标准的 var 声明语法是这样的: var variableName [type] [= InitExpression]。type、InitExpression 可以省略就有了如下 var 声明的组合: 无InitExpression 常量InitExpression 带类型信息的InitExpression 有type 变量 = type 类型的零值 变量 = type(常量) 变量 = type(类型常量) 无type 错误 变量的 type = 常量表达式的默认类型 变量 type = 常量类型 // 以整型值初始化的变量a，Go编译器会将之设置为默认类型int； // 以浮点值初始化的变量f，Go编译器会将之设置为默认类型float64。 var a = 17 var f = 3.14 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:1:1","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"1.2 声明聚类 go 在提供 var 声明的同时，还提供了提供var块用于将多个变量声明语句放在一起。我们一般 将同一类的变量声明放在一个var块中 将不同类的声明放在不同的var块中； 将延迟初始化的变量声明放在一个var块，而将声明并显式初始化的变量放在另一个var块中 目的是显而易见的，通过显示的代码块，让变量分门别类的聚合在一起。为了让声明更加规整，go 更推荐下面这种指定类型的声明方式: // 要显式为包级变量a和f指定类型 // 推荐: var ( a = 17 f = float32(3.14) ) // 不推荐: var ( a = 17 f float32 = 3.14 ) ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:1:2","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"1.3 短变量声明 短变量声明只能用在局部变量上，以下场景更推荐短变量 显式初始化的局部变量 分支控制时使用的局部变量 func (v *Buffers) WriteTo(w io.Writer) (n int64, err error) { // 显示初始化 value := 10 // 在if循环控制语句中使用短变量声明形式 if wv, ok := w.(buffersWriter); ok { return wv.writeBuffers(v) } // 在for条件控制语句中使用短变量声明形式 for _, b := range *v { nb, err := w.Write(b) n += int64(nb) if err != nil { v.consume(n) return n, err } } v.consume(n) return n, nil } 以下场景则更推荐 var 声明: 延迟初始化的局部变量 要声明的变量很多，适合聚类时，应该使用var块来声明多个局部变量 func Foo() { // 延迟初始化的局部变量 var err error defer func() { if err != nil { ... } }() err = Bar() ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:1:3","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"2. 无类型常量 首先我们来看一下什么叫无类型常量。 // 1. 形如下面，用在等号右边的，叫做字面量 \"我是中国人\" 1 3.14 // 2. 使用 var 关键字声明的叫变量 var a int = 10 // 这是有类型变量 var a = 10 // 这是无类型变量，无类型变量会赋予字面量的默认类型 // 3. 使用 const 关键字声明的，带类型的叫有类型常量 const b int = 30 // 4. 使用 const 关键字声明的，不带类型的叫无类型常量 const c = 40 Go是对类型安全要求十分严格的编程语言。Go要求: 两个类型即便拥有相同的底层类型（underlying type），也仍然是不同的数据类型，不可以被相互比较或混在一个表达式中进行运算，即不支持隐式的类型转换。 而将 有类型常量 与变量混合在一起进行运算求值时也要遵循这一要求，即如果有类型常量与变量的类型不同，那么混合运算的求值操作会报错。 type myInt int func main() { var a int = 5 var b myInt = 6 fmt.Println(a + b) // 编译器会给出错误提示：invalid operation: a + b (mismatched types int and myInt) } Go 中真正特殊的是无类型常量，Go的无类型常量拥有像字面值的特性: 使得无类型常量在参与变量赋值和计算过程时无须显式类型转换 拥有和字面量一样的默认类型：无类型的布尔型常量、整数常量、字符常量、浮点数常量、复数常量、字符串常量对应的默认类型分别为bool、int、int32(rune)、float64、complex128和string 数值型无类型常量可以提供比基础类型更高精度的算术运算，至少有256 bit的运算精度。 在给无类型变量、接口变量赋值时，无类型常量和字面量的默认类型对于确定无类型变量的类型及接口对应的动态类型是至关重要的。 type myInt int type myFloat float32 type myString string const ( a = 5 pi = 3.1415926 s = \"Hello, Gopher\" ) func main() { var j myInt = 5 var f myFloat = 3.1415926 var str myString = \"Hello, Gopher\" fmt.Println(j) // 输出：5 fmt.Println(f) // 输出：3.1415926 fmt.Println(str) // 输出：Hello, Gopher // 字面量无需显示的类型转换，不必像下面这样 var j myInt = myInt(5) var f myFloat = myFloat(3.1415926) var str myString = myString(\"Hello, Gopher\") // 无类型常量，也无需显示类型转换 var j myInt = a var f myFloat = pi var str myString = s var e float64 = a + pi // 注意 a 和 pi 属于混合数据类型 } ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:2:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"3. iota实现枚举常量 首先 Go 的 const 语法提供了“隐式重复前一个非空表达式”的机制。 const ( Apple, Banana = 11, 22 Strawberry, Grape Pear, Watermelon ) // 等同于 const ( Apple, Banana = 11, 22 Strawberry, Grape = 11, 22 Pear, Watermelon = 11, 22 ) 更高级的是使用 iota。iota 是 Go语言的一个预定义标识符，它表示的是const声明块（包括单行声明）中每个常量所处位置在块中的偏移值（从零开始）。同时，每一行中的iota自身也是一个无类型常量，可以像无类型常量那样自动参与不同类型的求值过程，而无须对其进行显式类型转换操作。 从实现上更容易看出来 iota 到底是个什么东西。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:3:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"3.1 实现原理 在编译器代码中，每个常量或者变量的声明语句使用 ValueSpec 结构表示，ValueSpec 定义在 src/go/ast/ast.go ValueSpec struct { Doc *CommentGroup // associated documentation; or nil Names []*Ident // value names (len(Names) \u003e 0) Type Expr // value type; or nil Values []Expr // initial values; or nil Comment *CommentGroup // line comments; or nil } ValueSpec 仅表示一行声明语句，比如: const ( // 常量块注释 a, b = iota, iota // 常量行注释 ) 上面的常量声明中仅包括一行声明语句，对应一个 ValueSpec 结构: Doc: 表示注释 Name: 常量的名字，使用切片表示当行语句中声明的多个变量 Type: 常量类型 Value: 常量值 Comment: 常量行注释 如果 const 包含多行常量声明，就会对应多个 ValueSpec，编译器在遍历时会使用类似下面的伪代码: for iota, spec := range ValueSpecs { for i, name := range spec.Names }{ obj := NewConst(name, iota) } } 从上面的代码就可以看出，iota 的本质: 仅代表常量声明的索引。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:3:1","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"3.2 iota 的使用 借助 iota 我们可以实现更灵活的枚举常量定义。 const ( mutexLocked = 1 \u003c\u003c iota //1 = 1 \u003c\u003c 0 // “隐式重复前一个非空表达式” mutexWoken //2 = 1 \u003c\u003c 1 mutexStarving //4 = 1 \u003c\u003c 2 mutexWaiterShift = iota //3 = 3 starvationThresholdNs = 1e6 ) // 位于同一行的iota即便出现多次，其值也是一样的： const ( Apple, Banana = iota, iota + 10 // 0, 10 (iota = 0) Strawberry, Grape // 1, 11 (iota = 1) Pear, Watermelon // 2, 12 (iota = 2) ) // 如果要定义非连续枚举值 const ( _ = iota // 0 Pin1 Pin2 Pin3 _ // 相当于_ = iota，略过了4这个枚举值 Pin5 // 5 ) // 枚举常量多数是无类型常量，如果要严格考虑类型安全，也可以定义有类型枚举常量 type Weekday int const ( Sunday Weekday = iota // “隐式重复前一个非空表达式”，下面常量都是 Weekday 类型 Monday Tuesday Wednesday Thursday Friday Saturday ) ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:3:2","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"4. 零值可用类型 定义零值可用的类型是Go语言积极倡导的最佳实践之一。首先我们来看什么是零值。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:4:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"4.1 零值 所谓零值，就是未对变量进行显示初始化时，变量会被赋予的默认值。当通过声明或调用new为变量分配存储空间，或者通过复合文字字面量或调用make创建新值，且不提供显式初始化时，Go会为变量或值提供默认值。 Go语言中的每个原生类型都有其默认值，这个默认值就是这个类型的零值。 所有整型类型：0 浮点类型：0.0 布尔类型：false 字符串类型：\"\" 指针、interface、切片（slice）、channel、map、function：nil 另外，Go的零值初始是递归的，即数组、结构体等类型的零值初始化就是对其组成元素逐一进行零值初始化。 而所谓零值可用，就是变量未显示初始化被赋予的默认值是可以操作的，包括调用它的自定义方法。 var zeroSlice []int zeroSlice = append(zeroSlice, 1) 我们声明了一个[]int类型的切片zeroSlice，但并没有对其进行显式初始化，这样zeroSlice这个变量就被Go编译器置为零值nil。由于Go中的切片类型具备零值可用的特性，我们可以直接对其进行append操作，而不会出现引用nil的错误。 零值可用自定义类型示例，可以参考 sync.Mutex和bytes.Buffer var mu sync.Mutex mu.Lock() mu.Unlock() func main() { var b bytes.Buffer b.Write([]byte(\"Effective Go\")) fmt.Println(b.String()) // 输出：Effective Go } // $GOROOT/src/bytes/buffer.go type Buffer struct { buf []byte // 字段buf支持零值可用策略的切片类型 off int lastRead readOp } 不过Go并非所有类型都是零值可用的，并且零值可用也有一定的限制 // 在append场景下，零值可用的切片类型不能通过下标形式操作数据： s[0] = 12 // 报错！ s = append(s, 12) // 正确 // map 这样的原生类型也没有提供对零值可用的支持： var m map[string]int m[\"go\"] = 1 // 报错！ m1 := make(map[string]int) m1[\"go\"] = 1 // 正确 // 零值可用的类型要注意尽量避免值复制： var mu sync.Mutex mu1 := mu // 错误: 避免值复制 foo(mu) // 错误: 避免值复制 持与Go一致的理念，给自定义的类型一个合理的零值，并尽量保持自定义类型的零值可用，这样我们的Go代码会更加符合Go语言的惯用法。这就要求我们，当我们为自定义类型添加各种方法时，都需要判断当前操作在当前状态下是不是是可执行的。比如: package algo type Product struct { Name string Attributes map[string]string } func (p *Product) AddAttr(attr, value string) { if p.Attributes == nil { p.Attributes = make(map[string]string) } p.Attributes[attr] = value } var p Product p.AddAttr(\"color\", \"red\") 为了保证自定义类型 Product 是零值可用的，我们在 AddAttr 方法中，必须判断其 Attributes 字段是否已经初始化，否则 Product 就会因为默认的 map 类型不支持零值可用导致，Product 本身不支持零值可用。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:4:1","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"5. 复合字面值 Go提供的复合字面值（composite literal）语法可以作为复合类型变量的初值构造器。合字面值由两部分组成：一部分是类型，另一部分是由大括号{}包裹的字面值。比如: a := [5]int{13, 14, 15, 16, 17} m := map[int]string {1:\"hello\", 2:\"gopher\", 3:\"!\"} Go 的复合字面值还有一些高级用法。 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:5:0","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"5.1 结构体复合字面值 go vet工具中内置了一条检查规则：composites。此规则用于检查源码中使用复合字面值对结构体类型变量赋值的行为。 如果源码中使用了从另一个包中导入的struct类型，但却未使用field:value形式的初值构造器，则该规则认为这样的复合字面值是脆弱的。因为一旦该结构体类型增加了一个新的字段，即使是未导出的，这种值构造方式也将导致编译失败。 显然，Go推荐使用field:value的复合字面值形式对struct类型变量进行值构造: // $GOROOT/src/net/http/transport.go var DefaultTransport RoundTripper = \u0026Transport{ Proxy: ProxyFromEnvironment, DialContext: (\u0026net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, DualStack: true, }).DialContext, MaxIdleConns: 100, IdleConnTimeout: 90 * time.Second, TLSHandshakeTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second, } 复合字面值作为结构体值构造器的大量使用，使得即便采用类型零值时我们也会使用字面值构造器形式，而较少使用new这一个Go预定义的函数来创建结构体变量实例： s := myStruct{} // 常用 s := new(myStruct) // 较少使用 ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:5:1","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"5.2 数组/切片/map复合字面值 组/切片使用下标（index）作为field:value形式中的field，从而实现数组/切片初始元素值的高级构造形式： numbers := [256]int{'a': 8, 'b': 7, 'c': 4, 'd': 3, 'e': 2, 'y': 1, 'x': 5} // [10]float{-1, 0, 0, 0, -0.1, -0.1, 0, 0.1, 0, -1} fnumbers := [...]float{-1, 4: -0.1, -0.1, 7:0.1, 9: -1} 对于数组/切片类型而言，当元素为复合类型时，可以省去元素复合字面量中的类型： type Point struct { x float64 y float64 } sl := []Point{ {1.2345, 6.2789}, // Point{1.2345, 6.2789} {2.2345, 19.2789}, // Point{2.2345, 19.2789} } 对于 对于map类型（这一语法糖在Go 1.5版本中才得以引入），当key或value的类型为复合类型时，我们也可以省去key或value中的复合字面量中的类型： // Go 1.5及之后版本 m := map[Point]string{ {29.935523, 52.891566}: \"Persepolis\", {-25.352594, 131.034361}: \"Uluru\", {37.422455, -122.084306}: \"Googleplex\", } 对于key或value为指针类型的情况，也可以省略“\u0026T”： m2 := map[string]*Point{ \"Persepolis\": {29.935523, 52.891566}, // 相当于value为\u0026Point{29.935523, 52.891566} \"Uluru\": {-25.352594, 131.034361}, // 相当于value为\u0026Point{-25.352594, 131.034361} \"Googleplex\": {37.422455, -122.084306}, // 相当于value为\u0026Point{37.422455, -122.084306} } ","date":"2022-12-26","objectID":"/posts/program/go/expert/go_export/expert_2/:5:2","tags":["go 进阶"],"title":"Go 声明、类型与初始化","uri":"/posts/program/go/expert/go_export/expert_2/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第二部分-go语言进阶","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"1. Go 语言进阶 前面 Go语言入门中我们学习了 Go 语言的基础语法和使用。算起来已经看过好几本 Go 的书籍了，但始终感觉\"不得其法\"，比如一直不明白reflect 库是如何实现 Go 语言变量自省的、Go 实现的http 服务底层有没有使用IO多路复用等等。直到今年双十一囤了《Go 语言精进之路》系列的两本书，花了一个月时间快速了看了一遍，收获真的很大。我感觉对于每个像我这样普通的程序员，学习一门语言总需要找到这样一本书，看完就感觉有种豁然开朗的感觉。所以这个系列我们来学习 《Go 语言精进之路》，作为 Go 语言的进阶。整个内容分成以下几个大的部分: Go 语言的语法进阶 测试与性能剖析 反射与 cgo 工具链与工程实践 我们正式进入学习之前，我们再来回顾一次 Go 语言的设计哲学。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:1:0","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"2. Go语言的设计哲学 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:2:0","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"2.1 追求简单，少即是多 Go 语言的语法简单这一说法，是我最近学习 Rust 体会最深的一点。相比于 Rust，Go 语言真实简单太多了。 首先 Go 语言不支持传统的面向对象，所以也就不用去理解面向对象里面的那一套，继承、方法重载一堆概念。 与继承相比，Go 语言更推崇组合的设计哲学。在设计上类型嵌入为类型提供垂直扩展能力，interface是水平组合的关键: 类型嵌入（type embedding）有些类似经典OO语言中的继承机制，但在原理上与其完全不同，这是一种Go设计者们精心设计的语法糖。被嵌入的类型和新类型之间没有任何关系，甚至相互完全不知道对方的存在。在通过新类型实例调用方法时，方法的匹配取决于方法名字，而不是类型 interface 只是方法集合，且与实现者之间的关系是隐式的。隐式的interface实现会不经意间满足依赖抽象、里氏替换、接口隔离等设计原则，通过interface将程序各个部分组合在一起的方法，实现水平组合 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:2:1","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"2.2 原生并发，轻量高效 goroutine 和 channel 直接拔高了 Go 在并发处理上的高度。由于goroutine的开销很小（相对线程），Go官方鼓励大家使用goroutine来充分利用多核资源。并发是有关结构的，它是一种将一个程序分解成多个小片段并且每个小片段都可以独立执行的程序设计方法；并发程序的小片段之间一般存在通信联系并且通过通信相互协作。并发与组合的哲学是一脉相承的，并发是一个更大的组合的概念，它在程序设计层面对程序进行拆解组合，再映射到程序执行层面：goroutine各自执行特定的工作，通过channel+select将goroutine组合连接起来。并发的存在鼓励程序员在程序设计时进行独立计算的分解，而对并发的原生支持让Go语言更适应现代计算环境。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:2:2","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"2.3 面向工程，“自带电池” 相比于其他语言，最起码相比于我比较熟悉的 Python，Go 语言的工具链真的是相当完善了。 官方工具链，涵盖了编译、编辑、依赖获取、调试、测试、文档、性能剖析等的方方面面。 构建和运行：go build/go run 依赖包查看与获取：go list/go get/go mod xx 编辑辅助格式化：go fmt/gofmt 文档查看：go doc/godoc 单元测试/基准测试/测试覆盖率：go test 代码静态分析：go vet 性能剖析与跟踪结果查看：go tool pprof/go tool trace 升级到新Go版本API的辅助工具：go tool fix 报告Go语言bug：go bug 值得重点提及的是gofmt统一了Go语言的编码风格(好处懂的很懂) 在提供丰富的工具链的同时，Go语言的语法、包依赖系统以及命名惯例的设计也让针对Go的工具更容易编写，并且Go在标准库中提供了官方的词法分析器、语法解析器和类型检查器相关包，开发者可以基于这些包快速构建并扩展Go工具链。 Go设计者将所有工程问题浓缩为一个词：scale。从Go1开始，Go的设计目标就是帮助开发者更容易、更高效地管理两类规模。 生产规模：用Go构建的软件系统的并发规模，比如这类系统并发关注点的数量、处理数据的量级、同时并发与之交互的服务的数量等。 开发规模：包括开发团队的代码库的大小，参与开发、相互协作的工程师的人数等。 为了有效管理规模，Go 语言在语法设计等各个层面，故意做了一些限制。比如: 如果源文件导入了它不使用的包，则程序将无法编译。 故意不支持默认函数参数。因为在规模工程中，很多开发者利用默认函数参数机制向函数添加过多的参数以弥补函数API的设计缺陷，这会导致函数拥有太多的参数，降低清晰度和可读性。 首字母大小写定义标识符可见性，这是Go的一个创新。它让开发人员通过名称即可知晓其可见性，等于变现的要求程序对外定义暴露的接口。 除了工具链，Go 语言还有丰富的标准库。Go团队还在golang.org/x路径下提供了暂未放入标准库的扩展库/补充库供广大Gopher使用，包括text、net、crypto等。这些库的质量也是非常高的，标准库中部分包也将golang.org/x下的text、net和crypto包作为依赖包放在标准库的vendor目录中。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:2:3","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"3. Go 语言典型目录结构 项目的目录结构，我个人觉得是存在一些最佳实践的，并且一个公司内部，项目结构最好保持一致，不然CI/CD 很难做。当然不同场景下，项目结构的设计是有一定差异的。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:3:0","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"3.1 以构建二进制可执行文件为目的的Go项目结构 cmd目录：存放项目要构建的可执行文件对应的main包的源文件。如果有多个可执行文件需要构建，则将每个可执行文件的main包单独放在一个子目录中，比如图中的app1、app2 pkg目录：存放项目自身要使用并且同样也是可执行文件对应main包要依赖的库文件。该目录下的包可以被外部项目引用，算是项目导出包的一个聚合。 Makefile：这里的Makefile是项目构建工具所用脚本的“代表”；对于构建脚本较多的项目，也可以建立build目录，并将构建脚本的规则属性文件、子构建脚本放入其中。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:3:1","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"3.2 以只构建库为目的的Go项目结构 这种结构去除了cmd和pkg两个子目录：由于仅构建库，没必要保留存放二进制文件main包源文件的cmd目录；由于Go库项目的初衷一般都是对外部（开源或组织内部公开）暴露API，因此也没有必要将其单独聚合到pkg目录下面了。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:3:2","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"3.3 internal 目录 无论是上面哪种类型的Go项目，对于不想暴露给外部引用，仅限项目内部使用的包，在项目结构上可以通过Go 1.4版本中引入的internal包机制来实现。 // 带internal的Go库项目结构 $tree -F ./chapter2/sources/GoLibProj GoLibProj ├── LICENSE ├── Makefile ├── README.md ├── go.mod ├── internal/ │ ├── ilib1/ │ └── ilib2/ ├── lib.go ├── lib1/ │ └── lib1.go └── lib2/ └── lib2.g 这样，根据Go internal机制的作用原理，internal目录下的ilib1、ilib2可以被以GoLibProj目录为根目录的其他目录下的代码（比如lib.go、lib1/lib1.go等）所导入和使用，但是却不可以为GoLibProj目录以外的代码所使用，从而实现选择性地暴露API包。当然internal也可以放在项目结构中的任一目录层级中，关键是项目结构设计人员明确哪些要暴露到外层代码，哪些仅用于同级目录或子目录中。对于以构建二进制可执行文件类型为目的的项目，我们同样可以将不想暴露给外面的包聚合到项目顶层路径下的internal下，与暴露给外部的包的聚合目录pkg遥相呼应。 关于 Go 语言项目结构的更多讨论，可以参考golang-standards 这个git项目 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:3:3","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["Go"],"content":"4. Go命名惯例 要想做好Go标识符的命名（包括对包的命名），至少要遵循两个原则：简单且一致；利用上下文辅助命名: 对于Go中的包（package），一般建议以小写形式的单个单词命名 保持简短命名变量含义上的一致性 对于接口类型优先以单个单词命名。对于拥有唯一方法（method）或通过多个拥有唯一方法的接口组合而成的接口，Go语言的惯例是用“方法名+er”命名。 ","date":"2022-12-25","objectID":"/posts/program/go/expert/go_export/expert_1/:4:0","tags":["go 进阶"],"title":"Go 语言进阶开篇","uri":"/posts/program/go/expert/go_export/expert_1/"},{"categories":["个人总结"],"content":"规整一下博客的内容","date":"2022-02-17","objectID":"/posts/about/","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["个人总结"],"content":"写博客也挺久了，是时候重构一下博客的内容了。 ","date":"2022-02-17","objectID":"/posts/about/:0:0","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["个人总结"],"content":"1. 新的博客 有段时间没更新自己的博客了，最开始写博客还是刚开始学编程的时候，跟着马哥学 Linux，把每天学习的内容都整理到博客上。后来博客成了自己的\"笔记本\"，几乎所有学到的东西都会整理在博客上。时间久了，内容就越来越多，越来越杂。2023 年准备从北京回老家了，想规划一下自己的未来。心里做了计划，准备继续在博客上写写笔记，却突然发现不知道应该把内容放在博客哪了。就跟代码一样，时间一长博客也变得杂乱无章。所以这段时间准备把博客好好规整一番，算是对知识再一次的总结和回顾。 ","date":"2022-02-17","objectID":"/posts/about/:1:0","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["个人总结"],"content":"2. 博客写那些内容 根据自己的知识结构和以后想学的东西，我把博客的内容做了下面的分类: Program: 编程语言，这个分类会记录所学的编程语言，以及与语言密切相关的周边知识包括: Python Golang C JavaScript Rust 数据结构与算法 设计模式 Linux: 操作系统，这个分类包含了所有与操作系统相关的底层知识，包括: 汇编语言，包括 x86 汇编以及 gcc asm 内联汇编 程序的编译、连接和加载 操作系统的实现 Linux 的基础使用 Linux 的源码解析 Linux 性能优化 profiling/epbf 网络的基本原理 容器和云的网络架构 Distribution: 分布式系统，这个部分包含了分布式系统相关的理论研究 Architecture: 架构，这部分包含了当前流行的开源组件和数据库的原理和使用，包括: k8s etcd mysql redis elasticsearch kafka flink …. Browser: 前端，这个部分包含的是前端的知识体系，包括: 浏览器的实现原理 html/css Vue React Hacker: 黑客，这部分会包含渗透相关的知识 Investment: 投资，这部分会记录学习量化投资相关的知识 Thinking: 记录自己的思考和感悟 tool: 记录平时用到的好用的工具 框架很大，内容很多，也不一定都会去学去写，先占个位置，什么时候想学了就往里面填一笔。学习应该成为一种乐趣。 ","date":"2022-02-17","objectID":"/posts/about/:2:0","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["个人总结"],"content":"3. 如何去学习一门语言 如何学习一门编译语言这是一个很大，也经常有大佬会谈的一个话题。我不是大佬，没法从类型系统，编译原理等各个层面去高度抽象的总结我们应该怎么学习一门语言。但是我想总结的是: 如果我们去学一门语言，我们到底要学些什么。 你可能经常也听身边的大佬说，我花了多少个小时学习了什么什么语言，这个语言怎么怎么样。如果说只是语法，花个几个小时的确就能很容易学会，但是要成为一个语言的开发者，仅仅了解一个语言的语法是远远不够的。我觉得从浅入深至少要学习下面这些内容: 语法: 学会了语法代表你已经踏入了这个语言的领域 惯例: 惯例包括了这个语言特有的最佳实践，最适合的设计模式等等，了解了这个语言惯例你才能写出这个语言纯正的代码，而不是把 go 写的像 java 实现: 了解一个语言底层实现，才能让你成为这个语言的专家 并发: 实现一个高性能的程序，离不开对并发的深入理解 库: 包括标准库和第三方库，掌握常用库的用法，编码才能更加高效 框架: 框架代表这个语言的技术生态和最佳实践 周边工具: 包括单元测试，这个语言提供的性能分析工具等等，对这些工具的使用能从侧面反映你对这个语言的熟练程度 所以，对于博客里面出现的编程语言，我都会按照上面的分块，由浅入深分步去学习。 ","date":"2022-02-17","objectID":"/posts/about/:3:0","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["个人总结"],"content":"4. 内容组织 上面经过一些简单的划分，其实是将知识划分了多个相对独立的模块，在这个博客里每个知识模块都对应着一个系列。每个系列我会选择一本书或多本书作为我们学习的核心内容，在核心内容之后，我会把我看到的好的与这个知识模块密切相关的文章整理更新在核心内容之后，以此来不断完善对这个知识的理解。 ","date":"2022-02-17","objectID":"/posts/about/:4:0","tags":["个人总结"],"title":"要写点什么","uri":"/posts/about/"},{"categories":["Go"],"content":"go 协程池","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"我们在 Go 第四部分 Go 并发系列的 sync.Pool 和 channel 提到了很多用于 Go 协程池的第三方库，今天我们就来详细介绍它们的使用和实现。 ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:0","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"1. worker 池 我们的第一个示例来自Marcio Castilho 在 使用 Go 每分钟处理百万请求 这篇文章中，就介绍了他们应对大并发请求的设计。这不是一个库，但是 worker pool 的实现很具有代表性: 他们将用户的请求放在一个 chan Job 中，这个 chan Job 就相当于一个待处理任务队列 除此之外，还有一个 chan chan Job 队列，用来存放可以处理任务的 worker 的缓存队列 每个 goroutine 都监听 chan chan Job 中的一个 chan Job 下面核心代码实现。 ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:1","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"1.1 核心对象 // 1. 定义Worker 池和消息队列的长度 var ( MaxWorker = os.Getenv(\"MAX_WORKERS\") MaxQueue = os.Getenv(\"MAX_QUEUE\") ) // 2. 定义任务队列 type Job struct { Payload Payload } var JobQueue chan Job // 3. 定义 Worker type Worker struct { WorkerPool chan chan Job JobChannel chan Job // 接收任务 quit chan bool // Worker 退出 } func NewWorker(workerPool chan chan Job) Worker { return Worker{ WorkerPool: workerPool, // 这个每个 worker 监听的任务队列 JobChannel: make(chan Job), quit: make(chan bool)} } // 4. 创建 Worker Pool type Dispatcher struct { // 这是 worker 池，也是任务传递的中介 WorkerPool chan chan Job } func NewDispatcher(maxWorkers int) *Dispatcher { pool := make(chan chan Job, maxWorkers) return \u0026Dispatcher{WorkerPool: pool} } ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:2","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"1.2 任务启动，创建 worker pool func (d *Dispatcher) Run() { // starting n number of workers for i := 0; i \u003c d.maxWorkers; i++ { worker := NewWorker(d.pool) worker.Start() } go d.dispatch() } // 4.1 将任务从 JobQueue 放入到 Worker Pool 中某一个 Workder 的 JobChannel 中，来调用 Worker func (d *Dispatcher) dispatch() { for { select { // JobQueue 就是一个待处理任务队列 case job := \u003c-JobQueue: // a job request has been received go func(job Job) { // try to obtain a worker job channel that is available. // this will block until a worker is idle jobChannel := \u003c-d.WorkerPool // dispatch the job to the worker job channel jobChannel \u003c- job }(job) } } } // 3.1 启动任务 func (w Worker) Start() { go func() { for { // 重要: 把当前 worker 注册到 worker 池中 w.WorkerPool \u003c- w.JobChannel select { case job := \u003c-w.JobChannel: // we have received a work request. if err := job.Payload.UploadToS3(); err != nil { log.Errorf(\"Error uploading to S3: %s\", err.Error()) } case \u003c-w.quit: // we have received a signal to stop return } } }() } // 3.2 停止任务 func (w Worker) Stop() { go func() { w.quit \u003c- true }() } ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:3","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"1.3 使用 worker pool // 5. 使用 Worker Pool func payloadHandler(w http.ResponseWriter, r *http.Request) { if r.Method != \"POST\" { w.WriteHeader(http.StatusMethodNotAllowed) return } // Read the body into a string for json decoding var content = \u0026PayloadCollection{} err := json.NewDecoder(io.LimitReader(r.Body, MaxLength)).Decode(\u0026content) if err != nil { w.Header().Set(\"Content-Type\", \"application/json; charset=UTF-8\") w.WriteHeader(http.StatusBadRequest) return } // Go through each payload and queue items individually to be posted to S3 for _, payload := range content.Payloads { // let's create a job with the payload work := Job{Payload: payload} // Push the work onto the queue. JobQueue \u003c- work } w.WriteHeader(http.StatusOK) } } ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:4","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"1.4 个人理解 这个 worker pool 第一看优点迷惑，有很多 channel，但是如果厘清里面的实现逻辑就感觉非常清晰，重点理解 Worker 这个 struct: 首先每个 worker 有各自监听的任务队列，而且一个 worker 就是一个 goroutine 然后他包含的 WorkerPool，就是 worker 挂载的 worker pool，worker 在启动时，需要把自己注册到 worker pool 中: w.WorkerPool \u003c- w.JobChannel Job 的流转过程是: 调用方把 Job 发送到全局的 JobQueue 中 dispatch 从 JobQueue 拿到一个 Job，然后从 worker pool 拿到一个 worker 的 chan Job，即一个 goroutine 把 job 发送到worker 的 chan Job 中，让 worker 开始执行 这个实现中我有点不理解的地方是，为什么 Worker 的方法传递的是 Worker 的值，而不是指针。因为 Worker 的成员都是 chan，chan 在内部实现上就是指向 hchan 的指针，所以不会有内部状态复制的问题。 ","date":"2021-06-23","objectID":"/posts/program/go/modules/33_work_pool/:0:5","tags":["go 库"],"title":"Go Work Pool","uri":"/posts/program/go/modules/33_work_pool/"},{"categories":["Go"],"content":"go 对象池化","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"我们在 Go 第四部分 Go 并发系列的 sync.Pool 提到了很多用于对象池化的第三方库，今天我们就来详细看看其中提到的对象池化库的使用和实现。 ","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/:0:0","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"1. buffer 池化 ","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/:1:0","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"2. TCP 连接池 ","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/:2:0","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"3. 数据库连接池 ","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/:3:0","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"4. Memcached Client 连接池 ","date":"2021-06-22","objectID":"/posts/program/go/modules/32_obj_pool/:4:0","tags":["go 库"],"title":"go 对象池化","uri":"/posts/program/go/modules/32_obj_pool/"},{"categories":["Go"],"content":"go 项目的配置管理","date":"2021-06-21","objectID":"/posts/program/go/modules/31_viper/","tags":["go 库"],"title":"配置管理神 Viper","uri":"/posts/program/go/modules/31_viper/"},{"categories":["Go"],"content":"1. Viper 简介 Viper 是适用于Go应用程序的完整配置解决方案。可以处理所有类型的配置需求和格式。作为配置管理器，Viper 按照如下的从高到低的优先级加载配置: 代码显示调用Set设置值 命令行参数（flag） 环境变量 配置文件 key/value存储 默认值 Viper支持JSON、TOML、YAML、HCL、envfile和Java properties格式的配置文件。Viper可以搜索多个路径，但是 Viper 不默认任何配置搜索路径，将默认决策留给应用程序。下面是一个如何使用Viper搜索和读取配置文件的示例。 # 1. 设置默认值 viper.SetDefault(\"LayoutDir\", \"layouts\") viper.SetDefault(\"Taxonomies\", map[string]string{\"tag\": \"tags\", \"category\": \"categories\"}) ","date":"2021-06-21","objectID":"/posts/program/go/modules/31_viper/:1:0","tags":["go 库"],"title":"配置管理神 Viper","uri":"/posts/program/go/modules/31_viper/"},{"categories":["Go"],"content":"go 网络库 net","date":"2021-06-06","objectID":"/posts/program/go/modules/15_net/","tags":["go 库"],"title":"go 网络库 net","uri":"/posts/program/go/modules/15_net/"},{"categories":["Go"],"content":"go 常用数据结构与算法库","date":"2021-06-05","objectID":"/posts/program/go/modules/14_algo/","tags":["go 库"],"title":"go 常用数据结构与算法库","uri":"/posts/program/go/modules/14_algo/"},{"categories":["Go"],"content":"go 执行操作系统命令","date":"2021-06-04","objectID":"/posts/program/go/modules/13_os/","tags":["go 库"],"title":"go 操作系统交互","uri":"/posts/program/go/modules/13_os/"},{"categories":["Go"],"content":"go 数据格式转换 json/yaml/ini","date":"2021-06-03","objectID":"/posts/program/go/modules/12_encoding/","tags":["go 库"],"title":"go 数据格式转换","uri":"/posts/program/go/modules/12_encoding/"},{"categories":["Go"],"content":"1. json ","date":"2021-06-03","objectID":"/posts/program/go/modules/12_encoding/:1:0","tags":["go 库"],"title":"go 数据格式转换","uri":"/posts/program/go/modules/12_encoding/"},{"categories":["Go"],"content":"2. yaml ","date":"2021-06-03","objectID":"/posts/program/go/modules/12_encoding/:2:0","tags":["go 库"],"title":"go 数据格式转换","uri":"/posts/program/go/modules/12_encoding/"},{"categories":["Go"],"content":"3. ini ","date":"2021-06-03","objectID":"/posts/program/go/modules/12_encoding/:3:0","tags":["go 库"],"title":"go 数据格式转换","uri":"/posts/program/go/modules/12_encoding/"},{"categories":["Go"],"content":"go 字符操作","date":"2021-06-02","objectID":"/posts/program/go/modules/11_strings/","tags":["go 库"],"title":"go 文本操作","uri":"/posts/program/go/modules/11_strings/"},{"categories":["Go"],"content":"1. 字符操作 strings 和 bytes 提供了 go 语言中的字符操作，因为还不不支持泛型，所以这两个包提供了几乎一样的函数和类型，区别仅仅在于一个操作 string，一个操作 []byte。 ","date":"2021-06-02","objectID":"/posts/program/go/modules/11_strings/:1:0","tags":["go 库"],"title":"go 文本操作","uri":"/posts/program/go/modules/11_strings/"},{"categories":["Go"],"content":"go 的文件 I/O","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"这个系列我们开始学习 Go 语言的第五个部分: 库。 接下来我们就从 Go 的文件 I/O 说起。 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:0:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"1. 文件 IO 概述 Go 的标准库我们就从文件 IO 开始。Go 标准库中为文件 IO 提供了如下这些包: os: 文件操作的方法都在 os 包中 io： 为了扩展\"文本操作\"的范围(类似 Linux 中一切接文件，可以把文本操作扩展到其他类型的资源上) io 包提供了I/O原语的基本接口 io 包基本任务是包装这些原语已有的实现（如os包里的原语），使之成为共享的公共接口。 bufio: os 包内的文件IO 是不带语言层的缓存的， bufio 提供了语言层带缓存 IO 通过带缓存 IO，使得我们可以以特定的方式读取类文件中的内容，比如按特定分隔符读取等等 string/bytes：为了以类文件方式操作 string 和 []bytes ，string 和 bytes 包为 string 和 bytes 实现了部分文件 io 的公共接口 io/ioutil: 提供了一些文件 IO 的便捷函数 接下来我们就一一来介绍这些包的使用。 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:1:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"2. os 文件操作 os包提供了操作系统函数的不依赖平台的接口。os包的接口规定为在所有操作系统中都是一致的，非公用的属性可以从操作系统特定的syscall包获取。os 包中与文件 IO 相关的部分如下: // 文件对象 type File struct { // 内含隐藏或非导出字段 } type File func Create(name string) (file *File, err error) func Open(name string) (file *File, err error) // 文件操作的核心函数 func OpenFile(name string, flag int, perm FileMode) (file *File, err error) func NewFile(fd uintptr, name string) *File func Pipe() (r *File, w *File, err error) func (f *File) Name() string func (f *File) Stat() (fi FileInfo, err error) func (f *File) Fd() uintptr func (f *File) Chdir() error // Chdir将当前工作目录修改为f，f必须是一个目录 func (f *File) Chmod(mode FileMode) error func (f *File) Chown(uid, gid int) error func (f *File) Readdir(n int) (fi []FileInfo, err error) func (f *File) Readdirnames(n int) (names []string, err error) func (f *File) Truncate(size int64) error func (f *File) Sync() (err error) // 重要: 文件 IO 公共接口包含的方法 func (f *File) Read(b []byte) (n int, err error) // off 表示相对于文件开始 off 位置起 func (f *File) ReadAt(b []byte, off int64) (n int, err error) func (f *File) Write(b []byte) (n int, err error) func (f *File) WriteString(s string) (ret int, err error) func (f *File) WriteAt(b []byte, off int64) (n int, err error) func (f *File) Seek(offset int64, whence int) (ret int64, err error) func (f *File) Close() error // 文件状态对象 type FileInfo interface { Name() string // 文件的名字（不含扩展名） Size() int64 // 普通文件返回值表示其大小；其他文件的返回值含义各系统不同 Mode() FileMode // 文件的模式位 ModTime() time.Time // 文件的修改时间 IsDir() bool // 等价于Mode().IsDir() Sys() interface{} // 底层数据来源（可以返回nil） } type FileInfo func Stat(name string) (fi FileInfo, err error) func Lstat(name string) (fi FileInfo, err error) // FileMode代表文件的模式和权限位 type FileMode uint32 type FileMode func (m FileMode) IsDir() bool func (m FileMode) IsRegular() bool func (m FileMode) Perm() FileMode func (m FileMode) String() string os 包为文件 IO 提供了这样几个核心对象: File: 代表一个打开的文件对象 File 中提供了几个文件读写方法就是 io 包抽象的公共接口 FileInfo: 描述一个文件对象 FileMode: 代表文件的模式和权限位 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:2:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"3. io 抽象的公共接口 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:3:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"3.1 io 中的接口 io 包将文件 IO 中所有的文件操作及其组合都抽象为独立的接口，其接口大致上分成了三类: os 包文件操作及其组合 带读取撤回的接口 文件互操作 // 1. 基础 io 操作及其组合 type Reader type Writer type Closer type Seeker type ReaderAt type WriterAt type ReadCloser type ReadSeeker type WriteCloser type WriteSeeker type ReadWriter type ReadWriteCloser type ReadWriteSeeker // 2. 可撤回读 type ByteWriter type ByteReader type ByteScanner type RuneReader type RuneScanner type ByteWriter interface { WriteByte(c byte) error } type ByteReader interface { ReadByte() (c byte, err error) } type ByteScanner interface { ByteReader //读回撤 UnreadByte() error } // 3. 文件互操作 type ReaderFrom type WriterTo // ReadFrom方法从r读取数据直到EOF或者遇到错误。返回值n是读取的字节数，执行时遇到的错误（EOF除外） type ReaderFrom interface { ReadFrom(r Reader) (n int64, err error) } // WriteTo方法将数据写入w直到没有数据可以写入或者遇到错误。返回写入的字节数和执行时遇到的任何错误 type WriterTo interface { WriteTo(w Writer) (n int64, err error) } ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:3:1","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"3.2 io 中的数据结构 除了接口外，io 包还提供了一些具有特殊用途的数据结构: // 1. 只能限制读取 n 个字节的 Reader type LimitedReader func LimitReader(r Reader, n int64) Reader func (l *LimitedReader) Read(p []byte) (n int, err error) // 2. 从 r 中的偏移量off处为起始，读取n个字节后以EOF停止的SectionReader type SectionReader func NewSectionReader(r ReaderAt, off int64, n int64) *SectionReader func (s *SectionReader) Size() int64 func (s *SectionReader) Read(p []byte) (n int, err error) func (s *SectionReader) ReadAt(p []byte, off int64) (n int, err error) func (s *SectionReader) Seek(offset int64, whence int) (int64, error) // 3. 管道符 type PipeReader func Pipe() (*PipeReader, *PipeWriter) func (r *PipeReader) Read(data []byte) (n int, err error) func (r *PipeReader) Close() error func (r *PipeReader) CloseWithError(err error) error type PipeWriter func (w *PipeWriter) Write(data []byte) (n int, err error) func (w *PipeWriter) Close() error func (w *PipeWriter) CloseWithError(err error) error ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:3:2","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"3.3 io 中的功能函数 除了接口和数据结构，io 包还包含了如下具有特殊用途的功能函数: // 返回一个从 r 读，并且往 w 写的 Reader func TeeReader(r Reader, w Writer) Reader // 将多个 Reader 合并为一个 Reader func MultiReader(readers ...Reader) Reader // 将写同时写入多个 writer func MultiWriter(writers ...Writer) Writer // 文件拷贝 func Copy(dst Writer, src Reader) (written int64, err error) // 文件拷贝，限制长度为 n func CopyN(dst Writer, src Reader, n int64) (written int64, err error) // 至少读取min字节数据填充进buf func ReadAtLeast(r Reader, buf []byte, min int) (n int, err error) // 精确地读取len(buf)字节数据填充进buf func ReadFull(r Reader, buf []byte) (n int, err error) // 将字符串s的内容写入w中 func WriteString(w Writer, s string) (n int, err error) ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:3:3","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"4. io/ioutil 说完了 io 包，我们先来看看 io/ioutil，这个包也是提供了一些 io 的功能函数。 // 写黑洞，/dev/null 所有Write调用都会无实际操作的成功返回 var Discard io.Writer = devNull(0) // 用一个无操作的Close方法包装r返回一个ReadCloser接口 func NopCloser(r io.Reader) io.ReadCloser // r 读取数据直到EOF或遇到error，返回读取的数据和遇到的错误, EOF 错误不会被返回 func ReadAll(r io.Reader) ([]byte, error) // 同 ReadAll，接收的是一个文件路径 func ReadFile(filename string) ([]byte, error) // 向filename指定的文件中写入数据，文件不存在创建，文件存在清空 func WriteFile(filename string, data []byte, perm os.FileMode) error // 返回dirname指定的目录的目录信息的有序列表，与 os.File Readdir 方法作用一致 func ReadDir(dirname string) ([]os.FileInfo, error) // 在dir目录里创建一个新的、使用prfix作为前缀的临时文件夹，并返回文件夹的路径 // 如果dir是空字符串，TempDir使用默认用于临时文件的目录（即 os.TempDir函数返回的临时目录） func TempDir(dir, prefix string) (name string, err error) // 在dir目录下创建一个新的、使用prefix为前缀的临时文件，以读写模式打开该文件并返回os.File指针 func TempFile(dir, prefix string) (f *os.File, err error) ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:4:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"5. strings/bytes 为了能像读写文件一样去操作 strings 和 []byte，strings/bytes 提供了对应类型的 io 接口实现。 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:5:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"5.1 strings strings.Reader 将一个字符串转换成，可读的类文本对象。 type Reader func NewReader(s string) *Reader func (r *Reader) Len() int func (r *Reader) Read(b []byte) (n int, err error) func (r *Reader) ReadByte() (b byte, err error) func (r *Reader) UnreadByte() error func (r *Reader) ReadRune() (ch rune, size int, err error) func (r *Reader) UnreadRune() error func (r *Reader) Seek(offset int64, whence int) (int64, error) func (r *Reader) ReadAt(b []byte, off int64) (n int, err error) func (r *Reader) WriteTo(w io.Writer) (n int64, err error) type Reader struct { // 内含隐藏或非导出字段 } type Replacer // 多组old、new字符串对， func NewReplacer(oldnew ...string) *Replacer // 在传入的 s 中执行替换，用初始化时的 new 替换 old func (r *Replacer) Replace(s string) string // 对 s 进行替换并写入 w func (r *Replacer) WriteString(w io.Writer, s string) (n int, err error) type Replacer struct { // 内含隐藏或非导出字段 } ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:5:1","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"5.2 bytes bytest.Reader 将一个 []byte 转换成可读的类文本对象。而比较特殊的是 Buffer 对象，这是一个可读写的字节缓冲。 type Reader func NewReader(b []byte) *Reader func (r *Reader) Len() int func (r *Reader) Read(b []byte) (n int, err error) func (r *Reader) ReadByte() (b byte, err error) func (r *Reader) UnreadByte() error func (r *Reader) ReadRune() (ch rune, size int, err error) func (r *Reader) UnreadRune() error func (r *Reader) Seek(offset int64, whence int) (int64, error) func (r *Reader) ReadAt(b []byte, off int64) (n int, err error) func (r *Reader) WriteTo(w io.Writer) (n int64, err error) type Reader struct { // 内含隐藏或非导出字段 } // 可读写的字节缓冲 type Buffer struct { // 内含隐藏或非导出字段 } type Buffer func NewBuffer(buf []byte) *Buffer func NewBufferString(s string) *Buffer // Reset重设缓冲，因此会丢弃全部内容，等价于b.Truncate(0) func (b *Buffer) Reset() func (b *Buffer) Len() int // 返回未读取部分字节数据的切片 func (b *Buffer) Bytes() []byte func (b *Buffer) String() string func (b *Buffer) Truncate(n int) // 必要时会增加缓冲的容量，以保证n字节的剩余空间 func (b *Buffer) Grow(n int) // 返回未读取部分前n字节数据的切片，并且移动读取位置，就像调用了Read方法一样 // 切片只在下一次调用b的读/写方法前才合法 func (b *Buffer) Next(n int) []byte func (b *Buffer) Read(p []byte) (n int, err error) func (b *Buffer) ReadByte() (c byte, err error) func (b *Buffer) UnreadByte() error func (b *Buffer) ReadRune() (r rune, size int, err error) func (b *Buffer) UnreadRune() error // ReadBytes读取直到第一次遇到delim字节，返回一个包含已读取的数据和delim字节的切片 func (b *Buffer) ReadBytes(delim byte) (line []byte, err error) func (b *Buffer) ReadString(delim byte) (line string, err error) // Write将p的内容写入缓冲中，如必要会增加缓冲容量。返回值n为len(p func (b *Buffer) Write(p []byte) (n int, err error) func (b *Buffer) WriteString(s string) (n int, err error) func (b *Buffer) WriteByte(c byte) error func (b *Buffer) WriteRune(r rune) (n int, err error) func (b *Buffer) ReadFrom(r io.Reader) (n int64, err error) func (b *Buffer) WriteTo(w io.Writer) (n int64, err error) Buffer 的初始化有三种方式: NewBuffer(buf []byte): 使用buf作为初始内容创建并初始化一个Buffer 用于创建一个用于读取已存在数据的buffer 也用于指定用于写入的内部缓冲的大小，此时，buf应为一个具有指定容量但长度为0的切片 func NewBufferString(s string) *Buffer: 使用s作为初始内容创建一个用于读取已存在数据的buffer new(Buffer): 大多数情况下使用，初始化一个Buffer ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:5:2","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"6. bufio bufio包实现了有缓冲的I/O。它包装一个io.Reader或io.Writer接口对象，创建另一个也实现了该接口。因为有了缓存 bufio 可以实现下面这些非常使用的功能: 读取文件直至特定的分隔符 文件扫描，实现按行或者按照特定分隔符流式读取文件 ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:6:0","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"6.1 文件分割 为了实现读取文件直至xxx功能，bufio 定义了一个特殊的函数类型: type SplitFunc func(data []byte, atEOF bool) (advance int, token []byte, err error) SplitFunc类型代表用于对输出作词法分析的分割函数。bufio 中他有如下实现: // 将每个字节作为一个token返回 func ScanBytes(data []byte, atEOF bool) (advance int, token []byte, err error) // 将每个utf-8编码的unicode码值作为一个token返回 func ScanRunes(data []byte, atEOF bool) (advance int, token []byte, err error) // 将单词(空白符分割)作为一个 token 返回 func ScanWords(data []byte, atEOF bool) (advance int, token []byte, err error) // 将每一行文本去掉末尾的换行标记作为一个token返回 func ScanLines(data []byte, atEOF bool) (advance int, token []byte, err error) ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:6:1","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"6.2 文件扫描 Scanner 使用 SplitFunc 定义的词法分割函数，实现文件扫描: type Scanner struct { // 内含隐藏或非导出字段 } type Scanner // 返回一个从r读取数据的Scanner，默认的分割函数是ScanLines func NewScanner(r io.Reader) *Scanner // 设置该Scanner的分割函数 func (s *Scanner) Split(split SplitFunc) // Scan 方法获取当前位置的token（该token可以通过Bytes或Text方法获得） // 并让Scanner的扫描位置移动到下一个token // 当扫描因为抵达输入流结尾或者遇到错误而停止时，本方法会返回false // 在Scan方法返回false后，Err方法将返回扫描时遇到的任何错误；除非是io.EOF，此时Err会返回nil func (s *Scanner) Scan() bool // 返回最近一次Scan调用生成的token func (s *Scanner) Bytes() []byte func (s *Scanner) Text() string // 反回 Scanner 遇到的第一个非 EOF 的错误 func (s *Scanner) Err() error scanner := bufio.NewScanner(os.Stdin) for scanner.Scan() { fmt.Println(scanner.Text()) // Println will add back the final '\\n' } if err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, \"reading standard input:\", err) } ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:6:2","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"6.3 带缓存 IO bufio 剩下的部分就是实现了一个带缓存的 io Reader type Reader struct { // 内含隐藏或非导出字段 } type Reader // 创建一个具有默认大小缓冲、从r读取的*Reader func NewReader(rd io.Reader) *Reader // 创建一个具有最少有size尺寸的缓冲、从r读取的*Reader // 如果参数 r 已经是一个具有足够大缓冲的* Reader类型值，会返回r func NewReaderSize(rd io.Reader, size int) *Reader // 丢弃缓冲中的数据，清除任何错误 func (b *Reader) Reset(r io.Reader) // 返回缓冲中现有的可读取的字节数 func (b *Reader) Buffered() int // Peek返回输入流的下n个字节，而不会移动读取位置 // 返回的[]byte只在下一次调用读取操作前合法 // 如果Peek返回的切片长度比n小，它也会返会一个错误说明原因 // 如果n比缓冲尺寸还大，返回的错误将是ErrBufferFull。 func (b *Reader) Peek(n int) ([]byte, error) // Read读取数据写入p // 本方法一次调用最多会调用下层Reader接口一次Read方法，因此返回值n可能小于len(p) // 读取到达结尾时，返回值n将为0而err将为io.EOF func (b *Reader) Read(p []byte) (n int, err error) func (b *Reader) ReadByte() (c byte, err error) func (b *Reader) UnreadByte() error func (b *Reader) ReadRune() (r rune, size int, err error) func (b *Reader) UnreadRune() error // ReadLine 和 ReadSlice 是比较底层的函数，不建议使用 // 因为存在写满，或者可能被重写的问题 func (b *Reader) ReadLine() (line []byte, isPrefix bool, err error) func (b *Reader) ReadSlice(delim byte) (line []byte, err error) // 读取直到第一次遇到delim字节，返回一个包含已读取的数据和delim字节的切片 func (b *Reader) ReadBytes(delim byte) (line []byte, err error) func (b *Reader) ReadString(delim byte) (line string, err error) func (b *Reader) WriteTo(w io.Writer) (n int64, err error) Writer type Writer struct { // 内含隐藏或非导出字段 } type Writer // 创建一个具有默认大小缓冲、写入w的*Writer func NewWriter(w io.Writer) *Writer // 创建一个具有最少有size尺寸的缓冲、写入w的*Writer // 如果参数w已经是一个具有足够大缓冲的*Writer类型值，会返回w func NewWriterSize(w io.Writer, size int) *Writer // Reset丢弃缓冲中的数据，清除任何错误，将b重设为将其输出写入w func (b *Writer) Reset(w io.Writer) // 返回缓冲中已使用的字节数 func (b *Writer) Buffered() int // 返回缓冲中还有多少字节未使用 func (b *Writer) Available() int // 将p的内容写入缓冲。返回写入的字节数。如果返回值nn \u003c len(p)，还会返回一个错误说明原因 func (b *Writer) Write(p []byte) (nn int, err error) func (b *Writer) WriteString(s string) (int, error) func (b *Writer) WriteByte(c byte) error func (b *Writer) WriteRune(r rune) (size int, err error) // 将缓冲中的数据写入下层的io.Writer接口 func (b *Writer) Flush() error func (b *Writer) ReadFrom(r io.Reader) (n int64, err error) ReadWriter ReadWriter类型保管了指向Reader和Writer类型的指针，因此实现了io.ReadWriter接口。Reader 和 Writer 中的缓存是各自内部创建的，彼此之间不存在共享，ReadWriter 只是做了一个读写分派。 type ReadWriter struct { *Reader *Writer } // 申请创建一个新的、将读写操作分派给r和w 的ReadWriter func NewReadWriter(r *Reader, w *Writer) *ReadWriter ","date":"2021-06-01","objectID":"/posts/program/go/modules/10_io/:6:3","tags":["go 库"],"title":"go 的文件 IO","uri":"/posts/program/go/modules/10_io/"},{"categories":["Go"],"content":"go 运行时","date":"2021-03-02","objectID":"/posts/program/go/expert/go_deep/11_go_scheduler/","tags":["go 底层"],"title":"go 调度器","uri":"/posts/program/go/expert/go_deep/11_go_scheduler/"},{"categories":["Go"],"content":"go 运行时","date":"2021-03-01","objectID":"/posts/program/go/expert/go_deep/02_go_memory/","tags":["go 底层"],"title":"go 内存管理","uri":"/posts/program/go/expert/go_deep/02_go_memory/"},{"categories":["Go"],"content":"go 运行时","date":"2021-02-28","objectID":"/posts/program/go/expert/go_deep/01_go_start/","tags":["go 底层"],"title":"go 启动过程","uri":"/posts/program/go/expert/go_deep/01_go_start/"},{"categories":["architecture"],"content":"kubernetes 学习资源","date":"2021-01-31","objectID":"/posts/architecture/k8s/k8s_resources/","tags":["学习资源"],"title":"k8s 学习资源","uri":"/posts/architecture/k8s/k8s_resources/"},{"categories":["architecture"],"content":"1. 容器实现 耗子叔容器实现的博客 ","date":"2021-01-31","objectID":"/posts/architecture/k8s/k8s_resources/:1:0","tags":["学习资源"],"title":"k8s 学习资源","uri":"/posts/architecture/k8s/k8s_resources/"},{"categories":["architecture"],"content":"2. k8s 的设计和使用 极客时间张磊老师的专栏-深入剖析 Kubernetes Kubernetes in Action中文版 ","date":"2021-01-31","objectID":"/posts/architecture/k8s/k8s_resources/:2:0","tags":["学习资源"],"title":"k8s 学习资源","uri":"/posts/architecture/k8s/k8s_resources/"},{"categories":["architecture"],"content":"k8s 技能图谱 ","date":"2021-01-31","objectID":"/posts/architecture/k8s/k8s_resources/:3:0","tags":["学习资源"],"title":"k8s 学习资源","uri":"/posts/architecture/k8s/k8s_resources/"},{"categories":["Go"],"content":"go 里面的一些 hacker 编程","date":"2021-01-11","objectID":"/posts/program/go/grammar/go_11/","tags":["go 语法"],"title":"go hacker 编程","uri":"/posts/program/go/grammar/go_11/"},{"categories":["Go"],"content":"每个语言都有一些 hacker 编程，这些 hacker 编程在某些时候能起到奇效，但是不能被乱用。 ","date":"2021-01-11","objectID":"/posts/program/go/grammar/go_11/:0:0","tags":["go 语法"],"title":"go hacker 编程","uri":"/posts/program/go/grammar/go_11/"},{"categories":["Go"],"content":"1. 获取 goroutine id 获取 goroutine id，方式有两种，分别是 简单方式：通过 runtime.Stack 方法获取栈帧信息，栈帧信息里包含 goroutine id hacker 方式: 原理: 我们获取运行时的 g 指针，反解出对应的 g 的结构。每个运行的 goroutine 结构的 g 指针保存在当前 goroutine 的一个叫做 TLS 对象中 第一步：我们先获取到 TLS 对象 第二步：再从 TLS 中获取 goroutine 结构的 g 指针 第三步：再从 g 指针中取出 goroutine id。 需要注意的是，不同 Go 版本的 goroutine 的结构可能不同，所以需要根据 Go 的不同版本进行调整。没必要重复造轮子，直接使用第三方库就可以: petermattis/goid ","date":"2021-01-11","objectID":"/posts/program/go/grammar/go_11/:1:0","tags":["go 语法"],"title":"go hacker 编程","uri":"/posts/program/go/grammar/go_11/"},{"categories":["Go"],"content":"1.1 普通方式 runtime.Stack 方法可以获取当前的 goroutine 信息，第二个参数为 true 会输出所有的 goroutine 信息，信息的格式如下： goroutine 1 [running]: main.main() ....../main.go:19 +0xb1 第一行格式为 goroutine xxx，其中 xxx 就是 goroutine id，你只要解析出这个 id 即可。解析的方法可以采用下面的代码： func GoID() int { var buf [64]byte n := runtime.Stack(buf[:], false) // 得到id字符串 idField := strings.Fields(strings.TrimPrefix(string(buf[:n]), \"goroutine \"))[0] id, err := strconv.Atoi(idField) if err != nil { panic(fmt.Sprintf(\"cannot get goroutine id: %v\", err)) } return id } ","date":"2021-01-11","objectID":"/posts/program/go/grammar/go_11/:1:1","tags":["go 语法"],"title":"go hacker 编程","uri":"/posts/program/go/grammar/go_11/"},{"categories":["Go"],"content":"1.2 hacker 方式 import ( \"github.com/petermattis/goid\" // 使用第三方包通过 hacker 方式获取 goroutine id ) gid := goid.Get() ","date":"2021-01-11","objectID":"/posts/program/go/grammar/go_11/:1:2","tags":["go 语法"],"title":"go hacker 编程","uri":"/posts/program/go/grammar/go_11/"},{"categories":["Go"],"content":"go 程序包组织结构和程序管理工具箱","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go 程序包组织结构和程序管理工具箱 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:0:0","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"1. 包简介 包和模块的概念几乎存在于所有的编程语言之中，它的存在是为了简化大型程序的设计和维护工作。通过将一组相关的特性放进一个独立的单元以便于理解和更新，这种特性提供诸多益处: 每个包可以被其它的不同项目共享和重用 包提供了一个独立的命名空间，减少了与其他部分的命名冲突 通过控制包内名字的可见性和是否导出来实现封装 Go 通过使用名字的开头字母的大小写决定了名字在包外的可见性，小写字符开头包成员不会导出，在包外不可见。通过这种方式可以严格的隐藏包内实现的 API，通过强制用户使用特定函数来访问和更新内部变量，可以保证内部变量的一致性和并发时的互斥约束。 当我们修改了一个源文件，我们必须重新编译该源文件对应的包和所有依赖该包的其他包。即使是从头构建，Go语言编译器的编译速度也明显快于其它编译语言。Go语言的闪电般的编译速度主要得益于三个语言特性: 第一点，所有导入的包必须在每个文件的开头显式声明，这样的话编译器就没有必要读取和分析整个源文件来判断包的依赖关系 第二点，禁止包的环状依赖，因为没有循环依赖，包的依赖关系形成一个有向无环图，每个包可以被独立编译，而且很可能是被并发编译 第三点，编译后包的目标文件不仅仅记录包本身的导出信息，目标文件同时还记录了包的依赖关系。因此，在编译一个包的时候，编译器只需要读取每个直接导入包的目标文件，而不需要遍历所有依赖的的文件。 本节我们就来学习与 Go 语言包相关的内容。 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:1:0","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"2. Go 程序包 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:0","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"2.1 包声明 Go 语言的源码也是以代码包为基本组织单位的。在文件系统中，这些代码包其实是与目录一一对应的。由于目录可以有子目录，所以代码包也可以有子包。一个代码包中可以包含任意个以.go 为扩展名的源码文件，这些源码文件都需要被声明属于同一个代码包。 在每个Go语言源文件的开头都必须有包声明语句。包声明语句的主要目的是确定当前包被其它包导入时默认的标识符（也称为包名）。代码包的名称一般会与源码文件所在的目录同名。如果不同名，那么在构建、安装的过程中会以代码包名称为准。 通常来说，默认的包名就是包导入路径名的最后一段，因此即使两个包的导入路径不同，它们依然可能有一个相同的包名。例如，math/rand包和crypto/rand包的包名都是rand。这也有三种例外情况。 第一个例外，包对应一个可执行程序，也就是main包，这时候main包本身的导入路径是无关紧要的。名字为main的包是给go build 构建命令一个信息，这个包编译完之后必须调用连接器生成一个可执行程序。 第二个例外，包所在的目录中可能有一些文件名是以 _test.go为后缀的Go源文件（译注：前面必须有其它的字符，因为以 _前缀的源文件是被忽略的），并且这些源文件声明的包名也是以_test为后缀名的。这种目录可以包含两种包：一种普通包，加一种则是测试的外部扩展包。所有以_test为后缀包名的测试外部扩展包都由go test命令独立编译，普通包和测试的外部扩展包是相互独立的。测试的外部扩展包一般用来避免测试代码中的循环导入依赖，具体细节我们将在下一章讲解。 第三个例外，一些依赖版本号的管理工具会在导入路径后追加版本号信息，例如\"gopkg.in/yaml.v2\"。这种情况下包的名字并不包含版本号后缀，而是yaml ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:1","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"2.2 包的导入 每个包是由一个全局唯一的字符串所标识的导入路径定位。在实际使用程序实体之前，我们必须先导入其所在的代码包。在工作区中，一个代码包的导入路径实际上就是从 src 子目录，到该包的实际存储位置的相对路径。而导入时包可以被重命名，被隐藏。下面是包导入时常用的语法: package package_name import fmt import ( \"crypto/rand\" mrand \"math/rand\" // 包导入重命名，避免冲突 import _ \"image/png\" // 匿名导入 ) 需要注意的事: 包的导入必须在包声明语句之后，其它非导入声明语句之前 每个导入声明语句都明确指定了当前包和被导入包之间的依赖关系。如果遇到包循环导入的情况，Go语言的构建工具将报告错误。 Go语言的规范并没有指明包的导入路径字符串的具体含义，导入路径的具体含义是由构建工具来解释的，当使用Go语言自带的go工具箱时，一个导入路径代表一个包在文件系统的路径 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:2","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"2.3 包的初始化 每个包在解决依赖的前提下，包会以导入声明的顺序初始化，包的初始化首先是解决包级变量的依赖顺序，然后按照包级变量声明出现的顺序依次初始化： var a = b + c // a 第三个初始化, 为 3 var b = f() // b 第二个初始化, 为 2, 通过调用 f (依赖c) var c = 1 // c 第一个初始化, 为 1 func f() int { return c + 1 } 如果包中含有多个.go源文件，它们将按照发给编译器的顺序进行初始化，Go语言的构建工具首先会将.go文件根据文件名排序，然后依次调用编译器编译。 每个包只会被初始化一次。因此，如果一个p包导入了q包，那么在p包初始化的时候可以认为q包必然已经初始化过了。初始化工作是自下而上进行的，main包最后被初始化。以这种方式，可以确保在main函数执行之前，所有依赖的包都已经完成初始化工作了。 对于在包级别声明的变量，如果有初始化表达式则用表达式初始化，还有一些没有初始化表达式的，例如某些表格数据初始化并不是一个简单的赋值过程。在这种情况下，我们可以用一个特殊的init初始化函数来简化初始化工作。每个文件都可以包含多个init初始化函数 func init() { /* ... */ } 这样的init初始化函数除了不能被调用或引用外，其他行为和普通函数类似。在每个文件中的init初始化函数，在程序开始执行时按照它们声明的顺序被自动调用。 匿名导入 如果只是导入一个包而并不使用导入的包将会导致一个编译错误。但是有时候我们只是想利用导入包而产生的副作用：计算包级变量的初始化表达式和执行导入包的init初始化函数。我们可以用下划线 _来重命名导入的包。像往常一样，下划线 _为空白标识符，并不能被访问。 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:3","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"包文档 Go语言中包文档注释一般是完整的句子，第一行是包的摘要说明，注释后仅跟着包声明语句。包注释可以出现在任何一个源文件中。如果包的注释内容比较长，一般会放到一个独立的源文件中；fmt包注释就有300行之多。这个专门用于保存包文档的源文件通常叫doc.go。 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:4","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"内部包 有时候，一个中间的状态可能也是有用的，对于一小部分信任的包是可见的，但并不是对所有调用者都可见。例如，当我们计划将一个大的包拆分为很多小的更容易维护的子包，但是我们并不想将内部的子包结构也完全暴露出去。同时，我们可能还希望在内部子包之间共享一些通用的处理包，或者我们只是想实验一个新包的还并不稳定的接口，暂时只暴露给一些受限制的用户使用 为了满足这些需求，Go语言的构建工具对包含internal名字的路径段的包导入路径做了特殊处理。这种包叫internal包，一个internal包只能被和internal目录有同一个父目录的包所导入。例如，net/http/internal/chunked内部包只能被net/http/httputil或net/http包导入，但是不能被net/url包导入。不过net/url包却可以导入net/http/httputil包。 net/http net/http/internal/chunked net/http/httputil net/url ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:5","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go 命令使用 go get 使用命令 go get可以下载一个单一的包或者用 …下载整个子目录里面的每个包。Go语言工具箱的go命令同时计算并下载所依赖的每个包，一旦 go get命令下载了包，然后就是安装包或包对应的可执行的程序 go get命令支持当前流行的托管网站GitHub、Bitbucket和Launchpad，可以直接向它们的版本控制系统请求代码。对于其它的网站，你可能需要指定版本控制系统的具体路径和协议，例如 Git或Mercurial。 go get github.com/golang/lint/golint cd $GOPATH/src/golang.org/x/net git remote ‐v origin https://go.googlesource.com/net (fetch) origin https://go.googlesource.com/net (push) 需要注意的是导入路径含有的网站域名和本地Git仓库对应远程服务地址并不相同，真实的Git地址是go.googlesource.com。这其实是Go语言工具的一个特性，可以让包用一个自定义的导入路径，但是真实的代码却是由更通用的服务提供，例如googlesource.com或github.com。因为页面 https://golang.org/x/net/html 包含了如下的元数据，它告诉Go语言的工具当前包真实的Git仓库托管地址： \u003cmeta name=\"go‐import\" content=\"golang.org/x/net git https://go.googlesource.com/net\"\u003e 如果指定 ‐u命令行标志参数， go get命令将确保所有的包和依赖的包的版本都是最新的，然后重新编译和安装它们。如果不包含该标志参数的话，而且如果包已经在本地存在，那么代码那么将不会被自动更新。 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:6","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go build go build命令编译命令行参数指定的每个包。如果包是一个库，则忽略输出结果；这可以用于检测包的可以正确编译的。如果包的名字是main， go build将调用连接器在当前目录创建一个可执行程序；以导入路径的最后一段作为可执行程序的名字 默认情况下， go build命令构建指定的包和它依赖的包，然后丢弃除了最后的可执行文件之外所有的中间编译结果。 go install命令和 go build命令很相似，但是它会保存每个包的编译成果，而不是将它们都丢弃。被编译的包会被保存到$GOPATH/pkg目录下，目录路径和 src目录路径对应，可执行程序被保存到$GOPATH/bin目录。 goinstall命令和 go build命令都不会重新编译没有发生变化的包，这可以使后续构建更快捷。为了方便编译依赖的包， go build ‐i命令将安装每个目标所依赖的包。 因为编译对应不同的操作系统平台和CPU架构， go install命令会将编译结果安装到GOOS和GOARCH对应的目录。例如，在Mac系统，golang.org/x/net/html包将被安装到$GOPATH/pkg/darwin_amd64目录下的golang.org/x/net/html.a文件。 针对不同操作系统或CPU的交叉构建也是很简单的。只需要设置好目标对应的GOOS和GOARCH，然后运行构建命令即可。下面交叉编译的程序将输出它在编译时操作系统和CPU类型：有些包可能需要针对不同平台和处理器类型使用不同版本的代码文件，以便于处理底层的可移植性问题或提供为一些特定代码提供优化。如果一个文件名包含了一个操作系统或处理器类型名字，例如net_linux.go或asm_amd64.s，Go语言的构建工具将只在对应的平台编译这些文件。还有一个特别的构建注释注释可以提供更多的构建过程控制。例如，文件中可能包含下面的注释： // +build linux darwin 在包声明和包注释的前面，该构建注释参数告诉 go build只在编译程序对应的目标操作系统是Linux或Mac OS X时才编译这个文件。下面的构建注释则表示不编译这个文件 // +build ignore 更多细节，可以参考go/build包的构建约束部分的文档 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:7","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go doc go doc命令，该命令打印包的声明和每个成员的文档注释，该命令并不需要输入完整的包导入路径或正确的大小写 go doc time go doc time.Since go doc time.Duration.Seconds go doc json.decode godoc，它提供可以相互交叉引用的HTML页面，但是包含和 go doc命令相同以及更多的信息。godoc的在线服务 https://godoc.org ，包含了成千上万的开源包的检索工具。你也可以在自己的工作区目录运行godoc服务。运行下面的命令，然后在浏览器查看 http://localhost:8000/pkg 页面： $ godoc ‐http :8000 其中 ‐analysis=type和 ‐analysis=pointer命令行标志参数用于打开文档和代码中关于静态分析的结果 ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:8","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go list go list命令可以查询可用包的信息。其最简单的形式，可以测试包是否在工作区并打印它的导入路径，还可以用 “…“表示匹配任意的包的导入路径。我们可以用它来列表工作区中的所有包： $ go list github.com/go‐sql‐driver/mysql github.com/go‐sql‐driver/mysql $ go list gopl.io/ch3/... $ go list ...xml... go list命令还可以获取每个包完整的元信息，而不仅仅只是导入路径，这些元信息可以以不同格式提供给用户。其中 ‐json命令行参数表示用JSON格式打印每个包的元信息。命令行参数 ‐f则允许用户使用text/template包（§4.6）的模板语言定义输出文本的格式。 go list ‐json hash go list ‐f '{{join .Deps \" \"}}' strconv go list ‐f '{{.ImportPath}} ‐\u003e {{join .Imports \" \"}}' compress/... ","date":"2021-01-10","objectID":"/posts/program/go/grammar/go_10/:2:9","tags":["go 语法"],"title":"go 包和管理工具","uri":"/posts/program/go/grammar/go_10/"},{"categories":["Go"],"content":"go 语言的自省","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"go 反射机制 ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:0:0","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"1. 反射机制 反射是一个复杂的内省技术。所谓内省即可以动态获取变量的类型，值，以及方法属性等元数据。需要反射的根本原因是，很多时候我们在编程时，并不能确定输入的具体类型，需要我们动态去判断。 Go语言提供的反射机制，能够让我们在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要在编译时就知道这些变量的具体类型。也可以让我们将类型本身作为第一类的值类型处理。 GO 中有两个至关重要的API是使用反射机制实现： fmt包提供的字符串格式功能 类似encoding/json和encoding/xml提供的针对特定协议的编解码功能。 本节我们就来看看如何使用 Go 的反射机制，以及上述两个包使用 reflect 的方式。 ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:1:0","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"2. Reflect API 反射是由 reflect 包提供的。 它定义了两个重要的类型, Type 和 Value ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:2:0","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"2.1 Type Type 是一个接口类型，唯一能反映 reflect.Type 实现的是接口的类型描述信息。 我们在接口一节说过，接口的值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。对于像Go语言这种静态类型的语言，类型是编译期的概念；因此一个类型不是一个值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。而 reflect.Type 的实现方式就与接口中的类型描述符类似。 reflect.Type 有许多办法来区分类型以及检查它们的组成部分, 例如一个结构体的成员或一个函数的参数等。 TypeOf reflect.TypeOf 接受任意的 interface{} 类型, 并以reflect.Type形式返回一个动态类型的接口值。reflect.Type 满足 fmt.Stringer 接口。 fmt.Printf 提供的 %T 参数, 内部就是使用 reflect.TypeOf 来输出接口的动态类型。 t := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // \"int\" fmt.Println(t) // \"int\" fmt.Printf(\"%T\\n\", 3) // \"int\" ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:2:1","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"2.2 Value reflect.Value 可以装载任意类型的值。函数 reflect.ValueOf 接受任意的 interface{} 类型, 并返回一个装载着其动态值的 reflect.Value。和 reflect.Type 类似, reflect.Value 也满足 fmt.Stringer 接口, 但是除非 Value 持有的是字符串, 否则 String 方法只返回其类型. 而使用 fmt 包的 %v 标志参数会对 reflect.Values 特殊处理. v := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \"3\" fmt.Printf(\"%v\\n\", v) // \"3\" fmt.Println(v.String()) // NOTE: \"\u003cint Value\u003e\" 对 Value 调用 Type 方法将返回具体类型所对应的 reflect.Type: t := v.Type() // a reflect.Type fmt.Println(t.String()) // \"int\" ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:2:2","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"2.3 Value 与 interface reflect.ValueOf 的逆操作是 reflect.Value.Interface 方法. 它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值。 v := reflect.ValueOf(3) // a reflect.Value x := v.Interface() // an interface{} i := x.(int) // an int fmt.Printf(\"%d\\n\", i) // \"3 reflect.Value 和 interface{} 都能装载任意的值. 所不同的是, 一个空的接口隐藏了值内部的表示方式和所有方法, 因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值(就像上面那样),内部值我们没法访问. 相比之下, 一个 Value 则有很多方法来检查其内容, 无论它的具体类型是什么。 与 switch x := x.(type) 相比 reflect.Value.Kind 返回的数据类型是有限的: Bool, String 和 所有数字类型的基础类型 Array 和 Struct 对应的聚合类型; Chan, Func, Ptr, Slice, 和 Map 对应的引用类型; interface 类型; 还有表示空值的 Invalid 类型 (空的 reflect.Value 的 kind 即为 Invalid.) Kind 只关心底层表示, 所有的具名类型都会归属到对应的原始类型之上。 ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:2:3","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"2.4 示例 func Display(name string, x interface{}) { fmt.Printf(\"Display %s (%T):\\n\", name, x) display(name, reflect.ValueOf(x)) } func formatAtom(v reflect.Value) string { switch v.Kind() { case reflect.Invalid: return \"invalid\" case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return strconv.FormatInt(v.Int(), 10) case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr: return strconv.FormatUint(v.Uint(), 10) // ...floating‐point and complex cases omitted for brevity... case reflect.Bool: return strconv.FormatBool(v.Bool()) case reflect.String: return strconv.Quote(v.String()) case reflect.Chan, reflect.Func, reflect.Ptr, reflect.Slice, reflect.Map: return v.Type().String() + \" 0x\" + strconv.FormatUint(uint64(v.Pointer()), 16) default: // reflect.Array, reflect.Struct, reflect.Interface return v.Type().String() + \" value\" } } func display(path string, v reflect.Value) { switch v.Kind() { case reflect.Invalid: fmt.Printf(\"%s = invalid\\n\", path) case reflect.Slice, reflect.Array: for i := 0; i \u003c v.Len(); i++ { display(fmt.Sprintf(\"%s[%d]\", path, i), v.Index(i)) } case reflect.Struct: for i := 0; i \u003c v.NumField(); i++ { fieldPath := fmt.Sprintf(\"%s.%s\", path, v.Type().Field(i).Name) display(fieldPath, v.Field(i)) } case reflect.Map: for _, key := range v.MapKeys() { display(fmt.Sprintf(\"%s[%s]\", path, formatAtom(key)), v.MapIndex(key)) } case reflect.Ptr: if v.IsNil() { fmt.Printf(\"%s = nil\\n\", path) } else { display(fmt.Sprintf(\"(*%s)\", path), v.Elem()) } case reflect.Interface: if v.IsNil() { fmt.Printf(\"%s = nil\\n\", path) } else { fmt.Printf(\"%s.type = %s\\n\", path, v.Elem().Type()) display(path+\".value\", v.Elem()) } default: // basic types, channels, funcs fmt.Printf(\"%s = %s\\n\", path, formatAtom(v)) } } ","date":"2021-01-09","objectID":"/posts/program/go/grammar/go_9/:2:4","tags":["go 语法"],"title":"go reflect","uri":"/posts/program/go/grammar/go_9/"},{"categories":["Go"],"content":"goroutines 和 channel","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"Go 并发编程原语，Goroutines和Channels ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:0:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"1. GO 并发编程简介 上一篇我们讲解了 Go 语言中的接口，至此对于 Go 语言的类型系统我们基本上讲的差不都了。接下来我们将深入了解 Go 最为人推广的特性并发编程。对于那些完全独立的子问题，并发是简单的，但是真正复杂的是处理那些存在资源共享的多进程多线程并发问题。我们需要有效的通信机制来处理程序中的竞争条件，同时避免可能出现的死锁问题。 Go 之所以在并发编程中被人推广，是因为它提供的 goroutine 和 channel 支持“顺序通信进程”(communicating sequential processes)简称为CSP，这是一种现代的并发编程模型。CSP的具体原理我也不是很懂，但是 Go 有一句口头禅“不要使用共享数据来通信；使用通信来共享数据” 。学完这部分内容，你就能理解这句话的含义了。 没有一招鲜吃遍天的技术，每个模型都是特定的假设条件和使用情景，CSP 也不例外。相比于 GSP 传统的并发模型：多线程共享内存，可能更容易出错(竞争条件和死锁)，但是也更加灵活。所以要想写出正确的并发程序，对操作系统提供的锁，信号量等进程间通信的底层机制的了解必不可少。我们将分为三节来介绍这些并发编程的技巧，本节我们先来学习 goroutine 和 channel。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:1:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"2. Goroutine 在Go语言中，每一个并发的执行单元叫作一个goroutine。当一个程序启动时，其主函数即在一个单独的goroutine中运行，我们叫它main goroutine 。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:2:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"2.1 goroutine 创建 新的goroutine会用go语句来创建。在语法上，go语句是一个普通的函数或方法调用前加上关键字go。go语句会使其语句中的函数在一个新创建的goroutine中运行。而go语句本身会迅速地完成。 f() // call f(); wait for it to return go f() // create a new goroutine that calls f(); don't wait ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:2:1","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"2.2 goroutine 退出与回收 通常goroutine在执行完毕时会自动回收，当主函数返回时，所有未执行完毕的 goroutine 会被直接打断，程序退出。如果 goroutine 因为阻塞永远被卡住，我们称发生了goroutine泄漏，和垃圾变量不同，泄漏的goroutines并不会被自动回收，因此确保每个不再需要的goroutine能正常退出是重要的。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:2:2","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"2.3 goroutine 中断 除了从主函数退出或者直接终止程序之外，没有其它的编程方法能够让一个goroutine来打断另一个的执行。但是通过 goroutine 之间的通信机制，可以实现让一个 goroutine 在收到其它的 goroutine 特定信号时终止退出。这个必须得等到我们讲完 channel 时才能继续说明。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:2:3","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"3. channels 如果说goroutine是Go语言程序的并发体的话，那么 channels 则是它们之间的通信机制。一个 channels 可以让一个 goroutine 通过它给另一个 goroutine 发送值信息。 每个channel都有一个特殊的类型，也就是channels可发送数据的类型。和其它的引用类型一样，channel的零值也是nil，因此channel 可以与 nil 值比较。两个相同类型的channel可以使用==运算符比较。如果两个channel引用的是相通的对象，那么比较的结果为真。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:3:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"3.1 channel 创建 创建 channel 最简单的方式是使用 make 函数，第二个可选参数，用于指定 channel 的容量。 ch = make(chan int) // 无缓存 channel ch = make(chan int, 0) // 无缓存 channel ch = make(chan int, 3) // 待缓存的 channel cap(ch) // 获取 channel 容量 len(ch) // 返回 channel 中有效元素个数 channel 与并发的先进先出队列极其相似: 发送在队尾插入元素，接收从队首删除元素 当 channel 空时，从 channel 接收值的 goroutine 将被阻塞，直至另一个 goroutine 向 channel 发送值 当 channel 满时，向 channel 发送值的 goroutine 将被阻塞，直至另一个 goroutine 从 channel 接收值 特别的对于无缓存 channels 的发送和接收操作将导致两个goroutine做一次同步操作，需要注意的是当通过一个无缓存 channels 发送数据时，接收者收到数据发生在唤醒发送者 goroutine 之前。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:3:1","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"3.2 发送与接收 channel有发送和接受两种操作: ch \u003c‐ x // 向 channel 发送一个值 x = \u003c‐ch // 从 channel 接收值 \u003c‐ch // 从 channel 接收值，但丢弃 close(ch) // 关闭 channel 为了防止 channel 被乱用，Go语言还提供了单方向的 channel 类型，即只发送或只接收的channel。 // 只发送和只接受的 channel 类型 chan\u003c‐ int // 只发送int的channel，不能接收 \u003c‐chan int // 只接收int的channel，不能发送 func squarer(out chan\u003c‐ int, in \u003c‐chan int) {} 任何双向channel向单向channel变量的赋值操作都将导致该隐式转换。但是没有反向转换的语法，即不能将类似 chan\u003c‐ int类型的单向型的channel转换为 chan int类型的双向型的channel。 因为关闭操作只用于断言不再向channel发送新的数据，所以只有在发送者所在的 goroutine 才会调用close函数，因此对一个只接收的channel调用 close 将是一个编译错误。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:3:2","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"3.3 关闭 channel还支持close操作，用于关闭channel，对于接收方和发送方，关闭channel之后的操作是不同的: 发送方: 对一个关闭的 channel 的任何发送操作都将导致panic异常，因此关闭操作只能由发送方执行 接收方: 在 channel 关闭之后依然可以接受到之前已经成功发送的数据；如果channel中已经没有数据，后续的接收操作也不会再阻塞，而是立即返回一个零值。稍后我们就会利用这个特性，通过关闭 channel实现一种广播机制。 所以对于下面这个例子，即使 naturals变量对应的channel 被关闭，循环也不会终止，它依然会收到一个永无休止的零值序列。 // Squarer go func() { for { x := \u003c‐naturals squares \u003c‐ x * x } }() 没有办法直接测试一个channel是否被关闭，但是接收操作有一个变体形式：它多接收一个结果，多接收的第二个结果是一个布尔值ok，ture表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。range 可以简化对 channels 的读取和关闭测试，下面是一些代码示例: // 通过可选的第二个参数，在接收方判断 channel 是否关闭 go func() { for { x, ok := \u003c‐naturals if !ok { break // channel was closed and drained } squares \u003c‐ x * x } close(squares) }() // range循环可直接在channels上迭代，当channel被关闭并且没有值可接收时跳出循环 go func() { for x := range naturals { squares \u003c‐ x * x } close(squares) }() 最后，试图关闭一个nil值的channel也将导致panic异常。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:3:3","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"4. select 多路复用 有些时候，我们需要同时监听多个 channel 的接收和发送操作，并选择第一个可执行 channel 进行操作。此时我们就需要 select 多路复用。select 与 和 switch 语句稍微有点相似，select 也会有几个 case和最后的default选择分支。每一个case代表一个通信操作(在某个channel上进行发送或者接收)并且会包含一些语句组成的一个语句块。 select { case \u003c‐ch1: // ... case x := \u003c‐ch2: // ...use x... case ch3 \u003c‐ y: // ... default: // ... } select会等待case中的 channel 操作，直至出现一个可通信的 channel 时，执行通信并选择对应的 case 执行；这时候其它通信是不会执行的。一个没有任何case的select语句写作select{}，会永远地等待下去。如果多个case同时就绪时，select会随机地选择一个执行，这样来保证每一个channel都有平等的被select的机会。 对一个nil的channel发送和接收操作会永远阻塞，在select语句中操作nil的channel永远都不会被select到。这使得我们可以用nil来激活或者禁用case，来达成处理其它输入或输出事件时超时和取消的逻辑。 ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:4:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"5. goroutine 的中断 有了上面的铺垫，我们回头来看如何中断一个 goroutine 的执行。现在我们知道，当一个被关闭的 channel 被消费掉了所有已发送的值之后，对channel 的任何操作会立即被执行，并且产生零值。我们将代表取消操作的 channel 作为 select 的一个分支，一个立刻返回的分支；通过关闭 channel 让所有操作该 channel 的代码都可以立马执行，从而 select 会选择退出分支，让 goroutine 立刻终止。通过 channel 的取消操作，我们实现了一种广播机制。下面是一个简单的代码示例: # 广播机制 var done = make(chan struct{}) func cancelled() bool { select { case \u003c‐done: // channel 被关闭后，立马就会执行 return true default: return false } } # 监听用户的取消操作 go func() { os.Stdin.Read(make([]byte, 1)) // read a single byte close(done) // 通过关闭 channel，进行消息广播 }() func walkDir(dir string, n *sync.WaitGroup, fileSizes chan\u003c‐ int64) { defer n.Done() if cancelled() { // 发现用户取消，立刻终止 return } for _, entry := range dirents(dir) { // ... } } ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:5:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"6. 使用示例 接下来，我们将探究一个生成缩略图的问题来作为 goroutine 和 channel 的使用示例。下面是一个顺序执行的版本。 // makeThumbnails makes thumbnails of the specified files. func makeThumbnails(filenames []string) { for _, f := range filenames { # 缩略图执行的函数，具体代码省略 if _, err := thumbnail.ImageFile(f); err != nil { log.Println(err) } } } 显然，我们可以使用并发来加快程序的执行速度。 // NOTE: incorrect! func makeThumbnails2(filenames []string) { for _, f := range filenames { go thumbnail.ImageFile(f) // NOTE: ignoring errors } } 然而上面面的程序是有问题的，makeThumbnails(下称主函数)在 go 创建的 goroutine(下称 work goroutine) 还没有完成工作之前就已经返回了。我们需要主函数等待 work goroutine 完成。我们可以使用 channel 进行同步。 func makeThumbnails4(filenames []string) error { errors := make(chan error) for _, f := range filenames { go func(f string) { _, err := thumbnail.ImageFile(f) errors \u003c‐ err }(f) } for range filenames { if err := \u003c‐errors; err != nil { return err // NOTE: incorrect: goroutine leak! } } return nil } 这个程序有一个微秒的bug。当它遇到第一个非nil的error时会直接将error返回到调用方，使得没有一个goroutine去排空errors channel。这样剩下的worker goroutine在向这个channel中发送值时，都会永远地阻塞下去，并且永远都不会退出。即出现goroutine泄露，可能会导致整个程序卡住或者跑出out of memory的错误。 最简单的解决办法就是用一个具有合适大小的buffered channel(c h := make(chan item, len(filenames)))，这样这些worker goroutine向channel中发送错误时就不会被阻塞。另一个可选的解决办法是创建一个另外的goroutine，当maingoroutine返回第一个错误的同时去排空channel。 此外，如果文件过多，程序可能会创建成百上千的 goroutine，我们需要用计数信号量来限制并发的数量。 // 限制并发数的信号量 var sema = make(chan struct{}, 20) go func(f string) { sema \u003c‐ struct{}{} // 执行前获取 token defer func() { \u003c‐sema }() // 执行结束后释放 token _, err := thumbnail.ImageFile(f) errors \u003c‐ err }(f) ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:6:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"7. 使用局限 至此，我们已经掌握了goroutine 和 channel的基本使用，但是还远远不够。我们无法解决像下面这些问题: 1. ","date":"2021-01-08","objectID":"/posts/program/go/grammar/go_8/:7:0","tags":["go 语法"],"title":"go 并发编程","uri":"/posts/program/go/grammar/go_8/"},{"categories":["Go"],"content":"go 接口的定义、使用以及类型断言","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"Go 的泛型编程 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:0:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"1. 接口概述 接口是 Go 语言提供的泛型的核心概念。所谓泛型就是允许程序员在强类型程序设计语言中编写代码时使用一些以后才指定的类型，目的是增加函数的通用性。当然我们没必要去纠结概念，最重要的是搞明白，Go 如何通过接口来提高程序的灵活性。 在学习接口之前，我们需要对它有如下一个整体的认识，以把握住接口的整体脉络: Go 的接口类型是抽象类型，与 Python 中鸭子类型类似，通过类型支持的方法来约束对象的适用范围。我们将学些如何在 Go 定义接口，如何判断一个具体类型实现了哪些接口。 接口不仅是对类型的抽象和限定，也代表了将接口作为参数的函数和函数调用者之间的一个约定(正是通过这种约定提高了函数的可用性): 调用者需要提供符合接口的具体类型作为参数 函数在接受任何满足接口的值时都可以工作，函数不会调用接口限定之外的任何其他方法 有了上面的铺垫，我们将按照下面的顺序介绍接口的相关内容: 接口类型 接口的定义 接口归属判断 接口的约定 接口值 类型断言 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:1:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"2. 接口类型 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:2:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"2.1 接口定义 接口类型是一种抽象的类型，与字符串，整数这些具体类型相比，我们并不知道接口类型代表的具体值；它只包含方法声明，描述了一系列方法的集合。下面是 Go 接口类型的定义示例: package io type Reader interface { Read(p []byte) (n int, err error) } type Closer interface { Close() error } type Writer interface { Write(p []byte) (n int, err error) } type ReadWriter interface { Reader Writer } 与结构体嵌入类似，我们也可以通过类似的方式进行接口内嵌，实现接口组合。在接口的定义中方法的定义顺序没有影响，唯一重要的是接口内的方法集合。 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:2:1","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"2.2 接口归属判断 如果一个类型拥有一个接口需要的所有方法，那么这个类型就实现了这个接口，我们称这个具体类型是这个接口类型的实例。正如我们在 go 方法一章所描述的，一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了所有值方法和所有指针方法。因此对于一个自定义类型，他的类型和他的指针类型实现的接口并不相同。 // 1. 表达一个类型属于某个接口只要这个类型实现这个接口 var rwc io.ReadWriteCloser rwc = os.Stdout // OK: *os.File has Read, Write, Close methods rwc = new(bytes.Buffer) // compile error: *bytes.Buffer lacks Close method // 2. 接口归属的判断同样适合接口之间 w = rwc // OK: io.ReadWriteCloser has Write method rwc = w // compile error: io.Writer lacks Close method // 3. 类型 与 类型的指针类型，实现的接口并不相同，后者可能实现了更多的接口 type IntSet struct { /* ... */ } func (*IntSet) String() string var _ fmt.Stringer = \u0026s // OK var _ fmt.Stringer = s // compile error: IntSet lacks String method 每一个具体类型的组基于它们相同的行为可以表示成一个接口类型。接口不止是一种有用的方式来分组相关的具体类型和表示他们之间的共同特定。在Go语言中我们可以在需要的时候定义一个新的抽象或者特定特点的组，而不需要修改具体类型的定义。 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:2:2","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"2.3 接口的约定 正如我们开篇所说的，接口类型不仅是对类型的约束，也代表着函数和调用者之间的约定。 type Writer interface { Write(p []byte) (n int, err error) } func Fprintf(w io.Writer, format string, args ...interface{}) (int, error) type ByteCounter int func (c *ByteCounter) Write(p []byte) (int, error) { *c += ByteCounter(len(p)) // convert int to ByteCounter return len(p), nil } var c ByteCounter c.Write([]byte(\"hello\")) fmt.Println(c) // \"5\", = len(\"hello\") c = 0 // reset the counter var name = \"Dolly\" fmt.Fprintf(\u0026c, \"hello, %s\", name) fmt.Println(c) // \"12\", = len(\"hello, Dolly\") 如上例所述，io.Writer 接口约定了，函数调用者必须提供实现了 io.Writer 接口的具体类型作为函数参数，而 Fprintf 函数只能调用 io.Writer 接口暴露出来的方法，即使具体类型有其它的方法也不能调用。 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:2:3","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"2.4 空接口 interface{}被称为空接口，空接口类型是不可或缺的。因为空接口类型对实现它的类型没有要求，所以我们可以将任意一个值赋给空接口类型。当然我们不能直接对它持有的值做操作，因为interface{}没有任何方法。我们会在稍后介绍一种用类型断言来获取interface{}中值的方法。 var any interface{} any = true any = 12.34 any = \"hello\" any = map[string]int{\"one\": 1} any = new(bytes.Buffer) ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:2:4","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"3. 接口的值 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:3:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"3.1 接口赋值 概念上讲一个接口的值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。对于像Go语言这种静态类型的语言，类型是编译期的概念；因此一个类型不是一个值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。 我们通过下面一个赋值的示例来了解接口的值 var w io.Writer w = os.Stdout w = new(bytes.Buffer) w = nil var w io.Writer 定义了变量w，变量总是被一个定义明确的值初始化，即使接口类型也不例外。对于一个接口的零值就是它的类型和值的部分都是nil。一个接口值仅基于它的动态类型被描述为空或非空，因此一个不包含任何值的nil接口值和一个刚好包含nil指针的接口值是不同的，后者不为 nil。 你可以通过使用w==nil或者w!=nil来判读接口值是否为空。调用一个空接口值上的任意方法都会产生panic。调用一个包含 nil 指针的接口上的方法是否会报错，取决于接口内包含的动态类型。 // w，f 都是特定类型的空值，将他们赋值给 w 都将得到一个 包含nil指针的接口值 var w io.Writer var f *os.File var buf *bytes.Buffer // 对 *os.File的类型，nil是一个有效的接收者，所以不会报错 w = f w.Writer() // (*bytes.Buffer).Write方法的接收者必须非空，调用会报错 w = buf buf，Writer() w = os.Stdout 这个赋值过程调用了一个具体类型到接口类型的隐式转换，这和显式的使用io.Writer(os.Stdout)是等价的。此时这个接口值的动态类型被设为*os.File指针的类型描述符，它的动态值持有os.Stdout的拷贝； w = nil 这个重置将它所有的部分都设为nil值，把变量w恢复到和它之前定义时的状态。 一个接口值可以持有任意大的动态值。从概念上讲，不论接口值多大，动态值总是可以容下它。（这只是一个概念上的模型；具体的实现可能会非常不同） ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:3:1","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"3.2 接口比较 接口值可以使用==和!＝来进行比较。两个接口值相等仅当它们都是nil值或者它们的动态类型相同并且动态值也根据这个动态类型的==操作相等。因为接口值是可比较的，所以它们可以用在map的键或者作为switch语句的操作数。 然而，如果两个接口值的动态类型相同，但是这个动态类型是不可比较的（比如切片），将它们进行比较就会失败并且panic: var x interface{} = []int{1, 2, 3} fmt.Println(x == x) // panic: comparing uncomparable type []int 考虑到这点，接口类型是非常与众不同的。其它类型要么是安全的可比较类型（如基本类型和指针）要么是完全不可比较的类型（如切片，映射类型，和函数），但接口的可比性取决接口包含的动态类型。但是在比较接口值或者包含了接口值的聚合类型时，我们必须要意识到潜在的panic。同样的风险也存在于使用接口作为map的键或者switch的操作数。只能比较你非常确定它们的动态值是可比较类型的接口值。 通过 fmt包的%T 动作，我们可以获取接口值的动态类型，在fmt包内部，使用反射来获取接口动态类型的名称。关于反射，我们后面在详述。 var w io.Writer fmt.Printf(\"%T\\n\", w) // \"\u003cnil\u003e\" w = os.Stdout fmt.Printf(\"%T\\n\", w) // \"*os.File\" w = new(bytes.Buffer) fmt.Printf(\"%T\\n\", w) // \"*bytes.Buffer\" ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:3:2","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"4. 类型断言 类型断言是我们使用 Go 语言中接口的另一种方式。前面的第一个方式中，一个接口的方法表达了实现这个接口的具体类型间的相似性，但是隐藏了代表的细节和这些具体类型本身的操作。重点在于方法上，而不是具体的类型上。 第二种使用方式利用了一个接口值可以持有各种具体类型值的能力并且将这个接口认为是这些类型的 union（联合）。类型断言用来动态地区别出接口包含的每一个类型，做不同处理。在这个方式中，重点在于具体的类型满足这个接口，而不是在于接口的方法（如果它确实有一些的话），并且没有任何的信息隐藏。我们将以这种方式使用的接口描述为discriminated unions（可辨识联合）。 通过类型断言，我们至少可以实现下面这些目标: 区别错误类型 判断对象是否支持特定的方法 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:4:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"4.1 语法 x.(T): x - 表示待判断的接口类型，T - 表示断言的类型 如果 T 是一个具体类型，类型断言检查 x 的动态类型是否和T相同，相同，返回 x 的动态值 如果 T 是一个接口类型，类型断言检查 x 的动态类型是否满足T，满足，返回包含 x 动态类型和动态值的接口 T 的值 // 具体类型断言 var w io.Writer w = os.Stdout rw := w.(io.ReadWriter) // success: *os.File has both Read and Write w = new(ByteCounter) rw = w.(io.ReadWriter) // panic: *ByteCounter has no Read method， 断言失败触发 panic // 接口类型断言 var w io.Writer = os.Stdout f, ok := w.(*os.File) // success: ok, f == os.Stdout b, ok := w.(*bytes.Buffer) // failure: !ok, b == nil // 通过第二个变量接受断言是否成功，替代断言失败时的异常 if w, ok := w.(*os.File); ok { // if 引出了新的作用域，因此这里发生的是对变量名的重新，发生了变量的覆盖，不是变量的重新赋值。 // ...use w... } 换句话说，对一个接口类型的断言改变了类型的表述方式，改变了可以获取的方法集合（通常更大），我们几乎不需要对一个更少限制性的接口类型（更少的方法集合）做断言，因为它表现的就像赋值操作一样，除了对于nil接口值的情况。如果断言操作的对象是一个nil接口值，那么不论被断言的类型是什么这个类型断言都会失败。 // 对更小的接口无需断言，可直接赋值 w = rw // io.ReadWriter is assignable to io.Writer w = rw.(io.Writer) // fails only if rw == nil ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:4:1","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"4.2 类型开关 类型断言有一个 Switch 的便捷语法，称为类型开关，一个类型开关像普通的switch语句一样，它的运算对象是x.(type)－它使用了关键词字面量type－并且每个case有一到多个类型。一个类型开关基于这个接口值的动态类型使一个多路分支有效。一个使用示例如下所示: func sqlQuote(x interface{}) string { switch x := x.(type) { case nil: return \"NULL\" case int, uint: return fmt.Sprintf(\"%d\", x) // x has type interface{} here. case bool: if x { return \"TRUE\" } return \"FALSE\" case string: return sqlQuoteString(x) // (not shown) default: panic(fmt.Sprintf(\"unexpected type %T: %v\", x, x)) } } 这个示例还展示了，类型开关语句的一个扩展的形式，它可以将提取的值绑定到一个在每个case范围内的新变量 switch x := x.(type) { /* ... */ }。在这个版本的函数中，在每个单一类型的case内部，变量x和这个case的类型相同。例如: 变量 x 在bool的case中是bool类型和string的case中是string类型 在所有其它的情况中，变量x是 switch 运算对象的类型（接口）；在这个例子中运算对象是一个interface{} 当多个 case 需要相同的操作时，比如int和uint的情况，类型开关可以很容易的合并这些情况 ","date":"2021-01-07","objectID":"/posts/program/go/grammar/go_7/:5:0","tags":["go 语法"],"title":"go 接口","uri":"/posts/program/go/grammar/go_7/"},{"categories":["Go"],"content":"使用 struct 实现对象组合和类型嵌套","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"Go 的对象组合技术 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:0:0","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"1. 内容概要 方法是面向对象编程(OOP)中的概念。有关 OOP 的定义我也说不清楚。但是与概念相比，更重要的是OOP的两个关键点:封装和组合。我们的目的是看看 Go 语言如何通过结构体嵌入等技术实现这两个关键点。 Go 语言中的方法和接口密切相关，接口是 Go 语言提供的用来支持泛型编程的核心组件，我们会在下一章详细讨论。现在我们只需要明白: 方法是与特定类型关联的函数，可以被声明到任意命名类型，包括 Go 的内置类型;但不能是一个指针或者一个接口类型 方法分为值方法和指针方法两类，这会影响到类型是否属于特定接口的判断 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:1:0","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2. 方法 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:0","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2.1 方法声明 在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。 type Point struct{ X, Y float64 } // 1. 为 Point 定义一个值方法 // 参数p，叫做方法的接收器(receiver) func (p Point) Distance(q Point) float64 { return math.Hypot(q.X‐p.X, q.Y‐p.Y) } // 2. 调用方法 p := Point{1, 2} q := Point{4, 6} fmt.Println(p.Distance(q)) // \"5\", method call 从上面的示例可以看出来，在方法的定义和调用等行为上，Go 与 Python 并没有什么太大差别。有一点不同的是，当出现命名冲突时，Python 的默认行为是覆盖，而 Go 在编译阶段就直接失败。此外需要注意的是方法和属性在同一命名空间，因此它们之间的命名冲突也是不允许的。 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:1","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2.2 值方法与指针方法 前面函数的部分我们说过，Go 中实参通过值的方式传递。类似的，传递给方法接收器的对象也是按值传递。在上面的 Distance 内接收器 p 是外部 p 对象的拷贝。相对应的我们可以像下面这样，用其指针而不是对象来声明方法。 func (p *Point) ScaleBy(factor float64) { p.X *= factor p.Y *= factor } ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:2","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2.3 接收器限制 只有类型(Point)和指向他们的指针(*Point)，才是可能会出现在接收器声明里的两种接收器。为了避免歧义，在声明方法时，如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的，比如下面这个例子。即我们不能为指针定义方法。 type P *int func (P) f() { /* ... */ } // compile error: invalid receiver type ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:3","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2.4 方法调用中的隐式转换 原则上，类型 Point只能调用其值方法，*Point只能调用其指针方法。这样在方法的调用中会有很多转换操作。幸运的是，Go 为我们提供了隐示的转换，就像我们直接通过指针去访问结构的成员变量一样。 p := Point{1, 2} pptr := \u0026p // type --\u003e *type p.ScaleBy(2) // 等同于 (\u0026p).ScaleBy(2) // *type --\u003e type pptr.Distance(q) // 等同于 (*pptr).Distance(q) 需要特别注意的是 type --\u003e *type 转换的前提是对象是可取址的。我们不能通过一个无法取到地址的接收器来调用指针方法，比如临时变量： Point{1, 2}.ScaleBy(2) // compile error: can't take address of Point literal ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:4","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"2.5 类型的方法集合 如上所述，正因为我们总是可以通过对一个地址解引用(*)来获取变量，但是却不一定能获取一个对象的地址(临时对象)，所以一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 //1. pkg 包内定义 animal 和 Dog package pkg type animal struct { Name string } type Dog struct { animal Weight int } func NewDog() Dog { return Dog{animal{\"aaa\"}, 100} } func (g Dog) GetName() string { return g.Name } func (g *Dog) GetWeight() int { return g.Weight } // 2 mian 包内使用 package main import ( \"fmt\" \"mygo/pkg\" ) func main() { g := pkg.NewDog() fmt.Printf(\"%T, %#v\\n\", g, g) fmt.Println(g.Weight) // 注意: 此处我们可以直接访问 g.Weight fmt.Println(g.Name) fmt.Printf(\"%T\\n\", (*pkg.Dog).GetName) // func(*pkg.Dog) string fmt.Printf(\"%T\\n\", (*pkg.Dog).GetWeight) // func(*pkg.Dog) int fmt.Printf(\"%T\\n\", pkg.Dog.GetName) // func(pkg.Dog) string // fmt.Printf(\"%T\\n\", pkg.Dog.GetWeight) } 在上面的示例中: 通过结构体直接访问方法，我们将获取一个方法值，值方法是一个函数，其接受的参数与调用的方式有关，以结构体调用，返回的函数需要接受结构体，以结构体指针调用，返回的函数需要接受结构体的指针 所有的值方法可以通过结构体，也可以通过结构体的指针进行访问，所有的指针方法只能通过结构体指针进行访问 这里也反应出一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:2:5","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"3. 结构体嵌入 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:3:0","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"3.1 结构体嵌入与类的继承 在结构体一节中，我们就已经提到了，结构体中通过匿名字段嵌入的不仅仅是结构体的成员还是其方法。以下面嵌入了 Point 的 ColoredPoint 为例，我们可以把ColoredPoint类型当作接收器来调用Point里的方法，即使ColoredPoint里没有声明这些方法。 import \"image/color\" type Point struct{ X, Y float64 } type ColoredPoint struct { Point Color color.RGBA } red := color.RGBA{255, 0, 0, 255} blue := color.RGBA{0, 0, 255, 255} var p = ColoredPoint{Point{1, 1}, red} var q = ColoredPoint{Point{5, 4}, blue} fmt.Println(p.Distance(q.Point)) // \"5\" p.ScaleBy(2) q.ScaleBy(2) fmt.Println(p.Distance(q.Point)) // \"10\" 这种行为看起来跟 OOP 类的继承一样，但是有本质区别。最明显的地方是，在类的继承中，子类的实例也是基类的实例，但是在结构体嵌入中，ColoredPoint 类型的\"实例\"，并不是 Point 的\"实例\"。 请注意上面例子中对Distance方法的调用。尽管q有着Point这个内嵌类型，但是q并不是一个Point类，我们必须要显式地选择它。 p.Distance(q.Point) // right p.Distance(q) // compile error: cannot use q (ColoredPoint) as Point 在 Go 的结构体嵌入中，我们只能说 ColoredPoint has a Point 而不能说 ColoredPoint 继承自 Point。内嵌可以使我们将复杂类型的定义拆分，将字段先按小类型分组，然后定义小类型的方法，之后再把它们组合起来。 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:3:1","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"3.2 嵌入命名类型的指针 在类型中内嵌的匿名字段也可能是一个命名类型的指针，添加这一层间接关系让我们可以共享通用的结构并动态地改变对象之间的关系。 type ColoredPoint struct { *Point Color color.RGBA } p := ColoredPoint{\u0026Point{1, 1}, red} q := ColoredPoint{\u0026Point{5, 4}, blue} // 注意访问 *q.Point 的区别 fmt.Println(p.Distance(*q.Point)) // \"5\" q.Point = p.Point // p and q now share the same Point p.ScaleBy(2) fmt.Println(*p.Point, *q.Point) // \"{2 2} {2 2}\" ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:3:2","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"3.3 多匿名字段的查找顺序 如果结构体中嵌入了多个匿名字段，将遵循下面的字段和方法查找顺序: 直接定义在类型里方法 内嵌字段引入的方法 内嵌字段的内嵌字段引入的方法，然后一直递归向下找 如果在同一级里有两个同名的方法，编译器会报错 上面说的同一级可以理解为，由内嵌所构成的树的同一层。 type A struct { A1 } type A1 struct { } type B struct { B1 } type B1 struct{ } func (a A1) name() { fmt.Println(\"a1\") } func (b B1) name() { fmt.Println(\"b1\") } type C struct { A B } c := C{} // 同一级的 A1，B1 的 同名 name 方法导致编译错误 c.name() // ambiguous selector c.name ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:3:3","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"4. 封装 一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。封装有时候也被叫做信息隐藏，同时也是面向对象编程最关键的一个方面。 Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。 这种基于名字的手段使得在语言中最小的封装单元是package。一个struct类型的字段对同一个包的所有代码都有可见性，无论你的代码是写在一个函数还是一个方法里。 ","date":"2021-01-06","objectID":"/posts/program/go/grammar/go_6/:4:0","tags":["go 语法"],"title":"go 的结构体和方法","uri":"/posts/program/go/grammar/go_6/"},{"categories":["Go"],"content":"go 函数的使用","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"函数，代码封装的基本单元 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:0:0","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"1. 函数 函数通常使用起来并不复杂，定义或声明函数后，直接使用即可。但是为了函数更加易用，编程语言会为函数添加很多特性。在 Python 和 Go 中，函数都是一等\"公民\"，即函数可以用在任何变量可以使用的地方，并且具有类型。因此接下来我们按照下面的顺序来讲解 Go 函数的相关内容: 第一部分: Go 函数作为基础数据类型的特性: 函数声明 函数的类型 函数的零值 第二部分: Go 函数语言层的特性 匿名函数与闭包 异常处理 Deferred ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:0:1","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"2. 函数 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:1:0","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"2.1 函数声明 Go 函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。函数的参数，返回值以及函数调用时的传值方式是函数的核心。 func name(parameter‐list) (result‐list) { body } 下面是几个函数声明的示例: func hypot(x, y float64) float64 { return math.Sqrt(x*x + y*y) } // 参数类型相同时，可以合并 func f(i, j, k int, s, t string) { /* ... */ } func f(i int, j int, k int, s string, t string) { /* ... */ } // func add(x int, y int) int {return x + y} func sub(x, y int) (z int) { z = x ‐ y; return} func first(x int, _ int) int { return x } // _ 可以强调某个参数未被使用 func zero(int, int) int { return 0 } // 在返回值的类型都相同时， 返回值变量名可以传达函数返回值的含义 func Size(rect image.Rectangle) (width, height int) func Split(path string) (dir, file string) 返回值 与 Python 默认返回 None 不同，Go 有返回值列表，但是没有默认的返回值，返回值列表就是对函数返回值的约束: 返回值列表描述了函数返回值的变量名以及类型 如果没有返回值列表，函数不能返回任何值 如果包含返回值列表，函数必须返回与返回值列表类型相符的值 返回值可以被命名，此时每个返回值被声明成一个局部变量，并根据返回值的类型，被其初始化为 0 当如果函数返回一个无名变量或者没有返回值，返回值列表的括号可以省略。 Go 的函数返回值符合 Go 强变量类型的约束。 参数 Go 函数参数没有默认值，也不能通过参数名指定行参。每一次函数调用都必须按照声明顺序为所有参数提供实参（参数值）。因此形参和返回值的变量名对于函数调用者而言没有意义。 为了让函数更加通用，Go 和 Python 都提供了可变参数的特性。在 Go 中声明可变参数时，需要在参数列表的最后一个参数类型之前加上省略符号“…”，这表示该函数会接收任意数量的该类型参数。 func sum(vals...int) int { total := 0 for _, val := range vals { total += val } return total } // fmt.Println(sum()) // \"0\" fmt.Println(sum(3)) // \"3\" fmt.Println(sum(1, 2, 3, 4)) // \"10\" 在上面的代码中，调用者隐式的创建一个数组，并将原始参数复制到数组中，再把数组的一个切片作为参数传给被调函数。如果原始参数已经是切片类型，可以像下面这样向函数传递参数。 // values := []int{1, 2, 3, 4} fmt.Println(sum(values...)) // \"10\" ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:1:1","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"2.2 函数类型与值 Go 中函数的类型被称为函数的标识符，函数的取决于参数和返回值的类型: 如果两个函数形式参数列表和返回值列表中的变量类型一一对应，那么它们有相同的类型和标识符 形参和返回值的变量名不不会影响函数标识符 函数类型的零值是 nil。调用值为nil的函数值会引起panic错误。函数值可以与nil比较，但是函数值之间是不可比较的，也不能用函数值作为map的key。函数之间之所以不可比，是因为函数闭包，函数会保留定义函数时，存在的自由变量的绑定。我们会在下面讲解。 // 此处f的值为nil, 会引起panic错误 var f func(int) int f(3) // 函数与 nil 比较 var f func(int) int if f != nil { f(3) } ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:1:2","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"2.3 函数调用的传值方式 我们把调用函数时传递给函数的值称为实参，函数接收参数值的变量称为行参。 Go 中实参通过值的方式传递，因此函数的形参是实参的拷贝。对形参进行修改不会影响实参。但是，如果实参包括引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的间接引用被修改。 在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值。函数的形参和有名返回值作为函数最外层的局部变量，被存储在相同的词法块中。我们甚至可以直接修返回值变量，来修改函数的返回值。我们会在讲解 Deffer 时详述。 说完了函数作为基本类型的特性，我们再来看为了方便编程，Go 为函数提供的语言层特性。 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:1:3","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"3. 函数特性 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:2:0","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"3.1 函数闭包 Go 里面一个有意思的地方是拥有函数名的函数只能在包级语法块中被声明。即我们不能在函数内部使用，使用 func name(parameter‐list) (result‐list) 方式定义函数，但不带 name 的 func (parameter‐list) (result‐list) 匿名函数可以。func (parameter‐list) (result‐list) 是 Go 函数的函数字面量。函数值字面量是一种表达式，它的值被成为匿名函数（anonymousfunction） 说起来比较绕，即如果我们想在函数内定义命名函数必须使用下面这种方式；或者直接使用匿名函数。 // 1. 函数内定义命名函数 func f1(a, b int) (r int) { v := func() { r += b } defer v() return a + b } // 2. 直接使用匿名函数 func squares() func() int { var x int return func() int { x++ return x * x } } f := squares() fmt.Println(f()) // \"1\" fmt.Println(f()) // \"4\" 注意在上面第二个示例中，squares中定义的匿名内部函数可以访问和更新squares中的局部变量，这意味着匿名函数和squares中存在变量引用。这就是函数闭包，也是函数值属于引用类型和函数值不可比较的原因。 需要注意的是函数闭包内保存的是变量的引用而不是变量的值。我们来看下面删除临时文件的示例: var rmdirs []func() for _, dir := range tempDirs() { // dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) rmdirs = append(rmdirs, func() { os.RemoveAll(dir) // NOTE: incorrect! }) } 在上面的程序中，for循环语句引入了新的词法块，循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以dir为例，后续的迭代会不断更新dir的值，当删除操作执行时，for循环已完成，dir中存储的值等于最后一次迭代的值。这意味着，每次对os.RemoveAll的调用删除的都是相同的目录。 如果你使用go语句或者defer语句会经常遇到此类问题。这不是go或defer本身导致的，而是因为它们都会等待循环结束后，再执行函数值。 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:2:1","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"3.2 Defer 机制 Go 的 Defer 机制与 Python 的上下文管理器有点类似，都是为了保证某些代码一定要执行，无论代码是否出现了异常。 defer 的语法很简单，只需要在调用普通函数或方法前加上关键字defer。 当defer语句被执行时，跟在defer后面的函数会被延迟执行。 直到包含该defer语句的函数执行完毕时，defer后的函数才会被执行，不论包含defer语句的函数是通过return正常结束，还是由于panic导致的异常结束。 可以在一个函数中执行多条defer语句，它们的执行顺序与声明顺序相反。 通过defer机制，不论函数逻辑多复杂，都能保证在任何执行路径下，资源被释放。释放资源的defer应该直接跟在请求资源的语句后。需要注意的是跟在 defer 之后的是函数调用，而不是函数本身。 // defer 关闭文件 package ioutil func ReadFile(filename string) ([]byte, error) { f, err := os.Open(filename) if err != nil { return nil, err } defer f.Close() return ReadAll(f) } // 释放锁 var mu sync.Mutex var m = make(map[string]int) func lookup(key string) int { mu.Lock() defer mu.Unlock() return m[key] } 利用 defer中的函数会在return语句更新返回值变量后再执行，以及在函数中定义的匿名函数可以访问该函数包括返回值变量在内的所有变量，我们就可以上面说到的改变函数返回值的目的。 func triple(x int) (result int) { defer func() { result += x }() return double(x) } fmt.Println(triple(4)) // \"12 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:2:2","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"3.3 错误与异常处理 严格的区分错误和异常，应该是 Go 编码风格一个最大的特点。在Go中，错误是程序运行的几个预期的结果之一。而异常是未被预料到的错误，即bug，而不是那些在健壮程序中应该被避免的程序错误。正因为如此，在 Go 的代码中你会看到很多类似下面的条件判断。Go 将对错误的处理放在了代码的逻辑控制中，让程序员更多的关注错误。 // 导致失败的原因只有一个，额外的返回值可以是一个布尔值，通常被命名为ok value, ok := cache.Lookup(key) if !ok { // ...cache[key] does not exist… } // 导致失败的原因不止一种时，额外的返回值是error类型， resp, err := http.Get(url) if err != nil{ return nill, err } 错误处理 对于那些将运行失败看作是预期结果的函数，它们会返回一个额外的返回值，通常是最后一个，来传递错误信息。调用者需要处理程序出现的潜在错误。因此Go中大部分函数的代码结构几乎相同，首先是一系列的初始检查，防止错误发生，之后是函数的实际逻辑。 对于函数返回的错误，通常有以下五种处理方式: 传播错误 重新尝试失败的操作 输出错误信息并结束程序 有时，只输出错误信息就足够了，不需要中断程序的运行 直接忽略掉错误 需要注意的是，输出错误信息并结束程序只应在main中执行。对库函数而言，应仅向上传播错误，除非该错误意味着程序内部包含不一致性，即遇到了bug，才能在库函数中结束程序。 异常处理 Go 中的异常称为 Panic。一般而言，当panic异常发生时，程序会中断运行，并立即执行在该goroutine 中被延迟的函数（defer 机制），在Go的panic机制中，延迟函数的调用在释放堆栈信息之前。直接调用内置的panic函数也会引发panic异常，panic函数接受任何值作为参数。 通常来说，不应该对panic异常做任何处理，但有时候我们需要从异常中恢复，此时就需要 Go 的 Recover 机制来捕获异常。 func Parse(input string) (s *Syntax, err error) { defer func() { if p := recover(); p != nil { err = fmt.Errorf(\"internal error: %v\", p) } }() // ...parser... } 如上所示，如果在deferred函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。 通常我们不应该不加区分的恢复所有的panic异常，同时作为被广泛遵守的规范，也不应该试图去恢复其他包引起的panic。安全的做法是有选择性的recover。 为了标识某个panic是否应该被恢复，我们可以将panic value设置成特殊类型。在recover时对panic value进行检查，如果发现panic value是特殊类型，就将这个panic作为errror处理，如果不是，则按照正常的panic进行处理。 func soleTitle(doc *html.Node) (title string, err error) { type bailout struct{} defer func() { switch p := recover(); p { case nil: // no panic case bailout{}: // \"expected\" panic err = fmt.Errorf(\"multiple title elements\") default: panic(p) // unexpected panic; carry on panicking } }() } 最后某些致命错误会导致Go在运行时终止程序，无法恢复，比如内存不足。 ","date":"2021-01-05","objectID":"/posts/program/go/grammar/go_5/:2:3","tags":["go 语法"],"title":"go 函数","uri":"/posts/program/go/grammar/go_5/"},{"categories":["Go"],"content":"go 提供的复合数据类型","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"Go 的类型系统 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:0:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"1. Go 的复合数据类型 接着上一篇，我们来继续讨论 Go 里面的复合数据类型，包括数组、slice、map和结构体。数组和结构体是聚合类型；它们的值由许多元素或成员字段的值组成。slice,map 分别与 Python 中的 array.Array,dict 相对应，它们是 Go 提供给我们容器数据类型。 编程语言提供的复合数据类型应该是数据结构与算法的基础内容，如果你熟悉常用的数据结构，对复合类型的特性和支持的操作应该很容易就能理解。因此接下来的内容，我们会先简单说一说数据结构的特点，然后在介绍它们在 Go 中的实现和支持的操作。 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:1:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"2. 数组 数组应该是最基本的数据结构，简单来说，数组具有如下特性: 数组是一段连续的内存空间，用来存储一组具有相同类型的数据 数组一经创建，大小便不能更改，连续的内存要求元素之间不能出现空洞 数组的特性决定了数组天然支持基于下标的“随机访问”(索引)。Go 中的数组我们需要关注以下几个知识点: 数组的长度是数组类型的一个组成部分，[3]int和[4]int是两种不同的数组类型 数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定 数组的可比性取决于数组的类型是否相同以及数组元素是否可比，只有当两个数组类型相同并且所有元素都是相等的时候数组才相等 下面是数组常用操作的代码示例: // 1. 数组字面量 var q [3]int = [3]int{1, 2, 3} q := [...]int{1, 2, 3} // “...”省略号，表示数组的长度是根据初始化值的个数来计算 r := [...]int{99: ‐1} // 直接按位置初始化，未初始化的为对应类型的零值 // 2. 索引和切片 fmt.Println(q[0]) // print the first element fmt.Println(q[len(q)‐1]) // print the last element, q[2] e := [3]int{1, 2, 3} ff := e[0:2] // 对数组切片返回的是 slice 而不是原数组类型 if ff == e { // missmatch type []int and [3]int } // 3. for 循环迭代 for i, v := range q { fmt.Printf(\"%d %d\\n\", i, v) } // 4. 数组可比性 a := [2]int{1, 2} d := [3]int{1, 2} fmt.Println(a == d) // compile error: cannot compare [2]int == [3]int ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:2:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"3. slice 切片 因为数组的大小固定，类型限定严格，我们通常很少直接使用数组，使用更多的是数组的容器，Go 中数组的容器类型就是 slice (切片)。容器的最主要作用是能够根据元素大小对数组进行扩缩容。因此我们可以从 slice 的组成和扩缩容两个方面去理解 slice。 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:3:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"3.1 slice 组成 Go 的 slice由三个部分构成： 指针: 指针指向第一个slice元素对应的底层数组元素的地址 容量: 容量一般是从 slice 的开始位置到底层数据的结尾位置 长度: 对应slice中元素的数目，长度不能超过容量 需要注意的是，因为 slice 底层数组是可以共享(通常是由于切片行为引起的)，因此slice 指针指向的第一个元素并不一定就是数组的第一个元素。内置的len和cap函数分别返回slice的长度和容量。下面是一个 slice 结构示意图: months := [...]string{1: \"January\", /* ... */, 12: \"December\"} Q2 := months[4:7] summer := months[6:9] 对数组 months 的切片操作返回的是 slice []int，Q2和summer 共用了底层的 months 数组。 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:3:1","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"3.2 slice 扩缩容 slice 扩缩容策略由 append 函数实现，但 append 只能向slice追加元素，Go 并没有删除 slice 中元素的函数。append扩容的过程大体是这样的: 在每次向 slice 添加时，append 会判断当前数组的大小是否足以容纳新增元素，足够则直接插入 如果数组容量不够，append 将创建一个原有数组两倍大小的新数组，并将原数组中的元素拷贝到新数组中去 最后将 slice 中的指针的指向新的底层数组 append 函数可以向 slice 追加多个元素，甚至追加一个slice: var x []int x = append(x, 1) x = append(x, 2, 3) x = append(x, 4, 5, 6) x = append(x, x...) // append the slice x fmt.Println(x) // \"[1 2 3 4 5 6 1 2 3 4 5 6]\" 需要注意的是，通常我们要将 append 的返回值直接赋值给输入的slice变量，这么做与 Go 中函数的参数传值方式有关: Go 中的函数参数是按值传递的，因此传入 append 的是 slice 的副本，但是它们的指针指向了相同的底层数组 如果 append 函数发生了扩容，函数内的 slice 副本将指向新的内存数组，此时 append 函数将不会影响到传入的 slice 变量，为了达到修改 slice 的目的，通常要对输入的slice变量重新赋值 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:3:2","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"3.3 slice 操作 说完了 slice 的实现，我们再来看看 slice 支持的操作: slice 的字面量与数组类似，只是去掉长度声明 对 slice 的切片操作如果超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了slice，新slice的长度会变长 为了避免创建 slice 多次内存分配，内置的 make 函数可以创建指定长度和容量的 slice slice之间不能比较，我们不能使用==操作符来判断两个slice是否含有全部相等元素，slice唯一合法的比较操作是和nil比较 因为 Go 没有提供删除 slice 元素的函数，只能采用覆盖的方式进行 slice 元素删除 下面是 slice 常用操作的代码示例: // 1. slice 字面量 var m = []int{3: 10} // 2. slice 创建函数 // make创建了一个匿名的数组变量，然后返回一个slice make([]T, len) make([]T, len, cap) // same as make([]T, cap)[:len] // 3. slice 与 nil 的比较和转换 if summer == nil { /* ... */ } var s []int // len(s) == 0, s == nil s = nil // len(s) == 0, s == nil s = []int(nil) // len(s) == 0, s == nil，类型转换 s = []int{} // len(s) == 0, s != nil // 4. slice 为空测试，不应该使用 s == nil if len(s) == 0{ } // 5. slice 复制 // copy函数可以方便地将一个slice复制另一个相同类型的slice // copy函数将返回成功复制的元素的个数，等于两个slice中较小的长度 copy(m, s) // 将 s 复制到 m // 6. slice 元素删除 //如果要保持 slice 原来顺序 func remove(slice []int, i int) []int { copy(slice[i:], slice[i+1:]) return slice[:len(slice)‐1] } //如果不用保持原来顺序的话，使用最后元素覆盖删除元素 func remove(slice []int, i int) []int { slice[i] = slice[len(slice)‐1] return slice[:len(slice)‐1] } // 7. slice 模拟栈操作 stack = append(stack, v) // push v top := stack[len(stack)‐1] // top of stack stack = stack[:len(stack)‐1] // pop ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:3:3","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"4. Map 散列表 在Go语言中，一个map就是一个散列表的引用，散列表是映射的一种实现方式，因此要想理清楚散列表，我们要从映射入手。所谓映射就是支持以下方法的键值对: M[k]: 返回键 k 对应的值，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 我列出了 Python 中与之对应的方法，但是 Go 中实现方式有所不同，我们会在下面讲解。散列表是映射高效的实现方式，可以实现 O(1) 时间复杂度的元素查找。那散列表是如何实现的呢？ ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:4:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"4.1 散列表的实现 散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，有三个核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 下面是散列表实现映射的示意图: 限于篇幅的原因，有关散列表的实现，我就不过多解释，不了解的同学可以看看这篇文章散列表实现。这里我们需要关注的是散列表在使用上的限制。 首先，由于映射过程以及散列冲突的存在，所有的编程语言的散列表都会有以下两点要求: key 不可变，如果key 可变，元素的哈希值就会变化，查找就会失败 key 之间可比，当发生散列冲突时，要通过比较进行二次查找 而 Go 对散列表使用更加严格: 散列表中所有的key必须是相同的类型，所有的value也必须是相同的类型，但是 key 和 value 的类型可以不同 因为 Go 中可变的元素都是不可比的，所以上面的条件就退化成 key 必须是支持==比较运算符的数据类型,例如整数、数组或结构体等 虽然浮点数类型也是支持相等运算符比较的，但是将浮点数用做key类型则是一个坏的想法，最坏的情况是可能出现的NaN和任 何浮点数都不相等 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:4:1","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"4.2 map 操作 说完了散列表的实现，接下来我们看看 Go map 支持的操作。在Go语言中，一个map就是一个哈希表的引用，map类型可以写为map[K]V，其中K和V分别对应key和value。与 slice 类似，我们可以使用字面量和 make 来创建 map。 map 支持上面所说的映射操作，但是与 Python 相比 Go map 有以下两个鲜明特点: key 不存在时，执行 M[key]，不会触发异常，而是返回 value 类型对应的零值 map类型的零值是nil，也就是没有引用任何哈希表，map上的查找、删除、len和range循环都可以安全工作在nil值的map上，它们的行为和一个空的map类似。但是向一个nil值的map存入元素将导致一个panic异常 此外和slice一样，map之间也不能进行相等比较；唯一的例外是和nil进行比较。要判断两个map是否包含相同的key和value，我们必须通过一个循环实现。下面 map 操作的代码示例: // 1. 字面量 ages := map[string]int{ \"alice\": 31, \"charlie\": 34, } // 2. 初始化函数 make ages := make(map[string]int) ages[\"alice\"] = 31 ages[\"charlie\"] = 34 // 3. 元素访问与删除 ages[\"alice\"] = 32 fmt.Println(ages[\"alice\"]) // \"32 delete(ages, \"alice\") // remove element ages[\"alice\"] // 元素不存在的判断 if age, ok := ages[\"bob\"]; !ok { /* ... */ } // 判断元素是否存在 // 4. 迭代和遍历，迭代总是随机和无序的 for name, age := range ages { fmt.Printf(\"%s\\t%d\\n\", name, age) } // 有序遍历 import \"sort\" var names []string for name := range ages { names = append(names, name) } sort.Strings(names) for _, name := range names { fmt.Printf(\"%s\\t%d\\n\", name, ages[name]) } // 5. 零值，以及是否为空的比较 var ages map[string]int fmt.Println(ages == nil) // \"true\" fmt.Println(len(ages) == 0) // \"true\" // 6. 两个相同 map 判等 func equal(x, y map[string]int) bool { if len(x) != len(y) { return false } for k, xv := range x { // 注意必须先判断，元素是否存在 if yv, ok := y[k]; !ok || yv != xv { return false } } return true } 最后，Go语言中并没有提供一个set类型，可以通过 map 实现类似set的功能，常用的 map 类型就是map[string]bool。 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:4:2","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"5. 结构体 结构体是一种聚合的数据类型由零个或多个任意类型的值聚合成的实体。每个值称为结构体的成员。结构体是 Go 提供给我们创建自定义类型的载体，下面是一个创建示例: type Employee struct { ID int Name, Address string DoB time.Time Position string Salary int ManagerID int } var dilbert Employee struct 定义了一个结构体，type 为这个结构体定义类型别名，便于引用，这种定义方式与 C 很接近。 在结构体的定义上，Go 中还有下面一些特性: 结构体成员的输入顺序也有重要的意义，拥有相同成员但是成员顺序不同的结构体属于不同的结构体类型 如果结构体成员名字是以大写字母开头的，那么该成员就是导出的；这是Go语言导出规则决定的。一个结构体可能同时包含导出和未导出的成员。 结构体的操作稍显复杂，我们分成下面两块来讲解 结构体通用操作，包括成员变量的引用，结构体的创建和比较 结构体的嵌入和匿名变量，这个是 Go 语言的特性，需要重点关注 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:5:0","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"5.1 结构体通用操作 成员引用 结构体是一个变量，它所有的成员也同样是变量，可以赋值或者取址，然后通过指针访问。结构体变量的成员可以通过点操作符访问，点操作符也可以和指向结构体的指针一起工作： // 通过点操作直接访问 var dilbert Employee dilbert.Salary ‐= 5000 // 可以对成员变量取址，然后访问 position := \u0026dilbert.Position *position = \"Senior \" + *position // promoted, for outsourcing to Elbonia // 点操作也可以直接用在结构体指针上 var employeeOfTheMonth *Employee = \u0026dilbert employeeOfTheMonth.Position += \" (proactive team player)\" // 等同于 (*employeeOfTheMonth).Position += \" (proactive team player)\" 结构体字面量 结构体字面值有两种语法格式: 以结构体成员定义的顺序为每个结构体成员指定一个面值，这种方式在结构定义发生变化时就会导致编译错误，因此这种方式只在定义结构体的包内部使用，或者是在较小的结构体中使用，这些结构体的成员排列比较规则 以成员名字和相应的值来初始化，可以包含部分或全部的成员,如果成员被忽略的话将默认用零值 需要注意的是两种不同形式的写法不能混合使用。而且，你不能企图在外部包中用第一种顺序赋值的技巧来偷偷地初始化结构体中未导出的成员。 // 方式一: 按照成员定义顺序，依次赋值 type Point struct{ X, Y int } p := Point{1, 2} // 方式二: 以成员名字和相应的值来初始化 f := Point{X: 1, Y: 2} // 未导出变量，无法赋值 package p type T struct{ a, b int } // a and b are not exported package q import \"p\" var _ = p.T{a: 1, b: 2} // compile error: can't reference a, b var _ = p.T{1, 2} // compile error: can't reference a, b 除了字面量外，我们还可以用前面介绍的 new 函数来创建结构体变量 pp := \u0026Point{1, 2} pp := new(Point) *pp = Point{1, 2} 结构体的零值与比较 结构体类型的零值是每个成员都是零值。如果结构体没有任何成员的话就是空结构体，写作struct{}。它的大小为0，也不包含任何信息，通常用作占位。 如果结构体的全部成员都是可以比较的，那么结构体也是可以比较的。可比较的结构体类型和其他可比较的类型一样，可以用于map的key类型。 type address struct { hostname string port int } hits := make(map[address]int) hits[address{\"golang.org\", 443}]++ ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:5:1","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"5.2 结构体的嵌入与匿名变量 结构体嵌入 结构体嵌入是 Go 语言提供的类似类继承机制，形式上是让一个命名的结构体包含另一个结构体类型的匿名成员，目的是实现通过简单的点运算符x.f来访问匿名成员链中嵌套的x.d.e.f成员的机制。说起来很复杂，举个例子。考虑一个图形系统，我们需要定义点，线，圆。显然圆可以在点即园心的基础上添加半径来表示。在 Go 中可以使用下面的结构体表示这样的结构。 // 点 type Point struct { X, Y int } // 圆 type Circle struct { Center Point Radius int } type Wheel struct { Circle Circle Spokes int } // 创建圆 var w Wheel w.Circle.Center.X = 8 w.Circle.Center.Y = 8 w.Circle.Radius = 5 w.Spokes = 20 如上所示，现在想访问Wheel的结构体成员 X 将变的异常繁琐。而结构嵌入就是为了在满足上面结构不变的情况，实现 w.X 成员快速访问。结构体声明如下所示: type Point struct { X, Y int } type Circle struct { Point // 匿名成员 Radius int } type Wheel struct { Circle // 匿名成员 Spokes int } var w Wheel w.X = 8 // equivalent to w.Circle.Point.X = 8 w.Y = 8 // equivalent to w.Circle.Point.Y = 8 w.Radius = 5 // equivalent to w.Circle.Radius = 5 w.Spokes = 20 Point，Circle 此时为匿名成员。所谓匿名成员，就是只声明一个成员对应的数据类型而不指名成员的名字。匿名成员并不是没有名字，其名字就是命名的类型名字，但是这些名字在点操作符中是可选的。上面 w.Circle.Point.X = 8 这样的访问方式依旧是合法的。 不幸的是，结构体字面值并没有简短表示匿名成员的语法， 因此下面的语句都不能编译通过。结构体字面值必须遵循形状类型声明时的结构 // 错误 w = Wheel{8, 8, 5, 20} // compile error: unknown fields w = Wheel{X: 8, Y: 8, Radius: 5, Spokes: 20} // compile error: unknown fields // 正确 w = Wheel{Circle{Point{8, 8}, 5}, 20} w = Wheel{ Circle: Circle{ Point: Point{X: 8, Y: 8}, Radius: 5, }, Spokes: 20, // NOTE: trailing comma necessary here (and at Radius) } 匿名变量的使用要求 需要注意的是 Go 对匿名成员的使用存在一些约束: 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针 因为匿名成员也有一个隐式的名字，因此不能同时包含两个类型相同的匿名成员，这会导致名字冲突 因为成员的名字是由其类型隐式地决定的，所有匿名成员也有可见性的规则约束 比如将上面改成小写字母开头的point和circle），此时在包内依旧可以使用 w.X = 8；但是在包外部，因为circle和point没有导出不能访问它们的成员，因此简短的匿名成员访问语法也是禁止的。 匿名结构的可见性只与属性和方法的获取的表达式有关，比如将上面改成小写字母开头的point和circle），在包外部不能通过 w.point.X 访问成员 X，但是可以通过 w.X 直接访问成员 X。下面是另一个例子: //1. pkg 包内定义 animal 和 Dog package pkg type animal struct { Name string } type Dog struct { animal Weight int } func NewDog() Dog { return Dog{animal{\"aaa\"}, 100} } func (g Dog) GetName() string { return g.Name } func (g *Dog) GetWeight() int { return g.Weight } // 2 mian 包内使用 package main import ( \"fmt\" \"mygo/pkg\" ) func main() { g := pkg.NewDog() fmt.Printf(\"%T, %#v\\n\", g, g) fmt.Println(g.Weight) // 注意: 此处我们可以直接访问 g.Weight fmt.Println(g.Name) fmt.Printf(\"%T\\n\", (*pkg.Dog).GetName) // func(*pkg.Dog) string fmt.Printf(\"%T\\n\", (*pkg.Dog).GetWeight) // func(*pkg.Dog) int fmt.Printf(\"%T\\n\", pkg.Dog.GetName) // func(pkg.Dog) string // fmt.Printf(\"%T\\n\", pkg.Dog.GetWeight) } 最后匿名成员并不要求是结构体类型；其实任何命名的类型都可以作为结构体的匿名成员。但是为什么要嵌入一个没有任何子成员类型的匿名成员类型呢？答案是匿名类型的方法集。 简短的点运算符语法可以用于选择匿名成员嵌套的成员，也可以用于访问它们的方法。实际上，外层的结构体不仅仅是获得了匿名成员类型的所有成员，而且也获得了该类型导出的全部的方法。 这个机制可以用于将一个有简单行为的对象组合成有复杂行为的对象。组合是Go语言中面向对象编程的核心。我们在下一章将方法时会再来讨论。 ","date":"2021-01-04","objectID":"/posts/program/go/grammar/go_4/:5:2","tags":["go 语法"],"title":"go 复合数据类型","uri":"/posts/program/go/grammar/go_4/"},{"categories":["Go"],"content":"go 的基础数据类型","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"Go 的类型系统 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:0:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"1. Go 中的数据类型 Go语言将数据类型分为四类：基础类型、复合类型、引用类型和接口类型。基础类型，包括：数字、字符串和布尔型。复合数据类型包括数组和结构体(通过组合简单类型，来表达更加复杂的数据结构)。引用类型包括指针、切片、字典、函数、通道，虽然数据种类很多，但它们都是对程序中一个变量或状态的间接引用。函数和通道并不属于我们通常所说的数据类型，我们放在后面相关章节来介绍。 对于大多数编程语言来说，基础类型以及它们之上的可用运算符都是类似，更加需要我们注意的是，编程语言提供给我们的数据容器以及操作它们的方式。因此我们分成以下几个部分来讲解 Go 的类型系统。 数值与布尔型 字符串与编码 数组与结构体 切片 字典 本节我们先来介绍 Go 中的基本数据类型，即数值，布尔值和字符串。在介绍这些数据类型之前，我们先来谈谈变量类型的含义，这有助于加深我们对编程语言本身的理解。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:1:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"1.1 变量的类型 无论什么数据，在存储器内都是 0-1，那数据是数值还是字符完全取决于我们对这些二进制数据的解释。变量的类型就是用来定义对应存储值的属性特征，即它们在内部是如何表示的，支持的操作符，以及关联的方法集等。 而在一个编程语言类型系统中，除了内置的变量类型外，还有如下一些问题: 自定义类型 定义新的类型名称(类型重命名) 类型转换 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:1:1","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"1.2 自定义类型 自定义类型允许我们在编程语言底层类型的基础上定义更加复杂的类型，它是面向对象编程的基础。在 Go 中自定义类型就是使用结构体。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:1:2","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"1.2 类型重命名 在任何程序中都会存在一些变量有着相同的内部结构，但是却表示完全不同的概念。例如，一个int类型的变量可以用来表示一个循环的迭代索引、或者一个时间戳、或者一个文件描述符。类型重命名就是为分隔不同概念的类型。新的类型名称使用类型声明语句创建。Go 的类型声明语法如下所示: type 类型名字 底层类型 新的类型和底层类型具有相同的底层结构，支持和底层类型相同的运算符。但是新类型与底层类型以及基于相同底层类型的不同新类型，是完全不不同的数据类型。 import \"fmt\" type Celsius float64 // 摄氏温度 type Fahrenheit float64 // 华氏温度 // 因为 Fahrenheit，float64，Celsius 是完全不同的类型，所以它们不能直接比较 // compile error: type mismatch fmt.Println(Fahrenheit(1.0) == float64(1.0)) fmt.Println(Fahrenheit(1.0) == Celsius(1.0)) ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:1:3","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"1.2 类型转换 对于每一个类型T，都有一个对应的类型转换操作T(x)，用于将x转为T类型。如果T是指针类型，可能会需要用小括弧包装T，比如 (*int)(0)。 在编程语言中，不同类型的变量之间是不能进行直接赋值和比较的，要这样做就需要显示或隐式的类型转换。对于不同编程语言而言，有不同的类型转换规则，但大多数规则都是类似。在 Go 中: 数值之间的转类型转换有一套特定规则，这个规则在不同的编程语言中是一样的，比如将浮点数转换为整数会损失小数部分 显示的类型转换T(x)要求 T 和 x 具有相同的底层基础类型或指向相同底层结构的指针类型；对于数据容器而言需要它们有类似的实现，比如可以将一个字符串转为 []byte类型 自定义的新类型名称，不会自动应用底层类型的隐式类型转换规则，一个命名类型的变量只能和另一个有相同类型的变量，或有着相同底层类型的未命名类型的值之间做比较；依赖相同底层类型的不同自定义类型之间想要进行比较或赋值必须进行显示的类型转换。 import \"fmt\" // 自定义类型与其底层类型不可比较 type tt int fmt.Println(tt(1) \u003e int(0)） // compile error: type mismatch var c Celsius var f Fahrenheit fmt.Println(c == 0) // \"true\" fmt.Println(f \u003e= 0) // \"true\" // 依赖相同底层类型的不同自定义类型不可比较 fmt.Println(c == f) // compile error: type mismatch fmt.Println(c == Celsius(f)) // \"true\"! 说了这么多，接下来我们开始正式讲解 Go 中的数据类型。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:1:4","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"2. 数值 Go语言的数值类型包括几种不同大小的整数、浮点数和复数，还有一些为特定用途定义的类型别名。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:2:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"2.1 整数 整数包括如下几种类型及类型别名： 类型 大小 含义 uint8 8 无符号 8 位整型 uint16 16 无符号 16 位整型 uint32 32 无符号 32 位整型 uint64 64 无符号 64 位整型 uint 32 或 64位 平台相关，取决于CPU平台机器字大小 int 32 或 64位 平台相关，取决于CPU平台机器字大小 int8 8 有符号 8 位整型 int16 16 有符号 16 位整型 int32 32 有符号 32 位整型 int64 64 有符号 64 位整型 byte 8, int8的别名 表示原始的二进制数据 rune 32, int32的别名 Unicode字符，表示一个Unicode码点 uintptr 无符号整数，没有明确指定大小 用于存放一个指针，GO 底层使用 其中int是应用最广泛的数值类型。内置的len函数返回一个有符号的int，虽然使用uint无符号类型似乎是一个更合理的选择。len函数返回有符号 int ，可以使我们像下面这样处理逆序循环。 medals := []string{\"gold\", \"silver\", \"bronze\"} for i := len(medals) ‐ 1; i \u003e= 0; i‐‐ { fmt.Println(medals[i]) // \"bronze\", \"silver\", \"gold\" } 所以尽管Go语言提供了无符号数和运算，并且在数值本身不可能出现负数的情况下，我们还是倾向于使用有符号的int类型。出于这个原因，无符号数往往只有在位运算或其它特殊的运算场景才会使用，就像bit集合、分析二进制文件格式或者是哈希和加密操作等。它们通常并不用于仅仅是表达非负数量的场合。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:2:1","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"2.2 整数的运算符 Go 的整数支持如下操作符号，其中大多数与其他语言类似，只有一个比较特殊x \u0026^ y，它表示将 x 中与 y 对应的且 y 中等于 1 的位置为 0，即位清空(AND NOT) # 优先级递减 * / % # 算数运算符 \u003c\u003c \u003e\u003e \u0026 \u0026^ # 位运算符 + ‐ # 算数运算符 | ^ # 位运算符 == != \u003c \u003c= \u003e \u003e= # 比较运算符 \u0026\u0026(AND) ||(or) # 逻辑运算符 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:2:2","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"2.3 浮点数 Go语言提供了两种精度的浮点数，float32 和 float64 。浮点数的范围极限值可以在math包找到。常量math.MaxFloat32表示float32能表示的最大数值，对应的 float64 为 math.MaxFloat64。 一个float32类型的浮点数可以提供大约6个十进制数的精度，而float64则可以提供约15个十进制数的精度；通常应该优先使用float64类型。小数点前面或后面的数字都可能被省略（例如.707或1.）。很小或很大的数最好用科学计数法书写，通过e或E来指定指数部分。 // float32的有效bit位只有23个，整数大于23bit表示范围时，将出现误差 var f float32 = 16777216 // 1 \u003c\u003c 24 fmt.Println(f == f+1) // \"true\"! const a = .909 const Avogadro = 6.02214129e23 // 阿伏伽德罗常数 const Planck = 6.62606957e‐34 // 普朗克常数 math包中除了提供大量常用的数学函数外，还提供了IEEE754浮点数标准中定义的特殊值的创建和测试。 v := math.Inf(1) // 返回正无穷 p := math.Inf(-1) // 返回负无穷 n := math.NaN() // 返回 NaN 非数，一般用于表示无效的除法操作结果0/0或Sqrt(­1). t ：= math.IsNaN(n) // 测试是否为 NaN // NaN和任何数都是不相等的 nan := math.NaN() fmt.Println(nan == nan, nan \u003c nan, nan \u003e nan) // \"false false false\" ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:2:3","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"2.4 复数 Go语言提供了两种精度的复数类型：complex64 和 complex128，分别对应 float32 和 float64 两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部。复数的字面量使用 i 后缀。 var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // \"(‐5+10i)\" fmt.Println(real(x*y)) // \"‐5\" fmt.Println(imag(x*y)) // \"10\" // 复数的字面量 x := 1 + 2i y := 3 + 4i ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:2:4","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"3. 布尔值 Go 布尔类型的值只有两种：true 和 false，if 和 for 语句的条件部分都是布尔值。需要特别注意的是 在 Go 中布尔之值不会与其他任何类型作隐式转换，将其他类型的值用在 if 或 for 中作为条件判断时，必须作显示的类型转换。 func itob(i int) bool { return i != 0 } b := 0 i := 0 if itob(b) { i = 1 } ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:3:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4. 字符串 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.1 字符串操作 创建字符串最简单的方式是字符串字面量。在 Go 中，单个字符的字面量使用单引号，字符串字面量使用双引号，原生字符串使用反引号。所谓原生字符类似于 Python 中的 r\"\" 用于消除字符串中的所有转义操作。Go 的原生字符甚至可以消除换行，实现跨行，所以原生字符广泛使用再正则表达式，HTML模板、JSON面值以及命令行提示信息中。 与 Python 将大多数字符串操作作为字符串对象的方法不同，Go 大多数的字符串操作都在 strings 包，我们将这部分内容放在后面专门介绍，先来看看Go 提供的字符串基础操作。下面是一些代码示例: // 原生字符串 const GoUsage = `Go is a tool for managing Go source code. Usage: go command [arguments] ` s := \"hello, world\" // 1. len 函数获取字符串长度 fmt.Println(len(s)) // \"12\" // 2. 索引 fmt.Println(s[0], s[7]) // \"104 119\" ('h' and 'w') // 3. 切片 fmt.Println(s[0:5]) // \"hello // 4. + 拼接 fmt.Println(\"goodbye\" + s[5:]) // \"goodbye, world\" // 5. 不可修改 s[0] = 'L' // compile error: cannot assign to s[0] 虽然字符串作为一个基本的数据类型被几乎所有的编程语言所支持，但是字符串本身确是很复杂。而复杂的地方至少有如下两点: 字符串的实现 字符的编码问题 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:1","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.1 字符串的实现 上面是字符串以及切片操作结果的示意图，在 Go 中，字符串是一个不可改变的字节序列，底层是一个字符数组，一个字符串可认为由两个部分构成:指针、长度 指针指向第一个字符对应的底层数组元素的地址 长度对应字符串中字符的个数 字符串的底层数组位于受保护的内存中，不能被修改，因此字符串是不可变的 对字符串变量进行重新赋值，不会改变字符串的底层数组，而只是改变了字符串中的指针的指向 不变性意味两个字符串可以安全的共享相同的底层数据，这使得字符串复制和切片不会发生实际的复制行为，而是直接共享原有的底层字符数组，因此操作非常迅速。 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:2","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.3 字符集 在上面关于字符串的实现中，我们忽略了一个问题，即如何把字符串中的字符保存在一个数组中。我们知道在计算机上保存的数据只有二进制的 0 和 1，显然计算机没办法直接保存每个字符，于是就有了字符集的概念。 对于字符集以及字符的编码和解码，我是这样理解的: 字符集中最重要的概念就是码表，其作用是将每个字符与一个特定的数字对应起来，用特定的数字(又称码点)来表示特定的字符，因此码表就是字符集能表示的字符范围 有了码表，并没有解决保存字符的问题，显然就算是数字也要保存为整数的二进制格式。对于不同字符集而言，码点到特定的二进制也有一套特定的转换规则 因此，字符集实现了字符 --\u003e 码点 ---\u003e 码点二进制值的转换过程，码点 ---\u003e 码点二进制值被称为编码，反过来就是解码 有了上面的说明，就能解释清楚下面两个问题: ASCII 字符集 与 Unicode 字符集区别: ASCII字符集使用7bit来表示一个码点，而 Unicode 使用32bit表示一个 Unicode 码点，Unicode 显然能表示更大的字符范围 UTF8 编码与 UTF32 编码的区别: UTF32 编码直接将每个 Unicode 码点保存为 int32 的整数，而UTF8 会根据Unicode码点变长编码成二进制，它们都表示 Unicode 字符集，但是编码规则不同 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:3","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.4 字符串和 []rune Go语言的源文件采用UTF8编码，因此程序运行之后，保存在字符数组内的是 UTF8 编码的二进制值。因此前面我们所讲的字符串基础操作，操作的其实是UTF8 编码的每个字节，并不是我们理解的字符。为了处理真实的字符，我们需要对字符串进行解码。Go 将 Unicode 码点表示为 rune 整数类型，因此字符串解码后的类型就是 []rune。下面就是Go 中字符编码解码的一些代码示例: // 1. 字符串基础操作操作的是 UTF8 中的字节 import \"unicode/utf8\" s := \"Hello, 世界\" fmt.Println(len(s)) // \"13\" fmt.Println(utf8.RuneCountInString(s)) // \"9\" // 2. unicode 提供了 UTF8 的解码函数 for i := 0; i \u003c len(s); { r, size := utf8.DecodeRuneInString(s[i:]) fmt.Printf(\"%d\\t%c\\n\", i, r) i += size } // 3. range 会自动对字符串解码 for i, r := range \"Hello, 世界\" { fmt.Printf(\"%d\\t%q\\t%d\\n\", i, r, r) } // 4. []rune 字符串的类型转换 s := \"プログラム\" fmt.Printf(\"% x\\n\", s) // \"e3 83 97 e3 83 ad e3 82 b0 e3 83 a9 e3 83 a0\" // 字符串 --\u003e []rune r := []rune(s) fmt.Printf(\"%x\\n\", r) // \"[30d7 30ed 30b0 30e9 30e0] // string 函数： []rune ---\u003e 字符串 fmt.Println(string(r)) // \"プログラム // 5. 生成Unicode码点字符的UTF8字符串 fmt.Println(string(65)) // \"A\", not \"65\" fmt.Println(string(0x4eac)) // \"京\" ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:4","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.5 字符串和 []byte 一个字符串是包含的只读字节数组，一旦创建，是不可变的。相比之下，一个字节slice(即 []byte，下一节我们会详述)的元素则可以自由地修改。字符串和字节slice之间可以相互转换： s := \"abc\" b := []byte(s) s2 := string(b) ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:5","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"4.6 字符串相关类型的包 标准库中有四个包对字符串处理尤为重要：bytes、strings、strconv和unicode包 strings包提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能。 bytes包也提供了很多类似功能的函数，但是针对和字符串有着相同结构的[]byte类型 strconv包提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换 unicode包提供了IsDigit、IsLetter、IsUpper和IsLower等类似功能，它们用于给字符分类，每个函数有一个单一的rune类型的参数，然后返回一个布尔值 下面是字符串与数值转换的代码示例，我们会在后面专门讲解这些包的实现和使用。 // 数值转字符串 x := 123 y := fmt.Sprintf(\"%d\", x) fmt.Println(y, strconv.Itoa(x)) // \"123 123\" // 数值的进制转换 fmt.Println(strconv.FormatInt(int64(x), 2)) // \"1111011\" s := fmt.Sprintf(\"x=%b\", x) // \"x=1111011 // 字符串转数值 x, err := strconv.Atoi(\"123\") // x is an int y, err := strconv.ParseInt(\"123\", 10, 64) // base 10, up to 64 bits ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:4:6","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"5. 常量 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:5:0","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"5.1 常量的类型 在讲常量之前，先问大家一个问题，你知道字面量，常量，变量，字面量类型之间的区别么？ 字面量是编程语言提供的用来创建特定值的快捷方式，因此字面量也有类型，特定的字面量代表什么类型，完全有编程语言决定。因此对于像下面的赋值语句来说，在字面量类型和变量类型之间发生了类型转换。 var f float64 = 3 常量和变量都是变量，但是相比与变量，常量有以下特点: 常量的值不可变，并且常量的类型只能是基础类型：boolean、string或数字 常量表达式的值在编译期计算，而不是在运行期，因此常量可以是构成类型的一部分，例如用于指定数组类型的长度 因为常量也是变量，所以常量通常有确定的类型，但Go语言的常量有个不同寻常之处， Go 中的常量可以没有一个明确的基础类型。 首先在 Go 中，有六种无类型的字面量，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。例如0、0.0、0i和’\\u0000’分别对应无类型的整数、无类型的浮点数、无类型的复数和无类型的字符。 其次在如下不带类型声明的常量声明语句中，不会发生隐式类型转换，常量的类型依旧为无类型的整数。 const deadbeef = 0xdeadbeef // untyped int with value 3735928559 为了便于描述下面我们将无类型的字面量和常量统称为无类型常量，这些无类型常量有诸多好处。 编译器为这些无类型常量提供了比基础类型更高精度的算术运算。通过延迟明确常量的具体类型，无类型的常量不仅可以提供更高的运算精度，而且可以直接用于更多的表达式而不需要显式的类型转换。 只有常量可以是无类型的。当一个无类型的常量被赋值给一个变量的时候，或者出现在有明确类型的变量声明的右边，无类型的常量将会被隐式转换为对应的类型，如果转换合法的话。对于一个没有显式类型的变量声明（包括简短变量声明），字面量的形式将隐式决定变量的默认类型，Go 有一个明确的转换规则。如果要给变量一个不同的类型，我们必须显式地将无类型的常量转化为所需的类型，或给声明的变量指定明确的类型。 // 1. 常量可以无类型，无类型常量可以提供更高的精度 const ( deadbeef = 0xdeadbeef // untyped int with value 3735928559 a = uint32(deadbeef) // uint32 with value 3735928559 b = float32(deadbeef) // float32 with value 3735928576 (rounded up) c = float64(deadbeef) // float64 with value 3735928559 (exact) d = int32(deadbeef) // compile error: constant overflows int32 e = float64(1e309) // compile error: constant overflows float64 f = uint(‐1) // compile error: constant underflows uint ) // 2. 无类型常量，可以直接应用在更多的表达式中，无需显示类型转换 var f float64 = 3 + 0i // untyped complex ‐\u003e float64 f = 2 // untyped integer ‐\u003e float64 f = 1e123 // untyped floating‐point ‐\u003e float64 f = 'a' // untyped rune ‐\u003e float64 // 3. 有类型声明时，无类型常量将根据类型隐式类性转换 var x float32 = math.Pi var y float64 = math.Pi var z complex128 = math.Pi // 4. 无类型声明时，根据字面量形式，决定变量类型 i := 0 // untyped integer; implicit int(0) r := '\\000' // untyped rune; implicit rune('\\000') f := 0.0 // untyped floating‐point; implicit float64(0.0) c := 0i // untyped complex; implicit complex128(0i) var i = int8(0) var i int8 = 0 ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:5:1","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"5.2 常量批量声明 最后，Go 为常量的批量声明提供了一些便捷方式，下面是代码示例: // 1. 批量声明多个常量 const ( e = 2.71828182845904523536028747135266249775724709369995957496696763 pi = 3.14159265358979323846264338327950288419716939937510582097494459 ) const ( a = 1 b // 省略初始化表达式，表示使用前面常量的初始化表达式写法， b=1 c = 2 d // d=2 ) // 2. iota常量生成器初始化，用于生成一组以相似规则初始化的常量 type Weekday int const ( Sunday Weekday = iota // 在第一个声明的常量所在的行，iota将会被置为0， Monday // 然后在每一个有常量声明的行加一， 1 Tuesday // 2 Wednesday // 3 Thursday Friday Saturday ) const ( _ = 1 \u003c\u003c (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 \u003c\u003c 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 \u003c\u003c 64) YiB // 1208925819614629174706176 ) ","date":"2021-01-03","objectID":"/posts/program/go/grammar/go_3/:5:2","tags":["go 语法"],"title":"go 基础数据类型","uri":"/posts/program/go/grammar/go_3/"},{"categories":["Go"],"content":"go 变量与流程控制语法","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"Golang Hello World! ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:0:0","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"1. Hello World 抛开数据结构，代码封装和复杂的库文件，我们接触一门新语言的第一步可能就是学会这门语言的基础语法。下面是我写的 go 的一个 “Hello World” 程序。在这个简单的代码中包含了很多 Go 基础语法的内容: 变量及常量的命名，声明和创建 条件判断和循环 变量的生命周期与作用域 下面我们就分成这几块来讲讲 Go 的基础语法。 package main import \"fmt\" const defaultUser = \"unsigned\" func main() { name := \"A\" if name == defaultUser { fmt.Println(\"Helll man\") } else { fmt.Println(\"Hey it is you\") } num := 100 r := 0 for i := 0; i \u003c= num; i++ { r += i } fmt.Println(r) } ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:1:0","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"2. 变量及常量的命名，声明和创建 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:2:0","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"2.1 命名规则 几乎所有的编程语言变量，常量，函数以及类型的命名规则都是相同的，即一个名字必须以一个字母或下划线开头，后面可以跟任意数量的字母、数字或下划线。 Go 与众不同的是名称中可以包含Unicode字母(不建议使用)，并且使用名字的开头字母的大小写决定了名字在包外的可见性。关于变量的导出我们会在模块的相关内容详述。 习惯上，Go语言程序员推荐使用驼峰式命名。 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:2:1","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"2.2 声明和创建 Go语言主要有四种类型的声明语句：var、const、type和func，分别对应变量、常量、类型和函数实体对象的声明。我们先说变量以及常量。 与 Python 这种动态语言不同的是，Go 是静态语言，变量必须先声名才能使用。Go 中变量可以看成一个“容器”，一个变量对应一个保存了变量对应类型值的内存空间；变量一经声明，其类型就不能再改变。下面是 Go 中声明和创建变量的几种方式: //方式一: var 声明语句 var name string = \"abc\" var i, j, k int var b, f, s = true, 2.3, \"four\" //方式二: 函数内的短变量声明，用于局部变量的声明和初始化 t := 10 i, j := 0, 1 //方式三: new 函数，创建变量，并返回对应变量的指针 p := new(int) // 此处创建了两个变量: new 函数创建的匿名变量，以及指向匿名变量的指针变量 p *p = 2 var var声明语句可以创建一个特定类型的变量，然后给变量附加一个名字，并且设置变量的初始值。对于 var 变量名字 类型 = 表达式，“类型”或“= 表达式”两个部分可以省略其中的一个。 如果省略的是类型信息，那么将根据初始化表达式来推导变量的类型信息。 如果初始化表达式被省略，那么将用零值初始化该变量，规则如下 数值类型变量对应的零值是0 布尔类型变量对应的零值是false 字符串类型对应的零值是空字符串 接口或引用类型（包括slice、指针、map、chan和函数）变量对应的零值是nil 数组或结构体等聚合类型对应的零值是每个元素或字段都是对应该类型的零值 常量的声明和创建使用 const 声明语句，用法与 var 类似。 短变量声明 短变量声明语句用在函数内，用于声名和初始化局部变量，语法为变量名:=表达式，变量的类型根据表达式自动推导。Go 的短变量声明有一些微妙之处: 首先“:=”是一个变量声明语句，而“=”是一个变量赋值操作 其次，简短变量声明左边的变量可以包含已经声明过的变量，对于这些变量将只是赋值，而不是再声明 最后，简短变量声明语句中必须至少要声明一个新的变量否则无法通过编译 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:2:2","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"new 函数 new 是 Go 预定义的一个函数，new(T)将创建一个T类型的匿名变量，初始化为T类型的零值，然后返回变量地址。 用new创建变量和普通变量声明语句方式创建变量没有什么区别，除了不需要声明一个临时变量的名字外。因为 new 只是一个普通函数，因此可以使用在任何函数可用的地方，甚至new名字可以被重定义其他类型。 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:2:3","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"3. 条件判断和循环 看完了变量创建，我们再来看看 Go 为我们提供的逻辑控制语句: if, switch, for。Go 没有 while 语句，但是 for 语句包含了 while 语句的功能。除了 if 外，switch 和 for 的用法都不简单。 除了这些基础的逻辑控制语句外，Go 还有一个特殊的与 Go 高并发相关的多路复用器 select。 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:3:0","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"3.1 if Go 应该是类 C 风格的语言，使用 {} 来分隔代码块。一个完整的 if 语句如下所示: if r == 0 { fmt.Println(\"aaa\") } else if r == 1 { fmt.Println(\"bbbb\") } else { fmt.Println(\"cccc\") } ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:3:1","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"3.2 switch switch 是多分支条件判断的便捷语法，用于基于不同条件执行不同动作，Go 的 switch 有如下三种使用方式。 //方式一: 变量值判断 switch var1 { case v1: // var1 变量与 case 语句中的值类型必须相同 ... case v2,v3: // 逗号分隔表示可匹配多个值 ... default: ... } // 方式二: 条件判断的变形 switch { case condition1: ... case condition2, condition3: // 逗号分隔表示可匹配多个条件 ... default: ... } // 方式三: type-switch 用来判断某个 interface 变量中实际存储的变量类型 // 我们会在后面讲接口类型时详述 switch x.(type) { case type1: .... case type2: .... default: .... } 不同语言的 switch 语句差异很大，Go 的 switch 有如下特点: switch 语句的执行过程是从上直下逐一测试，直到匹配就会停止 每个 case 分支的最后不需要再加break，即默认只会执行第一个匹配到的 case 分支 Python 中没有 switch 语句，shell 脚本则必须在每个 case 分支之后添加 break，否则第一次匹配成功后后，会继续匹配之后的 case 分支。 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:3:2","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"3.3 select select 类似于用于通信的switch语句，它的一个使用示例如下所示: func main() { var c1, c2 chan int var i1, i2 int select { case i1 = \u003c-c1: fmt.Printf(\"received \", i1, \" from c1\\n\") case c2 \u003c- i2: fmt.Printf(\"sent \", i2, \" to c2\\n\") default: fmt.Printf(\"no communication\\n\") } 在 select 中: 每个case必须是一个通信操作，要么是发送要么是接收 所有channel表达式都会被求值，如果有多个 case 可以运行，select会随机执行一个可运行的case 如果没有case可运行，此时 如果有default子句，则执行该语句，defalut 子句应该总是可运行的 如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:3:3","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"3.3 for Go 的 for 循环有四种常见的使用方式，如下所示。最特殊的是第四种 for 循环的 range 格式，它可以对 slice、map、数组、字符串等进行迭代循环。 //方式一: 典型的类 C for 循环 for init; condition; post { } //方式二: 类 while 循环 for condition { } //方式三: 无限循环 for { } //无限循环的另一种方式 for true { } //方式四: 类Python 的迭代循环 for index, value := range oldMap { // index: 索引 // value: 索引对应的值 } ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:3:4","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"4. 变量的生命周期与作用域 变量的生命周期指的是在程序运行期间变量有效存在的时间间隔，变量作用域是指源代码中可以有效使用这个名字的范围。虽然我将变量的生命周期与作用域放在一起，但是其实它们之间并没有什么联系。声明语句的作用域对应的是一个源代码的文本区域；它是一个 编译时的属性。一个变量的生命周期是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用；是一个运行时的概念。 Go 与 Python 类似，通过引用计数的方式，解释器会自动实现对象内存的分配和释放。变量的生命周期取决于变量是否可达，即其引用计数是否为 0，而与变量的作用域无关。虽然大多数位于函数内的局部变量的生命周期都是函数调用的存续区间，但是函数内的局部变量可以\"逃逸\"成为全局变量，或者从函数返回，从而延长生命周期。 变量的作用域取决于变量声明语句所在的语法块(又称词法域)，语法块通常由花括号显示限定，除此之外还有一些特殊的语法块。对于 Go 作用域从大到小依次是: 整个源代码，称为全局语法块 每个包的包语法块 每个源文件的源文件级的语法块 由显示花括号限定的由外而内的语法块 对于 if,for,switch,select 还有隐式的语法块 一个程序可能包含多个同名的声明，只要它们在不同的作用域。位于内部作用域的变量声明显然会覆盖外部的同名变量。对于大多数程序的作用于而言，都有类似规则。而 Go 比较特殊的是 if,for,switch,select引入的隐式作用域。 if, for 等的隐式作用域 if x := f(); x == 0 { fmt.Println(x) } else if y := g(x); x == y { fmt.Println(x, y) } else { fmt.Println(x, y) } fmt.Println(x, y) // compile error: x and y are not visible here 在上面的示例中存在多个作用域，从大到小依次是: 全局作用域 外层 if 语句条件部分创建隐式词法域 外层 if 语句花括弧包含的显式作用域 内层 if 语句条件部分创建隐式词法域 ….. 因此内层 if 语句的条件测试部分，能访问到外层 if 语句条件部分声明的变量 x。for 语句循环的初始化部分，switch 语句的条件测试部分都会引入类似的隐式作用域。 变量的作用域问题说起来比较复杂，但是大多数情况下，只要我们不在不同的作用域内声明同名变量，导致变量覆盖，基本上都不会现问题。但是在 Go 中要特别注意短变量声明语句的作用域。 在下面的示例中，虽然cwd在外部已经声明过，但是 := 语句还是将cwd和err重新声明为新的局部变量。因为内部声明的cwd将屏蔽外部的声明，因此上面的代码并不会正确更新包级声明的cwd变量。 var cwd string func init() { cwd, err := os.Getwd() // compile error: unused: cwd if err != nil { log.Fatalf(\"os.Getwd failed: %v\", err) } } // 正确做法 var cwd string func init() { var err error # 单独声明 err 变量 cwd, err = os.Getwd() if err != nil { log.Fatalf(\"os.Getwd failed: %v\", err) } } 最后，Go 变量遵循先声明后使用的规则，但是在包级别，声明的顺序并不会影响作用域范围，因此一个先声明的可以引用它自身或者是引用后面的一个声明，这可以让我们定义一些相互嵌套或递归的类型或函数。 ","date":"2021-01-02","objectID":"/posts/program/go/grammar/go_2/:4:0","tags":["go 语法"],"title":"go 变量及流程控制","uri":"/posts/program/go/grammar/go_2/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的第一部分-语法","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"如果编程的世界是海贼王里的\"大航海时代\", go 语言可能就是\"草帽海贼团\" ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:0:0","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"1. 要去学 Go 了 学习和使用 Python 有三四年,好想学一门新语言,打算学 Go。为什么是 Go，其实更想学 Rust。但是 Go 有谷歌这个大佬，背靠k8s，显然学 Go 好处大大的。其实也无所谓，哪天想学 Rust，就拿来看看对比着学可能更快。当然学 Go 还有另一个重要原因，想转运维开发。 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:1:0","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"2. 怎么学 Go 因为已经不是第一次学编程了，之前也看过一段时间 C，想看看在学习了编程这么长时间之后，在编程领域的学习能力相比于一开始有没有提升。所以这次打算从语言特性的角度出发，有目的性的对比学习，看看能不能以更快的速度学好 Go。下面是我能想到知识面: 基础语法，包括变量，循环，判断以及运算符 Go 语言提供的基本数据结构 异常处理 函数，类与泛型 并发编程 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:2:0","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"3. 学习资料 书选的《Go程序设计语言》，在写博客之前已经翻过一遍，的确是一本可以拿来入门的好书。 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:3:0","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4. 环境搭建 在学习 Go 语言之前，最重要的是搭建一个 Go 的开发环境。为了对 Go 有一个更好的整体把握，对于这个开发环境我们至少完成下面这些任务。下面涉及的 Go 专业术语，后面会详细解释，为了便于理解，我简单的跟 Python作了一个对比 安装 Go，搭建基本的go开发环境 – python 安装 Go 语言工具箱，特别是 go 程序包的查询，下载和管理 – pip 的使用 Go 语言的工作目录 – 模块的搜索路径 IDE 编程环境 我们主要讲解 Linux 下的环境搭建，Windows 的搭建类似。我们使用 VScode 作为我们的IDE，没其他原因，因为大佬们都推荐。 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:0","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.1 Go 安装 Go 语言官方文档有完整的安装文档,Linux 下可直接运行下面的 bash 脚本，而唯一需要修改的是最后三个环境变量的配置。其中 PATH: 用于将 go 命令添加到环境变量的命令搜索路径中，便于直接使用 go 命令 GOPATH: 用于指定 go 的工作区，可以是单个目录路径，也可以是冒号分割的多个路径 GOBIN: 用于指定 GO 程序生成的可执行文件（executable file）的存放路径 先让你的 Go 可以运行起来，别的不用着急，马上我们就会讲解环境变量的作用，在你理解这些环境变量的含义之后就可以按需修改。 go_vsersion=go1.12.4.linux-amd64.tar.gz # 1. 下载安装包 wget https://studygolang.com/dl/golang/${go_vsersion}.tar.gz # 2. 解压到指定目录 tar -C /usr/local -xzf ${go_version}.tar.gz # 3. 配置相关环境变量 # 将 go 命令添加到 PATH 环境变量中，以便直接使用，PATH 环境变量与 GO 本身无关 echo 'export PATH=/usr/local/go/bin:$PATH' \u003e /etc/profile.d/go.sh # 添加 Go的工作区，下面默认为 $HOME/go echo 'export GOPATH=$(go env GOPATH)' \u003e\u003e /etc/profile.d/go.sh echo 'export GOBIN=$GOPATH/bin' \u003e\u003e /etc/profile.d/go. # 4. 并通过在命令行中输入go version来验证是否安装成功。 go version ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:1","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.2 Go语言工具箱 在 go 安装完毕之后，在 go 安装目录的 bin 子目录下会有一个 go 命令(默认为/usr/local/go/bin)，这就是 go 语言提供给我们的管理工具箱，它是一系列功能的集合: 首先它是一个构建系统，计算文件的依赖关系，然后调用编译器、汇编器和连接器构建程序 其次它是一个包管理器（类似于python pip），用于包的查询、下载、依赖关系解决。 最后它是一个单元测试和基准测试的驱动程序 go 命令的执行依赖很多环境变量，使用 go env 可以查看所有的环境变量，大多数环境变量在 go 语言正确安装之后(主要是选择与操作系统匹配的安装包)会自动配置，唯一需要用户配置是GOPATH，用于指定go 语言的工作区，工作区是 go 语言中的一个核心概念，Go 语言项目在其生命周期内的所有操作（编码、依赖管理、构建、测试、安装等）基本上都是围绕着 GOPATH 和工作区进行的。 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:2","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.3 Go 工作区 GOPATH对应的工作区目录有三个子目录: src 子目录用于存储源代码，使用 go get 下载的 go 包和自定义的 go 程序源代码都存在此目录中，同时也是代码包搜索和导入的启始根目录 pkg子目录用于保存编译后的包的目标文件 bin子目录用于保存编译后的可执行程序 go build命令编译命令行参数指定的每个包。如果 src 使用命令 go get可以下载一个单一的包或者用 …下载整个子目录里面的每个包。go get 会自动下载所依赖的每个包 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:3","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.3 GOROOT 环境变量GOROOT用来指定Go的安装目录，还有它自带的标准库包的位置。GOROOT的目录结构和GOPATH类似，因此存放fmt包的源代码对应目录应该为$GOROOT/src/fmt。用户一般不需要设置GOROOT，默认情况下Go语言安装工具会将其设置为安装的目录路径。 下面是我当前工作区目录的示例: $ tree -L 2 /home/tao/go /home/tao/go ├── bin │ ├── a │ ├── dlv │ ├── gocode │ ├── godef │ ├── go-outline │ ├── gopkgs │ ├── goreturns │ └── helloworld ├── pkg │ └── linux_amd64 └── src ├── algo ├── blog ├── github.com ├── golang.org ├── gopl.io ├── sourcegraph.com └── test 你可以运行go或go help命令查看内置的帮助文档，为了查询方便，我们列出了最常用的命令 $ go Go is a tool for managing Go source code. Usage: go \u003ccommand\u003e [arguments] The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages Use \"go help \u003ccommand\u003e\" for more information about a command. ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:4","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.3 Go 环境变量 GOPATH对应的工作区目录有三个子目录。 与 Python 不同的是，Go 的包不是通过镜像的方式，而是直接从远程版本控制系统(eg: githup)直接下载的，因此当我们使用标准的 go get 下载Go包时，可能会由于不可描述的原因失败。因此我们必须手动解决一些包的安装问题。 ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:5","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["Go"],"content":"4.2 Vscode 安装 在Vscode官网 下载与你系统时配的安装包，安装即可。安装完成后在 VScode Extension 安装与 go 相关的扩展，如下图所示: ","date":"2021-01-01","objectID":"/posts/program/go/grammar/go_1/:4:6","tags":["go 语法"],"title":"go 入门开篇","uri":"/posts/program/go/grammar/go_1/"},{"categories":["architecture"],"content":"k8s 安装部署","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"今天我们来介绍 k8s 的安装部署，为我们后面的学习做准备。作为一个分布式的复杂项目，k8s 的安装部署并不容易，我们将分别介绍两种 k8s 的部署方法: kubeadmin: 实验环境的 k8s 部署 k8s ansible 部署: 线上环境的 k8s 部署 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:0:0","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"1. kubeadmin kubeadmin 可以让用户通过这样两条指令完成一个 Kubernetes 集群的部署： # 创建一个Master节点 $ kubeadm init # 将一个Node节点加入到当前集群中 $ kubeadm join \u003cMaster节点的IP和端口\u003e ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:1:0","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"1.1 kubeadmin 部署的原理 kubeadmin 使用 docker 来部署 k8s 的各个组件，但是由于 kubelet 在启动容器、配置容器网络、管理容器数据卷时，都需要直接操作宿主机，kubeadm 在 kubelet 的部署上做了妥协：把 kubelet 直接运行在宿主机上，然后使用容器部署其他的 Kubernetes 组件。 所以，你使用 kubeadm 的第一步，是在机器上手动安装 kubeadm、kubelet 和 kubectl 这三个二进制文件(执行 yum install kubeadmin 即可)。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:1:1","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"1.2 kubeadm init 的工作流程 当你执行 kubeadm init 指令后，kubeadmin 会执行下面的一系列操作: Preflight Checks，即一系列的检查工作，以确定这台机器可以用来部署 Kubernetes 生成 Kubernetes 对外提供服务所需的各种证书和对应的目录，这些文件都放在 Master 节点的 /etc/kubernetes/pki 目录下 证书生成后，kubeadm 接下来会为其他组件生成访问 kube-apiserver 所需的配置文件。这些文件的路径是：/etc/kubernetes/xxx.conf 接下来，kubeadm 会为 Master 组件生成 Pod 配置文件。三个 Master 组件 kube-apiserver、kube-controller-manager、kube-scheduler，而它们都会被使用 Pod 的方式部署起来 在上一步完成后，kubeadm 还会再生成一个 Etcd 的 Pod YAML 文件，用来通过同样的 Static Pod 的方式启动 Etcd Master 容器启动后，kubeadm 会通过检查 localhost:6443/healthz 这个 Master 组件的健康检查 URL，等待 Master 组件完全运行起来 在master 组件都启动后，kubeadm 就会为集群生成一个 bootstrap token，只要持有这个 token，任何一个安装了 kubelet 和 kubadm 的节点，都可以通过 kubeadm join 加入到这个集群当中。 在 token 生成之后，kubeadm 会将 ca.crt 等 Master 节点的重要信息，通过 ConfigMap 的方式保存在 Etcd 当中，供后续部署 Node 节点使用。这个 ConfigMap 的名字是 cluster-info kubeadm init 的最后一步，就是安装默认插件。Kubernetes 默认 kube-proxy 和 DNS 这两个插件是必须安装的。它们分别用来提供整个集群的服务发现和 DNS 功能。这两个插件也只是两个容器镜像而已，所以 kubeadm 只要用 Kubernetes 客户端创建两个 Pod 就可以了。 证书文件 $ /etc/kubernetes/pki 其中: ca.crt/ca.key: apiserver-kubelet-client.crt/apiserver-kubelet-client.key: kube-apiserver 访问 kubelet 的证书 服务配置文件 $ ls /etc/kubernetes/ admin.conf controller-manager.conf kubelet.conf scheduler.conf 这些文件里面记录的是，当前这个 Master 节点的服务器地址、监听端口、证书目录等信息。这样，对应的客户端（比如 scheduler，kubelet 等），可以直接加载相应的文件，使用里面的信息与 kube-apiserver 建立安全连接。 Pod Yaml 文件 在 Kubernetes 中，有一种特殊的容器启动方法叫做“Static Pod”。它允许你把要部署的 Pod 的 YAML 文件放在一个指定的目录里。这样，当这台机器上的 kubelet 启动时，它会自动检查这个目录，加载所有的 Pod YAML 文件，然后在这台机器上启动它们。 在 kubeadm 中，Master 组件的 YAML 文件会被生成在 /etc/kubernetes/manifests 路径下。 $ ls /etc/kubernetes/manifests/ etcd.yaml kube-apiserver.yaml kube-controller-manager.yaml kube-scheduler.yaml bootstrap token 为什么执行 kubeadm join 需要这样一个 token 呢？因为，任何一台机器想要成为 Kubernetes 集群中的一个节点，就必须在集群的 kube-apiserver 上注册。可是，要想跟 apiserver 打交道，这台机器就必须要获取到相应的证书文件（CA 文件）。可是，为了能够一键安装，我们就不能让用户去 Master 节点上手动拷贝这些文件。所以，kubeadm 至少需要发起一次“不安全模式”的访问到 kube-apiserver，从而拿到保存在 ConfigMap 中的 cluster-info（它保存了 APIServer 的授权信息）。而 bootstrap token，扮演的就是这个过程中的安全验证的角色。只要有了 cluster-info 里的 kube-apiserver 的地址、端口、证书，kubelet 就可以以“安全模式”连接到 apiserver 上，这样一个新的节点就部署完成了。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:1:2","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"1.3 kubeadmin 参数配置 kubeadm 确实简单易用，可是我又该如何定制我的集群组件参数呢？荐你在使用 kubeadm init 部署 Master 节点时，使用下面这条指令，给 kubeadm 提供一个 YAML 文件，在这个配置文件里自定义 k8s 各个组件的启动参数: $ kubeadm init --config kubeadm.yaml kubeadm 就会使用 kubeadm.yaml 中的信息替换 /etc/kubernetes/manifests/ 里对应服务的 pod yaml 文件。kubeadmin.yaml 支持的参数参见 k8s 的文档。 kubeadm 的源代码，直接就在 kubernetes/cmd/kubeadm 目录下，是 Kubernetes 项目的一部分。其中，app/phases 文件夹下的代码，对应的就是我在这篇文章中详细介绍的每一个具体步骤。 kubeadm 目前应该已经具备一键部署一个高可用的 Kubernetes 集群，即：Etcd、Master 组件都应该是多节点集群，而不是现在这样的单点。可参考文档Creating Highly Available Clusters with kubeadm。除了 kubadmin 更推荐采用如下两种方式: 使用kops 使用Ansible ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:1:3","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2. kubadmin 安装 k8s 使用 kubadmin 安装 k8s 分成如下几个步骤: 在所有节点上安装 Docker 和 kubeadm； 部署 Kubernetes Master； 部署容器网络插件； 部署 Kubernetes Worker 部署 Dashboard 可视化插件； 部署容器存储插件 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:0","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.1 安装 Docker 和 kubeadm； 准备 yum 源 首先准备 yum 源安装 Docker 和 kubeadmin cd /etc/yum.repo.d/ # docker-ce 源 wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # kubernetes 源 vim kubernetes.repo [kuberneters] name=kuberneters repo baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ gpgcheck=1 enabled=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg # 设置 docker kubelet 开机自启动 systemctl enable docker kubelet 安装配置相关组件 # 安装相关组件 yum install docker-ce kubectl kubelet kubeadm # 配置 docer 的 unit file 添加 https 代理，以便能下载相关被墙的镜像 # 不过依旧不能用，此步骤省略 # vim /usr/lib/systemd/system/docker.service # 添加 # Environment=\"HTTPS_PROXY=http://www.ik8s.io:10080\" systemctl daemon-reload systemctl restart docker docker info # 看到 HTTPS_PROXY 行即可 # 配置 kuberneters 不受 swap 分区的影响 vim /etc/sysconfig/kubelet KUBELET_EXTRA_ARGS=\"--fail-swap-on=false\" # 系统参数初始化 sysctl -w net.bridge.bridge-nf-call-ip6tables=1 sysctl -w net.bridge.bridge-nf-call-iptables=1 iptables -F 准备 kubeadm 所需镜像 因为某种不可描述的原因，kubeadm 使用到的镜像无法访问，因此需要手动准备 kubeadm 所需的镜像文件。这里有片文章可以指导你去构建相应的 镜像 https://ieevee.com/tech/2017/04/07/k8s-mirror.html \u003e kubeadm config images list k8s.gcr.io/kube-apiserver:v1.12.2 k8s.gcr.io/kube-controller-manager:v1.12.2 k8s.gcr.io/kube-scheduler:v1.12.2 k8s.gcr.io/kube-proxy:v1.12.2 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.2.24 k8s.gcr.io/coredns:1.2.2 我是自己去阿里云自建的镜像，使用下面的脚本对镜像进行重命名 #!/bin/bash base=k8s.gcr.io aliyun=\"registry.cn-qingdao.aliyuncs.com/htttao\" images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2) for i in ${images[@]} do docker pull $aliyun/$i docker tag $aliyun/$i $base/$i done ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:1","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.2 初始化 Master 节点 首先我们为 kubadmin 准备一个配置文件，已启动一些特殊实验性功能。 apiVersion: kubeadm.k8s.io/v1alpha1 kind: MasterConfiguration controllerManagerExtraArgs: horizontal-pod-autoscaler-use-rest-clients: \"true\" horizontal-pod-autoscaler-sync-period: \"10s\" node-monitor-grace-period: \"10s\" apiServerExtraArgs: runtime-config: \"api/all=true\" kubernetesVersion: \"stable-1.11\" 其中 horizontal-pod-autoscaler-use-rest-clients: \"true\" 意味着，将来部署的 kube-controller-manager 能够使用自定义资源（Custom Metrics）进行自动水平扩展。然后我们只需要下面的命令就可以完成 master 节点的部署。 $ kubeadm init --config kubeadm.yaml # 运行完成之后，会提示将 Node 节点加入集群的命令 kubeadm join 192.168.1.106:6443 --token z5fqxu.dn3awhi0u5n2i6eb --discovery-token-ca-cert-hash sha256:dc333a8af6ee0c7cd1e180b43251800685b90d6338929fa508e42f76579ce50c # 按照初始化后的提示，创建一个普通用户，并复制相应文件 # user: kubernetes mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 测试 kubectl get cs kubectl get nodes kubectl get pods -n kube-system kubectl get ns 需要这些配置命令的原因是：Kubernetes 集群默认需要加密方式访问。所以，这几条命令，就是将刚刚部署生成的 Kubernetes 集群的安全配置文件，保存到当前用户的.kube 目录下，kubectl 默认会使用这个目录下的授权信息访问 Kubernetes 集群。如果不这么做的话，我们每次都需要通过 export KUBECONFIG 环境变量告诉 kubectl 这个安全配置文件的位置。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:2","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.3 部署网络组件 初始化 Master 还有非常重要的一步，就是部署网络组件，否则各个 pod 等组件之间是无法通信的 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml kubectl get pods -n kube-system ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:3","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.4 部署 Worker 节点 相比与 Master Worker 节点的部署只需要两步即可完成: 安装 kubeadm 和 Docker 执行 Master 初始化后输出的 kubadmin join 命令 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:4","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.5 调整 Master 执行 Pod 的策略 默认情况下 Master 节点是不允许运行用户 Pod 的。而 Kubernetes 做到这一点，依靠的是 Kubernetes 的 Taint/Toleration 机制: 某个节点可以被加上了一个 Taint 一旦某个节点被加上了一个 Taint，即被“打上了污点”，那么所有 Pod 就都不能在这个节点上运行 除非，Pod 声明自己能“容忍”这个“污点”，即声明了 Toleration 才能调度到有 Taint 污点的节点上运行 taint 命令 为节点打上“污点”（Taint）的命令是： kubectl taint nodes node1 foo=bar:NoSchedule 其中值里面的 NoSchedule，意味着这个 Taint 只会在调度新 Pod 时产生作用，而不会影响已经在 node1 上运行的 Pod，哪怕它们没有 Toleration。 声明 Toleration 声明 Toleration 只要在 Pod 的.yaml 文件中的 spec 部分，加入 tolerations 字段即可： apiVersion: v1 kind: Pod ... spec: tolerations: - key: \"foo\" operator: \"Equal\" value: \"bar\" effect: \"NoSchedule\" 这个 Toleration 的含义是，这个 Pod 能“容忍”所有键值对为 foo=bar 的 Taint（ operator: “Equal”，“等于”操作）。 master 节点去污点 回到搭建的集群上，kubectl describe 可以查看 Master 节点的 Taint 字段: $ kubectl describe node master Name: master Roles: master Taints: node-role.kubernetes.io/master:NoSchedule 你可以在像下面一样，在 pod 声明 Toleration 容忍这个污点: apiVersion: v1 kind: Pod ... spec: tolerations: - key: \"node-role.kubernetes.io/master\" operator: \"Exists\" effect: \"NoSchedule\" 或者是删除这个污点，让 master 可以被调度执行 pod $ kubectl taint nodes --all node-role.kubernetes.io/master- 短横线“-”，意味着移除所有以“node-role.kubernetes.io/master”为键的 Taint。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:5","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.6 部署 Dashboard 可视化插件 $ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-rc6/aio/deploy/recommended.yaml $ kubectl get pods -n kube-system 1.7 版本之后的 Dashboard 项目部署完成后，默认只能通过 Proxy 的方式在本地访问，想要直接访问，具体的操作，你可以查看 Dashboard 项目的官方文档。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:6","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.7 部署容器存储插件 容器的持久化存储，就是用来保存容器存储状态的重要手段：存储插件会在容器里挂载一个基于网络或者其他机制的远程数据卷，使得在容器里创建的文件，实际上是保存在远程存储服务器上，或者以分布式的方式保存在多个节点上，而与当前宿主机没有任何绑定关系。这样，无论你在其他哪个宿主机上启动新的容器，都可以请求挂载指定的持久化存储卷，从而访问到数据卷里保存的内容。这就是“持久化”的含义。 绝大多数存储项目，比如 Ceph、GlusterFS、NFS 等，都可以为 Kubernetes 提供持久化存储能力。在这次的部署实战中，我会选择部署一个很重要的 Kubernetes 存储插件项目：Rook。 Rook 项目是一个基于 Ceph 的 Kubernetes 存储插件（它后期也在加入对更多存储实现的支持）。不过，不同于对 Ceph 的简单封装，Rook 在自己的实现中加入了水平扩展、迁移、灾难备份、监控等大量的企业级功能，使得这个项目变成了一个完整的、生产级别可用的容器存储插件。 整个部署过程也很简单: $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/common.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/operator.yaml $ kubectl apply -f https://raw.githubusercontent.com/rook/rook/master/cluster/examples/kubernetes/ceph/cluster.yaml $ kubectl get pods -n rook-ceph-system $ kubectl get pods -n rook-ceph 部署完成后，接下来在 Kubernetes 项目上创建的所有 Pod 就能够通过 Persistent Volume（PV）和 Persistent Volume Claim（PVC）的方式，在容器里挂载由 Ceph 提供的数据卷了。 得益于对 k8s 诸如 Operator、CRD 等重要的扩展特性的使用，使得 Rook 项目，成为了目前社区中基于 Kubernetes API 构建的最完善也最成熟的容器存储插件。这也正是开发和使用 Kubernetes 的重要指导思想，即：基于 Kubernetes 开展工作时，你一定要优先考虑这两个问题： 我的工作是不是可以容器化？ 我的工作是不是可以借助 Kubernetes API 和可扩展机制来完成？ 如果能够基于 Kubernetes 实现容器化，那么将大大降低我们的 运维工作。 ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:7","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.8 k8s 集群重至 如果配置过程中出现了错误，想重新配置集群， 可以使用 kubeadm reset 对整个集群进行重至，然后重新使用 kubeadm init 进行初始化创建。但是需要注意的时，kubeadm reset 不会重至 flannel 网络，想要完全重至可使用以下脚本 #!/bin/bash kubeadm reset systemctl stop kubelet systemctl stop docker rm -rf /var/lib/cni/ rm -rf /var/lib/kubelet/* rm -rf /etc/cni/ ifconfig cni0 down ifconfig flannel.1 down ifconfig docker0 down ip link delete cni0 ip link delete flannel.1 systemctl start docker ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:2:8","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"2.9 安装脚本 整个集群安装比较复杂，因此我将物理环境准备以及镜像下载写成了两个脚本，以便于 k8s 集群的安装。 基础环境配置脚本 #!/bin/bash # 1. 设置系统参数 mount /dev/cdrom /cdrom iptables -F # 2. 准备 yum 源 wget -P /etc/yum.repos.d/ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo cat \u003c\u003c EOF \u003e\u003e /etc/yum.repos.d/kubernetes.repo [kuberneters] name=kuberneters repo baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ gpgcheck=1 enabled=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF # 3. 配置 kuberneters 不受 swap 分区的影响 yum install docker-ce kubelet kubeadm kubectl -y echo 'KUBELET_EXTRA_ARGS=\"--fail-swap-on=false\"' \u003e /etc/sysconfig/kubelet # 4. 启动相关服务 systemctl start docker systemctl enable docker kubelet cat \u003c\u003c EOF \u003e /etc/docker/daemon.json { \"registry-mirrors\": [\"https://osafqkzd.mirror.aliyuncs.com\"] } EOF 镜像下载脚本 执行下面的下载脚本 /root/kubernetes.sh #!/bin/bash sudo docker login --username=1556824234@qq.com registry.cn-qingdao.aliyuncs.com sysctl net.bridge.bridge-nf-call-ip6tables=1 sysctl net.bridge.bridge-nf-call-iptables=1 base=k8s.gcr.io aliyun=\"registry.cn-qingdao.aliyuncs.com/htttao\" images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2) for i in ${images[@]} do docker pull $aliyun/$i docker tag $aliyun/$i $base/$i done flannel=flannel:v0.10.0-amd64 docker pull $aliyun/$flannel docker tag $aliyun/$flannel quay.io/coreos/$flannel ","date":"2020-08-02","objectID":"/posts/architecture/k8s/k8s_use/02_k8s/:3:0","tags":["k8s"],"title":"k8s 安装部署","uri":"/posts/architecture/k8s/k8s_use/02_k8s/"},{"categories":["architecture"],"content":"这个系列我们开始学习 k8s","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"这个系列我们开始学习 k8s，但是想学好 k8s 并不容易，网络、操作系统、分布式原理都是 k8s 重要的组成部分。我自己将整个学习分成了如下几个系列: k8s 的设计和使用: 这个系列我们从使用层次上，明白 k8s 高层次的抽象和设计，达到能高效使用 k8s 的目的 k8s 的源码解析: 这个系列我们从源码层次上，透析 k8s 的设计与实现，并学习 k8s 里面优秀的代码设计 k8s 的网络模型: 这个系列我们从网络层次上，学习 k8s 上不同的网络插件对应的网络模型及其实现 这篇文章开始，我们学习 k8s 的设计和使用，选用的教材是: 极客时间张磊老师的专栏-深入剖析 Kubernetes Kubernetes in Action中文版 而今天的内容则是跟容器有关。容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”，而使用到的核心技术就是: Namespace: 修改进程视图，创建进程的边界 Cgroups: 限制容器的资源使用量 chroot/容器镜像: 容器镜像配合 chroot 更改容器看到的根目录 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:0:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1. Namespace ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.1 Namespace 原理 Namespace 用来修改应用进程看待整个计算机“视图”，即应用进程的“视线”被操作系统做了限制，只能“看到”某些指定的内容。Linux 操作系统提供了六种 Namespace: PID: 用于让被隔离进程只看到当前 Namespace 里启动的进程 Mount: 用于让被隔离进程只看到当前 Namespace 里的挂载点信息 Network: 用于让被隔离进程看到当前 Namespace 里的网络设备和配置 UTS: 隔离域名 IPC: 隔离进程间通信 User: 隔离用户 要知道在 Namespace 的隔离技术是在，操作系统发展的后期演化的，他们都是在已有的进程创建扩展而来。所以这些 Namespace 实际上是在创建容器进程时，指定的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。所以说，容器，其实是一种特殊的进程而已。对于宿主机来说，这些被“隔离”了的进程跟其他进程并没有太大区别。 Namespace 的底层实现原理参见，耗子叔的博客: DOCKER基础技术：LINUX NAMESPACE（上） DOCKER基础技术：LINUX NAMESPACE（下） ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:1","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.2 进程 Namespace 查看 一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。 # 1. 查看容器对应的进程 PID $ docker inspect --format '{{ .State.Pid }}' 3cfcb77fe21b # 2. 查看容器进程的所有 Namespace 对应的文件 $ ll /proc/82155/ns 总用量 0 lrwxrwxrwx. 1 root root 0 3月 5 21:05 cgroup -\u003e 'cgroup:[4026531835]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 ipc -\u003e 'ipc:[4026532619]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 mnt -\u003e 'mnt:[4026532617]' lrwxrwxrwx. 1 root root 0 3月 5 20:20 net -\u003e 'net:[4026532622]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 pid -\u003e 'pid:[4026532620]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 pid_for_children -\u003e 'pid:[4026532620]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 time -\u003e 'time:[4026531834]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 time_for_children -\u003e 'time:[4026531834]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 user -\u003e 'user:[4026531837]' lrwxrwxrwx. 1 root root 0 3月 5 21:05 uts -\u003e 'uts:[4026532618]' 正是因为 Namespace 对应的是一个个正是的文件，所以一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的，这正是 docker exec 的实现原理。而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。 Docker 还专门提供了一个参数，可以让你启动一个容器并“加入”到另一个容器的 Network Namespace 里，这个参数就是 -net，比如: $ docker run -it --net container:4ddf4638572d busybox ifconfig 如果指定–net=host，就意味着这个容器不会为进程启用 Network Namespace，而共享宿主机的物理网络。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:2","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.2 Cgroups Linux Cgroups 是 Linux 内核中用来为进程设置资源限制的一个重要功能。Linux Cgroups 的全称是 Linux Control Group 用来限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。 Cgroups 接口 在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。 # 查看 cgroup 挂载点 $ mount -t cgroup $ pwd /sys/fs/cgroup $ ll dr-xr-xr-x. 6 root root 0 10月 19 06:26 blkio lrwxrwxrwx. 1 root root 11 10月 19 06:26 cpu -\u003e cpu,cpuacct lrwxrwxrwx. 1 root root 11 10月 19 06:26 cpuacct -\u003e cpu,cpuacct dr-xr-xr-x. 6 root root 0 10月 19 06:26 cpu,cpuacct dr-xr-xr-x. 2 root root 0 10月 19 06:26 cpuset dr-xr-xr-x. 6 root root 0 10月 19 06:26 devices dr-xr-xr-x. 2 root root 0 10月 19 06:26 freezer dr-xr-xr-x. 2 root root 0 10月 19 06:26 hugetlb dr-xr-xr-x. 6 root root 0 10月 19 06:26 memory lrwxrwxrwx. 1 root root 16 10月 19 06:26 net_cls -\u003e net_cls,net_prio dr-xr-xr-x. 2 root root 0 10月 19 06:26 net_cls,net_prio lrwxrwxrwx. 1 root root 16 10月 19 06:26 net_prio -\u003e net_cls,net_prio dr-xr-xr-x. 2 root root 0 10月 19 06:26 perf_event dr-xr-xr-x. 6 root root 0 10月 19 06:26 pids dr-xr-xr-x. 2 root root 0 10月 19 06:26 rdma dr-xr-xr-x. 6 root root 0 10月 19 06:26 systemd /sys/fs/cgroup 目录下的每个子目录代表着一种资源的子系统，比如 blkio，为​​​块​​​设​​​备​​​设​​​定​​​I/O 限​​​制，一般用于磁盘等设备； cpuset，为进程分配单独的 CPU 核和对应的内存节点； memory，为进程设定内存使用的限制。 使用方法也很简单: 首先进入到想限制的资源的目录，然后创建一个目录，这个目录就是一个控制组 cgroup 挂载的虚拟文件系统会在创建目录的同时，在目录内创建一系列资源限制文件 往这些文件里面写入进程的资源使用限额即可 当前目录下有一个 task 文件，将被限制进程 PID 写入 task，就可以指定资源限定的目标 Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。 而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令： $ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3cfcb77fe21b ubuntu:latest \"sleep 3600\" 19 seconds ago Up 18 seconds strange_leakey $ ll /sys/fs/cgroup/cpu/docker/3cfcb77fe21b26db68d05aceaa6790ba998ac157a566bdd241b8fc0de13600a4/ 总用量 0 -rw-r--r--. 1 root root 0 3月 5 20:21 cgroup.clone_children -rw-r--r--. 1 root root 0 3月 5 20:20 cgroup.procs -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.stat -rw-r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_all -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_percpu -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_percpu_sys -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_percpu_user -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_sys -r--r--r--. 1 root root 0 3月 5 20:21 cpuacct.usage_user -rw-r--r--. 1 root root 0 3月 5 20:21 cpu.cfs_period_us -rw-r--r--. 1 root root 0 3月 5 20:21 cpu.cfs_quota_us -rw-r--r--. 1 root root 0 3月 5 20:21 cpu.rt_period_us -rw-r--r--. 1 root root 0 3月 5 20:21 cpu.rt_runtime_us -rw-r--r--. 1 root root 0 3月 5 20:21 cpu.shares -r--r--r--. 1 root root 0 3月 5 20:21 cpu.stat -rw-r--r--. 1 root root 0 3月 5 20:21 notify_on_release -rw-r--r--. 1 root root 0 3月 5 20:21 tasks $ cat /sys/fs/cgroup/cpu/docker/3cfcb77fe21b26db68d05aceaa6790ba998ac157a566bdd241b8fc0de13600a4/cpu.cfs_period_us 100000 $ cat /sys/fs/cgroup/cpu/docker/3cfcb77fe21b26db68d05aceaa6790ba998ac157a566bdd241b8fc0de13600a4/cpu.cfs_quota_us 20000 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:3","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.3 容器镜像 容器镜像和 Mount Namespace 要理解容器镜像的关键是搞清楚容器镜像与 Mount Namespace 之间的关系。 首先 Mount Namespace 修改的，是容器进程对文件系统“挂载点”的认知。但是，这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。这就是 Mount Namespace 跟其他 Namespace 的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。 所以处理 Mount Namespace 我们还需要在容器进程启动之前重新挂载它的整个根目录“/”，而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。 在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成重新挂载整个根目录“/”。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。 容器镜像带来的改变 对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:4","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.4 容器启动过程 所以对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程： 启用 Linux Namespace 配置； 设置指定的 Cgroups 参数； 切换进程的根目录（Change Root）。 不过，Docker 项目在最后一步的切换上会优先使用 pivot_root 系统调用，如果系统不支持，才会使用 chroot。这两个系统调用虽然功能类似，但是也有细微的区别。另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。所以说，rootfs 只包括了操作系统的“躯壳”，并没有包括操作系统的“灵魂”。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:5","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.5 容器的缺陷 容器的缺陷，根本原因在于隔离不够彻底。 共享内核 首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。这意味着，如果你要在 Windows 宿主机上运行 Linux 容器，或者在低版本的 Linux 宿主机上运行高版本的 Linux 容器，都是行不通的。 同时这也意味着，如果你的应用程序需要配置内核参数、加载额外的内核模块，以及跟内核进行直接的交互，你就需要注意了：这些操作和依赖的对象，都是宿主机操作系统的内核，它对于该机器上的所有容器来说是一个“全局变量”，牵一发而动全身。 Namespace 隔离粒度不够 其次，在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。这就意味着，如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。 资源统计不准确 另外，跟 Namespace 的情况类似，Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息。但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。 在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。这也是在企业中，容器化应用碰到的一个常见问题，也是容器相较于虚拟机另一个不尽如人意的地方。注: 解决办法参见 lxcfs。 安全限制不够 此外，由于上述问题，尤其是共享宿主机内核的事实，容器给应用暴露出来的攻击面是相当大的，应用“越狱”的难度自然也比虚拟机低得多。尽管在实践中我们确实可以使用 Seccomp 等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，必然会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。 所以，在生产环境中，没有人敢把运行在物理机上的 Linux 容器直接暴露到公网上。当然，我后续会讲到的基于虚拟化或者独立内核技术的容器实现，则可以比较好地在隔离与性能之间做出平衡。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:6","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"1.6 容器的单进程模型 正因为容器的 Namespace 和 Cgroups 是施加在单个进程上的，所以容器技术中一个非常重要的概念，即：容器是一个“单进程”模型。 由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。 在容器的设计模式中，容器本身的设计，是希望容器和应用能够同生命周期，这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:1:7","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"2. 联合文件系统 为了提高容器镜像的复用能力，Docker 在容器镜像的制作上采用了一个叫联合文件系统的新实现。联合文件系统（Union File System）的能力。Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:2:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"2.1 overlay2 在我的 Centos 机器上，docker 使用的联合文件系统是 overlay2，它的关键目录位于 /var/lib/docker/overlay2。我在前面运行了一个 ubuntu 的容器，docker 自动将 ubuntu 的镜像拉取了本地。 这个所谓的“镜像”，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。而这个 Ubuntu 的镜像实际上是由多个层组成的。 首先我们看一下上面我们启动的 8cc9715e0e9d rootfs 挂载在哪: docker inspect 3cfcb77fe21b \"GraphDriver\": { \"Data\": { \"LowerDir\": \"/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200-init/diff:/var/lib/docker/overlay2/7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/work\" }, \"Name\": \"overlay2\" }, 在 overlay2 中: LowerDir：指向镜像层； UpperDir：指向容器层，在容器中创建文件后，文件出现在此目录； MergedDir：容器挂载点 ，lowerdir和upperdir整合起来提供统一的视图给容器，作为根文件系统； WorkDir：用于实现copy_up操作。 所以 3cfcb77fe21b 的镜像由下面三个层组成: /var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/diff /var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200-init/diff /var/lib/docker/overlay2/7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff 并被联合挂载在 /var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/merged 而 7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff 正是 ubuntu 镜像的容器层: $ docker image inspect 2b4cba85892a|less \"GraphDriver\": { \"Data\": { \"MergedDir\": \"/var/lib/docker/overlay2/7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/work\" }, \"Name\": \"overlay2\" }, 通过系统的 mount 信息，可以看到同样的挂载信息: $ cat /proc/mounts |grep overlay overlay /var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/merged overlay rw,seclabel,relatime,lowerdir=/var/lib/docker/overlay2/l/72ZL2SJGZXEDYBHENYYYYXVRYS:/var/lib/docker/overlay2/l/GRNLLRA54UDERQYOS6AQFNC5K4,upperdir=/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/diff,workdir=/var/lib/docker/overlay2/b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/work 0 0 $ ll /var/lib/docker/overlay2/l 总用量 0 lrwxrwxrwx. 1 root root 72 3月 5 20:20 2QUYA4NJODHDXHYSIDH3TEFKSW -\u003e ../b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/diff lrwxrwxrwx. 1 root root 77 3月 5 20:20 72ZL2SJGZXEDYBHENYYYYXVRYS -\u003e ../b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200-init/diff lrwxrwxrwx. 1 root root 72 3月 5 15:49 GRNLLRA54UDERQYOS6AQFNC5K4 -\u003e ../7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:2:1","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"2.2 容器的 rootfs 组成 从这个结构可以看出来，这个容器的 rootfs 由如下图所示的三部分组成： 第一部分，只读层: 这个容器的 rootfs 最下面的一层，挂载方式都是只读的(ro+wh) 所谓 wh 就是当删除只读层里的一个文件，联合文件系统会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来，比如删除只读层的 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义 第二部分，可读写层: 这个容器的 rootfs 最上面的一层 在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。 结合 copy-on-write 以及 whiteout 可读写层就可以用来存放所有修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里 我们使用 docker commit 和 push 指令，保存的正是这个被修改过的可读写层 第三部分，Init 层: Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息 这一部分属于私密信息，即便用户修改后也不希望被提交到 docker hub 上去，所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。 注: 图片摘录自专栏，上面的 overlay2 就是如下三层: b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200/diff b09b7979ceab286d53ed72fe122c2807cb2145e14b60bdc33ab3de3267a73200-init/diff 7c200b7659c9c12d5ab0baeae54d03bbeb7d490c3d97f6a85d18c8ae8d1a2f0e/diff ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:2:2","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"2.3 copy-on-write 由于使用了联合文件系统，你在容器里对镜像只读层的 rootfs 所做的任何修改，都会被操作系统先复制到最上层的可读写层，然后再修改。这就是所谓的：Copy-on-Write。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:2:3","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"3.Dockerfile 相比如手动制作 rootfs,Docker 为你提供了一种更便捷的方式，叫作 Dockerfile。 # 使用官方提供的Python开发镜像作为基础镜像 FROM python:2.7-slim # 将工作目录切换为/app WORKDIR /app # 将当前目录下的所有内容复制到/app下 ADD . /app # 使用pip命令安装这个应用所需要的依赖 RUN pip install --trusted-host pypi.python.org -r requirements.txt # 允许外界访问容器的80端口 EXPOSE 80 # 设置环境变量 ENV NAME World # 设置容器进程为：python app.py，即：这个Python应用的启动命令 CMD [\"python\", \"app.py\"] Dockerfile 描述了我们所要构建的 Docker 镜像，它使用一些标准的原语，docker build 命令会自动加载当前目录下的 Dockerfile 文件，然后按照顺序，执行文件中的原语。而这个过程，实际上可以等同于 Docker 使用基础镜像启动了一个容器，然后在容器中依次执行 Dockerfile 中的原语。 需要注意的是，Dockerfile 中的每个原语执行后，都会生成一个对应的镜像层。即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，这个层是空的。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:3:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"4. docker exec 一个进程的每种 Linux Namespace，都在它对应的 /proc/[进程号]/ns 下有一个对应的虚拟文件，并且链接到一个真实的 Namespace 文件上。有了这些 Linux Namespace 的文件，我们就可以对 Namespace 做一些很有意义事情了，比如：加入到一个已经存在的 Namespace 当中。这也就意味着：一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到“进入”这个进程所在容器的目的，这正是 docker exec 的实现原理。而这个操作所依赖的，乃是一个名叫 setns() 的 Linux 系统调用。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:4:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"5. docker volume ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:5:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"5.1 volume 介绍 有了容器镜像，我们还有两个问题需要考虑: 容器里进程新建的文件，怎么才能让宿主机获取到？ 宿主机上的文件和目录，怎么才能让容器里的进程访问到？ 这正是 Docker Volume 要解决的问题：Volume 机制，允许你将宿主机上指定的目录或者文件，挂载到容器里面进行读取和修改操作。 在 Docker 项目里，它支持两种 Volume 声明方式 $ docker run -v /test ... $ docker run -v /home:/test ... 而这两种声明方式的本质，实际上是相同的：只不过，在第一种情况下，由于你并没有显示声明宿主机目录，那么 Docker 就会默认在宿主机上创建一个临时目录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的 /test 目录上。而在第二种情况下，Docker 就直接把宿主机的 /home 目录挂载到容器的 /test 目录上。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:5:1","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"5.2 volume 原理 前面已经介绍过，当容器进程被创建之后，尽管开启了 Mount Namespace，但是在它执行 chroot（或者 pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统。而宿主机上的文件系统，也自然包括了我们要使用的容器镜像。在容器进程启动后这些容器的镜像层就会被联合挂载到 /var/lib/docker/overlay2/[container_id]/merged 下，这样容器所需的 rootfs 就准备好了。 我们只需要在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录（比如 /home 目录），挂载到指定的容器目录（比如 /test 目录）在宿主机上对应的目录（即 /var/lib/docker/overlay2/[container_id]/merged/test）上，这个 Volume 的挂载工作就完成了。 更重要的是，由于执行这个挂载操作时，“容器进程”已经创建了，也就意味着此时 Mount Namespace 已经开启了。所以，这个挂载事件只在这个容器里可见。你在宿主机上，是看不见容器内部的这个挂载点的。这就保证了容器的隔离性不会被 Volume 打破。 注意：这里提到的\"容器进程\"，是 Docker 创建的一个容器初始化进程 (dockerinit)，而不是应用进程 (ENTRYPOINT + CMD)。dockerinit 会负责完成根目录的准备、挂载设备和目录、配置 hostname 等一系列需要在容器内进行的初始化操作。最后，它通过 execv() 系统调用，让应用进程取代自己，成为容器里的 PID=1 的进程。 而这里要使用到的挂载技术，就是 Linux 的 绑定挂载（bind mount） 机制。它的主要作用就是，允许你将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上。并且，这时你在该挂载点上进行的任何操作，只是发生在被挂载的目录或者文件上，而原挂载点的内容则会被隐藏起来且不受影响。 其实，如果你了解 Linux 内核的话，就会明白，绑定挂载实际上是一个 inode 替换的过程。在 Linux 操作系统中，inode 可以理解为存放文件内容的“对象”，而 dentry，也叫目录项，就是访问这个 inode 所使用的“指针”。 正如上图所示，mount –bind /home /test，会将 /home 挂载到 /test 上。其实相当于将 /test 的 dentry，重定向到了 /home 的 inode。这样当我们修改 /test 目录时，实际修改的是 /home 目录的 inode。这也就是为何，一旦执行 umount 命令，/test 目录原先的内容就会恢复：因为修改真正发生在的，是 /home 目录里。 所以，在一个正确的时机，进行一次绑定挂载，Docker 就可以成功地将一个宿主机上的目录或文件，不动声色地挂载到容器中。这样，进程在容器里对这个 /test 目录进行的所有操作，都实际发生在宿主机的对应目录里，而不会影响容器镜像的内容。 这个 /test 目录里的内容，既然挂载在容器 rootfs 的可读写层，它会不会被 docker commit 提交掉呢？也不会。这个原因其实我们前面已经提到过。容器的镜像操作，比如 docker commit，都是发生在宿主机空间的。而由于 Mount Namespace 的隔离作用，宿主机并不知道这个绑定挂载的存在。所以，在宿主机看来，容器中可读写层的 /test 目录，始终是空的。 不过，由于 Docker 一开始还是要创建 /test 这个目录作为挂载点，所以执行了 docker commit 之后，你会发现新产生的镜像里，会多出来一个空的 /test 目录。毕竟，新建目录操作，又不是挂载操作，Mount Namespace 对它可起不到“障眼法”的作用。 $ sudo docker run -it -v /test ubuntu:latest bash $ docker volume ls DRIVER VOLUME NAME local a4c01d9046842c0f19addd9012c2f01556af04ea02fdb6a826d0d342ce35808e $ ll /var/lib/docker/volumes/a4c01d9046842c0f19addd9012c2f01556af04ea02fdb6a826d0d342ce35808e/_data/ 总用量 0 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:5:2","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"5.3 Docker copyData 功能 执行 docker run -v /home:/test 的时候，如果宿主机 /home 和 容器 /test 同时存在文件，最终以哪个为准，是可以设置的。(怎么设置未查到) ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:5:3","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"5.4 容器的总结 Docker 容器，我们就可以用下面这个“全景图”描述出来： 其包含如下几个部分: 这个容器进程“python app.py”，运行在由 Linux Namespace 和 Cgroups 构成的隔离环境里； 它运行所需要的各种文件，比如 python，app.py，以及整个操作系统文件，则由多个联合挂载在一起的 rootfs 层提供。 rootfs 层的最下层，是来自 Docker 镜像的只读层 只读层之上，是 Docker 自己添加的 Init 层，用来存放被临时修改过的 /etc/hosts 等文件 rootfs 的最上层是一个可读写层，它以 Copy-on-Write 的方式存放任何对只读层的修改，容器声明的 Volume 的挂载点，也出现在这一层 从这个结构中我们不难看出，一个正在运行的 Linux 容器，其实可以被“一分为二”地看待： 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs，这一部分我们称为“容器镜像”（Container Image），是容器的静态视图； 一个由 Namespace+Cgroups 构成的隔离环境，这一部分我们称为“容器运行时”（Container Runtime），是容器的动态视图。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:5:4","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"6. 从容器到 kubernetes ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:6:0","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"6.1 kubernetes 架构 Kubernetes 的架构由 Master 和 Node 两种节点组成，而这两种角色分别对应着控制节点和计算节点。 控制节点，即 Master 节点，由三个紧密协作的独立组件组合而成，它们分别是: 负责 API 服务的 kube-apiserver 负责调度的 kube-scheduler 负责容器编排的 kube-controller-manager 整个集群的持久化数据，则由 kube-apiserver 处理后保存在 Etcd 中 计算节点上最核心的部分，则是一个叫作 kubelet 的组件 kubelet 主要负责同容器运行时（比如 Docker 项目）打交道。这个交互所依赖的，是一个称作 CRI（Container Runtime Interface） 的远程调用接口，这个接口定义了容器运行时的各项核心操作 具体的容器运行时，比如 Docker 项目，则一般通过 OCI 这个容器运行时规范同底层的 Linux 操作系统进行交互，即：把 CRI 请求翻译成对 Linux 操作系统的调用（操作 Linux Namespace 和 Cgroups 等） kubelet 还通过 gRPC 协议同一个叫作 Device Plugin 的插件进行交互。这个插件，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件，也是基于 Kubernetes 项目进行机器学习训练、高性能作业支持等工作必须关注的功能 kubelet 的另一个重要功能，则是调用网络插件和存储插件为容器配置网络和持久化存储。这两个插件与 kubelet 进行交互的接口，分别是 CNI（Container Networking Interface） 和 CSI（Container Storage Interface） 。 Kubernetes 从 Google Borg 系统演化而来。因此从一开始就把关注点放到了如何编排、管理、调度用户提交的作业上。这个出发点来自于 Borg 的研究人员在论文中提到的一个非常重要的观点：运行在大规模集群中的各种任务之间，实际上存在着各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:6:1","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["architecture"],"content":"6.2 kubernetes 核心功能 所以 Kubernetes 项目最主要的设计思想是，从更宏观的角度，以统一的方式来定义任务之间的各种关系，并且为将来支持更多种类的关系留有余地。除了应用与应用之间的关系外，应用运行的形态是影响“如何容器化这个应用”的第二个重要因素。 正是基于容器间关系和形态两个维度，Kubernetes 演化出了下面的核心功能: 当我们在使用这些核心功能时 Kubernetes 所推崇的使用方法是： 首先，通过一个“编排对象”，比如 Pod、Job、CronJob 等，来描述你试图管理的应用； 然后，再为它定义一些“服务对象”，比如 Service、Secret、Horizontal Pod Autoscaler（自动水平扩展器）等。这些对象，会负责具体的平台级功能。 这种使用方法，就是所谓的声明式 API。这种 API 对应的编排对象和服务对象，都是 Kubernetes 项目中的 API 对象（API Object）。 过去很多的集群管理项目（比如 Yarn、Mesos，以及 Swarm）所擅长的，都是把一个容器，按照某种规则，放置在某个最佳节点上运行起来。这种功能，我们称为“调度”。而 Kubernetes 项目所擅长的，是按照用户的意愿和整个系统的规则，完全自动化地处理好容器之间的各种关系。这种功能，就是我们经常听到的一个概念：编排。所以说，Kubernetes 项目的本质，是为用户提供一个具有普遍意义的容器编排工具。 不过，更重要的是，Kubernetes 项目为用户提供的不仅限于一个工具。它真正的价值，乃在于提供了一套基于容器构建分布式系统的基础依赖。 ","date":"2020-08-01","objectID":"/posts/architecture/k8s/k8s_use/01_k8s/:6:2","tags":["k8s"],"title":"容器基础","uri":"/posts/architecture/k8s/k8s_use/01_k8s/"},{"categories":["loveit"],"content":"探索 Hugo - LoveIt 主题的全部内容和背后的核心概念.","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"探索 Hugo - LoveIt 主题的全部内容和背后的核心概念. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:0:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"1 准备 由于 Hugo 提供的便利性, Hugo 本身是这个主题唯一的依赖. 直接安装满足你操作系统 (Windows, Linux, macOS) 的最新版本  Hugo (\u003e 0.62.0). 为什么不支持早期版本的 Hugo? 由于 Markdown 渲染钩子函数 在 Hugo 圣诞节版本 中被引入, 本主题只支持高于 0.62.0 的 Hugo 版本. 推荐使用 Hugo extended 版本 由于这个主题的一些特性需要将  SCSS 转换为  CSS, 推荐使用 Hugo extended 版本来获得更好的使用体验. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:1:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2 安装 以下步骤可帮助你初始化新网站. 如果你根本不了解 Hugo, 我们强烈建议你按照此 快速入门文档 进一步了解它. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.1 创建你的项目 Hugo 提供了一个 new 命令来创建一个新的网站: hugo new site my_website cd my_website ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:1","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.2 安装主题 LoveIt 主题的仓库是: https://github.com/dillonzq/LoveIt. 你可以下载主题的 最新版本  .zip 文件 并且解压放到 themes 目录. 另外, 也可以直接把这个主题克隆到 themes 目录: git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 或者, 初始化你的项目目录为 git 仓库, 并且把主题仓库作为你的网站目录的子模块: git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:2","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.3 基础配置 以下是 LoveIt 主题的基本配置: baseURL = \"http://example.org/\" # [en, zh-cn, fr, ...] 设置默认的语言 defaultContentLanguage = \"zh-cn\" # 网站语言, 仅在这里 CN 大写 languageCode = \"zh-CN\" # 是否包括中日韩文字 hasCJKLanguage = true # 网站标题 title = \"我的全新 Hugo 网站\" # 更改使用 Hugo 构建网站时使用的默认主题 theme = \"LoveIt\" [params] # LoveIt 主题版本 version = \"0.2.X\" [menu] [[menu.main]] identifier = \"posts\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" name = \"文章\" url = \"/posts/\" # 当你将鼠标悬停在此菜单链接上时, 将显示的标题 title = \"\" weight = 1 [[menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" weight = 2 [[menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" weight = 3 # Hugo 解析文档的配置 [markup] # 语法高亮设置 (https://gohugo.io/content-management/syntax-highlighting) [markup.highlight] # false 是必要的设置 (https://github.com/dillonzq/LoveIt/issues/158) noClasses = false 注意 在构建网站时, 你可以使用 --theme 选项设置主题. 但是, 我建议你修改配置文件 (config.toml) 将本主题设置为默认主题. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:3","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.4 创建你的第一篇文章 以下是创建第一篇文章的方法: hugo new posts/first_post.md 通过添加一些示例内容并替换文件开头的标题, 你可以随意编辑文章. 注意 默认情况下, 所有文章和页面均作为草稿创建. 如果想要渲染这些页面, 请从元数据中删除属性 draft: true, 设置属性 draft: false 或者为 hugo 命令添加 -D/--buildDrafts 参数. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:4","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.5 在本地启动网站 使用以下命令启动网站: hugo serve 去查看 http://localhost:1313. 基本配置下的预览 技巧 当你运行 hugo serve 时, 当文件内容更改时, 页面会随着更改自动刷新. 注意 由于本主题使用了 Hugo 中的 .Scratch 来实现一些特性, 非常建议你为 hugo server 命令添加 --disableFastRender 参数来实时预览你正在编辑的文章页面. hugo serve --disableFastRender ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:5","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"2.6 构建网站 当你准备好部署你的网站时, 运行以下命令: hugo 会生成一个 public 目录, 其中包含你网站的所有静态内容和资源. 现在可以将其部署在任何 Web 服务器上. 技巧 网站内容可以通过 Netlify 自动发布和托管 (了解有关通过 Netlify 进行 HUGO 自动化部署 的更多信息). 或者, 您可以使用 AWS Amplify, Github pages, Render 以及更多… ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:2:6","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"3 配置 ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:3:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"3.1 网站配置 除了 Hugo 全局配置 和 菜单配置 之外, LoveIt 主题还允许您在网站配置中定义以下参数 (这是一个示例 config.toml, 其内容为默认值). 请打开下面的代码块查看完整的示例配置 : [params] # LoveIt 主题版本 version = \"0.2.X\" # 网站描述 description = \"这是我的全新 Hugo 网站\" # 网站关键词 keywords = [\"Theme\", \"Hugo\"] # 网站默认主题样式 (\"light\", \"dark\", \"auto\") defaultTheme = \"auto\" # 公共 git 仓库路径，仅在 enableGitInfo 设为 true 时有效 gitRepo = \"\" # 哪种哈希函数用来 SRI, 为空时表示不使用 SRI # (\"sha256\", \"sha384\", \"sha512\", \"md5\") fingerprint = \"\" # 日期格式 dateFormat = \"2006-01-02\" # 网站图片, 用于 Open Graph 和 Twitter Cards images = [\"/logo.png\"] # 应用图标配置 [params.app] # 当添加到 iOS 主屏幕或者 Android 启动器时的标题, 覆盖默认标题 title = \"LoveIt\" # 是否隐藏网站图标资源链接 noFavicon = false # 更现代的 SVG 网站图标, 可替代旧的 .png 和 .ico 文件 svgFavicon = \"\" # Android 浏览器主题色 themeColor = \"#ffffff\" # Safari 图标颜色 iconColor = \"#5bbad5\" # Windows v8-10磁贴颜色 tileColor = \"#da532c\" # 搜索配置 [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" # 页面头部导航栏配置 [params.header] # 桌面端导航栏模式 (\"fixed\", \"normal\", \"auto\") desktopMode = \"fixed\" # 移动端导航栏模式 (\"fixed\", \"normal\", \"auto\") mobileMode = \"auto\" # 页面头部导航栏标题配置 [params.header.title] # LOGO 的 URL logo = \"\" # 标题名称 name = \"\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" # 是否为标题显示打字机动画 typeit = false # 页面底部信息配置 [params.footer] enable = true # 自定义内容 (支持 HTML 格式) custom = '' # 是否显示 Hugo 和主题信息 hugo = true # 是否显示版权信息 copyright = true # 是否显示作者 author = true # 网站创立年份 since = 2019 # ICP 备案信息，仅在中国使用 (支持 HTML 格式) icp = \"\" # 许可协议信息 (支持 HTML 格式) license = '\u003ca rel=\"license external nofollow noopener noreffer\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\"\u003eCC BY-NC 4.0\u003c/a\u003e' # Section (所有文章) 页面配置 [params.section] # section 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # List (目录或标签) 页面配置 [params.list] # list 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # 主页配置 [params.home] # RSS 文章数目 rss = 10 # 主页个人信息 [params.home.profile] enable = true # Gravatar 邮箱，用于优先在主页显示的头像 gravatarEmail = \"\" # 主页显示头像的 URL avatarURL = \"/images/avatar.png\" # 主页显示的网站标题 (支持 HTML 格式) title = \"\" # 主页显示的网站副标题 subtitle = \"这是我的全新 Hugo 网站\" # 是否为副标题显示打字机动画 typeit = true # 是否显示社交账号 social = true # 免责声明 (支持 HTML 格式) disclaimer = \"\" # 主页文章列表 [params.home.posts] enable = true # 主页每页显示文章数量 paginate = 6 # 被 params.page 中的 hiddenFromHomePage 替代 # 当你没有在文章前置参数中设置 \"hiddenFromHomePage\" 时的默认行为 defaultHiddenFromHomePage = false # 作者的社交信息设置 [params.social] GitHub = \"xxxx\" Linkedin = \"\" Twitter = \"xxxx\" Instagram = \"xxxx\" Facebook = \"xxxx\" Telegram = \"xxxx\" Medium = \"\" Gitlab = \"\" Youtubelegacy = \"\" Youtubecustom = \"\" Youtubechannel = \"\" Tumblr = \"\" Quora = \"\" Keybase = \"\" Pinterest = \"\" Reddit = \"\" Codepen = \"\" FreeCodeCamp = \"\" Bitbucket = \"\" Stackoverflow = \"\" Weibo = \"\" Odnoklassniki = \"\" VK = \"\" Flickr = \"\" Xing = \"\" Snapchat = \"\" Soundcloud = \"\" Spotify = \"\" Bandcamp = \"\" Paypal = \"\" Fivehundredpx = \"\" Mix = \"\" Goodreads = \"\" Lastfm = \"\" Foursquare = \"\" Hackernews = \"\" Kickstarter = \"\" Patreon = \"\" Steam = \"\" Twitch = \"\" Strava = \"\" Skype = \"\" Whatsapp = \"\" Zhihu = \"\" Douban = \"\" Angellist = \"\" Slidershare = \"\" Jsfiddle = \"\" Deviantart = \"\" Behance = \"\" Dribbble = \"\" Wordpress = \"\" Vine = \"\" Googlescholar = \"\" Researchgate = \"\" Mastodon = \"\" Thingiverse = \"\" Devto = \"\" Gitea = \"\" XMPP = \"\" Matrix = \"\" Bilibili = \"\" Email = \"xxxx@xxxx.com\" RSS = true # # 文章页面配置 [params.page] # 是否在主页隐藏一篇文章 hiddenFromHomePage = false # 是否在搜索结果中隐藏一篇文章 hiddenFromSearch = false # 是否使用 twemoji twemoji = false # 是否使用 lightgallery lightgallery = false # 是否使用 ruby 扩展语法 ruby = true # 是否使用 fraction 扩展语法 fraction = true # 是否使用 fontawesome 扩展语法 fontawesome = true # 是否在文章页面显示原始 Markdown 文档链接 linkToMarkdown = true # 是否在 RSS 中显示全文内容 rssFullText = ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:3:1","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"3.2 网站图标, 浏览器配置, 网站清单 强烈建议你把: apple-touch-icon.png (180x180) favicon-32x32.png (32x32) favicon-16x16.png (16x16) mstile-150x150.png (150x150) android-chrome-192x192.png (192x192) android-chrome-512x512.png (512x512) 放在 /static 目录. 利用 https://realfavicongenerator.net/ 可以很容易地生成这些文件. 可以自定义 browserconfig.xml 和 site.webmanifest 文件来设置 theme-color 和 background-color. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:3:2","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"3.3 自定义样式 注意 Hugo extended 版本对于自定义样式是必需的. 通过定义自定义 .scss 样式文件, LoveIt 主题支持可配置的样式. 包含自定义 .scss 样式文件的目录相对于 你的项目根目录 的路径为 assets/css. 在 assets/css/_override.scss 中, 你可以覆盖 themes/LoveIt/assets/css/_variables.scss 中的变量以自定义样式. 这是一个例子: @import url('https://fonts.googleapis.com/css?family=Fira+Mono:400,700\u0026display=swap\u0026subset=latin-ext'); $code-font-family: Fira Mono, Source Code Pro, Menlo, Consolas, Monaco, monospace; 在 assets/css/_custom.scss 中, 你可以添加一些 CSS 样式代码以自定义样式. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:3:3","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"4 多语言和 i18n LoveIt 主题完全兼容 Hugo 的多语言模式, 并且支持在网页上切换语言. 语言切换 ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:4:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"4.1 兼容性 语言 Hugo 代码 HTML lang 属性 主题文档 Lunr.js 支持 英语 en en 简体中文 zh-cn zh-CN 法语 fr fr 波兰语 pl pl 巴西葡萄牙语 pt-br pt-BR 意大利语 it it 西班牙语 es es 德语 de de 塞尔维亚语 pl pl 俄语 ru ru 罗马尼亚语 ro ro 越南语 vi vi ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:4:1","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"4.2 基本配置 学习了 Hugo如何处理多语言网站 之后, 请在 站点配置 中定义你的网站语言. 例如, 一个支持英语, 中文和法语的网站配置: # [en, zh-cn, fr, pl, ...] 设置默认的语言 defaultContentLanguage = \"zh-cn\" [languages] [languages.en] weight = 1 title = \"My New Hugo Site\" languageCode = \"en\" languageName = \"English\" [[languages.en.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"Posts\" url = \"/posts/\" title = \"\" weight = 1 [[languages.en.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"Tags\" url = \"/tags/\" title = \"\" weight = 2 [[languages.en.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"Categories\" url = \"/categories/\" title = \"\" weight = 3 [languages.zh-cn] weight = 2 title = \"我的全新 Hugo 网站\" # 网站语言, 仅在这里 CN 大写 languageCode = \"zh-CN\" languageName = \"简体中文\" # 是否包括中日韩文字 hasCJKLanguage = true [[languages.zh-cn.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"文章\" url = \"/posts/\" title = \"\" weight = 1 [[languages.zh-cn.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" weight = 2 [[languages.zh-cn.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" weight = 3 [languages.fr] weight = 3 title = \"Mon nouveau site Hugo\" languageCode = \"fr\" languageName = \"Français\" [[languages.fr.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"Postes\" url = \"/posts/\" title = \"\" weight = 1 [[languages.fr.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"Balises\" url = \"/tags/\" title = \"\" weight = 2 [[languages.fr.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"Catégories\" url = \"/categories/\" title = \"\" weight = 3 然后, 对于每个新页面, 将语言代码附加到文件名中. 单个文件 my-page.md 需要分为三个文件: 英语: my-page.en.md 中文: my-page.zh-cn.md 法语: my-page.fr.md 注意 请注意, 菜单中仅显示翻译的页面. 它不会替换为默认语言内容. 技巧 也可以使用 文章前置参数 来翻译网址. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:4:2","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"4.3 修改默认的翻译字符串 翻译字符串用于在主题中使用的常见默认值. 目前提供一些语言的翻译, 但你可能自定义其他语言或覆盖默认值. 要覆盖默认值, 请在你项目的 i18n 目录 i18n/\u003clanguageCode\u003e.toml 中创建一个新文件，并从 themes/LoveIt/i18n/en.toml 中获得提示. 另外, 由于你的翻译可能会帮助到其他人, 请花点时间通过  创建一个 PR 来贡献主题翻译, 谢谢! ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:4:3","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"5 搜索 基于 Lunr.js 或 algolia, LoveIt 主题支持搜索功能. ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:5:0","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"5.1 输出配置 为了生成搜索功能所需要的 index.json, 请在你的 网站配置 中添加 JSON 输出文件类型到 outputs 部分的 home 字段中. [outputs] home = [\"HTML\", \"RSS\", \"JSON\"] ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:5:1","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["loveit"],"content":"5.2 搜索配置 基于 Hugo 生成的 index.json 文件, 你可以激活搜索功能. 这是你的 网站配置 中的搜索部分: [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" 怎样选择搜索引擎? 以下是两种搜索引擎的对比: lunr: 简单, 无需同步 index.json, 没有 contentLength 的限制, 但占用带宽大且性能低 (特别是中文需要一个较大的分词依赖库) algolia: 高性能并且占用带宽低, 但需要同步 index.json 且有 contentLength 的限制 文章内容被 h2 和 h3 HTML 标签切分来提高查询效果并且基本实现全文搜索. contentLength 用来限制 h2 和 h3 HTML 标签开头的内容部分的最大长度. 关于 algolia 的使用技巧 你需要上传 index.json 到 algolia 来激活搜索功能. 你可以使用浏览器来上传 index.json 文件但是一个自动化的脚本可能效果更好. Algolia Atomic 是一个不错的选择. 为了兼容 Hugo 的多语言模式, 你需要上传不同语言的 index.json 文件到对应的 algolia index, 例如 zh-cn/index.json 或 fr/index.json… ","date":"2020-03-06","objectID":"/posts/hugo/loveit_config/:5:2","tags":["loveit"],"title":"Loveit 配置","uri":"/posts/hugo/loveit_config/"},{"categories":["Linux"],"content":"7.3 Go 语言的性能优化工具","date":"2020-03-04","objectID":"/posts/linux/linux_perf/63.go%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","tags":["Linux 性能调优"],"title":"7.3 Go 语言的性能优化工具","uri":"/posts/linux/linux_perf/63.go%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"7.2 Java 语言的性能优化工具","date":"2020-03-03","objectID":"/posts/linux/linux_perf/62.java%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","tags":["Linux 性能调优"],"title":"7.2 Java 语言的性能优化工具","uri":"/posts/linux/linux_perf/62.java%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"7.1 Python 语言的性能优化工具","date":"2020-03-02","objectID":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/","tags":["Linux 性能调优"],"title":"7.1 Python 语言的性能优化工具","uri":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"工具 systemtap-python-tools vprof py-spy ","date":"2020-03-02","objectID":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/:1:0","tags":["Linux 性能调优"],"title":"7.1 Python 语言的性能优化工具","uri":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"参考 pyflame python 性能分析 manpage-perf-python ","date":"2020-03-02","objectID":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/:2:0","tags":["Linux 性能调优"],"title":"7.1 Python 语言的性能优化工具","uri":"/posts/linux/linux_perf/61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"6.3 案例-redis性能优化","date":"2020-02-25","objectID":"/posts/linux/linux_perf/53_redis%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","tags":["Linux 性能调优"],"title":"6.3 案例-redis性能优化","uri":"/posts/linux/linux_perf/53_redis%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"本节我们来介绍一个Redis性能优化的案例。 ","date":"2020-02-25","objectID":"/posts/linux/linux_perf/53_redis%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/:0:0","tags":["Linux 性能调优"],"title":"6.3 案例-redis性能优化","uri":"/posts/linux/linux_perf/53_redis%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"6.3 案例-MySQL性能优化","date":"2020-02-24","objectID":"/posts/linux/linux_perf/52_mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","tags":["Linux 性能调优"],"title":"6.3 案例-MySQL性能优化","uri":"/posts/linux/linux_perf/52_mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"本节我们来介绍一个MySQL性能优化的案例。 ","date":"2020-02-24","objectID":"/posts/linux/linux_perf/52_mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/:0:0","tags":["Linux 性能调优"],"title":"6.3 案例-MySQL性能优化","uri":"/posts/linux/linux_perf/52_mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"6.2 案例-容器问题","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"本节我们来学习Linux性能优化的第二个案例容器问题。来自极客时间专栏-Linux性能优化实战-46讲 ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:0:0","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1. 容器问题简介 容器封装了环境了依赖，给运维部署带来了非常大的遍历。但是任何技术都不是银弹。这些新技术，在带来诸多便捷功能之外，也带来了更高的复杂性，比如性能降低、架构复杂、排错困难等等。 容器对应用程序的影响体现在以下几个方面: 容器本身通过 cgroups 进行资源隔离，所以，在分析时要考虑 cgroups 对应用程序的影响。 容器的文件系统、网络协议栈等跟主机隔离。虽然在容器外面，我们也可以分析容器的行为，不过有时候，进入容器的命名空间内部，可能更为方便。 资源隔离导致的另一个问题是，很多动态追踪工具因为获取不到应用程序的符号链接文件，而我们通常也不会在容器内安装过多的性能排查工具，这样就导致了排查问题受阻 容器的运行可能还会依赖于其他组件，比如各种网络插件（比如 CNI）、存储插件（比如 CSI）、设备插件（比如 GPU）等，让容器的性能分析更加复杂。如果你需要分析容器性能，别忘了考虑它们对性能的影响。 ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:0","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.1 案例准备 本节我们使用一个 tomcat 服务器作为实例，来看看容器对服务的影响。 # 1. 镜像准备 git clone https://github.com/feiskyer/linux-perf-examples.git cd tomcat cd nat sudo make build # 2. 容器启动 $ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8 docker 命令参数: -m 512M: 限制容器内存为 512M –cpus 0.1: 限制容器的 CPU 使用率 ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:1","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.2 问题发现 容器启动后，我们去请求 tomcat 服务: # 1. 请求tomcat 服务 $ curl localhost:8080 curl: (56) Recv failure: Connection reset by peer # 2. 查看 tomcat 容器日志 $ docker logs -f tomcat Using CATALINA_BASE: /usr/local/tomcat Using CATALINA_HOME: /usr/local/tomcat Using CATALINA_TMPDIR: /usr/local/tomcat/temp Using JRE_HOME: /docker-java-home/jre Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar # 3. 查看 tomcat 容器状态 $ docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0f2b3fcdd257 feisky/tomcat:8 \"catalina.sh run\" 2 minutes ago Exited (137) About a minute ago tomcat # 显示容器状态，jq用来格式化json输出 $ docker inspect tomcat -f '{{json .State}}' | jq { \"Status\": \"exited\", \"Running\": false, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": true, \"Dead\": false, \"Pid\": 0, \"ExitCode\": 137, \"Error\": \"\", ... } 上面列示的命令是我们查看容器服务常用的命令。显然容器已经被 OOMKilled 了。问题是我们为 tomcat 分配了 512M 内存，大于 tomcat 应用所需的内存256M(容器内的 tomcat 程序只申请了一个 256M 的数组)，为什么容器会 OOMKilled 呢？ ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:2","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.3 dmesg 查看 OOM 异常 系统会把相关的 OOM 信息，记录到日志中，通过 dmesg 命令我们可以定位 OOM 的异常信息: $ dmesg [193038.106393] java invoked oom-killer: gfp_mask=0x14000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=0 [193038.106396] java cpuset=0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 mems_allowed=0 [193038.106402] CPU: 0 PID: 27424 Comm: java Tainted: G OE 4.15.0-1037 #39-Ubuntu [193038.106404] Hardware name: Microsoft Corporation Virtual Machine/Virtual Machine, BIOS 090007 06/02/2017 [193038.106405] Call Trace: [193038.106414] dump_stack+0x63/0x89 [193038.106419] dump_header+0x71/0x285 [193038.106422] oom_kill_process+0x220/0x440 [193038.106424] out_of_memory+0x2d1/0x4f0 [193038.106429] mem_cgroup_out_of_memory+0x4b/0x80 # 内存超 cgroups 限制 [193038.106432] mem_cgroup_oom_synchronize+0x2e8/0x320 [193038.106435] ? mem_cgroup_css_online+0x40/0x40 [193038.106437] pagefault_out_of_memory+0x36/0x7b [193038.106443] mm_fault_error+0x90/0x180 [193038.106445] __do_page_fault+0x4a5/0x4d0 [193038.106448] do_page_fault+0x2e/0xe0 [193038.106454] ? page_fault+0x2f/0x50 [193038.106456] page_fault+0x45/0x50 [193038.106459] RIP: 0033:0x7fa053e5a20d [193038.106460] RSP: 002b:00007fa0060159e8 EFLAGS: 00010206 [193038.106462] RAX: 0000000000000000 RBX: 00007fa04c4b3000 RCX: 0000000009187440 [193038.106463] RDX: 00000000943aa440 RSI: 0000000000000000 RDI: 000000009b223000 [193038.106464] RBP: 00007fa006015a60 R08: 0000000002000002 R09: 00007fa053d0a8a1 [193038.106465] R10: 00007fa04c018b80 R11: 0000000000000206 R12: 0000000100000768 [193038.106466] R13: 00007fa04c4b3000 R14: 0000000100000768 R15: 0000000010000000 [193038.106468] Task in /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 killed as a result of limit of /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 [193038.106478] memory: usage 524288kB, limit 524288kB, failcnt 77 [193038.106480] memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0 [193038.106481] kmem: usage 3708kB, limit 9007199254740988kB, failcnt 0 [193038.106481] Memory cgroup stats for /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53: cache:0KB rss:520580KB rss_huge:450560KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:520580KB inactive_file:0KB active_file:0KB unevictable:0KB [193038.106494] [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name [193038.106571] [27281] 0 27281 1153302 134371 1466368 0 0 java [193038.106574] Memory cgroup out of memory: Kill process 27281 (java) score 1027 or sacrifice child [193038.148334] Killed process 27281 (java) total-vm:4613208kB, anon-rss:517316kB, file-rss:20168kB, shmem-rss:0kB [193039.607503] oom_reaper: reaped process 27281 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB total-vm:4613208kB, anon-rss:517316kB, file-rss:20168kB 表示总的虚拟内存，匿名页常驻内存和页缓存。为什么 Tomcat 会申请这么多的堆内存呢？ ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:3","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.4 JVM 配置问题 JVM 根据系统的内存总量，来自动管理堆内存，不明确配置的话，堆内存的默认限制是物理内存的四分之一。 # 重新启动容器 $ docker rm -f tomcat $ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8 # 查看堆内存，注意单位是字节 $ docker exec tomcat java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 {product} uintx HeapSizePerGCThread = 87241520 {product} uintx InitialHeapSize := 132120576 {product} uintx LargePageHeapSizeThreshold = 134217728 {product} uintx MaxHeapSize := 2092957696 {product} 可以看到，初始堆内存的大小（InitialHeapSize）是 126MB，而最大堆内存则是 1.95GB，这可比容器限制的 512 MB 大多了。 之所以会这么大，其实是因为，容器内部看不到 Docker 为它设置的内存限制。虽然我们限制了容器的最大内存 512M，但是，从容器内部看到的限制，却并不是 512M。 $ docker exec tomcat free -m total used free shared buff/cache available Mem: 7977 521 1941 0 5514 7148 Swap: 0 0 0 问题找到了，现在只要给 JVM 正确配置内存限制为 512M 就可以了。 # 删除问题容器 $ docker rm -f tomcat # 运行新的容器 $ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8 在 Docker 容器中运行 Java 应用，一定要确保，在设置容器资源限制的同时，配置好 JVM 的资源选项（比如堆内存等）。当然，如果你可以升级 Java 版本，那么升级到 Java 10 ，就可以自动解决类似问题了。 ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:4","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.5 CPU 限制问题 现在我们重新测试，看看 tomcat 服务是否已经正常: # 请求 tomcat 服务 $ for ((i=0;i\u003c30;i++)); do curl localhost:8080; sleep 1; done curl: (56) Recv failure: Connection reset by peer curl: (56) Recv failure: Connection reset by peer Hello, wolrd! Hello, wolrd! Hello, wolrd! # 查看容器日志 $ docker logs -f tomcat ... 18-Feb-2019 12:52:00.823 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/manager] 18-Feb-2019 12:52:01.422 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [598] ms 18-Feb-2019 12:52:01.920 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"http-nio-8080\"] 18-Feb-2019 12:52:02.323 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\"ajp-nio-8009\"] 18-Feb-2019 12:52:02.523 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 22798 ms 日志显示 tomcat 启动过程，居然需要 22 秒。那么 tomcat 启动过程到底慢在哪呢？top 应该是我们很自然想到的第一个命令，但是我们需要查看的仅仅是 tomcat 服务，所以我们可以使用 pidstat 命令。 # 删除旧容器 $ docker rm -f tomcat # 运行新容器 $ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8 # 查询新容器中进程的Pid $ PID=$(docker inspect tomcat -f '{{.State.Pid}}') # 执行 pidstat $ pidstat -t -p $PID 1 12:59:28 UID TGID TID %usr %system %guest %wait %CPU CPU Command 12:59:29 0 29850 - 10.00 0.00 0.00 0.00 10.00 0 java 12:59:29 0 - 29850 0.00 0.00 0.00 0.00 0.00 0 |__java 12:59:29 0 - 29897 5.00 1.00 0.00 86.00 6.00 1 |__java ... 12:59:29 0 - 29905 3.00 0.00 0.00 97.00 3.00 0 |__java 12:59:29 0 - 29906 2.00 0.00 0.00 49.00 2.00 1 |__java 12:59:29 0 - 29908 0.00 0.00 0.00 45.00 0.00 0 |__java 输出显示等待运行的使用率（%wait）非常高，这说明，这些线程大部分时间都在等待调度，而不是真正的运行。原因很简单，因为我们设置了 --cpus 0.1 的限制。所以放开 CPU 限制即可解决 tomcat 启动慢的问题。 在容器云的环境，我们通常都要预先评估应用程序的性能，然后据此设置容器的资源限制。没有资源限制，意味着容器可以占用整个系统的资源。这样，一旦任何应用程序发生异常，就可能拖垮整个环境。 ","date":"2020-02-23","objectID":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/:1:5","tags":["Linux 性能调优"],"title":"6.2 案例-容器问题","uri":"/posts/linux/linux_perf/51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"6.1 案例-NAT 优化和丢包分析","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"本节我们来学习Linux性能优化的第一个案例 NAT 优化。来自极客时间专栏-Linux性能优化实战-42讲 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:0:0","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"1. NAT 基础 Linux 内核提供的 Netfilter 框架，允许对网络数据包进行修改（比如 NAT）和过滤（比如防火墙）。所以所谓防火墙并不是一个服务，而一个内核功能。而iptables、ip6tables、ebtables 等工具是管理和配置 Netfilter 上规则的工具。Netfilter 同样也是 LVS 四层负载均衡的基础 要掌握 iptables 的原理和使用方法，最核心的就是高清楚 Netfilter 的工作流向，即所谓的四表五链。下面是 Netfilter 工作流向的示意图 说明: 绿色背景的方框，表示表（table） 跟 table 一起的白色背景方框，则表示链（chain） 灰色的 conntrack ，表示连接跟踪模块。 conntrack 通过内核中的连接跟踪表（也就是哈希表），记录网络连接的状态，是 iptables 状态过滤（-m state）和 NAT 的实现基础。通过 conntrack 命令可以查看系统当前的连接跟踪表。内核的连接跟踪模块在维护每个连接状态的同时，也会带来很高的性能成本。 在使用 iptables 配置 NAT 规则时，Linux 需要转发来自其他 IP 的网络包，所以你千万不要忘记开启 Linux 的 IP 转发功能。 $ sysctl net.ipv4.ip_forward net.ipv4.ip_forward = 1 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:1:0","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2. NAT 优化 我们准备两个服务: 一个是通过 host NetWork 直接启动的Nginx 服务，作为测试的基准，即对照组 一个是通过 Docker NAT 启动的Nginx 服务作为实现组 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:0","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.1 对照组 # 1. 镜像准备 git clone https://github.com/feiskyer/linux-perf-examples.git cd linux-perf-examples cd nat sudo make build # 2. 运行对照组的Nginx 服务 docker run --name nginx-hostnet --privileged --network=host -itd feisky/nginx:80 curl 192.168.1.18 # 3. 更改 文件描述符限制，默认只有 1024 # 临时修改 ulimit -n 65536 # 永久修改 vi /etc/security/limits.conf # 3. 执行 ab 基准测试 # -c表示并发请求数为5000，-n表示总的请求数为10万 # -r表示套接字接收错误时仍然继续执行，-s表示设置每个请求的超时时间为2s yum install httpd-tools ab -c 2000 -n 10000 -r -s 2 http://192.168.1.18/ .... Total transferred: 8450000 bytes HTML transferred: 6120000 bytes Requests per second: 5291.69 [#/sec] (mean) Time per request: 377.951 [ms] (mean) .... # 4. 停止服务 docker rm -f nginx-hostnet ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:1","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.2 实验组服务 # 1. 启动实验组服务 $ docker run --name nginx --privileged -p 8080:8080 -itd feisky/nginx:nat curl http://192.168.1.18:8080/ # 2. 查看 NAT 规则 iptables -nL -t nat # 3. ab 测试 ab -c 2000 -n 10000 -r -s 2 http://192.168.1.18:8080/ ... Benchmarking 192.168.1.18 (be patient) apr_pollset_poll: The timeout specified has expired (70007) ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:2","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.3 追踪内核丢包 实验组并发请求数大大降低，根据前面介绍的 NAT 原理，我们有理由相信内核发生了丢包。下面我们使用Systemtap 来跟踪内核的kfree_skb。Systemtap 中 kernel.trace(“kfree_skb”)表示内核释放了一个网络缓冲区的事件。 创建一个 dropwatch.stp 的脚本文件 #! /usr/bin/env stap ############################################################ # Dropwatch.stp # Author: Neil Horman \u003cnhorman@redhat.com\u003e # An example script to mimic the behavior of the dropwatch utility # http://fedorahosted.org/dropwatch ############################################################ # Array to hold the list of drop points we find global locations # Note when we turn the monitor on and off probe begin { printf(\"Monitoring for dropped packets\\n\") } probe end { printf(\"Stopping dropped packet monitor\\n\") } # increment a drop counter for every location we drop at probe kernel.trace(\"kfree_skb\") { locations[$location] \u003c\u003c\u003c 1 } # Every 5 seconds report our drop locations probe timer.sec(5) { printf(\"\\n\") foreach (l in locations-) { printf(\"%d packets dropped at %s\\n\", @count(locations[l]), symname(l)) } delete locations } 执行 kfree_skb 动态追踪 # 1. 执行 stap 动态追踪脚本 $ stap --all-modules dropwatch.stp # 2. 执行 ab 测试，过一会就能看到上面 stap 脚本的输出 $ ab -c 5000 -n 10000 -r -s 30 http://192.168.1.18:8080/ # 3. dropwatch.stp 的输出 6120 packets dropped at nf_hook_slow 436 packets dropped at tcp_rcv_state_process 374 packets dropped at tcp_v4_rcv 10 packets dropped at netlink_broadcast_filtered 3 packets dropped at unix_stream_connect 大量丢包都发生在 nf_hook_slow 位置，我们还得再跟踪 nf_hook_slow 的执行过程。可以使用 stap，更简单的是通过 perf 来完成。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:3","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.4 跟踪 nf_hook_slow 执行过程 $ ab -c 5000 -n 10000 -r -s 30 http://192.168.0.30:8080/ # 使用 perf 记录函数调用堆栈 $ perf record -a -g -- sleep 30 # 进入 perf 交互界面，输入查找命令 / 然后，在弹出的对话框中，输入 nf_hook_slow $ perf report -g graph,0 # 实际: 实际情况是进入 nf_hook_slow 后看到的都是十六进制符号，而不是函数名，说明符号链接出现了问题。 进入 nf_hook_slow 调用栈，我们可以看到下面的调用栈: 可以看到，nf_hook_slow 调用最多的有三个地方: ipv4_conntrack_in: 接收网络包时，在连接跟踪表中查找连接，并为新的连接分配跟踪对象（Bucket） br_nf_pre_routing: 在 Linux 网桥中转发包。这是因为案例 Nginx 是一个 Docker 容器，而容器的网络通过网桥来实现； iptable_nat_ipv4_in: 接收网络包时，执行 DNAT，即把 8080 端口收到的包转发给容器 这三个来源，都是 Linux 的内核机制，所以接下来的优化，自然也是要从内核入手。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:4","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.5 conntrack 内核参数 使用 sysctl 可以查看内核选项的各种参数，我们可以先看看，内核提供了哪些 conntrack 的配置选项。 $ sysctl -a | grep conntrack net.netfilter.nf_conntrack_count = 180 net.netfilter.nf_conntrack_max = 1000 net.netfilter.nf_conntrack_buckets = 65536 net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 60 net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 120 net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 ... 最重要的有三个: net.netfilter.nf_conntrack_count，表示当前连接跟踪数； net.netfilter.nf_conntrack_max，表示最大连接跟踪数； net.netfilter.nf_conntrack_buckets，表示连接跟踪表的大小。 并发请求数是 5000，而请求数是 100000。显然，跟踪表设置成，只记录 1000 个连接，是远远不够的。 实际上，内核在工作异常时，会把异常信息记录到日志中。比如前面的 ab 测试，内核已经在日志中报出了 “nf_conntrack: table full” 的错误。执行 dmesg 命令，你就可以看到： $ dmesg | tail [104235.156774] nf_conntrack: nf_conntrack: table full, dropping packet [104243.800401] net_ratelimit: 3939 callbacks suppressed [104243.800401] nf_conntrack: nf_conntrack: table full, dropping packet [104262.962157] nf_conntrack: nf_conntrack: table full, dropping packet 其中，net_ratelimit 表示有大量的日志被压缩掉了，这是内核预防日志攻击的一种措施。而当你看到 “nf_conntrack: table full” 的错误时，就表明 nf_conntrack_max 太小了。 接下来，我们将 nf_conntrack_max 改大一些，比如改成 131072（即 nf_conntrack_buckets 的 2 倍）： $ sysctl -w net.netfilter.nf_conntrack_max=131072 $ sysctl -w net.netfilter.nf_conntrack_buckets=65536 然后再切换到终端二中，重新执行 ab 命令。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:5","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.6 查看链接追踪表 conntrack 命令行工具，来查看连接跟踪表的内容 # -L表示列表，-o表示以扩展格式显示 $ conntrack -L -o extend|head ipv4 2 tcp 6 27 TIME_WAIT src=192.168.1.18 dst=192.168.1.18 sport=60162 dport=8080 src=172.17.0.2 dst=192.168.1.18 sport=8080 dport=60162 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 use=1 ipv4 2 tcp 6 27 TIME_WAIT src=192.168.1.18 dst=192.168.1.18 sport=60398 dport=8080 src=172.17.0.2 dst=192.168.1.18 sport=8080 dport=60398 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 use=1 # 统计总的连接跟踪数 $ conntrack -L -o extended | wc -l # 统计TCP协议各个状态的连接跟踪数 $ conntrack -L -o extended | awk '/^.*tcp.*$/ {sum[$6]++} END {for(i in sum) print i, sum[i]}' conntrack v1.4.4 (conntrack-tools): 13852 flow entries have been shown. CLOSE 2075 ESTABLISHED 4 SYN_SENT 3579 TIME_WAIT 8192 # 统计各个源IP的连接跟踪数 $ conntrack -L -o extended | awk '{print $7}' | cut -d \"=\" -f 2 | sort | uniq -c | sort -nr | head -n 10 可以看到，大部分 TCP 的连接跟踪，都处于 TIME_WAIT 状态，这些处于 TIME_WAIT 的连接跟踪记录，会在超时后清理，而默认的超时时间是 120s，你可以执行下面的命令来查看： $ sysctl net.netfilter.nf_conntrack_tcp_timeout_time_wait net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 所以，如果你的连接数非常大，确实也应该考虑，适当减小超时时间。更多 conntrack 选项参见nf_conntrack文档 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:6","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2.7 总结 Linux 这种通过连接跟踪机制实现的 NAT，也常被称为有状态的 NAT，而维护状态，也带来了很高的性能成本。所以，除了调整内核行为外，在不需要状态跟踪的场景下（比如只需要按预定的 IP 和端口进行映射，而不需要动态映射），我们也可以使用无状态的 NAT （比如用 tc 或基于 DPDK 开发），来进一步提升性能。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:2:7","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3. 网络丢包分析 前面我们分析了由于连接跟踪导致的网络丢包，但这只是网络丢包众多原因中的一个。如下图所示，可能发生丢包的位置，实际上贯穿了整个网络协议栈 从下往上: 在两台 VM 连接之间，可能会发生传输失败的错误，比如网络拥塞、线路错误等； 在网卡收包后，环形缓冲区可能会因为溢出而丢包； 在链路层，可能会因为网络帧校验失败、QoS 等而丢包； 在 IP 层，可能会因为路由失败、组包大小超过 MTU 等而丢包； 在传输层，可能会因为端口未监听、资源占用超过内核限制等而丢包； 在套接字层，可能会因为套接字缓冲区溢出而丢包； 应用层，可能会因为应用程序异常而丢包； 此外，如果配置了 iptables 规则，这些网络包也可能因为 iptables 过滤规则而丢包。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:0","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.1 实践案例 本次我们使用一个存在丢包的 Nginx 服务作为案例。 # 1. 镜像构建 git clone https://github.com/feiskyer/linux-perf-examples.git cd linux-perf-examples cd packet-drop sudo make build make run # 2. 问题发现，验证 nginx 服务是否可以访问 # -c表示发送10个请求，-S表示使用TCP SYN，-p指定端口为80 $ hping3 -c 10 -S -p 80 192.168.0.30 HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=5120 rtt=7.5 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=5120 rtt=7.4 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=3.3 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=5120 rtt=3.0 ms # 3s 的 RTT ，很可能是因为丢包后重传导致的 len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=3027.2 ms --- 192.168.0.30 hping statistic --- 10 packets transmitted, 5 packets received, 50% packet loss # 50% 丢包 round-trip min/avg/max = 3.0/609.7/3027.2 ms 接下来我们就按照上面的排查思路，看看到底是哪里发生了丢包？ ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:1","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.2 链路层 网卡丢包 首先，来看最底下的链路层。当缓冲区溢出等原因导致网卡丢包时，Linux 会在网卡收发数据的统计信息中，记录下收发错误的次数。通过 ethtool 或者 netstat ，来查看网卡的丢包记录。 root@nginx:/# netstat -i Kernel Interface table Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 100 31 0 0 0 8 0 0 0 BMRU lo 65536 0 0 0 0 0 0 0 0 LRU RX-OK、RX-ERR、RX-DRP、RX-OVR ，分别表示接收时的总包数、总错误数、进入 Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。 netstat -i 的输出表明容器的虚拟网卡没有丢包。 注意，由于 Docker 容器的虚拟网卡，实际上是一对 veth pair，一端接入容器中用作 eth0，另一端在主机中接入 docker0 网桥中。veth 驱动并没有实现网络统计的功能，所以使用 ethtool -S 命令，无法得到网卡收发数据的汇总信息。 Qos 接下来，我们还要检查一下 eth0 上是否配置了 tc 规则，并查看有没有丢包。 root@nginx:/# tc -s qdisc show dev eth0 qdisc netem 800d: root refcnt 2 limit 1000 loss 30% Sent 432 bytes 8 pkt (dropped 4, overlimits 0 requeues 0) backlog 0b 0p requeues 0 tc 输出显示， eth0 上面配置了一个网络模拟排队规则（qdisc netem），并且配置了丢包率为 30%（loss 30%）。netem 模块导致了 Nginx 丢包，我们直接删掉 netem 模块就可以 root@nginx:/# tc qdisc del dev eth0 root netem loss 30% $ hping3 -c 10 -S -p 80 192.168.0.30 HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=5120 rtt=7.9 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=2 win=5120 rtt=1003.8 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=7.6 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=7.4 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=5120 rtt=3.0 ms --- 192.168.0.30 hping statistic --- 10 packets transmitted, 5 packets received, 50% packet loss round-trip min/avg/max = 3.0/205.9/1003.8 ms 但是 hping3 显示丢包问题仍然存在。既然链路层已经排查完了，我们就继续向上层分析，看看网络层和传输层有没有问题。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:2","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.3 网络层和传输层 netstat -s，可以查看各网络协议的收发汇总，以及错误信息: root@nginx:/# netstat -s Ip: Forwarding: 1 //开启转发 31 total packets received //总收包数 0 forwarded //转发包数 0 incoming packets discarded //接收丢包数 25 incoming packets delivered //接收的数据包数 15 requests sent out //发出的数据包数 Icmp: 0 ICMP messages received //收到的ICMP包数 0 input ICMP message failed //收到ICMP失败数 ICMP input histogram: 0 ICMP messages sent //ICMP发送数 0 ICMP messages failed //ICMP失败数 ICMP output histogram: Tcp: 0 active connection openings //主动连接数 0 passive connection openings //被动连接数 11 failed connection attempts //失败连接尝试数 + 0 connection resets received //接收的连接重置数 0 connections established //建立连接数 25 segments received //已接收报文数 21 segments sent out //已发送报文数 4 segments retransmitted //重传报文数 0 bad segments received //错误报文数 0 resets sent //发出的连接重置数 Udp: 0 packets received ... TcpExt: 11 resets received for embryonic SYN_RECV sockets //半连接重置数 + 0 packet headers predicted TCPTimeouts: 7 //超时数 + TCPSynRetrans: 4 //SYN重传数 + ... TCP 协议有多次超时和失败重试，并且主要错误是半连接重置。换句话说，主要的失败，都是三次握手失败。netstat -s 告诉了我们出错的位置，但是没有告诉我们具体的出错原因，我们还要继续向下进行分析。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:3","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.4 iptables 除了网络层和传输层的各种协议，iptables 和内核的连接跟踪机制也可能会导致丢包。 连接追踪 要确认是不是连接跟踪导致的问题，其实只需要对比当前的连接跟踪数和最大连接跟踪数即可。 # 容器终端中执行exit，连接追踪是操作系统级的，需要在宿主机上查看 root@nginx:/# exit exit # 主机终端中查询内核配置 $ sysctl net.netfilter.nf_conntrack_max net.netfilter.nf_conntrack_max = 262144 $ sysctl net.netfilter.nf_conntrack_count net.netfilter.nf_conntrack_count = 182 262144 \u003e 182 没有问题 iptables 对于丢包问题来说，最大的可能就是被 filter 表中的规则给丢弃了。要弄清楚这一点，就需要我们确认，那些目标为 DROP 和 REJECT 等会弃包的规则，有没有被执行到。iptables -nvL 命令，查看各条规则的统计信息。 # 在主机中执行 $ docker exec -it nginx bash # 在容器中执行 root@nginx:/# iptables -t filter -nvL Chain INPUT (policy ACCEPT 25 packets, 1000 bytes) pkts bytes target prot opt in out source destination 6 240 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 15 packets, 660 bytes) pkts bytes target prot opt in out source destination 6 264 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981 statistic 模块，执行了 30% 的随机丢包。并且 pkts 显示的确有包被丢弃了。显然把这两条规则直接删除即可: root@nginx:/# iptables -t filter -D INPUT -m statistic --mode random --probability 0.30 -j DROP root@nginx:/# iptables -t filter -D OUTPUT -m statistic --mode random --probability 0.30 -j DROP $ hping3 -c 10 -S -p 80 192.168.0.30 HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=5120 rtt=11.9 ms len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=1 win=5120 rtt=7.8 ms ... len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=5120 rtt=15.0 ms --- 192.168.0.30 hping statistic --- 10 packets transmitted, 10 packets received, 0% packet loss round-trip min/avg/max = 3.3/7.9/15.0 ms hping3 显示已经没有丢包了。不过，到目前为止，我们只能验证案例 Nginx 的 80 端口处于正常监听状态，却还没有访问 Nginx 的 HTTP 服务。 $ curl --max-time 3 http://192.168.0.30 curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received http 连接超时了，说明我们的服务还有问题。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:4","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.5 应用层抓包 对于应用层，抓包工具就是我们的大杀器了。 # 1. 抓包 root@nginx:/# tcpdump -i eth0 -nn port 80 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes # 2.发送请求 $ curl --max-time 3 http://192.168.0.30/ curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received # 3. 抓包输出 # seq 14:40:00.589235 IP 10.255.255.5.39058 \u003e 172.17.0.2.80: Flags [S], seq 332257715, win 29200, options [mss 1418,sackOK,TS val 486800541 ecr 0,nop,wscale 7], length 0 # ack 14:40:00.589277 IP 172.17.0.2.80 \u003e 10.255.255.5.39058: Flags [S.], seq 1630206251, ack 332257716, win 4880, options [mss 256,sackOK,TS val 2509376001 ecr 486800541,nop,wscale 7], length 0 # seq，ack 三次握手完成 14:40:00.589894 IP 10.255.255.5.39058 \u003e 172.17.0.2.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 486800541 ecr 2509376001], length 0 # 时间超过 3 秒，客户端发起来断开连接请求 FIN 14:40:03.589352 IP 10.255.255.5.39058 \u003e 172.17.0.2.80: Flags [F.], seq 76, ack 1, win 229, options [nop,nop,TS val 486803541 ecr 2509376001], length 0 # 服务器端重复ACK 14:40:03.589417 IP 172.17.0.2.80 \u003e 10.255.255.5.39058: Flags [.], ack 1, win 40, options [nop,nop,TS val 2509379001 ecr 486800541,nop,nop,sack 1 {76:77}], length 0 使用 Wireshark 显示TCP交互流程图: 服务器端回应了两次相同的ACK，说明中间出现了丢包。并且也没有看到 curl 发送的 GET 请求。那么，究竟是网卡丢包了，还是客户端压根儿就没发过来呢？ netstat -i 命令，确认一下网卡有没有丢包问题： root@nginx:/# netstat -i Kernel Interface table Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg eth0 100 157 0 344 0 94 0 0 0 BMRU lo 65536 0 0 0 0 0 0 0 0 LRU 接收丢包数（RX-DRP）是 344。不过问题也来了，为什么刚才用 hping3 时不丢包，现在换成 GET 就收不到了呢？ 其实，仔细观察上面 netstat 的输出界面，第二列正是每个网卡的 MTU 值。eth0 的 MTU 只有 100，而以太网的 MTU 默认值是 1500。HTTP GET ，本质上也是一个 TCP 包，但跟 SYN 包相比，它还携带了 HTTP GET 的数据。因此其大小超过 MTU 所以被丢包了。 root@nginx:/# ifconfig eth0 mtu 1500 修改完成后，再次执行 curl 命令，问题得到了解决。 ","date":"2020-02-22","objectID":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/:3:5","tags":["Linux 性能调优"],"title":"6.1 案例-NAT 优化和丢包分析","uri":"/posts/linux/linux_perf/50_nat%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"5.8 容器的性能分析工具","date":"2020-02-18","objectID":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","tags":["Linux 性能调优"],"title":"5.8 容器的性能分析工具","uri":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"本节我们来介绍一些专门用于容器性能分析的工具。 ","date":"2020-02-18","objectID":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/:0:0","tags":["Linux 性能调优"],"title":"5.8 容器的性能分析工具","uri":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1. 工具简介 本节我们将介绍如下一些性能分析工具的使用: nsenter: 可以进入容器命名空间 sysdig: 用于容器的动态追踪，汇集了一些列性能工具的优势 ","date":"2020-02-18","objectID":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/:1:0","tags":["Linux 性能调优"],"title":"5.8 容器的性能分析工具","uri":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2. nsenter nsenter 作用: 可以进入容器命名空间 # 1. 安装 docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter # 2. 使用 # 由于这两个容器共享同一个网络命名空间，所以我们只需要进入app的网络命名空间即可 $ PID=$(docker inspect --format {{.State.Pid}} app) # -i表示显示网络套接字信息 $ nsenter --target $PID --net -- lsof -i COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME redis-ser 9085 systemd-network 6u IPv4 15447972 0t0 TCP localhost:6379 (LISTEN) redis-ser 9085 systemd-network 8u IPv4 15448709 0t0 TCP localhost:6379-\u003elocalhost:32996 (ESTABLISHED) python 9181 root 3u IPv4 15448677 0t0 TCP *:http (LISTEN) python 9181 root 5u IPv4 15449632 0t0 TCP localhost:32996-\u003elocalhost:6379 (ESTABLISHED) ","date":"2020-02-18","objectID":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/:2:0","tags":["Linux 性能调优"],"title":"5.8 容器的性能分析工具","uri":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"3. sysdig ","date":"2020-02-18","objectID":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/:3:0","tags":["Linux 性能调优"],"title":"5.8 容器的性能分析工具","uri":"/posts/linux/linux_perf/49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"5.8 systemtap-lwtools","date":"2020-02-17","objectID":"/posts/linux/linux_perf/48_systemtap_lwt/","tags":["Linux 性能调优"],"title":"5.8 systemtap-lwtools","uri":"/posts/linux/linux_perf/48_systemtap_lwt/"},{"categories":["Linux"],"content":"5.7 DTraceToolkit","date":"2020-02-16","objectID":"/posts/linux/linux_perf/47_dtracetoolkit/","tags":["Linux 性能调优"],"title":"5.7 DTraceToolkit","uri":"/posts/linux/linux_perf/47_dtracetoolkit/"},{"categories":["Linux"],"content":"5.6 bcc","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"1. bcc 简介 BCC 软件包是使用 eBPF 开发的工具包。这些工具是提供的编写 eBPF 工具的参考示例，并且很实用。它们的使用场景如下图所示： 不过需要注意的是很多 eBPF 的新特性，都需要比较新的内核版本（如下图所示） ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:1:0","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"1.2 安装 # 注意：bcc-tools 需要内核版本为 4.1 或者更新的版本， CentOS，需要手动升级内核版本后再安装。 yum install bcc -y rpm -ql bcc-tools # bcc 工具位于 /usr/share/bcc/tools/ 目录中 cd /usr/share/bcc/tools/ ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:1:1","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"2. CPU 监测 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:2:0","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"3. 内存监测 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:3:0","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"3.1 cachestat cachestat [t [n]] 作用: 查看整个操作系统缓存的读写命中情况 参数: $ cachestat 1 3 TOTAL MISSES HITS DIRTIES BUFFERS_MB CACHED_MB 2 0 2 1 17 279 2 0 2 1 17 279 2 0 2 1 17 279 指标含义: TOTAL: 表示总的 I/O 次数； MISSES: 表示缓存未命中的次数； HITS: 表示缓存命中的次数； DIRTIES: 表示新增到缓存中的脏页数； BUFFERS_MB: 表示 Buffers 的大小，以 MB 为单位； CACHED_MB: 表示 Cache 的大小，以 MB 为单位。 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:3:1","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"3.2 cachetop cachetop [interval] 作用: 类似 top，实时查看间隔时间内每个进程的缓存命中情况 输出: 默认按照缓存的命中次数（HITS）排序 说明: cachetop 并不会把直接 I/O 算进来。因此观察缓存命中率的同时，我们也需要注意 HITS 命中次数，看起是否匹配应用程序实际I/O大小，以免遗漏直接I/O造成的影响 $ cachetop 11:58:50 Buffers MB: 258 / Cached MB: 347 / Sort: HITS / Order: ascending PID UID CMD HITS MISSES DIRTIES READ_HIT% WRITE_HIT% 13029 root python 1 0 0 100.0% 0.0% 指标含义: MISSES: 表示缓存未命中的次数； HITS: 表示缓存命中的次数； DIRTIES: 表示新增到缓存中的脏页数； READ_HIT: 表示读缓存命中率 WRITE_HIT: 表示写缓存命中率 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:3:2","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"3.3 memleak memleak [t [c]] 作用: memleak 可以跟踪系统或指定进程的内存分配、释放请求，然后定期输出一个未释放内存和相应调用栈的汇总情况（默认 5 秒）。 参数: -p PID, –pid PID: 执行跟踪的进程，不指定跟踪内核的内存分配和释放 -a, –show-allocs: 表示显示每个内存分配请求的大小以及地址 ./memleak -h usage: memleak [-h] [-p PID] [-t] [-a] [-o OLDER] [-c COMMAND] [--combined-only] [-s SAMPLE_RATE] [-T TOP] [-z MIN_SIZE] [-Z MAX_SIZE] [-O OBJ] [--percpu] [interval] [count] Trace outstanding memory allocations that weren\\'t freed. Supports both user-mode allocations made with libc functions and kernel-mode allocations made with kmalloc/kmem_cache_alloc/get_free_pages and corresponding memory release functions. positional arguments: interval interval in seconds to print outstanding allocations count number of times to print the report before exiting optional arguments: -h, --help show this help message and exit -p PID, --pid PID the PID to trace; if not specified, trace kernel allocs -t, --trace print trace messages for each alloc/free call -a, --show-allocs show allocation addresses and sizes as well as call stacks -o OLDER, --older OLDER prune allocations younger than this age in milliseconds -c COMMAND, --command COMMAND execute and trace the specified command --combined-only show combined allocation statistics only -s SAMPLE_RATE, --sample-rate SAMPLE_RATE sample every N-th allocation to decrease the overhead -T TOP, --top TOP display only this many top allocating stacks (by size) -z MIN_SIZE, --min-size MIN_SIZE capture only allocations larger than this size -Z MAX_SIZE, --max-size MAX_SIZE capture only allocations smaller than this size -O OBJ, --obj OBJ attach to allocator functions in the specified object --percpu trace percpu allocations EXAMPLES: ./memleak -p $(pidof allocs) Trace allocations and display a summary of \"leaked\" (outstanding) allocations every 5 seconds ./memleak -p $(pidof allocs) -t Trace allocations and display each individual allocator function call ./memleak -ap $(pidof allocs) 10 Trace allocations and display allocated addresses, sizes, and stacks every 10 seconds for outstanding allocations ./memleak -c \"./allocs\" Run the specified command and trace its allocations ./memleak Trace allocations in kernel mode and display a summary of outstanding allocations every 5 seconds ./memleak -o 60000 Trace allocations in kernel mode and display a summary of outstanding allocations that are at least one minute (60 seconds) old ./memleak -s 5 Trace roughly every 5th allocation, to reduce overhead 下面是 memleak 定位内存泄漏的一个示例: $ /usr/share/bcc/tools/memleak -p $(pidof app) -a Attaching to pid 12512, Ctrl+C to quit. [03:00:41] Top 10 stacks with outstanding allocations: addr = 7f8f70863220 size = 8192 addr = 7f8f70861210 size = 8192 addr = 7f8f7085b1e0 size = 8192 addr = 7f8f7085f200 size = 8192 addr = 7f8f7085d1f0 size = 8192 40960 bytes in 5 allocations from stack fibonacci+0x1f [app] child+0x4f [app] start_thread+0xdb [libpthread-2.27.so] ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:3:3","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"4. 磁盘I/O分析 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:4:0","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"4.1 filetop filetop 作用: 主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。 # 切换到工具目录 $ cd /usr/share/bcc/tools # -C 选项表示输出新内容时不清空屏幕 $ ./filetop -C TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 0 1 0 2832 R 669.txt 514 python 0 1 0 2490 R 667.txt ... TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 2 0 5957 0 R 651.txt 514 python 2 0 5371 0 R 112.txt 指标含义: 输出了 8 列内容，分别是线程 ID、线程命令行、读写次数、读写的大小（单位 KB）、文件类型以及读写的文件名称。 ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:4:1","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"4.2 opensnoop opensnoop:s 作用: 动态跟踪内核中的 open 系统调用 $ opensnoop 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/651.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/652.txt ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:4:2","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"4.3 biosnoop ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:4:3","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"4.4 biotop ","date":"2020-02-15","objectID":"/posts/linux/linux_perf/46_bcc/:4:4","tags":["Linux 性能调优"],"title":"5.6 bcc","uri":"/posts/linux/linux_perf/46_bcc/"},{"categories":["Linux"],"content":"5.5 perf-tool","date":"2020-02-14","objectID":"/posts/linux/linux_perf/45_perf_tool/","tags":["Linux 性能调优"],"title":"5.5 perf-tool","uri":"/posts/linux/linux_perf/45_perf_tool/"},{"categories":["Linux"],"content":"5.3 ps","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps 命令 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:0:0","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps ps [options] 作用：ps 用于查看进程状态信息 说明：ps 命令参数很乱，我们以常用命令的方式来说明其使用，下面只列出过滤参数 过滤参数: u user: 指定用户的所有进程 o [field1,field2…]: 指定显示的字段 k [-]field: 以指定字段排序 -h：去掉标题栏 -H: 显示线程详细信息 -f: 以树形结构显示进程间关系 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:0","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"pstree # -t表示显示线程，-a表示显示命令行参数 $ pstree -t -a -p 27458 mysqld,27458 --log_bin=on --sync_binlog=1 ... ├─{mysqld},27922 ├─{mysqld},27923 └─{mysqld},28014 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:1","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps aux f ps aux f 作用：显示所有进程，并显示进程树 参数: a表示所有用户，u表示面向用户的扩展信息，x表示没有终端的进程 ps aux f USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 2 0.0 0.0 0 0 ? S Feb11 33:45 [kthreadd] root 3 0.0 0.0 0 0 ? S Feb11 2:21 \\_ [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S\u003c Feb11 0:00 \\_ [kworker/0:0H] 输出: PID: 进程ID %CPU: CPU 使用率 %MEM: 常驻内存占用百分比 VSZ: 虚拟内存大小 RSS: 常驻内存大小 TTY: 所属终端 STAT: 进程的状态： TIME: 进程使用的总cpu时间 COMMAND: 启动命令 说明: RSS 显示主存使用，它也包括如系统库在内的映射共享段，可能会被几十个进程共享。如果 RSS 求和，可能会发现超过系统可用内存，这是由于重复计算了共享内存。分析共享内存可以使用 pmap 命令。 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:2","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps -efT ps -efT 作用: 显示所有线程信息 参数: e 表示所有进程，f 表示完整信息，T 表示显示线程 ps -efT|head UID PID SPID PPID C STIME TTY TIME CMD root 1 1 0 0 11:44 ? 00:00:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 22 root 2 2 0 0 11:44 ? 00:00:00 [kthreadd] root 3 3 2 0 11:44 ? 00:00:00 [ksoftirqd/0] 指标含义: SPID: 线程ID ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:3","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps -efl ps -efl 作用: 显示所有进程 参数: e 表示所有进程，f 表示完整信息 ps -efl k -rss|head -10 F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD 4 S analyzer 58379 58363 99 80 0 - 585639778 futex_ Feb29 ? 30277:59 /opt/jdk-10.0.2/bin/java 输出: UID： 用户ID（effective User ID） PID： 进程ID（Process ID） PPID： 父进程的进程ID（Parent Process id） C: cpu 使用率，百分比但没有 % PRI：进程优先级 NI： Nice 值 ADDR： 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-” SZ： 使用掉的内存大小 WCHAN： STIME： 启动时间 TTY： 与进程关联的终端（tty） TIME： 进程使用的总cpu时间 CMD： 正在执行的命令行命令 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:4","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps axZ ps axZ 作用: 显示进程的安全信息(selinux) ps axZ|head -10 LABEL PID TTY STAT TIME COMMAND system_u:system_r:init_t:s0 1 ? Ss 138:29 /usr/lib/systemd/systemd --switched-root --system --deserialize 21 system_u:system_r:kernel_t:s0 2 ? S 33:45 [kthreadd] system_u:system_r:kernel_t:s0 3 ? S 2:21 [ksoftirqd/0] system_u:system_r:kernel_t:s0 5 ? S\u003c 0:00 [kworker/0:0H] system_u:system_r:kernel_t:s0 8 ? S 3:23 [migration/0] 输出: label: selinux 的进程标识 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:5","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps axjf ps axjf 作用: 显示进程树 ps axjf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 2 0 0 ? -1 S 0 33:46 [kthreadd] 2 3 0 0 ? -1 S 0 2:21 \\_ [ksoftirqd/0] 2 5 0 0 ? -1 S\u003c 0 0:00 \\_ [kworker/0:0H] 2 8 0 0 ? -1 S 0 3:23 \\_ [migration/0] 输出: PPID: 父进程ID PID: 进程ID PGID: 进程组 ID，等于 leader 进程的pid SID: session id TTY: 进程关联的终端 TPGID: 后台进程组关联的终端id？ STAT: 进程状态 UID: effective User ID ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:6","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps -eo 自定义 ps 显示的列 ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm ps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm ps -Ao pid,tt,user,fname,tmout,f,wchan ps -eo pid,maj_flt,min_flt # 显示主次缺页异常数 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:7","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"ps -U root -u root u ps -U root -u root u 作用: 显示real user \u0026 effective user 为 root 的进程 ps -C syslogd -o pid= 作用: 打印 syslogd 的进程 id ps -q 42 -o comm= 作用: 打印进程id 为 42 的进程名 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/43_ps/:1:8","tags":["Linux 性能调优"],"title":"5.3 ps","uri":"/posts/linux/linux_perf/43_ps/"},{"categories":["Linux"],"content":"5.4 pidstat","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pidstat 命令 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:0:0","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pidstat pidstat options [ interval [ count ]] 作用: 监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况 内容参数: -u：默认的参数，显示各个进程的cpu使用统计 -r：显示各个进程的内存使用统计 -d：显示各个进程的IO使用情况 -w：显示每个进程的上下文切换情况 -t：显示选择任务的线程的统计信息外的额外信息，显示线程统计信息时，必须使用 过滤参数: -l：显示命令名和所有参数 -p：指定进程号 -T { TASK | CHILD | ALL } 这个选项指定了pidstat监控的。TASK表示报告独立的task，CHILD关键字表示报告进程下所有线程统计信息。ALL表示报告独立的task和task下面的所有线程。 注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:1:0","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pid -u pidstat -u 2 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU) 04:34:07 PM UID PID %usr %system %guest %CPU CPU Command 04:34:09 PM 0 926 0.51 0.00 0.00 0.51 0 python 04:34:09 PM 0 1100 0.51 0.00 0.00 0.51 0 docker-containe 输出： UID: real user id PID: 进程ID %usr: 用户态 CPU 使用率，包括以低优先级运行的CPU时间(nice 时间)，但不包活运行虚拟化程序的时间 %system: 内核态 CPU 使用率 %guest: 运行虚拟化程序的 CPU 使用率 %CPU: 总的 CPU 占用率 CPU: Processor number to which the task is attached. Command: 进程的启动命令 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:1:1","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pidstat -r pidstat -r 2 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU) 04:44:53 PM UID PID minflt/s majflt/s VSZ RSS %MEM Command 04:44:55 PM 0 926 0.51 0.00 784756 37600 0.23 python 04:44:55 PM 1000 3648 12.76 0.00 1132080 118140 0.73 node 04:44:55 PM 0 8343 297.96 0.00 108496 1228 0.01 pidstat 输出： minflt/s: 每秒次缺页异常数 majflt/s: 每秒主缺页异常书 VSZ: 虚拟内存大小 RSS: 实际占用的物理内存大小 %MEM: 物理内存占用百分比 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:1:2","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pidstat -d pidstat -d 2 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU) 04:47:46 PM UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 04:47:48 PM 0 923 0.00 2.02 0.00 python 04:47:48 PM 1000 2994 0.00 6.06 0.00 java 输出： kB_rd/s: 读请求速率，单位KB/s kB_wr/s: 写请求速率，单位KB/s kB_ccwr/s: 任务取消的写入磁盘的KB。当任务截断脏页时会发生 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:1:3","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"pidstat -w pidstat -w 2 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU) 04:52:37 PM UID PID cswch/s nvcswch/s Command 04:52:39 PM 0 3 5.08 0.00 ksoftirqd/0 04:52:39 PM 0 9 92.39 0.00 rcu_sched 04:52:39 PM 0 11 0.51 0.00 watchdog/0 输出： cswch/s: 每秒主动任务上下文切换数量 nvcswch/s: 每秒被动任务上下文切换数量 ","date":"2020-02-13","objectID":"/posts/linux/linux_perf/44.pidstat/:1:4","tags":["Linux 性能调优"],"title":"5.4 pidstat","uri":"/posts/linux/linux_perf/44.pidstat/"},{"categories":["Linux"],"content":"5.2 Sar","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"sar 命令 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:0:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"1. sar sar [options] [-A] [-o file] t [n] 作用：查看系统各种使用信息 控制参数： -o file：将命令结果以二进制格式存放在文件中 t：采样间隔 =0 :表示统计系统启动以来的平均值 t被设置，n未被设置，会按照时间间隔循环输出 n：采样次数，可选，默认值是1 内容参数： -A：等于 -bBdFHqSvwWy -I SUM -m ALL -n ALL -r ALL -u ALL -I ALL -P ALL 显示所以内容 CPU统计信息: -u：CPU利用率 -q: 查看系统平均负载 -w: 统计任务创建和上下文切换 内存统计信息: -B：换页的统计信息 -H: 大页面统计信息 -r：内存使用率 -R: 内存分配和释放速率统计信息 -S: 交换空间统计信息 -W：swap分区交换速率统计信息 磁盘统计信息 -b：磁盘 IO 传送速率 -d：块使用信息 -I：中断统计信息 网络统计信息: -n: 统计网络使用情况 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:1:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"2. CPU 统计信息 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:2:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"2.1 sar -u sar -u -P { cpu_list | ALL } 作用：CPU利用率 -P { cpu_list | ALL }：选定要展示的 cpu，ALL 展示所有 CPU 及其合计 sar -u 1 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU) 06:32:44 PM CPU %user %nice %system %iowait %steal %idle 06:32:45 PM all 41.02 0.00 3.61 6.22 0.00 49.15 Average: all 41.02 0.00 3.61 6.22 0.00 49.15 指标含义： CPU： %user：us，代表用户态 CPU 时间，包括应用运用虚拟化的时间 %usr：表用户态 CPU 时间，不包括应用运用虚拟化的时间 %nice：代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间 %system：代表内核态 CPU 时间，包括运行软终端，硬中断的时间 %sys：代表内核态 CPU 时间，不包括运行软终端，硬中断的时间 %iowait：wa，代表等待 I/O 的 CPU 时间 %steal：st，代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间 %idle：id，代表空闲时间。注意，它不包括等待 I/O 的时间（iowait） %irq：hi，代表处理硬中断的 CPU 时间 %softirq：si，代表处理软中断的 CPU 时间 %guest：代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间 %guest_nice：gnice，代表以低优先级运行虚拟机的时间 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:2:1","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"2.2 sar -q sar -q 作用: 查看平均负载 sar -q 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月01日 _x86_64_ (1 CPU) 00时34分09秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked 00时34分10秒 1 164 0.00 0.01 0.05 0 00时34分11秒 1 164 0.00 0.01 0.05 0 平均时间: 1 164 0.00 0.01 0.05 0 指标含义: runq-sz: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 plist-sz: 任务队列中的任务总数 ldavg-1 最后1分钟的CPU平均负载 ldavg-5 最后5分钟的CPU平均负载 ldavg-15 最后15分钟的CPU平均负载 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:2:2","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"2.3 sar -w sar -w 1 Linux 3.10.0-957.el7.x86_64 (lv) 2020年06月03日 _x86_64_ (2 CPU) 11时31分13秒 proc/s cswch/s 11时31分14秒 0.00 136.00 11时31分15秒 0.00 157.00 11时31分16秒 0.00 142.57 指标含义: proc/s: 每秒创建的任务数(进程数) cswch/s: 每秒发生的上下文切换次数 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:2:3","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3. 内存统计信息 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.1 sar -B 作用: 换页统计信息 sar -B 2 1 Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU) 16:13:02 pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff 16:13:04 0.00 0.00 30.50 0.00 14.50 0.00 0.00 0.00 0.00 Average: 0.00 0.00 30.50 0.00 14.50 0.00 0.00 0.00 0.00 指标含义： pgpgin/s：操作系统每秒从磁盘换入的分页大小，单位 KB pgpgout/s：操作系统每秒从磁盘换出的分页大小，单位 KB fault/s：每秒的缺页异常，包括主次缺页异常(major + minor) majflt/s：每秒主缺页异常数(major 大小) pgfree/s：每秒放回空闲链表(free list)的页的数量 pgscank/s：kswapd 后台进程每秒扫描的分页数 pgscand/s：每秒直接扫描的分页数 pgsteal/s：为了满足其他内存需求，每秒从 cache 缓存中回收的分页数 – 包括页面及交换高速缓存 %vmeff：=(pgsteal / pgscan), 用于衡量分页的回收效率 高数值意味着成功从非活动列表回收了页(健康) 接近 100%：高数值，健康 接近 30%：标识虚拟内存很紧张，因为没有页可以被回收 =0：标识时间间隔内没有分页被扫描 内存分页机制: http://linuxperf.com/?p=97 https://www.jianshu.com/p/ea7ed85918ac ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:1","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.2 sar -H 作用: 大页面统计信息 \u003e sar -H 1 4 22时14分00秒 kbhugfree kbhugused %hugused 22时14分01秒 0 0 0.00 22时14分02秒 0 0 0.00 22时14分03秒 0 0 0.00 22时14分04秒 0 0 0.00 指标含义: kbhugfree: 空闲大页面的大小 kbhugused: 已经使用的大页面 %hugused: 大页面使用百分比 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:2","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.3 sar -r 作用: 内存使用率，包括页缓存和可回收的slab 缓存 sar -r 1 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU) 07:14:04 PM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty 07:14:05 PM 721588 114505136 99.37 0 19673952 153573644 133.28 65880260 11269348 783372 Average: 721588 114505136 99.37 0 19673952 153573644 133.28 65880260 11269348 783372 指标含义： kbmemfree:这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间. kbmemused:这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间. %memused:这个值是kbmemused和内存总量(不包括swap)的一个百分比. kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. kbcommit:保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)，估计值. %commit:这个值是kbcommit与内存总量(包括swap)的一个百分比. kbactive: 活跃内存，也就是最近使用过的内存，一般不会被系统回收 kbinact: 表示非活跃内存，也就是不常访问的内存，有可能会被系统回收 kbdirty：需要写入磁盘的脏页大小 kbanonpg：用户控件的 non-file 内存大小 kbslab：slab 内存大小 kbkstack：内核栈空间大小 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:3","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.4 sar -R 作用: 内存分配和释放速率 sar -R 1 2 22时27分44秒 frmpg/s bufpg/s campg/s 22时27分45秒 0.00 0.00 0.00 22时27分46秒 0.00 0.00 0.00 指标含义: frmpg/s: 每秒释放的分页数，负数表示分配 bufpg/s: 每秒增加的用于 buffer 的分页数 campg/s: 每秒增加的用于 cache 的分页数 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:4","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.4 sar -S 作用: 交换空间统计信息 \u003e sar -S 1 2 22时31分57秒 kbswpfree kbswpused %swpused kbswpcad %swpcad 22时31分58秒 2097148 0 0.00 0 0.00 22时31分59秒 2097148 0 0.00 0 0.00 指标含义: kbswpfree: 释放的 swap 空间大小 kbswpused: 占用的 swap 空间大小 %swpused: swap 空间占用百分比 kbswpcad: 高速缓存 cache 的交换空间大小，同时保存在主存和交换设备中，因此不需要磁盘IO就能被页面换出 %swpcad: kbswpcad占用百分比 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:5","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"3.5 sar -W 作用: swap 交换速率 sar -W 1 2 22时35分27秒 pswpin/s pswpout/s 22时35分28秒 0.00 0.00 22时35分29秒 0.00 0.00 指标含义: pswpin/s: swap换入速率，页面/s pswpout/s: swap 换出速率，页面/s ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:3:6","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"4. 磁盘信息统计 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:4:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"4.1 sar -b 作用：磁盘 IO 传送速率 sar -b 1 1 Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU) 16:53:21 tps rtps wtps bread/s bwrtn/s 16:53:22 0.00 0.00 0.00 0.00 0.00 Average: 0.00 0.00 0.00 0.00 0.00 指标含义： tps：每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的，一般情况下tps=(rtps+wtps) rtps：每秒的读请求数 wtps：每秒的写请求数 bread/s: 每秒读磁盘的数据块数(in blocks 1 block = 512B, 2.4以后内核) bwrtn/s:每秒写磁盘的数据块数(in blocks 1 block = 512B, 2.4以后内核) bdscd/s：磁盘每秒丢失的数据块数 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:4:1","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"4.2 sar -d sar -dp –dev=[dev_list] 作用：块设备(磁盘)统计信息 参数： -p：显示磁盘名称，默认情况磁盘显示为devM-n(M-主设备号，n-次设备号) –dev=[dev_list]：指定要显示的设备 sar -dp 1 1 Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU) 18:38:56 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util 18:38:57 sda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 18:38:57 centos-root 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 18:38:57 centos-swap 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标含义： DEV：设备名称 tps：每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的 rd_sec/s：每秒从磁盘读取的数据量，扇区数 wr_sec/s：每秒写入磁盘的数据量，扇区数 avgrq-sz：I/O 请求的平均大小，单位 KB avgqu-sz：平均请求队列的长度 await：I/O 请求的平均时间，包括等待时间，单位 milliseconds svctm：IO的处理时间，不包括等待时间，推断值，可能不准确 %util：磁盘处理IO的时间百分比，即使用率，因此可能存在并行，100% 不一定代表磁盘饱和 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:4:2","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"4.3 sar -I sar -I { int_list | SUM | ALL } 作用：统计中断信息 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:4:3","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"5. 网络统计信息 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:5:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"5.1 sar -n sar -n { keyword [,…] | ALL } 作用：统计网络使用情况 keyword: 统计对象，可选值包括 DEV, EDEV, FC, ICMP, EICMP, ICMP6,EICMP6 IP, EIP, IP6, EIP6, NFS, NFSD SOCK, SOCK6, SOFT, TCP,ETCP, UDP and UDP6 常用选项: -n DEV: 网络接口统计信息 -n EDEV: 网络接口错误 -n IP: IP 数据报统计信息 -n EIP: IP 错误统计信息 -n TCP: TCP 统计信息 -n ETCP: TCP 错误统计信息 -n SOCK: 套接字使用 sar -n DEV 统计网卡的PPS与发送速率 sar -n DEV 1 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU) 06:21:04 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s 06:21:05 PM veth934832e 0.00 0.00 0.00 0.00 0.00 0.00 0.00 06:21:05 PM vethc869b5c 0.00 0.00 0.00 0.00 0.00 0.00 0.00 06:21:05 PM eth0 10287.00 6519.00 13892.42 7946.05 0.00 0.00 20.00 06:21:05 PM eth1 2.00 0.00 0.12 0.00 0.00 0.00 1.00 06:21:05 PM lo 2958.00 2958.00 31135.78 31135.78 0.00 0.00 0.00 06:21:05 PM virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.00 06:21:05 PM virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 06:21:05 PM veth145e746 0.00 0.00 0.00 0.00 0.00 0.00 0.00 06:21:05 PM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标含义： rxpck/s：接收的 PPS，单位为包 / 秒 txpck/s：发送的 PPS，单位为包 / 秒 rxkB/s： 接收的吞吐量，单位是 KB/ 秒 txkB/s： 发送的吞吐量，单位是 KB/ 秒 rxcmp/s：接收的压缩数据包数，单位是包 / 秒 txcmp/s：发送的压缩数据包数，单位是包 / 秒 rxmcst/s：广播包的 PPS，单位为包 / 秒 %ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。 sar -n EDEV sar -n EDEV 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU) 15时36分56秒 IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s 15时36分57秒 enp0s3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15时36分57秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15时36分57秒 virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15时36分57秒 virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标: rxerr/s: 接收数据包错误，数据包/s txerr/s: 传输数据包错误，数据包/s coll/s: 碰撞，数据包/s rxdrop/s: 接收数据包丢包(缓冲满)，数据包/s txdrop/s: 传输数据包丢包，数据包/s txcarr/s: 发送数据包时，每秒载波错误数 rxfram/s: 每秒接收数据包的帧对齐错误数 rxfifo/s: 接收的数据包 FIFO 超限错误，数据包/s txfifo/s: 传输的数据包 FIFO 超限错误，数据包/s ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:5:1","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"sar -n IP sar -n IP 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU) 15时42分15秒 irec/s fwddgm/s idel/s orq/s asmrq/s asmok/s fragok/s fragcrt/s 15时42分16秒 1.00 0.00 1.00 1.00 0.00 0.00 0.00 0.00 15时42分17秒 1.01 0.00 1.01 1.01 0.00 0.00 0.00 0.00 平均时间: 1.01 0.00 1.01 1.01 0.00 0.00 0.00 0.00 指标: irec/s: [ipInReceives] 输入的数据报文(接收)，数据报文/s fwddgm/s:[ipForwDatagrams] 转发的数据报文，数据报文/s idel/s: [ipInDelivers] 每秒向应用程序传输的数据报文数量 orq/s: [ipOutRequests] 输出/传输的数据报文，数据报文/s asmrq/s: [ipReasmReqds] 每秒收到需要被重新组装的 IP fragments 数量 asmok/s: [ipReasmOKs] 每秒成功重新组装的(re-assembled)的数据报数量 fragok/s: [ipFragOKs] 每秒成功被分段(fragmented )的数据包数量 fragcrt/s: [ipFragCreates] 每秒对数据包成功分段产生的IP分段数 sar -n EIP sar -n EIP 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU) 15时48分42秒 ihdrerr/s iadrerr/s iukwnpr/s idisc/s odisc/s onort/s asmf/s fragf/s 15时48分43秒 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 15时48分44秒 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 平均时间: 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标: ihdrerr/s: [ipInHdrErrors] 每秒由于 IP Header 错误而丢弃的数据包数量 iadrerr/s: [ipInAddrErrors] 每秒由于 IP header’s 里的IP地址不合法而丢弃的数据包数量 iukwnpr/s: [ipInUnknownProtos] 每秒由于未知的网络协议而丢弃的数据包数量 idisc/s: [ipInDiscards] 数据包本身没有问题，因为其他原因比如缓冲满而丢弃的输入数据包数量 odisc/s: [ipOutDiscards] 数据包本身没有问题，因为其他原因比如缓冲满而丢弃的输出数据包数量 onort/s: [ipOutNoRoutes] 由于没有转发的路由而丢弃的数据包数量 asmf/s: [ipReasmFails] The number of failures detected per second by the IP re-assembly algorithm (for whatever reason: timed out, errors, etc) fragf/s: [ipFragFails] 因为需要分片但无法分片(fragmented)，而被丢弃的数据包数量 sar -n TCP sar -n TCP 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU) 15时50分54秒 active/s passive/s iseg/s oseg/s 15时50分55秒 0.00 0.00 1.00 1.00 15时50分56秒 0.00 0.00 1.01 1.01 平均时间: 0.00 0.00 1.01 1.01 指标: active/s: [tcpActiveOpens] 新的主动 TCP 连接(connect()) passive/s: [tcpPassiveOpens] 新的被动 TCP 连接(listen()) iseg/s: [tcpInSegs] 输入的段，段/s oseg/s: [tcpOutSegs] 输出的段，段/s sar -n ETCP sar -n ETCP 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU) 15时51分29秒 atmptf/s estres/s retrans/s isegerr/s orsts/s 15时51分30秒 0.00 0.00 0.00 0.00 0.00 15时51分31秒 0.00 0.00 0.00 0.00 0.00 平均时间: 0.00 0.00 0.00 0.00 0.00 atmptf/s: [tcpAttemptFails] 每秒发生的以下状态转换的连接数 SYN-SENT or SYN-RCVD -\u003eCLOSED SYN-RCVD -\u003e LISTEN estres/s: [tcpEstabResets]每秒由 ESTABLISHED or CLOSE-WAIT -\u003e CLOSED 状态的连接数 retrans/s: [tcpRetransSegs]每秒重发的段数 isegerr/s: [tcpInErrs]每秒收到的错误段数 orsts/s: [tcpOutRsts]每秒收到的包含 RST flag TCP段数 sar -n SOCK 统计套接字的使用情况 sar -n SOCK 1 1 Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU) 06:25:57 PM totsck tcpsck udpsck rawsck ip-frag tcp-tw 06:25:58 PM 4957 821 47 0 0 201 Average: 4957 821 47 0 0 201 指标含义： totsck：在使用的 socket 数量 tcpsck：在使用的 tcp socket 数量 udpsck：在使用的 udp socket 数量 rawsck：在使用的 raw socket 数量 ip-frag：当前队列中的 IP 数据片 tcp-tw：处于 TIME_WAIT 状态的 TCP数量 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:5:2","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"6. 文件系统 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:6:0","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"6.1 sar -v 报告文件系统缓存 \u003e sar -v 1 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月21日 _x86_64_ (1 CPU) 18时08分59秒 dentunusd file-nr inode-nr pty-nr 18时09分00秒 14637 2080 24198 1 18时09分01秒 14637 2080 24198 1 指标含义: dentunusd: 目录项缓存未用计数 file-nr: 使用中的文件描述符个数 inode-nr: 使用中的 inode 个数 ","date":"2020-02-12","objectID":"/posts/linux/linux_perf/42_sar/:6:1","tags":["Linux 性能调优"],"title":"5.2 Sar","uri":"/posts/linux/linux_perf/42_sar/"},{"categories":["Linux"],"content":"5.1 top","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"top 命令 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:0:0","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"top top [options] 选项： -b：批处理模式 -n max：设置迭代数量，通常与 -b 一起使用 -d：屏幕刷新间隔 -u user：指定用户名 -p pid(s)：指定进程 交互命令： h：显示帮助画面，给出一些简短的命令总结说明 k：终止一个进程 i：忽略闲置和僵死进程，这是一个开关式命令 q：退出程序 r：重新安排一个进程的优先级别 S：切换到累计模式 l：切换显示平均负载和启动时间信息 m：切换显示内存信息 t：切换显示进程和CPU状态信息 c：切换显示命令名称和完整命令行 M：根据驻留内存大小进行排序 P：根据CPU使用百分比大小进行排序 T：根据时间/累计时间进行排序 w：将当前设置写入~/.toprc文件中 缺陷: top 自身的 CPU用量可能会变得很大，因为 top 会遍历 /proc 内的很多进程项目 top 会对 /proc 做快照，因此会错过一些寿命较短的进程，这些进程在快照之前已经退出了 可以使用 atop 替代top，它使用进程核算技术来捕获短寿命进程并显示，也可以使用 pidstat 捕获短时进程 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:1:0","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"指标含义 top - 14:58:20 up 4:33, 3 users, load average: 0.09, 0.11, 0.13 Tasks: 252 total, 3 running, 249 sleeping, 0 stopped, 0 zombie %Cpu(s): 2.5 us, 0.8 sy, 0.0 ni, 95.9 id, 0.0 wa, 0.0 hi, 0.8 si, 0.0 st KiB Mem : 16267424 total, 2198240 free, 12617508 used, 1451676 buff/cache KiB Swap: 0 total, 0 free, 0 used. 3264332 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3653 analyzer 20 0 3214268 611932 17464 S 2.4 3.8 6:45.42 java 2994 analyzer 20 0 5456164 108580 9244 S 0.8 0.7 0:11.13 java ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:0","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"系统运行时间 top - 14:58:20 up 4:33, 3 users, load average: 0.09, 0.11, 0.13 输出: top - 14:58:20: 系统当前时间 up 4:33: 系统已运行时间 3 users：当前在线用户 load average：平均负载：最近1分钟、5分钟、15分钟系统的平均负载 说明： 平均负载：平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数 可运行状态：正在使用 CPU 或者正在等待 CPU 的进程，对应 ps R 状态（Running 或 Runnable）进程 不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的，对应 ps D 状态（Uninterruptible Sleep，也称为 Disk Sleep）进程 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:1","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"tasks Tasks: 252 total, 3 running, 249 sleeping, 0 stopped, 0 zombie 输出： 标准： 基于线程转态切换的任务数统计，统计的是线程数 shows total tasks or threads, depending on the state of the Threads-mode toggle. total：总的线程数 running：处于运行状态的线程数 sleeeping：处于休眠状态的线程数 stopped：被跟踪或已停止 Stopped的线程数 zombie：僵尸进程数 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:2","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"CPU %Cpu(s): 2.5 us, 0.8 sy, 0.0 ni, 95.9 id, 0.0 wa, 0.0 hi, 0.8 si, 0.0 st 输出： 名称 缩写 含义 user us 用户态 CPU 时间，不包括下面的 nice 时间，但包括 guest 时间。 nice ni 代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。 nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system sys,sy 代表内核态 CPU 时间。 idle id 代表空闲时间。注意，它不包括等待 I/O 的时间（iowait） iowait wa 代表等待 I/O 的 CPU 时间，出现 iowait 有两个条件，一是进程在等io，二是等io时没有进程可运行 irq hi 代表处理硬中断的 CPU 时间。 softirq si 代表处理软中断的 CPU 时间。 steal st 代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间 guest guest 代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间 guest_nice gnice 代表以低优先级运行虚拟机的时间 注意：通常我们收的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:3","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"memery swap KiB Mem : 16267424 total, 2198240 free, 12617508 used, 1451676 buff/cache KiB Swap: 0 total, 0 free, 0 used. 3264332 avail Mem 输出: total: 总的内存或 swap 分区大小 free：处于空闲状态的内存或 swap 分区大小 used：已经的内存或 swap 分区大小 buff/cache: 用于buff/cache 的内存大小 avail Mem：可用内存，包括 free，以及可回收的页缓存，内存，和slab 缓存 ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:4","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"进程信息 PID Process Id 进程ID USER Effective User Name 进程的有效属主，用于判断进程对文件系统的访问权限 PR Priority 进程优先级 NI Nice Value nice值 VIRT Virtual Image (KiB) 进程使用的虚拟内存大小，包括换到 swap 分区，以及隐射了但未分配内存 RES Resident Size (KiB) 实际占用的物理内存大小 SHR Shared Memory (KiB) 共享内存大小 S Process Status 进程状态 %CPU CPU Usage 基于CPU时间片计算的CPU使用率 并没有细分进程的用户态 CPU 和内核态 CPU %MEM Memory Usage (RES) 内存占用百分比 TIME+ CPU Time, hundredths 进程使用的CPU时间总计，单位1/100秒 COMMAND Command Name/Line 进程名称及命令 PPID Parent Process pid 父进程ID UID Effective User Id RUID Real User Id 由启动进程的用户决定 RUSER Real User Name SUID Saved User Id SUSER Saved User Name GID Group Id GROUP Group Name PGRP Process Group Id TTY Controlling Tty 所属终端 TPGID Tty Process Grp Id SID Session Id 会话ID nTH Number of Threads 包含的线程数 P Last Used Cpu (SMP) 最后运行该进程的CPU TIME CPU Time 同TIME+，但没有TIME+精确 SWAP Swapped Size (KiB) 使用的swap分区大小 CODE Code Size (KiB) 代码段占用内存大小 DATA Data+Stack (KiB) 数据段占用内存大小 nMaj Major Page Faults 累计主缺页异常次数 nMin Minor Page Faults 累计次缺页异常次数 nDRT Dirty Pages Count 待刷新的脏页数 WCHAN Sleeping in Function Flags Task Flags \u003csched.h\u003e 进程调度标识 CGROUPS Control Groups SUPGIDS Supp Groups IDs SUPGRPS Supp Groups Names TGID Thread Group Id 所属线程组ID ENVIRON Environment vars 进程依赖的环境变量 vMj Major Faults delta 当前时间间隔内的主缺页异常 vMn Minor Faults delta USED Res+Swap Size (KiB) nsIPC IPC namespace Inode 进程所属的IPC命令空间 nsMNT MNT namespace Inode nsNET NET namespace Inode nsPID PID namespace Inode nsUSER USER namespace Inode nsUTS UTS namespace Inode ","date":"2020-02-11","objectID":"/posts/linux/linux_perf/41_top/:2:5","tags":["Linux 性能调优"],"title":"5.1 top","uri":"/posts/linux/linux_perf/41_top/"},{"categories":["Linux"],"content":"5 高级工具包","date":"2020-02-10","objectID":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/","tags":["Linux 性能调优"],"title":"5 高级工具包","uri":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/"},{"categories":["Linux"],"content":"从本文开始我们将进入Linux性能优化的第二阶段，高级工具包。 ","date":"2020-02-10","objectID":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/:0:0","tags":["Linux 性能调优"],"title":"5 高级工具包","uri":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/"},{"categories":["Linux"],"content":"1. 内容概要 这一部分我们将分成两个部分，介绍如下工具的使用: 高级命令: top sar pidstat ps 高级工具包 perf-tool bcc dtrace-toolkit systemtap-lwt 容器分析工具 ","date":"2020-02-10","objectID":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/:1:0","tags":["Linux 性能调优"],"title":"5 高级工具包","uri":"/posts/linux/linux_perf/40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85/"},{"categories":["Linux"],"content":"4.18 监控系统构建","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"我们不能总是去当救火队员，更重要的是监控系统。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:0:0","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. 监控系统 线上的系统 24 小时运转，有一些问题稍纵即逝，我们总不能 24 小时盯着。对于线上业务更重要的是一套完备的监控系统，把系统和应用程序的运行状况监控起来，并定义一系列的策略，在发生问题时第一时间告警通知。 要做好监控，最核心的就是全面的、可量化的指标。接下来我们就从系统和应用两个方面来看看如何构建我们的监控指标体系。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:0","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2. 系统资源 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:2:0","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.1 USE法 USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。 使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。 错误数表示发生错误的事件个数。错误数越多，表明系统的问题越严重。 这三个类别的指标，涵盖了系统资源的常见性能瓶颈，所以常被用来快速定位系统资源的性能瓶颈。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:2:1","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.1 系统资源指标 下面是 USE 法建立的系统资源指标体系: 需要注意的是，USE 方法只关注能体现系统资源性能瓶颈的核心指标，但这并不是说其他指标不重要。诸如系统日志、进程资源使用量、缓存使用量等其他各类指标，也都需要我们监控起来。只不过，它们通常用作辅助性能分析。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:2:2","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3. 应用 应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。这指标可以帮助我们快速确定应用是否发生了性能问题。如何想确定程序的问题所在，我们还需要监控以下指标: 第一个，是应用进程的资源使用情况，比如进程占用的 CPU、内存、磁盘 I/O、网络等。使用过多的系统资源，导致应用程序响应缓慢或者错误数升高，是一个最常见的性能问题。 第二个，是应用程序之间调用情况，比如调用频率、错误数、延时等。由于应用程序并不是孤立的，如果其依赖的其他应用出现了性能问题，应用自身性能也会受到影响。 第三个，是应用程序内部核心逻辑的运行情况，比如关键环节的耗时以及执行过程中的错误等。由于这是应用程序内部的状态，从外部通常无法直接获取到详细的性能数据。所以，应用程序在设计和开发时，就应该把这些指标提供出来，以便监控系统可以了解其内部运行状态。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:3:0","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4. 监控系统 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:4:0","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.1 监控系统 一个完整的监控系统通常由数据采集、数据存储、数据查询和处理、告警以及可视化展示等多个模块组成。现在已经有很多开源的监控工具可以直接使用，比如最常见的 Zabbix、Nagios、Prometheus 等等。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:4:1","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.2 全链路跟踪系统 业务系统通常会涉及到一连串的多个服务，形成一个复杂的分布式调用链。为了迅速定位这类跨应用的性能瓶颈，还可以使用 Zipkin、Jaeger、Pinpoint 等各类开源工具，来构建全链路跟踪系统。 全链路跟踪除了可以帮你快速定位跨应用的性能问题外，还可以帮你生成线上系统的调用拓扑图。这些直观的拓扑图，在分析复杂系统（比如微服务）时尤其有效。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:4:2","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.3 日志监控 同样的一个接口，当请求传入的参数不同时，就可能会导致完全不同的性能问题。所以，除了指标外，我们还需要对这些指标的上下文信息进行监控，而日志正是这些上下文的最佳来源。 对比来看，指标是特定时间段的数值型测量数据，通常以时间序列的方式处理，适合于实时监控。而日志则完全不同，日志都是某个时间点的字符串消息，通常需要对搜索引擎进行索引后，才能进行查询和汇总分析。 日志监控来说，最经典的方法，就是使用 ELK 技术栈，即使用 Elasticsearch、Logstash 和 Kibana 这三个组件的组合。 Logstash 资源消耗比较大。所以，在资源紧张的环境中，我们往往使用资源消耗更低的 Fluentd，来替代 Logstash。 ","date":"2020-02-01","objectID":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:4:3","tags":["Linux 性能调优"],"title":"4.18 监控系统构建","uri":"/posts/linux/linux_perf/38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.16 C10K 与网络I/O模型","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"各种网络I/O模型是面试的必考考点，那么到底有哪些I/O模型，C10K 问题到底又是怎么解决的呢？ ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:0:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1. C10K问题 所谓 C10K 问题就是如何在单机中同时处理 1 万个请求（并发连接 1 万）的问题。从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。 到目前为止有两种最基本的I/O模型: 同步阻塞: 也就是每个请求都分配一个进程或者线程。当并发请求数增加到 10000 时，10000 个进程或线程的调度、上下文切换乃至它们占用的内存，都会成为瓶颈。 非阻塞I/O: 非阻塞I/O 可以让我们周期性轮询检查某个文件描述符上的I/O是否可以执行。我们可以在一个线程内同时轮询多个文件描述，但是如果轮询的频率不高，那么应用程序响应I/O事件的延时可能达到难以接受的程度。但是一个紧凑的轮询是非常浪费CPU的。 显然通过每个请求分配一个线程的方式不合适，通过轮询的方式也不合适。那么核心问题就变成如何在一个线程内处理多个请求呢？这需要我们解决以下几个问题: 如何同时检查多个文件描述，在它们准备就绪时(即网络请求到来时)，及时处理。我们需要新的I/O模型。 一个线程内处理多个I/O请求，需要维护每个请求的上下文信息，这就引申出另外两种并发机制: 回调和协程 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:1:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.1 I/O 模型 “新的”I/O模型有下列几种备选方案: I/O多路复用: 允许进程同时检查多个文件描述符，看其中任何一个是否可以执行I/O操作，系统调用 select，poll 可以用来执行I/O多路复用 信号驱动I/O: 指当有输入或者数据可以写到指定的文件描述符时，内核向请求数据的进程发送一个信号。 epoll: Linux 专有特性，select，poll 的升级版本，使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。 I/O多路复用，信号驱动，epoll 都是用来实现同一个目标技术: 同时检查多个文件描述符，看它们是否准备好了执行I/O操作。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:1:1","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"1.2 事件通知方式 在深入讨论各种I/O机制之前，我们需要先区分两种文件描述符准备就绪的通知模式: 水平触发: 只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。 边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。 select,pool 支持水平触发，信号驱动I/O支持边缘触发。epoll 同时支持水平触发和边缘触发，默认情况下提供的是水平触发机制。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:1:2","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"2. I/O模型的对比 下面是几种I/O模型之间的对比图: 在具体比较这几种 I/O 模式的区别之前，我们需要明白下面几个要点: 同步阻塞，非阻塞I/O 通常都是用在单个进程每次只在一个文件描述符上执行I/O操作 I/O多路复用，信号驱动则是用来同时检查多个文件描述符，因为需要同时处理多个I/O请求，所以在单个文件描述符上采用的仍然是非阻塞的I/O模式。 非阻塞I/O需要在I/O发生时，通知进程及时进行I/O操作，“通知”包含以下几个方面: 什么时候通知: 水平触发还是边缘触发 在I/O栈的什么位置通知: 数据到达时即通知，还是在内核将数据完全拷贝到用户空间时在通知 通知什么: 回调注册在每个文件描述符上的回调函数，每个文件描述符上的回调函数即维护了每个请求的上下文信息。 最开始我们提到了两种并发机制: 回调和协程，本质上协程也是回调，因为协程最终也是要为每个描述符注册回调函数。 但是协程与回调的区别在于，协程保存了回调前后的上下文信息，简单的理解，协程在通知的前后位于同一个函数栈中，其保留了程序执行的上下文信息，可以让我们像编写同步代码一样编写异步调用，避免了“回调地狱”的问题。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:2:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"2.1 I/O多路复用 I/O多路复用包括 select，poll 和 epoll。epoll 是 select，poll 的升级版。 select 和 poll 存在下面这些问题: 每次调用 select 和 poll，内核都必须检查所有被指定的文件描述符 每次调用 select 和 poll 时，程序都必须传递一个表示所有需要被检查的文件描述符的结构到内核，内核检查过后，要把这个结构返回给用户程序，显然随着文件描述符的增多，拷贝所有文件描述所需的内存和CPU都会增多 select 和 poll调用完成后，程序还必须检查返回的数据结构中的每个元素才能知道哪些描述符可用 epoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。 epoll 使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:2:1","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"3.1 信号驱动I/O 信号驱动I/O使用信号作为I/O就绪的触发机制。在效率上甚至比I/O多路复用更高。但是使用信号的I/O的问题在于: 内核可用的信号类型有限，不太容易随着I/O事件的类型而扩展。I/O多路复用为不同描述符定义了不同的I/O事件集合，并且可以指定希望检查的事件类型。 可排队的实时信号的数量是有限的，超过限制信号就会丢失，这样I/O请求就无法及时得到处理。使用信号驱动I/O 需要复杂的信号处理流程，I/O多路复用不需要。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:2:2","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"4.1 异步I/O 信号驱动I/O有时也被称为异步I/O，这一点从打开的文件标志O_ASYNC 中就能看出(注: 使用信号驱动I/O必须要使用 O_ASYNC 标识打开文件描述符)。现在异步I/O专指有POSIX_AIO 规范所提供的功能。 异步I/O与I/O多路复用不同在于在I/O栈的什么位置通知。异步I/O使用的较少，详细内容后续在补充。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:2:3","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"5. 工作模型 使用 I/O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型: 第一种，主进程 + 多个 worker 子进程，这也是最常用的一种模型 第二种，监听到相同端口的多进程模型 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:3:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"5.1 主进程 + 多个 worker 子进程 主进程 + 多个 worker 子进程: 主进程执行 bind() + listen() 后，创建多个子进程； 然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。 最常用的反向代理服务器 Nginx 就是这么工作的。主进程主要用来初始化套接字，并管理子进程的生命周期；而 worker 进程，则负责实际的请求处理。 这里要注意，accept() 和 epoll_wait() 调用，还存在一个惊群的问题。换句话说，当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠。 其中，accept() 的惊群问题，已经在 Linux 2.6 中解决了； epoll 的问题，到了 Linux 4.5 ，才通过 EPOLLEXCLUSIVE 解决。 为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒。 当然，也可以用线程代替进程：主线程负责套接字初始化和子线程状态的管理，而子线程则负责实际的请求处理。由于线程的调度和切换成本比较低，实际上你可以进一步把 epoll_wait() 都放到主线程中，保证每次事件都只唤醒主线程，而子线程只需要负责后续的请求处理。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:3:1","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"5.2 监听到相同端口的多进程模型 在这种方式下，所有的进程都监听相同的接口，并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。比如，Nginx 在 1.9.1 中就已经支持了这种模式。想要使用 SO_REUSEPORT 选项，需要用 Linux 3.9 以上的版本才可以。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:3:2","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"6. C1000K,C10M 问题 随着并发请求的进一步提高，原本不是瓶颈的地方也会出现问题。 从软件资源上来说，大量的连接也会占用大量的软件资源，比如文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等。 大量请求带来的中断处理，也会带来非常高的处理成本。这样，就需要多队列网卡、中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。 在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了。无论你怎么优化应用程序和内核中的各种网络参数，想实现 1000 万请求的并发，都是极其困难的。 究其根本，还是 Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了。 要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:4:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"6.1 DPDK DPDK，是用户态网络的标准。它跳过内核协议栈，直接由用户态进程通过轮询的方式，来处理网络接收。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:4:1","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"6.2 XDP XDP（eXpress Data Path），则是 Linux 内核提供的一种高性能网络数据路径。它允许网络包，在进入内核协议栈之前，就进行处理，也可以带来更高的性能。XDP 底层跟我们之前用到的 bcc-tools 一样，都是基于 Linux 内核的 eBPF 机制实现的。 详细的原理参见: xdp ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:4:2","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"6.3 分布式 在大多数场景中，我们并不需要单机并发 1000 万的请求。通过调整系统架构，把这些请求分发到多台服务器中来处理，通常是更简单和更容易扩展的方案。常见的CDN，LVS，Nginx 负载均衡等就是可选解决方案之一。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:4:3","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"7. 文件描述符 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:5:0","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"7.1 打开标识 前面我们说的信号驱动I/O，非阻塞I/O都有文件的打开文件描述符有关。 open() 调用的flags 有如下参数: 标志 作用 O_ASYNC 信号驱动I/O，当操作可行是，产生信号通知进程 O_ASYNC 信号驱动I/O，仅对特定的文件有效 O_CLOSEXEC 为新创建的文件描述符设置close-on-exec标志 O_DSYNC 根据同步I/O数据完整性的完成要求来执行写操作，与内核I/O 缓冲有关 O_SYNC 同步I/O，与内核I/O 缓冲有关 O_NONBLOCK 非阻塞方式打开文件 O_NONBLOCK: 非阻塞方式打开文件。管道，FIFO，设备都支持非阻塞模式。 由于内核缓冲区保证了普通文件I/O不会陷入阻塞，故而打开普通文件时一般会忽略 O_NONBLOCK 标志。 当使用强制文件锁时，O_NONBLOCK 对普通文件也是起作用的。 O_CLOSEXEC: 为新创建的文件描述符设置close-on-exec标志 在创建进程，成功执行 exec()系统调用之前关闭文件描述符。如果 exce() 失败，文件描述符会保持打开状态。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:5:1","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"7.2 I/O事件 I/O 多路复用为不同描述符何时就绪定义了不同的I/O事件。不同的I/O事件表示文件描述符可执行的不同I/O操作。 对于普通文件的文件描述符总是被 select 标记为可读可写。但是 epoll 没有普通文件的I/O事件，不能将普通文件的文件描述符添加到 epoll 中。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/:5:2","tags":["Linux 性能调优"],"title":"4.16 C10K 与网络I/O模型","uri":"/posts/linux/linux_perf/35_c10k%E9%97%AE%E9%A2%98/"},{"categories":["Linux"],"content":"4.17 总结-内核线程","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"本节我们来看看，操作系统内都有哪些内核线程。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:0:0","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"1. 内核线程 Linux 中，用户态进程的“祖先”，都是 PID 号为 1 的 init 进程(或者 systemd)。那么，内核态线程又是谁来管理的呢？ 实际上，Linux 在启动过程中，有三个特殊的进程，也就是 PID 号最小的三个进程。 0 号进程为 idle 进程，这也是系统创建的第一个进程，它在初始化 1 号和 2 号进程后，演变为空闲任务。当 CPU 上没有其他任务执行时，就会运行它。 1 号进程为 init 进程，通常是 systemd 进程，在用户态运行，用来管理其他用户态进程。 2 号进程为 kthreadd 进程，在内核态运行，用来管理内核线程。 所以可以像下面这样查看所有内核线程: # 1. 通过 2 号进程查看所有内核线程 $ ps -f --ppid 2 -p 2 UID PID PPID C STIME TTY TIME CMD root 2 0 0 12:02 ? 00:00:01 [kthreadd] root 9 2 0 12:02 ? 00:00:21 [ksoftirqd/0] root 10 2 0 12:02 ? 00:11:47 [rcu_sched] root 11 2 0 12:02 ? 00:00:18 [migration/0] ... root 11094 2 0 14:20 ? 00:00:00 [kworker/1:0-eve] root 11647 2 0 14:27 ? 00:00:00 [kworker/0:2-cgr] # 2. 内核线程的名称（CMD）都在中括号里 $ ps -ef | grep \"\\[.*\\]\" root 2 0 0 08:14 ? 00:00:00 [kthreadd] root 3 2 0 08:14 ? 00:00:00 [rcu_gp] root 4 2 0 08:14 ? 00:00:00 [rcu_par_gp] ... ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:1:0","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"1.1 常见的内核线程 性能分析中经常会碰到如下几个内核线程: ksoftirqd: 处理软中断的内核线程，每个 CPU 上都有一个 kswapd0：用于内存回收 kworker：用于执行内核工作队列，分为 绑定 CPU （名称格式为 kworker/CPU86330）和 未绑定 CPU（名称格式为 kworker/uPOOL86330）两类 migration：在负载均衡过程中，把进程迁移到 CPU 上，每个 CPU 一个 jbd2/sda1-8： jbd 是 Journaling Block Device 的缩写 用来为文件系统提供日志功能，以保证数据的完整性； 名称中的 sda1-8，表示磁盘分区名称和设备 每个使用了 ext4 文件系统的磁盘分区，都会有一个 jbd2 内核线程 pdflush：用于将内存中的脏页（被修改过，但还未写入磁盘的文件页）写入磁盘（已经在 3.10 中合并入了 kworker 中） ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:1:1","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"2. 内核线程性能剖析 对于普通进程，我们要观察其行为有很多方法，比如 strace、pstack、lsof 等等。但这些工具并不适合内核线程，比如，如果你用 pstack ，或者通过 /proc/pid/stack 查看 ksoftirqd/0（进程号为 9）的调用栈时，分别可以得到以下输出： # pstack 报出的是不允许挂载进程的错误 $ pstack 9 Could not attach to target 9: Operation not permitted. detach: No such process # /proc/9/stack 方式虽然有输出，但输出中并没有详细的调用栈情况。 $ cat /proc/9/stack [\u003c0\u003e] smpboot_thread_fn+0x166/0x170 [\u003c0\u003e] kthread+0x121/0x140 [\u003c0\u003e] ret_from_fork+0x35/0x40 [\u003c0\u003e] 0xffffffffffffffff 内核的追踪，我们需要借助动态追踪技术，比如 perf，Systemtap, eBPF。借助于这些工具我们可以生成火焰图，帮助我们分析各种问题。各种工具的使用，我们在这个系列文章的开始都作了详细介绍。希望大家多多练习，熟练掌握。下面我举几个例子，让大家看看，这些工具是如何达到异曲同工之妙的。 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:2:0","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"3. 跟踪网络丢包 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:3:0","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"4. 火焰图追踪 ksoftirqd 调用栈 ","date":"2020-01-31","objectID":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/:4:0","tags":["Linux 性能调优"],"title":"4.17 总结-内核线程","uri":"/posts/linux/linux_perf/37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B/"},{"categories":["Linux"],"content":"4.15 网络动态追踪","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"本节我们来介绍网络的动态追踪技术 ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:0:0","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1. Systemtab 磁盘网络 Dtrace/Systemtab 可以在内核和应用程序内部检查网络事件，包括 套接字连接 套接字I/O TCP事件 数据包重传 积压队列丢包 TCP重传 这些功能能够支持工作负载特征归纳和延时分析 ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:0","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.1 Dtrace 下面列出了用来跟踪网络的 Dtrace provider 层次 稳定 provider 不稳定 provider 应用程序 取决于应用 pid 系统库 pid 系统调用 syscall 套接字 fbt TCP tcp,mib fbt UDP udp,mib fbt IP ip,mib fbt 链路层 fbt 设备驱动 fbt ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:1","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.2 Systemtap Systemtap 提供了如下了 tapset 进行网络追踪: Socket Tapset Networking Tapset ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:2","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.网络跟踪 ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:0","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.1 套接字连接 由处理网络的应用程序函数，系统套接字库，系统调用层，或者在内核中都可以跟踪套接字活动。通常偏好在系统调用层，因为文档最全，系统开销最低并且是系统级的。 除了 connect() 和 accept() 还能跟踪 socket() 和 close() 系统调用，这允许在创建时发现文件描述符，并用时间差衡量套接字的持续时间。 Dtrace # 1. 用 connect() 计数出站连接 dtrace -n 'syscall::connect:entry { @[execname] =count(); }' # 2. 用 accept() 计算入站连接 dtrace -n 'syscall:🉑entry { @[execname] =count(); }' # 3. 通过检查用户栈可以揭示为什么会执行套接字 dtrace -n 'syscall::connect:entry /execname == 'ssh'/ { ustack(); }' # 4. 检查系统调用的参数，源自 Gregg # https://github.com/brendangregg/bpf-perf-tools-book soconnect.d Systemtap # 1. 用 connect() 计数出站连接 stap -ve 'global s;probe syscall.connect { s[execname()] \u003c\u003c\u003c 1} probe end { foreach(i in s- limit 10) {printf(\"%s: %d\\n\", i, @count(s[i]))}}' # 2. 用 accept() 计算入站连接 stap -ve 'global s;probe syscall.accept { s[execname()] \u003c\u003c\u003c 1} probe end { foreach(i in s- limit 10) {printf(\"%s: %d\\n\", i, @count(s[i]))}}' # 3. 通过检查用户栈可以揭示为什么会执行套接字 stap -ve 'global s; probe syscall.connect { s[ubacktrace()] \u003c\u003c\u003c 1} probe end { foreach(i in s- limit 10) {print_ustack(i); printf(\"%d\\n\", @count(s[i]))}}' # 4. 检查系统调用的参数，源自 Gregg # https://github.com/brendangregg/bpf-perf-tools-book soconnect.d # bpftrace 安装 sudo yum install epel-release sudo yum install snapd sudo systemctl enable --now snapd.socket sudo ln -s /var/lib/snapd/snap /snap sudo snap install --devmode bpftrace sudo snap connect bpftrace:system-trace # 执行 soconnect.dt git clone https://github.com/brendangregg/bpf-perf-tools-book.git cd bpf-perf-tools-book/originals/Ch10_Networking/ bpftrace soconnect.bt ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:1","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.2 套接字I/O Dtrace # 1. 按 execname 计数套接字读取次数 dtrace -n 'syscall::read:entry,syscall::recv:entry /fds[arg0].fi_fs == \"sockfs\"/ { @[execname]=count() }' # 2. 按 execname 计数套接字读取次数 dtrace -n 'syscall::write:entry,syscall::send:entry /fds[arg0].fi_fs == \"sockfs\"/ { @[execname]=count() }' Systemtap socket tapset 提供套接字读取的详细信息 # 1. 按 execname 计数套接字读取次数 stap -ve 'global s; probe socket.receive { s[execname()] \u003c\u003c\u003c 1 } probe end { foreach(i in s- limit 10) { printf(\"%s: %d\\n\", i, @count(s[i]))} }' # 2. 按 execname 计数套接字读取次数 stap -ve 'global s; probe socket.send { s[execname()] \u003c\u003c\u003c 1 } probe end { foreach(i in s- limit 10) { printf(\"%s: %d\\n\", i, @count(s[i]))} }' ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:2","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.3 套接字延时 延时包括: 连接延时: 同步系统调用: 就是 connect() 耗时 异步系统调用: 这是执行 connect() 至 poll() 或者 select() 或其他系统调用报告套接字就绪的时间 首字节延时: 自执行 connect() 或从 accept() 返回，直到第一字节数据由任何一个 I/O 系统调用从套接字接收到的时间 套接字持续时间: 同一个套接字从 socket() 到 close() 的时间要聚焦连接时长可以由connect() 或者 accetp() 开始计时 Dtrace Systemtap ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:3","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.4 套接字内部活动 Dtrace 利用 fbt provider 能跟踪套接字的内核运行。 # linux 查看套接字内核函数探针 dtrace -ln 'fbt::sock*:entry' Systemtap # linux 查看套接字内核函数探针 \u003e stap -l 'kernel.function(\"sock*\")' kernel.function(\"sock_aio_dtor@net/socket.c:890\") kernel.function(\"sock_aio_read@net/socket.c:959\") kernel.function(\"sock_aio_write@net/socket.c:1001\") kernel.function(\"sock_alloc@net/socket.c:535\") ..... \u003e stap -L 'kernel.function(\"sock_recv_drops@net/socket.c:788\")' kernel.function(\"sock_recv_drops@net/socket.c:788\") $skb:struct sk_buff* $sk:struct sock* $msg:struct msghdr* ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:4","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.5 TCP 事件 Dtrace TCP 的内核运行也能用 fbt provider，但是 tcp 有专属的 tcp provider TCP 探针 描述 tcp:::accept-established 接受一个入站连接，被动 open tcp:::connect-request 启动一个出站连接，主动 open tcp:::connect-established 建立一个出站连接，完成三次握手 tcp:::accetp-refused 拒绝一个连接请求，关闭本地端口 tcp:::connect-refused 拒绝一个连接请求，关闭远程端口 tcp:::send 发送一个数据段，ip可能直接将数据段映射到一个数据包 tcp:::receive 接受一个数据段，ip可能直接将数据段映射到一个数据包 tcp:::state-change 一个会话发生状态改变 tcp provider 提供了协议包头细节以及内核内部状态，其中包含\"缓冲\"的进程ID，通常DTrace 内置的 execname 跟踪的进程名不一定有效，因为内核 TCP 时间可能与进程非同步发生。 # 以频率计数接受的 TCP 连接(被动)以及远程 IP 地址和本地端口 dtrace -n 'tcp:::accept-established{ @[args[3]-\u003etcps_raddr, args[3]-\u003etcps_lport] = count(); }' Systemtap # 以频率计数接受的 TCP 连接(被动)以及远程 IP 地址和本地端口 stap -ve 'global s; probe kernel.{function(\"tcp_accept\"),function(\"inet_csk_accept\")}.return? {sock = $return;if (sock != 0){s[inet_get_local_port(sock), inet_get_ip_source(sock)] \u003c\u003c\u003c 1}} probe end { foreach([i,j] in s- limit 10) { printf(\"%s,%d: %d\\n\", j,i, @count(s[i,j]))} }' tcp 连接监控 #! /usr/bin/env stap probe begin { printf(\"%6s %16s %6s %6s %16s\\n\", \"UID\", \"CMD\", \"PID\", \"PORT\", \"IP_SOURCE\") } probe kernel.{function(\"tcp_accept\"),function(\"inet_csk_accept\")}.return? { sock = $return if (sock != 0) printf(\"%6d %16s %6d %6d %16s\\n\", uid(), execname(), pid(), inet_get_local_port(sock), inet_get_ip_source(sock)) } ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:5","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.6 数据包传输 tcp provider 提供的功能有限，跟踪内核函数是跟踪网络传输的根本方法。一个快速穿越网络栈的方法是跟踪一个深层次的事件并且检查它的调用栈。 Dtrace # 1. 跟踪网络调用内核栈 \u003e dtrace -n 'fbt::ip_output:entry { @[stack(100)] = count(); }' ..... kernel`tcp_sendmsg_Ox895` # 网络调用内核栈中的一个函数 ..... # 2. 跟踪调用栈中的特定系统调用比如 tcp_sendmsg，查看他的参数 # 假设 tcp_sendmsg 的第四个参数是以字节为单位的长度，我们就可以统计 TCP 发送段的长度 \u003e dtrace -n 'fbt::tcp_sendmsg:entry { @['TCP send bytes']=quantize(arg3); }' Systemtap ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:6","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.7 重传跟踪 研究 TCP 重传有助于调查网络健康程度 Dtrace tcp_retransmit_skb.d # 云计算性能优化工具包中用于跟踪重传的 dtrace 脚本 # https://github.com/brendangregg/dtrace-cloud-tools tcpretranssnoop.d Systemtap git clone https://github.com/brendangregg/systemtap-lwtools.git # 未找到类似工具 ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:7","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.8 积压队列丢包 Dtrace # 云计算性能优化工具包中用于跟踪 积压队列丢包的 dtrace 脚本 # https://github.com/brendangregg/dtrace-cloud-tools tcpconnreqmaxq-pid_sdc6.d Systemtap # 未找到类似工具 ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:8","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"3. 高级网络跟踪脚本 Dtrace 云计算性能优化工具包 DTraceBook 的 Network Lower-Level Protocals 章节 https://github.com/brendangregg/bpf-perf-tools-book Systemtap https://sourceware.org/systemtap/SystemTap_Beginners_Guide/useful-systemtap-scripts.html#mainsect-network https://github.com/brendangregg/bpf-perf-tools-book https://github.com/brendangregg/systemtap-lwtools.git ","date":"2020-01-30","objectID":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:9","tags":["Linux 性能调优"],"title":"4.15 网络动态追踪","uri":"/posts/linux/linux_perf/34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4.14 网络监测命令","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"本节我们来介绍内存相关的监测工具。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令总览 下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了网络相关的性能检测工具: 从网络的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握网络分析的套路 我们会介绍如下网络统计信息的工具 Linux Solaris 作用 说明 netstat,ss netstat 多种网络栈和接口统计信息 sar 统计信息历史 ifconfig ifconfig 接口配置 ip ip 网络配置接口统计信息 nicstat nicstat 网络接口吞吐量和使用率 ethtool ethtool 查看网络接口的带宽 ping ping 测试网络连通性 traceroute traceroute 测试网络路由 pathchar pathchar 确定网络路径特征 tcpdump tcpdump/snoop 网络数据报嗅探器 nethogs nethogs 查看进程的网络收发情况 iftop iftop 查看IP的网络收发情况 conntrack conntrack 查看和管理连接跟踪状况 ts ts 网络Qos设置 Wireshark Wireshark 图形化网络数据包检查器 DTrace,perf DTrace TCP/IP栈跟踪: 连接、数据包、丢包、延时 除此之外，还包括以下内容: 网络基准测试 网络调优 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.1 网络相关的理论 阅读中遇到下面不理解的概念，记录如下: TCP TIME-WAIT CPU 扇出 链路聚合 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:1:1","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 网络统计命令 网络的统计信息由以下两个文件提供: /proc/net/snmp /proc/net/netstat ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 ss ss options 作用: 多种网络栈和接口统计信息 选项: 套接字: 默认: 列出连接的套接字 -a: 列出所有套接字的信息 -4：只显示ipv4的套接字； -6：只显示ipv6的套接字； -t：只显示tcp套接字； -n：不解析服务名称，以数字方式显示； -l：显示处于监听状态的套接字； -u：只显示udp套接字； -d：只显示DCCP套接字； -w：仅显示RAW套接字； -x：仅显示UNIX域套接字 -S: display only SCTP sockets -f: 显示 FAMILY类型的套接字，FAMILY可选包括 inet|inet6|link|unix|netlink|vsock|help 套接字相关资源: -m：显示套接字的内存使用情况 -p：显示使用套接字的进程信息 -E: continually display sockets as they are destroyed -Z: display process SELinux security contexts -z: display process and socket SELinux security contexts -K: forcibly close sockets, display what was closed 统计信息: -s: 网络栈统计信息 -i: 网络接口信息 输出控制: -o: 显示计时器信息 -D, –diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -N: switch to the specified network namespace name -e: show detailed socket information -A, –query=QUERY, –socket=QUERY，QUERY 包括: all|inet|tcp|udp|raw|unix unix_dgram|unix_stream|unix_seqpacket|packet| netlink|vsock_stream|vsock_dgram ss -s Total: 283 (kernel 0) # ss 只显示已经连接、关闭、孤儿套接字等简要统计 TCP: 14 (estab 2, closed 1, orphaned 0, synrecv 0, timewait 0/0), ports 0 Transport Total IP IPv6 * 0 - - RAW 0 0 0 UDP 11 8 3 TCP 13 8 5 INET 24 16 8 FRAG 0 0 0 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:1","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.2 netsat netstat [-vWeenNcCF] [\u003cAf\u003e] -r netstat [-vWnNcaeol] [\u003cSocket\u003e ...] netstat { [-vWeenNac] -I[\u003cIface\u003e] | [-veenNac] -i | [-cnNe] -M | -s [-6tuw] } [delay] 选项: 统计选项: -i: 显示网络接口信息 -s: 显示网络栈统计信息 系统信息: -p: 显示使用套接字的进程信息 -r: 显示路由表 -g：显示多重广播功能群组组员名单 -M: 显示伪装的网络连线 -F: display Forwarding Information Base (default) -C: display routing cache instead of FIB -Z: 显示套接字的 SELinux 信息 显示控制: -v, –verbose be verbose -W, –wide don’t truncate IP addresses -n: 显示 IP 地址 -N: 显示网络硬件外围设备的符号连接名称； -e: 显示扩展信息 -o: 显示计时器 -c: 持续输出 套接字筛选: -a: 列出所有套接字的信息 -l: 显示处于监听状态的套接字 -t|–tcp -u|–udp -U|–udplite -S|–sctp -w|–raw -x|–unix –ax25 –ipx –netrom -6: inet6 (IPv6) -4: inet (IPV4) netstat -i 常与 -c 一起使用，每秒输出下面的累计计数。 Kernel Interface table Iface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flg enp0s3 1500 140998 0 0 0 12029 0 0 0 BMRU lo 65536 107 0 0 0 107 0 0 0 LRU virbr0 1500 0 0 0 0 0 0 0 0 BMU virbr0-nic 1500 0 0 0 0 0 0 0 0 BMU 输出: ifcae: 网络接口 MTU 一系列的接收(RX-)和传输(TX-) OK: 成功传输的数据包 ERR: 错误数据包 DRP: 丢包 - 网络接口是否饱和指针 OVR: 超限 - 网络接口是否饱和指针 netstat -s $ netstat -s Ip: 21721 total packets received 0 forwarded 0 incoming packets discarded 15111 incoming packets delivered 10909 requests sent out 98 dropped because of missing route Icmp: 0 ICMP messages received 0 input ICMP message failed. ICMP input histogram: 244 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 244 IcmpMsg: OutType3: 244 Tcp: 14 active connections openings 17 passive connection openings 0 failed connection attempts 0 connection resets received 2 connections established 14307 segments received 9608 segments send out 4 segments retransmited 0 bad segments received. 8 resets sent .... 理解上面的信息需要对 TCP行为有着深刻的理解。下面是值的查找的示例指标: 相比接收的总数据包更高速率的包转发，检查服务器是否需要转发数据包 更高的数据段重传输率 套接字缓冲超限导致的数据包从接收队列中删除 重要字段: tcpListenDrops： tcp 丢包数量 netstat -nlp 查询套接字信息： # -l 表示只显示监听套接字 # -t 表示只显示 TCP 套接字 # -n 表示显示数字地址和端口(而不是名字) # -p 表示显示进程信息 $ ss -ltnp | head -n 3 State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 127.0.0.53%lo:53 0.0.0.0:* users:((\"systemd-resolve\",pid=840,fd=13)) LISTEN 0 128 0.0.0.0:22 0.0.0.0:* users:((\"sshd\",pid=1459,fd=3)) 其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。 套接字处于连接状态（Established）时: Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。 套接字处于监听状态（Listening）时 Recv-Q 表示全连接队列的长度(全连接队列的长度就是上一篇文章所说的侦听积压队列的长度) Send-Q 表示全连接队列的最大长度 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:2","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.3 ifconfig/ip ifconfig ens33: flags=4163\u003cUP,BROADCAST,RUNNING,MULTICAST\u003e mtu 1500 inet 192.168.44.128 netmask 255.255.255.0 broadcast 192.168.44.255 ether 00:0c:29:74:60:60 txqueuelen 1000 (Ethernet) # txqueuelen 为接口发送队列的长度 RX packets 59072 bytes 32261953 (30.7 MiB) # 同 netstat -i 的输出 RX errors 0 dropped 0 overruns 0 frame 0 TX packets 14288 bytes 2090118 (1.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ip -s link 1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast # 同 netstat -i 的输出 10284 108 0 0 0 0 TX: bytes packets errors dropped carrier collsns 10284 108 0 0 0 0 指标含义: 网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。 ifconfig txqueuelen: 表示接口发送队列的长度 对于速度较低的高延时设备，设置较小的值有助于预防高速的大量传输影响 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions errors 表示发生错误的数据包数，比如校验错误、帧同步错误等； dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包； overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包； carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等； collisions 表示碰撞数据包数。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:3","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.4 pathchar pathchar ip: 作用: 类似于 traceroute，并且包括了每一跳间的带宽 缺点: 找不到可运行的版本，并且运行非常耗时 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:4","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.5 tcpdump tcpdump [选项] [过滤表达式] 作用: 捕获并分析网络数据包 原理: 基于 libpcap ，利用内核中的 AF_PACKET 套接字，抓取网络接口中传输的网络包 注意: CPU 和存储而言，捕获数据包是昂贵的，应在尽可能短的时间内使用 选项: -w file: -c NUM: 限制要抓取的网络包的个数 -A: 以 ASCII 格式显示网络包内容，不指定时只显示头部信息 -i: 指定网络接口卡 -nn: 禁止 IP 地址反解 -v: 显示数据包详细细节 -e: 显示链路层报头 -x: 十六进制地址转换 -ttt: 时间戳显示为数据包间的时间差 -tttt: 时间戳显示为第一个数据包以来的时间差 # 1. 将 eth4 接口的数据写入文件 tcpdump -i etch4 -w /tmp/out.tcpdump # 2. 从导出的文件中检查数据包 tcpdump -nr /tmp/out.tcpdump # 3. 监听 etho0 tcp 80 端口的网络包 tcpdump -i eth0 -n tcp port 80 # 4. 监听DNS解析 # -nn ，表示不解析抓包中的域名（即不反向解析）、协议以及端口号。 # udp port 53 ，表示只显示 UDP 协议的端口号 53 # host 35.190.27.188 ，表示只显示 IP 地址（包括源地址和目的地址）为 35.190.27.188 的包。 # 中间的“ or ”，表示或的关系 tcpdump -nn udp port 53 or host 35.190.27.188 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:5","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.6 Wireshark Wireshark 也是最流行的一个网络分析工具，它最大的好处就是提供了跨平台的图形界面。跟 tcpdump 类似，Wireshark 也提供了强大的过滤规则表达式，同时，还内置了一系列的汇总分析工具。在实际分析网络性能时，先用 tcpdump 抓包，后用 Wireshark 分析，是一种常用的方法。 $ tcpdump -nn udp port 53 or host 35.190.27.188 -w ping.pcap $ scp host-ip/path/ping.pcap . # 再用 Wireshark 打开 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:6","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.7 ethtool ethtool DEVICENAME 作用: 查看网络接口的各种信息 ethtool enp0s3 Settings for enp0s3: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Supported FEC modes: Not reported Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: No Advertised auto-negotiation: Yes Advertised FEC modes: Not reported Speed: 1000Mb/s # 网络接口的带宽 Duplex: Full Port: Twisted Pair PHYAD: 0 Transceiver: internal Auto-negotiation: on MDI-X: off (auto) Supports Wake-on: umbg Wake-on: d Current message level: 0x00000007 (7) drv probe link Link detected: yes ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:7","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.8 iftop ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:8","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.9 nethogs ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:9","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 网络基准测试 我们将从下往上，了解不同协议层的网络性能测试方法，包括: 转发性能 TCP/UDP 性能 HTTP 性能 应用负载性能 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 转发性能 网络接口层和网络层，主要负责网络包的封装、寻址、路由以及发送和接收。在这两个网络协议层中，每秒可处理的网络包数 PPS，就是最重要的性能指标，特别是 64B 小包的处理能力。 hping3 和 pktgen 是网络性能测试的常用工具。 hping3 hping3 作用: 可以构造 TCP/IP 协议数据包的工具 可以对系统进行安全审计、防火墙测试等 参数: -S: 表示设置TCP协议的SYN（同步序列号）， -p: 表示目的端口为80 -i u100: 表示每隔100微秒发送一个网络帧 –flood: 尽可能按最快速度发,不用回应 –rand-source: 使用随机源地址 # 1. 通过 TCP 测量网络延时 # -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80 $ hping3 -c 3 -S -p 80 baidu.com # --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析 $ traceroute --tcp -p 80 -n baidu.com pktgen pktgen 是一个内核线程，需要加载 pktgen 内核模块，并通过 /proc 文件系统来交互。 $ modprobe pktgen $ ps -ef | grep pktgen | grep -v grep root 26384 2 0 06:17 ? 00:00:00 [kpktgend_0] root 26385 2 0 06:17 ? 00:00:00 [kpktgend_1] $ ls /proc/net/pktgen/ kpktgend_0 kpktgend_1 pgctrl pktgen 在每个 CPU 上启动一个内核线程，并可以通过 /proc/net/pktgen 下面的同名文件，跟这些线程交互；而 pgctrl 则主要用来控制这次测试的开启和停止。 在使用 pktgen 测试网络性能时，需要先给每个内核线程 kpktgend_X 以及测试网卡，配置 pktgen 选项，然后再通过 pgctrl 启动测试。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:1","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.2 TCP/UDP 性能 传输层的 TCP 和 UDP，它们主要负责网络传输。对它们而言，吞吐量（BPS）、连接数以及延迟，就是最重要的性能指标。可以用 iperf 或 netperf ，来测试传输层的性能。 不过要注意，网络包的大小，会直接影响这些指标的值。所以，通常，需要测试一系列不同大小网络包的性能。 iperf # 1. 安装 yum install iperf3 # 2. 在目标机器上启动 iperf 服务端： # -s表示启动服务端，-i表示汇报间隔，-p表示监听端口 $ iperf3 -s -i 1 -p 10000 # 3. 运行客户端，执行测试 # -c表示启动客户端，192.168.0.30为目标服务器的IP # -b表示目标带宽(单位是bits/s) # -t表示测试时间 # -P表示并发数，-p表示目标服务器监听端口 $ iperf3 -c 192.168.0.30 -b 1G -t 15 -P 2 -p 10000 # 4. 服务器端输出的测试报告 # 包括测试时间、数据传输量以及带宽等 [ ID] Interval Transfer Bandwidth ... [SUM] 0.00-15.04 sec 0.00 Bytes 0.00 bits/sec sender [SUM] 0.00-15.04 sec 1.51 GBytes 860 Mbits/sec receiver ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:2","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.3 HTTP 性能 应用层，最需要关注的是吞吐量（BPS）、每秒请求数以及延迟等指标。ab、webbench 是常用的 HTTP 压力测试工具。 ab $ yum install -y httpd-tools # -c表示并发请求数为5000， # -n表示总的请求数为10万 # -r表示套接字接收错误时仍然继续执行， # -s表示设置每个请求的超时时间为2s $ ab -c 5000 -n 100000 -r -s 2 http://192.168.0.30/ # -c表示并发请求数为1000，-n表示总的请求数为10000 $ ab -c 1000 -n 10000 http://192.168.0.30/ ... Server Software: nginx/1.15.8 Server Hostname: 192.168.0.30 Server Port: 80 ... Requests per second: 1078.54 [#/sec] (mean) # 平均延迟，包括了线程运行的调度时间和网络请求响应时间 # 所有并发用户(这里是100)都请求一次的平均时间 Time per request: 927.183 [ms] (mean) # 单个用户请求一次的平均时间 Time per request: 0.927 [ms] (mean, across all concurrent requests) # 吞吐量 Transfer rate: 890.00 [Kbytes/sec] received Connection Times (ms) # 建立连接、请求、等待以及汇总的时间 min mean[+/-sd] median max Connect: 0 27 152.1 1 1038 Processing: 9 207 843.0 22 9242 Waiting: 8 207 843.0 22 9242 Total: 15 233 857.7 23 9268 Percentage of the requests served within a certain time (ms) 50% 23 66% 24 75% 24 80% 26 90% 274 95% 1195 98% 2335 99% 4663 100% 9268 (longest request) ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:3","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.4 应用负载性能 iperf 或者 ab 等测试工具得到某个页面的访问性能，但是真实的用户请求时带负载的。为了得到应用程序的实际性能，就要求性能工具本身可以模拟用户的请求负载。我们还可以用 wrk、TCPCopy、Jmeter 或者 LoadRunner 等实现这个目标。 wrk \u003c选项\u003e \u003c被测HTTP服务的URL\u003e Options: -c, –connections \u003cN\u003e 跟服务器建立并保持的TCP连接数量 -d, –duration \u003cT\u003e 压测时间 -t, –threads \u003cN\u003e 使用多少个线程进行压测 -s, –script \u003cS\u003e 指定Lua脚本路径 -H, –header \u003cH\u003e 为每一个HTTP请求添加HTTP头 –latency 在压测结束后，打印延迟统计信息 –timeout 超时时间 -v, –version 打印正在使用的wrk的详细版本信息 说明: \u003cN\u003e代表数字参数，支持国际单位 (1k, 1M, 1G) \u003cT\u003e代表时间参数，支持时间单位 (2s, 2m, 2h) wrk 工具本身不提供 yum 或 apt 的安装方法，需要通过源码编译来安装。 yum groupinstall 'Development Tools' yum install -y openssl-devel git git clone https://github.com/wg/wrk.git wrk cd wrk make cp wrk /usr/local/bin/ 下面是 wrk 执行类似 ab 测试的示例: # -c表示并发连接数1000，-t表示线程数为2 $ wrk -c 1000 -t 2 http://192.168.0.30/ Running 10s test @ http://192.168.0.30/ 2 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 65.83ms 174.06ms 1.99s 95.85% # 延迟 Req/Sec 4.87k 628.73 6.78k 69.00% 96954 requests in 10.06s, 78.59MB read Socket errors: connect 0, read 0, write 0, timeout 179 Requests/sec: 9641.31 # 每秒请求数 Transfer/sec: 7.82MB # 吞吐量 wrk 最大的优势，是其内置的 LuaJIT，可以根据实际需求，生成所需的请求负载，或者自定义响应的处理方法。wrk 在调用 Lua 脚本时，可以将 HTTP 请求分为三个阶段，即 setup、running、done，如下图所示： # -s 指定 lua 脚本 $ wrk -c 1000 -t 2 -s auth.lua http://192.168.0.30/ ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:4","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.5 DNS 解析 nslookup 和 dig 是DNS 解析的常用工具 # 执行 dns 解析 # -debug 开启 nslookup 的调试输出 nslookup -debug time.geekbang.org # 反向解析 nslookup -type=PTR 35.190.27.188 8.8.8.8 # +trace表示开启跟踪查询 # +nodnssec表示禁止DNS安全扩展 $ dig +trace +nodnssec time.geekbang.org # -n 选项禁止名称解析 $ ping -n -c3 geektime.org DNS 缓存 DNS 通常使用UDP 协议，受网络抖动影响比较大。我们可以使用DNS 缓存来加速DNS解析。dnsmasq 是最常用的 DNS 缓存服务之一，还经常作为 DHCP 服务来使用。 # 启动 dnsmasq 服务 systemctl start dnsmasq # 修改 /etc/resolv.conf，将 DNS 服务器改为 dnsmasq 的监听地址 echo nameserver 127.0.0.1 \u003e /etc/resolv.conf ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:5","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. 网络内核优化 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:0","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 TCP 优化 SYN FLOOD 为了缓解 SYN FLOOD 等，利用 TCP 协议特点进行攻击而引发的性能问题，你可以考虑优化与 SYN 状态相关的内核选项: 增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）。 减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries # 1. 查看和就该积压队列的容量 # 查看积压队列的容量 sysctl net.ipv4.tcp_max_syn_backlog # 修改积压队列的容量 sysctl -w net.ipv4.tcp_max_syn_backlog=1024 net.ipv4.tcp_max_syn_backlog = 1024 # 2. 查看和修改建立连接时，发送 SYN_RECV 失败重试次数 sysctl -w net.ipv4.tcp_synack_retries=1 net.ipv4.tcp_synack_retries = 1 # 3. 开启 TCP SYN cookie sysctl -w net.ipv4.tcp_syncookies=1 net.ipv4.tcp_syncookies = 1 并发请求高 在请求数比较大的场景下，会有大量处于 TIME_WAIT 状态的连接(短连接的方式，http 会成为主动断开连接的一方)，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项: 增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets 增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。 减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。 开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。 增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力。 增加最大文件描述符的数量。你可以使用 fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。 长连接 在长连接的场景中，通常使用 Keepalive 来检测 TCP 连接的状态，以便对端连接断开后，可以自动回收。但是，系统默认的 Keepalive 探测间隔和重试次数，一般都无法满足应用程序的性能要求。所以，这时候你需要优化与 Keepalive 相关的内核选项，比如： 缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time； 缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl； 减少 Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:1","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.2 Socket 缓冲区 为了提高网络的吞吐量，你通常需要调整这些缓冲区的大小，可调内核参数和参考值如下图所示: 需要注意的是: tcp_rmem 和 tcp_wmem 的三个数值分别是 min，default，max，系统会根据这些设置，自动调整 TCP 接收 / 发送缓冲区的大小。 udp_mem 的三个数值分别是 min，pressure，max，系统会根据这些设置，自动调整 UDP 发送缓冲区的大小。 表格中的数值只提供参考价值，具体应该设置多少，还需要你根据实际的网络状况来确定。比如，发送缓冲区大小，理想数值是吞吐量 * 延迟，这样才可以达到最大网络利用率。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:2","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.3 网络层 网络层，负责网络包的封装、寻址和路由，包括 IP、ICMP 等常见协议。在网络层，最主要的优化，其实就是对路由、 IP 分片以及 ICMP 等进行调优。 路由和转发 从路由和转发的角度出发，可以调整下面的内核选项: 在需要转发的服务器中，比如用作 NAT 网关的服务器或者使用 Docker 容器时，开启 IP 转发，即设置 net.ipv4.ip_forward = 1。 调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl = 64。注意，增大该值会降低系统性能。 开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter = 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题。 MTU 从分片的角度出发，最主要的是调整 MTU（Maximum Transmission Unit）的大小。在使用 VXLAN、GRE 等叠加网络技术时，要注意，网络叠加会使原来的网络包变大，导致 MTU 也需要调整。 比如，就以 VXLAN 为例，它在原来报文的基础上，增加了 14B 的以太网头部、 8B 的 VXLAN 头部、8B 的 UDP 头部以及 20B 的 IP 头部。换句话说，每个包比原来增大了 50B。所以，我们就需要把交换机、路由器等的 MTU，增大到 1550， 或者把 VXLAN 封包前（比如虚拟化环境中的虚拟网卡）的 MTU 减小为 1450。 现在很多网络设备都支持巨帧，如果是这种环境，你还可以把 MTU 调大为 9000，以提高网络吞吐量。 ICMP 为了避免 ICMP 主机探测、ICMP Flood 等各种网络问题，你可以通过内核选项，来限制 ICMP 的行为。 可以禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all = 1。这样，外部主机就无法通过 ICMP 来探测主机 可以禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts = 1。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:3","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.4 链路层 链路层负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。自然，链路层的优化，也是围绕这些基本功能进行的。接下来，我们从不同的几个方面分别来看。 网络中断负载 网络中断会消耗大量的CPU，需要在多个CPU间平衡负载： 你可以为网卡硬中断配置 CPU 亲和性（smp_affinity），或者开启 irqbalance 服务。 再如，你可以开启 RPS（Receive Packet Steering）和 RFS（Receive Flow Steering），将应用程序和软中断的处理，调度到相同 CPU 上，这样就可以增加 CPU 缓存命中率，减少网络延迟。 网络功能卸载 现在的网卡都有很丰富的功能，原来在内核中通过软件处理的功能，可以卸载到网卡中，通过硬件来执行。 TSO（TCP Segmentation Offload）和 UFO（UDP Fragmentation Offload）：在 TCP/UDP 协议中直接发送大包；而 TCP 包的分段（按照 MSS 分段）和 UDP 的分片（按照 MTU 分片）功能，由网卡来完成 。 GSO（Generic Segmentation Offload）：在网卡不支持 TSO/UFO 时，将 TCP/UDP 包的分段，延迟到进入网卡前再执行。这样，不仅可以减少 CPU 的消耗，还可以在发生丢包时只重传分段后的包。 LRO（Large Receive Offload）：在接收 TCP 分段包时，由网卡将其组装合并后，再交给上层网络处理。不过要注意，在需要 IP 转发的情况下，不能开启 LRO，因为如果多个包的头部信息不一致，LRO 合并会导致网络包的校验错误。 GRO（Generic Receive Offload）：GRO 修复了 LRO 的缺陷，并且更为通用，同时支持 TCP 和 UDP。 RSS（Receive Side Scaling）：也称为多队列接收，它基于硬件的多个接收队列，来分配网络接收进程，这样可以让多个 CPU 来处理接收到的网络包。 VXLAN 卸载：也就是让网卡来完成 VXLAN 的组包功能。 网络接口卡 最后，对于网络接口本身，也有很多方法，可以优化网络的吞吐量。 比如，你可以开启网络接口的多队列功能。这样，每个队列就可以用不同的中断号，调度到不同 CPU 上执行，从而提升网络的吞吐量。 再如，你可以增大网络接口的缓冲区大小，以及队列长度等，提升网络传输的吞吐量（注意，这可能导致延迟增大）。 你还可以使用 Traffic Control 工具，为不同网络流量配置 QoS。 DPDK 和 XDP 使用 DPDK 技术，跳过内核协议栈，直接由用户态进程用轮询的方式，来处理网络请求。同时，再结合大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。 使用内核自带的 XDP 技术，在网络包进入内核协议栈前，就对其进行处理，这样也可以实现很好的性能。 ","date":"2020-01-29","objectID":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:4","tags":["Linux 性能调优"],"title":"4.14 网络监测命令","uri":"/posts/linux/linux_perf/33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.13 网络","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"本节我们讲解网络相关的操作系统原理。网络分析的目的除了改进网络延时和吞吐量外，另一个常见的任务是消除可能由丢包引起的延时异常。网络分析是跨硬件和软件的。硬件指的是物理网络包括网络接口卡，交换机，路由器和网管。软件指的是内核协议栈。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:0:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"1. 网络 本节我们将从以下几个方面介绍网络相关的操作系统原理: 网络协议栈 TCP 连接状态转移 TCP 拥塞控制 操作系统的网络栈 最后我们会介绍网络相关的检测指标。想对网络深入了解，推荐大家阅读: CCNA学习指南 TCP/IP详解 卷1：协议 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:1:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"1. 网络协议栈 网络的五层和七层模型想必大家都听过，下面是这两个协议栈模型的示意图: 数据经过网络协议栈时，通过包封装将每层协议的元数据添加到负载前(包头)，之后(包后)，或者二者，但不会修改负载数据。下面展示了以太网 TCP/IP 的栈封装过程: 数据就是这样经过封装，并通过路由器等网络设备在网络上进行传播，并最后被目标主机接收和解析。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:2:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"2. TCP 状态转移 下面是TCP建立连接三次握手和断开连接四次挥手，TCP 状态示意图: 实际传输过程中，服务器端收到客户端的 FIN 后，服务器端可以同时关闭连接，这样就可以把 ACK 和 FIN 合并到一起发送，节省了一个包，变成了“三次挥手”。 而如果服务器端收到客户端的 FIN 后，还没发送完数据，就会先回复客户端一个 ACK 包。稍等一会儿，完成所有数据包的发送后，才会发送 FIN 包。这也就是四次挥手了。 更详细的状态转移过程参见: TCP 状态转移 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:3:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"2.1 长连接和短连接 长连接和短连接除了关闭连接的时机，更重要的是长连接需要有一个保活机制。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:3:1","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"3. TCP 拥塞控制 TCP 的滑动窗口，拥塞控制可以看这篇文章图解TCP 重传、滑动窗口、流量控制、拥塞控制发愁，图文并茂很容易理解。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:4:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"3.1 Socket 连接选项 Socket Api 提供了众多选项用于控制 TCP 的传输。常见的会影响传输性能的选项包括: TCP_QUICKACK: 取消延迟确认 延迟确认是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。 只有 TCP 套接字专门设置了 TCP_QUICKACK ，才会开启快速确认模式；否则，默认情况下，采用的就是延迟确认机制： TCP_NODELAY: 禁用 Nagle 算法 Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。它通过合并 TCP 小包，提高网络带宽的利用率。 Linux 上默认会启用 Nagle 算法，只有设置了 TCP_NODELAY 后才会禁用 当客户端的延迟确认和服务器端的 Negle 算法同时启用时会对网络性能造成非常明显的网络延时。通常都需要关闭Nagle 算法。 TCP_CORK: 开启 TCP_CORK 后，可以让小包聚合成大包后再发送（会阻塞小包的发送） SO_SNDBUF 和 SO_RCVBUF ，可以分别调整套接字发送缓冲区和接收缓冲区的大小 使用 strace 可以跟踪网络发送的系统调用，从而确认网络连接启用的 Socket 连接选项。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:4:1","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"4. 操作系统的网络栈 网络通信软件包括网络栈、TCP和设备驱动程序。下面是一个通用的网络栈模型。 ARP: 地址解析协议 Data Link(generic net driver): 数据链路，通用网络驱动软件 NIC: 网卡: 网卡是发送和接收网络包的基本设备。在系统启动过程中，网卡通过内核中的网卡驱动程序注册到系统中。而在网络收发过程中，内核通过中断跟网卡进行交互。 网络的收发的过程中，网卡硬中断只处理最核心的网卡数据读取或发送，而协议栈中的大部分逻辑，都会放到软中断中处理。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:5:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"4.1 网络包收发过程 网络包的收过程 当一个网络帧到达网卡后: 网卡会通过 DMA 方式，把这个网络包放到收包队列中；然后通过硬中断，告诉中断处理程序已经收到了网络包。 DMA(Direct Memory Access，直接存储器访问) 允许不同速度的硬件装置来沟通，而不需要依赖于 CPU 的大量中断负载 网卡中断处理程序会为网络帧分配内核数据结构（sk_buff），并将其拷贝到 sk_buff 缓冲区中；然后再通过软中断，通知内核收到了新的网络帧。 内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧。 在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。 网络层取出 IP 头，判断网络包下一步的走向,当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理 传输层取出 TCP 头或者 UDP 头后，根据 \u003c 源 IP、源端口、目的 IP、目的端口 \u003e 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。 最后，应用程序就可以使用 Socket 接口，读取到新接收到的数据了。 环形缓冲区，由于需要 DMA 与网卡交互，属于网卡设备驱动的范围。 sk_buff 缓冲区，是一个维护网络帧结构的双向链表，链表中的每一个元素都是一个网络帧（Packet）。虽然 TCP/IP 协议栈分了好几层，但上下不同层之间的传递，实际上只需要操作这个数据结构中的指针，而无需进行数据复制。 套接字缓冲区，则允许应用程序，给每个套接字配置不同大小的接收或发送缓冲区。应用程序发送数据，实际上就是将数据写入缓冲区；而接收数据，其实就是从缓冲区中读取。至于缓冲区中数据的进一步处理，则由传输层的 TCP 或 UDP 协议来完成。 sk_buff、套接字缓冲、连接跟踪等，都通过 slab 分配器来管理。你可以直接通过 /proc/slabinfo，来查看它们占用的内存大小。 网络包的发送过程 网络包的发送方向，正好跟接收方向相反: 应用程序调用 Socket API（比如 sendmsg）发送网络包。由于这是一个系统调用，所以会陷入到内核态的套接字层中。套接字层会把数据包放到 Socket 发送缓冲区中。 接下来，网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理。 这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。 最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。 更加详细的收发过程详见Linux网络包收发总体过程 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:5:1","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"4.2 Linux Linux 中 TCP，IP以及通用网络驱动软件是内核的核心组件，设备驱动程序是附加模块，数据包以 struct_sk_buff 数据类型穿过这些内核组件。通用驱动程序能通过合并中断提高性能。 数据包的高处理器率通过调用多个 CPU 处理包和 TCP/IP 栈。Linux3.7 记录了如下不同的方法: RSS，接收端缩放: 现代 NIC 支持多个队列并且计算包哈希以放置不同的队列，而后依次按直接中断由不同的 CPU 处理。这个哈希值可能基于 IP和TCP 端口，因此源自同一连接的包能被同一个 CPU 处理。 RPS，接收数据包转向: 对于不支持多队列的NIC的RSS关键实现。一个短中断服务例行程序映射传入的数据包给 CPU 处理，用一个类似的哈希按数据包头的字段映射数据包到 CPU RFS，接收流转向: 类似 RPS，不过偏向前一个处理套接字的CPU，以提高CPU缓存命中率和内存本地性 加速接收数据流转向: 对于支持该功能的NIC，这是 RFS 的硬件实现。它用流信息更新NIC以确定中断哪个CPU XPS，传输数据包转向: 对于支持多个传输队列的NIC，这支持多个 CPU传输队列 当缺乏数据包的CPU负载均衡时，NIC会中断同一个CPU，进而达到100% 的使用率并成为瓶颈。 基于例如RFS 实现的缓存一致性等因素而映射中断到多个 CPU，能显著提升网络性能。这样能通过 irqbalancer 进程实现，它能分配中断请求 IRQ 给 CPU。 注:NIC 是网络接口卡的简称 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:5:2","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"4.3 积压队列和缓冲 积压队列 突发的链接由积压队列处理。这里有两个队列: 一个在TCP 握手完成前处理未完成的连接，又称为SYN积压队列 另一个处理等待应用程序接受的已建立的会话，又称为侦听积压队列 有两个队列的情况下第一个可作为潜在的伪造连接的集结地，仅在连接建立后才迁移到第二个队列，此队列可以设置的很长以吸收海量 SYN，并且优化为仅存放最少的必要元数据 第二个队列可由应用程序 listent() 的积压队列参数设置。 # 查看积压队列的容量 sysctl net.ipv4.tcp_max_syn_backlog # 修改积压队列的容量 sysctl -w net.ipv4.tcp_max_syn_backlog=1024 net.ipv4.tcp_max_syn_backlog = 1024 缓冲 利用套接字的发送和接收缓冲能够提升数据的吞吐量: 对于写通道，数据缓冲在 TCP发送缓冲区，然后送往IP发送。尽管IP协议有能力分段数据包，TCP仍试图发送 MSS 长度的段给IP以避免这种情况。这意味重发送单位对应分段的单位，否则一个被丢弃的数据段会导致整个分段前的数据包被重新传输。由于避免了分段和组装常规数据包，这种实现方式提升了 TCP/IP 栈的效率。 缓冲区的大小是可调整的。Linux 会基于连接的活跃度自动调节缓冲区大小。 网络设备驱动 网络设备驱动通常还有一个附加的缓冲区(环形缓冲区 DMA)用于在内核内存与NIC间发送和接收数据包。 随着10GbE以太网网的引入，利用中断结合模式的利于性能的功能愈发常见。一个中断仅仅在计时器激活或者达到一定数据量的包时才被发送，而不是每当有数据包达到就中断内核。这降低了内核与 NIC 通信的频率。允许缓冲更多的发送，从而达到更高的吞吐量。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:5:3","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"5. 网络监测 下面是网络常用的性能测量指标: 延时 带宽: 表示链路的最大传输速率 吞吐量: 表示单位时间内成功传输的数据量，吞吐量 / 带宽，也就是该网络的使用率。 PPS: PPS，是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率。 PPS 通常用来评估网络的转发能力。基于 Linux 服务器的转发，很容易受到网络包大小的影响 交换机通常不会受到太大影响，可以做到线性转发 对于数据库、缓存等系统，快速完成网络收发，即低延迟，是主要的性能目标 应用层指标: 网络的可用性（网络能否正常通信） 并发连接数（TCP 连接数量） 丢包率（丢包百分比） 重传率（重新传输的网络包比例）等也是常用的性能指标。 DNS DDos 拒绝服务攻击 总的来说，先要获得网络基准测试报告，然后通过相关性能工具，定位出网络性能瓶颈。在优化网络性能时，可以结合 Linux 系统的网络协议栈和网络收发流程，然后从应用程序、套接字、传输层、网络层再到链路层等，进行逐层优化。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:0","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"5.1 延时 延时是一个重要的网络性能指标，并且有多种测量方法，包括: 主机名解析延时 ping 延时: 往返延时 RTT（Round-Trip Time） 连接延时 首字节延时 往返延时 除了使用 ping， traceroute 或 hping3 的 TCP 和 UDP 模式，也可以获取网络延迟。 # 1. 通过 TCP 测量网络延时 # -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80 $ hping3 -c 3 -S -p 80 baidu.com # --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析 $ traceroute --tcp -p 80 -n baidu.com # 使用 wrk 可以测量并发连接的延时 # 测试80端口性能 $ wrk --latency -c 100 -t 2 --timeout 2 baidu.com 网络延时的排查思路 在发现网络延迟增大后，你可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如: 使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。 使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。 使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。 使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。 这样，就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:1","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"5.2 带宽、吞吐量和PPS 网络吞吐量和 PPS 可以使用 sar 命令查看。带宽的查看可以使用 ethtool 工具。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:2","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"使用率 网络连接口的使用率可以用当前的吞吐量除以最大带宽来计算。但是考虑到可变的带宽和自动协商的双工模式，计算不像看上去那么简单。对于全双工，使用率适合每个方向且用该方向当前的吞吐量除以当前协商的带宽来计算。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:3","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"饱和度 测量连接积压队列导致的丢包是一种衡量网络连接饱和度的方法 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:4","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"5.2 DNS DNS 不仅方便了人们访问不同的互联网服务，更为很多应用提供了，动态服务发现和全局负载均衡（Global Server Load Balance，GSLB）的机制。这样，DNS 就可以选择离用户最近的 IP 来提供服务。即使后端服务的 IP 地址发生变化，用户依然可以用相同域名来访问。 DNS 解析是基础而重要的一个环节。我们需要关注它的性能。 可以借助 nslookup 或者 dig 的调试功能，分析 DNS 的解析过程，再配合 ping 等工具调试 DNS 服务器的延迟，从而定位出性能瓶颈。 DNS 有如下几种常见的优化方法: 对 DNS 解析的结果进行缓存 对 DNS 解析的结果进行预取。这是浏览器等 Web 应用中最常用的方法 使用 HTTPDNS 取代常规的 DNS 解析。这是很多移动应用会选择的方法，特别是如今域名劫持普遍存在，使用 HTTP 协议绕过链路中的 DNS 服务器，就可以避免域名劫持的问题。 基于 DNS 的全局负载均衡（GSLB）。这不仅为服务提供了负载均衡和高可用的功能，还可以根据用户的位置，返回距离最近的 IP 地址。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:5","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"5.3 DDos 拒绝服务攻击 DDos 的类型 DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。 DDoS 可以分为下面几种类型。 第一种，耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。 第二种，耗尽操作系统资源 第三种，耗尽应用程序资源 DDoS 并不一定是因为大流量或者大 PPS，有时候，慢速的请求也会带来巨大的性能下降（这种情况称为慢速 DDoS）。比如，很多针对应用程序的攻击，都会伪装成正常用户来请求资源。这种情况下，请求流量可能本身并不大，但响应流量却可能很大，并且应用程序内部也很可能要耗费大量资源处理。 DDos 的缓解方案 针对DDos 我们有一下方法缓解其影响: 单源Dos攻击: 通过防火墙禁止特定源的访问 限制syn并发数 限制单个IP在60秒新建立的连接数 扩大半开状态的连接数 减少每个 SYN_RECV 失败时的重试次数 使用 TCP SYN Cookies 多源DDos: 只能缓解，而无法彻底解决 在服务器外部的网络设备中，设法识别并阻断流量（当然前提是网络设备要能扛住流量攻击）。比如，购置专业的入侵检测和防御设备，配置流量清洗设备阻断恶意流量等。 针对应用，需要应用程序考虑识别，并尽早拒绝掉这些恶意流量，比如合理利用缓存、增加 WAF（Web Application Firewall）、使用 CDN 等等。 下面是用 hping3 模拟 Dos，并尝试缓解 Dos 攻击的示例: # 1. 构造一个 SYN 泛洪攻击 # -S参数表示设置TCP协议的SYN（同步序列号）， # -p表示目的端口为80 # -i u10表示每隔10微秒发送一个网络帧 # --flood 尽可能按最快速度发,不用回应 # --rand-source 使用随机源地址 $ hping3 -S -p 80 -i u10 --flood --rand-source 192.168.0.30 # 1. SYN 泛洪攻击对策 -- 针对单个源 # 限制syn并发数为每秒1次 $ iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT # a.限制单个IP在60秒新建立的连接数为10 $ iptables -I INPUT -p tcp --dport 80 --syn -m recent --name SYN_FLOOD --update --seconds 60 --hitcount 10 -j REJECT # b.查看半连接容量并修改积压队列的容量 sysctl net.ipv4.tcp_max_syn_backlog sysctl -w net.ipv4.tcp_max_syn_backlog=1024 net.ipv4.tcp_max_syn_backlog = 1024 # c.连接每个 SYN_RECV 时，如果失败的话，内核还会自动重试， # 默认的重试次数是 5 次。可将其减小为 1 次： sysctl -w net.ipv4.tcp_synack_retries=1 net.ipv4.tcp_synack_retries = 1 # d.TCP SYN Cookies 也是一种专门防御 SYN Flood 攻击的方法 TCP SYN Cookies: 是基于连接信息（包括源地址、源端口、目的地址、目的端口等）以及一个加密种子（如系统启动时间），计算出一个哈希值（SHA1），这个哈希值称为 cookie。 然后，这个 cookie 就被用作序列号，来应答 SYN+ACK 包，并释放连接状态。 当客户端发送完三次握手的最后一次 ACK 后，服务器就会再次计算这个哈希值，确认是上次返回的 SYN+ACK 的返回包，才会进入 TCP 的连接状态。 因而，开启 SYN Cookies 后，就不需要维护半开连接状态了，进而也就没有了半连接数的限制。 开启 TCP syncookies 后，内核选项 net.ipv4.tcp_max_syn_backlog 也就无效了。 ","date":"2020-01-28","objectID":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/:6:6","tags":["Linux 性能调优"],"title":"4.13 网络","uri":"/posts/linux/linux_perf/32_%E7%BD%91%E7%BB%9C/"},{"categories":["Linux"],"content":"4.12 磁盘动态追踪","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"本节我们来介绍磁盘的动态追踪技术 ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:0:0","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1. Systemtab 磁盘追踪 Dtrace/Systemtab 能从内核角度检查磁盘 I/O 时间，包括: 块设备接口 I/O I/O 调度器事件 目标驱动 I/O 设备驱动 I/O ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:0","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.1 Dtrace 下面列出了用来跟踪磁盘 I/O 的Dtrace provider 层次 稳定 provider 不稳定 provider 应用程序 取决于应用 pid 系统库 pid 系统调用 syscall VFS fsinfo fbt 文件系统 fbt 块设备接口 io fbt 目标驱动 fbt 设备驱动 fbt io provider io provider 使得外界可以从块设备几口的角度进行观察，以支持工作负载特征归纳和延时分析。其提供了如下的探测器: io:::start: 一个I/O请求被发到设备上 io::🔚 一个 I/O请求在设备上完成(完成中断) io:::wait-start: 一个线程开始等待一个 I/O 请求 io:::wait-down: 一个线程等完了一个 I/O 请求 探测器有一些稳定的参数提供 I/O 的详细信息，如下所示: 语法 作用 说明 args[0]-\u003eb_count I/O 大小(字节数) args[0]-\u003eb_blkno 设备 I/O 偏移量(块) args[0]-\u003eb_flags 位元标志位，包括表示读I/O的B_READ args[0]-\u003eb_error 错误状态 args[0]-\u003edev_statname 设备实例名+实例/小编号 args[0]-\u003edev_pathname 设备路径名 args[0]-\u003efi_pathname 文件系统名 args[0]-\u003efi_fs 文件系统类型 I/O方向(读写) 可以使用表达式 args[0]-\u003eb_flags \u0026 B_READ ? \"read\": \"write\" ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:1","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.2 Systemtap Systemtap 提供了用于跟踪磁盘 I/O 的 ioblock.stp tapset，其包含了下面这些探针: DTrace Systemtap 描述 io:::start ioblock.request io:::done ioblock.end ioblock.request ioblock.request 内置了下面的变量来提供 I/O 的详细信息。 变量 内容 name probe point 名称 devname 设备名称 ino inode number of the mapped file sector beginning sector for the entire bio flags see below BIO_UPTODATE 0 ok after I/O completion BIO_RW_BLOCK 1 RW_AHEAD set, and read/write would block BIO_EOF 2 out-out-bounds error BIO_SEG_VALID 3 nr_hw_seg valid BIO_CLONED 4 doesn’t own data BIO_BOUNCED 5 bio is a bounce bio BIO_USER_MAPPED 6 contains user pages BIO_EOPNOTSUPP 7 not supported rw binary trace for read/write request vcnt bio vector count which represents number of array element (page, offset, length) which make up this I/O request idx offset into the bio vector array phys_segments number of segments in this bio after physical address coalescing is performed hw_segments number of segments after physical and DMA remapping hardware coalescing is performed size total size in bytes bdev target block device bdev_contains points to the device object which contains the partition (when bio structure represents a partition) p_start_sect points to the start sector of the partition structure of the device ioblock.end 除了上面这些变量，ioblock.end 还提供了下面这些变量来提供I/O的结果 变量 内容 bytes_done number of bytes transferred error 0 on succes ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:2","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2. 磁盘跟踪示例 下面的 Dtrace 脚本位于 https://github.com/opendtrace/toolkit/blob/master/Disk/seeksize.d ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:0","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.1 事件跟踪 以下跟踪的是每一个磁盘I/O请求 # dtrace: \u003e dtrace -n 'io:::start {printf(\"%d %s %d\", pid, execname, args[0]-\u003eb_bcount);}' # stap \u003e stap -ve 'probe ioblock.request {printf(\"%d %s %d\\n\", pid(), execname(), size)}' ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:1","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.2 按照应用程序名汇总磁盘 I/O 大小 # dtrace: \u003e dtrace -n 'io:::start {@[execname]=quantize(arg[0]-\u003eb_bcount)}' # stap \u003e stap -ve 'global s;probe ioblock.request {s[execname()] \u003c\u003c\u003c size} probe end {foreach (k in s){printf(\"%s\\n\", k);print(@hist_log(s[k]))};}' ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:2","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.3 I/O 寻道汇总 下面的脚本跟踪同一应用程序，同一设备的连续 I/O 之间寻道距离，按照进程输出直方图。 dtrace 脚本 #!/usr/sbin/dtrace -s dtrace:::BEGIN { printf(\"Tracing... Hit Ctrl-C to end.\\n\"); } self int last[dev_t]; /* * Process io start */ io:genunix::start /self-\u003elast[args[0]-\u003eb_edev] != 0/ { /* calculate seek distance */ this-\u003elast = self-\u003elast[args[0]-\u003eb_edev]; this-\u003edist = (int)(args[0]-\u003eb_blkno - this-\u003elast) \u003e 0 ? args[0]-\u003eb_blkno - this-\u003elast : this-\u003elast - args[0]-\u003eb_blkno; /* store details */ @Size[pid, curpsinfo-\u003epr_psargs] = quantize(this-\u003edist); } io:genunix::start { /* save last position of disk head */ self-\u003elast[args[0]-\u003eb_edev] = args[0]-\u003eb_blkno + args[0]-\u003eb_bcount / 512; } /* * Print final report */ dtrace:::END { printf(\"\\n%8s %s\\n\", \"PID\", \"CMD\"); printa(\"%8d %S\\n%@d\\n\", @Size); } ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:3","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"stap 脚本 未完成 ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:4","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2.3 I/O 延时汇总 下面的脚本跟踪块I/O开始和结束的时间 # dtrace \u003e dtrace -n 'io:::start {start[arg0] = timestamp;} io:::done /start[arg0]/ {@[\"block I/O(ns)\"] = quantize(timestamp - start[arg0]);start[arg0] = 0}' # stap \u003e stap -ve 'global t,s; probe ioblock.request {t[$bio] = gettimeofday_ns();} probe ioblock.end {if (t[$bio]) {s \u003c\u003c\u003c gettimeofday_ns() - t[$bio];delete t[$bio];} } probe end{print(@hist_log(s))}' ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:2:5","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"3.高级工具 磁盘常用的高级跟踪脚本: DTrace: https://github.com/opendtrace/toolkit Systemp: https://sourceware.org/systemtap/SystemTap_Beginners_Guide/mainsect-disk.html ","date":"2020-01-27","objectID":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:3:0","tags":["Linux 性能调优"],"title":"4.12 磁盘动态追踪","uri":"/posts/linux/linux_perf/32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4.11 磁盘监测命令","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"本节我们来介绍磁盘相关的监测工具。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令总览 下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了磁盘相关的性能检测工具: 从磁盘的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握磁盘分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍如下磁盘专用的分析工具的使用 Linux Solaris 作用 说明 iostat iostat 各种单个磁盘的统计信息 pidstat,iotop iotop 按进程列出磁盘I/O使用情况 blktrace iosnoop 磁盘I/O事件追踪 MegaCli MegaCli LSI控制统计信息 smartctl smartctl 磁盘控制器统计信息 sar sar 磁盘历史统计信息 通用命令，位于独立的一节中 lsof lsof 查看进程打开的文件列表 biosnoop biosnoop 跟踪进程的块设备I/O大小 bcc工具包 biotop biotop 跟踪进程块I/O大小并实时排序 bcc工具包 除此之外，还包括以下内容: 磁盘性能测试 磁盘性能调优 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 磁盘统计命令 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 iostat iostat options [interval [count]] 作用: 单个磁盘的统计信息，统计信息的来源直接由内核维护，几乎没有开销 默认: 打印自启动以来的 -c和-d 选项的汇总报告 说明: SCSI 设备包括磁带和 CD-ROM 在当前Linux 不会显示 来源: iostat 的数据来自 /proc/diskstats 参数: -c: 显示 CPU 报告 -d: 显示磁盘报告 -k: 使用 KB代替(512B)块数量 -m: 使用 MB代替(512B)块数量 -p: 包括单个分区的统计信息 -t: 时间戳输出 -x: 扩展统计信息 -z: 不显示空活动汇总 iostat Linux 3.10.0-1062.el7.x86_64 (hostname) 2020年04月21日 _x86_64_ (1 CPU) # 启动以来的CPU和磁盘设备统计信息 avg-cpu: %user %nice %system %iowait %steal %idle 0.39 0.00 0.22 0.01 0.00 99.37 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 1.71 67.68 5.39 925064 73658 dm-0 1.64 65.32 5.24 892891 71574 dm-1 0.01 0.16 0.00 2204 0 输出: tps: IOPS 每秒事务数 kB_read/s: 每秒读KB数 kB_wrtn/s: 每秒写KB数 kB_read: 总读取KB数 kB_wrtn: 总写入KB数 扩展输出 iostat -xkdz 1 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月21日 _x86_64_ (1 CPU) Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util sda 0.00 0.07 1.37 0.29 65.70 5.25 85.36 0.00 1.38 0.69 4.60 0.48 0.08 dm-0 0.00 0.00 1.28 0.32 63.41 5.10 85.88 0.00 1.67 0.72 5.46 0.49 0.08 dm-1 0.00 0.00 0.01 0.00 0.16 0.00 50.09 0.00 0.23 0.23 0.00 0.17 0.00 输出 含义 rrqm/s 每秒合并放入驱动请求队列的读请求数 wrqm/s 每秒合并放入驱动请求队列的写请求数 r/s 每秒发给磁盘设备的读请求书，这是实际发给磁盘的请求数 w/s 每秒发给磁盘设备的写请求书，这是实际发给磁盘的请求数 rkB/s 每秒从磁盘设备读取的 KB 数 wkB/s 每秒向磁盘设备写入的 KB 数 avgrq-sz 平均请求大小，单位为扇区(512B) avgqu-sz 在驱动请求队列和在设备中活跃的平均请求数 await 平均I/O响应时间，包括在驱动请求队列里等待和设备的I/O响应时间(ms) r_await 同awit，不过只针对读 w_await 同awit，不过只针对写 svctm 推断的磁盘设备的I/O平均响应时间 %util 使用率，设备忙处理I/O请求的百分比 说明: 非零的 rrqm/s 和 wrqm/s 说明为了提高性能，连续的请求在发往设备之前已经被合并了，这个指标也是工作负载为连续的标志 avgrq-sz 是合并之后的数字，小尺寸(16个扇区或者更小)可以视为无法合并的随机I/O负载。大尺寸有可能是大I/O，或者是合并的连续负载 r/s+w/s ，就是 IOPS； rkB/s+wkB/s ，就是吞吐量； r_await+w_await ，就是响应时间。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:1","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.2 iotop iotop options 作用: 参数: -o, –only只显示正在产生I/O的进程或线程。除了传参，可以在运行过程中按o生效 -P, –processes仅显示进程，默认iotop显示所有线程 -a, –accumulated显示累积的I/O，而不是带宽 -d SEC, –delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1 -p PID, –pid=PID指定监测的进程/线程 -u USER, –user=USER指定监测某个用户产生的I/O -k, –kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用 -b, –batch非交互模式，一般用来记录日志。 -n NUM, –iter=NUM设置监测的次数，默认无限。在非交互模式下很有用 -t, –time 加上时间戳，非交互非模式 -q, –quiet 禁止头几行，非交互模式。有三种指定方式 -q 只在第一次监测时显示列名 -qq 永远不显示列名 -qqq 永远不显示I/O汇总。 交互按键： left和right方向键：改变排序 r：反向排序 o：切换至选项–only p：切换至–processes选项 a：切换至–accumulated选项 q：退出 i：改变线程的优先级 $ iotop Total DISK READ : 0.00 B/s | Total DISK WRITE : 7.85 K/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO\u003e COMMAND 15055 be/3 root 0.00 B/s 7.85 K/s 0.00 % 0.00 % systemd-journald 指标含义: SWAPIN, IO\u003e: 表示换入和等待 I/O 的时钟百分比等。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:2","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.3 disktop.stp 作用: disk 值的是从用户角度看的磁盘的读写 原理: 通过跟踪VFS实现 安装: https://github.com/dengliu/systemtap \u003e git clone git clone https://github.com/dengliu/systemtap \u003e cd systemtap \u003e stap -v disktop.stp Tue Apr 21 14:59:27 2020 , Average: 5Kb/sec, Read: 27Kb, Write: 0Kb UID PID PPID CMD DEVICE T BYTES 0 9084 9083 pgrep dm-0 R 17864 0 9081 9080 awk dm-0 R 2888 0 9086 9082 awk dm-0 R 2888 0 9087 801 sleep dm-0 R 1224 0 9081 9080 ksmtuned dm-0 R 788 0 9084 9083 ksmtuned dm-0 R 788 0 9086 9082 ksmtuned dm-0 R 788 0 9087 801 ksmtuned dm-0 R 788 0 1067 1 rs:main Q:Reg dm-0 W 120 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:3","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.4 iosnoop iosnoop [-hQst] [-d device] [-i iotype] [-p PID] [-n name] 原理: 通过块设备接口同时跟踪所有磁盘，并为每个磁盘I/O打印一条输出 作用: 有助于跟踪和延时分析 位置: https://github.com/brendangregg/perf-tools 参数 -d device # device string (eg, “202,1) -i iotype # match type (eg, ‘R’ for all reads) -n name # process name to match on I/O issue -p PID # PID to match on I/O issue -Q # use queue insert as start time -s # include start time of I/O (s) -t # include completion time of I/O (s) -h # this usage message duration # duration seconds, and use buffers 命令选项组合 作用 iosnoop watch block I/O live (unbuffered) iosnoop 1 trace 1 sec (buffered) iosnoop -Q include queueing time in LATms iosnoop -ts include start and end timestamps iosnoop -i '*R*' trace reads iosnoop -p 91 show I/O issued when PID 91 is on-CPU iosnoop -Qp 91 show I/O queued by PID 91, queue time 输出 \u003e git clone https://github.com/brendangregg/perf-tools \u003e cd perf-tools/bin \u003e ll iosnoop lrwxrwxrwx. 1 tao tao 10 4月 21 23:03 iosnoop -\u003e ../iosnoop \u003e sudo ./iosnoop Tracing block I/O. Ctrl-C to end. COMM PID TYPE DEV BLOCK BYTES LATms \u003cidle\u003e 0 WM 8,0 10911200 16384 1.48 \u003cidle\u003e 0 WM 8,0 30932994 512 1.47 \u003cidle\u003e 0 WM 8,0 30933056 16384 1.47 iosnoop 输出: COMM: 进程名 PID TYPE: DEV: BLOCK: 磁盘块地址，可以看出IO是否随机 BYTES: I/O 大小 LATms: ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:4","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.5 blktrace blktrace 是一个 Linux 块设备I/O事件，包括 用来跟踪和缓冲数据的内核组件 供用户态工具使用的控制和报告机制 命令: blktrace: 启用内核驱动跟踪机制获取跟踪裸数据 blkparse: 处理blktrace的数据并产生输出 btrace: 合并调用上述两个程序，下面的程序是等价的 \u003e blktrace -d /dev/sda -o -|blkparse -i - \u003e btrace /dev/sda btrace 使用 btrace [-s] [-t] [-w N] [-n N] [-b N] [-r \u003cdbg mnt\u003e] [-a \u003ctrace\u003e...] \u003cdev\u003e... 选项: -a trace: 设置活动的过滤条件 -a issue: 值跟踪 D活动(发出I/O) -a read: 仅跟踪读 -a write: 仅跟踪写 -a sync: 跟踪同步操作 活动标识 活动标识 作用 A IO was remapped to a different device B IO bounced C IO completion D IO issued to driver F IO front merged with request on queue G Get request I IO inserted onto request queue M IO back merged with request on queue P Plug request Q IO handled by request queue code S Sleep request T Unplug due to timeout U Unplug request X Split \u003e sudo btrace /dev/sda 8,0 0 1 0.000000000 0 C R 82106200 + 32 [0] 8,2 0 2 0.000152172 11194 A R 80007032 + 64 \u003c- (253,0) 75810680 8,0 0 3 0.000152439 11194 A R 82106232 + 64 \u003c- (8,2) 80007032 8,0 0 4 0.000153208 11194 Q R 82106232 + 64 [blkparse] 8,0 0 5 0.000155426 11194 G R 82106232 + 64 [blkparse] 8,0 0 6 0.000155991 11194 P N [blkparse] 8,0 0 7 0.000157235 11194 I R 82106232 + 64 [blkparse] 8,0 0 8 0.000157845 11194 U N [blkparse] 1 8,0 0 9 0.000158495 11194 D R 82106232 + 64 [blkparse] 8,0 0 10 0.000561421 0 C R 82106232 + 64 [0] ^CCPU0 (8,0): Reads Queued: 1, 32KiB Writes Queued: 0, 0KiB Read Dispatches: 1, 32KiB Write Dispatches: 0, 0KiB Reads Requeued: 0 Writes Requeued: 0 Reads Completed: 2, 48KiB Writes Completed: 0, 0KiB Read Merges: 0, 0KiB Write Merges: 0, 0KiB Read depth: 1 Write depth: 0 IO unplugs: 1 Timer unplugs: 0 输出默认情况下有 7 列: 设备主次号 CPU ID 序号 活动时间 进程ID 活动标识符 RWBS 描述: R-读，W-写，D-块丢弃，B-屏蔽操作，S-同步 后面的输出取决于活动，82106232 + 64 [blkparse] 表示一个位于地址 82106232，大小为 64 扇区，来源于 blkparse 进程 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:5","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.6 MegaCli 磁盘控制器(主机总线适配器)由系统外部的硬件和固件组成。操作系统分析工具，甚至是动态追踪都无法直接观察他们。某些特定的磁盘控制器有专门的分析工具，例如 LSI 的MegaClie ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:6","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.6 smartctl 磁盘有控制磁盘操作的逻辑，包括排队、缓存和错误处理。与磁盘控制器类似，操作系统不能直接看到磁盘的内部行为，这些信息通过观察 I/O请求和延时来推断。 许多现代驱动器提供了 SMART(自监控分析和报告分析)数据。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:7","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.7 lsof lsof options 作用: 查看进程打开文件列表，文件包括了普通文件、目录、块设备、动态库、网络套接字等。 参数: -p: 指定进程ID -a：列出打开文件存在的进程； -c\u003c进程名\u003e：列出指定进程所打开的文件； -g：列出GID号进程详情； -d\u003c文件号\u003e：列出占用该文件号的进程； +d\u003c目录\u003e：列出目录下被打开的文件； +D\u003c目录\u003e：递归列出目录下被打开的文件； -n\u003c目录\u003e：列出使用NFS的文件； -i\u003c条件\u003e：列出符合条件的进程。（4、6、协议、:端口、 @ip ） -u：列出UID号进程详情； -h：显示帮助信息； -v：显示版本信息。 $ lsof -p 18940 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME python 18940 root cwd DIR 0,50 4096 1549389 / python 18940 root rtd DIR 0,50 4096 1549389 / … python 18940 root 2u CHR 136,0 0t0 3 /dev/pts/0 python 18940 root 3w REG 8,1 117944320 303 /tmp/logtest.txt 指标含义: FD: 表示文件描述符号 TYPE: 表示文件类型 NAME: 表示文件路径 DEVICE: 主次设备号 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:8","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. I/O 性能测试 在基准测试时，一定要注意根据应用程序 I/O 的特点，来具体评估指标。这就需要你测试出，不同 I/O 大小（一般是 512B 至 1MB 中间的若干值）分别在随机读、顺序读、随机写、顺序写等各种场景下的性能情况。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 hdparm ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:1","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.磁盘调优 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:0","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 操作系统 ionice ionice -c 3 -p 1623 作用: 设置一个进程的 I/O 调度级别和优先级 级别: 0: 无，不指定优先级，内核会挑选一个默认值-尽力 1: 实时，对磁盘的最高级别访问，如果误用会导致其他进程饿死 2: 尽力，默认调度级别，包括优先级 0-7,0 为最高级 3: 空闲，在一段磁盘空闲的期间过后才允许进行 I/O 参数: -c: 指定级别 -p: 指定进程 可调参数 /sys/block/sda/queue/scheduler 作用: 选择I/O调度策略 /sys/block/sdb/queue/read_ahead_kb 作用: 调整 /dev/sdb 磁盘预读的大小 默认大小是 128 KB，单位为 KB /sys/block/sdb/queue/nr_requests 作用: 调整内核磁盘队列的长度 适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。 磁盘故障检测 可以通过 dmesg 查看是否有硬件 I/O 故障的日志。 还可以使用 badblocks、smartctl 等工具，检测磁盘的硬件问题，或用 e2fsck 等来检测文件系统的错误。如果发现问题，你可以使用 fsck 等工具来修复。 ","date":"2020-01-26","objectID":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:1","tags":["Linux 性能调优"],"title":"4.11 磁盘监测命令","uri":"/posts/linux/linux_perf/31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.10 磁盘","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"本节我们来介绍磁盘相关的操作系统原理。磁盘I/O可能会造成严重性能的问题(注意是可能)。在高负载下，磁盘成为瓶颈，CPU 持续空转以等待磁盘磁盘I/O结束。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:0:0","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"1. 磁盘相关的操作原理 我们将从下面几个方面入手来讲解磁盘相关的操作系统原理: 磁盘的基础知识 磁盘I/O栈 最后我们会说一说磁盘检测的相关指标。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:1:0","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"2. 磁盘的基础知识 这一部分内容与磁盘的构造相关，能帮助解释为什么磁盘慢。目前我们使用的磁盘主要有两种类型: 磁性旋转机械盘，也就是我们常说的机械硬盘 基于闪存的 SSD ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:2:0","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"2.1 机器硬盘 机械硬盘(hard disk drive HDD) 由机械手臂，磁头，盘片组成。慢I/O通常由磁头寻道时间,盘片旋转时间造成。 磁盘缓存 这些磁盘共有的一个部件是一小块内存(RAM)用来缓存读取的结果和缓冲要写入的数据。还允许I/O命令在设备上排队，以更高效的方式重新排序。 电梯寻道 电梯算法又名电梯寻道是提高命令队列效率的一种方式。它根据磁盘位置把I/O重新排序，最小化磁头的移动。电梯算法会容易对偏移量远的I/O操作造成饥饿。 ECC 磁盘在每个扇区的结尾存储了一个纠错码，以便在数据读取时进行验证并有可能纠错。如果验证失败，可能发生重读，这可能是异常缓慢I/O的原因。检查操作系统和磁盘上的错误计数器以确认。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:2:1","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"2.2 SSD 固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。 固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还是差了很多。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:2:2","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"3. 磁盘I/O栈 磁盘I/O栈的组件和层次取决于操作系统、版本和采用的软硬件技术。下面延时了一个通用模型: Block Device Interface: 块设备接口 Buffer Cache: 缓冲区高速缓存 Target I/O Driver: 目标I/O驱动 Multpathing I/O Driver: 多路I/O驱动 Host Bus Adaptor Driver: 主机总线适配器 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:3:0","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"3.1 Linux的块层 Linux 中，磁盘实际上是作为一个块设备来管理的。每个块设备都会被赋予两个设备号，分别是主、次设备号。主设备号用在驱动程序中，用来区分设备类型；而次设备号则是用来给多个同类设备编号。 块I/O设备一般可以通过 iostat 监控。Linux 改进了内核组成了块层。通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层，主要有两个作用: 第一个功能跟虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。 第二个功能 I/O调度器: 通用块层会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。 下面是 Linux 块层的示意图: Virtual Block Driver: 虚拟快驱动 Elevator Layer: 电梯层 I/O Scheduler: I/O 调度器 Physical Block Driver: 物理块驱动 电梯层提供了通用功能，例如排序，合并以及聚合请求发送。 I/O调度器使 I/O 能够排队排序或者重新调度以优化发送，具体由调度策略决定，可用的策略如下: 空操作: 不调度 截止时间: 试图强制给延迟设置截止时间 预期: 通过启发式方法预测I/O CFQ: 完全公平调度器 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:3:1","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"3.2 I/O 栈 结合文件系统和今天的内容，我们可以把 Linux 存储系统的 I/O 栈，由上到下分为三个层次: 文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据 通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统和应用程序的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:3:2","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.磁盘检测 下面是磁盘常用的性能测量指标: IOPS 使用率 饱和度 IOPS 很难横向比较，有意义的IOPS需要包含其他细节: 随机I/O还是连续I/O I/O大小 读写比例 基于时间的指标使用率和饱和度可以更简单的进行比较。 在介绍这些指标之前，我们先来看看磁盘性能领域的一些重要概念：测量时间 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:4:0","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.1 测量时间 存储设备的响应时间指的是从I/O请求到结束的时间，由服务和等待时间组成: 等待时间: I/O在队列中等待服务的时间 服务时间: I/O 得到处理的时间 响应时间，服务时间，等待时间取决于测量所处的位置。在上面的磁盘io 栈的示意图中，io 栈的每一层都有可能实现自己的队列，在不同的测量位置可以得到不同的等待时间和服务时间。iostat 展示的磁盘设备接口的服务时间只是一种简化。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:4:1","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.2 使用率 使用率通过某段时间内磁盘运行时间的忙时间的比例计算得出。为了确定高使用率是否会导致应用程序性能问题，需要研究磁盘的反映时间和应用程序是否阻塞在此I/O上。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:4:2","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.3 饱和度 饱和度可以通过操作系统的磁盘等待队列的长度计算得出。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:4:3","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.4 磁盘I/O vs 应用程序I/O 最后犹如文件系统一章所提到的，文件系统性能比磁盘性能更加重要。最快的I/O就是没有I/O，所以要充分利用缓存来降低磁盘I/O的次数。 由于经过了中间的层层组件，磁盘I/O与应用程序I/O在频率和大小上都不匹配。所以需要细致研究磁盘I/O与应用程序阻塞之间的关系。而不能仅仅通过数值的大小去评判。 ","date":"2020-01-25","objectID":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/:4:4","tags":["Linux 性能调优"],"title":"4.10 磁盘","uri":"/posts/linux/linux_perf/30_%E7%A3%81%E7%9B%98/"},{"categories":["Linux"],"content":"4.9 文件系统动态追踪","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"本节我们来介绍文件系统的动态追踪技术 ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:0:0","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1. 使用 Systemtap 进行文件系统分析 Dtrace/Systemtap 能从系统调用、VFS 接口或文件系统内部的角度来查看文件系统行为。这些功能能用在负载特征分析和延时分析上。 ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:0","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.1 操作计数 按照应用程序和类型统计文件系统操作，为负载特征归纳提供有用测量信息。 DTrace # Solaris # 1. 按照应用程序名统计文件系统操作 \u003e dtrace -n 'fsinfo:::{@[execname] = count();}' # 2. 按秒统计 \u003e dtrace -n 'fsinfo:::{@[execname] = count();} tick-1s{printa(@);}' # 3. 按 probename 统计 \u003e dtrace -n 'fsinfo::: /execname == \"splunkd\"/ { @[probename] = count();}' # Linux # 1. fsinfo provider 无法使用，文件系统操作可以通过 syscall 和 fbt provider 观察 \u003e dtrace -n 'fbt::vfs_*:entry { @[execname] = count(); }' \u003e dtrace -n 'fbt::vfs_*:entry /execname == \"sysbench\"/ { @[probename] = count(); }' Systemtap # 1. \u003e stap -ve 'global c; probe kernel.function(\"vfs_*\") { c[execname()] \u003c\u003c\u003c 1} probe end {foreach (k in c+){printf(\"%-36s %d\\n\", k, @count(c[k]))}}' # 2. 每秒统计 \u003e stap -ve 'global c; probe begin, timer.s(1) {printf(\"%-36s %s\\n\", \"execname\", \"count\")} probe kernel.function(\"vfs_*\") { c[execname()] \u003c\u003c\u003c 1} probe timer.s(1) {foreach (k in c+){printf(\"%-36s %d\\n\", k, @count(c[k]))}; delete c}' # 3. 按probename 统计 \u003e stap -ve 'global c; probe kernel.function(\"vfs_*\") { if ( execname() == \"sshd\" ){ c[probefunc()] \u003c\u003c\u003c 1};}' ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:1","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.2 文件打开 DtraceToolkit 工具箱中包含了如下的工具: opensnoop: 显示了进程打开的所有文件，和错误信息 rwsnoop: 跟踪和统计逻辑 I/O，包括 read()和write() 系统调用 rwtop: 跟踪和统计逻辑 I/O，使用 sysinfo proveder 统计吞吐量 DTrace \u003e opensnoop \u003e rwsnoop \u003e rwtop Linux \u003e yum install bcc \u003e rpm -ql bcc-tools \u003e cd /usr/share/bcc/tools \u003e ./opensnoop PID COMM FD ERR PATH 506 systemd-journal 22 0 /proc/2016/cgroup 506 systemd-journal 22 0 /proc/2016/comm 506 systemd-journal 22 0 /proc/2016/cmdline 506 systemd-journal 22 0 /proc/2016/status 506 systemd-journal 22 0 /proc/2016/sessionid ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:2","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.3 系统调用延时 DTrace # 1. 系统调用接口级别测量了文件系统的超时 \u003e dtrace -n 'syscall::read:entry /fds[arg0].fi_fs == \"zfs\"/ {self-\u003estart = timestamp;} syscall::read:return /self-\u003estart/ {@[\"ns\"] = quantize(timestamp - self.start);self-\u003estart = 0}' 说明: 这个方法跟踪单个系统调用 read()，为了捕获所有的系统调用，所有系统调用都要跟踪包括他们的变体 这个方法跟踪了 zfs 文件系统的活动，也可以跟踪其他文件系统包括，非存储类型的文件系统入 sockfs 如果应用程序使用非阻塞I/O或者这是一个后台异步的后台任务，可能并不会应用程序性能产生影响 通过捕获用户态系统调用 I/O 的调用栈可以更准确的反映应用程序性能，比如使用 @[ustack(), ’ns’],不过这是一个耗时操作深度调查 Systemp # 1. 获取 read 系统调用的文件系统 stap -ve ' probe syscall.read { file = @cast(task_current(), \"task_struct\")-\u003e files-\u003efdt-\u003efd[fd] \u0026 ~3; if(!file) next; dentry = @cast(file, \"file\")-\u003ef_path-\u003edentry; inode = @cast(dentry, \"dentry\")-\u003ed_inode; device = kernel_string(@cast(inode, \"inode\")-\u003ei_sb-\u003es_id); filesystem_type = kernel_string(@cast(dentry, \"dentry\")-\u003ed_sb-\u003es_type-\u003ename); printf(\"READ %d: file '%s' of size '%d' on device: %s, with filesystem: %s \\n\", fd, d_name(dentry), @cast(inode, \"inode\")-\u003ei_size, device, filesystem_type); } ' -c 'cat /etc/passwd \u003e /dev/null' # 2. 统计 xfs 文件系统级别 read 的调用延迟 stap -ve 'global s; probe syscall.read.return { file = @cast(task_current(), \"task_struct\")-\u003efiles-\u003efdt-\u003efd[fd] \u0026 ~3; if(!file) next; dentry = @cast(file, \"file\")-\u003ef_path-\u003edentry; filesystem_type = kernel_string(@cast(dentry, \"dentry\")-\u003ed_sb-\u003es_type-\u003ename); if (filesystem_type == \"xfs\") {s \u003c\u003c\u003c gettimeofday_ns() - @entry(gettimeofday_ns());}} probe end{print(@hist_log(s))}' ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:3","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.4 VFS 缓存 DTrace # 1. Solaris 上 VFS 可通过 fop_* 函数跟踪 \u003e dtrace -ln 'fbt::fop_*:entry' # 可以匹配所有的读调用变体 \u003e dtrace -n 'fbt::ftop_read:entry /stringof(arg[0]-\u003ev_op_\u003evnop_name) == \"zfs\"/ {self-\u003estart = timestamp;} fbt::ftop_read:return /self-\u003estart/ {@[\"ns\"] = quantize(timestamp - self.start);self-\u003estart = 0}' # 2. Linux \u003e dtrace -n 'fbt::vfs_read:entry /stringof(((struct file *)arg0)-\u003ef_path.dentry-\u003ed_sb-\u003es_type-\u003ename) == \"ext4\"/' {self-\u003estart = timestamp;} fbt::vfs_read:return /self-\u003estart/ {@[\"ns\"] = quantize(timestamp - self.start);self-\u003estart = 0}' Systemp # 1. 获取 read 系统调用的文件系统 # 2. 统计 xfs 上所有读调用的延迟 \u003e stap -ve 'global s; probe kernel.function(\"vfs_read\").return { file = @cast(task_current(), \"task_struct\")-\u003efiles-\u003efdt-\u003efd[fd] \u0026 ~3; if(!file) next; dentry = @cast(file, \"file\")-\u003ef_path-\u003edentry; filesystem_type = kernel_string(@cast(dentry, \"dentry\")-\u003ed_sb-\u003es_type-\u003ename); if (filesystem_type == \"xfs\") {s \u003c\u003c\u003c gettimeofday_ns() - @entry(gettimeofday_ns());}} probe end{print(@hist_log(s))}' # 3. 列出 VFS 函数入口 \u003e stap -l 'kernel.function(\"vfs_*\")' ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:4","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.5 块设备 I/O调用栈 查看块设备 I/O调用栈和发出磁盘 I/O 的代码路径，是理解文件系统内部工作机制的绝佳方法。 DTrace # 1. # 统计发出块设备 I/O 时内核调用栈的内容及次数 \u003e dtrace 'io:::start { @[stack()] =count();}' Systemp 参考: https://groups.google.com/forum/#!topic/openresty/u-puKWWONMk # 1. 未成功 \u003e stap -ve 'global s; probe ioblock.request { s[backtrace()] \u003c\u003c\u003c 1;} probe end { foreach (k in s- limit 1000) {print(@count(s[k]))};}' ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:5","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.6 跟踪文件系统内部 对于同步读，直接跟踪文件系统的内核函数是可行的，但是对于异步执行的I/O操作，测量读延时 I/O 发起的和结束时间需要一一关联和对比，或者跟踪更高一级调用栈。 DTrace # 1. 列出 zfs 内核函数 \u003e dtrace -ln 'fbt:zfs::entry' # 2. 跟踪 zfs 同步读的读延时 \u003e dtrace -n 'fbt::zfs_read:entry {self-\u003estart = timestamp;} syscall::read:return /self-\u003estart/ {@[\"ns\"] = quantize(timestamp - self.start);self-\u003estart = 0}' Systemp # 1. 未找到 xfs 内核函数 \u003e ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:6","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.7 慢事件跟踪 由于文件系统缓存命中，在文件系统级别跟踪会产生大量的输出。一个解决办法是仅仅打印出慢操作。 DTrace \u003e ./zfsslower.d Systemp \u003e cd /user/share/bcc/tools ll|grep lower -rwxr-xr-x. 1 root root 10096 8月 9 2019 btrfsslower -rwxr-xr-x. 1 root root 7321 1月 12 2019 dbslower -rwxr-xr-x. 1 root root 10431 8月 9 2019 ext4slower -rwxr-xr-x. 1 root root 7712 8月 9 2019 fileslower -rwxr-xr-x. 1 root root 10726 1月 12 2019 funcslower -rwxr-xr-x. 1 root root 3286 1月 12 2019 mysqld_qslower -rwxr-xr-x. 1 root root 9550 8月 9 2019 nfsslower -rwxr-xr-x. 1 root root 7396 8月 9 2019 runqslower -rwxr-xr-x. 1 root root 8397 8月 9 2019 xfsslower \u003e ./xfsslower ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:7","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.8 高级跟踪: DTrace 文件系统常用的高级跟踪脚本: DTrace: https://github.com/brendangregg/DTrace-book-scripts/tree/master/Chap5 Systemp: https://sourceware.org/systemtap/SystemTap_Beginners_Guide/mainsect-disk.html ","date":"2020-01-24","objectID":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:8","tags":["Linux 性能调优"],"title":"4.9 文件系统动态追踪","uri":"/posts/linux/linux_perf/29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4.8 文件系统监测命令","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"本节我们来介绍文件系统相关的监测工具。 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令总览 我们会介绍如下文件系统统计信息的工具 Linux Solaris 作用 说明 vfsstat 文件系统统计信息，包括平均延时 fsstat 文件系统统计信息 kstat 各种文件系统和缓存统计信息 fcachestat 各种缓存命令中率和大小 free 缓存容量统计信息 strace truss 系统调用调试器 slaptop mdb:kmastat 内核 slab 分配器统计信息 /proc/memeinfo mdb:memstat 内核内存使用情况 sar sar 内存，swap使用统计信息 通用命令，位于独立的一节中 除此之外，还包括以下内容: 文件系统基准测试 文件系统调优 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 文件系统统计命令 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 LatencyTop LatencyTop 是一个报告延时根源的工具。可以针对整个系统，也可以针对单个进程。 启用 LatencyTop 需要两个内核选项的支持: CONFIG_LATENCYTOP CONFIG_HAVE_LATENCYTOP_SUPPORT # 1. LatencyTop 启用 \u003e yum install latencytop \u003e rpm -ql latencytop # 2. LatencyTop 查看 \u003e cat /proc/latency_stats ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:1","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 文件系统测试 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 dd 可以执行文件系统连续读写负载的特定性能测试 \u003e dd if=/dev/zero of=file1 bs=1024k count=1k \u003e dd if=file1 of=/dev/null bs=1024 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:1","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.2 Bonnie 是一个在单文件上一单线程测试集中负载的简单 C程序 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:2","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.3 fio 有很多高级功能的可定制文件系统基准测试工具: 非标准随机分布，可以更准确的模拟真实的访问模式 延时百分位数报告，包括 99,99.5,99.9,99.99 使用 fio（Flexible I/O Tester）正是最常用的文件系统和磁盘 I/O 性能基准测试工具，并且提供了大量定制化的选项。下面是对随机读、随机写、顺序读以及顺序写的基准测试。 # 随机读 fio -name=randread -direct=1 -iodepth=64 -rw=randread -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb # 随机写 fio -name=randwrite -direct=1 -iodepth=64 -rw=randwrite -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb # 顺序读 fio -name=read -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb # 顺序写 fio -name=write -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb # mysql IOPS innodb_io_capacity 参数确定 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 示例命令中包含的参数的含义如下: direct，表示是否跳过系统缓存。上面示例中，我设置的 1 ，就表示跳过系统缓存。 iodepth，表示使用异步 I/O（asynchronous I/O，简称 AIO）时，同时发出的 I/O 请求上限。在上面的示例中，我设置的是 64。 rw，表示 I/O 模式。我的示例中， read/write 分别表示顺序读 / 写，而 randread/randwrite 则分别表示随机读 / 写。 ioengine，表示 I/O 引擎，它支持同步（sync）、异步（libaio）、内存映射（mmap）、网络（net）等各种 I/O 引擎。上面示例中，我设置的 libaio 表示使用异步 I/O。bs，表示 I/O 的大小。示例中，我设置成了 4K（这也是默认值）。 filename，表示文件路径，当然，它可以是磁盘路径（测试磁盘性能），也可以是文件路径（测试文件系统性能）。示例中，我把它设置成了磁盘 /dev/sdb。不过注意，用磁盘路径测试写，会破坏这个磁盘中的文件系统，所以在使用前，你一定要事先做好数据备份。 I/O 重放 fio 支持 I/O 的重放。借助前面提到过的 blktrace，再配合上 fio，就可以实现对应用程序 I/O 模式的基准测试。比如像下面这样: # 使用blktrace跟踪磁盘I/O，注意指定应用程序正在操作的磁盘 $ blktrace /dev/sdb # 查看blktrace记录的结果 # ls sdb.blktrace.0 sdb.blktrace.1 # 将结果转化为二进制文件 $ blkparse sdb -d sdb.bin # 使用fio重放日志 $ fio --name=replay --filename=/dev/sdb --direct=1 --read_iolog=sdb.bin 输出 read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64 fio-3.1 Starting 1 process Jobs: 1 (f=1): [R(1)][100.0%][r=16.7MiB/s,w=0KiB/s][r=4280,w=0 IOPS][eta 00m:00s] read: (groupid=0, jobs=1): err= 0: pid=17966: Sun Dec 30 08:31:48 2018 read: IOPS=4257, BW=16.6MiB/s (17.4MB/s)(1024MiB/61568msec) slat (usec): min=2, max=2566, avg= 4.29, stdev=21.76 clat (usec): min=228, max=407360, avg=15024.30, stdev=20524.39 lat (usec): min=243, max=407363, avg=15029.12, stdev=20524.26 clat percentiles (usec): | 1.00th=[ 498], 5.00th=[ 1020], 10.00th=[ 1319], 20.00th=[ 1713], | 30.00th=[ 1991], 40.00th=[ 2212], 50.00th=[ 2540], 60.00th=[ 2933], | 70.00th=[ 5407], 80.00th=[ 44303], 90.00th=[ 45351], 95.00th=[ 45876], | 99.00th=[ 46924], 99.50th=[ 46924], 99.90th=[ 48497], 99.95th=[ 49021], | 99.99th=[404751] bw ( KiB/s): min= 8208, max=18832, per=99.85%, avg=17005.35, stdev=998.94, samples=123 iops : min= 2052, max= 4708, avg=4251.30, stdev=249.74, samples=123 lat (usec) : 250=0.01%, 500=1.03%, 750=1.69%, 1000=2.07% lat (msec) : 2=25.64%, 4=37.58%, 10=2.08%, 20=0.02%, 50=29.86% lat (msec) : 100=0.01%, 500=0.02% cpu : usr=1.02%, sys=2.97%, ctx=33312, majf=0, minf=75 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, \u003e=64=100.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, \u003e=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, \u003e=64=0.0% issued rwt: total=262144,0,0, short=0,0,0, dropped=0,0,0 latency : target=0, window=0, percentile=100.00%, depth=64 Run status group 0 (all jobs): READ: bw=16.6MiB/s (17.4MB/s), 16.6MiB/s-16.6MiB/s (17.4MB/s-17.4MB/s), io=1024MiB (1074MB), run=61568-61568msec Disk stats (read/write): sdb: ios=261897/0, merge=0/0, ticks=3912108/0, in_queue=3474336, util=90.09% 这个报告中，需要我们重点关注的是， slat、clat、lat ，以及 bw 和 iops: slat ，是指从 I/O 提交到实际执行 I/O 的时长（Submission latency）； clat ，是指从 I/O 提交到 I/O 完成的时长（Completion latency） lat ，指的是从 fio 创建 I/O 到 I/O 完成的总时长。 bw ，它代表吞吐量 iops ，其实就是每秒 I/O 的次数 对同步 I/O 来说，由于 I/O 提交和 I/O 完成是一个动作，所以 slat 实际上就是 I/O 完成的时间，而 clat 是 0。而从示例可以看到，使用异步 I/O（libaio）时，lat 近似等于 slat + clat 之和。 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:3","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.4 SysBench ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:4","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.5 丢弃缓存 Linux 提供了丢弃缓存的方法，可用于缓存开始执行的基准测试 # 丢弃页缓存 \u003e ehco 1 \u003e /proc/sys/vm/drop_cache # 丢弃 dentries 和 inodes 缓存 \u003e ehco 2 \u003e /proc/sys/vm/drop_cache # 丢弃所有缓存 \u003e ehco 3 \u003e /proc/sys/vm/drop_cache ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:5","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. 调优 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:0","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 应用程序调优 应用程序可以给内核提供信息，来提高缓存和预期的效率，包括: posix_fadvise() madvise() posix_fasvise() int posix_fasvise(int fd, off_t offset, off_t len, int advice) 作用: 这个库函数调用操作文件的一个区域 advice: 建议标志位: POSIX_FAD_SEQUENTIAL: 指定的数据范围会被连续访问 POSIX_FAD_RANDOM: 指定的数据范围会被随机访问 POSIX_FAD_NOREUSE: 数据不会被重用 POSIX_FAD_WILLNEED: 数据会在不远的将来重用 POSIX_FAD_DONTNEED: 数据不会在不远的将来重用 madvise() int madvise(void *addr, size_t length, int advice 作用: 库函数调用对一块内存映射进行操作 advice: 建议标志位 MADV_RANDOM: 偏移量将以随机顺序访问 MADV_SEQUENTIAL: 偏移量将以连续顺序访问 MADV_WILLNEED: 数据还会再用，请缓存 MADV_DONTNEED: 数据不会再用，无缓存 ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:1","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.2 文件系统调优 ext 文件系统 # 1. 查看文件系统配置 \u003e tunefs -l dev_name \u003e mount # 2. 可以使用选项 noatime 禁用文件访问时间戳更新 # 3. tunefs 提升性能的关键选项 -- 使用哈希B数提高大目录的查找速度 \u003e tune2fs -O dir_index /dev/hdX # 4. 重建文件系统目录的索引 \u003e e2fsck -D -f /dev/hdX ","date":"2020-01-23","objectID":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:2","tags":["Linux 性能调优"],"title":"4.8 文件系统监测命令","uri":"/posts/linux/linux_perf/28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.7 文件系统","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"本节我们来介绍文件系统相关的操作系统原理。文件系统性能比磁盘性能更加重要。文件系统通过缓存，缓冲以及异步I/O等手段来缓和了磁盘延时对应用程序的影响。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:0:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. 文件系统相关的操作原理 我们从下面几个方面入手来讲解文件系统相关的操作系统原理: 文件系统I/O栈 文件系统缓存 I/O的多种方式 最后我们会说一说文件系统检测的相关指标。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2. 文件系统 I/O 栈 下面是文件系统I/O栈的一般模型，具体的模块和层次依赖于使用的操作系统。 Volume Manager: 卷管理器 Block Device Interface: 块设备接口 Host Bus Adaptor Driver: 主机总线适配器驱动 Disk Devices: 磁盘设备 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.1 VFS 虚拟文件系统 VFS 是一个文件系统类型作抽象的内核界面。VFS 接口让内核添加新的文件系统时更加简单。 VFS 接口可以作为测量文件系统性能的通用平台，能够利用操作系统提供的统计信息，静态及动态追踪技术。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:2:1","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3. 文件系统缓存 UNIX 原本只有缓冲区高速缓存，如今 Linux 和 Solaris 都有多种缓存。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.1 Solaris 的文件系统缓存 下图是基于 Solaris 系统的文件系统缓存的概览。 其中有三种缓存是文件系统里通用的，其他的都是每个文件系统特有的，这三种缓存包括: Old Buffer Cache: 旧式的缓冲区高速缓存 page Cache: 页缓存 DNLC: 目录名查找缓存 旧式的缓冲区高速缓存(buffer cache) 最初 UNIX 在块设备接口使用缓冲区高速缓存来缓存磁盘设备块。页缓存的加入带来了优化问题，比如: 如何平衡二者之间的负载 双重缓存和同步开销 这些问题后来基本被 SunOS 中的统一缓冲区高速缓存解决了，方法是使用页缓存来存储缓冲区高速缓存 在 Solaris 旧式的缓冲区高速缓存依然存在，不过仅用于 UFS inode 和文件系统的元数据，这些数据通过它们的块号寻址，与文件无关。 页缓存 页缓存就是我们在内存一章所说的文件系统页缓存。它缓存了虚拟内存页面映射过的文件系统页面。 DNLC DNLC 目录名查找缓存记录了目录项到 vnode 的映射关系。用于加速文件的查找。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:1","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.2 Linux 的文件系统缓存 与 Solaris 类似，Linux 也经历旧式的缓冲区高速缓存到统一缓冲区高速缓存的过程。方法也是类似的，即缓冲区高速缓存被存在了页缓存中。 缓冲区高速缓存的功能仍在，用于缓存文件系统的元数据，提升了块设备I/O的性能。 写回缓存 写回缓存的原理是当数据写入主存(页缓存)后，就认为写入已经结束并返回，之后再异步的把数据刷入磁盘。文件系统写入\"脏页\"的过程称为刷新，就是我们经常说的刷脏页。 刷新的机制牺牲了可靠性，因为基于DRAM的主存是不可靠的，主机掉电写入的数据就会丢失。应用程序可能认为数据写入完成，但是实际上未被写入，甚至不完整写入。如果文件系统的元数据遭到破坏，可能无法加载，对业务造成严重的影响。 为了平衡系统对于速度和可靠性的需求，文件系统默认采用写回缓存，但同时提供了同步写的选项绕过这个机制。 页缓存管理 文件系统使用的内存脏页由内核线程写回到磁盘，现在这个写回线程为 flusher thread，线程名为 flush，每个设备分配一个线程。这样能平衡每个设备的负载，提高吞吐量。 写脏页的时机包括: 过了一段时间(30s) 调用了 sync()，fsync(), msync() 等系统调用 过多的脏页(dirty_ratio) 页缓存没有可用的页面 如果系统内存不足，另一个内核线程，页面换出守护进程kswapd() 会定位并安排把脏页面写入到磁盘上，腾出可重用的内存页面。 目录项缓存和 inode 缓存 目录项缓存记录了从目录项到 VFS inode 的映射关系。inode 缓存缓存的对象是 VFS inode，每一个都描述了文件系统一个对象的属性。 内核使用 Slab 机制，管理目录项和索引节点的缓存。通过 /proc/slabinfo 可以查看到各种 inode与目录项缓存的大小: $ cat /proc/slabinfo | grep -E '^#|dentry|inode' # name \u003cactive_objs\u003e \u003cnum_objs\u003e \u003cobjsize\u003e \u003cobjperslab\u003e \u003cpagesperslab\u003e : tunables \u003climit\u003e \u003cbatchcount\u003e \u003csharedfactor\u003e : slabdata \u003cactive_slabs\u003e \u003cnum_slabs\u003e \u003csharedavail\u003e xfs_inode 0 0 960 17 4 : tunables 0 0 0 : slabdata 0 0 0 ... ext4_inode_cache 32104 34590 1088 15 4 : tunables 0 0 0 : slabdata 2306 2306 0hugetlbfs_inode_cache 13 13 624 13 2 : tunables 0 0 0 : slabdata 1 1 0 sock_inode_cache 1190 1242 704 23 4 : tunables 0 0 0 : slabdata 54 54 0 shmem_inode_cache 1622 2139 712 23 4 : tunables 0 0 0 : slabdata 93 93 0 proc_inode_cache 3560 4080 680 12 2 : tunables 0 0 0 : slabdata 340 340 0 inode_cache 25172 25818 608 13 2 : tunables 0 0 0 : slabdata 1986 1986 0 dentry 76050 121296 192 21 1 : tunables 0 0 0 : slabdata 5776 5776 0 指标含义: inode_cache: VFS 索引节点缓存 dentry 行表示目录项缓存 其余的则是各种文件系统的索引节点缓存。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:2","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.3 buffer 和 cache 目前为止我们在两个地方提到了 buffer，cache: 第一地方是页缓存，我们说页缓存统一了缓冲区高速缓存(buffer cache)。 第二地方是内存一节我们提到 /proc/meminfo 文件记录了各种内存指标的统计信息，其中包括 Buffers 和 Cached cat /proc/meminfo MemTotal: 2895444 kB MemFree: 2498868 kB MemAvailable: 2535384 kB Buffers: 3108 kB Cached: 165872 kB ..... 那么问题是buffer, cache, 页缓存与Buffers, Cached 之间到底有什么关系。 man proc 可以看到 /proc/meminfo 文件内各个字段的准确含义: Buffers: 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。 通过 Buffer 内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等 Cached: 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据 以前看到的文章说 Buffer 是对将要写入磁盘数据的缓存，Cache 是对从文件读取数据的缓存。但事实上: Buffers 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。 Cached 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存” 简单来说， Buffers 是对磁盘数据的缓存，而 Cached 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。 页缓存统一了缓冲区高速缓存(buffer cache) 但是并没有改变它的作用: 缓冲区高速缓存(buffer cache)用来缓存磁盘设备块的写和读， 被用作缓冲区高速缓存(buffer cache) 的页缓存保存的是磁盘设备块 对磁盘的直接读写，数据以磁盘设备块，保存在用作缓冲区高速缓存(buffer cache) 的页缓存中 对文件系统的读写，数据以文件内容，保存在页缓存中 文件内容和磁盘设备块不会同时保存，因此才避免了双重缓存和同步开销 Buffers 统计的是用作缓冲区高速缓存(buffer cache) 的页缓存大小 Cached 统计的是文件系统的页缓存大小 最后需要说明的是，free，top，vmstat，显示的 buffer/cache 依计算规则不同而有所不同，但是数据都来自/proc/meminfo 文件。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:3:3","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4. I/O 的多种方式 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.1 顺序与随机I/O 按照I/O的文件偏移量，I/O分为: 顺序 I/O: 顺序I/O里每个 I/O 都开始于上一个 I/O 结束的地址 随机 I/O: 随机 I/O则找不出I/O之间的关系 由于存储设备的性能特性，顺序I/O的速度要远远高于随机I/O。文件系统可以测量逻辑I/O的访问模式，从中识别出顺序I/O，然后通过预取或者预读来提高性能。 预取 预取指当文件系统检测出当前为顺序读负载时，在应用程序请求前向磁盘发出读指令，以填充文件系统缓存。如果应用程序真的发出顺序读请求，就会命中缓存。 预期一旦命中读性能将会有显著提升，但是如果预测不准，文件系统会发起应用程序不需要的I/O，不仅污染了缓存，也消耗了磁盘和I/O传输的资源。 预取一般被认为是预读。Linux 的 readahead(2) 系统调用允许应用程序显示的预热文件系统缓存，此时二者就不同了。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:1","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.2 同步写和非阻塞I/O 在前面的文件系统缓存，我们提到了文件系统的写回缓存和 buffer 机制，为了控制文件写入过程，操作系统提供了同步写。同步用于指绕过写回缓存机制，写操作必须等待至所有的数据以及必要的文件系统元数据完整的写入到存储设备中。写操作支持如下标识: O_DSYNC: 表示，写操作必须要等文件数据写入磁盘后，才能返回； O_SYNC: 则是在 O_DSYNC 基础上，要求文件元数据也要写入磁盘后，才能返回。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:2","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.3 裸I/O和直接I/O 裸I/O: 如上图所示，绕过整个文件系统，直接发送磁盘地址 数据库会使用裸I/O，因为它们能比文件系统更好地缓存自己的数据 直接I/O: 绕过缓存使用文件系统 可用于备份文件系统，放置污染文件系统缓存 裸I/O和直接I/O还可以用于那些在进程堆里自建缓存的应用程序，避免双重缓存的问题。kafka 应该就是舍弃了堆缓存，直接使用了操作系统的页缓存。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:3","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.4 内存映射文件 内存映射文件可以把文件映射到进程地址空间，并直接存取内存地址的方法来提高文件系统I/O性能。这样可以避免调用 read() 和 write() 存取文件数据时产生的系统调用和上下文切换开下。 如果内核支持直接复制文件数据缓冲到进程进程地址空间，那么还能防止数据被复制两次。(It can also avoid double copying of data, if the kernel supports direct copying of the file data buffer to the process address space) (数据为什么会复制两次: 意思是如果 mmap 映射的文件正在被另一进程写，它们是无法共享相同的页缓存的？) 内存映射文件通过系统调用 mmap() 创建，通过 munmap() 销毁，映射可以通过 madvise() 调整。 如果系统问题是由于磁盘设备高I/O延时所至，用 mmap() 消除小小的系统调用是无济于事的。 在多处理器上使用内存映射文件的缺点在于同步每个 CPU MMU 的开销。尤其是跨 CPU 的映射删除调用(TLB 击落)。延时 TLB 更新可能把影响最小化，这取决于内核和映射项。(A disadvantage of using mappings on multiprocessor systems can be the overhead to keep each CPU MMU in sync, specifically the CPU cross calls to remove mappings (TLB shootdowns). Depending on the kernel and mapping, these may be minimized by delaying TLB updates (lazy shootdowns) [Vahalia 96]) ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:4","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.5 逻辑I/O 与物理I/O 逻辑I/O 指向文件系统发起的I/O 物理I/O: 磁盘I/O 与应用程序I/O相比，磁盘I/O有时显得无关、间接、放大或者缩小。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:4:5","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"6. 文件系统监测指标 与 CPU 相关的专业术语或者指标包括: 文件系统延时 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:5:0","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"6.1 文件系统延时 文件系统延时指的是一个文件系统逻辑从开始到结束的时间，它包括消耗在文件系统，内核磁盘I/O子系统以及等待磁盘设备(物理I/O)的时间。 文件系统延时是否会影响应用程序，取决于应用程序的 I/O 方式，同步I/O会有直接影响，非阻塞I/O或异步I/O则不会。文件系统一直以来未开放查看文件系统延时的接口。相反提供了磁盘设备级别的指标信息。但是多数情况下这些指标跟应用程序并无直接关系。原因同样是实际发生的物理I/O并不与应用程序的执行同步。 ","date":"2020-01-22","objectID":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:5:1","tags":["Linux 性能调优"],"title":"4.7 文件系统","uri":"/posts/linux/linux_perf/27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"4.6 内存动态追踪","date":"2020-01-21","objectID":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/","tags":["Linux 性能调优"],"title":"4.6 内存动态追踪","uri":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"本节我们来介绍内存动态追踪技术 ","date":"2020-01-21","objectID":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:0:0","tags":["Linux 性能调优"],"title":"4.6 内存动态追踪","uri":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1. Systemtap 进行 内存 分析 Systemtap 可以用来剖析 跟踪用户和内核的内存分配 主次缺页异常 页面换出守护进程的运行 这些功能支持负载特征分析、向下挖掘分析。 ","date":"2020-01-21","objectID":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:0","tags":["Linux 性能调优"],"title":"4.6 内存动态追踪","uri":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.1 分配跟踪 用户级别的分配跟踪使用 pid provider，内核的分配跟踪使用 fbt provider Dtrace # 1. 按进程汇报用户级 malloc 请求的长度 # arg0 参数记录了 malloc 请求的字节数 dtrace -n 'pid$target::malloc:entry { @[\"request\"] = quantize(arg0); }' -p PID dtrace -n 'pid$target::malloc:entry { @[ustack()] = quantize(arg0); }' -p PID # 2. 计算libumem函数调用 # 列出libumem分配器的入口探针 dtrace -ln 'pid$target:libumem::entry' -p PID dtrace -n 'pid$target:libumem::entry { @[probefunc] = count(); }' -p PID # 3. 按堆增长(通过 brk())计算用户栈 dtrace -n 'syscall::brk:entry { @[execname, ustack()] = count(); }' # 4. 按照缓存名称和栈跟踪内核 slab 分配器 dtrace -n 'fbt::kmem_cache_alloc:entry' { @[stringof(arg[0]-\u003ecache_name), stack()] = count(); } Systemtap # 1. 汇报用户级 malloc 请求的长度 stap -ve 'global s; probe vm.kmalloc { s[execname(),caller_function] \u003c\u003c\u003c bytes_req} probe end { foreach([i,j] in s){printf(\"%s %s: %d\\n\", i, j, @count(s[i,j]))}}' # 3. stap -ve 'global s; probe vm.brk { s[ubacktrace()] \u003c\u003c\u003c 1} probe end { foreach(i in s- limit 10) {print_ustack(i); printf(\"%d\\n\", @count(s[i]))}}' # 4. stap -ve 'global s; probe vm.kmem_cache_alloc { s[caller_function] \u003c\u003c\u003c 1; } probe end { foreach(i in s- limit 10) {printf(\"%s: %d\\n\", i, @count(s[i]))}}' ","date":"2020-01-21","objectID":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:1","tags":["Linux 性能调优"],"title":"4.6 内存动态追踪","uri":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.2 缺页跟踪 跟踪缺页异常能更深入解释系统如何分配内存，可以利用 fbt provider，或者在可用的情况下使用稳定的 vminfo provider Dtrace # 1.跟踪 beam.smp 进程的缺页异常 # as_fault 次缺页异常，maj_fault 主缺页异常 dtrace -n 'vminfo:::as_fault /execname == 'beam.smp' / { @[ustack(4)] = count();}' # 2. 匿名页面换入探测, 跟踪整个系统，按频率统计引起匿名页面换入进程ID和进程名 dtrace -n 'vminfo:::anonpgin { @[pid, execname] = count();}' Systemtap # 1. 跟踪系统的主缺页异常 stap -ve 'global s; probe vm.pagefault.return { if (fault_type == VM_FAULT_MAJOR){s[execname()] \u003c\u003c\u003c 1}} probe end { foreach(i in s- limit 10){printf(\"%s: %d\\n\", i, @count(s[i]))}}' # 2. 跟踪整个系统，按频率统计引起匿名页面 stap -ve 'global s; probe vm.pagefault.return { if (fault_type == VM_FAULT_SIGBUS){s[execname()] \u003c\u003c\u003c 1}} probe end { foreach(i in s- limit 10){printf(\"%s: %d\\n\", i, @count(s[i]))}}' ","date":"2020-01-21","objectID":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:2","tags":["Linux 性能调优"],"title":"4.6 内存动态追踪","uri":"/posts/linux/linux_perf/26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4.5 内存监测工具","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"本节我们来介绍内存相关的监测工具。 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令总览 下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了内存相关的性能检测工具: 从内存的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握内存分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍如下内存专用的分析工具的使用 Linux Solaris 作用 说明 vmstat vmstat 虚拟和物理内存统计信息 slabtop ::kmastat 内核块分配统计信息 pmap pmap 进程地址空间统计信息 pcstat pcstat 查看文件在内存中的缓存大小以及缓存比例 cachetop cachetop 实时查看间隔时间内每个进程的缓存命中情况 bcc工具包中 cachestat cachestat 查看整个操作系统缓存的读写命中情况 bcc工具包中 memleak memleak 内存泄漏跟踪 bcc工具包中 ps ps 进程状态 通用命令，位于独立的一节中 top prstat 监控进程内存使用 通用命令，位于独立的一节中 sar sar 内存，swap使用统计信息 通用命令，位于独立的一节中 Systemtap Dtrace 动态追踪 通用命令，位于独立的一节中 除此之外，还包括以下内容: 内存调优 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 内存统计命令 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 vmstat \u003e vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 1077816 2116 620312 0 0 65 43 34 53 0 0 99 0 0 # 说明: # 除了 r 列外，第一行是系统启动以来的总结信息 \u003e vmstat -a procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free inact active si so bi bo in cs us sy id wa st 2 0 0 342188 472012 815924 0 0 68 84 160 72 9 1 90 0 0 \u003e vmstat -s 1882152 K total memory 250252 K used memory 815892 K active memory 472012 K inactive memory 341924 K free memory 172 K buffer memory 1289804 K swap cache 2097148 K total swap 0 K used swap 2097148 K free swap 99051 non-nice user cpu ticks 0 nice user cpu ticks 12143 system cpu ticks 998690 idle cpu ticks 360 IO-wait cpu ticks 0 IRQ cpu ticks 358 softirq cpu ticks 0 stolen cpu ticks 758858 pages paged in 934798 pages paged out 0 pages swapped in 0 pages swapped out 1777012 interrupts 803881 CPU context switches 1586602557 boot time 31172 forks vmstat [t [n]] 作用: 虚拟内存统计命令 参数: -t：采样间隔 -n：采样次数，可选，默认值是1 -S: -Sm 以MB 为单位显示结果 -a: 输出非活动和活动页缓存的明细 -s: 以列表显示内存统计信息 输出: r: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 cpu: 系统全局范围内的平均负载 第一行统计的系统启动以来的平均负载 – 新版本可能不会显示 其余行统计的是时间间隔周期内的平均负载 memory: swpd: 交换出的内存量 free: 空闲可用内存 buff: 用于缓冲缓存的内存 cache: 用于页缓存的内存 swap: si: 换入的内存 so: 换出的内存 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:1","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.2 slabtop \u003e sudo slabtop -sc Active / Total Objects (% used) : 1079865 / 1085229 (99.5%) # slab 管理的对象数量 Active / Total Slabs (% used) : 27647 / 27647 (100.0%) # Slab 数量 Active / Total Caches (% used) : 69 / 97 (71.1%) # 缓存的 slab 数量 Active / Total Size (% used) : 151423.96K / 153971.68K (98.3%) # slab 管理的内存大小 Minimum / Average / Maximum Object : 0.01K / 0.14K / 8.00K OBJS ACTIVE USE OBJ SIZE SLABS OBJ/SLAB CACHE SIZE NAME 50440 50440 100% 0.94K 6305 8 50440K xfs_inode 81879 81087 99% 0.19K 3899 21 15596K dentry 15392 15266 99% 1.00K 1924 8 15392K kmalloc-1024 139737 139737 100% 0.10K 3583 39 14332K buffer_head 16419 16419 100% 0.58K 1263 13 10104K inode_cache 17262 17262 100% 0.57K 1233 14 9864K radix_tree_node slabtop: 作用: 内核内存信息统计，等同于 vmstat -m 来源: slab 统计信息来自 /proc/slabinfo 参数 -d n：每n秒更新一次显示的信息，默认是每3秒； -s S：指定排序标准进行排序； -o：显示一次后退出 -V：显示版本 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:2","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.3 pmap \u003e sudo pmap -x 792|head 792: /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopid Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 4 0 r-x-- python2.7 0000000000600000 4 4 4 r---- python2.7 0000000000601000 4 4 4 rw--- python2.7 00000000017b4000 8800 8684 8684 rw--- [ anon ] .... \u003e sudo pmap -d 792 |head 792: /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopid Address Kbytes Mode Offset Device Mapping 0000000000400000 4 r-x-- 0000000000000000 0fd:00000 python2.7 0000000000600000 4 r---- 0000000000000000 0fd:00000 python2.7 0000000000601000 4 rw--- 0000000000001000 0fd:00000 python2.7 00000000017b4000 8800 rw--- 0000000000000000 000:00000 [ anon ] 00007fa0ac000000 132 rw--- 0000000000000000 000:00000 [ anon ] ..... mapped: 359028K writeable/private: 30856K shared: 36K pmap PID 作用: 列出进程的内存映射，显示它们的大小，权限和映射对象 参数: -x：显示扩展格式； -d：显示设备格式； -q：不显示头尾行； -V：显示指定版本 输出: pid -X Address: 映射的起始地址 Kbytes: 虚拟内存大小 RSS: 主存大小 Dirty: 脏页大小 Mode: 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write) Mapping: 映像的文件,[anon]为已分配内存 [stack]为程序堆栈 pid -d Offset: 文件偏移 Device: 设备名 mapped: 进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz writeable/private: 进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小 shared: 表示进程和其他进程共享的内存大小 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:3","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.4 pcstat pcstat 是一个基于 Go 语言开发的工具，所以安装它之前，首先需要安装 Go 语言。由于不可描述的原因，go 包的安装可能会遇到问题，建议像下面这样设置一下代理后在安装: # go 安装 cd /usr/local wget https://dl.google.com/go/go1.14.4.linux-amd64.tar.gz tar -C /usr/local -xzf go1.14.4.linux-amd64.tar.gz echo 'export PATH=$PATH:/usr/local/go/bin' \u003e /etc/profile.d/go.sh # 设置代理 https://goproxy.io/zh/ go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.io,direct # 安装 pcstat go get golang.org/x/sys/unix go get github.com/tobert/pcstat/pcstat pcstat 作用: 查看文件在内存中的缓存大小以及缓存比例 参数: $ pcstat /bin/ls +---------+----------------+------------+-----------+---------+ | Name | Size (bytes) | Pages | Cached | Percent | |---------+----------------+------------+-----------+---------| | /bin/ls | 133792 | 33 | 0 | 000.000 | +---------+----------------+------------+-----------+---------+ 指标含义: Cached: /bin/ls 在缓存中的大小 Percent: 缓存的百分比 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:4","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.5 smem ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:5","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.6 其他命令 命令 作用 dmesg 检查 OOM valgrind 包含一个 memcheck 性能分析套件，可用于发现泄漏， 会有严重的系统开销 swapon 添加和观察swap分区 iostat 如果 swap 是物理磁盘或块，可用此命令观测系统是否在换页 /proc/zoneinfo 内存区域 NUMA 节点的统计信息 NUMA 非均匀访存模型 /proc/buddyinfo 内核页面伙伴分配器统计信息 伙伴分配器:Linux 的页面分配器 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:2:6","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 内存调优 最重要的内存调优是保证应用程序保留在主存中，并且避免换页和交换经常发生。 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 可调参数 Documention/sysctl/vm.txt 的内核源码文档介绍了多种内存可调参数。常用示例如下 参数 默认值 作用 vm.dirty_background_ratio 10 触发pdflush后台回写的脏页百分比 vm.dirty_ratio 20 触发一个写入进程开始回写脏页比例 vm.dirty_expire_centisecs 3000 使用pdflush的脏存储器最小时间 vm.dirty_writeback_centisecs 5000 pdflush 活跃时间间隔，0为停用 vm.min_free_kbytes dynamic 设置期望的空闲内存大小，dynamic为系统自动设置 vm.overcommit_memory 0 0: 利用探索算法允许合理的过度使用 1: 一致过度使用 3: 不允许过度使用 vm.swappiness 60 相对于页面高速缓存回收更倾向于用交换释放内存的程度 高数值更倾向于交换应用程序而保留页缓存 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:3:1","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.2 配置大页面 更大的页面能通过提高 TLB 缓存命令率，来提升内存 IO 性能。现在处理器支持多个页面大小。设置大页面(巨页面)参考文档hugetlbpage.txt。关于大页面的使用详见文档 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:3:2","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.3 分配器 应用程序的用户级分配器可以在编译阶段选择，也可以在执行时用 LD_PRELOAD 环境变量设置。 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:3:3","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.4 资源控制 主存限制和虚拟内存限制，可通过 ulimit 实现。Linux cgroup 内存子系统可提供多种附加控制: memory.memsw.limit_in_bytes: 允许的最大内存和交换空间 memory.limit_in_bytes: 允许的最大用户内存，包括文件缓存 memory.swappiness: 类似 vm.swappiness，作用于 cgroups memory.oom_control: 设置为 0，允许 OOM 应用于此 cgroup，1 不允许 ","date":"2020-01-20","objectID":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/:3:4","tags":["Linux 性能调优"],"title":"4.5 内存监测工具","uri":"/posts/linux/linux_perf/25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.4 内存","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"本节我们来介绍内存相关的操作系统原理。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:0:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"1. 内存相关的操作原理 我们从下面几个方面入手来讲解内存相关的操作系统原理: 虚拟内存和页: 内存架构 内存管理 进程地址空间 最后我们会说一说内存检测的相关指标。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:1:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"2. 虚拟内存和换页 虚拟内存是一个抽象概念，它向每个进程和内核提供巨大的、线性的并且私有的地址空间。它简化了软件开发，把物理内存的分配交给操作系统管理。 从上面的图可以看到进程的地址空间由虚拟内存子系统隐射到主内存和物理交换设备。当内存不够用时，内核需要按需在它们之间移动内存页，称为换页。 换页分为两种类型: 为交换共享文件系统的页缓存而产生的文件系统换页 虚拟内存的匿名换页 文件系统换页 文件系统换页由读写位于内存中的映射文件页引发。映射文件产生自: 使用文件内存映射 mmap 的应用程序 使用了页缓存的文件系统 文件系统页可能因为在主存修改过(“脏的”)在换出时需要写回磁盘。如果没有修改过(干净的)因为磁盘已有副本，换页仅仅需要释放内存即可。 匿名换页 匿名换页涉及进程私有数据: 堆和栈，要求数据保存至交换设备，因为这些数据磁盘没有副本。匿名页换入会给应用程序带来同步延时，因为必然发生读磁盘I/O，换出可能不会直接应用程序性能，因为换出是内核异步执行的。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:2:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"2.1 按需换页 按需换页将CPU创建和映射内存的开销延时到实际访问或需要，而不是初次分配内存时。访问一个未映射的内存页将产生一个缺页异常。 虚拟内存页存在以下几种状态: 未分配 已分配，未映射 已分配，已映射到主存 已分配，已映射到物理交换空间(磁盘) 从 2-\u003e3就是缺页，如果需要磁盘读写就是严重缺页异常，否则就是次缺页异常。从这几种状态出发可以定义另外两个内存时术语: 常驻集合大小 RSS: 已分配的主存(状态3)大小 虚拟内存大小: 所有已分配区域(2+3+4) 除此之外我们还能经常看到另一个内存术语，共享内存 SHR，它标识与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等所占用的内存。要注意共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:2:1","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"3.内存架构 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:3:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"3.1 UMA 架构 内存硬件包括主存，总线，CPU 缓存和 MMU(内存管理单元)。下面展示了一个普通双处理器均匀访问模型(UMA) 系统的主存架构，又称对称多处理器架构 SMP 通过共享总线，每个 CPU 访问所有内存都有均匀的访问延时。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:3:1","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"3.2 NUMA 作为对照下面是一个双处理器非均匀访问模型 NUMA 系统，其中采用一个 CPU 互联(CPU 原理一章有提到)。 在 NUMA 架构下，多个处理器被划分到不同 Node 上，对主存的访问时间随着相对 CPU 的位置不同而变化。与 CPU 直接相连的内存称为本地内存。 既然 NUMA 架构下的每个 Node 都有自己的本地内存空间，那么，在分析内存的使用时，我们也应该针对每个 Node 单独分析。 可以通过 numactl 命令，来查看处理器在 Node 的分布情况，以及每个 Node 的内存使用情况。 numactl --hardwar available: 1 nodes (0) node 0 cpus: 0 # Node 0 包含的CPU编号 node 0 size: 2047 MB # Node 0 内存大小 node 0 free: 534 MB # Node 0 剩余内存大小 node distances: node 0 0: 10 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:3:2","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"4.内存管理 内存管理软件包括虚拟内存系统，地址转换，换页。与性能相关的内容包括: 内存释放 内存分配 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:4:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"4.1 内存分配 内存分配器用于内存分配。下图展示了分配器的作用，以及分配器的一些常见类型: slab: 内核级分配器 libc: 用户级分配器的统称，包括 libmalloc, libumem, mumalloc Page Allocator: Linux 用于管理页的伙伴分配器，在下面的空闲链表中会详细介绍 slab 内核 slab 分配器管理特定大小的对象缓存，使它们能被快速的回收利用，并且避免页分配开销。这对经常处理固定大小结构的内核内存分配来说特别有效。slab 大小固定，因此可以一次分配 M 个 slab 大小的缓存，也就避免了多次页分配的开销。大小固定类似于数组也便于回收利用。 Linux 基于 slab 分配器提供了另一个分配器 SLUB。SLUB 为解决多个问题设计，特别是 slab 分配器的复杂性。包括移除对象队列，以及每 CPU 缓存，吧 NUMA 优化留个页分配器(Page Allocator) SLUB 现在是 Linux 的默认选项. 用户级分配器 有多种用户级分配器，他们的性能也有所差异： libc: 不建议使用，性能较差，容易导致内存碎片化 glibc: 分配基于分配请求的长度，是结合了多种分配策略的高效分配器 较小的分配来自内存集合，包括伙伴关系算法合并长度相似的单位 较大的分配用树高效搜索空间 非常大的分配转到 mmap() ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:4:1","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"4.2 内存释放 内存过低时，系统会按照上面的高到低的次序释放内存: 空闲链表: 未使用的页列表，能立即用于分配。通常每个 NUMA 的内存有一个 回收: 内核释放可以轻易释放的内存 换页: 对于 Linux 可以配置一个交换倾向的可调参数 /proc/sys/vm/swappiness，范围为 0-100，默认值为 40。 值越高: 倾向于\"换页\"来释放内存，此处的换页指匿名换页 值越低: 倾向于收回页缓存，即文件系统换页 这就通过在保留热文件系统缓存的同时，换出冷应用程序的内存来提高系统的吞吐量 OOM: 搜索并杀死可牺牲的进程来释放内存。Linux 采用 select_band_process() 搜索后用 omm_kill_process() 杀死进程 空闲链表 类UNIX系统使用空闲链表和页面换出守护进程来管理内存，如上图所示: 回收的内存添加到空闲链表表头以便将来分配 通过页面换出守护进程释放的内存被加到表尾。kswapd 释放的内存包括有价值的文件系统缓存，这些文件系统缓存在未被重用前，如有对任一页的请求，它能被取回并从空闲链表中移除 空闲链表通常由分配器消耗，如内核的 slab 分配器，以及用户空间的 libc malloc。上面的单个空闲链表是一种简化，具体实现依内核版本不同。 Linux 使用伙伴分配器管理页。它以2的幂的方式向不同尺寸的内存分配器提供多个空闲链表。术语伙伴指找到相邻的空闲内存页以被同时分配。 回收 回收大多是从内核的slab 分配器缓存释放内存。这些缓存包括 slab 大小的未使用内存块，以供重用。回收将这些内存交还给系统进行分配。 文件系统部分我们会说到内核使用 Slab 机制来管理目录项和索引节点的缓存，/proc/sys/vm/vfs_cache_pressure 可以定义目录项缓存和索引节点缓存的回收倾向，默认值 100，数值越大，就表示越容易回收。 换页 页面换出守护进程管理利用换页释放内存。当主存中可用的空闲链表低于阀值时，kswapd就会开始页扫描。页扫描仅会按需启动，通常平衡的系统不会经常做页扫描并且仅以短期爆发方式扫描。因此如果页扫描多于几秒通常是内存压力问题的预兆。 Linux 的页面换出守护进程称作 kswapd()，如下图所示，它扫描非活动和活动内存的 LRU 页列表以释放页面。 页的活动列表和非活动列表采用 LRU 方式工作，kswapd 先扫描非活动列表，然后按需扫描活动列表。扫描会遍历列表检查页面，找出可以释放的页面: 如果是干净的页直接释放 如果是脏页会需要先将脏页写回磁盘然后释放。 kswapd 只有在系统严重不足才会选择脏页释放，其他情况下脏页由 flush 内核线程写回磁盘。脏页的管理详见文件系统的操作系统原理部分。 kswapd 的激活基于空闲内存和两个提供滞后的阀值。如下图所示: 一旦空闲内存达到最低阀值，kswapd 运行于同步模式，按需求释放内存页(内核排除在外)，此时只有内核才可以分配内存。 最低阀值通过 vm.min_free_kbytes 设置，其他阀值基于此按比例放大两倍，三倍。 在 NUMA 架构下，三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看。 某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项： 默认的 0 ，也就是刚刚提到的模式，表示既可以从其他 Node 寻找空闲内存，也可以从本地回收内存。 1、2、4 都表示只回收本地内存，2 表示可以回写脏数据回收内存，4 表示可以用 Swap 方式回收内存。 OOM OOM（Out of Memory），其实是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分： 一个进程消耗的内存越大，oom_score 就越大 一个进程运行占用的 CPU 越多，oom_score 就越小 这样，进程的 oom_score 越大，代表消耗的内存越多，也就越容易被 OOM 杀死。 可以通过 /proc 文件系统，手动设置进程的 oom_adj ，从而调整进程的 oom_score。oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。 # 调整 sshd 进程的 oom_adj echo -16 \u003e /proc/$(pidof sshd)/oom_adj ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:4:2","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"5. 进程地址空间 用户空间内存，从低到高分别是五种不同的内存段。 只读段，包括代码和常量等 数据段，包括全局变量等 堆，包括动态分配的内存，从低地址开始向上增长，堆上的内存是匿名页 文件映射段，包括动态库、共享内存等，从高地址开始向下增长， 栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB 堆和文件映射段的内存是动态分配的。比如使用 C 标准库 malloc(): 可以在堆动态分配内存 mmap(): 可以在文件映射段动态分配内存 对于大多数分配器，free() 不会将内存换给操作系统，相反会保留它们以备将来分配。这意味着对会不停增长，进程的常驻内存只会增加，并且是正常现象。 使用 mmap() 分配，使用 munmap() 释放的内存则会归还给操作系统。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:5:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"6. 内存监测指标 与内存相关的专业术语或者指标包括: 内存统计: 包括各种内存的使用统计 缓存命中率 内存泄漏 swap 的影响 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:6:0","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"6.1 内存统计 各种内存的统计信息记录在下面几个文件中: /proc/meminfo: 系统各内存统计 /proc/zoneinfo: 各 NUMA Node 内存以及页缓存统计信息 /proc/pid: 进程的各项统计信息 /proc/buddyinfo: 内核页面伙伴分配器统计信息 meminfo cat /proc/meminfo MemTotal: 2895444 kB MemFree: 2498868 kB MemAvailable: 2535384 kB Buffers: 3108 kB Cached: 165872 kB SwapCached: 0 kB Active: 115656 kB Inactive: 126632 kB Active(anon): 73964 kB Inactive(anon): 9412 kB Active(file): 41692 kB Inactive(file): 117220 kB Unevictable: 0 kB ..... 其中: Buffers 是内核缓冲区用到的内存 Cache 是内核页缓存 Reclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。 执行 man proc 我们可以看到这些指标的准确含义，有关 Buffers 和 Cached 的区别我们在文件系统一节再详述。 zoneinfo head -15 /proc/zoneinfo Node 0, zone DMA pages free 1937 min 95 low 118 high 142 scanned 0 spanned 4095 present 3998 managed 3977 nr_free_pages 1937 nr_alloc_batch 24 nr_inactive_anon 26 nr_active_anon 158 nr_inactive_file 579 nr_active_file 1040 .... 其中: pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是剩余内存页数，它跟后面的 nr_free_pages 相同。 nr_zone_active_anon 和 nr_zone_inactive_anon，分别是活跃和非活跃的匿名页数。 nr_zone_active_file 和 nr_zone_inactive_file，分别是活跃和非活跃的文件页数。 后面我们看到的诸如 top，free，sar 命令输出的内存统计信息基本上都是基于这两个文件。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:6:1","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"6.2 缓存命中率 所谓缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。 不过 Linux 系统中并没有直接提供查询缓存命中率的接口。基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制的软件包bcc 提供了查询缓存命中率的工具: cachestat 提供了整个操作系统缓存的读写命中情况。 cachetop 提供了每个进程的缓存命中情况。 最后，Buffers 和 Cache 都是操作系统来管理的，应用程序并不能直接控制这些缓存的内容和生命周期。所以，在应用程序开发中，一般要用专门的缓存组件，来进一步提升性能。比如，程序内部可以使用堆或者栈明确声明内存空间，来存储需要缓存的数据。再或者，使用 Redis 这类外部缓存服务，优化数据的访问效率。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:6:2","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"6.3 内存泄漏 堆和文件映射段由应用程序自己来分配和管理，如果应用程序没有正确释放内存，就会造成内存泄漏。内存泄漏的危害这么大，因此我们需要有能检测内存泄漏的方法 – memleak。memleak 同样是位于 bcc工具包中的命令。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:6:3","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"6.4 swap 影响 # 间隔1秒输出一组数据 # -r表示显示内存使用情况，-S表示显示Swap使用情况 $ sar -r -S 1 # -d 表示高亮变化的字段 # -A 表示仅显示Normal行以及之后的15行输出 $ watch -d grep -A 15 'Normal' /proc/zoneinfo Node 0, zone Normal pages free 21328 min 14896 low 18620 high 22344 spanned 1835008 present 1835008 managed 1796710 protection: (0, 0, 0, 0, 0) nr_free_pages 21328 nr_zone_inactive_anon 79776 nr_zone_active_anon 206854 nr_zone_inactive_file 918561 nr_zone_active_file 496695 nr_zone_unevictable 2251 nr_zone_write_pending 0 像上面这样，使用后面讲到的诸如sar, free, cachetop 命令可以帮我找到Swap 发生的根源。但另一个问题是 Swap 到底影响了哪些应用程序呢？ 通过 /proc/pid/status 中的 VmSwap 字段，我们可以查到进程 Swap 换出的虚拟内存大小: # 按VmSwap使用量对进程排序，输出进程名称、进程ID以及SWAP用量 $ for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid/{printf $2 \" \" $3}END{ print \"\"}' $file; done | sort -k 3 -n -r | head dockerd 2226 10728 kB docker-containe 2251 8516 kB snapd 936 4020 kB networkd-dispat 911 836 kB polkitd 1004 44 kB 或者直接使用 smem --sort swap可以直接将进程按照swap使用量排序显示。 最后要想从根本上降低 swap 带来的影响可以按需使用下面几种方法: 禁止 Swap，现在服务器的内存足够大，所以除非有必要，禁用 Swap 就可以了。随着云计算的普及，大部分云平台中的虚拟机都默认禁止 Swap。 如果实在需要用到 Swap，可以尝试降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以用库函数 mlock() 或者 mlockall() 锁定内存，阻止它们的内存换出。 ","date":"2020-01-19","objectID":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/:6:4","tags":["Linux 性能调优"],"title":"4.4 内存","uri":"/posts/linux/linux_perf/24.%E5%86%85%E5%AD%98/"},{"categories":["Linux"],"content":"4.3 CPU 动态追踪","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"本节我们来介绍 CPU 动态追踪技术，包括 perf，systemtap，dtrace ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:0:0","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1. Systemtap 进行 CPU 分析 Systemtap 可以用来剖析用户级和内核级的 CPU 用量，也能跟踪 函数执行 CPU 交叉调用 中断 内核调度器 这些功能支持负载特征分析、剖析、下钻分析和延时分析。 ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:0","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"1.1 内核剖析 Dtrace # solaris # 1. 以 997Hz 频率取样内核栈 dtrace -n 'profile-997 /agr0/ { @[stack()] = count()}' # 2. 以 997Hz 频率取样内核栈，仅输出最频繁的 10 个 dtrace -n 'profile-997 /agr0/ { @[stack()] = count()} END { trunc(@, 10); }' # 3. 以 997Hz 频率取样内核栈，每个栈只取 5 个帧 dtrace -n 'profile-997 /agr0/ { @[stack(5)] = count()}' # 4. 以 997Hz 频率取样在 CPU 上运行的函数 dtrace -n 'profile-997 /arg0/ @[func(arg0)] = count()' # 5. 以 997Hz 频率取样在 CPU 上运行的模块 dtrace -n 'profile-997 /arg0/ @[mod(arg0)] = count()' Systemtap # 1.以 997Hz 频率取样内核栈 stap -d kernel -ve 'global s; probe timer.profile { s[backtrace()] \u003c\u003c\u003c 1 } probe end {foreach (i in s+){ print_stack(i); printf(\"\\t%d\\n\", @count(s[i]));}}' # 2. 以 997Hz 频率取样内核栈，仅输出最频繁的 10 个 stap -d kernel -ve 'global s; probe timer.hz(997) { s[backtrace()] \u003c\u003c\u003c 1 } probe end { foreach (i in s- limit 10) {print_stack(i); printf(\"\\t%d\\n\", @count([s[i]]));} }' # 4. 以 997Hz 频率取样在 CPU 上运行的函数 - 未确认 stap -d kernel -ve 'global s; probe timer.profile { s[caller()] \u003c\u003c\u003c 1 } probe end {foreach (i in s+){printf(\"\\t%s - %d\\n\", i, @count(s[i]));}}' # 5. 以 997Hz 频率取样在 CPU 上运行的模块 - 未确认 stap -d kernel -ve 'global s; probe timer.profile { s[module_name()] \u003c\u003c\u003c 1 } probe end {foreach (i in s+){printf(\"\\t%s - %d\\n\", i, @count(s[i]));}}' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:1","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"2. 用户剖析 Dtrace # solaris # 1. 以 997Hz 频率取样进程的用户栈 dtrace -n 'profile-997 /agr1 \u0026\u0026 pid == 123/ { @[ustack()] = count()}' dtrace -n 'profile-997 /agr1 \u0026\u0026 execname == \"sshd\"/ { @[ustack()] = count()}' dtrace -n 'profile-997 /agr1/ { @[execname, ustack()] = count()}' # 取样所有进程的用户栈 # 无 arg1 筛选，此时统计将包括用户栈被冻结的时间(一般是系统调用期间) dtrace -n 'profile-997 /pid == 123/ { @[ustack()] = count()}' # 2. 以 997Hz 频率取样用户栈，仅输出最频繁的 10 个 dtrace -n 'profile-997 /agr1 \u0026\u0026 pid == 123/ { @[ustack()] = count()} END { trunc(@, 10); }' # 3. 以 997Hz 频率取样用户栈，每个栈只取 5 个帧 dtrace -n 'profile-997 /agr1 \u0026\u0026 pid == 123/ { @[ustack(5)] = count()}' # 4. 以 997Hz 频率取样用户栈，仅输出在 CPU 上运行的函数名 dtrace -n 'profile-997 /arg1 \u0026\u0026 pid == 123/ @[ufunc(arg1)] = count()' # 5. 以 997Hz 频率取样用户栈，仅输出在 CPU 上运行的模块名 dtrace -n 'profile-997 /arg1 \u0026\u0026 pid == 123/ @[umod(arg1)] = count()' # 6.以 997Hz 频率取样用户进程的运行 CPU dtrace -n 'profile-997 /pid == 123/ {@[cpu] == count()}' Systemtap # 1. 未确认 stap -ve 'global s; probe timer.hz(97) {if (execname() == \"mysqld\") {s[ubacktrace()] \u003c\u003c\u003c 1 }} probe end { foreach (i in s- limit 10) {print_ustack(i); printf(\"\\t%d\\n\", @count(s[i]));} }' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:2","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"3. 函数跟踪 统计函数的 CPU 时间 # Dtrace dtrace -n 'fbt::zio_checksum_generate:entry {self-\u003ev = vtimestamp;} fbt::zio_checksum_generate:return /self-\u003ev/ {@[\"ns\"] = quantize(vtimestamp - self-\u003ev);self-\u003ev=0 }' # Systemtap stap -ve 'global s; probe kernel.function(\"sys_open\").return {s \u003c\u003c\u003c gettimeofday_ns() - @entry(gettimeofday_ns());} probe end {print(@hist_log(s))}' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:3","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4. CPU 交叉调用 打印CPU交叉调用以及这些调用的代码路径 # Dtrace dtrace -n 'sysinfo:::xcalls { @[stack()] = count(); }' # Systemtap stap -d kernel -ve 'global s;probe scheduler.migrate {s[backtrace()] \u003c\u003c\u003c 1} probe end { foreach (i in s- limit 10) {print_stack(i); printf(\"\\t%d\\n\", @count([s[i]]));} }' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:4","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"5. 中断 # Dtrace 通过 intrstat 命令 intrstat 1 # Systemtap cd /usr/share/systemtap/tapset/linux/ vim irq.stp probe irq_handler.exit = kernel.trace(\"irq_handler_exit\") ? { irq = $irq // the tracepoint doesn't have the struct definition, so we must @cast action = \u0026 @cast($action, \"irqaction\", \"kernel\u003clinux/interrupt.h\u003e\") ret = $ret handler = action-\u003ehandler flags = action-\u003eflags flags_str = irqflags_str(flags) dev_name = action-\u003ename dev_id = action-\u003edev_id next_irqaction = action-\u003enext dir = action-\u003edir thread_fn = action-\u003ethread_fn thread = action-\u003ethread thread_flags = action-\u003ethread_flags } stap -ve 'global s; probe irq_handler.exit { s[dev_id] \u003c\u003c\u003c 1} probe end { foreach (i in s+) {printf(\"%s: %d\\n\", i, s[i])}}' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:5","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"6. 调度器跟踪 Dtrace sched provider 提供了对内核 CPU 调度器的跟踪操作。 # 跟踪 sshd 在 CPU 上的运行时间 dtrace -n 'sched::on-cpu /execname == \"sshd\"/ {self-\u003ets = timestamp;} sched::off-cpu / self-\u003ets / { @[\"ns\"] = quantize(timestamp - self-\u003ets); self-\u003ets = 0; }' Systemtap # 跟踪 sshd 在 CPU 上的运行时间 stap -ve 'global s, t; probe scheduler.cpu_on { if (execname() == \"sshd\") { t[tid()] = gettimeofday_ns(); }} probe scheduler.cpu_off { if (t[tid()]) {s \u003c\u003c\u003c gettimeofday_ns() - t[tid()];delete t[tid()]}} probe end{print(@hist_log(s))}' ","date":"2020-01-18","objectID":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/:1:6","tags":["Linux 性能调优"],"title":"4.3 CPU 动态追踪","uri":"/posts/linux/linux_perf/23_cpu%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA/"},{"categories":["Linux"],"content":"4.2 CPU 监测工具","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"本节我们来介绍 CPU 相关的监测工具，这类工具属于我们前面所说的第一类计数器类命令。 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:0:0","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令总览 下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了 CPU 相关的性能检测工具: 从 CPU 的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握 CPU 分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍 CPU 专用的分析工具的使用 Linux Solaris 作用 说明 uptime uptime 平均负载 vmstat vmstat 系统范围的CPU平均负载 mpstat mpstat 单个CPU统计信息 time ptime 命令计时，带CPU用量分解 dstat 等于 vmstat + iostat + ifstat 可同时观察CPU、磁盘 I/O、网络以及内存使用情况 通用命令，位于独立的一节中 sar sar 可统计包括内存，磁盘，中断等各种信息 通用命令，位于独立的一节中 ps ps 进程状态 通用命令，位于独立的一节中 top prstat 监控每个进程的基本信息 通用命令，位于独立的一节中 pidstat prstat 统计每个进程的内存，IO，上下文切换等信息 通用命令，位于独立的一节中 stap，perf Dtrace CPU剖析和跟踪 通用命令，位于独立的一节中 perf cpustat CPU性能计数器分析 通用命令，位于独立的一节中 除了上述命令之外，还包括以下内容: CPU 调度延迟统计 CPU 的调优手段 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:1:0","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. CPU 统计工具 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:0","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 uptime \u003e uptime 23:51:13 up 1:34, 3 users, load average: 0.00, 0.01, 0.05 输出: top - 14:58:20: 系统当前时间 up 4:33: 系统已运行时间 3 users：当前在线用户 load average：平均负载：最近1分钟、5分钟、15分钟系统的平均负载 说明： 平均负载：平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数 可运行状态：正在使用 CPU 或者正在等待 CPU 的进程，对应 ps R 状态（Running 或 Runnable）进程 不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的，对应 ps D 状态（Uninterruptible Sleep，也称为 Disk Sleep）进程 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:1","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.2 vmstat \u003e vmstat -w procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 1077816 2116 620312 0 0 65 43 34 53 0 0 99 0 0 # 说明: # 除了 r 列外，第一行是系统启动以来的总结信息 -- 取决于 vmstat 的版本，最新的版本不是 vmstat [t [n]] 作用: 虚拟内存统计命令 说明: 完成的使用方法见内存相关部分的内容，CPU 中重点关注 procs 中 r 值的输出 参数: -t：采样间隔 -n：采样次数，可选，默认值是1 -S: -Sm 以MB 为单位显示结果 -a: 输出非活动和活动页缓存的明细 -s: 以列表显示内存统计信息 -w: 以整齐格式显示 输出: system: in: 硬中断次数 cs: 上下文切换次数 procs: r: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 b: 等待IO的进程数量 cpu: 系统全局范围内的平均负载 第一行统计的系统启动以来的平均负载 – 新版本可能不会显示 其余行统计的是时间间隔周期内的平均负载 memory: swpd: 交换出的内存量 free: 空闲可用内存 buff: 用于缓冲缓存的内存 cache: 用于页缓存的内存 swap: si: 换入的内存 so: 换出的内存 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:2","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.3 mpstat \u003e mpstat -P ALL 1 2 Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月01日 _x86_64_ (1 CPU) 00时22分51秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 00时22分52秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 00时22分52秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 00时22分52秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 00时22分53秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 00时22分53秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 平均时间: all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 平均时间: 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 \u003e mpstat -P ON -I SUM 00时22分51秒 CPU intr/s 00时22分51秒 all 1009.18 mpstat [t [n]] 作用: 报告每个 CPU的统计信息 参数: -P {cpu [，...] | ON | ALL}: 指示要报告统计信息的处理器编号，从 0 开始 ON: 表示在线的 CPU ALL: 表示所有 CPU I {SUM | CPU | ALL}: 报告中断统计信息 使用SUM关键字，mpstat命令报告每个处理器的软中断总数 使用CPU关键字，显示CPU或CPU每秒接收的每个中断的数量 ALL关键字等效于指定上面的所有关键字，因此显示所有中断统计信息。 -A: 等效于 mpstat -I ALL -u -P ALL -u: 报告CPU使用率，默认参数 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:3","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.4 time time command 作用: 运行命令并报告 CPU用量 其他: /usr/bin/time -v command 可以输出更详细的信息 \u003e time ls docker_print.py real 0m0.002s # 实际耗时 user 0m0.001s # 用户空间耗时 sys 0m0.001s # 内核空间耗时 \u003e /usr/bin/time -v ls docker_print.py Command being timed: \"ls\" User time (seconds): 0.00 System time (seconds): 0.00 Percent of CPU this job got: 100% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.00 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 968 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 309 Voluntary context switches: 1 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:2:4","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. CPU 延时统计 getdelays.c ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:3:0","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. CPU 调优 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:0","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 sysbench CPU 性能测试 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:1","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.2 chrt nice/renice 系统调用: setpriority(): 调整优先级 sched_setscheduler(): 设置优先级和调度策略 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:2","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.3 调度器选项 /proc/sys/sched ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:3","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.4 进程绑定 taskset ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:4","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.5 独占CPU组 ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:5","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.6 资源控制 cgroups ","date":"2020-01-17","objectID":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/:4:6","tags":["Linux 性能调优"],"title":"4.2 CPU 监测工具","uri":"/posts/linux/linux_perf/22_cpu%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 CPU","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"本节我们来介绍 CPU 相关的操作系统原理。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:0:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"1. CPU 相关的操作原理 我们从下面几个方面入手来讲解 CPU 相关的操作系统原理: CPU 架构 中断处理 调度器: CPU 分配的内核子系统 进程: 上下文切换 僵尸进程 最后我们会说一说 CPU 检测的相关指标 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:1:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2. CPU 架构 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2.1 CPU 的组成 一颗通用的双核处理器的组成如上。具体的组件就不一一解释了。 可以看到内存可能会同时被缓存在不同处理的多个 CPU 缓存中，缓存一致性确保了 CPU 永远访问正确的内存状态。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2.2 CPU 互联 多处理器架构的 CPU 互联与系统的内存架构(同一内存访问 UMA，或者 NUMA)有关。常见的CPU有两种连接方式: 共享系统总线: 在处理器数量增加增加的情况下，会因为共享总线而出现扩展性问题 专用互联: 互联不仅仅是处理器，还可以是其他组件。 处理器之间的私有连接提供了无须竞争的访问以及比共享系统总线更高的带宽。除了外部互联，处理器还有核间通信用的内部互联。 一个早期的 intel 共享总线的四处理器如下所示: 一个四处理器的Intel QPI 架构如下所示: ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:2","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2.3 MMU 和 TLB I$: 一级指令缓存: 按照虚拟地址空间寻址 D$: 一级数据缓存: 按照虚拟地址空间寻址 TLB: 转移后备缓冲器 E$: 二级缓存：按照物理内存地址寻址 MMU 负责虚拟地址到物理地址的转换，主存里的页表由MMU(硬件)直接读取，处理缓存未命中情况。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:3","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2.4 指令的执行 CPU 指令的执行包括预期，解码，执行，内存访问，寄存器写回。内存访问往往需要几十个CPU周期，这段期间指令执行陷入停滞，这段时间称为停滞周期，因此需要CPU缓存降低内存访问的周期数。 CPI和IPC: CPI: 每指令周期数，IPC 的倒数，代表了指令处理的效率，是 CPU 使用率的本质，CPI 较高代表 CPU 经常陷入停滞 IPC: 每周期指令数， instructions per cycle ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:4","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"2.5 CPU性能计数器 CPU性能计数器(CPC) 有很多别名包括性能监测点计数器(PIC)、性能监控单元(PMU)、硬件时间和性能监控事件。它们是可以计数低级 CPU 活动的处理器寄存器。通常包括下列计数器: CPU 周期: 包括停滞周期和停滞周期类型 CPU 指令: 一级，二级，三级缓存访问: 命中，未命中 浮点单元操作 内存 I/O: 读写停滞周期 资源 I/O: 读写停滞周期 每个 CPU 有少量，通常是 2-8 个，可编程记录类似事件的寄存器，哪些寄存器可用取决于处理器的型号。计数器计量哪些事件通过事件选择和 UMASK 确定。事件选择确定要计数的事件类型，UMASK 确定子类型或者子类型组。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:2:5","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"3. 中断处理 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:3:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"3.1 中断和中断线程 中断被内核用来响应设备的服务请求，分为: 中断服务程序: 需要通过注册来处理设备中断，这类程序需要运行的尽可能块，以减少对活动线程中断的影响。如果中断要做的工作不少，尤其是可能被阻塞，最好通过中断线程来处理，由内核调度 从中断开始到中断被服务之间的时间叫做中断延时 中断是一种异步的事件处理机制，用来提高系统的并发处理能力。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:3:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"3.2 Linux 中断处理 Linux 将中断处理过程分成了两个阶段: 上半部分: 用于快速处理中断，运行在中断禁止模式，会推迟新的中断的产生 主要处理跟硬件紧密相关的或时间敏感的工作。 下半部分: 可以作为tasklet 或者工作队列，之后通常作为内核线程由内核做调度 用来延迟处理上半部未完成的工作 以网络接收到数据包为例: 对上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个软中断信号，通知下半部做进一步的处理。 而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。 所以: 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行； 下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 实际上上半部会打断 CPU 正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个 CPU 都对应一个软中断内核线程，名字为 “ksoftirqd/CPU 编号”，比如说， 0 号 CPU 对应的软中断内核线程的名字就是 ksoftirqd/0。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:3:2","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"3.1 软中断 tasklet 和工作队列 首先软中断有三种实现方式: softirq: 也叫软中断，为避免歧义，用英文表示 tasklet: work queue: ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:3:3","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"4. 调度器 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:4:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"4.1 调度器简介 分时系统，通过划分执行时间，让多个进程同时运行。进程在处理器上和CPU间的调度是由调度器完成的。调度器操作线程(Linux 中是任务 task)，并将它们隐射到 CPU 上。 VCX: 资源上下文切换 ICX: 非自愿上下文切换 Premption: 抢占 Time Sharing: 分时 ON-PROC: 运行中 RUNNABLE: 可运行 调度器功能及实现 调度器要实现如下功能: 分时: 可运行多线程 抢占: 高优先级线程在变为可运行状态时，能抢占当前运行的线程 负载均衡: CPU 之间的负载均衡 在 Linux 上 分时通过系统时钟中断调用 scheduler_tick() 实现 scheduler_tick 调用调度器类函数管理优先级和称为时间片的 CPU时间单位的到期事件 当线程变成可运行状态后就出发抢占，调度类函数 check_preempt_curr() 被调用 线程切换有 _schedule()管理，后者通过 pick_next_task() 选择最高优先级的线程运行 负载均衡由 load_balance() 函数负责执行 空闲线程 内核\"空闲\"线程只在没有其他可运行线程的时候才在 CPU 上运行，通常被设计为通知CPU执行停止指令或者减速以节省资源，CPU会在下一次硬件中断醒来。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:4:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"4.2 CPU 运行队列 运行队列由调度器管理。花在等待 CPU 运行上的时间称为运行队列延时，又称调度器延时。 对于多处理器系统，内核通常为每个 CPU 提供一个运行队列，并尽量使得线程每次都被放到同一队列之中。目的是为了提高内存本地性，更高效的使用缓存。为每个 CPU 提供一个运行队列避免了队列操作的线程同步开销(mutex 锁)。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:4:2","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"5.进程 进程包括进程地址空间内的数据和内核里的元数据(上下文)： 内核上下文包含各种进程属性和统计信息 每一线程都包含一些元数据，包括在内核上下文里自己的优先级以及用户地址空间里自己的栈。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:5:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"5.1上下文切换 在前面的文章我们说过，用户进程通过系统调用执行内核特权操作时，会做上下文切换，从用户态进入到内核态。但是根据切换的任务的不提供，上下文切换包括多种类型: 进程上下文切换 线程上下文切换 中断上下文切换 系统调用的上下文切换 首先我们要明白的是，无论什么类型的上下文切换， CPU 寄存器和程序计数器（Program Counter，PC）都需要保存和重载，这一部又分称为CPU 上下文切换。其次不同的类型上下文切换因为不同任务间共享层次不同，需要交换的内容也就不同。 系统调用的上下文切换 前面我们说过，执行系统调用时，一个进程的线程有两个栈: 一个用户级别栈和一个内核级别的栈。线程被阻塞时，用户级别的栈在系统调用期间不会改变。所以系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，上下文交换需要完成的操作其实很少。 进程上下文切换 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。这些资源在进程上下文切换时都要保存和恢复。 Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新。在多处理器系统上，缓存是被多个处理器共享的，进程切换也会导致缓存被刷新。 由此可见进程上下文切换成本较高。 线程切换 通常线程切换说的是同一进程内的线程，因为不同进程内的线程切换叫做进程切换。 线程会共享相同的虚拟内存和全局变量等资源。这些在上下文切换时是不需要修改的。需要保存的仅仅是线程的私有数据，比如栈和寄存器等。 中断上下文切换 为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。因此中断上下文切换并不涉及到进程的用户态，只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 可以查看上下文切换到工具有 vmstat, pidstat -tw ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:5:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"5.2 僵尸进程 正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册 SIGCHLD 信号的处理函数，异步回收资源。如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。子进程的回收可以参考Python: 僵尸进程的产生和清除方法 通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。 对于僵尸进程，我们通常需要通过 pstree 找到其父进程，然后在父进程中解决。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:5:2","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"5.3 进程状态 进程状态有如下几种 状态 含义 D 不可中断睡眠，表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断 目的是为了保护进程数据和硬件的一致性 R 正在运行或可运行（处于就绪排队中） S 可中断睡眠 (休眠中, 受阻, 在等待某个条件的形成或接受到信号) T 已停止的 进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行 收到 SIGCONT 信号进程会回复运行 W 正在换页(2.6.内核之前有效) X 死进程 (未开启) Z 僵尸进程，进程已终止, 进程资源未被回收(比如进程的描述符、PID 等) I Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上，没有任何负载 D 状态的进程会导致平均负载升高，I 状态的进程不会 \u003c 高优先级(not nice to other users) N 低优先级(nice to other users) L 页面锁定在内存（实时和定制的IO） s 表示这个进程是一个会话的领导进程 会话是指共享同一个控制终端的一个或多个进程组。 l 多线程（使用 CLONE_THREAD，像NPTL的pthreads的那样） + 在前台进程组，进程组表示一组相互关联的进程 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:5:3","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6. CPU 监测指标 与 CPU 相关的专业术语或者指标包括: 系统负载 CPU 使用率 中断计数 上下文切换 CPU 缓存命中率 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:6:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6.1 进程状态与系统负载 \u003e uptime # 过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average） 05:10:14 up 8:37, 2 users, load average: 0.21, 0.06, 0.06 \u003e watch -d uptime # 查看 CPU 个数 \u003e grep 'model name' /proc/cpuinfo | wc -l uptime 中定义的系统负载与进程状态有关，平均负载是指单位时间内，系统处于可运行状态(R)和不可中断状态(D)的平均进程数,因此平均负载跟CPU使用率没有必然联系。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:6:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6.2 CPU 使用率 CPU 使用率是通过测量 CPU 未运行内核空闲线程的时间得出的。CPU 使用率的测量包括了除此之外的所有时钟周期，包括内核停滞周期。CPU 可能会因为经常停滞等待 I/O 而导致高使用率，而不仅是执行指令。 如何测量时间跟 CPU 时间片有关: Linux 通过事先定义的节拍率（内核中表示为 HZ），来定义时间片的长短。HZ 是内核的可配选项，可以通过查询 /boot/config 内核选项来查看它的配置值。 时间片到期时，会触发系统计时器中断即clock()例程，会更新系统时钟和 jiffies 计数器；为了方便用户空间程序，内核还提供了一个用户空间节拍率 USER_HZ，它总是固定为 100，也就是 1/100 秒 根据计数器操作系统统计 CPU 运行不同运行程序的时间 /proc/stat 提供了 CPU 运行不同程序的计数信息 /proc/[pid]/stat 提供了每个进程运行情况的计数信息 grep 'CONFIG_HZ=' /boot/config-$(uname -r) cat /proc/stat cpu 772 0 812 17070 27 0 20 0 0 0 cpu0 772 0 812 17070 27 0 20 0 0 0 intr 38176 154 74 0 0 0 0 0 0 0 0 0 0 208 0 0 280 0 0 0 395 0 6282 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ctxt 83630 btime 1591280448 processes 2288 procs_running 2 procs_blocked 0 softirq 52342 1 20713 43 422 6208 0 100 0 0 24855 诸如 top, ps, mpstat, pidstat -u 正是使用上面的数据计算的 CPU 使用率，不同的是计算的方式和周期不同而已。对于CPU使用率的深入分析，需要借助 perf 等高级分析工具。 短时进程 top, ps, pidstat -u 这类展示系统概要和进程快照的工具很难发现短时进程导致 CPU 使用率高的问题，需要使用记录事件的工具来配合诊断。下面是一些常见的分析思路: 需要时刻关注处于 Running 状态的进程数(top 命令 Tasks 行有不同状态进程的计数) 使用 pstree 可以查看进程树，有助于发现多进程问题 sar -w 1: 可以实时统计系统每秒创建的任务数(进程数) execsnoop: 是一个专为短时进程设计的工具，它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息 对于CPU使用率的深入分析，需要借助 perf 等高级分析工具。 CPU 使用率的相关指标 下面这些指标在各种 CPU 监测工具中都能看到，使用 man proc 可以看到他们的说明，但是最好是能记住: 指标 缩写 含义 user us 代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。 nice ni 代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system sys 代表内核态 CPU 时间。 idle id 代表空闲时间。注意，它不包括等待 I/O 的时间 iowait wa 代表等待 I/O 的 CPU 时间，出现 iowait 有两个条件，一是进程在等io，二是等io时没有进程可运行 irq hi 代表处理硬中断的 CPU 时间。 softirq si 代表处理软中断的 CPU 时间。 steal st 代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。 guest guest 代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。 guest_nice gnice 代表以低优先级运行虚拟机的时间。而我们通常所说的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 注意：通常我们收的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:7:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6.3 中断计数 中断的计数信息位于: /proc/softirqs: 提供了软中断的计数信息 /proc/interrupts: 提供了硬中断的计数信息 # 动态查看中断计数器的变化 \u003e watch -d cat /proc/interrupts # 动态查看软中断的变化 \u003e watch -d cat /proc/softirqs 硬中断 硬中断的类型很多，常见的需要我们知道，包括: 重调度中断(RES): 又称处理器中断，与CPU之间实现缓存一致性和负载均衡有关 软中断 # 查看软中断计数 \u003e cat /proc/softirqs CPU0 HI: 1 TIMER: 526599 NET_TX: 4262 NET_RX: 121304 BLOCK: 42438 BLOCK_IOPOLL: 0 TASKLET: 358 SCHED: 0 HRTIMER: 0 RCU: 113508 # 查看软中断内核线程 \u003e ps aux | grep softirq root 6 0.0 0.0 0 0 ? S 09:13 0:00 [ksoftirqd/0] /proc/softirqs 文件记录了所有的软中断类型以及它们在 CPU 上的发生次数。除了发生次数，我们要注意的是同一种软中断在不同 CPU 上的分布情况。正常情况下，同一种中断在不同 CPU 上的累积次数应该差不多。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:7:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6.4 上下文切换次数 从性能分析角度，上下文切换可以分为: 无法获取资源而导致的自愿上下文切换: 通常意味发生了锁，磁盘等资源竞争 被系统强制调度导致的非自愿上下文切换: 通常以为的应用程序负载较高 但过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成为性能瓶颈。可以使用 vmstat, pidstat -w 查看系统和进程的上下文切换次数。 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:8:0","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"6.5 CPU 缓存命中率 ","date":"2020-01-16","objectID":"/posts/linux/linux_perf/21_cpu/:8:1","tags":["Linux 性能调优"],"title":"4.1 CPU","uri":"/posts/linux/linux_perf/21_cpu/"},{"categories":["Linux"],"content":"4. 操作系统","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"从本文开始我们将进入Linux性能优化的第二阶段，操作系统部分。操作系统原理是复杂的，不可能也没有能力把操作系统都将清楚。我们会列出每个部分相关的关键术语，并就其中与性能优化相关的关键部分进行讲解。本文是一个关于操作系统和内核知识的概览，为后面做一点准备。 与操作系统相关的术语: 进程: 一个 OS 的抽象概念，是用来执行程序的环境，运行在用户模式(用户态)，通过系统调用或自陷来进入内核模式 线程: 可被调度的运行在 CPU上的可执行上下文 系统调用: 一套明确定义的协议，为用户程序请求内核执行特权操作 自陷: 信号发送到内核，请求执行一段系统程序(特权操作)，自陷类型包括系统调用、处理器异常以及中断 中断: 由物理设备发送到内核的信号，通常是请求 I/O 服务，中断是自陷的一种类型 时钟: 是一个驱动所有处理器逻辑的数字信号，CPU 以一个特定的时钟频率执行 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:0:0","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. 内核 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:0","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.1 时钟 UNIX 内核的一个核心组件是 clock() 例程，从一个计时器中断执行，每执行一次成为一个 tick。功能包括更新系统时间，计时器和线程调度时间片的到时结束，维护CPU计数器，以及执行 callout(内核调度例程)。 但是 clock() 曾经有过性能问题。现代内核已经把许多功能移出了 clock 例程，放到了按需中断中，这是为了努力创造无 tick 内核。包括 Linux 在内，clock 例程即系统计时器中断，除了更新系统时钟和更新 jiffies 计数器之外，执行的工作很少。jiffies 是 Linux 的时间单元与 tick 类似。 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:1","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.2 内核态 用户进程通过系统调用执行内核特权操作时，会做上下文切换，从用户态到内核态。 无论是用户态还是内核态，都有自己的软件执行上下文，包括栈和寄存器。这些状态切换上下文是会耗费 CPU 周期的，这对每次I/O都增加了一小部分的时间开销。 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:2","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.3 用户栈和内核栈 执行系统调用时，一个进程的线程有两个栈: 一个用户级别栈和一个内核级别的栈。线程被阻塞时，用户级别的栈在系统调用期间不会改变，当执行在内核上下文时，线程用的是一个单独的内核级别栈。此处有一个例外，信号处理程序取决于其配置，可以借用用户级别的栈。 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:1:3","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2. Linux 性能监测工具 接下来我们会按照操作系统的组成，讲解各个部分的监测工具和基准测试工具，下面是这些工具的概览，来自brendangregg ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:0","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.1 监测工具 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:1","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.2 测试工具 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:2","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.3 内核调参工具 ","date":"2020-01-15","objectID":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/:2:3","tags":["Linux 性能调优"],"title":"4. 操作系统","uri":"/posts/linux/linux_perf/20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.6 Systemtap 与 Dtrace 的语法比较","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"《性能之巅》内对 Dtrace 和 Systemtap 的语法做了一个对比，对于学习二者是一个不错的资源，现整理如下。 ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:0:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"1. DTrace To Systemtap 下面是一份 DTrace 转换成 Systemtap 的简易指南，包括如下几个部分 语法 探针 内置变量 函数 转换示例 ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:1:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"2. 语法 DTrace Systemtap 描述 探针名 probe 探针名 探针名 {var[a] = } global var; probe 探针名 {var[a]=} systemtap 的全局变量必须事先声明 /predicate/ {if (test) {}} @a = count(x) printa(@a) a «\u003c x print(count(a)) 聚合变量使用 arg0 …. agrN args[0] … args[N] 目标变量 $var 全局变量 @var(“file_stat@fs/file_table.c”) 如何获取探针中的变量 ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:2:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"3. 探针 DTrace Systemtap 描述 BEGIN dtrace:::BEGIN begin probe begin END dtrace:::END end probe end syscall:::entry syscall.* syscall:::return syscall.*.return syscall::read:entry syscall.read syscall::read:return syscall.read.return sched:::on-cpu scheduler.cup_on sched:::off-cpu scheduler.cpu_off profile:::profile-100 timer.profile profile:::tick-10s timer.s(10) fbt::foo:entry kernel.function(“foo”) fbt::foo:return kernel.function(“foo”).return io:::start ioblock.request io:::done ioblock.end ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:3:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"4. 内置变量 DTrace Systemtap 描述 execname execname() 执行在CPU上的进程名 uid uid() 执行在CPU上的用户ID pid pid() 执行在CPU上的进程PID cpu cpu() 进程当前所在的 CPU timestamp gettimeofday_s() 自启动以来的纳秒数 vtimestamp CPU上的线程时间，单位是纳秒 arg0..N 目标变量 探针参数(uint64_t) args[0]…[N] 目标变量 探针参数(类型化的) curthread task_current() 指向当前线程内核结构的指针 probefunc probefunc() 打印探针所在位置的内核函数名称 probename 当前探针名称 curpsinfo 当前进程信息 curpsinfo-\u003epr_psargs cmdline_str() 进程启动的命令 $target target() 返回stap,dtrace 通过命令行设置的进程 pid ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:4:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"5. 函数 Dtrace Systemtap 描述 stringof(addr) kernel_string() 返回来自内核空间的字符串 copyinstr(addr) user_tring() 返回用户空间地址的字符串 内核会执行一次从用户空间到内核空间的复制 stack(count) print_backtrace() 打印内核级别栈追踪 ustack(count) print_ubacktrace() 打印用户级别栈追踪 exit(status) exit() 退出DTrace并返回状态 quantize(value) @hist_log() 用 2 的幂次方直方图统计 value lquantize(value,min,max,step) @hist_linear() 用给定最下值，最大值和步进值做线性直方图记录 value ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:5:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"6. 转换示例 列出系统调用入口探针 \u003e dtrace -ln syscall:::entry \u003e stap -l 'syscall.*' syscall.accept syscall.accept4 syscall.access ..... 统计 read() 返回大小 # dtrae1: arg1 作为系统调用 read() 的返回 \u003e dtrace -n 'syscall::read:return { @bytes = quantize(arg1); }' # stap1: 查看 stap 目标变量，$return 是read() 的返回 \u003e stap -L 'syscall.read.return' syscall.read.return name:string retval:long retstr:string $return:long int $fd:long int $buf:long int $count:long int $ret:long int # stap2: \u003e stap -e 'global bytes;probe syscall.read.return { bytes \u003c\u003c\u003c $return } probe end { print(@hist_log(bytes)); }' 根据进程名统计系统调用 # dtrace1: \u003e dtrace -n 'syscall:::entry { @x[execname] = count(); }' # stap1: 不便阅读 \u003e stap -e 'global x; probe syscall.* { x[execname()] \u003c\u003c\u003c 1 } ' # stap2: 格式化输出 \u003e stap -ve 'global x; probe syscall.* { x[execname()] \u003c\u003c\u003c 1 } probe end { foreach (k in x+) {printf(\"%-36s %8d\\n\", k, @count(x[k])); } }' 对 PID 为 123 的进程，根据系统调用名统计系统调用次数 # dtrace1: pid \u003e dtrace -n 'syscall:::entry /pid == 123/ { @x[probefunc] == count(); }' # stap1: \u003e stap -ve 'global x; probe syscall.* { if (pid() == 123) { x[probefunc()] \u003c\u003c\u003c 1 }; } probe end { foreach (k in x+) {printf(\"%-36s %8d\\n\", k, @count(x[k])); } }' 对 httpd 进程，根据系统调用名统计系统调用次数 # dtrace1: execname \u003e dtrace -n 'syscall:::entry /execname == \"httpd\"/ { @x[probefunc] == count(); }' # stap1: \u003e stap -ve 'global x; probe syscall.* { if (execname() == \"httpd\") { x[probefunc()] \u003c\u003c\u003c 1 }; } probe end { foreach (k in x+) {printf(\"%-36s %8d\\n\", k, @count(x[k])); } }' 用进程名和路径名跟踪文件的open() # dtrace \u003e dtrace -l 'syscall::open.entry { printf(\"%s, %s\", execname, copyinstr(arg0)); }' # stap \u003e stap -ve 'probe syscall.open { filename = user_string_quoted($filename); printf(\"%s %s\\n\", execname(), filename); }' 对 mysqld 进程统计 read() 延时 # dtrace1: \u003e dtrace -n 'syscall::read:entry /execname == \"mysqld\"/ {self-\u003ets = timestamp;} syscall::read:return /self-\u003ets/ { @[\"ns\"] = quantize(timestamp - self-\u003ets);self-\u003ets=0}' \u003e stap1: gobal t,s; probe syscall.read { if (execname() == \"mysqld\"){ t[tid()] = gettimeofday_ns(); } } probe syscall.read.return { if (t[tid()]){ s \u003c\u003c\u003c gettimeofday_ns() - t[tid()]; delete t[tid()]; } } probe end { printf(\"ns\\n\"); print(@hist_log(s)) } \u003e stap2: 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值 \u003e stap -ve 'global s; probe syscall.read.return {if (execname() == \"mysqld\") {s \u003c\u003c\u003c gettimeofday_ns() - @entry(gettimeofday_ns());}} probe end{print(@hist_log(s))}' 根据进程名和参数跟踪新进程 # dtrace: \u003e dtrace -n 'proc::exec-success { trace(curpsinfo-\u003epr_psargs) }' # stap \u003e stap -ve 'probe process.begin { printf(\"%s\\n\", cmdline_str()) }' 以100Hz对内核栈采样 # dtrace \u003e dtrace -n 'profile-100 { @[stack()]=count() }' # stap \u003e stap -e 'global s; probe timer.profile { s[backtrace()] \u003c\u003c\u003c 1 } probe end {foreach (i in s+){ print_stack(i); printf(\"\\t%d\\n\", @count(s[i]));}}' ","date":"2020-01-13","objectID":"/posts/linux/linux_perf/16_dtrace_stap/:6:0","tags":["Linux 性能调优"],"title":"3.6 Systemtap 与 Dtrace 的语法比较","uri":"/posts/linux/linux_perf/16_dtrace_stap/"},{"categories":["Linux"],"content":"3.5 Systemtap Python","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"本节我们来看看如何使用 Systemtap 来追踪 Python 程序的执行。 ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:0:0","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"1. 环境配置 从 Python 3.6 开始，CPython 可以使用嵌入式“标记”，也称为“探测器”，使得可以通过 DTrace 或 SystemTap 来追踪 Cpython。 在 Linux 上，为了Systemtap 能够动态追踪 Cpython 的执行，必须按照如下步骤配置系统环境: 必须安装 SystemTap 开发工具 CPython 必须启用 –with-dtrace 编译选项 ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:1:0","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"1.1 安装 SystemTap 开发工具 yum install systemtap-sdt-devel ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:1:1","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"1.2 Cpython 启用 –with-dtrace 默认情况下，通过 yum 安装的 Python 都已启用 –with-dtrace 编译选项。可使用如下方式进行确认 \u003e import sysconfig \u003e sysconfig.get_config_vars() \u003e sysconfig.get_config_var('WITH_DTRACE') ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:1:2","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"1.3 验证 Cpython 支持 Systemtap 在 Linux 上，可以通过查看程序是否包含“.note.stapsdt”部分来验证构建的二进制文件中是否存在 SystemTap 静态标记。 如果 Cpython 未启用 –enable-shared 选项，可使用如下两种方式进行确认: \u003e readelf -S ./python | grep .note.stapsdt [30] .note.stapsdt NOTE 0000000000000000 00308d78 \u003e readelf -n ./python # 显示的元数据或包含 SystemTap 的信息 stapsdt 通常情况下 yum 安装的 python 都会启用 –enable-shared 编译选项，因此需要通过下面的方式进行验证: \u003e readelf -S /usr/lib64/libpython3.6m.so.1.0 |grep -i .note.stapsdt [28] .note.stapsdt NOTE 0000000000000000 002f5bcc ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:2:0","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"2. 使用 Systemtap 追踪 Python ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:3:0","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"2.1 直接使用 Python 的静态标记 使用 Systemtap 动态追踪 Python 的第一种方式是直接使用 Python 的静态标记。 # Python 未启用 --enable-shared 时 probe process(\"python\").mark(\"function__entry\") { filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(\"%s =\u003e %s in %s:%d\\\\n\", thread_indent(1), funcname, filename, lineno); } # Python 启用 --enable-shared 时，静态标记包含在 libpython shared library 中 probe process(\"python\").library(\"libpython3.6m.so.1.0\").mark(\"function__entry\") { filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(\"%s =\u003e %s in %s:%d\\\\n\", thread_indent(1), funcname, filename, lineno); } Python 为 Systemtap 提供了以下静态标记: function__entry(str filename，str funcname，int lineno) 作用: 表示开始 Python 函数调用 说明: 这个静态标记，等同于内核函数，可以通过目标变量访问静态标记内的变量 参数: filename，funcname，lineno，必须使用$arg1，$arg2，$arg3访问 $arg1：(const char *) filename，使用user_string($arg1)获取 filename 的值 $arg2：(const char *) function name，使用user_string($arg2)获取funcname的值 $arg3：int 行号 function__return(str filename，str funcname，int lineno) 作用: 表示Python 函数调用结束，即return 或 exception 参数: 同 function__entry line(str filename，str funcname，int lineno) 作用: 此标记表示即将执行 Python 脚本一行，相当于使用 Python 探查器进行 line-by-line 跟踪 参数: 同 function__entry gc__start(int generation) 作用: Python interpreter 启动垃圾回收周期时触发 gc__done(long collected) 作用: Python interpreter 完成垃圾回收周期时触发 参数: $arg0: int 回收的对象数量。 import__find__load__start(str modulename) 作用: 在importlib尝试查找并加载模块之前触发 参数: $arg0: (const char *) modulename，使用user_string($arg0)获取modulename的值 import__find__load__done(str modulename，int found) 作用: 调用importlib的 find_and_load function 后触发。 参数: $arg0: (const char *) modulename，使用user_string($arg0)获取modulename的值 $arg1: int 表示模块是否已成功加载 追踪示例 追踪Python调用的脚本 # stap 脚本 probe process(\"python3.6\").library(\"/usr/lib64/libpython3.6m.so.1.0\").mark(\"function__entry\") { filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(\"%s =\u003e %s in %s:%d\\n\", thread_indent(1), funcname, filename, lineno); } probe process(\"python3.6\").library(\"/usr/lib64/libpython3.6m.so.1.0\").mark(\"function__return\") { filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(\"%s \u003c= %s in %s:%d\\n\", thread_indent(-1), funcname, filename, lineno); } 试验的 Python 脚本 # test.py def two(): c = 1 + 2 return c def one(): d = two() return d one() 执行 Python 动态追踪 # stap 监测 \u003e stap stap_test.stp -c \"python3.6 test.py\" ...... 0 python3.6(29732): =\u003e __init__ in \u003cfrozen importlib._bootstrap_external\u003e:800 4 python3.6(29732): \u003c= __init__ in \u003cfrozen importlib._bootstrap_external\u003e:804 0 python3.6(29732): =\u003e \u003cmodule\u003e in test.py:2 5 python3.6(29732): =\u003e one in test.py:6 8 python3.6(29732): =\u003e two in test.py:2 10 python3.6(29732): \u003c= two in test.py:4 13 python3.6(29732): \u003c= one in test.py:8 16 python3.6(29732): \u003c= \u003cmodule\u003e in test.py:11 ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:3:1","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"2.2 使用 Systemtap 提供的 typeset typeset 提供的函数库，可以帮助我们隐藏一些Python 静态标记的细节。从目前提供的 typeset 来看，提供的库还是很低级。 ll /usr/share/systemtap/tapset/|grep python -rw-r--r--. 1 root root 522 8月 7 2019 libpython2.7-64.stp -rw-r--r--. 1 root root 31021 10月 19 00:12 python2.stp -rw-r--r--. 1 root root 30405 10月 19 00:12 python3.stp ","date":"2020-01-12","objectID":"/posts/linux/linux_perf/15_stap_python/:3:2","tags":["Linux 性能调优"],"title":"3.5 Systemtap Python","uri":"/posts/linux/linux_perf/15_stap_python/"},{"categories":["Linux"],"content":"3.4 Systemtap 用户空间探测","date":"2020-01-11","objectID":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/","tags":["Linux 性能调优"],"title":"3.4 Systemtap 用户空间探测","uri":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"本节我们继续来学习 Systemtap 的使用 – 用户空间的动态追踪 1. 用户空间探测 SystemTap从0.6版本开始也支持探测用户空间的进程。SystemTap可以探测用户空间进程内函数的调用和退出，可以探测用户代码中预定义的标记，可以探测用户进程的事件。 SystemTap进行用户空间探测需要uprobes模块。如果Linux内核版本大于等于3.5, 它已经内置了uprobes。 不过，SystemTap的用户空间事件跟踪功能依然需要你的内核支持utrace拓展。要想验证当前内核是否提供了必要的utrace支持，在终端中输入下面的命令： \u003e grep CONFIG_UTRACE /boot/config-`uname -r` CONFIG_UTRACE=y # 输出此，表示支持 ","date":"2020-01-11","objectID":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:0:0","tags":["Linux 性能调优"],"title":"3.4 Systemtap 用户空间探测","uri":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"2. 用户空间事件 所有的用户空间事件都以process开头: 可以通过进程ID指定要检测的进程 也可以通过可执行文件名的路径名指定 SystemTap会查看系统的PATH环境变量，所以既可以使用绝对路径，也可以使用在命令行中运行可执行文件时所用的名字。以下将两者统称为PATH。 下面列出的事件都需要进程ID或可执行文件的路径。不在其中的process事件不需要PID和可执行文件路径名。 process(\"PATH\").function(\"function\") 进入可执行文件PATH的用户空间函数function 相当于内核空间中的kernel.function(“function”) 允许使用通配符和.return后缀 process(\"PATH\").statement(\"statement\") 代码中第一次执行statement的地方 相当于内核空间中的kernel.statement(“statement”) process(\"PATH\").mark(\"marker\") 在PATH中定义的静态探测点 可以使用通配符 有些用户空间下的可执行程序提供了这些静态探测点，比如Java process(\"PATH\").begin 创建了一个用户空间下的进程 可以限定某个进程ID或可执行文件的路径 如果不限定，任意进程的创建都会触发该事件 process(\"PATH\").thread.begin 创建了一个用户空间下的线程 可以限定某个进程ID或可执行文件的路径，也可以不限定 process(\"PATH\").end 销毁了一个用户空间下的进程 可以限定某个进程ID或可执行文件的路径，也可以不限定 process(\"PATH\").thread.end 销毁了一个用户空间下的线程。你可以限定某个进程ID或可执行文件的路径。 process(\"PATH\").syscall 一个用户空间进程调用了系统调用 可以通过上下文变量$syscall获取系统调用号 还可以通过$arg1到$arg6分别获取前六个参数 添加.return后缀后会捕获退出系统调用的事件 在syscall.return中，可以通过上下文变量$return获取返回值 可以用某个进程ID或可执行文件的路径进行限定 # java Hotspot 虚拟机，静态探测点 probe hotspot.gc_begin = process(\"/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/lib/amd64/server/libjvm.so\").mark(\"gc__begin\") ","date":"2020-01-11","objectID":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:1:0","tags":["Linux 性能调优"],"title":"3.4 Systemtap 用户空间探测","uri":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"3.目标变量 访问用户空间目标变量，所用的语法与访问内核空间目标变量的语法相同。同样的对于指向基本类型（如整数和字符串）的指针，可以使用下列的函数访问用户空间的数据。这些函数都是在process(PATH).xxx事件的处理程序中使用的 函数 作用 user_char(address) 从用户空间地址中获取char变量 user_short(address) user_long(address) user_int(address) user_string(address) user_string_n(address, n) 从用户空间地址中获取长为n的字符串 ","date":"2020-01-11","objectID":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:2:0","tags":["Linux 性能调优"],"title":"3.4 Systemtap 用户空间探测","uri":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"4. 用户空间栈回溯 pp（probe point）函数可以返回触发当前处理程序的事件名（包含展开了的通配符和别名）。如果该事件与特定的函数相关，pp的输出会包括触发了该事件的函数名。 许多情况下触发同一个事件的函数可能来自于程序中不同的模块；特别是在该函数位于某个共享库的情况下。还好SystemTap提供了用户空间栈的回溯（backtrace）功能，便于查看事件是怎么被触发的。 编译器优化代码时会消除栈帧指针（stack frame pointers），这将混淆用户空间栈回溯的结果。所以要想查看栈回溯，需要有编译器生成的调试信息。 SystemTap用户空间栈回溯机制可以利用这些调试信息来重建栈回溯的现场。要想使用这些调试信息来重建栈回溯，给可执行文件加上-d executable选项，并给共享库加上-ldd选项。 # 需要安装 coreutils的debuginfo stap -d /bin/ls --ldd \\ -e 'probe process(\"ls\").function(\"xmalloc\") {print_usyms(ubacktrace())}' \\ -c \"ls /\" 关于在用户空间栈回溯中可用的函数的更多内容，请查看ucontext-symbols.stp和ucontext-unwind.stp两个tapset。上述tapset中的函数的描述信息也可以在SystemTap Tapset Reference Manual找到。 ","date":"2020-01-11","objectID":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:3:0","tags":["Linux 性能调优"],"title":"3.4 Systemtap 用户空间探测","uri":"/posts/linux/linux_perf/14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"3.3 Systemtap 内核空间探测","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"本节我们继续来学习 Systemtap 的使用 – 内核的动态追踪 ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:0:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"1. 内核变量的获取 本节我们来看如何获取内核空间中的变量，包括: 目标变量获取 全局以及静态变量获取 内置的便捷变量 ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:1:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"2. 内核变量获取 跟内核代码相关的事件，如kernel.function(“function”)和kernel.statement(“statement”)，允许使用目标变量获取这部分代码中可访问到的变量的值。stap -L 可以列出特定探测点下可用的目标变量。 \u003e stap -L `kernel.function(\"vfs_read\")` kernel.function(\"vfs_read@fs/read_write.c:277\") $file:struct file* $buf:char* $count:size_t $pos:loff_t* stap -L 输出的每个目标变量前面都以$开头，并以:加变量类型结尾。上面的输出表示，vfs_read函数入口处有4个变量可用: $file（指向描述文件的结构体） $buf（指向接收读取的数据的用户空间缓冲区） $count（读取的字节数） $pos（读开始的位置） 下面使用目标变量的一个示例: \u003e stap -L 'syscall.read' stap -L 'syscall.read' syscall.read name:string fd:long buf_uaddr:long count:long argstr:string $fd:long int $buf:long int $count:long int $ret:long int probe syscall.read.return { p = pid() fd = $fd # 引用目标变量 bytes = $return time = gettimeofday_us() - @entry(gettimeofday_us()) if (bytes \u003e 0) fileread[p, fd] += bytes time_io[p, fd] \u003c\u003c\u003c time } ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:2:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"2.全局变量获取 对于那些不属于本地变量的变量，像是全局变量或一个在文件中定义的静态变量，可以用@var(\"varname@src/file.c\")获取。 SystemTap会保留目标变量的类型信息，并且允许通过-\u003e访问其中的成员。 -\u003e既可以用来访问指针指向的值，也可以用来访问子结构体中的成员。在获取复杂结构体中的信息时，-\u003e可以链式使用。下面是一个获取 fs/file_table.c中的静态目标变量files_stat 的示例，files_stat存储着一些当前文件系统中可调节的参数。 probe kernel.function(vfs_read) { printf(\"current file_stat max_files: %d\\n\", @var(\"file_stat@fs/file_table.c\")-\u003emax_files) exit() } 有许多函数可以通过指向基本类型的指针获取内核空间对应地址上的数据： 函数 作用 kernel_char(address) 从内核空间地址中获取char变量 kernel_short(address) kernel_long(address) kernel_int(address) kernel_string(address) kernel_string_n(address, n) 从内核空间地址中获取长为n的字符串 ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:3:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"3. 内置变量 某些场景中，我们可能需要输出当前可访问的各种变量，以便于记录底层的变化。SystemTap提供了一些操作，可以生成描述特定目标变量的字符串： $$vars: 输出作用域内每个变量的值 等同于 sprintf(\"parm1=%x ... parmN=%x var1=%x ... varN=%x\", parm1, ..., parmN, var1, ..., varN) $$locals: 同$$vars，只输出本地变量 $$parms: 同$$vars，只输出函数入参。 $$return: 仅在带return的探针中可用 如果被监控的函数有返回值，它等价于sprintf(“return=%x”, $return)，否则为空字符串。 \u003e stap -e 'probe kernel.function(\"vfs_read\") {printf(\"%s\\n\", $$parms); exit(); }' # vfs_read的入参有四个：file，buf，count，和pos # $$params会给这些入参生成描述字符串。在这个例子里，四个变量都是指针 file=0xffff8800b40d4c80 buf=0x7fff634403e0 count=0x2004 pos=0xffff8800af96df48 # 要想输出指针指向的值，我们可以加上$后缀 \u003e stap -e 'probe kernel.function(\"vfs_read\") {printf(\"%s\\n\", $$parms$); exit(); }' file={.f_u={...}, .f_path={...}, .f_op=0xffffffffa06e1d80, .f_lock={...}, .... # 要想展开嵌套的结构体，你需要使用$$后缀。下面是一个使用$$的例子： # $$的输出，会受到字符串最长长度的限制而被截断 \u003e stap -e 'probe kernel.function(\"vfs_read\") {printf(\"%s\\n\", $$parms$$); exit(); }' ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:4:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"4. 如何使用 tapset tapset 是 systemtap 提供的函数库，提供了: 可用的内置函数 对于常见的目标变量，已将其提取为直接可用的内置变量。 我们以 ioblock 为例，来看看如何使用 tapset。 \u003e /usr/share/systemtap/tapset/linux/ioblock.stp /** * probe ioblock.request - Fires whenever making a generic block I/O request. * * @name - name of the probe point * @devname - block device name * @ino - i-node number of the mapped file * @sector - beginning sector for the entire bio * @flags - see below * BIO_UPTODATE 0 ok after I/O completion * BIO_RW_BLOCK 1 RW_AHEAD set, and read/write would block * BIO_EOF 2 out-out-bounds error * BIO_SEG_VALID 3 nr_hw_seg valid * BIO_CLONED 4 doesn't own data * BIO_BOUNCED 5 bio is a bounce bio * BIO_USER_MAPPED 6 contains user pages * BIO_EOPNOTSUPP 7 not supported * * @rw - binary trace for read/write request * @vcnt - bio vector count which represents number of array element (page, offset, length) which make up this I/O request * @idx - offset into the bio vector array * @phys_segments - number of segments in this bio after physical address coalescing is performed * @hw_segments - number of segments after physical and DMA remapping hardware coalescing is performed * @size - total size in bytes * @bdev - target block device * @bdev_contains - points to the device object which contains the partition (when bio structure represents a partition) * @p_start_sect - points to the start sector of the partition structure of the device * * Context: * The process makes block I/O request */ probe ioblock.request = kernel.function (\"generic_make_request\") { name = \"ioblock.request\" devname = __bio_devname($bio) ino = __bio_ino($bio) sector = $bio-\u003ebi_sector flags = $bio-\u003ebi_flags rw = $bio-\u003ebi_rw vcnt = $bio-\u003ebi_vcnt idx = $bio-\u003ebi_idx phys_segments = $bio-\u003ebi_phys_segments hw_segments = (@defined($bio-\u003ebi_hw_segments) ? $bio-\u003ebi_hw_segments : 0) size = $bio-\u003ebi_size bdev = $bio-\u003ebi_bdev bdev_contains = $bio-\u003ebi_bdev-\u003ebd_contains p_start_sect = __bio_start_sect($bio) } 说明: 上面是 ioblock.stp 内容的一部分 probe ioblock.request 将常用的目标变量定义成了直接可用内部变量，eg: 通过 devname，我们可以直接获取设备名称，而不需要通过目标变量去获取 __bio_ino 是 ioblock.stap 内定义的函数，但是 __ 开头的属于内置函数不能使用。 stap -ve 'probe ioblock.request {printf(\"%s,%s\\n\", \"devname: \", devname)}' ","date":"2020-01-10","objectID":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/:5:0","tags":["Linux 性能调优"],"title":"3.3 Systemtap 内核空间探测","uri":"/posts/linux/linux_perf/13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B/"},{"categories":["Linux"],"content":"3.2 stap 脚本","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"本节我们来看看 stap 脚本的基本语法。 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:0:0","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"1. Systemtap 执行细节 SystemTap脚本运行时，会启动一个对应的SystemTap会话。整个会话大致流程如下： 首先，SystemTap会检查脚本中用到的tapset，确保它们都存在于tapset库中（通常是/usr/share/systemtap/tapset/） SystemTap会把找到的tapset替换成在tapset库中对应的定义 tapset是tap（听诊器）的集合，指一些预定义的SystemTap事件或函数 SystemTap接着会把脚本转化成C代码，运行系统的C编译器编译出一个内核模块。 SystemTap随即加载该模块，并启用脚本中所有的探,这一步由system-runtime包的staprun完成 每当被监控的事件发生，对应的处理程序就会被执行。 一旦SystemTap会话终止，探针会被禁用，内核模块也会被卸载。 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:1:0","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"1.1 tapsets tapsets是一些包含常用的探针和函数的内置脚本，你可以在SystemTap脚本中复用它们。当用户运行一个SystemTap脚本时，SystemTap会检测脚本中的事件和处理程序，并在翻译脚本成C代码之前，加载用到的tapset。 与 SystemTap脚本一样，tapset的拓展名也是.stp。默认情况下tapset位于/usr/share/systemtap/tapset/。跟SystemTap脚本不同的是，tapset不能被直接运行；它只能作为库使用。 tapset库让用户能够在更高的抽象层次上定义事件和函数。tapset提供了一些常用的内核函数的别名，这样用户就不需要记住完整的内核函数名了（尤其是有些函数名可能会因内核版本的不同而不同）。另外tapset也提供了常用的辅助函数，比如下面将介绍的 thread_indent()。 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:1:1","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"1.2 SystemTap脚本 SystemTap脚本由两部分组成：事件和处理程序。一旦SystemTap会话准备就绪，SystemTap会监控操作系统中特定的事件，并在事件发生的时候触发对应的处理程序。 一个事件和它对应的处理程序合称探针。一个SystemTap脚本可以有多个探针。 一个探针的处理程序部分通常称之为探针主体（probe body） 下面是一个 Systemtap 脚本的简单示例。需要注意的是 SystemTap脚本会一直运行，直到执行了exit()函数。如果你想中途退出一个脚本，可以用Ctrl+c中断 probe begin { printf (\"hello world\\n\") exit () } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:1:2","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2. SystemTap脚本的基本语法 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:0","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.1 Systemtap 探针定义 SystemTap脚本的后缀是.stp，并以这样的语句表示一个探针：probe event,event1 {statment} # 1. 定义探针 # 一个探针指定多个事件；每个事件以逗号隔开 # 语句块由花括号（{}）括住，语句间通常不需要特殊的分隔符或终止符 probe event,event1 {statment} ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:1","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.2 Systemtap 事件 SystemTap事件大致分为两类：同步事件和异步事件。 同步事件会在任意进程执行到内核特定位置时触发。 syscall.system_call: 作用: 名为 system_call 的系统调用的调用事件 syscall.system_call.return: .return 表示 system_call 系统调用的退出事件 vfs.file_operation: 作用: 进入虚拟文件系统（VFS）名为file_operation的文件操作 vfs.file_operation.return: .return 表示 file_operation 的退出事件 file_operation取值的范畴，取决于当前内核中struct file_operations的定义的操作（可能位于include/linux/fs.h中，不同版本位置不同，建议上http://lxr.free-electrons.com/ident 查找 kernel.function(\"func_name@file_name[:line_num]\"): 作用: 内核调用和返回事件 参数: func_name: 函数名，可使用 * 通配 file_name: 文件名 [:line_num]: 指定行号，可选，如从行x到y，使用:x-y这样格式作为行号 eg: kernel.function(“sys_open”)即内核函数sys_open被调用时所触发的事件 eg: kernel.function(“sys_open”)即内核函数sys_open被调用时所触发的事件 eg: kernel.function(\"*@net/socket.c\"): net/socket.c中的所有函数的调用事件 kernel.trace(\"tracepoint\"): 作用: 跟踪内核的静态探测点。 表示到达名为tracepoint的静态内核探测点 eg: kernel.trace(“kfree_skb”)表示内核释放了一个网络缓冲区的事件 sudo perf list: 列出所有的静态内核探测点 module(\"module\").function(\"function\") 作用: 进入指定模块module的function函数 eg: module(\"ext3\").function(\"*\") 表示 ext3 模块中的每个函数调用 系统内的所有内核模块通常都在/lib/modules/$(uname -r) find -name '*.ko' -printf '%f\\n' | sed 's/\\.ko$//': 列出所有的内核模块 除了上面的这些基础事件，Systemtap 按照特定的功能集合，创建了不同的 tapset，常见的包括: 6. ioblock: - 作用: 块设备接口和 I/O 调度器 7. scheduler: - 作用: 内核 CPU 调度器事件 8. memeory: - 进程和虚拟内存的使用 9. scsi: - 作用: SCSI 目标的事件 10. networking: - 作用: 网络设备事件，包括接收和传输 11. tcp - 作用: TCP 协议事件，包括发送和接收事件 12. socket - 作用: 套接字事件 异步事件跟特定的指令或代码的位置无关。 这部分事件主要包含计数器、定时器和其它类似的东西 begin: 作用: SystemTap会话的启动事件，会在脚本开始时触发 end: 作用: SystemTap会话的结束事件，会在脚本结束时触发。 timer events 作用: 用于周期性执行某段处理程序 说明: 定时事件总是跟其它事件搭配使用。其它事件负责收集信息，而定时事件定期输出当前状况，让你看到数据随时间的变化情况。 eg: probe timer.s(4) { printf(\"hello world\\n\") }: 每隔4秒就会输出hello world 其它规格的定时器: timer.ms(milliseconds) timer.us(microseconds) timer.ns(nanoseconds) timer.hz(hertz) timer.jiffies(jiffies): jiffies 表示时钟中断 timer.profile: 按照内核时钟频率对所有 CPU 都触发的探针，用于采样/剖析 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:2","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.3 函数 内置函数 函数 作用 printf 格式化输出 execname 获取触发事件的进程名，下面将触发时间发生的进程称为当前进程 pid 当前进程ID tid 当前线程ID uid 当前进程的UID cpu 当前CPU gettimeofday_s 自epoch以来的秒数 ctime 将 gettimeofday_s 返回的秒数转化成时间字符串 pp 返回描述当前处理的探测点的字符串 thread_indent 打印空白，组织输出，以反映函数的调用次序和调用层级 name 返回系统调用的名字。只能在syscall.system_call触发的处理程序中使用 target 返回 -x PID 或 -c command 指定的PID或命令名 自定义函数 SystemTap允许你编写函数来提取探针间公共的逻辑，函数的定义和使用如下所示: # 函数定义 function function_name(arguments) {statements} # 函数使用 # arguments是传递给函数的可选的入参 probe event {function_name(arguments)} 下面是Systemtap 脚本的使用示例: # 示例1 probe syscall.open { printf (\"%s(%d) open\\n\", execname(), pid()) } # 示例2 probe kernel.function(\"*@net/socket.c\").call { printf (\"%s -\u003e %s\\n\", thread_indent(1), probefunc()) } probe kernel.function(\"*@net/socket.c\").return { printf (\"%s \u003c- %s\\n\", thread_indent(-1), probefunc()) } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:3","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.4 变量定义 下面是 Systemtap 脚本内使用变量的一个示例，通过示例可以发现: global 用于定义全局变量，可在所有探针内使用 探针内的局部变量(eg: hz) 仅限探针内使用 SystemTap可以自动判定变量的类型，且属于强类型语言 # 计算内核的CONFIG_HZ配置 global count_jiffies, count_ms probe timer.jiffies(100) { count_jiffies ++ } probe timer.ms(100) { count_ms ++ } probe timer.ms(12345) { hz=(1000*count_jiffies) / count_ms printf (\"jiffies:ms ratio %d:%d =\u003e CONFIG_HZ=%d\\n\", count_jiffies, count_ms, hz) exit () } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:4","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.5 关联数组 关联数组即字典，Systemtap 中关联数组需要定义为全局变量。在一个数组语句中你最多可以指定九个表达式，每个表达式间以,隔开。这样做可以给单个键附加多个信息。 # 1. 数组赋值 foo[\"tom\"] = 23 foo[\"dick\"] = 24 foo[\"harry\"] = 25 # 2. 数组读取 # 如果数组中没有对应的键，默认情况下在数值计算中返回 0，在字符串操作中返回空字符串 printf(\"%s\", foo[\"harry\"]) # 3. 删除数组和数组中的元素 delete foo delete foo['tom'] # 4. 数组的键可以指定多个表达式 device[pid(),execname(),uid(),ppid(),\"W\"] = devname global reads probe vfs.read { reads[execname(),pid()] \u003c\u003c\u003c 1 } probe timer.s(3) { foreach([var1,var2] in reads) printf(\"%s (%d) : %d \\n\", var1, var2, @count(reads[var1,var2])) } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:5","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.6 条件与循环 SystemTap支持C风格的条件语句，另外对于数组还支持foreach (VAR in ARRAY) {}形式的遍历。 # 1. if 条件 probe syscall.*{ if (pid() == target()) printf(\"if condition\") } # 2. 判断键是否在数组中 if (index_expression in array_name) # 3. foreach 循环 global reads probe vfs.read { reads[execname()] ++ } probe timer.s(3) { foreach (count in reads) printf(\"%s : %d \\n\", count, reads[count]) } # 4. foreach 遍历控制 # 可以给数组名加个后缀+来表示按升序遍历，或-按降序遍历。 # 可以用limit加一个数字来限制迭代的次数 probe timer.s(3) { foreach (count in reads- limit 10) printf(\"%s : %d \\n\", count, reads[count]) } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:6","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.7 聚合变量 聚合变量用于实现对数据的流式处理，其可以是全局变量，也可以是数组中的值。使用«\u003c运算符可以往聚集变量中添加新数据。 global reads probe vfs.read { reads[execname()] \u003c\u003c\u003c $count } 在上面示例中: $count的值是一段时间内当前进程的读次数 «\u003c会把$count的值存储到reads数组execname()关联的聚集变量中 «\u003c 是把值存储在聚集变量里面；它们既没有加到原来的值上，也没有覆盖掉原来的值,就像是reads数组值每个键都有多个关联的值 要想从聚集变量中获取汇总的结果，使用这样的语法@extractor(variable/array_index _expression), eg： @sum(reads[execname()])。extractor可以取以下的函数： @count @sum @min @max @avg global reads probe vfs.read { reads[execname(),pid()] \u003c\u003c\u003c 1 } probe timer.s(3) { foreach([var1,var2] in reads) printf(\"%s (%d) : %d \\n\", var1, var2, @count(reads[var1,var2])) } ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:7","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.8 命令行参数 通过$或@加个数字的形式可以访问对应位置的命令行参数 $会把用户输入当作整数，eg: $1,$2 @会把用户输入当作字符串, eg: @1,@2 ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:8","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"2.9 @表示的操作符 在Systemtap 中 @cast,@entry，表示的是一个操作符，操作符就是我们程序中的 “\u003c\u003e=\u0026” 等等操作: @cast 表示的是一个类型转换的操作符 @entry 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值 @hist_log,@count 等等，都是用来操作聚合变量的操作符 下面是 @entry 的一个使用示例 \u003e stap2: 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值 \u003e stap -ve 'global s; probe syscall.read.return {if (execname() == \"mysqld\") {s \u003c\u003c\u003c gettimeofday_ns() - @entry(gettimeofday_ns());}} probe end{print(@hist_log(s))}' ","date":"2020-01-09","objectID":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/:2:9","tags":["Linux 性能调优"],"title":"3.2 stap 脚本","uri":"/posts/linux/linux_perf/12_stap%E8%84%9A%E6%9C%AC/"},{"categories":["Linux"],"content":"3.1 Systemp 简介","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"从今天开始我们将学习第一个可编程的动态追踪工具 Systemtap。本节是 Systemtap 的一个基本介绍。 ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:0:0","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1. Systemtap 简介 动态追踪技术起源于 Solaris 系统的 DTrace。Dtrace 有 Linux Mac OS X 等系统的移植版，但是实现的都差强人意，不支持很多高级特性。Systemtap 是 Redhat 开源的 Linux 上的动态追踪工具，是 Linux 上目前最成熟的动态追踪框架。 ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:1:0","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.1 Systemtap 框架 Systemtap 的框架如上图所示: Systemtap 并不是 Linux 内核的一部分，因此第一步需要把 Systemtap 自己的“小语言”脚本（有点像 D 语言）动态编译成一个 Linux 内核模块的 C 源码，并加载到内核才能运行 Systemtap 使用的我们前面介绍的内核工具框架 DWARF 是Linux的调试符号表格式 整个SystemTap脚本所做的，无非就是声明感兴趣的事件，然后添加对应的处理程序。当SystemTap脚本运行时，SystemTap会监控声明的事件；一旦事件发生，Linux内核会临时切换到对应的处理程序，完成后再重拾原先的工作。 可供监控的事件种类繁多：进入/退出某个函数，定时器到期，会话终止，等等。处理程序由一组SystemTap语句构成，指明事件发生后要做的工作。其中包括从事件上下文中提取数据，存储到内部变量中，输出结果。 ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:1:1","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.2 Systemtap 的优缺点 Systemtap 有如下的优缺点: 首先，它并不是 Linux 内核的一部分，就是说它并没有与内核紧密集成，所以它需要一直不停地追赶主线内核的变化。 另一个缺点是，它需要动态编译，因此经常需要在线部署 C 编译器工具链和 Linux 内核的头文件。出于这些原因，SystemTap 脚本的启动相比 DTrace 要慢得多 无论是 DTrace 还是 SystemTap，其实都不支持编写完整的调试工具，因为它们都缺少方便的命令行交互的原语。所以我们才看到现实世界中许多基于它们的工具，其实最外面都有一个 Perl、Python 或者 Shell 脚本编写的包裹。比如 stap++ SystemTap 的优点是它有非常成熟的用户态调试符号的自动加载，同时也有循环这样的语言结构可以去编写比较复杂的探针处理程序，可以支持很多很复杂的分析处理。 GitHub 上面，有很多针对像 Nginx、LuaJIT 和操作系统内核这样的系统软件，也有一些是针对更高层面的像 OpenResty 这样的 Web 框架。有兴趣的朋友可以查看 GitHub 上面的 nginx-systemtap-toolkit、perl-systemtap-toolkit 和 stappxx 这几个代码仓库。 ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:1:2","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. stap 安装 SystemTap需要内核信息，这样才能注入指令。此外，这些信息还能帮助SystemTap生成合适的检测代码。 这些必要的内核信息分别包括在特定内核版本所对应的-devel，-debuginfo和-debuginfo-common包中。对于“标准版”内核（指按照常规配置编译的内核），所需的-devel和-debuginfo等包命名为： kernel-debuginfo kernel-debuginfo-common kernel-devel: 通常已经安装 下面是Centos7 安装过程的示例： # 方法一，直接执行 stap-prep，如果不起作用，需要手动安装方法二中的包 stap-prep ## 方法二 # 1. 配置yum 源 [debug] name=CentOS-$releasever - DebugInfo baseurl=http://debuginfo.centos.org/$releasever/$basearch/ gpgcheck=0 enabled=1 protect=1 priority=1 # 2.安装 kernel-debuginfo yum --enablerepo=debug install -y kernel-debuginfo-$(uname -r) # 3. rpm 包位置，可直接下载手动 yum install http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-3.10.0-957.el7.x86_64.rpm http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-3.10.0-957.el7.x86_64.rpm http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-3.10.0-1062.el7.x86_64.rpm http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-3.10.0-1062.el7.x86_64.rpm ## 4. 运行下面命令开始检查，显示 pass 5 表示运行成功 stab-prep stap -v -e 'probe vfs.read {printf(\"read performed\\n\"); exit()}' Pass 1: parsed user script and 474 library scripts using 251936virt/49240res/3488shr/45992data kb, in 80usr/330sys/411real ms. Pass 2: analyzed script: 1 probe, 1 function, 7 embeds, 0 globals using 416832virt/210188res/4872shr/210888data kb, in 1100usr/960sys/2058real ms. Pass 3: translated to C into \"/tmp/stapdYWPVH/stap_5e2f013414e74a4de164b8e5c7459ef6_2765_src.c\" using 416832virt/210444res/5128shr/210888data kb, in 10usr/70sys/85real ms. Pass 4: compiled C into \"stap_5e2f013414e74a4de164b8e5c7459ef6_2765.ko\" in 1090usr/660sys/1643real ms. Pass 5: starting run. read performance Pass 5: run completed in 10usr/70sys/373real ms. ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:2:0","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 为其他计算机生成检测模块 为了避免为所有带监测机器配置 Systemtap 环境的问题，SystemTap提供了交叉检测（cross-instrumentaion）的功能: 在一台计算机上运行SystemTap脚本，生成在另一台机器上可用的SystemTap检测模块 目标机器仅需安装 systemtap-runtime 来使用生成的SystemTap检测模块 创建和分发的过程如下: # 1. 创建检测模块 stap -r kernel_version script -m module_name \u003e stap -r `uname -r` -e 'probe vfs.read {printf(\"read performance\\n\"); exit()}' -m test \u003e ll test.ko -rw-r--r-- 1 root root 97392 4月 9 10:23 test.ko # 2. 分发运行检测模块 \u003e staprun test.ko ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:2:1","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"3. stap stap 作用: 从SystemTap脚本中读取探测指令，把它们转化为C代码，构建一个内核模块，并加载到当前的Linux内核中运行 参数: -v 让SystemTap会话输出更加详细的信息.重复该选项多次来提高执行信息的详尽程度 -o file_name: 将输出重定向到file_name -S size[,count]: 将输出文件的最大大小限制成sizeMB，存储文件的最大数目为count -x process_id: 设置SystemTap处理函数target()为指定PID，target() 是 systemtap 脚本的内置函数 -c 'command': 运行command，并在command结束时退出。同时会把target()设置成command运行时的PID -e script: 直接执行给定的脚本 -F: 进入SystemTap的飞行记录仪模式，并在后台运行该脚本 man: man probe::ioblock.request ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:3:0","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"3.1 stap 飞行记录模式 SystemTap的飞行记录仪模式允许你长时间运行一个SystemTap脚本，并关注最新的输出。飞行记录仪模式会限制输出的生成量。 飞行记录仪模式还可以分成两种：内存型（in-memory）和文件型（file）。无论哪一种 SystemTap脚本都是作为后台进程运行。 内存型: 有 -F 选项，但没有指定 -o 选项时启用，SystemTap会把脚本输出结果存储在内核内存的缓冲区内。默认情况下，缓冲区大小为1MB.你可以使用-s(小s)来调整这个值 \u003e stap -F iotime.stp Disconnecting from systemtap module. To reconnect, type \"staprun -A stap_5dd0073edcb1f13f7565d8c343063e68_19556\" # 重连，得到输出结果 \u003e staprun -A stap_5dd0073edcb1f13f7565d8c343063e68_19556 文件型 同时指定 -F,-o 选项时启用，-S选项来控制输出文件的大小和数目-S选项来控制输出文件的大小和数目。 \u003e stap -F -o /tmp/pfaults.log -S 1,2 pfaults.stp 7590 # stap 进程的 PID # 终止 stap 进程 \u003e kill -s SIGTERM 7590 ","date":"2020-01-08","objectID":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/:3:1","tags":["Linux 性能调优"],"title":"3.1 Systemp 简介","uri":"/posts/linux/linux_perf/11_stap%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.6 eBPF","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"今天我们来讲第二动态追踪技术 eBPF，eBPF 就是 Linux 版的 DTrace，可以通过 C 语言自由扩展。 ","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/:0:0","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"1. eBPF 简介 eBPF 的工作原理如下图所示: eBPF 通过 C 语言自由扩展（这些扩展通过 LLVM 转换为 BPF 字节码后，加载到内核中执行。从图中你可以看到，eBPF 的执行需要三步： 从用户跟踪程序生成 BPF 字节码； 加载到内核中运行； 向用户空间输出结果。 实际上，在 eBPF 执行过程中，编译、加载还有 maps 等操作，对所有的跟踪程序来说都是通用的。把这些过程通过 Python 抽象起来，也就诞生了 BCC（BPF Compiler Collection）。 BCC 把 eBPF 中的各种事件源（比如 kprobe、uprobe、tracepoint 等）和数据操作（称为 Maps），也都转换成了 Python 接口（也支持 lua）。这样，使用 BCC 进行动态追踪时，编写简单的脚本就可以了。 不过要注意，因为需要跟内核中的数据结构交互，真正核心的事件处理逻辑，还是需要我们用 C 语言来编写。 ","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/:1:0","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"1.1 bcc 安装 # REHL 7.6 $ yum install bcc-tools # 安装后，BCC 会把所有示例（包括 Python 和 lua），放到 /usr/share/bcc/examples 目录中 $ ls /usr/share/bcc/ exampleshello_world.py lua networking tracing ","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/:1:1","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"1.2 eBPF 与 Systemtap 在 eBPF 出现之前，SystemTap 是 Linux 系统中，功能最接近 DTrace 的动态追踪机制。SystemTap 在很长时间以来都游离于内核之外（而 eBPF 自诞生以来，一直根植在内核中。从稳定性上来说，SystemTap 只在 RHEL 系统中好用，在其他系统中则容易出现各种异常问题。当然，反过来说，支持 3.x 等旧版本的内核，也是 SystemTap 相对于 eBPF 的一个巨大优势。 ","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/:1:2","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"2. eBPF 编码示例 接下来，以 do_sys_open 为例，我们一起来看看，如何用 eBPF 和 BCC 来动态跟踪 do_sys_open 系统调用。 如下面的代码所示，通常我们可以把 BCC 应用，拆分为下面这四个步骤。 第一，跟所有的 Python 模块使用方法一样，在使用之前，先导入要用到的模块 BPF 第二，需要定义事件以及处理事件的函数。这个函数需要用 C 语言来编写，作用是初始化刚才导入的 BPF 对象。这些用 C 语言编写的处理函数，要以字符串的形式送到 BPF 模块中处理： 定义一个输出函数，并把输出函数跟 BPF 事件绑定 最后一步，就是执行事件循环，开始追踪 do_sys_open 的调用 # 1. 导入模块 from bcc import BPF # 2. 定义事件以及处理事件的函数 # define BPF program (\"\"\" is used for multi-line string). # '#' indicates comments for python, while '//' indicates comments for C. prog = \"\"\" #include \u003cuapi/linux/ptrace.h\u003e #include \u003cuapi/linux/limits.h\u003e #include \u003clinux/sched.h\u003e // define output data structure in C struct data_t { u32 pid; u64 ts; char comm[TASK_COMM_LEN]; char fname[NAME_MAX]; }; BPF_PERF_OUTPUT(events); // define the handler for do_sys_open. // ctx is required, while other params depends on traced function. int hello(struct pt_regs *ctx, int dfd, const char __user *filename, int flags){ struct data_t data = {}; data.pid = bpf_get_current_pid_tgid(); data.ts = bpf_ktime_get_ns(); if (bpf_get_current_comm(\u0026data.comm, sizeof(data.comm)) == 0) { bpf_probe_read(\u0026data.fname, sizeof(data.fname), (void *)filename); } events.perf_submit(ctx, \u0026data, sizeof(data)); return 0; } \"\"\" # load BPF program b = BPF(text=prog) # attach the kprobe for do_sys_open, and set handler to hello b.attach_kprobe(event=\"do_sys_open\", fn_name=\"hello\") # 3. 定义一个输出函数，并把输出函数跟 BPF 事件绑定 # process event start = 0 def print_event(cpu, data, size): global start # event’s type is data_t event = b[\"events\"].event(data) if start == 0: start = event.ts time_s = (float(event.ts - start)) / 1000000000 print(\"%-18.9f %-16s %-6d %-16s\" % (time_s, event.comm, event.pid, event.fname)) # loop with callback to print_event b[\"events\"].open_perf_buffer(print_event) # 4. 就是执行事件循环，开始追踪 do_sys_open 的调用 # print header print(\"%-18s %-16s %-6s %-16s\" % (\"TIME(s)\", \"COMM\", \"PID\", \"FILE\")) # start the event polling loop while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit() 通过这个简单的示例，你也可以发现，eBPF 和 BCC 的使用，其实比 ftrace 和 perf 有更高的门槛。想用 BCC 开发自己的动态跟踪程序，至少要熟悉 C 语言、Python 语言、被跟踪事件或函数的特征（比如内核函数的参数和返回格式）以及 eBPF 提供的各种数据操作方法。 BCC 软件包也内置了很多已经开发好的实用工具，默认安装到 /usr/share/bcc/tools/ 目录中，后面我们会详细介绍各个工具的使用。 ","date":"2020-01-07","objectID":"/posts/linux/linux_perf/08.ebpf/:2:0","tags":["Linux 性能调优"],"title":"2.6 eBPF","uri":"/posts/linux/linux_perf/08.ebpf/"},{"categories":["Linux"],"content":"2.5 Dtrace","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"今天我们来讲解第一个动态追踪技术 DTrace， 它是动态追踪技术的鼻祖 ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:0:0","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"1. Dtrace 简介 Solaris 系统的 DTrace 是动态追踪技术的鼻祖，它提供了一个通用的观测框架，并可以使用 D 语言进行自由扩展。 DTrace 的工作原理如下图所示。它的运行常驻在内核中，用户可以通过 dtrace 命令，把 D 语言编写的追踪脚本，提交到内核中的运行时来执行。 DTrace 本身依然无法在 Linux 中运行。很多工程师都尝试过把 DTrace 移植到 Linux 中，这其中，最著名的就是 RedHat 主推的 SystemTap。 ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:1:0","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"2. DTrace 语法 ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:2:0","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"2.1 探针 provider:module:function:name: provider: 相关探针的集合 module,function: 探针指示的代码位置的代号 name: 探针的名字 可以使用通配符，\"::\" == “:*:” provider DTrace 包含的 provider 如下所示: provider 作用 syscal 系统调用 vminfo 虚拟内存统计 sysinfo 系统统计 profile 任意频率的采样 sched 内核调度事件 proc 进程级别事件 io 块设备接口跟踪，即磁盘I/O pid 用户级别动态跟踪 tcp TCP协议事件，连接、发送和接收 ip IP 协议事件，发送和接收 fbt 内核级别动态追踪 高级语言的 provider 参数 探针通过一组称为参数的变量来提供数据。例如系统调用 syscal 给每一个系统调用都做了入口(entry)和返回(return)探针。这组参数变量如下: 入口: arg0….argN，表示系统调用的参数 返回: arg0 或 arg1，表示返回值，errno 也会设置 ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:2:1","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"2.2 D 语言 D 语言定义了DTrace 的语法。DTrace 语句如下: probe_description /predicate/ {action}: probe_description: 探针 predicate: 可选的过滤表达式 action: 探针触发时执行的操作，分号分隔的语句 proc:::exec-success /execname == \"httpd\"/ {trace{pid};} # exec-success 用于跟踪新进程的创建和系统调用 exec() 的执行 内置变量 内置变量用来计算和判断 变量 描述 execname 执行在CPU上的进程名 uid 执行在CPU上的用户ID pid 执行在CPU上的进程PID timestamp 自启动以来的纳秒数 vtimestamp CPU上的线程时间，单位是纳秒 arg0..N 探针参数(uint64_t) args[0]…[N] 探针参数(类型化的) curthread 指向当前线程内核结构的指针 probefunc 探针描述的函数组件 probename 当前探针名称 curpsinfo 当前进程信息 变量类型 类型 前缀 作用域 开销 多CPU安全 赋值示例 聚合变量 @ 全局 低 是 @x = count(); 带键聚合变量 @[] 全局 低 是 @x[pid] = count(); 从句局部变量 this-\u003e 从句实例 非常低 是 this-\u003ex = 1; 线程局部变量 self-\u003e 线程内 中等 是 self-\u003ex = 1; 标量 无 全局 中下 否 x = 1; 关联数组 无 全局 中上 否 x[y] = 1 说明: 线程局部变量: 作用域线程内，像时间戳这样的数据容易与线程关联 从句局部变量: 用于中间计算，只在针对同一探针描述的 action 子句有效 聚合变量: 可以由 CPU 单独计算汇总后在传递到用户空间 action action 作用 trace(arg) 打印arg printf(format, arg…) 格式化输出 stringof(addr) 返回来自内核空间的字符串 copyinstr(addr) 返回用户空间地址的字符串 内核会执行一次从用户空间到内核空间的复制 stack(count) 打印内核级别栈追踪，如果有 count 按 count 截断 ustack(count) 打印用户级别栈追踪，如果有 count 按 count 截断 func(pc) 从内核程序计数器，返回内核函数名 ufunc(pc) 从用户程序计数器，返回用户函数名 exit(status) 退出DTrace并返回状态 聚合变量的特有的 action action 作用 trunc(@agg, count) 截断聚合变量 删除全部键，或者按照 count 指定的键数目截断 clear(@agg) 删除聚合变量的值，键保留 printa(format, @agg) 格式化打印聚合变量 count() 发生计数 sum(value) value 求和 min(value) max(value) quantize(value) 用 2 的幂次方直方图统计 value lquantize(value,min,max,step) 用给定最下值，最大值和步进值做线性直方图记录 value # 显示系统调用 read(),返回的尺寸,使用2的幂次直方图显示 \u003e dtrace -n 'syscall::read:return { @[\"rval (bytes)\"] = quantize(arg0); }' # 跟踪系统调用 open()，打印进程名和文件路径名 \u003e dtrace -n 'syscall::open:entry { printf(\"%s, %s\", execname, copyinstr(arg0)); }' # 按进程名归纳所有的 CPU 交叉调用 \u003e dtrace -n 'sysinfo:::xcalls { @[execname] = count(); }' # 按 99Hz 采样内核级栈 \u003e dtrace -n 'profile:::profile-99 { @[stack()] = count() }' ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:2:2","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"2.3 DTrace 脚本 #!/usr/sbin/dtrace -s dtrace:::BEGIN { printf(\"Tracing .... Hit Ctrl-C to end. \\n\") } io:::start { this-size = arg[0]-\u003eb_bcount; @Size[pid, curpsinfo-\u003epr_psargs] = quantize(this-\u003esize) } dtrace:::END { printf(\"\\n%8s %s\\n\", \"PID\", \"CMD\") printa(\"%8d %S\\n%@d\\n\", @Size) } ","date":"2020-01-06","objectID":"/posts/linux/linux_perf/07.dtrace/:2:3","tags":["Linux 性能调优"],"title":"2.5 Dtrace","uri":"/posts/linux/linux_perf/07.dtrace/"},{"categories":["Linux"],"content":"2.4 perf 的使用","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"上一节我们学习了 perf 的基本原理，对 perf 有了一个整体上的认识，本节我们来学如何使用 perf 进行性能分析。 我们将按照如下几个部分来介绍 perf 的使用: perf 的辅助性命令，包括 perf list，perf probe 等 perf 的三种使用方式，计数模式，采样事件，以及事件上的 bp 程序 perf 提供的特殊用途的子命令，包括 perf sched，perf mem 等等 perf.data 的处理，这一部分命令用于格式化输出 perf.data 的内容便于生成类似火焰图等更复杂的图表 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:0:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"1. perf 命令概览 作为开始，我们先来回顾一下 perf 命令的一个概览 perf [--version] [--help] [OPTIONS] COMMAND [ARGS] 子命令 作用 list List all symbolic event types 列出当前系统支持的所有事件名,可分为三类：硬件事件、软件事件，检查点 probe Define new dynamic tracepoints 用于定义动态检查点 stat Run a command and gather performance counter statistics 对程序运行过程中的性能计数器进行统计 record Run a command and record its profile into perf.data 对程序运行过程中的事件进行分析和记录，并写入perf.data report Read perf.data (created by perf record) and display the profile 读取perf.data(由perf record生成) 并显示分析结果 top System profiling tool. 对系统的性能进行分析，类似top命令 sched Tool to trace/measure scheduler properties (latencies) 针对调度器子系统的分析工具 lock Analyze lock events 分析内核中的锁信息，包括锁的争用情况，等待延迟等 mem Profile memory accesses 分析内存访问 kmem Tool to trace/measure kernel memory properties 分析内核内存的使用 kvm Tool to trace/measure kvm guest os 分析kvm虚拟机上的guest os timechart Tool to visualize total system behavior during a workload 对record结果进行可视化分析输出，record命令需要加上timechart记录 script Read perf.data (created by perf record) and display trace output 读取perf.data(由perf record生成)，生成trace记录，供其他分析工具使用 data Data file related processing 把perf.data文件转换成其他格式 diff Read perf.data files and display the differential profile 读取多个perf.data文件，并给出差异分析 evlist List the event names in a perf.data file 列出perf.data中采集的事件列表 bench General framework for benchmark suites perf提供的基准套件的通用框架，可以对当前系统的调度，IPC，内存访问进行性能评估 test Runs sanity tests. perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能 trace strace inspired tool 类似于strace，跟踪目标的系统调用，但开销比strace小 ftrace simple wrapper for kernel ftrace functionality annotate Read perf.data (created by perf record) and display annotated code 读取perf.data(由perf record生成)显示反汇编后的代码 archive Create archive with object files with build-ids found in perf.data file 根据perf.data(由perf record生成)文件中的build-id将相关的目标文件打包 buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file c2c Shared Data C2C/HITM Analyzer. config Get and set variables in a configuration file. inject Filter to augment the events stream with additional information kallsyms Searches running kernel for symbols version display the version of perf binary ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:1:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"1. perf 辅助性命令 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:2:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"1.1 perf list perf list [--no-desc] [--long-desc] [event_class] 作用: 列出perf可以支持的所有事件 event_class: 事件的分类，包括: hw|sw|cache|pmu|sdt|metric|metricgroup tracepoint: 静态探针 event_glob: 事件的通配符 perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] bpf-output [Software event] context-switches OR cs [Software event] cpu-clock [Software event] cpu-migrations OR migrations [Software event] .......... perf list给出的事件是厂家上传上去给Linux社区的，但有些厂家会有自己的事件统计，没有上传出去，这需要从厂家的用户手册中获得，这种事件称为原始事件，可以直接用编号表示，格式为:rUUEE，其中UU == umask, EE ==事件编号。比如在我们的芯片里面，0x13号表示跨芯片内存访问，你就可以用-e r0013来跟踪软件的跨片访问次数。 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:2:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"1.2 perf probe perf probe 用来定义一个动态探针，定义的方式有如下几种: 用户空间: 通过 -x 指定二进制文件的路径，可以为该二进制程序添加库函数的动态探针 内核: 通过符号表和寄存器来添加，这种方式不需要内核调试信息(即 kernel-debuginfo) 通过 C 函数，C 函数中的特定行，并且可以附加函数上下文中的变量，这种方式需要内核调试信息。 命令使用 Usage: perf probe [\u003coptions\u003e] 'PROBEDEF' ['PROBEDEF' ...] or: perf probe [\u003coptions\u003e] --add 'PROBEDEF' [--add 'PROBEDEF' ...] or: perf probe [\u003coptions\u003e] --del '[GROUP:]EVENT' ... or: perf probe --list [GROUP:]EVENT ... or: perf probe [\u003coptions\u003e] --line 'LINEDESC' or: perf probe [\u003coptions\u003e] --vars 'PROBEPOINT' or: perf probe [\u003coptions\u003e] --funcs -a, --add \u003c[EVENT=]FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT [[NAME=]ARG ...]\u003e probe point definition, where GROUP: Group name (optional) EVENT: Event name FUNC: Function name OFF: Offset from function entry (in byte) %return: Put the probe at function return SRC: Source code path RL: Relative line number from function entry. AL: Absolute line number in file. PT: Lazy expression of line code. ARG: Probe argument (local variable name or kprobe-tracer argument format.) -D, --definition \u003c[EVENT=]FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT [[NAME=]ARG ...]\u003e Show trace event definition of given traceevent for k/uprobe_events. -d, --del \u003c[GROUP:]EVENT\u003e delete a probe event. -f, --force forcibly add events with existing name -F, --funcs \u003c[FILTER]\u003e Show potential probe-able functions. -L, --line \u003cFUNC[:RLN[+NUM|-RLN2]]|SRC:ALN[+NUM|-ALN2]\u003e -V, --vars \u003cFUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT\u003e Show accessible variables on PROBEDEF 添加动态探针 # 一: 基于 uprobes ，为用户空间库函数添加动态探针 # 想要查看普通应用的函数名称和参数，那么在应用程序的二进制文件中，同样需要包含调试信息。 # 为/bin/bash添加readline探针，获取其返回值，并作为 string 类型返回 $ perf probe -x /bin/bash 'readline' $ perf probe -x /bin/bash 'readline%return +0($retval):string' Added new event: probe_bash:readline__return (on readline%return in /usr/bin/bash with +0($retval):string) You can now use it in all perf tools, such as: perf record -e probe_bash:readline__return -aR sleep 1 # 查询所有的函数 $ perf probe -x /bin/bash --funcs # 查询函数的参数 $ perf probe -x /bin/bash -V readline Available variables at readline @\u003creadline+0\u003e char* prompt # 二: 基于 kprobes，为内核函数添加动态探针 # 1. 通过符号表和寄存器添加 malloc 探针 $ perf probe -x /lib64/libc-2.17.so '--add=malloc' $ perf probe --del \"malloc\" $ perf probe -x /lib64/libc-2.17.so '--add=malloc size=%di' # 2. 通过 C 扩展 $ yum --enablerepo=base-debuginfo install -y kernel-debuginfo-$(uname -r) $ perf probe --add tcp_sendmsg Added new event: probe:tcp_sendmsg (on tcp_sendmsg) You can now use it in all perf tools, such as: # 自动显示使用方式 perf record -e probe:tcp_sendmsg -aR sleep 1 # 获取 tcp_sendmsg 的返回值 $ perf probe 'tcp_sendmsg%return $retval' # 2.1 列出tcp_sendmsg()可用的变量 $ perf probe -V tcp_sendmsg Available variables at tcp_sendmsg @\u003ctcp_sendmsg+0\u003e size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk # 2.2 添加带参数的探针 $ perf probe --add 'tcp_sendmsg size' # 2.3 列出tcp_sendmsg()可用的行探测: $ perf probe -L tcp_sendmsg \u003ctcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0\u003e 0 int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg, size_t size) 2 { struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; 6 int iovlen, flags, err, copied = 0; 7 int mss_now = 0, size_goal, copied_syn = 0, offset = 0; bool sg; long timeo; [...] # 2.4 检查在第81行有哪些变量可用 $ perf probe -V tcp_sendmsg:81 Available variables at tcp_sendmsg:81 @\u003ctcp_sendmsg+537\u003e bool sg int copied int copied_syn int flags int mss_now int offset int size_goal long int timeo size_t seglen struct iovec* iov struct sock* sk unsigned char* from # 2.5. 跟踪第81行，并使用循环中的seglen变量 $ perf probe --add 'tcp_sendmsg:81 seglen' ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:2:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"2. perf stat(计数模式) perf stat 是 perf 三种使用模式中的第一种模式计数模式。 perf stat: 命令格式: perf stat [-e \u003cEVENT\u003e | --event=EVENT] [-a] \u003ccommand\u003e perf stat [-e \u003cEVENT\u003e | --event=EVENT] [-a] — \u003ccommand\u003e [\u003coptions\u003e] perf stat [-e \u003cEVENT\u003e | --event=EVENT] [-a] record [-o file] — \u003ccommand\u003e [\u003coptions\u003e] perf stat report [-i file] 作用: 可以对程序运行过程中的性能计数器(包括Hardware，software counters)进行统计，分析程序的整体消耗情况 参数: -d, -dd, -ddd 输出更详细的信息 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:3:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"2.1 perf stat 默认输出 默认情况 perf stat 只会对 Software Events 和 Hardware Events 进行计数分析。下面是 perf stat 的使用示例 $ perf stat ls Performance counter stats for 'ls': 2.164836 task-clock (msec) # 0.808 CPUs utilized 51 context-switches # 0.024 M/sec 4 cpu-migrations # 0.002 M/sec 333 page-faults # 0.154 M/sec 5506056 # 2.543 GHz 0 stalled-cycles-frontend # 0.00% frontend cycles idle 0 stalled-cycles-backend # 0.00% backend cycles idle 6100570 instructions # 1.11 insns per cycle 1298744 branches # 599.927 M/sec 18509 branch-misses # 1.43% of all branches 0.002679758 seconds time elapsed 指标含义: task-clock (msec): cpu处理task所消耗的时间，单位ms 0.808 CPUs utilized的表示cpu使用率为80.8%，该值越高代表程序是CPU bound而非IO bound 类型 instructions： 执行的指令条数， insns per cycle: 即IPC，每个cpu周期执行的指令条数，IPC比上面的CPU使用率更能说明CPU的使用情况 更高的IPC值意味着更高的指令吞吐量，更低的值表示更多的停顿周期。 一般来说，我认为IPC值越高(例如，超过1.0)就越好，表示工作的最佳处理。但是，需要检查执行指令是什么，以防这是一个旋转循环: 指令率高，但实际完成的工作率低。 stalled-cycles-frontend和stalled-cycles-backend: 表示CPU停滞统计 前端和后端指标指的是CPU管道，统计的是它们的停顿次数 前端按顺序处理CPU指令。它包括指令获取，以及分支预测和解码。 解码后的指令成为后端处理的微操作(uops)，并且可能会乱序地执行。 每条指令的停滞周期类似于IPC(反向)，但是，只计算停滞周期，这将用于内存或资源总线访问。 branches：这段时间内发生分支预测的次数。现代的CPU都有分支预测方面的优化。 branches-misses：这段时间内分支预测失败的次数，这个值越小越好。 详细模式 可以使用 -d 选项输出更详细的信息，带 -d 选项的输出会包含用于一级数据缓存事件和最后一级缓存(LLC)事件的额外计数器。-dd,-ddd可输出更加详细的信息。 $ perf stat -d gzip file1 Performance counter stats for 'gzip file1': 1610.719530 task-clock # 0.998 CPUs utilized 20 context-switches # 0.012 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.160 K/sec 5,491,605,997 cycles # 3.409 GHz [40.18%] 1,654,551,151 stalled-cycles-frontend # 30.13% frontend cycles idle [40.80%] 1,025,280,350 stalled-cycles-backend # 18.67% backend cycles idle [40.34%] 8,644,643,951 instructions # 1.57 insns per cycle # 0.19 stalled cycles per insn [50.89%] 1,492,911,665 branches # 926.860 M/sec [50.69%] 53,471,580 branch-misses # 3.58% of all branches [51.21%] 1,938,889,736 L1-dcache-loads # 1203.741 M/sec [49.68%] 154,380,395 L1-dcache-load-misses # 7.96% of all L1-dcache hits [49.66%] 0 LLC-loads # 0.000 K/sec [39.27%] 0 LLC-load-misses # 0.00% of all LL-cache hits [39.61%] 1.614165346 seconds time elapsed ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:3:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"2.2 指定 Hardware Events 计数器 下面是对 Hardware Events 指定计数的示例。如果 -e 指定的硬件事件包含“ cycle ”和“ instructions ”计数器，那么 perf 的输出中将包含 IPC。硬件事件通常是特定于处理器模型的，许多可能无法从虚拟化环境中获得。 # 指定硬件计数器 $ perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores gzip file1 Performance counter stats for 'gzip file1': 1,947,551,657 L1-dcache-loads 153,829,652 L1-dcache-misses # 7.90% of all L1-dcache hits 1,171,475,286 L1-dcache-stores 1.538038091 seconds time elapsed # 使用原始事件 $ perf stat -e cycles,instructions,r80a2,r2b1 gzip file1 Performance counter stats for 'gzip file1': 5,586,963,328 cycles # 0.000 GHz 8,608,237,932 instructions # 1.54 insns per cycle 9,448,159 raw 0x80a2 11,855,777,803 raw 0x2b1 1.588618969 seconds time elapsed # PMCs: counting cycles and frontend stalls via raw specification: $ perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:3:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"2.3 通过静态探针统计系统调用 通过 -e 指定 Kernel Tracepoint Events，perf stat 可以统计程序执行的系统调用: # 统计系统调用统计系统调用并打印摘要(非零计数) $ perf stat -e 'syscalls:sys_enter_*' gzip file1 2\u003e\u00261 | awk '$1 != 0' Performance counter stats for 'gzip file1': 1 syscalls:sys_enter_utimensat 1 syscalls:sys_enter_unlink 5 syscalls:sys_enter_newfstat 1,603 syscalls:sys_enter_read 3,201 syscalls:sys_enter_write 使用系统调用跟踪程序strace -c可以看到类似的报告，但是它可能导致比perf高得多的开销，因为perf在内核中缓冲数据。strace的当前实现使用ptrace(2)附加到目标进程并在系统调用期间停止它，就像调试器一样。这是暴力的，并可能导致严重的开销。 perf trace 子命令提供与 strace 类似的功能，但开销要低得多。perf trace 还可以进行系统级的系统调用跟踪（即跟踪所有进程），而 strace 只能跟踪特定的进程。 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:3:3","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3. 采样事件 perf record 是perf 的第二种使用方式，采样事件，他包含如下几种模式: Timed Profiling，以固定间隔采样，使用 -F 选项 Event Profiling，基于事件采样(通常是硬件事件，软件事件较少)，使用 -e 指定采样事件 Static Kernel Tracing: 基于内核的静态探针，使用 -e 指定静态探针类型。 perf-record用来启动一次跟踪: perf record在当前目录产生一个perf.data文件，用来记录过程数据 如果这个文件已经存在，旧的文件会被改名为perf.data.old perf.data只包含原始数据，perf report 需要访问本地的符号表，pid和进程的对应关系等信息来生成报告。 所以perf.data不能直接拷贝，可以通过perf-archive命令把所有这些数据打包，然后复制 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.1 perf record/report 命令 perf record 命令格式: perf record [-e \u003cEVENT\u003e | --event=EVENT] [-a] \u003ccommand\u003e perf record [-e \u003cEVENT\u003e | --event=EVENT] [-a] — \u003ccommand\u003e [\u003coptions\u003e] 参数: -p, --pid \u003cpid\u003e: 指定跟踪固定的一组进程，即仅仅跟踪发生在特定pid的事件 -a, --all-cpus: 跟踪整个系统的性能，常用选项 -c, --count \u003cn\u003e: 累计多少个事件记录一次 -g: 开启堆栈追踪，通常无需使用 -F: 事件采样的频率, 单位HZ, 更高的频率会获得更细的统计，但会带来更多的开销 sleep: 采样的时间 perf.data 文件可以用多种方法处理。perf report命令启动ncurses导航器来检查调用图。或者使用 –stdio 选项将调用图打印成树状，并标注百分比: perf report [-i \u003cfile\u003e | --input=file] 使用: 显示的是一个菜单项，回车可以查看折叠的代码，esc 或者 q 可以退出返回上一级 参数: --pid=: 指定 pid --tid=: 指定 tid -S, --symbols=: Only consider these symbols. --stdio: 在终端将调用图以树状图打印 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.2 Timed Profiling perf 可以基于对指令指针或堆栈跟踪的固定间隔采样(定时分析)来分析CPU使用情况。入下例所示以99赫兹(-F 99)，对整个系统(-a，对所有CPU)采样CPU堆栈，采样10秒，并记录堆栈(-g，调用图): $ perf record -F 99 -a -g -- sleep 30 选择99赫兹而不是100赫兹，是为了避免偶然地与某些周期性活动同步采样，以免产生扭曲的结果。这也是粗糙的:你可能想要增加到更高的速率(例如，高达997赫兹)以获得更好的分辨率，请记住，更高的频率意味着更高的开销。 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.3 Event Profiling 除了按时间间隔采样外，由CPU硬件计数器触发的采样是CPU分析的另一种形式。某些事件发生的频率非常高，在每次出现时都收集堆栈会导致过多的开销并降低系统速度并改变目标的性能特征。通常，只测量它们出现的一小部分，而不是全部，就足够了。这可以通过使用“-c” 指定触发事件收集的阈值来实现。“-c count”机制是由处理器实现的，它只在达到阈值时中断内核。 例如，下面的一行程序统计 1级数据缓存加载失败次数，每10000次失败收集一次堆栈跟踪: # 每 1000 次收集一次堆栈跟踪 perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:3","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.4 Static Kernel Tracing 通过内核静态探针，可以跟踪内核的系统调用。 跟踪新进程的创建 # perf record -e sched:sched_process_exec -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ] # perf report -n --sort comm --stdio [...] # Overhead Samples Command # ........ ............ ....... # 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff 跟踪出站连接 $ perf record -e syscalls:sys_enter_connect -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.057 MB perf.data (~2489 samples) ] # perf report --stdio # ======== # Samples: 21 of event 'syscalls:sys_enter_connect' # Event count (approx.): 21 # Overhead Command Shared Object Symbol ........ ....... .................. ........................... 52.38% sshd libc-2.15.so [.] __GI___connect_internal 19.05% groups libc-2.15.so [.] __GI___connect_internal 9.52% sshd libpthread-2.15.so [.] __connect_internal 9.52% mesg libc-2.15.so [.] __GI___connect_internal 9.52% bash libc-2.15.so [.] __GI___connect_internal 记录connect()的堆栈跟踪可以解释为什么会出现这些出站连接: $ perf record -e syscalls:sys_enter_connect -ag ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.057 MB perf.data (~2499 samples) ] $ perf report --stdio 跟踪套接字缓冲区消耗 跟踪套接字缓冲区的消耗和堆栈跟踪是识别导致套接字或网络I/O的原因的一种方法。 $ perf record -e 'skb:consume_skb' -ag ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.065 MB perf.data (~2851 samples) ] $ perf report ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:4","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.4 Static User Tracing 在4.x 的内核中，添加了用户态静态追踪机制。下面演示了Linux 4.10(附加了一个补丁集)，如何跟踪Node.js 的USDT探针: # perf buildid-cache --add `which node` # perf list | grep sdt_node sdt_node:gc__done [SDT event] sdt_node:gc__start [SDT event] sdt_node:http__client__request [SDT event] sdt_node:http__client__response [SDT event] sdt_node:http__server__request [SDT event] sdt_node:http__server__response [SDT event] sdt_node:net__server__connection [SDT event] sdt_node:net__stream__end [SDT event] # perf record -e sdt_node:http__server__request -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.446 MB perf.data (3 samples) ] # perf script node 7646 [002] 361.012364: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.204718: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.363043: sdt_node:http__server__request: (dc2e69) ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:5","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"3.5 Dynamic Tracing 使用动态追踪需要启用如下的内核参数: 内核动态跟踪需要启用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y 用户级动态跟踪需要启用 CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y 为避免内核栈指针优化，需要启用 CONFIG_FRAME_POINTER=y 下面是几个在 Linux 使用 perf 进行动态追踪的示例 检测内核tcp_sendmsg()函数 # 1. 添加动态探针 $ perf probe --add tcp_sendmsg Failed to find path of kernel module. Added new event: probe:tcp_sendmsg (on tcp_sendmsg) You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1 # 2. 使用动态探针 $ perf record -e probe:tcp_sendmsg -a -g -- sleep 5 # 3. 输出追踪报告 $ perf report --stdio # 如果内核有debuginfo (CONFIG_DEBUG_INFO=y)，那么可以从函数中提取内核变量。 # 这是在Linux 3.13.1上检查size_t(整数)的一个简单示例。 # 5.列出tcp_sendmsg()可用的变量 $ perf probe -V tcp_sendmsg Available variables at tcp_sendmsg @\u003ctcp_sendmsg+0\u003e size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk # 6. 使用变量“size”为tcp_sendmsg()创建一个探针: $ perf probe --add 'tcp_sendmsg size' # 7. 跟踪此探针 $ perf record -e probe:tcp_sendmsg -a $ perf script # 内核:将显示 tcp_sendmsg()行号和本地变量值 # ======== # sshd 1301 [001] 502.424719: probe:tcp_sendmsg: (ffffffff81505d80) size=b0 # 使用debuginfo, perf_events可以为内核函数中的行创建跟踪点。 # 必须安装 kernel-debuginfo 包，或者启用CONFIG_DEBUG_INFO=y # 8. 列出tcp_sendmsg()可用的行探测: $ perf probe -L tcp_sendmsg \u003ctcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0\u003e 0 int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg, size_t size) 2 { struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; 6 int iovlen, flags, err, copied = 0; 7 int mss_now = 0, size_goal, copied_syn = 0, offset = 0; bool sg; long timeo; [...] # 9. 检查在第81行有哪些变量可用 $ perf probe -V tcp_sendmsg:81 Available variables at tcp_sendmsg:81 @\u003ctcp_sendmsg+537\u003e bool sg int copied int copied_syn int flags int mss_now int offset int size_goal long int timeo size_t seglen struct iovec* iov struct sock* sk unsigned char* from # 10. 跟踪第81行，并使用循环中的seglen变量 $ perf probe --add 'tcp_sendmsg:81 seglen' $ perf record -e probe:tcp_sendmsg -a $ perf script sshd 4652 [001] 2082360.931086: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x80 app_plugin.pl 2400 [001] 2082360.970489: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x20 postgres 2422 [000] 2082360.970703: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x52 [...] 跟踪 malloc 函数调用 # 1. 添加 malloc 探针 $ perf probe -x /lib64/libc-2.17.so '--add=malloc' $ perf record -e probe_libc:malloc -a $ perf report -n # 2. 添加带 size 参数的 malloc 探针 # size 保存的寄存器信息，依赖于你的处理器架构 $ perf probe -x /lib64/libc-2.17.so '--add=malloc size=%di' malloc()调用非常频繁，因此需要考虑跟踪这样的调用的开销。 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:4:6","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"4. perf eBPF ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:5:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"5. perf 特殊功能子命令 说完了 perf 的三种基础使用方式，我们来看perf 提供特殊功能的子命令。 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:6:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"5.1 perf trace perf trace 类似于 strace 用于跟踪进程的系统调用，前面我们也提到了，相对于 strace 使用的 ptrace 机制来说，perf trace 基于内核事件，比进程跟踪的性能好很多。perf trace 还可以进行系统级的系统调用跟踪（即跟踪所有进程），而 strace 只能跟踪特定的进程。 Usage: perf trace [\u003coptions\u003e] [\u003ccommand\u003e] or: perf trace [\u003coptions\u003e] -- \u003ccommand\u003e [\u003coptions\u003e] or: perf trace record [\u003coptions\u003e] [\u003ccommand\u003e] or: perf trace record [\u003coptions\u003e] -- \u003ccommand\u003e [\u003coptions\u003e] -a, --all-cpus system-wide collection from all CPUs -C, --cpu \u003ccpu\u003e list of cpus to monitor -D, --delay \u003cn\u003e ms to wait before starting measurement after program start -e, --event \u003cevent\u003e event/syscall selector. use 'perf list' to list available events -f, --force don't complain, do it -F, --pf \u003call|maj|min\u003e Trace pagefaults -G, --cgroup \u003cname\u003e monitor event in cgroup name only -i, --input \u003cfile\u003e Analyze events in file -m, --mmap-pages \u003cpages\u003e number of mmap data pages -o, --output \u003cfile\u003e output file name -p, --pid \u003cpid\u003e trace events on existing process id --sched show blocking scheduler events --syscalls Trace syscalls 下面是 perf trace 的使用示例: $ perf trace --syscalls ls ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:6:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"5.1 perf top perf top [-e \u003cEVENT\u003e | --event=EVENT] [\u003coptions\u003e] 作用: 可以动态收集和更新统计列表 options: -e: 指定跟踪的事件，包括 perf list提供的所有事件以及 tracepoint 可以多次使用，也可以一次指定多个事件，事件使用逗号分隔 对于厂家为上传的事件可以直接是用编号，eg: -e r0013 事件可以指定后缀，用于限定跟踪范围 -s: 指定按什么参数来进行分类 默认会按函数进行分类，按照 pid 分类需要指定 -s pid -s也可以指定多个域（用逗号隔开） 可选值包括: pid, comm, dso, symbol, parent, srcline, weight, local_weight, abort, in_tx, transaction, overhead, sample, period -a：显示在所有CPU上的性能统计信息 -p：指定进程PID -t：指定线程TID -K：隐藏内核统计信息 -U：隐藏用户空间的统计信息 -S, –symbols: Only consider these symbols -g, –call-graph: 得到函数的调用关系图 格式: \u003cprint_type,threshold[,print_limit],order,sort_key[,branch],value\u003e print_type: flat: single column, linear exposure of call chains. graph: use a graph tree, displaying absolute overhead rates. (default) fractal: like graph, but displays relative rates. Each branch of the tree is considered as a new profiled object. folded: call chains are displayed in a line, separated by semicolons none: disable call chain display. # 1. -e 指定多个事件 \u003e sudo perf top -e branch-misses,cycles # 2. 指定后缀，只跟踪用户态发生的分支预测失败 \u003e sudo perf top -e branch-misses:u,cycles \u003e sudo perf top -e '{branch-misses,cycles}:u' # 3. 指定分类 \u003e sudo perf top -e 'cycle' -s comm,pid,dso ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:6:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"5.2 perf sched perf sched子命令提供了许多用于分析内核CPU调度器行为的工具。您可以使用它来识别和量化调度器延迟的问题。 这个命令的开销很大。如果开销是一个问题，可以使用eBPF/bcc工具。其中runqlat和runqlen，只记录内核内的调度器事件摘要，进一步减少开销。perf sched转储所有事件的一个优点是不局限于摘要，对于分析问题而言可以获取更全面的信息。 # perf sched -h Usage: perf sched [] {record|latency|map|replay|script|timehist} -D, --dump-raw-trace dump raw trace in ASCII -f, --force don't complain, do it -i, --input input file name -v, --verbose be more verbose (show symbol address, etc) perf sched 有{record|latency|map|replay|script|timehist}使用模式，我们来一一介绍。 perf sched record perf sched latency perf sched latency 将按任务统计调度程序延迟，包括平均延迟和最大延迟: # perf sched latency ----------------------------------------------------------------------------------------------------------------- Task | Runtime ms | Switches | Average delay ms | Maximum delay ms | Maximum delay at | ----------------------------------------------------------------------------------------------------------------- cat:(6) | 12.002 ms | 6 | avg: 17.541 ms | max: 29.702 ms | max at: 991962.948070 s ar:17043 | 3.191 ms | 1 | avg: 13.638 ms | max: 13.638 ms | max at: 991963.048070 s rm:(10) | 20.955 ms | 10 | avg: 11.212 ms | max: 19.598 ms | max at: 991963.404069 s perf sched map perf sched map 显示所有CPU和上下文切换事件，其中的列表示每个CPU正在做什么以及何时做。 # perf sched map *A0 991962.879971 secs A0 =\u003e perf:16999 A0 *B0 991962.880070 secs B0 =\u003e cc1:16863 *C0 A0 B0 991962.880070 secs C0 =\u003e :17023:17023 *D0 C0 A0 B0 991962.880078 secs D0 =\u003e ksoftirqd/0:6 D0 C0 *E0 A0 B0 991962.880081 secs E0 =\u003e ksoftirqd/3:28 D0 C0 *F0 A0 B0 991962.880093 secs F0 =\u003e :17022:17022 perf sched replay perf sched script perf sched timehist ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:6:3","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"5.3 perf mem ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:6:4","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"6. perf.data 处理 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:7:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"6.1 perf diff perf diff [baseline file] [data file1] [[data file2] ... ] 作用: 比较两次运行的区别 场景: 可以用不同参数运行程序，看看两次运行的差别 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:7:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"6.2 perf script perf script [\u003coptions\u003e] 作用: 对 perf.data 数据做格式转换 # 1. 导出原始分析数据 \u003e perf record \u003e perf script # 导出 perf record 中记录的原始数据 \u003e perf script | ./stackcollapse-perf.pl | ./flamegraph.pl \u003e perf-kernel.svg # List all perf.data events, with customized fields (\u003c Linux 4.1): perf script -f time,event,trace # List all perf.data events, with customized fields (\u003e= Linux 4.1): perf script -F time,event,trace # List all perf.data events, with my recommended fields (needs record -a; newer kernels): perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso # List all perf.data events, with my recommended fields (needs record -a; older kernels): perf script -f comm,pid,tid,cpu,time,event,ip,sym,dso # Dump raw contents from perf.data as hex (for debugging): perf script -D ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:7:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"7. perf 数据可视化 ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:8:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"7.1 perf chart perf timechart输出的是进程运行过程中系统调度的情况，无法对程序的具体代码段进行性能分析，但可以看出总结运行情况：running，idle，I/O等， perf timechart record ./a.out # 记录数据 perf timechart # 生成 output.svg ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:8:1","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"7.2 火焰图 Brendangregg写了两款对perf采样结果进行可视化分析的开源工具： FlameGraphs即所谓的火焰图，能清晰的展示程序各个函数的性能消耗 HeatMap可以从采样数据中的延迟数据来进行消耗展示 # 生成火焰图 git clone https://github.com/brendangregg/FlameGraph # or download it from github cd FlameGraph perf record -F 99 -ag -- sleep 60 perf script | ./stackcollapse-perf.pl \u003e out.perf-folded cat out.perf-folded | ./flamegraph.pl \u003e perf-kernel.svg ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:8:2","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"参考 brendangregg-perf 在Linux下做性能分析3：perf ","date":"2020-01-05","objectID":"/posts/linux/linux_perf/06_perf_use/:9:0","tags":["Linux 性能调优"],"title":"2.4 perf 的使用","uri":"/posts/linux/linux_perf/06_perf_use/"},{"categories":["Linux"],"content":"2.2 perf 的原理","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"perf 感觉像是一个完全版的 top，可以帮助我们看到操作系统运行的全貌。perf 的使用非常复杂，本文只是一个入门，推荐大家去阅读大神 Brendangregg 的文章perf Examples。 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:0:0","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"1. perf 简介 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:1:0","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"1.1 perf event perf 的使用依赖我们前面所说的 event(事件)。event 是不同内核工具框架的统一接口，上面的图片说明了 event 来源: Hardware Events: CPU性能监视计数器 PMCs Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点，即静态探针 User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 使用perf -FHz选项以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 list子命令列出当前可用的事件，使用动态跟踪时，就是在扩展下面这个列表。这个列表中的 probe:tcp_sendmsg 探针就是动态插入 tcp_sendmsg() 的示例。 # perf list List of pre-defined events (to be used in -e): cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] cpu-clock [Software event] task-clock [Software event] page-faults OR faults [Software event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event] [...] rNNN [Raw hardware event descriptor] cpu/t1=v1[,t2=v2,t3 ...]/modifier [Raw hardware event descriptor] (see 'man perf-list' on how to encode it) mem:\u003caddr\u003e[:access] [Hardware breakpoint] probe:tcp_sendmsg [Tracepoint event] [...] sched:sched_process_exec [Tracepoint event] sched:sched_process_fork [Tracepoint event] sched:sched_process_wait [Tracepoint event] sched:sched_wait_task [Tracepoint event] sched:sched_process_exit [Tracepoint event] [...] # perf list | wc -l 657 采样事件 perf -FHz 是这样的：perf 每隔一个固定的时间，就在CPU上（每个核上都有）产生一个中断，在中断上看看，当前是哪个pid，哪个函数，然后给对应的pid和函数加一个统计值，这样，我们就知道CPU有百分几的时间在某个pid，或者某个函数上了。 这种方式可以推广到各种事件，此时使用的不再是 -FHz 指定的频率，而是 -e 参数指定的各种 event。当指定的事件发生的时候，perf 就会上来冒个头，看看击中了谁，然后算出分布，我们就知道谁会引发特别多的那个事件了。 所以本质上 perf 属于一种抽样统计。既然是抽样统计我们就要警惕抽样带来的抽样误差。每次看perf report的报告，首先要去注意一下总共收集了多少个点，如果你只有几十个点，你这个报告就可能很不可信了。 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:1:1","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"1.2 perf 事件说明 软件事件 perf提供了少量固定的软件事件，这些也记录在手册页perf_event_open(2) 中。软件事件可能有一个默认的周期。这意味着当使用它们进行抽样时，是在对事件的子集进行抽样，而不是跟踪每个事件。你可以通过 perf record -vv 查看: # perf record -vv -e context-switches /bin/true Using CPUID GenuineIntel-6-55 ------------------------------------------------------------ perf_event_attr: type 1 size 112 config 0x3 { sample_period, sample_freq } 4000 sample_type IP|TID|TIME|PERIOD disabled 1 inherit 1 mmap 1 comm 1 freq 1 enable_on_exec 1 [...] 有关这些字段的描述，请参见perf_event_open(2)手册页。这个默认的意思是内核调整采样率，以便它每秒捕获大约4000个上下文切换事件。如果你真的想把它们全部记录下来，请使用-c1: # perf record -vv -e context-switches -c 1 /bin/true Using CPUID GenuineIntel-6-55 ------------------------------------------------------------ perf_event_attr: type 1 size 112 config 0x3 { sample_period, sample_freq } 1 sample_type IP|TID|TIME disabled 1 inherit 1 mmap 1 comm 1 enable_on_exec 1 首先使用perf stat检查事件的速率，这样您就可以估计将要捕获的数据量。在默认情况下对子集进行采样可能是一件好事，特别是对于上下文切换这样的高频率事件。许多其他事件(比如跟踪点)的默认值都是1。对于许多软件和硬件事件，您将遇到非1的缺省值。 其他事件参见前文\"Linux 性能调优概览\"中的说明 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:1:2","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"1.3 perf 使用注意事项 idle 进程 现代CPU基本上已经不用忙等的方式进入等待了，所以，如果CPU在idle，击中任务也会停止，所以，在Idle上是没有点的。看到Idle函数本身的点并非CPU Idle的点，而是准备进入Idle前后花的时间。所以，perf的统计不能用来让你分析CPU占用率的。ftrace和top等工具才能看CPU占用率，perf是不行的。 中断 perf还有一个问题是对中断的要求，perf很多事件都依赖中断，但Linux内核是可以关中断的，关中断以后，你就无法击中关中断的点了，你的中断会被延迟到开中断的时候，所以，在这样的平台上，你会看到很多开中断之后的函数被密集击中。但它们是无辜的。但更糟糕的是，如果在关中断的时候，发生了多个事件，由于中断控制器会合并相同的中断，你就会失去多次事件，让你的统计发生错误。 现代的Intel平台，基本上已经把PMU中断都切换为NMI中断了（不可屏蔽），所以前面这个问题不存在。但在大部分ARM/ARM64平台上，这个问题都没有解决，所以看这种平台的报告，都要特别小心，特别是你看到_raw_spin_unlock()一类的函数击中极高，你就要怀疑一下你的测试结果了（注意，这个结果也是能用的，只是看你怎么用）。 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:1:3","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.perf 使用 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:0","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.1 安装 perf的源代码就是Linux的源代码目录中，因为它在相当程度上和内核是关联的。一般Linux 的各种发行版本都会安装好与内核相对应的 perf 命令。perf 有两种安装方式 通过包管理进行安装，perf工具在 linux-tools-common工具包里，通过包管理软件安装的时候还需要依赖linux-tools-kernelversion包 源码编译：找到对应内核版本的源码包，在tools/perf目录下进行编译 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:1","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.2 使用前提 符号表 与其他调试工具一样，perf_events需要符号信息(符号)。它们被用来将内存地址转换成函数和变量名，以便我们人类能够读取它们。如果没有符号，您将看到十六进制数字表示所分析的内存地址。 类似于 Java Node 这些使用虚拟机编写的程序，使用虚拟机自行管理执行函数和管理堆栈，perf 只能查看到虚拟机级别堆栈，是无法解析语言本身的上下文的。使用 perf 分析java，node 等语言需要需要语言的JIT 提供支持。下面是一些常见语言如何支持 perf 的参考链接: java perf-map-agent Java in flame Java火焰图部分 Java Performance Analysis on Linux with Flame Graphs. node: Node.js火焰图在Linux上的步骤 通常软件包的符号表通过类似 -dbgsym 命令符号的调试包提供。libc6-dbgsym和coreutils-dbgsym 可以提供用户级 OS 代码页的一些符号表。实在不行只能自己编译软件，保留符号表。 # 安装内核符号表 yum search debuginfo|grep kernel yum install kernel-debuginfo # 安装应用程序符号表，如果其提供了调试的 yum 包 debuginfo-install bash 省略帧指针优化问题 省略帧指针是编译器默认的优化选项，使得 perf 无法看到完整的堆栈。 有下面几种方法可以解决这个问题: 使用dwarf数据展开堆栈: 从3.9内核开始，perf_events 支持用户级栈中缺少帧指针的解决方案:libunwind，叫做 dwarf 使用\"–call-graph dwarf\"(或“-g dwarf”)启用此功能 perf 可以在没有 dwarf 支持的情况下构建。因此是否支持 dwarf 要查阅安装信息 使用可用的最后一个分支记录(LBR)(如果处理器特性支持) LBR，全称是 Last Branch Record，需要处理器支持，通常在云环境中都是禁用的 LBR通常限制了堆栈深度(8、16或32帧)，所以它可能不适合深度堆栈或火焰图生成 返回帧指针 还有其他堆栈遍历技术，比如BTS(分支跟踪存储)和新的ORC解卷器 内核也有类似省略帧指针的问题。启动 CONFIG_FRAME_POINTER=y 内核选项可以避免此问题。 堆栈追踪深度问题 使用堆栈跟踪要注意的是: 堆栈跟踪受扫描深度的限制，太深的堆栈可能回溯不过去，这是有可能影响结果的。 有些我们从源代码看来是函数调用的，其实在汇编一级并不是函数调用 比如inline函数，宏，都不是函数调用 另外，gcc在很多平台中，会自动把很短的函数变成inline函数，这也不产生函数调用 还有一种是，fastcall函数，通过寄存器传递参数，不会产生调用栈，也有可能不产生调用栈 部分平台使用简化的堆栈回溯机制，在堆栈中看见一个地址像是代码段的地址，就认为是调用栈 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:2","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.3 perf 的运行方式 perf_events有三种使用方式: 计数模式: 对应 perf stat 命令，对内核上下文中的事件进行计数，并输出统计的摘要信息 此模式不生成perf.data文件 开销最小 采样事件： 通过采样的方式，将事件数据写入内核缓冲区； 然后以异步的方式，将内核缓冲区的内容写入 perf.data 文件 perf report 或 perf script 命令读取 perf.data 并输出结果 开销取决于正在跟踪的事件的频率 事件上的bpf程序: 这是Linux 4.4+内核中的一个新特性，它可以在内核空间中执行自定义用户定义的程序，可以执行高效的数据筛选和总结。 bpf 是先筛选在写入内核缓冲区，相比于采样事件模式高效的多 下面是 perf 三种使用方式的一些示例，我们会在后面详细 perf 的使用。 # gzip命令的性能计数器总结，包括IPC: perf stat gzip largefile # 按照静态探针对进程调度事件进行计数，持续 5s perf stat -e 'sched:sched_process_*' -a sleep 5 # 按照静态探针跟踪进程调度事件，持续 5s perf record -e 'sched:sched_process_*' -a sleep 5 perf report # 按照静态探针跟踪进程调度事件，持续 5s，并转储事件信息信息 perf record -e 'sched:sched_process_*' -a sleep 5 perf script # 跟踪请求的字节小于10 的 read() 系统调用 perf record -e 'syscalls:sys_enter_read' --filter 'count \u003c 10' -a # 以 99hz 的频率抽样CPU堆栈 perf record -F 99 -ag -- sleep 5 perf report # 添加 tcp_sendmsg 动态探针，追踪 5s，并记录堆栈 perf probe --add tcp_sendmsg perf record -e probe:tcp_sendmsg -ag -- sleep 5 perf probe --del tcp_sendmsg perf report ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:3","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.3 perf 命令概览 除此上面介绍的三种使用方式之外， perf 还有许多子命令提供特殊用途的功能。这些子命令都是在 perf 三种检测功能的基础上，记录特定的事件并以定制的方式报告，包括: perf c2c (Linux 4.10+): cache-2-cache and cacheline false 共享分析 perf kmem: 内核内存分配分析。 perf kvm：KVM虚拟客户端分析。 perf lock: 锁分析 perf mem: 内存访问分析。 perf sched: 内核调度器的统计数据 下面是 perf 子命令的一个完整列表。 perf [--version] [--help] [OPTIONS] COMMAND [ARGS] 子命令 作用 list List all symbolic event types 列出当前系统支持的所有事件名,可分为三类：硬件事件、软件事件，检查点 stat Run a command and gather performance counter statistics 对程序运行过程中的性能计数器进行统计 top System profiling tool. 对系统的性能进行分析，类似top命令 record Run a command and record its profile into perf.data 对程序运行过程中的事件进行分析和记录，并写入perf.data report Read perf.data (created by perf record) and display the profile 读取perf.data(由perf record生成) 并显示分析结果 sched Tool to trace/measure scheduler properties (latencies) 针对调度器子系统的分析工具 lock Analyze lock events 分析内核中的锁信息，包括锁的争用情况，等待延迟等 mem Profile memory accesses 分析内存访问 kmem Tool to trace/measure kernel memory properties 分析内核内存的使用 kvm Tool to trace/measure kvm guest os 分析kvm虚拟机上的guest os timechart Tool to visualize total system behavior during a workload 对record结果进行可视化分析输出，record命令需要加上timechart记录 script Read perf.data (created by perf record) and display trace output 读取perf.data(由perf record生成)，生成trace记录，供其他分析工具使用 data Data file related processing 把perf.data文件转换成其他格式 diff Read perf.data files and display the differential profile 读取多个perf.data文件，并给出差异分析 evlist List the event names in a perf.data file 列出perf.data中采集的事件列表 bench General framework for benchmark suites perf提供的基准套件的通用框架，可以对当前系统的调度，IPC，内存访问进行性能评估 test Runs sanity tests. perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能 probe Define new dynamic tracepoints 用于定义动态检查点 trace strace inspired tool 类似于strace，跟踪目标的系统调用，但开销比strace小 ftrace simple wrapper for kernel ftrace functionality annotate Read perf.data (created by perf record) and display annotated code 读取perf.data(由perf record生成)显示反汇编后的代码 archive Create archive with object files with build-ids found in perf.data file 根据perf.data(由perf record生成)文件中的build-id将相关的目标文件打包 buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file c2c Shared Data C2C/HITM Analyzer. config Get and set variables in a configuration file. inject Filter to augment the events stream with additional information kallsyms Searches running kernel for symbols version display the version of perf binary ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:4","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.4 perf 一些重要的选项参数 perf 有一些重要的选项参数包括: -g/--child/--cal-graph 下面我们来一一讲解 -g perf record 和 perf report 都有 -g 选项。perf record 中 -g 用于启用堆栈追踪。perf report 中 -g/--call-graph 用于指定堆栈的显示方式，这是我们讲解的重点。 -g/--call-graph 参数格式为 \u003cprint_type,threshold[,print_limit],order,sort_key[,branch],value\u003e print_type: 指定堆栈调用图的显示方式 可选值包括 (graph|flat|fractal|folded|none) 默认值为 graph 表示以调用关系图的方式显示堆栈，通常无须更改 threshold: 一个百分比值，当函数调用所占用的CPU小于这个百分比值的时候，不显示堆栈信息 默认值为 0.5(表示的是百分之0.5) print_limit: 调用关系图显示的最大行数，可不指定 order: 调用关系图的显示方式，可选值包括 (caller|callee) caller: 默认值，表示基于调用者的调用图 callee: caller 的反转，基于被调用者的调用图，也可以使用 -G 或者 --children sort_key: 调用关系图的排序键，可选值包括(function|address)，通常无须更改 branch: include last branch info to call graph (branch) 可不指定 value: call graph value (percent|period|count) 调用关系图中显示什么，CPU占用百分比，CPU周期数，还是调用总次数 默认为 percent，同行无须更改 默认值为: graph,0.5,caller,function,percent 这之中最难理解的是 order。我们看下面这个例子 # perf report --stdio # ======== # captured on: Mon Jan 26 07:26:40 2014 # hostname : dev2 # os release : 3.8.6-ubuntu-12-opt # perf version : 3.8.6 # arch : x86_64 # nrcpus online : 8 # nrcpus avail : 8 # cpudesc : Intel(R) Xeon(R) CPU X5675 @ 3.07GHz # cpuid : GenuineIntel,6,44,2 # total memory : 8182008 kB # cmdline : /usr/bin/perf record -F 99 -a -g -- sleep 30 # event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = ... # HEADER_CPU_TOPOLOGY info available, use -I to display # HEADER_NUMA_TOPOLOGY info available, use -I to display # pmu mappings: software = 1, breakpoint = 5 # ======== # # Samples: 22K of event 'cpu-clock' # Event count (approx.): 22751 # # Overhead Command Shared Object Symbol # ........ ....... ................. ............................... # 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--96.67%-- extract_buf | extract_entropy_user | urandom_read | vfs_read | sys_read | system_call_fastpath | read | |--1.69%-- account | | | |--99.72%-- extract_entropy_user | | urandom_read | | vfs_read | | sys_read | | system_call_fastpath | | read | --0.28%-- [...] | |--1.60%-- mix_pool_bytes.constprop.17 [...] 默认情况下 perf report 使用 caller 即显示基于调用者的调用图。 最顶端显示的是最终被调用的子函数。从上往下是调用它的父函数。 其中最热(最频繁)的堆栈跟踪发生频率是 90.99%(extract_buf 部分)，它是Overhead列的百分比和顶部堆栈叶(94.12% x 96.67%)的乘积。 96.67% 表示的是调用 _raw_spin_unlock_irqrestore 函数的相对百分比，即_raw_spin_unlock_irqrestore的调用次数中，extract_buf 占了 96.67%。 Overhead 列显示的是这个进程的CPU占用百分比 通过使用-G， -g caller 或者 –children 来反转调用关系图 说明: 在我的Linux 上 perf 默认是按照绝对百分显示的 CPU 调用，即extract_buf 显示的是90.99%，不是 96.67%。 -s -s 用于在 perf record 中指定调用关系图的排序字段。可选值包括: overhead: 默认值，Overhead percentage of sample，抽样占比 overhead_sys: Overhead percentage of sample running in system mode overhead_us: Overhead percentage of sample running in user mode comm: command (name) of the task which can be read via /proc//comm pid: command and tid of the task socket: processor socket number the task ran at the time of sample …. -F -F 用于指定 perf report 中显示的字段，可选值与 -s 类似。 下面是一个跟踪进程创建的例子，使用-n来打印“Samples”列，使用--sort comm来定制其余的列。 # perf record -e sched:sched_process_exec -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ] # perf report -n --sort comm --stdio [...] # Overhead Samples Command # ........ ............ ....... # 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff –filter 在使用 perf record 进行追踪时，可以通过 –filter 选项对堆栈进行过滤，只记录满足条件的堆栈信息。 ","date":"2020-01-04","objectID":"/posts/linux/linux_perf/04_perf/:2:5","tags":["Linux 性能调优"],"title":"2.2 perf 的原理","uri":"/posts/linux/linux_perf/04_perf/"},{"categories":["Linux"],"content":"2.1 ftrace 的原理与使用","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"最早 ftrace 是一个 function tracer，仅能够记录内核的函数调用流程。如今 ftrace 已经成为一个 framework，采用 plugin 的方式支持开发人员添加更多种类的 trace 功能。 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:0:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"1. ftrace 简介 Ftrace 最初是在 2.6.27 中出现，那时 systemTap 已经开始崭露头角，其他的 trace 工具包括 LTTng 等也已经发展多年。那为什么人们还要再开发一个 trace 工具呢？ SystemTap 目标是达到甚至超越 Dtrace 。因此 SystemTap 设计比较复杂，在真正的产品环境，人们依然无法放心的使用她。不当的使用和 SystemTap 自身的不完善都有可能导致系统崩溃。 Ftrace 的设计目标简单，本质上是一种静态代码插装技术，不需要支持某种编程接口让用户自定义 trace 行为。静态代码插装技术更加可靠，不会因为用户的不当使用而导致内核崩溃。 ftrace 代码量很小，稳定可靠。实际上，即使是 Dtrace，大多数用户也只使用其静态 trace 功能。因此 ftrace 的设计非常务实。 ftrace一个比较明显的缺点是没有用户态的跟踪点支持。perf-tools 对Ftrace的功能进行了很好的封装和集成，建议大家用perf-tools来使用Ftrace，则效果更佳更简单。后面会介绍 perf-tools 的使用，在此之前我们先来看看怎么使用 ftrace。 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:1:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"2. ftrace 原理 Ftrace 有两大组成部分: 一是 framework 二是一系列的 tracer， 每个 tracer 完成不同的功能，它们统一由 framework 管理 ftrace 的 trace 信息保存在 ring buffer(内存缓冲区) 中，由 framework 负责管理 ftrace有两种主要跟踪机制可以往缓冲区中写数据 一是函数: 即动态探针，可以跟踪内核函数的调用栈，包括 function tracer，function graph tracer 两个 tracer 二是事件: 即静态探针，包括其他大多数的 tracer Framework 利用 debugfs 系统在 /debugfs 下建立 tracing 目录，对用户空间输出 trace 信息，并提供了一系列的控制文件 ftrace的目录设置和sysfs类似，都是把目录当作对象，把里面的文件当作这个对象的属性。debugfs/tracing 目录可以理解成一个独立的监控实例 instance，在 tracing 目录或者子目录创建任何目录相当于创建了一个新的 ftrace 实例，ftrace 会为这个 ftrace 实例自动创建 ring buffer 内存缓冲区，并在这个目录下创建 ftrace 实例所需的与 tracing 目录完全相同的文件。 debugfs在大部分发行版中都mount在**/sys/kernel/debug**目录下，而ftrace就在这个目录下的tracing目录中。如果系统没有mount这个文件系统，可以手动 mount。 # 1. 重新挂在 debugfs mount -t debugfs none /debugs # 2. debugfs/tracing 目录 ll /debugs/tracing # 3. 创建新的 ftrace trace 实例 mkdir /debugs/tracing/instance/python # ftrace 会创建新的内存缓冲区并生成 ftrace 相关文件 ll tracing/instances/python/ ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:2:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"3. ftrace 控制机制 在讲解 ftrace 的 tracer 之前，我们先来看看 tracing 目录下的文件，它们提供了对 ftrace trace 过程的控制。 ls available_events free_buffer printk_formats snapshot trace_stat available_filter_functions function_profile_enabled README stack_max_size tracing_cpumask available_tracers hwlat_detector saved_cmdlines stack_trace tracing_max_latency buffer_size_kb instances saved_cmdlines_size stack_trace_filter tracing_on buffer_total_size_kb kprobe_events set_event trace tracing_thresh current_tracer kprobe_profile set_ftrace_filter trace_clock uprobe_events dyn_ftrace_total_info max_graph_depth set_ftrace_notrace trace_marker uprobe_profile enabled_functions options set_ftrace_pid trace_options events per_cpu set_graph_function trace_pipe tracing 目录下的文件分成了下面四类: 提示类：显示当前系统可用的event，tracer 列表 控制类：控制 ftrace 的跟踪参数 显示类：显示 trace 信息 辅助类：一些不明或者不重要的辅助信息 提示类 ftrace 文件 作用 available_events 可用事件列表，也可查看 events/ 目录 available_filter_functions 当前内核导出的可以跟踪的函数 dyn_ftrace_total_info 显示available_filter_functins中跟中函数的数目 available_tracers 可用的 tracer，不同的 tracer 有不同的功能 events 1. 查看可用事件列表以及事件参数(事件包含的内核上下文信息) cat events/sched/sched_switch/format 2.设置事件的过滤条件 echo ’next_comm ~ “cs”’ \u003e events/sched/sched_switch/filter 控制类 适用 tracer ftrace 文件 作用 通用 tracing_on 用于控制跟踪打开或停止，0停止跟踪，1继续跟踪 通用 tracing_cpumask 设置允许跟踪特定CPU 通用 tracing_max_latency 记录Tracer的最大延时 通用 tracing_thresh 延时记录Trace的阈值，当延时超过此值时才开始记录Trace。单位是ms，只有非0才起作用 通用 events 1. 查看可用事件列表以及事件参数(事件包含的内核上下文信息) cat events/sched/sched_switch/format 2.设置事件的过滤条件 echo ’next_comm ~ “cs”’ \u003e events/sched/sched_switch/filter 通用 set_event 设置跟踪的 event 事件，与通过events目录内的 filter 文件设置一致 通用 current_tracer 1. 设置或者显示当前使用的跟踪器列表 2. 系统缺省为nop，可以通过写入nop重置跟踪器 3. 使用echo将跟踪器名字写入即可打开 echo function_graph \u003e current_tracer 通用 buffer_size_kb 设置单个CPU所使用的跟踪缓存的大小 如果跟踪太多，旧的信息会被新的跟踪信息覆盖掉 不想被覆盖需要先将current_trace设置为nop才可以 通用 buffer_total_size_kb 显示所有CPU ring buffer 大小之和 通用 trace_options trace 过程的复杂控制选项 控制Trace打印内容或者操作跟踪器 也可通过 options/目录设置 通用 options/ 显示 trace_option 的设置结果 也可以直接设置，作用同 trace_options func function_profile_enabled 打开此选项，trace_stat就会显示function的统计信息 echo 0/1 \u003e function_profile_enabled func set_ftrace_pid 设置跟踪的pid func set_ftrace_filter 用于显示指定要跟踪的函数 func set_ftrace_notrace 用于指定不跟踪的函数，缺省为空 graph max_graph_depth 函数嵌套的最大深度 graph set_graph_function 设置要清晰显示调用关系的函数 缺省对所有函数都生成调用关系 Stack stack_max_size 当使用stack跟踪器时，记录产生过的最大stack size Stack stack_trace 显示stack的back trace Stack stack_trace_filter 设置stack tracer不检查的函数名称 输出类 ftrace 文件 作用 printk_formats 提供给工具读取原始格式trace的文件 trace 查看 ring buffer 内跟踪信息 echo \u003e trace可以清空当前RingBuffer trace_pipe 输出和trace一样的内容，但输出Trace同时将RingBuffer清空 可避免RingBuffer的溢出 保存文件内容: cat trace_pipe \u003e trace.txt \u0026 snapshot 是对trace的snapshot echo 0清空缓存，并释放对应内存 echo 1进行对当前trace进行snapshot，如没有内存则分配 echo 2清空缓存，不释放也不分配内存 trace_clock 显示当前Trace的timestamp所基于的时钟，默认使用local时钟 local：默认时钟；可能无法在不同CPU间同步 global：不同CUP间同步，但是可能比local慢 counter：跨CPU计数器，需要分析不同CPU间event顺序比较有效 trace_marker 从用户空间写入标记到trace中，用于用户空间行为和内核时间同步 trace_stat 每个CPU的Trace统计信息 per_cpu/ trace等文件的输出是综合所有CPU的，如果你关心单个CPU可以进入per_cpu目录，里面有这些文件的分CPU版本 enabled_functions 显示有回调附着的函数名称 saved_cmdlines 放pid对应的comm名称作为ftrace的cache，这样ftrace中不光能显示pid还能显示comm saved_cmdlines_size saved_cmdlines的数目 trace、trace_pipe和snapshot的区别: trace是从RingBuffer中取出内容 trace_pipe会一直读取Buffer流。 snapshot是trace的一个瞬间快照： 辅助类 ftrace 文件 作用 free_buffer 此文件用于在一个进程被关闭后，同时释放RingBuffer内存，并将调整大小到最小值 instances 空目录，可在此目录创建新的 ftrace 实例 hwlat_detector kprobe_events kprobe_profile uprobe_events uprobe_profile ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:3:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"4. ftrace tracer 下面是 ftrace tracer 的不完全列表，每一个 tracer 输出的内容和格式都不一样，对于我们比较常用的是 Function，Graph，Schedule switch，softirq。 ftrace 作用 Function 跟踪函数调用 Function graph tracer 跟踪函数调用，显示调用关系 Schedule switch 跟踪进程调度情况 Wakeup 跟踪进程的调度延迟，即高优先级进程从进入 ready 状态到获得 CPU 的延迟时间。该 tracer 只针对实时进程 Irqsoff 当中断被禁止时，系统无法相应外部事件，比如键盘和鼠标，时钟也无法产生 tick 中断。这意味着系统响应延迟，irqsoff 这个 tracer 能够跟踪并记录内核中哪些函数禁止了中断，对于其中中断禁止时间最长的，irqsoff 将在 log 文件的第一行标示出来，从而使开发人员可以迅速定位造成响应延迟的罪魁祸首 Preemptoff 和前一个 tracer 类似，preemptoff tracer 跟踪并记录禁止内核抢占的函数，并清晰地显示出禁止抢占时间最长的内核函数 Preemptirqsoff 同上，跟踪和记录禁止中断或者禁止抢占的内核函数，以及禁止时间最长的函数 Branch 跟踪内核程序中的 likely/unlikely 分支预测命中率情况。 Branch tracer 能够记录这些分支语句有多少次预测成功。从而为优化程序提供线索 Hardware branch 利用处理器的分支跟踪能力，实现硬件级别的指令跳转记录。在 x86 上，主要利用了 BTS 这个特性 Initcall 记录系统在 boot 阶段所调用的 init call Mmiotrace 记录 memory map IO 的相关信息 Power 记录系统电源管理相关的信息 Sysprof 缺省情况下，sysprof tracer 每隔 1 msec 对内核进行一次采样，记录函数调用和堆栈信息 Kernel memory 内存 tracer 主要用来跟踪 slab allocator 的分配情况。包括 kfree，kmem_cache_alloc 等 API 的调用情况，用户程序可以根据 tracer 收集到的信息分析内部碎片情况，找出内存分配最频繁的代码片断，等等 Workqueue statistical 这是一个 statistic tracer，统计系统中所有的 workqueue 的工作情况，比如有多少个 work 被插入 workqueue，多少个已经被执行等。开发人员可以以此来决定具体的 workqueue 实现，比如是使用 single threaded workqueue 还是 per cpu workqueue Event 跟踪系统事件，比如 timer，系统调用，中断等 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:3:1","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"5. ftrace 的实战 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:4:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"5.1 跟踪进程调度 示例一我们来看看如何跟踪 Python 进程执行过程发生的进程调度: # 1. 假设我们要跟踪一个 Python 文件执行中的进程调度 \u003e vim run.py with open(\"./content.csv\") as bf: print(bf.readlines()) # 2. 将 ftrace 的选项写入脚本中 \u003e vim ftrace.sh py=/home/tao/debugs/tracing/ mkdir -pv $py echo nop \u003e $py/current_tracer echo 0 \u003e $py/tracing_on echo $$ \u003e $py/set_ftrace_pid echo \"sched:*\" \u003e $py/set_event #replace test_proc_show by your function name #echo test_proc_show \u003e $py/set_graph_function echo 1 \u003e $py/tracing_on exec \"$@\" # 3.启动跟踪并查看结果 \u003e bash ftrace.sh python ftrace.py \u0026\u0026 echo 0 \u003e /home/tao/debugs/tracing/tracing_on \u003e vim /home/tao/debugs/tracing/trace ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:4:1","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"5.2 跟踪系统调用 示例2 我们来看看如何跟踪系统调用。以 ls 命令为例，显示 do_sys_open 调用栈。 # 这次使用系统默认挂载的 debugfs $ cd /sys/kernel/debug/tracing/ # 1. 设置要显示调用栈的函数 $ echo do_sys_open \u003e set_graph_function # 2. 配置跟踪选项，开启函数调用跟踪，并跟踪调用进程 $ echo function_graph \u003e current_tracer $ echo funcgraph-proc \u003e trace_options # 3. 开启追踪 $ echo 1 \u003e tracing_on # 4. 执行一个 ls 命令后，再关闭跟踪： $ ls $ echo 0 \u003e tracing_on # 5.查看追踪结果 $ cat trace # tracer: function_graph # # CPU TASK/PID DURATION FUNCTION CALLS # | | | | | | | | | 0) ls-12276 | | do_sys_open() { 0) ls-12276 | | getname() { 0) ls-12276 | | getname_flags() { 0) ls-12276 | | kmem_cache_alloc() { 0) ls-12276 | | _cond_resched() { 0) ls-12276 | 0.049 us | rcu_all_qs(); 0) ls-12276 | 0.791 us | } 0) ls-12276 | 0.041 us | should_failslab(); 0) ls-12276 | 0.040 us | prefetch_freepointer(); 0) ls-12276 | 0.039 us | memcg_kmem_put_cache(); 0) ls-12276 | 2.895 us | } 0) ls-12276 | | __check_object_size() { 0) ls-12276 | 0.067 us | __virt_addr_valid(); 0) ls-12276 | 0.044 us | __check_heap_object(); 0) ls-12276 | 0.039 us | check_stack_object(); 0) ls-12276 | 1.570 us | } 0) ls-12276 | 5.790 us | } 0) ls-12276 | 6.325 us | } ... 输出: 第三列是函数执行延迟；最后一列，则是函数调用关系图。 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:4:2","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"6. trace-cmd trace-cmd 可以把上面这些步骤给包装起来，通过同一个命令行工具，就可完成上述所有过程。下面是示例2 中跟踪 do_sys_open 的 trace-cmd 版本。 # 1. 安装 $ yum install trace-cmd # 2. 启动追踪 $ trace-cmd record -p function_graph -g do_sys_open -O funcgraph-proc ls # 3. 查看追踪结果 $ trace-cmd report ... ls-12418 [000] 85558.075341: funcgraph_entry: | do_sys_open() { ls-12418 [000] 85558.075363: funcgraph_entry: | getname() { ls-12418 [000] 85558.075364: funcgraph_entry: | getname_flags() { ls-12418 [000] 85558.075364: funcgraph_entry: | kmem_cache_alloc() { ls-12418 [000] 85558.075365: funcgraph_entry: | _cond_resched() { ls-12418 [000] 85558.075365: funcgraph_entry: 0.074 us | rcu_all_qs(); ls-12418 [000] 85558.075366: funcgraph_exit: 1.143 us | } ls-12418 [000] 85558.075366: funcgraph_entry: 0.064 us | should_failslab(); ls-12418 [000] 85558.075367: funcgraph_entry: 0.075 us | prefetch_freepointer(); ls-12418 [000] 85558.075368: funcgraph_entry: 0.085 us | memcg_kmem_put_cache(); ls-12418 [000] 85558.075369: funcgraph_exit: 4.447 us | } ls-12418 [000] 85558.075369: funcgraph_entry: | __check_object_size() { ls-12418 [000] 85558.075370: funcgraph_entry: 0.132 us | __virt_addr_valid(); ls-12418 [000] 85558.075370: funcgraph_entry: 0.093 us | __check_heap_object(); ls-12418 [000] 85558.075371: funcgraph_entry: 0.059 us | check_stack_object(); ls-12418 [000] 85558.075372: funcgraph_exit: 2.323 us | } ls-12418 [000] 85558.075372: funcgraph_exit: 8.411 us | } ls-12418 [000] 85558.075373: funcgraph_exit: 9.195 us | } ... ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:5:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"参考 ftrace 简介 在Linux下做性能分析2：ftrace Linux ftrace框架介绍及运用 宋宝华：关于Ftrace的一个完整案例 ","date":"2020-01-03","objectID":"/posts/linux/linux_perf/03_ftrace/:6:0","tags":["Linux 性能调优"],"title":"2.1 ftrace 的原理与使用","uri":"/posts/linux/linux_perf/03_ftrace/"},{"categories":["Linux"],"content":"1.2 Linux 性能调优概览","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"为了调试和追踪程序的运行过程，Linux 提供了众多的分析工具，本节我们先对它们做一个宏观概览。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:0:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"1. 我们到底要优化什么 在我们了解接下来的各种工具之前，我们首先应该问自己，我们要追踪或者说我们要优化什么。我们都知道程序的运行会占用包括 CPU，内存，文件描述符，锁，磁盘，网络等等在内的各种操作系统资源。根据2/8定律，当其中的某一个或多个资源出现瓶颈的时候，我们需要找到程序中耗费资源最大的地方，并对其优化。 那么我们可能需要做如下这些事情: 对系统资源持续进行观测以及时发现哪些资源出现了瓶颈 统计各个程序(进程)，确定哪个或哪些进程占用了过多的资源 分析问题进程，找出其占用过量资源的原因。 所谓追踪技术本质上就是获取操作系统记录中程序运行的各种信息，所以尽管工具多种多样，但本质上都是查询操作系统\"数据\"的工具。在了解这些工具之前，我们非常有必要先去看看操作系统都提供了哪些数据查询接口，即操作系统提供给我们的观测来源。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:1:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2. 观测源 Linux 中的观测源被称为 event ，它是不同内核工具框架的统一接口，上面的图片说明了 event 来源: Hardware Events: CPU性能监视计数器 PMCs Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点，即静态探针 User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 内核维护了部分事件的计数器，通过 /proc 和 /sys 文件系统对外输出。 /proc 是一个提供内核统计信息的文件系统接口，将内核和进程的统计数据用目录树的形式暴露给用户空间。 /sys 最初设计用于提供设备驱动的统计信息，不过现在已经扩展到了提供所有信息的统计，/sys 同时也是调整内核参数的入口。 我们也可以各种分析工具，使用抽样的方式收集这些事件发生时内核的上下文信息。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2.1 PMCs PMCs 又称 PMU 全称为硬件计数器，也叫做性能监视计数器(pmmc)或性能仪表计数器(PICs)。它监测低层次的处理器活动，例如，CPU周期，指令退役，内存失速周期，二级缓存丢失，等等。其中一些将作为硬件缓存事件列出。 PMU计数器大部分CPU都有的功能。它可以在这些计数器的计数超过一个特定的值的时候产生一个中断，这个中断，我们可以用和时钟一样的方法，来抽样判断系统中哪个函数发生了最多的Cache失效，分支预测失效等。 典型的处理器将以以下方式实现pmc:在可用的数千个pmc中，只能同时记录几个pmc。这是因为它们是处理器上的固定硬件资源(寄存器的有限数量)，并且被编程为开始计算所选事件。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:1","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2.2 Software Events 除了 PMU 外，内核也维护了各种统计数据，称为计数器，包括 CPU migrations(处理器迁移次数), minor faults(soft page faults), major faults(hard page faults) 等等。这些数据一般都通过 /proc 文件系统对外输出。 如果开启了Linux 的CONFIG_TASK_DELAY_ACCT 选项，Linux 会跟踪每个任务的延时包括: 调度器延时: 等待 CPU 的延时 块 I/O: 等待块 I/O 的延时 交换: 等待换页的延时 内存回收: 等待内存回收的延时 用户空间的工具通过 taskstats 可以读取这些统计数据，部分统计数据也会通过 /proc 对外提供。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:2","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2.3 Kernel Tracepoints 静态探针 tracepoints ，是散落在内核源代码中的一些 hook，开启后，它们便可以在特定的代码被运行到时被触发。可以用来跟踪特定的事件。 如果你看过内核源码，经常会看到下面这种 trace_开头的函数调用： if (likely(prev != next)) { rq-\u003enr_switches++; rq-\u003ecurr = next; ++*switch_count; trace_sched_switch(preempt, prev, next); # trace_ 开头的函数调用 rq = context_switch(rq, prev, next, cookie); /* unlocks the rq */ } else { lockdep_unpin_lock(\u0026rq-\u003elock, cookie); raw_spin_unlock_irq(\u0026rq-\u003elock); } trace_sched_switch 就是一个事件，程序执行到这个地方就会把这个点（就是一个整数，而不是函数名），加上后面的三个参数（preempt, prev, next)都写到缓冲区中。ftrace 可以读取并保存这些信息，perf 可以在事件被触发时收到通知，dtrace 和 systemtap 可以在事件触发时执行指定的 “action”。 这些跟踪点被硬编码在内核的有用的位置上，以便更高层次的行为可以很容易地被跟踪。例如，系统调用、TCP事件、文件系统I/O、磁盘I/O等等。它们被分组到跟踪点库中;例如，“sock:”表示套接字事件，“sched:”表示CPU调度器事件。跟踪点的一个关键价值是它们应该有一个稳定的API，因此如果您编写的工具在一个内核版本上使用它们，那么它们也应该适用于以后的版本。 Tracepoints 通常通过放置在 include/trace/events/*.XXX 中的宏添加到内核代码中来实现。 下面是 Linux4.10 系统上对 tracepoint 库和数量的统计。 \u003e perf list | awk -F: '/Tracepoint event/ { lib[$1]++ } END { for (l in lib) { printf \" %-16.16s %d\\n\", l, lib[l] } }' | sort | column alarmtimer 4 i2c 8 page_isolation 1 swiotlb 1 block 19 iommu 7 pagemap 2 syscalls 614 btrfs 51 irq 5 power 22 task 2 cgroup 9 irq_vectors 22 printk 1 thermal 7 clk 14 jbd2 16 random 15 thermal_power_ 2 cma 2 kmem 12 ras 4 timer 13 compaction 14 libata 6 raw_syscalls 2 tlb 1 cpuhp 3 mce 1 rcu 1 udp 1 dma_fence 8 mdio 1 regmap 15 vmscan 15 exceptions 2 migrate 2 regulator 7 vsyscall 1 ext4 95 mmc 2 rpm 4 workqueue 4 fib 3 module 5 sched 24 writeback 30 fib6 1 mpx 5 scsi 5 x86_fpu 14 filelock 10 msr 3 sdt_node 1 xen 35 filemap 2 napi 1 signal 2 xfs 495 ftrace 1 net 10 skb 3 xhci-hcd 9 gpio 2 nmi 1 sock 2 huge_memory 4 oom 1 spi 7 这些包括: block: 块设备I/O ext4: 文件系统操作 kmem: 内核内存分配事件 random: 内核随机数生成器事件 sched: CPU调度器事件 random: 系统调用的进入和返回 task: 任务事件 在每次内核升级之后，都有必要检查跟踪点列表，看看是否有新的跟踪点。添加它们是经过充分考虑的，包括评估有多少人会使用它们。需要实现一个平衡:我将包括尽可能少的探测，以充分满足常见需求，任何不寻常或不常见的情况都可以留给动态跟踪。 有关使用跟踪点的示例，请参见静态内核跟踪。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:3","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2.4 User-Level Statically Defined Tracing (USDT) 与内核跟踪点类似，这些跟踪点是硬编码的(通常通过将宏放置在应用程序源代码中)，并作为稳定的API呈现(事件名称和参数)。许多应用程序已经包括跟踪点，这些跟踪点是为了支持DTrace而添加的。然而，许多这些应用程序在Linux上默认情况下并不编译它们。通常需要使用—with-dtrace标志自己编译应用程序。 例如，用这个版本的Node.js编译USDT事件: $ sudo apt-get install systemtap-sdt-dev # adds \"dtrace\", used by node build $ wget https://nodejs.org/dist/v4.4.1/node-v4.4.1.tar.gz $ tar xvf node-v4.4.1.tar.gz $ cd node-v4.4.1 $ ./configure --with-dtrace $ make -j 8 检查产生的二进制程序是否包含了 USDT 探测点: $ readelf -n node 有关使用USDT事件的示例，请参见静态用户跟踪。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:4","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2.5 Dynamic Tracing 静态探针跟动态探针之间的区别在于: 静态探针是在编译之前就已经存在代码中的。动态探针是在编译之后软件运行时才加入的，本质上是内核地址空间的现场修改(live patching)，所采用的的技术会因处理器类型的不同而有所不同。它们覆盖的范围如下图所示: 虽然动态跟踪可以看到所有东西，但它也是一个不稳定的接口，因为它检测的是原始代码。这意味着您开发的任何动态跟踪工具在内核补丁或更新之后可能会中断。首先尝试使用静态跟踪点，因为它们的接口应该更加稳定。它们也更容易使用和理解，因为它们是为跟踪最终用户而设计的。 动态跟踪的一个好处是，它可以在活动的系统上启用，而不需要重新启动任何东西。您可以使用一个已经运行的内核或应用程序，然后开始动态检测，它(安全地)在内存中修补指令以添加检测。这意味着在您开始使用此功能之前，此功能的开销或税收为零。这一刻，您的二进制文件还在以全速运行，而下一刻，它又在运行一些您动态添加的额外的检测指令。当您使用完动态跟踪会话后，这些指令最终应该被删除。 在使用动态跟踪和执行额外指令时的开销，与插装事件的频率乘以在每个插装上所做的工作有关。 kprobes 和 uprobes kprobes 和 uprobes 机制就是我们所说的动态探针。它们可以在指定的探测点(比如函数的某行, 函数的入口地址和出口地址, 或者内核的指定地址处)插入一组处理程序。kprobes 主要用于调试内核，uprobes 类似 kprobes, 不过主要用于用户空间的追踪调试。它们作用的位置如下图所示: 内核参数 使用动态追踪需要启用如下的内核参数: 内核动态跟踪需要启用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y 用户级动态跟踪需要启用 CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y 为避免内核栈指针优化，需要启用 CONFIG_FRAME_POINTER=y ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:2:5","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"3. 观测工具 按照使用的观测源的不同，我们可以将调优工具分为以下三种: 计数器类 跟踪 剖析 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:3:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"3.1 计数器类 计数器类工具读取并展示内核和进程各种统计信息，包括 top，vmstat，mpstat，iostat 等绝大多数我们常用的系统命令。它们的使用可以认为是无成本，因为计数器由内核维护的。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:3:1","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"3.2 跟踪 跟踪指的是跟踪每一个事件的详细数据，相关的工具包括: tcpdump: 网络报跟踪 blktrace: 块 I/O 跟踪 execsnoop: 跟踪新进程(位于后面要讲的高级工具中) 跟踪捕获数据会有 CPU 开销，还需要存储空间存放数据，会拖慢跟踪对象，因此在使用时需要注意工具自身对观测对象的影响。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:3:2","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"3.3 剖析 剖析通过对目标收集采样或快照来归纳目标特征。跟踪是查看事件的详细数据，剖析可以理解为对事件的统计，以了解系统和程序当前运行的全貌。各种静态和动态追踪技术是完成跟踪和剖析的主要工具。也是我们接下来要介绍的难点内容。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:3:3","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4. 动态追踪技术 下面是一个追踪技术的不完全列表。 工具 使用的 event 特点 ftrace 静态探针 内核的动态探针 1.总体跟踪法，统计了一个事件到下一个事件所有的时间长度 2.可以知道整个系统运行在时间轴上的分布 3.方法很准确，但跟踪成本很高，只能跟踪内核程序 perf 全部的 event 1.抽样跟踪，需要注意抽样导致的结果是否准确 2.直接跟踪到整个系统的所有程序 perf通常是我们分析系统性能的第一步 Dtrace Solaris 的动态追踪技术 Systemtap Linux 的动态追踪技术 eBPF Linux 4.x 以上版本的动态追踪技术 在介绍这些工具之前，需要强调的是，无论什么动态追踪技术依赖的都是上面所说的内核工具框架的统一接口-events。它们都需要通过 event 去采集内核或者应用程序的运行信息。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4.1 ftrace ftrace 最早用于函数跟踪，后来又扩展支持了各种事件跟踪功能。ftrace 的使用接口跟我们之前提到的 procfs 类似，它通过 debugfs（4.1 以后也支持 tracefs），以普通文件的形式，向用户空间提供访问接口。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:1","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4.2 perf perf 主要功能是事件记录和分析，这实际上只是一种最简单的静态跟踪机制。你也可以通过 perf ，来自定义动态事件（perf probe），只关注真正感兴趣的事件。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:2","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4.3 Dtrace Solaris 系统的 DTrace 是动态追踪技术的鼻祖，它提供了一个通用的观测框架，并可以使用 D 语言进行自由扩展。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:3","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4.4 Systemtap DTrace 本身依然无法在 Linux 中运行。很多工程师都尝试过把 DTrace 移植到 Linux 中，这其中，最著名的就是 RedHat 主推的 SystemTap。 同 DTrace 一样，SystemTap 也定义了一种类似的脚本语言，方便用户根据需要自由扩展。不过，不同于 DTrace，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。 为了追踪内核或用户空间的事件，Dtrace 和 SystemTap 都会把用户传入的追踪处理函数（一般称为 Action），关联到被称为探针的检测点上。这些探针的检测点就是各种 events。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:4","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"4.3 eBPF eBPF 则在 BPF（Berkeley Packet Filter）的基础上扩展而来，不仅支持事件跟踪机制，还可以通过自定义的 BPF 代码（使用 C 语言）来自由扩展。所以，eBPF 实际上就是常驻于内核的运行时，可以说就是 Linux 版的 DTrace。 ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:4:5","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"参考 Linux 系统动态追踪技术介绍 在Linux下做性能分析2：ftrace ","date":"2020-01-02","objectID":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/:5:0","tags":["Linux 性能调优"],"title":"1.2 Linux 性能调优概览","uri":"/posts/linux/linux_perf/02_linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"1.1 Linux 性能调优入门指南","date":"2020-01-01","objectID":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/","tags":["Linux 性能调优"],"title":"1.1 Linux 性能调优入门指南","uri":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":" 这个系列文章，目的是学习一下 Linux 的性能优化，希望下一次服务器出问题时，不是只会一个 top。Linux 性能优化与 Linux 操作系统密切相关，所以想要学好非常不容易。 ","date":"2020-01-01","objectID":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/:0:0","tags":["Linux 性能调优"],"title":"1.1 Linux 性能调优入门指南","uri":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"1. 系列大纲 下面是 Linux 性能优化系列文章的大纲: 动态追踪: 将介绍常见的静态和动态追踪技术的原理和使用，包括 ftrace，perf，DTrace，Systemtap 等 操作系统：将介绍 CPU，内存，文件系统，磁盘，网络的基本原理以及可监测它们的工具(命令) 高级工具: 将介绍基于动态追踪技术的一些高级工具，包括: perf-tool systemtap-lwtools DTraceToolkit bpf-perf-tools bpf-bcc openresty-systemtap openresty_stapxx 高级语言性能优化: 将介绍如何利用上面介绍的工具，对 Python，Go，Java 进行性能调优，使用这些工具的好处是语言无关，更加具有普适性。 ","date":"2020-01-01","objectID":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/:1:0","tags":["Linux 性能调优"],"title":"1.1 Linux 性能调优入门指南","uri":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"2. 学习资源 下面是我在学习过程中发现的学习资源，推荐大家阅读。本系列的文章也参考了很多他们的内容，在此特别说明。 《性能之巅》 极客时间专栏-Linux性能优化实战 动态追踪技术漫谈 Systemtap: 优秀的systemtap学习资源 SystemTap新手指南中文 SystemTap Tapset Reference Manual Python: 使用 DTrace 和 SystemTap 检测 CPython ","date":"2020-01-01","objectID":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/:2:0","tags":["Linux 性能调优"],"title":"1.1 Linux 性能调优入门指南","uri":"/posts/linux/linux_perf/01_linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88/"},{"categories":["Linux"],"content":"30.2 zabbix安装与入门","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"zabbix安装与入门 前面我们对一个完整的监控系统包含的内容做了一个简单概述，各种监控系统的开源实现无非都是围绕我们介绍的内容展开。在监控系统的众多实现中 zabbix 最为常见，功能也最为强大，本节我们首先对 zabbix 做个详细介绍，内容包括: zabbix 的框架与组成 zabbix 的安装和配置 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. zabbix zabbix 当前长期维护的版本有三个，2.2，3.0，4.0，本节我们就以3.0 为例来讲解。 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 zabbix 特性 zabbix 支持以下特性: 数据采样: snmp, agent, ipmi, jmv 报警升级功能 数据存储: mysql, pgsql 展示: php 程序，实时绘图，支持 支持模板: 支持网络主机自动发现 通过监控代理，支持分布式监控 支持二次开发 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.2 zabbix 系统架构 agent 监控模式 数据采集的有两种方式: 被动模式: zabbix server 向 zabbix agent pull 数据 主动模式: zabbix agent 主动向 zabbix server push 数据 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.3 zabbix 逻辑组件 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:1:3","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2. zabbix 安装配置 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:2:0","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.1 zabbix serve 安装配置 默认的 epel 在配置 zabbix 过程中出现了问题，因此需要为 zabbix 配置 yum 源。参考 zabbix document # 1. zabbix database - mysql ## 1.1 安装配置 mysql yum install mariadb-server vim /etc/my.cnf [mysqld] skip_name_resolve = ON innodb_file_per_table = ON systemctl start mariadb-server systemctl enabled mariadb-server mysql_secure_installation ### 1.2 为 zabbix 创建 mysql 用户 mysql -uroot -p1234 \u003e create database zabbix character set utf8 collate utf8_bin; \u003e grant all on zabbix.* to 'zabbix'@'192.168.%.%' identified by 'zbxpass'; \u003e grant all on zabbix.* to 'zabbix'@'127.0.0.1' identified by 'zbxpass'; \u003e flush privileges; # 2. zabbix server ## 2.1 配置 zabbix yum 源 rpm -i http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm ## 2.2 安装 zabbix server $ yum list zabbix-* 已安装的软件包 zabbix-release.noarch 3.0-1.el7 installed 可安装的软件包 zabbix-agent.x86_643.0.22-1.el7 zabbix zabbix-get.x86_64 3.0.22-1.el7 zabbix zabbix-java-gateway.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-sqlite3.x86_64 3.0.22-1.el7 zabbix zabbix-sender.x86_64 3.0.22-1.el7 zabbix zabbix-server-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-server-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-web.noarch 3.0.22-1.el7 zabbix zabbix-web-japanese.noarch 3.0.22-1.el7 zabbix zabbix-web-mysql.noarch 3.0.22-1.el7 zabbix zabbix-web-pgsql.noarch 3.0.22-1.el7 zabbix yum install zabbix-server-mysql.x86_64 $ rpm -ql zabbix-server-mysql.x86_64 /etc/zabbix/zabbix_server.conf # zabbix server 配置文件 /usr/lib/systemd/system/zabbix-server.service # unit file /usr/lib/zabbix/alertscripts /usr/lib/zabbix/externalscripts /usr/sbin/zabbix_server_mysql /usr/share/doc/zabbix-server-mysql-3.0.22 /usr/share/doc/zabbix-server-mysql-3.0.22/create.sql.gz # zabbix 数据库初始化 ## 2.3 导入数据库脚本生成数据库环境 gzip -d /usr/share/doc/zabbix-server-mysql-3.0.22/create.sql -c \u003e\u003e/root/create.sql mysql -uroot -p1234 zabbix \u003c /root/create.sql ## 2.4 zabbix serve 配置启动 $ grep ^##### /etc/zabbix/zabbix_server.conf ############ GENERAL PARAMETERS ################# ############ ADVANCED PARAMETERS ################ ####### LOADABLE MODULES ####### ####### TLS-RELATED PARAMETERS ####### SourceIP=192.168.1.106 LogFile=/var/log/zabbix/zabbix_server.log LogFileSize=0 PidFile=/var/run/zabbix/zabbix_server.pid DBHost=192.168.1.106 DBName=zabbix DBUser=zabbix DBPassword=zbxpass SNMPTrapperFile=/var/log/snmptrap/snmptrap.log Timeout=4 AlertScriptsPath=/usr/lib/zabbix/alertscripts ExternalScripts=/usr/lib/zabbix/externalscripts LogSlowQueries=3000 ## 2.5 服务启动 systemctl start zabbix-server # 3. 安装 zabbix web gui ## 3.1 安装 lamp 以及 zabbix web yum install zabbix-web.noarch zabbix-web-mysql.noarch yum install httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml -y ## 3.2 zabbix web httpd 配置文件 rpm -ql zabbix-web /etc/httpd/conf.d/zabbix.conf /etc/zabbix/web # web 根目录 vim /etc/httpd/conf.d/zabbix.conf php_value date.timezone Asia/ShangHai # 根改时区 ## 3.3 启动 httpd systemctl start httpd ## 3.4 web 初始化 http://192.168.1.106/zabbix/setup.php ## 3.5 初始化生成的配置文件位于 /etc/zabbix/web/zabbix.conf.php ## 3.6 登陆，初始化的帐号: Admin 密码: zabbix ## 密码保存在 mysql zabbix.users 中 ## select * from zabbix.users ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:2:1","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.2 zabbix agent 配置 # 1. 安装 yum install zabbix-sender.x86_64 zabbix-agent.x86_64 -y # 2. 配置 $ rpm -ql zabbix-agent /etc/logrotate.d/zabbix-agent /etc/zabbix/zabbix_agentd.conf # agent 配置文件 /etc/zabbix/zabbix_agentd.d /etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf /usr/lib/systemd/system/zabbix-agent.service # unit file /usr/lib/tmpfiles.d/zabbix-agent.conf /usr/sbin/zabbix_agentd $ grep -i \"^####\" /etc/zabbix/zabbix_agentd.conf ############ GENERAL PARAMETERS ################# ##### Passive checks related # 被动监控配置项 ##### Active checks related # 主动监控配置 ############ ADVANCED PARAMETERS ################# ####### USER-DEFINED MONITORED PARAMETERS ####### # 用户自定义的监控参数 UserParamter ####### LOADABLE MODULES ####### ####### TLS-RELATED PARAMETERS ####### ##### Passive checks related Server=IP1,IP2... # 访问控制授权，允许哪些主机过来采集数据 ListenIP=0.0.0.0 StartAgents=3 ##### Active checks related ServerActive=IP1,IP2... # 主动报告的目标主机地址 Hostname=node1 # 当前被监控主机在 zabbix 中的 id # 3. 启动服务 systemctl start zabbix-agent ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:3:0","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3. 监控配置 在 zabbix 中快速配置一个监控需要按照如下顺序: 监控配置: host group--\u003e host--\u003e application--\u003e item--\u003etrriger---\u003eaction(conditons, operations) 展示配置: item --\u003e simple graph items --\u003e graphs ---\u003e screen --\u003e slide show 每一个监控项 item 对应着一个 item key，其代表了在被检控主机上要执行的命令。 ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:4:0","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.1 zabbix 监控测试 yum install zabbix-get.x86_64 zabbix_get -s 192.168.1.155 -k \"system.cpu.switches\" ","date":"2018-11-11","objectID":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/:4:1","tags":["马哥 Linux"],"title":"30.2 zabbix安装与入门","uri":"/posts/linux/linux_mt/33-zabbix/zabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"30.1 运维故障发现与监控系统应用","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"运维故障发现思路与监控系统应用 运维领域有一句话\"我们不应该允许没有被监控的系统上线的\"，显然监控对于我们快速发现问题解决问题至关重要。本章我们就来学习最常用的监控系统 zabbix 的安装，配置和使用。 在学习 zabbix 之前，我们首先需要对 zabbix 本身有所理解，因为无论是 zabbix 还是其他开源实现都是一种特定的解决方案，而不便的是怎样构建监控系统本身。 假设我们从头构建一个监控系统，应该如何做呢？我们需要思考以下几个问题: 监控哪些内容? 如何对监控项进行数据采集 如何判断系统是否处于非稳定状态，并在确定异常之后预警 如何能快速了解当前系统的状态及展示的问题。 这些问题就是我们构建一个监控系统的关键。因此一个完整的监控系统至少应该包含以下几个功能: 数据采集: 定期的采集监控指标的数据 数据存储: 将采集的数据保存起来，以便通过对比了解当前系统的状态 数据展示: 将存储的指标数据，直观的展示出来，以便运维工程师快速的了解整个系统的运行状态 报警: 当系统出现问题时，能发出报警及时通知管理员进行修复 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:0:0","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. 监控系统 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:0","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.1 监控内容 监控包含多个层面: 硬件: 硬件状态是否，硬件设备的资源是否满足业务需要，比如 CPU 使用率是否一直超过 90% 软件: 软件是否正成工作，比如我们的 nginx 服务进程是否正常 业务: 当前系统的并发请求数是否过高 不同的监控内容需要不同的监控设备以帮助我们收集监控数据，我们将监控设备称之为“传感器”(sensor)。 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:1","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.2 数据采集 监控系统采集数据的通道通常包括 ssh/telnet agent: master/agent IPMI: 英特尔智慧平台接口，允许在硬件层级直接收集系统硬件状态信息 SNMP: Simple Network Management Protocol JMX: java 管理扩展，用于监控 jvm 虚拟机 yum info net-snmp # linux snmp 协议的实现 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:2","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.3 存储系统 监控数据分为两类: 历史数据: 每一次的采样数据，保存时间长较短 趋势数据: 一段时间内的聚合数据，保存时间较长 1.4 报警 预警有多种方式，包括邮件，短信，微信，除了通用的邮件预警外，其他大多数的预警方式都是通过脚本来实现的。 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:3","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.5 展示 数据展示有 WebGui，GUI，APP 等方式 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:4","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.6 监控系统的实现 cactl， nagios: 功能有限 zabbix: 功能强大 ","date":"2018-11-10","objectID":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/:1:5","tags":["马哥 Linux"],"title":"30.1 运维故障发现与监控系统应用","uri":"/posts/linux/linux_mt/33-zabbix/%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"29.9 ansible 最佳实践","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"ansible 最佳实践 当我们刚开始学习运用 playbook 时，可能会把 playbook 写成一个很大的文件，到后来可能你会希望这些文件是可以方便去重用的，所以需要重新去组织这些文件。ansible 支持 include 语法对 tasks, handlers, playbook 进行引用，从而我们可以对基础的通用功能进行封装，通过 “include” 对通用的功能进行组装从而实现复用。 ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:0:0","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"1. include ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:1:0","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"1.1 task include tasks: - include: wordpress.yml wp_user=timmy - include: wordpress.yml wp_user=alice - include: wordpress.yml wp_user=bob # Ansible 1.4 及以后的版本 tasks: - { include: wordpress.yml, wp_user: timmy, ssh_keys: [ 'keys/one.txt', 'keys/two.txt' ] } # 传递结构化变量 tasks: - include: wordpress.yml vars: wp_user: timmy some_list_variable: - alpha - beta - gamma ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:1:1","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"1.2 playbook include - name: this is a play at the top level of a file hosts: all remote_user: root tasks: - name: say hi tags: foo shell: echo \"hi...\" - include: load_balancers.yml - include: webservers.yml - include: dbservers.yml ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:1:2","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"2. ansible 最佳实践 ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:2:0","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"2.1 项目目录结构 一个完整的 ansible 项目，顶层目录结构应当包括下列文件和目录，如果你正在使用云服务，使用动态清单会更好。 production # inventory file for production servers 关于生产环境服务器的清单文件 stage # inventory file for stage environment 关于 stage 环境的清单文件 group_vars/ group1 # here we assign variables to particular groups 这里我们给特定的组赋值 group2 # \"\" host_vars/ hostname1 # if systems need specific variables, put them here 如果系统需要特定的变量,把它们放置在这里. hostname2 # \"\" library/ # if any custom modules, put them here (optional) 如果有自定义的模块,放在这里(可选) filter_plugins/ # if any custom filter plugins, put them here (optional) 如果有自定义的过滤插件,放在这里(可选) site.yml # master playbook 主 playbook webservers.yml # playbook for webserver tier Web 服务器的 playbook dbservers.yml # playbook for dbserver tier 数据库服务器的 playbook roles/ common/ # this hierarchy represents a \"role\" 这里的结构代表了一个 \"role\" tasks/ # main.yml # \u003c-- tasks file can include smaller files if warranted handlers/ # main.yml # \u003c-- handlers file templates/ # \u003c-- files for use with the template resource ntp.conf.j2 # \u003c------- templates end in .j2 files/ # bar.txt # \u003c-- files for use with the copy resource foo.sh # \u003c-- script files for use with the script resource vars/ # main.yml # \u003c-- variables associated with this role defaults/ # main.yml # \u003c-- default lower priority variables for this role meta/ # main.yml # \u003c-- role dependencies webtier/ # same kind of structure as \"common\" was above, done for the webtier role monitoring/ # \"\" fooapp/ # \"\" ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:2:1","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"2.2 playbook 通过 include 将独立分散的 ansible 任务整合在一起 --- # file: site.yml # 顶层的 site - include: webservers.yml - include: dbservers.yml --- # file: webservers.yml # webservers 的配置 - hosts: webservers roles: - common - webtierv 理念是我们能够通过 “运行”(running) site.yml 来选择整个基础设施的配置.或者我们能够通过运行其子集 webservers.yml 来配置. 这与 Ansible 的 --limit 类似,而且相对的更为显式: ansible-playbook site.yml --limit webservers ansible-playbook webservers.yml ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:2:2","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"2.3 任务执行 # 想重新配置整个基础设施,如此即可: ansible-playbook -i production site.yml # 那只重新配置所有的 NTP 呢？太容易了.: ansible-playbook -i production site.yml --tags ntp # 只重新配置我的 Web 服务器呢？: ansible-playbook -i production webservers.yml #只重新配置我在波士顿的 Web服务器呢?: ansible-playbook -i production webservers.yml --limit boston ","date":"2018-11-09","objectID":"/posts/linux/linux_mt/32-ansible/ansible_practice/:2:3","tags":["马哥 Linux"],"title":"29.9 ansible 最佳实践","uri":"/posts/linux/linux_mt/32-ansible/ansible_practice/"},{"categories":["Linux"],"content":"29.8 ansible role","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"ansible role role 角色，基于一个已知的文件结构，去自动的加载某些 vars_files，tasks 以及 handlers。基于 roles 对内容进行分组，使得我们可以容易地与其他用户分享 roles。 roles 是 playbook 的一个独立自包含目录，包含了执行 playbook 任务所有的配置文件及被操作文件，使得 playbook 的执行不需要依赖于任何外部环境。 ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:0:0","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"1. roles 使用 ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:1:0","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"1.1 roles 目录结构 一个包含 roles 的典型项目结构如下所示，如果你在 playbook 中同时使用 roles 和 tasks，vars_files 或者 handlers，roles 将优先执行。 webservers.yml roles/ webservers/ # 与 playbook 对应的 roles 目录 files/ # copy tasks，script tasks，引用 roles/x/files/ 中的文件无需指明路经 templates/ # template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径 tasks/ # main.yml 存在, 其中列出的 tasks 将被添加到 webservers.yml 中 handlers/ # main.yml 存在, 其中列出的 handlers 将被添加到 play 中 vars/ # main.yml 存在, 其中列出的 variables 将被添加到 play 中 defaults/ # main.yml 用于定义默认变量，这些变量在所有可用变量中拥有最低优先 meta/ # main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 (1.3 and later) ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:1:1","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"1.2 roles 使用 角色的使用，只需在 playbook 的 roles 语句中添加角色即可 # vim webservers.yml --- - hosts: webservers roles: - common - webservers 也可以使用参数化的 roles，这种方式通过添加变量来实现 --- - hosts: webservers roles: - common - { role: foo_app_instance, dir: '/opt/a', port: 5000 } - { role: foo_app_instance, dir: '/opt/b', port: 5001 } 也可以为 roles 设置触发条件 --- - hosts: webservers roles: - { role: some_role, when: \"ansible_os_family == 'RedHat'\" } 最后，也可以给 roles 分配指定的 tags。比如: --- - hosts: webservers roles: - { role: foo, tags: [\"bar\", \"baz\"] } ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:1:2","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"1.3 执行顺序 如果 play 同时包含 tasks 和roles，这些 tasks 将在所有 roles 应用完成之后才被执行。如果你希望定义一些 tasks，让它们在 roles 之前以及之后执行，你可以这样做: --- - hosts: webservers pre_tasks: - shell: echo 'hello' roles: - { role: some_role } tasks: - shell: echo 'still busy' post_tasks: - shell: echo 'goodbye' ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:1:3","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"1.4 角色依赖 角色依赖可以自动地将其他 roles 拉取到现在使用的 role 中。角色依赖保存在 roles 目录下的 meta/main.yml 文件中。这个文件应包含一列 roles 和 为之指定的参数 --- dependencies: - { role: common, some_parameter: 3 } - { role: apache, port: 80 } - { role: postgres, dbname: blarg, other_parameter: 12 } “角色依赖” 总是在 role （包含”角色依赖”的role）之前执行，并且是递归地执行。默认情况下，作为 “角色依赖” 被添加的 role 只能被添加一次，如果另一个 role 将一个相同的角色列为 “角色依赖” 的对象，它不会被重复执行。但这种默认的行为可被修改，通过添加 allow_duplicates: yes 到 meta/main.yml 文件中。 # wheel 角色中 --- allow_duplicates: yes dependencies: - { role: tire } - { role: brake } # 引用 wheel 的其他角色 --- dependencies: - { role: wheel, n: 1 } - { role: wheel, n: 2 } - { role: wheel, n: 3 } - { role: wheel, n: 4 } ","date":"2018-11-08","objectID":"/posts/linux/linux_mt/32-ansible/ansible_roles/:1:4","tags":["马哥 Linux"],"title":"29.8 ansible role","uri":"/posts/linux/linux_mt/32-ansible/ansible_roles/"},{"categories":["Linux"],"content":"29.7 ansible playbook","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"ansible playbook playbook 是 基于 yaml 语法的一种编排 ansible 命令的\"脚本\"，类似与 shell scritp；但是 playbook 并不是一门语言。我的理解是 playbook 就是一个配置文件，必需按照 ansible 要求的特定格式编排 ansible 的任务，这样 ansible 才能对其进行解释并执行。其能提供的功能是由 ansible 决定的。我们的目的就是学习 playbook 特定的编写要求。 相对于 ad-doc 的好处类似于 shell script 之与 shell 命令，可以重复执行，拥有更加强大的逻辑控制，因此便于执行更复杂的任务。 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:0:0","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"1. playbook 配置语法 下面是一个 playbook 的示例，我们将以这个示例为基础讲解如何编写 playbook。playbook 使用的 yaml 语法，因此在学习接下来的内容之前你需要先了解一下 yaml。 --- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:1:0","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"1.1 playbook的核心元素 - host: vars: remote_user: tasks: - - - variables: - - - handlers: - - - host: - host: 我们将 playbook 的配置语法分成两个部分来看，第一部分是基本的核心元素，使用这些元素我们就完全可以定义 ansible 的任务，包括 host: 任务要操作的主机，用法与 ansible \u003chost-pattern\u003e 选项相同 remote_user: 登陆的被管控主机的用户 tasks: 任务列表 handlers: 触发器， 第二部分是为了提高任务编排效率而额外提供的扩展语法包括 var: 变量 templates: 模板，模板可以利用 ansible 中的变量，为主机定义配置文件 when: 条件判断，比如可以依据操作系统类型决定安装什么，怎么安装模块，启动服务等 with_item: 循环，比如可以批量安装多个程序包，而不用定义多个任务 roles: 角色，抽象和独立 ansible 任务，使其可以自包含，便于移植。 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:1:1","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"1.2 核心元素 host \u0026 remote_user host \u0026 remote_user 定义要操作的主机以及以哪个用户身份去完成要执行的步骤。host 是一个或多个组或主机的 patterns与 ansible 的 \u003chost-pattern\u003e 选项使用完全一致，详细内容已经在上一节阐述在此不再累述。 --- - hosts: webservers remote_user: yourname sudo: yes sudo_user: postgres tasks: - service: name=nginx state=started remote_user: root sudo: yes sudo_user: root task task 用于定义任务列表，任务的执行是从上而下顺序执行的，且只有在所有匹配到的 host 均执行完当前的任务之后，才会继续执行下一个任务。如果某一 host 在执行任务中失败，它将会从 host 中移除，不会继续执行接下来的任务。 每个 task 的目标在于执行一个 moudle, 通常是带有特定的参数来执行.在参数中可以使用变量（variables）。 # 任务用于执行特定的模块，且必需具有 name tasks: - name: make sure apache is running service: name=httpd state=running # shell|command 执行命令的成功返回状态码非 0 时 tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true tag: run # 使用命令 tasks: - name: create a virtual host file for {{ vhost }} template: src=somefile.j2 dest=/etc/httpd/conf.d/{{ vhost }} 需要注意的是还可以为每个任务定义标签，在执行 ansible-playbook 时通过 -t TAGS, --tags=TAGS 选项，只运行指定标签对应的任务。 handlers Handlers 也是一些 task 的列表,通过名字来引用,它们和一般的 task 并没有什么区别.Handlers 是由通知者进行 notify, 如果没有被 notify,handlers 不会执行.不管有多少个通知者进行了 notify,等到 play 中的所有 task 执行完成之后,handlers 也只会被执行一次. Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了. tasks - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: # 按名称触发 handlers - restart memcached - restart apache handlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:1:2","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"2. 变量与模板 为了为不同的目标主机自定义配置文件，ansible 引入了 python jinja2 的模板。通过将配置文件中与目标主机相关的配置参数(比如网卡，绑定的 ip 地址)定义成模板中变量，来达到为每个主机自定义配置文件的目的。 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:2:0","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"2.1 模板 ansible 中使用的模板是 python 的 jinja2，因此在创建模板之前，有必要学习一下如何定义 jinja2 模板，而将模板填充为文件，需要使用 ansible template 模块 task - name: nginx confiure - template: src=/var/template/nginx.j2 dest=/etc/nginx/nginx.conf ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:2:1","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"2.1 变量的定义 ansible 中变量的定义有如下几种方式: Facts中生成的变量: facts 生成的是远程目标主机的所有系统信息，可通过 ansible -m setup 查看 命令行中传递变量： ansible-playbook --extra-vars \"name=value name=value\" 或 --extra-vars \"@some_file.json\" 通过 inventory 主机清单传递变量，这种方式我们在 32.5 ansible简介 详细讲解过配置方法 通过 var 在 playbook 中自定义变量，这种定义方式还可以将变量独立到特定的文件中 通过 role 定义的变量，这种定义变量的方式我们会在下一节详细介绍 - hosts: webservers vars: - http_port: 80 vars_files: - /vars/external_vars.yml ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:2:2","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"2.2 变量的作用顺序 在 ansible 中最好不要重复定义变量，保持 ansible 配置文件的简洁有助于我们维护和排错，如果相同的变量出现在不同的，其作用顺序由高到低如下所示 * extra vars (在命令行中使用 -e)优先级最高 * 然后是在inventory中定义的 inventory 参数(比如ansible_ssh_user) * 接着是大多数的其它变量(命令行转换,play中的变量,included的变量,role中的变量等) * 然后是在inventory定义的其它变量 * 然后是由系统发现的facts * 然后是 \"role默认变量\", 这个是最默认的值,很容易丧失优先权 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:2:3","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"3. 逻辑控制 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:3:0","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"3.1 判断 when ansible 中的条件判断使用 when 语句，而 when 语句的值是 Jinja2 表达式 tasks: - name: \"shutdown Debian flavored systems\" command: /sbin/shutdown -t now when: ansible_os_family == \"Debian\" 一系列的Jinja2 “过滤器” 也可以在when语句中使用, 但有些是Ansible中独有的. 比如我们想忽略某一错误,通过执行成功与否来做决定,我们可以像这样: tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 在playbooks 和 inventory中定义的变量在 when 语句中都可以使用. 下面一个例子,就是基于布尔值来决定一个任务是否被执行: vars: - epic: true tasks: - shell: echo \"This certainly is epic!\" when: epic 下面是 when 语句的几个常用示例 # 依据变量是否定义进行判断 tasks: - shell: echo \"I've got '{{ foo }}' and am not afraid to use it!\" when: foo is defined - fail: msg=\"Bailing out. this play requires 'bar'\" when: bar is not defined # 与 with_items 一起使用 tasks: - command: echo {{ item }} with_items: [ 0, 2, 4, 6, 8, 10 ] when: item \u003e 5 ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:3:1","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"3，2 循环 with_item ansible 中标准循环使用 with_item 语句实现，典型的使用方式如下 - name: add several users user: name={{ item.name }} state=present groups={{ item.groups }} with_items: - { name: 'testuser1', groups: 'wheel' } - { name: 'testuser2', groups: 'root' } - name: add several users user: name={{ item }} state=present groups=wheel with_items: - testuser1 - testuser2 除此之外， ansible 还提供了多种循环方式，迭代包括哈希表，文件列表等诸多内容。 前套循环 - name: give users access to multiple databases mysql_user: name={{ item[0] }} priv={{ item[1] }}.*:ALL append_privs=yes password=foo with_nested: - [ 'alice', 'bob' ] - [ 'clientdb', 'employeedb', 'providerdb' ] 对文件列表使用循环 --- - hosts: all tasks: # first ensure our target directory exists - file: dest=/etc/fooapp state=directory # copy each file over that matches the given pattern - copy: src={{ item }} dest=/etc/fooapp/ owner=root mode=600 with_fileglob: - /playbooks/files/fooapp/* ","date":"2018-11-07","objectID":"/posts/linux/linux_mt/32-ansible/ansible_playbook/:3:2","tags":["马哥 Linux"],"title":"29.7 ansible playbook","uri":"/posts/linux/linux_mt/32-ansible/ansible_playbook/"},{"categories":["Linux"],"content":"29.6 ansible 常用模块","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"ansible 常用模块 上一节我们对 ansible 做了一个概括性的介绍，本节我们来看看 ansible 主程序与常见模块的使用，模块是我们定义服务配置的关键。 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:0:0","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"1. ansible 核心程序 ansible 的核心程序有三个 ansible: ad-hoc 执行命令 ansible-doc: ansible 插件(模块)文档查看工具 ansible-playbook: playbook 执行命令 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:1:0","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"1，1 ansible ansible \u003chost-pattern\u003e [-m module_name] [-a args] options 作用: ansible 命令行工具 模块: [-m module_name]: 指定使用的模块 [-a args]: 传递给模块的参数 选项: ansible 命令行工具的选项可分为三类 通用选项 连接选项 权限选项 通用选项: -C, --check: 不实际执行，只显示程序执行可能的结果 -D, --diff: 当执行的命令改变了文件或模板的内容时，显示更改前后的内容比较，最好和 -C, --check 一起使用 -e EXTRA_VARS, --extra-vars=EXTRA_VARS: 向 ansible 传递的额外参数，参数值必需是行如key=value的键值对 -f FORKS, --forks=FORKS: 并发操作的最大机器数 -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY: 定义 inventory 文件位置 --list-hosts: 只显示被操作的主机 --syntax-check :只对 playbook 执行语法检查, 不执行 -t TREE, --tree=TREE: 日志的输出目录 --version: 显示 ansible 的版本信息 连接选项: --private-key=PRIVATE_KEY_FILE: 指定连接的密钥文件 --key-file=PRIVATE_KEY_FILE:指定连接的密钥文件 -u,--user=REMOTE_USER: 连接到被管控主机的帐户，默认为 None -c, --connection=CONNECTION: 连接的类型，默认为 smart -T, --timeout=TIMEOUT: 连接超时时长 权限选项: -b, --become: --become-user=BECOME_USER: 提权限操作切换到的用户，默认为 root --become-method=BECOME_METHOD: 进行权限升级时使用的操作，默认为 sudo，可选值包括sudo | su --ask-become-pass: 使用 sudo 或 su 时，使用的密码 host-pattern ansible 支持多种主机匹配方式，以便我们能灵活的控制要操作的主机范围。常见的方式有如下几种 # 1. 全部主机 all * # 2. IP地址或系列主机名 one.example.com one.example.com:two.example.com 192.168.1.50 192.168.1.* # 3. 一个或多个groups webservers # 单个组 webservers:dbservers # 多个组的并集 webservers:\u0026staging # 多个组的交集 webservers:!phoenix # ! 表示排除关系，隶属 webservers 组但同时不在 phoenix组 # 4. host names, IPs , groups都支持通配符 *.example.com *.com # 5. 通配和groups的混合使用 one*.com:dbservers # 6. 应用正则表达式，只需要以 ‘~’ 开头 ~(web|db).*\\.example\\.com # 7. 通过 --limit 标记来添加排除条件 ansible-playbook site.yml --limit datacenter2 # 8. 从文件读取hosts,文件名以@为前缀即可 ansible-playbook site.yml --limit @retry_hosts.txt ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:1:1","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"1.2 ansible-doc ansible-doc options 作用: ansible 文档查看工具 选项: -l, --list: 显示所有可用插件及模块 -s, --snippet=module: 显示指定插件的的帮助信息 -t, --type=TYPE: 指定被选择的插件类型，默认为 module ~$ ansible-doc -s shell - name: Execute commands in nodes. shell: chdir: # cd into this directory before running the command creates: # a filename, when it already exists, this step will *not* be run. executable: # change the shell used to execute the command. Should be an absolute path to the executable. free_form: # (required) The shell module takes a free form command to run, as a string. There's not an actual option named \"free form\". See the examples! removes: # a filename, when it does not exist, this step will *not* be run. stdin: # Set the stdin of the command directly to the specified value. warn: # if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false. ansible-doc 显示的参数都是可以在 ansible 命令中 通过 -a 选项中传递给模块的参数 ansible -m shell -a \"echo 'test' chdir=/root\" ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:1:2","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"ansible-playbook ansible-playbook [options] playbook.yml [playbook2 ...] 作用: playbook 的执行命令 参数: playbook.yml... 表示 playbook 的路经 选项: ansible-playbook 与 ansible 命令行工具的选项基本类似 --playbook-dir=BASEDIR: playbook 的根目录，这个根目录的设置会影响 roles/ group_vars/ 等目录的查找路经 -t TAGS, --tags=TAGS: 运行指定标签对应的任务 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:1:3","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.ansible 常用模块 ansible 命令的执行是为了达到期望的状态，如果被管控主机的当前状态与命令指定的状态不一致，则执行命令，所以ansible 的命令都是通过 state 参数指定要进行的操作。 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:0","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.1 基本模块 user ansible -m user -a \"options\" 作用: 用户管理 选项: name: 用户名 uid: 指定创建用户的 uid shell: 设置默认shell group: 设置默认组 groups: 设置附加组，默认操作是替换 append: groups 操作为追加而不是替换 home: 家目录 system: yes|no 是否为系统用户 move: 更新用户家目录时，是否将原有家目录的内容移动到新的目录中去 state: 用户操作 present: 创建用户 absent: 删除用户 $ ansible-doc -s user $ ansible all -m user -a \"name=test uid=3000 shell=/bin/tsh groups=testgrp\" group ansible -m user -a \"options\" 作用: 用户组管理 选项: name: 组名 gid: 指定gid system: yes|no 是否为系统用户 state: 目标状态 present|absent copy ansible -m copy -a 'options' 作用: 文件复制和创建 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代\"src\",可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用\"/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync remote_src: yes|no，指定 scr 参数的源是本机还是远程的被管理主机，no 为本机 owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 ansible -m copy -a \"src=/etc/fstab dest=/tmp/fstab.ansible\" ansible -m copy -a \"content='hi ansible\\n' dest=/tmp/fstab.ansible mode=600\" file ansible -m file -a \"options\" 作用: 文件属性管理 选项: force：yes|no 是否强制创建软连接 一种是源文件不存在但之后会建立的情况下，强制创建 另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链 group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 ansible test -m file -a \"src=/etc/fstab dest=/tmp/fstab state=link\" ansible test -m file -a \"path=/tmp/fstab state=absent\" ansible test -m file -a \"path=/tmp/test state=touch\" template ansible -m template -a 'option' 作用: 基于 python jinja2 模板生成文件并复制到目标主机 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no src：要被链接的源文件的路径，只应用于state=link的情况 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:1","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.2 命令执行 command ansible -m command -a 'option' 作用: 命令执行，但是无法解析 bash 中的特殊字符，比如 |，只能执行简单命令 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 ansible -m command -a \"ifconfig\" shell ansible -m shell -a 'option' 作用: 命令执行，能正常解析 shell 语法 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 ansible -m command -a \"echo pswd|password --stdin tao\" script ansible -m script -a 'option' 作用: 将脚本复制到管控主机并执行 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 ansible -m script -a \"mount.sh\" ping ansible -m ping -a 'option' 作用: 测试主机是否是通的 选项：无 ansible 10.212.52.252 -m ping 10.212.52.252 | success \u003e\u003e { \"changed\": false, \"ping\": \"pong\" } ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:2","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.3 程序安装 yum ansible -m yum -a 'option' 作用: 文件属性管理 选项： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，可附带版本信息，也可以传递一个url或者一个本地的rpm包的路径 allow_downgrade: 是否允许降级安装，默认为 no；默认的安装操作相当于 yum -y update，如果 name 指定的版本相对于已安装的版本较低，则不会安装 state：状态（present，absent，latest） ansible test -m yum -a 'name=httpd state=latest' ansible test -m yum -a 'name=\"@Development tools\" state=present' ansible test -m yum -a 'name=http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm state=present' pip ansible -m pip -a 'option' 作用: 文件属性管理 选项： chdir: pip 命令运行前切换到此目录 executable: 指定运行 pip的版本，pip 的名称或绝对路经；不能与virtualenv同时使用 extra_args: 传给 pip的额外参数 name: 安装的程序包名称，可以是一个 url version: 指定的Python库的安装版本 virtualenv：virtualenv 虚拟环境目录，不能与 executable 同时使用，如果虚拟环境不存在，将自动创建 virtualenv_command: 虚拟环境使用的管理命令或绝对路经，eg:pyvenv, ~/bin/virtualenv virtualenv_python: 虚拟环境中的 python 版本，当virtualenv_command使用pyvenv或-m venv模块时，不应使用此参数 state: present:默认的，表示为安装 lastest: 安装为最新的版本 absent：表示删除 forcereinstall：“forcereinstall”选项仅适用于可ansible 2.1及更高版本 # 支持 pipenv 么？ ansible -m pip -a \"name=ipython virtualenv=/opt/vdd/project virtualenv_command=pipenv\" ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:3","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.4 服务管理 cron ansible -m cron -a 'option' 作用: 周期性任务管理 选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日 hour：小时 minute：分钟 month：月 weekday：周 job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数包括 reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除，present or absent user：以哪个用户的身份执行 ansible test -m cron -a 'name=\"a job for reboot\" special_time=reboot job=\"/some/job.sh\"' ansible test -m cron -a 'name=\"yum autoupdate\" weekday=\"2\" minute=0 hour=12 user=\"root ansible 10.212.52.252 -m cron -a 'backup=\"True\" name=\"test\" minute=\"0\" hour=\"2\" job=\"ls -alh \u003e /dev/null\"' ansilbe test -m cron -a 'cron_file=ansible_yum-autoupdate state=absent' service ansible -m service -a 'option' 作用: 管理服务管理 选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） ansible -m service -a \"name=httpd state=started enabled=yes\" ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:4","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"2.5 变量获取 setup ansible -m setup -a 'option' 作用: 获取被管控主机的所有系统参数信息 选项： filter: 参数过滤，支持 shell 通配语法 gather_subset: 限制返回的参数范围，可选值包括 all, min, hardware, network, virtual, ohai,值前的 ! 表示取反 gather_timeout: 参数收集的超时时长 ansible 10.212.52.252 -m setup -a 'filter=ansible_*_mb' //查看主机内存信息 ansible 10.212.52.252 -m setup -a 'filter=ansible_eth[0-2]' //查看地接口为eth0-2的网卡信息 ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中 ","date":"2018-11-06","objectID":"/posts/linux/linux_mt/32-ansible/ansible_module/:2:5","tags":["马哥 Linux"],"title":"29.6 ansible 常用模块","uri":"/posts/linux/linux_mt/32-ansible/ansible_module/"},{"categories":["Linux"],"content":"29.5 ansible简介","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"ansible简介 在本章的开篇我们说过自动化运维的几个层次 BootStraping: 引导安装操作系统 Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理 Command \u0026 Control: 批量运行程序 ansible 正是配置系统，和批量命令执行两个层面的轻量级强大的解决方案。 为了批量的管理主机，我们需要与本管控主机进行通信，目前\"通信\"存在两种方式。一种是以 saltstack 为代表的 agent 模式，及在被管控主机之上必需部署客户端代理，由其接收指令并在被管控主机之上执行。另一种是以 ansible 为代表的 less agent 模式，通过 ssh 连接直接远程执行命令。本节开始我们就来学习 ansible 的安装配置及使用。 ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:0:0","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1. ansible 简介 ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:1:0","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.1 程序框架 上图是 ansible 架构示意图，ansible 是高度模块化，由如下几个部分组成 Ansible： 作用: Ansible的核心程序 Host Inventory： 作用: 记录了每一个由Ansible管理的主机信息，信息包括ssh端口，root帐号密码，ip地址等等 Connection Plugins： 作用: 连接插件，Ansible和Host通信使用 Core Modules： 作用: Ansible执行任何管理任务都不是由Ansible自己完成，而是由核心模块完成；Ansible管理主机之前，先调用core Modules中的模块，然后指明管理Host Inventory中的主机，就可以完成管理主机。 Custom Modules: 作用: 自定义模块，完成Ansible核心模块无法完成的功能，此模块支持任何语言编写。 Playbooks： 作用: YAML格式文件，多个任务定义在一个文件中，使用时可以统一调用，类似于“剧本”用来定义那些主机需要调用那些模块来完成的功能. 模块 Ansible 任务的执行则是通过模块实现的，ansible 的模块通常是 Linux 中的命令是或者特定工具是一一对应，要学习 ansible 配置主要内容之一就是学习常见模块的应用。 playbook Ansible提供了两种方式去完成任务,一是 ad-hoc 命令,一是写 Ansible playbook，两者的关系类似于在命令行敲入shell命令和 写shell scripts playbook 中最重要的概念称为role(角色)，角色是一个自包涵的任务集合，不仅包含 playbook，也包含 playbook 内每一个命令所需的文件。role 存在的目的是让 ansible 更加容易移植。 ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:1:1","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.2 ansible 安装 $ sudo yum install ansible $ ansible --version $ rpm -ql ansible |egrep -v \"(python|man|doc)\" /etc/ansible /etc/ansible/ansible.cfg # ansible 自身的配置文件 /etc/ansible/hosts # Host Inventory /etc/ansible/roles # roles 所在目录 /usr/bin/ansible # ad-hoc 执行命令 /usr/bin/ansible-2 /usr/bin/ansible-2.7 /usr/bin/ansible-config /usr/bin/ansible-connection /usr/bin/ansible-console /usr/bin/ansible-console-2 /usr/bin/ansible-console-2.7 /usr/bin/ansible-galaxy /usr/bin/ansible-galaxy-2 /usr/bin/ansible-galaxy-2.7 /usr/bin/ansible-inventory /usr/bin/ansible-playbook # playbook 执行命令 /usr/bin/ansible-playbook-2 /usr/bin/ansible-playbook-2.7 /usr/bin/ansible-pull /usr/bin/ansible-pull-2 /usr/bin/ansible-pull-2.7 /usr/bin/ansible-vault /usr/bin/ansible-vault-2 /usr/bin/ansible-vault-2.7 ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:1:2","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.3 ansible 认证机制 使用 ansible 之前最主要的任务是配置 Host Inventory，即定义 ansible 管控的主机。但是在定义 Host Inventory 之前，我们有必要先了解一下 Ansible是如何通过SSH与远程服务器连接。 备注: 参考马哥Linux Ansible 权威教程 Ansible 1.3及之后 Ansible 1.3及之后的版本默认会在本地的 OpenSSH可用时会尝试用其进行远程通讯.这会启用ControlPersist(一个性能特性),Kerberos,和在~/.ssh/config中的配置选项如 Jump Host setup。 然而,当你使用Linux企业版6作为主控机(红帽企业版及其衍生版如CentOS),其OpenSSH版本可能过于老旧无法支持ControlPersist. 在这些操作系统中,Ansible将会退回并采用 paramiko (由Python实现的高质量OpenSSH库). 如果你希望能够使用像是Kerberized SSH之类的特性,烦请考虑使用Fedora, OS X, 或 Ubuntu 作为你的主控机直到相关平台上有更新版本的OpenSSH可供使用,或者启用Ansible的“accelerated mode”.参见 Accelerated Mode. Ansible 1.2 及之前 在Ansible 1.2 及之前的版本,默认将会使用 paramiko. 本地OpenSSH必须通过-c ssh 或者 在配置文件中设定. 偶尔会遇到不支持SFTP的设备.虽然这很少见,但你会有概率中奖.你可以通过在配置文件(Ansible的配置文件)中切换至 SCP模式来与之链接. 说起远程设备,Ansible会默认假定你使用 SSH Key(我们推荐这种)但是密码也一样可以.通过在需要的地方添加 –ask-pass选项 来启用密码验证.如果使用了sudo 特性,当sudo需要密码时,也同样适当的提供了–ask-sudo-pass选项. ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:1:3","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.4 ansible 初始化配置 ansible 初始化配置很容易分为两步: 配置主控机与被管控主机基于 SSH 密钥通信 在 Host Inventory 定义被管控的主机 下面是一个配置示例 # SSH Key 免密码登陆 ssh-kengen -t rsa -P \"\" ssh-copy-id ~/.ssh/id_rsa.pub root@172.168.0.3 # 配置 Host Inventory vim /etc/ansible/hosts [webservers] 172.16.0.3 # 测试 ansible webservers --list-hosts ansible webservers -m ping ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:1:4","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. 配置 Host Inventory Host Inventory 用于定义 ansible 管理的主机及主机组。默认的文件路径为 /etc/ansible/hosts 除默认文件外,你还可以同时使用多个 inventory 文件,也可以从动态源,或云上拉取 inventory 配置信息。下面是 Host Inventory 配置示例 mail.example.com [webservers] foo.example.com bar.example.com Host Inventory 是 ini 风格的配置文件，使用 [组名] 定义组。组用于对系统进行分类，便于对不同系统进行统一管理。一个主机可以属于不同组。 ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:2:0","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 主机定义 mail.example.com # 1. 标准形式 172.16.0.1 badwolf.example.com:5309 # 2. 自定义端口 www[01:50].example.com # 3. 扩展形式 db-[a:f].example.com jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 # 4. 通过参数定义 [targets] localhost ansible_connection=local other1.example.com ansible_connection=ssh ansible_ssh_user=mpdehaan Host Inventory 内主机有多种定义方式，我的理解核心就是 IP/FQDN [Lnventory 参数] IP/FQDN: 指明管控的主机，可以 ip 地址也可以是域名 Inventory 参数: 控制 ansible 与远程主机的交互方式 在 jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 的示例中 jumper 是主机的别名，通过参数 ansible_ssh_host 设置主机的 IP 地址。 Inventory 参数 Inventory 有如下常用参数 ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置. ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置. ansible_ssh_user 默认的 ssh 用户名 ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥) ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass) ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本) ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko. 1.2 以后默认使用 'smart','smart' 方式会根据是否支持 ControlPersist, 来判断'ssh' 方式是否可行. ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况. ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 'sh' 语法,可设置为 'csh' 或 'fish'. ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是\"/usr/bin/python\", 比如 \\*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 \"/usr/bin/env\" 机制, 因为这要求远程用户的路径设置正确,且要求 \"python\" 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:2:1","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 变量定义 除了定义主机和组，Inventory 内还能主机和组定义特定的变量。这些变量定义后可在 playbooks 中使用。但是不建议在Inventory 中定义变量。变量定义的其他方式我们会在 playbook 中在详细介绍。 主机变量 [atlanta] host1 http_port=80 maxRequestsPerChild=808 host2 http_port=303 maxRequestsPerChild=909 组变量 [atlanta] host1 host2 [atlanta:vars] ntp_server=ntp.atlanta.example.com proxy=proxy.atlanta.example.com 分文件定义 Host 和 Group 变量 在 inventory 主文件中保存所有的变量并不是最佳的方式.还可以保存在独立的文件中,这些独立文件与 inventory 文件保持关联. 不同于 inventory 文件(INI 格式),这些独立文件的格式为 YAML。 # 假设 inventory 文件的路径为: /etc/ansible/hosts # 分文件为 groups 和 host 定义的变量文件 /etc/ansible/group_vars/raleigh # raleigh 组变量 /etc/ansible/group_vars/webservers # webservers 组变量 /etc/ansible/host_vars/foosball # foosball 主机变量 还有更进一步的运用,你可以为一个主机,或一个组,创建一个目录,目录名就是主机名或组名.目录中的可以创建多个文件, 文件中的变量都会被读取为主机或组的变量。注意,分文件定义变量的方式只适用于 Ansible 1.4 及以上版本. /etc/ansible/group_vars/raleigh/db_settings /etc/ansible/group_vars/raleigh/cluster_settings Ansible 1.2 及以上的版本中,group_vars/ 和 host_vars/ 目录可放在 inventory 目录下,或是 playbook 目录下. 如果两个目录下都存在,那么 playbook 目录下的配置会覆盖 inventory 目录的配置。把你的 inventory 文件 和 变量 放入 git repo 中,以便跟踪他们的更新,这是一种非常推荐的方式. ","date":"2018-11-05","objectID":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/:2:2","tags":["马哥 Linux"],"title":"29.5 ansible简介","uri":"/posts/linux/linux_mt/32-ansible/ansible%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"29.4 运维自动化入门","date":"2018-11-04","objectID":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"29.4 运维自动化入门","uri":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"运维自动化入门 ","date":"2018-11-04","objectID":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"29.4 运维自动化入门","uri":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. 运维工作 ","date":"2018-11-04","objectID":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"29.4 运维自动化入门","uri":"/posts/linux/linux_mt/32-ansible/%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"29.3 pxe与cobbler","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"pxe与cobbler cobbler 就是 pex 环境的二次封装，为用户提供了一个管理工具，能将多个 pxe 环境整合在一起，让用户自行选择安装的系统。 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:0:0","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"1， cobbler 安装 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:1:0","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"1.1 rpm 包组成 yum install cobbler $ rpm -ql cobbler|egrep -v \"(man|python|doc)\" /etc/cobbler # 配置文件 /etc/cobbler/settings # 自身运行的配置文件 /etc/cobbler/auth.conf /etc/cobbler/cheetah_macros /etc/cobbler/cobbler_bash /etc/cobbler/completions /etc/cobbler/dhcp.template /etc/cobbler/dnsmasq.template /etc/cobbler/import_rsync_whitelist /etc/cobbler/iso /etc/cobbler/iso/buildiso.template /etc/cobbler/ldap /etc/cobbler/ldap/ldap_authconfig.template /etc/cobbler/modules.conf /etc/cobbler/mongodb.conf /etc/cobbler/named.template /etc/cobbler/power # 服务的配置模板 /etc/cobbler/power/fence_apc_snmp.template ........ /etc/cobbler/pxe /etc/cobbler/pxe/bootcfg_esxi5.template ........ ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:1:1","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"2. cobbler 环境配置 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:2:0","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"2.1 cobbler 启动 cobbler 配置文件提供了对多种环境的配置，默认配置通常就可以直接使用。我们可以根据 cobbler 启动时的报错信息对必要的参数作出调整即可。 systemctl restart httpd systemctl start cobblerd.service cobbler check # 1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it. 2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network. 3 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux 4 : change 'disable' to 'no' in /etc/xinetd.d/tftp 5 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements. 6 : enable and start rsyncd.service with systemctl 7 : debmirror package is not installed, it will be required to manage debian deployments and repositories 8 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: \"openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'\" to generate new one 9 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them cobbler 启动之后使用 check 对 cobbler 环境进行检查，会显示当前 cobbler 环境存在的问题，我们只要相应的修改配置文件解决这些问题，我们的 cobbler 环境也就准备好了。现在我们来解决这些问题 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:2:1","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"2.2 环境配置 # 1. server 绑定地址，改为外网地址，以便其他主机能访问到 vim /etc/cobbler/settings server: 172.16.0.2 # 2. next server 指向改为 tftp server 地址 vim /etc/cobbler/settings next_server: 172.16.0.2 # 3. SELinux 设置为 Permissive，无影响 # 4. 编辑 /etc/xinetd.d/tftp 启动 tftp 服务 vim /etc/xinetd.d/tftp service tftp { socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no # disable 改为 no per_source = 11 cps = 100 2 flags = IPv4 } # 5. 某些 bootloader 不在 /var/lib/cobbler/loaders 文件夹内 yum install syslinux cp /usr/share/syslinux/{menu.c32, pxelinux.0} /var/lib/cobbler/loaders # 6. 启用 rsync 服务 systemctl start rsyncd.service systemctl enable rsyncd.service # 7. 安装 debmirror 包 yum install debmirror # 8. 修改 default_password_crypted 为超级用户设置的密码 # openssl passwd -1 -salt 'random-phrase-here' 'your-password-here' openssl passwd -1 -salt dgea 1234 $1$dgea$nPoeNaw5o4mv6kkXjhzVI1 vim /etc/cobbler/settings default_password_crypted: $1$dgea$nPoeNaw5o4mv6kkXjhzVI1 # 9. 安装 fence-agents，这个是高可用集群所使用的组件，此处可以先忽略 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:2:2","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"2.3 配置 pxe 所依赖的服务 cobbler 虽然依赖于 pxe 环境，但是对 pxe 支持自动配置，只需要提供 pex 对应服务的配置文件，cobbler 能实现自动安装，配置和启动。相比于使用 cobber 自动安装，可能我们手动配置其他服务器可能更熟悉快捷。所以接下来我们也是以手动配置为主。 手动管理 pxe 所需服务，还是由 cobbler 自己管理需要在配置文件中进行配置。如果是由 cobbler 自动配置，还需要在 /etc/cobbler/modules.conf 配置文件内为各服务提供配置参数。 vim /etc/cobbler/settings manage_dhcp: 0 # 0 表示手动配置，1 表示 cobbler 自动配置 manage_dns: 0 manage_tftpd: 1 manage_rsync: 0 # 为各服务配置服务参数 $ cat /etc/cobbler/modules.conf |grep \"^\\[\" [authentication] [authorization] [dns] [dhcp] [tftpd] ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:2:3","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"3. 配置 cobbler 服务 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:0","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"3.1 cobbler 服务组成 如下图，cobbler 服务由如下几个部分组成，我们的目的就是配置好这几个组成部分。 Disribution : distro, 表示一个发行版，包括内核，initrd Repository: repo 创建仓库，比如yum仓库等，可以直接创建，也可以导入光盘的 yum 仓库 system： system 通过mac地址来定制化系统 profile： profile 对需要安装某个系统的所有配置，包括 kickstart 配置文件 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:1","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"3.2 cobbler 命令使用 # cobbler usage ===== cobbler \u003cdistro|profile|system|repo|image|mgmtclass|package|file\u003e ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help] cobbler \u003caclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink\u003e [options|--help] 子命令 首先 cobbler 有众多字命令，每一个子命令用于配置 cobbler 服务的一部份 distro: 用于配置 Disribution，核心是定义 kernel 和 initrd profile: 配置 profile repo: 配置 Repository yum 源 system: 配置 system 定制系统 操作 其次每个组件都有相关的管理操作: add edit copy getks* list remove rename report cobbler distro list cobbler distro add --help ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:2","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"辅助命令 最后剩下的部分是 cobbler 的辅助命令，可以基于当前已有的光盘和 yum 仓库快速配置相应组件，也包括其他一些辅助功能 buildiso import: 通过导入光盘自动生成一个 distro sync: cobbler 同步，每次执行新的操作之后最好都同步一次 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:3","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"3.2 distro 管理 cobbler import [options] 作用: 通过导入光盘自动生成一个 distro 过程: 会在 /var/www/cobbler/ks_mirror 下自动创建一个--name参数的文件夹，将光盘内的所有内容复制到该目录下 import 会自动为导入的 distro 生成一个 profile Options: -h, --help: 帮助 --arch=ARCH: 被导入操作系统的平台架构 --breed=BREED: the breed being imported --os-version=OS_VERSION: the version being imported --path=PATH: 光盘镜像挂载点 --name=NAME: distro 名称 --available-as=AVAILABLE_AS: tree is here, don’t mirror --kickstart=KICKSTART_FILE: assign this kickstart file --rsync-flags=RSYNC_FLAGS: pass additional flags to rsync cobbler import --name=Centos-7.1-x86_64 --path=/cdrom ls /var/www/cobbler/ks_mirror Centos-7.1-x86_64 cobbler distro list cobbler profile list cobbler sync ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:4","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"3.3 profile 管理 # cobbler profile --help usage ===== cobbler profile add cobbler profile copy cobbler profile dumpvars cobbler profile edit cobbler profile find cobbler profile getks cobbler profile list cobbler profile remove cobbler profile rename cobbler profile report add cobbler profile add options 作用: 添加 profile options: --name --distro --kickstart cobbler profile add --name=Centos-7.1-x86_64_service --distro=Centos-7.1-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks.cfg cobbler sync # 将新增的 profile 添加到 /var/lib/tfpt/pexlinux.cfg/default 的开机菜单中 edit cobbler profile edit options rename cobbler profile rename options --name --newname ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:3:5","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"4. cobbler web cobbler web 提供了以web 界面供我们配置 cobbler 服务使用。在使用 cobbler web 之前我们需要进行认证配置。其认证分为如下几种形式 ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:4:0","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"4.1 cobbler web 认证 auth_pam 认证 此配置是基于系统帐户完成认证 vim /etc/cobbler/modules.conf [authentication] module = authn_pam # 添加帐户 useradd cblradmin echo cblpass |passwd --stdin cblradmin # 将用户添加至 cobbler user 组中 vim /etc/cobbler/users [admins] admin = cblradmin # 重启服务 systemctl restart cobblerd authn_configfile 此认证是基于帐号密码文件完成认证 vim /etc/cobbler/modules.conf [authentication] module = authn_configfile # 创建认证文件 htdigest -c /etc/cobbler/users.digest Cobbler cblradmin # 重启服务 systemctl restart cobblerd htdigest [-c] passwordfile realm username ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:4:1","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"4.2 cobbler web 配置 # 1. 安装 yum install cobbler-web # 2. 配置 authn_configfile 认证 htdigest -c /etc/cobbler/users.digest Cobbler cblradmin Adding password for cblradmin in realm Cobbler. New password: Re-type new password: # 3. 重启 httpd systemctl restart httpd # 4. 访问 http://ip/colbbler_web ","date":"2018-11-03","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/:4:2","tags":["马哥 Linux"],"title":"29.3 pxe与cobbler","uri":"/posts/linux/linux_mt/32-ansible/pxe%E4%B8%8Ecobbler/"},{"categories":["Linux"],"content":"29.2 PXE 系统自动化部署","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"PXE 系统自动化部署 PXE 全称是 preboot execute environment 由 Intel 公司开发，用于为完成基于网络的引导安装。 ","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/:0:0","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"1. PXE 工作过程 pxe 要求客户端主机的网卡必需支持网络引导机制，并将网络设置为第一引导设备。整个过程如上图所示: 未安装操作系统的主机启动时，网卡首先发送一个 rarp 协议报文，从局域网中的 dhcp 服务获取一个 IP 地址，并同时获取引导文件，和引导文件所在的文件服务器(dhcp 的 filename,next-server 参数指定) 主机加载引导文件后，会依据引导文件继续向文件服务器获取内核和 initrd 文件，启动Linux 内核，并依据之前获取的 IP 地址，配置好网络属性 内核加载完成之后，会依据开机启动配置文件中指定的 yum 仓库获取操作系统安装程序 anaconda，并启动安装过程 此后的安装过程就与我们通过硬盘安装操作系统的过程类似，Centos 系可借助 kickstart 文件完成自动安装，这部分请参阅 15.2 Centos安装过程 因此整个 PXE 依赖于以下服务: dhcp: 提供 IP 地址，引导文件和文件服务器的指向(执行 tftp server) tftp: 文件服务器，用于提供引导文件，操作系统内核，initrd yum repository: 一个 yum 仓库，为系统安装提供源，可通过 http,https, ftp,nfs 任意服务提供 ","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/:1:0","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"2. tftp server tftp 监听在 udp 的 69 号端口上 # 安装 yum install tftp-server tftp rpm -ql tftp-server|egrep -v \"(man|doc)\" /etc/xinetd.d/tftp /usr/lib/systemd/system/tftp.service /usr/lib/systemd/system/tftp.socket /usr/sbin/in.tftpd /var/lib/tftpboot # tftp 默认文件目录 # centos 7 启动 systemctl start tftp.socket # centos 6 启动 chkconfig tftp on service xinetd restart ","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/:2:0","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"3. CentOS 7 PXE # 1. 配置 DHCP 服务，配置见上节 # 2. 配置 tftp 服务 yum install -y dhcp yum -y install syslinux tftp-server # 2.1 复制内核，开机启动的所需的配置文件 mount /dev/cdrom /cdrom cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ cp /cdrom/images/pxelinux/{vmlinuz,initrd.img} /var/lib/tftp/boot/ cp /usr/share/syslinux/{chain.c32,mboot.c32,menu.c32,memdisk} /var/lib/tftpboot/ # 2.2 配置开机启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ vim /var/lib/tftpboot/pxelinux.cfg/default default menu.c32 prompt 5 timeout 30 MENU TITLE CentOS 7 PXE Menu LABEL linux MENU LABEL Install CentOS 7 x86_64 KERNEL vmlinuz APPEND initrd=initrd.img inst.repo=http://172.16.0.2/centos ks=http://172.16.0.2/ks.cfg # 3. 准备 yum 仓库 yum install httpd mount -B /cdrom /var/www/html/centos # 4. 准备 kickstart 文件 vim /var/www/html/ks.cfg # ks 文件内需要通过 url --url=\"http://172.16.0.2/centos\" 指明 yum 源 ","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/:3:0","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"4. CentOS 6 PXE # 2.1 复制内核，开机启动的所需的配置文件 yum -y install syslinux tftp-server cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/ cp /media/cdrom/images/pxelinux/{vmlinuz,initrd.img} /var/lib/tftp/boot/ cp /media/cdrom/isolinux/{boot.msg,vesamenu.c32,splash.png} /var/lib/tftp/boot/ # 2.2 配置开机启动菜单 mkdir /var/lib/tftpboot/pxelinux.cfg/ cp /media/cdrom/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default vim /var/lib/tftpboot/pxelinux.cfg/default # 添加 label autoinst menu label ^Auto menu default kernel vmlinuz append initrd=initrd.img ks=http://172.16.0.2/ks.cfg ","date":"2018-11-02","objectID":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/:4:0","tags":["马哥 Linux"],"title":"29.2 PXE 系统自动化部署","uri":"/posts/linux/linux_mt/32-ansible/pxe%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"categories":["Linux"],"content":"29.1 dhcp服务简介","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"dhcp服务简介 当集群内的主机达到一定规模时，我们就需要由手动运维转向自动化运维，以提高我们运维的效率，同时也是为减少我们平均故障修复时间。自动化运维的最新技术是docker，而更加传统的方法则是以 ansible 为代表的配置系统。配置系统的基础是标准化，我们需要为我们的主机配置同样的操作系统，并为相同服务集群内的主机提供相同的配置文件。 不考虑虚拟技术，我们的自动化运维工具可以如下几个层面: BootStraping: 用于引导安装操作系统的，os isntallation，常用工具就是 pxe，cobbler Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理， 常用工具包括 ansible，puppet,saltstack Command \u0026 Control: 批量运行程序，常用工具包括 ansible 本章的内容主要包括两个部分 自动化安装: 基于 PXE 自动化安装系统 配置系统: 基于 ansible 的配置系统 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:0:0","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1. DHCP 简介 DHCP(Dynamic Host Configuration Protocol) 全称是动态主机配置协议，主要用于为主机配置IP 地址。将一台主机接入互联网时，我们需要为其配置 IP/Netmask,Gateway,DNS Server等等网络参数。我们可以手动配置，也可以借助于 DHCP 协议实现动态分配。dhcp 的前身是 bootp 引导协议，出现于无盘工作站，这种类型的机器没有硬盘，所以操作系统不会安装在本地。此时需要借助网卡的特定功能，它能在开机时被唤醒，并能作为 bootp 协议客户端去请求服务端去获取地址，并加载属于自己的操作系统文件。第一次获取地址时是动态，之后获取的地址则是固定的，因为要实现客户端操作系统与 IP 地址绑定。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:1:0","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.1 工作过程 dhcp 可以理解成引入租约概念的 bootp 协议，能在主机开机时自动分配地址，并在主机关机时收回临时分配的 IP 地址并在分配，同时也保留了 bootp 保留地址的功能。 dhcp 在动态分配地址的过程中，首先在局域网中有一台 dhcp 服务，其维护着一组可用地址列表(地址池)，也包含要为其他主机配置的网关，DNS 服务器等等。某主机开机之后如果其配置了通过 DHCP 动态获取地址，其将发送一个 RARP 的广播报文 arp: address resolving Protocol，IP -\u003e MAC rarp: reverse arp, MAC -\u003e IP 服务器收到，主机的 Rarp 请求之后，就会为其提供一个地址，整个过程如下所示: dhcp 提供的 IP 地址时存在续租期限的，一般主机要在租约期限到一半时进行续租，此时 Client: 向服务器发送一个 dhcp request Server: 如果同意续租则回复 dhcp ack，不同意在回复 dhcp nak 服务器端不允许续租的原因可能是因为管理员更改了可用的地址池，客户端的IP 地址已经不可用。如果不能续租，此时客户端要重新进行广播获取 IP 地址。 如果客户端在续租时服务器端没有响应，客户端会在剩余时间过去一半的时候再次发起续租直至到达一个足够小的时间，此时将认定服务器不可用，客户端将重新广播获取 IP 地址。 需要注意的是开机获取 IP 地址是广播的，续租则是单播的。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:1:1","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.2 dhcp 中继服务 dhcp 服务不能穿越网关(路由器)，所以要为不同物理网络中的主机分配地址时，需要借助于 dhcp 的中继服务。中继的过程如下 dhcp 中继服务用的很少，了解即可。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:1:2","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.3 dhcp 作用域 dhcp 每一个可分配的地址范围称为一个作用域，不同的作用域可以为不同的网络分配地址，还可以定义超级作用域。 dhcp 在分配地址时，还可以告诉客户端一个网络文件服务器地址，并告诉其到这个文件服务器上请求什么文件，这就是通过网络引导系统的基础。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:1:3","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. dhcp 服务 Linux DHCP协议的实现程序 dhcp dnsmasq: 同时实现了dns 和dhcp 服务，用于嵌入式环境中 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:2:0","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 程序组成 # rpm -ql dhcp|egrep -v \"(share|man)\" /etc/NetworkManager /etc/NetworkManager/dispatcher.d /etc/NetworkManager/dispatcher.d/12-dhcpd /etc/dhcp/dhcpd.conf # ipv4 的配置文件 /etc/dhcp/dhcpd6.conf # ipv6 地址分配相关的配置文件 /etc/dhcp/scripts /etc/dhcp/scripts/README.scripts /etc/openldap/schema/dhcp.schema /etc/sysconfig/dhcpd /usr/bin/omshell /usr/lib/systemd/system/dhcpd.service # ipv4 unit file /usr/lib/systemd/system/dhcpd6.service # ipv6 unit file /usr/lib/systemd/system/dhcrelay.service /usr/sbin/dhcpd # dhcp 服务的主程序 /usr/sbin/dhcrelay # dhcp 中继服务的主程序 /var/lib/dhcpd /var/lib/dhcpd/dhcpd.leases # 已经分配的的 IP 地址的相关信息 /var/lib/dhcpd/dhcpd6.leases dhcp 的服务器端监听在 udp 的 67 号端口，dhcp 的客户端则监听在 68/udp，因为dhcp 协议的客户端与服务器端随时需要相互通信，所以其客户端也必须作为一个守护进程监听在特定端口上。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:2:1","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.2 服务配置 dhcp 的 rpm 包提供了一个dhcp 配置的参考文件 /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example，可复制直接使用 # dhcpd.conf # # Sample configuration file for ISC dhcpd # # option definitions common to all supported networks... option domain-name \"tao.com\"; # 搜索域 option domain-name-servers 172.16.0.1; # DNS 服务器地址，可指定多个，最多三个，逗号分隔 default-lease-time 600; # 默认租约期限 max-lease-time 7200; # 最大租约期限 log-facility local7; subnet 172.16.0.0 netmask 255.255.255.0 { # subnet 定义一个作用域即一个子网 range 172.16.0.3 172.16.0.10; # 可分配的ip 地址池 option broadcast-address 172.16.0.255; # 广播地址 option routers 172.16.0.1; # 默认网关 filename \"pxelinux.0\"; # 指明引导文件名称 next-server 172.16.0.2; # 提供引导文件的服务器IP地址；tftp server } host fantasia { # 为特定主机始终分配固定的 IP 地址 hardware ethernet 08:00:07:26:c0:a5; # 主机网卡的 MAC 地址 fixed-address 172.16.100.6; # 为其分配的固定 IP，不能在地址池内 } dhcp option 定义的参数可位于子域中，也可以位于全局配置中，子域中的配置优先级更高。 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:2:2","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.3 dhclient dhclient options 作用: dhcp 客户端程序，可手动发起 dhcp 请求 选项: -d: 将 dhclient 工作于前台，显示 dhcp 的工作过程 ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:2:3","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.4 已分配地址 cat /var/lib/dhcpd/dhcpd.leases # The format of this file is documented in the dhcpd.leases(5) manual page. # This lease file was written by isc-dhcp-4.2.5 lease 172.16.0.3 { starts 2 2018/09/25 09:34:08; ends 2 2018/09/25 09:44:08; tstp 2 2018/09/25 09:44:08; cltt 2 2018/09/25 09:34:08; binding state free; hardware ethernet 08:00:27:f4:d9:52; } ","date":"2018-11-01","objectID":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/:2:4","tags":["马哥 Linux"],"title":"29.1 dhcp服务简介","uri":"/posts/linux/linux_mt/32-ansible/dhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"28.3 haproxy 访问控制","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"haproxy 访问控制 本节我们来 介绍 haproxy 配置的第二部分，acl 访问控制。 ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:0:0","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"1. acl acl 能分类请求和响应报文，进而根据分类结果作出转发决策和访问控制。 ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:1:0","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"1.1 acl 使用 acl \u003caclname\u003e \u003ccriterion\u003e [flags] [operator] [\u003cvalue\u003e] 作用: 根据设置的条件分类请求和响应报文 参数: \u003caclname\u003e: 作用: acl 的名称标识，以便在后续的访问控制和转发中进行引用 命名: 可用字符包括大小写子母，数字 -，_，.， :，大小写敏感的 说明: 多个 acl 可以使用同一个名字，彼此之间属于 OR 关系 \u003ccriterion\u003e: 匹配的标准，表示要检查什么内容 [operator]: 匹配操作，比如等于，小于，或正则表达式匹配 \u003cvalue\u003e: 标准匹配的目标值 [flags]: 比较控制标识 过程: acl 的匹配过程就是把\u003ccriterion\u003e指定的匹配标准和 \u003cvalue\u003e指定的值基于[operator]指定的操作符作比较操作，如果符合条件则为真，否则为假 value value 值可以是以下类型: boolean integer or integer range IP address / network string，字符串的比较分为如下多种类型 exact: criterion表示的值 与 value 完全匹配 substring: value 是criterion表示值的子串 suffix: value 是criterion表示值的后缀 prefix: value 是criterion表示值的前串 subdir: value 是criterion表示路经中的子路经 domain: value 是criterion表示域名的的子域 regular expression hex block flags flags 有如下几个选项 -i : 比较时忽略大小写. -m : 使用一个特殊的模式匹配方法，很少用到 -n : 禁止 DNS 反向解析 -u : 禁止两个 acl 使用相同的名称 -- : flag的结束符标记，强制结束 flag operator 比较操作有如下几种类型 匹配整数值：eq、ge、gt、le、lt 匹配字符串： exact match (-m str) : 精确匹配 substring match (-m sub) : 字串匹配 prefix match (-m beg) : 前缀匹配 suffix match (-m end) : 后缀匹配 subdir match (-m dir) : 子路经匹配，即是否是/分隔的子串 domain match (-m dom) : 域名匹配，即是否是.分隔的子串 acl作为条件时的逻辑关系 AND: 默认多个条件使用空格分隔即表示逻辑与 OR: 使用 or 或 || 表示逻辑与 Not: 使用 ! 表示取反 if invalid_src invalid_port if invalid_src || invalid_port if ! invalid_src invalid_port criterion criterion 用于指定匹配请求报文或响应报文的哪些内容 匹配传输层和网络层报文中的内容 dst: 目标 ip dst_port: 目标端口 integer src: 源ip src_port: 源端口 eg: acl invalid_src src 172.16.200.2 匹配 url 中的路经，即path 部分(/path;\u003cparams\u003e)，string path : exact string match path_beg : prefix match path_dir : subdir match path_dom : domain match path_end : suffix match path_len : length match path_reg : regex match path_sub : substring match 匹配整个 url ，string url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match 匹配请求报文首部中的特定字段，相同报文只会匹配最后一次出现，string hdr([[,]]) : exact string match hdr_beg([[,]]) : prefix match hdr_dir([[,]]) : subdir match hdr_dom([[,]]) : domain match hdr_end([[,]]) : suffix match hdr_len([[,]]) : length match hdr_reg([[,]]) : regex match hdr_sub([[,]]) : substring match 匹配响应状态码 status，integer status # 示例： acl bad_curl hdr_sub(User-Agent) -i curl block if bad_curl 预订义的 ACL Pre-defined ACLs ACL name Equivalent to Usage FALSE always_false never match HTTP req_proto_http match if protocol is valid HTTP HTTP_1.0 req_ver 1.0 match HTTP version 1.0 HTTP_1.1 req_ver 1.1 match HTTP version 1.1 HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-length HTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with scheme HTTP_URL_SLASH url_beg / match URL beginning with \"/\" HTTP_URL_STAR url * match URL equal to \"*\" LOCALHOST src 127.0.0.1/8 match connection from local host METH_CONNECT method CONNECT match HTTP CONNECT method METH_GET method GET HEAD match HTTP GET or HEAD method METH_HEAD method HEAD match HTTP HEAD method METH_OPTIONS method OPTIONS match HTTP OPTIONS method METH_POST method POST match HTTP POST method METH_TRACE method TRACE match HTTP TRACE method RDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookie REQ_CONTENT req_len gt 0 match data in the request buffer TRUE always_true always match WAIT_END wait_end wait for end of content analysis ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:1:1","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"2. 访问控制指令 use_backend use_backend \u003cbackend\u003e [{if | unless} \u003ccondition\u003e] 作用: 当符合指定的条件时使用特定的backend； block block { if | unless } \u003ccondition\u003e 作用: 当符合指定的条件时阻止七层 http 的访问 acl invalid_src src 172.16.200.2 block if invalid_src errorfile 403 /etc/fstab http-request http-request { allow | deny } [ { if | unless } \u003ccondition\u003e ] 作用: 控制七层的访问请求 tcp-request tcp-request connection {accept|reject} [{if | unless} \u003ccondition\u003e] 作用: 四层的连接请求控制 listen ssh bind :22022 balance leastconn acl invalid_src src 172.16.200.2 tcp-request connection reject if invalid_src mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check backup ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:2:0","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"3. 基于ACL的动静分离示例 需要注意的 haproxy 不能作为 fastcgi 的客户端，因此其后端主机不能是 phpfpm 这种 fastcgi 的应用程序服务器。后端服务器只能是 httpd 或者 nginx，并通过它们来反代 fpm。 frontend web *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend appsrvs backend staticsrvs balance roundrobin server stcsrv1 172.16.100.6:80 check backend appsrvs balance roundrobin server app1 172.16.100.7:80 check server app1 172.16.100.7:8080 check listen stats bind :9091 stats enable stats auth admin:admin stats admin if TRUE ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:3:0","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"4. 配置HAProxy支持https协议： # 1 支持ssl会话 bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE # crt后的证书文件要求PEM格式，且同时包含证书和与之匹配的所有私钥； cat demo.crt demo.key \u003e demo.pem # 2 把80端口的请求重向定443； bind *:80 redirect scheme https if !{ ssl_fc } # 3 如何向后端传递用户请求的协议和端口 http_request set-header X-Forwarded-Port %[dst_port] http_request add-header X-Forwared-Proto https if { ssl_fc } ","date":"2018-10-24","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/:4:0","tags":["马哥 Linux"],"title":"28.3 haproxy 访问控制","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6/"},{"categories":["Linux"],"content":"28.2 haproxy 配置","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"haproxy 配置 本节开始我们来学习 haproxy 的配置。haproxy 有众多的配置选项，我打算将其分为两个部分，第一部分为haproxy 的全局配置，以及常用的代理段配置，第二部分为 haproxy 的访问控制。本节为的一部分，内容包括 global 全局配置 进程及安全管理 性能调整 代理段配置 前端服务配置 后端主机配置 haproxy 状态统计及管理页面配置 自定义错误页 首部处理 日志配置 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. global配置参数 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 进程及安全管理 global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon deamon 作用: 以后端服务的方式运行 haproxy log \u003caddress\u003e [len \u003clength\u003e] \u003cfacility\u003e [max level [min level]] 作用: 定义全局的syslog服务器；最多可以定义两个； nbproc \u003cnumber\u003e 作用: 要启动的haproxy的进程数量 默认: 启动一个进程，无需修改 ulimit-n \u003cnumber\u003e 作用: 每个haproxy进程可打开的最大文件数 默认: haproxy 会自动调整，无需配置 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 性能调整: maxconn \u003cnumber\u003e 作用: 设定每个haproxy进程所能接受的最大并发连接数； maxsslconn \u003cnumber\u003e 作用: 设定每个haproxy进程所能接受的最大 sll 并发连接数； maxconnrate \u003cnumber\u003e 作用: 设定每个进程每秒种所能创建的最大连接数量； maxsessrate \u003cnumber\u003e 作用: 设定每个进程每秒种所能创建的最大会话数量； spread-checks \u003c0..50, in percent\u003e 作用: 设置后端服务器状态检测的速率偏斜，以免同时对所有后端主机进行状态检测，占用太多带宽 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. 代理配置段 与 nginx 类似，代理配置段内的参数有受限的应用范围，下面是常用的配置参数 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 前端服务配置 mode mode { tcp|http|health } 作用: 定义haproxy的工作模式； 参数: tcp: 基于layer4实现代理；可代理mysql, pgsql, ssh, ssl等协议； http: 仅当代理的协议为http时使用； health: 工作为健康状态检查的响应模式，当连接请求到达时回应“OK”后即断开连接； listen ssh bind :22022 balance leastconn mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check bind bind [\u003caddress\u003e]:\u003cport_range\u003e [, ...] [param*] 作用: 定义前端服务监听的地址和端口 listen http_proxy bind :80,:443 # 监听多个端口 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy # 监听本地 sock default_backend default_backend \u003cbackend\u003e 作用: 设定默认的backend，用于frontend中 maxconn maxconn \u003cconns\u003e: 作用: 为指定的frontend定义其最大并发连接数；默认为2000； 说明: 如果未设置，会继承 global 中的配置 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 后端主机配置 balance balance \u003calgorithm\u003e [ \u003carguments\u003e ] balance url_param \u003cparam\u003e [check_post] 作用: 定义后端服务器组内的服务器调度算法 algorithm: 算法 roundrobin: 动态算法, 支持权重的运行时调整，支持慢启动 每个后端中最多支持4095个server； static-rr: 静态算法，不支持权重的运行时调整及慢启动 后端主机数量无上限； leastconn: 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first: 根据服务器在列表中的位置，自上而下进行调度； 前面服务器的连接数达到上限，新请求才会分配给下一台服务； source: 源地址hash，hash 算法下面的 hash-type 选项指定 hash-type map-based:除权取余法，这种方法不支持权重的运行时调整，也不支持慢启动，但资源耗费少 hash-type consistent: 一致性哈希，支持权重运行时调整，也支持慢启动，但是资源耗费多 uri: 目标地址 hash，对URI的左半部分做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 完整 url: `://:@:/;?#`` 左半部分: /\u003cpath\u003e;\u003cparams\u003e 整个uri: /\u003cpath\u003e;\u003cparams\u003e?\u003cquery\u003e#\u003cfrag\u003e url_param: 对用户请求的uri的 \u003cparams\u003e中的部分的参数的值作hash计算 hash 算法可由 hash-type 指定，默认是 map-based 通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server hdr(\u003cname\u003e): 对于每个http请求，此处由\u003cname\u003e指定的http首部将会被取出做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 没有有效值的会被轮询调度； eg: hdr(Cookie) hash-type hash-type \u003cmethod\u003e \u003cfunction\u003e \u003cmodifier\u003e 作用: 指定 hash 计算的算法 method: map-based: 除权取余法，哈希数据结构是静态的数组； consistent: 一致性哈希，哈希数据结构是一个树； function: 哈希函数，eg: sdbm, djb2, wt6 default-server default-server [param*] 作用: 为backend中的各server设定默认选项 选项: 同 serve server server \u003cname\u003e \u003caddress\u003e[:[port]] [param*] 作用: 定义后端主机的各服务器及其选项； name: 服务器在haproxy上的内部名称；出现在日志及警告信息 address: 服务器地址，支持使用主机名； [:[port]]: 端口映射；省略时，表示同bind中绑定的端口； [param*]: 参数 maxconn \u003cmaxconn\u003e: 当前server的最大并发连接数； backlog \u003cbacklog\u003e: 当前server的连接数达到上限后的后援队列长度； backup: 设定当前server为备用服务器； check: 对当前server做健康状态检测； addr : 检测时使用的IP地址； port : 针对此端口进行检测； inter \u003cdelay\u003e: 连续两次检测之间的时间间隔，默认为2000ms; rise \u003ccount\u003e: 连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall \u003ccount\u003e: 连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意: httpchk，“smtpchk”, “mysql-check”, “pgsql-check” and “ssl-hello-chk” 用于定义应用层检测方法； cookie \u003cvalue\u003e: 为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled: 标记为不可用； redir \u003cprefix\u003e: 将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight \u003cweight\u003e: 权重，默认为1; cookie cookie \u003cname\u003e options 作用: 启用基于 cookie 的用户绑定 参数: \u003cname\u003e 待操作的 cookie 的键 选项: rewirte: 重写 insert: 插入 prefix: 前缀 nocache: 只对非从缓存中响应的值进行操作 indirect: 如果对应的cookie 键已经存在值，则不修改直接发送给客户端 说明: cookie 的值有 server cookie\u003cvalue\u003e 配置 # 基于cookie的session sticky的实现: backend websrvs cookie WEBSRV insert nocache indirect server srv1 172.16.100.6:80 weight 2 check rise 1 fall 2 maxconn 3000 cookie srv1 server srv2 172.16.100.7:80 weight 1 check rise 1 fall 2 maxconn 3000 cookie srv2 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.3 健康状态检测 option httpchk option httpchk \u003cmethod\u003e \u003curi\u003e \u003cversion\u003e 作用: 对后端服务器做http协议的健康状态检测,基于http协议的7层健康状态检测机制； 参数: uri: 指定检测的链接 method: 指定检测使用的请求方法 version: 指定发送的 http 的协议版本 backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\\r\\nHost:\\ www server apache1 192.168.1.1:443 check port 80 http-check expect http-check expect [!] \u003cmatch\u003e \u003cpattern\u003e 作用: 指定健康状态检测的内容 [!]: 表示取反操作 match: status: 完全匹配响应码 rstatus: 以正则表达式匹配响应码 string: 完全匹配响应内容 rstring: 以正则表达式匹配响应内容 pattern: 字符串或正则表达式，表示 match 指定的选项要匹配的内容 http-check expect status 200 http-check expect ! string SQL\\ Error http-check expect ! rstatus ^5 # check that we have a correct hexadecimal tag before /html http-check expect rstring \u003c!--tag:[0-9a-f]*\u003c/html\u003e ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:1","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.4 统计接口 stats enable 作用: 启用统计页；基于默认的参数启用stats page； 默认启用参数: stats uri : /haproxy?stats stats realm : “HAProxy Statistics” stats auth : no authentication stats scope : no restriction stats auth \u003cuser\u003e:\u003cpasswd\u003e 作用: 认证时的账号和密码，可使用多次； stats realm \u003crealm\u003e 作用: 认证时的realm； `stats uri `` 作用: 自定义stats page uri stats refresh \u003cdelay\u003e 作用: 设定自动刷新时间间隔； stats admin { if | unless } \u003ccond\u003e 作用: 启用stats page中的管理功能 stats hide-version 作用: 隐藏页面的有关 haproxy 的版本信息 # 配置示例: listen stats bind :9099 stats enable stats realm HAPorxy\\ Stats\\ Page stats auth admin:admin stats admin if TRUE ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:2","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.5 自定义错误页 errorfile errorfile \u003ccode\u003e \u003cfile\u003e 作用: 自定义错误响应页，响应页的内容由文件指定 \u003ccode\u003e: HTTP 响应码， HAProxy 目前支持自定义 200, 400, 403, 408, 500, 502, 503, and 504 \u003cfile\u003e: 响应内容所在的位置 errorfile 400 /etc/haproxy/errorfiles/400badreq.http errorfile 408 /dev/null # workaround Chrome pre-connect bug errorfile 403 /etc/haproxy/errorfiles/403forbid.http errorfile 503 /etc/haproxy/errorfiles/503sorry.http errorloc \u003ccode\u003e \u003curl\u003e errorloc302 \u003ccode\u003e \u003curl\u003e errorloc303 \u003ccode\u003e \u003curl\u003e 作用: 自定义错误响应页，错误页的内容由 url 指定 说明: errorloc302/303 会以 302/303 响应码响应客户端而不是原本的响应码 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:3","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.6 首部处理 option forwardfor option forwardfor [except \u003cnetwork\u003e] [header \u003cname\u003e] [if-none] 作用: 用于向后端主发送真实的客户端IP 在由haproxy发往后端主机的请求报文中添加X-Forwarded-For首部，其值为前端客户端的地址 选项: [except \u003cnetwork\u003e]: 请求报文来自此处指定的网络时不予添加此首部； [header \u003cname\u003e ]: 使用自定义的首部名称，而非X-Forwarded-For [if-none]: 只在不存在 X-Forwarded-For 时才添加此报文首部 reqadd/rspadd reqadd \u003cstring\u003e [{if | unless} \u003ccond\u003e] 作用: 向发送给后端服务器的请求添加首部字段 rspadd \u003cstring\u003e [{if | unless} \u003ccond\u003e] 作用: 向发送给客户端响应中添加首部字段 eg: rspadd X-Via: HAPorxy reqdel \u003csearch\u003e [{if | unless} \u003ccond\u003e] reqidel \u003csearch\u003e [{if | unless} \u003ccond\u003e] 作用: 删除正则表达式匹配到的，发往后端服务器的请求的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: reqidel 表示在进行正则表达式匹配时不区分大小写 rspdel \u003csearch\u003e [{if | unless} \u003ccond\u003e] rspidel \u003csearch\u003e [{if | unless} \u003ccond\u003e] 作用: 删除正则表达式匹配到的，发往客户端的的响应的的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: rspidel 表示在进行正则表达式匹配时不区分大小写 # remove X-Forwarded-For header and SERVER cookie reqidel ^X-Forwarded-For:.* reqidel ^Cookie:.*SERVER= rspidel ^Server:.* ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:4","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.7 日志系统 log log global 作用: 从 global 全局配置段继承日志配置 no log 作用: 不记录日志 log \u003caddress\u003e [len \u003clength\u003e] \u003cfacility\u003e [\u003clevel\u003e [\u003cminlevel\u003e]] 作用: 自定义日志记录 注意: 一个配置段内，log 日志记录只能使用两次，如果使用log global，并且global 配置了两次log，算作两次 # 注意：默认发往本机的日志服务器，配置如下 vim /etc/rsyslog.conf local2.* /var/log/local2.log $ModLoad imudp $UDPServerRun 514 log-format log-format \u003cstring\u003e 作用: 自定义日志记录格式 capture capture cookie \u003cname\u003e len \u003clength\u003e 作用: 提取并记录请求和响应的 cookie 中特定字段的值 参数: \u003cname\u003e: 指定的首部字段 len \u003clength\u003e: 最大记录的长度 capture request header \u003cname\u003e len \u003clength\u003e 作用: 提取并记录请求首部特定字段的值 参数: \u003cname\u003e: 指定的首部字段 len \u003clength\u003e: 最大记录的长度 capture response header \u003cname\u003e len \u003clength\u003e 作用: 提取并记录响应首部特定字段的值 参数: \u003cname\u003e: 指定的首部字段 len \u003clength\u003e: 最大记录的长度 capture request header Host len 15 capture request header X-Forwarded-For len 15 capture request header Referer len 15 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:5","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.8 压缩功能 compression algo compression algo \u003calgorithm\u003e 作用：启用http协议的压缩机制，指明压缩算法gzip, deflate； compression type compression type \u003cmime type\u003e 作用: 指明压缩的MIMI类型； compression algo gzip compression type text/html text/plain ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:6","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.9 连接超时时长 timeout client \u003ctimeout\u003e 作用: 客户端非活动状态的超时时长 timeout server \u003ctimeout\u003e 作用: 客户端与服务器端建立连接后，等待服务器端的超时时长， timeout http-keep-alive \u003ctimeout\u003e 作用: 持久连接的持久时长； timeout http-request \u003ctimeout\u003e 作用: 定义保持连接的超时时长 timeout connect \u003ctimeout\u003e 作用: haproxy 连接后端主机的超时时长 timeout client-fin \u003ctimeout\u003e 作用: 半关闭状态连接，client端非活动超时时间 timeout server-fin \u003ctimeout\u003e 作用: 半关闭状态连接，server端非活动超时时间 ","date":"2018-10-23","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/:4:7","tags":["马哥 Linux"],"title":"28.2 haproxy 配置","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"28.1 haproxy 入门","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"haproxy 入门 本章我们来介绍负载均衡集群的另一种实现 haproxy。与 nginx 类似，haproxy 工作于应用层属于七层代理，但是在其 tcp 模式下也能模拟实现四层代理。本章我们就来学习如何使用 haproxy。在学习配置 haproxy 之前我们先来对其做个简单了解，看看其程序与配置文件结构。 ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:0:0","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1. haproxy 简介 ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:1:0","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.1 主站与文档 对于 haproxy 介绍和性能优势这里就不多介绍，推荐大家多看看 haproxy 的主页和官方文档，特别是官方文档 主站: http://www.haproxy.org http://www.haproxy.com 文档: http://cbonte.github.io/haproxy-dconv/ ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:1:1","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.2 程序结构 haproxy 已经被收录至 yum 的 base 仓库，可直接安装，下面是 rpm 包的程序结构 $ rpm -ql haproxy|egrep -v \"(doc|man)\" /etc/haproxy /etc/haproxy/haproxy.cfg # 主配置文件 /usr/sbin/haproxy # 主程序 /usr/sbin/haproxy-systemd-wrapper /usr/bin/halog # 辅助工具 /usr/bin/iprange /usr/lib/systemd/system/haproxy.service # Unit file /etc/sysconfig/haproxy # Unit file 的配置文件 /usr/share/haproxy # 错误页 /usr/share/haproxy/400.http /usr/share/haproxy/403.http /usr/share/haproxy/408.http /usr/share/haproxy/500.http /usr/share/haproxy/502.http /usr/share/haproxy/503.http /usr/share/haproxy/504.http /usr/share/haproxy/README /var/lib/haproxy /etc/logrotate.d/haproxy ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:1:2","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.3 配置文件结构 #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats #--------------------------------------------------------------------- # common defaults that all the 'listen' and 'backend' sections will # use if not designated in their block #--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 #--------------------------------------------------------------------- # main frontend which proxys to the backends #--------------------------------------------------------------------- frontend main *:80 default_backend app #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- backend app balance roundrobin server py 127.0.0.1:8888 check haproxy 的配置分成两大配置段 global：全局配置段，用于定义 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxies：代理配置段，包括四小配置段 defaults：为frontend, listen, backend提供默认配置； fronted：定义前端监听的服务，相当于nginx, server {} backend：定义后端服务器组，相当于nginx, upstream {} listen：后端服务器组与前端服务一一对应时的便捷配置方式，可同时定义前端与后端 ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:1:3","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.4 haproxy 简单配置示例 下面是两个配置示例，我们会在下一节详细介绍 haproxy 各个重要配置选项。 frontend web bind *:80 default_backend websrvs backend websrvs balance roundrobin # 定义调度算法 server srv1 172.16.100.6:80 check server srv2 172.16.100.7:80 check listen http-in # listen 同时定义前后端 bind *:3306 server server1 127.0.0.1:3396 maxconn 32 ","date":"2018-10-22","objectID":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/:1:4","tags":["马哥 Linux"],"title":"28.1 haproxy 入门","uri":"/posts/linux/linux_mt/31-haproxy/haproxy%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"27.6 varnish 日志查看","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"varnish 日志查看 varnish 的日志存放在特定的内存区域中，分为计数器和日志信息两个部分，查看日志需要专门的工具。本节我们来学习这部分命令的使用。 ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:0:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"1. varnishstat varnishstat options 作用: 显示 varnish 缓存的计数器 选项: -1: 一次输出所有统计计数 -f field_list : 列出特定的统计字段，field 支持通配符， ^ 开头表示取反 -l: 列出可供 -f 选择的所有字段 -n varnish_name: 从哪个 varnish 实例获取日志 -V: 显示 varnish 的版本信息 -w delay: 间隔输出，可结合-1, -x , -j 使用 -x: 以 xml 格式输出 -j: 以 json 格式输出 varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_miss varnishstat -l -f MAIN -f MEMPOOL ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:1:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"2. varnishtop varnishtop options 作用: 对 varnish 日志排序后输出 选项: [-1]: 运行一次，输出所有日志排序后的结果 [-b]: Only display backend records [-c]: Only display client records [-f]: First field only [-i taglist]: Include tags [-I \u003c[taglist:]:regex\u003e]: Include by regex [-x taglist]: Exclude tags [-X \u003c[taglist:]:regex\u003e]: Exclude by regex [-V]: Version ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:2:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"3. varnishlog varnishlog options 作用: 显示 varnish 日志 ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:3:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"4. varnishncsa varnishncsa 作用: 以类似 httpd combined 格式显示 varnish 日志 ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:4:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"5. 日志记录服务 varnish 的日志只会记录在内存中，空间不够用时，新的日志就会覆盖老的日志。因此需要定期执行 varnishlog 或 varnishncsa 保存日志。yum 安装已经自动为我们配置了 Unit file，启用下面两个服务之一即可: /usr/lib/systemd/system/varnishlog.service /usr/lib/systemd/system/varnishncsa.service ","date":"2018-10-21","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/:5:0","tags":["马哥 Linux"],"title":"27.6 varnish 日志查看","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"27.5 varnish 后端主机配置","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"varnish 后端主机配置 在讲解完 varnish 的缓存配置之后，我们来看看如何配置后端服务器，包括后端服务器组的定义，调度算法，以及健康状态检测。 ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. 后端主机配置 ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 定义后端主机 定义后端主机使用 backend 关键字，在定义主机的同时，我们可以设置后端主机的多项属性。 backend BE_NAME { .host = .port = .probe = # 指定健康状态检测方法 .connect_timeout = 0.5s; .first_byte_timeout = 20s; .between_bytes_timeout = 5s; .max_connections = 50; } ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 读写分离 # 定义后端主机 backend default { .host = \"172.16.100.6\"; .port = \"80\"; } backend appsrv { .host = \"172.16.100.7\"; .port = \"80\"; } # 对后端主机进行读写分离 sub vcl_recv { if (req.url ~ \"(?i)\\.php$\") { set req.backend_hint = appsrv; } else { set req.backend_hint = default; } ... } ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:1:2","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 定义服务器组 定义后端服务器组，并配置调度算法需要导入 varnish 的 Director 模块，使用 import directors； # 1. 导入模块 import directors; # load the directors # 2. 定义后端主机 backend server1 { .host = .port = } backend server2 { .host = .port = } # 3. 服务器组定义，并指定调度算法 sub vcl_init { new GROUP_NAME = directors.round_robin(); GROUP_NAME.add_backend(server1); GROUP_NAME.add_backend(server2); } # 4. 使用服务器组 sub vcl_recv { # send all traffic to the bar director: set req.backend_hint = GROUP_NAME.backend(); } # 5. 基于cookie的session sticky： sub vcl_init { new h = directors.hash(); h.add_backend(one, 1); // backend 'one' with weight '1' h.add_backend(two, 1); // backend 'two' with weight '1' } sub vcl_recv { // pick a backend based on the cookie header of the client set req.backend_hint = h.backend(req.http.cookie); } ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:1:3","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.3 健康状态检测 后端服务器的健康状态检测有两种方式 使用专用 probe 关键词，定义检测方式，可复用 在使用 backend 定义后端主机时通过 .probe 单独指定 probe 配置参数 probe PB_NAME { .url ：检测时要请求的URL，默认为”/\"; .request ：发出的具体请求； .request = \"GET /.healthtest.html HTTP/1.1\" \"Host: www.magedu.com\" \"Connection: close\" .window ：基于最近的多少次检查来判断其健康状态； .threshold ：最近.window次检查中至有.threshhold定义的次数是成功的； .interval ：检测频度； .timeout ：超时时长； .expected_response ：期望的响应码，默认为200； } 示例 probe check { .url = \"/.healthcheck.html\"; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s; } backend default { .host = \"10.1.0.68\"; .port = \"80\"; .probe = { .url = \"/.healthcheck.html\"; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s; } } backend appsrv { .host = \"10.1.0.69\"; .port = \"80\"; .probe = check; } ","date":"2018-10-20","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/:1:4","tags":["马哥 Linux"],"title":"27.5 varnish 后端主机配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"27.4 varnish缓存策略配置","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"varnish缓存策略配置 前面我们讲解了 VCL 的语法，并通过示例讲解了一部分 varnish 缓存的配置。本节我们来看看 varnish 内置的缓存策略，然后着重来看看如何对缓存进行修剪。 ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. VCL 域默认配置 ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 vcl_recv # vcl_recv 默认配置 sub vcl_recv { if (req.method == \"PRI\") { /* We do not support SPDY or HTTP/2.0 */ return (synth(405)); } if (req.method != \"GET\" \u0026\u0026 req.method != \"HEAD\" \u0026\u0026 req.method != \"PUT\" \u0026\u0026 req.method != \"POST\" \u0026\u0026 req.method != \"TRACE\" \u0026\u0026 req.method != \"OPTIONS\" \u0026\u0026 req.method != \"DELETE\") { /* Non-RFC2616 or CONNECT which is weird. */ return (pipe); } if (req.method != \"GET\" \u0026\u0026 req.method != \"HEAD\") { /* We only deal with GET and HEAD by default */ return (pass); } if (req.http.Authorization || req.http.Cookie) { /* Not cacheable by default */ return (pass); } return (hash); } } ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. 缓存修剪 varnish 让缓存过期有多种方式，最常见的是通过 purge, 和ban purge: 是在 varnish 内置监视一个特殊的 PURGE 请求方法，并对请求的资源进行缓存请求 ban: 可以使用类似 purge 的方式，更常用的实在 varnishadm 内使用正则表达式对特定一组资源进行缓存处理 ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 使用 purge # 1. 添加修剪操作的访问控制 acl purgers { \"127.0.0.0\"/8; \"10.1.0.0\"/16; } # 2. 如何执行修剪，即能执行purge操作 sub vcl_purge { return (synth(200,\"Purged\")); } # 3.何时执行purge操作 sub vcl_recv { if (req.method == \"PURGE\") { if (!client.ip ~ purgers) { # 访问控制 return(synth(405,\"Purging not allowed for \" + client.ip)); } return(purge); } ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:2:1","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 使用 Banning 在 varnishadm 中使用 ban 子命令，可以使用正则表达式批量修剪 command: ban \u003cfield\u003e \u003coperator\u003e \u003carg\u003e eg: ban req.url ~ ^/javascripts 在配置文件中定义，使用ban()函数； if (req.method == \"BAN\") { ban(\"req.http.host == \" + req.http.host + \" \u0026\u0026 req.url == \" + req.url); # Throw a synthetic page so the request won't go to the backend. return(synth(200, \"Ban added\")); } ","date":"2018-10-19","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/:2:2","tags":["马哥 Linux"],"title":"27.4 varnish缓存策略配置","uri":"/posts/linux/linux_mt/30-varnish/varnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"27.3 VCL 语法基础","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"VCL 语法基础 varnish 的缓存配置，使用的是 VCL，一种与 C 类似的域专有类型的配置语言。本节我们先来对 VCL 做一个介绍。 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:0:0","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1. VCL 组成与处理流程 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:1:0","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.1 VCL 组成 vcl 4.0; # Default backend definition. Set this to point to your content server. backend default { .host = \"127.0.0.1\"; .port = \"8080\"; } sub vcl_recv { # Happens before we check if we have this in cache already. # # Typically you clean up the request here, removing cookies you don't need, # rewriting the request, etc. } sub vcl_backend_response { # Happens after we have read the response headers from the backend. # # Here you clean the response headers, removing silly Set-Cookie headers # and other mistakes your backend does. VCL 可以看作是在 C 语言基础上二次开发的子语言，保留了 C 语言基本的语法，并额外附加了特性: 首先作为一门语言 VCL 具有变量，赋值，条件判断等基本语法特性，需要额外提醒的是 VCL 没有循环 为了在更高层级上抽象缓存处理逻辑， VCL 在 C 基础上添加了\"状态引擎\"(state engine) VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x)指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为 subroutine ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:1:1","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.2 VCL 状态引擎 VCL 的状态引擎可以分为三类: Client Side： 作用: 客户端请求的状态引擎 包括: vcl_recv, vcl_pass, vcl_hit, vcl_miss, vcl_pipe, vcl_purge, vcl_synth, vcl_deliver... Backend Side: 作用: 后端服务器响应相关的状态引擎 包括: vcl_backend_fetch, vcl_backend_response, vcl_backend_error 两个特殊的引擎： vcl_init: 在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs； vcl_fini: 所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:1:2","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.2 VCL 处理流程 varnish 已经为状态引擎内置了关联逻辑，这种内在逻辑就是缓存的处理流程。varnish 不同版本缓存处理的流程并不相同，下面是 varnish4.0 流程图。 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:1:3","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2. VCL 语法 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:0","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.1 VCL 基础特性 VCL的语法格式： vcl 4.0;: 必需位于开头，表示 VCL 的版本 //, #, /* foo */: 注释; sub sub_name {}: 使用 sub 关键字定义状态域,例如sub vcl_recv { ...} return(sub_name): 用于实现状态引擎转换； 没有循环, 并且受限于引擎的内建变量 VCL 有限状态机 每一个请求都会被单独的线程处理，并且在任何时间都与其他请求无关 return(action); 将请求从当前状态引擎传递到一个新的状态引擎 状态引擎存在逻辑上的关联，但是彼此是相互独立的 内置的 VCL 代码总是被附加自定义的 VCL 代码之后 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:1","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.2 三类主要语法 sub subroutine { ... } if CONDITION { ... } else { ... } return(), hash_data() ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:2","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.3 变量 内建变量： req.*: 作用: request，表示与客户端发来的请求报文相关的变量 req.http.* 作用: http 首部字段相关变量 eg: `req.http.User-Agent, req.http.Referer, …`` bereq.*： 作用: 由varnish发往后端主机的httpd请求相关； bereq.http.* beresp.*: 由BE主机响应给varnish的响应报文相关； beresp.http.* resp.*: 由varnish响应给client相关； obj.*: 存储在缓存空间中的缓存对象的属性；只读； # obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数； if (obj.hits\u003e0) { set resp.http.X-Cache = \"HIT via \" + server.ip; } else { set resp.http.X-Cache = \"MISS via \" + server.ip; } |变量组|变量|作用| |:—|:—|| |bereq.|bereq.http.HEADERS|| ||bereq.request|请求方法；| ||bereq.url|请求的url；| ||bereq.proto|请求的协议版本；| ||bereq.backend|指明要调用的后端主机；| |req.|req.http.Cookie|客户端的请求报文中Cookie首部的值| ||req.http.User-Agent |～ 表示使用正则表达式| |beresp.|beresp.http.HEADERS|| ||beresp.status|响应的状态码| ||beresp.backend.name|BE主机的主机名；| ||beresp.ttl|BE主机响应的内容的余下的可缓存时长| |resp.|reresp.proto|协议版本| |obj.|obj.hits|此对象从缓存中命中的次数| |obj.|obj.ttl|对象的ttl值| |server.|server.ip|| ||server.hostname|| |client.|client.ip|| 用户自定义变量 使用 set, unset 自定义变量和取消变量 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:3","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.3 内置操作 内置函数 常用内置函数: regsub(str, regex, sub): 把str中被regex第一次匹配到字符串替换为sub；主要用于URL Rewrite regsuball(str, regex, sub): 把str中被regex每一次匹配到字符串均替换为sub； ban(boolean expression): Bans所有的其URL可以被此处的regex匹配到的缓存对象； hash_data(input): 指明哈希计算的数据；减少差异，以提升命中率； synth(status,\"STRING\")：purge操作； 关键字 常见的内置关键子: call subroutine return(action) new set unset 操作符： 判断: ==, !=, ~, \u003e, \u003e=, \u003c, \u003c= 逻辑操作符: \u0026\u0026, ||, ! 变量赋值: = 正则表达式 VCL 使用 ~ 表示使用正则表达式。eg: req.url ~ \"(?i)^/(login|admin)\", 其中 (?i) 表示不区分字符大小写。 ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:4","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.4 示例 # 示例1：强制对某类资源的请求不检查缓存： vcl_recv { if (req.url ~ \"(?i)^/(login|admin)\") { return(pass); } } # 示例2：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的时长； # 定义在 vcl_backend_response 中 vcl_backend_response{； if (beresp.http.cache-control !~ \"s-maxage\") { if (bereq.url ~ \"(?i)\\.(jpg|jpeg|png|gif|css|js)$\") { unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; } } } # 示例 3: 向后端主机传递客户端 IP # 定义在vcl_recv中； vcl_recv{ if (req.restarts == 0) { if (req.http.X-Fowarded-For) { set req.http.X-Forwarded-For = req.http.X-Forwarded-For + \",\" + client.ip; } else { set req.http.X-Forwarded-For = client.ip; } } } ","date":"2018-10-18","objectID":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/:2:5","tags":["马哥 Linux"],"title":"27.3 VCL 语法基础","uri":"/posts/linux/linux_mt/30-varnish/vcl%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"27.2 varnish 架构及安装","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"varnish 架构及安装 varnish 是 http 缓存服务器的\"新星势力\"，它与 squid的关系，类似于 httpd 与 nginx。varnish 有个最大的问题是，它的配置文件随着版本的变化变化非常大。本节我们以 4.0 系列的版本来讲解 varnish 的架构，安装和程序组成 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:0:0","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1. varnish 基础 官网: https://www.varnish-cache.org ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:0","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.1 varnish 架构图 varnish 由如下几个部分组成 管理进程(The management process) Varnish主要有两个进程，管理进程和子进程，管理进程负责：管理配置的变更（包括VCL和参数）、编译VCL、监控Varnish运行、初始化Varnish，以及提供命令行接口等。管理进程会每隔几秒钟检查一下子进程，如果发现子进程挂了，会kill掉然后重新启动一个。这些操作都会记录在日志里面，以利于你检查错误。 子进程(The child process) 子进程包括几个不同类型的线程，包括但不限于： Acceptor线程：接受新的连接并代表它们 Worker线程：一个会话一个线程，通常会使用数百个Worker线程 Expiry线程：负责从缓存中清除旧的内容 shared memory log: 为提升性能，日志是直接存放在内存中的，因此需要特定的工具查看和保存 varnishlog varnishncsa varnishstat… ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:1","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.2 配置文件组成 varnish 的配置文件分成两个部分 varnish 自身的配置，用于配置 varnish 自身的功能和特性 缓存策略配置， 用于配置供 Child/cache 进程使用的缓存策略。其配置接口为 VCL(Varnish Configuration Language)，通过 Management 提供的命令行接口进行配置，需要经过 VCL 编译器和 C 编译器编译，最后生成供 Child/cache 使用的共享对象(Share object) ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:2","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2. varnish 程序结构 $ rpm -ql varnish|egrep -v \"(man|doc)\" /etc/varnish /etc/varnish/default.vcl # 配置各Child/Cache线程的缓存策略； /etc/varnish/varnish.params # 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制； /usr/bin/varnishadm # CLI interface /usr/bin/varnishhist # Shared Memory Log交互工具 /usr/bin/varnishlog /usr/bin/varnishncsa /usr/bin/varnishstat /usr/bin/varnishtop /usr/bin/varnishtest # 测试工具程序 /usr/lib/systemd/system/varnish.service # varnish服务 /usr/lib/systemd/system/varnishlog.service # 日志持久的服务 /usr/lib/systemd/system/varnishncsa.service /usr/sbin/varnish_reload_vcl # VCL配置文件重载程序： /usr/sbin/varnishd # 主程序 /var/lib/varnish /var/log/varnish /run/varnish.pid /etc/logrotate.d/varnish ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:3","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.1 varnishd varnishd [options] 作用: varnish 主程序 配置文件: /etc/varnish/varnish.params 选项: -a address[:port][,address[:port][...]: varnish 监听的地址和端口，默认为6081 -T address[:port]: varnishadm 管理服务监听的地址和端口，默认为6082端口； -s [name=]type[,options]: 定义缓存存储机制； -u user: 运行用户 -g group: 运行用户组 -f config: VCL配置文件； -F：运行于前台； -p param=value：设定运行参数及其值； 可重复使用多次； -r param[,param...]: 设定指定的参数为只读状态； varnish 缓存存储机制 varnish 缓存存储机制(Storage Types)，分三种机制通过 -s [name=]type[,options] 指定: malloc[,size]: 内存存储，[,size]用于定义空间大小；重启后所有缓存项失效； file[,path[,size[,granularity]]]: 磁盘文件存储，黑盒；重启后所有缓存项失效； persistent,path,size: 文件存储，黑盒；重启后所有缓存项有效；实验阶段 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:4","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.2 varnish_reload_vcl varnish_reload_vcl 作用: 重载vcl配置文件 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:5","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.3 varnishadm varnishadm [-S secretfile] -T [address]:port command [...] 作用: varnish 命令行接口 选项: -S secretfile: 指定链接 varnishadm 服务的密钥文件，通常位于 /etc/varnish/secret -T [address]:port: varnishadm 服务监听的地址和端口 command: varnish 执行命令后则退出，不会进入交互命令行 $ sudo varnishadm -S /etc/varnish/secret [sudo] tao 的密码： 200 ----------------------------- Varnish Cache CLI 1.0 ----------------------------- Linux,3.10.0-862.9.1.el7.x86_64,x86_64,-smalloc,-smalloc,-hcritbit varnish-4.0.5 revision 07eff4c29 Type 'help' for command list. Type 'quit' to close CLI session. help 200 help [\u003ccommand\u003e] ping [\u003ctimestamp\u003e] auth \u003cresponse\u003e quit banner status start stop # val 配置相关 vcl.load \u003cconfigname\u003e \u003cfilename\u003e # 装载，加载并编译 vcl 配置文件 vcl.inline \u003cconfigname\u003e \u003cquoted_VCLstring\u003e vcl.use \u003cconfigname\u003e # 激活 vcl.discard \u003cconfigname\u003e # 删除 vcl.list # 查看所有 vcl 配置文件 vcl.show [-v] \u003cconfigname\u003e # 查看指定的配置文件的详细信息 # 运行时参数相关 param.show [-l] [\u003cparam\u003e] param.set \u003cparam\u003e \u003cvalue\u003e panic.show panic.clear storage.list # 缓存存储 backend.list [\u003cbackend_expression\u003e] # 后端服务器 backend.set_health \u003cbackend_expression\u003e \u003cstate\u003e # 手动设置后端服务器状态 ban \u003cfield\u003e \u003coperator\u003e \u003carg\u003e [\u0026\u0026 \u003cfield\u003e \u003coper\u003e \u003carg\u003e]... ban.list ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:1:6","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3. varnish 运行参数 varnish 运行时参数用于指定 Child/cache 子进程的工作特性。有三种配置方式: 通过 varnishd -p 选项指定 在 varnishadm 中使用 param.set 子命令配置 /etc/varnish/varnish.params 配置文件中使用 DEAMON_OPTS 选项配置，永久有效 $ cat /etc/varnish/varnish.params |grep DAEMO #DAEMON_OPTS=\"-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300\" varnish有众多的运行时参数，通常需要配置包括 线程相关的参数 Timer 与超时相关的参数 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:2:0","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3.1 线程相关的参数 在线程池内部，其每一个请求由一个线程来处理； 其worker线程的最大数决定了varnish的并发响应能力； thread_pools: 线程池数量，默认值为2，其值取决于 CPU 的核心数 thread_pool_max：每个线程池创建最大线程的数量，默认5000， thread_pool_min：每个线程池保持最少线程的数量；额外意义为“最大空闲线程数”；默认100 thread_pool_timeout： 线程空闲时间，超过阈值则摧毁线程 thread_pool_add_delay：创建一个新线程的延迟时间，默认值为0s thread_pool_destroy_delay：摧毁一个线程的延迟时间，默认值为2s； varnish最大并发连接数=thread_pools * thread_pool_max，最大的并发连接数最好不要超过 3 万，否则 varnish 将不稳定。 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:2:1","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3.2 Timer相关的参数 Timer 参数用于控制 varnish 内部的各种超时时长： send_timeout：向客户端发送响应的超时时间 timeout_idle：客户端链接最大的空闲时长 timeout_req： 从客户端接收请求的超时时长 cli_timeout：child 子进程向 Management 的命令行接口进行响应的超时时长 ","date":"2018-10-17","objectID":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/:2:2","tags":["马哥 Linux"],"title":"27.2 varnish 架构及安装","uri":"/posts/linux/linux_mt/30-varnish/varnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"27.1 web架构缓存优化","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"web架构缓存优化 上一章我们学习了如何使用 keepalived 实现一个高可用集群，接下来我们来继续完善我们的 web 站点架构，本章我们来讲解另一个重要内容，web 站点的缓存系统。 计算机组件衔接中非常常见而且重要策略就是: 两个环节连接起来不是很流畅，加中间层 两个环节连接起来在性能上不匹配，加缓存 缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在\"热区\"，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 本章我们就来讲解 web 缓存中一种常见实现 varnish，内容包括: web 站点架构演变 varnish 架构与安装配置 varnish 缓存策略配置 varnish 优化与进阶 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:0:0","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"1. Cache “Cache is Key”，缓存是 web 架构中一个非常重要的组件，因此在学习 varnish 之前，我们必需先了解一下缓存，以及缓存如何影响着我们 web 架构的演变。本节内容包括: 缓存的基本知识 web 架构缓存优化 http 协议的缓存机制 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:1:0","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"1.1 缓存基础 缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在\"热区\"，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 因此对于缓存有一些基础的必需理解的概念 首先我们缓存的是热区数据而不是所有数据，所以缓存存在空间限制，当缓存空间耗尽时，会基于 LRU(最近最少使用) 算法来更新缓存 缓存存在时效性，需要定期对过期缓存进行清理，因此通常只会对那些读多写少的内容进行缓存 缓存的有效性使用缓存命中率 hit/(hit+miss) 进行衡量，有两个衡量的指标 页面命中率：基于页面数量进行衡量 字节命中率：基于页面的体积进行衡量 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:1:1","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"1.2 缓存的分级结构 缓存存在多级结构，不同缓存级别下，有些缓存是公共的，有些缓存是私有的，公共缓存只能缓存多个用户之间可以共享的公共数据，因此我们需要在服务器指明数据是否可以被公共缓存缓存。通常 私有数据：只能被私有缓存缓存(private，private cache) 公共数据：可同时被公共和私有缓存进行缓存(public, public or private cache) 对于公共缓存，我们在设置缓存键时，应该尽量排除用户的私有信息，以提高缓存的命中率。因此非常有必要组织好缓存键，减少用户私有数据的参与。 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:1:2","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"1.3 缓存模式 缓存的实现分为两种模式 代理缓存: 缓存服务器如果未能命中，缓存服务器自己需要去找后端服务器请求资源并反回给客户端，所以又称为递归缓存 旁挂缓存: 缓存服务器未命中，需要客户端自己发送请求获取结果 memcached 就是典型的旁挂缓存，所有的 http 协议的缓存都是代理。web 缓存的两个重要开源实现是 squid, varnish，它们类似于 web 服务器的 httpd 和 nginx。 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:1:3","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"2. web 架构缓存优化 多看几次视频(34-1:17) ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:2:0","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3. HTTP 缓存控制 HTTP 协议在 1.1 增强了缓存控制机制，在 HTTP 协议的缓存控制中，服务器会会在响应报文中为资源\"打标\"，客户端则会根据\"标记\"来决定是否使用本地缓存以及如何请求。 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:3:0","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.1 响应报文的缓存控制 响应报文中有两种缓存控制机制 过期时间机制 Expires: 作用: HTTP/1.0 使用，表示缓存的过期的绝对时间，在缓存未到期之前客户端会直接使用本地缓存不会发起请求 缺陷: 可能由于时区或系统时间问题而提前失效 Cache-Control: maxage=: 作用: HTTP/1.1 可用表示缓存有效时长 说明: Cache-Control 是缓存控制的专用首部，maxage 只是其使用方式之一 条件式请求机制 Last-Modified: 作用: 文件的最近一次修改时间戳，请求报文使用 If-Modified-Since 首部配合使用 局限: Last-Modified 记录的最小单位是秒，如果响应的内容在 1s 内更新了好几次，此首部是无法反映的 Etag: 作用: 基于文件的校验码来判别，请求报文使用 If-None-Match 首部配合使用 # 响应报文中的缓存控制首部信息示例 Expires:Thu, 13 Aug 2026 02:05:12 GMT # 有效的绝对时间 Cache-Control:max-age=315360000 # 有效时长 ETag:\"1ec5-502264e2ae4c0\" # 内容校验码 Last-Modified:Wed, 03 Sep 2014 10:00:27 GMT # 文件最近一次修改时间 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:3:1","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.2 条件式请求首部 对于时间控制机制，客户端会自动根据 Expires 和 Cache-Control 来判断缓存是否过期，只有缓存过期时客户端才会发起新的请求。 对于条件式请求机制，用户会根据 Last-Modified 或 Etag 发起条件式请求 Last-Modified 对应的条件式请求首部包括: If-Modified-Since：从指定时间开始，内容是否发生变更 If-Unmodified-Since Etag 对应的条件式请求首部: If-Match: 当前缓存资源的 Etag 是否与服务器资源的 Etag 相同 If-None-Match: 以 Etag 为例，条件式请求的整个过程如下: 第一次客户端请求时，服务器会在响应报文的附加 Etag 首部，其值是响应内容的哈希值 客户端需要再次获取同一资源时，将发起条件式请求，请求中 If-Match 首部字段的值就是第一响应的 Etag 首部字段的值 服务器会将请求报文中的 Etag 值与当前资源进行比较 如果原始内容未改变，则仅响应首部（不附带body部分），响应码304 （Not Modified） 如果原始内容发生改变，则正常响应，响应码200； 如果原始内容消失，则响应404，此时缓存中的cache object也应该被删除； ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:3:2","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"3.3 缓存过程 通常情况下，http 的缓存的过期时间和条件式请求会结合使用，客户端接收到响应之后，在过期时间到期之前都会是使用本地缓存，缓存到期之后才会发送条件式请求。这样过期时间机制减少了发送请求的次数，条件式请求减少了传输内容。可以最大程度上提升传输速率。 ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:3:3","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"4. http Cache-Control 首部值 http 头中的 Cache-Control 首部有特殊作用 请求报文中用于通知缓存服务如何使用缓存响应请求 no-cache:（不要缓存的实体，要求现在从WEB服务器去取） max-age：（只接受 Age 值小于 max-age 值，并且没有过期的对象） max-stale：（可以接受过去的对象，但是过期时间必须小于 max-stale 值） min-fresh：（接受其新鲜生命期大于其当前 Age 跟 min-fresh 值之和的缓存对象） 响应报文中用于通知缓存服务器如何存储上级服务器响应的内容 public: (可以用 Cached 内容回应任何用户) private:（只能用缓存内容回应先前请求该内容的那个用户） no-cache: 可缓存，但响应给客户端之前需要revalidation，即必须发出条件式请求进行缓存有效性验正 max-age：（本响应包含的对象的过期时间） no-store: 不允许存储响应内容于缓存中 # http 协议缓存控制指令 Cache-Control = \"Cache-Control\" \":\" 1#cache-directive cache-directive = cache-request-directive | cache-response-directive cache-request-directive = \"no-cache\" | \"no-store\" (backup) | \"max-age\" \"=\" delta-seconds | \"max-stale\" [ \"=\" delta-seconds ] | \"min-fresh\" \"=\" delta-seconds | \"no-transform\" | \"only-if-cached\" | cache-extension cache-response-directive = \"public\" | \"private\" [ \"=\" \u003c\"\u003e 1#field-name \u003c\"\u003e ] | \"no-cache\" [ \"=\" \u003c\"\u003e 1#field-name \u003c\"\u003e ] | \"no-store\" | \"no-transform\" | \"must-revalidate\" | \"proxy-revalidate\" | \"max-age\" \"=\" delta-seconds | \"s-maxage\" \"=\" delta-seconds | cache-extension ","date":"2018-10-16","objectID":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/:4:0","tags":["马哥 Linux"],"title":"27.1 web架构缓存优化","uri":"/posts/linux/linux_mt/30-varnish/web%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96/"},{"categories":["Linux"],"content":"26.3 keepalived 配置示例","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"keepalived 配置示例 前面我们已经介绍了如何安装和配置 keepalived，本节我们就来看看如何使用 keepalived 对 nginx 的负载均衡集群做高可用。需要提醒大家注意的是无论是学习还是以后工作，当我们配置一个复杂服务时，都应该按照简单到复杂的顺序一步步进行配置，完成一步，验证一次，成功之后在进行下一步，这样便于排错。所以本节的示例我们将按照如下顺序展示，最终完成我们的LVS 双主模型的高可用集群配置。 单主模型下配置 keepalived 完成地址流动 双主模型下配置 keepalived 完成地址流动 单主模型的 LVS 高可用集群配置 双主模型的 LVS 高可用集群配置 双主模型 nginx 高可用集群配置 ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:0:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"1. 单主模型下完成地址流动 ! Configuration File for keepalived global_defs { notification_email { root@localhost } notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19 } vrrp_instance VI_1 { state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 571f97b2 } virtual_ipaddress { 192.168.1.168/24 dev eno16777736 } notify_master \"/etc/keepalived/notify.sh master\" notify_backup \"/etc/keepalived/notify.sh backup\" notify_fault \"/etc/keepalived/notify.sh fault\" } 通知脚本的使用方式： #!/bin/bash # contact='root@localhost' notify() { local mailsubject=\"$(hostname) to be $1, vip floating\" local mailbody=\"$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1\" echo \"$mailbody\" | mail -s \"$mailsubject\" $contact } case $1 in master) notify master ;; backup) notify backup ;; fault) notify fault ;; *) echo \"Usage: $(basename $0) {master|backup|fault}\" exit 1 ;; esac 脚本的调用方法： notify_master \"/etc/keepalived/notify.sh master\" notify_backup \"/etc/keepalived/notify.sh backup\" notify_fault \"/etc/keepalived/notify.sh fault\" ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:1:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"2. 双主模型下完成地址流动 双主模型的地址流动，只需在单主模型下额外添加一个 vrrp 实例，在新的实例下: 修改 virtual_router_id 修改 vrrp 认证的密码 修改 virtual_ipaddress 绑定的地址 原来的 MASTER 变成 BACKUP，BACKUP 变成 MASTER vrrp_instance VI_2 { state BACKUP interface eno16777736 virtual_router_id 15 priority 98 advert_int 1 authentication { auth_type PASS auth_pass 578f07b2 } virtual_ipaddress { 192.168.1.169/24 dev eno16777736 } } ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:2:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"3. 双主模型的 LVS 高可用集群配置 配置步骤如下: 首先要配置 LVS 集群的后端 RS，可参照27.5 LVS 4层负载均衡-DR模型 在\"双主模型下完成地址流动\"的基础上添加 virtual_server，配置方式如下所示 virtual_server 192.168.1.168 80 { delay_loop 3 lb_algo rr lb_kind DR protocol TCP sorry_server 127.0.0.1 80 real_server 192.168.1.137 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 1 nb_get_retry 3 delay_before_retry 1 } } real_server 192.168.1.107 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 1 nb_get_retry 3 delay_before_retry 1 } } } virtual_server 192.168.1.169 80 { ....... # 配置同上 } ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:3:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"4. 单主模型的nginx高可用集群 nginx 服务的高可用，我们需要使用 vrrp_script{} 定义 nginx 的检测方式，并将这种检测通过 track_script 添加到 vrrp 实例中去，让 vrrp 能够在检测到 nginx 服务异常时进行主备服务器切换。 ! Configuration File for keepalived global_defs { notification_email { root@localhost } notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19 } vrrp_script chk_down { script \"[[ -f /etc/keepalived/down ]] \u0026\u0026 exit 1 || exit 0\" interval 1 weight -5 } vrrp_script chk_nginx { # 定义 script \"killall -0 nginx \u0026\u0026 exit 0 || exit 1\" interval 1 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 571f97b2 } virtual_ipaddress { 10.1.0.93/16 dev eno16777736 } track_script { chk_down chk_nginx } notify_master \"/etc/keepalived/notify.sh master\" notify_backup \"/etc/keepalived/notify.sh backup\" notify_fault \"/etc/keepalived/notify.sh fault\" } ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:4:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"5. 双主模型的nginx高可用集群 双主模型在单主模型基础上添加一个 vrrp 实例即可 ","date":"2018-10-15","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/:5:0","tags":["马哥 Linux"],"title":"26.3 keepalived 配置示例","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"26.2 keepalived 安装和配置","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"keepalived 安装和配置 上一节我们对高可用集群 和 keepalived 做了一个简单介绍，本节我们来学习 keepalived 的安装配置。我们的最终目的是使用 keepalived 对 nginx 的负载均衡集群做高可用，本节内容包括: HA 集群配置的前题 keepalived 安装与组成 keepalived 配置文件格式与参数 ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. HA 集群的配置前提 HA 集群因为主备节点之间需要通信以协调工作，所以在配置之前需要一些准备工作: 各节点时间必须同步，参考 25.1 Linux时间服务-chrony 确保iptables及selinux不会成为阻碍 各节点之间可通过主机名互相通信 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 建议使用/etc/hosts文件实现，避免 DNS 称为单点故障所在 确保各节点的用于集群服务的网卡接口支持MULTICAST通信，以便进行组播 各节点之间的 root 用户可以基于密钥认证的 ssh 服务完成互相通信。 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 因为 corosync 需要在节点之间复制配置文件 ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. keepalived CentOS 6.4 只有 keepalived 就已经被收录至 base 仓库，因此可通过 yum 直接安装。 ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 程序环境 $ rpm -ql keepalived |grep -v \"share\" /usr/sbin/keepalived # 主程序文件 /etc/keepalived /etc/keepalived/keepalived.conf # 主配置文件 /usr/bin/genhash /etc/sysconfig/keepalived # Unit File的环境配置文件 /usr/lib/systemd/system/keepalived.service # Unit File /usr/libexec/keepalived ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 配置文件格式 # 1. GLOBAL CONFIGURATION # 1.1 Global definitions global_defs { } # 1.2 Static routes/addresses static_ipaddress{ } static_routes{ } static_rules{ } # 2. VRRPD CONFIGURATION # 2.1 VRRP synchronization group(s) vrrp_sync_group VG_1 { group { inside_network # name of the vrrp_instance (see below) outside_network # One for each movable IP ...} } # 2.2 VRRP instance(s) vrrp_instance inside_network { } # 3. LVS CONFIGURATION # 3.1 Virtual server group(s) virtual_server_group \u003cSTRING\u003e { } # 3.2 Virtual server(s) virtual_server group string{ } 上面是 keepalived.conf 的缩略结构，主要由如下几个配置段组成: GLOBAL CONFIGURATION: 全局配置段 Global definitions: 全局参数 Static routes/addresses: 静态地址和静态路由配置 VRRPD CONFIGURATION: vrrp 配置段 VRRP synchronization group(s)：vrrp同步组，同一组内的 vrrp 会同进同退 VRRP instance(s)：每个vrrp instance即一个vrrp路由器； LVS CONFIGURATION: lvs 规则管理配置段 Virtual server group(s): 将一组集群服务进行统一调度 Virtual server(s): ipvs集群的vs和r ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. global_defs global_defs 用于全局参数 # 示例一: global_defs 全局配置 ! Configuration File for keepalived global_defs { notification_email { # 邮件通知的管理员帐户，收件箱 root@localhost } notification_email_from keepalived@localhost # 发件箱 smtp_server 127.0.0.1 smtp_connect_timeout 30 # smtp 链接超时时长 router_id node1 # 当前节点的标识，重要 vrrp_mcast_group4 224.0.100.19 # 组播域，重要 } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:5:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4. vrrp_instance vrrp_instance 用于定义虚拟路由器 vrrp_instance \u003cSTRING\u003e { .... } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:6:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.1 vrrp_instance 常用参数 vrrp_instance 参数 作用 state MASTER/BACKUP 当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP interface IFACE_NAME 绑定为当前虚拟路由器使用的物理接口 virtual_router_id VRID 当前虚拟路由器的惟一标识，范围是0-255 priority 100 当前主机在此虚拟路径器中的优先级；范围1-254 advert_int 1 vrrp通告的时间间隔； authentication{} vrrp 认证，详细使用见下 virtual_ipaddress{} 虚拟路由器的 IP 地址，详细使用见下 virtual_routes{} 虚拟路由，详细使用见下 track_interface{} 配置要监控的网络接口，一旦接口出现故障，则转为FAULT状态,，详细使用见下 nopreempt 定义工作模式为非抢占模式，默认为抢占模式 preempt_delay 300 抢占式模式下，节点上线后触发新选举操作的延迟时长； notify_master path 当前节点成为主节点时触发的脚本 notify_backup path 当前节点转为备节点时触发的脚本 notify_fault path 当前节点转为“失败”状态时触发的脚本 notify path 通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知 # vrrp 认证 authentication { auth_type AH|PASS auth_pass \u003cPASSWORD\u003e } # 虚拟路由器 ip virtual_ipaddress { \u003cIPADDR\u003e/\u003cMASK\u003e brd \u003cIPADDR\u003e dev \u003cSTRING\u003e scope \u003cSCOPE\u003e label \u003cLABEL\u003e 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1 } # 虚拟路由 virtual_routes { src 192.168.100.1 to 192.168.109.0/24 via 192.168.200.254 dev eth1 192.168.110.0/24 via 192.168.200.254 dev eth1 } # 监控的网络接口 track_interface { eth0 eth1 ... } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:6:1","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.2 vrrp_instance 配置示例 # 示例二: 单主模型下完成地址流动 global_defs{ # 配置见示例一 ..... } vrrp_instance VI_1 { state BACKUP # 节点初始状态 interface eno16777736 # 绑定虚拟地址的网卡接口 virtual_router_id 14 # 虚拟路由器 ID priority 98 # 优先级 advert_int 1 # 组播频率 authentication { # vrrrp 认证 auth_type PASS auth_pass 571f97b2 } virtual_ipaddress { # 虚拟 IP 地址 10.1.0.91/16 dev eno16777736 label eno16777736:0 } } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:6:2","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5. vrrp_sync_group ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:7:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5.1 vrrp_sync_group 作用 VRRP synchronization group(s)：用于定义 vrrp 同步组，同一组内的 vrrp 会同进同退。所谓同进同退的意思是 vrrp 组的服务，当某一个服务发生故障转移或故障恢复时，组内的所有服务都会一同进行转移。典型的情景是高可用 NAT 模型的 LVS。 vip ----------- VS1(100) ------ DIP vip ------------VS2(99) -------DIP 如上，前段我们将 vip 定义为虚拟路由 router1，对外提供服务，后端我们将 DIP 配置为虚拟路由器 router2 向后端服务转发请求。当 router1 因为某种原因从 VS1 转移到 VS2 时，我们的 router2 也必需要转移过去。原因是 NAT 模型的 LVS 后端的 RS 必需将网关指向VS，当 VS 由 VS1 转移到 VS2 时，如果 router2 不随之转移，RS 的报文将将默认发送至 VS1，此时将无法完成目标地址转换。 需要注意的是对于 nginx 我们无需配置 router2，因为请求报文是通过 IP 地址路由的，而 IP 地址是不会变化的。 ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:7:1","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5.2 vrrp_sync_group 配置示例 vrrp_sync_group G1 { group { VI_1 # vrrp_instance 定义 vrrp 虚拟路由器名称 VI_2 VI_5 } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:7:2","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"6. virtual_server virtual_server 用于定义 ipvs 集群规则 virtual_server IP port | # 只支持 tcp 协议 virtual_server fwmark int # 防火墙标记 { ... real_server { ... } ... } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:8:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"6.1 virtual_server 常用参数 delay_loop \u003cINT\u003e：健康状态检测的时间间隔 lb_algo rr|wrr|lc|wlc|lblc|sh|dh：调度方法 lb_kind NAT|DR|TUN：集群的类型 persistence_timeout \u003cINT\u003e：持久连接时长 protocol TCP：服务协议，仅支持TCP sorry_server \u003cIPADDR\u003e \u003cPORT\u003e：备用服务器地址 real_server \u003cIPADDR\u003e \u003cPORT\u003e{}：RS 定义 RS 定义 real_server \u003cIPADDR\u003e \u003cPORT\u003e { weight \u003cINT\u003e : 权重 notify_up \u003cSTRING\u003e|\u003cQUOTED-STRING\u003e : 启动的通知脚本 notify_down \u003cSTRING\u003e|\u003cQUOTED-STRING\u003e : 关闭的通知脚本 HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK { ... }：定义当前主机的健康状态检测方法； } 健康状态检测方法: HTTP_GET|SSL_GET{}：应用层检测 TCP_CHECK{}：传输层检测 应用层检测 位于 real_server{}配置段内 HTTP_GET|SSL_GET { url { path \u003cURL_PATH\u003e ：定义要监控的URL； status_code \u003cINT\u003e ：判断上述检测机制为健康状态的响应码； digest \u003cSTRING\u003e ：判断上述检测机制为健康状态的响应的内容的校验码； } nb_get_retry \u003cINT\u003e ：重试次数； delay_before_retry \u003cINT\u003e ：重试之前的延迟时长； connect_ip \u003cIP ADDRESS\u003e ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port \u003cPORT\u003e ：向当前RS的哪个PORT发起健康状态检测请求 bindto \u003cIP ADDRESS\u003e ：发出健康状态检测请求时使用的源地址； bind_port \u003cPORT\u003e ：发出健康状态检测请求时使用的源端口； connect_timeout \u003cINTEGER\u003e：连接请求的超时时长； } 传输层检测 位于 real_server{}配置段内 TCP_CHECK { connect_ip \u003cIP ADDRESS\u003e ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port \u003cPORT\u003e ：向当前RS的哪个PORT发起健康状态检测请求 bindto \u003cIP ADDRESS\u003e ：发出健康状态检测请求时使用的源地址； bind_port \u003cPORT\u003e ：发出健康状态检测请求时使用的源端口； nb_get_retry \u003cINT\u003e ：重试次数； delay_before_retry \u003cINT\u003e ：重试之前的延迟时长； connect_timeout \u003cINTEGER\u003e ：连接请求的超时时长； } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:8:1","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"6.2 配置示例 virtual_server 10.1.0.93 80 { delay_loop 3 # 健康状态监测时间间隔 lb_algo rr # 调度算法 lb_kind DR # 集群类型 protocol TCP # 服务协议 sorry_server 127.0.0.1 80 # sorry server real_server 10.1.0.69 80 { # RS 配置 weight 1 # 权重 HTTP_GET { # 应用层健康状态监测 url { path / # 检测路经 status_code 200 } connect_timeout 1 # 链接超时时长 nb_get_retry 3 # 重试次数 delay_before_retry 1 # 重试间隔 } } real_server 10.1.0.71 80 { weight 1 HTTP_GET { url { path / status_code 200 } connect_timeout 1 nb_get_retry 3 delay_before_retry 1 } } } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:8:2","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"7. keepalived 高可用 nginx keepalived 最初的设计目的是为了高可用 LVS，所以要想高可用其他服务需要借助于 keepalived 的脚本调用接口。keepalived 通过调用外部的辅助脚本进行资源监控，并根据监控的结果实现节点的优先调整，以便在主节点发生故障时实现故障转移。 对于 nginx 调度器为例，其最重要的资源是对外提供服务的 IP 地址和 nginx 进程，keepalived 的 vrrp stack 已经能自动完成 IP 转移，但是 keepalived 并没有内置判断 nginx 是否故障，以及故障之后如何转移的功能。nginx 资源的监控，以及如何进行优先级调整只能通过提供辅助脚本进行。并且此时后端服务器的健康状态检测由 nginx 自己进行，与 keepalived 无关。 因此使用 keepalived 高可用 nginx 分两步： 先定义一个 nginx 的监控脚本，使用 keepalived 的 vrrp_script{} 配置段 调用此脚本，在 vrrp_instance{} 配置段内使用 track_script{} 配置段 ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:9:0","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"7.1 vrrp_script vrrp_script \u003cSCRIPT_NAME\u003e { script \"\" # 脚本路经 interval INT # 脚本执行的时间间隔 weight -INT # 脚本执行失败后，对优先级的调整大小 fall INT # 认定失败的检测次数 rise INT # 认定恢复正常的检测次数 user USERNAME [GROUPNAME] # 执行脚本的用户和用户组 } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:9:1","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"7.2 track_script track_script { SCRIPT_NAME_1 # vrrp_script 定义的脚本名称 SCRIPT_NAME_2 ... } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:9:2","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"7.3 配置示例 vrrp_script chk_down { script \"[[ -f /etc/keepalived/down ]] \u0026\u0026 exit 1 || exit 0\" interval 1 weight -5 } vrrp_script chk_nginx { script \"killall -0 nginx \u0026\u0026 exit 0 || exit 1\" interval 1 weight -5 fall 2 rise 1 } vrrp_instance VI_1 { state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication { auth_type PASS auth_pass 571f97b2 } virtual_ipaddress { 10.1.0.93/16 dev eno16777736 } track_script { chk_down chk_nginx } notify_master \"/etc/keepalived/notify.sh master\" notify_backup \"/etc/keepalived/notify.sh backup\" notify_fault \"/etc/keepalived/notify.sh fault\" } ","date":"2018-10-14","objectID":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:9:3","tags":["马哥 Linux"],"title":"26.2 keepalived 安装和配置","uri":"/posts/linux/linux_mt/29-keepalived/keepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"26.1 高可用集群介绍以及开源软件应用","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"高可用集群介绍以及开源软件应用 我们已经介绍了如何使用 LVS/Nginx 如何搭建一个负载均衡集群。为实现负载均衡我们需要一个前端调度器，同时为了让后端服务器共享 session，我们可能需要使用到 session 服务器，等等。调度器，session 服务器则是整个集群的单点故障所在(SPoF: Single Point of Failure)，它们一旦发生故障整个集群将不可用。 在讲解 LVS 时，我们提到了一个衡量系统可用性的标准(平均无故障时间/平均无故障时间 + 平均修复时间)。要想提升系统可用性，必需降低故障的修复时间。因此我们需要对单点故障实现高可用，以通过冗余来降低系统修复时间提高系统可用性。 本章我们就来讲解高可用集群的其中一种实现方案 keepalived。本章内容包括: 高可用集群的实现方案及原理概述 keepalived 安装配置 keepalived高可用 nginx 高可用集群有众多的解决方案，典型的包括 keepalived: 基于 VRRP 协议的实现 heartbeat/corosync: 通用的HA集群解决方案，corosync 是 heartbeat 的升级版 heartbeat/corosync 是通用的高可用集群解决方案，因此对于特定服务，它能提供了功能是有限的。因此大多数情况下，不同服务通常有各自特定的高可用解决方案。keepalived 最开始是为专门高可用 LVS 的，也可以用来高可用 nginx。本节我们就来简述这两种解决方案的基本原理。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:0:0","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1. 高可用集群面临的问题 所谓的高可用集群就是为主服务，又称为主节点提供了一个冗余的备用节点，当主节点不可用时，备用节点能自动替代主节点对外提供服务。但是这个冗余与替换的过程有许多问题需要解决: ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:0","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1.1 心跳信息 首先备用节点如何判断主节点不可用。为此主节点需要不断的向备用节点发送\"心跳\"信息(heartbeat)，备用节点通过心跳信息判断主节点是否正常。然而我们面对的集群环境，除了主机异常之外，也很有可能出现网络异常。所以备用节点收到心跳信息时，不一定是主节点故障，而有可能是网络异常，我们称此种状况为网络发生分区(Network partition)。 其次高可用集群中的服务器可能不止一台，应该如何同步心跳信息呢？很显然一对一通信效率太低，我们需要借助组播，因此搭建高可用集群很重要的一步就是配置集群的组播域。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:1","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1.2 网络分区 当网络发生分区时，原本的集群就会划分成多个集群，此时应该如何决定由哪个部分来提供服务呢？按照少数服从多数的原则，应该由包含超过半数节点的分区网络继续提供服务。确定了提供服务器的分区之后还不够，首先如果主节点并不再此分区网络中，需要重新选举一个主节点；其次为防止其他分区网络争抢资源，需要对剩余的其他分区作服务器隔离。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:2","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1.3 选举协议 中心节点的选举有众多协议，其中最著名的就是分布式网络中的 Paxos，以及再次基础上衍生出来的 Raft 协议。很建议大家多读一读这两个协议相关的论文和文章。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:3","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1.4 服务隔离 准确来说，高可用集群高可用的是特定的服务。以 nginx 负载均衡集群来说，我们高可用的是 nginx 调度器这个服务，这个服务由两个核心资源组成一是对外提供服务的 IP 地址，另一个是我们的 nginx 进程。对于 nginx 即成我们只需要在备用节点上配置好相同的 nginx 服务即可。因此对于负载均衡集群来说，最重要的资源是对外提供的 IP 地址。当服务发生分区时，如果不进行服务隔离，不同的分区网络就会争抢 IP，导致服务间歇性不可用。当然这种情况并不是很严重。 我们考虑另一个更加严重的情况，假设所有后端服务器都挂载到了一个共享的块存储设备上，比如 SAN 这种块级别的共享存储区域网络。网络分区发生时，如果一个分区对磁盘块做了删除操作，另一个做了修改操作，那么最终的将对导致文件系统的元数据不可用进而导致整个系统不可用。 服务隔离有两种曾经: STONITH(Shooting The Other Node In The Head)：主机级别的隔离，“爆头\"直接将服务器停机处理 fence: 资源级别的隔离，限制对特定资源的访问 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:4","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"1.5 相关术语 在高可用集群中我们有如下一些专用术语 Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作； Failback：故障移回，即某资源的主节点故障后重新修改上线后，将转移至其它节点的资源重新切回的过程 接下来我们首先来介绍 heartbeat/corosync 架构。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:1:5","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"2.heartbeat/corosync 如图是 corosync 的结构图，其由三个部分组成，由下而上是 messaging/infrastructure: 发送心跳信息 ClusterResource Manager(CRM): 资源分配层，用于定义集群服务，包括 Cluster Information Base (CIB): CIB使用XML表示整个集群的配置和当前状态信息。它包含所有集群选项、节点、资源、约束的定义和彼此之间的关系。 并且CIB同步更新至所有的集群节点。在集群内有一个通过DC维护的主CIB节点。其它所有节点存在一个CIB的副本。 Designated Coordinator (DC): 某一个CRM被推选为DC。DC 是群集中唯一可以决定需要在整个群集执行更改（例如节点屏蔽或资源移动）的实体。 其它所有的节点从当前DC获得配置和资源分配信息` Policy Engine (PE): 只要DC需要进行群集范围的更改（对新 CIB 作出反应），PE会根据当前集群状态和配置计算出下一个状态并反馈生成一列指令给DC。 PE通常在DC上运行。 Local Resource Manager (LRM): LRM是CRM的代理，代表 CRM 调用本地RA.它可以执行start/stop/monitor操作并把结果反馈给CRM。 并且可以隐藏不同RA(OCF,LSB)直接的差异。LRM 是其本地节点上所有资源相关信息的权威来源。 Resource Layer: RL包含不同的RA。RA是已写入的用来启动、停止和监视某种服务（资源）的程序（通常是shell脚本），仅能被LRM调用 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:2:0","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"3. vrrp 协议 keepalived 是基于 vrrp 协议的，因此在搞清楚 keepalived 之前我们首先需要了解 vrrp 协议。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:0","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"3.1 vrrp 协议概述 VRRP(Virtual Router Redundancy Protocol) 虚拟路由器冗余协议，是一种容错协议，它保证当主机的下一跳路由器出现故障时，由另一台路由器来代替出现故障的路由器进行工作，从而保持网络通信的连续性和可靠性。 vrrp 架构如上图所示，vrrp 通过将多个路由器组成一个虚拟路由器，对外提供路由服务。虚拟路由器有自己的虚拟IP地址和虚拟MAC地址。局域网内的主机将虚拟路由器的IP地址设置为默认网关，通过 虚拟路由器与外部网络进行通信。当主路由器发生故障时，自动选择一个备用路由器继续提供服务。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:1","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"3.2 VRRP 术语 在讲解 VRRP 工作过程之前，我们先来了解一下相关述语: 虚拟路由器： 由一个 Master 路由器和多个 Backup 路由器组成 主机将虚拟路由器当作默认网关。 VRID： 虚拟路由器的标识 有相同 VRID 的一组路由器构成一个虚拟路由器。 Master 路由器： 虚拟路由器中承担报文转发任务的路由器 Backup 路由器： Master 路由器出现故障时，能够代替 Master 路由器工作的路由器 虚拟 IP 地址： 虚拟路由器的 IP 地址 IP 地址拥有者： 接口 IP 地址与虚拟 IP 地址相同的路由器被称为 IP 地址拥有者 虚拟 MAC 地址： 一个虚拟路由器拥有一个虚拟 MAC 地址 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:2","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"3.3 工作流程 VRRP 工作时，首先需要选举出 Master 路由器，并且Master 路由器需要实时同步自己的状态信息，以让备用节点在主节点故障时及时替换，整个详细过程如下: Master 选举: 虚拟路由器中的路由器根据优先级选举出 Master。 Master 路由器通过发送免费 ARP 报文，将自己的虚拟 MAC 地址通知给与它连接的设备或者主机，从而承担报文转发任务 心跳信息: Master 路由器周期性发送 VRRP 报文，以公布其配置信息（优先级等）和工作状况； 故障转移: 如果 Master 路由器出现故障，虚拟路由器中的 Backup 路由器将根据优先级重新选举新的 Master； 虚拟路由器状态切换: Master 路由器由一台设备切换为另外一台设备，新的 Master 路由器只是简单地发送一个携带虚拟路由器的 MAC 地址和虚拟 IP 地址信息的免费 ARP 报文，这样就可以更新与它连接的主机或设备中的ARP 相关信息。网络中的主机感知不到 Master 路由器已经切换为另外一台设备。 抢占/非抢占: Backup 路由器的优先级高于 Master 路由器时，由 Backup 路由器的工作方式（抢占方式和非抢占方式）决定是否重新选举 Master 同时，为了提高安全性， VRRP 还提供了认证功能VRRP提供了三种认证方式： 无认证 简单字符认证：在一个有可能受到安全威胁的网络中，可以将认证方式设置为简单字符认证 MD5 认证：在一个非常不安全的网络中，可以将认证方式设置为 MD5 认证 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:3","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"3.4 工作模式 如果备用的路由只是备用，将会造成资源浪费，我们可以配置多个虚拟路由器组如上图所示: 三个路由器上配置了，三个虚拟路由器，每个虚拟路由器以某一个路由器为主服务器对外提供服务，另外两台路由器作为其备用路由器 前端主机可以将网关平均指向三个虚拟 IP，这样每个路由器都为部分主机提供了路由服务 这种模式我们称为 VRRP N/M 或 N/N 模式，即在一组路由上提供多个虚拟路由器。 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:3:4","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"4. keepalived ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:4:0","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"4.1 keepalived 功能 keepalived 是 vrrp协议的软件实现，原生设计的目的为了高可用ipvs服务，其提供了如下功能: 基于vrrp协议完成地址流动； 为vip地址所在的节点生成ipvs规则（在配置文件中预先定义） 为ipvs集群的各RS做健康状态检测； 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务，正是基于此功能，keepalived 才能实现高可用 nginx ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:4:1","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"4.2 keepalived 架构 如图，keepalived 由如下几个部分组成: vrrp stack: vrrp 协议的实现 ipvs wrapper: 生成 ipvs 规则 checkers: 后端服务器状态检测 watch dog: 监控进程 smtp: 邮件服务 ","date":"2018-10-13","objectID":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/:4:2","tags":["马哥 Linux"],"title":"26.1 高可用集群介绍以及开源软件应用","uri":"/posts/linux/linux_mt/29-keepalived/%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0/"},{"categories":["Linux"],"content":"25.5 nginx线上部署示例","date":"2018-10-12","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/","tags":["马哥 Linux"],"title":"25.5 nginx线上部署示例","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"nginx线上部署示例 ","date":"2018-10-12","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:0:0","tags":["马哥 Linux"],"title":"25.5 nginx线上部署示例","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"1. nginx 线上部署示例 user nobody nobody; worker_processes 4; worker_rlimit_nofile 51200; error_log logs/error.log notice; pid /var/run/nginx.pid; events { use epoll; worker_connections 51200; } http { server_tokens off; include mime.types; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 20m; client_body_buffer_size 256k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; default_type application/octet-stream; charset utf-8; client_body_temp_path /var/tmp/client_body_temp 1 2; proxy_temp_path /var/tmp/proxy_temp 1 2; fastcgi_temp_path /var/tmp/fastcgi_temp 1 2; uwsgi_temp_path /var/tmp/uwsgi_temp 1 2; scgi_temp_path /var/tmp/scgi_temp 1 2; ignore_invalid_headers on; server_names_hash_max_size 256; server_names_hash_bucket_size 64; client_header_buffer_size 8k; large_client_header_buffers 4 32k; connection_pool_size 256; request_pool_size 64k; output_buffers 2 128k; postpone_output 1460; client_header_timeout 1m; client_body_timeout 3m; send_timeout 3m; log_format main '$server_addr $remote_addr [$time_local] $msec+$connection ' '\"$request\" $status $connection $request_time $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; open_log_file_cache max=1000 inactive=20s min_uses=1 valid=1m; access_log logs/access.log main; log_not_found on; sendfile on; tcp_nodelay on; tcp_nopush off; reset_timedout_connection on; keepalive_timeout 10 5; keepalive_requests 100; gzip on; gzip_http_version 1.1; gzip_vary on; gzip_proxied any; gzip_min_length 1024; gzip_comp_level 6; gzip_buffers 16 8k; gzip_proxied expired no-cache no-store private auth no_last_modified no_etag; gzip_types text/plain application/x-javascript text/css application/xml application/json; gzip_disable \"MSIE [1-6]\\.(?!.*SV1)\"; upstream tomcat8080 { ip_hash; server 172.16.100.103:8080 weight=1 max_fails=2; server 172.16.100.104:8080 weight=1 max_fails=2; server 172.16.100.105:8080 weight=1 max_fails=2; } server { listen 80; server_name www.magedu.com; # config_apps_begin root /data/webapps/htdocs; access_log /var/logs/webapp.access.log main; error_log /var/logs/webapp.error.log notice; location / { location ~* ^.*/favicon.ico$ { root /data/webapps; expires 180d; break; } if ( !-f $request_filename ) { proxy_pass http://tomcat8080; break; } } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } server { listen 8088; server_name nginx_status; location / { access_log off; deny all; return 503; } location /status { stub_status on; access_log off; allow 127.0.0.1; allow 172.16.100.71; deny all; } } } ","date":"2018-10-12","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:1:0","tags":["马哥 Linux"],"title":"25.5 nginx线上部署示例","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"2. tornado 配置 upstream pyapi_prod { server 10.80.85.26:9999 max_fails=3 fail_timeout=20s; } upstream pyapi_pre { server 10.81.33.246:9999 max_fails=3 fail_timeout=20s; } upstream prediction_prod { server 10.47.208.181:8083 max_fails=3 fail_timeout=20s; } upstream crawlerLink_prod { server 10.47.208.181:8086 max_fails=3 fail_timeout=20s; } upstream crawlerLink_pre { server 10.47.208.181:8087 max_fails=3 fail_timeout=20s; } server { #include drop.conf; listen 80; server_name pyapi.internal.enlightent.com pyapi.enlightent.com; location /prediction/ { proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } location /crawlerLink/ { proxy_pass http://crawlerLink_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } location / { proxy_pass http://pyapi_prod; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } } server { #include drop.conf; listen 80; server_name pre.pyapi.internal.enlightent.com pre.pyapi.enlightent.com; location / { proxy_pass http://pyapi_pre; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } location /prediction/ { proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } location /crawlerLink/ { proxy_pass http://crawlerLink_pre/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; } } ","date":"2018-10-12","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:2:0","tags":["马哥 Linux"],"title":"25.5 nginx线上部署示例","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"3. pycgi \u003cVirtualHost *:8083\u003e ServerName pycgi.internal.enlightent.com DocumentRoot \"/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times\" \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/\" \u003c/IfModule\u003e \u003cDirectory \"/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/\"\u003e AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost *:8084\u003e ServerName pycgi.internal.enlightent.com DocumentRoot \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor\" \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/\" \u003c/IfModule\u003e \u003cDirectory \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/\"\u003e AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost *:8085\u003e ServerName pre.pycgi.internal.enlightent.com DocumentRoot \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor\" \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/\" \u003c/IfModule\u003e \u003cDirectory \"/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/\"\u003e AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost *:8086\u003e ServerName pycgi.internal.enlightent.com DocumentRoot \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi\" \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/\" \u003c/IfModule\u003e \u003cDirectory \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/\"\u003e AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost *:8087\u003e ServerName pre.pycgi.internal.enlightent.com DocumentRoot \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi\" \u003cIfModule alias_module\u003e ScriptAlias /cgi-bin/ \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/\" \u003c/IfModule\u003e \u003cDirectory \"/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/\"\u003e AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip \u003c/Directory\u003e \u003c/VirtualHost\u003e ","date":"2018-10-12","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:3:0","tags":["马哥 Linux"],"title":"25.5 nginx线上部署示例","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"25.4 nginx 四层代理和负载均衡","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"nginx 四层代理和负载均衡 新版的 nginx 除了代理 http 服务外，还可以基于 stream 模块来实现四层协议的转发、代理或者负载均衡等等。与 LVS 不同的是，nginx 的四层代理依然工作在用户空间，“一手拖两家”，一边作为服务器接收用户请求，另一边作为客户端向后端服务器发送请求。四层的反代和负载均衡配置与 http 的反代和负载均衡基本类似。 ","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:0:0","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"1. 四层反代和负载均衡示例 worker_processes auto; error_log /var/log/nginx/error.log info; events { worker_connections 1024; } stream { upstream backend { # stream 模块的 upstream 模块 hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; } upstream dns { server 192.168.0.1:53535; server dns.example.com:53; } server { listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend; } server { listen 127.0.0.1:53 udp reuseport; proxy_timeout 20s; proxy_pass dns; } server { listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; } } ","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:1:0","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"2. ngx_stream_core_module stream 模块使用 server { ... } 上下文来配置反代的四层服务，有如下特殊的配置指令 listen listen address:port options Default: — Context: server 作用: nginx 反代服务监听的地址和端口 选项: [udp]: 默认为tcp协议, 指定监听udp协议的端口 [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; server { listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend; } ","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:2:0","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"3. ngx_stream_proxy_module ngx_stream_proxy_module 主要来实现四层代理功能，其作用与提供的指令与 ngx_http_proxy_module 基本一致 proxy_pass address; proxy_pass address; Default: — Context: location, if in location 作用: 配置后端服务器 参数: address 为后端服务器的地址，可以 IP，域名, upstream 定义的服务器组 proxy_timeout timeout; proxy_timeout timeout; Default: proxy_timeout 10m; Context: stream, server 作用: 设置 nginx 与客户端和后端服务器，超过多长时间未传输数据时则断开链接 proxy_connect_timeout `proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； ","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:3:0","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"4. ngx_stream_upstream_module ngx_stream_proxy_module 主要来实现四层负载均衡功能，其作用与提供的指令与 ngx_http_upstream_module 基本一致 配置示例 stream { upstream sshsrvs { server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; } server { listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; } } ","date":"2018-10-11","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/:4:0","tags":["马哥 Linux"],"title":"25.4 nginx 四层代理和负载均衡","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"categories":["Linux"],"content":"25.3 nginx负载均衡器","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"nginx负载均衡器 nginx http 的负载均衡功能主要由 ngx_http_upstream_module 提供，其作用是将后端服务器定义为 nginx 中的服务器组，然后将服务器组作为反向代理的目标。在反代请求时，服务器组首先通过配置的调度算法选择一个后端服务器，然后向其转发请求。因此服务器组是 nginx 负载均衡功能的核心组件。 服务器组在 nginx 中是通过 upstream 上下文定义的。upstream 上下文内有特定的配置选项，用于定制后端服务器的权重，调度算法，健康状态检测策略等等。 ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:0:0","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"1. ngx_http_upstream_module ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:1:0","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"1.1 定义 upstream 组 upstream name { ... } Default: — Context: http 作用: upstream 上下文，用于定义服务器组 应用: 可被 proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, and grpc_pass 使用 upstream httpdsrvs { server ... server... ... } ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:1:1","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"1.2 upstream 服务器配置选项 server server address [parameters]; Default: — Context: upstream 选项: weight=num : 权重 max_conns=number: 最大并发连接数 max_fails=number: 健康状态监测: 失败多少次将被标记为不可用，为 0 表示不做健康状态检测，默认为 1 fail_timeout=tim: 健康状态检测: 定义失败的超时时长，默认为 10s backup : 指定备用服务器(sorry server) down : 将服务器标记下线，灰度发布使用 slow_start=time : 慢启动，指平滑的将请求迁移到新增的服务器上 …其他商用版本参数 # eg： upstream 配置示例 http{ upstream dynamic { ip_hash; zone upstream_dynamic 64k; server backend1.example.com weight=5; server backend2.example.com:8080 fail_timeout=5s slow_start=30s; server 192.0.2.1 max_fails=3; server backend3.example.com resolve; server backend4.example.com service=http resolve; server backup1.example.com:8080 backup; server backup2.example.com:8080 down; server unix:/tmp/backend3; } server { location / { proxy_pass http://dynamic; health_check; } } } keepalive keepalive connections; Default: — Context: upstream 作用: 激活 nginx 与后端 upstream server 之间的持久连接功能 参数: connections 表示每个 workder 进程与后端服务器总共能保持的长连接数 # eg: memcache 启动keepalive 长连接 upstream memcached_backend { server 127.0.0.1:11211; server 10.0.0.2:11211; keepalive 32; } server { ... location /memcached/ { set $memcached_key $uri; memcached_pass memcached_backend; } } health_check health_check [parameters]; Default: — Context: location 作用: 定义对后端主机的健康状态检测机制；只能用于location上下文； 选项: interval=time：检测频率，默认为每隔5秒钟； fails=number：判断服务器状态转为失败需要检测的次数； passes=number：判断服务器状态转为成功需要检测的次数； uri=uri：判断其健康与否时使用的uri； match=name：基于指定的match来衡量检测结果的成败，name 是 match 上下文定义的检测机制 port=number：使用独立的端口进行检测； 说明: 健康状态检测 upstream 内会自动对服务器组进行健康状态检测，但检测的是服务是否存在 health_check 可在特定应用内，按照特定的方式进行额外的健康状态检测 建议在此location 中关闭访问日志 仅Nginx Plus有效； # eg: 健康状态检测 http { server { ... location / { proxy_pass http://backend; health_check match=welcome; } } match welcome { status 200; header Content-Type = text/html; body ~ \"Welcome to nginx!\"; } } match match{} 上下文用来定义衡量某检测结果是否为成功的衡量机制；有如下专用指令： status：期望的响应码； status CODE status ! CODE header：基于响应报文的首部进行判断 header HEADER=VALUE header HEADER ~ VALUE body：基于响应报文的内容进行判断 body ~ \"PATTERN\" body !~ \"PATTERN\" 需要注意的是 match{}, health_check 都进在仅Nginx Plus中有效 ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:1:2","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"1.2 upstream 调度算法配置 least_conn least_conn Default: — Context: upstream 作用: 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； least_time least_time header | last_byte [inflight]; Default: — Context: upstream 作用: 最短平均响应时长和最少连接； 参数: header：response_header; last_byte: full_response; 说明: 仅Nginx Plus有效； ip_hash ip_hash; Default: — Context: upstream 作用: 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； hash hash key [consistent]; Default: — Context: upstream 作用: 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； 参数: consistent 指定使用一致性hash算法； hash $request_uri consistent # 基于请求 url 进行绑定，lvs 的 DH算法 hash $remote_addr # == ip_hash hash $cookie_name sticky 用于实现基于 cookie的 session 绑定，只在商业版才能使用 ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:1:3","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"1.3 http upstream 内置变量 内置变量: $upstream_addr: 挑选的上游服务器地址 $upstream_cache_status: 缓存命中状态 # 自定义响应首部 http { add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status } ","date":"2018-10-10","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/:1:4","tags":["马哥 Linux"],"title":"25.3 nginx负载均衡器","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8/"},{"categories":["Linux"],"content":"25.2 nginx反向代理facgi","date":"2018-10-09","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/","tags":["马哥 Linux"],"title":"25.2 nginx反向代理facgi","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/"},{"categories":["Linux"],"content":"nginx反向代理facgi 在讲解 httpd 的时候，我们说过通过 php 搭建一个 动态站点时，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 nginx 与 php 结合的话则只能通过 fpm，将 php 运行为独立的应用程序服务器，nginx 通过反代的模式与 fpm 结合起来。nignx 基于 ngx_http_fastcgi_module 模块就能作为 fastcgi 协议的客户端与 fpm 通信。本节我们就来详解 nignx fastcgi 反向代理的相关配置。 ","date":"2018-10-09","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/:0:0","tags":["马哥 Linux"],"title":"25.2 nginx反向代理facgi","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/"},{"categories":["Linux"],"content":"1. ngx_http_fastcgi_module ngx_http_fastcgi_module 提供的配置的参数与 ngx_http_proxy_module 提供的参数几乎完全相同，只是将开头的 http 换成的 fastcgi。 ","date":"2018-10-09","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/:1:0","tags":["马哥 Linux"],"title":"25.2 nginx反向代理facgi","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/"},{"categories":["Linux"],"content":"1.1 fastcgi 反向代理服务配置 fastcgi_pass fastcgi_pass address; Default: — Context: location, if in location 参数: address为fastcgi server的地址 fastcgi_index fastcgi_index name; Default: — Context: http, server, location 作用: fastcgi默认的主页资源; fastcgi_param fastcgi_param parameter value [if_not_empty]; Default: — Context: http, server, location 作用: 设置传递给后端 fastcgi serve 的参数 # 配置示例1： # 前提：配置好fpm server和mariadb-server服务； location ~* \\.php$ { root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html$fastcgi_script_name; include fastcgi_params; } # 配置示例2 # 通过/pm_status和/ping来获取fpm server状态信息； location ~* ^/(pm_status|ping)$ { include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name; } ","date":"2018-10-09","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/:1:1","tags":["马哥 Linux"],"title":"25.2 nginx反向代理facgi","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/"},{"categories":["Linux"],"content":"1.2 fastcgi 缓存配置 fastcgi_cache_path fastcgi_cache_path path options Default: — Context: http 作用: 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； 选项: levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE keys_zone=name:size: k/v映射的内存空间的名称及大小 inactive=time: 非活动时长 max_size=size: 磁盘上用于缓存数据的缓存空间上限 fastcgi_cache fastcgi_cache zone | off; Default: fastcgi_cache off; Context: http, server, location 作用: 调用指定的缓存空间来缓存数据 fastcgi_cache_key fastcgi_cache_key string; Default: — Context: http, server, location 作用: 定义用作缓存项的key的字符串； fastcgi_cache_key localhost:9000$request_uri; fastcgi_cache_methods fastcgi_cache_methods GET | HEAD | POST ...; Default: fastcgi_cache_methods GET HEAD; Context: http, server, location 作用: 为哪些请求方法使用缓存； fastcgi_cache_min_uses `fastcgi_cache_min_uses number;`` Default: fastcgi_cache_min_uses 1; Context: http, server, location 作用: 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； fastcgi_cache_valid `fastcgi_cache_valid [code …] time;`` Default: — Context: http, server, location 作用: 不同的响应码各自的缓存时长； fastcgi_keep_conn fastcgi_keep_conn on | off; Default: fastcgi_keep_conn off; Context: http, server, location 作用: 是否启动 nginx 于 fastcgi server 之间的长链接 示例： fastcgi 缓存配置 http { ... fastcgi_cache_path /var/cache/nginx/fastcgi_cache levels=1:2:1 keys_zone=fcgi:20m inactive=120s; ... server { ... location ~* \\.php$ { ... fastcgi_cache fcgi; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; ... } ... } ... } ","date":"2018-10-09","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/:1:2","tags":["马哥 Linux"],"title":"25.2 nginx反向代理facgi","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi/"},{"categories":["Linux"],"content":"25.1 nginx反向代理http","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"nginx反向代理http 26 章我们讲解了 nginx 作为 web 服务的应用，除了 web 服务功能，nginx 还能作为七层的反向代理实现负载均衡功能。本章我们就来讲解 nginx 的另两项主要功能: 反向代理服务器 负载均衡调度器 nginx 是高度模块化的，只要nginx 具有实现了相关协议的模块，就可以作为相关的反向代理服务器。ngx_http_proxy_module 是 http 反向代理模块，ngx_http_fastcgi_module 是 fastcgi 协议的反代模块。 在介绍 LVS 的负载均衡集群时，我们对 LVS 和 nginx 的负载均衡能力就进行的比较。nginx 作为七层的负载均衡器，能获取应用层的报文信息，因此提供了更多的功能。但是由于工作于用户空间，需要通过套接字与客户端和后端服务器进行交互，所以并发能力受到系统套接字数量的限制。 在讲解 nginx 之前，我们再来回顾一下 LB集群的软件方式 四层调度: lvs, nginx(stream module), haproxy(mode tcp) 七层调度: nginx(http_up_stream module), haproxy(mode http) nginx 的 http 模块，和 stream 模块都具有 up_stream 模块 http 的 up_stream 主要是用来负载均衡 http 服务的 stream 本身只是一个能基于四层协议的反代模块，stream 的 up_stream 则是用来负载这类服务的 nginx 是高度模块化，http 的反向代理功能主要由 ngx_http_proxy_module 模块提供，本节我们来讲解如何将 nginx 配置成一个 http 的反向代理服务器，内容包括: nginx 七层反向代理原理 反向代理服务器参数配置 后端服务配置 代理缓存配置 http 首部字段配置 超时时长配置 ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:0:0","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"1. nginx 七层反向代理原理 ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:1:0","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"2. ngx_http_proxy_module # http 反向代理示例 location / { proxy_pass http://localhost:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; } ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:0","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"2.1 后端服务配置 proxy_pass proxy_pass URL 作用: 指定被代理的后端服务器 参数: URL=http://IP:PORT[/PATH] Default: — Context: location, if in location, limit_except locations url_pattern{ proxy_pass URL } nginx 通过 proxy_pass URL 传递 location 匹配到的 url 时存在一些规则和限制 proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri，效果是 nginx 会将 location 匹配到的剩余部分直接附加在 URL 后，传递给后端服务器，所以 locations 与 URL 通常是要么都以 / 结尾，要么都不以 / 结尾。 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； # 1. location /uri/ { proxy http://hos[:port]; } http://HOSTNAME/uri --\u003e http://host/uri # 2. location /uri/ { proxy http://host/new_uri/; } http://HOSTNAME/uri/ --\u003e http://host/new_uri/ location /uri/ { proxy http://host/new_uri; # 错误，要么都以 `/` 结尾，要么都不以 `/` 结尾。 } http://HOSTNAME/uri/test --\u003e http://host/new_uritest # 3. location ~|~* /uri/ { proxy http://host; } http://HOSTNAME/uri/ --\u003e http://host/uri/； ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:1","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"2.2 代理缓存配置 proxy_cache_path proxy_cache_path path options Default: — Context: http 作用: 定义可用于proxy功能的缓存 options: [levels=levels]: 缓存的目录结构层级 keys_zone=name:size: 缓存区域名称即内存大小 [inactive=time]: 非活动链接的检测时间间隔 [max_size=size]: 缓存的文件所占用的最大磁盘大小 proxy_cache proxy_cache zone | off Default: proxy_cache off; Context: http, server, location 作用: 指明要调用的缓存，或关闭缓存机制 参数: zone: proxy_cache_path 定义的缓存 proxy_cache_key proxy_cache_key string Default: proxy_cache_key $scheme$proxy_host$request_uri; Context: http, server, location 作用: 缓存中用于“键”的内容； proxy_cache_valid proxy_cache_valid [code ...] time; Default: — Context: http, server, location 作用: 定义对特定响应码的响应内容的缓存时长； 参数: code: 响应码 time: 缓存时长 proxy_cache_methods proxy_cache_methods GET | HEAD | POST ... Default: proxy_cache_methods GET HEAD; Context: http, server, location 作用: 只对哪些方法获取的内容进行缓存 proxy_cache_use_stale proxy_cache_use_stale param Default: proxy_cache_use_stale off; Context: http, server, location 作用: 被代理服务器响应失败时，是否使用过期缓存进行响应 参数: 可选值包括 error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off ...; proxy_cache_min_uses proxy_cache_min_uses number Default: proxy_cache_min_uses 1; Context: http, server, location 作用: proxy_path 定义的 inactive 非活动时间内，最少被访问多少次才不会被清理 proxy_cache_bypass proxy_cache_bypass string ... Default: — Context: http, server, location 作用: 在何种情况下，nginx 将不从缓存中取数据 # 缓存配置示例 http { proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; # 配置 server { ... location / { proxy_pass http://backend; proxy_cache cache_zone; # 使用 proxy_cache_key $uri; proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_use_stale error timeout http_500 http_502 http_503; proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment; proxy_cache_bypass $http_pragma $http_authorization; } } } ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:2","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"2.3 代理 header 设置 proxy_set_header proxy_set_header field value Default: proxy_set_header Host $proxy_host; proxy_set_header Connection close; Context: http, server, location 作用: 设定发往后端主机的请求报文的请求首部的值 proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for proxy_hide_header proxy_hide_header field; Default: — Context: http, server, location 作用: 禁止 nginx 将哪些从后端服务器接收的响应传递给客户端，默认情况下 nignx 已经禁止将 “Date”, “Server”, “X-Pad”, and “X-Accel-…” 发送给客户端，此选项的配置值会附加到禁止列表中。 ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:3","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"2.4 超时设置 proxy_connect_timeout `proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 与后端服务器建立链接的超时时长 proxy_read_timeout proxy_read_timeout time; Default: proxy_read_timeout 60s; Context: http, server, location 作用: nginx 向接收后端服务器响应时，两次报文之间的超时时长 proxy_send_timeout proxy_send_timeout time; Default: proxy_send_timeout 60s; Context: http, server, location 作用: nginx 向后端服务器发送请求时，两次报文之间的超时时长 ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:4","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"3. ngx_http_headers_module ngx_http_headers_module 允许 nginx 配置发给用户的响应报文的 header add_header add_header name value [always]; Default: — Context: http, server, location, if in location 作用: 向响应报文中添加自定义首部； add_header X-Via $server_addr; add_header X-Accel $server_name; expires expires [modified] time; expires epoch | max | off; Default: expires off; Context: http, server, location, if in location 作用: 用于定义Expire或Cache-Control首部的值，或添加其它自定义首部； ","date":"2018-10-08","objectID":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/:2:5","tags":["马哥 Linux"],"title":"25.1 nginx反向代理http","uri":"/posts/linux/linux_mt/28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http/"},{"categories":["Linux"],"content":"24.7 LVS 高可用","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"LVS 高可用 前面我们搭建的负载均衡集群，一旦调度器发生故障，整个服务将不可用，我们需要对其进行高可用。keepalived 是 LVS 高可用最简单有效的解决方案，但是本节我们先不会讲解 keepalived，后面有一个章的内容专门讲解。本节的目的是通过对 LVS 高可用的讲解，让大家理解高可用集群中的重要概念，特别是健康状态检测。 ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"1. LVS 的单点故障 LVS 的单点故障 Director不可用，整个系统将不可用，这是整个集群的单点故障所在 解决方案: 高可用 实现: keepalived，heartbeat/corosync 某RS不可用时，Director依然会调度请求至此RS； 解决方案：对各RS的健康状态做检查，失败时禁用，成功时启用； 实现: keepalived, heartbeat/corosync, ldirectord 对于后端服务器的健康状态检测应该是调度器本身所具有的功能，但是因为 LVS 工作的太多底层，所以 LVS 本身不具有此功能，其需要借助外部工具来实现。 keepalived 是帮助 LVS 实现高可用的，但是额外也能帮助 LVS 实现健康状态检测，并且在服务器状态发生变化时，完成 ipvs 对服务器的增删操作。ldirectord 则主要就是为了帮助 LVS 做后端状态检测，并且在服务器状态发生变化时，完成对服务器的增删操作，除此之外没有别的功能。 ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 健康状态检测 对服务器的健康状态检测理解，可以从检查机制，检查后的操作进行理解 检查机制 检查机制: 又称检查方法，即通过什么方式，怎么判断服务器已经故障或已恢复 检查方法: 网络层检测: ping 主机 传输层检测: 端口探测，检测服务端口是否存在 应用层检测: 某关键资源是否能被请求到 判断方式: 很显然，我们不能因为某一次检测失败就判定后端服务器故障，因为有可能网络出现问题，也有可能服务器繁忙还没来得及响应。因此我们需要经过多次检测结果来判断服务器的状态。 # 服务器状态转换 第一次故障时 --------\u003e 软状态 ----\u003e 多次故障 ------\u003e 硬状态(真正认定为故障) ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"2. ldirectord ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"2.1 安装 ldirectord 的rpm 包下载链接 ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/network:/ha-clustering:/Stable/CentOS_CentOS-6/x86_64/ldirectord-3.9.5-3.1.x86_64.rpm $ rpm -ql ldirectord /etc/ha.d # 配置文件目录 /etc/ha.d/resource.d /etc/ha.d/resource.d/ldirectord # 主程序链接 /etc/init.d/ldirectord /etc/logrotate.d/ldirectord /usr/lib/ocf/resource.d/heartbeat/ldirectord /usr/sbin/ldirectord # 主程序 /usr/share/doc/ldirectord-3.9.5 /usr/share/doc/ldirectord-3.9.5/COPYING /usr/share/doc/ldirectord-3.9.5/ldirectord.cf # 配置文件示例 ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"2.2 配置 需要在注意的是 ldirectord 会自动根据配置文件及后端服务器可用状态生成规则，因此无需在使用 ipvsadm 创建集群。 cp /usr/share/doc/ldirectord-3.9.5/ldirectord.cf /etc/ha.d/ vim /etc/ha.d/ldirectord.cf # 配置示例 # Global Directives checktimeout=3 # 检测的超时时长 checkinterval=1 # 检测的频率，单位秒 fallback=127.0.0.1:80 # 所有后端服务器都不可用，最后的备用服务器，sorry server autoreload=yes # 配置文件修改时，是否自动加载 logfile=\"/var/log/ldirectord.log\" #logfile=\"local0\" #emailalert=\"admin@x.y.z\" # 通知管理员 #emailalertfreq=3600 # 故障未修复，每隔多长时间发一次邮件 #emailalertstatus=all # 对哪些状态改变发送邮件 quiescent=no # virtual 对应于 LVS 一个集群 virtual=3 real=192.168.1.107:80 gate 2 # RS real=192.168.1.109:80 gate 1 fallback=127.0.0.1:80 gate service=http scheduler=wrr #persistent=600 #netmask=255.255.255.255 checktype=negotiate checkport=80 request=\"index.html\" #receive=\"CentOS\" #virtualhost=www.x.y.z # 向哪个 httpd 的虚拟机主机发送请求 ","date":"2018-10-07","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"24.7 LVS 高可用","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"categories":["Linux"],"content":"24.6 防火墙标记和LVS持久链接","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"防火墙标记和LVS持久链接 前面我们演示了如何使用 LVS 创建一个负载均衡服务，然而在生产环境中，我们可能要同时调度两个及以上的集群服务。典型的情景是，同时部署了 http，https 服务，用户浏览网页的时候使用的 http 服务，当用户登陆或支付时因为 http 是明文的不安全，此时必需切换成 https。如果这个两个服务是单独调度，很有可能用户登陆之后被重新调度到其他服务器上，这样用户原有的缓存就会丢失。所以我们必需将 http，https 作为一组服务进行同一调度，这就需要使用到防火墙标记。我们本节我们就来演示如何使用LVS 统一调度 http，https 服务。 ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:0:0","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"1. 防火墙标记 FWM 要想将一组RS的集群服务统一进行调度，我们需要借助 iptables 的防火墙标记功能(FWM) 首先在 director iptables 的 mangle 表的 PREROUTING 链上对一组服务标打上同样的防火墙标记 然后基于FWM 定义集群服务，让 ipvs 对相同标记的服务进行统一调度 ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:1:0","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"2. http/https 统一调度示例 上一节我们基于 LVS-DR 配置了一个 http 服务，在此基础上我们继续配置一个 https 服务，并将它们统一调度 ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:2:0","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"2.1 RS https 服务 https 的负载均衡 首先各个 RS 密钥和证书文件必需一致 ssh 回话会大量的耗费系统资源，因此服务器会对 ssh 会话进行缓存，为了使缓存生效，lvs 必需使用 sh 算法进行调度，但是 sh 算法会影响负载均衡的效果 如果负载均衡器是 nginx 我们可以在调度器上进行 ssh 会话的建立和缓存，发送到后端服务器请求就可以直接基于 http 协议。我们称这种方式为 ssh 会话拆除。但是 LVS 是工作在内核上，无法理解 ssh 会话，也就做不到 ssh 会话拆除。 # 1. VS 上私建 CA # CA (umask 077;openssl genrsa -out private/cakey.pem 2048) openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365 # 证书 (umask 077;openssl genrsa -out /root/http.key 2048) openssl req -new -key /root/http.key -out /root/http.csr -days 365 openssl ca -in /root/http.csr -out /root/http.crt -days 365 # 2. RS 的 https 服务配置 scp /root/http.* root@192.168.1.107:/etc/httpd/ssl yum install mod_ssl vim /etc/httpd/cond/ssl.conf # 3.验证 https 服务 # 在客户端导入证书 scp /etc/pki/CA/cacert.pem root@192.168.1.106:/root/ vim /etc/hosts # 添加域名 curl --cacert /root/cacert.pem \"https://www.tao.com/test.html\" ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:2:1","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"2.2 VS 集群服务配置 case $1 in start) iptables -F ipvsadm -C iptables -t mangle -A PREROUTING -d 192.168.1.99 -p tcp -m multiport --dports 443,80 -j MARK --set-mark 3 ipvsadm -A -f 3 -s sh ipvsadm -a -f 3 -r 192.168.1.107 -g -w 1 ipvsadm -a -f 3 -r 192.168.1.109 -g -w 1 ;; stop) iptables -F ipvsadm -C ;; esac ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:2:2","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"2.3 测试 for i in {1..10};do curl --cacert /root/cacert.pem \"https://www.tao.com/test.html\";curl --cacert /root/cacert.pem \"http://www.tao.com/test.html\";done ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:2:3","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"3. lvs persistence lvs 持久连接 功能: 实现无论使用任何调度算法，在一段时间内，能够实现将来自同一个地址的请求始终发往同一个RS； 实现: lvs 的持久连接模板，独立于调度算法存在 类型: PPC: 每个端口对应定义为一个集群服务，每集群服务单独调度； PFWMC: 基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity； PCC: 基于0端口定义集群服务，即将客户端对所有应用的请求统统调度至后端主机，必须定义为持久模式； 启用: ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] -p [timeout]: 使用 -p 参数就可以启用 lvs 持久链接功能，默认为 360 秒 # PPC: ipvsadm -A -t 192.168.1.99:80 -s rr -p [600] ipvsadm -a -t 192.168.1.99:80 -r 192.168.1.107 -g ipvsadm -a -t 192.168.1.99:80 -r 192.168.1.109 -g # PFWMC -- 基于防火墙标记定义集群服务即可 ipvsadm -A -f 10 -s rr -p [600] # PCC -- 端口定义为 0，此时必需使用 -p 选项 ipvsadm -A -t 192.168.1.99:0 -s rr -p [600] ","date":"2018-10-06","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/:3:0","tags":["马哥 Linux"],"title":"24.6 防火墙标记和LVS持久链接","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8Clvs%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5/"},{"categories":["Linux"],"content":"24.5 LVS DR模型实战","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"LVS DR模型实战 本节我们将搭建一个 LVS-DR 的负载均衡集群。 ","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/:0:0","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1. 网络拓扑结构 拓扑结构说明: VS， RS1， RS2 在虚拟机内均采用桥接方式，桥接到物理机的网卡上 VIP 配置在 DIP 所在网卡的别名上 ","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/:1:0","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"2. lvs-dr 配置示例 ","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/:2:0","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"2.1 RS 配置脚本 #!/bin/bash vip=\"192.168.1.99\" case $1 in start) echo 1 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 2 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce iptables -F ifconfig lo:0 $vip netmask 255.255.255.255 broadcast $vip up route add -host $vip dev lo:0 ;; stop) ifconfig lo:0 down echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 0 \u003e /proc/sys/net/ipv4/conf/lo/arp_announce ;; *) echo \"Usage $(basename $0) start|stop\" exit 1 ;; esac echo \"/proc/sys/net/ipv4/conf/all/arp_ignore:\" `cat /proc/sys/net/ipv4/conf/all/arp_ignore` echo \"/proc/sys/net/ipv4/conf/lo/arp_ignore:\" `cat /proc/sys/net/ipv4/conf/lo/arp_ignore` echo \"/proc/sys/net/ipv4/conf/all/arp_announce:\" `cat /proc/sys/net/ipv4/conf/all/arp_announce` echo \"/proc/sys/net/ipv4/conf/lo/arp_announce:\" `cat /proc/sys/net/ipv4/conf/all/arp_announce` ","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/:2:1","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"2.2 VS 配置脚本 #!/bin/bash vip=\"192.168.1.99\" ifc=\"enp0s3:0\" port=80 rs1=\"192.168.1.107\" rs2=\"192.168.1.109\" case $1 in start) ifconfig $ifc $vip netmask 255.255.255.255 broadcast $vip up iptables -F ipvsadm -A -t $vip:$port -s wrr ipvsadm -a -t $vip:$port -r $rs1 -g -w 1 ipvsadm -a -t $vip:$port -r $rs2 -g -w 1 ;; stop) ipvsadm -C ifconfig $ifc down ;; *) echo \"Usage $(basename $0) start|stop\" exit 1 ;; esac ","date":"2018-10-05","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/:2:2","tags":["马哥 Linux"],"title":"24.5 LVS DR模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_dr%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"24.4 LVS nat模型实战","date":"2018-10-04","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/","tags":["马哥 Linux"],"title":"24.4 LVS nat模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"LVS nat模型实战 本节我们将搭建一个 LVS-NAT 的负载均衡集群。 ","date":"2018-10-04","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/:0:0","tags":["马哥 Linux"],"title":"24.4 LVS nat模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1. 网络拓扑结构 ","date":"2018-10-04","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/:1:0","tags":["马哥 Linux"],"title":"24.4 LVS nat模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"2. lvs-nat 配置 # 1. 配置 RS # - 配置 ip 地址 # - 配置 httpd # - 关闭 iptables # - 关闭 SELinux # 2. 配置 Director ipvs sysctl net.ipv4.ip_foward=1 ipvsadm -A -t 192.168.1.254:80 -s rr ipvsadm -a -t 192.168.1.254:80 -r 172.16.0.251 -m -w 1 ipvsadm -a -t 192.168.1.254:80 -r 172.16.0.252 -m -w 1 ipvsadm -L -n ipvadm -S -n \u003e /etc/sysconfig/ipvsadm ipvsadm-save -n \u003e /etc/sysconfig/ipvsadm ipvsadm -C ipvsadm -R \u003c /etc/sysconfig/ipvsadm # 修改规则 ipvsadm -E -t 192.168.1.148:80 -s sh ipvsadm -L -n ipvsadm -e -t 192.168.1.148:80 -r 172.16.0.2:8080 -m # 不行 ipvsadm -d -t 192.168.1.148:80 -r 172.16.0.2 ","date":"2018-10-04","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/:2:0","tags":["马哥 Linux"],"title":"24.4 LVS nat模型实战","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4_nat%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"24.3 LVS 调度算法和 ipvsadmin","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"LVS 调度算法和 ipvsadmin 命令使用 上一节我们对 LVS 的工作原理和四种模型下如何实现负载均衡做了简单介绍，本节我们来学习 LVS 种可用的调度算法以及 ipvsadmin 命令的使用。 ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. lvs 调度算法 LVS 的调度算法分为静态方法和动态方法两类 ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 静态算法 静态方法: 仅根据算法本身进行调度 RR: round robin, 轮调 WRR: weighted rr, 加权轮调 SH: source hash, 源地址哈希，实现 session 保持的机制 – 来自同一个IP的请求始终调度至同一RS DH: destination hash，目标地址哈希，将对同一个目标的请求始终发往同一RS ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 动态算法 动态方法: 根据算法及各 RS 的当前负载(Overhead)状态进行调度 LC: Least Connection Overhead = Active * 256 + Inactive WLC: Weighted LC Overhead = (Active * 256 + Inactive) / weight SED: Shortest Expection Delay Overhead = (Active + 1) * 256 / weight NQ: Never Queue, 按照 SED 进行调度，但是被调度的主机，在下次调度时不会被选中 – SED 算法改进 LBLC: 定义: Locality-Based LC，即动态的 DH 算法 作用: 正向代理情形下的 cache server 调度 LBLCR: 定义: Locality-Based Least-Connection with Replication 带复制的LBLC算法 特性: 相对于 LBLC，缓存服务器之间可以通过缓存共享协议同步缓存 ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:1:2","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. ipvsadm ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.1 ipvsadmin 简介 使用 ipvsadmin 定义一个负载均衡集群时 首先要定义一个集群，然后向集群内添加 RS。 一个 ipvs 主机可以同时定义多个集群服务 一个 cluster server 上至少应该有一个 real server 在适用 ipvsadmin 定义集群服务之前，首先要确定 ipvs 已在内核中启用。Centos 的 /boot/config-VERSION 文件内记录了编译内核的所有参数，通过此文件查看 ipvs 配置参数即可确定 ipvs 是否启用。 # 查看 ipvs 在内核中是否启用，及其配置 $ grep -i -A 10 \"IP_VS\" /boot/config-3.10.0-514.el7.x86_64 CONFIG_IP_VS=m CONFIG_IP_VS_IPV6=y # CONFIG_IP_VS_DEBUG is not set CONFIG_IP_VS_TAB_BITS=12 # # IPVS transport protocol load balancing support # CONFIG_IP_VS_PROTO_TCP=y CONFIG_IP_VS_PROTO_UDP=y CONFIG_IP_VS_PROTO_AH_ESP=y CONFIG_IP_VS_PROTO_ESP=y CONFIG_IP_VS_PROTO_AH=y CONFIG_IP_VS_PROTO_SCTP=y # # IPVS scheduler # CONFIG_IP_VS_RR=m CONFIG_IP_VS_WRR=m CONFIG_IP_VS_LC=m CONFIG_IP_VS_WLC=m CONFIG_IP_VS_LBLC=m CONFIG_IP_VS_LBLCR=m CONFIG_IP_VS_DH=m CONFIG_IP_VS_SH=m CONFIG_IP_VS_SED=m CONFIG_IP_VS_NQ=m ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.2 ipvsadmin 程序包组成 $ yum install ipvsadm $ rpm -ql ipvsadm /etc/sysconfig/ipvsadm-config # 默认的规则保存文件 /usr/lib/systemd/system/ipvsadm.service # unit file /usr/sbin/ipvsadm # 主程序 /usr/sbin/ipvsadm-restore # 规则保存工具 /usr/sbin/ipvsadm-save # 规则重载工具 ipvs 直接附加在内核之上，只要内核正常运行，ipvs 即可工作。ipvs 的 Unit file 主要是在启动时加载规则，在关闭时保存规则而已 # cat /usr/lib/systemd/system/ipvsadm.service [Unit] Description=Initialise the Linux Virtual Server After=syslog.target network.target [Service] Type=oneshot # start 加载规则 ExecStart=/bin/bash -c \"exec /sbin/ipvsadm-restore \u003c /etc/sysconfig/ipvsadm\" # stop 保存规则 ExecStop=/bin/bash -c \"exec /sbin/ipvsadm-save -n \u003e /etc/sysconfig/ipvsadm\" ExecStop=/sbin/ipvsadm -C RemainAfterExit=yes [Install] WantedBy=multi-user.target ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.3 ipvsadm 使用 ipvsadm命令的核心功能： 集群服务管理：增、删、改； 集群服务的RS管理：增、删、改； 集群的查看 集群服务管理 ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 作用: 集群服务的增，改 选项: -A: 添加集群服务 -E: 修改集群服务 -t|u|f service-address: 指定集群的作用的协议，地址和端口，唯一标识一个集群 -t: TCP协议 VIP:TCP_PORT -u: UDP协议，VIP:UDP_PORT -f：firewall MARK，是一个数字 -s scheduler: 调度算法，默认为 wlc ipvsadm -D -t|u|f service-address 作用: 删除集群服务 选项: -t|u|f service-address: 指定删除的集群 ipvsadm -C 作用: 清空定义的所有内容 管理集群服务上的 RS ipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 作用: 添加或修改集群服务的 RS 选项: -a: 添加 RS -e: 修改 RS -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 -g|i|m: 指定lvs类型，默认为 m -g: gateway, dr类型 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight: 权重 ipvsadm -d -t|u|f service-address -r server-address 作用: 删除集群服务上的 RS 选项: -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 查看 ipvsadm -L|l [options] 作用: 查看集群状态信息 选项: --numeric, -n: 基于数字格式显示ip和端口 --connection，-c: 显示当前的连接 --exact: 显示统计数据精确值 --stats: 显示统计数据 --rate : 显示速率 ipvsadm -Z [-t|u|f service-address] 作用: 清空集群的计数器 选项: -t|u|f service-address:指定管理的集群 规则保存和重载 ipvsadm -R 作用: 重载 == ipvsadm-restore ipvsadm -S [-n] 作用: 保存 == ipvsadm-save ","date":"2018-10-03","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/:2:3","tags":["马哥 Linux"],"title":"24.3 LVS 调度算法和 ipvsadmin","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"24.2 LVS 4层负载均衡原理","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"LVS 4层负载均衡原理 本节我们先来讲解 LVS 实现负载均衡的原理，内容包括: LVS nginx 工作层级 LVS 负载均衡原理 LVS 负载均衡的四种模型 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1. LVS nginx 工作层级 要想区分 lvs 与 nginx 实现负载均衡的区别，关键是要明白它们工作在TCP/IP 协议哪个层级。12.1 计算机网络基础知识 我们详细讲解过 TCP/IP 协议。计算机网络被分成两个层次，通信子网和资源子网，应用层是资源子网位于用户空间，下四层位于内核空间。应用层想进行网络通信，必需通过套接子接口向内核发起系统调用，而 Linux 上套接子的数量是有数量限制的。 LVS LVS 是四层的负载均衡器又称为四层路由器，四层交换机，位于内核空间，直接附加在 iptables netfilter 的 nat 表的 INPUT 链上。可直接根据请求报文的目标 IP 和 port 向后端服务器转发报文，无需创建套接字，因此没有套接字数量的限制。 LVS 通过修改请求报文的或IP地址或端口或 MAC 地址直接将报文转发至后端服务器，后端服务器看到的请求依然可能是用户的IP而与中间转发的主机无关。 nginx ngxin/haproxy 则工作在应用层，同时充当服务器端和客户端，作为服务器接收外部用户请求，再作为客户端向后端服务器发起请求，将用户请求转发给后端服务器。整个过程需要创建套接字以完成网络通信，所以存在套接字数量限制。 应用对比 相比于 nginx，LVS 在实际的生产环境中使用相对较少，原因有以下几点: 大多数企业并没有达到使用 LVS 进行负载均衡的规模，通常情况下使用 nginx，haproxy 就可以很好的完整负载均衡任务 LVS 工作于内核，没有很好的用户端工具，也没有操作更高应用级别的能力，比如无法通过 cookie 进行转发，所以没有 nginx/haproxy 易用 当企业的并发请求超过套接子的限制时，更加倾向于通过硬件实现负载均衡。 但是 LVS 仍然不失为高并发下负载均衡的有效解决方案，而且LVS 是我们理解其他负载均衡集群非常重要的组件，同时 LVS 也是面试重点，因此我们还是要学好 LVS。 实际工作环境中，如果并发请求达到了使用 LVS 的级别，通常采用二级调度的方式，第一级是 LVS，第二级是 nginx/haproxy. ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"2. LVS 负载均衡原理 如上图所示 LVS 由两个部分组成: ipvs: 工作于内核空间中 netfilter INPUT 链上的钩子函数 ipvsadmin: ipvs 的用户空间命令行工具，用于向 ipvs 添加集群服务和规则 我们需要通过ipvsadmin 向 ipvs 添加监听的服务和对应的集群。当请求报文到来时: 经过第一次路由决策，发往本机的报文会由 PREROUTING 到达 INPUT 附加在 INPUT 的 ipvs 会根据 ipvs 上集群服务的IP，协议和端口来判断报文是否需要向后端的集群进行转发 如果是需要转发的报文，LVS 会根据配置的调度算法，选择集群中某一台主机，将请求报文直接送往 POSTROUTING链转，转发至该服务器 LVS 有 4 种工作类型，不同类型下，LVS 会相应的修改请求报文的 ip，端口或 mac 地址，以将报文转发至目标服务器 因此对于 LVS 而言，报文的在内核的流经顺序为 PREROUTING --\u003e INPUT --\u003e POSTROUTING ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3. LVS 术语及架构 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:3:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.1 LVS 组成 LVS(Linux Virtual Server) 由 VS, RS 两个部分组成 VS：Virtual Server, 负载均衡的调度器，又称为 Director, Dispatcher, Balancer rs：Real Server, 真正提供服务的集群服务器，又称为 upstream server, backend server ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:3:1","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.2 LVS的类型(架构) LVS 有四种不同的类型，这四中类型的工作流程实现就是我们接下来讲解的重点: lvs-nat: Network Address Translation，多目标IP的DNAT，通过修改请求报文的目标IP完整转发 lvs-dr: Direct Routing，直接路由，通过重新封装新的MAC地址完成转发 lvs-tun:IP Tunneling，在原请求IP报文之外新加一个IP首部 lvs-fullnat:修改请求报文的源和目标IP，非标准实现 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:3:2","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.3 LVS-NAT(MASQUERADE) 附注: IP 命名: VIP：Virtual IP DIP: Director IP RIP: Real Server IP CIP：Client IP LVS-NAT 就是一个多用途的 DNAT(iptables) 通过修改请求报文的目标IP地址(端口)至挑选出的某RS IP 地址实现转发。相比与 DNAT 只能将报文转发至固定主机，LVS-NAT 可以根据调度算法选择转发的后端主机。LVS-NAT 具有如下一些特征: RS(RIP),DIP应该使用私有地址；RS的网关必须指向DIP； 请求和响应都要经过Director；高负载场景中，Director易成为性能瓶颈； 支持端口映射； vs必须是Linux系统，rs可以是任意系统； RS 的 RIP 和 Director 的 DIP 必须在同一 IP 网络 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:4:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.4 LVS-DR(GATEWAY) LVS-DR 通过修改请求报文的目标 MAC 地址进行转发。如上图所示，报文经过了如下的转发过程: VS 接收到来自用户的请求报文 VS 通过调度算法选择一个 RS，通过修改请求报文的目标 MAC 地址为该 VS 的 mac 地址直接向其转发请求报文。因为 VS 必需要能获取 RS 的 MAC 地址，所以 RS 与 VS 必需位于同一物理网络中 RS 接收到响应报文后无需经过 VS 直接向客户端进行响应。因为客户端请求的目标地址是 VIP，所以 RS 进行响应的源地址必需是 VIP，否则客户端不会接收响应。 那我们如何确保 RS 响应的源地址是 VIP 呢？ 首先我们需要在所有的 RS 的网卡上添加 VIP 的 IP 地址 因为 VS 和 RS 都绑定了 VIP ，我们需要保证前端路由将目标地址为VIP的报文统统发往 VS，而不能发往 RS Linux 上响应报文的源IP，是由其发出的第一块网卡上的IP 地址决定，因此我们必需设置 RS 的路由条目，让所有的响应报文从 VIP 所在的网卡发出。 那我们如何保证前端路由将目标地址为VIP的报文统统发往 VS，而不能是 RS 呢？有三种方法: 在前端路由器上静态绑定 VS VIP 地址所在网卡的 MAC 地址；问题是未必有路由操作权限，且无法为 VS 实现高可用，因为 VS 发生故障转移时，VS 所在的服务器就会发生变化，VIP 所在的网卡也就发生了变化。 使用 aprtables 在 RS 上拒绝对 VIP 的 arp 响应和通告，aprtables 类似防火墙的工作于物理层，可通过 MAC 过滤，使用复杂不便于配置 修改RS上内核参数，将RS上的VIP配置在lo接口的别名上，并限制lo接口的 arp 通告和响应，这样就能阻断 RS 对 VIP 地址的解析请求，这是最佳的解决方案。 因此 VIP 必需配置的 lo 接口的别名上，同时必需设置路由，强制让响应报文先经过 lo 接口，再通过内核的转发功能从网卡发出。 LVS-DR 具有如下特征: RS可以使用私有地址；但也可以使用公网地址，此时可通过互联网通过RIP对其直接访问； RS跟Directory必须在同一物理网络中，以便能基于物理地址做转发； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS可以是大多数常见的OS； RS的网关绝不允许指向DIP； ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:4:1","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.5 LVS-TUN(IPIP) LVS-NAT 需要 RS 的网关必需指向 DIP，因此 RS 和 VS 必需位于同一网段中，LVS-DR VS 需要能获取到 RS 的 MAC 地址，因此 VS 和 RS 必需位于同一物理网段中；通常的传输介质，比如双绞线最大的传输距离也就只有 100 米，所以 VS 和 RS 必需位于同一机房内，所以如果各 RS 不再同一位置，比如为了灾备在不同地方分别放置了集群服务器，这两种模式就无法使用。 LVS-TUN 类似 LVS-DR 不过其能跨越地理位置的限制。 LVS-TUN 不修改请求报文的 ip 首部，而是通过在原有的 ip 首部之外，在封装一个 ip 首部。真个请求响应过程如下图所示。 与 LVS-DR 相同的是每个 RS 都必须配置 VIP，并将 VIP 所在网卡作为响应报文的出口以确保响应报文的源IP 为 VIP。但是 RS 无需限制 ARP 的通告和响应，因为此时 VS 与 RS 不再同一网络中。RS 上配置的 VIP 不会影响请求报文到达 VS，因为 VIP 不可能位于 RS 的网段中，因此 RS 中 VIP 是不可达网络，不能接收到发送到 VIP 的请求。 因为额外添加一层 IP 首部，因此 RS 必需要支持隧道协议，否则无法解析转发的报文。同时额外增加的 IP 首部会增加报文大小，如果刚好使得报文从小于 MTU 变成大于 MTU，则会发生报文拆分降低传输速度，因此 VS 上最好能针对这种情况自动拆分报文。 LVS-TUN 具有如下特性: RIP、VIP、DIP全部是公网地址； RS的网关不会也不可能指向DIP； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS的OS必须支持隧道功能； ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:4:2","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.6 LVS-FULLNAT LVS-TUN 虽然能跨越地理位置的限制，但是配置起来不便，很少使用。为了满足跨越机房的需求，LVS 有第四种非标准实现 LVS-FULLNAT。LVS-FULLNAT 未收录进内核，要使用需要自己编译内核才能使用。 LVS-NAT 只修改了请求报文的目标地址，因此 RS 进行响应时，为了让目标地址为 CIP 经过 VS，必需将 RS 的网关设置为 RS。LVS-FULLNAT 会同时修改请求报文的目标地址和源地址进行转发， 这样 RS 的响应报文的目标地址为 DIP 而不是 CIP，报文经过路由一定到达 VS，因此 就可以跨越同一网络的限制。 LVS-FULLNAT具有如下特性: VIP 是公网地址，RIP 和 DIP 是私网地址，二者无须在同一网络中 RS 接收到的请求报文的源地址为 DIP，因此要响应给 DIP 请求报文和响应报文都必须经由 Director 支持端口映射 RS 可以使用任意 OS ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:4:3","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3.7 总结 lvs-nat, lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIP； lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信； lvs-dr, lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun：通过在原IP报文之外封装新的IP首部实现转发，支持远距离通信 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:4:4","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"4. arp 内核控制参数 LVS-DR 模型中，我们说到可以通过内核参数来控制 arp 的通告和响应，arp_ignore, apr_announce 就是控制参数。每个网卡都有对应 arp_ignore, apr_announce 控制参数 $ ls /proc/sys/net/ipv4/conf all default lo virbr0 virbr0-nic wlp1s0 # all 表示所有网卡 $ ll /proc/sys/net/ipv4/conf/lo/|grep arp -rw-r--r--. 1 root root 0 9月 7 09:51 arp_accept -rw-r--r--. 1 root root 0 9月 7 09:51 arp_announce -rw-r--r--. 1 root root 0 9月 7 09:51 arp_filter -rw-r--r--. 1 root root 0 9月 7 09:51 arp_ignore -rw-r--r--. 1 root root 0 9月 7 09:51 arp_notify -rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp -rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp_pvlan ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:5:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"4.1 arp_ignore arp_ignore 作用: 控制系统在收到外部的arp请求时，是否要返回arp响应 取值: 主要有0，1，2，3~8较少用到 0: 响应任意网卡上接收到的对本机IP地址的arp请求（包括环回网卡上的地址），而不管该目的IP是否在接收网卡上。 1: 只响应目的IP地址为接收网卡上的本地地址的arp请求 2: 只响应目的IP地址为接收网卡上的本地地址的arp请求，并且arp请求的源IP必须和接收网卡同网段。 3: 如果ARP请求数据包所请求的IP地址对应的本地地址其作用域（scope）为主机（host），则不回应ARP响应数据包，如果作用域为全局（global）或链路（link），则回应ARP响应数据包 4~7: 保留未使用 8: 不回应所有的arp请求 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:6:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"图示 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址允许响应。 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址不允许响应。 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:6:1","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"4.2 arp_announce arp_announce 作用: 控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址 取值: 0：允许使用任意网卡上的IP地址作为arp请求的源IP，通常就是使用数据包a的源IP。 1：尽量避免使用不属于该发送网卡子网的本地地址作为发送arp请求的源IP地址。 2：忽略IP数据包的源IP地址，选择该发送网卡上最合适的本地地址作为arp请求的源IP地址。 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:7:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"图示 arp_announce=0 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址仍然为 lo 接口的 IP。 arp_announce=1 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址重新选择为 eth1 的IP 地址。 ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:7:1","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"4.3 修改 arp 参数 echo 1 \u003e /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 \u003e /proc/sys/net/ipv4/conf/eth1/arp_ignore echo 2 \u003e /proc/sys/net/ipv4/conf/all/arp_announce echo 2 \u003e /proc/sys/net/ipv4/conf/eth1/arp_announce ","date":"2018-10-02","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/:8:0","tags":["马哥 Linux"],"title":"24.2 LVS 4层负载均衡原理","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"24.1 架构拓展及集群介绍","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"架构拓展及集群介绍 前面我们已经介绍了，如何使用 nginx 或 httpd 部署一台 web 服务器，但是受限于单太服务器的资源，一台服务器能提供的响应能力有限。因此从本章开始，我们将从最简单 LAMP/LNMP 出发，不断向其添加组件来扩展我们的 web 服务框架，以提供更快，更稳定的服务。本章我们开始讲解第一个组件，如何使用 LVS 实现一个负载均衡集群，内容包括: web 架构拓展和集群简介 LVS 负载均衡原理 LVS 的 NAT 模型 LVS 的 DR 模型 负载均衡集群除了 LVS 之外还有多种其他实现包括 nginx，haproxy,我们会在后面详细介绍。 ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:0:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. 架构拓展 单台计算受限于本地的存储资源，计算资源等各种资源的额限制，单台服务的响应能力有限。比如我们的单台 nginx 服务最多能并发响应 2 万个用户。当并发请求数超过此限制时，我们有两种优化方式: 换一台计算能力更强的计算机，这种方式我们称之为向上扩展(scale up) 将并发请求按照特定的调度算法分散到多台计算上，这种方式称为向外扩展(scale out)，多台计算的组合就称为集群(cluster) 集群主要分为三类，此处的用于分散用户请求的集群称为负载均衡集群(Loader Balance Cluster)。分散用户请求有一个前提，每个用户请求都是独立可分离的。然后这可能会存在一些问题: 难以完全追踪用户状态，因为用户可能会被调度到不同的机器上 某用户的写操作会被单台服务器所承载，当对新上传资源的请求被调度到其他服务器，将无法获取此资源 对于第一个问题，web 服务通常使用 cookie 和 session 追踪用户，我们需要想办法让集群内的所有服务器能共享 session 信息，这样就能追踪用户状态。session 共享有三种方式: session 绑定，将来自同一用户的请求始终发送同一服务器，这种方式并没有共享 session，当服务器挂机之后 session 可能会丢失，因此需要 session 持久化。用户识别有两种方式，一是 IP，而是用户 cookie，因为 SNAT的存在 cookie 更准确 session 复制集群，每个服务器都拥有集群上所有服务器的 session 会话，因为 session 会在集群内传输，会极大的占用带宽与内存资源。 session 服务器，将 session 保存在共享的内存服务器中，每台服务器从session 服务器中获取 session。但此时 session 服务器是单点故障所在(Single Point of Failure, SPoF) 对于第二个问题，我们可以将用户写操作放到共享存储上。通常用户的数据分为三类，我们可以将其分别存放在不同存储介质中 结构化数据，通常存放在关系型数据库中 半结构化数据，通常存放在 NoSql 中，比如 mongo 非结构化数据，比如图片，我们可以存在分布式文件系统之上 用户的请求需要分散到多台服务器上，负责分散用户请求的服务器称为负载均衡器或分发器或调度器。因此我们的 web 服务框架将如下所示。调度器在分发用户请求时，有不同的调度算法，会依据不同的标准分发请求。 此时负载均衡服务器将是最大的单点故障所在，我们需要对其做冗余。我们需要提供另一台备用服务器，当负载均衡服务器迭机之后，能够取代其继续提供服务。这种提供冗余能力的服务器组合我们称为高可用集群(High Availability)。 ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:1:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2. 集群介绍 前面我们提到了两类集群，集群(Cluster) 总共可分为三类: LB：负载均衡集群 Load Balancing HA：高可用集群，High Availability,实现包括 HP：高性能集群 High Performance， HP 集群作用在于集合 CPU，以提供更高的计算能力，最典型应用就是现在的超级计算机。当前企业面临情景主要是海量数据，以及由海量数据引发的大数据计算，HP 只能提供高的计算能力，并没有拓宽计算机的存储能力，所以 HP 集群再企业中应用很少(我是这么理解的)。企业对大数据的计算是通过分布式系统进行的。 ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:2:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.1 LB 集群 LB 有多种实现，包括软件实现和硬件实现: 软件实现有: lvs, haproxy(mode tcp) (传输层) haproxy, nginx (应用层) ats(apache traffic server) 硬件实现有: F5 BIG-IP Citrix Netscaler A10 A10 Array Redware 不同实现工作不同的协议层次上,按照工作的协议层次 LB集群可以划分为 传输层: 通用，包括lvs, nginx(stream), haproxy(mode tcp) 应用层: 专用，只能应用于特定协议，包括 http: nginx(http), httd, haproxy(mode http) fastcgi: nginx, httpd mysql: ProxySQL ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:3:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.2 HA 集群 HA：高可用集群，常见实现包括 heartbeat corosync + pacemaker RHCS: cman + rgmanager cman + pacemaker keepalived HA 集群主要是提供系统稳定性，衡量系统稳定性有一个评价标准: A=MTBF/(MTBF + MTTR) MTBF: 系统可用时间 MTTR: 平均修复时间 这个计算公式就是我们通常所说的 3个9(99.9%)，4个9(99.99%). ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:4:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.3 分布式系统 分布式系统包括分布式存储和分布式计算。对于分布式存储依据存储的是海量小文件还是单个大文件，有不同的实现方式。在后面的高级部分，我们会有专门章节来详细讲解。 ","date":"2018-10-01","objectID":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/:5:0","tags":["马哥 Linux"],"title":"24.1 架构拓展及集群介绍","uri":"/posts/linux/linux_mt/27-lvs4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"23.5 nginx_http配置段(功能模块)","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"nginx_http配置段(核心模块) 本节是 nginx http 配置的第三部分。上一节我们讲解了 http_core_codule 提供的配置指令，本节我们来讲解 http 的各种功能模块提供的配置指令，内容包括: 功能模块 访问控制 开启状态页 url重写和自定义日志格式 访问日志配置 文本压缩 https 服务配置 fastcgi 配置 ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:0:0","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1. 功能模块 ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:0","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.1 访问控制 allow IP/Network; deny IP/Netword; # 作用: 基于 ip 的访问控制, all 表示所有 # 模块: ngx_http_access_module模块 auth_basic string | off; # 作用: 基于用户的访问控制 # 模块: ngx_http_auth_basic_module模块 auth_basic_user_file # 作用: 账号密码文件 # 产生: 建议使用 htppasswd 创建 location /admin/ { auth_basic \"only for adminor\"; auth_basic_user_filer /etc/nginx/user/.httppasswd; } htpasswd -c -m /path/user/.passwd tom ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:1","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.2 开启状态页 模块: ngx_http_stub_status_module 模块 location /status { stub_status on; allow 172.16.0.0/16; deny all; } stub_status {on|off}; # 作用: 是否开启状态页，用于输出nginx的基本状态信息 # 附注: 仅能用于 location 上下文 # 显示: # Active connnections: 当前所有处于打开状态的连接数 # server accept handled requests # n1 n2 n3 # - n1：已经接受的客户端请求的总数； # - n2：已经处理完成的客户端请求的总数； # - n3：客户端发来的总的请求数； # Reading: n Writing: w Waiting: t # - Reading: 处于读取客户端请求报文首部的连接的连接数； # - Writing: 处于向客户端发送响应报文过程中的连接数； # - Waiting: 处于等待客户端发出请求的空闲连接数； ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:2","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.3 url 重写与自定义日志 模块: ngx_http_rewrite_module 模块 rewrite regex replacement flag; # 作用: url 重写 # eg: rewrite ^/images/(.*\\.jpg)$ /imgs/$1 break; # flag: # last: 默认 # 一旦被当前规则匹配并重写后立即停止检查后续的其它rewrite的规则， # 然后用重写后的规则再从头开始执行 rewriter 检查； # break: # 一旦被当前规则匹配并重写后立即停止后续的其它rewrite的规则， # 而后通过重写后的规则重新发起请求 # 且不会被当前的location 内的任何 rewriter 规则所检查； # redirect: 以302临时重定向返回新的URL； # permanent: 以301永久重定向返回新的URL； # 说明: # last,break 只会发生在 nginx 内部，不会与客户端交互，客户端收到的是正常的响应 # redict, permanent 则是直接返回 30x 响应，跨站重写必需使用 redirect或permanent # 如果 last 发生死循环，nginx 会在循环 10 此之后返回 50x 响应 return code [text]; return code URL; return URL; # 作用: 停止进程并返回特定的响应给客户端，非标准的 444 将直接关闭链接，且不会发送响应 rewrite_log on | off; # 作用: 是否开启重写日志； # 示例 server { ... rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra last; return 403; ... } location / { rewriter ^/bbs/(.*)$ /forum/$1 break; rewriter ^/bbs/(.*)$ https://www.tao.com/$1 redirect; # http --\u003e https } if ($http_user_agent ~ MSIE) { rewrite ^(.*)$ /msie/$1 break; } if ($http_cookie ~* \"id=([^;]+)(?:;|$)\") { set $id $1; } if ($request_method = POST) { return 405; } if ($slow) { limit_rate 10k; } if ($invalid_referer) { return 403; } ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:3","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.4 日志配置 模块: ngx_http_log_module 模块 log_format name string ...; # 作用: string可以使用nginx核心模块及其它模块内嵌的变量； access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]]; # 作用: 访问日志文件路径，格式及相关的缓冲的配置； # buffer=size: 日志缓冲区大小 # flush=time access_log off; # 作用: 关闭记录日志功能， open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off; # 作用: 缓存各日志文件相关的元数据信息； # 参数: # max：缓存的最大文件描述符数量； # min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项； # inactive：非活动时长； # valid：验正缓存中各缓存项是否为活动项的时间间隔 ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:4","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.5 文本压缩 模块: ngx_http_gzip_module： gzip on | off; # 作用: 是否启用压缩功能 gzip_comp_level level; # 作用: 设置压缩级别，1-9 gzip_disable regex ...; # 作用: 对哪些浏览器禁用压缩 # 参数: regex 用于匹配请求报文 \"User-Agent\" 头信息 gzip_min_length length; # 作用: 启用压缩功能的响应报文大小阈值； gzip_buffers number size; # 作用: 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小； gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...; # 作用: nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的； # 选项: # off：对代理的请求不启用 # no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的 # Cache-Control的值为此三者中任何一个，则启用压缩功能； gzip_types mime-type ...; # 作用: 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能； gzip on; gzip_comp_level 6; gzip_min_length 64; gzip_proxied any; gzip_types text/xml text/css application/javascript; ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:5","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2. https 服务配置 模块: ngx_http_ssl_module模块 ssl on | off; # 作用: 是否 ssl ssl_certificate file; # 作用: 当前虚拟主机使用PEM格式的证书文件； ssl_certificate_key file; # 作用:当前虚拟主机上与其证书匹配的私钥文件； ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2]; # 作用: 支持ssl协议版本，默认为后三个； ssl_session_cache off | none | [builtin[:size]] [shared:name:size]; # 作用: 是否缓存 sll 会话 # 选项: # builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有； # [shared:name:size]：在各worker之间使用一个共享的缓存； # 说明: 如果用户请求被不同的 worker 处理时，私有缓存可能时效，因此应该使用公共缓存 ssl_session_timeout time; # 作用: 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长； server { listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; # 1m 空间大约能缓存 4000 个会话 } ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:1:6","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"3. 防盗链 模块: ngx_http_referer_module模块 valid_referers none | blocked | server_names | string ...; # 作用: 定义referer首部的合法可用值； # 参数: # none：请求报文首部没有referer首部； # blocked：请求报文的referer首部没有值； # server_names：参数，其可以有值作为主机名或主机名模式； # arbitrary_string：直接字符串，但可使用*作通配符； # regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*\\.magedu\\.com； $invalid_referer # 作用: 内置的变量，表示当前请求 referer首部是否不符合 valid_referers 定义的规则 #配置示例： valid_referers none block server_names *.magedu.com *.mageedu.com magedu.* mageedu.* ~\\.magedu\\.; if($invalid_referer) { return http://www.magedu.com/invalid.jpg; } valid_referers none blocked server_names *.example.com example.* www.example.org/galleries/ ~\\.google\\.; ","date":"2018-09-25","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/:2:0","tags":["马哥 Linux"],"title":"23.5 nginx_http配置段(功能模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"23.4 nginx_http配置段(核心模块)","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"nginx_http配置段(核心模块) 本节我们来讲解 http 配置的第二部分，http 配置段的配置。nginx 没有中心主机的概念，所以 web 服务包括默认的都是虚拟主机，直接支持基于ip，端口和主机名的虚拟主机。http 配置段用于配置 ngnix 的 web 服务器，由ngx_http_core_codule 和其他众多的 http 功能模块组成。本节我们首先来讲解 http_core_codule 提供的配置指令，内容包括 http 配置段简介 配置框架 内置变量 if 上下文 http 基础配置 虚拟主机定义 访问路径配置 索引及错误页配置 网络连接相关的设置 客户端请求的限制 文件操作的优化 客户端请求的特殊处理 内存及磁盘资源分配 ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:0:0","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1. http 配置段简介 ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:1:0","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.1 http 配置段框架 http配置段的框架如下所示，其遵循以下一些原则 必须使用虚拟机来配置站点；每个虚拟主机使用一个server {}段配置； 非虚拟主机的配置或公共配置，需要定义在server之外，http之内； 与 http 相关的指令仅能够放置于 http、server、location、upstream、if 上下文，某些指令只能用于 5 中上下文中的某一种 http { sendfile on; # 各server的公共配置 tcp_nopush on; ...： upstream { # 配置反向代理 ...... } server { # 定义一个虚拟主机；nginx支持使用基于主机名或IP的虚拟主机 # 每个 server 类似于 httpd 中的一个 \u003cvirtualHost\u003e listen; server_name; root; alias; # 类似 http 中的 \u003clocation\u003e, 用于定义URL与本地文件系统的关系 location URL { if .... { .... } } } server { } ... } ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:1:1","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.2 http核心模块的内置变量 http核心模块常用的内置变量: $uri: 当前请求的uri，不带参数； $request_uri: 请求的uri，带完整参数； $host: http请求报文中host首部； 如果请求中没有host首部，则以处理此请求的虚拟主机的主机名代替； $hostname: nginx服务运行在的主机的主机名； $remote_addr: 客户端IP $remote_port: 客户端Port $remote_user: 使用用户认证时客户端用户输入的用户名； $request_filename: 用户请求中的URI经过本地root或alias转换后映射的本地的文件路径； $request_method: 请求方法 $server_addr: 服务器地址 $server_name: 服务器名称 $server_port: 服务器端口 $server_protocol: 服务器向客户端发送响应时的协议，如http/1.1, http/1.0 $scheme: 在请求中使用scheme, 如https://www.magedu.com/中的https； $http_HEADER: 匹配请求报文中指定的HEADER， $http_host匹配请求报文中的host首部 $sent_http_HEADER: 匹配响应报文中指定的HEADER， 例如$http_content_type匹配响应报文中的content-type首部； $document_root:当前请求映射到的root配置； ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:1:2","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"1.3 if 上下文 http 配置段内的 if 上下文可以根据 nginx 内的变量执行判断逻辑 语法: if (condition) {.....} 应用: 可应用在 server, location 上下文中 condition: 基于 nginx 变量的测试表达式，支持以下几种测试方式 变量是否为空: 变量名为空串，或者以\"0\"开始，为 false，否则为 true 比较操作: = ！= 正则表达式模式匹配 ~: 区分大小写 ~*: 不区分大小写 !~ !~*: 表示取反 测试是否为文件: -f !-f 测试是否为目录: -d 测试文件存在性: -e 检查文件是否有执行权限: -x # if 使用示例 server { if ($http_user_agent ~* MSIE) { rewrite ^(.*)$ /mise/$1 break; } } ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:1:3","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2. http 服务配置 nginx 中所有路经都是 uri，nginx 会按照配置的 uri，按照当前配置文件重新查找一次，以找到匹配的文件。 ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:2:0","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.1 虚拟主机定义 server { listen 8080 default_server; server_name www.httttao.com; root \"/vhost/web/\"; } # 作用: 定义一个虚拟主机 # 特性: nginx支持使用基于主机名或IP的虚拟主机 listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILE listen address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] # 作用: 指定监听的地址和端口 # 参数: # default_server：设定为默认虚拟主机； # ssl：限制仅能够通过ssl连接提供服务； # backlog=number：后援队列长度； # rcvbuf=size：接收缓冲区大小； # sndbuf=size：发送缓冲区大小； server_name [...]; # 作用: 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串； # 过程: 当nginx收到一个请求时，会取出其首部的server的值，而后跟众server_name进行比较， # * 匹配任意长度字符串 # ~ 正则表达式模式匹配 # 主机名匹配顺序如下： # 先做精确匹配；www.magedu.com # 左侧通配符匹配；*.magedu.com # 右侧通配符匹配；www.abc.com, www.* # 正则表达式匹配: ~^.*\\.magedu\\.com\\$ server_name_hash_bucket_size 32|64|128; # 作用: 为了实现快速主机查找，nginx使用hash表来保存主机名； tcp_nodelay on|off; # 在keepalived模式下的连接是否启用TCP_NODELAY选项，建议启用； tcp_nopush on|off; # 在sendfile模式下，是否启用TCP_CORK选项，建议启用； sendfile on | off; # 是否启用sendfile功能，建议启用； ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:2:1","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.2 访问路径配置 root path # 作用: # 设置资源路径映射 # 用于指明请求的 URL 所对应的资源所在的文件系统上的起始路径 # 位置：http, server, location, if in location； alias path # 作用: 只能用于location中，定义路径别名； # 对比: # root path 用于替换 location URL 中 URL 最左侧的 \"/\" # alias path 用于替换 location URL 中 URL 最右侧的 \"/\" location /image { root '/vhost/web1'' } http://www.tao.com/images/a.jpg ---\u003e /vhost/web1/images/a.jpg location /imapge { alias \"/www/pictures\"; } http://www.tao.com/images/a.jpg ---\u003e /www/pictures/a.jpg ######################################## location [ = | ~ | ~* | ^~ ] uri { ... } location @name { ... } # 功能： # 允许根据用户请求的URI来匹配指定的各location以进行访问配置； # url被匹配到时，将被location块中的配置所处理； # 匹配类型 # =：精确匹配； # ~：正则表达式模式匹配，匹配时区分字符大小写 # ~*：正则表达式模式匹配，匹配时忽略字符大小写 # ^~: URI前半部分匹配，不检查正则表达式 # 不带符号：匹配起始于此uri的所有的url； # 匹配优先级：精确匹配(=) ^~ ~ ~* 不带任何符号的 location http { server { listen 80; server_name www.tao.comm; location / { root '/vhosts/web1'; } location /images/ { root '/vhosts/images'; } location ~* \\.php$ { fcgipass } } } ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:2:2","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.2 索引及错误页配置 index uri ...; # 作用: 定义默认页面，可参跟多个值； # 说明: 这里 uri 与 root，文件系统没有任何关系， # nginx 会按照当前配置的匹配逻辑，找到 uri 的位置 error_page code ... [=code] uri | @name; # 作用: # 错误页面重定向 # 根据 http 响应状态码来指明特用的错误页面 # [=code]: 以指明的响应吗进行响应，而是默认的原来的响应 error_page 500 502 503 504 =200 /50x.html; location = /50x.html { root html; } try_files path1 [path2 ...] uri; # 作用: # 自左至右尝试读取由path所指定路径，在第一次找到即停止并返回 # 如果所有path均不存在，则返回最后一个uri; # eg: # location ~* ^/documents/(.*)\\$ { # root /www/htdocs; # try_files \\$uri /docu/\\$1 /temp.html; # } # http://www.magedu.com/documents/a.html # http://www.magedu.com/docu/a.html # http://www.magedu.com/temp.html ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:2:3","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.3 网络连接相关的设置 keepalive_timeout time; # 保持连接的超时时长；默认为75秒； keepalive_requests n; # 在一次长连接上允许承载的最大请求数； keepalive_disable [msie6 | safari | none ] # 对指定的浏览器(User Agent)禁止使用长连接； tcp_nodelay on|off # 对keepalive连接是否使用TCP_NODELAY选项, on 表示不启用； client_header_timeout time; # 读取http请求首部的超时时长； client_body_timeout time; # 读取http请求包体的超时时长； send_timeout time; # 发送响应的超时时长； client_body_buffer_size size; # 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k； # 超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置； client_body_temp_path path [level1 [level2 [level3]]]; # 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量； client_body_temp_path /var/tmp/client_body 2 1 1 # 1：表示用一位16进制数字表示一级子目录；0-f # 2：表示用2位16进程数字表示二级子目录：00-ff # 2：表示用2位16进程数字表示三级子目录：00-ff ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:3:0","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.4 对客户端请求的限制 limit_except method ... { ... } # 指定对范围之外的其它方法的访问控制； limit_except GET { allow 172.16.0.0/16; deny all; } client_max_body_size SIZE; # http请求包体的最大值； # 常用于限定客户所能够请求的最大包体； # 根据请求首部中的Content-Length来检测，以避免无用的传输； limit_rate speed; # 限制客户端每秒钟传输的字节数；默认为0，表示没有限制； limit_rate_after time; # nginx向客户发送响应报文时，如果时长超出了此处指定的时长，则后续的发送过程开始限速； ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:3:1","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.5 文件操作的优化 sendfile on|off # 是否启用sendfile功能； aio on | off | threads[=pool]; # 是否启用aio功能； directio size | off; # 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m; open_file_cache max=N [inactive=time]|off # 作用: 是否打开文件缓存功能； # 参数： # max: 缓存条目的最大值；当满了以后将根据LRU算法进行置换； # inactive: 缓存项的非活动时长，某缓存条目在此选项指定时长内没有被访问过或 # 访问次数少于open_file_cache_min_uses指令所指定的次数，则为非活动项， # 将自动被删除；默认为60s; # 缓存信息包括： # 文件句柄、文件大小和上次修改时间； # 已经打开的目录结构； # 没有找到或没有访问权限的信息； open_file_cache_min_uses number; # 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项； open_file_cache_valid time; # 多长时间检查一次缓存中的条目是否超出非活动时长，默认为60s; open_file_cache_errors on|off # 是否缓存文件找不到或没有权限访问等相关信息； ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:3:2","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.6 客户端请求的特殊处理 ignore_invalid_headers on|off # 是否忽略不合法的http首部；默认为on; # off意味着请求首部中出现不合规的首部将拒绝响应；只能用于server和http; log_not_found on|off # 是否将文件找不到的信息也记录进错误日志中； resolver address; # 指定nginx使用的dns服务器地址； resover_timeout time; # 指定DNS解析超时时长，默认为30s; server_tokens on|off; # 是否在错误页面中显示nginx的版本号； ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:3:3","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"2.7 内存及磁盘资源分配 client_body_in_file_only on|clean|off # HTTP的包体是否存储在磁盘文件中； # 非off表示存储，即使包体大小为0也会创建一个磁盘文件； # on表示请求结束后包体文件不会被删除，clean表示会被删除； client_body_in_single_buffer on|off; # HTTP的包体是否存储在内存buffer当中；默认为off； cleint_body_buffer_size size; # nginx接收HTTP包体的内存缓冲区大小； client_body_temp_path dir-path [level1 [level2 [level3]]]; client_body_temp_path /var/tmp/client/ 1 2 # HTTP包体存放的临时目录； client_header_buffer_size size; # 正常情况下接收用户请求的http报文header部分时分配的buffer大小；默认为1k; large_client_header_buffers number size; # 存储超大Http请求首部的内存buffer大小及个数； connection_pool_size size; # nginx对于每个建立成功的tcp连接都会预先分配一个内存池， # 此处即用于设定此内存池的初始大小；默认为256； request_pool_size size; # nginx在处理每个http请求时会预先分配一个内存池，此处即用于设定此内存池的初始大小；默认为4k; ","date":"2018-09-24","objectID":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/:3:4","tags":["马哥 Linux"],"title":"23.4 nginx_http配置段(核心模块)","uri":"/posts/linux/linux_mt/26-nginx/nginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97/"},{"categories":["Linux"],"content":"23.3 nginx main 配置段","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"nginx main 配置段 nginx 配置文件有众多参数，因此我们按照配置文件的配置段分别讲解 nginx 配置。本节主要是 ngnix 核心配置段。这些参数可分为如下几个类别: 正常运行的必备配置 优化性能相关的配置 事件相关的配置 用于调试、定位问题 nginx 参数的详细配置可参阅 dirindex ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:0:0","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"1. 基础核心配置 最长需要修改的参数: worker_process worker_connections worker_cpu_affinity worker_priority ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:1:0","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"1.1 正常运行的必备配置： user username [groupname]; # 指定运行worker进程的用户和组 pid /path/to/pidfile_name; # 指定nginx的pid文件 include file | mask; # eg: include /etc/nginx/conf.d/*.conf; # 指明包含进来的其它配置文件片断,mask 表示支持通配符； load_module file; # load_module \"/usr/lib64/nginx/modules/ngx_stream_module.so\"; # 指明要装载的动态模块； ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:1:1","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"1.2 优化性能相关的配置： worker_processes n; # worker进程的个数；通常其数值应该小于或等于CPU的物理核心数； worker_processes auto; # nginx 将根据 cpu 数量自动选择 worker 进程数 worker_cpu_affinity cpumask ...; # 作用: 对 worker 进程进行 CPU 绑定，用于提升缓存命中率 只有在系统上不存在其他耗费资源的进程时才建议开启 # eg: # worker_processes 6; # worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000; worker_cpu_affinity auto; # nginx 将根据 cpu 数量自动绑定 worker_priority nice; # 作用: 指明 work 进程的 nice 值, -20,19之间的值 worker_rlimit_nofile n; # 指定所有worker进程所能够打开的最大文件句柄数； worker_rlimit_sigpending n; # 设定每个用户能够发往worker进程的信号的数量； ssl_engine device; # 在存在ssl硬件加速器的服务器上，指定所使用的ssl硬件加速设备； timer_resolution t # 作用: # 每次内核事件调用返回时，都会使用gettimeofday()来更新nginx缓存时钟； # timer_resolution用于定义每隔多久才会由gettimeofday()更新一次缓存时钟； # x86-64系统上，gettimeofday()代价已经很小，可以忽略此配置； ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:1:2","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"1.3 事件相关的配置 此配置位于 events {} 配置段内 work_connections nums # 设定单个 worker 进程能处理的最大并发连接数量, 尽可能大，以避免成为限制，eg: 51200 use [epoll|rtsig|select|poll] # 作用: 指明使用的IO模型，建议让Nginx 自动选择 accept_mutex [on|off] # 作用: 是否打开Ningx的负载均衡锁； # 功能: # 此锁能够让多个worker进轮流地、序列化地与新的客户端建立连接； # 而通常当一个worker进程的负载达到其上限的7/8，master就尽可能不再将请求调度此worker； accept_mutex_delay ms; # 作用: # accept锁模式中，一个worker进程为取得accept锁的等待时长 # 如果某worker进程在某次试图取得锁时失败了，至少要等待ms才能再一次请求锁； lock_file /path/to/lock_file; # 作用: accept_mutex 用到的lock文件路径 multi_accept on|off; # 作用: 是否允许一次性地响应多个用户请求；默认为Off; ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:1:3","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"1.4 用于调试、定位问题: 只调试nginx时使用 daemon on|off; # 作用: # 是否以守护进程让ningx运行后台；默认为on， # 调试时可以设置为off，使得所有信息去接输出控制台； master_process on|off # 作用: # 是否以master/worker模式运行nginx；默认为on； # 调试时可设置off以方便追踪； error_log path level; # 作用: # 错误日志文件及其级别；默认为error级别；调试时可以使用debug级别， # 但要求在编译时必须使用--with-debug启用debug功能； # path: stderr | syslog:server=address[,paramter=value] | memory:size # level: debug | info | notice| warn|crit| alter| emreg ","date":"2018-09-23","objectID":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/:1:4","tags":["马哥 Linux"],"title":"23.3 nginx main 配置段","uri":"/posts/linux/linux_mt/26-nginx/nginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5/"},{"categories":["Linux"],"content":"23.2 nginx基础入门","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"nginx基础入门 在学习 nginx 之前，我们首先来对 nginx 做一个入门介绍，后续我们会详细介绍 nginx web server 的配置。本节内容包括: nginx 框架 nginx 安装 nginx 配置文件格式 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. nginx 架构与特性 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 架构 ngnix 架构如上图所示: Master 进程: 作用: 主控进程负责生成和管理 Worker 进程 特性: 支持动态加载配置文件，平滑升级 Worker: 作用: 作为 web 服务，Worker 进程负责接收和处理用户请求 作为反代服务器，可通过 httpd/FastCGI 等协议向后端服务器(Backend) 转发请求 特性: 支持 http 和 https Workder 内是高度模块化的，新版本 nginx 支持部分模块动态装卸载 支持 epoll，kqueue 等高效的事件驱动的 IO 模型，一个 Worker 进程可同时响应多个用户请求，支持更高的并发链接 Cache: 作用: 支持本地缓存，Cache Loader 缓存加载，Cache manager 缓存管理 特性: 支持 AIO，senfile，mmap 拥有高效的磁盘 IO nginx 高度模块化，但其模块早期不支持DSO机制；近期版本支持动态装载和卸载.模块可分为: 核心模块: core module 标准http模块: Optional HTTP modules 可选的http模块: Standard HTTP modules 邮件模块: Mail modules 传输层代理模块:Stream modules 第三方模块 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.2 nginx 功用 nginx 可实现如下功能: 静态资源的web服务器，能缓存打开的文件描述符； http, smtp, pop3 协议的反向代理服务器 缓存、负载均衡； 支持FastCGI(fpm, LNMP), uWSGI(python) 模块化，非DSO机制，过滤器gzip，SSI和图像大小调整等 支持SSL 作为web 服务支持: 基于名称和IP做虚拟主机 支持keepalive 支持平滑配置更新或程序版本升级 定制访问日志，支持使用日志缓存以提高性能 支持url rewrite 支持路径别名 支持基于IP及用户的认证； 支持速率限制，并发限制等； ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2. nginx 安装 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:0","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.1 rpm 包安装 默认情况下 epel 仓库与 nginx 官方仓库 rpm 组织 nginx 方式有所不同。 epel 仓库 Linux 上 nginx 的 rpm 包由 epel 源提供，因此在安装 nginx 之前需要配置好 epel 的 yum 源 $ sudo vim /etc/yum.repos.d/epel.repo [epel] name=Extra Packages for Enterprise Linux 7 - $basearch baseurl=http://mirrors.aliyun.com/epel/7/$basearch http://mirrors.aliyuncs.com/epel/7/$basearch #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7\u0026arch=$basearch failovermethod=priority enabled=1 gpgcheck=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 $ sudo yum install nginx $ yum info nginx $ rpm -ql nginx nginx 官方仓库 使用 nginx 官方仓库，可以安装 nginx 最新的稳定版本，安装之前首先需要配置其 yum 源，可参考 nginx yum 源 $ sudo vim /etc/yum.repos.d/nginx.repos [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=0 enabled=1 $ sudo yum install nginx $ yum info nginx $ rpm -ql nginx ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:1","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.2 编译安装 # 1. 编译环境准备 yum grouplist yum groupinstall \"Development Tools\" yum install pcre-devel zlib-devel yum install openssl openssl-devel # 2. 编译安装 cd /usr/local tar xf nginx-1.14.0.tar.gz cd nginx-1.14.0 ./configure --help groupadd -r nginx useradd -g nginx -r nginx ./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aio make \u0026\u0026 make install mkdir -pv /var/tmp/nginx/{client,proxy,fastcgi,uwsgi} # 3. 启动 nginx /usr/local/nginx/sbin/nginx # 4. 可以仿照 rpm 安装时生成的 unit file 为编译安装创建一个服务管理脚本 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:2","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.3 nginx 主程序使用 nginx 的主程序 nginx, 位于 /usr/sbin/nginx，其使用方式如下: nginx options: 作用: 启动和管理 nginx 服务 选项: ?,-h : 显示命令帮助 v: 显示 nginx 版本 V: 显示 nginx 版本和编译参数 t: 检查配置文件 T: 检查配置文件，并显示配置文件内容 q: nginx 启动测试 s signal: 向 nginx 发送管理信号 stop, quit, reopen, reload c filename : 设置配置文件路经 (default: /etc/nginx/nginx.conf) g directives : 设置 nginx 的全局配置参数，会负载配置文件中同名参数 p prefix: set prefix path (default: /usr/share/nginx/) ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:3","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3. nginx 配置文件 # rpm -ql nginx /etc/nginx/ # 配置文件目录 /etc/nginx/nginx.conf # 主配置文件 /usr/sbin/nginx # 主程序 /usr/bin/nginx-upgrade /usr/lib/systemd/system/nginx.service # systemctl 服务管理脚本 /usr/lib64/nginx/modules # nginx 模块目录 /var/log/nginx # 默认日志存放目录 /etc/logrotate.d/nginx ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:3:0","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.1 配置文件结构 nginx 配置参数由下面四个个部分组成 ###### main 配置段 ###### main block：主配置段，也即全局配置段； event { ... }：事件驱动相关的配置； ###### http 配置段 ###### http { ... }：http/https 协议相关的配置段； ###### mail 配置段 ###### mail { ... } ###### 传输层代理段 ###### stream { ... } main配置段: 基本核心配置，包括 用于调试、定位问题 正常运行的必备配置 优化性能的配置 事件类的配置 http 配置段: 配置 nginx web server mail 配置段: 通常没什么用 ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:3:1","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.2 配置文件语法 user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; nginx 由如下语法要求: 语法格式: directive value1 [value2....]; 必需以分号结尾 支持使用变量，自定义变量可以覆盖内置变量的值 内置变量: nginx 内置变量索引 自定义变量: set $var_name value 变量引用: $variable_name ","date":"2018-09-22","objectID":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:3:2","tags":["马哥 Linux"],"title":"23.2 nginx基础入门","uri":"/posts/linux/linux_mt/26-nginx/nginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"23.1 IO模型","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"IO模型 nginx 是一个 web 服务器，同时还能作为 http 协议的反向代理服务器。相比于 http，nginx 使用了更先进的 IO 模型，异步通信以及进程间通信的技术，能支持更多的并发请求，具有更高的性能和稳定性。本章我们首先来学习如何使用 nginx 配置一个 web serve，nginx 的反向代理功能我们留在 28 章再来介绍。本章内容包括 IO 事件模型 nginx 框架与配置 nginx web 服务配置 有关 web 的基础概念和 http 协议的内容将不再此累述，大家可以回看以下几个章节: 20.1 web基础概念 20.2 http协议基础 20.3 http协议进阶 想要讲清楚 IO 模型并不容易，对于没有编程经验的来说这是一个很抽象的概念。想理解这个概念可以从以下几点入手: 我们的 web 需要同时响应多个用户请求，但是我们的程序通常是顺序执行的，一次只能响应一个用户请求 响应的内容通常位于磁盘上，而读取磁盘文件，利用网卡发送数据包都是内核提供的功能，应用程序需要发起系统调用 在系统调用返回结果之前，发起调用的应用程序通常只能等待 总结起来就是，web 程序需要同时处理多个用户请求，但是程序通常是顺序执行的，且经常经常阻塞在磁盘和网络 IO 之上。为能够为多个用户同时提供响应我们需要新的技术，这些技术目的是提高程序的 IO 效率称为 IO 模型。要想明白 IO 模型，我们首先要明白系统调用的过程。 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:0:0","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1. IO 系统调用 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:0","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1.1 IO 过程 我们以读取磁盘文件为例: 当我们需要读取文件时，首先发起 read 系统调用 此时会陷入内核，执行内核代码，将数据从磁盘读取到内核缓冲区中 将内核缓冲区中的数据从内核拷贝到应用程序内存空间 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:1","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1.1 同步/异步 同步/异步关注的是 被调用者，如何通知调用者，即被调用者与调用者之间消息通知的机制 在 IO 上就是应用程序与操作系统的交互方式 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:2","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1.2 阻塞/非阻塞 阻塞/非阻塞关注的是 调用者如何等待结果，即调用程序的执行模式 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:3","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"1.3 IO 模型类别 同步阻塞 同步非阻塞 IO复用(事件驱动IO)：select, poll，epoll: 信号驱动I/O 异步IO 参考连接: https://songlee24.github.io/2016/07/19/explanation-of-5-IO-models/ https://blog.csdn.net/wuzhengfei1112/article/details/78242004 https://blog.csdn.net/lijinqi1987/article/details/71214974 ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:4","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Linux"],"content":"2. httpd 的IO 模型 多进程模型：prefork, 一个进程响应一个用户请求，并发使用多个进程实现； 多线程模型：worker, 一个进程生成多个线程，一个线程响应一个用户请求；并发使用多个线程实现；n进程，n*m个线程； 事件模型：event, 一个线程响应多个用户请求，基于事件驱动机制来维持多个用户请求； ","date":"2018-09-21","objectID":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/:1:5","tags":["马哥 Linux"],"title":"23.1 IO模型","uri":"/posts/linux/linux_mt/26-nginx/io%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B/"},{"categories":["Python"],"content":"virtualenv 基本使用","date":"2018-06-09","objectID":"/posts/program/python/modules/virtualenv/","tags":["python 库"],"title":"virtualenv","uri":"/posts/program/python/modules/virtualenv/"},{"categories":["Python"],"content":"1. 环境创建 virtualenv dirname – 创建虚拟环境 source dirname/bin/activate – 启用虚拟环境 virtualenv 可用选项 作用 –distribute dirname 创建新的虚拟环境，并安装 pip –no-site-packages 使系统环境的包对虚拟环境不可见 ","date":"2018-06-09","objectID":"/posts/program/python/modules/virtualenv/:1:0","tags":["python 库"],"title":"virtualenv","uri":"/posts/program/python/modules/virtualenv/"},{"categories":["Python"],"content":"2.virtualenvwrapper 作用：virtualenv 管理工具，方便的创建/激活/管理/销毁虚拟环境 命令 作用 mkvirtualenv virname 新建虚拟环境 workon virname 激活 deactivate 关闭 rmvirtualenv virname 删除 ","date":"2018-06-09","objectID":"/posts/program/python/modules/virtualenv/:2:0","tags":["python 库"],"title":"virtualenv","uri":"/posts/program/python/modules/virtualenv/"},{"categories":["Python"],"content":"通过 supervisor 创建监听套接字的文件描述符，为多个 tornado 进程共享","date":"2018-06-08","objectID":"/posts/program/python/modules/supervisor_tornado/","tags":["python 库"],"title":"supervisor tornado 部署","uri":"/posts/program/python/modules/supervisor_tornado/"},{"categories":["Python"],"content":"1. tornado 启动 from tornado.netutil import set_close_exec def main(): app = AnalyticApiApplication() http_serve = httpserver.HTTPServer(app) # http_serve.listen(options.port) # supervisor 创建的监听套接字文件描述符，通过 0 号传递给 tornado的所有进程 sock = socket.fromfd(0, family=socket.AF_INET, type=socket.SOCK_STREAM) set_close_exec(sock.fileno()) sock.setblocking(0) # 设置套接字为非阻塞调用 http_serve.add_socket(sock) ioloop.IOLoop.instance().start() ","date":"2018-06-08","objectID":"/posts/program/python/modules/supervisor_tornado/:0:1","tags":["python 库"],"title":"supervisor tornado 部署","uri":"/posts/program/python/modules/supervisor_tornado/"},{"categories":["Python"],"content":"2. supervisor 配置 command=/home/tao/.local/bin/pipenv run python app.py --connect=local-dev --debug=1 socket=tcp://localhost:8888 directory=/home/tao/projects/analytics_api user=tao numprocs=4 process_name=%(program_name)s_%(process_num)02d stdout_logfile =/var/log/tornado_pyapi_stdout_%(process_num)02d.log stderr_logfile =/var/log/tornado_pyapi_stderr_%(process_num)02d.log ","date":"2018-06-08","objectID":"/posts/program/python/modules/supervisor_tornado/:0:2","tags":["python 库"],"title":"supervisor tornado 部署","uri":"/posts/program/python/modules/supervisor_tornado/"},{"categories":["Python"],"content":"3. tornado.bind_socket def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False): \"\"\"Creates listening sockets bound to the given port and address. Returns a list of socket objects (multiple sockets are returned if the given address maps to multiple IP addresses, which is most common for mixed IPv4 and IPv6 use). Address may be either an IP address or hostname. If it's a hostname, the server will listen on all IP addresses associated with the name. Address may be an empty string or None to listen on all available interfaces. Family may be set to either `socket.AF_INET` or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise both will be used if available. The ``backlog`` argument has the same meaning as for `socket.listen() \u003csocket.socket.listen\u003e`. ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``. ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket in the list. If your platform doesn't support this option ValueError will be raised. \"\"\" if reuse_port and not hasattr(socket, \"SO_REUSEPORT\"): raise ValueError(\"the platform doesn't support SO_REUSEPORT\") sockets = [] if address == \"\": address = None if not socket.has_ipv6 and family == socket.AF_UNSPEC: # Python can be compiled with --disable-ipv6, which causes # operations on AF_INET6 sockets to fail, but does not # automatically exclude those results from getaddrinfo # results. # http://bugs.python.org/issue16208 family = socket.AF_INET if flags is None: flags = socket.AI_PASSIVE bound_port = None for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags)): af, socktype, proto, canonname, sockaddr = res if (sys.platform == 'darwin' and address == 'localhost' and af == socket.AF_INET6 and sockaddr[3] != 0): # Mac OS X includes a link-local address fe80::1%lo0 in the # getaddrinfo results for 'localhost'. However, the firewall # doesn't understand that this is a local address and will # prompt for access (often repeatedly, due to an apparent # bug in its ability to remember granting access to an # application). Skip these addresses. continue try: sock = socket.socket(af, socktype, proto) except socket.error as e: if errno_from_exception(e) == errno.EAFNOSUPPORT: continue raise set_close_exec(sock.fileno()) if os.name != 'nt': sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if reuse_port: sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) if af == socket.AF_INET6: # On linux, ipv6 sockets accept ipv4 too by default, # but this makes it impossible to bind to both # 0.0.0.0 in ipv4 and :: in ipv6. On other systems, # separate sockets *must* be used to listen for both ipv4 # and ipv6. For consistency, always disable ipv4 on our # ipv6 sockets and use a separate ipv4 socket when needed. # # Python 2.x on windows doesn't have IPPROTO_IPV6. if hasattr(socket, \"IPPROTO_IPV6\"): sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1) # automatic port allocation with port=None # should bind on the same port on IPv4 and IPv6 host, requested_port = sockaddr[:2] if requested_port == 0 and bound_port is not None: sockaddr = tuple([host, bound_port] + list(sockaddr[2:])) sock.setblocking(0) sock.bind(sockaddr) bound_port = sock.getsockname()[1] sock.listen(backlog) sockets.append(sock) return sockets ","date":"2018-06-08","objectID":"/posts/program/python/modules/supervisor_tornado/:0:3","tags":["python 库"],"title":"supervisor tornado 部署","uri":"/posts/program/python/modules/supervisor_tornado/"},{"categories":["Python"],"content":"16 wrapt 模块实战","date":"2018-06-07","objectID":"/posts/program/python/modules/wrapt/python_decorator_16/","tags":["python 库"],"title":"16 wrapt 模块实战","uri":"/posts/program/python/modules/wrapt/python_decorator_16/"},{"categories":["Python"],"content":"装饰器和 wrapt 模块的介绍已经结束，作为整个系列的最后一篇的实战篇，我们来实现在一开始我提出的一个需求 ","date":"2018-06-07","objectID":"/posts/program/python/modules/wrapt/python_decorator_16/:0:0","tags":["python 库"],"title":"16 wrapt 模块实战","uri":"/posts/program/python/modules/wrapt/python_decorator_16/"},{"categories":["Python"],"content":"1. 应用场景 在我日常的开发过程中，经常要查询各种数据库，比如 mysql, mongo，es 。基本上所有的数据库对查询语句能添加的查询条件都有限制。对于大批量的查询条件，只能分批多次查询，然后将查询结果合并。我们能不能将这种查询分批在合并的操作抽象出来实现为一个装饰器，在需要时对查询函数包装即可？下面是我的一个实现示例。 ","date":"2018-06-07","objectID":"/posts/program/python/modules/wrapt/python_decorator_16/:0:1","tags":["python 库"],"title":"16 wrapt 模块实战","uri":"/posts/program/python/modules/wrapt/python_decorator_16/"},{"categories":["Python"],"content":"2. 代码实现 #!/usr/bin/python # -*- coding: utf-8 -*- \"\"\" 作用：用于优化的装饰器 功能： 1. 实现分组迭代，分批查询的装饰器 \"\"\" import os import sys import wrapt import inspect import pandas def get_slice(total_num, slice_num): \"\"\" :return: 等大小切片 \"\"\" r = [] n = total_num / slice_num m = total_num % slice_num end = 0 for i in range(1, n + 1): start = slice_num * (i - 1) end = slice_num * i r.append(slice(start, end)) else: if m \u003e 0: r.append(slice(end, end + m)) return r def slice_call(iter_param, slice_num=500): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 函数自省 param = inspect.getcallargs(wrapped, *args, **kwargs) if instance: param.pop('self') if 'kwargs' in param: kwargs = param.pop('kwargs',{}) param.update(kwargs) iter_value = param.get(iter_param) if iter_value is None: return wrapped(**param) if isinstance(iter_value, pandas.DataFrame): iter_value.reset_index(drop=True, inplace=True) # 分批 total_num = len(iter_value) slice_iter = get_slice(total_num, slice_num) result = [] # 合并 for s in slice_iter: param[iter_param] = iter_value[s] result.append(wrapped(**param)) if result: return pandas.concat(result) else: return pandas.DataFrame() return wrapper # slice_call 使用示例 @slice_call(iter_param='names') def get_video_by_name(self, names, c_type): where_name = \"'\" + \"','\".join(names) + \"'\" sql = ('select * from table' 'where a=\"%s\" and b in (%s) and c\u003e=0;' % (c_type, where_name)) print sql df = self.mysql_obj.query('', sql) df['updateTime'] = df['updateTime'].apply(lambda x: x.strftime(\"%Y-%m-%d\")) return df slice_call 函数在使用有一个限制条件，被包装函数的返回值必需是 pandas.DataFrame。因为在我日常的工作中，经常使用到 pandas 进行数据分析，对我来说，DataFrame 是一个非常通用的数据结构，因此就在此基础上构建了 slice_call 装饰器。整个实现中使用的额外知识就是函数的自省，由 inspect 模块提供，其他有关装饰器的部分都是前面博客介绍的内容，相信大家应该很容易就能看懂。 ","date":"2018-06-07","objectID":"/posts/program/python/modules/wrapt/python_decorator_16/:0:2","tags":["python 库"],"title":"16 wrapt 模块实战","uri":"/posts/program/python/modules/wrapt/python_decorator_16/"},{"categories":["Python"],"content":"结语 至此 Python 装饰器的内容就先到此为止，接下来想结合 wrapt, unittest, mock 来说一说如何在 Python 中作单元测试。 ","date":"2018-06-07","objectID":"/posts/program/python/modules/wrapt/python_decorator_16/:1:0","tags":["python 库"],"title":"16 wrapt 模块实战","uri":"/posts/program/python/modules/wrapt/python_decorator_16/"},{"categories":["Python"],"content":"15 wrapt 模块使用","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"GrahamDumpleton wrapt blog 的翻译部分到此就结束。很可惜的是作者并没有把猴子补丁部分写完，查阅了 wrapt 的官方文档，上面只介绍了 wrapt 的装饰器，代理对象以及 synchronized 同步装饰器，也没有介绍猴子补丁相关内容。不过已经介绍的内容足够用了，接下来我想结合 wrapt 的文档介绍一下 wrapt 模块的使用，算是整个博客的总结。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:0:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"1. 前文回顾 在阐述 wrapt 的使用之前，有必要对之前的内容做一个简单总结，因为 wrapt 模块的接口正是与之前的内容一一对应的。GrahamDumpleton 编码 wrapt 的本意是想实现为 Python 代码中添加猴子补丁，然而 Python 中装饰器，辅助测试的模拟库与猴子补丁的实现方式极其相似，因此 GrahamDumpleton 就按照如下的方式为将我们讲解了 wrapt 模块的功用。 如何在 Python 实现一个通用的装饰器 如何使用 wrapt 实现模拟库来辅助单元测试 如何为 Python 添加猴子补丁 装饰器，模拟库，猴子补丁的实现是递进的。装饰器通常是在导入时，在被装饰的函数定义之后立即运行，且永久全局有效；模拟库作用的范围变窄，需要实现只作用于特定范围，比如特定的测试函数中；猴子补丁更随意，通常在类创建一段时间之后再执行，这种延迟性导致猴子补丁存在相对导入的次序问题。对于我们而言搞清楚装饰器与模拟库的使用即可，能使用到猴子补丁的情景少之又少。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:1:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"装饰器 那如何实现一个装饰器？传统的通过闭包实现的装饰器存在以下问题: 无法保留函数的自省属性和签名信息，无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 为解决这些问题和解决代码复用问题，wrapt 创建了以下对象或函数: 代理对象: ObjectProxy，解决了自省问题 包装对象: FunctionWrapper, BoundFunctionWrapper 继承自 ObjectProxy，并为装饰行为实现了描述符协议 工厂函数: decorator 解决了创建装饰器的代码复用问题。 wrapt 为辅助单元测试提供了另外一个工厂函数 transient_function_wrapper，其能创建一个仅仅限于特定范围的临时补丁。 装饰器实现的核心就是包装器对象，它同时接收包装函数，和被包装函数，并作为装饰结果的返回值替换被包装函数。在被包装函数被调用时，实际调用包装函数。所以包装对象同时实现了对象代理和描述符协议。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:1:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2. wrapt 接口 # wrapt.__init__ from .wrappers import (ObjectProxy, CallableObjectProxy, FunctionWrapper, BoundFunctionWrapper, WeakFunctionProxy, resolve_path, apply_patch, wrap_object, wrap_object_attribute, function_wrapper, wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper) from .decorators import (adapter_factory, AdapterFactory, decorator, synchronized) from .importer import (register_post_import_hook, when_imported, notify_module_loaded, discover_post_import_hooks) wrapt 模块提供的接口大体上分成了以下几类: 代理对象: ObjectProxy, CallableObjectProxy, WeakFunctionProxy 包装对象: FunctionWrapper, BoundFunctionWrapper 装饰器工厂函数: function_wrapper, decorator 辅助测试的工厂函数: wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper 猴子补丁相关: .importer synchronized: java synchronized 的 Python 实现 接下来我们会详细介绍上述典型接口的使用方式。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:2:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2. 代理对象 ObjectProxy 所谓代理包含两个层面的意思: 将上层的请求传递给后端的对象 将后端对象的返回值返回给上层的调用方 wrapt 模块的底层实现就是基于透明对象代理的包装器类。这种代理对象不仅代理了普通方法和属性的访问，也代理了众多内置方法和自省属性。这使得代理对象和被代理对象在 Python 的数据模型层面是完全一致。使用代理对象去代替被代理对象不会打破 Python 的内省机制。并且我们可以在代理对象上自定义属性和方法，以此来重载被代理对象的默认功能。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2.1 对象联动 class ObjectProxy(with_metaclass(_ObjectProxyMetaType)): __slots__ = '__wrapped__' def __init__(self, wrapped): object.__setattr__(self, '__wrapped__', wrapped) ObjectProxy 是 wrapt 代理功能实现的基类，通常不直接使用，而是作为自定义代理对象的基类使用。代理对象实现了如下功能: 所有对代理对象的访问都会传递给被代理对象，包括比较操作，哈希这些 Python 的内置方法 在代理对象上自定义的方法会覆盖被代理对象同名方法，因此我们可以通过代理对象实现对被代理对象的方法重载 所有对代理对象属性的修改都会传递并修改后端的被代理对象 对后端被代理对象属性的直接修改也会直接反映在代理对象之上 也就是说默认情况下，对 ObjectProxy 的操作，方法是重载的，而对属性的修改，是直接作用在被代理对象上的。 \u003e\u003e\u003e table = {} \u003e\u003e\u003e proxy = wrapt.ObjectProxy(table) \u003e\u003e\u003e proxy['key-1'] = 'value-1' \u003e\u003e\u003e proxy['key-2'] = 'value-2' \u003e\u003e\u003e proxy.keys() ['key-2', 'key-1'] \u003e\u003e\u003e table.keys() ['key-2', 'key-1'] \u003e\u003e\u003e isinstance(proxy, dict) True ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2.2 不可变对象 上述操作对于不可变对象的自操作是特例。 \u003e\u003e\u003e value = 1 \u003e\u003e\u003e proxy = wrapt.ObjectProxy(value) \u003e\u003e\u003e type(proxy) \u003ctype 'ObjectProxy'\u003e \u003e\u003e\u003e proxy += 1 \u003e\u003e\u003e type(proxy) \u003ctype 'ObjectProxy'\u003e \u003e\u003e\u003e print(proxy) 2 \u003e\u003e\u003e print(value) 1 对于不可变对象，被代理对象保存的被代理对象的副本，因此对其自身的修改不会影响到后端的被代理对象。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:2","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2.3 类型比较 由于 Python 复杂的对象模型和底层设计，以及 instance 函数内在比较逻辑，想把 ObjectProxy 类型比较的原理说清楚实在不容易。这里就不深入见解了，简而言之 ObjectProxy 类实例的__class__ 属性返回的是被代理对象的__class__ 属性值，instance()在进行类型检查时，首先比较的是 __class__，所以对代理对象进行类型比较的结果与以被代理对象本身进行比较的结果完全一致。同时由于抽象基类机制，ObjectProxy 实例与 ObjectProxy 类的类型比较也能正常进行。 \u003e\u003e\u003e value = 1 \u003e\u003e\u003e proxy = wrapt.ObjectProxy(value) \u003e\u003e\u003e type(proxy) \u003ctype 'ObjectProxy'\u003e \u003e\u003e\u003e class CustomProxy(wrapt.ObjectProxy): ... pass \u003e\u003e\u003e proxy = CustomProxy(1) \u003e\u003e\u003e type(proxy) \u003cclass '__main__.CustomProxy'\u003e # 与被代理对象的类型比较 \u003e\u003e\u003e proxy.__class__ \u003ctype 'int'\u003e \u003e\u003e\u003e isinstance(proxy, int) True # 与代理对象的类型比较 \u003e\u003e\u003e isinstance(proxy, wrapt.ObjectProxy) True \u003e\u003e\u003e isinstance(proxy, CustomProxy) True ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:3","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2.4 方法重载 方法重载只要在自定义代理对象上自定义同名的方法即可，在代理对象内，通过 __wrapped__ 属性可以访问到原始的被代理的对象。 def function(): print('executing', function.__name__) class CallableWrapper(wrapt.ObjectProxy): def __call__(self, *args, **kwargs): print('entering', self.__wrapped__.__name__) try: return self.__wrapped__(*args, **kwargs) finally: print('exiting', self.__wrapped__.__name__) \u003e\u003e\u003e proxy = CallableWrapper(function) \u003e\u003e\u003e proxy() ('entering', 'function') ('executing', 'function') ('exiting', 'function') ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:4","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"2.5 属性重载 因为对 ObjectProxy 属性的访问都会直接代理至后端被代理对象，那如何自定义 ObjectProxy 自身的属性呢？ 方法一，任何以 _self_ 开头的属性只会保存在 ObjectProxy 上，不会传递给后端的被代理对象 def function(): print('executing', function.__name__) class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs) def wrapper(wrapped, args, kwargs): print('entering', wrapped.__name__) try: return wrapped(*args, **kwargs) finally: print('exiting', wrapped.__name__) \u003e\u003e\u003e proxy = CallableWrapper(function, wrapper) \u003e\u003e\u003e proxy._self_wrapper \u003cfunction wrapper at 0x1005961b8\u003e \u003e\u003e\u003e function._self_wrapper Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AttributeError: 'function' object has no attribute '_self_wrapper' 方法二，借助于 @property，定义属性描述符 class CustomProxy(wrapt.ObjectProxy): def __init__(self, wrapped): super(CustomProxy, self).__init__(wrapped) self._self_attribute = 1 @property def attribute(self): return self._self_attribute @attribute.setter def attribute(self, value): self._self_attribute = value @attribute.deleter def attribute(self): del self._self_attribute \u003e\u003e\u003e proxy = CustomProxy(1) \u003e\u003e\u003e print proxy.attribute 1 \u003e\u003e\u003e proxy.attribute = 2 \u003e\u003e\u003e print proxy.attribute 2 \u003e\u003e\u003e del proxy.attribute \u003e\u003e\u003e print proxy.attribute Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AttributeError: 'int' object has no attribute 'attribute' 方法三，将属性定义为类属性 \u003e\u003e\u003e class CustomProxy(ObjectProxy): ... attribute = None ... \u003e\u003e\u003e def function(): ... print('executing', function.__name__) ... \u003e\u003e\u003e j = CustomProxy(function) \u003e\u003e\u003e j.attribute = 2 \u003e\u003e\u003e \u003e\u003e\u003e function.attribute = 5 \u003e\u003e\u003e print(j.attribute) 2 \u003e\u003e\u003e print(function.attribute) 5 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:3:5","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"3. 扩展的代理对象 除了默认 ObjectProxy 代理基类，wrapt 还提供了另外两个通用的代理对象。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:4:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"3.1 CallableObjectProxy class CallableObjectProxy(ObjectProxy): def __call__(self, *args, **kwargs): return self.__wrapped__(*args, **kwargs) CallableObjectProxy 代理对象专用于代理函数，只是额外的附加了__call__方法，让代理对象成为可调用对象。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:4:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"3.2 WeakFunctionProxy # 代理有点长，不粘了，有兴趣查看 wrapt 的源码 class WeakFunctionProxy(ObjectProxy): __slots__ = ('_self_expired', '_self_instance') def __init__(self, wrapped, callback=None): 默认情况下，代理对象通过 __wrapped__ 属性保存了对被代理对像的引用，这样会导致被代理对象始终被引用而无法被垃圾处理器收回，WeakFunctionProxy 的作用就是实现在代理对象中实现对被代理对象的弱引用。在代理对象中实现弱引用并不容易，特别是对绑定方法对象的处理，以及要避免在回调函数中出现循环引用。有兴趣的同学可以看看 wrapt 的源代码。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:4:2","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"3.3 自定义代理对象 如上述两个内置扩展的代理对象，通过继承 ObjectProxy，我们也可以自定代理对象。代理对象中的方法会覆盖被代理对象的同名方法，利用这个特性我们可以重载被代理对象的行为，这在单元测试中经常使用，待会会有使用的详细示例。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:4:3","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"4. 包装对象 下面是在代理对象基础上实现包装器的简单示例，包装器继承自 wrapt.ObjectProxy，并将被代理对象作为参数传递给 ObjectProxy，从而具备了代理功能，并在此基础上附加了描述协议的处理逻辑。我们需要使用或者自定义包装对象的情景很少，此处不再对其作过多描述。 class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __get__(self, instance, owner): function = self.__wrapped__.__get__(instance, owner) return BoundCallableWrapper(function, self._self_wrapper) def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs) ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:5:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"5. 辅助测试 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:6:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"5.1 工厂函数 wrapt 中有三个辅助测试的包装对象 5. wrapt.wrap_function_wrapper: 创建猴子补丁的工厂函数，会创建永久有效的补丁 6. wrapt.patch_function_wrapper: 简化 wrapt.wrap_function_wrapper 的装饰器函数 7. wrapt.transient_function_wrapper: 创建一个仅仅限于特定范围的临时补丁 下面是它们的使用实例 def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) class Example(object): def name(self): return 'name' import wrapt # 版本一 wrapt.wrap_function_wrapper(Example, 'name', wrapper) # 等同于 wrapt.wrap_function_wrapper('example', 'Example.name', wrapper) # 版本二 @wrapt.patch_function_wrapper('example', 'Example.name') def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) # 版本三，wrapper 只对 test_method() 函数有效 @transient_function_wrapper('example', 'Example.name') def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @wrapper def test_method(): pass ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:6:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"5.2 高阶用法 除了上述简单的使用示例外，12 使用 wrapt 辅助测试 还有更高级的使用示例，下面是示例代码。 包装一个返回函数的被包装对象 from wrapt import transient_function_wrapper, function_wrapper def function(): pass class ProductionClass(object): def method(self, a, b, c, key): return function @function_wrapper def result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs)) @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 包装一个类示例的被包装对象 from wrapt import transient_function_wrapper, function_wrapper class StorageClass(object): def run(self): pass storage = StorageClass() class ProductionClass(object): def method(self, a, b, c, key): return storage @function_wrapper def run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:6:2","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"6. synchronized synchronized 装饰器实现了 java 中的同步原语 synchronized 功能。synchronized 功能和实现请参阅 07 实现 java 的 @synchronized 装饰器，下面是其使用方式 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:7:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"6.1 作为装饰器 @synchronized # lock bound to function1 def function1(): pass @synchronized # lock bound to function2 def function2(): pass @synchronized # lock bound to Class class Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:7:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"6.2 作为上下文管里器 class Class(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass class Class(object): @synchronized @classmethod def function_cm(cls): pass def function_im(self): with synchronized(Class): pass ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:7:2","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"6.3 基于任意对象作同步 除了使用默认的内置锁，synchronized 支持接收任意对象实现同步。但是作为同步而传入的对象必需能添加属性，因为 synchronized 会在传入的对象上保存创建的锁对象。因此为解除这个限制，synchronized 也支持传入支持 .require 和 .release 的类锁对象实现同步。 class Data(object): pass data = Data() def function_1(): with synchronized(data): pass def function_2(): with synchronized(data): pass # synchronized 使用到了 vars(data)，任何没有 `__dict__` 属性的对象，都会调用失败 \u003e\u003e\u003e vars({}) Traceback (most recent call last): File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File \"\u003cipython-input-3-880c6250c41c\u003e\", line 1, in \u003cmodule\u003e vars({}) TypeError: vars() argument must have __dict__ attribute ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:7:3","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"6.4 基于传入的类锁对象作同步 semaphore = threading.Semaphore(2) @synchronized(semaphore) def function(): pass 任何支持 acquire() 和 release() 对象均可作为 synchronized的参数，因此用户可传入包含这两个方法的自定义对象来实现额外的功能。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:7:4","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"7. decorator def decorator(wrapper=None, enabled=None, adapter=None): pass decorator 工厂函数是 function_wrapper 工厂函数的升级版本，在装饰器基础上添加了另外两个控制功能，enabled 和 adapter参数必需作为关键词参数被使用。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:8:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"7.1 装饰启动开关 静态控制 enabled 参数用于控制装饰器是否被启用，接收布尔值作为参数，enabled=True 时，装饰器正常启用， enabled=False 时不会应用任何包装器。因此，这提供了一种方便的方法，可以全局禁用特定的decorator，而不必删除decorator的所有用法，或者使用decorator函数的特殊变体。 ENABLED = False @wrapt.decorator(enabled=ENABLED) def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @pass_through def function(): pass \u003e\u003e\u003e type(function) \u003ctype 'function'\u003e 动态控制 在定义修饰符时为启用的选项提供一个布尔值，从而控制修饰符是否应该应用。因此，这是一个全局开关，一旦禁用，就无法在运行时在进程执行时动态地重新启用它。类似地，一旦启用，就不能禁用它。 提供布尔值的另一种方法是为enabled提供一个可调用对象 callable，该值返回一个布尔值。每次调用修饰函数时都将调用callable。如果callable返回True，表示decorator是活动的，则将调用包装器函数。如果callable返回False，包装器函数将被绕过，原始包装函数将被直接调用。 如果enabled不是None、布尔值或可调用值，则将对提供的对象执行布尔检查。这允许使用支持逻辑操作的定制对象。如果定制对象计算为False，包装器函数将再次被绕过。 def _enabled(): return True @wrapt.decorator(enabled=_enabled) def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:8:1","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"7.2 更改签名信息 默认的包装函数的签名来自被包装对象，adapter 参数的作用用于修改包装函数的签名信息。其接收一个函数作为参数，此函数的签名信息将作为包装函数的签名信息被返回。这个用的很少，就不再累述了。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:8:2","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"实战 有关 wrapt 的模块的实现和接口到此就介绍完了，在本系列博客的开篇我提到了我使用装饰器的一个典型应用场景: 对数据库查询实现分批操作。在接下来的的博客中，作为实战篇，我们来看看如何通过 wrapt 实现这个比较通用的需求。 ","date":"2018-06-06","objectID":"/posts/program/python/modules/wrapt/python_decorator_15/:9:0","tags":["python 库"],"title":"15 wrapt 模块使用","uri":"/posts/program/python/modules/wrapt/python_decorator_15/"},{"categories":["Python"],"content":"14 为 Python 应用自动打补丁","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"前面我们已经决绝了猴子补丁的导入次序问题，但是这个解决方案有个前提，就是我们必需能修改应用程序代码，以在程序的最开始执行我们的注册函数。本节我们的目的是找到另一种解决方案取消这个限制。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:0:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"1. 猴子补丁的问题所在 在之前关于猴子的文章中，我们讨论了导入次序问题。也就是说，正确使用猴子补丁取决于，我们能在任何其他代码导入我们想要修补的模块之前为其打上打补丁。换句话说就是在我们打补丁之前，其他代码是否已经按名称导入了对模块内函数的引用，并将其存储在它自己的名称空间中。即在打补丁之前，其他模块是否已经使用了 from module import function 如果我们不能尽早进入，那么就需要对目标函数的所有使用打补丁，这在一般情况下是不可能的，因为我们不知道函数在哪里被导入。我所描述的一种解决方案是使用导入后钩子机制，使我们能够在模块被任何代码导入之前访问模块并打补丁。这种技术仍然依赖于在有效运行其他代码之前安装导入后钩子机制本身。这意味着必须手动修改应用程序的主Python脚本文件，这并不总是实用的。本文的目的是研究如何避免修改主Python脚本文件来解决导入次序问题。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:1:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"2. 在 .pth 文件中执行代码 作为Python导入系统的一部分，以及在哪些目录中搜索Python模块，有一种扩展机制，即可以将一个.pth扩展名文件安装到Python的site-packages目录中。用于指明Python包代码并不在默认的Python模块搜索路径上，而是存在于其他位置，通常是在site-packages的子目录中。.pth文件的目的是充当指向Python包的实际代码的指针。 在简单的情况下，.pth文件将包含与包含Python包代码的实际目录的名称相关的或绝对的路径名。如果它是一个相对路径名，那么它将相对于.pth文件所在的目录。 如果使用 .pth，当Python 解释器初始化时，它会创建Python模块的搜索路经，在添加所有默认搜索目录后，它将查找 site-packages内的所有目录，并解析每一个 .pth 文件，并将 .pth 内的目录添加到最后的搜索目录列表中。 现在，在Python的历史中，这个.pth机制被增强了，以支持一个特殊的情况。这种特殊情况是，如果.pth文件中的一行从导入开始，那么该行将作为Python代码执行，而不是简单地将其作为目录添加到要搜索模块的目录列表中。 这最初是为了允许为模块执行特殊的启动代码，以允许为Unicode注册一个非标准的编解码器。不过，它后来也被用于easy_install的实现中，如果您曾经运行过easy-install并查看了site-packages目录中的easy-install.pth文件，您会发现以下代码: import sys; sys.__plen = len(sys.path) ./antigravity-0.1-py2.7.egg import sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new) 因此，只要能够将代码放在一行上，就可以在每次运行Python解释器时，在.pth文件中做一些非常古怪的事情。我(作者)认为可执行代码在.pth文件中的概念是非常危险的，到目前为止，我(作者)一直避免依赖.pth文件的这个特性。 我(作者)对.pth文件中的可执行代码的担心是它总是在运行。这意味着，即使您已经将预构建的RPM/DEB包或Python wheel 安装到系统中的Python安装环境中，并且认为这样做更安全，因为避免了作为根用户运行 setup.py。但是.pth文件意味着包仍然可以在您不知情的情况下运行代码，甚至不需要将模块导入任何应用程序。考虑到安全性，Python真应该有一个白名单机制，用于确定信任哪些.pth文件，以允许其在每次运行Python解释器(特别是作为根用户)时执行代码。 如果有人关心的话，我将把这个讨论留给其他人来讨论，至少现在我将展示如何使用.pth文件的这个特性(滥用)来实现对正在运行的任何Python应用程序进行自动的猴子补丁的机制。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:2:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"3. 添加导入勾子 在前一篇文章中，我们讨论的导入后钩子机制，在任何Python应用程序脚本文件的开头，我都需要手动添加如下代码: import os from wrapt import discover_post_import_hooks patches = os.environ.get('WRAPT_PATCHES') if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 它所做的是使用环境变量作为任何使用setuptools入口点注册的包的名称来源，这些入口点包含我们想要应用的猴子补丁。 了解了可以在.pth文件执行代码的能力,现在可以使用它，让这段代码在Python解释器启动时自动执行,从而避免了每次都需要手动修改每个Python应用程序，来应用我们的猴子补丁。 但是在实践中，我们需要的代码实际上要比这个稍微复杂一些，并且不能很容易地直接添加到.pth文件中，这是由于需要将所有代码写在一行上。因此，我们要做的是将所有代码放在一个单独的模块中，然后执行该模块。我们不希望每次都导入那个模块，也许用户看到它被导入时会感到害怕，即使它没有被使用，所以我们将通过环境变量的判断使用它。因此，我们可以在我们的.pth中使用的是: import os, sys; os.environ.get('AUTOWRAPT_BOOTSTRAP') and __import__('autowrapt.bootstrap') and sys.modules['autowrapt.bootstrap'].bootstrap() 也就是说，如果环境变量被设置为非空值，那么我们需要导入包含引导代码的模块并执行它。至于引导代码，这就有点麻烦了。我们不能只使用以前手动修改Python应用程序脚本文件时使用的代码。这是因为.pth文件的解析发生在Python解释器初始化。 问题有两个。第一个问题发生在执行导入钩子的发现，当.pth文件被执行时，它被处理的顺序是未知的，所以在我们的代码运行的时候，最终的Python模块搜索路径可能没有设置。第二个问题是.pth文件的处理发生在任何sitecustomize.py或usercustomize.py被处理完之前。因此，Python解释器可能不在其最终配置状态。因此，我们必须对我们所做的事情小心一点。 我们真正需要的是将任何操作延迟到Python解释器的初始化完成之后。问题是我们如何做到这一点。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:3:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"4. site 模块 Python解释器初始化的最后部分是由site 模块的main()函数完成的 def main(): global ENABLE_USER_SITE abs__file__() known_paths = removeduppaths() if ENABLE_USER_SITE is None: ENABLE_USER_SITE = check_enableusersite() known_paths = addusersitepackages(known_paths) known_paths = addsitepackages(known_paths) if sys.platform == 'os2emx': setBEGINLIBPATH() setquit() setcopyright() sethelper() aliasmbcs() setencoding() execsitecustomize() if ENABLE_USER_SITE: execusercustomize() # .pth 在此之后执行 # Remove sys.setdefaultencoding() so that users cannot change the # encoding after initialization. The test for presence is needed when # this module is run as a script, because this code is executed twice. if hasattr(sys, \"setdefaultencoding\"): del sys.setdefaultencoding 我们希望依赖的.pth解析和代码执行是在addsitepackages()函数中完成的。因此，我们真正需要的是将代码的任何执行推迟到execsitecustomize()中或execusercustomize()函数运行之后。实现这一点的方法是对这两个函数进行修改，并在它们完成时触发我们的代码。 我们需要都打上补丁，因为usercustomize.py的执行是可选的，取决于ENABLE_USER_SITE环境变量是否为真。因此，我们的bootstrap()函数应该如下 def _execsitecustomize_wrapper(wrapped): def _execsitecustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: if not site.ENABLE_USER_SITE: # 判断 _register_bootstrap_functions() return _execsitecustomize def _execusercustomize_wrapper(wrapped): def _execusercustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: _register_bootstrap_functions() return _execusercustomize def bootstrap(): site.execsitecustomize = _execsitecustomize_wrapper(site.execsitecustomize) site.execusercustomize = _execusercustomize_wrapper(site.execusercustomize) 尽管我曾经说过手工构建的猴子补丁有多糟糕，并且wrapt模块应该用于创建猴子补丁，但是在这种情况下，我们实际上不能使用wrapt模块。这是因为从技术上讲，作为用户安装的包，wrapt包此时可能不能使用。如果wrapt的安装方式是这样的，那么导入它的能力本身就依赖于.pth文件的处理。因此，我们使用一个函数闭包来使用简单的包装器。 在实际的包装器中，您可以看到两个包装器中哪个最终调用 _register_bootstrap_functions() 取决于ENABLE_USER_SITE是否为真，如果启用了对usersitecustomize()的支持，那么只能在execsitecustomize()中调用它。 最后，我们现在将_register_bootstrap_functions() 定义为: _registered = False def _register_bootstrap_functions(): global _registered if _registered: return _registered = True from wrapt import discover_post_import_hooks for name in os.environ.get('AUTOWRAPT_BOOTSTRAP', '').split(','): discover_post_import_hooks(name) ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:4:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"5. 初始化包 我们已经解决了所有问题，但是如何安装它，特别是如何安装自定义的.pth文件。为此我们使用一个设置.py文件: import sys import os from setuptools import setup from distutils.sysconfig import get_python_lib setup_kwargs = dict( name = 'autowrapt', packages = ['autowrapt'], package_dir = {'autowrapt': 'src'}, data_files = [(get_python_lib(prefix=''), ['autowrapt-init.pth'])], entry_points = {'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']}, install_requires = ['wrapt\u003e=1.10.4'], ) setup(**setup_kwargs) 为了安装.pth，我们使用了setup()调用的data_files参数。使用distutils.sysconfig模块中的get_python_lib()函数确定安装文件的实际位置。前缀“空字符串”的参数确保了Python包安装的路经为 site-packages 的相对路径，而不是绝对路径。** 安装这个包时非常重要的一点是，您不能使用easy_install或python setup.py安装。只能使用pip安装这个包。 这样做的原因是，如果不使用pip，那么包安装工具可以将包安装为egg。在这种情况下，自定义.pth文件实际上将安装在egg目录中，而不是实际安装在site-packages目录中。 .pth文件只有被添加到 site-packages 目录中，才能用于映射autowrapt包存在的子目录。从site模块调用的addsitepackages()函数并不会处理包含在.pth文件添加的目录中的.pth文件，因此我们的自定义.pth文件将被跳过。** 在使用“pip”时，默认情况下不使用eggs，所以可行。 还要注意的是，这个包不能与buildout一起工作，因为它总是将包作为eggs安装，并且在Python 安装环境中安装任何脚本时，都会显式地设置Python模块搜索路径本身。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:5:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"6. 使用示例 此软件包的实际完整源代码可在: https://github.com/GrahamDumpleton/autowrapt 这个包也在PyPi上作为autowrapt发布，因此您可以尝试它，如果您真的想使用它的话。为了方便快速地测试它是否有效，autowrapt包打包了一个示例monkey patch。在上面的setyp.py被设置如下:** entry_points = {'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']}, 这个entry point 定义了一个名为autowrapt.examples的猴子补丁。定义了当导入 this 模块时，模块autowrapt.examples中的猴子补丁函数autowrapt_this()将被执行。** 所以要运行这个测试需要: pip install autowrapt 如果没有所需的最小版本，也应该安装wrapt模块。现在正常运行命令行解释器，并在提示符处执行: import this 这应该会显示Python的Zen。退出Python解释器，现在运行: AUTOWRAPT_BOOTSTRAP=autowrapt.examples python 这将再次运行Python解释器，并将环境变量AUTOWRAPT_BOOTSTRAP设置为autowrapt.examples,以匹配在setup.py中为autowrapt定义的entry point。autowrapt_this()”函数的实际代码是: from __future__ import print_function def autowrapt_this(module): print('The wrapt package is absolutely amazing and you should use it.') 所以如果我们再一次运行: import this 我们现在应该看到Python Zen的扩展版本。在本例中，我们实际上并没有对目标模块中的任何代码打补丁，但它显示了补丁函数实际上是按预期被触发。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:6:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"7. 其他机制 虽然这种机制相当干净，并且只需要设置环境变量，但是不能像前面提到的那样与buildout一起使用。对于buildout，我们需要研究其他可以实现同样效果的方法。我将在下一篇关于这一主题的博文中讨论这些其他选择。 ","date":"2018-06-05","objectID":"/posts/program/python/modules/wrapt/python_decorator_14/:7:0","tags":["python 库"],"title":"14 为 Python 应用自动打补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_14/"},{"categories":["Python"],"content":"13 猴子补丁在 Python 中的加载次序问题","date":"2018-06-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_13/","tags":["python 库"],"title":"13 猴子补丁在 Python 中的加载次序问题","uri":"/posts/program/python/modules/wrapt/python_decorator_13/"},{"categories":["Python"],"content":"本节我们就来解决如何在 Python 中打补丁的问题。 ","date":"2018-06-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_13/:0:0","tags":["python 库"],"title":"13 猴子补丁在 Python 中的加载次序问题","uri":"/posts/program/python/modules/wrapt/python_decorator_13/"},{"categories":["Python"],"content":"1. 猴子补丁的加载次序问题 在第 11 篇博客中，我们提到了应用猴子补丁时可能存在的问题。具体地说，如果需要被打补丁的模块已经被导入并被其他代码使用，那么它可能已经在自己的名称空间中创建了一个被打补丁的目标函数的本地引用。因此，尽管猴子补丁可以正常工作，但是仍然无法覆盖这种原始函数已经导入，并过通过本地引用直接访问原始函数的情况。 导入次序问题的解决方案之一是所谓的导入钩子。这是在PEP 369中描述的一种机制，虽然它从未进入Python核心，但是仍然可以使用现有的api将这种能力移植到Python中。然后，在模块导入目标函数并在自己的名称空间中创建对函数的引用之前，我们可以添加其他功能来发现猴子补丁代码，并在导入模块时自动应用它。 ","date":"2018-06-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_13/:1:0","tags":["python 库"],"title":"13 猴子补丁在 Python 中的加载次序问题","uri":"/posts/program/python/modules/wrapt/python_decorator_13/"},{"categories":["Python"],"content":"Post import hook mechanism 暂时将 “Post import hook” 称为导入后勾子。导入后勾子机制在 PEP 369 中有一个使用示例: import imp @imp.when_imported('decimal') def register(decimal): Inexact.register(decimal.Decimal) 其基本思想是，当看到这段代码时，它将导致在Python导入系统中注册一个回调，以便在导入decimal模块时，调用装饰器应用的register()函数。register()函数的参数是对被注册的模块的引用。然后，该函数可以对模块执行一些操作，最后再将模块返回到最初请求导入的代码中。除了使用作为装饰器的@imp.where_imported函数 ，还可以显式地使用imp.register_post_import_hook() 函数来注册导入后钩子。 import imp def register(decimal): Inexact.register(decimal.Decimal) imp.register_post_import_hook(register, 'decimal') 尽管PEP 369从未被合并到Python中，但是wrapt 提供了类似功能的装饰器和函数。尽管装饰器和函数被用来解决导入次序问题。但如果目标模块在导入后钩子函数执行之前就已经被导入，我们仍会面临导入次序问题。 这个问题最简单的解决方案是修改应用程序的主Python脚本，并将您需要的所有的\"导入后勾子\"的注册设置为绝对的第一件事。也就是说，在从应用程序导入任何其他模块包括任何解析命令行参数的标准库之前注册\"导入后勾子\"。 尽管你确实可以做到这一点，但是由于注册函数会发生事实上的调用，这意味注册函数的执行可能转而导入那些将要被打补丁的模块，所以依然可能发生导入错误。 有一种间接的方式可以解决所有的问题，下面是应用这个原则的例子。方法是相对于导入猴子补丁代码，我们创建一个注册函数，只有当被补丁的模块被导入，猴子补丁才会被惰性加载，之后才会被执行。 import sys from wrapt import register_post_import_hook def load_and_execute(name): def _load_and_execute(target_module): __import__(name) patch_module = sys.modules[name] getattr(patch_module, 'apply_patch')(target_module) return _load_and_execute register_post_import_hook(load_and_execute('patch_tempfile'), 'tempfile') patch_tempfile.py代码如下: from wrapt import wrap_function_wrapper def _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs) def apply_patch(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 使用交互式解释器运行第一个脚本，以便将我们留在解释器中，然后，我们可以显示导入tempfile模块并执行mkdtemp()函数，看看会发生什么。 $ python -i lazyloader.py \u003e\u003e\u003e import tempfile patching tempfile \u003e\u003e\u003e tempfile.mkdtemp() calling mkdtemp '/var/folders/0p/4vcv19pj5d72m_bx0h40sw340000gp/T/tmpfB8r20' 上述整个导入过程是这样的: register_post_import_hook 为 tempfile 模块注册了 _load_and_execute 函数 import tempfile 时，会先执行 _load_and_execute 函数，此时会加载patch_tempfile 模块，并执行 apply_patch 函数 apply_patch 接收 tempfile 模块对象作为参数后执行，并使用 wrap_function_wrapper 函数为 mkdtemp 打上补丁。 mkdtemp 执行的就是打补丁之后的函数 整个过程，tempfile 模块被导入时，猴子补丁才被惰性加载。 换句话说，与大多数猴子补丁不同，我们并不是强行导入一个模块，以便在可能使用的基础上应用猴子补丁。相反，猴子补丁代码保持休眠和未使用，直到目标模块稍后被导入。如果没有导入目标模块，则该模块的猴子补丁代码本身甚至没有导入。 ","date":"2018-06-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_13/:1:1","tags":["python 库"],"title":"13 猴子补丁在 Python 中的加载次序问题","uri":"/posts/program/python/modules/wrapt/python_decorator_13/"},{"categories":["Python"],"content":"3. 发现导入后勾子 如上所述，导入后钩子提供了一种稍微更好的方法来设置猴子补丁，以便应用它们。这是因为只有当包含要修补的函数的目标模块被导入时，它们才会被激活。这避免了不必要地导入可能不使用的模块，否则会增加应用程序的内存使用。 导入次序仍然很重要，因此，要确保在导入任何其他模块之前设置所有导入后钩子。并且在每次更改应用的猴子补丁后，需要修改应用程序代码。如果只是为了调试问题而频繁地添加猴子补丁，则可能不太方便。 后一个问题的解决方案是将猴子补丁分离到单独的模块中，并使用一个注册机制来宣布它们的可用性。然后，Python应用程序可以在一开始就执行通用的模板代码，该代码根据提供的配置发现应该应用哪些猴子补丁。注册机制将允许在运行时发现猴子补丁模块。 这里可以使用的一种特殊的注册机制是setuptools入口点。使用这个我们可以打包猴子补丁，这样它们就可以被单独安装以备使用。这样一套方案的结构是: setup.py src/__init__.py src/tempfile_debugging.py 这个包的 setup.py 代码将会是: from setuptools import setup NAME = 'wrapt_patches.tempfile_debugging' def patch_module(module, function=None): function = function or 'patch_%s' % module.replace('.', '_') return '%s = %s:%s' % (module, NAME, function) ENTRY_POINTS = [ patch_module('tempfile'), ] setup_kwargs = dict( name = NAME, version = '0.1', packages = ['wrapt_patches'], package_dir = {'wrapt_patches': 'src'}, entry_points = { NAME: ENTRY_POINTS }, ) setup(**setup_kwargs) 作为一种约定，我们使用命名空间包，以便我们的猴子补丁模块易于识别。在本例中，父包将是wrapt_patch，因为我们专门使用wrapt。这个特定包的名称将是wrapt_patch.tempfile_debug,表示我们将创建一些猴子补丁，以帮助我们调试使用tempfile模块。 setup.py的关键部分是定义entry_points。它将被设置成程序包名到猴子补丁映射的列表，这个列表包含了这个补丁模块要作用的所有目标Python模块。此处 ENTRY_POINTS 的值为 ENTRY_POINTS = [ 'tempfile = wrapt_patches.tempfile_debugging:patch_tempfile', ] src/init.py 将包含: import pkgutil __path__ = pkgutil.extend_path(__path__, __name__) 这是创建命名空间包的要求。最后，猴子补丁实际上包含在src/tempfile_debug中。代码跟以前很像。 from wrapt import wrap_function_wrapper def _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs) def patch_tempfile(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 定义了包后，我们将它安装到正在使用的Python安装或虚拟环境中。现在，我们可以在Python应用程序主脚本文件的开头添加显式的注册，我们将添加: import os from wrapt import discover_post_import_hooks patches = os.environ.get('WRAPT_PATCHES') if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 如果我们在没有为猴子补丁特定配置的情况下运行应用程序，那么什么也不会发生。如果它们是启用的，那么它们将被自动发现并根据需要应用。 $ WRAPT_PATCHES=wrapt_patches.tempfile_debugging python -i entrypoints.py discover wrapt_patches.tempfile_debugging \u003e\u003e\u003e import tempfile patching tempfile 理想的情况是，如果PEP 369真的进入了Python的核心，那么将类似的引导机制合并到Python本身中，以便在解释器初始化过程中尽早强制对猴子补丁进行注册。有了这一点，我们就有了一种有保证的方法来解决在做猴子补丁时的导入次序问题。 由于现在PEP 369还未进入Python的核心，所以我们在本例中所做的是修改Python应用程序自己添加引导代码，以便在应用程序执行的最开始执行注册。当应用程序归自己管理时这是可以的，但是如果想要对第三方应用程序进行打补丁，并且不希望修改其代码，那该怎么办呢?在这种情况下有什么选择? 在这种情况下可以使用一些技巧。下一篇关于猴子补丁主题的博文中我们将讨论为应用程序打补丁的可用选项。 ","date":"2018-06-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_13/:2:0","tags":["python 库"],"title":"13 猴子补丁在 Python 中的加载次序问题","uri":"/posts/program/python/modules/wrapt/python_decorator_13/"},{"categories":["Python"],"content":"12 使用 wrapt 辅助测试","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"前面我们说道过 Python 中使用猴子补丁典型情景之一就是使用模拟库来帮助执行单元测试，本节我们先把补丁和模块导入的相对次序问题放一放，先来看看如何使用 wrapt 模块辅助单元测试。 ","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:0:0","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"1. 使用 wrapt 进行测试 在Python中讨论单元测试时，用于辅助该任务的比较流行的包之一是 mock 包。但是我(wrapt 的作者)觉得 mock 包不符合我的思维方式。 也可能只是我试图应用它的东西不太适合。在我想要测试的内容中，通常我不仅想要模拟更低的层，而且我想要验证传递到下一层的数据，或者修改结果。换句话说，我通常仍然需要系统作为一个整体来结束，并可能在很长一段时间内。 因此，对于我需要做的更复杂的测试，我实际上一直在依靠wrapt的猴子补丁功能。很有可能，因为我写了wrapt，我更熟悉它的范例，或者我更倾向于更明确的方式。不管怎样，至少对我来说，wrapt 能帮助我更快地完成工作。 为了进一步解释 wrapt 的猴子补丁功能，我在这篇博客文章中向大家展示了用wrapt模块实现部分 Mock 包的功能。只要记住，对于Mock模块我是一个绝对的新手，也可能也我太笨了，不能理解如何正确简单地使用它来做我想做的事情。 ","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:1:0","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"Return values and side effects 如果你正在使用Mock，并且希望在调用时临时覆盖类的方法返回的值，一种方法是: from mock import Mock, patch class ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key @patch(__name__+'.ProductionClass.method', return_value=3) def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') mock_method.assert_called_with(3, 4, 5, key='value') assert result == 3 就我迄今为止提出的wrapt包而言，一种类似的做法是: from wrapt import patch_function_wrapper class ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key @patch_function_wrapper(__name__, 'ProductionClass.method') def wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3 def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 不过，这里的一个问题是，wrapt.patch_function_wrapper()函数应用了一个永久补丁。在这个过程的生命周期中，这是可以的，但是在测试的情况下，我们通常希望一个补丁只应用于当时正在运行的单个单元测试函数。因此，补丁应该在测试结束时和调用下一个函数之前应该被删除。 对于该场景，wrapt包提供了另一个装饰器@wrapt.transient_function_wrapper。用来创建一个包装函数，该函数只应用于修饰函数所应用的特定调用的范围。因此，我们可以把上面写为: from wrapt import transient_function_wrapper class ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3 @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 尽管这个示例展示了如何临时覆盖类的方法返回的值，但更典型的情况是，我们仍然希望能够调用原始的被覆盖的函数。可能验证传入的参数或从底层返回的返回值。当我尝试用Mock解决这个问题时，我想到的一般方法如下。 from mock import Mock, patch class ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key def wrapper(wrapped): def _wrapper(self, *args, **kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(self, *args, **kwargs) return _wrapper @patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper(ProductionClass.method)) def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') 这里有两个技巧 第一个是@Mock.path 的 autospec=True参数，用于执行方法绑定 第二个是需要在对它应用任何mock之前从’ProductionClass’捕获原始方法，这样当调用mock的副作用函数时，我就可以反过来调用它。 毫无疑问，有人会告诉我，我做错了，有一种更简单的方法，但这是我在阅读模拟文档10分钟后所能想到的最好的方法。 当使用wrapt执行相同的操作时，使用的方式与模拟返回值没有什么不同。这是因为wrapt函数包装器能同时适用普通函数或方法，所以在包装方法时不需要额外处理。此外，当调用wrapt包装函数时，它总是传递被包装的原始函数，因此不需要使用任何魔法来隐藏它。 from wrapt import transient_function_wrapper class ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(*args, **kwargs) @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') 使用此功能可以轻松地拦截调用，来执行传递的数据的验证，但仍然可调用原始函数，我可以相对轻松地创建一大堆装饰器，以便对数据执行验证，因为数据可能是通过系统的不同部分传递的。然后，我可以将这些装饰器堆叠在任何需要添加它们的测试函数上。 ","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:1:1","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"2. 包装不同类型的返回值 ","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:2:0","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"返回函数 上面的示例包括能够返回一个假的返回值，返回原始值，或者在部分原始数据类型或集合上进行一些轻微的修改。但在某些情况下，我实际上希望在返回值周围放置一个包装器，以修改后续代码与返回值的交互方式。 第一个例子是包装函数返回另一个函数，这个函数将被调用链中更高的函数调用。在这里，我可能想在返回的函数周围放置一个包装器，以便在调用它时拦截它。 Mock 包的使用方式如下 from mock import Mock, patch def function(): pass class ProductionClass(object): def method(self, a, b, c, key): return function def wrapper2(wrapped): def _wrapper2(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper2 def wrapper1(wrapped): def _wrapper1(self, *args, **kwargs): func = wrapped(self, *args, **kwargs) return Mock(side_effect=wrapper2(func)) return _wrapper1 @patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper1(ProductionClass.method)) def test_method(mock_method): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: ProductionClass.method 函数返回值是另一个函数 side_effect 指定了第一层的包装函数 wrapper1，截获了ProductionClass.method 返回的 function 函数 wrapper1 将 function 包装再 wrapper2 内返回给了调用链中更高层的函数 更高层的函数调用 function 时，调用的则是 wrapper2 wrapt 包的使用方式: from wrapt import transient_function_wrapper, function_wrapper def function(): pass class ProductionClass(object): def method(self, a, b, c, key): return function @function_wrapper def result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs)) @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: apply_ProductionClass_method_wrapper 装饰了原始的 ProductionClass.method 方法 apply_ProductionClass_method_wrapper 内 wrapped(*args, **kwargs) 返回结果就是 function，其又被 result_function_wrapper 装饰 调用链中更高层的函数调用 ProductionClass.method，实际调用的是 result_function_wrapper 本例使用了一个名为@wrapt.function_wrapper的新装饰器。还可以使用@wrapt.decorator。@wrapt.function_wrapper 实际上只是@wrapt.decorator的一个简化版本，它缺少一些在做显式的猴子补丁时通常不需要的铃铛和口子，但除此之外，它也可以用同样的方式使用。因此，我可以对结果返回的函数应用一个包装器。我甚至可以应用相同的原理应用在当函数作为参数传递给另一个函数的情况。 返回类的实例 返回函数的另一个场景是返回类的实例。在这种情况下，我可能想要对类的实例的特定方法应用一个包装器。在mock 包中，需要再次使用“Mock”类，并且必须以不同的方式应用它来实现您想要的结果。现在我将不再关注mock，只关注wrapt的实现方式。 所以，根据需求，有几种方法可以用wrapt来实现。第一个方法是用封装原始方法的包装器直接替换实例上的方法 from wrapt import transient_function_wrapper, function_wrapper class StorageClass(object): def run(self): pass storage = StorageClass() class ProductionClass(object): def method(self, a, b, c, key): return storage @function_wrapper def run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage @apply_ProductionClass_method_wrapper def test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 包装过程是: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method run_method_wrapper 包装 ProductionClass.method 的返回值 storage.run 这样可以得到想要的结果，但在本例中，实际上是一种糟糕的方法。问题是返回的对象是一个在测试之外有生命时间的对象。也就是说，我们正在修改一个存储在全局范围内的对象，该对象可能用于其他测试。通过简单地替换实例上的方法，我们进行了永久性的更改。 如果它是一个仅为一次调用而按需创建的类的临时实例，那么这是可以的，但是在其他情况下不行，因为它的影响是持久的。因此，我们不能修改实例本身，需要以其他方式封装实例来拦截方法调用。 为此，我们使用了所谓的对象代理。这是一个特殊的对象类型，我们可以创建一个实例来包装另一个对象。当访问代理对象时，任何访问属性的尝试都会从包装对象返回属性。类似地，调用代理上的方法将调用包装对象上的方法。 但是，拥有一个不同的代理对象允许我们更改代理对象上的行为，从而更改代码与包装对象的交互方式。因此，我们可以避免更改原始对象本身。因此，对于这个例子，我们可以做的是: from wrapt import transient_function_wrapper, ObjectProxy class StorageClass(object): def run(self): pass storage = StorageClass() class ProductionClass(object): def method(self, a, b, c, key): return storage class StorageClassProxy(ObjectProxy): def run(self): return self.__wrapped__.run() @transient_function_wrapper(__name__, 'ProductionClass.method') def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(stor","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:2:1","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"3. 更好的使用 Mock 模块 这时你可能会说Mock做的远不止这些。你甚至可能想指出 mock 如何保存了调用的细节，这样就可以回溯，而不需要进行打点测试，这样甚至可以避免打点测试触发的异常被意外捕获的情况。 这是正确的，我们的意思是不要局限于使用基本的构建块本身，可以将多个模块结合使用，wrapt 是构建更好的模拟库进行测试的一个很好的基础。因此，我留给你们最后一个例子来让你们思考，如何使用 mock 来实现。 from wrapt import transient_function_wrapper class ProductionClass(object): def method(self, a, b, c, key): pass def patch(module, name): def _decorator(wrapped): class Wrapper(object): @transient_function_wrapper(module, name) def __call__(self, wrapped, instance, args, kwargs): self.args = args self.kwargs = kwargs return wrapped(*args, **kwargs) wrapper = Wrapper() @wrapper def _wrapper(): return wrapped(wrapper) return _wrapper return _decorator @patch(__name__, 'ProductionClass.method') def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert real.method.__name__ == 'method' assert mock_method.args == (3, 4, 5) assert mock_method.kwargs.get('key') == 'value' 这是 wrapt 包实现猴子补丁的概览。还有一些其他的东西，但这是核心部分。我使用猴子补丁将工具添加到现有代码中以支持性能监视，但是我在这里展示了如何将相同的技术用于编写代码测试，以替代Mock等包。 正如我在上一篇文章中提到的，猴子补丁的一个主要问题是模块的导入结果与打补丁完成的时间相关。我将在下一篇文章中进一步讨论这个问题。 ","date":"2018-06-03","objectID":"/posts/program/python/modules/wrapt/python_decorator_12/:3:0","tags":["python 库"],"title":"12 使用 wrapt 辅助测试","uri":"/posts/program/python/modules/wrapt/python_decorator_12/"},{"categories":["Python"],"content":"11 在 Python 中安全的使用猴子补丁","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"在之前 10 篇博客中，我们几乎完整的讨论了装饰器的实现。现在我们将焦点从装饰器转移到猴子补丁上来。 ","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/:0:0","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"1. 猴子补丁 通常在Python中永远不应该做的事情之一就是编写猴子补丁。但有些人认为这是一种有用的必需品，你可能无法避免修补第三方代码中的错误。其他人则可能会争辩说，现在有这么多的软件是开源的，所以您应该简单地向上游包维护人员提交一个补丁。 猴子补丁除了补丁还有其他用途。在Python中最常用的两种形式的猴子补丁是装饰器和使用模拟库来帮助执行单元测试，甚至你可能不把它与猴子补丁等同起来。另一个不常见的猴子补丁的例子是对现有的Python代码添加性能监视功能。 前面我们介绍了装饰器可能会导致什么问题。主要的问题就是，装饰器的实现方式可能没有保留适当的自省能力，当应用于类的方法时，它们可能也没有保留Python描述符协议的正确语义。当人们开始讨论如何修改任意代码，而不是简单地对自己的代码应用装饰器时，这两个问题就变得更加重要了，因为可能很容易地干扰现有代码的行为，或者以意想不到的方式打补丁。 典型的案例是，对一个类方法打补丁。与装饰器在类被创建时即运行不同，补丁代码运行时，类已经被创建，因此需要额外处理一些潜在问题。 我打算用这篇博文来解释wrapt包的猴补丁功能。尽管 wrapt 模块提供了创建装饰器的良好方式，但这并不是创建该包的主要目标。创建wrapt包的真正原因实际上是为猴子补丁代码实现健壮的机制。碰巧，安全执行猴子补丁所需的基本原则和机制也适用于实现装饰器。 ","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/:1:0","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"2. 创建一个装饰器 在开始修改任意代码之前，我们首先需要重新复述一下wrapt包如何用于创建装饰器。主要模式是: import wrapt import inspect @wrapt.decorator def universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) wrapt包创建装饰器的一个特性是，在装饰器中，可以确定装饰器所使用的上下文。即可以确定修饰符是被应用于类、函数或静态方法、类方法或实例方法中的哪一个。对于将装饰器应用于实例方法的情况，为类的实例提供了一个单独的参数。对于类方法，单独的参数是对类本身的引用。在这两种情况下，它们都与“args”和“kwargs”参数相分离，因此不需要自己动手提取它们。因此，我将使用wrapt创建的装饰器称为通用装饰器。换句话说，可以创建一个单独的装饰器，它可以跨函数、方法和类使用，可以在不同的调用场景中相应地调整装饰器的行为。而不再需要创建一个装饰器的多个实现，并确保在每个场景中都使用了正确的实现。 这种装饰器的使用与其他方式创建的装饰器无异。 class Example(object): @universal def name(self): return 'name' 需要注意的是 @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖 class Example(object): def name(self): return 'name' name = universal(name) 这么写仍然可行，当以这种方式编写时，它使装饰者在某种程度上成为一种猴子补丁。这是因为猴子补丁通常所做的就是在一些现有函数周围引入一个包装器，这样就可以对原始函数进行拦截。然后，包装器函数允许在调用原始函数之前或之后执行操作，或者允许修改传递给包装函数的参数，或者以某种方式修改结果，或者甚至完全替换结果。 与装饰器的一个重要区别是，装饰器在类被创建时即运行。相比之下，猴子补丁更随意，通常在类创建一段时间之后再执行。 事实上你所作的是: class Example(object): def name(self): return 'name' Example.name = universal(Example.name) 尽管使用wrapt包创建的装饰器函数可以以这种方式使用，并且仍将按预期工作，但总体而言，我不建议以这种模式给类的现有方法添加补丁。这是因为这种方式实际上并不等同于当类被定义时在类的主体内做同样的事情。特别是Example.name的访问实际上调用了描述符协议，因此返回了实例方法。我们可以通过运行代码看到这一点: class Example(object): def name(self): return 'name' print type(name) print type(Example.name) which produces: \u003ctype 'function'\u003e \u003ctype 'instancemethod'\u003e 一般来说，这可能并不重要，但我看到过一些非常奇怪的情况，它们的区别很重要。因此，为了解决这个问题，wrapt包提供了执行猴子补丁的另一种实现机制。在上面为类的方法添加包装器的情况下，使用这种机制可以避免由这种细微差别所引起的任何问题。 ","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/:2:0","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"3. 猴子补丁创建 猴子补丁的创建与装饰器创建类似，首先需要创建一个包装函数，猴子补丁的包装函数与装饰器是一样的，如下图所示 def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 不同的是不是使用装饰器工厂函数 @wrapt.decorator 创建装饰器并将其应用到被包装对象上，而是使用 wrapt.wrap_function_wrapper() 函数。 class Example(object): def name(self): return 'name' import wrapt wrapt.wrap_function_wrapper(Example, 'name', wrapper) 在这种情况下，我们将类放在同一个代码文件中，但是我们也可以这样做:** import example import wrapt wrapt.wrap_function_wrapper(example, 'Example.name', wrapper) 也就是说，我们将目标所在的模块作为第一参数，第二个参数则是我们希望应用包装器的目标方法对象的路径。我们也可以完全跳过导入模块，只使用模块的名称。 import wrapt wrapt.wrap_function_wrapper('example', 'Example.name', wrapper) 为了证明任何东西都可以被装饰器简化，我们最终可以把整个东西写成: import wrapt @wrapt.patch_function_wrapper('example', 'Example.name') def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 在这个最后的示例中，将会发生的事情是，一旦导入了包含上述代码的模块，在“示例”模块中定义的指定目标函数将自动地使用包装器函数进行修补。 ","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/:3:0","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"4. 延迟补丁问题 现在需要着重提醒的是。在上述的操作之后应用补丁并不总是有效的。 问题的核心在于，是否正在对一个已导入的模块应用补丁。如果模块没有导入，wrap .wrap_function_wrapper() 调用将确保模块被导入，但是如果模块已经被代码的其他部分或第三方包导入，那么可能就会有问题。 特别的是，您尝试打补丁的目标函数是模块的一个正常的全局函数，其他一些代码可以通过以下步骤直接获取对它的引用: from example import function 如果你后来来了 import wrapt @wrapt.patch_function_wrapper('example', 'function') def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 最后，目标模块中包含的函数的副本将应用包装器，但是其他代码创建的对它的引用将没有包装器。即在打补丁之后导入的目标函数都是被包装的，之前的都是未被包装的。 为了确保在此场景中始终使用包装器，您不仅需要在原始模块中，而且还需要在存储引用的任何模块中对其进行补丁。这只在非常有限的情况下是可行的因为在现实中，如果函数是一个普通的函数，你将不知道函数在哪里被使用。 这个问题的一个确切体现就是对gevent或eventlet等包打补丁时存在的问题。这两个包都延迟了功能的修补，因此对导入模块的顺序非常敏感。要解决这个问题，至少对于Python标准库中的模块来说，要打补丁的time.sleep()函数不仅需要在time模块中进行修补，还需要在threading模块中进行修补。 有一些技术可以用来尝试和避免这些问题，但我将把这些解释推迟到以后的一段时间。在我的下一篇博客文章中，我想介绍一些使用使用猴子补丁示例，看看如何在进行测试时使用wrapt替代 mock 模块。 ","date":"2018-06-02","objectID":"/posts/program/python/modules/wrapt/python_decorator_11/:4:0","tags":["python 库"],"title":"11 在 Python 中安全的使用猴子补丁","uri":"/posts/program/python/modules/wrapt/python_decorator_11/"},{"categories":["Python"],"content":"10 装饰类的性能","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"在上一篇文章中，我们对作为函数闭包实现的装饰器与前文描述的通用装饰器进行了性能比较。本节我们继续我们的性能测试，看看装饰一个类方法时，不同实现方式的性能表现。 ","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/:0:0","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"1. 装饰函数的性能比较 在上一篇文章中，函数闭包实现的装饰器与前文描述的通用装饰器性能测试结果如下 对于2012年的MacBook Pro，直接调用函数的测试结果是: 10000000 loops, best of 3: 0.132 usec per loop 使用函数闭包实现的装饰器的测试结果是: 1000000 loops, best of 3: 0.326 usec per loop 最受，使用装饰器工厂函数的测试结果是: 1000000 loops, best of 3: 0.771 usec per loop 上述是代理对象，和 function wrapper 对象的Python实现测试结果，如果将它们以Python C扩展实现，可以降低至: 1000000 loops, best of 3: 0.382 usec per loop 这与使用函数闭包实现的装饰器，性能相差无几。 将装饰器应用在类方法会怎样？ ","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/:1:0","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"2. 必须绑定函数的开销 将装饰器应用于类的方法的问题是，如果要遵守Python执行模型，则需要将装饰器实现为描述符，并在访问时正确地将方法绑定到类或类实例。在本系列文章中描述的装饰器中，我们正是实现了此机制，以便能够确定装饰器整被应用于与普通的函数、实例方法或类方法中的哪一个。 相比于使用函数闭包实现的装饰器不会遵守任何的Python 执行模型，这个绑定过程确保了正确的操作，但是也带来了额外的开销。为了查看发生了哪些额外的步骤，我们可以再次使用Python profile挂钩机制来跟踪修饰函数调用的执行。当前即跟踪实例方法的调用 首先，让我们来跟踪函数闭包实现的装饰器调用了哪些函数: def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapper class Class(object): @my_function_wrapper def method(self): pass instance = Class() import sys def tracer(frame, event, arg): print(frame.f_code.co_name, event) sys.setprofile(tracer) instance.method() 结果跟装饰器一个普通函数类似: _my_function_wrapper call method call method return _my_function_wrapper return 因此，我们应该预期，当我们执行实际的时间测试时，开销不会有很大的不同。现在使用我们的装饰器工厂函数。为了提供上下文，我展示了完整的代码实现 class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 我们的装饰器实现如下: @decorator def my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 装饰实例方法的测试输出结果如下: ('__get__', 'call') # function_wrapper ('__init__', 'call') # bound_function_wrapper ('__init__', 'call') # object_proxy ('__init__', 'return') ('__init__', 'return') ('__get__', 'return') ('__call__', 'call') # bound_function_wrapper ('my_function_wrapper', 'call') ('method', 'call') ('method', 'return') ('my_function_wrapper', 'return') ('__call__', 'return') 可以看到，由于方法与发生在 __get__() 中的类实例的绑定，现在发生了很多事情。因此，开销也会显著增加。 ","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/:2:0","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"3. 执行类方法的开销 与前面一样，不再使用上面的实现，而是再次使用wrapt库中的实际实现。这次我们的测试代码是: $ python -m timeit -s 'import benchmarks; c=benchmarks.Class()' 'c.method()' 没有被装饰的实例方法，直接运行的结果是: 10000000 loops, best of 3: 0.143 usec per loop 这比普通函数调用的情况要多一点，因为发生的了实例方法的绑定。 使用函数闭包实现的装饰器。测试结果如下: 1000000 loops, best of 3: 0.382 usec per loop 再一次，比未修饰的情况稍微多一点，与被应用到函数的装饰器相差无几。因此，当应用于普通函数与实例方法时，装饰器的开销并没有太大的差异。现在轮到我们的装饰器工厂函数和 function wrapper对象。首先测试Python 实现: 100000 loops, best of 3: 6.67 usec per loop 与使用函数闭包实现装饰器相比，这在运行时开销上增加了不少负担。虽然每次执行只需要额外的6个usec，但是您需要在上下文中考虑这个问题。特别是，如果在处理web请求的过程中对一个调用了1000次的函数应用了这样的装饰器，那么在该web请求的响应时间之上增加了6 ms。 在这一点上，许多人无疑会辩称，如果运行成本太高，那么正确是不值得的。但是，装饰函数和装饰器本身也不可能什么都不做，因此所产生的额外开销可能只是运行时成本的一小部分，因此在实践中并不明显。同样的，如果使用Python C扩展模块实现呢？对于作为C扩展实现的对象代理和函数包装器，结果是: 1000000 loops, best of 3: 0.836 usec per loop 所以不是6ms，而是小于1ms的额外开销如果修饰函数被调用1000次。它仍然比使用作为函数闭包实现的装饰器要多，但再次重申，在修饰类的方法时使用函数闭包不符合Python执行模型。 ","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/:3:0","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"4. 需要大费周折么 我是在吹毛求疵、过于迂腐地想把事情做好吗？当然，对于你现在所使用的装饰器，闭包实现可能工作的很好。但是当您开始使用函数包装器执行任意代码的猴子补丁时，情况就不一样了。如果你在做猴子补丁时不遵守Python的执行模型，那么你很容易以非常微妙和晦涩的方式打破第三方代码。客户可不会喜欢你破坏了他们的web应用程序。所以至少我现在所作的是很重要的。 在本文中，我只考虑了修饰类实例方法时的开销。我没有涵盖在修饰静态方法和类方法时的开销。如果您对它们的不同之处感到好奇，您可以在wrapt文档中查看完整的案例的基准。 在下一篇文章中，我将再次讨论性能开销问题，但也将讨论实现装饰器的一些替代方法，以便尝试并解决我在第一篇文章中提出的问题。这些内容将作为，对博客中描述的实现和 PyPi 模块中的实现的对比的一部分。 ","date":"2018-06-01","objectID":"/posts/program/python/modules/wrapt/python_decorator_10/:4:0","tags":["python 库"],"title":"10 装饰类的性能","uri":"/posts/program/python/modules/wrapt/python_decorator_10/"},{"categories":["Python"],"content":"09 装饰器性能比较","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"前面我们探讨了装饰器的实现方式，并实现了一个所谓的通用装饰器模式，并用它创建了一个类似 Java 的 @synchronized 装饰器作为使用示例。本节我们来看看不同的装饰器实现方式的性能问题。在这篇关于装饰器的实现性能这篇文章之后，我们将开始深入探讨如何实现代理，它是通用装饰器机制中的基础组件。 ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:0:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"1. 装饰一个普通函数 在这篇文章中，我将只讨论用装饰器修饰一个普通函数的开销。相关的装饰器代码如下: class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper ... def __get__(self, instance, owner): ... def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 如果你想回忆完整的代码，你可以去查看之前的文章，那里有完整描述。使用装饰器工厂函数，创建装饰器，并装饰器一个普通函数可以像下面这样: @decorator def my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @my_function_wrapper def function(): pass 这与使用函数闭包以更传统的方式创建的decorator不同。使用闭包创建一个函数装饰器如下所示: def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapper @my_function_wrapper def function(): pass 在我们调用函数时function()，这两种情况各自会发生什么? ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:1:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"2. 追踪函数执行 为了跟踪代码的执行，我们可以使用Python的profile hook机制。 import sys def tracer(frame, event, arg): print(frame.f_code.co_name, event) sys.setprofile(tracer) function() profile hook的目的是允许注册一个回调函数，该函数在所有函数的入口和出口调用。这样就可以追踪正在进行的函数调用的序列。对于函数闭包，输出如下: _my_function_wrapper call function call function return _my_function_wrapper return 我们在这里看到的是函数闭包的嵌套函数被调用。这是因为在使用函数闭包的情况下，装饰器将函数替换为对嵌套函数的引用。当这个嵌套函数被调用时，它将依次调用原来的包装函数。对于我们的工厂函数，输出如下: __call__ call my_function_wrapper call function call function return my_function_wrapper return __call__ return 这里的区别是，decorator 用 function wrapper 类的实例替换了函数。作为一个类，当它作为一个函数被调用时，__call__() 方法在类的实例上被调用。__call__() 方法随后调用用户提供的包装器函数，该函数反过来调用原始包装函数。 因此，结果是我们引入了额外的间接级别，或者换句话说，在执行路径中引入了额外的函数调用。记住，__call__()实际上是一个方法，而不仅仅是一个普通的函数。作为一种方法，实际上在幕后进行的工作要比普通的函数调用多得多。特别是，在调用未绑定方法之前，需要将其绑定到函数包装器类的实例。这不会出现在调用的跟踪中，但是它正在发生，并且会产生额外的开销。 ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:2:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"3. 函数执行时间 通过执行上面的跟踪，我们知道我们的解决方案会带来额外的方法调用开销。但是这会产生多少额外的开销呢？为了尝试度量每个解决方案中开销的增加，我们可以使用timeit模块来执行我们的函数调用。作为基线，我们首先需要知道在不应用任何修饰符的情况下对函数进行调用的时间开销。 # benchmarks.py def function(): pass 为记录时间，我们需要使用以下命令: $ python -m timeit -s 'import benchmarks' 'benchmarks.function()' 以这种方式使用的timeit模块时，它将执行适当的大量函数调用，将所有调用的总时间除以调用次数，最后得到单个调用的时间值。对于2012年款的MacBook Pro来说，输出如下: 10000000 loops, best of 3: 0.132 usec per loop 接下来测试函数闭包，输出如下: 1000000 loops, best of 3: 0.326 usec per loop 最后测试我们的装饰器工厂函数: 1000000 loops, best of 3: 0.771 usec per loop 在这个最后的例子中，我使用的是wrapt模块实现，而不是本系列博文中迄今为止给出的代码。这个实现的工作方式略有不同，因为它在描述的内容上有一些额外的功能，设计也有一些不同。即便是最轻量级的实现，性能开销也差不多。 ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:3:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"4. 加速包装器的执行 在这一点上毫无疑问会有人们想要指出,即使对于方法调用而言，它更加正确的实现了描述符协议，但是这所谓的的更好的方法实在是太慢，难以在实际生产环境中使用。因此，是否可以做些什么来加速实现呢? 此时可以采用的方法是将函数包装器和对象代理实现为Python C扩展模块。为了简单起见，我们可以将装饰器工厂函数本身作为纯Python代码来实现，因为工厂函数只在修饰符应用到函数时才调用，而不是修饰函数的每次调用时都会调用，因此它的时间开销并不重要。** 我绝对不会做的一件事是写博客，讨论如何将函数包装器和对象代理作为Python C扩展模块实现。不过请放心，它的工作方式与纯Python实现相同。显然，它的运行速度要快得多，因为它是使用Python C api实现的C代码，而不是纯粹的Python代码。 将函数包装器和对象代理作为Python C扩展模块实现的开销如何呢?测试如下: 1000000 loops, best of 3: 0.382 usec per loop 因此，尽管将函数包装器和对象代理作为Python C扩展模块实现需要付出更多的努力，但这些努力是值得的，结果时现在非常接近使用函数闭包的装饰器实现。 ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:4:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"4. 装饰类方法性能 到目前为止，我们只考虑了装饰一个普通函数的情况。正如预期的那样，与function wrapper作为一个类实现类似，由于引入了额外的间接层，因此开销明显更多。尽管如此，它仍然只有半微秒。 尽管如此，通过实现我们的函数包装器和对象代理作为C代码，我们还是能够将性能达到同一量级，在这里，作为函数闭包实现的装饰器工厂函数的开销可以忽略不计。 那么装饰类方法的性能如何呢。将在下一篇博客揭晓。 ","date":"2018-05-30","objectID":"/posts/program/python/modules/wrapt/python_decorator_09/:5:0","tags":["python 库"],"title":"09 装饰器性能比较","uri":"/posts/program/python/modules/wrapt/python_decorator_09/"},{"categories":["Python"],"content":"08 将 @synchronized 实现为上下文管理器","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"在前一篇文章中，我们描述了如何使用新的通用装饰器模式来实现Python的 @synchronized 同步原语装饰器。在Java提供的两个同步机制中，同步方法和同步原语，目前为止我们只实现了同步方法。本文将描述如何将其扩展为上下文管理器，从而等效的实现Java的同步原语。 ","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/:0:0","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"1. @synchronized 当前实现 到目前为止，我们的@synchronized 装饰器的实现是。 @decorator def synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 通过确定装饰器被用于包装普通函数、实例方法或类的方法中的哪一个，我们可以在许多场景中使用同一一个装饰器。 @synchronized # lock bound to function1 def function1(): pass @synchronized # lock bound to function2 def function2(): pass @synchronized # lock bound to Class class Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 我们现在想要实现的是让同步装饰器也能完成如下操作: class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，除了可以用作装饰器之外，它还能与with语句一起用作上下文管理器。通过这样做，它就能够对函数中的部分语句加锁，而不是整个函数。用作上下文管理器时，如果需要与实例方法同步，我们需要将把self参数或类实例传递给synchronized。如果需要与类方法同步，则传递类对象本身。 ","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/:1:0","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"2. 将 function_wrapper 实现为上下文管里器 在现有的synchronized实现上，当使用synchronized作为函数调用时，它将返回函数包装器类的一个实例。 \u003e\u003e\u003e synchronized(None) \u003c__main__.function_wrapper object at 0x107b7ea10\u003e 这个函数包装器没有实现作为上下文管理器的对象所需的__enter__()和__exit__()函数。函数包装器是我们自己的类，所以我们只需要创建子类并为其添加这两个方法即可。同时这个函数包装器的创建是在@decorator的定义中绑定的，所以我们需要绕过@decorator并直接使用函数包装器。因此，第一步是重写我们的 @synchronized decorator，不使用@decorator。 def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) return function_wrapper(wrapped, _synchronized_wrapper) 这与我们最初的实现相同，但是我们现在可以访问到创建函数包装器对象 function_wrapper。因此我们可以创建一个满足上下文管里器协议的 function_wrapper 的子类来替换 function_wrapper。 def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) class _synchronized_function_wrapper(function_wrapper): def __enter__(self): self._lock = _synchronized_lock(self.wrapped) self._lock.acquire() return self._lock def __exit__(self, *args): self._lock.release() return _synchronized_function_wrapper(wrapped, _synchronized_wrapper) ","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/:2:0","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"3. 两种调用方式 当 synchronized 作为装饰器使用时，新的function wrapper子类被用于包装被包装函数和方法。当函数或类方法被调用时，function wrapper 基类中的 __call__ 方法被调用。装饰器将在尝试获取锁之后执行被包装函数。 当synchronized作为上下文管里器使用时。子类将用于包装类实例或类本身。没有方法会被调用，取而代之的是在进入上下文时，__enter__() 会获取锁，离开上下文时，__exit__() 会释放锁。 与在之前的文章中形容的复杂度相比，现在的实现简单明了。 ","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/:3:0","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"4. 不只是个装饰器 希望这能说明的一点是，尽管@decorator被用来创建自定义装饰器，但这并不总是最合适的方式。function wrapper 对象的单独存在为修改被包装对象的行为提供了很大的灵活性。在某些情况下，还可以直接删除和使用对象代理。所有这些都提供了一个通用的工具集，用于进行任何类型的包装或修补，而不仅仅是用于装饰。现在，我将开始将这一系列博客文章的焦点转移到更一般的包装和猴子补丁上。 在此之前，在下一篇文章中，我将首先讨论与使用函数闭包实现装饰器的更传统方式相比，使用 function wrapper 隐含的性能影响。以及使用Python C扩展实现完整的对象代理和 function wrapper 后，性能改善的大小。 ","date":"2018-05-29","objectID":"/posts/program/python/modules/wrapt/python_decorator_08/:4:0","tags":["python 库"],"title":"08 将 @synchronized 实现为上下文管理器","uri":"/posts/program/python/modules/wrapt/python_decorator_08/"},{"categories":["Python"],"content":"07 实现 java 的 @synchronized 装饰器","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"在之前的博客中，我们讨论了装饰器的实现，并实现了一个通用装饰器模式。作为这种模式的使用示例，本节我们来实现 java 中的 @synchronized 装饰器。 ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:0:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"1. Java @synchronized 装饰器 java 的同步原语有两种形式，分别是同步方法和同步代码块。在Java 中创建同步方法，只需要在其定义时添加synchronized关键字即可。 public class SynchronizedCounter { private int c = 0; public synchronized void increment() { c++; } public synchronized void decrement() { c--; } public synchronized int value() { return c; } } 使一个方法同步意味着不可能在同一个对象上同时调用多个同步方法。当一个线程正在执行一个对象的同步方法时，所有其他调用相同对象的同步方法的线程将阻塞直至当前同步方法调用完成。 换句话说，类的每个实例都有一个内在的锁对象，并且在进入一个方法时，锁会被获取，当方法返回时它会被释放。锁是所谓的重入锁，这意味着线程可以在它持有锁的同时，再次获得它，而不会阻塞。正因为如此，一个同步的方法可以调用同一个对象上的另一个同步方法。 在Java中创建同步代码的第二种方法是同步代码块。与同步方法不同，同步代码块必须指定提供内在锁的对象。 public void addName(String name) { synchronized(this) { lastName = name; nameCount++; } nameList.add(name); } 值得注意的是，在Java中，可以使用任何对象作为锁的源，不需要创建特定锁类型的实例来同步。如果在类中需要更细粒度的锁，那么可以简单地创建或使用现有的任意对象进行同步。 public class MsLunch { private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() { synchronized(lock1) { c1++; } } public void inc2() { synchronized(lock2) { c2++; } } } 这些同步原语使用起来相对简单，因此，如何才能通过装饰器在Python中让类似操作以同样简单的方式实现呢。 ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:1:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"2.同步线程的互斥锁 在Python中，不可能使用任意对象做同步。相反必要创建一个特定的锁对象，该对象内部持有一个线程互斥锁。锁对象提供了一个 acquire()和release() 方法来操作锁。同时由于上下文管理器被引入到 Python 中，所以锁也支持与with语句一起使用。使用这个特定的特性，用于实现Python的@synchronized 装饰器的典型实现是: def synchronized(lock=None): def _decorator(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper return _decorator lock = threading.RLock() @synchronized(lock) def function(): pass 使用此方法在一段时间后变得很烦人，因为对于需要同步的每个不同的函数，必须首先创建一个线程锁。替代方法是，为每个装饰器自动创建一个线程锁。 def synchronized(wrapped): lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper @synchronized def function(): pass 我们甚至可以使用前面描述的模式，为每次调用提供一个可选的参数 def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper @synchronized def function1(): pass lock = threading.Lock() @synchronized(lock=lock) def function2(): pass 无论方法如何，基于函数闭包的装饰器都会遇到我们已经列出的所有问题。因此，我们可以采取的第一步是使用我们新的装饰器工厂函数替代它。 def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @decorator def _wrapper(wrapped, instance, args, kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper(wrapped) 因为使用了我们的装饰器工厂函数，这意味着相同的代码可以安全的应在实例、类或静态方法上。需要强调的是在类方法上使用此装饰器看似简单，但并不是很有用。因为锁仅仅对被装饰的方法有用，并且会对类的所有实例在同一方法上施加同步锁。这并不是我们想要的，也不能同java的同步方法相对应。 在次重申我们要实现的目标是，被装饰器标识为同步的所有实例方法，我们希望每个类实例都有一个独立的同步锁来实现实例内的方法同步。不同类实例之间不要同步。 过去已经有一些文章描述了如何改进这一点，包括这个很复杂的尝试。个人觉得它的实现方式是相当笨拙的，甚至怀疑它实际上不是线程安全的，因为在创建一些锁的过程中有一个竞争条件。因为它使用了函数闭包，并且没有我们的通用装饰器的概念，所以还需要创建大量不同的装饰器，然后在一个装饰器入口点上尝试将它们整合在一起。显然，我们现在应该能够做得更好。 ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:2:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"3. 将互斥锁存储在被包装对象上 解决这个问题的关键在于我们可以在哪里存储线程锁。在被包装对象调用之间存储任何数据的惟一选项将是被包装对象本身，包括被包装的函数，类实例方法和类方法。因此相对于需要传入锁，或者在函数闭包中创建锁，让我们尝试在包装器本身中的创建和管理锁。** 首先考虑一个正常函数的情况。在这种情况下，我们所能做的就是将所需的线程锁存储在包装的函数对象本身上。 @decorator def synchronized(wrapped, instance, args, kwargs): lock = vars(wrapped).get('_synchronized_lock', None) if lock is None: lock = vars(wrapped).setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs) @synchronized def function(): pass \u003e\u003e\u003e function() \u003e\u003e\u003e function._synchronized_lock \u003c_RLock owner=None count=0\u003e 我们要处理的一个关键问题是如何第一次创建线程锁。为此我们需要做的是查看线程锁是否已被创建。** lock = vars(wrapped).get('_synchronized_lock', None) 如果返回一个有效的线程锁对象，那么我们就可以继续尝试获取锁。如果锁不存在我们需要创建锁,但是我们必需小心避免竞态条件，因为当两个线程同时进入这部分代码时，它们都会判断需要第一次创建锁。我们用来解决这个问题的窍门是: lock = vars(wrapped).setdefault('_synchronized_lock', threading.RLock()) 当两个线程同时尝试创建锁时，它们都可能创建一个锁实例，但是由于使用了dict.setdefault()，只会有一个进程会成功。因为 dict.setdefault() 总是返回它第一次存储的值。所以所有的线程都会继续运行并且尝试获取相同的锁对象。其中一个线程对象会被丢弃也不存在任何问题，因为这只会在初始化并出现竞争条件时才会发生。 因此，我们已经成功地复制了最初的内容，不同之处在于线程锁存储在被包装的函数上，而不是存储在一个封闭函数的堆栈上。我们仍然有一个问题，即每个实例方法都有一个不同的锁。(而不是一个实例内的所有同步方法共用一个锁)。简单的解决方案是利用我们的通用装饰器，它提供了判断装饰器被使用的上下文的能力。 具体点说，我们需要判断当前是否在装饰一个类方法或实例方法，如果是，则将锁对象存储在 instance 参数上。 @decorator def synchronized(wrapped, instance, args, kwargs): if instance is None: context = vars(wrapped) else: context = vars(instance) lock = context.get('_synchronized_lock', None) if lock is None: lock = context.setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs) class Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): pass o1 = Object() o2 = Object() \u003e\u003e\u003e o1.method_im() \u003e\u003e\u003e o1._synchronized_lock \u003c_RLock owner=None count=0\u003e \u003e\u003e\u003e id(o1._synchronized_lock) 4386605392 \u003e\u003e\u003e o2.method_im() \u003e\u003e\u003e o2._synchronized_lock \u003c_RLock owner=None count=0\u003e \u003e\u003e\u003e id(o2._synchronized_lock) 4386605456 这个简单的改变实际上已经达到了我们想要的结果。如果同步的装饰器被用于一个正常的函数，那么线程锁将被存储在函数本身上，并且它将单独存在，并且只在调用相同的函数之间进行同步。 对于实例方法，线程锁将被存储在类的实例上，实例方法会绑定到类，因此在该类上标记为同步的任何实例方法都将在该线程锁上同步，从而模拟Java的行为 那类方法呢。在这种情况下，instance 参数实际上是类。如果线程锁被存储在类上，那么结果将是，如果有多个类方法，并且它们都被标记为synchronized，那么它们将相互排斥。这种情况下线程锁的使用方式将不同于实例方法，但这实际上也是我们想要的。 代码是否对类方法有效? \u003e\u003e\u003e Object.method_cm() Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"test.py\", line 38, in __call__ return self.wrapper(self.wrapped, instance, args, kwargs) File \"synctest.py\", line 176, in synchronized lock = context.setdefault('_synchronized_lock'), AttributeError: 'dictproxy' object has no attribute 'setdefault' 很不幸，有错。这种情况的原因是，类 __dict__ 不是一个普通的字典，而是一个 dictproxy 。一个 dictproxy 不与普通的dict共享相同的方法，特别是它不提供setdefault()方法。因此，我们需要一种不同的方法来为类创建同步线程锁。dictproxy 还导致了另一个问题，即它不支持属性设置。但是类本身支持属性设置 \u003e\u003e\u003e vars(Object)['_synchronized_lock'] = threading.RLock() Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: 'dictproxy' object does not support item assignment \u003e\u003e\u003e setattr(Object, '_synchronized_lock', threading.RLock()) \u003e\u003e\u003e Object._synchronized_lock \u003c_RLock owner=None count=0\u003e 由于函数对象和类实例都可以，所以我们需要切换更新属性的方法。 ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:3:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"4. 存储在装饰器上的元线程锁 作为dict.setdefault()第一次设置锁的原子方式的替代方法，我们可以做的是使用存储在@synchronized 装饰器本身上的元线程锁。由于元线程锁的创建仍存在竞争条件，因此需要使用dict.setdefault()实现元线程锁的原子性创建。 @decorator def synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 请注意，由于对封装函数的锁存在的检查与创建元锁之间的间隙，在我们获得了元锁之后，我们需要再次检查锁是否存在。这是为了避免两个线程同时在尝试创建锁而发生竞争条件。 这里有一点很重要，我们仅仅在更新被包装对象上的锁时使用了属性访问方法。而在查找被包装对象上是否存在锁时，没有使用getattr()方法，而是继续在vars()返回的__dict__中查找它。这是必要的，因为当在类的实例上使用getattr()时，如果该属性在类的实例中不存在，那么查找规则意味着如果该属性在类本身上存在，那么将返回该属性。 如果一个同步的类方法是第一个被调用的，这会导致问题，因为它会在类本身上留下一个锁。当随后调用实例方法时，如果使用了getattr()，它会找到类类型的锁并返回它，并且会被错误地使用。因此，我们继续通过 __dict__ 寻找锁，因为它只包含实例中实际存在的内容。 有了这些修改，所有锁的创建都可以自动完成，并在不同的上下文中创建一个适当的锁。 @synchronized def function(): pass class Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): pass o = Object() \u003e\u003e\u003e function() \u003e\u003e\u003e id(function._synchronized_lock) 4338158480 \u003e\u003e\u003e Object.method_cm() \u003e\u003e\u003e id(Object._synchronized_lock) 4338904656 \u003e\u003e\u003e o.method_im() \u003e\u003e\u003e id(o._synchronized_lock) 4338904592 代码也适用于在静态方法或类中使用@synchronized。综上所述，@synchronized 可以被应用的场景如下: @synchronized # lock bound to function1 def function1(): pass @synchronized # lock bound to function2 def function2(): pass @synchronized # lock bound to Class class Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:4:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"5. 实现同步代码块 所以，我们已经完成了对同步方法的支持，如何实现同步代码块呢。要实现的目标是能按照下面的方式编写代码: class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，我们需要 synchronized 装饰器不仅可以用作装饰器，而且还可以作为上下文管理器使用。在synchronized作为上下文管理器时，类似于Java，需要提供给它执行同步操作的对象，对于实例方法而言，这个对象是 self 参数或者类的实例。为了解释我们如何做到这一点，需要等待下一篇文章。 ","date":"2018-05-26","objectID":"/posts/program/python/modules/wrapt/python_decorator_07/:5:0","tags":["python 库"],"title":"07 实现 java 的 @synchronized 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_07/"},{"categories":["Python"],"content":"06 装饰器的类实现","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"上一篇文章中，我们讨论了如何实现一个带参数的装饰器，以及如何让装饰器可选的接收参数而不是必需输入参数。也讨论了如何让装饰器能在被包装函数的不同调用之间保持状态。保持状态的一种可用方法是使用类实现装饰器。然而我们实现的通用装饰器模式在使用类实现装饰器还存在一些问题，本文我们将来探讨问题出现的根源以及如何解决。 ","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/:0:0","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"1. 装饰器工厂函数 正如前文所述，我们通过类实现装饰器的模式如下 class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @with_arguments(arg=1) def function(): pass 当我们这么做时，装饰器在被应用时发生了如下错误: Traceback (most recent call last): File \"test.py\", line 483, in \u003cmodule\u003e @with_arguments(1) TypeError: _decorator() takes exactly 1 argument (2 given) _decorator() 是我们装饰器工厂函数的内部函数。 def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 错误的原因是我们使用函数闭包实现装饰器工厂函数，却希望它能同时工作在普通函数和类方法上。当类方法被访问时，将触发描述符协议，绑定将会发生；类实例的引用将自动作为第一个参数传递给类方法。而 _decorator() 却没有被定义成同时接收 self和wrapped 作为参数，所以调用失败。我们可以创建一个仅用于类实例的装饰器工厂函数。但是这与我们之前要为类方法和函数创建统一的装饰器的初衷相违背。 解决问题的方法是，使用我们的 function_wrapper 作为装饰器工厂的返回对象，而不是函数闭包。 def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): return function_wrapper(wrapped, wrapper) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @with_arguments(arg=1) def function(): pass 这种方式特别巧妙，但是很不容易理解，我们再来看看整个调用的发生过程 with_arguments(arg=1) 带参数的装饰器被使用时，将创建一个类实例 ins 在 @decorator 装饰下, ins 的 __call__ 方法此时是 function_wrapper(__call__, _wrapper) 对象 @ 将 function 对象作为参数传递给创建的类实例，将调用 ins.__call__(function) 方法，此时将触发function_wrapper的描述符协议，并进一步调用 _wrapper(__call__, ins) 函数，functions 对象则通过 arg 传递给 _execute 函数，_execute 执行返回新的 function_wrapper(functions, __call__) 对象 装饰的最终结果是，我们现在不必担心 @decorator 被应用在普通函数，实例方法还是一个类方法上。因为在所有的情况下，被绑定的实例对象不会通过 args 被传递 细心的读者很快就会发现另一个问题，在 __call__ 在被调用时，需要传入装饰器类的实例即 self 参数，而在上述的实现中并没有此步骤。(不过我没懂为什么作者在 _wrapper 内多嵌套一层_execute函数，应该是想说名这是要被执行的部分。) ","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/:1:0","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"2. 类的绑定要求 更改之后，重新进行测试，我们遇到了一个新的问题。这次发生在被被包装函数被调用的时候。 \u003e\u003e\u003e function() Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"test.py\", line 243, in __call__ return self.wrapper(self.wrapped, None, args, kwargs) TypeError: __call__() takes exactly 5 arguments (4 given) 现在这个问题是__call__()方法传递给@decorator发生在 类初始化，此时它是未绑定方法，任何类实例远还没被创建。通常情况下，类实例的引用在方法被绑定时被提供，但是因为我们的装饰器实际是一个工厂函数，因此这里涉及到了两层绑定。外部包装函数的类实例被传递给工厂函数内部的 _wrapper 函数的instance参数。但是它在 function wrapper 对象被创建的时候，完全没有被使用。为了解决这个问题，我们需要根据是否绑定了一个实例方法，显示使用类实例绑定我们的包装函数 def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 在这个示例中，有三种情况需要我们处理。 第一种情况是 instance 为 None。这对应于decorator函数被应用在普通函数，类静态方法或一个类上 第二种情况是 instance 不为 None，但是是一个类对象。这对应用于一个类方法。这种情况下，我们需要通过包装函数的__get__()将包装函数显示绑定到一个类对象。 第三种即最后一种情况下，instance 不是None，也不是一个类对象。这对应于实例方法。在这种情况我们仍然需要绑定包装函数，只不过这次绑定的是类实例。 ","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/:2:0","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"3. 总结 改进之后，我们解决了所有问题，而且很大程度上完善了我们的装饰器模式。所以，目前我们的通用装饰器解决方案如下: class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 尽管在之前的文章中提到过。这里给出的对象代理实现并不是一个完美实现。因此，不要使用这段代码。如果你使用了，就会发现。在被包装函数上的部分内省操作不会按照我们所预期的执行。特别的，访问函数的__doc__属性总是返回 None。类似Python3中的新增变量 __qualname__ 和 __module__ 也不能正确显示。 正确处理像__doc__这样的内置属性是比较费劲的，因为内置属性的获取逻辑与普通属性有时候并不相同。上述实现中我们期望的是，无论从代理对象还是代理对象的子类，我们都是从被包装函数获取并返回属性值，但是对于__doc__属性，即便是代理对象的子类没有__doc__属性，它也同样会覆盖父类的__doc__，结果是代理对象的子类拦截了对 __doc__ 属性的获取。所以这里展示的代理对象仅仅是一个参照实现。 大体上说，这里所有的代码都仅仅是参照实现。目的不是使用而是展示如何实现一个更加通用的装饰器。它只是提供给你一个学习的途径。不要期望通过简单的几行代码就能实现，事情不会那么简单。 ","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/:3:0","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"4. wrapt 模块 如果我告诉你不要使用这里的代码，那你应该怎么做呢？答案是在PyPi上已经有现成的 wrapt 模块。wrapt 模块已经上线几个月了，但是目前为止并没有广为人知。它实现了这里描述的所有细节，甚至更多。这个模块实现了一个完整的代理对象，能使所有代码正确执行。并且提供了很多和装饰器工厂函数相关的特性，也提供了很多和猴子补丁相关的特性。 虽然我指出了wrapt 模块的存在，但是博客内容不会就此停止，因为我还有其他一些主题想要阐述。这些内容包括通用装饰器的应用，启用和关闭装饰器，装饰器执行性能问题，以及代理对象，猴子补丁的实现问题等等。 接下来的博客，我将举一个通用装饰器应用的特殊示例，来说明Python 装饰器如此强大，为什么Pyhton不提供一个@synchronized装饰器。在装饰器第一次被引入编程语言时，这个装饰器被当作是如何使用装饰器的经典示例。然而我能找到的所有实现都是半成品，很少在现实世界中被使用。我相信这里的通用装饰器能帮助我们实现一个可用的@synchronized装饰器。我将在下一篇博客中详述它。 ","date":"2018-05-25","objectID":"/posts/program/python/modules/wrapt/python_decorator_06/:4:0","tags":["python 库"],"title":"06 装饰器的类实现","uri":"/posts/program/python/modules/wrapt/python_decorator_06/"},{"categories":["Python"],"content":"05 带参数的装饰器","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"在之前的博客，通过使用代理对象，装饰器工厂函数等技术，我们已经实现了一个通用装饰器。在这篇文章中，我们将使用前面文章中描述的装饰器工厂函数，介绍如何使用它来实现接受参数的装饰器，包括强制参数和可选的接收参数。 ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:0:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"1. 装饰器创建模式 前面文章中描述的关键组件是一个函数包装器对象。我不打算复制代码，所以请参阅前面的帖子。简而言之，它是一个类类型，它接受要被包装的函数和一个用户提供的包装器函数。所得到的函数包装器对象的实例被用来代替被包装函数，当调用时，会将被包装函数的调用委托给用户提供的包装器函数。这允许用户修改调用的方式，在调用被包装函数之前或之后执行操作，或者修改输入参数或结果。function_wrapper 和装饰器工厂一起使用创建装饰器的方式如下:** # 装饰器工厂函数 def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator # 使用工厂函数创建的装饰器 @decorator def my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) print('KWARGS', kwargs) return wrapped(*args, **kwargs) # 应用装饰器包装函数 @my_function_wrapper def function(a, b): pass 在本例中，创建的最终装饰器不接受任何参数，但如果我们希望装饰器能够接受参数，在调用用户提供的包装器函数时可访问传入的参数，那么我们该如何做呢？ ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:1:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"2. 使用函数闭包收集参数 最简单的实现一个能接收参数的装饰器的方式是使用函数闭包 def with_arguments(arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper @with_arguments(arg=1) def function(): pass 实际上，外部函数本身是一个工厂函数，可根据传入的参数，返回不同的装饰器实例。因此，当外部工厂函数被应用到一个具有特定参数的函数时，它返回内部装饰器函数，实际上它是应用于被包装的函数。当包装器函数最终被调用时，它会调用被包装函数，并通过作为函数闭包的一部分来访问传递给外部工厂函数的原始参数。** 位置或关键字参数可以与外部装饰器工厂函数一起使用，但是我认为关键字参数可能是一个更好的惯例，我稍后会展示。现在，如果带有参数的装饰器具有默认值，使用这种方法来实现装饰器，即使不传递参数，也必需将其作为一个不同的调用来使用。也就是说，仍然需要提供空括号。 def with_arguments(arg='default'): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper @with_arguments() def function(): pass 尽管这只是一个特例，但看起来不优雅。大多数更喜欢当所有参数都是可选，并没有被显示传递参数时，括号时可选的。换句话说，当没有参数被传递时，可以被写成 @with_arguments def function(): pass 当我们从另一个角度看问题时，这个想法实际上是有价值的。如果一个装饰器最初不接收参数，但是之后又需要可选的接收参数。如果括号是可选的，那么原来不带参数调用装饰器的代码也无需改变。 ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:2:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"3. 带可选参数的装饰器 允许装饰器添加可选参数，可以将上面的方法更改为: def optional_arguments(wrapped=None, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped) @optional_arguments(arg=2) def function1(): pass @optional_arguments def function2(): pass 当具有默认的可选参数时，外部工厂函数将被包装函数作为第一个参数并默认为 None。第一次调用时，被包装函数是 None，通过 partical 函数再一次返回装饰器工厂函数。第二次调用，被包装函数将被传入并被装饰器包装。 将装饰器被直接装饰函数时，因为默认参数的存在，我们不需要显示传递参数。因为 wrapped 惨数值不是None，装饰器直接返回工厂函数，直接装饰函数。 此时工厂函数的参数必需是关键词参数，Python 3允许您使用新的关键字参数语法来强制使用关键词参数。 def optional_arguments(wrapped=None, *, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped) 这样，就可以避免有人不小心将装饰器参数作为位置参数传递给 wrapped。对于一致性，关键字参数也可以被强制执行，即使它不是必需的。 def required_arguments(*, arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:3:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"4. 在调用之间保持状态 某些时候，装饰器可能需要在函数调用之间保持状态。一个典型的例子是缓存装饰器。此时，由于包装器函数本身没有任何状态收集器，所以只能借助于装饰器能够访问到的外部数据结构作为状态收集器进行状态保持。 有几种方法可以做到这一点。 第一个是将保持状态的对象作为显式参数传递给装饰器 def cache(d): @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = wrapped(*args, **kwargs) return result return _wrapper _d = {} @cache(_d) def function(): return time.time() 除非有特定的需要能够传入状态对象，否则第二个更好的方法是在外部函数的调用中创建状态对象。 def cache(wrapped): d = {} @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped) @cache def function(): return time.time() 这种情况下，外部包装函数在函数内部自定状态对象，而不是通过参数显示传递。如果这是一个合理的默认值，但是在某些情况下，仍然需要将状态对象作为参数传递进来，那么可以使用可选的装饰数参数。 def cache(wrapped=None, d=None): if wrapped is None: return functools.partial(cache, d=d) if d is None: d = {} @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped) @cache def function1(): return time.time() _d = {} @cache(d=_d) def function2(): return time.time() @cache(d=_d) def function3(): return time.time() ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:4:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"5. 使用类创建装饰器 在第一篇文章中，我们说过可以使用类实现装饰器。 class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 就像之前已经阐述的，这种通过类实现的装饰器存在缺陷，但是作为一种替代模式，这种原始的方法也能保持状态。具体地说，类的构造函数可以将状态对象连同被包装函数保存为类实例的属性。 class cache(object): def __init__(self, wrapped): self.wrapped = wrapped self.d = {} def __call__(self, *args, **kwargs): try: key = (args, frozenset(kwargs.items())) return self.d[key] except KeyError: result = self.d[key] = self.wrapped(*args, **kwargs) return result @cache def function(): return time.time() 在装饰器逻辑特别复杂时，这种通过类实现的装饰器也存在一些好处。可以拆分封装在不同的类方法中。那么使用我们的新函数包装器和装饰器工厂，能否将装饰器实现为类呢？一种可能的方式是这样: class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @with_arguments(arg=1) def function(): pass 装饰器执行逻辑是这样的，当带参数的装饰器被使用时，将创建一个类实例。在被包装函数被调用时，将调用 @decorator 装饰的实例方法 __call__()，__call__()进而调用被包装函数。因为__call__()是实例的绑定方法，所以能够访问到类实例拥有的状态对象。 那么事实上是否能正常运行呢？ Traceback (most recent call last): File \"test.py\", line 483, in \u003cmodule\u003e @with_arguments(1) TypeError: _decorator() takes exactly 1 argument (2 given) 理想很丰满，显示很骨干。失败的原因就在于装饰器工厂函数的实现方式，我们将在下一篇文章种解释并解决这个特别的问题。 def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 作为另一种一种替代方式是，仍然使用类封装所需的逻辑，并在函数闭包类创建实例供包装函数使用。装饰器将功能委托给类实例，但是本身不作为类实现。这种方式需要额外创建一个类，使用起来并不优雅。 ","date":"2018-05-24","objectID":"/posts/program/python/modules/wrapt/python_decorator_05/:5:0","tags":["python 库"],"title":"05 带参数的装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_05/"},{"categories":["Python"],"content":"04 实现一个通用装饰器","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"本节我们将实现一个\"通用装饰器\"，它能够让用户提供的包装函数通过传入的参数判断其被使用的上下文，即确定，它是被应用在函数，实例方法，类方法，类对象中的哪一个。因为装饰器不是在各个环境种被单独实现，而是以一种更加统一的方式创建，所以将这种能确定上下文的装饰器称为通用装饰器。 ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:0:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"1. 内容回顾 到目前为止，我们创建装饰器的方式已经经过了几次迭代: 第一篇博客中我们介绍使用函数创建装饰器的传统方式，这种方式存在几个重大问题 为解决函数创建装饰器的问题，我们在第二篇博客中使用了代理对象，并将装饰器实现成了描述符，这种方式有效的解决了之前的问题，但是存在大量的样板代码 为了提高创建装饰器的效率，第三篇博客中我们使用了装饰器工厂函数，抽象了装饰器的创建过程，用户只需提供一个执行所需的包装函数即可。我们的目的是实现一个通用装饰器，能够让用户的包装函数通过传入参数确定其被使用的上下文。 # 包装函数通过传入参数确定其被使用的上下文 @decorator def universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 目前为止我们已经能够区分装饰器是被用于普通函数和还是实例方法，但是当通过类调用类方法和静态方法时将出现问题。本文我们将继续探索如何调整我们的装饰器工厂函数，以区分类方法和静态方法，以便找到实现通用装饰器的模式 ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:1:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"2. 区分普通函数和实例方法 目前为止，我们的通用装饰器模式实现如下: class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) # 装饰器工厂函数 def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 为了测试当前的模式能在任何情况下都能工作，我们需要使用装饰器工厂创建一个装饰器，它能在执行时打印绑定的 instance 对象，以及传递进来的参数。 @decorator def my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) 当装饰器被应用到一个正常的函数和实例方法时，包括通过显式传入实例调用实例方法时，我们能够得到符合预期的结果 @my_function_wrapper def function(a, b): pass \u003e\u003e\u003e function(1, 2) INSTANCE None ARGS (1, 2) class Class(object): @my_function_wrapper def function_im(self, a, b): pass c = Class() \u003e\u003e\u003e c.function_im(1, 2) INSTANCE \u003c__main__.Class object at 0x1085ca9d0\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_im(c, 1, 2) INSTANCE \u003c__main__.Class object at 0x1085ca9d0\u003e ARGS (1, 2) 但是当装饰起被应用到类方法以及静态方法时，参数传递发生了错误。instance 按预期要么为空，要么接收的是类实例或类对象，现在却是传递给函数的第一个实参。并不符合我们通用装饰器的要求 。 class Class(object): @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): pass \u003e\u003e\u003e Class.function_cm(1, 2) INSTANCE 1 ARGS (2,) \u003e\u003e\u003e Class.function_sm(1, 2) INSTANCE 1 ARGS (2,) ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:2:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"3. 区分类方法和静态方法 因此，我们要指出的是，在实例被传递为None的情况下，我们需要能够区分这三种情况: 通过类直接调用实例方法 类方法被调用 静态方法被调用 一种判断方法是查看绑定函数的__self__属性。该属性保存了函数在特定时间点绑定到的对象类型信息。我们先来看看通过类调用不同方法时，此属性的值。 \u003e\u003e\u003e print(Class.function_im.__self__) None \u003e\u003e\u003e print(Class.function_cm.__self__) \u003cclass '__main__.Class'\u003e \u003e\u003e\u003e print(Class.function_sm.__self__) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"test.py\", line 19, in __getattr__ return getattr(self.wrapped, name) AttributeError: 'function' object has no attribute '__self__' 通过类调用实例方法的情况，__self__ 值为 None，对于类方法，它将是类对象，在静态方法的情况下，不存在 __self__ 属性。似乎检查 __self__ 是一个有效的判断方法 在我们编写一个基于此的解决方案之前，我们先检查一下Python 3，以确保我们在那里没问题，并且没有任何变化。 \u003e\u003e\u003e print(Class.function_im.__self__) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"dectest.py\", line 19, in __getattr__ return getattr(self.wrapped, name) AttributeError: 'function' object has no attribute '__self__' \u003e\u003e\u003e print(Class.function_cm.__self__) \u003cclass '__main__.Class'\u003e \u003e\u003e\u003e print(Class.function_sm.__self__) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"test.py\", line 19, in __getattr__ return getattr(self.wrapped, name) AttributeError: 'function' object has no attribute '__self__' Python 3 与 Python 2 表现并不相同，此方法无效。但是为什么会出现这种情况？发生这种情况的原因是，Pyhton3 已经没有未绑定对象这个对象，通过类直接调用实例方法时返回的也是函数。而Python2中通过类调用实例的返回值类型依赖于 __self__ 是否为None，所以Python3中删除了此属性。因此，我们现在不能区分通过类调用实例方法和调用静态方法这两种情况。 另一个方法是在 function_wrapper 构造函数内，检查被包装对象的类型，并确定它是类方法还是静态方法。然后，将判定信息传递到 bound function wrapper 并进行进一步检查。 class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function' and self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 如果有人实际上在他们的decorator中实现了描述符协议，那么希望他们也可以在这里使用对象代理。因为对象代理拥有__class__属性，它将返回被包装对象的类，这意味着isinstance()检查仍然会成功，因为isinstance()会优先考虑__class__的返回结果，而不是对象的实际类型。 无论如何，更改后，我们重新测试如下 \u003e\u003e\u003e c.function_im(1,2) INSTANCE \u003c__main__.Class object at 0x101f973d0\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_im(c, 1, 2) INSTANCE \u003c__main__.Class object at 0x101f973d0\u003e ARGS (1, 2) \u003e\u003e\u003e c.function_cm(1,2) INSTANCE \u003c__main__.Class object at 0x101f973d0\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_cm(1, 2) INSTANCE None ARGS (1, 2) \u003e\u003e\u003e c.function_sm(1,2) INSTANCE \u003c__main__.Class object at 0x101f973d0\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_sm(1, 2) INSTANCE None ARGS (1, 2) 成功，我们已经修复了调用类方法和静态方法时参数列表问题。现在的问题是，虽然对通过实例调用方法时， instance 参数没有问题。但是无论是通过实例还是类，传递给类方法和静态方法的 instance 参数都没有什么用。并且我们不能将它同其他情形区别开。理想情况下，我们希望调用类方法时 instance 参数始终为类对象，而调用静态方法时，则使用为 None。因此 对于静态方法，我们只需要在检查被包装类型时，判断 ‘staticmethod’ 即可 对于类方法的情况，如果我们回头看一下我们的测试，看看是否可以使用__self__属性，我们发现，对于类方法，__self__是类实例，对于静态方法，属性不存在。因此，我们可以做的是，如果包装对象的类型不是一个函数，那么我们可以查找__self__的值，如果它不存在的话，就会默认为None。这将满足这两种情况。进一步改进后如下 class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function': # 通过类调用的实例方法 if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.par","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:3:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"4. 多层绑定 还有一个我们还没有考虑到的特殊情况，即为方法创建别名，并通过别名调用时。 \u003e\u003e\u003e Class.function_rm = Class.function_im \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE 1 ARGS (2,) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"test.py\", line 132, in __call__ return self.wrapper(wrapped, instance, args, kwargs) File \"test.py\", line 58, in my_function_wrapper return wrapped(*args, **kwargs) TypeError: unbound method function_im() must be called with Class instance as first argument (got int instance instead) \u003e\u003e\u003e Class.function_rm = Class.function_cm \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE \u003cclass '__main__.Class'\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_rm = Class.function_sm \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE None ARGS (1, 2) 对于类方法或静态方法来说，一切都很好，但是对于实例方法来说却失败了。这里的问题是由于在第一次访问实例方法时，它将返回绑定的bound_function wrapper对象。然后把它作为类的属性分配回来。当通过新名称进行后续查找时，在正常情况下，绑定将再次发生，以将其绑定到实际实例。在我们的绑定函数包装器的实现中，我们不提供__get__()方法，因此不会发生这种重新绑定。结果是，在随后的调用中，它全部崩溃。 Class.function_rm = Class.function_im 设置别名时，发生第一次描述符协议，function_rm 绑定得是 bound_function_wrapper 对象，第二次通过别名调用实例方法时会发生第二次描述符协议，进行第二次绑定。 因此，解决方案是我们需要向 bound_function_wrapper 添加__get__()方法，为其提供了执行进一步绑定的能力。我们只希望在实例为None的地方执行这个操作，这表明我们处理的是实例方法，而不是类方法或静态方法。 (注: Class.function_rm = Class.function_im 第一次绑定时，self.binding 为 function，并且由于时通过类直接调用实例方法，因此 instance 参数是 None。包装普通函数时也符合此类情况，但是不会触发描述符协议，只有通过实例调用发生第二次绑定时，才会调用bound_function_wrapper 的__get__方法) 另一个问题是，我们需要绑定的是原始的被包装函数，而不是绑定后的包装函数。最简单的处理方法是将对原始函数包装器 function_wrapper 的引用传递给绑定的函数包装器bound_function_wrapper，并通过它获得原始的被包装函数。 class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent # 目的是获取原始的被包装函数 def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): # 仅在通过类调用实例方法时才会发生第二次绑定 if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) # instance 是第二次绑定传入的实例对象 return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 再次运行测试得到如下所示 \u003e\u003e\u003e Class.function_rm = Class.function_im \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE \u003c__main__.Class object at 0x105609790\u003e ARGS (1, 2) # 不会发生二次绑定 \u003e\u003e\u003e Class.function_rm = Class.function_cm \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE \u003cclass '__main__.Class'\u003e ARGS (1, 2) # 不会发生二次绑定 \u003e\u003e\u003e Class.function_rm = Class.function_sm \u003e\u003e\u003e c.function_rm(1, 2) INSTANCE None ARGS (1, 2) ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:4:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"5. 装饰器应用顺序 目前为止，我们的装饰器一直被放置在将方法标记为类方法或静态方法的装饰器之外。如果我们颠倒顺序会怎样？ class Class(object): @classmethod @my_function_wrapper def function_cm(self, a, b): pass @staticmethod @my_function_wrapper def function_sm(a, b): pass c = Class() \u003e\u003e\u003e c.function_cm(1,2) INSTANCE None ARGS (\u003cclass '__main__.Class'\u003e, 1, 2) \u003e\u003e\u003e Class.function_cm(1, 2) INSTANCE None ARGS (\u003cclass '__main__.Class'\u003e, 1, 2) \u003e\u003e\u003e c.function_sm(1,2) INSTANCE None ARGS (1, 2) \u003e\u003e\u003e Class.function_sm(1, 2) INSTANCE None ARGS (1, 2) 静态方法按预期运行，但是类方法不行。在这个特殊的例子中，它实际上可以被看作是Python本身的一个bug。具体地说，classmethod 装饰器本身并不能对它包装的所有对象都遵守描述符协议。这也是为什么当使用闭包实现装饰器会发生错误的原因。如果classmethod 装饰器能正常工作，一起都是OK 的。对于那些对细节感兴趣的人，您可以在Python bug跟踪器中查看19072。 ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:5:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"6. 装饰器一个类 除了与类方法的装饰器顺序之外，我们实现的通用装饰器的模式看起来很好。我在上一篇文章中提到过，我们的目标是，我们也可以区分什么时候装饰器被应用到一个类中。所以让我们试试 @my_function_wrapper class Class(object): pass \u003e\u003e\u003e c = Class() INSTANCE None ARGS () 基于此，我们无法将其与普通函数或类方法区分开来。如果我们再考虑一下，在这个例子中传递给包装器函数的包装对象将是类本身。让我们输出传递给用户包装函数的 wrapped参数，看看是否能区分出这种情景 @decorator def my_function_wrapper(wrapped, instance, args, kwargs): print('WRAPPED', wrapped) print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) @my_function_wrapper def function(a, b): pass \u003e\u003e\u003e function(1, 2) WRAPPED \u003cfunction function at 0x10e13bb18\u003e INSTANCE None ARGS (1, 2) class Class(object): @my_function_wrapper def function_im(self, a, b): pass @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): pass c = Class() \u003e\u003e\u003e c.function_im(1,2) WRAPPED \u003cbound method Class.function_im of \u003c__main__.Class object at 0x107e90950\u003e\u003e INSTANCE \u003c__main__.Class object at 0x107e90950\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_im(c, 1, 2) WRAPPED \u003cfunctools.partial object at 0x107df3208\u003e INSTANCE \u003c__main__.Class object at 0x107e90950\u003e ARGS (1, 2) \u003e\u003e\u003e c.function_cm(1,2) WRAPPED \u003cbound method type.function_cm of \u003cclass '__main__.Class'\u003e\u003e INSTANCE \u003cclass '__main__.Class'\u003e ARGS (1, 2) \u003e\u003e\u003e Class.function_cm(1, 2) WRAPPED \u003cbound method type.function_cm of \u003cclass '__main__.Class'\u003e\u003e INSTANCE \u003cclass '__main__.Class'\u003e ARGS (1, 2) \u003e\u003e\u003e c.function_sm(1,2) WRAPPED \u003cfunction function_sm at 0x107e918c0\u003e INSTANCE None ARGS (1, 2) \u003e\u003e\u003e Class.function_sm(1, 2) WRAPPED \u003cfunction function_sm at 0x107e918c0\u003e INSTANCE None ARGS (1, 2) @my_function_wrapper class Class(object): pass c = Class() \u003e\u003e\u003e c = Class() WRAPPED \u003cclass '__main__.Class'\u003e INSTANCE None ARGS () 答案是肯定的，因为它是唯一一个被包装对象是类型对象的情况。 ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:6:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"7. 通用装饰器结构 我们的目标是，一个装饰器能同时被应用在普通函数，示例方法，类方法以及类上。比较特殊的是静态方法，但是实践中，静态方法与函数并没有本质上的不同，只是它被放在不同的地方。在装饰器的执行过程中区分出静态方法是必要的，但是静态方法不会包含任何连接到它所在的类的参数。如果需要，在开始更应该创建一个类方法。最后我们的通用装饰器可以被展示如下: @decorator def universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) 这样的通用装饰器有实际用途吗?我相信有一些很好的例子，我将在随后的博客文章中特别提到其中一个。其他一些框架，比如Django，也使用了一些技巧来创建同时适用于函数和实例方法的装饰器。事实证明，他们使用的方法是不正确的，因为它不遵守描述符协议。如果您对此感兴趣，请参见Django bug跟踪器中的第21247号问题。下一篇博客中将介绍一些具有可选参数的装饰器的问题，通用装饰器的使用实例留在以后展示。 ","date":"2018-05-22","objectID":"/posts/program/python/modules/wrapt/python_decorator_04/:7:0","tags":["python 库"],"title":"04 实现一个通用装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_04/"},{"categories":["Python"],"content":"03 使用工厂函数创建装饰器","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"上一篇文章描述了一种基于代理对象创建装饰器的模式，并且通过将装饰器实现为一个描述符，解决了当装饰器应用于类方法时，对象绑定问题。代理对象和描述符的组合自动确保了内省机制能正常进行。现在的问题是如何消除样本代码来解决代码复用的问题。 本文我们将进一步改进创建装饰器的方式，通过使用装饰器工厂函数，来抽象装饰器的创建，用户只需提供一个执行所需功能的的包装函数即可。 ","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/:0:0","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"1. 装饰器的实现模式 如前所述，我们需要一个代理对象，其实现如下 class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 正如最后一次指出的那样，这是对它所做事情的最小表示。一个通用的对象代理需要做更多的工作。 描述符本身将按照如下模式实现 class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 当将装饰器应用于一个正常的函数时，将使用包装器的 __call__()方法。如果将包装器应用于类的方法，则在属性访问时调用 __get__() 方法，返回一个新的绑定对象之后的装饰器，并在被调用时调用新的装饰器的__call__()方法。这使得我们的包装器能作为描述符来传递描述符协议，以根据需要对包装的对象进行绑定。 ","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/:1:0","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"2. 创建装饰器的装饰器 正常工作的装饰器有一个固定的实现模式，因此，我们可以使用工场函数抽象装饰器创建的过程，工厂函数可以作为一个装饰器使用，创建一个装饰器的过程如下: @decorator def my_function_wrapper(wrapped, args, kwargs): return wrapped(*args, **kwargs) @my_function_wrapper def function(): pass 这个装饰器工厂函数 decorator 应该怎么实现呢？就像表现的一样，我们的装饰器工厂函数是非常简单的，与partial()函数并没有很大不同，在装饰器定义时接收用户提供的包装函数，在装饰器应用时接收被包装函数，并将他们传递到function wrapper对象中。 def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 我们现在只需要修改我们的装饰器 function wrapper 对象的实现，将包装对象的实际执行委托给用户提供的包装函数。 class bound_function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs) function_wrapper 和 bound_function_wrapper 同时接收包装函数，和被包装函数，并将 __call__() 实际执行委托给用户提供的包装函数，由用户调用被包装函数并返回值。 因此，我们可以使用工厂来简化创建装饰器的过程。现在让我们来检查一下，在所有的情况下，这将在实际工作中发挥作用，并且看看我们还能找到什么其他的问题，以及我们是否能在这些情况下改进。 ","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/:2:0","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"3. 装饰类方法 第一个可能导致问题的领域是创建一个单独的decorator，它可以同时处理类的正常函数和实例方法。为了测试我们的新decorator是如何工作的，我们可以在调用包装函数时打印传递给包装器的args，并可以比较结果。 @decorator def my_function_wrapper(wrapped, args, kwargs): print('ARGS', args) return wrapped(*args, **kwargs) 首先让我们尝试包装一个普通函数: @my_function_wrapper def function(a, b): pass \u003e\u003e\u003e function(1, 2) ARGS (1, 2) 正如所期望的那样，在函数被调用时，只有两个参数被输出。包装一个实例方法会如何？ class Class(object): @my_function_wrapper def function_im(self, a, b): pass c = Class() \u003e\u003e\u003e c.function_im() ARGS (1, 2) 同样，当调用实例方法时传入的两个参数被输出。因此，装饰器对正常函数和实例方法的工作方式是相同的。 这里的问题是，用户如何在他们的包装函数中获取类的实例。当函数被绑定到类的实例时，我们丢失了这个信息，因为类实例现在与传入的绑定函数关联，而不是参数列表。要解决这个问题，我们可以记住在调用绑定函数时传递给 __get__() 方法的实例是什么。在 bound wrapper被创建，作为参数传递给bound wrapper。 class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, self.instance, args, kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 在bound wrapper中，类实例作为额外的参数传给用户创建的包装函数。对于普通函数，在顶级包装器中，对于这个新的实例参数，我们没有传递任何内容。现在，我们可以修用户的包装函数，以输出实例和传递的参数。 @decorator def my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) \u003e\u003e\u003e function(1, 2) INSTANCE None ARGS (1, 2) \u003e\u003e\u003e c.function_im(1, 2) INSTANCE \u003c__main__.Class object at 0x1085ca9d0\u003e ARGS (1, 2) 因此，这种变化能让我们在包装器函数中区分出一个普通函数调用和一个的实例方法调用。对实例的引用甚至是单独传递的，在调用原始被包装函数时，我们不必为一个实例方法去判断并移除额外的类实例参数。对于类，原始的被包装函数已经是绑定对象，所以不能在传入类实例对象。 需要注意的是实例方法可以通过类，显示传递类实例来调用，我们需要验证这种情况是否仍然符合我们的要求。 \u003e\u003e\u003e Class.function_im(c, 1, 2) INSTANCE None ARGS (\u003c__main__.Class object at 0x1085ca9d0\u003e, 1, 2) 不幸的是，将实例显式地传递给类中的函数作为参数时，类实例没有通过 instance 传递给包装函数，而是作为 arg 的第一个参数被传递。这并不是一个理想的结果 为了处理这种变化，我们可以在调用bound_function_wrapper.__call__()之前检查实例，并从参数列表的开头弹出实例。然后使用 partcial 函数将实例绑定到被包装函数上，并调用用户的包装函数。 class bound_function_wrapper(object_proxy): def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs) # We then get the same result no matter whether the instance method is called via the class or not. \u003e\u003e\u003e Class.function_im(c, 1, 2) INSTANCE \u003c__main__.Class object at 0x1085ca9d0\u003e ARGS (1, 2) 对于实例方法，一切都可以正常执行，被包装函数无论是实例方法和还是普通函数接收参数完全相同。得益与 instance 参数，在将装饰器应用于实例方法时，我们可以按需调用类方法。 对于类可以拥有的其他方法类型，特别是类方法和静态方法会怎样？ class Class(object): @my_function_wrapper @classmethod def function_cm(cls, a, b): pass \u003e\u003e\u003e Class.function_cm(1, 2) INSTANCE 1 ARGS (2,) 正如所看见得，装饰器对类方法和静态方法有非常严重得问题。这两种情况下，在函数被绑定时，instance 参数将为空。此时传递给函数的第一实参将被传递给 instance，这显然是不正确的，应该怎么做？ ","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/:3:0","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"4. 通用装饰器 所以我们并没有完成一个通用的装饰器，但我们到底想要达到什么目的呢?我们最初的装饰模式有什么问题?这里的终极目标是我所说的“通用装饰器”。一个可以应用于普通函数、实例方法、类方法、静态方法甚至是类的修饰符，修饰符能够在使用的时候自动适用它被使用的上下文。 目前为止，实现装饰器的所有方法想达到上述目标是不可能了。只能通过复制代码，或者通过某种技巧转换装饰器，以便装饰器能在不同的上下文中使用。我的目标是能实现如下功能: @decorator def universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 本文中，我们已经实现了让装饰器在普通函数和实例方法上正确执行，我们现在需要了解如何处理类方法、静态方法以及将装饰器应用于类的场景。本系列的下一篇文章将继续追求这个目标，并描述如何进一步调整我们的装饰器。 ","date":"2018-05-12","objectID":"/posts/program/python/modules/wrapt/python_decorator_03/:4:0","tags":["python 库"],"title":"03 使用工厂函数创建装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_03/"},{"categories":["Python"],"content":"02 装饰器与描述符协议","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"上一篇文章说明了普通函数实现的装饰器存在的问题。本文我们将着眼于之前阐述的最后一个问题，如何将装饰器应用到一个描述符上。 ","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/:0:0","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"1. 描述符协议 有关 Python 的对象模型和底层设计原理推荐大家读一读《流畅的Python》，这里不会详细解释描述符是什么以及他们的工作原理。简而言之，描述符就是存在绑定行文的对象，即属性访问会被描述符协议实现的方法所覆盖。实现描述符协议的特殊方法包括 __get__(), __set__(), 和 __delete__()。如果任意一中方法在一个对象中被定义，就可以说该对象是一个描述符** obj.attribute attribute.__get_(obj.type(obj)) obj.attribute = value attribute.__set_(obj, value) del obj.attribute attribute.__delete_(obj, value) 上述描述的是，如果一个类的属性包含上述任意一中特殊方法，当相应操作在类属性被执行时，这些特殊方法将取代默认方法被调用。这就允许一个属性去覆盖将发生默认操作。 也许你以为你从未使用过描述符，事实上，函数对象就是描述符。当在类中定义函数时，函数就是普通的函数。当你通过’.‘属性访问函数时，你将调用函数的 __get__()方法，将函数与一个类实例绑定，进而返回一个绑定方法对象** def f(obj): pass \u003e\u003e\u003e hasattr(f, '__get__') True \u003e\u003e\u003e f \u003cfunction f at 0x10e963cf8\u003e \u003e\u003e\u003e obj = object() \u003e\u003e\u003e f.__get__(obj, type(obj)) \u003cbound method object.f of \u003cobject object at 0x10e8ac0b0\u003e\u003e 所以当你调用类方法时，调用的不是原始函数的 __call__()，而是访问函数时临时创建的绑定方法对象的 __call__() 方法，当然，你通常不会看到所有这些中间步骤，只看到结果。 \u003e\u003e\u003e class Object(object): ... def f(self): pass \u003e\u003e\u003e obj = Object() \u003e\u003e\u003e obj.f \u003cbound method Object.f of \u003c__main__.Object object at 0x10abf29d0\u003e\u003e 现在回想一下在第一个博客文章中给出的例子，当我们对一个类方法应用了装饰器时，我们遇到了如下错误: class Class(object): @function_wrapper @classmethod def cmethod(cls): pass \u003e\u003e\u003e Class.cmethod() Traceback (most recent call last): File \"classmethod.py\", line 15, in \u003cmodule\u003e Class.cmethod() File \"classmethod.py\", line 6, in _wrapper return wrapped(*args, **kwargs) TypeError: 'classmethod' object is not callable 示例中的问题在于 @classmethod 装饰器返回的 classmethod 对象本身并没有 __call__() 方法，__call__() 方法仅存在于 classmethod 对象__get__()被调用时返回的结果中。 更具体的说， 人们使用的简单装饰器，并没有对被包装的描述符对象执行描述符协议以产生的一个可调用对象。想反，只是简单的直接调用被包装对象。因为其没有 __call__() 方法，结果当然会失败。 那为什么将装饰器应用在普通的实例方法上仍然可以运行呢？原因是一个普通函数本身具有 __call__() 方法，包装函数直接调用的是此方法。而且尽管绑定步骤被跳过，但是包装函数将 self 包含的实例对象通过第一参数显示传递给了原始的未绑定函数对象。因此对于一个普通的实例方法包装前后调用实际上是相同的，只有当被包装的对象(如@classmethod)依赖于正确应用的描述符协议时，才会崩溃。 ","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/:1:0","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"2. 包装描述符对象 解决包装器不能在类方法执行描述符协议获取绑定对象的方法是，让包装器也成为一个描述符对象。 class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 如果将包装器应用于一个正常的函数，则使用包装器的 __call__()方法。如果将包装器应用于类的方法，则调用__get__()方法，该方法返回一个新的绑定包装器，并调用该方法的 __call__() 方法。这样我们的包装器就可以在描述符的传播过程中使用。 因为将装饰器实现为一个描述符对象时，使用闭包总是会失败，因此这种情况下为了让所有的事都能正常工作，我们必需总是使用类实现装饰器。装饰器类将实现描述符协议，如上所式。 现在的问题是，我们如何解决我们列出的其他问题。我们使用functools.wrap() 和 functools.update_wrapper() 解决命名问题，现在我们应该怎么做以便继续使用他们。因为 functools.wrap() 内部使用 update_wrapper(),所以我们只需要看看它如何实现。 WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__') WRAPPER_UPDATES = ('__dict__',) def update_wrapper(wrapper, wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES): wrapper.__wrapped__ = wrapped for attr in assigned: try: value = getattr(wrapped, attr) except AttributeError: pass else: setattr(wrapper, attr, value) for attr in updated: getattr(wrapper, attr).update( getattr(wrapped, attr, {})) 如上展示的是Python3.3中的代码，事实上它还存在一个bug，在Python3.4中已经修复。 在函数体中，3件事需要被做。 第一件是将被包装函数保存为包装函数的__wrapped__属性。这就是那个bug，因为它应该在最后实现 第二步，复制诸如 __name__ 和 __doc__ 属性； 最后一步，复制被包装函数__dict__属性值到包装函数，结果是很多对象需要被复制 如果我们使用的是一个函数闭包或直接的类包装器，那么这个复制就可以在decorator应用的时候完成。当装饰器被实现为描述符时，也需要在 bound wrapper 中完成上述工作。 class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) 因为bound wrapper 在包装器每次被作为类的绑定方法调用时都会被创建，所有将非常慢。我们需要更高效的方式处理它。 ","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/:2:0","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"2. 代理对象 性能问题的解决方法是，使用代理对象。这是一个特殊的包装类，因为它的行为跟它包装的东西看起来很像。 class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 一个完全透明的对象代理本身就是一个复杂的怪物，所以我打算暂时把细节掩盖起来，并在一个单独的博客文章中讨论它。上面的例子是它所做事情的最小表示。实际上，它实际上需要做更多的工作。简而言之，它将有限的属性从包装的对象复制到自身，并使用特殊的方法、属性和 __getattr__() 来从包装对象中获取属性，从而避免需要复制许多可能永远不会被访问的属性。 我们现在要做的是从对象代理中派生出包装器类，并取消调用update_wrapper()。 class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 现在从包装器中查询像 __name__ 和 __doc__ 这样的属性时，将从被包装函数直接返回。使用透明的对象代理也意味着像 inspect.getargspec() 和 inspection.getsource() 这样的调用也将按照预期正常工作。 ","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/:3:0","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"3. 代码复用 尽管这种模式解决了最初确定的问题，但它包含了大量的重复样板代码。此外，在现在的代码中有两个位置，调用被包装函数。因而需要在两个地方重复实现包装逻辑。因此，每次需要实现一个装饰器时都要复制这一点，因此会有点痛苦。 我们可以做的是将整个过程打包到一个装饰器工厂函数中，从而避免每次都需要手工完成这一切。如何做到这一点将成为本系列下一篇博客文章的主题。从这一点开始，我们可以开始研究如何进一步改进功能，并引入新的功能，这些都是使用常规的装饰器实现方法难以实现的。 ","date":"2018-05-08","objectID":"/posts/program/python/modules/wrapt/python_decorator_02/:4:0","tags":["python 库"],"title":"02 装饰器与描述符协议","uri":"/posts/program/python/modules/wrapt/python_decorator_02/"},{"categories":["Python"],"content":"01 如何实现一个 Python 装饰器","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"稍微对 Python 有所了解的程序员一定知道 Python 装饰器和函数闭包。我曾经也以为很了解，直到在《流畅的Python》中看到了 Wrapt 模块。 Wrapt 模块的作者 Graham Dumpleton 先生写了 14 篇博客详细讲解了如何在 Python 中实现一个能同时包装函数，类方法，实例方法的通用装饰器。本文以及接下来几篇文章是我对那 14 篇博客的整理和笔记。 Graham Dumpleton 先生的博文 和 Wrapt 模块请参阅: GrahamDumpleton wrapt blog wrapt 1.10.11 documentation ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:0:0","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"1. 通过函数闭包实现装饰器 装饰器的典型目的是为被包装函数附加的额外的处理逻辑。我遇到的使用装饰器的最典型场景是，大多数数据库对一次查询可设置的查询的条件有数量限制，大量查询时需要将多个查询条件分组进行多次查询在合并查询结果。比如我有100000 用户需要根据ID 查询其性别，查询条件太多，只能分批多次查询，然后将查询结果合并。这种分批查询不仅对 mysql，对其他任何数据库都适用，所以非常适用用装饰器将分批查询再合并的功能抽象出来。 ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:1:0","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"1.1 实现原理 大多数人(我)都是通过闭包来创建一个装饰器，就像下面这样。 def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper # @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖 @function_wrapper def function(): pass function = function_wrapper(function) 整个包装的执行过程如下: 包装函数(function_wrapper)接收被包装函数(wrapped)作为参数，并将内部的另一个内部函数(_wrapper) 作为返回值 通过@装饰器或函数的调用赋值，使用 _wrapper 替换 wrapped，这样对 wrapped 的调用实际是调用的 _wrapped _wrapped 通过函数闭包保留了对 wrapped 函数的引用，这样它就可以在内部调用 wrapped 函数并返回调用结果。 _wrapped 在调用 wrapped 之前或之后可以添加其他处理逻辑，以达到为 wrapped 附加功能的目的。 虽然通常都是适用函数闭包实现装饰器，但是能展示它工作原理的更好的示例是使用一个类实现它: function_wrapper 类通过属性保留对被包装函数的引用 当被包装函数被调用时，包装类的 __call__ 方法被调用，并进而调用原始的被包装函数 __call__ 包含了附加的通用处理逻辑。 class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) @function_wrapper def function(): pass ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:1:1","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"1.2 局限 尽管通过闭包实现装饰器很简单，但是这种方式存在很多局限，其中最重要的是打断了 Python 内部的自省，也没有遵循 Python 对象模型的执行方式。 猴子补丁 与装饰器十分相似的一个技术是 monkey patching(猴子打补丁)，猴子打补丁会进入并修改其他人的代码。二者不同的是装饰器作用的时间是函数定义完成之后，而猴子补订在函数导入模块时被应用。为了能同时使用函数包装器和猴子补丁，函数包装器必需是透明的，并且内部维护了一个堆，以便多个装饰器，猴子补订能按照预期的顺序执行。 ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:1:2","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"2. 自省丢失 当我们讨论函数闭包时，我们会预期函数的自省属性和函数的外在表现相一致。这些包括__name__，__doc__ 属性。但是当使用函数闭包时，原函数的自省属性会被内嵌函数所替代，因为函数闭包返回的是内嵌函数。 def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper @function_wrapper def function(): pass \u003e\u003e\u003e print(function.__name__) _wrapper 当使用类实现闭包时，类实例没有 __name__ 属性，访问此属性时，会导致 AttributeError 异常 class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) @function_wrapper def function(): pass \u003e\u003e\u003e print(function.__name__) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e AttributeError: 'function_wrapper' object has no attribute '__name__' 此处的解决方式是，在函数闭包内，将被包装函数的内省属性复制到内嵌函数上。这样函数名称和文档字符串属性就能表现正常 def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) _wrapper.__name__ = wrapped.__name__ _wrapper.__doc__ = wrapped.__doc__ return _wrapper @function_wrapper def function(): pass \u003e\u003e\u003e print(function.__name__) function 手动复制属性是费劲的，如果未来扩展了其他自省属性，代码需要被更新。例如需要复制 __module__ 属性，在Python3 中需要复制 __qualname__ 和 __annotations__ 属性。为了避免这么做，Python 标准库为我们提供了 functools.wraps() 装饰器，完成自省属性的复制 import functools def function_wrapper(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper @function_wrapper def function(): pass \u003e\u003e\u003e print(function.__name__) function 使用类实现装饰器时，我们需要使用 functools.update_wrapper() 函数 import functools class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 或许你已经认为通过 functolls.wraps 函数我们能确保函数的自省属性是正确的，但事实上它并不能一直有效。假如我们去访问函数的参数信息，返回的将是包装函数的参数信息而不是被包装函数的。即，在使用闭包的方式中，内嵌函数的参数信息被返回。因此包装器没能保留函数签名信息 import inspect def function_wrapper(wrapped): ... @function_wrapper def function(arg1, arg2): pass \u003e\u003e\u003e print(inspect.getargspec(function)) ArgSpec(args=[], varargs='args', keywords='kwargs', defaults=None) 类包装器更加严重，因为会触发异常，并解释称被包装函数不是一个函数。我们完全不能获取函数签名信息，即使被包装函数是可调用的 class function_wrapper(object): ... @function_wrapper def function(arg1, arg2): pass \u003e\u003e\u003e print(inspect.getargspec(function)) Traceback (most recent call last): File \"...\", line XXX, in \u003cmodule\u003e print(inspect.getargspec(function)) File \".../inspect.py\", line 813, in getargspec raise TypeError('{!r} is not a Python function'.format(func)) TypeError: \u003c__main__.function_wrapper object at 0x107e0ac90\u003e is not a Python function 另外一个自省的示例是使用 inspect.getsource() 获取函数源代码。闭包装饰器返回的是内嵌函数的源代码，而类装饰器则会触发异常 ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:2:0","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"3.描述符协议 同函数类似，装饰器也可以应用于类方法。Python 包含了两个特殊的装饰器@classmethod 和 @staticmethod 将实例方法转换为特殊的类方法。装饰器应用于类方法同样隐含着几个问题 class Class(object): @function_wrapper def method(self): pass @classmethod def cmethod(cls): pass @staticmethod def smethod(): pass 第一即使使用了 functools.wraps 或者 functools.update_wrapper，当装饰器被用在 @classmethod，@staticmethod 上时，仍然会导致异常。这是因为这两个特殊的装饰器没能将一些必要的属性复制过来。这是一个Python2 的bug，并在Python3中通过忽略丢失的属性修复了 class Class(object): @function_wrapper @classmethod def cmethod(cls): pass Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"\u003cstdin\u003e\", line 3, in Class File \"\u003cstdin\u003e\", line 2, in wrapper File \".../functools.py\", line 33, in update_wrapper setattr(wrapper, attr, getattr(wrapped, attr)) AttributeError: 'classmethod' object has no attribute '__module__' 即使我们运行在 Python3 上，我们依然会遇到问题。这是因为所有类型的装饰器都假设被包装函数是直接可调用的。事实上并非如此。Python classmethod 装饰器返回一个描述符，这个描述符不是直接可调用的，但是装饰器假设被包装函数直接可调用，因此会出错。 class Class(object): @function_wrapper @classmethod def cmethod(cls): pass \u003e\u003e\u003e Class.cmethod() Traceback (most recent call last): File \"classmethod.py\", line 15, in \u003cmodule\u003e Class.cmethod() File \"classmethod.py\", line 6, in _wrapper return wrapped(*args, **kwargs) TypeError: 'classmethod' object is not callable ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:3:0","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Python"],"content":"4. 总结 函数闭包实现的装饰器存在以下问题: 无法保留函数的自省属性 无法获取函数签名信息 无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 使用 functools.wraps() 和 functools.update_wrapper() 能保留常规的自省属性，但依旧无法保留函数签名信息和源代码，而且由于 Python2 的bug，无法将装饰器直接应用于类方法和静态方法(导入时即报错) 确实存在第三方包，尝试解决这些问题，例如PyPi上的decorator模块。这个模块虽然对前两类问题有所帮助，但仍然存在一些潜在的问题，当尝试通过猴子补丁动态应用函数包装时，可能会导致问题 这并不意味着这些问题是不可解决的，而且可以以一种不牺牲性能的方式解决。现在已经说明了要解决的问题，在随后的文章将会解释如何解决这些问题，以及提供哪些额外的功能。 ","date":"2018-05-04","objectID":"/posts/program/python/modules/wrapt/python_decorator_01/:4:0","tags":["python 库"],"title":"01 如何实现一个 Python 装饰器","uri":"/posts/program/python/modules/wrapt/python_decorator_01/"},{"categories":["Linux"],"content":"22.3 sudo","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"sudo sudo是linux系统管理指令，它允许用户临时以其他用户(通常是root)执行一些或全部指令，其实现的是一种授权机制。普通用户想执行root 用户的特权命令时，可以使用 su 切换到管理员，但是这样做有两个坏处，一是 root 用户会被普通用户知道，二是普通用户切换为 root 后获取的是 root 的所有权限，这些都存在安全风险。而 sudo 可以实现授权普通用户执行部分或全部命令，同时无需 root 密码。本节我们就来介绍 sudo 的使用，内容如下: su 用户切换 sudo 配置 sudo 命令使用 ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:0:0","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"1. su 用户切换 su [OPTION]... [-] [USER [ARG]...] 作用: 用户切换 参数: USER，可省，默认为 root 选项: -l: 交互式登录shell进程，su -l user == su - user -c 'COMMAND': 不切换用户只执行命令后，并退出 有关交互式登陆，可以回看 6.10 bash配置文件 ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:1:0","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"2. sudo 配置 sudo 能够让获得授权的用户以另外一个用户的身份运行指定的命令。授权文件为 /etc/sudoers，此文件有特定的语法格式，因此有个专用的编辑命令 visudo,其在退出时，可以帮助我们检查语法错误。sudoers 配置如下 ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:2:0","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"2.1 授权机制 $ sudo visudo root ALL=(ALL) ALL tao ALL=(ALL) ALL %wheel ALL=(ALL) ALL # 总结: 那个用户 从什么地方 以谁的身份 执行什么命令 who where=(whom) commands users hosts=(runas) commands 授权选项格式 users: 授权用户 username: 用户名 #uid: 用户ID(UID) %groupname: 用户组名称 %#gid: 用户组ID(GID) user_alias: 用户别名 hosts: 用户登陆限制，只有在限制范围内登陆的用户才能使用授权的命令 ip: ip 地址 hostname: 域名 NetAddr: 子网 host_alias: 网络别名 runas: 以哪些用户的身份执行命令 commands: 授权的命令，必需是全路经 command: 命令 directory: 目录 sudoedit：特殊权限，可用于向其它用户授予sudo权限 cmnd_alias: 命令别名 wheel 组 wheel 组是 Linux 中的特殊组即管理员组，属于 wheel 组的成员均具有所有管理员权限 # root 身份执行 $ usermod pythoner -a -G wheel $ su - pythoner # 必需要以交互式登陆的方式切换到 pythoner 才能生效 $ id pythoner uid=1001(pythoner) gid=1001(pythoner) 组=1001(pythoner),10(wheel) $ sudo cat /etc/shadow ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:2:1","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"2.2 定义别名的方法 suders 支持设置别名，用于简化配置工作。别名类似于变量，可复用，可避免重复输入。别名设置的语法格式为: ALIAS_TYPE NAME=item1, item2, item3, ... NAME：别名名称，必须使用全大写字符； ALIAS_TYPE: 别名类型，分别与上面一一对应 User_Alias Host_Alias Runas_Alias Cmnd_Alias: 包含的命令必需全路经 # 别名设置 User_Alias NETADMIN=tom, jerry Cmnd_Alias NETCMND=/usr/sbin/ip, /usr/sbin/ifconfig # 使用别名进行配置 NETADMIN localhost=(root) NETCMND ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:3:0","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"2.3 sudo命令s使用 sudo [options] COMMAND options -l: 列出用户能执行的命令 -k: 清除此前缓存用户成功认证结果； -u: 以哪个用户执行 默认 sudo 有检票机制，即能记录成功认证结果一段时间，默认为5分钟。-k 选项则可以手动取消，下此使用 sudo 时必需输入密码。同时需要提醒大家注意的是，执行 sudo 时输入的是用户自己的密码，不是 root 密码。 ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:3:1","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"2.4 sudoers 配置示例 Cmnd_Alias USERADMINCMNDS = /usr/sbin/useradd, /usr/sbin/usermod, /usr/bin/passwd [a-z]*, !/usr/bin/passwd root User_Alias USERADMIN = bob, alice USERADMIN ALL=(root) NOPASSWD:USERADMINCMNDS sudoers 中常用的标签 NOPASSWD: 标识使用命令时，无需输入密码 PASSWD: 默认，使用命令时，需要输入密码 !COMMAND: ! 表示不允许执行 COMMAND 命令 ","date":"2018-04-07","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/:3:2","tags":["马哥 Linux"],"title":"22.3 sudo","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/sudo/"},{"categories":["Linux"],"content":"22.2 日志管理系统rsyslog","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"日志管理系统rsyslog rsyslog 是Linux 系统上日志管理系统，应用程序可直接调用 rsyslog 的接口将日志写入到 rsyslog 特定的 facility 中即可完成日志记录。如果应用程序通过 rsyslog 来记录日志，通常在其自己的配置文件中有专门的选项用来定义将日志存入到 rsyslog 哪个 facility。facility 可以理解为 rsyslog 日志收集器的基本单元，rsyslog 内部的配置文件定义了每个 facility 的日志存储于何处。应用程序只需要将日志信息教给 rsyslog，rsyslog 会自动根据日志所属的 facility 将日志存储到对应的位置。本节我们就来详细介绍 rsyslog 的配置使用 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:0:0","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1. rsyslog 简介 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:1:0","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1.1 syslog syslog 是 rsyslog 的上一版，syslog 服务分成了两个部分: syslogd： system，为 Linux 上的应用程序提供日志记录服务 klogd：kernel，为开机启动，系统内核提供日志记录服务 除了本地服务，syslog 还支持C/S架构，即可通过UDP或TCP协议为网络上的其他主机提供日志记录服务。这种模式下 # C/S rsyslog -------- kernel --------\u003e |本机 | | | tcp/utp ssh --------\u003e |rsyslog| ------------\u003e rsyslog server | | ... ---------\u003e |服务 | --------- 作为 server 的 syslog 服务监听在 tcp/utp 的 514 端口上 作为客户端的应用程序，首先将日志发送到本地的 syslog 服务上，再由 本地的 syslog 服务作为客户端将应用程序的日志发送到 server 端的 syslog 上加以记录，因此 syslog 的客户端与服务器都是 syslog rsyslog server 收到客户端发来的日志后，根据自己 facility 的配置将日志记录到特定位置。 因此应用程序只是将日志写入到特定的 facility，syslog server 只是本地 syslog 记录日志的一种方式。syslog 可定义 facility 的日志存储方式，可以是本地文件，也可以是远程的 syslog server syslog 日志格式无法自定义，统一为事件产生的日期时间 主机 进程[pid] ：事件内容，因此只能记录一些简单的日志。 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:1:1","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1.2 rsyslog rsyslog 是 syslog 的升级版本，支持所有 syslog 特定，它只有 rsyslogd 一个服务来完成所有日志的记录功能。相比于 syslog，rsyslog 具有如下新特性: 支持多线程； 支持多种C/S连接协议，UDP，TCP，SSL，TLS，RELP； 可存储日志信息于MySQL、PGSQL、Oracle等数据管理系统； 强大的过滤器，实现过滤日志信息中任何部分的内容； 自定义输出格式 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:1:2","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"2. rsyslog 组成 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:2:0","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"2.1 日志收集器单元 rsyslog日志收集器有两个重要的概念: facility： 作用: 设施，从功能或程序上对日志收集进行分类 内置: rsyslog 上默认的 facility 有 auth, authpriv, cron, daemon, kern, lpr, mail, mark, news, security, user, uucp, local0-local7, syslog priority： 作用: 日志级别，用于定义日志的重要性，facility 可定义记录日志的级别范围 级别: 日志级别从低到高有 debug, info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:2:1","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"2.2 程序组成 $ rpm -ql rsyslog /etc/logrotate.d/syslog /etc/pki/rsyslog /etc/rsyslog.conf # 配置文件 /etc/rsyslog.d /etc/sysconfig/rsyslog # rsyslog 服务的配置文件 /usr/bin/rsyslog-recover-qi.pl /usr/lib/systemd/system/rsyslog.service # 服务脚本 /usr/lib64/rsyslog # 模块目录 /usr/lib64/rsyslog/im*.so # im 开头的为输入相关模块 /usr/lib64/rsyslog/om*.so # om 开头的为输出相关模块 /usr/lib64/rsyslog/lm*.so /usr/lib64/rsyslog/mm*.so /usr/lib64/rsyslog/pm*.so ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:2:2","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"3. rsyslog 配置 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:3:0","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"3.1 配置文件结构 $ cat /etc/rsyslog.conf |grep -v \"^# \" #### MODULES #### # 模块加载 $ModLoad imuxsock # provides support for local system logging (e.g. via logger command) $ModLoad imjournal # provides access to the systemd journal #$ModLoad imklog # reads kernel messages (the same are read from journald) #$ModLoad immark # provides --MARK-- message capability $ModLoad imudp # utp 服务 $UDPServerRun 514 $ModLoad imtcp # tcp 服务 $InputTCPServerRun 514 #### GLOBAL DIRECTIVES #### # 全局目录配置 $WorkDirectory /var/lib/rsyslog $IncludeConfig /etc/rsyslog.d/*.conf #### RULES #### # facility 日志记录配置 *.info;mail.none;authpriv.none;cron.none /var/log/messages mail.* -/var/log/maillog *.emerg :omusrmsg:* 配置文件由三个部分组成 MODULES: 模块加载 GLOBAL DIRECTIVES: 全局变量 RULES: 用于定义 facility 记录日志的级别和位置，格式为 facilty.priority target ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:3:1","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1.2 RULES 格式 RULES 用于定义 facility 记录日志的级别和位置，其语法为 facilty.priority target priority: 日志级别，有如下几种表示方式 *：所有级别； none：没有级别； priority：此级别以高于此级别的所有级别； =priorty：仅此级别 target: 日志输出的位置，有如下几种格式 /var/log/messages: 记录到特定文件中，默认为同步写入，大量日志记录会拖慢系统性能 -/var/log/maillog: 记录到文件，- 表示异步写入，不重要的日志可异步写入，减少系统 IO :omusrmsg:tao: 调用 omusrmsg 将日志发送到用户登陆的终端，* 表示所有登陆用户； @192.168.1.101: 将日志发送到 rsyslog server | COMMAND: 将日志送入管道 说明: target 中可使用 :module:param 调用 rsyslog 内置的模块，每个模块有自己特定的参数 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:3:2","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1.3 默认 facilty *.info;mail.none;authpriv.none;cron.none /var/log/messages authpriv.* /var/log/secure mail.* -/var/log/maillog cron.* /var/log/cron *.emerg :omusrmsg:* uucp,news.crit /var/log/spooler # Save boot messages also to boot.log local7.* /var/log/boot.log local2.* /var/log/haproxy.log ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:3:3","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"1.4 其他日志文件 除了 rsyslog 记录的日志外，系统上还有其他一些重要的日志文件 /var/log/wtmp： 作用: 当前系统成功登录系统的日志 查看: last 命令 /var/log/btmp： 作用: 当前系统尝试登录系统失败相关的日志 查看: lastb命令 附注: lastlog命令，能显示当前系统上的所有用户最近一次登录系统的时间； /var/log/dmesg： 作用: 系统引导过程中的日志信息 查看: 也可以使用dmesg命令进行查看 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:3:4","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"4. rsyslog 高级配置 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:4:0","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"4.1 rsyslog server 配置 配置 C/S 架构的 rsyslog 步骤如下所示 # 1. 服务器端: 启动 rsyslog server 监听 tcp/udp 的模块 # Provides UDP syslog reception $ModLoad imudp $UDPServerRun 514 # Provides TCP syslog reception $ModLoad imtcp $InputTCPServerRun 514 # 2. 客户端: 配置 facility 将日志发往服务端 *.info;mail.none;authpriv.none;cron.none @192.168.1.149 ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:4:1","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"4.2 记录日志于mysql中 记录日志于mysql中首先要安装配置 rsyslog mysql 的模块，配置步骤如下: # 1. rsyslog mysql 模块安装 $ yum search rsyslog $ sudo yum install rsyslog-mysql.x86_64 # 2. mysql 配置 $ rpm -ql rsyslog-mysql.x86_64 /usr/lib64/rsyslog/ommysql.so /usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql # 通过导入createDB.sql脚本创建依赖到的数据库及表 $ mysql -uUSER -hHOST -pPASSWORD \u003c /usr/share/doc/rsyslog-mysql-VERSION/createDB.sql # 登陆 mysql 配置 rsyslog 使用的特定帐户 $ mysql -uUSER -hHOST -pPASSWORD MariaDB [(none)]\u003e grant all on Syslog.* to \"rsyslog\"@\"%\" identified by \"rsyspass\"; MariaDB [(none)]\u003e flush privileges; mysql -ursyslog -prsyspass \u003e # 3. 配置rsyslog使用ommysql模块 $ sudo vim /etc/rsyslog.conf ### MODULES #### $ModLoad ommysql #### RULES #### # facility.priority :ommysql:DBHOST,DB,DBUSER,DBUSERPASS facility.priority :ommysql:127.0.0.1,Syslog,rsyslog,rsyspass # 重启rsyslog服务 $ sudo systemctl restart rsyslog ","date":"2018-04-06","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/:4:2","tags":["马哥 Linux"],"title":"22.2 日志管理系统rsyslog","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog/"},{"categories":["Linux"],"content":"22.1 Linux时间服务-chrony","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"Linux时间服务-chrony Linux 中有一些通用原则，比如如果上下层衔接不通畅，通常的解决方法就是添加一个中间层，虚拟文件系统就是最典型的一例，再比如如果一个功能被很多应用所需要，通常会做成一个公共服务以便，认证功能 pam 还有本节将要介绍的 日志服务 rsyslog 就是典型的示例。本章我们会讲一些类似这些的 Linux 中基础的但是并不复杂的基础服务，包括: 时间同步服务 chrony 日志管理服务 rsyslog sudo 权限管理 Linux 中很多服务在跨主机通信需要保持时间同步，特别是对于一个集群而言，多台主机之间的时间必需严格一致。Linux 在启动时会从硬件中读取时间，在操作系统启动之后，系统时钟就会同硬件时钟相独立。系统始终依赖 CPU 的工作频率更新时间，因此不同主机之间的时间很难保持一致。特别是在虚拟化环境中，每个虚拟机只能获取一部份的 CPU 周期，时间基本不可能保持一致，此时就需要进行时间同步。本节我们就来 Linux 中的时间服务，内容包括: Linux 中时间同步的协议和方式 ntp 和 chrony ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:0:0","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"1. Linux 中的时间同步 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:1:0","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"1.1 Linux 时间同步的方式 ntp(Network Time Protocol) 是 Linux 同步时间的协议。当时间出现偏差时，Linux 不能将当前时间直接调整为准确时间，这是因为 Linux 上很多服务依赖于时间的连续性，时间不能跳越。Linux 只能通过让时间走\"更快\"或\"更慢\"来同步时间。 ntp 协议的最早实现是 ntp 服务，但是 ntp 存在一个缺陷，时间同步太慢，在时间相差较大时需要很长时间才能完成时间同步。chrony 服务是 ntp 的改进版本，它采用了一种很精巧的策略，在保证时间连续的同时能在几秒甚至更短的时间内完成时间同步。 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:1:1","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"1.2 Linux 时间同步服务 ntp，chrony 既是客户端也是服务端，这是因为我们的系统需要实时同步时间，因此 ntp，chrony 要作为后台进程实时进行。ntp 和 chrony 都监听在 utp的 123 端口上，因此 chrony 是兼容 ntp 的，即 ntp 的客户端也能从 chrony 服务同步时间。 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:1:2","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"1.3 时间同步配置 在 Linux 中同步时间只需要，安装 chrony，修改其配置文件，更改其同步时间服务器，如果其同时作为服务器使用，需要修改 allow 参数指定允许按些客户端过来同步；配置完成后启动 chrony 的服务，并将其设置为开机自动启动即可。 也可以使用 ntpdate 命令临时进行手动时间同步。下面我们就来详细介绍 ntp 和 chrony 的配置。Linux 上建议使用 chrony。 # 1. 安装 chrony 服务 yum install chrony # 2. 修改配置文件，详细配置见下 vim /etc/chrony.conf allow= # 允许同步的客户端 server= # 时间同步服务器 # 3. 启动服务 systemctl start chronyd systemctl enable chronyd ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:1:3","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"2. ntp # rpm -ql ntp /etc/dhcp/dhclient.d /etc/dhcp/dhclient.d/ntp.sh /etc/ntp.conf # 配置文件 /etc/ntp/crypto /etc/ntp/crypto/pw /etc/sysconfig/ntpd /usr/bin/ntpstat /usr/lib/systemd/ntp-units.d/60-ntpd.list /usr/lib/systemd/system/ntpd.service /usr/sbin/ntp-keygen /usr/sbin/ntpd /usr/sbin/ntpdc /usr/sbin/ntpq /usr/sbin/ntptime /usr/sbin/tickadj ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:2:0","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"2.1 配置文件 # cat /etc/ntp.conf |grep -v \"^#\" driftfile /var/lib/ntp/drift restrict default nomodify notrap nopeer noquery restrict 127.0.0.1 # 允许哪些主机过来同步时间 restrict ::1 server 0.centos.pool.ntp.org iburst # 时间服务器地址 server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst includefile /etc/ntp/crypto/pw keys /etc/ntp/keys disable monitor ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:2:1","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"2.2 时间同步命令 ntpdate server_ip 作用: 手动向 server_ip 指向的服务同步时间 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:2:2","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"3. chrony # rpm -ql chrony /etc/NetworkManager/dispatcher.d/20-chrony /etc/chrony.conf # chrony 配置文件 /etc/chrony.keys /etc/dhcp/dhclient.d/chrony.sh /etc/logrotate.d/chrony /etc/sysconfig/chronyd /usr/bin/chronyc # chrony 服务管理工具 /usr/lib/systemd/ntp-units.d/50-chronyd.list /usr/lib/systemd/system/chrony-dnssrv@.service /usr/lib/systemd/system/chrony-dnssrv@.timer /usr/lib/systemd/system/chrony-wait.service /usr/lib/systemd/system/chronyd.service /usr/libexec/chrony-helper /usr/sbin/chronyd # 客户端亦是服务端程序 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:3:0","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"3.1 组成 chrony 由如下几个部分组成: 配置文件：/etc/chrony.conf 主程序文件：chronyd 工具程序：chronyc unit file: chronyd.service ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:3:1","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"3.2 配置 $ cat /etc/chrony.conf # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second. makestep 1.0 3 # Enable kernel synchronization of the real-time clock (RTC). rtcsync # Enable hardware timestamping on all interfaces that support it. #hwtimestamp * # Increase the minimum number of selectable sources required to adjust # the system clock. #minsources 2 # Allow NTP client access from local network. #allow 192.168.0.0/16 # Serve time even if not synchronized to a time source. #local stratum 10 # Specify file containing keys for NTP authentication. #keyfile /etc/chrony.keys # Specify directory for log files. logdir /var/log/chrony # Select which information is logged. #log measurements statistics tracking 核心配置选项包括: server:指明时间服务器地址，本机会向 server指向的机器同步时间 allow NETADD/NETMASK: chrony 作为服务端使用时，允许哪些网络的主机同步时间 allow all:允许所有客户端主机 deny NETADDR/NETMASK: 不允许哪些网络的主机同步时间 deny all:拒绝所有客户端 bindcmdaddress:命令管理接口监听的地址, chronc 命令连接此地址对 chrony进行远程管理，因此不要监听在公网地址上 local stratum 10:即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端 ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:3:2","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"3.3 chronc chronc 是 chrony 服务的管理工具，它能远程连接 chrony 服务，chrony 会监听在 bindcmdaddress 参数配置的地址，等待 chronc 连接。chronc 是一个交互的客户端工具，最常使用的子命令为 sources，sourcestats，sourcestats -v，help。 # chronyc chronyc\u003e sources 210 Number of sources = 4 MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^? ns3106355.ip-37-187-100.\u003e 2 7 5 14 +20ms[ +22ms] +/- 236ms ^? . 0 8 0 - +0ns[ +0ns] +/- 0ns ^? cn.ntp.faelix.net 0 8 0 - +0ns[ +0ns] +/- 0ns ^* ntp2.flashdance.cx 2 6 45 15 +3857us[+6412us] +/- 246ms chronyc\u003e sourcestats chronyc\u003e sourcestats -v chronyc\u003e help ","date":"2018-04-05","objectID":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/:3:3","tags":["马哥 Linux"],"title":"22.1 Linux时间服务-chrony","uri":"/posts/linux/linux_mt/25-linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo/linux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony/"},{"categories":["Linux"],"content":"21.7 网络接口类型","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"网络接口类型 网络虚拟化我们会在之后的高级篇详细讲解，但是为了方便大家理解，我们在此章节简单描述以下不同虚拟网卡的类型的作用范围。虚拟网卡分为四种主要类型: bridge:桥接，将当前主机的物理网卡与VMware 内部的虚拟交换机进行关联 nat: 在当前物理主机的物理网卡上启动 nat 转发功能，转发内部虚拟主机的网络请求，以连接外部物理主机 host-only: 功能: 虚拟主机能与其他虚拟主机以及当前物理主机进行通信，不能与外部物理主机通信 特征: 与 nat 相比，仅仅是取消了当前物理网卡的 nat 功能 私有网桥(VMnet2) 功能: 仅虚拟主机之间可以通信，不能与当前物理主机通信 ","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/:0:0","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"1. bridge (图片来自于马哥Linux) 桥接的原理是当前主机的物理网卡与VMware 内部的虚拟交换机进行关联，原本的物理网卡被当作交换机使用，vmware 会再虚拟出一块网卡 VMNate8 作为当前物理主机的网卡。所有的虚拟机和当前物理主机(VMNate0网卡)都会连接到虚拟交换机上，这样所有的虚拟主机就可以共享物理主机的网络。 ","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/:1:0","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"2. nat nat 的原理是 vmware 在当前的物理主机上虚拟出一块网卡 VMNate8，并在其上启动 nat和 DHCP 功能，使用 nat 网络的虚拟主机会处于VMNate8 网卡所在的网络，因此会自动分配 IP 并将网关指向 VMNate8；然后由 VMNate8 做 SNAT 转发内网的主机请求以连接外部物理主机。 ","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/:2:0","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"3. host-only host-only 与 nat 功能类似，只不过 vmware 虚拟出的网卡不会启动 nat 功能，虚拟机无法与外部物理主机通信，只能当前的物理机通信 ","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/:3:0","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"4. 私有网络 私有网络更简单，vmware 会虚拟出一块网卡，而且此虚拟网卡不会添加在当前的物理主机之上。只有连接到相同私有网络的虚拟机之间才能通信，也无法与当前主机进行通信。 ","date":"2018-04-04","objectID":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/:4:0","tags":["马哥 Linux"],"title":"21.7 网络接口类型","uri":"/posts/linux/linux_mt/24-iptables/%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B/"},{"categories":["Linux"],"content":"21.6 TCP 协议简述","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"TCP 协议简述 tcp 连接是由两个有来有往的半个连接组成的 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:0:0","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"1. 连接建立与拆除 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:1:0","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"1.1 三此握手 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:1:1","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"1.2 四次挥手 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:1:2","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"1.3 连接重置 tcp 连接过程中可能因为网络抖动导致双方无法通信，但是连接未拆除，过了一段时间后网络又恢复正常，双方的连接状态依旧存在，此时需要发送 RST 标识位的报文实现 tcp 连接重置。 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:1:3","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"1.4 连接过程 ","date":"2018-04-03","objectID":"/posts/linux/linux_mt/24-iptables/tcp_protocol/:1:4","tags":["马哥 Linux"],"title":"21.6 TCP 协议简述","uri":"/posts/linux/linux_mt/24-iptables/tcp_protocol/"},{"categories":["Linux"],"content":"21.5 nat路由","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"nat路由 nat (network address translation) 是 iptables 另一功能，起初设计的目的是为了隐藏内网中的主机，后来为解决 ipv4 地址的紧缺问题提供了重要帮助。本节我们就来学习如何使用 nat 来隐藏内网中 主机，内容包括 源地址转换原理 目标地址转换原理 本地端口映射 iptables nat 规则配置 要想使用 nat 首先必需打开 Linux 的核心转发功能。如何修改内核参数详见 14.6 Linux内核功能及模块应用，打开核心转发功能可参考如下 echo 1 \u003e /proc/sys/net/ipv4/ip_forward systcl -w net.ipv4.ip_forward=1 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:0:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"1. 源地址转换 如上图所示: 内部网络的报文经由网关向外部网络转发 网关服务器在 POSTROUTING 上将请求报文源地址转换为网关的外网地址并向外部服务器转发请求 外网服务收到源地址为网关服务器的请求，则向网关服务器返回响应 网关在收到来自服务端的响应时，再将目标地址从本机转换为内网主机，并转发给内网主机。 源地址转换称为 snat，可工作于 POSTROUTING 和 INPUT 链上，绝大多数都是工作于 POSTROUTING 链上。这是因为 POSTROUTING 作用于第二次路由之后，是报文离开主机的最后一个环节，此时 snat 一定是作用在发出的报文，而如果在 INPUT 上，则有可能将由本机发往本机的报文也做了地址转换，这实际上没有必要。 外部服务器，看到的请求始终是网关服务器的外网 IP，因此达到隐藏内网客户端的目的。 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:1:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"2. 目标地址转换 如上图所示: 外网客户端向我们的网关服务器发送请求 网关服务器在 PREROUTING 上将请求报文目标地址转换为内网服务器地址并向其转发请求 内网服务器返回响应，报文经网关服务器向外转发 网关服务将响应报文的源地址从内网服务器转换为本机地址，并向外网客户端转发响应。因为客户端发送的请求的目标地址是网关，所以返回响应的也必需是网关而不能是内网服务器。 目标地址转换称为 dnat，可工作于 PREROUTING 和 OUTPUT 链上，绝大多数都是工作于 PREROUTING 链上。这是因为第一路由决策会决定报文由 INPUT 进入用户空间，还是进入 FORWARD 转发出去，因此应该在第一路由之前就将报文的目标地址为内网服务器地址，否则报文就被送往内核而不是被转发到内网服务器。 外部客户端，发送始终是向网关服务器发送请求，根本不知道网关服务器是否转发的请求报文，因此达到了隐藏内网服务器的目的。 我们可以在内网部署多台 web 服务器，让 iptables 将请求转发到不同的内网服务器上，此时就实现了负载均衡的功能。只不过 iptables 的负载均衡功能已经独立为 lvs，并提供了更加丰富的功能，而不再由 dnat 实现。 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:2:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"3. 本机端口映射 还有一种情形，比如本地的 tomcat 监听载 8080 端口上，但是http 默认是 80 端口，为了让客户端可通过 80 端口直接能请求到web 服务而不用修改默认端口，此时我们需要在本机做一个端口映射；将 80 端口的请求转发至 8080 上。本机端口映射是通过 iptables REDIRECT 扩展实现的。 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:3:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"4. iptables nat 实现 iptables 实现地址转换，只需要使用 nat 特用的 target(处理动作即可) SNAT: -j SNAT options 作用: 源地址转换 选项: --to-source [ipaddr[-ipaddr]][:port[-port]]: 指定源端口和地址 DNAT: -j DNAT options 作用: 目标地址转换 选项: --to-destination [ipaddr[-ipaddr]][:port[-port]] 指定目标端口和地址 MASQUERADE: -j MASQUERADE 作用: 源地址转换，当主机的 ip 是动态获取时，会自动指定源地址 REDIRECT: -j REDIRECT options 作用: 端口重定向，做端口映射 选项: --to-ports port[-port] 指定源端口 # SNAT示例： \u003e iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j SNAT --to-source 172.16.100.67 # MASQUERADE示例： # 源地址转换：当源地址为动态获取的地址时，MASQUERADE可自行判断要转换为的地址； \u003e iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j MASQUERADE # DNAT示例 \u003e iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j DNAT --to-destination 192.168.12.77 \u003e iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 22012 -j DNAT --to-destination 192.168.12.78:22 # REDIRECT \u003e iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j REDIRECT --to-ports 8080 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:4:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"5. dnat 于 filter 在 dnat 的网关服务器上对转发报文做过滤时，由于 dnat 已经在 PREROUTING 上将报文的目标地址转和端口转换为了内网服务器地址和端口，因此在设置过滤条件时应该使用内网服务器地址作为过滤条件，而不是网关地址。 ","date":"2018-04-02","objectID":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/:5:0","tags":["马哥 Linux"],"title":"21.5 nat路由","uri":"/posts/linux/linux_mt/24-iptables/nat%E8%B7%AF%E7%94%B1/"},{"categories":["Linux"],"content":"21.4 网络防火墙配置","date":"2018-04-01","objectID":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"21.4 网络防火墙配置","uri":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"网络防火墙配置 前面我们讲解了 iptables 命令的使用，其中主要是以配置主机防火墙作为示例，本节将来介绍如何配置一个网络防火墙。iptables 命令的使用没变，只是网络防火墙配置载 forward 链上有一些额外注意的事项。 1. 网络防火墙配置 在进行网络防火墙配置之前，我们首先需要规划一下网络拓扑结构，好方便解说 iptables 命令的作用。 如上图所示，左半部分是我们模拟的内网，右半部分是模拟的公网，在使用 virtualbox 或 vimware 模拟上述网络时，有以下几点需要注意: 内网的网卡类型选择仅主机或 nat 网络，外网的网卡选择桥接。有关虚拟网卡的几种类型请参考 24.7 虚拟网卡类型 为使得从外网 192.168.1.10 返回的响应能到达我们的内网，需要将其网关指向 192.168.1.168,或者手动添加路由条目将，发往 172.16.0.0/24 的报文的下一跳设置成 192.168.1.168 需要打开中间的网络防火墙的核心转发功能 为测试防火墙，配置，我们需要在 172.16.0.2 和 192.168.1.10 上均配置好 httpd,vsftpd 等服务 # 添加路由 route add -net 172.16.0.0/24 gw 192.168.1.168 # 打开ia核心转发 sysctl -w net.ipv4.ip_forward=1 ","date":"2018-04-01","objectID":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"21.4 网络防火墙配置","uri":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 放行 httpd 防火墙 filter 功能只能添加在 INPUT FORWARD OUTPUT 链上，对于网络防火墙而言，报文只会经过 FORWARD 链，因此网络防火墙只能配置在 FORWARD 链上。一次 http 事务包括请求和响应两个过程，因此我们需要在 FORWARD 上同时添加发送请求和接收响应两个方向的规则。下面是配置示例，我们的目的是，内网的主机能访问所有的外网主机，但外网主机仅能访问内网的 httpd,ftp 服务。 modprobe nf_conntrack_ftp # 设置默认策略为拒绝 $ iptables -A FORWARD -j DROP # 开放 80 端口 $ iptables -I FORWARD -s 172.16.0.0/24 -p tcp --dport 80 -j ACCEPT $ iptables -I FORWARD 2 -d 172.16.0.0/24 -p tcp --sport 80 -j ACCEPT # 开放 ftp $ iptables -R FORWARD 3 -s 172.16.0.0/24 -p tcp -m state --stat RELATED -j ACCEPT $ iptables -R FORWARD 4 -p tcp -d 172.16.0.0/24 -m state --state ESTABLISHED -j ACCEPT ","date":"2018-04-01","objectID":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"21.4 网络防火墙配置","uri":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 基于连接追踪机制配置 使用连接追踪机制，可以让 iptables 规则更加简单 # 开放内网到外网的所有请求 $ iptables -A FORWARD -j DROP # 1. 开放已经建立的连接 $ iptables -R FORWARD 1 -p tcp -m state --state ESTABLISHED -j ACCEPT # 2. 开放由内到外的新连接,此时 ftp 也可访问，因为 RELATED 也是 NEW 连接 $ iptables -I FORWARD 2 -p tcp -s 172.16.0.0/24 -m state --state NEW -j ACCEPT # 开放外网到内网特定主机的 80 访问 $ iptables -I FORWARD 2 -d 172.16.0.10 -p tcp --dport 80 -m state --state NEW -j ACCEPT ","date":"2018-04-01","objectID":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"21.4 网络防火墙配置","uri":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. 利用 iptables 抵御 DOS 攻击 利用iptables的recent模块来抵御DOS攻击: 建立一个列表，保存有所有访问过指定的服务的客户端IP ssh: 远程连接， # one \u003e iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 3 -j DROP # two \u003e iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH # three \u003e iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j LOG --log-prefix \"SSH Attach: \" # four \u003e iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP # 也可以使用下面的这句记录日志： \u003e iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --name SSH --second 300 --hitcount 3 -j LOG --log-prefix \"SSH Attack\" one: two: 利用connlimit模块将单IP的并发设置为3；会误杀使用NAT上网的用户，可以根据实际情况增大该值； 第二句是记录访问tcp 22端口的新连接，记录名称为SSH –set 记录数据包的来源IP，如果IP已经存在将更新已经存在的条目 three 利用recent和state模块限制单IP在300s内只能与本机建立2个新连接。被限制五分钟后即可恢复访问。 four: 第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接。 –update 是指每次建立连接都更新列表； –seconds必须与–rcheck或者–update同时使用 –hitcount必须与–rcheck或者–update同时使用 附注: iptables的记录：/proc/net/xt_recent/SSH ","date":"2018-04-01","objectID":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"21.4 网络防火墙配置","uri":"/posts/linux/linux_mt/24-iptables/%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"21.3 iptables扩展匹配","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"iptables扩展匹配 上一节我们基本上把 iptables 基本使用方法讲完了，而且我们提到过 iptables 是高度模块化的，为在报文匹配和处理动作提供了很多扩展模块，本节我们就来介绍这些扩展模块的使用。可以使用如下命令查看这些扩展模块的帮助信息 # CentOS 6 man iptables # CentOS 7 man iptables-extensions rpm -ql iptables|grep '[[:lower:]]\\+\\.so$' ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:0:0","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1. iptables 可用显示扩展 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:0","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.1 multiport扩展 作用: 以离散方式定义多端口匹配；最多指定15个端口； 参数: [!] --source-ports,--sports port[,port|,port:port]…：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]…：指定多个目标端口； [!] --ports port[,port|,port:port]…：指明多个端口； \u003e iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -j ACCEPT \u003e iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp -m multiport --sports 22,80 -j ACCEPT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:1","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.2 iprange扩展 作用: 指明连续的（但一般不能扩展为整个网络）ip地址范围； 参数: [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； \u003e iptables -A INPUT -d 172.16.100.67 -p tcp --dport 80 -m iprange --src-range 172.16.100.5-172.16.100.10 -j DROP \u003e iptables -I INPUT -d 172.16.100.67 -p tcp -m multiport 22:23,80 -m iprange --src-range 172.16.100.1-172.168.100.120 -j ACCEPT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:2","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.3 string扩展 作用: 对报文中的应用层数据做字符串模式匹配检测； 参数: --algo {bm|kmp}：字符串匹配检测算法； bm：Boyer-Moore kmp：Knuth-Pratt-Morris [!] --string pattern：要检测的字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制格式； \u003e iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp --sport 80 -m string --algo bm --string \"gay\" -j REJECT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:3","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.4 time扩展 作用: 根据将报文到达的时间与指定的时间范围进行匹配； 参数: --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestart hh:mm[:ss] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核上的时区，而非默认的UTC； \u003e iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:4","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.5 connlimit扩展 作用: 根据每客户端IP(也可以是地址块)做并发连接数数量匹配； 参数: --connlimit-upto n：连接的数量小于等于n时匹配； --connlimit-above n：连接的数量大于n时匹配； \u003e iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m connlimit --connlimit-above 2 -j REJECT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:5","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"1.6 limit扩展 作用: 基于收发报文的速率做匹配，匹配的发送报文数，而不是报文大小 原理: 令牌桶过滤器，进程在发送报文之前必需获取令牌，一个报文一个，通过限制令牌的发放速率达到限制报文发送速率 参数: --limit rate[/second|/minute|/hour|/day]: 报文发送的速率 --limit-burst number: 进程在空闲时可收集的最大令排数 \u003e iptables -I INPUT -d 172.16.100.67 -p icmp --icmp-type 8 -m limit --limit 30/minute --limit-burst 5 -j ACCEPT \u003e iptables -I INPUT 2 -p icmp -j REJECT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:1:6","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2. state扩展 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:0","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2.1 连接追踪 iptables 的 state 会启动内核的连接追踪机制，即内核在会在内存中记录一段时间内与主机通信过的主机，这样在相应主机再次访问本机时，就能追踪其连接状态。iptables 就能根据”连接追踪机制“去检查连接的状态。连接追踪与通信协议没有任何关系，是内核记录连接状态的一种机制，它有如下几种状态: NEW：新发出请求；连接追踪模板中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求； ESTABLISHED：NEW状态之后，连接追踪模板中为其建立的条目失效之前期间内所进行的通信状态； RELATED：相关联的连接；如ftp协议中的数据连接与命令连接之间的关系； INVALID：无效的连接； UNTRACKED：未进行追踪的连接 连接追踪有时长限制，如果一条连接在设置的时长范围内没有再次发生连接，此连接记录就会被删除。下此与对应的主机再次建立连接时就会被当作新连接被重新记录。连接追踪机制非常耗费内容，如果连接追踪占据了所有的内存，新的连接就无法建立，因此不要在连接非常繁忙的反代服务器上开启连接追踪机制。如果一定要开启连接追踪机制，一是要准备足够大的内存，二是调大 nf_conntrack_max 的值。 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:1","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2.2 连接追踪相关配置 内核会在如下文件中记录连接追踪相关的信息: /proc/net/nf_conntrack: 作用: 已经追踪到并记录下来的连接 /proc/sys/net/netfilter/nf_conntrack_max 作用: 连接追踪功能所能够容纳的最大连接数量的配置文件 注意: 在一个非常繁忙的服务器上，一是要准备足够大的内存，二是将此配置调大 /proc/sys/net/netfilter/*timeout*: 不同的协议的连接追踪时长 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:2","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2.3 state 扩展 作用: 对连接追踪的状态做匹配 参数: [!] --state state 配置: \u003e iptables -A INPUT -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT \u003e iptables -A OUTPUT -s 172.16.100.67 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT \u003e iptables -I OUTPUT -m state --state ESTABLISHED -j ACCEPT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:3","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2.4 state 扩展相关问题 iptables的链接跟踪表最大容量为/proc/sys/net/netfilter/nf_conntrack_max配置的值， 链接碰到各种状态的超时后就会从表中删除；当内存满载时，后续的连接可能会超时 解決方法一般有两个： 加大 nf_conntrack_max 值 降低 nf_conntrack timeout时间 # 加大 nf_conntrack_max 值 vi /etc/sysctl.conf net.ipv4.nf_conntrack_max = 393216 net.ipv4.netfilter.nf_conntrack_max = 393216 # 降低 nf_conntrack timeout时间 vi /etc/sysctl.conf net.ipv4.netfilter.nf_conntrack_tcp_timeout_established = 300 net.ipv4.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 net.ipv4.netfilter.nf_conntrack_tcp_timeout_close_wait = 60 net.ipv4.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120 iptables -t nat -L -n ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:4","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"2.5 如何开放被动模式的ftp服务 装载ftp连接追踪的专用模块： 放行命令连接(假设Server地址为172.16.100.67)： 放行数据连接(假设Server地址为172.16.100.67)： # 1. 装载ftp连接追踪的专用模块 \u003e modinfo /lib/modules/3.10.0-514.el7.x86_64/kernel/net/netfilter/nf_conntrack_ftp \u003e modproble nf_conntrack_ftp \u003e lsmod # 2. 放行请求报文 # 命令连接: NEW, ESTABLISHED # 数据连接: RELATED(仅数据连接的第一次连接建立), ESTABLISHED \u003e iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state **NEW,ESTABLISHED** -j ACCEPT \u003e iptables -A OUTPUT -s 172.16.100.67 -p tcp --sport 21 -m state --state ESTABLISHED -j ACCEPT # 3. 放行响应报文 ESTABLISHED \u003e iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state **RELATED,ESTABLISHED** -j ACCEPT \u003e iptables -I OUTPUT -s 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT # 4. 合并 iptables 规则 iptables -t filter -A INPUT -m --state ESTABLISHED,RELATED -j ACCEPT iptables -t filter -A INPUT -p tcp -d 192.168.1.108 -m multiport --dports 21,22,80 -m state --state NEW -j ACCEPT iptable -t filter -A OUTPUT -m --state ESTABLISHED -j ACCEPT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:2:5","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"3. iptables 规则管理 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:0","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"3.1 规则优化 我们已经学习了很多 iptables 的扩展模块，有一些通用原则可以帮助我们优化 iptables 的规则 使用自定义链管理特定应用的相关规则，模块化管理 可安全放行所有入站的状态为ESTABLISHED状态的连接； 可安全放行所有出站的状态为ESTABLISHED状态的连接； 谨慎放行入站的新请求 有特殊目的限制访问功能，要于放行规则之前加以拒绝； 载规则的最后自定义默认策略，而不是直接使用 iptables 的默认策略，放置意外将 iptables 规则清空导致 ssh 无法连接至服务器 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:1","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"3.2 自定义链 自定义链需要被内置链调用才能生效，且自定义链最后需要定义返回内置链。返回规则使用的处理动作叫做 RETURN，默认自定义链最后会自动 return 到调用链，提前返回需要提前显示 return。下面是自定义链的一个示例 $ iptables -N ping_rule # 创建自定义链 # 向自定义链添加规则 $ iptables -A ping_rule -d 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT # 被内置链调用 $ iptables -A INPUT -d 192.168.1.168 -p icmp -j ping_rule $ iptales -L ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:2","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"3.3 规则的保存及重载 使用iptables命令定义的规则，会立刻送往内核，手动删除之前，其生效期限为kernel存活期限。永久保存需要手动保存规则至指定的文件中，需要时可重载保存于文件中的规则。 iptables-save iptables-save \u003e path: 作用: 输出当前的 iptables 规则至终端，保存至文件需要重定向 iptables-restore iptables-restore options \u003c path 作用: 重载文件中的 iptables 规则 选项: -n --noflush: 默认会清除已有规则，此选项表示不清除已有规则，只追加 -t --test: 仅分析生成规则集，不提交 # 1. 保存规则 # CentOS 6： iptables-save \u003e /PATH/TO/SOME_RULES_FILE service iptables save # 将规则保存至/etc/sysconfig/iptables文件中； # CentOS 7: iptables-save \u003e /PATH/TO/SOME_RULES_FILE # 2. 重载规则: 重新载入预存规则文件中的规则 iptables-restore \u003c /PATH/FROM/SOME_RULES_FILE service iptables restart # 从 /etc/sysconfig/iptables文件中重载规则，仅限于Centos6 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:3","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"3.4 iptables 规则开机自动载入 Centos 6 Centos 中 iptables 是独立的服务，其管理配置如下所示 # 开机启动 iptables chkconfig iptables on # iptables 服务启动脚本 /etc/rc.d/init.d/iptables # iptables 规则的默认配置文件 /etc/sysconfig/iptables # iptables 服务的配置文件 /etc/sysconfig/iptables-config IPTABLES_MODULE=\" # 此选项配置要装载的模块 # 开机自动导入可用脚本保存各iptables命令；让此脚本开机后自动运行； # 或者载自定义脚本中使用 iptables-restore 重载规则文件即可 CentOS 7 Centos7 引入了新的iptables前端管理服务工具 firewalld，其包括很多管理工具，比如 firewalld-cmd，firewalld-config。其详细使用方式参见文档: http://www.ibm.com/developerworks/cn/linux/1507_caojh/index.html 所以在 Centos7 中实现规则开机自动载入，可以 编写 Unit 配置文件通过 systemctl 调用 iptables-restore 实现 借助于 firewalld 编写脚本，对于 iptables，最好还是使用此种方式，而且最好不要开机自动载入以免产生问题 ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:4","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"5. 练习 练习：INPUT和OUTPUT默认策略为DROP； 1、限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机； 2、在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.16.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个； 3、开放本机的ssh服务给172.16.x.1-172.16.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机； 4、拒绝TCP标志位全部为1及全部为0的报文访问本机； 5、允许本机ping别的主机；但不开放别的主机ping本机； 练习：判断下述规则的意义： # iptables -N clean_in # iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP # iptables -A clean_in -d 172.16.255.255 -p icmp -j DROP # iptables -A clean_in -p tcp ! --syn -m state --state NEW -j DROP # iptables -A clean_in -p tcp --tcp-flags ALL ALL -j DROP # iptables -A clean_in -p tcp --tcp-flags ALL NONE -j DROP # iptables -A clean_in -d 172.16.100.7 -j RETURN # iptables -A INPUT -d 172.16.100.7 -j clean_in # iptables -A INPUT -i lo -j ACCEPT # iptables -A OUTPUT -o lo -j ACCEPT # iptables -A INPUT -i eth0 -m multiport -p tcp --dports 53,113,135,137,139,445 -j DROP # iptables -A INPUT -i eth0 -m multiport -p udp --dports 53,113,135,137,139,445 -j DROP # iptables -A INPUT -i eth0 -p udp --dport 1026 -j DROP # iptables -A INPUT -i eth0 -m multiport -p tcp --dports 1433,4899 -j DROP # iptables -A INPUT -p icmp -m limit --limit 10/second -j ACCEPT ","date":"2018-03-31","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/:3:5","tags":["马哥 Linux"],"title":"21.3 iptables扩展匹配","uri":"/posts/linux/linux_mt/24-iptables/iptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D/"},{"categories":["Linux"],"content":"21.2 iptables使用入门","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"iptables使用入门 iptables 是防火墙规则的管理工具，使用复杂，但是也有规律可循，个人总结起来就是\"在哪，对什么报文，作出什么样的处理\"。 iptables 有四表五链，首先要确定在iptables 的哪个表，哪个链条添加规则，这取决于要实现的功能和报文的流经途径 规则添加就是要对我们要处理的报文作出处理，因此就要指定报文的匹配条件和处理动作。 个人觉得按照这样的逻辑去记忆能比较容易记住 iptables 的使用方式。下面我们就来详细介绍 iptables 的使用 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. iptables 命令简介 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 规则配置原则 iptables 会按照链上的规则每次从上至下依次检查，如果报文匹配并作出处理，那么就不会继续匹配接下来的规则。因此这样的检查次序隐含一定的应用法则： 同类规则（访问同一应用），匹配范围小的放上面； 不同类的规则（访问不同应用），匹配到报文频率较大的放在上面； 将那些可由一条规则描述的多个规则合并起来； 设置默认策略； 这些应用原则其实很好懂，将频率高的放在最上面是为了减少匹配的次数，匹配范围小的放上面是为了让范围小的规则优先生效，很容易明白。 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.2 命令组成 iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 iptables 命令组成如上所示: -t: 指定操作的表，默认为 filter chain: 指定操作的链 [-m matchname [per-match-options]]: 指定匹配条件，根据协议报文特征进行报文筛选，分为 基本匹配条件: iptables 内置，不会使用扩展模块，不需要 -m 选项指定模块 扩展匹配条件: 需要使用 -m 选项指定使用的扩展模块 -j targetname [per-target-options]: 指定处理动作，可分为: 基本处理动作: iptables 内置的处理动作 扩展处理动作: 通过扩展模块扩展的处理动作 自定义处理机制: 通常指的是自定义链 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.3 iptables 的扩展机制 iptables 是高度模块化的，可以通过扩展模块更细粒度设置匹配条件和处理动作，这就是上面所说的扩展匹配条件和扩展处理动作。 $ rpm -ql iptables |grep xtables /usr/lib64/xtables/libip6t_MASQUERADE.so # IPv6 的扩展模块 /usr/lib64/xtables/libip6t_REDIRECT.so /usr/lib64/xtables/libip6t_REJECT.so /usr/lib64/xtables/libip6t_SNAT.so ..... /usr/lib64/xtables/libip6t_ah.so /usr/lib64/xtables/libip6t_dst.so /usr/lib64/xtables/libip6t_eui64.so ..... /usr/lib64/xtables/libipt_MASQUERADE.so # IPv4 扩展模块 /usr/lib64/xtables/libipt_MIRROR.so ...... /usr/lib64/xtables/libxt_CT.so # libxt /usr/lib64/xtables/libxt_DSCP.so /usr/lib64/xtables/libxt_HMARK.so ..... iptables 扩展模块的命名机制: 小写子母命名的是匹配条件 大写子母命令的是处理动作 libip6t 开头的对应于 IPv6 协议 libxt 和 libxt 开头的对应于 IPv4 协议 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:1:3","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.4 iptables 自定义链 iptables的链分为内置链和自定义链 内置链：对应于netfilter 的勾子函数(hook function) 自定义链接：用于内置链的扩展和补充，可实现更灵活的规则管理机制；但报文不会经过自定义链，只能在内置链上通过规则进行引用后生效 有了这些基本介绍，我们现在开始介绍 iptables 的详细使用。 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:1:4","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2. iptables 命令使用 iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:2:0","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.1 基本命令 iptables [-t table] COMMAND chain -t: 指定操作的表，默认为 filter (raw, mangle, nat, filter) chain: 指定操作的链(PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING) COMMAND: 字命令 链管理： -N：new, 自定义一条新的规则链； -X：delete，删除自定义的空的规则链，链非空或被其他链引用无法删除 -Z：zero，将规则计数器置零； -F：flush，清空指定的规则链；省略表示清空指定表上的所有链 -P：Policy，为指定链设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 REJECT：拒绝 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除； 规则管理： -A：append，追加； -I：insert, 插入，要指明位置，省略时表示第一条； -D：delete，删除； 指明规则序号； 指明匹配条件； -R：replace，替换指定链上的指定规则； 查看： -L：list, 列出指定鏈上的所有规则； -n：numberic，以数字格式显示地址和端口号(不对ip地址进行反解)； -v：verbose，详细信息，还有-vv, -vvv选项显示更详细的信息 -x：exactly，显示计数器结果的精确值； --line-numbers：显示规则的序号； 注意: -nvL 可以，-Lnv 不可以，因为 -L 是命令，其他的是 -L 的选项 $ sudo iptables -L -nv Chain INPUT (policy ACCEPT 1368 packets, 8346K bytes) pkts bytes target prot opt in out source destination 0 0 ACCEPT udp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 udp dpt:53 0 0 ACCEPT tcp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:53 iptables的每条规则都有两个计数器： pkts: 统计匹配到的报文的个数； bytes: 匹配到的所有报文的大小之和； COMMAND 子命令格式 # rule-specification = [matches...] [target] # match = -m matchname [per-match-options] # target = -j targetname [per-target-options] iptables [-t table] {-A|-C|-D} chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] {-F|-L|-Z} [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:2:1","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.2 匹配条件： [-m matchname [per-match-options]] 基本匹配条件：无需加载任何模块，由iptables/netfilter自行提供； 扩展匹配条件： 需要加载扩展模块，方可生效； 基本匹配条件 [!] -s, --source address[/mask][,...]： 作用: 检查报文中的源IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -d, --destination address[/mask][,...]： 作用: 检查报文中的目标IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -p, --protocol {tcp|udp|icmp}： 作用: 检查报文中的协议，即ip 首部中的 protocols 所标识的协议 protocol: tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh or “all” [!] -i, --in-interface IFACE： 作用: 数据报文流入的接口；只能应用于数据报文流入的环节，只能应用于PREROUTING，INPUT和FORWARD链； [!] -o, --out-interface IFACE： 作用: 数据报文流出的接口；只能应用于数据报文流出的环节，只能应用于FORWARD、OUTPUT和POSTROUTING链 扩展匹配条件 扩展匹配条件可分为显示扩展和隐式扩展两种: 显式扩展：必须要手动加载扩展模块， [-m matchname [per-match-options]]； 隐式扩展：不需要手动加载扩展模块；因为它们是对协议的扩展，所以，但凡使用-p指明了协议，就表示已经指明了要扩展的模块； 常见协议的隐式扩展如下所示: tcp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； [!] --tcp-flags list1 list2 作用: 检查list1 所指明的所有标志位，且这其中，list2 所列出的标志位必须为1，余下的必须为0，没在 list1 指明的，不做检查 例如：--tcp-flags SYN,ACK,FIN,RST SYN表示，要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0； [!] --syn：用于匹配第一次握手，相当于--tcp-flags SYN,ACK,FIN,RST SYN； 说明: 有关 tcp 连接的标识位，详见 24.8 tcp 协议简述 udp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； icmp [!] --icmp-type {type[/code]|typename} echo-request：ping 命令发送的请求的 icmp-type 为 8 echo-reply：ping 命令响应的 icmp-type 为 0 # 允许 ssh 连接 \u003e iptables -t filter -A INPUT -d 192.168.1.105 -p tcp [-m tcp] --dport 22 -j ACCEPT \u003e iptables -t filter -A OUTPUT -s 192.168.1.105 -p tcp [-m tcp] --sport 22 -j ACCEPT # 允许 ping 出，不允许 ping 入 \u003e iptables -A OUTPUT -s 192.168.1.105 -p icmp --icmp-type 8 -j ACCEPT \u003e iptables -A INPUT -d 192.168.1.105 -p icmp --icmp-type 0 -j ACCEPT # 通过规则设置默认策略 \u003e iptables -P INPUT ACCEPT \u003e iptables -P OUTPUT ACCEPT \u003e iptables -F \u003e iptables -A INPUT -d 192.168.1.168 -p tcp --dport 22 -j ACCEPT \u003e iptables -A OUTPUT -s 192.168.1.168 -p tcp --sport 22 -j ACCEPT \u003e iptables -A OUTPUT -s 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT \u003e iptables -A INPUT -d 192.168.1.168 -p icmp --icmp-type 0 -j ACCEPT \u003e iptables -A INPUT -i enp0s3 -j DROP \u003e iptables -A OUTPUT -o enp0s3 -j DROP \u003e # iptables -L -nv Chain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 659 49584 ACCEPT tcp -- * * 0.0.0.0/0 192.168.1.168 tcp dpt:22 2 168 ACCEPT icmp -- * * 0.0.0.0/0 192.168.1.168 icmptype 0 10 677 DROP all -- enp0s3 * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 311 30248 ACCEPT tcp -- * * 192.168.1.168 0.0.0.0/0 tcp spt:22 2 168 ACCEPT icmp -- * * 192.168.1.168 0.0.0.0/0 icmptype 8 18 1304 DROP all -- * enp0s3 0.0.0.0/0 0.0.0.0/0 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:2:2","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.3 处理动作： -j targetname [per-target-options] ACCEPT: 接受 DROP: 丢弃 REJECT: 拒绝 RETURN: 返回调用链 REDIRECT: 端口重定向 LOG: 记录日志 MARK: 做防火墙标记 DNAT: 目标地址转换 SNAT: 源地址转换 MASQUERADE: 地址伪装 自定义链: 由自定义链上的规则进行匹配检查 …… REJECT REJECT --reject-with --reject-with 设置拒绝连接的原因 可选值: icmp6-no-route, no-route, icmp6-adm-prohibited, adm-prohibited, icmp6-addr-unreachable, addr-unreach, or icmp6-port-unreachable, 默认为 icmp-port-unreach‐able LOG LOG options 作用: 记录日志，默认日志保存于 /var/log/messages 选项: --log-level: 记录的日志级别 --log-prefix: 在日志前增加的前缀 # 记录 telnet 连接 $ iptables -I INPUT -d 192.168.1.168 -p tcp --dport 23 -m state --state NEW -j LOG ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:3:0","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"课后作业 开放本机web服务器给非192.168.0.0/24网络中的主机访问 禁止本机被非172.16.0.0/16网络中的主机进行ping请求 开放本机的dns服务给所有主机 ","date":"2018-03-30","objectID":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/:3:1","tags":["马哥 Linux"],"title":"21.2 iptables使用入门","uri":"/posts/linux/linux_mt/24-iptables/iptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"21.1 Linux防火墙基础理论","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"Linux防火墙基础理论 对于大多数人包括我自己在内，在未了解防火墙之前，防火墙是一个非常抽象的存在，只知道它能保护我们的计算机免受入侵；但是对于它是什么怎么工作的完全不知道。本章我们就来学习 Linux 的防火墙，对其一窥究竟。本章我们会首先介绍Linux 防火墙的理论，让大家清楚防火墙是什么，以及其工作原理，然后再来学习怎么写防火墙的过滤规则。本章内容包含如下: Linux 防火墙的理论基础 iptables 命令的使用 实现 nat 功能 要想说清楚防火墙的工作机制并不容易，需要从网络通信说起，我们首先得明白网络通信都是通过 TCP/IP 协议进行得，无论是正常得请求响应还是非法得入侵首先必需与我们得主机建立通信，而我们得防火墙就是在数据包到达本机之后，在报文得必经之地设下\"管卡\"，利用我们设置得过滤对报文进行检查，放行我们允许得数据报文，阻挡可疑得报文以达到保护主机得目的。所以 Linux 中得防火墙又称为包过滤型的防火墙。下面我们就来详细解释防火墙得工作机制，本节内容包括: Linux 防火墙工作机制 Linux 防火墙 Firewall 简介 iptables 的四表五链 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:0:0","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1. 防火墙工作机制 (图一摘录自: http://bubufx.com/detail-1702595.html) (图一摘录自: 原作者不详) 上面两幅图很好的展示了Linux 防火墙的工作机制，说清楚第一幅图也就说清楚了防火墙的工作机制。 报文解析位于内核空间 前面我们说过 TCP/IP 协议可分为 4 层，应用层，传输层，网络层和物理层；应用层属于资源子网位于用户空间，用于确定数据的组织形式，其他三层属于传输子网位于内核空间，用于传输数据。网络协议报文的封装，拆封装，路由决策都位于内核空间，由内核提供。 报文流向 报文到达我们的主机时，首先经由网卡进入内核，内核解析 IP 报文首部得到报文的目标主机，此时发生第一路由决策。如果目标 IP 与本机 IP 相同，则该报文是发往本机，此时需要进一步拆封装传输层首部得到报文的目标端口，将其发送至注册使用此端口的进程，报文进入用户空间。这是图一中 1-\u003e2 标识的过程。 如果目标 IP 与本机 IP 不同，并且本机打开了路由转发功能，则需要将报文转发至其它主机，此时将发生第次二路由决策，因为本机可能由多块网卡，需要根据路由表决定由哪块网卡发出报文。这是图一中 1-\u003e4-\u003e5 标识的过程。 报文也可能经由本机发出，此时也将发生第二次路由决策，内核需要更据目标 IP和路由表决定报文由哪块网卡发出，这是图一中 3-\u003e5 标识的过程。 防火墙位于报文的必经之处 流经本机的报文只有三个方向: 发往本机进入用户空间 流经本机，需要转发至其他主机 由本机发出 而防火墙就是在报本的必经之处设置了勾子(hook)，我们可以在勾子上添加规则，防火墙就可以根据我们设置的规则对报文进行过滤，以达到保护主机的功能。因此防火墙由两个部分组成: netfilter: 提供防火墙框架，位于内核中，提供了钩子函数(hook function),勾子位于图一中1-5标识的五个位置 iptables: 防火墙规则管理工具，便于用户向钩子函数添加规则。这部分是可有可无的，因为 netfilter 提供了系统调用接口，可以直接调用该系统调用向勾子添加规则，iptables 只是一个辅助工具。 netfilter 提供的勾子(hook function)在 iptables 中称为链，勾子跟链是一一对应的，链是勾子名称的大写而已。 勾子–\u003e链 prerouting -\u003e PREROUTING: 报文进入主机，并在第一次路由之前 input -\u003e INPUT: 进入用户空间之前 forward -\u003e FORWARD: 转发 output -\u003e OUTPUT: 由本机发出，并在第二次路由之前 postrouting -\u003e POSTROUTING: 报文离开主机，并在第二次路由之后 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:1:0","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"总结 因此报文的流向可以总结为: 流向 途径的链 流入本机 PREROUTING --\u003e INPUT 由本机流出 OUTPUT --\u003e POSTROUTING 转发 PREROUTING --\u003e FORWARD --\u003e POSTROUTING 而路由发生在： 报文进入本机后：判断目标主机是谁 报文离开本机之前：判断经由哪个接口送往下一站 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:1:1","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2. Firewall 简介 现在我们可以对防火墙下一个定义了。防火墙是一种隔离工具，工作于主机或网络边缘，对于进出本主机或本网络的报文根据事先定义的检查规则作匹配检测，对于能够被规则匹配到的报文作出相应处理的组件。 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:2:0","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.1 分类和版本 Firewall 在 Linux 已经迭代了三个版本，详细的信息大家可以查阅其他资料 ipfw (firewall framework) ipchains (firewall framework) iptables(netfilter) netfilter：位于 kernel，是防火墙框架，提供 hook functions iptables：rules until，防火墙规则管理工具 按照防火墙提供的功能可以将防火墙分为: 主机防火墙: 位于主机上，仅为当前主前主机提供防火墙功能 网络防火墙: 位于默认网关之上，为局域网内的所有主机提供防火墙功能。 也可以按照防火墙实现的方式分成: 软件防火墙（软件逻辑） 硬件防火墙（硬件和软件逻辑) ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:2:1","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.2 功能 防火墙除了过滤功能外，还有其他功能，并且不同功能之间具有不同的优先级，优先级从高到低如下所示: filter：过滤，防火墙； nat：network address translation；用于修改源IP或目标IP，也可以改端口； mangle：拆解报文，做出修改，并重新封装起来； raw：关闭nat表上启用的连接追踪机制； ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:2:2","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2.3 四表五链 防火墙提供的功能在 iptables 中被称为表，不同的功能只能工作于特定的链上，因此就有了 iptables 的四表五链 功能 工作的链 filter INPUT，FORWARD，OUTPUT nat PREROUTING(DNAT)，[INPUT，OUTPUT](少见)，POSTROUTING(SNAT) mangle PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING raw PREROUTING， OUTPUT iptables 规则添加就是要确定在哪个表的何处添加规则 要实现哪种功能: 判断添加在哪张表上 报文流经的路径: 判断添加在哪条链上 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:2:3","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3. Centos 的防火墙服务 ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:3:0","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.1 CentOS 6 service iptables {start|stop|restart|status} start：读取事先保存的规则，并应用到netfilter上； stop：清空netfilter上的规则，以及还原默认策略等； status：显示生效的规则； restart：清空netfilter上的规则，再读取事先保存的规则，并应用到netfilter上； 默认的规则文件：/etc/sysconfig/iptables ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:3:1","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.2 CentOS 7 Centos7 中默认的防火墙服务是 firewalld，这是在 iptables 基础上使用 python 编写的扩展，又一个图形化节界面，可以更方便的进行防火墙规则管理。因为内部仍然使用的 iptables，想根本的学会使用，还是要学习 iptables 的使用。 systemctl start|stop|restart|status firewalld.service # Linux 操作练习时建议关闭 systemctl disable firewalld.service systemctl stop firewalld.service ","date":"2018-03-29","objectID":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/:3:2","tags":["马哥 Linux"],"title":"21.1 Linux防火墙基础理论","uri":"/posts/linux/linux_mt/24-iptables/linux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"20.1 ftp基础入门","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"ftp基础入门 计算机上的磁盘设备有 SATA，SAS；IDE，SCSI；USB 等各种接口。以 SCSI 而言，SCSI 接口可以分线，一个接口可连接多个设备，我们的操作系统想要往磁盘上写数据时，需要标识哪块磁盘哪个位置。因此 SCSI 不仅代表一种硬盘，也代表了一种操作系统如和向磁盘读写数据的协议，而且与网络协议类似，这种协议是分层的。SCSI 协议结构如下图所示 因为协议是分层，所以如果将最底下的物理层替换为光纤，并通过 TCP/IP 协议进行网络传输，我们的磁盘设备就可以被互联网上的其他访问，从而达到共享存储的目的。对于 SCSI 大家不用太关心，只需要知道数据传输的协议都是分层的，我们可以通过替换底层的传输协议达到共享存储的目的，具体怎么实现大家无需关心。 类似于磁盘这种直接附加在总线上的的设备通常被称为 DAS(Direct Attached Storage)，DAS 输出给操作系统的接口是块(block),块可以被分区格式化。按照附加到操作系统的方式，我们将存储设备分成以下几个类别: DAS: Direct Attached Storage 接口类型：输出给操作系统的接口是\"块\" 设备：SATA，SAS；IDE，SCSI；USB； NAS: Network Attached Storage 接口类型: 输出给操作系统的接口是\"文件\" 依据传输数据的协议可以分为 CIFS: samba NFS: Network File System 说明: 这种方式就是我们可以把别人共享出来的文件系统直接挂载使用 SAN：Storage Area Network 存储区域网络 接口类型：“block” 协议：iSCSI(IP-SAN), FCSAN, FCoE, … 说明: 这种方式的实现方式就是类似与我们上述所说的，将 SCSI 协议底层的物理协议替换成 TCP/IP，让磁盘设备能够通过网络向其他主机输出块接口。而为了能够进行网络传输，原来的 SCSI 磁盘将被替换为一个主机，该主机负责向外输出存储。 ftp 不能视为为一种存储，因为其基本调用接口是不能在文件系统层级进行的，只能使用专门的客户端与其交互。ftp 是应用层协议实现的共享存储。本节我们就来依次介绍这几种服务: vsftpd NFS samba 需要注意的是，如果不是当网管上述几个服务用到的很少，所以我们只需要达到基本应用即可。 ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. ftp 简介 ftp 全称为 file transfer protocol，文件传输协议。ftp 诞生与互联网的早期，目标是完成文件传输，所以其传输数据的方式比较奇葩，本节我们就来对 ftp 做一个简单介绍。 ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 ftp 传输过程 如上图所示，ftp 的连接分为两类 命令连接：传输命令 数据连接：传输数据 当需要传输数据时，客户端向 ftp 服务端的 21 端口发起连接请求建立连接，此连接主要用来传输客户端的命令。然后命令的操作不能在当前连接上传输，必需新建一条连接进行数据传输。 数据连接的创建有两种模式(从服务端的角度看) 主动模式(PORT)：Server端向客户端发起连接请求，请求的端口为命令连接使用的端口向后的第一个可用端口发起连接请求 被动模式(PASV): Server端打开一个随机端口，并通过命令连接告知客户端，并等待客户端连接 数据传输完成后，数据连接即断开，下此传输时在重新建立连接。 ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.2 ftp 数据传输格式 ftp 不会使用 MIME 对数据进行编码，ftp 会自动根据要传输的数据是文本格式还是二进制格式来选择传输机制。 ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.3 ftp 的认证机制 Linux 上有一个提供认证的共享服务 PAM(Pluggable Authenticate Module),PAM 是一个认证框架包括各种库，是高度模块化的，我们 ftp 就是调用 PAM 的服务提供认证功能的。 $ rpm -ql pam /etc/pam.d /etc/pam.d/config-util /etc/pam.d/fingerprint-auth /etc/pam.d/other /etc/pam.d/password-auth /etc/pam.d/postlogin /etc/pam.d/smartcard-auth /etc/pam.d/system-auth /etc/security # pam 的模块目录,每一个模块可以实现一种认证功能 /usr/lib64/security /usr/lib64/security/pam_access.so /usr/lib64/security/pam_chroot.so ............ # 所有调用 pam 进行认证的服务如何进行认证，由此目录下的配置文件配置 /etc/pam.d /etc/pam.d/config-util /etc/pam.d/fingerprint-auth /etc/pam.d/other /etc/pam.d/password-auth /etc/pam.d/postlogin ...... ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:3","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.4 协议实现 ftp 是 C/S 架构的服务，其服务端与客户端的常见实现有 Server 端： Windows: Serv-U, IIS, Filezilla 开源：wuftpd, proftpd, pureftpd, vsftpd(Very Secure FTP daemon), … Client 端： Windows：ftp, Filezilla, CuteFTP, FlashFXP, … 开源：lftp, ftp, Filezilla, gftp, … ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:1:4","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2. vsftpd 简介 vsftpd 全称是非常安全的 ftp 服务，功能有限但是非常安全，是 Linux 上最常用的 ftp 服务的实现。 rpm -ql vsftpd $ rpm -ql vsftpd /etc/logrotate.d/vsftpd /etc/pam.d/vsftpd # pam 认证配置文件 /etc/vsftpd # 配置文件目录 /etc/vsftpd/ftpusers /etc/vsftpd/user_list /etc/vsftpd/vsftpd.conf # 配置文件 /etc/vsftpd/vsftpd_conf_migrate.sh /usr/lib/systemd/system-generators/vsftpd-generator /usr/lib/systemd/system/vsftpd.service # 作为独立服务 /usr/lib/systemd/system/vsftpd.target # 作为托管服务 /usr/lib/systemd/system/vsftpd@.service /usr/sbin/vsftpd ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:0","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.1 路经映射 ftp 也是通过 URL 进行资源定位的 SCHEME://username:password@HOST:PORT/PATH/TO/FILE。每个用户的URL的/映射到当前用户的家目录。yum 安装 vsftpd 时默认会创建 ftp 用户，vsftpd 以 ftp 用户的身份启动进程，默认用户即为ftp用户。匿名访问 ftp 服务时，匿名用户将自动映射为 ftp 用户。匿名用户又可称为 anonymous。所以匿名用户的/ 为 ftp 用户的家目录 /var/ftp/。 $ grep \"^ftp\" /etc/passwd ftp❌14:50:FTP User:/var/ftp:/sbin/nologin $ systemctl start vsftpd.service # 默认就是匿名用户登陆 $ lftp 192.168.1.106 lftp 192.168.1.106:~\u003e ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub # 使用 ftp 匿名登陆 $ lftp -u ftp 192.168.1.106 口令: lftp ftp@192.168.1.106:~\u003e ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub # 使用 anonymous 匿名登陆 $ lftp -u anonymous 192.168.1.106 口令: lftp anonymous@192.168.1.106:~\u003e ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:1","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.3 ftp 用户的权限 一个用户通过文件共享服务访问文件系统上的文件的生效权限为此用户在共享服务上拥有的共享权限与其在本地文件系统上拥有的权限的交集。 ","date":"2018-03-28","objectID":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/:2:2","tags":["马哥 Linux"],"title":"20.1 ftp基础入门","uri":"/posts/linux/linux_mt/23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1/ftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"19.4 MariaDB 权限管理","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"MariaDB 权限管理 本节我们来介绍 MariaDB 中的权限管理 ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"1. mysql 状态查询 前面我们学习了 DDL 与 DML，下面是 mysql 一些常用的状态查询语句，用于查看mysql 的各种状态和变量。 作用 sql语句 -可用配置查询- ———- 查看支持的所有字符集 SHOW CHARACTER SET 查看支持的所有排序规则 SHOW COLLATION 查看数据库支持的所有存储引擎类型 SHOW ENGINES; -表状态信息- ———— 查看表状态 SHOW TABLES STATUS [LIKE 'tbl_name']\\G 查看表上的索引的信息 SHOW INDEXES FROM tbl_name; 查看表结构 desc tbl_name; 查看表创建命令 show create table tbl_name; 查看指定用户所获得的授权 SHOW GRANTS FOR 'user'@'host' 查看指定用户所获得的授权 SHOW GRANTS FOR CURRENT_USER; ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:0:1","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2. DCL 用户账号及权限管理： ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2.1 用户账号 mysql的用户账号由两部分组成：'USERNAME'@'HOST' USER: 表示用户名称 HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务. HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 vim /etc/mysql/my.cnf # 添加三个选项： [mysqld] datadir = /mydata/data innodb_file_per_table = ON skip_name_resolve = ON # 配置禁止检查主机名 ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:1","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2.2 账号管理 创建用户账号：CREATE USER 'username'@'host' [IDENTIFIED BY 'password']; 删除用户账号：DROP USER ’user‘@’host' [, user@host] ... mysql mysql\u003e create user 'wpuser'@'%' identified by 'wppass'; mysql\u003e select * from mysql.user; ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:2","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2.3 授权 GRANT priv_type,... ON [object_type] db_name.tbl_name TO 'user'@'host' [IDENTIFIED BY 'password']; priv_type： 要授权的操作 ALL: 所有操作 db_name.tbl_name： 授权的范围 *.*：所有库的所有表； db_name.*：指定库的所有表； db_name.tbl_name：指定库的特定表； db_name.routine_name：指定库上的存储过程或存储函数 [object_type]: 授权可操作额对象 TABLE，默认 FUNCTION PROCEDURE mysql mysqsl\u003e grant select,delete on testdb.* to 'test'@'%' identified by 'testpass' mysql\u003e revoke delete on testdb.* from 'test'@'%'; ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:3","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"3.4 回收权限： REVOKE priv_type, ... ON db_name.tbl_name FROM 'user'@'host'; 注意：MariaDB服务进程启动时，会读取mysql库的所有授权表至内存中； GRANT或REVOKE命令等执行的权限操作会保存于表中，MariaDB此时一般会自动重读授权表，权限修改会立即生效； 其它方式实现的权限修改，要想生效，必须手动运行FLUSH PRIVILEGES命令方可； ","date":"2018-03-27","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:4","tags":["马哥 Linux"],"title":"19.4 MariaDB 权限管理","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"19.3 SQL DDL 与 DML","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"SQL DDL 与 DML SQL 是关系型数据库专用的结构化查询语言，用来管理和查询关系型数据库中的数据。本节我们就来学习基础的 SQL 语言。 ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:0:0","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"1. SQL 的分类 MariaDB [(none)]\u003e help contents You asked for help about help category: \"Contents\" For more information, type 'help \u003citem\u003e', where \u003citem\u003e is one of the following categories: Account Management Administration Compound Statements Data Definition Data Manipulation Data Types Functions Functions and Modifiers for Use with GROUP BY Geographic Features Help Metadata Language Structure Plugins Procedures Table Maintenance Transactions User-Defined Functions Utility 在 mysql 客户端内使用 help contents 可以查看到 SQL 语句的所有类别，最常用的是如下三类: DDL：Data Defined Language 作用: 数据定义语言，主要用于管理数据库组件，例如表、索引、视图、用户、存储过程 命令: CREATE、ALTER、DROP DML：Data Manapulating Language 作用: 数据操纵语言，主要用管理表中的数据，实现数据的增、删、改、查； 命令: INSERT， DELETE， UPDATE， SELECT DCL: 作用: 权限管理命令 命令: GRANT，REVOKE ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:1:0","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"2 MariaDB 中的数据类型 MariaDB 在存储数据之前，我们首先需要创建表，创建表的核心就是定义字段和取定表使用的字符集，而定义字段，关键的一步即为确定其数据类型。 数据类型用于确定数据存储格式、能参与运算种类、可表示的有效的数据范围。字符集就是码表，在字符和二进制数字之间建立映射关系，对于非英语系的国家字符集的设置至关重要。mysql 默认的字符集是 latin1，UTF8 在 mysql 中是 utf8mb4 而不是 utf8 show character set # 查看 mysql 支持的字符集 show collation # 查看字符集支持的排序方法 ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:2:0","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"2.1 数据类型 MariaDB 常见的数据类型如下所示: 字符型： 定长字符型： CHAR(#)：不区分字符大小写 BINARY(#)：区分字符大小写 变长字符型： VARCHAR(#)：不区分字符大小写 VARBINARY(#)：区分字符大小写 对象存储： TEXT：不区分字符大小写 BLOB：区分字符大小写 内置类型： SET ENUM 数值型： 精确数值型： INT（TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT) DECIMAL: 十进制数 近似数值型： FLOAT DOBULE 日期时间型： 日期型：DATE 时间型：TIME 日期时间型：DATETIME 时间戳：TIMESTAMP 年份：YEAR(2), YEAR(4)` ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:2:1","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"2.3 数据类型的修饰符 MariaDB 的数据类型还有修饰符的概念，用于限定字段属性，常见的修饰符如下所示: 所有类型修饰符： NOT NULL：非空； DEFAULT value：默认值； primary key unique key 整型修饰符: UNSIGNED：无符号 AUTO_INCREMENT: 自增 ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:2:2","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"3. DDL ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:3:0","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"3.1 数据库管理 # 1. 创建： CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name; [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name # 2. 修改： ALTER {DATABASE | SCHEMA} [db_name] [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name # 3. 删除： DROP {DATABASE | SCHEMA} [IF EXISTS] db_name # 4. 查看： SHOW DATABASES LIKE ’‘; ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:3:1","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"3.2 表管理： help create table 创建： CREATE TABLE [IF NOT EXISTS] tbl_name (create_defination) [table_options] create_defination: 字段：col_name data_type 键： PRIMARY KEY (col1, col2, …) UNIQUE KEY (col1, col2,…) FOREIGN KEY (column) 索引：KEY|INDEX [index_name] (col1, col2,…) table_options： ENGINE [=] engine_name 修改： ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name [alter_specification [, alter_specification] ...] alter_specification: 字段： 添加：ADD [COLUMN] col_name data_type [FIRST | AFTER col_name ] 删除：DROP [COLUMN] col_name 修改： CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER col_name] – 更改字段名称 MODIFY [COLUMN] col_name column_definition [FIRST | AFTER col_name] – 更改字段属性定义 ALTER [COLUMN] col_name [SETDEFAULT literal | DROP DEFAULT] – 更改字段默认值 键： 添加：ADD {PRIMARY|UNIQUE|FOREIGN} KEY (col1, col2,…) 删除： 主键：DROP PRIMARY KEY 外键：DROP FOREIGN KEY fk_symbol 索引： 添加：ADD {INDEX|KEY} [index_name] (col1, col2,…) 删除：DROP {INDEX|KEY} index_name 表选项：ENGINE [=] engine_name 删除： DROP TABLE [IF EXISTS] tbl_name [, tbl_name] ... 表创建的其他方式 # 1. 复制表结构； CREATE table like table_name; # 2. 复制表数据； CREATE table select_sql; ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:3:2","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"3.3 索引管理： 索引是特殊的数据结构,定义在查找时作为查找条件的字段上，实现快速查找 创建 CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [BTREE|HASH] ON tbl_name (col1, col2,,...)` 删除 DROP INDEX index_name ON tbl_name ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:3:3","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"4. DML： INSERT， DELETE， UPDATE， SELECT ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:4:0","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"4.1 INSERT INSERT [INTO] tbl_name [(col1,...)] {VALUES|VALUE} (val1, ...),(...),... 注意： 字符型：引号； 数值型：不能用引号； ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:4:1","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"4.2 SELECT： SELECT * FROM tbl_name; SELECT col1, col2, ... FROM tbl_name; 显示时，字段可以显示为别名: col_name AS col_alias SELECT col1, ... FROM tbl_name WHERE clause; WHERE clause：用于指明挑选条件； col_name 操作符 value： age \u003e 30; \u003e, \u003c, \u003e=, \u003c=, ==, != 组合条件：and or not BETWEEN … AND … LIKE ‘PATTERN’ %：任意长度的任意字符； _：任意单个字符； RLIKE ‘PATTERN’ 正则表达式对字符串做模式匹配； IS NULL IS NOT NULL SELECT col1, ... FROM tbl_name [WHERE clause] ORDER BY col_name, col_name2, ... [ASC|DESC]; ASC: 升序； DESC： 降序； ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:4:2","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"4.3 DELETE： DELETE FROM tbl_name [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] DELETE FROM tbl_name WHERE where_condition DELETE FROM tbl_name [ORDER BY ...] [LIMIT row_count] ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:4:3","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"4.4 UPDATE： UPDATE [LOW_PRIORITY] [IGNORE] table_reference SET col_name1=value1 [, col_name2=value2] ... [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] ","date":"2018-03-26","objectID":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/:4:4","tags":["马哥 Linux"],"title":"19.3 SQL DDL 与 DML","uri":"/posts/linux/linux_mt/22-mysql/sql_ddl_dml/"},{"categories":["Linux"],"content":"19.2 mysql的安装配置","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"mysql的安装配置 上一节我们对关系型数据库和 mariadb 做了一个简单介绍，接下来我们来学习 mariadb 的安装配置 ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. Mariadb 配置 ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 配置文件格式 mysql 的配置文件是 ini 风格的配置文件；客户端和服务器端的多个程序可通过一个配置文件进行配置，使用 [program_name] 标识配置的程序即可。 vim /etc/my.cnf [mysqld] datadir=/var/lib/mysql socket=/var/lib/mysql/mysql.sock [mysqld_safe] log-error=/var/log/mariadb/mariadb.log pid-file=/var/run/mariadb/mariadb.pid # include all files from the config directory !includedir /etc/my.cnf.d ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 配置文件读取次序 mysql 的各类程序启动时都读取不止一个配置文件，配置文件将按照特定的顺序读取，最后读取的为最终生效的配置。可以使用 my_print_defaults 查看默认的配置文件查找次序。 $ my_print_defaults Default options are read from the following files in the given order: /etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf 配置文件查找次序 默认情况下 OS Vendor提供mariadb rpm包安装的服务的配置文件查找次序： /etc/mysql/my.cnf /etc/my.cnf /etc/my.cnf.d/ --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 通用二进制格式安装的服务程序其配置文件查找次序 2. /etc/my.cnf 3. /etc/my.cnf.d/ /etc/mysql/my.cnf --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 # os rpm 包安装的 mariadb 配置文件 ll -d /etc/my* -rw-r--r--. 1 root root 570 6月 8 2017 /etc/my.cnf drwxr-xr-x. 2 root root 67 2月 27 09:57 /etc/my.cnf.d ll /etc/my.cnf.d 总用量 12 -rw-r--r--. 1 root root 295 4月 30 2017 client.cnf -rw-r--r--. 1 root root 232 4月 30 2017 mysql-clients.cnf -rw-r--r--. 1 root root 744 4月 30 2017 server.cnf ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:2","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.3 初始化配置 mysql的用户账号由两部分组成：'USERNAME'@'HOST'; HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务.HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 vim /etc/mysql/my.cnf # 添加三个选项： datadir = /mydata/data innodb_file_per_table = ON skip_name_resolve = ON ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:3","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.4 mysql 安全初始化 默认安装的情况下 mysql root 帐户是没有密码的，可通过 mysql 提供的安全初始化脚本，快速进行安全初始化。 # 查看mysql用户及其密码 mysql \u003e use mysql; \u003e select user,host,password from user; # 运行脚本安全初始化脚本 /user/local/mysql/bin/mysql_secure_installation ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:1:4","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. MariaDB 安装 常见的安装方式有如下三种: rpm包；由OS的发行商提供，或从程序官方直接下载 源码包编译安装: 编译安装，除非需要定制功能，否则一般不推荐编译安装 通用二进制格式的程序包: 展开至特定路径，并经过简单配置后即可使用，这种方式便于部署，无需解决环境依赖 ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 二进制程序包安装 Centos 6： 准备数据目录；以/mydata/data目录为例； 安装配置mariadb groupadd -r -g 306 mysql useradd -r -g 306 -u 306 mysql tar xf mariadb-VERSION.tar.xz -C /usr/local cd /usr/local ln -sv mariadb-VERSION mysql cd /usr/local/mysql chown -R root:mysql ./* scripts/mysql_install_db --user=mysql -datadir=/mydata/data cp support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld chkconfig --list mysqld # 跳过名称解析，并进行安全初始化 ","date":"2018-03-25","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/:2:1","tags":["马哥 Linux"],"title":"19.2 mysql的安装配置","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"19.1 mysql 数据库基础","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"mysql 数据库基础 本章我们来学习 MySQL，数据库本身是一个很复杂的内容，有很多的基本概念，想在短篇幅之内把其中的知识点讲清除并不容易。本章博客自我感觉整理的不好，后续会持续更新。本章将包括以下内容: 什么是关系型数据库 mysql 客户端的使用 mysql 的安装与配置 sql 语句的使用 mysql 中的权限管理 mariadb(mysql) 是最常用的开源关系型数据库，本节我们就对关系型数据库和 mysql 做一个简单介绍。 ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:0:0","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1. 关系型数据库 ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:1:0","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.1 数据模型 数据模型有，层次模型、网状模型、关系模型。关系模型是二维关系表现为表中的列和行。数据库管理系统称为 DBMS(DataBase Management System)，关系型数据库管理系统则称为 RDBMS(Relational DataBase Management System)，常见的 RDMBS: Mysql/MariaDB/Percona-Server PostgreSQL Oracle ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:1:1","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.2 事务(Transaction) 事务含义是将多个操作为一个整体，要么全部都执行，要么全部都不执行；其遵循 ACID： A：Atomicity,原子性； C：Consistency,一致性； I：Isolation,隔离性； D：Durability,持久性； ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:1:2","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2. RDMBS设计范式 设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。目前关系数据库有六种范式： 第一范式（1NF）: 每一列都是原子，不可在分割的 第二范式（2NF）: 每一行都可以使用其有限字段进行唯一标志(不存在重复的行) 第三范式（3NF）、巴德斯科范式（BCNF）: 任何表都不应该有依赖于其他表的非主键字段 第四范式(4NF）和 第五范式（5NF，又称完美范式） 满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。 ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:2:0","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3. mysql 简介 自从 mysql 被 Oracle 收购之后，由于担心版权问题，mysql 的创始人就新建了另一开源分支 mariadb，在 Centos6 中默认安装的是 mysql，而在 Centos7 中默认安装的已经是 mariadb。mariadb 跟 mysql 底层的基础特性是类似的，但是高级特性有很大不同，彼此支持的高级功能也不相同。除了 mariadb，mysql还有很多二次发行版本，比如Percona，AllSQL(阿里的mysql 发行版)以及，TIDB mysql 与 mariadb 的官网分别是： www.mysql.com MariaDB: www.mariadb.org ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:3:0","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.1 mariadb 特性 MariaDB的 支持插件式存储引擎，即存储管理器有多种实现版本，彼此间的功能和特性可能略有区别；用户可根据需要灵活选择。存储引擎也称为“表类型”。常见的存储引擎就是 MyISAM:不支持事务和表级锁，奔溃后不保证安全恢复； InnoDB: 支持事务，行级锁，外键和热备份； MyISAM 在 mariadb 中被扩展为 Aria，支持安全恢复, InnoDB 在 Mariadb 中的开源实现为 XtraDB。在 mysql 的客户端中输入 show engines 即可查看 mariadb 支持的所有存储引擎。 MariaDB [(none)]\u003e show engines; +--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ | Engine | Support | Comment | Transactions | XA | Savepoints | +--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ | CSV | YES | CSV storage engine | NO | NO | NO | | MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO | | MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO | | BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO | | MyISAM | YES | MyISAM storage engine | NO | NO | NO | | InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES | | ARCHIVE | YES | Archive storage engine | NO | NO | NO | | FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES | | PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO | | Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO | +--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:3:1","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.2 MariaDB程序的组成 mariadb 是 C/S 架构的服务，其命令分为服务器端和客户端两个部分 C：Client mysql：CLI交互式客户端程序； mysqldump：备份工具； mysqladmin：管理工具； mysqlbinlog： … S：Server mysqld mysqld_safe：建议运行的服务端程序； mysqld_multi：多实例； msyql 服务器可监听在两种套接字上 IPV4/6 的 tcp 的 3306 端口上，支持远程通信 Unix Sock，监听在 socket 文件上，仅支持本地通信，套接子文件通常位于 /var/lib/mysql/mysql.sock或 /tmp/mysql.sock 由配置文件指定。 ll /var/lib/mysql/mysql.sock srwxrwxrwx. 1 mysql mysql 0 8月 21 11:10 /var/lib/mysql/mysql.sock ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:3:2","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.3 mysql 客户端启动命令 mysql [OPTIONS] [database] 常用选项： -u, --user=name：用户名，默认为root； -h, --host=name：远程主机（即mysql服务器）地址，默认为localhost; -p, --password：USERNAME所表示的用户的密码； 默认为空； -P, --port: 指定 mysql 服务监听的端口，默认为 3306 -D, --database：连接到服务器端之后，设定其处指明的数据库为默认数据库； -e, --execute='SQL COMMAND;'：连接至服务器并让其执行此命令后直接返回； -S, --socket: 指定本地通信的套接字路经 mysql 客户端内可输入的命令分为两类: 客户段命令: 只在客户端运行的命令，使用 help 可获取此类命令的帮助 服务段命令: 通过 mysql 的协议送到服务段运行的命令，所以必须要有命令结束符,默认为 ;；使用 help contents 获取服务器端命令使用帮助。 查看本地命令 mysql\u003e help \\u db_name：设定哪个库为默认数据库 \\q：退出 \\d CHAR：设定新的语句结束符，默认为 ; \\g：语句结束标记，默认就相当于 ; 作用 \\G：语句结束标记，结果竖排方式显式 \\! COMMAND: 在客户端内运行 shell 命令 \\. PATH: 在客户端内执行 sql 脚本(包含 sql 的文本) $ mysql -uroot -p1234 MariaDB [(none)]\u003e help # help 查看 mysql 的所有命令 List of all MySQL commands: Note that all text commands must be first on line and end with ';' ? (\\?) Synonym for `help'. clear (\\c) Clear the current input statement. connect (\\r) Reconnect to the server. Optional arguments are db and host. delimiter (\\d) Set statement delimiter. edit (\\e) Edit command with $EDITOR. ego (\\G) Send command to mysql server, display result vertically. exit (\\q) Exit mysql. Same as quit. go (\\g) Send command to mysql server. help (\\h) Display this help. nopager (\\n) Disable pager, print to stdout. notee (\\t) Don't write into outfile. pager (\\P) Set PAGER [to_pager]. Print the query results via PAGER. print (\\p) Print current command. prompt (\\R) Change your mysql prompt. quit (\\q) Quit mysql. rehash (\\#) Rebuild completion hash. source (\\.) Execute an SQL script file. Takes a file name as an argument. status (\\s) Get status information from the server. system (\\!) Execute a system shell command. tee (\\T) Set outfile [to_outfile]. Append everything into given outfile. use (\\u) Use another database. Takes database name as argument. charset (\\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets. warnings (\\W) Show warnings after every statement. nowarning (\\w) Don't show warnings after every statement. For server side help, type 'help contents' # 执行 shell 命令 MariaDB [(none)]\u003e \\! ls /var account cache db games iso lib lock mail nis preserve spool tmp yp adm crash empty gopher kerberos local log named opt run target www 查看服务端命令 MariaDB [(none)]\u003e help contents # 查看 mysql 命令的组成部分 For more information, type 'help \u003citem\u003e', where \u003citem\u003e is one of the following categories: Account Management Administration Compound Statements Data Definition Data Manipulation ......... MariaDB [(none)]\u003e help 'Account Management' # 查看特定命令组内的命令 topics: CREATE USER DROP USER GRANT RENAME USER REVOKE SET PASSWORD MariaDB [(none)]\u003e help 'CREATE USER' # 查看特定命令使用帮助 Name: 'CREATE USER' Description: Syntax: CREATE USER user_specification [, user_specification] ... user_specification: user [ IDENTIFIED BY [PASSWORD] 'password' | IDENTIFIED WITH auth_plugin [AS 'auth_string'] ] ............... ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:3:3","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"3.4 mysql 数据库组件 mysql 数据库包括如下组件: 数据库: database 表: table: 行: row 列: column 索引: index 视图: view 用户: user 权限: privilege 存储过程: procedure 存储函数: function 触发器: trigger 事件调度器: event scheduler ","date":"2018-03-24","objectID":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/:3:4","tags":["马哥 Linux"],"title":"19.1 mysql 数据库基础","uri":"/posts/linux/linux_mt/22-mysql/mariadb%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"18.5 编译安装 lamp-fpm","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"编译安装 lamp-fpm ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:0:0","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1. Centos6 编译安装 lamp-fpm ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:0","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.1 编译安装步骤 httpd：编译安装，httpd-2.4 mairadb：通用二进制格式，mariadb-5.5 php5：编译安装，php-5.4 xchache 注意：任何一个程序包被编译操作依赖到时，需要安装此程序包的“开发”组件，其包名一般类似于name-devel-VERSION； ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:1","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.2 编译安装apache # 准备开发环境 yum groupinstall \"Development Tools\" \"Server Platform Development\" -y # 1. 编译安装apr tar xf apr-1.5.0.tar.bz2 cd apr-1.5.0 ./configure --prefix=/usr/local/apr make \u0026\u0026 make install # 2. 编译安装apr-util tar xf apr-util-1.5.3.tar.bz2 cd apr-util-1.5.3 ./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr make \u0026\u0026 make install # 3. httpd-2.4.9编译过程也要依赖于pcre-devel软件包，需要事先安装 yum install pcre-devel -y # 4. 编译安装httpd-2.4.9 tar xf httpd-2.4.9.tar.bz2 cd httpd-2.4.9 ./configure --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --enable-modules=most --enable-mpms-shared=all --with-mpm=event --prefix=/usr/local/apache --sysconfdir=/etc/httpd24 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util make \u0026\u0026 make install # 5. 提供SysV服务脚本/etc/rc.d/init.d/httpd cd /etc/rc.d/init.d cp httpd httpd24 vim http24 \u003e apachectl=/usr/local/apache/bin/apachectl \u003e httpd=${HTTPD-/usr/local/apache/bin/httpd} \u003e pidfile= \u003e logfile= chkconfig --add httpd24 chkconfig --list httpd24 # 6. 配置系统环境 vim /etc/profile.d/httpd24.sh \u003e export PATH=/usr/local/apache/bin:$PATH . /etc/profile.d/httpd24.sh httpd -t service start httpd24 # 7. 修改配置文件 cd /etc/httpd24 vim httpd.conf \u003e PidFile \"/var/run/httpd.pid\" # 说明: # httpd.conf 中的 PidFile 必须与 init 服务启动脚本中的pidfile 保持一致 # 默认 httpd.conf 的PidFile=/usr/local/apache/logs/httpd.pid ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:2","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.3 编译安装 Mariadb # 1. 准备数据存放的文件系统 # 新建一个逻辑卷，并将其挂载至特定目录即可 # 假设挂载目录为/mydata，/mydata/data 为mysql数据的存放目录 # 2. 新建用户以安全方式运行进程： groupadd -r mysql useradd -g mysql -r -s /sbin/nologin -M -d /mydata/data mysql chown -R mysql:mysql /mydata/data # 3. 安装并初始化mariadb # 下载通用二进制包 mariadb-5.5.60-linux-systemd-x86_64.tar.gz tar xf mysql-5.5.33-linux2.6-i686.tar.gz -C /usr/local cd /usr/local/ ln -sv mysql-5.5.33-linux2.6-i686 mysql cd mysql chown -R mysql:mysql . scripts/mysql_install_db --user=mysql --datadir=/mydata/data chown -R root . # 4. 为mysql提供主配置文件： cd /usr/local/mysql cp support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf \u003e thread_concurrency = cpu * 2 \u003e datadir = /mydata/data \u003e innodb_file_per_table = on \u003e skip_name_resolve = on # 5. 为mysql提供sysv服务脚本： cd /usr/local/mysql cp support-files/mysql.server /etc/rc.d/init.d/mysqld chmod +x /etc/rc.d/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on service start mysqld # 6. 删除 mysql 匿名用户 cd /usr/local/mysql scripts/mysql_secure_installation # 7. man，PATH 环境变量 # 输出mysql的man手册至man命令的查找路径 vim /etc/man.config \u003e MANPATH /usr/local/mysql/man # 输出mysql的头文件至系统头文件路径/usr/include ln -sv /usr/local/mysql/include /usr/include/mysql # 输出mysql的库文件给系统库查找路径 echo '/usr/local/mysql/lib' \u003e /etc/ld.so.conf.d/mysql.conf ldconfig # 让系统重新载入库 # 修改PATH环境变量 vim /etc/profile.d/mysql.sh \u003e export PATH=/usr/local/mysql/bin:$PATH ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:3","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.4 编译安装 php # 1. 解决依赖关系： yum -y groupinstall \"X Software Development\" # 如果想让编译的php支持mcrypt扩展 yum install libmcrypt yum install libmcrypt-devel yum install mhash yum install mhash-devel # 2. 编译安装 php tar xf php-5.4.26.tar.bz2 cd php-5.4.26 ./configure --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-openssl --with-mysqli=/usr/local/mysql/bin/mysql_config --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --enable-fpm --with-mcrypt --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-bz2 # 说明： # fpm 必须启用 --enable-fpm # 需要更改的配置有 # --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d make make intall # 3. 为php提供配置文件： cp php.ini-production /etc/php.ini # 4. 为php-fpm提供SysV init脚本，并将其添加至服务列表： cp sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpm chmod +x /etc/rc.d/init.d/php-fpm chkconfig --add php-fpm chkconfig php-fpm on # 5. 为php-fpm提供配置文件： cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf # 配置fpm的相关选项为你所需要的值，并启用pid文件（如下最后一行）： vim /usr/local/php/etc/php-fpm.conf \u003e pm.max_children = 50 \u003e pm.start_servers = 5 \u003e pm.min_spare_servers = 2 \u003e pm.max_spare_servers = 8 \u003e pid = /usr/local/php/var/run/php-fpm.pid # 与 init 脚本一致 # 启动php-fpm, 默认情况下，fpm监听在127.0.0.1的9000端口 service php-fpm start ps aux | grep php-fpm ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:4","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.5 配置 httpd # 1. 启用httpd的相关模块 vim /etc/httpd/httpd.conf \u003e LoadModule proxy_module modules/mod_proxy.so \u003e LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so # 2. 配置虚拟主机支持使用fcgi # 在相应的虚拟主机中添加类似如下两行。 \u003e ProxyRequests Off \u003e ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1 # ProxyRequests Off：关闭正向代理 # ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。 # 虚拟主机配置示例 DirectoryIndex index.php \u003cVirtualHost *:80\u003e ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 \u003cDirectory \"/apps/vhosts/b.net\"\u003e Options None AllowOverride None Require all granted \u003c/Directory\u003e \u003c/VirtualHost\u003e # 3. 让apache能识别php格式的页面，并支持php格式的主页,并支持php格式的主页 vim /etc/httpd/httpd.conf \u003e AddType application/x-httpd-php .php \u003e AddType application/x-httpd-php-source .phps \u003e DirectoryIndex index.php index.html ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:5","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.6 安装 xcache # 1. 安装 tar xf xcache-3.0.3.tar.gz cd xcache-3.0.3 /usr/local/php/bin/phpize ./configure --enable-xcache --with-php-config=/usr/local/php/bin/php-config make \u0026\u0026 make install # 安装结束时，会出现类似如下行： # Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-zts-20100525/ cp xcache.ini /etc/php.d vim /etc/php.d/xcache.ini \u003e extension=\"上述安装结束提示的路径\" ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:6","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"1.7 php-fpm 配置 vim /usr/local/php/etc/php-fpm.conf pm = static|dynamic static：固定数量的子进程； pm.max_children； dynamic：子进程数据以动态模式管理； pm.start_servers pm.min_spare_servers pm.max_spare_servers ;pm.max_requests = 500 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限； # mkdir /var/lib/php/session # chown apache.apache /var/lib/php/session ","date":"2018-03-23","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/:1:7","tags":["马哥 Linux"],"title":"18.5 编译安装 lamp-fpm","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm/"},{"categories":["Linux"],"content":"18.4 LAMP部署示例","date":"2018-03-22","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/","tags":["马哥 Linux"],"title":"18.4 LAMP部署示例","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"LAMP部署示例 本节我们就来部署两个经典的 php 开源项目作为演示部署 LAMP 的示例 ","date":"2018-03-22","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:0:0","tags":["马哥 Linux"],"title":"18.4 LAMP部署示例","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"1. httpd部署示例 ","date":"2018-03-22","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:1:0","tags":["马哥 Linux"],"title":"18.4 LAMP部署示例","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"1.1 wordpress 部署 # wordpress 配置 unzip wordpress-2.9.2.zip cp -a wordpress /www/htdoc cd /www/htdoc/wordpress cp wp-config-sample.php wp-config.php vim wp-config.php # 更改mysql 连接的账号，密码，数据库 # mariadb 配置 mysql mysql\u003e grant all on wpdb.* to \"wpuser\"@\"localhost\" identified by \"wppasswd\" mysql\u003e grant all on wpdb.* to \"wpuser\"@\"127.0.0.1\" identified by \"wppasswd\" mysql\u003e create datebase wpdb mysql\u003e flush privileges vim /etc/my.cnf.d/server.cnf skip-name-resolve=ON ","date":"2018-03-22","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:1:1","tags":["马哥 Linux"],"title":"18.4 LAMP部署示例","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"1.2 phpMyAdmin 部署 # 系统环境 yum install php-mbstring # phpMyAdmin 配置 unzip phpMyAdmin-version.zip cp -a phpMyAdmin-version /www/htdoc/ cd /www/htdoc ln -sv phpMyAdmin-version pma cd pma cp config.sample.inc.php config.inc.php vim config.inc.php # 修改 $cfg['blowfish_secret'] = '' # mysql 账号配置: mysql mysql\u003e set password for 'root'@'localhost' = PASSWORD('mageedu') mysql\u003e set password for 'root'@'127.0.0.1' = PASSWORD('mageedu') mysql\u003e flush privileges ","date":"2018-03-22","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/:1:2","tags":["马哥 Linux"],"title":"18.4 LAMP部署示例","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B/"},{"categories":["Linux"],"content":"18.3 LAMP安装","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"LAMP安装 前面我们我们介绍了 LAMP 的原理部分，本节我们就来实践，搭建一个 LAMP。 ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:0:0","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1. php 配置 ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:1:0","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.1 httpd 与 php 结合方式 前面我们介绍 LAMP 的基本原理时提到过，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 prefork MPM 下需要加载 libphp5.so 模块 event, worker MPM 下需要加载 libphp5-zts.so 模块 modules 将 php 作为 http 的 modules 由 php 包提供 $ yum info php $ rpm -ql php /etc/httpd/conf.d/php.conf /etc/httpd/conf.modules.d/10-php.conf /usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块 /usr/share/httpd/icons/php.gif /var/lib/php/session fpm fpm 由 php-fpm 包提供 $ yum info php-fpm $ rpm -ql php-fpm /etc/logrotate.d/php-fpm /etc/php-fpm.conf # php-fpm 服务的配置文件 /etc/php-fpm.d /etc/php-fpm.d/www.conf /etc/sysconfig/php-fpm /run/php-fpm /usr/lib/systemd/system/php-fpm.service /usr/lib/tmpfiles.d/php-fpm.conf /usr/sbin/php-fpm ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:1:1","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.2 php 相关包 与 php 相关的 rpm 包有如下几个: php: 实现 php 作为 httpd 的一个模块 php-fpm: fpm php-common: php 的核心文件 php-mysql: php 的 mysql 驱动模块 php-xcache: php 的加速器 ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:1:2","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.3 php核心文件 $ rpm -ql php-common /etc/php.ini # 配置文件 /etc/php.d /etc/php.d/curl.ini /etc/php.d/fileinfo.ini /etc/php.d/json.ini /etc/php.d/phar.ini /etc/php.d/zip.ini /usr/lib64/php /usr/share/php /var/lib/php php 的所有核心文件均由 php-common 包提供，配置文件为: /etc/php.ini /etc/php.d/*.ini php 的配置文件在 php 启动时被读取一次 对于服务器模块存在的 php 仅在web 服务器启动时读取一次 Modules：重启httpd服务生效； FastCGI：重启php-fpm服务生效； 对于cgi 和 cli 版本，每次调用都会读取 php.ini php 的文档参考如下: php.ini的核心配置选项文档： http://php.net/manual/zh/ini.core.php php.ini配置选项列表：http://php.net/manual/zh/ini.list.php 注释符： 较新的版本中，已经完全使用;进行注释； #：纯粹的注释信息 ;：用于注释可启用的directive # 配置方式类似 yum.respo.d, 采用分段进行 # ;(分号) 表示注释符 [foo]：Section Header directive = value ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:2:0","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.3 php xcache 加速器 # 安装 yum install php-xcache # 配置 /etc/php.d/xcache.ini ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:2:1","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2. modules 模式的 LAMP 安装 首先我们来介绍将 php 作为 httpd 的一作模块这种模式下 LAMP 的安装配置。安装完成后 php 的配置文件位于 /etc/httpd/conf.d/php.conf ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:3:0","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.1 Centos 6 Centos 下需要安装 httpd, php, php-mysql, mysql-server，然后启动 httpd 和 mysql 服务 yum install -y httpd php php-mysql mysql-server service httpd start service mysqld star ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:3:1","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.2 Centos 7 Centos7 下需要安装 httpd, php, php-mysql, mariadb-server。需要注意的是 php 在不同的 MPM 下安装的方式不一样，默认 yum install php 安装要求 httpd 使用 prefork MPM。 # 1. 安装 LAMP yum install http php php-mysql mariadb-server systemctl start httpd systemctl start mariadb # 2. php 的配置 $ rpm -ql php /etc/httpd/conf.d/php.conf /etc/httpd/conf.modules.d/10-php.conf /usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块 /usr/share/httpd/icons/php.gif /var/lib/php/session ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:3:2","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2.3 测试 php 程序执行环境 \u003c?php phpinfo() ?\u003e php 与mysql 通信 # vim DocumentRoot/a.php \u003c?php $con=mysql_connect('127.0.0.1','',''); if ($con) echo \"OK\"; else echo \"faile\"; mysql_close(); phpinfo(); ?\u003e ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:3:3","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3. fpm 的 LAMP 安装 ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:4:0","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3.1 Centos6 PHP-5.3.2：默认不支持fpm机制；需要自行打补丁并编译安装； httpd-2.2：默认不支持fcgi协议，需要自行编译此模块； 解决方案：编译安装httpd-2.4, php-5.3.3+； ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:4:1","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3.2 Centos7 httpd-2.4：rpm包默认编译支持了fcgi模块； php-fpm包：专用于将php运行于fpm模式； 安装 msyql # 1. 安装 msyql yum isntall -y mariadb-server vim /etc/my.cnf.d/server.cnf [mysqld] skip_name_resolve=ON innodb_file_per_table=ON # 安全初始化 mysql_secure_installation # 创建普通登陆用户 # mysql -uroot -p mysql\u003e grant all on testdb.* to 'myuser'@'172.16.0.%' indentified by \"mypass\" mysql\u003e flush priviledges 安装 php-fpm # 2. 安装 php-fpm，最好不要与 php 包同时安装 yum install php-fpm php-mysql php-mbstring $ rpm -ql php-fpm /etc/logrotate.d/php-fpm /etc/php-fpm.conf /etc/php-fpm.d /etc/php-fpm.d/www.conf # 配置 php-fpm vim /etc/php-fpm.conf vim /etc/php-fpm.d/www.conf pm = static|dynamic # - static：固定数量的子进程； # - pm.max_children； # - dynamic：子进程数据以动态模式管理； # - pm.start_servers # - pm.min_spare_servers # - pm.max_spare_servers # - ;pm.max_requests = 500 # 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限； mkdir /var/lib/php/session chown apache.apache /var/lib/php/session 配置 httpd # 1. 确定是否启用httpd的相关模块 httpd -M|grep proxy_module # 未启用则启用代理模块 vim /etc/httpd/httpd.conf \u003e LoadModule proxy_module modules/mod_proxy.so \u003e LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so # 2. 配置虚拟主机支持使用fcgi # 在相应的虚拟主机中添加类似如下两行。 \u003e ProxyRequests Off \u003e ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1 # ProxyRequests Off：关闭正向代理 # ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。 # 虚拟主机配置示例 DirectoryIndex index.php \u003cVirtualHost *:80\u003e ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 \u003cDirectory \"/apps/vhosts/b.net\"\u003e Options None AllowOverride None Require all granted \u003c/Directory\u003e \u003c/VirtualHost\u003e 安装 php xcache yum install -y php-xcache $ rpm -ql php-xcache /etc/php.d/xcache.ini /usr/lib64/php/modules/xcache.so ","date":"2018-03-21","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/:4:2","tags":["马哥 Linux"],"title":"18.3 LAMP安装","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"18.2 PHP 基础","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"PHP 基础 “PHP 是世界上最好的语言”,因为我们后面会以 php 为例配置一个 LAMP，所以本节我们就来先了解一下 php。这里就是一个简单介绍，因为我也没学过 php，所以大多数内容都是摘录自马哥的上课笔记。 ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:0:0","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1. 关于PHP ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:0","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.1 PHP 简介 PHP是通用服务器端脚本编程语言，其主要用于web开发以实现动态web页面，它也是最早实现将脚本嵌入HTML源码文档中的服务器端脚本语言之一。同时，php还提供了一个命令行接口，因此，其也可以在大多数系统上作为一个独立的shell来使用。 Rasmus Lerdorf于1994年开始开发PHP，它是初是一组被Rasmus Lerdorf称作“Personal Home Page Tool” 的Perl脚本， 这些脚本可以用于显示作者的简历并记录用户对其网站的访问。后来，Rasmus Lerdorf使用C语言将这些Perl脚本重写为CGI程序，还为其增加了运行Web forms的能力以及与数据库交互的特性，并将其重命名为“Personal Home Page/Forms Interpreter”或“PHP/FI”。此时，PHP/FI已经可以用于开发简单的动态web程序了，这即是PHP 1.0。 1995年6月，Rasmus Lerdorf把它的PHP发布于comp.infosystems.www.authoring.cgi Usenet讨论组，从此PHP开始走进人们的视野。1997年，其2.0版本发布。 1997年，两名以色列程序员Zeev Suraski和Andi Gutmans重写的PHP的分析器(parser)成为PHP发展到3.0的基础，而且从此将PHP重命名为PHP: Hypertext Preprocessor。此后，这两名程序员开始重写整个PHP核心，并于1999年发布了Zend Engine 1.0，这也意味着PHP 4.0的诞生。 2004年7月，Zend Engine 2.0发布，由此也将PHP带入了PHP 5时代。PHP5包含了许多重要的新特性，如增强的面向对象编程的支持、支持PDO(PHP Data Objects)扩展机制以及一系列对PHP性能的改进。 ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:1","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.2 PHP Zend Engine Zend Engine是开源的、PHP脚本语言的解释器，它最早是由以色列理工学院(Technion)的学生Andi Gutmans和Zeev Suraski所开发，Zend也正是此二人名字的合称。后来两人联合创立了Zend Technologies公司。 Zend Engine 1.0于1999年随PHP 4发布，由C语言开发且经过高度优化，并能够做为PHP的后端模块使用。Zend Engine为PHP提供了内存和资源管理的功能以及其它的一些标准服务，其高性能、可靠性和可扩展性在促进PHP成为一种流行的语言方面发挥了重要作用。 Zend Engine的出现将PHP代码的处理过程分成了两个阶段： 首先是分析PHP代码并将其转换为称作Zend opcode的二进制格式(类似Java的字节码)，并将其存储于内存中； 第二阶段是使用Zend Engine去执行这些转换后的Opcode。 ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:2","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.3 PHP的Opcode Opcode: 是一种PHP脚本编译后的中间语言，就像Java的ByteCode,或者.NET的MSL。PHP执行PHP脚本代码一般经过如下4个步骤(确切的来说，应该是PHP的语言引擎Zend)： Scanning(Lexing): 将PHP代码转换为语言片段(Tokens) Parsing: 将Tokens转换成简单而有意义的表达式 Compilation: 将表达式编译成Opocdes Execution: 顺次执行Opcodes，每次一条，从而实现PHP脚本的功能 总结: 扫描–\u003e分析–\u003e编译–\u003e执行 ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:3","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.4 php的加速器 原理: 基于PHP的特殊扩展机制如opcode缓存扩展也可以将opcode缓存于php的共享内存中，从而可以让同一段代码的后续重复执行时跳过编译阶段以提高性能。 由此也可以看出，这些加速器并非真正提高了opcode的运行速度，而仅是通过分析opcode后并将它们重新排列以达到快速执行的目的。 常见的php加速器有： APC (Alternative PHP Cache) 遵循PHP License的开源框架，PHP opcode缓存加速器， 目前的版本不适用于PHP 5.4 项目地址，http://pecl.php.net/package/APC。 eAccelerator 源于Turck MMCache，早期的版本包含了一个PHP encoder和PHP loader，目前encoder已经不在支持 项目地址， http://eaccelerator.net/。 XCache 快速而且稳定的PHP opcode缓存，经过严格测试且被大量用于生产环境。 项目地址，http://xcache.lighttpd.net/ yum install php-xcache Zend Optimizer和Zend Guard Loader Zend Optimizer并非一个opcode加速器，它是由Zend Technologies为PHP5.2及以前的版本提供的一个免费、闭源的PHP扩展，其能够运行由Zend Guard生成的加密的PHP代码或模糊代码。 而Zend Guard Loader则是专为PHP5.3提供的类似于Zend Optimizer功能的扩展。 项目地址，http://www.zend.com/en/products/guard/runtime-decoders NuSphere PhpExpress NuSphere的一款开源PHP加速器，它支持装载通过NuSphere PHP Encoder编码的PHP程序文件，并能够实现对常规PHP文件的执行加速。 项目地址，http://www.nusphere.com/products/phpexpress.htm ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:4","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.5 PHP源码目录结构 其代码根目录中主要包含了一些说明文件以及设计方案，并提供了如下子目录： build: 顾名思义，这里主要放置一些跟源码编译相关的文件，比如开始构建之前的buildconf脚本及一些检查环境的脚本等。 ext: 官方的扩展目录，包括了绝大多数PHP的函数的定义和实现，如array系列，pdo系列，spl系列等函数的实现。 个人开发的扩展在测试时也可以放到这个目录，以方便测试等。 main: 这里存放的就是PHP最为核心的文件了，是实现PHP的基础设施，这里和Zend引擎不一样，Zend引擎主要实现语言最核心的语言运行环境。 Zend: Zend引擎的实现目录，比如脚本的词法语法解析，opcode的执行以及扩展机制的实现等等。 pear: PHP 扩展与应用仓库，包含PEAR的核心文件。 sapi: 包含了各种服务器抽象层的代码，例如apache的mod_php，cgi，fastcgi以及fpm等等接口。 TSRM: PHP的线程安全是构建在TSRM库之上的，PHP实现中常见的*G宏通常是对TSRM的封装，TSRM(Thread Safe Resource Manager)线程安全资源管理器。 tests: PHP的测试脚本集合，包含PHP各项功能的测试文件。 win32: 这个目录主要包括Windows平台相关的一些实现，比如sokcet的实现在Windows下和*Nix平台就不太一样，同时也包括了Windows下编译PHP相关的脚本。 ","date":"2018-03-20","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/:1:5","tags":["马哥 Linux"],"title":"18.2 PHP 基础","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/php%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"18.1 LAMP入门讲解","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"LAMP入门讲解 上一章我们讲解了 web 的基本概念，以及如何使用 httpd 搭建一个静态的 web 服务器。本章我们接着上一章的内容，讲解 web 服务框架 LAMP。 ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. LAMP ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 LAMP 简介 最早的 web 站点只能提供静态内容，我们的 web 服务只有一个 httpd 服务器，要想展示页面我们必需事先生成静态的 web 页面。但是我们很清楚，不论哪个网站大多数页面都是类似的，只有一小部分不同，大多数页面都可以套用相同的模板动态生成。而填充模板的数组则通常放置在数据库中，最为大家所熟知的也就是 mysql。因此我们的 web 资源就分成了静态资源和动态资源两种 静态资源：原始形式与响应内容一致； 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端 服务器端加载动态资源的方式，按照技术的出现的时间次序分为了: CGI, Common Gateway Interface FCGI, Fast CGI 接下来我们就来详细介绍，这两种动态资源的加载方式 ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.1 CGI CGI(Common Gateway Interface，通用网关接口)，是一种传输协议，它规范了客户端与服务器端如何传输动态资源以及服务器端如何加载动态资源的方式。它的模型如下图所示 这种模型下并不存在后端的应用程序服务器，由前端 web 服务器完成所有工作。动态资源的请求过程如下所示： httpd 服务接收用户请求(动态资源) httpd 基于cgi 协议，在子进程中自动调用 php 的解释器执行对应的 php 脚本，并获取脚本返回结果作为响应传递给客户端 后端应用程序，无须是一个服务，无须理解 http 协议，全部由 apache 服务器完成 即由 web 服务器理解和解析 url，并由 web 服务自行调用动态资源的解释器，运行该动态资源，并获取结果响应给客户端 CGI 在每响应一个动态资源时，必须创建和销毁子进程，性能很低。 ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.2 FCGI FCGI 是 CGI 的增强版本，其动态资源的请求过程如下所示 后端应用程序服务器作为独立的服务监听在特定端口，与 httpd 通过 tcp/udp 协议进行通信 httpd 接收用户请求后，作为客户端向应用程序服务器请求相同的动态资源 后端应用程序服务器加载并执行 php 脚本，并将执行结果作为响应返回给 httpd，httpd 响应给客户端 httpd 起到了反向代理的作用 后端应用程序服务器可以预先创建子进程，这样避免了每次请求都必须创建和销毁子进程带来的开销。 对于 php 而言还存在另一中 FCGI 模式。php 解释功能可作为 httpd 的一个模块存在，httpd 可直接执行 php 脚本，无需创建和销毁子进程。此时 httpd 既是一个静态 web 服务器，也充当应用程序服务器。这种模式也存在一定缺陷: web 服务器和应用程序服务器无法分离开 每个执行 php 的 httpd 进程都必需独自解析 php 脚本，无法利用 php 的加速技术。 此 LAMP 的结构如下所示 ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:1:3","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1.4 LAMP 架构 一个经典的 LAMP 架构如上图所示，包括: l: Linux a: apache httpd m: 数据库存储系统，可以是 mysql, mariadb，mongo p: 后端应用程序的开发语言，可以是 php, perl, python ","date":"2018-03-19","objectID":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/:1:4","tags":["马哥 Linux"],"title":"18.1 LAMP入门讲解","uri":"/posts/linux/linux_mt/21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84lamp/lamp%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"17.8 httpd 辅助工具","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"httpd 辅助工具 本章的最后一节我们来学习 httpd 提供了辅助工具的使用，包括: httpd: httpd 服务的主程序 apachectl：httpd自带的服务控制脚本，支持start和stop,restart； htpasswd：basic认证基于文件实现时，用到的账号密码文件生成工具； apxs：由httpd-devel包提供，扩展httpd使用第三方模块的工具； rotatelogs：日志滚动工具； suexec：访问某些有特殊权限配置的资源时，临时切换至指定用户身份运行； ab： apache benchmark ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:0:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1. httpd httpd[.event|worker] OPTIONS 作用: httpd 主程序 选项: -t: 仅对配置文件执行语法检查。程序在语法解析检查结束后立即退出，或者返回\"0\"(OK)，或者返回非0的值(Error)。如果还指定了\"-D DUMP_VHOSTS\"，则会显示虚拟主机配置的详细信息 -l: 输出一个静态编译在服务器中的模块的列表。它不会列出使用LoadModule指令动态加载的模块。 -L: 输出一个指令的列表，并包含了各指令的有效参数和使用区域。 -M: 输出一个已经启用的模块列表，包括静态编译在服务器中的模块和作为DSO动态加载的模块。 -v: 显示httpd的版本，然后退出。 -V: 显示httpd和APR/APR-Util的版本和编译参数，然后退出。 -X: 以调试模式运行httpd 。仅启动一个工作进程，并且服务器不与控制台脱离 -d serverroot: 将ServerRoot指令设置初始值为serverroot。它可以被配置文件中的ServerRoot指令所覆盖。 -f config: 在启动中使用config作为配置文件。如果config不以\"/“开头，则它是相对于ServerRoot的路径 -k start|restart|graceful|stop|graceful-stop: 发送信号使httpd启动、重新启动或停止 。 -C directive: 在读取配置文件之前，先处理directive的配置指令。 -c directive: 在读取配置文件之后，再处理directive的配置指令。 -D parameter: 设置参数parameter ，它配合配置文件中的段，用于在服务器启动和重新启动时，有条件地跳过或处理某些命 -e level: 在服务器启动时，设置LogLevel为level 。它用于在启动时，临时增加出错信息的详细程度，以帮助排错。 -E file: 将服务器启动过程中的出错信息发送到文件file 。 -R directory: 当在服务器编译中使用了SHARED_CORE规则时，它指定共享目标文件的目录为directory 。 -h: 输出一个可用的命令行选项的简要说明。 -S: 显示从配置文件中读取并解析的设置结果(目前仅显示虚拟主机的设置) -T: 在启动/重启的时候跳过根文件检查 (该参数在Apache 2.2.17及其以后版本有效) -t 选项的扩展: httpd -t -D DUMP_VHOSTS : 显示虚拟主机的配置 httpd -t -D DUMP_RUN_CFG : show parsed run setting httpd -t -D DUMP_MODULES : 显示所有已经启动的模块 httpd -M : httpd -t -D DUMP_MODULES 的快捷方式 $ httpd -l Compiled in modules: core.c mod_so.c http_core.c $ httpd -M Loaded Modules: core_module (static) so_module (static) http_module (static) access_compat_module (shared) actions_module (shared) ....... $ httpd -t Syntax OK ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:1:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2. apachectl apachectl OPTIONS 作用: 是slackware内附Apache HTTP服务器的script文件，可供管理员控制服务器 选项: configtest: 检查设置文件中的语法是否正确。 fullstatus: 显示服务器完整的状态信息。 graceful: 重新启动Apache服务器，但不会中断原有的连接。 help: 显示帮助信息。 restart: 重新启动Apache服务器。 start: 启动Apache服务器。 status: 显示服务器摘要的状态信息。 stop: 停止Apache服务器 说明: httpd 命令的所有选项， apachectl 均可用 ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:2:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"3. htpasswd htpasswd OPTIONS passwordfile username [password] 作用: 用于创建和更新储存用户名、域和用户基本认证的密码文件 参数: passwordfile: 密码文件的路经，使用 -n 选项时，无需此参数 username: 用户名 password: 密码，使用-b 选项时必需，默认显示提示符让用户输入密码 选项: -c：创建一个加密文件，文件已经存在会删除重建 -b：在命令行中一并输入用户名和密码而不是根据提示输入密码 -D：删除指定的用户 -n：不更新加密文件，只将加密后的用户名密码显示在屏幕上 -m：默认采用MD5算法对密码进行加密 -d：采用CRYPT算法对密码进行加密 -p：不对密码进行进行加密，即明文密码 -s：采用SHA算法对密码进行加密 $ htpasswd -c /tmp/.httpd tao # 首次创建文件，需要使用 -c New password: Re-type new password: Adding password for user tao $ htpasswd -b /tmp/.httpd pythoner python # 非首次创建不能使用 `-c` 否则会删除已有文件 Adding password for user pythoner ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:3:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"3. curl curl [options] [URL...] 作用: curl是基于URL语法在命令行方式下工作的文件传输工具 支持FTP, FTPS, HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议 支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器， cookies， 用户名/密码认证， 下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）， 甚至它还支持IPv6， socks5代理服务器,，通过http代理服务器上传文件到FTP服务器等等，功能十分强大。 options: -e/--referer \u003cURL\u003e: 来源网址 -A/--user-agent \u003cstring\u003e: 设置用户代理发送给服务器 -H/--header \u003cline\u003e: 自定义首部信息传递给服务器 -I/--head 只显示响应报文首部信息 --basic: 使用HTTP基本认证 -u/--user \u003cuser[:password]\u003e: 设置服务器的用户和密码 --cacert \u003cfile\u003e: CA证书 (SSL) --compressed 要求返回是压缩的格式 --limit-rate \u003crate\u003e: 设置传输速度 -0/--http1.0: 使用HTTP 1.0 --tcp-nodelay: 使用TCP_NODELAY选项 ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:4:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"5. elinks elinks [OPTION]... [URL]... 作用: 文本浏览器 选项: -dump: 不进入交互式模式，而直接将URL的内容输出至标准输出； ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:5:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"6. httpd的压力测试工具 市面上常见的 web 压力测试工具有以下几种: 命令行工具: ab, webbench, http_load, seige 图形化工具: jmeter, loadrunner 模拟真实请求: tcpcopy，网易开发，复制生产环境中的真实请求，并将之保存下来； ab [OPTIONS] URL 全称: apache benchmark 选项: -n：总请求数； -c：模拟的并行数； -k：以持久连接模式 测试； 附注: ulimit -n num 调整当前用户能同时打开的文件数 ","date":"2018-03-18","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/:6:0","tags":["马哥 Linux"],"title":"17.8 httpd 辅助工具","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"17.7 httpd 配置进阶","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"httpd 配置进阶 我们来继续学习 httpd 的配置，本节属于高级配置篇，核心是配置httpd支持https。 ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:0:0","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"1. 指定 httpd 服务的运行身份 User apache Group apache User 和 Group 指令用于指定以哪个用户的身份运行httpd服务进程。该帐户决定了 httpd 进程在本机的权限。千万不能以 root 用户运行我们的 httpd 进程，以免 httpd 被劫持导致整个机器被控制。 需要注意的是如果指定的帐户没有权限访问文件系统上的内容，即便 \u003cDirectory\u003e 开放了访问接口也一样无法访问。因此 httpd 提供了 SUexec，用于在特定的目录内进行用户切换以便能够方便的访问到受限的文件，而不用更改文件的权限。SUexec有安全风险，一般也很少使用。 ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:1:0","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"2. 页面压缩 mod_deflate 模块提供了压缩功能。压缩可以节约带宽，但是会额外消耗CPU；同时，可能有些较老浏览器不支持。是否启用压缩取决于网络带宽与 CPU 哪个更加稀缺。 有些资源是可压缩的，例如文件文件，而有些资源本身已经是压缩的，比如图片，这些则无需压缩。httpd 的压缩功能配置如下: # 1. 首先确认是否加载了 deflate 模块 $ httpd -M|grep -i deflate deflate_module (shared) # 2. 没有加载，则在配置文件中加载 deflate_module LoadModule deflate_module modules/mod_deflate.so # 3. 配置压缩功能 $ vim /etc/httpd/conf.d/compress.conf # 在单独配置文件中配置，方便取消 SetOutputFilter DEFLATE # 添加一个过滤器 # mod_deflate configuration # 向过滤器添加压缩哪些内容 # Restrict compression to these MIME types AddOutputFilterByType DEFLATE text/plain AddOutputFilterByType DEFLATE text/html AddOutputFilterByType DEFLATE application/xhtml+xml AddOutputFilterByType DEFLATE text/xml AddOutputFilterByType DEFLATE application/xml AddOutputFilterByType DEFLATE application/x-javascript AddOutputFilterByType DEFLATE text/javascript AddOutputFilterByType DEFLATE text/css # Level of compression (Highest 9 - Lowest 1) DeflateCompressionLevel 9 # 默认压缩级别 # Netscape 4.x has some problems. # 特殊浏览器的特殊处理 BrowserMatch ^Mozilla/4 gzip-only-text/html # Netscape 4.06-4.08 have some more problems BrowserMatch ^Mozilla/4\\.0[678] no-gzip # MSIE masquerades as Netscape, but it is fine BrowserMatch \\bMSI[E] !no-gzip !gzip-only-text/html ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:2:0","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"3. 配置httpd支持https SSL会话是基于IP地址创建；所以单IP的主机上，仅可以使用一个https虚拟主机 ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:3:0","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"3.1 SSL会话的简化过程 客户端发送可供选择的加密方式，并向服务器请求证书； 服务器端发送证书以及选定的加密方式给客户端； 客户端取得证书并进行证书验正： 验正证书来源的合法性；用CA的公钥解密证书上数字签名； 验正证书的内容的合法性：完整性验正 检查证书的有效期限； 检查证书是否被吊销； 证书中拥有者的名字，与访问的目标主机要一致； 客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器，完成密钥交换； 服务用此密钥加密用户请求的资源，响应给客户端； ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:3:1","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"3.2 配置httpd支持https 配置 https 需要如下几个步骤: 为服务器申请数字证书。本地测试时，可以私建CA发证书 配置httpd支持使用ssl，及使用的证书； 测试基于https访问相应的主机； 私建 CA 发证 参见18.4 私建CA.md 配置 ssl # 1. 安装 httpd 的 ssl 功能模块 yum -y install mod_ssl # 2. 编辑配置文件 $ vim /etc/httpd/conf.d/ssl.conf DocumentRoot \"/var/www/html\" ServerName \"www.magedu.com:443\" SSLCertificateFile \"/etc/httpd/ssl/http_crt.pem\" SSLCertificateKeyFile \"/etc/httpd/ssl/http_key.pem\" 测试 https 服务 我们可以在浏览器导入我们私建的 CA 直接在浏览器中进行测试，也可以通过 openssl 的 s_client 子命令进行测试 openssl s_client OPTIONS 作用: https 连接的客户端工具 选项: [-connect host:port]: 连接的主机和端口 [-CAfile filename]: CA 证书的位置 ","date":"2018-03-17","objectID":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/:3:2","tags":["马哥 Linux"],"title":"17.7 httpd 配置进阶","uri":"/posts/linux/linux_mt/20-web-apache/httpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"17.6 httpd2.4 基础配置","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"httpd2.4 基础配置 上一节我们详细介绍了httpd2.2 的配置，对比着 httpd2.2 本节我们来讲解 httpd2.4 的配置。 ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. httpd-2.4 ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 新特性 相比于 httpd2.2 httpd2.4 有如下新特性: MPM支持运行为DSO机制；以模块形式按需加载； event MPM生产环境可用； 异步读写机制； 支持每模块及每目录的单独日志级别定义； 每请求相关的专用配置: 增强版的表达式分析器； 毫秒级持久连接时长定义； 基于FQDN的虚拟主机也不再需要 NameVirutalHost 指令； 新指令，AllowOverrideList； 支持用户自定义变量； 新模块： mod_proxy_fcgi mod_raltelimit mod_remoteip ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 配置文件 ll /etc/httpd/ 总用量 0 drwxr-xr-x. 2 root root 37 8月 17 16:10 conf drwxr-xr-x. 2 root root 151 8月 17 16:08 conf.d drwxr-xr-x. 2 root root 205 8月 17 15:01 conf.modules.d lrwxrwxrwx. 1 root root 19 2月 10 2018 logs -\u003e ../../var/log/httpd lrwxrwxrwx. 1 root root 29 2月 10 2018 modules -\u003e ../../usr/lib64/httpd/modules lrwxrwxrwx. 1 root root 10 2月 10 2018 run -\u003e /run/httpd 主配置文件: /etc/httpd/conf/httpd.conf 辅助配置文件: /etc/httpd/conf.d/*.conf 模块配置文件: /etc/httpd/conf.modules.d/*.conf mpm 以DSO机制提供，配置文件为 /etc/httpd/conf.modules.d/00-mpm.conf ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:1:2","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. httpd2.4 配置 httpd2.4 官方文档 http://httpd.apache.org/docs/2.4/mod/directives.html ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 修改监听的IP和PORT Listen [IP-address:]portnumber [protocol] protocol: 限制必需通过 ssl 通信时，protocol 可定义为 https ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:1","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 持久连续 KeepAliveTimeout num[ms] 支持毫秒级持久时间，默认单位为秒 ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:2","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.3 MPM MPM支持运行为DSO机制，在/etc/httpd/conf.modules.d/00-mpm.conf中进行配置，启用要启用的MPM相关的LoadModule指令即可。 $ cat /etc/httpd/conf.modules.d/00-mpm.conf|grep LoadModule LoadModule mpm_prefork_module modules/mod_mpm_prefork.so #LoadModule mpm_worker_module modules/mod_mpm_worker.so #LoadModule mpm_event_module modules/mod_mpm_event.so ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:3","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. 访问控制机制 ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 基于IP的访问控制 新增访问路径必须添加 Require 进行 ip 授权，否则新增路径不允许访问，所有的IP 访问控制必须放置在 RequireAll 容器中 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all deny 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问； Require not ip IPADDR：拒绝 IPADDR： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 控制特定的主机访问： Require host HOSTNAME：授权指定来源的主机访问； Require not host HOSTNAME：拒绝 HOSTNAME： FQDN：特定主机 domin.tld：指定域名下的所有主机 # IP 访问控制 \u003cDirectory \"/www/htdoc\"\u003e \u003cRequireAll\u003e Require all granted Require not ip 172.16.100.2 \u003c/RequireAll\u003e \u003c/Directory\u003e ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4. 虚拟主机 基于FQDN的虚拟主机也不再需要NameVirutalHost指令； 注意：任意目录下的页面只有显式授权才能被访问； # 定义虚拟主机 \u003cVirtualHost *:80\u003e ServerName www.b.net DocumentRoot \"/apps/b.net/htdocs\" \u003cDirectory \"/apps/b.net/htdocs\"\u003e Options None AllowOverride None Require all granted \u003c/Directory\u003e \u003c/VirtualHost\u003e ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5. status页面 LoadModule status_module modules/mod_status.so \u003cLocation /server-status\u003e SetHandler server-status \u003cRequireAll\u003e Require ip 172.16 \u003c/RequireAll\u003e \u003c/Location\u003e ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:5:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"练习题：分别使用httpd-2.2和httpd-2.4实现 1. 建立httpd服务，要求： (1) 提供两个基于名称的虚拟主机： www1.stuX.com，页面文件目录为/web/vhosts/www1；错误日志为/var/log/httpd/www1/error_log，访问日志为/var/log/httpd/www1/access_log； www2.stuX.com，页面文件目录为/web/vhosts/www2；错误日志为/var/log/httpd/www2/error_log，访问日志为/var/log/httpd/www2/access_log； (2) 通过www1.stuX.com/server-status输出其状态信息，且要求只允许提供账号的用户访问； (3) www1不允许192.168.1.0/24网络中的主机访问； 2. 为上面的第2个虚拟主机提供https服务，使得用户可以通过https安全的访问此web站点； (1) 要求使用证书认证，证书中要求使用国家（CN），州（Beijing），城市（Beijing），组织为(MageEdu)； (2) 设置部门为Ops, 主机名为www2.stuX.com； ","date":"2018-03-16","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:6:0","tags":["马哥 Linux"],"title":"17.6 httpd2.4 基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"17.5 httpd2.2 的基础配置","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"httpd2.2 的基础配置 本节我们来讲解 httpd2.2 的基础配置 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. httpd-2.2 配置文件格式 $ grep \"^###\" /etc/httpd/conf/httpd.conf ### Section 1: Global Environment ### Section 2: 'Main' server configuration ### Section 3: Virtual Hosts httpd2.2 的主配置文件是：/etc/httpd/conf/httpd.conf，其分成三个部分: Section 1: Global Environment 全局配置 Section 2: ‘Main’ server configuration 主服务配置段 Section 3: Virtual Hosts 虚拟主机配置段 下面是一段配置示例 ServerRoot \"/etc/httpd\" Include conf.modules.d/*.conf \u003cDirectory /\u003e # 目录访问权限配置 AllowOverride none Require all denied \u003c/Directory\u003e \u003cIfModule dir_module\u003e # IfModule 判断动态模块是否存在，动态配置 DirectoryIndex index.html \u003c/IfModule\u003e 配置的格式为 directive value directive：配置参数，不区分字符大小写； value：参数值，为路径时，是否区分字符大小写，取决于文件系统； ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. httpd-2.2 常用配置 httpd2.2 的官方文档: http://httpd.apache.org/docs/2.2/ ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 修改监听的IP和PORT Listen [IP:]PORT 省略IP表示监听本地所有地址 Listen指令可重复出现多次，以监听多个IP地址和端口； Listen 80 Listen 8080 修改监听socket(不是新增)，需要重启服务进程才能生效； ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:1","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 持久连续 Persistent Connection # 持久链接配置相关参数 KeepAlive On|Off # 是否启用持久连接 KeepAliveTimeout 15 # 持久链接最大连接时长 MaxKeepAliveRequests 100 # 持久链接最多处理的请求数 前面我们说过 tcp 连接有长连接短连接之分 长连接能降低请求响应的时间 但对并发访问量较大的服务器，长连接机制会使得后续某些请求无法得到正常 响应； 因此通常的折衷策略是，采用长连接，但是使用较短的持久连接时长，以及较少的请求数量。 http 与长连接相关的参数包括 KeepAlive On|Off: 是否启用持久连接 KeepAliveTimeout time: 持久链接最大连接时长,httpd-2.4 支持毫秒级持久时间 MaxKeepAliveRequests: 单个持久连接能够处理的对大请求数 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:2","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.3 MPM MPM(Multipath Process Module) 多道处理模块,用来确定 httpd 响应用户请求的模型。 对于 httpd2.2: 不支持同时编译多个MPM模块，所以只能编译选定要使用的那个。 CentOS 6的rpm包为此专门提供了三个应用程序文件，httpd(prefork), httpd.worker, httpd.event，分别用于实现对不同的MPM机制的支持。 默认使用的为/usr/sbin/httpd，其为prefork的MPM模块 查看 httpd2.2 当前使用的 MPM 以及修改默认的 MPM 的方式如下: # 1. 查看当前使用MPM模式 ps aux|grep httpd # 2. 查看httpd程序的模块列表： ## 查看静态编译的模块(先确定使用的MPM): httpd -l httpd.event -l httpd.worker -l ## 查看静态编译及动态编译的模块: httpd -M httpd.envent -M httpd.woker -M # 3. 更改 service 使用的 httpd 程序 vim /etc/sysconfig/httpd HTTPD=/usr/sbin/httpd.{worker,event} # 修改 HTTPD 参数，重启服务进程方可生效 prefork的配置参数 # /etc/httpd/conf/httpd.conf \u003cIfModule prefork.c\u003e StartServers 8　＃ 服务启动时，启动的进程数 MinSpareServers 5 # 最小空闲进程数 MaxSpareServers 20 # 最大空闲进程数 ServerLimit 256 # 为 MaxClients 提供的最大进程数，通常等于 MaxClients MaxClients 256 # 并发的最大客户端请求数 MaxRequestsPerChild 4000 # 一个进程能处理的请求总数，超过会自动销毁 \u003c/IfModule\u003e worker的配置参数 # /etc/httpd/conf/httpd.conf \u003cIfModule worker.c\u003e StartServers 4 # 服务器启动时启动的进程数 MaxClients 300 MinSpareThreads 25 # 最小的空闲线程数 MaxSpareThreads 75 # 最大的空闲线程数 ThreadsPerChild 25 # 每个进程启动的线程数 MaxRequestsPerChild 0 # 每个线成能处理的请求总数，超过会自动销毁，0 表示无限 \u003c/IfModule\u003e event 的配置 event 在 httpd2.2 中尚且属于测试阶段，不建议在线上使用 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:3","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.4 DSO LoadModule mod_name mod_path 作用: 实现模块加载: 参数: mod_name: 模块的名称 mod_path: 模块的路经，可使用相对路径：相对于ServerRoot LoadModule alias_module modules/mod_alias.so # modules/mod_alias.so -- \u003e /etc/httpd/modules/mod_alias.so # /etc/httpd/modules ---\u003e /usr/lib64/httpd/modules ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:4","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.5 ‘Main’ server配置 DocumentRoot Dir 作用: 文档路径映射,DoucmentRoot指向的路径为URL路径的起始位置, 其相当于站点URL的根路径； DocumentRoot \"/var/www/html\" (FileSystem) /var/www/html/index.html --\u003e (URL)/index.html ServerName www.example.com:80 作用: 配置主服务的标识 默认: 未设置此参数时， httpd 会自动反解监听的 IP 地址，反解失败，则默认为当前主机的主机名 可以随意设置，如果没有注册 DNS 域名，也可以设置成 ip 地址 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:5","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.6 定义站点主页面 DirectoryIndex index.html index.html.var 作用: 配置当用户访问 URL 的指向是一个目录时，httpd 应该默认响应的内容 附注: 找不到主页面时，httpd 通过 /etc/httpd/conf.d/weibocom.conf 提供了一个默认主页面 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:6","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.7 定义路径别名 Alias /URL/ \"/PATH/TO/SOMEDIR/\" 作用: 定义 url 访问资源的路经别名 DocumentRoot \"/www/htdocs\" http://www.magedu.com/download/a.index --\u003e /www/htdocs/download/a.index Alias /download/ \"/rpms/pub/\" http://www.magedu.com/download/a.index --\u003e /rpms/pub/a.index http://www.magedu.com/images/logo.png ---\u003e /www/htdocs/images/logo.png ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:7","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.8 设定默认字符集 AddDefaultCharset UTF-8 作用: 设定默认字符集 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:8","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.9 日志设定 # 错误日志： ErrorLog logs/error_log # 错误日志的路经 LogLevel warn # 日志的级别 # 定义日志格式 LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined LogFormat \"%h %l %u %t \\\"%r\\\" %\u003es %b\" common CustomLog logs/access_log combined # 访问日志的路经，combined 为 LogFormat 名 LogLevel level 作用: 日志级别 可选值：debug, info, notice, warn, error, crit, alert, emerg LogFormat 格式化字符串 http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats 标志宏 作用 %h 客户端IP地址 %l Remote User, 通常为一个减号（“-”） %u Remote user (from auth; may be bogus if return status (%s) is 401)；非为登录访问时，其为一个减号 %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本 %\u003es 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文的http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的 %{User-Agent}i 请求报文中首部“User-Agent”的值；即发出请求的应用程序 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:2:9","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. httpd2.2 访问控制 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 访问控制机制 访问控制值的时允许哪些用户访问哪些站点资源 用户可以通过来源地址 或 账号 指定， 资源可以通过文件系统路径 或 URL 指定 因此 httpd 的访问控制机制有如下四中实现方式: 基于来源地址，通过文件路径实现访问控制机制 基于来源地址，通过 url 实现访问控制机制 基于账号，过文件路径实现访问控制机制 基于账号，通过 url 实现访问控制机制 httpd2.2 与 httpd2.4 最大的不同之处在于，httpd2.4 如果未授权，默认是所有用户都无法访问的，而 http2.2 则默认允许访问。因此当在 httpd2.4 中添加 Alias 路经别名，或更改 DocumentRoot 时，必需配置相应的访问权限。 资源界定 资源的文件系统路径由如下几种配置方式 \u003cDirectory \"\"\u003e # 目录 ... \u003c/Directory\u003e \u003cFile \"\"\u003e # 单文件 ... \u003c/File\u003e \u003cFileMatch \"PATTERN\"\u003e # 文件路经匹配的正则表达式 ... \u003c/FileMatch\u003e URL 有如下两种配置方式 \u003cLocation \"\"\u003e # URL 地址 ... \u003c/Location\u003e \u003cLocationMatch \"\"\u003e # URL 匹配的正则表达式 ... \u003c/LocationMatch\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 Directory 中“基于源地址”实现访问控制： \u003cDirectory \"/var/www/html\"\u003e Options All，None，Indexes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews AllowOverride None \u003c/Directory\u003e http2.2 访问控制参数如下: Options 作用: 后跟1个或多个以空白字符分隔的“选项”列表； 选项: Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户； – 危险，生产环境不能启用 FollowSymLinks：允许跟踪符号链接文件所指向的源文件；– 危险 None：关闭所有选项 All：启动全部选项 说明: 选项前加上-，表示关闭，但是只能要么都有-，要么都没有 AllowOverride 作用: 与访问控制相关的指令可以放在.htaccess文件，每个目录下都可以有一个；用于自定义每个目录的访问权限 启用 .htaccess 会对性能产生重大影响，不建议启用 Directory 中的配置相当于全局配置 选项: All: Directory 中的全局配置，覆盖 htaccess 中的配置 None：Directory 中的全局配置，不会覆盖 htaccess 中的配置 order和allow、deny 作用: 基于来源地址的访问控制 order：定义生效次序；写在后面的表示默认法则； Order allow，deny: 白名单 Order deny，allow: 黑名单 Allow from IP, Deny from IP: 注明来源IP 来源地址： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 \u003cDirectory \"/www/htdoc\"\u003e AllowOverride None Options Indexes FollowSymLinks Order allow,deny Allow from 192.168.1 # Deny from 192.168.1.104 \u003c/Directory\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:2","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.2 基于用户的访问控制 WWW-Authenticate（认证质询）是 http 协议早期提供的用户认证机制。当用户请求受控资源时，服务器响应 401，拒绝客户端请求，并说明要求客户端提供账号和密码；浏览器接收到响应时，会弹出认证窗口，客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源。需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因。 WWW-Authenticate 认证方式有两种： basic认证：会明文传输帐号和密码，不安全 digest认证： 用户的账号和密码可存储在文本文件，SQL数据库，ldap目录存储。但是通常都是存在本地的文本文件中，因为 httpd 访问 mysql 的模块是非标准模块，需要单独编译安装。现在 web 站点基本都是通过表单进行身份认证，认证质询因为安全性和便利性的问题，其实很少使用。 basic认证配置示例 # 1. 定义安全域 \u003cDirectory \"\"\u003e Options None AllowOverride None AuthType Basic AuthName \"String“ # 认证提时字符串 AuthUserFile \"/PATH/TO/HTTPD_USER_PASSWD_FILE\" # 帐号密码文件路经 Require user username1 username2 ... # 允许访问的用户 # Require valid-user # 允许账号文件中的所有用户登录访问 \u003c/Directory\u003e # 2. 使用 htpassword 命令创建帐号密码文件 $ htpassword -cb /etc/httpd/.httpd tao tao 基于组账号进行认证 # 1. 定义安全域 \u003cDirectory \"\"\u003e Options None AllowOverride None AuthType Basic AuthName \"String“ AuthUserFile \"/PATH/TO/HTTPD_USER_PASSWD_FILE\" AuthGroupFile \"/PATH/TO/HTTPD_GROUP_FILE\" Require group grpname1 grpname2 ... \u003c/Directory\u003e # 2. 创建用户账号和组账号文件； # 组文件：每一行定义一个组 # GRP_NAME: username1 username2 ... \u003e htpasswd -m /etc/httpd/conf.d/.http_passwd tom # 创建帐号文件 \u003e vim /etc/httpd/conf.d/.http_group # 创建组文件 admin: tom jerry # tom, jerry 为 admin 组 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:3:3","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4. 虚拟主机 通常如果我们在同一主机上提供了多个彼此毫不相干的服务时，通常是将他们隔离开，放在不同的域名下进行管理，而不是放在同一域名下；以免某一站点被劫持，所有站点都被劫持。虚拟主机就是帮助我们实现一个物理服务器服务多个网站的功能。 web 服务通过 tcp 进行通信，即每个服务都监听在一个特定的套接子socket 上，socket = ip + 端口，所以实现虚拟主机就有如下几种方法: IP相同，但端口不同； IP不同，但端口均为默认端口； FQDN不同: 为不同的 web 服务配置不同的域名 需要注意的是请求报文首部中的 Host 字段会保留浏览器中用户请求的域名，因此服务器端可以通过解析Host 字段来路由请求。httpd 中心主机与虚拟主机不能混用，httpd2.2 中使用虚拟主机必需禁用’main’主机,禁用方法：注释中心主机的DocumentRoot指令即可。http2.4 中启用虚拟主机后，中心主机会自动禁用。 ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.1 虚拟主机的配置方法 所有能用在中心主机的配置，均可以用在虚拟主机中 \u003cVirtualHost IP:PORT\u003e ServerName FQDN DocumentRoot \"\" # 其它可用指令： ServerAlias：虚拟主机的别名；可多次使用； ErrorLog： CustomLog： \u003cDirectory \"\"\u003e ... \u003c/Directory\u003e Alias ... \u003c/VirtualHost\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:1","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.2 基于IP的虚拟主机示例： \u003cVirtualHost 192.168.1.120:80\u003e ServerName web1.tao.com DocumentRoot \"/vhosts/web1/htdocs\" \u003cDirectory \"/vhosts/web1/htdocs\"\u003e Options None AllowOverride None Require all granted \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.7:80\u003e ServerName www.b.net DocumentRoot \"/www/b.net/htdocs\" \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.8:80\u003e ServerName www.c.org DocumentRoot \"/www/c.org/htdocs\" \u003c/VirtualHost\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:2","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.3 基于端口的虚拟主机： \u003cVirtualHost 172.16.100.6:80\u003e ServerName www.a.com DocumentRoot \"/www/a.com/htdocs\" \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.6:808\u003e ServerName www.b.net DocumentRoot \"/www/b.net/htdocs\" \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.6:8080\u003e ServerName www.c.org DocumentRoot \"/www/c.org/htdocs\" \u003c/VirtualHost\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:3","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.4 基于 hostname 的虚拟主机： # 重要，http2.2 中需要指明 NameVirtualHost NameVirtualHost 172.16.100.6:80 \u003cVirtualHost 172.16.100.6:80\u003e ServerName www.a.com DocumentRoot \"/www/a.com/htdocs\" \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.6:80\u003e ServerName www.b.net DocumentRoot \"/www/b.net/htdocs\" \u003c/VirtualHost\u003e \u003cVirtualHost 172.16.100.6:80\u003e ServerName www.c.org DocumentRoot \"/www/c.org/htdocs\" \u003c/VirtualHost\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:4:4","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5. status页面 LoadModule status_module modules/mod_status.so \u003cLocation /server-status\u003e SetHandler server-status Order allow,deny Allow from 172.16 \u003c/Location\u003e ","date":"2018-03-15","objectID":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/:5:0","tags":["马哥 Linux"],"title":"17.5 httpd2.2 的基础配置","uri":"/posts/linux/linux_mt/20-web-apache/httpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"17.4 apache httpd 简介","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"apache httpd 简介 httpd 是 ASF(apache software foundation, apache 软件基金会)下的顶级项目，也是目前市场占有率最高的 web 服务器。本节我们就来对 httpd 做一个概括行的介绍。在之后的章节我们再来详细的学习 httpd 的配置。 ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:0:0","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1. httpd 简介 ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:1:0","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.1 httpd 版本 httpd 目前有如下主流的版本 httpd 1.3：官方已经停止维护； httpd 2.0： httpd 2.2: Centos6 base 仓库的默认安装版本 httpd 2.4：目前最新稳定版，Centos7 base 仓库的默认安装版本 httpd2.2 和 httpd2.4 目前都有使用，他们之间存在比较大的差异。在介绍 httpd 的配置时，我们将首先介绍 http2.2，然后针对 httpd2.4 的不同之处单独讲解。 ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:1:1","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1.2 httpd的特性 httpd 具有如下的一些关键特性: 高度模块化： core + modules DSO：dynamic shared object 动态共享对象 MPM：Multipath processing Modules (多路处理模块) prefork：多进程模型, 每个进程响应一个请求； 一个主进程：负责生成子进程及回收子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； n个子进程：每个子进程处理一个请求； 工作模型：会预先生成几个空闲进程，随时等待用于响应用户请求；有最大空闲数和最小空闲数； worker：多进程多线程模型，每线程处理一个用户请求； 一个主进程：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 多个子进程：每个子进程负责生成多个线程； 每个线程：负责响应用户请求； 并发响应数量：m*n m：子进程数量 n：每个子进程所能创建的最大线程数量； event：事件驱动模型，多进程模型，每个进程响应多个请求； 一个主进程 ：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 子进程：基于事件驱动机制直接响应多个请求； 适用版本: httpd-2.2: 仍为测试使用模型； httpd-2.4：event可生产环境中使用； ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:1:2","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. httpd安装 httpd 可以通过 base 仓库的 rpm 包直接安装，也可以编译安装。通常除非需要定制新功能，或其它原因，不建议采用编译安装的方式。一是对规模部署不便，二是安装过程繁琐，需要准备编译环境，还需要额外的配置。 ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:2:0","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 httpd2.2 与 httpd2.4 的对比 下面是 httpd2.2 httpd2.4 安装，管理，以及配置文件路经的对比 $ ll /etc/httpd/ 总用量 0 drwxr-xr-x. 2 root root 37 5月 22 19:20 conf drwxr-xr-x. 2 root root 151 5月 8 09:35 conf.d lrwxrwxrwx. 1 root root 19 2月 10 2018 logs -\u003e ../../var/log/httpd lrwxrwxrwx. 1 root root 29 2月 10 2018 modules -\u003e ../../usr/lib64/httpd/modules lrwxrwxrwx. 1 root root 10 2月 10 2018 run -\u003e /run/httpd 配置 httpd2.2 httpd2.4 配置文件 /etc/httpd/conf/httpd.conf /etc/httpd/conf.d/*.conf /etc/httpd/conf/httpd.conf /etc/httpd/conf.d/*.conf /etc/httpd/conf.modules.d/*.conf(模块配置) 服务脚本 /etc/rc.d/init.d/httpd /etc/sysconfig/httpd(脚本配置) /usr/lib/systemd/system/httpd.service 主程序 /usr/sbin/httpd /usr/sbin/httpd.event /usr/sbin/httpd.worker /usr/sbin/httpd 支持MPM的动态切换 访问日志 /var/log/httpd/access_log /var/log/httpd/access_log 错误日志 /var/log/httpd/error_log /var/log/httpd/error_log 站点文档 /var/www/html /var/www/html 模块文件 /usr/lib64/httpd/modules /usr/lib64/httpd/modules 服务控制 chkconfig httpd on,off systemctl enable,disable httpd.service service {start,stop,restart,status,reload} httpd systemctl {start,stop,restart,status} httpd ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:2:1","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.2 http2.4 rpm 包 $ yum list all httpd* httpd.x86_64 2.4.6-80.el7.centos.1 updates httpd-devel.x86_64 2.4.6-80.el7.centos.1 updates httpd-itk.x86_64 2.4.7.04-2.el7 epel httpd-manual.noarch 2.4.6-80.el7.centos.1 updates httpd-tools.x86_64 2.4.6-80.el7.centos.1 updates httpd 相关rmp 包: httpd: httpd web 服务的主程序包 httpd-tools: httpd 相关的辅助工具 httpd-manual: httpd 文档 httpd $ rpm -ql httpd|grep -v share /etc/httpd # 配置文件 /etc/httpd/conf /etc/httpd/conf.d /etc/httpd/conf.d/* /etc/httpd/conf.modules.d /etc/httpd/conf/httpd.conf /etc/httpd/modules # httpd 模块所在目录 /usr/lib64/httpd/modules /usr/sbin/apachectl # httpd 相关的程序 /usr/sbin/fcgistarter /usr/sbin/htcacheclean /usr/sbin/httpd /usr/sbin/rotatelogs /usr/sbin/suexec /var/cache/httpd /var/cache/httpd/proxy /var/cache/httpd # 目录与日志文件 /var/cache/httpd/proxy /var/lib/dav /var/log/httpd /var/www /var/www/cgi-bin /var/www/html httpd-tools $ rpm -ql httpd-tools /usr/bin/ab # web 服务测试工具 /usr/bin/htdbm /usr/bin/htdigest /usr/bin/htpasswd # /usr/bin/httxt2dbm /usr/bin/logresolve ","date":"2018-03-14","objectID":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/:2:2","tags":["马哥 Linux"],"title":"17.4 apache httpd 简介","uri":"/posts/linux/linux_mt/20-web-apache/apache-httpd%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"17.3 http协议进阶","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"http协议进阶 在20.2 http协议基础我们对 http 协议做了简单介绍，本节我们来学 http 协议更深入的细节,包括: http 的状态追踪机制 http 协议的报文 市面上有很多的协议抓包分析工具，常见的有 tcpdump, tshark, wireshark，常见浏览器也提供了 http 协议的网络分析工具，大家可以学习了解了解。 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:0:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"1 http状态追踪 http 协议是无状态的(stateless),服务器无法持续追踪访问者来源。因此在 http 协议的基础上有 cookie 和 session 机制用来帮助状态追踪。 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:1:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"2. http 报文 请求报文 \u003cmethod\u003e \u003crequest-URL\u003e \u003cversion\u003e \u003cheaders\u003e \u003centity-body\u003e 响应报文 \u003cversion\u003e \u003cstatus\u003e \u003creason-phrase\u003e \u003cheaders\u003e \u003centity-body\u003e http 报文内容 http 的报文格式如上图所示，各个字段的含义如下 method: 请求方法，标明客户端希望服务器对资源执行的动作 – GET、HEAD、POST version: HTTP/\u003cmajor\u003e.\u003cminor\u003e，http 协议的版本 status: 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况； reason-phrase：状态码所标记的状态的简要描述； headers：每个请求或响应报文可包含任意个首部；每个首部都有首部名称，后面跟一个冒号，而后跟上一个可选空格，接着是一个值； entity-body：请求时附加的数据或响应时附加的数据； ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:2:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"2.1 method(方法)： http 协议的请求方法: GET：从服务器获取一个资源； HEAD：只从服务器获取文档的响应首部； POST：向服务器发送要处理的数据； PUT：将请求的主体部分存储在服务器上； DELETE：请求删除服务器上指定的文档； TRACE：追踪请求到达服务器中间经过的代理服务器； OPTIONS：请求服务器返回对指定资源支持使用的请求方法； ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:3:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"3.status(状态码) http 协议的状态码: 1xx：100-101, 信息提示； 2xx：200-206, 成功 3xx：300-305, 重定向 4xx：400-415, 错误类信息，客户端错误 5xx：500-505, 错误类信息，服务器端错误 常用的状态码： 200： 成功，请求的所有数据通过响应报文的entity-body部分发送；OK 301： 永久重定向，请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently 302： 临时重定向，与301相似，但在响应报文中通过Location指明资源现在所处临时新位置; Found 304： 条件式请求，客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端；Not Modified 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 请求被禁止；Forbidden 404： 服务器无法找到客户端请求的资源；Not Found 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应；Bad Gateway ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:4:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"4. headers(首部) http 的首部是形如 Name: Value的键值对，可分为: 通用首部 请求首部 响应首部 实体首部 扩展首部 Cache-Control:public, max-age=600 Connection:keep-alive Content-Type:image/png Date:Tue, 28 Apr 2015 01:43:54 GMT ETag:\"5af34e-ce6-504ea605b2e40\" Last-Modified:Wed, 08 Oct 2014 14:46:09 GMT Accept:image/webp,*/*;q=0.8 Accept-Encoding:gzip, deflate, sdch Accept-Language:zh-CN,zh;q=0.8 Cache-Control:max-age=0 Connection:keep-alive Host:access.redhat.com If-Modified-Since:Wed, 08 Oct 2014 14:46:09 GMT If-None-Match:\"5af34e-ce6-504ea605b2e40\" Referer:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/Installation_Guide/index.html User-Agent:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:5:0","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"4.1 通用首部： Date： 报文的创建时间 Connection：连接状态，如keep-alive, close Via：显示报文经过的中间节点 Cache-Control：控制缓存 Pragma： ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:5:1","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"4.2 请求首部： 基础请求首部 Accept：通知服务器自己可接受的媒体类型； Accept-Charset： Accept-Encoding：接受编码格式，如gzip Accept-Language：接受的语言 Client-IP： Host： 请求的服务器名称和端口号 Referer：包含当前正在请求的资源的上一级资源； User-Agent：客户端代理 条件式请求首部： Expect： If-Modified-Since：自从指定的时间之后，请求的资源是否发生过修改； If-Unmodified-Since： If-None-Match：本地缓存中存储的文档的ETag标签是否与服务器文档的Etag不匹配； If-Match： 安全请求首部： Authorization：向服务器发送认证信息，如账号和密码； Cookie： 客户端向服务器发送cookie Cookie2： 代理请求首部： Proxy-Authorization： 向代理服务器认证 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:5:2","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"4.3 响应首部： 信息性： Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多种表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其它首部列表； 安全响应首部： Set-Cookie：向客户端设置cookie； Set-Cookie2： WWW-Authenticate：来自服务器的对客户端的质询认证表单 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:5:3","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"4.4 实体首部： 基础实体首部 Allow： 列出对此实体可使用的请求方法 Location：告诉客户端真正的实体位于何处 Content-Encoding： 实体的编码方式 eg： gzip Content-Language： Content-Length： 主体的长度 Content-Location： 实体真正所处位置； Content-Type：主体的对象类型，MIME 类型 缓存相关： ETag：实体的扩展标签； Expires：实体的过期时间； Last-Modified：最后一次修改的时间 ","date":"2018-03-13","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/:5:4","tags":["马哥 Linux"],"title":"17.3 http协议进阶","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6/"},{"categories":["Linux"],"content":"17.2 http协议基础","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"http协议基础 前面我们了解了 web 的基础概念，本节来对 http 协议做一个更加详细的描述。 ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:0:0","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1. http 协议 http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html，有如下几个版本 http/0.9：原型版本，功能简陋 http/1.0: 增加了 cache, MIME, method, MIME：Multipurpose Internet Mail Extesion 多功能互联网邮件扩展 method：支持多种 http 方法，包括 GET， POST， HEAD，PUT， DELETE，TRACE， OPTIONS http/1.1：增强了缓存功能；spdy http/2.0：rfc ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:1:0","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.2 http 报文格式 http 报文有请求报文，响应报文组成，一次http事务包括完整的请求\u003c--\u003e响应 过程。报文格式如下所示。我们会在之后的章节中详细讲解 http 报文中各个字段的含义及作用，目前做了解即可。 请求报文 \u003cmethod\u003e \u003crequest-URL\u003e \u003cversion\u003e \u003cheaders\u003e \u003centity-body\u003e 示例如下: Host: ss1.bdstatic.com User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0 Accept: text/css,*/*;q=0.1 Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3 Accept-Encoding: gzip, deflate, br Referer: https://www.baidu.com/ Connection: keep-alive 响应报文 \u003cversion\u003e \u003cstatus\u003e \u003creason-phrase\u003e \u003cheaders\u003e \u003centity-body\u003e 示例如下: HTTP/1.1 200 OK Content-Encoding: gzip Content-Type: text/html;charset=utf-8 \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\" /\u003e \u003ctitle\u003eDocument\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003ethis is http response\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:2:0","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.1 MIME MIME: Multipurpose Internet Mail Extesion 作用: 多功能互联网邮件扩展，通过文本协议(http)发送非文本数据 MIME 类型: 媒体类型，由 http header 的 Content-Type 字段标识，决定了资源由哪一个浏览器外部插件打开 格式: major/minor text/html text/plain image/jpeg BDPAGETYPE: 1 BDQID: 0xbbfea62700012a90 Cache-Control: private Connection: Keep-Alive Content-Encoding: gzip Content-Type: text/html # MIME 类型 ..... ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:2:1","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.3 http 长短链接 http请求处理中的有两种连接模式： 非保持连接（短连接）：完成当前 http 事务后即断开 tcp 链接，下次请求需要重新建立链接 保持连接（又称长连接）：keep-alive，http 会复用当前的 tcp 链接。 tcp 链接的建立与拆除需要耗费时间，因此复用 tcp 链接能降低请求响应的时间，但是 tcp 链接会占用 web server 的 socket 文件，当链接过多时，其他客户将无法建立链接。所以是否启用保持链接取决于 tcp 链接的使用状态。通常情况下，http 1.1 中默认就会启动保持链接功能，服务器会在 tcp 链接达到一定时间，或者处理足够多的请求时自动断开链接，以免资源浪费。 ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:2:2","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"1.4 http请求过程 一次完整的 http 请求包括了如下过程: 建立或处理连接：接收请求或拒绝请求； 接收请求：接收来自于网络上的主机请求报文中对某特定资源的一次请求的过程； 处理请求：对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； 访问资源：获取请求报文中请求的资源； 构建响应报文： 发送响应报文： 记录日志： ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:2:3","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"2. 并发访问响应模型 web server 面对的时互联网上的所有潜在用户，因此同一时刻可能有多个用户访问我们的主机。面对多用户请求，web server 有如下几种访问响应模型: 单进程I/O模型：启动一个进程处理用户请求；这意味着，一次只能处理一个请求，多个请求被串行响应； 多进程I/O结构：并行启动多个进程，每个进程响应一个请求； 复用的I/O结构：一个进程响应n个请求； 多线程模式：一个进程生成n个线程，一个线程处理一个请求； 事件驱动(event-driven)：一个进程直接n个请求； 复用的多进程I/O结构：启动多个（m）个进程，每个进程生成（n）个线程； 响应的请求的数量：m*n ","date":"2018-03-12","objectID":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/:2:4","tags":["马哥 Linux"],"title":"17.2 http协议基础","uri":"/posts/linux/linux_mt/20-web-apache/http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"},{"categories":["Linux"],"content":"17.1 web服务基础概念","date":"2018-03-11","objectID":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/","tags":["马哥 Linux"],"title":"17.1 web服务基础概念","uri":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"categories":["Linux"],"content":"web服务基础概念 本章开始，我们将学习 Linux 运维中最重要的 web 服务。我们将学习: web 的基本概念和 http 协议 web 服务器 apache httpd 的安装与配置 web 服务也就是我们常说的网站开发，是构建在 http 协议上的 C/S 架构的应用程序。web serve 监听在 80 端口，浏览器就是我们的客户端。通过浏览器我们就可以访问 web 站点的内容。本节我们就来对 web 框架和浏览器的请求流程做一个概括性的描述。 ","date":"2018-03-11","objectID":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:0:0","tags":["马哥 Linux"],"title":"17.1 web服务基础概念","uri":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"categories":["Linux"],"content":"1. web 架构 最简单的 web 应用构建在我们通常称之为 LAMP 的架构上，如下图所示。 静态层称为 web 服务器(又叫静态资源服务器)，动态层称为应用程序服务器。之所以有动态和静态之分，是因为我们 web 资源分为两种类型 静态资源: 无须服务端做出额外处理,比如 .jpg, .png, .gif, .html, txt, .js, .css, .mp3, .avi 动态资源: 服务端需要通过执行程序做出处理，发送给客户端的是程序的运行结果，比如 .php, .jsp。 即我们看到的 web 页面的部分内容不是事先就存在的，而是根据每个访问的客户动态生成的，其中定制了每个人的特定信息。动态资源能根据用户的请求，到数据库中读取用户个人信息，然后执行再生成特定的页面供用户访问。 URL 通常一个页面中展示的资源可能有多个，每个资源都需要单独请求。每个资源由 URL(Uniform Resource Locator,统一资源定位符号)进行标识。URL 的格式为: \u003cscheme\u003e://\u003cuser\u003e:\u003cpassword\u003e@\u003chost\u003e:\u003cport\u003e/\u003cpath\u003e;\u003cparams\u003e?\u003cquery\u003e#\u003cfrag\u003e scheme: 协议类型，eg: http,https, ftp host: 主机 ip 地址 port: 端口 path: 资源在主机上的路经 params: 参数 http://www.magedu.com/bbs/hello;gender=f query： http://www.magedu.com/bbs/item.php?username=tom\u0026title=abc frag：https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/ web 服务器 常见的 web 服务器与应用程序有以下几种: web 服务器(静态资源服务器) httpd (apache) nginx lighttpd 应用程序服务器： 使用 C# 作为开发语言的 .Net 服务器: IIS 使用 java jsp 作为开发语言的 .jsp 服务器: tomcat, jetty, jboss, webshpere, weblogic 抛开动态层和数据层，客户端和 web 服务器就可以构成简单的 web 站点。 通信过程 web 是构建在 http 协议上的应用。http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html 这种超文本的应用层协议， 工作于tcp 的 80。 整个 web 请求和响应会有如下过程: web server 监听在 tcp 80 端口 用户在浏览器中输入网址，经 DNS 解析得到 ip 后，发起对 web server 的链接请求 通信双方基于 tcp 的三次握手建立 tcp 链接 web serve 收到用户的请求报文中对某一特定资源的请求 web server 对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； web server 获取请求的资源，构建响应报文，经 tcp 链接发送响应报文给客户端，并记录日志 浏览器接收响应报文并展示给用户 通信结束后，tcp 四次挥手断开 tcp 链接，通信结束。 web 技术栈 web 开发，分为前段和后端开发，前端指的是浏览器展示的页面，后端通常是应用程序部分。后端依所使用的开发语言而异，前端开发运用到的技术有: 2. html：hyper text mark language，超文本标记语言 3. css: Cascading Style Sheet 样式表 4. js：JavaScript, 客户端脚本 下面是一个简单的 html 的示例，这些技术如果了解过 web 开发很容易就会明白他们有什么作用。 \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eTITLE\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e\u003c/h1\u003e \u003cp\u003e blabla... \u003ca href=\"http://www.magedu.com/download.html\"\u003e bla... \u003c/a\u003e \u003c/p\u003e \u003ch2\u003e \u003c/h2\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2018-03-11","objectID":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:1:0","tags":["马哥 Linux"],"title":"17.1 web服务基础概念","uri":"/posts/linux/linux_mt/20-web-apache/web%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/"},{"categories":["Linux"],"content":"16.4 bind 高级配置","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"bind 高级配置 本节是 bind 配置的高级篇，实现 主从 DNS 服务器配置 DNS 子域授权 定义 DNS 的转发 DNS 访问控制 智能 DNS ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. 主从服务器 DNS 的主从配置，是以域名解析的区域为基本单位的，也就是说如果一台主机上配置了多个 DNS 解析域，为哪个区域配置了从域，哪个区域就实现了主从服务器配置。 配置从区域首先要在从服务器上配置 DNS 服务，但配置方法更简单，因为只要定义一个区域即可，无需配置区域解析库文件。然后在主 DNS 的解析库文件中添加从服务器。需要特别注意的是主从服务器的时间要同步否则无法实现主从同步，可使用 ntpdate命令完成时间同步。具体步骤如下 ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 On Slave 从域配置: 定义区域: 定义一个从区域； 配置文件语法检查：named-checkconf 重载配置 $ vim /etc/named.rfc1912.zones # 追加 zone \"ZONE_NAME\" IN { type slave; file \"slaves/ZONE_NAME.zone\"; # /var/named 目录是不允许 named 用户写的 masters { MASTER_IP; }; # 主服务器的 ip 地址 }; $ named-checkconf $ rndc reload ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 On Master 主域配置: 确保区域数据文件中为每个从服务配置NS记录， 并且在正向区域文件需要每个从服务器的NS记录的主机名配置一个A记录，且此A后面的地址为真正的从服务器的IP地址； $ vim /var/named/ZONE_NAME.zone @ IN NS ns2 # 从服务器具的 NS 记录 $ vim /var/named/ZONE_FQDN.zone # 必需在正向解析库文件中添加 A 记录 @ IN NS ns2 # 从服务器具的 NS 记录 ns2 IN A ip_addr # 从服务器的 ip 地址 ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:1:2","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. 子域授权 正向解析区域授权子域的方法，以在 magedu.com. 的二级域中授权 ops.magedu.com. 三级域为例: $ vim /var/named/ZONE_NAME.zone # 二级域的区域数据文件 ops.magedu.com. IN NS ns1.ops.magedu.com. # 子域的 NS 记录 ops.magedu.com. IN NS ns2.ops.magedu.com. ns1.ops.magedu.com. IN A IP.AD.DR.ESS # 子域的 A 记录 ns2.ops.magedu.com. IN A IP.AD.DR.ESS ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. 定义转发 默认情况下，DNS 服务在解析非自己负责的域名时，默认会向根域发起迭代查询。我们可以定义转发域，让 DNS 服务在解析非自己负责的域名时，向被转发服务器发起第归查询而不是向根域迭代查询。因此被转发的服务器必须允许为当前服务做递归。转发可分为区域转发和全局转发: ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 区域转发 区域转发: 仅转发对某特定区域的解析请求；配置方法如下 $ vim /etc/named.rfc1912.zones # 追加 zone \"ZONE_NAME\" IN { type forward; forward {first|only}; forwarders { SERVER_IP; }; }; 参数说明: forward:定义转发的特性 first：首先转发；转发器不响应时，自行去迭代查询； only：只转发； forwarders: 被转发服务器的 IP ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.2 全局转发 全局转发：凡本地没有通过zone定义的区域查询请求，通通转给某转发器； $ vim /etc/named.conf # 追加 options { ... ... forward {only|first}; forwarders { SERVER_IP; }; .. ... }; ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:3:2","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4. bind 安全配置 bind 的配置文件中可以使用 acl(访问控制列表)，把一个或多个地址归并一个命名的集合，随后通过此名称即可对此集全内的所有主机实现统一调用； acl 只能先定义后使用，所以通常位于 /etc/named.conf 最上面，并且是独立的配置段。 ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.1 acl acl acl_name { ip; net/prelen; }; # eg: acl mynet { 172.16.0.0/16; 127.0.0.0/8; }; ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:4:1","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.2 bind内置的acl bind 由四个内置的 acl: none：没有一个主机； any：任意主机； local：本机； localnet：本机所在的IP所属的网络； ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:4:2","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4.3 访问控制指令 访问控制指令位于 options 表示对全局生效，位于 zone区域段中，表示只对此区域有效，常见的控制指令有 allow-query {} 允许查询的主机；白名单，未在此范围内的不能发起查询 allow-transfer {} 允许向哪些主机做区域传送；默认为向所有主机； 应该配置仅允许从服务器；如果没有从服务器，必需设置为 None allow-recursion {} 允许哪些主机向当前DNS服务器发起递归查询请求； allow-update {} DDNS，允许动态更新区域数据库文件中内容；存在风险，一般都为 none $ vim /etc/named.conf acl \"slaves\" { 172.168.100.68; 172.168.0.0/16; } $ vim /etc/named.rfc1912.zones # 追加 zone \"magedu.com.\" IN { type master; file \"magedu.com.zone\" allow-transfer { slaves; }; allow-update { none; }; } ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:4:3","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"5. 智能 DNS - bind view 视图主要作用是实现，来自不同的用户的请求，可以返回不同的地址。比如来自内网的用户，得到的是内网的地址，来自公网的用户得到的是公网地址。 view VIEW_NAME { zone zone zone } 示例 view internal { # 优先匹配的位于上面 match-clients { 172.16.0.0/8; }; zone \"magedu.com\" IN { type master; file \"magedu.com/internal\"; # 内网的解析库文件 }; }; view external { match-clients { any; }; zone \"magecdu.com\" IN { type master; file magedu.com/external\"; # 外网的解析库文件 }; }; whois ","date":"2018-03-10","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/:5:0","tags":["马哥 Linux"],"title":"16.4 bind 高级配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"16.3 bind安装和配置","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"bind安装和配置 bind 全称为 Berkeley Internet Name Domain，是 DNS 协议的一种开源实现。由伯克利分校开发，现由 ISC 维护，也是现在使用最为广泛的DNS服务器软件，本节我们就来介绍如何使用 bind 配置一个 DNS 服务器。 ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. BIND ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.1 bind 安装 rpm 包组成 $ yum install bind $ yum list all bind* 已安装的软件包 bind.x86_64 32:9.9.4-61.el7 @base bind-libs.x86_64 32:9.9.4-61.el7 @base bind-libs-lite.x86_64 32:9.9.4-61.el7 @base bind-license.noarch 32:9.9.4-61.el7 @base bind-utils.x86_64 32:9.9.4-61.el7 @base bind 的 rpm 包主要由以下几个: bind：提供的dns server程序、以及几个常用的测试程序； bind-utils：bind客户端程序集，例如dig, host, nslookup等，可用于测试 dns 服务； bind-libs：被bind和bind-utils包中的程序共同用到的库文件； bind-chroot：选装，让named运行于jail模式下,目的是限定 bind 的运行环境，更加安全 程序文件 $ rpm -ql bind|grep sbin /usr/sbin/arpaname /usr/sbin/ddns-confgen /usr/sbin/dnssec-checkds # DNS 安全扩展 /usr/sbin/dnssec-coverage /usr/sbin/dnssec-dsfromkey /usr/sbin/dnssec-importkey /usr/sbin/dnssec-keyfromlabel /usr/sbin/dnssec-keygen /usr/sbin/dnssec-revoke /usr/sbin/dnssec-settime /usr/sbin/dnssec-signzone /usr/sbin/dnssec-verify /usr/sbin/genrandom /usr/sbin/isc-hmac-fixup /usr/sbin/lwresd /usr/sbin/named # bind serve 进程 /usr/sbin/named-checkconf # bind 配置文件检查 /usr/sbin/named-checkzone # DNS 数据库区域文件检查 /usr/sbin/named-compilezone /usr/sbin/named-journalprint /usr/sbin/nsec3hash /usr/sbin/rndc # bind 的远程控制工具 /usr/sbin/rndc-confgen bind rpm 包提供了以下核心程序: dnssec-*: Domain Name System Security Extensions,DNS 安全扩展 rndc: named 进程远程控制工具 named: bind server 的核心程序 named-checkconf: 用于检查 named 配置文件是否存在语法错误 named-checkzone: 用于检查 DNS 的区域解析库文件是否存在语法错误 named-checkconf named-checkconf [named.conf] 作用: 检查 named 配置文件是否存在语法错误 参数: named.conf 配置文件位置，默认为 /etc/named.conf named-checkzone named-checkzone zonename filename 作用: 用于检查 DNS 的区域解析库文件是否存在语法错误 参数: zonename: 区域名称 filename: 区域数据库文件所在位置 $ named-checkzone magedu.com. /var/named/magedu.com.zone ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:1:1","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.2 bind 配置文件 $ rpm -ql bind|egrep \"etc|var\"|grep -v \"share\" /etc/logrotate.d/named /etc/named /etc/named.conf # 核心配置文件 /etc/named.iscdlv.key # 核心配置文件内使用 include 包含的辅助配置文件 /etc/named.rfc1912.zones /etc/named.root.key /etc/rndc.conf # rndc 配置文件 /etc/rndc.key /etc/rwtab.d/named /etc/sysconfig/named /var/log/named.log # 日志文件 /var/named # DNS 数据库区域解析文件默认所在的目录 /var/named/data /var/named/dynamic /var/named/named.ca # 顶级域的配置文件 /var/named/named.empty /var/named/named.localhost /var/named/named.loopback /var/named/slaves bind 的配置文件包括两个部分: 主配置文件：/etc/named.conf 主配置文件内使用 include 包含进来辅助配置文件: /etc/named.iscdlv.key /etc/named.rfc1912.zones /etc/named.root.key 解析库文件默认存放在 /var/named/目录下；一般名字为：ZONE_NAME.zone。一台DNS服务器可同时为多个区域提供解析，且必需包含如下几个区域解析库文件: 根区域解析库文件： named.ca localhost 的正向解析库：named.localhost 127.0.0.1 的反向解析库：named.loopback 默认情况下，上述的区域解析库文件在 bind 安装时，已由 rpm 包自动提供。 ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1.3 bind 进程管理 $ rpm -ql bind|grep systemd /usr/lib/systemd/system/named-setup-rndc.service /usr/lib/systemd/system/named.service bind程序安装完成之后，默认即可做缓存名称服务器使用；如果没有专门负责解析的区域，直接即可启动服务。 CentOS 6: service named start CentOS 7: systemctl start named.service named 进程启动后，默认会监听 tcp 的 953 号端口，rndc 可通过此端口对 named 进程进行远程控制。但是 named 进程默认只监听在 127.0.0.1 上，因此仅允许本地使用。 rndc rndc：remote name domain contoller rndc [-b address] [-c config] [-s server] [-p port] [-k key-file ] [-y key] [-V] command command is one of the following: reload Reload configuration file and zones. reload zone [class [view]] Reload a single zone. refresh zone [class [view]] Schedule immediate maintenance for a zone. stats Write server statistics to the statistics file. status Display status of the server. stop Save pending updates to master files and stop the server. stop -p Save pending updates to master files and stop the server flush Flushes all of the server's caches. flush [view] Flushes the server's cache for a view. ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:2:1","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. bind 配置 ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.1 配置格式 $ cat /etc/named.conf options { # 全局配置段 listen-on port 53 { 127.0.0.1; }; listen-on-v6 port 53 { ::1; }; directory \"/var/named\"; # 区域解析库文件的默认存放目录 dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query { localhost; }; recursion yes; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file \"/etc/named.iscdlv.key\"; managed-keys-directory \"/var/named/dynamic\"; pid-file \"/run/named/named.pid\"; session-keyfile \"/run/named/session.key\"; }; logging { # 日志配置段 channel default_debug { file \"data/named.run\"; severity dynamic; }; }; zone \".\" IN { # 顶级域解析库配置文件 type hint; file \"named.ca\"; }; include \"/etc/named.rfc1912.zones\"; # 包含的辅助配置文件 include \"/etc/named.root.key\"; bind 的主配置 /etc/named.conf 由三个部分组成: 全局配置段：options { ... } 日志配置段: logging { ... } 区域配置段: zone { ... } 配置那些由本机负责解析的区域，或转发的区域 /etc/named.conf有如下语法要求: 每个配置语句必须以分号结尾 {} 左右都必需要有空格 使用 // 或 /* */ 进行注释 ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2.2 缓存名 DNS 服务器配置 named 进程默认启动后，即可作为缓存 DNS 服务器，但是默认配置只允许本地查询，无法对外提供服务，因此需要做如下修改。 更改 named 监听的地址，使其能与外部主机通信的地址； 学习使用时，建议关闭 dnssec 关闭仅允许本地查询配置 配置文件修改后应该使用named-checkconf，检查配置文件语法是否存在错误，在重起 named 进程。下面是配置过程 $ vim /etc/named.conf # 修改监听地址，使其能与外部主机通信的地址； listen-on port 53; listen-on port 53 { 172.16.100.67; }; # 学习时，建议关闭dnssec dnssec-enable no; dnssec-validation no; dnssec-lookaside no; # 关闭仅允许本地查询： //allow-query { localhost; }; # 检查配置文件语法 $ named-checkconf ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:3:2","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. 正反向解析区域配置 上一节我们学习过区域解析库文件的语法格式，现在我们就来学习，如何配置正向和反向区域。我们将以配置magedu.com 这个二级域为例。 ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:4:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 正向区域配置 配置一个正向解析区域需要: 定义区域: 在主配置文件中或主配置文件辅助配置文件中定义区域，区域名字即为域名 建立区域数据文件，正向区域的主要记录为A或AAAA记录，并更改配置文件属性 重启服务: 检查语法错误，然后让服务器重载配置文件和区域数据文件 下面是配置的详细过程: 定义区域 $ vim /etc/named.rfc1912.zones # 追加 zone \"magedu.com.\" IN { type master; file \"magedu.com.zone\"; }; 区域定义参数: type: 用于定义区域的主机类型，可选值为 master: 主服务器 slave: 从服务器 hint: 根域 forward file: 指定区域数据库文件位置，使用相对路经，则在 /etc/named.conf 配置的默认路经/var/named之下 建立区域数据文件 $ cd /var/named $ touch /var/named/magedu.com.zone # 创建区域数据文件 $ chgrp named /var/named/magedu.com.zone # 更改权限及属组 $ chmod o= /var/named/magedu.com.zone $ vim /var/named/magedu.com.zone $TTL 3600 $ORIGIN magedu.com. # ORIGIN 会自动补全下面 ns，mx1 的域名 @ IN SOA ns1.magedu.com. dnsadmin.magedu.com. ( 2017010801 1H 10M 3D 1D) IN NS ns1 IN MX 10 mx1 IN MX 20 mx2 ns1 IN A 172.16.100.67 mx1 IN A 172.16.100.68 mx2 IN A 172.16.100.69 www IN A 172.16.100.67 web IN CNAME www bbs IN A 172.16.100.70 bbs IN A 172.16.100.71 重启服务 # 检查语法错误 $ named-checkzone magedu.com. /var/named/magedu.com.zone $ named-checkconf # 重起服务 $ rndc reload # 或 $ systemctl reload named.service ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:4:1","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.2 反向解析区域配置 配置反向区域与配置正向区域类似，只不过区域名称和区域数据库文件不同: 反向区域的名字格式为: 反写的网段地址.in-addr.arpa, 例如区域 172.16.100 的区域名称为 100.16.172.in-addr.arpa 反向区域没有 MX 资源记录，主要为 PTR 资源记录 定义区域 $ vim /etc/named.rfc1912.zones # 追加 zone \"100.16.172.in-addr.arpa\" IN { type master; file \"172.16.100.zone\"; }; 建立区域数据文件 $ cd /var/named $ touch /var/named/172.16.100.zone # 创建区域数据文件 $ chgrp named /var/named/172.16.100.zone # 更改权限及属组 $ chmod o= /var/named/172.16.100.zone $ vim /var/named/172.16.100.zone $TTL 3600 $ORIGIN 100.16.172.in-addr.arpa. @ IN SOA ns1.magedu.com. nsadmin.magedu.com. ( 2017010801 1H 10M 3D 12H ) IN NS ns1.magedu.com. 67 IN PTR ns1.magedu.com. # 域名必需写全，此时 ORIGIN 不能补全 68 IN PTR mx1.magedu.com. 69 IN PTR mx2.magedu.com. 70 IN PTR bbs.magedu.com. 71 IN PTR bbs.magedu.com. 67 IN PTR www.magedu.com. 重启服务 # 检查语法错误 $ named-checkzone 100.16.172.in-addr.arpa /var/named/172.16.100.zone $ named-checkconf # 重起服务 $ rndc reload # 或 $ systemctl reload named.service ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:4:2","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"4. DNS 测试工具 dig dig [-t RR_TYPE] name [@SERVER] [query options] 作用: 用于测试dns系统，因此其不会查询hosts文件； 参数: name: DNS 资源记录的名称 @SERVER: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 +[no]trace：跟踪解析过程 +[no]recurse：进行递归解析； -x IP:进行反向解析测试 常用: 反向解析测试 : dig -x IP 模拟完全区域传送： dig -t axfr DOMAIN [@server] # 正向解析测试 $ dig -t NS baidu.com. $ dig -t A www.baidu.com ; \u003c\u003c\u003e\u003e DiG 9.9.4-RedHat-9.9.4-61.el7 \u003c\u003c\u003e\u003e -t A www.baidu.com +recurse ;; global options: +cmd ;; Got answer: ;; -\u003e\u003eHEADER\u003c\u003c- opcode: QUERY, status: NOERROR, id: 36303 ;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0 ;; QUESTION SECTION: ;www.baidu.com. IN A ;; ANSWER SECTION: www.baidu.com. 126 IN CNAME www.a.shifen.com. www.a.shifen.com. 126 IN A 61.135.169.125 www.a.shifen.com. 126 IN A 61.135.169.121 ;; Query time: 47 msec ;; SERVER: 192.168.1.1#53(192.168.1.1) ;; WHEN: 二 8月 14 11:54:53 CST 2018 ;; MSG SIZE rcvd: 90 # 反向解析测试 $ dig -x 61.135.169.125 host host [-t RR_TYPE] name [SERVER_IP] 作用: 用于测试dns系统，不会查询hosts文件； 参数: name: DNS 资源记录的名称 SERVER_IP: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 $ host -t A www.baidu.com www.baidu.com is an alias for www.a.shifen.com. www.a.shifen.com has address 61.135.169.125 www.a.shifen.com has address 61.135.169.121 $ host -t PTR 61.135.169.121 Host 121.169.135.61.in-addr.arpa. not found: 3(NXDOMAIN) nslookup nslookup [-options] [name] [server] 作用: 用于测试dns系统，默认进入交互式环境 nslookup\u003e server IP # 指定DNS服务器 set q=RR_TYPE # 要查询的资源记录类型； name # 要查询的名称 $ nslookup \u003e set q=A \u003e www.baidu.com Server: 192.168.1.1 Address: 192.168.1.1#53 Non-authoritative answer: www.baidu.com canonical name = www.a.shifen.com. Name: www.a.shifen.com Address: 61.135.169.121 Name: www.a.shifen.com Address: 61.135.169.125 \u003e ","date":"2018-03-09","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/:5:0","tags":["马哥 Linux"],"title":"16.3 bind安装和配置","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/bind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"16.2 DNS区域数据库文件格式","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"DNS区域数据库文件格式 DNS 的数据库文件记录了 FQDN 与 IP 的对应关系，有特定格式要求。本节我们就来学习DNS区域数据库文件格式 ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:0:0","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"1. 资源类型 DNS区域数据库文件一条记录为一行，被称为资源记录(Resource Record), 简称rr。常见的资源记录类型包括: SOA：Start Of Authority，起始授权记录； 一个区域解析库有且只能有一个SOA记录，而且必须放在第一条； NS：Name Service，域名服务记录；一个区域解析库可以有多个NS记录；其中一个为主的； A： Address, 地址记录，FQDN --\u003e IPv4； AAAA：地址记录， FQDN --\u003e IPv6； CNAME：Canonical Name，别名记录； PTR：Pointer，IP --\u003e FQDN MX：Mail eXchanger，邮件交换器；优先级：0-99，数字越小优先级越高 每种资源记录有特定的格式要求，接下来我们来分别介绍 ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:1:0","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2. DNS 资源记录的定义格式 name [TTL] IN RR_TYPE value 作用: DNS 资源记录定义的语法 参数: name: 名称 value: 名称对应的值与属性 TTL: Time To Live,有效是长 IN: 关键字 RR_TYPE： 资源类型 注意： TTL可以从全局继承； @表示当前区域的名称； 相邻的两条记录其name相同时，后面的可省略； 对于正向区域来说，各MX，NS等类型的记录的value为FQDN，此FQDN应该有一个A记录； 配置文件内 ; 后跟注释 FQDN 最后的根域名.不可省略 下面是各个资源记录的配置示例 # SOA leistudy.com. 86400 IN SOA ns.leistudy.com. nsadmin.leistudy.com. ( 2018022801 ;序列号 2H ;刷新时间 10M ;重试时间 1W ;过期时间 1D ;否定答案的TTL值 ) # NS leistudy.com. IN NS ns1.leistudy.com. leistudy.com. IN NS ns2.leistudy.com. # MX leistudy.com. IN MX 10 mx1.leistudy.com. IN MX 20 mx2.leistudy.com. # A www.leistudy.com. IN A 1.1.1.1 www.leistudy.com. IN A 1.1.1.2 mx1.leistudy.com. IN A 1.1.1.3 mx2.leistudy.com. IN A 1.1.1.3 # AAAA www.leistudy.com. IN AAAA ::1 # PTR 4.3.2.1.in-addr.arpa. IN PTR www.leistudy.com ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:0","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.1 SOA name [TTL] IN RR_TYPE value name: 当前区域的名字；例如mageud.com.，或者2.3.4.in-addr.arpa.； value：有多部分组成 当前区域的区域名称（也可以使用主DNS服务器名称）； 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般使用点号来替代 (主从服务协调属性的定义以及否定答案的TTL) magedu.com. 86400 IN SOA magedu.com. admin.magedu.com. ( 2017010801 ; serial 主从服务协调属性 2H ; refresh 10M ; retry 1W ; expire 1D ; negative answer ttl 否定答案的 TTL ) ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:1","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.2 NS name [TTL] IN RR_TYPE value name: 当前区域的区域名称 value: 当前区域的某DNS服务器的名字，例如ns.magedu.com.； 注意： 一个区域可以有多个ns记录； 相邻的两条记录其name相同时，后面的可省略； magedu.com. 86400 IN NS ns1.magedu.com. 86400 IN NS ns2.magedu.com. ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:2","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.3 MX name [TTL] IN RR_TYPE value name: 当前区域的区域名称 value：当前区域某邮件交换器的主机名； 注意：MX记录可以有多个；但每个记录的value之前应该有一个数字表示其优先级； # @ 可表示当前区域的名称 @ IN MX 10 mx1.magedu.com. @ IN MX 20 mx2.magedu.com. ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:3","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.4 A name [TTL] IN RR_TYPE value name：某FQDN，例如www.magedu.com. value：某IPv4地址； www.magedu.com. IN A 1.1.1.1 www.magedu.com. IN A 1.1.1.2 bbs.magedu.com. IN A 1.1.1.1 ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:4","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.5 AAAA name [TTL] IN RR_TYPE value name：FQDN value: IPv6 www.magedu.com. IN AAAA ::1 ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:5","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.6 PTR name [TTL] IN RR_TYPE value 作用: 反向解析的资源记录格式 name：IP地址，IP必需反过来写，而且必需加特定后缀；例如 1.2.3.4 的记录应该写为4.3.2.1.in-addr.arpa. value：FQND 4.3.2.1.in-addr.arpa. IN PTR www.magedu.com. ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:6","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"2.7 CNAME name [TTL] IN RR_TYPE value name: FQDN格式的别名； value: FQDN格式的正式名字； web.magedu.com. IN CNAME www.magedu.com. ","date":"2018-03-08","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/:2:7","tags":["马哥 Linux"],"title":"16.2 DNS区域数据库文件格式","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F/"},{"categories":["Linux"],"content":"16.1 DNS域名服务原理","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"DNS域名服务原理 本章我们开始学习 Linux 上的第一个服务，也是互联网的基础服务 DNS。之所以存在 DNS 服务是因为相对于数字形式的 ip 地址，人们更容易记住字符串，因此就有了将字符串格式的域名转换为数字格式的 ip 的需求。在互联网诞生的早期，计算机尚且属于稀缺资源，域名与 ip 地址的对应关系，保存在本地的 hosts (/etc/hosts) 文件上。随着连入互联网的主机越来越多，每个主机都保存所有域名与ip 对应的的副本已经不现实，于是就有了 DNS 服务。本节我们就来讲解 DNS 服务，内容包括: DNS 服务的原理 DNS 域名解析的过程 DNS 区域数据库文件 使用 bind 配置 DNS 服务 DNS 虽然是互联网的基础服务，但是实际上很少人会买域名，配置 DNS 服务器的人很少，所以很多人对 DNS 服务并不熟悉。本节我们就来讲解 DNS 服务的基本原理。 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1. DNS 概述 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1.1 DNS 相关概念 DNS 全称为 Domain Name Service 属于应用层协议，工作于 udp/tcp 的 53 号端口。DNS 服务工作于 udp 53 号端口，tcp 的 53 端口用于实现主从 DNS 同步。 为了分散 DNS 查询的负载，同时方便域名的管理，DNS 被组织成一个倒置的树结构。如下图所示 根域为 .，其下是顶级域和国家域，每个顶级域由不同的机构进行域名管理。顶级域下是二级域，我们购买的域名不是单个域名而是整个二级域，购买后可根据需要配置子域。比如，我在.com.顶级域下购买了域 tao.com.，可根据需求配置一个域名 web.tao.com.,也可以配置 image.web.tao.com.，对于域名大范围在右边，小范围在左边。 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:1","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1.2 DNS 服务 上面展示的倒置树是 DNS 的结构示意图，在每个域上，都是有一个个 DNS 服务器。DNS 服务由 bind 程序提供。按照提供的服务类型，可将 DNS 服务器分为 负责解析至少一个域的主名称服务器和辅助名称服务器； 不负责哉解析的缓存名称服务器； ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:2","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1.3 DNS 查询请求流程 12 章中我们讲解了如何配置 Linux 的网络属性，/etc/resolv.conf 配置文件内配置了我们的 DNS 服务器指向。当我们在浏览器内输入 www.baidu.com 时，将按照如下的顺序查询 百度的 ip 地址: 首先会访问本地的 hosts文件，如果有记录则直接返回结果 查询本地的DNS缓存DNS，有则直接返回 向 /etc/resolv.conf 配置的 DNS 服务器发起查询请求 如果域名是自己负责解析的域，DNS 服务器将直接查询数据库并返回结果； 如果不是自己负责解析域，并且服务器内未缓存，DNS 服务器将向发起迭代查询 如上图所式，配置文件指向的 DNS 服务器，将帮助我们按照 DNS 的层级结构从顶至下发起迭代查询，直至查询到结果返回给我们。 因此 DNS 的查询可分为: 递归查询：本机向配置的 DNS 服务器发起的即是递归查询，DNS 服务器返回给我们的是结果 迭代查询：DNS 服务向上层 DNS 服务器发起的则是迭代查询，需要根据返回结果继续迭代查询。 DNS 服务器返回给我们的结果有如下几种情况: 肯定答案：域名的解析结果 否定答案：不存在查询的键，因此，不存在与其查询键对应的值； 权威答案：由直接负责的DNS服务器返回的答案； 非权威答案：由非直接负责的DNS服务器的缓存返回，有可能缓存失效 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:3","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1.4 DNS 反向解析 DNS 除了将域名解析为 ip 外，还能将 ip 解析为主机名 名称 –\u003e IP：正向解析 IP –\u003e 名称：反向解析 但是需要注意的是，正向反向解析的的名称空间，不是同一个空间，即正向反向解析不是同一棵树，使用的是不同的解析库文件 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:4","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1.5 DNS 中的区域与域 域(domain)，FQDN（Full Qualified Domain Name）是一种逻辑概念，包括物理上的 由 FQDN --\u003e IP 的正向解析区域(zone) 由 IP --\u003e FQDN 的反向解析区域(zone) ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:1:5","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"2. 主从 DNS 服务器 为了放置 DNS 单节点故障导致整个服务不可用，也为了平衡负载，DNS 服务器通常为主从模式 主DNS服务器：为维护所负责解析的域数据库的那台服务器；读写操作均可进行； 从DNS服务器：从主DNS服务器那里或其它的从DNS服务器那里“复制”一份解析库；但只能进行读操作； ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"2.1 主从同步方式 DNS 服务器的主从复制有如下特性: 数据库有序列号(serial),即数据库的版本号；主服务器数据库内容发生变化时，其版本号递增 从服务器会按照设置的时间间隔从主服务器同步数据 refresh: 刷新时间间隔,从服务器每多久到主服务器检查序列号更新状况 retry: 重试时间间隔, 从服务器从主服务器请求同步解析库失败时，再次发起尝试请求的时间间隔； expire: 过期时长，从服务器始终联系不到主服务器时，多久之后放弃从主服务器同步数据；停止提供服务； 处理从服务器定时同步外，主服务器会在每次数据发生变更时，通知从服务器随时更新数据 数据传送(区域传送)分为如下两种，通常只会进行增量传送 全量传送：axfr, 传送整个数据库； 增量传送：ixfr, 仅传送变量的数据 ","date":"2018-03-07","objectID":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/:2:1","tags":["马哥 Linux"],"title":"16.1 DNS域名服务原理","uri":"/posts/linux/linux_mt/19-dns%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98/dns%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"15.4 私建 CA","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"私建 CA 很多时候我们为了测试目的，或者不便让用户去申请证书，我们就需要私建 CA，本节我们就来讲解如何私建 CA。 ","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/:0:0","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"1. 私建 CA CA创建的工具有两个，小范围内可直接使用 openssl 命令，如果要维护大量的CA，可以使用完全 CA 创建工具 openCA。 那么如何创建 CA？前面我们知道 PKI 公钥基础设施包括如下几个部分: 签证机构：CA 注册机构：RA 证书吊销列表：CRL 证书存取库： 所以私建 CA 首先要创建出上述的基础设施，然后才能签发证书。而证书的申请及签发大体上包括以下步骤: 申请方生成申请请求 RA 进行核验 CA 签署 证书获取 下面我们就分创建 CA，和签发一个证书两个步骤讲解私建 CA的整个过程。 ","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/:1:0","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"1.1 创建公钥基础设施 创建一个私有 CA非常简单，只要在确定配置为 CA 的服务上生成一个自签证书，并为CA提供所需要的目录及文件即可。CA 所需的目录定义在 CA 的配置文件中 /etc/pki/tls/openssl.cnf # less /etc/pki/tls/openssl.conf #################################################################### [ ca ] default_ca = CA_default # The default ca section #################################################################### [ CA_default ] dir = /etc/pki/CA # CA 的工作目录 certs = $dir/certs # 已经签发的证书目录 crl_dir = $dir/crl # 已吊销证书的放置目录 database = $dir/index.txt # 已经签发证书的索引 #unique_subject = no # Set to 'no' to allow creation of # several ctificates with same subject. new_certs_dir = $dir/newcerts # default place for new certs. certificate = $dir/cacert.pem # CA自签证书 serial = $dir/serial # 当前序列号，表示新签发证书的编号 crlnumber = $dir/crlnumber # 新吊销证书的编号 # must be commented out to leave a V1 CRL crl = $dir/crl.pem # The current CRL private_key = $dir/private/cakey.pem # CA 私钥 RANDFILE = $dir/private/.rand # private random number file default_days = 365 # 证书默认的有效时长 default_crl_days= 30 # how long before next CRL ","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/:1:1","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"1.2 证书申请签发查看 openssl req [options] outfile 作用: 生成证书签署请求 选项: -new：生成新证书签署请求； -x509: 生成自签格式证书，专用于创建私有CA时； -key：生成请求时用到的私钥文件,openssl 会自动提取出公钥放置在证书签署请求中； -out：生成的请求文件路径，自签证书将直接生成签署过的证书 -days：证书的有效时长，单位是day； openssl ca 作用: CA 签发证书 选项: -in \u003cfile\u003e: 证书签署请求文件路径 -out \u003cfile\u003e: 生成的新证书的保存路径 -days：证书的有效时长，单位是day； openssl x509 作用: 查看证书信息 选项: -in：指定输入文件，默认是标准输入。 -out：指定输出文件，默认是标准输出。 -passin：指定私钥密码的来源 -serial：显示序列号。 -subject：打印项目的DN -issuer：打印签发者的DN -email：打印email地址 -startdate：打印开始日期 -enddate：打印结束日期 -purpose：打印证书的用途 -dates：打印开始日期和结束日期 -public：输出公钥 -fingerprint：输出证书的指纹 -noout：没证书输出 -days: 设置证书的有效期时间，默认30天 -req：输入是一个证书请求，签名和输出 -CA：设置CA证书，必须是PEM格式的 -text：以文本格式输出证书 ","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/:1:2","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"1.3 构建私有CA步骤 # 1. 生成所需要的文件和目录 $ dir=/etc/pki/CA $ cd $dir $ touch {serial,index.txt} $ echo 01 $ serial $ mkdir -pv $dir{certs,crl,newcerts} # 2. CA 自签证书 # 生成私钥 $ (umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096) $ openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655 # new：生成新证书签署请求； # x509：生成自签格式证书，专用于创建私有CA时； # key：生成请求时用到的私钥文件； # out：证书的保存路径 # days：证书的有效时长，单位是day； # 3. 发证 # 3.1 要用到证书的主机生成证书请求： # 3.2 把请求文件传输给 CA # 3.3 CA 验证证书合法性，签署证书，并将证书发还给请求者 # 3.1 步骤：（以httpd为例） # 用到证书的主机生成私钥 $ mkdir /etc/httpd/ssl $ cd /etc/httpd/ssl $ (umask 077; openssl genrsa -out /etc/httpd/ssl/httpd.key 2048) # 生成证书签署请求，(csr - certificate security request) $ openssl req -new -key /etc/httpd/ssl/httpd.key -out /etc/httpd/ssl/httpd.csr -days 365 # 3.2 将请求通过可靠方式发送给CA主机； $ scp /etc/httpd/ssl/httpd.csr root@196.168.1.105:/tmp # 3.3 在CA主机上签署证书 (crt - certificate 的简写) $ openssl ca -in /tmp/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365 # 3.4 查看证书中的信息： $ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -text # 4. 吊销证书： # 4.1. 客户端获取要吊销的证书的serial： $ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject # 4.2 CA主机吊销证书 # 先根据客户提交的serial和subject信息，对比其与本机数据库index.txt中存储的是否一致； # 吊销, 其中的SERIAL要换成证书真正的序列号； $ openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem # 4.3. 生成吊销证书的吊销编号（第一次吊销证书时执行） $ echo 01 $ /etc/pki/CA/crlnumber # 4.4 更新证书吊销列表 $ openssl ca -gencrl -out thisca.crl # 4.5 查看crl文件： $ openssl crl -in /PATH/FROM/CRL_FILE.crl -noout -text ","date":"2018-03-06","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/:1:3","tags":["马哥 Linux"],"title":"15.4 私建 CA","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E7%A7%81%E5%BB%BAca/"},{"categories":["Linux"],"content":"15.3 openssl 命令使用","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"openssl 命令使用 OpenSSL 分为三个组成 libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 openssl 命令行工具有多个子命令，大体上分为如下三类 标准命令(standard) 消息摘要命令（dgst子命令） 加密命令（enc子命令） 本节我们就来讲解常见命令的使用 ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. openssl 使用概述 openssl ? openssl:Error: '?' is an invalid command. Standard commands # 可使用的标准子命令 asn1parse ca ciphers cms crl crl2pkcs7 dgst dh dhparam dsa dsaparam ec ecparam enc engine errstr gendh gendsa genpkey genrsa nseq ocsp passwd pkcs12 pkcs7 pkcs8 pkey pkeyparam pkeyutl prime rand req rsa rsautl s_client s_server s_time sess_id smime speed spkac ts verify version x509 # 消息摘要子命令 dgst, 下面是可用的算法 Message Digest commands (see the `dgst' command for more details) md2 md4 md5 rmd160 sha sha1 # 对称加密子命令 enc，下面是可用的算法 Cipher commands (see the `enc' command for more details) aes-128-cbc aes-128-ecb aes-192-cbc aes-192-ecb aes-256-cbc aes-256-ecb base64 bf bf-cbc bf-cfb bf-ecb bf-ofb camellia-128-cbc camellia-128-ecb camellia-192-cbc camellia-192-ecb camellia-256-cbc camellia-256-ecb cast cast-cbc cast5-cbc cast5-cfb cast5-ecb cast5-ofb des des-cbc des-cfb des-ecb des-ede des-ede-cbc des-ede-cfb des-ede-ofb des-ede3 des-ede3-cbc des-ede3-cfb des-ede3-ofb des-ofb des3 desx idea idea-cbc idea-cfb idea-ecb idea-ofb rc2 rc2-40-cbc rc2-64-cbc rc2-cbc rc2-cfb rc2-ecb rc2-ofb rc4 rc4-40 rc5 rc5-cbc rc5-cfb rc5-ecb rc5-ofb seed seed-cbc seed-cfb seed-ecb seed-ofb zlib ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. 标准命令 ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 生成用户密码 openssl password [OPTIONS] [password] 作用: 生成用户密码 参数: password 用户密码，可省略，默认会提示用户输入 选项: -crypt : standard Unix password algorithm (default) -1 : MD5-based password algorithm -salt string: use provided salt -in file : read passwords from file -stdin : read passwords from stdin -reverse : switch table columns $ openssl passwd -1 -salt tabc Password: # 根据提示输入用户密码 $1$tabc$dMfThcS/0AhHbG277/5.Y. ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 生成随机数 openssl rand OPTIONS num 参数: NUM 表示字节数 选项: -out file: write to file -base64 : base64 encode output -hex : hex encode output $ openssl rand -base64 10 CyrtOhCwGXySRQ== $ openssl rand -hex 10 61fc2a72e000622746f4 $ openssl passwd -1 -salt `openssl rand -hex 4` Password: $1$e3a21fb9$Zahip67zta7xJB2QiaVAm0 ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. 加密命令 ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.1 对称加密 openssl enc -ciphernam OPTIONS 作用: 使用对称加密算法加密文件 选项: -e: 加密 -d: 解密 -a/-base64: 使用 base64 编码和解码文件 -ciphernam: 指定使用的加密算法 -in \u003cfile\u003e: 待加密的明文文件 -out \u003cfile\u003e: 加密后的密文输出路径 -pass \u003carg\u003e: 加密使用的密码 -md: 指定密钥生成的摘要算法，用户输入的口令不能直接作为文件加密的密钥，而是经过摘要算法做转换，此参数指定摘要算法，默认md5 -S: 在把用户密码转换成加密密钥的时候需要使用盐值，默认盐值随机生成 -salt: use a salt in the key derivation routines. This is the default # -e 加密 openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertext # -d 解密 openssl enc -d -des3 -a -salt -out fstab -in fstab.ciphertext ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:1","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.2 单向加密 openssl dgst OPTIONS file 作用: 使用单向加密算法，提取摘要信息 参数: file 指定提取摘要的文件 提取算法: -md4 -md5 -ripemd160 -sha -sha1 -sha224 -sha256 -sha384 -sha512 -whirlpool 选项: -c : to output the digest with separating colons -r : to output the digest in coreutils format -d : to output debug info -hex : output as hex dump -binary : output in binary form $ openssl dgst -md5 /PATH/TO/SOMEFILE $ md5sum /path/to/somefile ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:2","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.3 公钥加密 openssl rsautl 作用: 使用RSA密钥进行加密、解密、签名和验证等运算 算法： 加解密: RSA，ELGamal 数字签名：RSA， DSA， ELGamal 密钥交换：DH ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:3","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3. 生成密钥 openssl genrsa OPTIONS numbits 作用: 生成私钥 参数: numbits 私钥的长度，只能是 1024 的证书倍 参数: -out \u003cfile\u003e: 输出的文件路径 -passout arg: 指定密钥文件的加密口令，可从文件、环境变量、终端等输入 openssl rsa [options] \u003cinfile \u003eoutfile 作用: 管理生成的密钥，rsa 默认输出私钥，通过 -pubout 指定输出公钥 选项: -in arg :输入文件 -out arg :输出文件 -passin arg :指定输入文件的加密口令，可来自文件、终端、环境变量等 -passout arg:指定输出文件的加密口令，可来自文件、终端、环境变量等 -pubin :指定输入文件是公钥 -pubout :指定输出文件是公钥 -text :以明文形式输出各个参数值 -check :检查输入密钥的正确性和一致性 # 生成私钥 # shell 中 () 内的命令会在同一个子 shell 中执行 $ (umask 077; openssl genrsa -out /PATH/TO/PRIVATE_KEY_FILE NUM_BITS) # 提出公钥 $ openssl rsa -in /PATH/FROM/PRIVATE_KEY_FILE -pubout -out outputfile ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:4","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"4. Linux系统上的随机数生成器 Linux 中有如下几个随机数生成器 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞； /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数，非阻塞；伪随机数不安全； 附注: 熵池中随机数的来源： 硬盘IO中断时间间隔； 键盘IO中断时间间隔； ","date":"2018-03-05","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:4:0","tags":["马哥 Linux"],"title":"15.3 openssl 命令使用","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/openssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"15.2 公钥基础设置与ssl会话","date":"2018-03-04","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/","tags":["马哥 Linux"],"title":"15.2 公钥基础设置与ssl会话","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/"},{"categories":["Linux"],"content":"公钥基础设置与ssl会话 上一节我们学习了通信加密的基础知识，常见的加密解密算法，ssl/tls 协议。 还概括性的介绍了在已知公钥和基于公钥基础设施实现安全通信的过程。ssl/tls 正是用来规范如何通过公钥基础设施来进行安全通信的协议，本节我们就来详细讲解公钥基础设施，数字证书以及 ssl 会话建立的过程。 ","date":"2018-03-04","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/:0:0","tags":["马哥 Linux"],"title":"15.2 公钥基础设置与ssl会话","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/"},{"categories":["Linux"],"content":"1. 公钥基础设施 公钥基础设置，PKI(Public Key Infrastructure)，由以下部分: 签证机构：CA，实际签发数字证书的机构 注册机构：RA，接收证书申请的机构 证书吊销列表：CRL 证书存取库 证书申请方向注册机构发起证书申请请求，注册机构统一提交给签证机构，由签证机构对申请者进行尽责调查，在确认无误后向申请方签发证书。如果申请者私钥丢失等其他原因，可向签证机构申请吊销证书。 ","date":"2018-03-04","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/:0:1","tags":["马哥 Linux"],"title":"15.2 公钥基础设置与ssl会话","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/"},{"categories":["Linux"],"content":"2. 数字证书 X.509v3 定义了证书的结构以及认证协议标准，数字证书包含了以下内容: 版本号 序列号 签名算法ID: 提取数字证书特征码的单向加密算法 发行者名称 有效期限 主体名称 主体公钥 发行者的惟一标识 主体的惟一标识 扩展 发行者的签名: CA 私钥对数字证书的特征码加密后的结果 ","date":"2018-03-04","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/:0:2","tags":["马哥 Linux"],"title":"15.2 公钥基础设置与ssl会话","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/"},{"categories":["Linux"],"content":"2. SSL会话 ssl 会话创建需要三个步骤: 客户端向服务器端索要并验正证书； 双方协商生成“会话密钥”； 双方采用“会话密钥”进行加密通信； SSL Handshake Protocol(ssl 握手协议) 就是用来规范客户端与服务器端如何协商生成会话密钥。如下图所示，其分成了四个阶段 第一阶段：ClientHello 客户端将向服务器端发送以下信息: 支持的协议版本，比如tls 1.2； 客户端生成一个随机数，稍后用户生成“会话密钥” 支持的加密算法，比如AES、3DES、RSA； 支持的压缩算法； 第二阶段：ServerHello 服务器端将向客户端发送以下信息 确认使用的加密通信协议版本，比如tls 1.2； 服务器端生成一个随机数，稍后用于生成“会话密钥” 确认使用的加密方法； 服务器证书； 第三阶段-Client： 客户端接收到服务器的证书后，验正服务器证书，在确认无误后取出其公钥；（发证机构、证书完整性、证书持有者、证书有效期、吊销列表）。发送以下信息给服务器端： 一个随机数； 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 客户端握手结束通知； 第四阶段-Server 服务器端收到客户端发来的第三个随机数pre-master-key后，计算生成本次会话所有到的“会话密钥”；向客户端发送如下信息： 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 服务端握手结束通知； ","date":"2018-03-04","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/:1:0","tags":["马哥 Linux"],"title":"15.2 公钥基础设置与ssl会话","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D/"},{"categories":["Linux"],"content":"15.1 通信加密和解密技术入门","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"通信加密和解密技术入门 从本章开始，我们进入 Linux 学习的第二部分 Linux 网络服务与安全。第二部分会涉及到以下的内容 网络安全加密，Openssl，Openssh DNS 服务 web 服务，包括构建在 apache httpd 服务上的 LAMP，和构建在 nginx 上的 LNMP 文件服务，包括 nfs，samble，ftp 自动化安装相关的 dhcp，pxe 防火墙 iptables 系统管理相关的一些命令和服务包括 sudo，pam, nsswitch 本章我们将学习网络加密和解密技术，内容分成了三个部分: 基础知识，包括常见的加密算法，ssl 协议，以及安全通信中的基础设施 CA 如何利用我们的加密算法实现安全通信 加密工具 openssl工具的使用 很多互联网的基础协议诞生于互联网产生的初期，那时候能使用互联网的人很少，能实现主机之间的通信就已经很不容易，也就没有安全通信的需求，所以大多数的基础网络通信协议都是明文传输的。随着互联网的普及，安全通信的需求越来越迫切，ssl 协议孕育而生，它位于应用层和传输层之间，为所有的应用层协议提供可选的安全通信服务。安全通信需要各种加密技术，同时也出现了通信安全的基础设施 CA，本节就会介绍这部分的基础知识，内容包括 网络安全概述，包括安全的目标，面临的威胁，以及可能的防范手段 ssl 协议的作用和实现 加密算法和协议 公钥基础设施及安全通信的过程 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:0:0","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"1. 网络安全概述 安全的目标： 保密性：confidentiality 完整性：integrity 可用性：availability 攻击类型： 威胁保密性的攻击：窃听、通信量分析； 威胁完整性的攻击：更改、伪装、重放、否认 威胁可用性的攻击：拒绝服务（DoS） 解决方案： 技术（加密和解密）、服务（用于抵御攻击的服务，也即是为了上述安全目标而特地设计的安全服务） 加密和解密： 传统加密方法：替代加密方法、置换加密方法 现代加密方法：现代块加密方法 服务： 认证机制 访问控制机制 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:1:0","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2. ssl 协议 通信协议栈分为 5 层，最上面是应用层，又称为资源子网，关注的是只关心数据是如何组织起来的，传输层及以下又称为通信子网关注的是如何传输数据。 ssl(Secure Sockets Layer) 协议相当于位于应用层与传输层之间的半层，它是可选的，可为所有的应用协议提供可选的安全通信服务。ssl 有众多实现，最著名的开源实现是 OpenSSL，任何想使用安全通信的服务，只要在进行网络传输时调用 OpenSSL 提供的服务即可。以 https 服务为例 http --\u003e ssl --\u003e https。 通过 OpenSSL 实现安全通信的过程其实是非常复杂的，http 与 https 其实是两个独立的服务，http的服务的默认端口是 80，https 则是 443。 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:1:1","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.1 ssl 版本 SSL协议的诞生 Netscape（网景通信公司）在1994年创建了SSL协议的原始规范，但是第一个SSL协议版本因为使用弱加密算法受到密码学界的质疑，所以从来没有公开发布过。Netscape在1995年2月修订了规范，并发布了一个大大改进的版本SSL 2.0协议，虽然SSL 2.0版本被认为是一个相当强大和健壮的协议，但仍存在一些易受攻击的漏洞。 SSL协议更名TLS协议 在1996年，由Netscape和Paul Kocher共同设计的版本SSL 3.0协议发布。SSL(Secure sockets Layer) 3.0协议获得互联网广泛认可和支持，因特网工程任务组（IETF）接手负责该协议，并将其重命名为传输层安全 TLS(Transport Layer Security) 协议。TLS协议的第一个版本（RFC 2246）于1999年1月发布，实质上就是SSL 3.0协议的适度改进版。虽然TLS协议和SSL协议是同一个协议的迭代升级，但是其重命名后在名称上造成的混淆一直延续到今天，业内通常将二者统称为SSL/TLS协议。 当前正在使用的时 TLS 的 V1.0, V1.1, V1.2, V1.3。TLS 采用分层设计 最底层：基础算法原语的实现，aes, rsa, md5 向上一层：各种算法的实现； 再向上一层：组合算法实现的半成品； 用各种组件拼装而成的各种成品密码学协议软件； ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:1:2","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"2.2 ssl 开源实现 Linux系统上 ssl 有两个开源实现:OpenSSL(ssl) 和 GPG(pgp)。GPG 是商业软件 pgp 的开源实现。更常用的是 OpenSSL，因此我们主要讲解 OpenSSL。OpenSSL 由三个部分组成: libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:1:3","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3. 加密算法和协议 加密算法分为以下几类，它们具有不同的特性，在安全通信中用于不同的安全目标。 对称加密: 数据加密 公钥加密: 数字签名和密钥交换 单向加密: 数据完整性认证 密钥交换: 完成密钥交换的特定协议 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:2:0","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.1 对称加密 定义: 加密和解密使用同一个密钥； 特性： 加密、解密使用同一个密钥； 将原始数据分割成为固定大小的块，逐个进行加密； 缺陷： 密钥过多； 密钥分发困难 算法 DES：Data Encryption Standard; 3DES：Triple DES; AES：Advanced Encryption Standard; (128bits, 192bits, 256bits, 384bits) Blowfish Twofish IDEA RC6 CAST5 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:2:1","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.2 公钥加密： 定义: 密钥分为公钥与私钥 公钥：从私钥中提取产生；可公开给所有人；pubkey 私钥：通过工具创建，使用者自己留存，必须保证其私密性；secret key； 特点：用公钥加密的数据，只能使用与之配对儿的私钥解密；反之亦然； 缺陷：加密时间长 用途： 数字签名：主要在于让接收方确认发送方的身份； 密钥交换：发送方用对方公钥加密一个对称密钥，并发送给对方； 数据加密 算法： RSA， DSA， ELGamal DSS: Digital Signature Standard DSA：Digital Signature Algorithm 3.3 单向加密 定义: 用于提出数据指纹；只能加密，不能解密； 特性：定长输出、雪崩效应； 功能：数据完整性校验； 算法： md5：Message Digest 5, 128bits sha1：Secure Hash Algorithm 1, 160bits sha224, sha256, sha384, sha512 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:2:2","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"3.4 密钥交换协议 密钥交换协议 IKE（Internet Key Exchange）主要作用是如何在不安全的网络环境中实现密钥交换。 主要有以下算法 RSA，使用公钥加密进行密钥交换 DH算法(迪菲-赫尔曼算法) ECDH(椭圆曲线DH算法) ECDHE(临时椭圆曲线DH算法) DH 算法的密钥交换过程如下所示 公钥加密 DH（Deffie-Hellman） A：p, g B：p, g A: x --\u003e p^x%g ==\u003e B A: (p^y%g)^x=p^yx%g B: y --\u003e p^y%g ==\u003e A B: (p^x%g)^y=p^xy%g ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:2:3","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"4. 公钥基础设施与安全通信过程 公钥基础设施主要作用是确保安全的获取通信双方的公钥，要完整了解公钥基础设施与安全通信过程我们得分成两步: 在已知通信双方公钥的情况下，我们如何安全通信 公钥基础设施如何确保我们安全拿到对方的公钥 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:3:0","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"4.1 已知公钥下安全通信过程 A —\u003e B A -----\u003e B ----\u003e 作用 ----------------------------------------------------- B公钥加密的 B 私钥解密 密钥交换 对称加密密钥 获取对称密钥 ------------------------------------------------------ 对称加密的 ------\u003e 使用对称密钥 -----\u003e 数据保密性 传输内容 解密传输内容 --------------------------------------------------------- A私钥加密的 --------\u003e 使用 A 公钥解密指纹 ---\u003e A 身份验证 传输内容的指纹 重算传输内容指纹 对比指纹 ---\u003e 数据完整性 A: A 使用单向加密提取传输内容特征码，并使用自己的私钥加密特征码 A 使用对称密钥加密传输内容 A 使用 B 的公钥加密使用到的对称加密的密钥 B: B 使用自己的私钥解密获取对称加密的密钥 使用对称加密密钥解密整个文件内容 使用 A 的公钥解密获取邮件内容特征码 使用同样的加密算法提取接收内容的特征码，与解密的特征码对比验证数据完整性 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:3:1","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"4.2 基于CA获取公钥 A —\u003e B 数字证书交换及验证 通信双方分别发送 hello 信息给对方，开启 ssl 会化，然后协商后续通信过程使用的加密算法等信息 双方分别获取对方的数字证书 通过发行者名称获取本地已经保存的CA的证书，获取CA公钥 验证CA: 使用 CA 公钥解密发行者签名，认证 CA，并获取数字证书特征码 验证数字证书完整性: 使用数字证书中签名算法ID表明的单向加密算法重新计算特征码，并与 3 中解密出来的特征码进行比对 对于主机数字证书，主体名称必须与访问的主机名称(域名) 必须一致，否则也可能不会通过认证 证书验证包括: 证书内容完整有效 证书名称与访问服务器是否一致 证书是否是信任的CA颁发的 证书是否在有效期内 证书是否在CA的吊销列表中 通信双方通过 CA 以安全方式获取私钥之后，就可以安全性的进行网络通信了。 ","date":"2018-03-03","objectID":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/:3:2","tags":["马哥 Linux"],"title":"15.1 通信加密和解密技术入门","uri":"/posts/linux/linux_mt/18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF/%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8/"},{"categories":["Linux"],"content":"14.6 systemd及systemctl","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"Centos7 的服务管理工具 本节我们学习 Centos7 的开机启动程序 Systemd，及其服务管理工具 systemctl。我们会与 Centos6 中的 upstart 的启动程序对比来讲解。大家也可以参考阮一峰老师的博客。本节内容如下: Systemd 概述 Systemctl 命令的使用 Systemd 配置文件格式 ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:0:0","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1. Sysmted 概述： MBR 架构的系统，开机启动过程是 POST --\u003e Boot Sequeue(BIOS) --\u003e Bootloader(MBR) --\u003e Kernel(ramdisk) --\u003e rootfs --\u003e /sbin/init，而 Systemd 正是 Centos7 的/sbin/init 程序 ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:1:0","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1.2 Systemd的新特性 systemd 相比于 Centos5 的 SysV init，和 Centos 的 Upstart，具有如下特性: 新特性 系统引导时实现服务并行启动； 按需激活进程； 系统状态快照； 基于依赖关系定义服务控制逻辑； 关键特性： 基于socket的激活机制：socket与程序分离； 基于bus的激活机制； 基于device的激活机制； 基于Path的激活机制； 系统快照：保存各unit的当前状态信息于持久存储设备中； 向后兼容sysv init脚本；/etc/init.d/ 不兼容： systemctl的命令是固定不变的； 非由systemd启动的服务，systemctl无法与之通信； 1.2 服务配置 Sysv init 和 Upstart 中，服务的管理单元是一个个具有特定格式的 shell 脚本，由 service 命令统一进行管理。而 Systemd 中服务的核心单元叫 Unit，unit 由其相关配置文件进行标识、识别和配置，配置文件中主要包含了系统服务、监听的socket、保存的快照以及其它与init相关的信息。systemd 按照功能将 unit 分为了如下几种类型。 unit的常见类型 类型 文件扩展名 作用 Service unit .service 用于定义系统服务 Target unit .target 用于模拟实现运行级别 Device unit .device 用于定义内核识别的设备 Mount unit .mount 定义文件系统挂载点 Socket unit .socket 用于标识进程间通信用到的socket文件 Snapshot unit .snapshot 管理系统快照 Swap unit .swap 用于标识swap设备 Automount unit .automount 文件系统自动点设备 Path unit .path 用于定义文件系统中的一文件或目录 systemd 的配置文件 systemd 的配置文件位于以下三个目录中 /usr/lib/systemd/system: 实际配置文件的存存放位置 /run/systemd/system：不常用 /etc/systemd/system: 基本上都是软连接 对于那些支持 Systemd 的软件，安装的时候，会自动在/usr/lib/systemd/system目录添加一个配置文件。 如果你想让该软件开机启动，就执行下面的命令（以httpd.service为例）。 [root@hp system]# ll /etc/systemd/system/default.target lrwxrwxrwx. 1 root root 40 3月 5 17:37 /etc/systemd/system/default.target -\u003e /usr/lib/systemd/system/graphical.target [root@hp system]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 上面的命令相当于在 /etc/systemd/system 目录添加一个符号链接，指向 /usr/lib/systemd/system 里面的httpd.service文件。 这是因为开机时，Systemd只执行 /etc/systemd/system 目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。 除了使用普通的文本查看命令外查看配置文件外，systemctl cat NAME.service 可通过服务名称直接查看配置文件 [root@hp system]$ systemctl cat httpd # /usr/lib/systemd/system/httpd.service [Unit] Description=The Apache HTTP Server After=network.target remote-fs.target nss-lookup.target Documentation=man:httpd(8) Documentation=man:apachectl(8) [Service] Type=notify EnvironmentFile=/etc/sysconfig/httpd ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND ExecReload=/usr/sbin/httpd $OPTIONS -k graceful ExecStop=/bin/kill -WINCH ${MAINPID} # We want systemd to give httpd some time to finish gracefully, but still want # it to kill httpd after TimeoutStopSec if something went wrong during the # graceful stop. Normally, Systemd sends SIGTERM signal right after the # ExecStop, which would kill httpd. We are sending useless SIGCONT here to give # httpd time to finish. KillSignal=SIGCONT PrivateTmp=true [Install] WantedBy=multi-user.target ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:1:1","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2. systemctl 命令使用 ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:2:0","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.1 管理系统服务 (service unit) systemctl [OPTIONS...] COMMAND [NAME...] OPTIONS: -t, --type=: 指定查看的 unit 类型 -a, --all：查看所由服务 服务启动与关闭 作用 init systemctl 启动 service NAME start systemctl start NAME.service 停止 service NAME stop systemctl stop NAME.service 重启 service NAME restart systemctl restart NAME.service 状态 service NAME status systemctl status NAME.service 条件式重启 service NAME condrestart systemctl try-restart NAME.service 重载或重启服务 systemctl reload-or-restart NAME.servcie 重载或条件式重启服务 systemctl reload-or-try-restart NAME.service [root@hp system]# systemctl status httpd ● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-07 09:14:30 CST; 1s ago Docs: man:httpd(8) man:apachectl(8) Main PID: 6170 (httpd) Status: \"Processing requests...\" CGroup: /system.slice/httpd.service ├─6170 /usr/sbin/httpd -DFOREGROUND ├─6174 /usr/sbin/httpd -DFOREGROUND ├─6176 /usr/sbin/httpd -DFOREGROUND ├─6177 /usr/sbin/httpd -DFOREGROUND ├─6178 /usr/sbin/httpd -DFOREGROUND ├─6180 /usr/sbin/httpd -DFOREGROUND └─6181 /usr/sbin/httpd -DFOREGROUND 8月 07 09:14:28 hp.tao systemd[1]: Starting The Apache HTTP Server... 8月 07 09:14:30 hp.tao systemd[1]: Started The Apache HTTP Server. 输出: Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志 服务状态查看 作用 init systemctl 查看某服务当前激活与否的状态 systemctl is-active NAME.service 查看所有已激活的服务 systemctl list-units –type service 查看所有服务（已激活及未激活) systemctl list-units -t service –all 开机自启 作用 init systemctl 设置服务开机自启 chkconfig NAME on systemctl enable NAME.service 禁止服务开机自启 chkconfig NAME off systemctl disable NAME.service 查看某服务是否能开机自启 chkconfig –list NAME systemctl is-enabled NAME.service 查看所有服务的开机自启状态 chkconfig –list systemctl list-unit-files –type service 禁止某服务设定为开机自启 systemctl mask NAME.service 取消此禁止 systemctl unmask NAME.servcie 依赖关系 作用 init systemctl 查看服务的依赖关系 systemctl list-dependencies NAME.service ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:2:1","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.2 管理 target units 作用 init systemctl 运行级别 0 runlevel0.target, poweroff.target 运行级别 1 runlevel1.target, rescue.target 运行级别 2 runlevel2.tartet, multi-user.target 运行级别 3 runlevel3.tartet, multi-user.target 运行级别 4 runlevel4.tartet, multi-user.target 运行级别 5 runlevel5.target, graphical.target 运行级别 6 runlevel6.target, reboot.target 级别切换 init N systemctl isolate NAME.target 查看级别 runlevel systemctl list-units –type target 查看所有级别 systemctl list-units -t target -a 获取默认运行级别 /etc/inittab systemctl get-default 修改默认运行级别 /etc/inittab systemctl set-default NAME.target 切换至紧急救援模式 systemctl rescue 切换至emergency模式 systemctl emergency ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:2:2","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.3 其它常用快捷命令 关机： systemctl halt, systemctl poweroff 重启： systemctl reboot 挂起： systemctl suspend 快照： systemctl hibernate 快照并挂起： systemctl hybrid-sleep ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:2:3","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"3. service unit file 配置 ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:3:0","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"3.1 unit file 组成 unit file 通常由如下 三个部分组成: [Unit]： 定义与Unit类型无关的通用选项； 用于提供 unit 的描述信息、unit 行为及依赖关系等； [Service]： 与特定类型相关的专用选项；此处为 Service 类型； [Install]： 定义由systemctl enable以及systemctl disable命令在实现服务启用或禁用时用到的一些选项； # systemctl cat sshd # /usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target Unit段 Description：当前服务的简单描述 After：定义unit的启动次序；表示当前unit应该晚于哪些unit启动；其功能与Before相反； Before：定义sshd.service应该在哪些服务之前启动 Requies：依赖到的其它units；强依赖，被依赖的units无法激活或异常退出时，当前unit即无法激活； Wants：依赖到的其它units；弱依赖，被依赖的units无法激活时，不影响当 unit 的启动； Conflicts：定义units间的冲突关系； 附注： After和Before字段只涉及启动顺序，不涉及依赖关系 Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的 Service段 Type：用于定义影响ExecStart及相关参数的功能的unit进程启动类型； simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 EnvironmentFile：指定当前服务的环境参数文件 ExecStart：指明启动unit要运行命令或脚本；其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件 ExecReload：重启服务时执行的命令 ExecStop：停止服务时执行的命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 Restart：定义了服务退出后，Systemd 的重启方式 no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 on-abnormal：只有被信号终止和超时，才会重启 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启 附注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal KillMode:定义 Systemd 如何停止服务 control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。 RestartSec：表示 Systemd 重启服务之前，需要等待的秒数 对于 sshd 服务而言将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。 所有的启动设置之前，都可以加上一个连词号（-），表示\"抑制错误\"，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误 Install段 Alias： RequiredBy：被哪些units所依赖； WantedBy：表示该服务所在的 Target ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:3:1","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"3.2 修改配置文件后重启 对于新创建的unit文件或修改了的unit文件，要通知systemd重载此配置文件 systemctl daemon-reload ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:3:2","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"4.Target 的配置文件 [root@hp system]$ systemctl cat multi-user.target # /usr/lib/systemd/system/multi-user.target # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. [Unit] Description=Multi-User System Documentation=man:systemd.special(7) Requires=basic.target Conflicts=rescue.service rescue.target After=basic.target rescue.service rescue.target AllowIsolate=yes Target 配置文件里面没有启动命令 Requires：要求basic.target一起运行。 Conflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。 After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。 AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target ","date":"2018-03-02","objectID":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/:4:0","tags":["马哥 Linux"],"title":"14.6 systemd及systemctl","uri":"/posts/linux/linux_mt/16-selinux/systemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"14.5 SELinux简介","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"SELinux简介 对于安全性很多人存在误解，觉得 Linux 比 windows 更加安全，其实不然。SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，用于增强 Linux 的安全性。SELinux 在实际生产环境中使用的很少，原因并不是 SELinux 不够好，而是想要做到精准的权限控制，需要明确知道并管理进程需要访问的资源，对这些信息的管理本身有很大负担。所以本节我们只介绍 SELinux 的简单原理和管理，并不会对其做深入介绍。具体内容包括: SELinux 的权限模型 SELinux 工作模型 SELinux 管理 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:0:0","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"1. SELinux 权限模型 Linux传统权限模型下，进程能够访问的哪些资源，取决于进程的发启者能够访问的资源集合。这样存在一些弊端，资源所需访问的资源很少，但是能够访问的资源却很大，一旦进程被不怀好意的人控制，就会对 Linux 安全造成威胁。因此 SELinux 才用最小权限法则，进程只能访问那些它必需访问控制的资源，这样就可以提高 Linux 的安全性。两种权限模型的对比如下: Linux传统权限模型 权限模型: DAC (Discretionary Access Control) 自主访问控制 进程权限: 取决于进程发起者作为属主、属组、其它用户的权限集和 SELinux: 权限模型: MAC (Mandatory Access Control): 强制访问控制 TE (Type Enforcement)：最小权限法则 进程权限: 取决于SELinux 规则库 SELinux 有两种工作级别，不同工作级别下，受控级别的范围不同: strict： 每个进程都收到 selinux 的控制 targeted: 仅有限个进程受到 selinux 的控制，只监控容易被入侵的进程 之所以有 targeted 级别，主要还是受限于管理所有进程能够访问资源的成本太高 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:1:0","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. SELinux 工作模型 进程的执行过程可以概括成 “进程对资源执行的操作” 即 subject operation object subject: 进程主体 object: 系统资源，主要是文件 operation: 进程对资源能够执行的操作 SELinux 的核心就是确定\"进程能够对哪些资源执行什么操作\"。为了将进程与资源关联起来，SELinux 为每个进程及文件提供了安全标签 安全标签: user:role:type:: user: SELinux 的 user role: 角色 type: 类型 进程的 type 称为域 domain,表示一个空间 资源的 type 称为类型，域能访问哪些资源类型取决于 SELinux 规则库 policy domian 包含的 type 即进程能够操作的资源范围，domian 与 type 的对应关系记录在 SELinux 的规则库中 除了对进程访问资源的控制外，SELinux 还对进程的功能作了限制，比如 httpd 进程而言，其有上传和下载等功能，相对于下载而言，上传功能的风险则高的多。因此默认情况下高风险功能在 SELinux 中是禁止的，想要启用必需显示开启。这部分控制又称为 SELinux 的布尔规则设置。 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:2:0","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.1 进程的安全标签 如下第一段 LABEL 即为进程的域，由 5 段组成，后两段对于我们了解 SELinux 意义不大 [root@hp ~]# ps auxZ LABEL USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND system_u:system_r:init_t:s0 root 1 0.7 0.1 194440 9048 ? Ss 21:28 0:02 /usr/lib/systemd/systemd --switched-root --system --deserialize system_u:system_r:kernel_t:s0 root 2 0.0 0.0 0 0 ? S 21:28 0:00 [kthreadd] system_u:system_r:kernel_t:s0 root 3 0.0 0.0 0 0 ? S 21:28 0:00 [ksoftirqd/0] system_u:system_r:kernel_t:s0 root 4 0.0 0.0 0 0 ? S 21:28 0:00 [kworker/0:0] ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:2:1","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.2 文件的类型 system_u:object_r:admin_home_t:s0 即为文件的类型 [root@hp ~]# ll -Z . -rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfg drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Desktop drwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Documents ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:2:2","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.3 SELinux 规则库 policy SELinux 的规则遵循“法无授权即禁止不可行”的原则，即如果进程受 SELinux 控制，如果规则库中没有显示定义规则则禁止访问。另外由于所由进程对资源的访问都会读取 SELinux 规则库，因此规则库以二进制格式进行存放，需要专用的命令才能修改。 SELinux 的规则库即按照我们之前所说的模型进行编写: subject operation object ==\u003e domain --\u003e policy --\u003e type subject: 主-进程 domain object: 宾-资源 type Files Directories Porcesses Special files or various types(块设备文件、字符设备、FIFO、socket) FileSystems Links File descriptors operation: 谓-操作 Create Read Write Lock Rename Link Unlink Append Excute I/O Control ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:2:3","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2. SELinux 配置文件 SELinux 的配置位于 /etc/sysconfig/selinux # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. SELINUX=permissive # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted 参数: SELINUXTYPE: SELinux 的工作级别 SELINUX: SELinux 启用状态 disabled: 禁用，关闭 SELinux enforcing: 启用，强制，一旦进程不符合 SELinux 的权限控制会禁止进程访问相关资源 permissive: 启用，警告，SELinux 不会禁止进程违规访问资源，仅记录日志 附注: SELinux 日志文件则位于: /var/log/audit/audit.log 需要特别说明的是由 disabled –\u003e enforcing|permissive 需要重启系统才会生效，因为系统要为所有受控的进程和文件打上安全标签 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:2:4","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"3. SELinux 相关命令 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:3:0","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"3.1 SELinux 启用状态管理 getenforce getenforce 作用: 获取当前 SELinux 状态 [root@hp ~]# getenforce Permissive 显示: disabled: 禁用 permissive: 警告，仅记录日志 enforcing: 强制 setenforce setenforce value 作用: 启用SELinux value: 0: 设置为 permissive 1: 设置为 enforcing 效力: 当前有效，开机后无效 附注: 永久有效，需修改配置文件。 需要特别注意的是使用 setenfoce 命令的前提是 SELinux 状态不能为 disabled。如果 SELinux 为 disabled 只能修改配置文件然后重启。 vim /etc/selinux/config # 或 /etc/sysconfig/selinux SELINUX={disabled|enforcing|permissive} ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:3:1","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.3 SELinux type 标签管理 ls -Z /path/to/somefile 作用: 查看文件标签 ps auxZ 作用: 查看进程标签 chcon chcon OPTIIONS file 作用: change context 修改文件安全标签 OPTIONS -t TYPE: 设置文件 type -R: 递归修改 --reference=file: 参考某文件的标签进行设置 [root@hp tmp]# ll -Z aa -rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa [root@hp tmp]# chcon -t admin_home_t aa [root@hp tmp]# ll -Z aa -rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 aa [root@hp tmp]# chcon aa --reference bb [root@hp tmp]# ll -Z aa -rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa restorecon restorecon -R file 作用: 还原默认标签 -R: 递归修改 ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:3:2","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"2.4 SELinux的布尔规则设置 getsebool getsebool [-a] [boolean_name] 作用: 显示 SELinux 布尔型规则 参数: boolean_name 规则名称 选项: -a 显示所有布尔型规则 [root@hp ~]# getsebool -a|grep httpd httpd_anon_write --\u003e off httpd_builtin_scripting --\u003e on httpd_can_check_spam --\u003e off httpd_can_connect_ftp --\u003e off httpd_can_connect_ldap --\u003e off httpd_can_connect_mythtv --\u003e off httpd_can_connect_zabbix --\u003e off httpd_can_network_connect --\u003e off httpd_can_network_connect_cobbler --\u003e off httpd_can_network_connect_db --\u003e off httpd_can_network_memcache --\u003e off setsebool setsebool [ -PNV ] boolean value | bool1=val1 bool2=val2 ... 作用: 设置布尔规则 VARIABLE: ={0|off|false}: 关闭功能 ={1|on|true}: 开启功能 选项: P: 将修改写入配置文件中，否则仅仅当前设置有效 [root@hp tmp]# getsebool httpd_use_nfs httpd_use_nfs --\u003e off [root@hp tmp]# setsebool httpd_use_nfs 1 [root@hp tmp]# getsebool httpd_use_nfs httpd_use_nfs --\u003e on ","date":"2018-03-01","objectID":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/:3:3","tags":["马哥 Linux"],"title":"14.5 SELinux简介","uri":"/posts/linux/linux_mt/16-selinux/selinux%E7%AE%80%E4%BB%8B/"},{"categories":["Linux"],"content":"14.4 通过 ks 自动安装系统","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"通过 ks 自动安装系统 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:0:0","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. 通过 ks 利用光盘的仓库安装操作系统 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:1:0","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.1 配置 http 服务器 在 192.168.1.110 配置一个 http 服务器，让局域网内的所有机器都能访问到(http://192.168.1.110/anaconda-ks.cfg) ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:1:1","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.2 修改 kickstart 文件 ksvalidator anaconda-ks.cfg: 检查 ks 语法错误 #version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use CDROM installation media cdrom # Use graphical install graphical # Run the Setup Agent on first boot firstboot --enable ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=cn --xlayouts='cn' # System language lang zh_CN.UTF-8 # Network information network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activate network --hostname=www.tao.com # Root password rootpw --iscrypted $6$LZCrSYmUUKgH0NFI$T49uuvCjfCfl/7f87EZUHFBcqIRWjkhGeNuyHhGn/xUzv1o2sHefEH3AwHoMV7eVWY5rg2BarnuzlUkOCLgbL0 # System services services --disabled=\"chronyd\" # System timezone timezone Asia/Shanghai --isUtc --nontp user --name=tao --password=$6$wpzzJIpol5z5KHw0$bsn4zRMv1hkBwg2HV8dqeE895i4YdgJU.J6q222HSec/sUBBPZflcdipfn9Z3U96mzlS48gZ5vFBAOG/WjV561 --iscrypted --gecos=\"tao\" # X Window System configuration information xconfig --startxonboot # System bootloader configuration bootloader --append=\" crashkernel=auto\" --location=mbr --boot-drive=sda # Partition clearing information clearpart --initlabel --list=nvme0n1p11,nvme0n1p10,nvme0n1p8 # Disk partitioning information part /boot/efi --fstype=\"efi\" --ondisk=nvme0n1 --size=1028 --fsoptions=\"umask=0077,shortname=winnt\" part pv.1133 --fstype=\"lvmpv\" --ondisk=nvme0n1 --size=153604 part /boot --fstype=\"xfs\" --ondisk=nvme0n1 --size=1021 volgroup cl --pesize=4096 pv.1133 logvol /home --fstype=\"xfs\" --size=25600 --name=home --vgname=cl logvol /var --fstype=\"xfs\" --size=46080 --name=var --vgname=cl logvol swap --fstype=\"swap\" --size=2048 --name=swap --vgname=cl logvol / --fstype=\"xfs\" --size=25600 --name=root --vgname=cl logvol /usr --fstype=\"xfs\" --size=51200 --name=usr --vgname=cl %packages @^developer-workstation-environment @base @core @debugging @desktop-debugging @development @dial-up @directory-client @fonts @gnome-apps @gnome-desktop @guest-desktop-agents @input-methods @internet-applications @internet-browser @java-platform @multimedia @network-file-system-client @performance @perl-runtime @print-client @ruby-runtime @virtualization-client @virtualization-hypervisor @virtualization-tools @web-server @x11 kexec-tools %end %addon com_redhat_kdump --enable --reserve-mb='auto' %end %anaconda pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty %end ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:1:2","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.3 创建虚拟机并启动安装 进入安装的 boot 界面输入 boot linux text ip=192.168.1.115 netmask=255.255.255.0 ks=http:/192.168.1.110/ks.cfg ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:1:3","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2. 通过自制光盘自动安装操作系统 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:2:0","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.1 创建 kickstart 文件 #version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use CDROM installation media cdrom # Use graphical install graphical # Run the Setup Agent on first boot firstboot --enable ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=cn --xlayouts='cn' # System language lang zh_CN.UTF-8 # Network information network --bootproto=dhcp --device=enp0s3 --onboot=off --ipv6=auto --no-activate network --hostname=virtual.tao # Root password rootpw --iscrypted $6$oSLEiL/Vx1k1thR7$5oER8NwNYgfdZcegPA6bBLyvMREZ5Pa6gEuikfDR.B09Mv7kWyJAaXAOoIbfBCZXDj91a5rBealE3S17i71.f1 # System services services --enabled=\"chronyd\" # System timezone timezone Asia/Shanghai --isUtc user --groups=wheel --name=tao --password=$6$U7NwGZhelPqRaCP5$3VO3wcfzClT/nGXqoQobVN7.jlIfSTHDgUApHjAcwDhxROWK5/s3zZE0zUIaIhZse1OES30roxS1yxEQyydUv. --iscrypted --gecos=\"tao\" # X Window System configuration information xconfig --startxonboot # System bootloader configuration bootloader --append=\" crashkernel=auto\" --location=mbr --boot-drive=sda # Partition clearing information clearpart --none --initlabel # Disk partitioning information part pv.157 --fstype=\"lvmpv\" --ondisk=sda --size=31747 part /boot --fstype=\"xfs\" --ondisk=sda --size=1024 volgroup centos --pesize=4096 pv.157 logvol / --fstype=\"xfs\" --size=10240 --name=root --vgname=centos logvol /var --fstype=\"xfs\" --size=10240 --name=var --vgname=centos logvol /home --fstype=\"xfs\" --size=10240 --name=home --vgname=centos logvol swap --fstype=\"swap\" --size=1020 --name=swap --vgname=centos %packages @^gnome-desktop-environment @base @core @desktop-debugging @development @dial-up @directory-client @fonts @gnome-desktop @guest-agents @guest-desktop-agents @input-methods @internet-browser @java-platform @multimedia @network-file-system-client @networkmanager-submodules @print-client @x11 chrony kexec-tools %end %addon com_redhat_kdump --enable --reserve-mb='auto' %end %anaconda pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty %end ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:2:1","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"2.2 创建磁盘映像文件 cd /var/iso mkdir cdrom mount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/ cp -ra cdrom/ myboot vim myboot/ks.cfg # 复制上述的 kickstart 文件 # 添加安装菜单 vim isolinux/isolinux.cfg label ks menu label ^Install tao linux kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet ks=cdrom:/ks.cfg # 创建光盘镜像 genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V \"CentOS 7 x86_64\" -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/ # -V \"CentOS 7 x86_64\" 必需与 hd:LABEL=CentOS\\x207\\x20x86_64 保持一致 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:2:2","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3. 通过自制光盘使用网络仓库安装操作系统 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:3:0","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.1 制作镜像文件 cd /var/iso mount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/ cp -ra cdrom/isolinux/ myiso/ vim isolinux/isolinux.cfg # 添加开机菜单 label ks menu label Ks Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet ks=cdrom:/ks.cfg cd myiso cp /root/anaconda-ks.cfg ks.cfg vim ks.cfg # Use CDROM installation media 更改为 # cdrom url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/ genisoimage -o Net.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V \"CentOS 7 x86_64\" -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myiso ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:3:1","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.2 修改 kickstart 文件 ks 文件与上面的配置类似，但是需要使用 url 命令指定外部仓库的位置，将 # Use CDROM installation media 更改为 cdrom # 更改为 url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/ ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:3:2","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"3.3 创建虚拟机并启动安装 创建虚拟机后，选择配置的菜单，启动自动安装过程 ","date":"2018-02-28","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/:3:3","tags":["马哥 Linux"],"title":"14.4 通过 ks 自动安装系统","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"14.3 Centos 安装程序 anaconda 配置","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"Centos 安装程序 anaconda 配置 上一节我们讲解了 Centos 的安装启动过程，下面我们来说一下，anaconda 启动后会进行哪些操作，以及如何配置 anaconda。 ","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/:0:0","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"1. anaconda的工作过程 anaconda 在进行操作系统安装时会经由如下几个步骤: 安装前配置阶段，包括设置如下参数 安装过程使用的语言； 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 Special Storage： iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置； 创建一个普通用户； 选定要安装的程序包； 安装阶段 在目标磁盘创建分区并执行格式化； 将选定的程序包安装至目标位置； 安装bootloader； 首次启动 iptables selinux core dump ","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/:1:0","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"2. anaconda的配置方式 安装前配置阶段，有两种配置方式 交互式配置方式；利用 anaconda 提供的安装界面，逐项进行选择配置 通过读取配置文件中，事先定义好的配置项，自动完成配置；此文件即为kickstart文件；交互式配置安装完成后，在 root 目录下会生成此次安装的 kickstart 文件 /root/anaconda-ks.cfg kickstart 文件有特定的语法格式 可以直接手动编辑，或依据模板修改 也可以使用创建工具 system-config-kickstart，此命令会提供给我们一个交互界面，类似模拟 anaconda 的安装界面。我们可以打开 root 目录下生成的 kickstart 文件作为模板来生成我们的kickstart 文件。system-config-kickstart 安装与使用界面如所示 yum install system-config-kickstart system-config-kickstart # ksvalidator 命令可用于检查 ks 文件是否有语法错误 ksvalidator /root/kickstart.cfg ","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/:2:0","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3. kickstart 文件格式 大体上，kickstart 文件由三个部分组成 # 1. 命令段 #version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use CDROM installation media cdrom # Use graphical install graphical ...... # 2. 程序包段 %packages # 开始标记 @group_name # 要安装的包组 package # 要安装的单个包 -package # 不要安装的单个程序包 %end # 结束标记 # 3. 脚本段 命令段：指定各种安装前配置选项，如键盘类型等；有一些是必备命令，有一些则是可选命令 程序包段：指明要安装程序包，以及包组，也包括不安装的程序包； 脚本段： %pre：安装前脚本，运行环境：运行安装介质上的微型Linux系统环境； %post：安装后脚本，运行环境：安装完成的系统； ","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/:3:0","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"3.1 命令段 kickstart 可用命令很多，想深入了解，可以参考官方文档：《Installation Guide》。下面是我安装 Centos7 之后生成的 ks 文件。我们只会介绍最常用的命令的。 #version=DEVEL # System authorization information auth --enableshadow --passalgo=sha512 # Use CDROM installation media cdrom # Use graphical install graphical # Run the Setup Agent on first boot firstboot --enable ignoredisk --only-use=sda # Keyboard layouts keyboard --vckeymap=cn --xlayouts='cn' # System language lang zh_CN.UTF-8 # Network information network --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activate network --hostname=localhost.localdomain # Root password rootpw --iscrypted $6$ji4or39qLiMVBwAi$E9N78iOYlZw9zzD3g3CGgVvb7MSUgLbsjq9WiwIu6qSGV.y8Sbmx8WtvrWyAPnKkHhdxJKhUAZqXl2zrzjp3t0 # System services services --enabled=\"chronyd\" # System timezone timezone Asia/Shanghai --isUtc user --groups=wheel --name=tao --password=$6$u/SLeiTrWJUgp.8E$fGCp/IAm01lyGVBkcYMTrutmAFDjdEblCorhX5Kv.cgCZvVpn8PB4LoQ/6.Qn1Tlvq0YqwhzivNqqCSeGpgc5/ --iscrypted --gecos=\"tao\" # X Window System configuration information xconfig --startxonboot # System bootloader configuration bootloader --append=\" crashkernel=auto\" --location=mbr --boot-drive=sda autopart --type=lvm # Partition clearing information clearpart --none --initlabel 必备命令 authconfig --enableshadow --passalgo=sha512:认证方式配置 bootloader --location=mbr --driveorder=sda --append=\"crashkernel=auto rhgb quiet\" 作用: 定义bootloader的安装位置及相关配置 --append: 添加到内核的参数 keyboard us: 设置键盘类型 lang zh_CN.UTF-8: 语言类型 part: 创建磁盘分区 clearpart --none --drives=sda：清空磁盘分区 part /boot --fstype=ext4 --size=500: 定义基本磁盘分区 part pv.008002 --size=51200: 创建逻辑卷的物理卷，008002 为物理卷的标识 volgroup myvg --pesize=4096 pv.008002: 创建逻辑卷组 logvol /home --fstype=ext4 --name=lv_home --vgname=myvg --size=5120: 创建逻辑卷 rootpw --iscrypted passwd: 管理员密码 timezone Asia/Shanghai: 时区 # 生成加密密码的方式(root 密码) openssl passwd -1 -salt `openssl rand -hex 4` 可选命令 install|upgrade：安装或升级； text|graphical：安装界面类型，text为tui，默认为GUI network --onboot yes --device eth0 --bootproto dhcp --noipv6 作用: 配置网络接口 --onboot yes: ifcfg 中的 ON_BOOT 参数，其他参数类似 firewall: 防火墙设置 firewall --disabled: 关闭防火墙 firewall --service ssh: 启动防火墙，放行 ssh 服务 selinux --disabled: 关闭 selinux halt|poweroff|reboot：安装完成之后的行为； repo --name=\"CentOS\" --baseurl=cdrom:sr0 --cost=100 作用: 指明安装时使用的repository； url --url=http://172.16.0.1/cobbler/ks_mirror/CentOS-6.7-x86_64/ 作用: 指明安装时使用的repository，但为url格式； url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/ ","date":"2018-02-27","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/:3:1","tags":["马哥 Linux"],"title":"14.3 Centos 安装程序 anaconda 配置","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/anaconda%E9%85%8D%E7%BD%AE/"},{"categories":["Linux"],"content":"14.2 Centos安装过程","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"Centos安装过程 本节我们来讲解 Centos 系统的安装过程。 ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:0:0","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"1. 安装程序：anaconda 前面我们说过操作系统的层次，如下图所示，因为直接面向硬件编程是一件非常困难的是，所以才有了操作系统。如果有安装过 Centos 系统就会知道，安装过程有一个操作界面供我们进行选择安装，显然这是一个应用程序，那么这个应用程序是直接在硬件之上编写的么？我们说过在硬件之上编写应用程序是极其困难的，且不易移植，所以我们的安装程序也是构建在内核之上，只不过这个内核不是来自我们的计算机，而是我们的安装光盘或U盘上。Centos 的安装程序就是 annaconda。 -------------- | 库调用接口 | --------------- | 系统调用接口 | ------------------------------- | 操 作 系 统 | ------------------------------- | 底 层 硬 件 | ------------------------------- ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:1:0","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"2. 安装光盘的结构 mount -r /dev/cdrom /media/cdrom cd /media/cdrom tree -L 1 . ├── CentOS_BuildTag ├── EFI ├── EULA ├── GPL ├── images ├── isolinux # 内核所在目录 ├── LiveOS ├── Packages ├── repodata ├── RPM-GPG-KEY-CentOS-7 ├── RPM-GPG-KEY-CentOS-Testing-7 └── TRANS.TBL 我们安装光盘的目录结构如上所示，isolinux 就是光盘上操作系统内核所在的目录，其余部分是程序包仓库。 操作系统安装时 首先加载操作系统内核； 光盘安装就是加载位于 isolinux 中的内核 除了光盘，内核还可以来自 U 盘，网络等其他引导设备 通过 PXE 可以实现通过网络自动安装操作系统，这个我们会在后面详述配置过程。 启动 anaconda，进而根据用户选择，安装操作系统 anacona及其安装用到的程序包等来自于程序包仓库，此仓库的位置可以为 本地光盘，光盘中 isolinx 之外的就是目录就是程序包仓库 本地硬盘 ftp server http server nfs server anaconda 提供的安装界面分为: tui：基于cureses的文本配置窗口 gui：图形界面 ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:2:0","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"3. CentOS的安装过程启动流程 当前我们就以光盘安装来讲解 Centos 的安装过程 cd /media/cdrom/isolinux tree -L 1 . ├── boot.cat # MBR 中的 bootLoader ├── boot.msg ├── grub.conf ├── initrd.img ├── isolinux.bin # 提供安装界面 ├── isolinux.cfg # 配置文件，包含开机菜单 ├── memtest ├── splash.png ├── TRANS.TBL ├── vesamenu.c32 └── vmlinuz 加载并启动 BootLoader Stage1: 执行 isolinux/boot.cat，光盘的 MBR 包含的就是此文件 Stage2: 执行 isolinux/isolinux.bin 提供安装界面和开机启动菜单 BootLoader 引导和加载内核，并装载根文件系统 内核: isolinux/vmlinuz 根文件系统: isolinux/initrd.img 启动anaconda 默认界面是图形界面：512MB+内存空间； 若需要显式指定启动TUI接口： 向启动内核传递一个参数\"text\"即可； 如果想手动指定安装仓库，也可以通过向内核传递参数更改 ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:3:0","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"3.1 isolinux.bin isolinux.bin 其配置文件位于 isolinux/isolinux.cfg，配置文件中包含了开机启动菜单 vim /media/cdrom/isolinux/isolinux.cfg .... label linux # 菜单标识 menu label ^Install CentOS 7 # 菜单名称 kernel vmlinuz # 指定内核 # 内核参数，通过 boot 命令行添加的参数会添加在此行后 append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet label rescue menu indent count 5 menu label ^Rescue a CentOS system text help If the system will not boot, this lets you access files and edit config files to try to get it booting again. endtext kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 rescue quiet ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:3:1","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"3.2 向内核传递参数 安装启动时，我们可以通过向内核传递参数，来更改 anacoda 的启动方式，那么如何向内核参数传递参数呢？ 首先进入安装界面，这个安装界面就是 isolinux/isolinux.bin 提供的，上面的选项就是 isolinux/isolinux.cfg 配置文件的内容 然后按 ESC 即进入 boot 命令行界面，输入菜单标识 参数即可以向对应菜单的内核传递参数。传递的参数将附加在, isolinux.cfg 对应菜单的 append 行后面。例如通过 boot 界面控制 anaconda 的启动方式: linux text: 指定 anaconda 以tui 方式启动 linux method: 手动指定程序包源 说明: 此处 linux 表示 isolinux.cfg 中的一个菜单标识 也可以在特定的菜单名称上按 TAB 键，就可以编辑特定菜单的参数 ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:3:2","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"3.3 boot 界面的安装引导选项 boot 界面有如下选项可供使用: text：文本安装方式 method：手动指定使用的安装方法 与网络相关的引导选项： ip=IPADDR netmask=MASK gateway=GW dns=DNS_SERVER_IP ifname=NAME:MAC_ADDR – 指定上述设置应用在哪个网卡上 远程访问功能相关的引导选项： vnc vncpassword='PASSWORD' 启动紧急救援模式： rescue 装载额外驱动： dd 指定 kickstart 文件的位置 ks= DVD drive: ks=cdrom:/PATH/TO/KICKSTART_FILE Hard Drive： ks=hd:/DEVICE/PATH/TO/KICKSTART_FILE HTTP Server： ks=http://HOST[:PORT]/PATH/TO/KICKSTART_FILE FTP Server: ks=ftp://HOST[:PORT]/PATH/TO/KICKSTART_FILE HTTPS Server: ks=https://HOST[:PORT]/PATH/TO/KICKSTART_FILE 安装选项文档: www.redhat.com/docs , 《installation guide》 ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:3:3","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"4. 创建引导光盘 我们可以创建自己的镜像文件，在镜像文件内创建好 kickstart 文件，并在菜单中配置好 ks 的位置，这样就可以直接进行安装。下面是配置过程 \u003e mkdir /tmp/myiso/isolinux \u003e cp /media/cdrom/isolinux/* /tmp/myiso/isolinux \u003e cp /root/kickstart.cfg /tmp/myiso/isoLinux # centos6 \u003e mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V \"CentOS 6 x86_64 boot\" -c isolinux/boot.cat -b isolinux/isolinux.bin -o /root/boot.iso myiso/ # Centos7 \u003e sudo genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V \"CentOS 7 x86_64\" -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/ ## 配置 isolinux/isolinux.cfg 添加安装项，直接配置 ks 参数 label ks menu label ^Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\\x207\\x20x86_64 quiet ks=cdrom:/ks.cfg mkisofs 使用 mkisofs 创建磁盘镜像文件时，有以下几个特别注意的点需要注意: -V 参数指定的标签必需与 isolinux/isolinux.cfg 中的 hd:LABEL=的值相同，否则开机启动时将找不到磁盘镜像文件 如果要在 efi 启动，需要添加如下参数： -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot 不能在 Centos6 的系统上制作 Centos7 因为两者系统的 genisoimage 命令的版本不一样， 6 的系统制作出来的 iso 不能在 efi 环境启动； 详细可参考这边博客 https://www.linuxidc.com/Linux/2015-03/114509.htm ","date":"2018-02-26","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/:4:0","tags":["马哥 Linux"],"title":"14.2 Centos安装过程","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/centos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/"},{"categories":["Linux"],"content":"14.1 Linux内核模块功能定制","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"Linux内核模块功能定制 上一章我们详细讲解了 Linux 启动流程，再此基础上，本章我们来讲解内核的编译和安装。本章内容如下: 编译内核以定制内核功能 Centos 操作系统的安装过程 Centos 安装程序 anaconda 配置 内核编译是一个大工程，需要对硬件，内核各个参数功能都有比较深入了解，才能编译出有特定功能需求的内核。本节主要是带大家了解内核的编译过程，能编译成功即可。本节内容如下: 编译内核的环境准备 根据当前操作系统的编译模板，编译内核 ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:0:0","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"1. 编译内核 在编译内核之前，我们需要了解目标主机的功能需求，并准备好开发环境，具体可包括如下几个方面: 准备好开发环境； 获取目标主机上硬件设备的相关信息； 获取到目标主机系统功能的相关信息，例如要启用的文件系统； 获取内核源代码包：http://www.kernel.org ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:1:0","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"1.1 准备开发环境 开发环境主要是准备编译环境，Centos6-7 中安装如下两个包组即可: Development Tools: 中文下叫\"开发工具\" Server Platform Development: 中文下叫 “服务器平台开发” - Centos7 可能没有此包组 ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:1:1","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"1.2 获取目标主机上硬件设备的相关信息 Linux 中有如下命令，可以帮助我们获取硬件设备的相关信息包括: CPU： cat /proc/cpuinfo lscpu x86info -a PCI设备： lspci [-v|-vv] lsusb [-v|-vv]: 显示 usb 信息 lsblk: 显示块设备信息 了解全部硬件设备信息：hal-device(Centos6) ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:1:2","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"2. 内核编译过程： 内核的编译与程序包的编译安装过程类似，遵循./configure ==\u003e make ==\u003e make install。接下来我们将利用现有操作系统的编译安装模板，来编译一个内核。 ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:2:0","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"2.1 简单依据模板文件的制作过程： #！/bin/bash # 1. 编译内核 tar xf linux-3.10.67.tar.xz -C /usr/src cd /usr/src ln -sv linux-3.10.67 linux cd linux # cp /boot/config-$(uname -r) .config # 复制当前系统的编译模板进行参考 make menuconfig # 配置内核选项 make [-j \\#] # 编译内核，可使用-j指定编译线程数量 make modules_install # 安装内核模块 make install # 安装内核 # make install 会自动完成以下步骤 # 2. 安装 bzImage 为 /boot/vmlinuxz-VERSION-RELEASE ll arch/x86/boot/bzImage ll arch/x86_64/boot/bzImage # 3. 生成 initramfs 文件 # 4. 编辑 grub 的配置文件 # 5. 重启系统，选择使用新内核 ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:2:1","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"2.2 screen命令： 执行 make 命令时，如果是远程连接到服务器，可能因为网络问题而断开连接，此时 make 就会终止。为了避免因为断开连接导致编译过程前功尽弃，可以使用 screen 命令 screen 作用: 终端模拟器，允许在一个终端上打开多个屏幕 特性: screen 的模拟终端不会因为当前物理终端断开连接而丢失，即 screen 内运行的程序不会因为物理终端断开连接而终止 选项: 打开screen： screen 拆除screen： Ctrl+a, d 列出screen： screen -ls 连接至screen：screen -r SCREEN_ID 关闭screen: exit ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:2:2","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"2.3 编译过程的详细说明： 配置内核选项 支持“更新”模式进行配置：在已有的.config文件的基础之上进行“修改”配置； make config：基于命令行以遍历的方式去配置内核中可配置的每个选项； make menuconfig：基于cureses的文本配置窗口；需要额外安装 ncurses-devel 包 make gconfig：基于GTK开发环境的窗口界面； 包组“桌面平台开发” make xonfig：基于QT开发环境的窗口界面； 支持“全新配置”模式进行配置： make defconfig：基于内核为目标平台提供的“默认”配置为模板进行配置； make allnoconfig：所有选项均为“no”； 编译 多线程编译：make [-j #] 编译内核中的一部分代码： 只编译某子目录中的相关代码： cd /usr/src/linux make path/to/dir/ – 只能在内核源码目录内，基于相对路径编译 只编译一个特定的模块 cd /usr/src/linux make path/to/dir/file.ko 如何交叉编译： 目标平台与当前编译操作所在的平台不同； make ARCH=arch_name 要获取特定目标平台的使用帮助： make ARCH=arch_name help 如何在执行过编译操作的内核源码树上做重新编译： 事先清理操作： make clean：清理编译生成的绝大多数文件，但会保留config，及编译外部模块所需要的文件； make mrproper：清理编译生成的所有文件，包括配置生成的config文件及某些备份文件； make distclean：相当于mrproper，额外清理各种patches以及编辑器备份文件； ","date":"2018-02-25","objectID":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/:2:3","tags":["马哥 Linux"],"title":"14.1 Linux内核模块功能定制","uri":"/posts/linux/linux_mt/15-linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98/linux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6/"},{"categories":["Linux"],"content":"13.6 Linux内核功能及模块应用","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"Linux内核功能及模块应用 之前的章节中，我们讲解了 Linux 系统的启动流程，grub，以及 系统启动之后的 init 程序，最后我们来讲解 Linux 内核相关内容，包括 Linux 内核的组成，包括 内核，内核模块，ramdisk 内核模块的管理 ramdisk 文件的制作 内核参数的修改 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"1. Linux 内核设计体系 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 内核的组成部分： Linux 是单内核设计，但引入了模块化机制，其组成包括如下几个部分 kernel：内核核心，一般为bzImage，通常位于/boot目录，名称为vmlinuz-VERSION-release； kernel object： 内核对象，即内核模块，一般放置于/lib/modules/VERSION-release/ 内核模块与内核核心版本一定要严格匹配； ramdisk：辅助性文件，并非必须，这取决于内核是否能直接驱动rootfs所在的设备。ramdisk 是一个简装版的根文件系统，可能包括 目标设备驱动，例如SCSI设备的驱动； 逻辑设备驱动，例如LVM设备的驱动； 文件系统，例如xfs文件系统； ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 内核信息获取 uname命令： uname [OPTION]... 作用: print system information 选项： -a: 显示所有内核信息 -r：内核的release号 -n：主机名，节点名称 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:1:2","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"2. 模块信息获取和管理 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"2.1 模块信息获取 模块信息获取有 lsmod, moinfo 两个命令，它们的用法如下 lsmod lsmod： 作用: 显示内核已经装载的模块 来源: 显示的内容来自于 /proc/modules 文件 modinfo modinfo [-F field] [-k kernel] [modulename|filename...]： 作用: 查看单个模块的详细信息 选项: -F field： 仅显示指定字段的信息； -n：显示模块文件路径； -p：显示模块参数 \u003e modinfo -F filename btrfs \u003e modinfo -n btrfs depmod depmod 作用: 内核模块依赖关系文件及系统信息映射文件的生成工具； ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"2.2 模块管理 模块装卸载有两组命令，一组是 modprobe 可以自动解决模块的依赖关系，另一组是 insmod,rmmod 不能自动解决模块的依赖关系，它们的用法如下 modprobe modprobe [ -C config-file] [-r] module_name [module params]： 作用: 装载和卸载模块，会自动解决模块之间的依赖关系 选项: 默认: 动态装载模块 modprobe module_name -r: 动态卸载 modprobe -r module_name -C: 指定模块装载时的配置文件，默认为 /etc/modprobe.conf /etc/modprobe.d/\\*.conf insmod insmod [filename] [module options...]： 作用: 模块的装载的另一命令，不会自动解决模块之间的依赖关系，不常用 filename：模块文件的文件路径； eg: insmod $(modinfo -n xfs) rmmod rmmod [module_name]： 作用: 模块卸载的另一命令 module_name: 模块名称，不需要模块的路径 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"3. ramdisk文件的制作： ramdisk 的制作有两个命令，Centos5 使用的 mkinitrd，Centos6-7 使用了 dracut，但是同时也提供了 mkinitrd, 其是基于 dracut 的脚本文件，它们的使用说明如下 mkinitrd mkinitrd [OPTION...] [\u003cinitrd-image\u003e] \u003ckernel-version\u003e 作用: 为当前使用中的内核重新制作ramdisk文件： 选项: --with=\u003cmodule\u003e：除了默认的模块之外需要装载至initramfs中的模块； --preload=\u003cmodule\u003e：initramfs所提供的模块需要预先装载的模块； eg： mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) dracut命令 dracut [OPTION...] [\u003cimage\u003e [\u003ckernel version\u003e]] 作用: low-level tool for generating an initramfs image eg： dracut /boot/initramfs-$(uname -r).img $(uname -r) 解开 ramdisk 文件 \u003e mv initramfs-3.10.0-514.el7.x86_64.img initramfs-3.10.0-514.el7.x86_64.img.gz \u003e gzip -d initramfs-3.10.0-514.el7.x86_64.img.gz \u003e mkdir initrd \u003e cd initrd \u003e cpio -id \u003c ../initramfs-3.10.0-514.el7.x86_64.img ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"4. 系统参数查看和修改 Linux 系统的所有参数通过 /proc，/sys 两个伪文件系统输出给用户查看和修改。 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:4:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"4.1 /proc 目录 /proc 的作用如下: 作用: 内核把自己内核状态和统计信息，以及可配置参数通过 /proc 伪文件系统加以输出： /proc：内核状态和统计信息的输出接口； /proc/sys: 内核参数的配置接口 ； 内核参数分为 只读：信息输出；例如/proc/#/* 可写：可接受用户指定一个“新值”来实现对内核某功能或特性的配置；/proc/sys/ ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:4:1","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"4.1 /proc/sys 管理工具 Linux 可修改的系统参数都放置在 /proc/sys 目录下，有三种修改方式 通过 sysctl 命令，这是专用修改内核参数的命令 由于 /proc 是伪文件系统，因此可以通过 cat，echo 等文件系统命令利用IO重定向进行修改，需要注意的是不能使用文本编辑器进行修改 上述两种方式只临时有效，要想永久有效，需要修改配置文件 # 修改示例 \u003e ls /proc/sys/kernel/hostname -l \u003e sysctl -w kernal.hostname='localhost' \u003e echo \"localhost\" \u003e /proc/sys/kernel/hostname sysctl命令 sysctl [options] [variable[=value]] 作用: 专用于查看或设定/proc/sys目录下参数的值； 查看： sysctl -a: 查看所有参数 sysctl parameter: 查看特定参数 修改：sysctl -w parameter=value 附注：sysctl 的内核参数是相对于 /proc/sys 目录下文件的相对路径而言的，比如 /proc/sys/net/ipv4/ip_forward 相当于 net.ipv4.ip_forward # /proc/sys/net/ipv4/ip_forward # parameter = net.ipv4.ip_forward \u003e sysctl -w net.ipv4.ip_forward=1 \u003e echo 1 \u003e /proc/sys/net/ipv4/ip_forward 文件系统命令（cat, echo) 查看： cat /proc/sys/PATH/TO/SOME_KERNEL_FILE 设定： echo \"VALUE\" \u003e /proc/sys/PATH/TO/SOME_KERNEL_FILE 修改配置文件 默认配置文件: /etc/sysctl.conf /etc/sysctl.d/\\*.conf 配置文件立即生效：sysctl -p [/PATH/TO/CONFIG_FILE] ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:4:2","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"4.2 常用内核参数： net.ipv4.ip_forward：路由核心转发功能； vm.drop_caches：设置值为 1，将回收buffer，cache 的缓存 kernel.hostname：主机名； net.ipv4.icmp_echo_ignore_all：忽略所有ping操作； ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:4:3","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"5. /sys目录： /sys 目录目前主要的作用是 输出内核识别出的各硬件设备的相关属性信息， 也有内核对硬件特性的可设置参数；对此些参数的修改，即可定制硬件设备工作特性； udev 命令 系统上所有的设备文件，都是由 udev 命令生成，这个命令的特点如下: udev 通过读取 /sys 目录下的硬件设备信息按需为各硬件设备创建设备文件； udev是用户空间程序；专用工具：devadmin, hotplug； udev为设备创建设备文件时，会读取其事先定义好的规则文件，一般在/etc/udev/rules.d/目录下，以及/usr/lib/udev/rules.d/目录下； # 1. 修改 vmware 网卡的名称 \u003e vim /usr/lib/udev/rules.d/70-persistent-net.rules # 修改特定 mac 地址网卡的名称 # 2. 如果网卡有特定的配置信息，需要为网卡重新生成对应名称的配置文件 \u003e cd /etc/sysconfig/net-work-script # 卸载网卡并重新装载网卡，让配置生效 \u003e modprobe -r e1000 \u003e modprobe e1000 ","date":"2018-02-24","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/:5:0","tags":["马哥 Linux"],"title":"13.6 Linux内核功能及模块应用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/linux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8/"},{"categories":["Linux"],"content":"13.5 grub2 系统配置与使用","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"grub2 系统配置与使用 上一节我们介绍了 grub 第一版的配置和使用，接下来我们学习 grub2。内容介绍同上一节相同，如下: grub2 概述 认识 grub2 的菜单 grub2 的启动流程 grub2 命令行的使用 grub2 的配置文件 安装 grub2 开机过程中常见问题解决 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. grub2 概述 grub2 支持 efi，比 grub 更加复杂，本人对此并不是很懂。关于 grub2 的详细描述可以参考这篇博文Grub 2：拯救你的 bootloader ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 认识 grub2 菜单 正常开机启动后，我们就会看到一个类似上图的grub2 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 设备表示 grub2 设备的表示方式与 grub 并不相同 grub2 中设备从 0 开始编号，而分区则是从 1 开始编号 MBR 和 GPT 两种分区格式表示并不相同 (hd0,1)： 一般的默认语法，由 grub2 自动判断分区格式 (hd0,msdos1)： 磁盘分区为传统的 MBR 模式 (hd0,gpt1)：磁盘分区为 GPT 模式 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:1:2","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. grub2 命令行的使用 下面是在 grub2 命令行中直接启动操作系统的示例，可以看到 grub2 更加接近我们 bash。 grub\u003e ls # 查看当前的磁盘分区设备 (hd0), (hd0, msdos1), (hd0, msdos2) grub\u003e set root=(hd0, msdos1) # 设置根设备 grub\u003e ls / # 查看当前设备内的文件 grub\u003e linux /vmlinux-VERSION-releaser ro root=/dev/mapper/centos-root # 设置内核和跟目录 grub\u003e initrd /initramfs-VErSION-releaser # 设置 initramdisk grub\u003e insmod gizo # 装载必要的驱动模块 grub\u003e insmod xfs grub\u003e insmod part_msdos grub\u003e boot # 启动开机流程 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3. grub2 的配置文件 grub2 的配置分成了核心配置和辅助配置两个部分 核心配置文件/boot/grub2/grub.cfg，是 grub2 在开机启动过程中读取的配置文件 辅助配置文件是 grub2-mkconfig 会读取的配置文件，此命令用于生成核心配置文件。辅助配置文件包括 /etc/default/grub文件 与 /etc/grub.d/目录两个部分。 因此 grub2 参数可分成两个步骤: 修改 /etc/default/grub 与 /etc/grub.d/ 内的相关辅助配置文件 使用 grub2-mkconfig -o /boot/grub2/grub.cfg 生成新的 grub.cfg 核心配置文件 通过 grub.cfg 的结构与注释，可以直接看出 辅助配置文件的作用结果。首先我们来看 grub.cfg 的文件结构。 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.1 grub2 配置文件 grub.cfg 主要包括两个部分 第一部分是环境配置段，大多是环境设置与默认值设置，对应于 /etc/default/grub 第二部分是菜单选项，/etc/grub.d/内每个配置文件生成的菜单选项，都包含在对应文件的注释中。 # 1. 最开始的部份，大多是环境设置与默认值设置 set timeout=5 set default=\"2\" ### BEGIN /etc/grub.d/10_linux ### # 2. /etc/grub.d/10_linux 生成的菜单项 menuentry 'CentOS Linux (4.9.86-30.el7.x86_64) 7 (Core)' --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option 'gnulinux-4.9.86-30.el7.x86_64-advanced-0afffff8-52f1-4af0-90e5-958f57489518' { load_video set gfxpayload=keep insmod gzio insmod part_gpt insmod xfs if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d else search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d fi linuxefi /vmlinuz-4.9.86-30.el7.x86_64 root=/dev/mapper/cl-root ro crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet initrdefi /initramfs-4.9.86-30.el7.x86_64.img } ### END /etc/grub.d/10_linux ### ### BEGIN /etc/grub.d/30_os-prober ### ### END /etc/grub.d/30_os-prober ### ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:3:1","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.2 grub2 辅助配置文件 下面我们来看各个辅助配置文件的组成 /etc/default/grub 主要环境配置文件，常见的配置选项如下 GRUB_TIMEOUT=5 # 作用: 指定默认倒数读秒的秒数，0 表示直接开机，-1 表示必需用户选择 GRUB_TIMEOUT_STYLE # 作用：是否隐藏菜单项目 # 选项：menu -- 默认，显示菜单 # countdown -- 显示剩余秒数，不显示菜单 # hidden -- 什么都不显示 GRUB_DISTRIBUTOR=\"$(sed 's, release .*$,,g' /etc/system-release)\" # GRUB_DEFAULT=2 # 作用： 指定要用哪一个菜单 （menuentry） 来作为默认开机项目 # 可选值：包括“ saved, 数字, title 名,ID 名”等等 # ID 名值的是 menuentry 后使用 --id 为选项指定的 ID # 默认值：就是以第一个开机菜单来作为默认项目 GRUB_DISABLE_SUBMENU=true # 作用：是否要隐藏次菜单，通常是藏起来的好！ GRUB_TERMINAL_OUTPUT=\"console\" # 作用：指定输出的画面应该使用哪一个终端机来显示 # 可选值：console, serial, gfxterm, vga_text # 默认值：console 文字终端机 GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet\" # 作用：为 menuentry 内 linux16 指定的内核追加额外的参数 GRUB_DISABLE_RECOVERY=\"true\" # 作用：取消救援菜单的制作 /etc/grub.d/ 分段配置，每个文件实现一个特殊功能，grub2-mkconfig 会分析并执行 /etc/grub.d/* 内的文件，来创建 grub.cfg 00_header: 创建初始的显示项目，包括需要载入的模块分析、屏幕终端机的格式、倒数秒数、菜单是否需要隐藏等等，大部分在 /etc/default/grub 里面所设置的变量，大概都会在这个脚本当中被利用来重建 grub.cfg 10_linux: 根据分析 /boot 下面的文件，尝试找到正确的 linux 核心与读取这个核心需要的文件系统模块与参数,将所有在 /boot 下面的核心文件创建为一个独立的菜单选项 30_os-prober: 查看系统其他分区是否存在操作系统，如果存在制作成一个独立的菜单选项，可通过 /etc/default/grub 内的选项 GRUB_DISABLE_OS_PROBER=true 来取消此文件的执行 40_custom: 如果还有其他想要自己手动加上去的菜单项目，或者是其他的需求，那么建议在这里补充 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:3:2","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.3 grub2 中的帐号机制 grub2 内将用户分为了两类，超级管理帐号(superusers) 和普通用户(users) 特性 superusers user 作用 设置系统管理员与相关参数还有密码等 设置一般帐号的相关参数与密码，可设置多个用户 权限 将可在 grub2 内具有所有修改的权限 使用这个密码的用户可以选择要进入某些菜单项目 附注 一旦设置了这个 superusers 的参数，则所有的指令修改将会被变成受限制的 菜单项目也要搭配相对的帐号才行 附注 只有系统管理员能够修改参数 一般用户只能选择可用的开机菜单，不能修改菜单 设置 grub 帐号的步骤 以设置一个超级管理员帐号 vbird,和一个普通帐号 dmtsai 为例，相关操作如下 # 1. 先取得 vbird 与 dmtsai 的密码。 \u003e grub2-mkpasswd-pbkdf2 Enter password: # 输入 vibird 密码 Reenter password: # 再一次输入密码 PBKDF2 hash of your password is XXXXXXXXXXXXXXXXXXXXX # 2. 将密码与帐号写入到 01_users 文件内 # 附注：在 /etc/grub.d/* 下面的文件是“执行脚本”,只能通过 cat 或 echo 来将帐密数据显示出来 \u003e vim /etc/grub.d/01_users cat \u003c\u003c eof set superusers=\"vbird\" password_pbkdf2 vbird XXXXXXXXXXXXXXXXXXXXX password_pbkdf2 dmtsai XXXXXXXXXXXXXXXXXXXXX eof # 3. 给 01_users 给予执行权限 \u003e chmod a+x /etc/grub.d/01_users # 4. 修改 menuentry，配置用户 # --unrestricted：默认不受限制 # --users \"帐号名称\"：限定特定账户使用 # 无 --users 无 --unrestricted：一定要系统管理员”才能够进入与修改 \u003e vim /etc/grup.d/40_custom menuentry MyLinux --users dmtsai { load_video insmod gzio linux16 ...... ......... } ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:3:3","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"4. 安装 grub2 grub2-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 \u003e mkdir /mnt/boot \u003e mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区 \u003e grub2-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中 \u003e grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:4:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5. 开机过程中常见问题解决 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:5:0","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.1 忘记开机密码 新版的 systemd 的管理机制中，需要 root 的密码才能以救援模式登陆 Linux，所以无法通过救援模式重新设置 root 密码。我们需要借助 rd.break 核心参数 进入开机画面，按下 e 来进入编辑模式，在 linux16 参数上添加 rd.break 参数 改完之后按下 [crtl]+x 开始开机 开机完成后屏幕会出现如下的类似画面,此时处于 RAM Disk 的环境，正真的根应该被挂载在 /sysroot \u003e mount # 检查一下挂载点！一定会发现 /sysroot 才是对的 /dev/mapper/centos-root on /sysroot \u003e mount -o remount,rw /sysroot # 挂载成可读写 \u003e chroot /sysroot # 实际切换了根目录的所在！取回你的环境了 \u003e echo \"your_root_new_pw\" | passwd --stdin root # 修改root密码 \u003e touch /.autorelabel # 如果SELinux=Enforcing，必需，详细说明见下 \u003e exit \u003e reboot # touch /.autorelabel 等同操作 # 1. 在 rd.break 模式下，修改完 root 密码后，将SELinux 该为 Permissive \u003e vim /etc/selinux/config SELINUX=permissive # 2. 重新开机后，重至 /etc SELinux 安全文本 \u003e restorecon -Rv /etc \u003e vim /etc/selinux/config SELINUX=Enforcing \u003e setenforce 1 SELinux 的说明: 在 rd.break 的 RAM Disk 环境下，系统是没有 SELinux 的,更改密码会修改 /etc/shadow， 所以的 shadow 的SELinux 安全本文的特性将会被取消，SELinux 为 Enforcing 的模式下，如果你没有让系统于开机时自动的回复 SELinux 的安全本文，你的系统将产生“无法登陆”的问题。加上 /.autorelabel 就是要让系统在开机的时候自动的使用默认的 SELinux type 重新写入 SELinux 安全本文到每个文件去 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:5:1","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.2 因文件系统错误而无法开机 文件系统错误常见原因有两个: 通常就是 /etc/fstab的设置问题，尤其是使用者在实作 Quota/LVM/RAID 时，最容易写错参数， 又没有经过 mount -a 来测试挂载，就立刻直接重新开机 曾经不正常关机后，也可能导致文件系统不一致情况， 也有可能会出现相同的问题 开机启动时，在检查文件系统时会有提示信息，类似下图所示。通常只要输入 root 密码进入救援模式，然后重新挂载根目录即可。 上图属于第二种错误状况。图中的第二行处，fsck 告知其实是 /dev/md0 出错。系统会自动利用 fsck.ext3 去检测 /dev/md0，等到系统发现错误，并且出现“clear [Y/N]”时，输入“ y ”即可。但是需要注意的是 partition 上面的 filesystem 有过多的数据损毁时，即使 fsck/xfs_repair 完成后，可能因为伤到系统盘，导致某些关键系统文件数据的损毁，那么依旧是无法进入 Linux 此时，最好就是将系统当中的重要数据复制出来，然后重新安装，并且检验一下，是否实体硬盘有损伤的现象才好 ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:5:2","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.3 进入紧急模式 systemd.unit=emergency.target ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:5:3","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.4 通过光盘进入救援模式 如果 grub 已经损坏，并已重启，将无法进入 grub，也就无法正常开机，此时需要借助光盘进入救援模式 进入 BIOS 调整开机启动次序 插入光盘或装机U盘，开机启动，进入如下画面 选择\"Troubleshooting\", 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 \u003e chroot /mnt/sysimage/ \u003e grub-install /dev/sda ","date":"2018-02-23","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/:5:4","tags":["马哥 Linux"],"title":"13.5 grub2 系统配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"13.4 grub配置与使用","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"grub配置与使用 本节我们我们将学习主流的 BootLoader 程序 grub。这部分内容与开机启动项设置，忘记 root 密码，操作系统修复相关。grub 有两个版本，使用方式几乎完全不一样，本节首先介绍第一个版本，下一节介绍第二个版本。本节内容如下: grub 概述 认识 grub 的菜单 grub 的启动流程 grub 命令行的使用 grub 的配置文件 安装 grub 开机过程中常见问题解决 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. grub 概述 grub: 是 GRand Unified Bootloader 的简称，目前包括如下两个版本。 grub 0.x: grub legacy，简称 grub grub 1.x: grub2 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 认识 grub 菜单 正常开机启动后，我们就会看到一个类似上图的grub 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。上图是我虚拟机上 grub2 的界面。grub 界面类似，操作完全相同。 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 启动步骤 grub 启动包括三个步骤: stage1: BIOS 读取并加载 mbr 中的 BootLoader stage1_5: 位于 mbr 之后的扇区，作用是让 stage1 中的 bootloader 能识别 stage2 所在的分区上的文件系统 stage2：位于/boot/grub/，stage2及内核等通常放置于一个基本磁盘分区，因为 stage1_5 能识别的文件系统有限，其实现的功用如下： 提供菜单、并提供交互式接口 加载用户选择的内核或操作系统 允许传递参数给内核 可隐藏此菜单 为菜单提供了保护机制 为编辑菜单进行认证 为启用内核或操作系统进行认证 在学习 grub 使用时，我们首先需要了解 grub 是如何识别设备的。grub 中使用 (hd#,#) 表示磁盘设备及分区 (hd#,#) hd#: 表示磁盘编号，用数字表示，从0开始编号 #: 表示分区编号，用数字表示; 从0开始编号 例如 (hd0,0) 表示第一块磁盘的第一个分区。 我们知道 grub 的作用就是在没有根文件系统的前提下直接加载内核，因此 grub 的根设备与操作根设备文件系统不是同一个概念。grub 的根设备指的是包含stage2 以及内核文件所在的设备，内核文件的位置也是相对于 grub 根设备的文件系统而言的。 如果 /boot 独立分区，那么 grub 的根设备就是 /boot 所在分区，内核文件直接位于根之下，所以其路径为 /vmlinuz-VERSION 如果 /boot 是 / 下的目录，那么 grub 的根设备就是 / 所在分区，内核文件的路径为 /vmlinuz-VERSION 所以 grub 的根对内核文件的路径有着直接影响。 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:1:2","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. grub的命令行接口 下面是在 grub 命令行中直接启动操作系统的示例，grub 命令行有很多可用命令，列示如下: # 手动在grub命令行接口启动系统 grub\u003e root (hd#,#) grub\u003e kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICE selinux=0 init=/bin/bash grub\u003e initrd /initramfs-VERSION-RELEASE.img grub\u003e boot help: 获取帮助列表 help COMMAND: command 详细帮助信息 root (hd#,#): 设置根设备 find (hd#,#)/PATH/TO/SOMEFILE：查找特定磁盘分区上的文件，如果使用了 root 指定了根设备可以省略 (hd#,#)，下同 kernel /PATH/TO/KERNEL_FILE: 设定本次启动时用到的内核文件；额外还可以添加许多内核支持使用的cmdline参数 initrd /PATH/TO/INITRAMFS_FILE: 设定为选定的内核提供额外文件的ramdisk boot: 引导启动选定的内核 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3. 配置文件： grub 的配置文件在 /boot/grub/grub.conf, /etc/grub.conf 是其软连接。一个最简单的配置文件如下，注释中描述了每一项的含义。grub 中实现了菜单编译和选中特定菜单的两级认证功能。可以使用明文密码，但是建议使用 md5 加密后字串。grub 为我们提供了一个快捷命令 grub-md5-crypt 用于生成密码的 md5 # grub 示例配置文件 default=0 # 设定默认启动的菜单项，编号从0开始 timeout=5 # 指定菜单项等待选项选择的时长 splashimage=(hd0,0)/PATH/TO/XPM_PIC_FILE： # 指明菜单背景图片文件路径 hiddenmenu # 隐藏菜单，不想隐藏，无须此项即可 password --md5 MD5_STRING # 设置菜单编辑密码，--md5 后跟 md5 加密后的密码字符串 title My Linux # 定义菜单项“标题”, 可出现多次； root (hd#,#) # grub查找stage2及kernel文件所在设备分区，为grub的“根”; kernel /PATH/TO/VMLINUZ_FILE [PARAMETERS] # 启动的内核 initrd /PATH/TO/INITRAMFS_FILE # 内核匹配的ramfs文件； password --md5 MD5_STRING #启动选定的内核或操作系统时进行认证； # 使用 grub-md5-crypt 生成 md5 密码串 \u003e grub-md5-crypt Password: # 输入两次密码 Password: MD5_STRING ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"4. 安装 grub grub 正常情况下，不\"瞎搞\"，不会损坏，毕竟不会有谁没事去覆盖掉磁盘的 MBR，但是不怕一万就怕万一。安装双系统时，如果后安装的 Window，window 的 BootLoader 是没法引导 Linux，但是 grub 能引导 Window，此时我们就需要重新安装 Linux。 安装 grub 有两种方法，如下 方法一 命令行 grub-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 \u003e mkdir /mnt/boot \u003e mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区 \u003e grub-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中 \u003e grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 方法二 grub 命令行 # 前提: 设备上必须存在 grup 目录，里面的文件必须齐全 grub\u003e root (hd#,#) grub\u003e setup (hd#) ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:4:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5. 常见开机问题的解决 ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:5:0","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.1 进入单用户模式： 编辑grub菜单(选定要编辑的title，而后使用e命令); 在选定的 kernel 后附加 1, s, S或single都可以； 在kernel所在行，键入“b”命令； ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:5:1","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"5.2 grub 已经损坏，并已重启 这种情况下已经无法进入 grub，因此需要使用光盘或装机 U 盘进入救援模式 进入 BIOS 调整开机启动次序 开机启动，进入如下画面 选择\"Troubleshooting\", 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 \u003e chroot /mnt/sysimage/ \u003e grub-install /dev/sda ","date":"2018-02-22","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/:5:2","tags":["马哥 Linux"],"title":"13.4 grub配置与使用","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/grub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"13.3 Centos7 Systemd 启动流程","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"Centos7 Systemd 启动流程 本节我们学习 Centos7 的开机启动程序 Systemd，及其服务管理工具 systemctl。我们会与 Centos6 中的 upstart 的启动程序对比来讲解。大家也可以参考阮一峰老师的博客。本节内容如下: Systemd 概述 Systemctl 命令的使用 Systemd 配置文件格式 ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:0:0","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1. Sysmted 概述： MBR 架构的系统，开机启动过程是 POST --\u003e Boot Sequeue(BIOS) --\u003e Bootloader(MBR) --\u003e Kernel(ramdisk) --\u003e rootfs --\u003e /sbin/init，而 Systemd 正是 Centos7 的/sbin/init 程序 ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:0","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.2 Systemd的新特性 systemd 相比于 Centos5 的 SysV init，和 Centos 的 Upstart，具有如下特性: 新特性 系统引导时实现服务并行启动； 按需激活进程； 系统状态快照； 基于依赖关系定义服务控制逻辑； 关键特性： 基于socket的激活机制：socket与程序分离； 基于bus的激活机制； 基于device的激活机制； 基于Path的激活机制； 系统快照：保存各unit的当前状态信息于持久存储设备中； 向后兼容sysv init脚本；/etc/init.d/ 不兼容： systemctl的命令是固定不变的； 非由systemd启动的服务，systemctl无法与之通信； 1.2 服务配置 Sysv init 和 Upstart 中，服务的管理单元是一个个具有特定格式的 shell 脚本，由 service 命令统一进行管理。而 Systemd 中服务的核心单元叫 Unit，unit 由其相关配置文件进行标识、识别和配置，配置文件中主要包含了系统服务、监听的socket、保存的快照以及其它与init相关的信息。systemd 按照功能将 unit 分为了如下几种类型。 unit的常见类型 类型 文件扩展名 作用 Service unit .service 用于定义系统服务 Target unit .target 用于模拟实现运行级别 Device unit .device 用于定义内核识别的设备 Mount unit .mount 定义文件系统挂载点 Socket unit .socket 用于标识进程间通信用到的socket文件 Snapshot unit .snapshot 管理系统快照 Swap unit .swap 用于标识swap设备 Automount unit .automount 文件系统自动点设备 Path unit .path 用于定义文件系统中的一文件或目录 systemd 的配置文件 systemd 的配置文件位于以下三个目录中 /usr/lib/systemd/system: 实际配置文件的存存放位置 /run/systemd/system：不常用 /etc/systemd/system: 基本上都是软连接 对于那些支持 Systemd 的软件，安装的时候，会自动在/usr/lib/systemd/system目录添加一个配置文件。 如果你想让该软件开机启动，就执行下面的命令（以httpd.service为例）。 [root@hp system]# ll /etc/systemd/system/default.target lrwxrwxrwx. 1 root root 40 3月 5 17:37 /etc/systemd/system/default.target -\u003e /usr/lib/systemd/system/graphical.target [root@hp system]# systemctl enable httpd Created symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 上面的命令相当于在 /etc/systemd/system 目录添加一个符号链接，指向 /usr/lib/systemd/system 里面的httpd.service文件。 这是因为开机时，Systemd只执行 /etc/systemd/system 目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。 除了使用普通的文本查看命令外查看配置文件外，systemctl cat NAME.service 可通过服务名称直接查看配置文件 [root@hp system]$ systemctl cat httpd # /usr/lib/systemd/system/httpd.service [Unit] Description=The Apache HTTP Server After=network.target remote-fs.target nss-lookup.target Documentation=man:httpd(8) Documentation=man:apachectl(8) [Service] Type=notify EnvironmentFile=/etc/sysconfig/httpd ExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUND ExecReload=/usr/sbin/httpd $OPTIONS -k graceful ExecStop=/bin/kill -WINCH ${MAINPID} # We want systemd to give httpd some time to finish gracefully, but still want # it to kill httpd after TimeoutStopSec if something went wrong during the # graceful stop. Normally, Systemd sends SIGTERM signal right after the # ExecStop, which would kill httpd. We are sending useless SIGCONT here to give # httpd time to finish. KillSignal=SIGCONT PrivateTmp=true [Install] WantedBy=multi-user.target ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:1","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"2. systemctl 命令使用 ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:2:0","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"2.1 管理系统服务 (service unit) systemctl [OPTIONS...] COMMAND [NAME...] OPTIONS: -t, --type=: 指定查看的 unit 类型 -a, --all：查看所由服务 服务启动与关闭 作用 init systemctl 启动 service NAME start systemctl start NAME.service 停止 service NAME stop systemctl stop NAME.service 重启 service NAME restart systemctl restart NAME.service 状态 service NAME status systemctl status NAME.service 条件式重启 service NAME condrestart systemctl try-restart NAME.service 重载或重启服务 systemctl reload-or-restart NAME.servcie 重载或条件式重启服务 systemctl reload-or-try-restart NAME.service [root@hp system]# systemctl status httpd ● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-07 09:14:30 CST; 1s ago Docs: man:httpd(8) man:apachectl(8) Main PID: 6170 (httpd) Status: \"Processing requests...\" CGroup: /system.slice/httpd.service ├─6170 /usr/sbin/httpd -DFOREGROUND ├─6174 /usr/sbin/httpd -DFOREGROUND ├─6176 /usr/sbin/httpd -DFOREGROUND ├─6177 /usr/sbin/httpd -DFOREGROUND ├─6178 /usr/sbin/httpd -DFOREGROUND ├─6180 /usr/sbin/httpd -DFOREGROUND └─6181 /usr/sbin/httpd -DFOREGROUND 8月 07 09:14:28 hp.tao systemd[1]: Starting The Apache HTTP Server... 8月 07 09:14:30 hp.tao systemd[1]: Started The Apache HTTP Server. 输出: Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志 服务状态查看 作用 init systemctl 查看某服务当前激活与否的状态 systemctl is-active NAME.service 查看所有已激活的服务 systemctl list-units –type service 查看所有服务（已激活及未激活) systemctl list-units -t service –all 开机自启 作用 init systemctl 设置服务开机自启 chkconfig NAME on systemctl enable NAME.service 禁止服务开机自启 chkconfig NAME off systemctl disable NAME.service 查看某服务是否能开机自启 chkconfig –list NAME systemctl is-enabled NAME.service 查看所有服务的开机自启状态 chkconfig –list systemctl list-unit-files –type service 禁止某服务设定为开机自启 systemctl mask NAME.service 取消此禁止 systemctl unmask NAME.servcie 依赖关系 作用 init systemctl 查看服务的依赖关系 systemctl list-dependencies NAME.service ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:2:1","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"2.2 管理 target units 作用 init systemctl 运行级别 0 runlevel0.target, poweroff.target 运行级别 1 runlevel1.target, rescue.target 运行级别 2 runlevel2.tartet, multi-user.target 运行级别 3 runlevel3.tartet, multi-user.target 运行级别 4 runlevel4.tartet, multi-user.target 运行级别 5 runlevel5.target, graphical.target 运行级别 6 runlevel6.target, reboot.target 级别切换 init N systemctl isolate NAME.target 查看级别 runlevel systemctl list-units –type target 查看所有级别 systemctl list-units -t target -a 获取默认运行级别 /etc/inittab systemctl get-default 修改默认运行级别 /etc/inittab systemctl set-default NAME.target 切换至紧急救援模式 systemctl rescue 切换至emergency模式 systemctl emergency ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:2:2","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"2.3 其它常用快捷命令 关机： systemctl halt, systemctl poweroff 重启： systemctl reboot 挂起： systemctl suspend 快照： systemctl hibernate 快照并挂起： systemctl hybrid-sleep ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:2:3","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"3. service unit file 配置 ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:3:0","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"3.1 unit file 组成 unit file 通常由如下 三个部分组成: [Unit]： 定义与Unit类型无关的通用选项； 用于提供 unit 的描述信息、unit 行为及依赖关系等； [Service]： 与特定类型相关的专用选项；此处为 Service 类型； [Install]： 定义由systemctl enable以及systemctl disable命令在实现服务启用或禁用时用到的一些选项； # systemctl cat sshd # /usr/lib/systemd/system/sshd.service [Unit] Description=OpenSSH server daemon Documentation=man:sshd(8) man:sshd_config(5) After=network.target sshd-keygen.service Wants=sshd-keygen.service [Service] Type=notify EnvironmentFile=/etc/sysconfig/sshd ExecStart=/usr/sbin/sshd -D $OPTIONS ExecReload=/bin/kill -HUP $MAINPID KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target Unit段 Description：当前服务的简单描述 After：定义unit的启动次序；表示当前unit应该晚于哪些unit启动；其功能与Before相反； Before：定义sshd.service应该在哪些服务之前启动 Requies：依赖到的其它units；强依赖，被依赖的units无法激活或异常退出时，当前unit即无法激活； Wants：依赖到的其它units；弱依赖，被依赖的units无法激活时，不影响当 unit 的启动； Conflicts：定义units间的冲突关系； 附注： After和Before字段只涉及启动顺序，不涉及依赖关系 Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的 Service段 Type：用于定义影响ExecStart及相关参数的功能的unit进程启动类型； simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 EnvironmentFile：指定当前服务的环境参数文件 ExecStart：指明启动unit要运行命令或脚本；其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件 ExecReload：重启服务时执行的命令 ExecStop：停止服务时执行的命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 Restart：定义了服务退出后，Systemd 的重启方式 no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 on-abnormal：只有被信号终止和超时，才会重启 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启 附注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal KillMode:定义 Systemd 如何停止服务 control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。 RestartSec：表示 Systemd 重启服务之前，需要等待的秒数 对于 sshd 服务而言将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。 所有的启动设置之前，都可以加上一个连词号（-），表示\"抑制错误\"，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误 Install段 Alias： RequiredBy：被哪些units所依赖； WantedBy：表示该服务所在的 Target ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:3:1","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"3.2 修改配置文件后重启 对于新创建的unit文件或修改了的unit文件，要通知systemd重载此配置文件 systemctl daemon-reload ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:3:2","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"4.Target 的配置文件 [root@hp system]$ systemctl cat multi-user.target # /usr/lib/systemd/system/multi-user.target # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. [Unit] Description=Multi-User System Documentation=man:systemd.special(7) Requires=basic.target Conflicts=rescue.service rescue.target After=basic.target rescue.service rescue.target AllowIsolate=yes Target 配置文件里面没有启动命令 Requires：要求basic.target一起运行。 Conflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。 After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。 AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target ","date":"2018-02-21","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:4:0","tags":["马哥 Linux"],"title":"13.3 Centos7 Systemd 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos7-systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"13.2 Centos5 init 启动流程","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"Centos5 init 启动流程 在上一节我们详细讲解了开机启动流程中内核级部分，接下来我们讲学习内核加载并完成根文件系统之后 init 程序的启动过程。因为内容过多，而且不同Centos 版本并不相同，因此我们将分成两个节，本节将讲解一下内容: CentOS5 SysV init 的启动流程 /etc/inittab 的格式和内容 Centos5 的服务启动方式 chkconfig 设置服务开机启动 /sbin/init 程序执行的操作 CentOS6 Upstart 的启动流程 ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:0:0","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.1 CentOS 5： SysV init ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:0","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.1 运行级别 运行级别：为了系统的运行或维护等目的而设定的机制； 0-6：7个级别； 0: 关机, shutdown 1: 单用户模式(single user)，root用户，无须认证；维护模式； 2: 多用户模式(multi user)，会启动网络功能，但不会启动NFS；维护模式； 3: 多用户模式(mutli user)，完全功能模式；文本界面； 4: 预留级别：目前无特别使用目的，但习惯以同3级别功能使用； 5: 多用户模式(multi user)， 完全功能模式，图形界面； 6: 重启，reboot 默认级别：3, 5 级别切换：init level 级别查看： who -r runlevel ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:1","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.2 配置文件：/etc/inittab /etc/inittab 作用: 每行定义一种 action 以及与之对应的 process 格式: id:runlevels:action:process id：一个任务的标识符； runlevels：在哪些级别启动此任务，格式如下: n: 单个数字例如 2，表示仅在第二级别 nnn: 多个数字例如 234，表示在第二三四级别 也可以为空，表示所有级别； action：在什么条件下启动此任务； process：任务； action： wait：等待切换至此任务所在的级别时执行一次； respawn：一旦此任务终止，就自动重新启动之； initdefault：设定默认运行级别；此时，process省略； sysinit：设定系统初始化方式，此处一般为指定/etc/rc.d/rc.sysinit脚本； id:3:initdefault: -- 设置系统默认启动级别 si::sysinit:/etc/rc.d/rc.sysinit -- 系统初始化脚本 l0:0:wait:/etc/rc.d/rc 0 -- rc 脚本框架，启动对应级别下的服务 l1:1:wait:/etc/rc.d/rc 1 ………… l6:6:wait:/etc/rc.d/rc 6 tty1:2345:respawn:/usr/sbin/mingetty tty1 --- 虚拟终端启动 ... ... tty6:2345:respawn:/usr/sbin/mingetty tty6 # mingetty会调用login程序； # 打开虚拟终端的程序除了mingetty之外，还有诸如getty等； rc 脚本框架： for srv in /etc/rc.d/rc#.d/K*; do $srv stop done for srv in /etc/rc.d/rc#.d/S*; do $srv start done rc脚本：接受一个运行级别数字为参数； rc 3: 意味着去启动或关闭/etc/rc.d/rc3.d/目录下的服务脚本所控制服务； K*：要停止的服务；K##*，优先级，数字越小，越是优先关闭；依赖的服务先关闭，而后关闭被依赖的； S*：要启动的服务；S##*，优先级，数字越小，越是优先启动；被依赖的服务先启动，而依赖的服务后启动； rc#.d/ 目录下所有文件都是链接文件，连接到 /etc/rc.d/init.d/ \u003e ls /etc/rd.d/ init.d rc rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local rc.sysinit ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:2","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.2 服务启动 /etc/init.d/* (/etc/rc.d/init.d/*)脚本执行方式： /etc/init.d/SRV_SCRIPT {start|stop|restart|status} service SRV_SCRIPT {start|stop|restart|status} ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:3","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.3 配置服务开机启动 chkconfig命令： 作用: 管控/etc/init.d/每个服务脚本在各级别下的启动或关闭状态； 添加：chkconfig --add name 作用: 将 name 脚本添加到service 命令的控制中，并按照脚本中 chkconfig 的配置在对应级别下设置开机启动，其他级别下设置开机关闭 启动/关闭指定级别服务： chkconfig [--level LEVELS] name on|off|reset --level LEVELS：指定要控制的级别；默认为2345； 查看：chkconfig --list [name] 删除：chkconfig --del name 作用: 将服务从 service 管理的范围内删除，并从各个级别的开机启动中删除 注意：正常级别下，最后启动的一个服务S99local 没有链接至/etc/init.d下的某脚本，而是链接至了/etc/rc.d/rc.local （/etc/rc.local）脚本；因此，不便或不需写为服务脚本的程序期望能开机自动运行时，直接放置于此脚本文件中即可 \u003e vim /etc/init.d/testsrv #!/bin/bash # testsrv serviec testing script # # chkconfig: 234 50 60 # description: testing service # 注解: 必须要有 chkconfig: # chkconfig: LLL NN NN -- 被添加到的级别，启动优先级，关闭优先级 # chkconfig: - 50 60 -- 表示没有级别 $prog=$(basename $0) if [ $# -lt 1 ]; then echo \"Usage: ${prog} {start|stop|status|restart}\" exit 1 fi if [ \"$1\" == \"start\" ]; then echo \"start $prog success\" elif [ \"$1\" == \"stop\" ]; then echo \"stop $prog success\" elif [ \"$1\" == \"status\" ]; then if pidof $prog \u0026\u003e /dev/null; then echo \"$prog is running\" else echo \"$prog is stopped\" fi elif [ \"$1\" == \"restart\" ]; then echo \"restart $prog success\" else echo \"Usage: ${prog} {start|stop|status|restart}\" exit 2 fi \u003e chkconfig --add testsrv \u003e ls /etc/rc.d/rc3.d/ |grep testsrv \u003e chkconfig --list testsrv \u003e chkconfig --level 23 testsrv off \u003e chkconfig --del testsrv ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:4","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"1.5 总结（用户空间的启动流程）： /sbin/init (/etc/inittab) 设置默认运行级别 运行系统初始化脚本(/etc/rc.d/rc.sysinit)，完成系统初始化 设置主机名 设置欢迎信息 激活udev和selinux 挂载/etc/fstab文件中定义的所有文件系统 检测根文件系统，并以读写方式重新挂载根文件系统 设置系统时钟； 根据/etc/sysctl.conf文件来设置内核参数 激活lvm及软raid设备 激活swap设备 加载额外设备的驱动程序 清理操作 关闭对应级别下需要停止的服务，启动对应级别下需要开启的服务 设置登录终端 [–\u003e 启动图形终端] ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:5","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"2. CentOS 6： Centos 6 中init程序为 upstart，但依然为/sbin/init 配置文件包括如下: /etc/init/*.conf /etc/inittab（仅用于定义默认运行级别） 注意：*.conf为upstart风格的配置文件，需遵循其配置语法； rcS.conf rc.conf start-ttys.conf CentOS 6启动流程： POST –\u003e Boot Sequence(BIOS) –\u003e Boot Loader (MBR) –\u003e Kernel(ramdisk) –\u003e rootfs –\u003e switchroot –\u003e /sbin/init –\u003e(/etc/inittab, /etc/init/*.conf) –\u003e 设定默认运行级别 –\u003e 系统初始化脚本 –\u003e 关闭或启动对应级别下的服务 –\u003e 启动终端 ","date":"2018-02-20","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/:1:6","tags":["马哥 Linux"],"title":"13.2 Centos5 init 启动流程","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/"},{"categories":["Linux"],"content":"13.1 CentOS系统启动流程介绍","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"CentOS系统启动流程介绍 本章我们将学习 Linux 启动流程和内核模块管理相关的内容。通过本章我们将学习如下内容: Linux 系统的组成及特点 CentOS 系统的启动流程 开机启动成 grub 的配置和使用 内核功能与内核模块的加载与使用 在学习本章内容之前，需要对之前学习的操作系统知识做一个简单梳理总结，目的是了解 Linux 系统在启动时面临了哪些问题，怎么去解决这些问题。这样我们才能知道为什么启动流程是\"这样\"。 -------------- | 库调用接口 | --------------- | 系统调用接口 | ------------------------------- | 操 作 系 统 | ------------------------------- | 底 层 硬 件 | ------------------------------- 在一个已经开机的计算机上，操作系统位于底层硬件之上，通过加载硬件的驱动程序从而能够管理各种硬件设备。操作系统通过系统调用，将管理底层硬件的接口暴露给各应用程序。应用程序在需要时发起系统调用即可完成对底层硬件的驱动。系统调用接口比较简陋，不便于程序员进行编程，因此在系统调用基础上有各种库，方便程序员进行编程。 操作系统=内核+根文件系统，Linux 中一切皆文件，Linux 的所有设备都表现为根文件系统上的某个文件。因此内核必需首先要加载底层磁盘设备的驱动程序，然后加载该磁盘设备上特定的文件系统，最后挂载根文件系统。 但是在系统启动之前，操作系统和各种驱动程序都是存放在硬盘上的。这样就会出现以下问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 因此开机启动，必需要解决上述两个问题。 本节，我们开始学习 Centos 系统的启动流程，本章开篇我们了解到，开机过程中存在两个问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 本节核心就是讲解如何解决上述两个问题，并在此基础上介绍 Linux 系统的启动。本节将包括以下内容: Linux 系统特性，包括Linux 系统的功能及设计思路 Linux 开机启动流程，包括: Linux 系统组成，Linux 为开机启动准备的额外文件 Linux 系统详细启动过程 ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:0:0","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. Linux 系统特性 Linux 主要由内核+根文件系统组成，一个运行中的Linux，可以看作是运行在内核之上，由内核负责完成底层硬件管理，从而将硬件接口抽象为系统接口以后，让根文件系统工作为文件系统的一个底层虚拟机。运行中的OS可以分为内核空间和用户空间两个部分，应用程序运行在用户空间，通常表现为一个进程或线程；而内核空间主要运行内核代码，执行特权操作，通过系统调用向用户空间输出接口。用户空间通过发起系统调用执行特权操作。 Linux 需要实现的功能包括: 进程管理，进程创建，调度，销毁 内存管理，将内存抽象为虚拟的线性地址格式，为每个进程提供一份，就好像每个进程单独运行在操作系统之上一样 IPC 机制: 消息队列 semerphor 信号量 share memory 共享内存 网络协议栈 文件系统 驱动程序 《Linux 设备驱动》 安全功能 内核设计有两种流派 单内核设计：把所有功能集成于同一个程序，典型代表为 Linux 微内核设计：每种功能使用一个单独的子系统实现，典型代表为 Windows, Solaris Linux 虽然为单内核设计但是充分吸收了微内核的特点，支持模块化(.ko (kernel object))，支持模块运行时动态装载或卸载。 ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:1:0","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. Linux 系统启动流程 ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:0","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.1 Linux 系统的组成 首先我们来解决开机启动的第二个问题。 内核加载根文件系统需要加载驱动程序，而驱动程序就在根之上。因此我们不能依赖根文件系统上的驱动程序，内核必须自带驱动程序。 一种方法是将设备的驱动程序编译进内核，对于个人用户自编译的系统没有有问题，因为只需要将其特定的驱动程序编译进内核即可，然后对于操作系统发行商而然，它面对的是各种用户的不同驱动设备，如果都将这些驱动程序编译进内核，内核将庞大无比，而每个用户又只会用到其中一个。 另一种方法是借助于中间临时根文件系统，中间临时根文件系统包含了加载根文件系统所在设备的驱动程序，而中间根文件系统放置在一个基于内存的磁盘设备中，内核无须加载其他驱动程序即可访问该设备。内核启动后，先访问基本设备挂载中间的临时根文件系统，并从中装载设备驱动程序，在真正的根文件系统准备完成之后，从临时根切换到真正的根。 用于系统初始化的基于内存的磁盘设备通常称为 ramdisk，内核在启动过程中需要将 ranmdisk 装载进内存 ，并将其识别为一个根文件系统。ramdisk 并不是发行商预先生成，而是在系统安装过程中针对当前设备临时生成了，因此其仅需包含当前设备的驱动程序即可。 因此从编译完成后的视角，Linux 系统由如下部分组成: 核心文件：/boot/vmlinuz-VERSION-release ramdisk： CentOS 5：/boot/initrd-VERSION-release.img # 基于 ram 的磁盘 CentOS 6,7：/boot/initramfs-VERSION-release.img # 基于 ram 的文件系统 模块文件： /lib/modules/VERSION-release 如果内核提供了多个版本，将会有多个内核目录 \u003e uname -r # 内核版本 4.9.86-30.el7.x86_64 \u003e ls /boot/|grep vm vmlinuz-4.9.86-30.el7.x86_64 \u003e ls /lib/modules/$(uname -r)/kernel arch crypto drivers fs lib mm net sound virt \u003e tree -L 2 /lib/modules/$(uname -r) /lib/modules/4.9.86-30.el7.x86_64 ├── build -\u003e ../../../usr/src/kernels/4.9.86-30.el7.x86_64 ├── extra ├── kernel │ ├── arch │ ├── crypto │ ├── drivers │ ├── fs │ ├── lib │ ├── mm │ ├── net │ ├── sound │ └── virt ├── modules.alias ├── modules.alias.bin ├── modules.block ├── modules.builtin ├── modules.builtin.bin ├── modules.dep ├── modules.dep.bin ├── modules.devname ├── modules.drm ├── modules.modesetting ├── modules.networking ├── modules.order ├── modules.softdep ├── modules.symbols ├── modules.symbols.bin ├── source -\u003e build ├── updates ├── vdso │ ├── vdso32.so │ └── vdso64.so └── weak-updates ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:1","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.2 MBR 与 BootSector 接下来我们来解决第一个问题，在没有根文件系统的前提下将内核加载进内存。 可引导设备的第一个分区叫MBR，MBR 中包含了开机引导程序 BootLoader。开机启动时会先加载 MBR内的BootLoader，由BootLoader 将内核加载到内存。有人可能会问，开机时是如何读取到MBR的，BootLoader又是如何读取到内核文件的。BIOS 通过硬件的 INT 13 中断功能来读取 MBR，也就是说，只要 BIOS 能够侦测的到你的磁盘 （不论磁盘是 SATA 还是 SAS ），那他就有办法通过 INT 13 这条信道来读取该磁盘的第一个扇区内的 MBR 软件，这样 boot loader 也就能够被执行。boot loader 能够识别操作系统的文件格式，也就能加载核心文件。其他分区的第一个扇区叫做 boot sector，也可以安装BootLoader，这样可以实现多系统安装。 有了上述阐述，我们就可以开始讲解开机启动流程了。 ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:2","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.2 Centos 系统的启动流程(MBR 架构) 启动流程: POST: 加电自检。 x86 架构的计算机被设计成，只要通电就会去执行，主板上有个 ROM 芯片内的BOIS程序 通过 BIOS 程序去载入 CMOS 的信息，并且借由 CMOS 内的设置值取得主机的各项硬件参数及设置，例如硬盘的大小与类型 在获取硬件信息后，BIOS 会进行开机自我测试 (Power-on Self Test, POST) ，然后开始执行硬件侦测的初始化，并设置 PnP 设 备，之后再定义出可开机的设备顺序，接下来就会开始进行开机设备的数据读取 Boot Sequence:开机启动次序 家电自检完成后，计算机就会按次序查找各引导设备，第一个有引导程序的设备即为本次启动用到的设备。 引导程序称为 BootLoader，又称引导加载器。 如果是通过U盘安装操作系统，就需要进入 BIOS 设置系统的开机启动次序 bootloader：引导加载器，程序，位于MBR中； 功能： 提供一个菜单，允许用户选择要启动的系统或不同的内核版本； 把用户选定的内核装载到RAM中的特定空间中，解压、展开，而后把系统控制权移交给内核 Windows：ntloader Linux： LILO：LIinux LOader GRUB：Grand Uniform Bootloader GRUB 0.X：Grub Legacy GRUB 1.X：Grub2 MBR/GRUB: MBR：Master Boot Record，512bytes： 446bytes：bootloader 64bytes：fat, 磁盘分区表 2bytes：55AA GRUB：两阶段加载 bootloader：1st stage Partition：filesystem driver, 1.5 stage Partition：/boot/grub, 2nd stage Kernel: 自身初始化： 探测可识别到的所有硬件设备； 加载硬件驱动程序；（有可能会借助于ramdisk加载驱动） 以只读方式挂载根文件系统； 运行用户空间的第一个应用程序：/sbin/init 执行 init 程序： CentOS 5：SysV init 配置文件：/etc/inittab CentOS 6：Upstart init 的升级版，可以并行启动 配置文件: /etc/inittab: 为向前兼容，基本没哟使用 /etc/init/\\*.conf CentOS 7：Systemd 配置文件： /usr/lib/systemd/system/ /etc/systemd/system/ ramdisk： Linux内核的特性之一：使用缓冲和缓存来加速对磁盘上的文件访问； 升级: ramdisk –\u003e ramfs 生成工具: CentOS 5: initrd – mkinitrd CentOS 6,7: initramfs – dracut, mkinitrd ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:3","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.3 总结:系统初始化流程（内核级别） POST自检， 按照BootSequence(BIOS)查找能开机启动的设备 在设备的 MBR上加载 BootLoader，BootLoader 去磁盘分区上读取内核。 Kernel可能会借助于 ramdisk 加载真正根文件系统所在设备的驱动程序 内核装载 rootfs（readonly，并执行开机启动程序 /sbin/init 需要说明的是无论是下述的 ramdisk 还是 BootLoader 都是在安装操作系统时针对当前硬件生成的。所以 BootLoader 是能够识别当前主机的硬盘设备的。但是需要注意的是BootLoader 是需要和磁盘分区打交道的，而BootLoader 本身一般是无法驱动那些软设备，逻辑设备(LVM),也无法驱动RAID这些复杂的逻辑结构，因此内核只能放在基本的磁盘分区上。 ","date":"2018-02-19","objectID":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/:2:4","tags":["马哥 Linux"],"title":"13.1 CentOS系统启动流程介绍","uri":"/posts/linux/linux_mt/14-linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86/centos%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"12.5 作业管理","date":"2018-02-18","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/","tags":["马哥 Linux"],"title":"12.5 作业管理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"作业管理 所谓作业管理就是我们如何在同一终端下执行多个任务。Linux 中作业分为 前台作业(foregroud)：通过终端启动，且启动后会一直占据终端； 后台作业(backgroud)：可以通过终端启动，但启动后即转入后台运行（释放终端）； 如果我们想在同一终端执行多个任务，就必须将当前的前台作业切换为后台作业 ","date":"2018-02-18","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"12.5 作业管理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"1. 将作业运行于后台 如何将作业运行于后台呢: 运行中的作业，使用 快捷键 Ctrl+z，作业被送往后台后，会转为停止状态； 尚未启动的作业 使用 COMMAND \u0026，命令后跟 \u0026，进程自动以后台作业运行 需要注意的是，上述作业虽然被送往后台，但其依然与终端相关；如果希望把送往后台的作业剥离与终端的关系使用 nohup 命令，即 nohup COMMAND \u0026 ","date":"2018-02-18","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"12.5 作业管理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2. 作业控制命令 fg [[%]JOB_NUM]：把指定的作业调回前台； bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行； kill %JOB_NUM：终止指定的作业； jobs：查看所有的作业 ","date":"2018-02-18","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"12.5 作业管理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"12.4 系统状态查看","date":"2018-02-17","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/","tags":["马哥 Linux"],"title":"12.4 系统状态查看","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"系统状态查看 系统状态查看命令，可以查看系统包括磁盘，CPU，内存，缓存，进程，网络等等几乎所有的状态信息。本节我们主要介绍 vmstat,pmap, dstat 三个命令的使用。 ","date":"2018-02-17","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/:0:0","tags":["马哥 Linux"],"title":"12.4 系统状态查看","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"1. vmstat命令： vmstat [options] [delay [count]] 作用: 查看虚拟内存使用状况 选项： -s：显示内存统计数据；类似于 cat /proc/meminfo tao@hp:~$ vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 484884 1292 3710880 0 0 179 83 455 865 14 4 82 1 0 输出: procs： r：等待运行的进程的个数；CPU上等待运行的任务的队列长度； b：处于不可中断睡眠态的进程个数；被阻塞的任务队列的长度； memory： swpd：交换内存使用总量； free：空闲的物理内存总量； buffer：用于buffer的内存总量； cache：用于cache的内存总量； swap si：数据进入swap中的数据速率（kb/s） so：数据离开swap的速率(kb/s) io bi：从块设备读入数据到系统的速度（kb/s） bo：保存数据至块设备的速率（kb/s） system in：interrupts，中断速率，即每秒发生的中断次数； cs：context switch, 上下文切换的速率，即每秒发生的进程切换次数； cpu us：user space，用户空间占用 cpu 比例 sy：system，内核空间占用 cpu 比例 id：idle，cpu 空闲比例 wa：wait，等待 I/O 完成，消耗的 cpu 时间比例 st: stolen，被虚拟化技术偷走的 cpu 时间比例 ","date":"2018-02-17","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/:1:0","tags":["马哥 Linux"],"title":"12.4 系统状态查看","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"2. pmap命令： pmap [options] pid [...] 作用: 显示进程虚拟内存到物理内存的映射关系表 -x：显示详细格式的信息； 另一种查看方式：cat /proc/PID/maps ","date":"2018-02-17","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/:2:0","tags":["马哥 Linux"],"title":"12.4 系统状态查看","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"3. dstat命令： dstat [-afv] [options..] [delay [count]] 作用: 统计系统资源的使用情况 常用选项： -c， --cpu：显示cpu相关信息； -C 1,3,...,total: 显示指定的cpu相关信息； -d, --disk：显示磁盘的相关信息 -D sda,sdb,...,tobal: 显示指定磁盘的相关信息 -g：显示page相关的速率数据； -m：Memory的相关统计数据 -n：显示network 相关统计数据； -p：显示process的相关统计数据； -r：显示io请求的相关的统计数据； -s：显示swapped的相关统计数据； --tcp --udp --raw --socket --ipc --top-cpu：显示最占用CPU的进程； --top-io：最占用io的进程； --top-mem：最占用内存的进程； --top-lantency：延迟最大的进程； tao@hp:~$ dstat You did not select any stats, using -cdngy by default. ----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system-- usr sys idl wai hiq siq| read writ| recv send| in out | int csw 14 3 82 1 1 0|1355k 633k| 0 0 | 0 0 |1788 3408 26 1 73 0 1 0| 0 4096B| 471B 224B| 0 0 |1916 1627 26 0 73 1 0 0| 0 188k| 92B 0 | 0 0 |1950 1744 ","date":"2018-02-17","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/:3:0","tags":["马哥 Linux"],"title":"12.4 系统状态查看","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B/"},{"categories":["Linux"],"content":"12.3 进程管理的实时动态命令","date":"2018-02-16","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"12.3 进程管理的实时动态命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"进程管理实时动态命令 下面介绍的 top, htop，glances 都是能实时查看系统状态的动态命令，有众多快捷键可以控制屏幕显示的内容。htop 是 top 命令的升级版，glance 则是另一款 htop 它们实现的功能类似。 ","date":"2018-02-16","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"12.3 进程管理的实时动态命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. top uptime 作用: 显示系统时间、运行时长及平均负载； 过去1分钟、5分钟和15分钟的平均负载； 等待运行的进程队列的长度； 注释: 显示内容即 top 命令的首部信息 top options 作用: display Linux processe 选项: -d #: 指定刷新时间间隔，默认为3秒； -b: 以批次方式显示； -n #: 显示多少批次，与 -b 一起使用； 快捷键: 排序: P: 以占据CPU百分比排序； M: 以占据内存百分比排序； T: 累积占用CPU时间排序； 首部信息: uptime信息: l 命令 tasks及cpu信息: t 命令 CPU分别显示使用数字 1 内存信息: m命令 退出命令: q 修改刷新时间间隔: s 终止指定的进程: k 帮助: h 显示COMMAND 详细信息: c #快捷键: l# top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40 #快捷键: t# Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie #快捷键: 1# %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st #快捷键: m# KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cache KiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4812 tao 20 0 2876852 431600 139652 S 9.5 5.3 49:00.29 atom 2150 root 20 0 447256 122816 71820 S 4.6 1.5 13:42.31 X 4384 tao 20 0 4824324 1.066g 39644 S 3.6 13.8 49:54.58 java top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40 作用: Top 任务队列信息(系统运行状态及平均负载)，与uptime命令结果相同 字段: 系统当前时间 系统运行时间，未重启的时间 当前登录用户数 系统负载，即任务队列的平均长度，3个数值分别统计最近1，5，15分钟的系统平均负载 单核CPU情况下，0.00 表示没有任何负荷，1.00表示刚好满负荷，超过1侧表示超负荷，理想值是0.7； 多核CPU负载：CPU核数 * 理想值0.7 = 理想负荷，例如：4核CPU负载不超过2.8何表示没有出现高负载 Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie 作用: Tasks 进程相关信息 字段: 进程总数，例如：Tasks: 231 total, 表示总共运行231个进程 正在运行的进程数，例如：1 running, 睡眠的进程数，例如：230 sleeping, 停止的进程数，例如：0 stopped, 僵尸进程数，例如：0 zombie %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st 作用: CPU 相关信息 字段: us: 用户空间占用CPU百分比，例如：Cpu(s): 12.7%us, sy: 内核空间占用CPU百分比，例如：8.4%sy, ni: 用户进程空间内改变过优先级的进程占用CPU百分比，例如：0.0%ni, id: 空闲CPU百分比，例如：77.1%id, wa: 等待输入输出的CPU时间百分比，例如：0.0%wa, hi: CPU服务于硬件中断所耗费的时间总额，例如：0.0%hi, si: CPU服务软中断所耗费的时间总额，例如：1.8%si, st: Steal time 虚拟机被hypervisor偷去的CPU时间（如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的） KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cache KiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem 作用: 内存 相关信息 字段: 物理内存总量，例如：Mem: 12196436k total, 使用的物理内存总量，例如：12056552k used, 空闲内存总量，例如：Mem: 139884k free, 用作内核缓存的内存量，例如：64564k buffers 字段值含义 PID = (Process Id): 进程Id； USER = (User Name): 进程所有者的用户名； PR = (Priority): 优先级 NI = (Nice value): nice值。负值表示高优先级，正值表示低优先级 VIRT = (Virtual Image (kb)): 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES = (Resident size (kb)): 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR = (Shared Mem size (kb)): 共享内存大小，单位kb S = (Process Status): 进程状态。D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程 %CPU = (CPU usage): 上次更新到现在的CPU时间占用百分比 %MEM = (Memory usage (RES)): 进程使用的物理内存百分比 TIME+ = (CPU Time, hundredths): 进程使用的CPU时间总计，单位1/100秒 PPID = (Parent Process Pid): 父进程Id RUSER = (Real user name): UID = (User Id): 进程所有者的用户id GROUP = (Group Name): 进程所有者的组名 TTY = (Controlling Tty): 启动进程的终端名。不是从终端启动的进程则显示为 ? P = (Last used cpu (SMP)): 最后使用的CPU，仅在多CPU环境下有意义 SWAP = (Swapped size (kb)): 进程使用的虚拟内存中，被换出的大小，单位kb TIME = (CPU Time): 进程使用的CPU时间总计，单位秒 CODE = (Code size (kb)): 可执行代码占用的物理内存大小，单位kb DATA = (Data+Stack size (kb)): 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb nFLT = (Page Fault count): 页面错误次数 nDRT = (Dirty Pages count): 最后一次写入到现在，被修改过的页面数 WCHAN = (Sleeping in Function): 若该进程在睡眠，则显示睡眠中的系统函数名 Flags = (Task Flags \u003csched.h\u003e): 任务标志，参考 sched.h COMMAND = (Command name/line): 命令名/命令行 ","date":"2018-02-16","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"12.3 进程管理的实时动态命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. htop htop options 选项: -d #: 指定延迟时间间隔； -u UserName: 仅显示指定用户的进程； -s COLUME: 以指定字段进行排序； 子命令: l: 显示选定的进程打开的文件列表； s: 跟踪选定的进程的系统调用； t: 以层级关系显示各进程状态； a: 将选定的进程绑定至某指定的CPU核心； ","date":"2018-02-16","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"12.3 进程管理的实时动态命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. glances命令： glances options 作用: 动态的系统状态监控工具，使用类似 top 常用选项： -b：以Byte为单位显示网上数据速率； -d：关闭磁盘I/O模块； -m：关闭mount模块； -n：关闭network模块； -t #：刷新时间间隔； -1：每个cpu的相关数据单独显示； -o {HTML|CSV}：输出格式； -f /PATH/TO/SOMEDIR：设定输出文件的位置； C/S模式下运行glances命令： 服务模式：glances -s -B IPADDR IPADDR：本机的某地址，用于监听； 客户端模式： glances -c IPADDR IPADDR：是远程服务器的地址； 附注: C/S 模式下无论是密码还是内容都是明文传输的，容易被截获，glances 不适合 C/S 模式使用 ","date":"2018-02-16","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"12.3 进程管理的实时动态命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"12.2 进程管理命令","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"进程管理命令 Linux系统上有众多进程查看及管理工具，不完全列示如下: 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall 进程优先级调整: nice, renice 这些命令在我们以后的运维过程中都能用到，希望大家能熟练掌握。 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 进程查看 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.1 pstree pstree options 作用: 以树状图的方式展现进程之间的派生关系 选项: -p: 显示程序 pid； -u: 显示用户名称； -n: 用 pid 排序,预设是以程序名称来排序； -a: 显示每个程序的完整指令，包含路径，参数或是常驻服务的标示； -c: 不使用精简标示法； -G: 使用VT100终端机的列绘图字符； -h: 列出树状图时，特别标明现在执行的程序； -H\u003cpid\u003e: 此参数的效果和指定\"-h\"参数类似，但特别标明指定的程序； -l: 采用长列格式显示树状图； -U: 使用UTF-8列绘图字符； -V: 显示版本信息 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:1","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.2 ps ps 命令简介 在前面的 4.1 Linux目录机构 我们提到过，Linux 有两个伪文件系统 /proc,/sys /proc/: 是基于内存的虚拟文件系统，保存了内核及进程的相关信息； /proc 内的内核参数分为两类: 状态变量: 其用于输出内核中统计信息或状态信息，仅用于查看 可设置其值从而调整内核运行特性的参数,位于 /proc/sys/，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； /sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径 其主要作用在于为管理Linux设备提供一种统一模型的的接口； Linux 进程的各种状态信息保存在 /proc 中以进程 PID 号命名的文件中。ps 命令即是通过读取 /proc/PID 目录内的文件，显示进程的相关信息。ps 命令选项有三种风格: UNIX 风格的参数，必需使用 - BSD 风格的参数, 不能使用 - GNU 风格的长选项, 使用--开头 ps 使用 ps [options]: 作用: report a snapshot of the current processes. BSD 选项: a: 所有与终端相关的进程； x: 所有与终端无关的进程； u: 以用户为中心组织进程状态信息显示； U\u003cuname\u003e: 显示特定用户进程 -o/o field1, field2,...: 可以加 - 也可以不加 用于自定义要显示的字段列表，字段列表以逗号分隔； 常用的field: pid, ni, pri, psr, pcpu, stat, comm, tty, ppid, rtprio UNIX 选项: -e: 显示所有进程 -f: 显示完整格式的进程信息 -F: 显示完整格式的进程信息，与 -f 显示的字段略不同 -H: 以层级结构显示进程的相关信息； -U\u003cuid\u003e: 显示特定用户进程 -u\u003cuid\u003e: 显示特定用户进程 常用组合之一: ps aux ps -ef ps -eFH ps -eo, ps axo ps aux tao@hp:~$ ps aux |head -10 USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.1 194436 9136 ? Ss 08:49 0:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 21 root 2 0.0 0.0 0 0 ? S 08:49 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? S 08:49 0:00 [ksoftirqd/0] root 5 0.0 0.0 0 0 ? S\u003c 08:49 0:00 [kworker/0:0H] root 7 0.0 0.0 0 0 ? S 08:49 0:03 [rcu_sched] root 8 0.0 0.0 0 0 ? S 08:49 0:00 [rcu_bh] root 9 0.0 0.0 0 0 ? S 08:49 0:01 [rcuos/0] root 10 0.0 0.0 0 0 ? S 08:49 0:00 [rcuob/0] root 11 0.0 0.0 0 0 ? S 08:49 0:00 [migration/0] %CPU: CPU 占用百分比 %MEM: 内存占用百分比 VSZ: 虚拟内存集； RSS: Resident Size，常驻内存集； TTY: 进程所属终端 STAT: 进程状态 R: running，运行中 S: interruptable sleeping，可中断睡眠 D: uninterruptable sleeping，不可中断睡眠 T: Stopped，停止状态 Z: zombie，僵尸进程 +: 前台进程 l: 多线程进程 N: 低优先级进程 \u003c: 高优先级进程 s: session leader，管理着多个其他进程的进程 START: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -ef tao@hp:~$ ps -ef|head -10 UID PID PPID C STIME TTY TIME CMD root 1 0 0 08:49 ? 00:00:04 /usr/lib/systemd/systemd --switched-root --system --deserialize 21 root 2 0 0 08:49 ? 00:00:00 [kthreadd] root 3 2 0 08:49 ? 00:00:00 [ksoftirqd/0] root 5 2 0 08:49 ? 00:00:00 [kworker/0:0H] root 7 2 0 08:49 ? 00:00:03 [rcu_sched] root 8 2 0 08:49 ? 00:00:00 [rcu_bh] PPID: 父进程的 pid C: cpu utilization, CPU 占用率 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eFH tao@hp:~$ ps -eFH|head -10 UID PID PPID C SZ RSS PSR STIME TTY TIME CMD root 2 0 0 0 0 2 08:49 ? 00:00:00 [kthreadd] root 3 2 0 0 0 0 08:49 ? 00:00:00 [ksoftirqd/0] root 5 2 0 0 0 0 08:49 ? 00:00:00 [kworker/0:0H] root 7 2 0 0 0 3 08:49 ? 00:00:03 [rcu_sched] root 8 2 0 0 0 0 08:49 ? 00:00:00 [rcu_bh] C: cpu utilization, CPU 占用率 SZ: VSZ 虚拟内存集； RSS: Resident Size，常驻内存集； PSR: 进程运行于哪颗CPU之上 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eo|axo tao@hp:~$ ps -eo user,uid,nice,priority,psr,pcpu,stat,rtprio,cmd,tty,ppid USER UID NI PRI PSR %CPU STAT RTPRIO CMD TT PPID root 0 0 20 0 0.0 Ss - /usr/lib/systemd/systemd -- ? 0 root 0 0 20 2 0.0 S - [kthreadd] ? 0 root 0 0 20 0 0.0 S - [ksoftirqd/0] ? 2 root 0 -20 0 0 0.0 S\u003c - [kworker/0:0H] ? 2 root 0 0 20 0 0.0 S - [rcu_sched] ? 2 root 0 0 20 0 0.0 S - [rcu_bh] ? 2 root 0 0 20 2 0.0 S - [rcuos/0] ? 2 root 0 0 20 0 0.0 S - [rcuob/0] ? 2 root 0 - -100 0 0.0 S 99 [migration/0] ? 2 ps -eo user, uid, nice, priority, psr, pcpu, stat, rtprio, cmd, tty, ppid ni/nice: nice值 priority: priority, 优先级 psr: PSR 进程运行于哪颗CPU之上 pcpu: %CPU cpu 占用百分比 stat: STAT 进程状态 rtprio: real time priority，实时优先级 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:2","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.3 pgrep pgrep [options] pattern 作用: 通过进程名或其他属性查找进程 参数: pattern 匹配进程名的模式 选项 -l: 显示进程名； -a: 显示完整格式的进程名； -u uid: effective user，有效用户 -U uid: real user，实际用户 -t TERMINAL: 与指定的终端相关的进程； -P pid: 显示此进程的子进程； -o：仅显示找到的最小（起始）进程号； -n：仅显示找到的最大（结束）进程号； tao@hp:~$ pgrep -la htt* 13163 /usr/sbin/httpd -DFOREGROUND 13169 /usr/sbin/httpd -DFOREGROUND 13172 /usr/sbin/httpd -DFOREGROUND 13173 /usr/sbin/httpd -DFOREGROUND 13177 /usr/sbin/httpd -DFOREGROUND 13178 /usr/sbin/httpd -DFOREGROUND 13180 /usr/sbin/httpd -DFOREGROUND ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:3","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.4 pidof命令: pidof [options] program [program..] 作用: 根据进程名，取其进程 pid 参数: program 进程名称 选项: -s：仅返回一个进程号； tao@hp:~$ pidof httpd 13180 13178 13177 13173 13172 13169 13163 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:4","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 进程管理 kill 类命令可以向进程发送信号，以实现对进程管理。Linux 中每个信号的标识方法有三种: 信号的数字标识； 信号的完整名称； 信号的简写名称； # HUP = SIGHUP = 1 tao@hp:monitor$ kill -l 1 HUP tao@hp:monitor$ kill -l SIGHUP 1 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.1 kill 查看信号类型 kill -l [signal] 作用: 查看信号类型 参数: signal 待查看的信号类型，可选，默认显示所有信号 常用信号: tao@hp:monitor$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX tao@hp:monitor$ kill -l 1 HUP tao@hp:monitor$ kill -l SIGHUP 1 发送信号管理进程 kill [-s signal|-SIGNAL] pid... 作用: 用于向进程发送信号，以实现对进程的管理 选项: -s signal|-SIGNAL: 指明要发送的信号 -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -u：指定用户 常用信号: 1） SIGHUP: 无须关闭进程而让其重读配置文件； 2）SIGINT: 终止正在运行的进程，相当于Ctrl+c 9）SIGKILL: 杀死运行中的进程； 15）SIGTERM: 终止运行中的进程； 18）SIGCONT: 启动暂停的进程 19）SIGSTOP: 暂停进程 kill -9 1999 kill -s 9 1999 kill -SIGKILL 1999 kill -KILL 1999 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:1","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.2 killall killall [-SIGNAL] program 作用: 使用进程的名称来杀死进程，使用此指令可以杀死一组同名进程 参数: program 进程名称 选项: -e：对长名称进行精确匹配； -l：忽略大小写的不同； -p：杀死进程所属的进程组； -i：交互式杀死进程，杀死进程前需要进行确认； -l：打印所有已知信号列表； -q：如果没有进程被杀死。则不输出任何信息； -r：使用正规表达式匹配要杀死的进程名称； -s signal|-SIGNAL：指定发送的信号 -u：杀死指定用户的进程。 ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:2","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2.3 pkill pkill [options] pattern 作用: 通过进程名或其他属性向进程发送信号，用法与 pgrep 类似 选项: -u uid: effective user，向指定的有效用户发送信号 -U uid: real user，向指定的实际用户发送信号 -t TERMINAL: 向指定的终端相关的进程发送信号； -P pid: 向此进程的子进程发送信号 -g：指定进程组； -o：仅向找到的最小（起始）进程号发送信号； -n：仅向找到的最大（结束）进程号发送信号； ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:3","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 进程优先级调整 Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级，Nice值用于调整静态优先级。 需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。进程启动时，nice值默认为0，优先级是120，可通过nice值调整的优先级范围是 100-139，nice值分别对应于-20, 19 诸多命令都可以查看进程的优先级与 nice 值，比如 ps axo pid, ni, priority, comm ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"nice nice [OPTION] [COMMAND [ARGU]...] 作用: 以指定的nice值启动并运行命令 参数: COMMAND： 要执行的命令，如果没给 COMMAND, 显示当前进程的优先级 ARGU: 传递给 COMMAND 的参数 选项： -n NICE: 指定优先级，默认为 5 注意：仅管理员可调低nice值； ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:1","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"renice renice [-n] NICE PID... 作用: 更改已经运行用户的优先级 参数: NICE: 新 nice 值 PID: 进程PID ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:2","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. 未涉及到的命令： sar, tsar, iostat, iftop, nethog, … ","date":"2018-02-15","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:0","tags":["马哥 Linux"],"title":"12.2 进程管理命令","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"12.1 Linux进程原理","date":"2018-02-14","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/","tags":["马哥 Linux"],"title":"12.1 Linux进程原理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"Linux进程原理 本章我们来学习 Linux 中的进程管理，这是运维的基本内容，我们需要借此查看 Linux 服务的负载，分析和删除系统上的异常进程等等。首先我们会简单介绍操作系统原理中有关进程，虚拟内存相关的基础知识，这是原理部分；如果对进程一无所知对很多命令的输出结果我们很难明白其含义。然后我们会介绍 Linux 上常用的进程查看和管理工具，这些都是我们分析和管理系统的重要工具，最后我们会说一说 Linux 中的作业管理。本章内容总结如下: 操作系统的基本原理之进程 常用的进程查看和管理工具 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall，nice, renice 实时动态命令的使用，top, glances, htop 系统状态查看,vmstat, pmap, dstat 作业管理 有关 Linux 的实现有两本书推荐大家观阅读 Linux内核设计与实现: 入门级 深入理解Linux内核: 进阶级 当然没那么容易说清楚进程是什么。无论是什么程序员，操作系统，编译原理永远都是谜一样的话题，但是人总是要慢慢进步的，随着我们不断成长，对其的认识也会慢慢深入。好吧，我们开始吧。 现代操作系统都是多任务系统，目前常用的服务器也就 64 个核心，通常要运行的任务一定比操作系统的核心多，那么就存在几个问题。一是我们应该如何给不同任务分配运行时间？二是多个任务如何共享使用我们的存储设备，特别是内存？这就涉及到进程和虚拟内存的概念了。 ","date":"2018-02-14","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"12.1 Linux进程原理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"1. 进程和内存的抽象 进程 进程是操作系统对一个独立的运行程序的抽象，是操作系统调度的基本单元(操作系统调度的基本单元应该是线程，但是通常一个进程只有一个线程，可以先这么理解)。每个进程都有一个叫作 task structure 的结构，其包含了该进程能正常运行的所有上下文。什么是程序运行的上下文呢？那我们要从计算机的存储系统说起。 我们都知道我们的计算机有硬盘，内存，缓存。为什么回有这么多存储设备呢？主要是因为不同的存储介质工作频率不相同，工作频率高的造价高。如果我存储介质跟不上 CPU 的频率就会造成 CPU 性能的浪费。因此基于最近被访问的数据很有可能在接下来再次被访问这样一个原理，计算机的存储系统被构建成了如下的层次结构 典型的 CPU 里面有寄存器，它的工作频率几乎和CPU 一致，但是容量很小，仅仅保存了当前指令的操作数和下一次要执行的指令。当发生进程切换时，寄存器就会被新进程的数据所覆盖。所以这些寄存器中的数据都应该被保存起来，以便下此进程再次执行时就好像从没有中断过一样能继续执行。包括 CPU 中寄存器的值，程序打开的文件描述符等等在内的维持程序能正常执行的所有数据就是进程的上下文。 虚拟内存 操作系统的任务是变化的，但是运行中的内存是不变。那么应该如何分配每个进程占用的空间，占用的内存位置，以避免它们相互影响呢？ 操作系统将内存抽象为虚拟内存，所有进程启动时，所见的内存空间均为虚拟内存，进程可以假设为当前系统上只有内核和自己。虚拟内存对于所用程序都是统一的，因此程序无需考虑实际内存的分配问题，直接向虚拟内存空间申请和释放内存即可。虚拟内存和物理内存被划分为一个个页框，当进程需要内存时，其向虚拟内存空间申请内存，然后由操作系统将空闲的物理页框与进程申请到的虚拟页框建立关联关系。进程访问数据时必需将虚拟地址转换实际的内存地址才能访问到数据。计算机上有一个专门的单元 MMU 用于完成虚拟地址的转换。上图 task_structure 中的 mm_struct 保存就是虚拟页框与物理页框的映射关系。 ","date":"2018-02-14","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"12.1 Linux进程原理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"2. 运行中进程 进程的内存空间结构如上图左边所示，包括代码段，数据段，堆栈等。创建进程时，父进程调用 fork() 系统调用创建子进程，此时子进程共享父进程的所有环境，然后子进程调用 exec() 系统调用将自己的代码装载入代码段；最后父子进程各自运行。Linux 使用写时复制，当子进程需要修改父进程的内存空间时，它首先将当前内存中的内容复制到新的空闲空间中，然后在修改。因此父子进程不会相互影响。 进程都是有父进程创建和销毁。Centos 中的第一个进程叫 init ，它是所有进程父进程。Centos567 的 init 程序并不相同。我们会在后面的系统开机启动中详细讲解。 运行中的进程存在优先级的概念，优先级用于控制进程的执行次序 Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级； 数字越小，优先级越高，Nice值(-20,19) 用于调整静态优先级。 需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。 进程之间可能需要通信，进程间通信叫作 IPC，IPC 有如下方式。 IPC: Inter Process Communication 同一主机上： signal: 信号 shm: shared memory: 共享内存 semerphor: 信号量 不同主机上： rpc: remote procecure call 远程系统调用 socket: 套接子 进程最终必需由父进程收回，如果父进程意外终止而没有收回进程，进程就会成为孤儿进程，在进程执行完成后将称为僵尸进程。 ","date":"2018-02-14","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"12.1 Linux进程原理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"3. 用户空间与内核空间 为了避免用户空间的程序破坏内核，Linux 将操作系统的指令分成了4个不同级别，这些级别的指令被分别放在操作系统抽象的环上。最内存的内核和系统调用属于特权指令，被称为内核空间，外层的指令属于普通指令，被称为用户空间。 当进程需要调用特权指令时，进程需要发出软中断，陷入内核，由内核执行所需的特权执行，并将执行结果交给用户进程。进程获取到结果后继续运行。进程等待系统调用结果而不能执行时，我们称进程处于不可中断睡眠状态。运行中的进程有如下几种状态 运行态：running，正在被CPU 执行 就绪态：ready，程序准备完成，等待内核调度执行 睡眠态： 可中断：interruptable，进程的执行时间耗尽而被换出CPU 不可中断：uninterruptable 停止态：暂停于内存中，但不会被调度，除非手动启动之；stopped 僵死态：zombie 最后Linux 中进程可以分为两类 守护进程: 在系统引导过程中启动的进程，跟终端无关的进程； 前台进程：跟终端相关，通过终端启动的进程，也可把在前台启动的进程送往后台，以守护模式运行； ","date":"2018-02-14","objectID":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/:3:0","tags":["马哥 Linux"],"title":"12.1 Linux进程原理","uri":"/posts/linux/linux_mt/13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86/linux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86/"},{"categories":["Linux"],"content":"11.7 网络客户端工具","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"网络客户端工具 在本章的最后一节，我们来说一说一些常用的网络客户端工具，包括 ping 命令 ftp 客户端工具 wget 下载工具 ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:0:0","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1. ping ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:1:0","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.1 ping ping [OPTION] destination 作用: send ICMP ECHO_REQUEST to network hosts 参数: destination 目标主机 选项: -c #：发送的ping包个数； -w #：ping命令超时时长； -W #：一次ping操作中，等待对方响应的超时时长； -s #：指明ping包报文大小； ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:1:1","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.2 hping hping options 作用: send (almost) arbitrary TCP/IP packets to network hosts 选项: --fast --faster --flood -i uX ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:1:2","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.3 traceroute traceroute ip/FQDN 作用: 跟踪从源主机到目标主机之间经过的网关； ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:1:3","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2. ftp 客户端 ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:2:0","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2.1 lftp lftp [-p port] [-u user[,pass]] server_ip 作用: ftp 客户端命令的升级版 子命令: get, mget put, mput rm, mrm help ls ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:2:1","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2.2 lftpget lftpget [-c] [-d] [-v] URL [URL...] 作用: 借助 lftp 下载文件 选项: -c：继续此前的下载； \u003e ftp server_ip # 无密码登录 \u003e Name: anonymous \u003e Password: 直接回车 ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:2:2","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"3. wget命令： wget [option]... [URL]... 作用: The non-interactive network downloader. 选项: -b：在后台执行下载操作； -q：静默模式，不显示下载进度； -O file：下载的文件的保存位置； -c：续传； --limit-rate=amount：以指定的速率传输文件； ","date":"2018-02-13","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/:3:0","tags":["马哥 Linux"],"title":"11.7 网络客户端工具","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"11.6 网络属性配置之 nmcli 系列命令","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"网络属性配置之 nmcli 系列命令 本节我们来介绍 Linux 网络属性配置的第三组系列命令 nm。nm(network management) 是 Centos7 新增的命令，使用方式类似 ip 命令，将网络属性分成了多个 OBJECT，每个 OBJECT 都有众多子命令用于对其进行管理配置。nm 主要包含两个工具: nmcli: nm 的命令行工具 nmtui: nm 的图形客户端 ","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. nmcli nmcli [ OPTIONS ] OBJECT { COMMAND | help } OBJECT: device: 显示和管理网络接口，类似 ip link connection: 启动，停止，管理网络连接，类似 ip addr ","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.1 nmcli device nmcli device COMMAND COMMAND:{status | show | connect | disconnect | delete | wifi | wimax } ","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:1","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.2 nmcli connection nmcli connection COMMAND COMMAND: { show | up | down | add | edit | modify | delete | reload | load } nmcli connection modify nmcli connection modify IFACE [+|-]\u003csetting\u003e.\u003cproperty\u003e \u003cvalue\u003e 作用: 如何修改IP地址等属性： 效力: 直接修改 ifcfg-IFACE 文件，修改完成不会生效，需要重启 参数: IFACE: 接口标识 setting.property: 网络属性值 ipv4.address ipv4.gateway ipv4.dns1 ipv4.method manual: 手动配置 dhcp localectl list-locales localectl set-locale LANG=en_US.utf8 nmcli g status # 显示网络接口状态 nmcli device show ens33 nmcli connection modify ens33 ipv4.address 192.168.1.101 # 重启以生效修改 nmcli con down ens33; nmcli connection up ens33 ","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:2","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. nmtui nmcli 命令的图形化工具 ","date":"2018-02-12","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"11.6 网络属性配置之 nmcli 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/centos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"11.5 网络配置文件","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"网络配置文件 本节我们来学习如何通过修改配置文件来更改网络属。RHEL系的网络配置文件主要包括两个部分: IP/NETMASK/GW/DNS等属性的配置文件，位于 /etc/sysconfig/network-scripts/ifcfg-IFACE 路由的相关配置文件，位于 /etc/sysconfig/network-scripts/route-IFACE 更改配置后需要重启网络服务以重载配置文件才能让配置的网络属性生效，因此我们会简单的说一说网络服务的管理。Linxu 的服务管理我们会在后面的章节详细介绍。本章将包括以下内容: 配置文件的修改 ifcfg-IFACE 配置参数 route-IFACE 配置参数 Centos 网络服务的管理 给网络接口配置多个地址 网卡名称修改 ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:0:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"1. 网络配置的修改 所有的配置文件都是文本文件，可通过vim 直接修改，Centos 也提供了专用的修改命令 CentOS 6：system-config-network-tui，setup CentOS 7: nmtui ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:1:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"2. ifcfg-IFACE ifcfg-IFACE 常用配置参数 DEVICE：此配置文件对应的设备的名称； HWADDR：设备的MAC地址； UUID：此设备的惟一标识； ONBOOT：在系统引导过程中，是否激活此接口； BOOTPROTO：激活此接口时使用什么协议来配置接口属性，常用的有dhcp、bootp、static、none； TYPE：接口类型，常见的有Ethernet, Bridge； IPADDR： IP地址； NETMASK：子网掩码；CentOS 7支持使用PREFIX以长度方式指明子网掩码； GATEWAY：默认网关； DNS1：第一DNS服务器指向； DNS2：备用DNS服务器指向； DOMAIN：DNS搜索域； IPV6INIT：是否初始化IPv6； IPV4_FAILURE_FATAL: 如果 IPV4 不可用是否关闭此网络接口 USERCTL：是否允许普通用户控制此设备； NM_CONTROLLED：是否使用NetworkManager服务来控制接口；Centos6 上建议为 no PEERDNS：如果BOOTPROTO的值为“dhcp”，是否允许dhcp server分配的dns服务器指向覆盖本地手动指定的DNS服务器指向；默认为允许 # ifcfg-IFACE 配置示例 ESSID=\"CLOUD3_5G\" NAME=CLOUD3_5G HWADDR=00:28:F8:35:06:EC UUID=816cdc8b-e62f-4bdb-9ca8-be2545a5a7e6 ONBOOT=yes BOOTPROTO=dhcp MODE=Managed KEY_MGMT=WPA-PSK TYPE=Wireless DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_ADDR_GEN_MODE=stable-privacy SECURITYMODE=open MAC_ADDRESS_RANDOMIZATION=default PEERDNS=yes PEERROUTES=yes ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"3. route-IFACE route-FACE 支持两种配置方式，但不可混用 方式一: 每行一个路由条目 TARGET via GW 192.168.1.101 via 172.168.2.1 方式一: 每三行一个路由条目 ADDRESS#=TARGET NETMASK#=MASK GATEWAY#=NEXTHOP ADDRESS0=192.168.4.0 NETMASK0=255.255.255.0 GATEWAY0=172.16.1.1 ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:3:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"4. 网络服务管理 Centos6 上网络管理的服务有两个 network，NetworkManager，但 NetworkManger 仍处于实验阶段，功能还不完善，比如创建集群或桥接接口 NetworkManger 都不支持。建议在 Centos6 中关闭 NetworkManager 只使用 network；即 将 ifcfg-IFACE 配置文件中的 NM_CONTROL 设置为 No 把 NetworkManager 服务禁止掉 Centos7 中 NetworkManager 已经很完善，并且已经是网络管理的默认服务 systemctl status network ● network.service - LSB: Bring up/down networking Loaded: loaded (/etc/rc.d/init.d/network; bad; vendor preset: disabled) Active: active (exited) since 三 2018-08-01 10:21:35 CST; 6min ago Docs: man:systemd-sysv-generator(8) Process: 12814 ExecStop=/etc/rc.d/init.d/network stop (code=exited, status=0/SUCCESS) Process: 13126 ExecStart=/etc/rc.d/init.d/network start (code=exited, status=0/SUCCESS) systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-08-01 08:45:21 CST; 1h 43min ago Docs: man:NetworkManager(8) Main PID: 1199 (NetworkManager) CGroup: /system.slice/NetworkManager.service ├─1199 /usr/sbin/NetworkManager --no-daemon ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:4:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"4.1 管理网络服务 Centos 6，7服务的启动和管理完全并相同，我们会在后面操作系统的启动流程以及服务管理详细讲解，现在大家只要知道可以使用以下这些命令即可: Centos6: service SERVICE {start|stop|restart|status} /etc/rc.d/init.d/network {start|stop|restart|status} CentOS 7： systemctl {start|stop|restart|status} SERVICE[.service] 网络配置文件修改之后，如果要生效，需要重启网络服务 CentOS 6：service network restart CentOS 7：systemctl restart NetworkManager.service ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:4:1","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"5. 给网卡配置多个地址 给网卡配置多个地址有多种方式: ip addr add ip dev IFACE label label_name ifconfig IFACE_LABEL IPADDR/NETMASK IFACE_LABEL: 地址别名，eth0:0, eth0:1, … eg: ifconfig ens33:1 192.168.1.117/24 up 为别名添加配置文件； cp ifcfg-eth0 ifcfg-eth0:0，然后修改 ifcfg-eth0:0 \u003e vim /etc/sysconfig/network-script/ifcfg-eth0:0 DEVICE=eth0:0 # DEVICE 修改为地址别名 BOOTPROTO=None # 网上别名不支持动态获取地址；只能使用 static, none 删除 HWADDR，UUID ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:5:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"6. 网络接口名称修改 udev 程序是 Linux 识别各种设备的辅助程序，因此通过修改其配置文件可以修改网络接口的名称。 # Centos6 修改过程 vim /etc/udev/rules.d/70-persistent-ipoib.rules # 更改网络接口名称 modprobe -r e1000 # 卸载网卡驱动 modprobe e1000 # 装载网卡驱动，会重新读取 70-persistent-ipoib.rules 配置文件 # Centos7 由于网卡命名规则变化，所以 Centos6 的规则不适用 ","date":"2018-02-11","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:6:0","tags":["马哥 Linux"],"title":"11.5 网络配置文件","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"11.4 网络属性配置之 ip 系列命令","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"网络属性配置之 ip 系列命令 本节我们来介绍 Linux 网络属性配置的第二组系列命令 ip 命令。ip 命令是 Linux 的\"新贵\"，相比于 ifcfg 它们更加的高效。ip 系列包括如下几个命令 ip 命令: 有众多子命令，拥有配置网络地址，网络接口属性，路由等多种功 能 ss 命令: netstat 命令的优化版，用于查看网络连接状态 ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. ip ip [ OPTIONS ] OBJECT { COMMAND | help } 作用: show / manipulate routing, devices, policy routing and tunnels. OBJECT: 作用对象 link: 网络接口属性 addr: 网络地址 route: 路由 netns: 网络命名空间 COMMAND: 每个作用对象上的可用子命令 help: 是一个通用子命令，用于显示特定作用对象的可用命令 注意： OBJECT可简写，各OBJECT的子命令也可简写； 通过上面的展示可以看出，ip 将网络地址，路由，网络接口等划分成了一个个独立的对象，每个独立的对象拥有特定的子命令来对其进行管理和配置。 ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.1 ip link ip link： network device configuration，是用来配置网络设备的子命令，可用于管理网络接口的各种属性。其常用子命令如下 ip link set ip link set [dev] NAME options 作用: 更改网络接口属性 [dev] NAME:指明要管理的设备，dev关键字可省略 参数： up|down：，up 表示启用，down 表示关闭； multicast on|off：启用或禁用多播功能； name NAME：重命名接口 mtu NUMBER：设置MTU的大小，以太网默认为1500； netns PID：ns为namespace，用于将接口移动到指定的网络名称空间 ip link set eth1 down ip link set multicast on ip link show # 改名 ip link set eno1 down ip link set name eno8888 ip link set eno8888 up ip link show|list ip link show|list options 作用: 显示网络接口属性 参数: [dev] NAME：指明要显示的接口，dev关键字可省略； up: 仅仅显示启用状态的接口设备 ip link help ip link help 作用: 显示 ip link 简要使用帮助 ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:1","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.2 ip netns ip netns：manage network namespaces. 用于管理网络命名空间。网络命名空间在虚拟化中具有重要作用，我们会在虚拟化重新介绍 ip netns 的使用，此处仅作了解即可 ip netns COMMAND: ip netns list：列出所有的netns ip netns add NAME：创建指定的netns ip netns del NAME：删除指定的netns ip netns exec NAME IP_COMMAND 作用: 在指定的netns中运行命令 NAME: 表示指定的命名空间 IP_COMMAND: 任何可使用的 ip 命令 ip netns help ip netns add mynet ip link set eno1 netns mynet # 将 eno1 添加到 mynet 名称空间中 ip link show ip netns exec mynet ip link show # 显示 mynet 中的网络设备 ip netns del mynet ip link show ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:2","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.3 ip address ip address:protocol address management. 用于管理网络地址，作用类似于 ifconfig 命令 ip addr add ip addr add IP dev IFACE IFADDR 作用: 为网络接口添加 IP 地址 参数: IP: ip/netmask dev IFACE: 指定网络接口 IFADDR: 为地址的添加的额外属性 label NAME：为额外添加的地址指明接口别名； broadcast ADDRESS：广播地址；会根据IP和NETMASK自动计算得到，一般无需指明 scope SCOPE_VALUE：指明网络接口的作用域了解即可 global：全局可用； link：接口可用； host：仅本机可用； ifconfig eth1 0 # 一个网卡可添加多个地址 ip addr add 192.168.1.101/24 dev eth1 ip addr add 192.168.100.100/24 dev eth1 label eth1:0 # 指定接口别名 ip addr delete ip addr add IP dev IFACE 作用: 删除网络接口的 IP 地址，delete 可简写成 del 参数: IP: 指明要删除的 ip/netmask dev IFACE: 指定网络接口 ip addr del 192.168.1.101/24 dev eth1 ip addr show ip addr show|list options 作用: 显示网络接口地址详细信息 选项: [dev] IFACE: 显示特定接口的地址，默认显示所有接口 label PATTERN: 显示指定模式别名的接口 ip addr flush ip addr flush dev IFACE options 作用: 清空网络设备的IP地址，不支持简写 选项: label PATTERN: 删除指定模式别名的接口 ip addr flush dev eth1 ip addr show eth1 ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:3","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1.4 ip route ip route routing table management，路由表管理 ip route add ip route {add|change|replace} TARGET via GW options 作用: add,change,replace 使用方式类似 add: 添加路由条目，可根据路由信息自动判断是主机路由还是网络路由 change: 更改路由 replace: 更改或添加路由 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK via GW: 网关或路由的下一跳 选项: dev IFACE: 指明从哪个网络接口发送报文 src SOURCE_IP: dev 指明的网卡存在多个地址时，指定出口IP ip addr add 10.0.0.100/8 dev eth1 ip addr add 10.0.20.100/8 dev eth1 ip route add 192.168.0.0/24 via 10.0.0.1 dev eth1 src 10.0.20.100 ip route add default via 192.168.1.1` ip route delete ip route delete TARGET [via GW] 作用: 删除路由条目 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK [via GW]: 如果 TARGET 能唯一指明路由条目则无需指明网管 eg: ip route del 192.168.1.0/24 ip route show ip route show options 作用: 查看路由条目 选项: TARGET: 显示特定路由条目 [dev] IFACE: 查看特定网卡的路由条目 via PREFIX: 查看特定网关的路由条目 ip route flush ip route flush options 作用: 清空路由条目 选项: prefix/mask: 删除特定前缀的路由条目 [dev] IFACE: 查看网卡的路由条目 via PREFIX: 删除特定网关的路由 ip route flush 10/8 # 删除前缀为 10，掩码为 8 位的条目 ip route flush 192/8 # 指定的 192/8 无法删除 192/24 的路由条目 ip route get ip route get TARGET [via GW] 作用: 获取一条特定的路由信息 ip route get 192.168.0.0/24 ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:4","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. ss命令： ss [options] [ FILTER ] 作用：类似于 netstat，用于查看网络连接状态 类 netstat 选项： -t：TCP协议的相关连接 -u：UDP相关的连接 -w：raw socket相关的连接 -x：unix socket 相关 -l：监听状态的连接 -a：所有状态的连接 -n：数字格式 -p：相关的程序及其PID -e：扩展格式信息 特有选项: -m：内存用量 -o：计时器信息 FILTER: ss 用于筛选的表达式 格式: [ state TCP-STATE ] [ EXPRESSION ] TCP-STATE： LISTEN：监听 ESTABLISEHD：建立的连接 FIN_WAIT_1： FIN_WAIT_2： SYN_SENT： SYN_RECV： CLOSED： EXPRESSION： dport = 目标端口号 sport = 源端口号 eg：'( dport = :22 or sport = :22 )' - 每个部分都必须有空格隔开 ss -tan '( dport = :22 or sport = :22 )' ss -tan state ESTABLISHED ","date":"2018-02-10","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"11.4 网络属性配置之 ip 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"11.3 网络属性配置之 ifcfg 系列命令","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"网络属性配置之 ifcfg 系列命令 本节我们来介绍 Linux 网络属性配置的第一组系列命令 ifcfg。ifcfg 系列是 Linux 中很古老的命令，几乎存在于所有的Linux 发行版中。ifcfg 系列包括如下几个命令: ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 ifup/ifdown: 启动/关闭接口 ","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. ifconfig ifconfig 的配置会立即送往内核中的TCP/IP协议栈，并生效 查看接口状态 ifconfig：默认显示活跃状态的接口 ifconfig IFACE [up|down]：后跟网络接口名，显示特定接口，up 表示激活接口，down 表示关闭接口 ifconfig -a：显示所有接口，包括inactive状态的接口； 设置接口地址 ifconfig IFACE {address [netmask NETMASK]} options ifconfig IFACE IP/MASK ifconfig IFACE IP netmask NETMASK options： up： 激活接口。如果给接口声明了地址，等于隐含声明了这个选项 down: 关闭此接口 [-]promisc: 启用混杂模式，减号表示禁用 add addr/prefixlen：添加 IPV6 地址 del addr/prefixlen：删除 IPV6 地址 ifconfig eth0 192.168.100.6/24 up ifconfig eth0 192.168.100.6 netmask 255.255.255.0 ","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2 route 路由表中的路由条目有三种类型，范围越小优先级越高: 主机路由：目标地址为单个IP； 网络路由：目标地址为IP网络； 默认路由：目标为任意网络，0.0.0.0/0.0.0.0 路由查看 route -n -n: 以数字形式显示主机名，默认会反解主机名 添加路由 route add [-net|-host] target [netmask Nm] [gw GW] [[dev] If] -net: 指定网络路由 -host: 指定主机路由 netmask: 指定掩码, 默认为 255.255.255.255 gw: 指定路由的下一跳 dev: 指定发送数据包的网卡 示例： route add -host 192.168.100.6 gw 192.168.0.1 dev eth0 route add -net 10.0.0.0/8 gw 192.168.10.1 dev eth1 route add -net 10.0.0.0 netmask 255.0.0.0 gw 192.168.10.1 dev eth1 route add -net 0.0.0.0/0.0.0.0 gw 192.168.10.1 route add default gw 192.168.10.1 -- 添加默认路由 route add -net 0.0.0.0 netmask 0.0.0.0 gw 192.168.10.1 -- 添加默认路由 删除路由 route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If] 示例： route del -host 192.168.100.6 gw 192.168.0.1 route del -net 10.0.0.0/8 gw 192.168.10.1 route del default ","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. netstat netstat can print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 显示路由表 netstat -rn -r：显示内核路由表 -n：以数字形式显示主机名，默认会反解主机名 显示网络连接 netstat [options] 选项: -t, --tcp：显示TCP协议的相关连接，及其链接状态； -u, --udp：显示UDP相关的连接 -U, --udplite：显示udplite 相关的链接 -S, --sctp：显示 sctp 相关的链接 -w, --raw：显示raw socket相关的连接,指不经过传输层，由应用层直接通过 ip 进行的链接 -l, --listening：显示处于监听状态的连接 -a, --all：显示所有状态 -n, --numeric：以数字格式显示IP和Port； -e, --extend：以扩展格式显示 -p, --program：显示相关的进程及PID； 显示接口的统计数据 netstat {--interfaces|-I|-i} [options] 选项: -I, --interfaces\u003ciface\u003e: 指定显示的接口 eg: netstat -Ietho -i: 显示所有活跃接口 -a, --all: 与 -i 同时使用显示所有接口，包括未激活的 -e, --extend: 以扩展格式进行显示 ","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. ifup/ifdown ifup|ifdown iface 作用: 启用或关闭接口 注意: 这两个命令是通过配置文件/etc/sysconfig/network-scripts/ifcfg-IFACE来识别接口并完成配置的；如果设备没有对应的配置文件，则无法通过这两个命令启动或关闭 ","date":"2018-02-09","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/:3:1","tags":["马哥 Linux"],"title":"11.3 网络属性配置之 ifcfg 系列命令","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/ifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"11.2 网络接口命名与配置指南","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"网络接口命名与配置指南 上一节我们讲解了网络的基础知识，很推荐大家读一读计算机网络-自顶向下方法。本节我们会介绍 Linux 中网络接口(网卡)的命名方式，以及概括性的说一说 Linux 中进行网络配置的方式；在接下来的章节中，我们会详细讲解每个命令的使用。本节内容如下: 网络配置方式 Linxu 网络接口的命名方式 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:0:0","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"1. 网络配置方式 将一台 Linux 主机接入到网络中，需要为其配置如下几个参数 IP/NETMASK：本地通信 路由（网关）：跨网络通信 DNS服务器地址：基于主机名的通信 这些参数的配置可以通过命令直接修改内核中的网络参数，也可以修改配置文件然后让内核重载配置文件或下次重新启动生效；也可以依赖本地局域网中配置的 DHCP 服务，为局域网中的其他主机动态配置。DHCP(Dynamic Host Configure Procotol) 服务的配置我们会在后面的章节中介绍。Linux 中配置网络属性的命令和相关配置文件如下 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:1:0","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"1.1 网络属性管理 网络属性配置的配置文件不同的发行版有所不同，RedHat及相关发行版的配置文件位于 /etc/sysconfig/network-scripts/ifcfg-NETCARD_NAME，其中 NETCARD_NAME 为特定网络接口的名称。网络属性管理有众多命令家族，概述如下: ifcfg家族： ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 iproute2家族： ip OBJECT：ip 命令下有众多子命令 addr：管理和查看地址和掩码； link：网络接口属性管理 route：路由查看与管理 ss：网络状态及统计数据查看 CentOS 7特有的 nm(Network Manager)家族 nmcli：nm 命令行工具 nmtui：text window 工具 Centos6 特有的: system-config-network-tui setup, setup 拥有专属的配置文件 system-config-netword-tui ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:1:1","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"1.2 DNS服务 DNS 服务配置 DNS 服务只能通过修改其配置文件 /etc/resolv.conf 进行配置。Linux 主机最多可指定三个 DNS 服务器 # vim /etc/resolv.conf nameserver 10.143.22.116 # 主DNS服务器地址 nameserver 10.143.22.118 # 备用DNS服务器地址 nameserver 10.143.22.116 # 第三备份DNS服务器地址 DNS 服务测试 测试 DNS 服务是否正常，可以使用 host, nslookup, dig 三个命令 正解: FQDN(域名)到 IP dig -t A FQDN host -t A FQND 反解: IP 到 FQDN dig -x IP host -t PTR IP DNS 是互联网的基础服务，我们会花一整章节，来详细介绍 DNS 服务。 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:1:2","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"1.3 本地主机名配置 主机名有三种配置方式 hostname, hostnamectl 和修改配置文件 hostname 查看：hostname 配置：hostname HOSTNAME 效力：只对当前系统有效，重启后无效； hostnamectl Centos7 新增的特有命令 hostnamectl status：显示当前主机名信息； hostnamectl set-hostname：设定主机名，永久有效； 效力: 通过 hostnamectl 修改的主机名立即生效，且永久有效 修改配置文件 主机名的配置文件位于 /etc/sysconfig/network 效力：此方法的设置不会立即生效； 但以后会一直有效； # vim /etc/sysconfig/network HOSTNAME=\"hostname\" ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:1:3","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"3. 网络接口命名方式 网络接口(网卡)的命名在Linux 中有特定设置过程。默认情况下，Centos6 采用传统的命名机制，Centos7 采用可预测命名方案，支持多种不同的命名机制，这种命名机制需要 biosdevname 程序的参与 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:2:0","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"3.1 命名机制 Centos6 传统命名： 以太网：ethX, [0,oo)，例如eth0, eth1, … PPP网络：pppX, [0,...], 例如，ppp0, ppp1, … CentOS7 可预测命名方案：支持多种不同的命名机制 如果Firmware(固件)或BIOS为主板上集成的设备提供的索引信息可用，则根据此索引进行命名，如eno1, eno2, … 如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名，如ens1, ens2, … 如果硬件接口的物理位置信息可用(硬件接口的拓扑结构)，则根据此信息命名，如enp2s0, … 如果用户显式定义根据MAC地址命名，例如enx122161ab2e10, … 上述均不可用，则仍使用传统方式命名； ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:2:1","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"3.2 名称组成格式 Centos7 中 eno1，ens1，enp2s0 命名组成如下所示: 前缀 en：ethernet 以太网接口 wl：wlan 无线局域网设备 ww：wwan 无线广域网设备 后缀 o\u003cindex\u003e: 集成设备的设备索引号；(onbus) s\u003cslot\u003e: 扩展槽的索引号； x: 基于MAC地址的命名； p\u003cbus\u003es\u003cslot\u003e: 基于总线及槽的拓扑结构进行命名； bus: PCI 总线编号 slot: 总线上的扩展槽编号 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:2:2","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"3.3 网卡设备的命名过程 Centos7 网卡命名经过了以下过程: udev 辅助工具程序 /lib/udev/rename_device 会根据 /usr/lib/udev/rules.d/60-net.rules 中的指示去查询 /etc/sysconfig/network-script/ifcfg-IFACE 配置文件，根据HWADDR 读取设备名称 biosdevname 根据 /user/lib/udev/rules.d/71-boosdevname.rules 通过检查网络接口设备，根据 /usr/lib/udev/rules.d/75-net-description 中 ID_NET_NAME_ONBOARD 和 ID_NET_NAME_SLOT,ID_NET_NAME_PATH 命名 Centos7 也可以设置网络接口回归传统方式的命名方式: vim /etc/default/grub 配置文件，添加 GRUB_CMDLINE_LINUX=\"net.ifnames=0 rhgb quiet\" 为 grub2 生成配置文件 grub2-mkconfig -o /etc/grub2.cfg 重启系统 ","date":"2018-02-08","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/:2:3","tags":["马哥 Linux"],"title":"11.2 网络接口命名与配置指南","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/"},{"categories":["Linux"],"content":"11.1 计算机网络基础知识","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"程序包编译安装 本章我们开始学习 Linux 网络配置相关知识。计算机网络包含了众多协议和基础设施，大学里一般都有专门的课程来讲解。本章主要还是对网络配置相关命令讲解，对于计算机网络的基础知识，在一章里肯定没法说清道明。不过有几本书推荐给大家，可以作为深入学习的参考资料。计算机网络-自顶向下方法 五星推荐，对计算机网络的整体架构，基础设施，大多数协议都作了详细概述，通俗易懂。TCP/IP详解 这一系列分成了三卷，对 TCP/IP 协议栈原理作了深入讲解。自己还没读过，大神都是力荐。本章将包含以下内容: 网络基础知识 Linux 网络配置的相关命令 ifcfg 系列命令 ip 系列命令 Centos7 特有的 nmcli 命令 网络配置的配置文件 网络客户端工具 本节先来简单说一说网络相关的基础知识。由于网络知识庞大繁杂，此篇文章将会持续更新，希望能以通俗易懂的方式让大家对网络有个基础的认识。 计算机网络协议是一个网络协议栈，目的是将计算机主机之间通信这一复杂问题划分为多个层次，每个层次通过协议进行规范，向上层输出标准 api。一来通过分层降低解决问题的难度，二来特定层次可以有不同的实现，可以变动改进，只要遵守即定的协议，就不会影响到起他层次的使用，提供了最大程度的灵活性。我们学习网络知识，就是要学习计算机网络的层次，每个层次面对的问题，怎么解决问题，涉及到的协议和基础设施；最后对整个网络有个整体性的认识。本节将按照这样的顺序，对计算机网络做一个简述，包括: 计算机网络的分层 计算机网络协议栈 ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:0:0","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"1. 计算机网络的分层 我们的数据都是以二进制的格式存放在磁盘上的，至于它是文本，还是视频取决于二进制数据的组织形式。因此我们在通过网络传输数据时，数据仍是以二进制的形式进行传输，只是不同的传输介质表示二进制的方式不同。比如以太网使用高电压表示 1，低电压表示 0。最终数据传输完成后仍然需要按照特定的组织方式还原数据。 因此从宏观上来看，计算机网络被分成两个层次，通信子网和资源子网。通信子网关注的是如何传输数据，资源子网则只关心数据是如何组织起来的。资源子网不必关心通信子网是如何实现的，只调用其提供的标准接口。因此整个过程有点类似于现实世界中寄快递，快递公司帮我们运输物品，我们不必关心快递公司是如何运输，但是我们必需确保我们物品没有损坏，也可以按需选择不同的快递公司。通过这样的分层我们将一个复杂问题分隔成一个个独立的子问题。 资源子网通常由各个应用程序提供，比如我们常用的 httpd，位于操作系统的用户空间中，通信子网由操作系统内核实现，通过套接子 socket，向用户空间的应用程序提供标准接口。 -------------------- 用户空间 \u003c--- | | ---\u003e 资源子网 |-------------------| 内核空间 \u003c--- | | ---\u003e 通信子网 |-------------------| ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:1:0","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"2. 计算机网络协议栈 计算机网络协议栈目前有两个标准: TCP/IP 协议栈，这是当前事实上的使用标准，在实际生产环境中逐步演化而来，缺点是每个网络层次之间的接口定义并不是非常明确 OSI 协议栈，这是 ISO 组织对 TCP/IP 作出改进之后的版本，各个网络层次之间界限明确，但是各个层次之间功能有所重复，并没有TCP/IP效率高。正因为其定义规范且明确，这是一个我们更容易学习的版本 上图就是两个协议栈的对比示意图，每个层次的作用概述如下: 通信子网: 物理层: 定义传输介质及介质之间的传输协议，比如电压等(网卡标准定义) 数据链路层: 定义局域网内主机之间的通信，比如传输速度等 网络层: 定义网络与网络之间的通信 传输层: 定义进程与进程之间的通信 资源子网: 5. 应用层: - 会话层 - 表示层 - 应用层 ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:0","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"2.1 物理层 设备：网桥或交换机 寻址：MAC 地址 Media Access Control 48bits，前 24bits 由 ICANN 分配 ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:1","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"2.2 网络层 设备：路由器 寻址：IP 地址 Internet protocol, 由网络号+主机号组成 IPv4：32bits 8bits.8bits.8bits.8bit ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:2","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"2.3 传输层 寻址：IP 地址 + 端口 端口号:16bits 1-1023：固定分配，而且只有管理员有权限启用； 1024-4W：半固定， 4W+：临时 ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:3","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"2.4 数据的传输过程 MAC：本地通信；范围：本地局域网； IP：界定通信主机，源和目标；范围：互联网； Port：界定进程；范围：主机 ； ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:4","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"3. IP地址分类 IP 地址用于标识网络及网络中的主机，按照用于表示网络的字节数将 IP 地址分为 ABCDE 五大类: A类： 第一段为网络号，后三段为主机号 网络号：0 000 0000 - 0 111 1111：1-127 网络数量：126，127 每个网络中的主机数量：2^24-2 默认子网掩码：255.0.0.0，/8 私网地址：10.0.0.0/8 B类： 前两段为网络号，后两段为主机号 网络号：10 00 0000 - 10 11 1111：128-191 网络数：2^14 每个网络中的主机数量：2^16-2 默认子网掩码：255.255.0.0，/16 私网地址：172.16.0.0/16-172.31.0.0/16 C类： 前三段为网络号，最后一段为主机号 网络号：110 0 0000 - 110 1 1111：192-223 网络数：2^21 每个网络中的主机数量：2^8-2 默认子网掩码：255.255.255.0, /24 私网地址: 192.168.0.0/24-192.168.255.0/24 D类：组播 网络号: 1110 0000 - 1110 1111：224-239 E类：科研 网络号: 1111 0000 - 1111 1111: 240-255 ","date":"2018-02-07","objectID":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/:2:5","tags":["马哥 Linux"],"title":"11.1 计算机网络基础知识","uri":"/posts/linux/linux_mt/12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8Alinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"},{"categories":["Linux"],"content":"10.4 程序包编译安装","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"程序包编译安装 前面我们讲解了使用 rpm，yum 安装程序包的方法，相比于编译安装，它们更加便捷，但是由于 rpm 包是编译好的二进制程序，我们就无法根据自己的需求去定制程序特性和功能。所有如果想定制程序，则必需编译安装，在编译时启用需要的特性。本节我们首先会说一说编译安装的过程，然后再来介绍如何在 Linux 中实现编译安装 C/++ 程序。本节内容概括如下: 程序的编译安装过程 如何获取源代码 编译安装C源代码 ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:0:0","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1. 程序的编译安装过程 如上图所示，C 程序的编译要经过 源代码 --\u003e 预处理 --\u003e 编译(gcc) --\u003e 汇编 --\u003e 链接 四步 预处理: 处理注释，宏替换，头文件 编译: 将预处理之后的源代码编译成汇编代码 汇编: 将汇编代码编译成二进制机器代码 链接: 如果程序用到了其他 C 库的代码，则需要将这部分代码动态链接至二进制机器代码中 上述就是一个简单 C 程序编译过程的概述，如果想了解更多细节，可查阅其他资料。 我们知道现在的大型软件工程都不太可能由一个人完成，同时为了程序的可维护性和扩展性，通常都会将代码放置在多个文件中，文件中的代码之间，很可能存在跨文件依赖关系。因此在编译 C 过程中，必需按照特定的顺序编译才能编译成功。为了辅助程序的编译，因此出现了很多项目管理工具。make,cmake 则时 C 和 C++ 中最常见的项目管理工具。 make 工具的配置文件 makefile 记录了程序编译的详细过程，make 工具根据 makefile 的配置可以自动完成程序的编译安装。通常在程序包中有两个辅助生成 makefile 的文件 – configure 和 Makefile.ini。Makefile.ini 是 makefile 的模板，configure 是一个脚本文件，有众多选项，能根据用户提供的参数，依据 Makefile.ini 模板动态生成 makefile 文件。因此用户可以借助于 configure 提供的选项定制 makefile 文件，从而定制程序包的编译安装。autoconf 工具可以辅助生成configure脚本，而 automake 则用于辅助生成 Makefile.in 顺便说一下，rpm 包中有一种类似 testapp-VERSION-release.src.rpm 的以 src.rpm 结尾的 rpm 源码包，其内部的代码是未编译的，需要使用rpmbuild命令制作成二进制格式的rpm包，而后才能安装，在 rpmbuild 过程中，用户就可以自定义程序的特性和功能。 ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:1:0","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.2 C代码编译安装三步骤 根据上述的编译过程阐述， C 代码编译安装大体需要如下三个步骤: ： 通过选项传递参数，指定启用特性、安装路径等；执行时会参考用户的指定以及Makefile.in文件生成makefile； 检查依赖到的外部环境； make：根据makefile文件，构建应用程序； make install: 脚本，将构建的应用程序放置到配置的目录中 附注: 安装前建议查看INSTALL，README ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:1:1","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"1.3 configure 可用选项 ./configure [options] 的众多选项可以分为如下几类 –help: 获取其支持使用的选项 安装路径设定： --prefix=/PATH/TO/SOMEWHERE: 指定默认安装位置；默认为/usr/local/ `–sysconfdir=``/PATH/TO/SOMEWHERE：配置文件安装位置； System types: 指定目标平台系统结构 Optional Features: 可选特性 --disable-FEATURE: 关闭特性 --enable-FEATURE[=ARG]: 启用特性 Optional Packages: 可选包 --with-PACKAGE[=ARG] --without-PACKAGE ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:1:2","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"2. 开源程序源代码的获取 常见的源代码有如下几个获取途径 官方自建站点： apache.org (ASF) mariadb.org 代码托管： SourceForge Github.com code.google.com ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:2:0","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"3. 编译安装C源代码 完整的编译安装过程还包括安装前的环境准备以及安装后的配置操作，C源代码完整的安装过程如下 提供开发工具及开发环境，通常包含在开发工具的包组中 开发工具包括：make, gcc等 开发环境包括：开发库，头文件, glibc(C 标准库) 开发工具安装: CentOS6: yum groupinstall \"Development Tools\" \"Server Platform Development\" Centos7: yum groupinstall \"Development Tools\" 执行 configure脚本，指定安装位置、指定启用的特性 执行 make make install 安装后的配置： 导出二进制程序目录至PATH环境变量中； 编辑文件/etc/profile.d/NAME.sh，export PATH=/PATH/TO/BIN:$PATH 导出库文件路径： 编辑/etc/ld.so.conf.d/NAME.conf ，添加新的库文件所在目录至此文件中； 让系统重新生成库文件缓存：ldconfig [-v] 导出头文件 基于链接的方式实现：ln -sv /path/include /usr/include/dir 导出帮助手册 编辑/etc/man.config文件，添加一个MANPATH ","date":"2018-02-06","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/:3:0","tags":["马哥 Linux"],"title":"10.4 程序包编译安装","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/"},{"categories":["Linux"],"content":"10.3 yum命令使用","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"yum命令使用 yum 是 rpm 的前端工具，在 rpm 基础上能自动解决程序包的依赖问题，管理程序更加的方便。本节我们就来介绍 yum 的使用，包括以下内容: yum 的架构示意图 yum 仓库指向定义 yum 命令的使用 yum 仓库管理 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. yum 概述 上图是 yum 架构的示意图，yum 是 C/S 架构的服务。yum 的 Serve 端就是一个文件服务器，称为 yum 仓库或 yum 源。yum 仓库包含了众多 rpm 包以及包相关的元数据文件。元数据放置在 repodata 目录，其中包含了包之间的依赖关系。 客户端在请求安装某 rpm 包时，首先会下载元数据到本地并缓存，然后分析包之间的依赖关系，分析完成后向 yum 仓库请求下载该 rpm 包及其缺失的依赖包并安装。 通常 rpm 包安装之后就会被删除，但元数据可以重复使用，因此 yum 客户端会在本地缓存yum 仓库的元数据。但缓存有可能失效，因此为及时发现 yum 仓库的变化，yum 仓库会生成元数据的特征码(单向加密算法提取的指纹信息)。yum 客户端在每次请求时首先下载特征码与本地缓存的特征码进行比对，如果不相同说明 yum 仓库发生变动，则重新下载元数据。 yum 的服务器端和客户端具有如下特征 yum Server yum 服务器端就是一个文件服务器，支持 ftp://，http://，nfs://，file:// 四种协议， file:// 表示本地文件系统 yum 仓库存储了众多rpm包，以及包的相关的元数据文件，元数据放置于 repodata 中 yum 客户端 yum 客户端即我们通常使用的 yum 命令 yum 的配置文件 /etc/yum.conf /etc/yum.repo.d/*.conf 用于配置 yum 源的指向 yum 仓库中包含 repodata 目录的路径，就是 yum 源应该指向的路径 接下来，我们就来逐一讲解 yum 的配置文件，yum 命令的使用以及如何创建 yum 仓库 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 yum 的配置文件 yum 的核心配置文件包括两个部分: /etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 可以使用 whatis/man yum.conf 获取配置文件的帮助信息，yum 仓库配置的常用选项如下所示 [repositoryID] # yum 源的唯一标识 ID name=Some name for this repository # yum 源的名称 baseurl=url://path/to/repository/ # yum 源的地址，可多个 url enabled={1|0} # 是否启用，默认为 1 启用 gpgcheck={1|0} # 包来对源合法性进行检验 gpgkey=URL # 秘钥文件位置 enablegroups={1|0} # 是否在此仓库上支持组 failovermethod={roundrobin|priority} # baseurl 指向多个时，失败后如何选择下一个连接 # 默认为：roundrobin，意为随机挑选；priority 表示从上至下顺序选取 cost=1000 # yum 源的开销，指定仓库优先级，开销越大，优先级越低 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 配置文件中的可用变量 yum 源的配置文件中有一些可用变量，可以方便根据当前平台特性，选择特定的 yum 源。常用变量包括 变量名称 作用 $releasever 当前OS的发行版的主版本号，即 centos-release 这个 rpm 包的 Version值 通过 rpm -qi centos-release 可查看 $arch 平台，比如 i386，x86, x86_64，通过 arch 命令可查看当前值 $basearch 基础平台，平台分类中的大类，比如 i386，i568，x86都属于 i386 $YUM0-$YUM9 用户可自定义使用的变量 # 阿里云 yum 配置示例 [base] name=CentOS-$releasever - Base - mirrors.aliyun.com failovermethod=priority baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/ #mirrorlist=http://mirrorlist.centos.org/?release=$releasever\u0026arch=$basearch\u0026repo=os gpgcheck=1 gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7 # 附注: 我的Linux 上 baseurl=http://mirrors.aliyun.com/centos/7/os/x86_64/ ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:2","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. yum 命令 yum 命令有众多子命令，大体上可以分为两个部分 用于安装，卸载，查看，搜索程序包和程序包组 yum 缓存，事务，历史等管理子命令 yum [options] [command] [package ...] 通用选项: --nogpgcheck：禁止进行gpg check； -y: 自动回答为“yes”； -q：静默模式； --disablerepo=repoidglob：临时禁用此处指定的repo； --enablerepo=repoidglob：临时启用此处指定的repo； --noplugins：禁用所有插件 子命令： 程序包管理子命令 install reinstall update update-to downgrade check-update upgrade upgrade-to remove|erase deplist list info search provides | whatprovides 程序包组管理子命令 groupinstall groupupdate grouplist groupremove groupinfo yum 管理子命令 clean makecache repolist version history help ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.1 程序包管理子命令 安装 yum install package1 [...]: 安装程序包 yum reinstall package1 [...]: 重新安装程序包 升级 yum update [package1] [...]: 升级程序包 yum downgrade package1 [...]: 降级安装程序包 yum check-update: 检查可用升级 卸载 yum remove | erase package1 [package2] [...] 作用: 卸载程序包 附注: 依赖被卸载的包的包也会被卸载 查询 yum search string1 [...]: 查找程序包，会以指定的关键字搜索程序包名及summary信息； yum info [package1]: 查看特定程序包相关信息 yum deplist package1 [...]: 查看指定包所依赖的特性(capabilities) yum provides | whatprovides feature1 [...] 作用: 查看指定的特性(可以是某文件)是由哪个程序包所提供 yum list [all | glob_exp1] [glob_exp2] [...] yum list {available|installed|updates} [glob_exp1] [...] 作用: 查找程序包，支持通配符，只会匹配程序包名称 选项: all: 列出所有包 available: 列出所有可用的包 installed: 列出所有已经安装的包 updates: 列出所有可更新的包 eg: yum list php* 搜索所有以 php 开头的包 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.2 程序包组管理的相关命令 yum groupinstall group1 [group2] [...]: 安装 yum groupupdate group1 [group2] [...]: 升级 yum groupremove group1 [group2] [...]: 卸载 yum grouplist [hidden] [groupwildcard] [...]: 查看所有可用包组 yum groupinfo group1 [...]: 查看特定包组相关信息 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2.3 yum 管理命令 缓存 yum clean [packages | metadata | expire-cache | rpmdb | plugins | all] 作用: 清理本地缓存 选项: 通过参数，可只清除特定内容 yum makecache 作用: 构建缓存 事务历史 yum history [PARAM] 作用: 查看yum事务历史 参数: [info|list|packages-list|packages-info|summary|redo|undo|rollback|new|sync|stats] 显示仓库列表 yum repolist [all|enabled|disabled] 作用: 显示仓库列表 参数: all: 显示所有仓库 enabled: 显示启用的仓库 disabled: 显示禁用的仓库 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:3","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3. yum 仓库管理 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.1 使用光盘当作本地yum仓库 使用光盘当作本地yum仓库的操作步骤如下: 挂载光盘至某目录，例如/media/cdrom mount -r -t iso9660 /dev/cdrom /media/cdrom 创建配置文件 [CentOS7] name= baseurl=file:////media/cdrom gpgcheck= enabled= ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:1","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.2 创建 yum 仓库 createrepo [options] \u003cdirectory\u003e 作用: 创建 yum 仓库所需的 repodata 目录 选项: -u --baseurl \u003curl\u003e：指定Base URL的地址 -o --outputdir \u003curl\u003e: 指定元数据的输出位置 -x --excludes \u003cpackages\u003e: 指定在形成元数据时需要排除的包 -q --quiet: 安静模式执行操作，不输出任何信息。 -g --groupfile \u003cgroupfile\u003e 作用: 指定本地软件仓库的组划分，范例如下： 注意：组文件需要和rpm包放置于同一路径下 eg: createrepo -g comps.xml /path/to/rpms -v --verbose: 输出详细信息 -c --cachedir \u003cpath\u003e 作用: 指定一个目录，用作存放软件仓库中软件包的校验和信息。 附注: 当createrepo在未发生明显改变的相同仓库文件上持续多次运行时，指定cachedir会明显提高其性能。 -d --database: 该选项指定使用SQLite来存储生成的元数据，默认项。 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:2","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3.3 yum 的使用奇巧 当我们安装一个不在 yum 仓库的本地 rpm 包时，可使用 yum install local_rpm.rpm 安装，如果次包依赖到 yum 仓库中的其他 rpm 包将自动解决依赖关系。 当我们安装一堆不再 yum 仓库的 rpm 包，且这些 rpm 包本身也存在依赖关系时，可将这些 rpm 包制作成一个本地yum 仓库，这样就可以使用 yum 自动解决所有的依赖关系。 ","date":"2018-02-05","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:3","tags":["马哥 Linux"],"title":"10.3 yum命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/yum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"10.2 软件包管理rpm命令使用","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"软件包管理rpm命令使用 本节我们主要来讲解 rpm 命令的使用。rpm 可实现程序的安装、卸载和升级。但相比于程序的管理，rpm 的查询命令能帮助我们快速找到文件或二进制程序所属的程序包，及程序包的配置文件等信息，反而更加重要。由于程序之间存在依赖关系，而 rpm 不能自动帮我们解决程序的依赖问题，因此在程序的管理更加常用的命令是 rpm 的前端管理工具 yum。yum 能自动帮我们解决程序的依赖问题，我们会在下个章节介绍 yum 的使用。 ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:0:0","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1. CentOS rpm rpm 提供了应用程序的安装、升级、卸载、查询、校验和数据库维护，其使用方式如下。我们会分段讲解各个命令的使用 rpm [OPTIONS] [PACKAGE_FILE] 子命令选项: 安装：-i, --install 升级：-U, --update, -F, --freshen 卸载：-e, --erase 查询：-q, --query 校验：-V, --verify 数据库维护：--builddb, --initdb 通用选项: -v：verbose，详细信息 -vv：更详细的输出 ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:0","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.1 安装 rpm {-i|--install} [install-options] PACKAGE_FILE ... [install-options]： -h：hash marks输出进度条；每个#表示2%的进度； --test：测试安装，检查并报告依赖关系及冲突消息等； --nodeps：忽略依赖关系；不建议； --replacepkgs：重新安装 --nosignature：不检查包签名信息，不检查来源合法性； --nodigest：不检查包完整性信息； --noscripts: 不执行程序包脚本片段，包括以下四种类型的脚本 注意：rpm可以自带脚本，包括四类： preinstall：安装过程开始之前运行的脚本，%pre ， --nopre 可禁止执行此类脚本 postinstall：安装过程完成之后运行的脚本，%post , --nopost 可禁止执行此类脚本 preuninstall：卸载过程真正开始执行之前运行的脚本，%preun, --nopreun 可禁止执行此类脚本 postuninstall：卸载过程完成之后运行的脚本，%postun , --nopostun 可禁止执行此类脚本 ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:1","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.2 升级： rpm {-U|--upgrade} [install-options] PACKAGE_FILE ... rpm {-F|--freshen} [install-options] PACKAGE_FILE ... rpm -Uvh PACKAGE_FILE ... rpm -Fvh PACKAGE_FILE ... -U：升级或安装； -F：升级，不存在旧版程序，不执行任何操作 --oldpackage：降级； --force：强制升级； [install-options]: 所有安装时可用选项，升级亦可用 注意： 不要对内核做升级操作；Linux支持多内核版本并存，因此，直接安装新版本内核； 如果某原程序包的配置文件安装后曾被修改过，升级时，新版本的程序提供的同一个配置文件不会覆盖原有版本的配置文件，而是把新版本的配置文件重命名(FILENAME.rpmnew)后提供； ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:0","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.3 卸载： rpm {-e|--erase} [--allmatches] [--nodeps] [--noscripts] [--test] PACKAGE_NAME ... --allmatches：卸载所有匹配指定名称的程序包的各版本； --nodeps：忽略依赖关系 --test：测试卸载，dry run模式 ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:1","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.4 查询： rpm {-q|--query} [select-options] [query-options] [select-options]: 通过什么查询程序包 PACKAGE_NAME：查询指定的程序包是否已经安装，及其版本； -a, --all：查询所有已经安装过的包； -f FILE：查询指定的文件由哪个程序包安装生成； -g, --group \u003cgroup\u003e: -p, --package PACKAGE_FILE：用于实现对未安装的程序包执行查询操作； --whatprovides CAPABILITY：查询指定的CAPABILITY由哪个程序包提供； --whatrequires CAPABILITY：查询指定的CAPABILITY被哪个包所依赖； [query-options]: 查询包的哪些信息 --changelog：查询rpm包的changlog； -l, --list：程序安装生成的所有文件列表； -i, --info：程序包相关的信息，版本号、大小、所属的包组，等； -c, --configfiles：查询指定的程序包提供的配置文件； -d, --docfiles：查询指定的程序包提供的文档； --provides：列出指定的程序包提供的所有的CAPABILITY； -R, --requires：查询指定的程序包的依赖关系； --scripts：查看程序包自带的脚本片断； 用法： 查询已安装包: -qi PACKAGE, -qf FILE, -qc PACKAGE, -ql PACKAGE, -qd PACKAGE 查询未安装包: -qpi PACKAGE_FILE, -qpl PACKAGE_FILE, -qpc PACKAGE_FILE, … ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:2","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"1.5 校验： rpm {-V|--verify} [select-options] [verify-options] [select-options]: 同 query [verify-options] \u003e vim /usr/share/zsh/5.0.2/functions/tcp_open # 修改了 zsh 包的部分文件 \u003e rpm -V zsh S.5....T. /usr/share/zsh/5.0.2/functions/tcp_open # 检验结果: - S file Size differs - M Mode differs (includes permissions and file type) - 5 digest (formerly MD5 sum) differs - D Device major/minor number mismatch - L readLink(2) path mismatch - U User ownership differs - G Group ownership differs - T mTime differs - P caPabilities differ ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:3","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"2. 包来源合法性验正和完整性验正 网络数据的合法性和完整性验证需要使用到加密技术，在后续的 web 服务章节我们会详细讲解加密算法在数据合法性和完整性上的应用，此处我们简单介绍一下。 加密算法分为对称加密，单向加密和非对称加密三类。 对称加密指的是加密和解密使用的是同一种密钥 单向加密，只要源数据发生微弱变化，加密结果会发生巨大变化，它通常用于提取指纹信息，被用作完整性验证 非对称加密，有公钥和私钥两部分组成，使用私钥加密的数据只能使用公钥解密，反之亦然。如果某人用其私钥加密了某个数据，我们用其私钥能够解密就可以说明数据来自他。 因此在包来源合法性和完整性验证过程中，包的制作者首先使用单向加密获取包的指纹信息，并将其用自己的私钥加密制作成数据签名。由于其公钥所有人都可以获取，包下载者下载包后，使用其公钥解密数字签名，如果能够解密说明包的确来自包制作者。然后在使用同样的单向加密算法，对包进行加密，将加密结果与数字签名内的指纹信息进行比对，如果相同说明包是完整的。 使用 rpm 验证包来源合法性和完整性包括如下两个步骤: 获取并导入信任的包制作者的公钥： rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 对于CentOS发行版来说公钥位于 /etc/pki/rpm-gpg 目录内 验正： 安装此组织签名的程序时，会自动执行验正； 手动验正：rpm -K PACKAGE_FILE ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:0","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"3. rpm 数据库重建 rpm 数据库记录了所有包的基本信息，所属文件，及其所属文件的存放路径等信息。rpm 查询操作都是基于此数据库进行的。rpm 管理器数据库在/var/lib/rpm/ 下。如果数据库出现损坏，可使用 rpm 命令进行修复，修复命令如下 rpm {--initdb|--rebuilddb} [--dbpath DIRECTORY] [--root DIRECTORY] --initdb：初始化数据库，当前无任何数据库可实始化创建一个新的；当前存在数据库时不执行任何操作； --rebuilddb：重新构建，通过读取当前系统上所有已经安装过的程序包进行重新创建；无论当前是否存在，都会重新创建数据库 获取帮助： CentOS 6：man rpm CentOS 7：man rpmdb ","date":"2018-02-04","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:4:0","tags":["马哥 Linux"],"title":"10.2 软件包管理rpm命令使用","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/rpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["Linux"],"content":"10.1 Linux程序包管理介绍","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"Linux程序包管理介绍 本节是 Linux 包管里器的一些背景知识，目的是让大家对为什么会存在包管里器，包管理器本身有个大体上的了解。在这之后我们会详细介绍 Centos 的包管理器 rpm 的使用。本节主要包含以下内容: 为什么会有包管里器 包管理器简介 包管理器的种类 包的命令格式 包依赖关系的解决 包的可能来源 ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:0:0","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. 为什么会有包管里器 大型程序的构建是一件非常复杂的使用，为了方便的程序的管理，我们不可能将几千甚至几万行的代码放在同一个文件中；如果有 C 程序的使用经验就会知道，在编译 C 的过程，如果程序文件存在依赖关闭，则必须按照依赖顺序进行编译，否则无法编译成功。因此出现了 make,cmake 这样的工具用于帮助实现程序的编译。于此同时编译需要特殊环境和工具，编译环境的准备也不是一件容易的事，因此为方便终端用户在 Linux 上安装使用程序出现了包管理器。 所谓包管理器就是预先将程序编译好；然后将其打包成程序包。程序包的安装过程，就是将编译好的目标程序(我们称之为目标二进制格式) 的二进制程序、库文件、配置文件、帮助文件放置到特定目录中即可，rpm 的数据库会记录每个程序的每个文件及其存放位置，因此通过我们也可以通过 程序包管理器轻松实现对程序的升级，卸载和查询。 二进制的 C 程序是与平台相关的，因此只能安装与自身平台架构相同的程序包。需要注意的是程序的特定功能是在程序编译时就确定的，因此为满足不同人对程序功能的定制需求，程序包通常会按照功能进行分包；即通用的功能放在主包中，其他额外的功能放在分包中。 ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:1:0","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2. 程序包管理器 ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:0","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.1 程序包管里器的种类 不同的主流 Linux 发行版为自家开发了特有的包管里器，目前比较流行的有如下几个，Centos主要使用 rpm，我们的介绍也以 rpm 为主 debian：dpt(dpkg), 后缀名为 .deb redhat：rpm(redhat package manager/rpm is package manager),后缀名为 .rpm S.u.S.E：rpm, “.rpm” Gentoo：ports ArchLinux：dnf ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:1","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.1 包命名格式 程序包的命名方式遵循特定的规则，包含了很多信息，通过包名我们大体上就可以判断其是否符合我们需要。rpm 的包名由源代码的名称衍生而来。 源代码名称: name-VERSION.tar.gz VERSION：major.minor.release eg: redis-3.0.2.targz rpm 包名称: name-VERSION-ARCH.rpm eg: redis-3.0.2-1.centos7.x64.rpm VERSION：major.minor.release 源代码包的版本号，此处为 3.0.2 ARCH:release.os.arch rpm包的发行号，此处为 1.centos7.x64 release: rpm 包制作的版本号 os: 操作系统平台 arch: archetecture 硬件架构包括i386, x64(amd64), ppc, noarch 等 由于 rpm 存在拆包的可能，支包的命名方式是在主包的基础上添加了支包的功能说明 主包：name-VERSION-ARCH.rpm 支包：name-function-VERSION-ARCH.rpm，function 可以是 devel, utils, libs, … ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:2","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.2 依赖关系： 包管理不能自动解决程序的依赖关系，因此每个程序包都有与之对应的前端工具，能自动解决安装卸载过程中的依赖关系 yum：rhel系列系统上rpm包管理器的前端工具； apt-get (apt-cache)：deb包管理器的前端工具； zypper：suse的rpm管理器前端工具； dnf：Fedora 22+系统上rpm包管理器的前端工具； ldd ldd /path/binary_file 作用: 查看二进制文件依赖的库文件 ldconfig ldconfig 作用: 管理和查看本机的挂载库文件 -p: 显示本机已经缓存的所有可用库文件及文件路径映射关系 配置文件: /etc/ld.so.conf, /etc/ld.so.conf.d/*.conf 缓存文件: /etc/ld.so.cache ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:3","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.3 程序包的组成 程序包由如下几个部分组成: 程序包的组成清单（每个程序包都单独 实现）； 文件清单 安装或卸载时运行的脚本 数据库（公共） 程序包的名称和版本； 依赖关系； 功能说明； 安装生成的各文件的文件路径及校验码信息； 等等等 /var/lib/rpm/ ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:4","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.4 获取程序包的途径 我们的程序包基本都是从网络上下载获取，因此应该尽量从正规途径下载程序包，防止被植入后门。包下载之后应该尽量对其来源合法性，程序包完整性进行检查，确认没有问题后在使用。可靠的包获取途径如下所示: 系统发行版的光盘或官方的文件服务器（或镜像站点） http://mirrors.aliyun.com, http://mirrors.sohu.com, http://mirrors.163.com 项目的官方站点 第三方组织： EPEL 搜索引擎 http://pkgs.org http://rpmfind.net http://rpm.pbone.net 自动动手，丰衣足食 ","date":"2018-02-03","objectID":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/:2:5","tags":["马哥 Linux"],"title":"10.1 Linux程序包管理介绍","uri":"/posts/linux/linux_mt/11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86/linux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"9.2 任务计划和周期性任务","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"任务计划和周期性任务 Linux 中定时执行的任务有任务计划和周期性任务两种，所谓任务计划即只在未来的某时间点执行一次某任务，周期性任务则是按照特定的时间规律定期执行某任务。本节我们就来讲解Linux 中这两种任务的实现方式。因为计划任务和周期任务的执行结果会通过邮件发送给用户，因此我们首先来简单说一下邮件服务。本节内容如下所示: 本地邮件服务和使用 mailx 收发邮件 任务计划：at 和 batch 周期性任务计划：cron ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:0:0","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"1. 本地邮件服务 上图是一个QQ邮箱用户编写一封邮件，发送给一个163邮箱用户，后者接收邮件并阅读的过程。其中 smtp协议: 属于TCP/IP 上的应用层协议，完成跨网络传输邮件，是邮件服务器之间的传输协议 pop3/imap4: 是客户端与邮件服务器之间的传输协议，定义了用户向服务商查询、分组、移动、编辑等方面的操作规范 POP3是比较老的协议，而IMAP稍微新一点 mailx mailx [-s 'SUBJECT'] username[@hostname] 作用: Mail User Agent, 用户收发邮件的工具程序； 收邮件: 不带参数使用 mailx 会进入命令行交互客户端，可用于接收邮件 发邮件: -s 'SUBJECT': 指定邮件的主题 username[@hostname]: 指定收件人，本地传送无需域名 附注: 默认进入交互式输入环境，填写邮件正文，也可通过输入重定向或管道指定 \u003e mail # 不带参数可进入 mail 的交互模式，可查收邮件 Heirloom Mail version 12.5 7/5/10. Type ? for help. \"/var/spool/mail/tao\": 3 messages 3 new \u003eN 1 root Tue Jul 24 09:59 17/583 N 2 root Tue Jul 24 10:00 18/553 \"hellp\" N 3 root Tue Jul 24 10:00 18/556 \"hellp\" \u0026 1 # \u0026 后输入邮件编号，即可查看邮件内容 \u003e mail -s \"welcome\" tao this is jerry , welcome # 交互式输入邮件内容 . # 空行后接 . 或使用 ctrl+d 表示结束输入 \u003e ls /var/log | mail -s \"subject\" tao # 通过管道输入邮件正文 \u003e mail -s \"subject\" tao \u003c /etc/fstab # 通过输入重定向输入邮件内容 ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:1:0","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"2. 任务计划 ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:2:0","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"2.1 at命令 at [OPTION]... TIME 作用: 在 time 指定的时间运行特定命令，默认会进入交互式命令行，用于输入要执行的命令 选项: -l: 查看作业队列，相当于atq -f /PATH/FROM/SOMEFILE: 从指定文件中读取作业任务，而不用再交互式输入； -d at_id: 删除指定的作业，相当于atrm，后跟任务的 id 号，通过 atq 即可查看； -c: 查看指定作业的具体内容； -q QUEUE: 指明队列, at的作业有队列，用单个字母表示，默认都使用a队列； TIME: HH:MM [YYYY-mm-dd]: 指定具体的时间 noon, midnight, teatime, tomorrow: 使用特定的时间标识 now+num[minutes, hours, days, OR weeks]: 使用相对时间 \u003e at now+2min at\u003e echo \"abc\" at\u003e \u003cEOT\u003e # 按 ctrl+d 表示结束输入 job 3 at Tue Jul 24 19:06:00 2018 \u003e atq 2 Tue Jul 24 19:06:00 2018 a tao 3 Tue Jul 24 19:06:00 2018 a tao ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:2:1","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"2.2 batch命令： batch 会让系统自行选择在系统资源较空闲的时间去执行指定的任务 ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:2:2","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"3. 周期性任务计划：cron ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:3:0","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"3.1 cron 简介 $ rpm -ql cronie /etc/cron.d /etc/cron.d/0hourly /etc/cron.deny /etc/pam.d/crond # 守护进程 /etc/sysconfig/crond /usr/bin/crontab # 辅助工具 /usr/lib/systemd/system/crond.service /usr/sbin/crond 周期性任务计划由 cronie 程序包提供，包括了 crond 守护进程及相关辅助工具。在定义周期性任务之前，首先需要确保crond守护进程(daemon)处于运行状态。centos7 和 centos6 检查服务运行状态的命令如下: # centos7 使用 systemctl 查看服务运行状态 \u003e systemctl status crond.service ● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-07-25 08:59:13 CST; 47min ago Main PID: 1897 (crond) CGroup: /system.slice/crond.service └─1897 /usr/sbin/crond -n # centos6 \u003e service crond status crond is running. 向crond提交作业的方式不同于at，它需要使用专用的配置文件，此文件有固定格式，不建议使用文本编辑器直接编辑此文件；要使用crontab命令。cron任务分为两类： 系统cron任务，主要用于实现系统自身的维护；需要手动编辑 /etc/crontab 文件进行任务配置 用户cron任务，可通过 crontab 命令，进行配置 ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:3:1","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"3.2 系统cron的配置 系统 cron 的配置文件位于 /etc/crontab，其内容如下。 SHELL=/bin/bash # 定义执行命令的 默认 shell PATH=/sbin:/bin:/usr/sbin:/usr/bin # 不同于用户登录后获得的环境，因此，建议命令使用绝对路径，或者自定义PATH环境变量； MAILTO=root # 执行结果邮件发送给MAILTO指定的用户 # For details see man 4 crontabs # Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed 周期性任务定义: 每一行定义一个周期性任务，共7个字段； * * * * * user-name command to be executed * * * * * : 定义周期性时间 user-name : 运行任务的用户身份 command to be executed：要执行的任务 需要特别注意的，cron 周期性任务的执行环境跟用户登陆后的系统环境并不一样，cron 执行时默认的 PATH 为 /sbin:/bin:/usr/sbin:/usr/bin，因此，建议命令使用绝对路径，或者在脚本中自定义PATH环境变量； ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:3:2","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"3.3 用户cron的配置 用户的 cron 配置文件位于 /var/spool/cron/USERNAME 与用户名同名的文件，其配置文件与系统 cron 配置文件类似，唯一的区别是在定义周期性任务时无需指明 user-name，默认是用户自己。建议使用 crontab 命令进行周期性任务的定义，因为其能自动检查语法错误，防止出错。 3.4 cron 中的时间表示法 * * * * * 周期性时间有如下定义方式: 特定值: 给定时间点有效取值范围内的值，day of week和day of month一般不同时使用； *: 给定时间点上有效取值范围内的所有值；表“每..” #,#,#:逗号分隔的离散值 #-#: 短线连接开头和结束的连续取值： */#:在指定时间点上，定义步长,表示每隔多少的意思 注意： 指定的时间点不能被步长整除时，其意义将不复存在； 最小时间单位为“分钟”，想完成“秒”级任务，得需要额外借助于其它机制； # cron 时间定义示例 3 * * * * # 每小时执行一次；每小时的第3分钟； 3 4 * * 5 # 每周执行一次；每周5的4点3分； 5 6 7 * * # 每月执行一次；每月的7号的6点5分； 7 8 9 10 * # 每年执行一次；每年的10月9号8点7分； 9 8 * * 3,7 # 每周三和周日； 0 8,20 * * 3,7 0 9-18 * * 1-5 */5 * * * * # 每5分钟执行一次某任务； ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:3:3","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"3.5 crontab命令 crontab [-u user] [-l | -r | -e] [-i] 作用: 编辑用户 cron 配置文件 选项 -e：编辑任务； -l：列出所有任务； -r：移除所有任务；即删除/var/spool/cron/USERNAME文件； -i：在使用-r选项移除所有任务时提示用户确认； -u user：root用户可为指定用户管理cron任务； 通知：命令运行结果将以以邮件通知给当前用户；想拒收邮件可通过如下方式实现 COMMAND \u003e /dev/null: 命令正常运行不通知用户，运行出错则通知用户 COMMAND \u0026\u003e /dev/null: 无论命令是否正常运行均不通知用户 转义：定义COMMAND时，如果命令需要用到%，需要对其转义；但放置于单引号中的%不用转义亦可； 注意: 某任务在指定的时间因关机未能执行，下次开机不会自动执行 如果期望某时间因故未能按时执行，下次开机后无论是否到了相应时间点都要执行一次，可使用anacron实现 ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:3:4","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"练习 1、每12小时备份一次/etc目录至/backups目录中，保存文件 名称格式为“etc-yyyy-mm-dd-hh.tar.xz” 2、每周2、4、7备份/var/log/secure文件至/logs目录中，文件名格式为“secure-yyyymmdd”； 3、每两小时取出当前系统/proc/meminfo文件中以S或M开头的行信息追加至/tmp/meminfo.txt文件中； ","date":"2018-02-02","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/:4:0","tags":["马哥 Linux"],"title":"9.2 任务计划和周期性任务","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/linux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1/"},{"categories":["Linux"],"content":"9.1 压缩打包工具","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"压缩打包工具 所谓压缩就是使用精心设计的压缩算法减少文本的容量大小，这对音频与视频无效，因为它们本身就是已压缩的。Linux 有众多的压缩和打包工具，本节我们将介绍如下命令的使用： gzip/gunzip bzip2/bunzip2 xz/unxz zip/unzip 通用的打包压缩工具 tar, cpio Linux 的打包工具 ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:0:0","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.1 gzip/gunzip/zcat gzip [OPTION]... FILE... -d：解压缩，相当于gunzip； -#：指定压缩比，默认是6；数字越大压缩比越大（1-9）； -c：将压缩结果输出至标准输出，默认 gzip 会删除源文件，只保留压缩后的文件 gzip -c FILE \u003e /PATH/TO/SOMEFILE.gz zcat GZIP_FILE 作用: 不用解压缩，直接查看压缩文件的内容 ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:0:1","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.2 bzip2/bunzip2/bzcat bzip2 [OPTION]... FILE... -d：解压缩，相当于 bunzip2 -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：keep，保留原文件； ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:0:2","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.3 xz/unxz/xzcat xz [OPTION]... FILE... -d：解压缩，相当于 unxz -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：保留原文件； ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:0:3","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2. 归档打包工具 ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:1:0","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.1 tar tar [OPTION]... FILE... 选项: 可以带- 可以不带 f: 指定要生成或解包的目标文件 c: 创建归档 x: 展开归档 t: 查看归档文件的文件列表 z: 使用 gzip 压缩 j: 使用 bzip2 压缩 J: 使用 xz 压缩 C: 展开归档时，将文件展开到指定目录 用法: 创建归档 -c -f /PATH/TO/SOMEFILE.tar FILE... -cf /PATH/TO/SOMEFILE.tar FILE... 查看归档文件的文件列表 -tf /PATH/TO/SOMEFILE.tar 归档压缩 -zcf /PATH/TO/SOMEFILE.tar.gz FILE... -jcf /PATH/TO/SOMEFILE.tar.bz2 FILE... -Jcf /PATH/TO/SOMEFILE.tar.xz FILE... 展开归档: -xf /PATH/FROM/SOMEFILE.tar -xf /PATH/FROM/SOMEFILE.tar -C /PATH/TO/SOMEDIR - 解压至指定目录 附注: 无须额外指定，tar 会自动根据文件名后缀使用响应的命令进行解压缩 ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:1:1","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.2 zip： zip/unzip 作用: 归档和压缩 后缀: .zip \u003e zip pam.d.zip pam.d/* # 必须指定打包压缩包含的文件 \u003e unzip pam.d.zip ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:1:2","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1.3 cpio ","date":"2018-02-01","objectID":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/:2:0","tags":["马哥 Linux"],"title":"9.1 压缩打包工具","uri":"/posts/linux/linux_mt/10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1/%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"8.5 btrfs文件系统管理与应用","date":"2018-01-31","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","tags":["马哥 Linux"],"title":"8.5 btrfs文件系统管理与应用","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"btrfs文件系统管理与应用 ","date":"2018-01-31","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:0:0","tags":["马哥 Linux"],"title":"8.5 btrfs文件系统管理与应用","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1. btrfs文件系统： ","date":"2018-01-31","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:0","tags":["马哥 Linux"],"title":"8.5 btrfs文件系统管理与应用","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.1 简介 简介: Btrfs (B-tree, Butter FS, Better FS), GPL, Oracle, 2007, CoW; 核心特性： 多物理卷支持：btrfs可由多个底层物理卷组成；支持RAID，以联机“添加”、“移除”，“修改”； 写时复制更新机制(CoW)：复制、更新及替换指针，而非“就地”更新； 数据及元数据校验码：checksum 子卷：sub_volume 快照：支持快照的快照； 透明压缩： ","date":"2018-01-31","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:1","tags":["马哥 Linux"],"title":"8.5 btrfs文件系统管理与应用","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"1.2 文件系统创建： mkfs.btrfs -L ‘LABEL’ -d : raid0, raid1, raid5, raid6, raid10, single -m : raid0, raid1, raid5, raid6, raid10, single, dup -O -O list-all: 列出支持的所有feature； 属性查看： btrfs filesystem show 挂载文件系统： mount -t btrfs /dev/sdb MOUNT_POINT 透明压缩机制： mount -o compress={lzo|zlib} DEVICE MOUNT_POINT 子命令：filesystem, device, balance, subvolume ","date":"2018-01-31","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/:1:2","tags":["马哥 Linux"],"title":"8.5 btrfs文件系统管理与应用","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/btrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"categories":["Linux"],"content":"8.4 Linux中实现LVM逻辑卷与快照","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"Linux中实现LVM逻辑卷与快照 LVM(Logical Volumn Manager) 逻辑卷，是将一个或多个底层块设备组织一个逻辑的工具。逻辑卷可以在使用过程中动态扩大和收缩，而不影响已经存在的文件。Centos7 默认安装下，会自动将磁盘组织成逻辑卷。本节我们就来介绍如何使用逻辑卷，将包含如下内容 LVM 简介 LVM 的创建和管理 ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:0:0","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"1. LVM 的简介 我们知道普通分区一旦确定之后便不能更改大小，想扩大或缩减分区，只能删除分区然后重新创建，但这势必会影响到分区上已经存在的文件。LVM 则是在物理设备(分区)的基础上添加了一层逻辑层，以达到可以动态更改容量的目的。对于那些实现无法确定磁盘使用量的情况，LVM 提供了很大的便利。但是额外的逻辑层使得 LVM 在数据恢复上变的更加困难。因此觉得LVM好的和感觉差的差不多对半开。 LVM 物理结构 LVM 的物理结构如下图所示 每个物理设备首先被组织成 PV(Physical Volume) 多个 PV 合并组成 VG(Volume Group) 逻辑卷组，统一进行管理，VG 可以动态增加和删除 PV 以扩大或收缩容量 PE(Physical Extent) 是 VG 容量分配的基本单元 LV(Logical Volume) 包含特定数量的 PE，构成逻辑上的分区，可动态调整包含的PE 数，以达到动态调整分区容量的目的；包含在 LV 中的PE 称为 LE LVM 创建过程 因此逻辑卷的创建，首先需要将物理设备创建为 PV，将多个 PV 创建为 VG，然后在 VG 的基础上创建 LV，LV 即是可以用来创建文件系统并挂载使用的逻辑分区。整个过程即 pv --\u003e vg --\u003e lv。LVM 由内核模块 dm, device mapper(设备映射组件)提供。下面是 pv,vg,lv 一众命令的概览。 作用 PV VG LV 创建 pvcreate vgcreate lvcreate 显示 pvdisplay vgdisplay lvdisplay 简要显示 pvs vgs lvs 删除 pvremove vgremove lvremove 降低容量 vgreduce lvreduce 添加容量 vgextend lvextend 搜索 pvscan vgscan lvscan ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:1:0","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"LV 的设备文件 一个逻辑卷 LV 的设备有三个，其中两个是便于访问的软连接 /dev/dm-#: LV 实际上的设备文件 /dev/VG_NAME/LV_NAME: 指向 dm-# 的软连接 /dev/mapper/VG_NAME-LV_NAME: 指向 dm-# 的软连接 ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:1:1","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"2. LVM 管理 下面我们开始学习pv，vg，lv 一众命令 ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:2:0","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"2.1 PV 管理 pvs|pvdisplays [pv_device] 作用: 显示系统上所有 pv 的基本信息 pv_device: pv 所在设备的设备文件名，显示特定 PV 信息；可选，默认显示所有 PV pvcreate /dev/DEVICE 作用: 创建 PV pvremove pv_device 作用: 删除 PV pv_device: pv 所在设备的设备文件名 ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:2:1","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"2.2 VG 管理 vgs|vgdisplays [vg_name] 作用: 显示系统上所有 vg 的基本信息 vg_name: 卷组名，可选，默认显示所有卷组 vgcreate [-s #] vg_name pv_device.... 作用: 创建卷组 -s: 指定PE 大小，默认4M，可用单位 kKmMgGtTpPeE vg_name: 卷组名 pv_device: pv 所在设备，可多个 vgextend vg_name pv_device.... 作用: 向 vg 添加 pv vgreduce vg_name pv_device.... 作用: 从 vg 删除 pv vgremove vg_name 作用: 删除整个卷组 ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:2:2","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"2.3 LV 管理 lv 的扩大或缩减不仅要调整 lv 自身大小，还需要调整 lv 上的文件系统大小。 lv 创建和删除 lvs|lvdisplays [lv_device] 作用: 显示系统上所有 lv 的基本信息 lv_device: 逻辑卷lv 的设备文件；可选，默认显示所有 lv lvcreate -L #[mMgGtT] -n lv_name vg_name: 作用: 在特定卷组内创建 lv -L: 指定 lv 的大小 -n: 指定 lv 的名称 lvremove /dev/VG_NAME/LV_NAME 作用: 删除 lv 附注: 删除前需先卸载文件系统 扩展逻辑卷： 扩展逻辑卷，首先需要调整逻辑卷大小，然后需要调整文件系统大小，相关命令如下 lvextend -L [+]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 扩展逻辑卷容量 -L: 指定逻辑卷大小，+ 表示增加多少，没有+直接指定变更后的总大小 eg: lvextend -L 4G /dev/myvg/mylv lvextend -L +2G /dev/myvg/mylv resize2fs /dev/myvg/mylv [size] 作用: 调整文件系统大小 size: 指定调整后大小，默认使用所有分区空间，单位有mMgGtT 缩减逻辑卷 缩减逻辑卷很危险，必需离线操作，大体上需要经过如下步骤: 先确定缩减后的目标大小；并确保对应的目标逻辑卷大小中有足够的空间可容纳原有所有数据； 卸载文件系统: umount /dev/VG_NAME/LV_NAME 文件系统强制检测: e2fsck -f 缩减文件系统大小: resize2fs DEVICE # 缩减逻辑卷大小: lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 重新挂载文件系统: mount lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 缩减逻辑卷容量 -L: 指定逻辑卷大小，- 表示减少多少，没有-直接指定变更后的总大小 创建快照卷： lvcreate -L #[mMgGtT] -p r -s -n 快照卷 原卷 作用: 创建 lv 的快照卷 -L #[mMgGtT]: 指定快照卷大小 -n: 指定快照卷名称 -s: 指明创建快照卷 -p r: 设置只读 注意：快照卷是对某逻辑卷进行的，因此必须跟目标逻辑卷在同一个卷组中；无须指明卷组； ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:2:3","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"练习 练习1：创建一个至少有两个PV组成的大小为20G的名为testvg的VG；要求PE大小为16MB, 而后在卷组中创建大小为5G的逻辑卷testlv；挂载至/users目录； \u003e pvcreate /dev/sdb \u003e pvcreate /dev/sdc \u003e vgcreate -s 16M testvg /dev/sdb /dev/sdc \u003e lvcreate -L 5G -n testlv testvg \u003e mkfs -t ext4 /dev/testvg/testlv \u003e mount /dev/testvg/testlv /users 练习2： 新建用户archlinux，要求其家目录为/users/archlinux，而后su切换至archlinux用户，复制/etc/pam.d目录至自己的家目录； \u003e useradd archlinux -d /users/archlinux \u003e echo \"aaaa\"|password archlinux --stdin \u003e cp -r /etc/pam /users/archlinux 练习3：扩展testlv至7G，要求archlinux用户的文件不能丢失； \u003e lvextend -L +20M /dev/testvg/testlv \u003e resize2fs /dev/testvg/testlv 练习4：收缩testlv至3G，要求archlinux用户的文件不能丢失； \u003e umount /user \u003e fsck -t ext4 -f /dev/testvg/testlv \u003e resize2fs /dev/testvg/testlv 30M \u003e lvreduce -L 30M /dev/testvg/testlv \u003e mount /dev/testvg/testlv /user/archlinux 练习5：对testlv创建快照，并尝试基于快照备份数据，验正快照的功能； ","date":"2018-01-30","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/:3:0","tags":["马哥 Linux"],"title":"8.4 Linux中实现LVM逻辑卷与快照","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/lvm%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7/"},{"categories":["Linux"],"content":"8.3 Linux RAID","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"Linux RAID 本章，我们来了解一些更复杂的磁盘使用方式，算是前一章的进阶。本章将包含以下内容: RAID 磁盘阵列 LVM 逻辑卷 btrfs 文件系统 RAID 全称叫廉价冗余磁盘阵列（Redundant Array of Inexpensive Disks)，后因磁盘不再廉价， RAID 咨询委员会将其改名为独立磁盘冗余阵列(Redundant Array of Independent Disks)。其设计初衷是为了将多个容量较小、相对廉价的磁盘进行有机组合，从而以较低的成本获得与昂贵大容量磁盘相当的容量、性能、可靠性。RAID 主要利用数据条带、镜像和数据校验技术来获取高性能、可靠性、容错能力和扩展性。根据运用或组合运用这三种技术的策略和架构，可以把 RAID 分为不同的等级，以满足不同数据应用的需求。本节我们学习的核心就是来了解 RAID 各个等级，包括如下内容 RAID 概述 RAID 各等级的组织结构和特性 软件RAID的实现 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:0:0","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"1. RAID 概述 从实现角度看， RAID 主要分为软 RAID、硬 RAID 以及软硬混合 RAID 三种。软 RAID 所有功能均有操作系统和 CPU 来完成。，没有独立的 RAID 控制 / 处理芯片和 I/O 处理芯片，效率自然最低。硬 RAID 配备了专门的 RAID 控制 / 处理芯片和 I/O 处理芯片以及阵列缓冲，不占用 CPU 资源，但成本很高。生长环境中则主要以硬 RAID为主。 RAID 中主要有三个关键概念和技术：镜像（ Mirroring ）、数据条带（ Data Stripping ）和数据校验（ Data parity ）。 镜像，将数据复制到多个磁盘，一方面可以提高可靠性，另一方面可并发从两个或多个副本读取数据来提高读性能。显而易见，镜像的写性能要稍低， 确保数据正确地写到多个磁盘需要更多的时间消耗。 数据条带，将数据分片保存在多个不同的磁盘，多个数据分片共同组成一个完整数据副本，这与镜像的多个副本是不同的，它通常用于性能考虑。数据条带具有更高的并发粒度，当访问数据时，可以同时对位于不同磁盘上数据进行读写操作， 从而获得非常可观的 I/O 性能提升 。 数据校验，利用冗余数据进行数据错误检测和修复，冗余数据通常采用海明码、异或操作等算法来计算获得。利用校验功能，可以很大程度上提高磁盘阵列的可靠性、鲁棒性和容错能力。不过，数据校验需要从多处读取数据并进行计算和对比，会影响系统性能。 不同等级的 RAID 采用一个或多个以上的三种技术，来获得不同的数据可靠性、可用性和 I/O 性能。至于设计何种 RAID （甚至新的等级或类型）或采用何种模式的 RAID ，需要在深入理解系统需求的前提下进行合理选择，综合评估可靠性、性能和成本来进行折中的选择。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:1:0","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2. RAID 等级 在实际应用领域中使用最多的 RAID 等级是 RAID0 、 RAID1 、 RAID4 、 RAID5 、RAID10 、JBOD。接下来将逐一介绍这几个 RAID 等级 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:0","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.1 RAID0 RAID0 又称条带，将数据分片保存在多个不同的磁盘，以获取读写性能的提升。其组织结构如下图所示，我们以竖向排列的磁盘表示条带。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:1","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.2 RAID1 RAID0 又称镜像，多个磁盘保存了数据的相同副本，通过冗余提供高的容错能力。其组织结构如下图所示，我们以横向排列的磁盘表示镜像，以与条带显示区分，介绍 RAID10 时更容易理解。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:2","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.3 RAID10 RAID10 指的是，先将磁盘两两分组组成 RAID1,然后将 RAID1 组织成RAID0。其组织结构如下图所示，数据先分片，在冗余保存。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:3","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.4 RAID4 RAID4 指的是有一块专门作为校验的磁盘，剩余磁盘组织成 RAID0，由校验盘提供冗余容错能力。其组织结构如下图所示，Ap,Bp等 表示校验数据块。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:4","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.5 RAID5 RAID4 有个明显的问题是，专门的校验盘负载过重。所以RAID5 将校验功能分散到了所有磁盘上。其组织结构如下图所示，校验数据块 Ap,Bp等分散在各个磁盘中。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:5","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.6 RAID6 RAID6 与 RAID5 类似，只不过有两个校验盘，能允许两块盘出现故障 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:6","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.7 JBOD JBOD 是将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘，一个存满了就存下一个。它只是简单提供一种扩展存储空间的机制，不提升存储性能，也没有提供冗余容错能力。其组织结构如下图所示。 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:7","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"2.8 各个 RAID 等级性能比较 |级别|读性能|写性能|容错性|最少磁盘数|可用空间 |:—|:—|:—|:—|:—| |RAID-0|提升|提升|降低|\u003e=2|Nmin(S1,S2,..)| |RAID-1|提升|略有下降|有|\u003e=2|1min(S1,S2..)| |RAID-4/5|提升|提升|允许坏1块磁盘|\u003e=3|(N-1)*min(S1,S2,…)| |RAID-6|提升|提升|允许坏2块磁盘|\u003e=4|(N-2)min(S1,S2,…)| |RAID-10|提升|提升|\u003e=4|每组镜像最多只能坏一块|Nmin(S1,S2,…)/2| |JBOD|不变|不变|降低|\u003e=2|sum(S1,S2,…)| ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:2:8","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"3. 软件RAID的实现 CentOS 上软RAID的实现由 md(multi devices)模块，及其提供 mdadm 命令组成 md 模块: multidisks, 一个内核模块，用于支持将任何块设备组织成RAID mdadm 命令: 操作 md 模块的模式化工具 mdadm mdadm [mode] raiddevice [options] component-devices mode: 管理模式 -A: 装配模式，重新识别此前实现的RAID -C：创建模式，创建RAID -F：监控模式 管理模式：-f, -r, -a raiddevice: RAID设备的设备文件,通常为/dev/md#，#表示一个数字 component-devices:成员设备 支持的RAID级别: JBOD, RAID0, RAID1, RAID4, RAID5, RAID10 options: C: 创建模式中专用选项 -n #: 用于创建RAID设备的磁盘个数； -l #: 级别 -a {yes|no}: 自动为创建的RAID生成设备文件; -c Chunk_Size: 指明块大小 -x #: 指明空闲盘的个数 管理模式 mdadm /dev/md# -f /dev/some_device：将/dev/md#中的/dev/some_device手动设置为损坏 mdadm /dev/md# -r /dev/some_device：将/dev/md#中的损坏状态的/dev/some_device移除 mdadm /dev/md# -a /dev/new_device: 新增设备 装配模式 停止软件RAID：mdadm -S /dev/md# 重新启用RAID： mdadm -A /dev/md# /dev/DEVICE... mdadm的配置文件/etc/mdadm.conf RAID 设备查看 cat /proc/mdstat: 当前系统上所有已启用的软件RAID设备及其相关信息 mdadm -D /dev/md#：显示指定的软RAID的详细信息 # 创建一个10G空间的RAID0 \u003e mdadm -C /dev/md0 -a yes -n 2 -l 0 /dev/sdb{1,2} # 创建大小为10G空间的RAID5 -- 3*5G，6*2G (n-1)*2G \u003e mdadm -C /dev/md1 -a yes -n 3 -l 5 /dev/sda{3,5} /dev/sdb3 ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:3:0","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"练习 # centos7 GPT 分区格式 练习1：创建一个可用空间为10G的RAID1设备，要求其chunk大小为128k，文件系统为ext4，有一个空闲盘，开机可自动挂载至/backup目录； \u003e fdisk /dev/nvme0n1 # 创建3个大小为 50M 的类型为 13 磁盘分区 \u003e mdadm -C /dev/md0 -n 2 -l 1 -c 128K -x 1 /dev/nvme0n1p{12,13,14} \u003e mdadm -D /dev/md0 \u003e mke2fs -t ext4 /dev/md0 \u003e blkid /dev/md0 /dev/md0: UUID=\"8d46d667-d3e2-4f5e-b918-4e6d9a576445\" TYPE=\"ext4\" \u003e vim /etc/fstab UUID=\"8d46d667-d3e2-4f5e-b918-4e6d9a576445\" /backup ext4 defaults,acl 0 0 \u003e mount -a # 拆除 RAID \u003e umount /dev/md0 \u003e mdadm -S /dev/md0 练习2：创建一个可用空间为10G的RAID10设备，要求其chunk大小为256k，文件系统为ext4，开机可自动挂载至/mydata目录； \u003e fdisk /dev/nvme0n1 # 创建4个大小为 50M 的类型为 13 磁盘分区 \u003e mdadm -C /dev/md0 -n 4 -l 10 -c 256K /dev/nvme0n1p{12,13,14,15} \u003e mkfs -t ext4 /dev/md0 \u003e blkid /dev/md0 /dev/md0: UUID=\"779bf9e4-846c-443d-970e-6a9b12a235c8\" TYPE=\"ext4\" \u003e vim /etc/fstab UUID=\"779bf9e4-846c-443d-970e-6a9b12a235c8\" /mydata ext4 defaults 0 0 \u003e mount -a ","date":"2018-01-29","objectID":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/:4:0","tags":["马哥 Linux"],"title":"8.3 Linux RAID","uri":"/posts/linux/linux_mt/09-raid%E5%92%8Clvm%E5%BA%94%E7%94%A8/linux_raid/"},{"categories":["Linux"],"content":"8.2 磁盘与文件系统的管理命令","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"磁盘使用与文件系统管理介绍 本节，我们来学习磁盘和文件系统管理的相关命令，我们将按照从磁盘到创建一个可用的文件系统的顺序，逐步讲解相关命令的使用，内容如下: 磁盘分区 重载内核分区表 文件系统管理 挂在文件系统 其他相关命令 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 磁盘进行分区 磁盘分区管理主要有 fdisk，parted，sfdisk 三个命令。掌握一个即可，我们主要来学习 fdisk。fdisk 提供了一个交互式接口来管理分区，它有许多子命令，分别用于不同的管理功能；所有的操作均在内存中完成，不会直接同步到磁盘，直到使用w命令保存至磁盘上。fdisk 命令的使用方式如下 查看磁盘的分区信息： fdisk -l [device...] 作用: 列出指定磁盘设备上的分区情况，默认列出所有磁盘设备的分区情况 参数: device 设备文件名 cat /proc/partitions 作用: 查看内核分区信息 管理分区 fdisk device 作用: 管理分区，进入 fdisk 交互式管理界面 # fdisk 使用示例 \u003e fdisk /dev/nvme0n1 WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion. 欢迎使用 fdisk (util-linux 2.23.2)。 更改将停留在内存中，直到您决定将更改写入磁盘。 使用写入命令前请三思。 命令(输入 m 获取帮助)：m 命令操作 d 删除已有分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l 列出所有的分区类型 m 查看帮助信息 n 创建新分区 o create a new empty DOS partition table p 显示现有分区信息 q 不保存并退出 s create a new empty Sun disklabel t 修改分区类型 v verify the partition table w 保存并退出 x extra functionality (experts only) ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 重载内存分区表 在已经分区并且已经挂载其中某个分区的磁盘设备上创建的新分区，内核可能在创建完成后无法直接识别；需要通知内核强制重读磁盘分区表。可用命令有如下三个: partprobe partprobe [device] 作用: inform the OS of partition table changes 附注: CentOS 5 仅能使用此命令 partx partx [-a|-u] device 作用: tell the Linux kernel about the presence and numbering of on-disk partitions 选项: -a: 向内核添加所有分区表 -u: 向内核更新分区表 -l: 列出分区表 -s, --show: 显示分区表详细信息 -n, --nr M:N: 与 -s一起使用，限制显示的行 -o, --output list: 与 -s一起使用，限制显示的列 kpartx kpartx -af device 作用: Create device maps from partition tables ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 文件系统管理 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 文件系统创建 Windows无法识别Linux的文件系统； 因此，存储设备需要两种系统之间交叉使用时，应该使用windows和Linux同时支持的文件系统：fat32(vfat)。mkfs.vfat device mkfs mkfs -t fs_type device 作用: 通用的文件系统创建命令，内部会调用特定文件系统的创建命令 选项: -t 指定要创建的文件系统 eg: mkfs -t ext4 /dev/sda1 == mkfs.ext4 /dev/sda1 \u003e mkfs mkfs mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.fat mkfs.minix mkfs.msdos mkfs.vfat mkfs.xfs mke2fs mke2fs [OPTIONS] device 作用: ext系列文件系统专用创建工具 选项: -t {ext2|ext3|ext4}： 指明要创建的文件系统类型 mkfs.ext4 = mkfs -t ext4 = mke2fs -t ext4 -b {1024|2048|4096}：指明文件系统的块大小； -L LABEL：指明卷标； -j： 创建有日志功能的文件系统ext3； mke2fs -j = mke2fs -t ext3 = mkfs - t ext3 = mkfs.ext3 -i #：bytes-per-inode，指明inode与字节的比率；即每多少字节创建一个Indode; -N #：直接指明要给此文件系统创建的inode的数量； -m #：指定预留的空间，百分比； -O [^]FEATURE：以指定的特性创建目标文件系统； mkswap mkswap [OPTIONS] device 作用: 创建swap文件系统 选项: -L LABEL：指明卷标 -f：强制创建 附注: Linux上的交换分区必须使用独立的swap文件系统； 且文件系统的System ID必须为82； swapon [OPTION] [DEVICE] 作用: 启用交换分区 选项: -a 启用定义在/etc/fstab文件中的所有swap设备； -p #: 指定此交换设备的优先级 swapoff DEVICE 作用: 禁用交换分区 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:1","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.2 文件系统查看和修改 e2label 作用: 查看与设定 ext 系列文件系统的卷标 查看: e2label device 设定: e2label device LABEL dumpe2fs dumpe2fs [-h] device 作用: 显示 ext 系列文件系统的属性信息 选项: -h 仅显示超级块信息 tune2fs tune2fs [OPTIONS] device 作用: 查看或修改ext系列文件系统的某些属性 注意：块大小创建后不可修改； 选项: -l：查看超级块的内容； -j：启动日志功能，即将 ext2 转换为 ext3； -L LABEL：修改卷标； -m #：调整预留空间百分比，后跟数字标直接表示百分之几； -O [^]FEATHER：开启或关闭某种特性； -o [^]mount_options：开启或关闭某种默认挂载选项 tune2fs -0 acl /dev/sda1: 开启访问控制列表功能 tune2fs -0 ^acl /dev/sda1: 关闭访问控制列表功能 blkid blkid 作用: 显示块设备属性，主要是显示文件系统类型 blkid device: 查看特定设备所有分区文件系统的类型和属性 blkid -L LABEL：根据LABEL定位设备 blkid -U UUID：根据UUID定位设备 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:2","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.3 文件系统检查 因进程意外中止或系统崩溃等原因导致定稿操作非正常终止时，可能会造成文件损坏；此时，应该检测并修复文件系统。建议离线进行，不能让其他用户在正在修复的文件系统中读写文件。Linux 上的文件系统检测工具 fsck 同 mkfs 一样是一个通用的文件系统修复工具 fsck fsck -t fs_type device 作用: check and repair a Linux file system 选项: -t fstype: 指明文件系统类型； -a：无须交互而自动修复所有错误； -r：交互式修复 eg: fsck -t ext4 = fsck.ext4 e2fsck e2fsck [OPTIONS] device 作用: ext系列文件系统的专用工具 选项: -y: 对所有问题自动回答为yes; -f：即使文件系统处于clean状态，也要强制进行检测 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:3","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4. 文件系统挂载 根文件系统这外的其它文件系统要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”；此目录即为“挂载点”。Linux 中用于挂载和卸载的命令是 mount,umount 挂载点，即用于作为另一个文件系统的访问入口,应该具有如下特性: 事先存在； 应该使用未被或不会被其它进程使用到的目录； 挂载点下原有的文件将会被隐藏； ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.1 文件系统挂载 mount [option]... [-t fstype] [-o option] 设备 挂载点 作用: 将设备挂载至特定目录 设备: 设备文件: /dev/sda 卷标: -L 卷标 UUID: -U UUID 常用的挂载选项： -r: readonly, 只读挂载 -w: read and write， 读写挂载 -t fstype：指明要挂载的设备上的文件系统的类型；多数情况下可省略，此时mount会通过blkid来判断要挂载的设备的文件系统类型； -L LABEL：以卷标方式指定设备， mount -L MYDATA 挂载点 -U UUID: 以UUID的方式指定设备，mount -U uuid 挂载点 -a: 自动挂载所有(/etc/fstab文件中定义的)支持自动挂载的设备 -n: 默认情况下，设备挂载或卸载的操作会同步更新至/etc/mtab文件中；-n用于禁止此特性； -B --bind: 绑定到目录到另一个目录上 -o option: 挂载文件系统的选项 async：异步I/O，数据写操作先于内存完成，而后再根据某种策略同步至持久设备中 sync: 同步I/O， atime/noatime: 文件和目录被访问时是否更新最近一次的访问时间戳 auto/noauto：设备是否支持mount的-a选项自动挂载 diratime/nodiratime: 目录被访问时是否更新最近一次的访问时间戳 dev/nodev: 是否支持在此设备上使用设备； user/nouser: 是否允许普通用户挂载此文件设备 exec/noexec: 是否允许执行此设备上的二进制程序文件 suid/nosuid: 是否支持在此设备的文件上使用suid ro: 只读 rw: 读写 remount: 重新挂载，通常用于不卸载的情况下重新指定挂载选项 acl: 启用此文件系统的 acl 功能，默认不支持； defaults: 默认选项 rw, suid, dev, exec, auto, nouser, and async eg: mount -o acl DEVICE MOUNT_POINT: 挂载后启动 acl 选型 tune2fs -o acl DEVICE 为设备设定默认挂载选项，启动 acl mount -o remount,ro /dev/sda: 以只读方式重新挂载 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:1","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.2 查看已挂载的设备 查看已挂载的设备可使用如下三个命令 mount cat /etc/mtab cat /proc/mounts ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:2","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.3 特殊设备挂载 挂载文件 mount --bind 源目录 目标目录: 作用: 可以实现将目录绑定至另一个目录上，作为其临时访问入口； 挂载光盘 mount -r /dev/cdrom mount_point 光盘设备文件： IDE 接口的光盘: /dev/hdc SATA接口的光盘: /dev/sr0 符号链接文件： /dev/cdrom /dev/cdrw: rw 表示是可写光盘 /dev/dvd /dev/dvdrw: rw 表示可写 dvd 挂载本地的回环设备 mount -o loop /PATH/TO/SOME_LOOP_FILE MOUNT_POINT ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:3","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.4 文件系统卸载 umount device|dir 作用: 卸载设备 参数: 设备文件或挂载点 注意：正在被进程访问到的挂载点无法被卸载，要想查看设备被哪个或哪些进程所战用，可以使用如下命令 lsof MOUNT_POINT: 查看占用设备的进程 fuser -v MOUNT_POINT: 查看占用设备的用户 fuser -km MOUNT_POINT: 终止所有正在访问某挂载点的进程 ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:4","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"4.5 自动挂载 /etc/fstab文件可用于配置除根文件系统以外的其它文件系统在开机时自动挂载。每行定义一个要挂载的文件系统及相关属性，每行有 6 个字段，从左往右各个字段的含义如下。使用 mount -a 可自动挂载定义在此文件中的所支持自动挂载的设备。需要额外注意的是swap 分区的挂载点永远是 swap, 且自动使用 swapon 挂载 挂载的设备： 设备文件 LABEL=\"\" UUID=\"\" 伪文件系统名称: proc, sysfs, devtmpfs, configfs 挂载点： 文件系统类型 挂载选项： 挂载选项可以有多个，彼此间使用逗号分隔； 转储频率：作用不大，大多数是 0 0：从不转储 1: 每天转储 2: 每隔一天 自检次序： 0：不自检，额外创建的文件系统都无须自动自检 1：首先自检，通常只有根文件系统需要首先自检 2：次级自检，不同的设备可以使用同一个自检次序 3 …. ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:4:5","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"5. 其他相关命令 其他命令主要包括如下几个命令: 手动创建设备文件的 mknod 命令 查看磁盘使用量的 df 命令 查看文件夹大小的 du 命令 mknod mknod [OPTION]... NAME TYPE [MAJOR MINOR] 作用: 可用于手动创建字符或块设备文件 选项: -m MODE：创建后的设备文件的访问权限 df df [OPTION]... [FILE]... 作用: 查看已挂载设备的磁盘使用量 选项: -l：仅显示本地挂载设备的相关信息； -h：human-readable，以易读的方式显示磁盘使用量 -i：显示inode的使用状态而非blocks -P, --portability: 使用POSIX格式输出，不会出现换行 du du [OPTION]... [FILE]... 作用: 查看文件夹的大小 选项: -s: sumary，只显示文件夹的总大小 -h: human-readable 以人类易读方式显示容量大小 练习： 1、创建一个10G的分区，并格式化为ext4文件系统； (1) block大小为2048；预留空间为2%，卷标为MYDATA； (2) 挂载至/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳； (3) 可开机自动挂载； 2、创建一个大小为1G的swap分区，并启动之； ","date":"2018-01-28","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:5:0","tags":["马哥 Linux"],"title":"8.2 磁盘与文件系统的管理命令","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"8.1 磁盘使用与文件系统管理介绍","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"磁盘使用与文件系统管理介绍 本章我们开始学习 Linux 磁盘和文件系统管理，这部分内容与操作系统原理，文件系统，磁盘硬件密切相关，内容多而且难。但是对Linux 运维而言，我们需要了解的仅仅是其中的基本概念以及如何使用命令管理分区和文件系统。因此将本章分为两个部分: 磁盘和文件系统的相关原理 磁盘和文件系统管理命令 第一部分讲解原理，属于概括性的数理总结，由于本人理解的有限，所以更加深入的内容还需要同学自己去谷歌相关的文档；第二部分是命令使用，将按照分区创建，文件系统创建管理的顺序，详细讲解管理磁盘和文件系统的所有常用命令。 磁盘是计算的五大基本组件之一，主要提供持久化存储功能。Linux 为管理磁盘，便于程序员扩展系统和用户读写磁盘数据，将磁盘管理划分成了多个层次。如同网络协议栈一样，各层级之间通过协议和接口进行规范，这样就能便于管理和扩展。这是编程领域常用的技术手段，如果两个层次无法衔接，就添加一个中间层。Linux 的磁盘管理大体分成了以下几个层次 -------------------------------- | 虚拟文件系统 | ---\u003e 提供了读写文件的统一接口 ------------------------------- | 特定的文件系统 | ---\u003e 抽象了对不同设备驱动程序的调用接口 -------------------------------- ---\u003e 磁盘设备文件，提供了管理磁盘的统一接口 | 磁盘设备的驱动程序 | ---\u003e 将对磁盘适配器的机器指令转换为系统调用 -------------------------------- |磁盘 | 磁盘适配器| --------------------------------- 本节我们将围绕此结构，逐层讲解各层，内容如下: 抽象层次的理解 磁盘的组成和磁盘分区 文件系统的组成 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:0:0","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. 抽象层次的理解 磁盘通常包括两个部分，一是存储数据的磁盘，另一个是与磁盘相对应的磁盘适配器，适配器相当于磁盘的控制单元，可以接收指令，并控制磁盘的寻道和读写。适配器的指令是与硬件相关的简单机器指令，与生产磁盘的硬件厂商密切相关。 所以为管理磁盘，包括其他硬件设备，都需要生产厂商提供与操作系统相适应的驱动程序。需要强调的是硬件的驱动程序是硬件厂商提供的，而不是内核开发者提供，因为硬件设备千千万万，只有厂商才最清楚他们生产的硬件设备是什么样。因此磁盘管理从发送与磁盘相关的机器指令变成了调用了相应驱动程序的系统调用。 我们知道越底层的东西越丑陋，也就越难用，想想如果你想创建一个文件，竟然需要写一个程序去调用系统调用，该多么费劲。文件系统的作用就是帮助我们管理磁盘，我们只需要调用文件系统的一条命令，就可以读写文件，而不用管数据到写到了磁盘何处。 此处还有一个问题，Linux 上的文件系统有很多，他们调用 api 可能都不一样，想想如果换一个文件系统，创建文件的函数就变了，大概编写 touch 命令的程序员就疯了，他要为所有文件系统都写一段代码。因此Linux 为统一管理所有的文件系统，创建了虚拟文件系统 vfs。可以将 vfs 理解为一个统一的框架，比如创建文件的命令就叫做 writer，此时不管什么文件系统，都要将其创建文件的调用向 vfs 注册。这样当我们调用 writer 时，vfs 就知道特定的文件系统创建文件的函数是什么，进而由 vfs 调用该函数创建文件。 因此，程序员只要调用 vfs 提供的标准接口就可以在所有的文件系统上读写文件了。了解了整个层次结构，接下来我们就来了解各个层次结构的细节。 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:1:0","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1. 磁盘 分区的作用就是将一个完成的磁盘，划分成逻辑上独立的管理单元。由于磁盘特殊的寻址特点，因此分区与磁盘的硬件结构密切相关。所以我们先来了解磁盘的硬件结构，然后再来看磁盘是如何分区的。 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:0","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.1 磁盘的类型 磁盘按照生产工艺可以分为机械硬盘，固态硬盘，按照接口类型可以分为 IDE(ata)：并口，133MB/s SCSI：并口，Ultrascsi320, 320MB/S, UltraSCSI640, 640MB/S SATA：串口，6gbps SAS：串口，6gbps USB：串口，480MB/s 并口指的是同一线缆可以接多块设备；串口则是同一线缆只可以接一个设备。对于电脑的硬件架构，大家可以找不用的台式机拆开看看，这样就会有更加具体的理解。由于机械硬盘更容易理解，我们首先来看机械式硬盘的硬件结构 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:1","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.2 机械式硬盘的硬件结构 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:2","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.3 磁盘的分区结构 上面几幅图是机械硬盘结构和分区的示意图，如果不能理解可以参阅此博客 https://blog.csdn.net/u012758088/article/details/76668465 Centos5-6 中分区是以柱面为单位进行划分，而 Centos7 中分区划分的基本单位则是扇区 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:3","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.4 磁盘设备文件 设备文件的主次设备号 Linux 中一切接文件，所有设备都组成了设备文件,放置在 /dev 目录下，用于关联至设备的驱动程序，是设备的访问入口，能利用 Linux 中的统一接口进行管理。设备有主，次设备号 major：主设备号，区分设备类型；用于标明设备所需要的驱动程序； minor：次设备号，区分同种类型下的不同的设备；是特定设备的访问入口； 设备文件命令规则 设备文件有统一的命名规则，由ICANN 规定，具体的规则如下；由于设备被检测到的顺序是可能发生变化的，设备的设备文件可能发生变化，因此除了设备文件名，Linux 还提供了其他引用设备的方式，包括卷标，UUID。 centos5 IDE: /dev/hd# SCSI,SATA,SAS,USB: /dev/sd[a-z]# [a-z]: 表示不同设备,为不同设备被检测到的次序 #: 表示不同设备上的不同分区 centos\u003e=6: 统一使用 /dev/sd[a-z]# \u003e /dev/nvme0n1p2 # 设备文件 # 259, 2 即为设备的主次设备号 brw-rw----. 1 root disk 259, 2 7月 17 09:16 /dev/nvme0n1p2 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:4","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"1.4 磁盘分区格式 分区格式顾名思义就是如何在磁盘上表示分区。分区格式除了会影响分区的划分，还会影响操作系统的开机启动方式。早期的分区格式是 MBR，这种分区格式有分区数量和磁盘大小有限制，对于超出范围的磁盘容量无法识别。GPT 是最新的磁盘分区技术，比 MBR 更复杂，但是已经没有了 MBR 的种种限制 MBR MBR 是 Master Boot Record 的简称。如图，MBR 是磁盘的的第一个扇区，它包括如下三个部分 446bytes：包含了 bootloader 开机启动程序，用于引导启动操作系统 64bytes：分区表，每16bytes标识一个分区，一共只能有4个分区，其中又一个可作为扩展分区，用于创建其他逻辑分区； 主分区和扩展分区的标识：1-4 逻辑分区：5+ 2bytes：MBR区域的有效性标识；55AA为有效； GPT GPT 暂时我也不是很清楚，大家可以参考此片博文 https://blog.csdn.net/diaoxuesong/article/details/9406015。过段时间会补充此部分，请稍等。 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:2:5","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2. 文件系统 内核级文件系统由内核提供文件系统驱动和用户空间的文件系统管理工具组成。因为 ext4 文件系统相对容易理解，此处我们 ext4 文件系统为列，讲解文件系统的基本原理 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:0","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.1 ext4 组成部分 block inode inode表 inode bitmap, block bitmap 块组 superblock 块组描述符表(GDT) ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:1","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.2 文件查找过程 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:2","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.3 链接文件 链接文件值访问同一个文件不同路径，有硬链接和软链接之分 硬链接 硬链接：指向同一个inode的多个文件路径； 特性： 目录不支持硬链接； 硬链接不能跨文件系统； 创建硬链接会增加inode引用计数； 创建： ln src link_file 符号链接 符号链接：指向一个文件路径的另一个文件路径； 特性： 符号链接与文件是两人个各自独立的文件，各有自己的inode；对原文件创建符号链接不会增加引用计数； 支持对目录创建符号链接，可以跨文件系统； 删除符号链接文件不影响原文件；但删除原文件，符号指定的路径即不存在，此时会变成无效链接； 符号链接文件的大小是其指定的文件的路径字符串的字节数； 创建：ln -s src link_file ln ln [-s] source dest: 作用: 创建链接文件 选项: -s 创建软链接，默认创建硬链接 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:3","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.4 文件管理操作 文件被删除： inode被标记为空闲，此inode指向的磁盘块被标记为空闲； 如果inode被引用了多次，且此次删除未使得其引用计数降低为的话，这意味着文件被删除仅删除了一个访问路径； 文件复制： 创建一个新文件，并原文件中数据在新文件指向的磁盘块中再写一次的过程； 文件移动： 在同一个分区移到：移动文件仅是改变了文件访问路径； 跨分区移到：在新分区创建文件，把数据复制过去，删除原分区数据； ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:4","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.5 文件系统挂载 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:5","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.6 日志文件系统 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:6","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"2.7 vfs 虚拟文件系统 ","date":"2018-01-27","objectID":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/:3:7","tags":["马哥 Linux"],"title":"8.1 磁盘使用与文件系统管理介绍","uri":"/posts/linux/linux_mt/08-linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/"},{"categories":["Linux"],"content":"7.6 awk使用与实战","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"sed命令应用与实战 Linxu 上有文本处理三剑客grep,sed,awk。本节我们来学习最后一个命令 awk 的使用。 awk 算得上是一门编程语言，这个编程语言内有包括变量，条件判断，循环，命令等诸多语言特性。我们将按照类似 bash 脚本的方式，从变量开始逐一讲解 awk 的使用。内容概述如下: awk 命令简介 awk 变量与数组的使用 awk 程序执行逻辑，包括顺序执行，条件判断和循环 awk 内置函数 有关 awk 的使用推荐大家阅读 《sed和awk》 《Linux Shell与脚本编程指南》 ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:0:0","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1. awk 简介 Centos 中的 awk 是 GNU awk即 gawk。awk 是指向 gawk 命令的软连接 tao@hp:~$ which awk /usr/bin/awk tao@hp:~$ ll /usr/bin/awk lrwxrwxrwx. 1 root root 4 5月 8 09:34 /usr/bin/awk -$ gawk ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:1:0","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1.1 awk 处理逻辑 如上图，awk 将文件处理分成三个阶段。第一阶段由 BEGIN 标识，第三阶段由 END标志，分别位于文件处理前和文件处理之后。 文本处理位于第二阶段，awk 每次读取文件中的一行，按照内部 FS 变量标识的分割符，将行分割成多个字段。字段按照位置分别保存在 $1,$2,$3…. 等变量中，供 awk 编程使用，$0 表示整行。awk 中的字段变量如下所示 ----------------------------------- | $0 | # 整行 ------------------------------------ | $1 | $2 | $3 | .......| # $n 表示分隔后的第 n 个字段 ------------------------------------ 作为一个编程语言，awk 有一些基本的语法特性，如果你有其他编程语言的使用经验，记住这些语法特性基本上很快就能写出 awk 程序。我们以如下例子来说明这些基本特性 awk -F: '/^r/{if ($3$10) {i=1;printf \"|%-15s |%-15s|\\n\",$1,$7} }' /etc/passwd 使用 {} 分割代码块 控制语句的条件判断放置在 ()内 代码块内的多条语句使用;分割，按顺序从左往右执行 使用 \"\" 表示字符串 使用/pattern/ 表示使用正则表达式 如果你不懂上面说的什么意思，没有关系，我们接下来会详细介绍 awk 的语法。 ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:1:1","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1.2 awk 命令使用 gawk [options] 'program' FILE ... 作用: 文件格式化工具 选项: -F：指明输入时用到的字段分隔符； -v var=value: 自定义变量； 参数: FILE: 待处理的文本文件，可多个 program: awk 编程脚本，必须使用单引号括起 格式: 'PATTERN{ACTION STATEMENTS}' PATTERN：过滤出要处理的行 {ACTION STATEMENTS}: 编程语句表达式 tao@hp:~$ awk -F: '{print $1}' /etc/passwd root bin daemon adm ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:1:2","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1.3 PATTERN PATTERN 用于过滤出要处理的行，有如下几种过滤方式 empty： 作用: 空模式，匹配每一行 /regular expression/ 作用: 仅处理能够被此处的模式匹配到的行； relational expression: 作用: 关系表达式；结果为“真”才会被处理;非0值，非空均为真； /pat1/,/pat2/： 作用: 从 pat1 匹配首行到 pat2 匹配的首行之间的行 注意: 不支持类似 sed 直接给出数字的格式 startline,endline,只能通过关系表达式实现 BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次； END{}：仅在文本处理完成之后执行一次； pattern 使用示例 下面是一些使用 PATTERN 的示例，可以先跳过。 # 1. empty # 显示eth0网卡配置文件的配置信息，只显示=号后的内容； $ gawk -F= '{print $2}' /etc/sysconfig/network-scripts/ifcfg-eth0 # 2. /regular expression/ # 显示默认shell为nologin的用户； $ gawk -F: '$7~/nologin$/{print $1}' /etc/passwd # 显示/etc/sysctl.conf文件定义的内核参数的参数名； $ awk -F= '/^[^#]/{print $1}' /etc/sysctl.conf # 显示eth0网卡的ip地址； $ ifconfig eth0 | awk -F: '/inet addr/{print $2}' | awk '{print $1}' # 3. relational expression # 显示gid小于500的组； $ gawk -F: '$3\u003c500{print $1}' /etc/group # 4. line ranges $ awk -F: '(NR$=2\u0026\u0026NR\u003c=10){print $1}' /etc/passwd $ awk -F: '/^r/,/^h/{print $1}' /etc/passwd # 5. BEGIN/END awk -F: 'BEGIN{printf \"%-15s|%-15s\\n\",\"user\",\"bash\"}{printf \"%-15s|%-15s\\n\",$1,$7}END{print \"---------------------------\\n\"}' /etc/passwd # 6. 指定复杂分隔符 $ ifconfig eth0 | awk 'BEGIN{FS=\"[ :]+\"}/inet addr/{print $4}' ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:1:3","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2. awk 编程语法 ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:0","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.1 变量 变量特性 awk 中变量具有如下特性: 区分大小的 变量直接引用，无需使用 $, $1 整体表示一个变量，存储了第一个字段的值 自定义变量可以通过 -v var=value 选项指定，也可以在program中直接定义 awk -v FS=: '{print $1}' /etc/passwd # 等同于 awk -F: '{print $1}' /etc/passwd # -F 就是指定 FS 变量的值 内置变量 awk 有众多内置变量，常见的如下所示: FS：input field seperator，默认为空白字符； OFS：output field seperator，默认为空白字符； RS：input record seperator，输入时的换行符； ORS：output record seperator，输出时的换行符；- NF：number of field，字段数量 {print NF}: 打印当前行列数 {print $NF}: 打印当前行最后一个字段的值 NR：number of record, 行数；如果 awk 后跟多个文件，这个 NR 将是所有行的累计值 FNR：各文件分别计数；行数； FILENAME：当前文件名； ARGC：命令行参数的个数； ARGV：数组，保存的是命令行所给定的各参数； 2.2 输出 awk 的输出有 print,printf 两个命令 print print item1, item2, ... 作用: 输出后跟的内容 特性: 逗号分隔符； 输出的各item可以字符串，也可以是数值；当前记录的字段、变量或awk的表达式； 如省略item，相当于print $0; printf printf FORMAT, item1, item2, ... 作用: 格式化输出,与 C 语言的 printf 函数的使用方式完全相同，bash中也有同名命令 说明: printf 不会自动换行，需要显式给出换行控制符，\\n 参数: FORMAT: 格式化字符串，表示以特定格式显示数据；包括格式符和修饰符两个部分 item1..: 被格式化的数据，FORMAT中需要分别为后面的每个item指定一个格式化符号； 格式符： %c: 显示字符的ASCII码； %d, %i: 显示十进制整数； %e, %E: 科学计数法数值显示； %f: 显示为浮点数； %g, %G：以科学计数法或浮点形式显示数值； %s：显示字符串； %u：无符号整数； %%: 显示%自身； 修饰符： #[.#]：第一个数字控制显示的宽度；第二个数字表示小数点后的精度 -: 左对齐 +：显示数值的符号 $ printf \"%-5.2f\\n\" 3.2 3.20 $ awk 'BEGIN{printf \"%-5.3f\\n\", 32.44456}' 32.445 $ printf \"%+20.2f\\n\" 3.2 +3.20 ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:1","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.3 操作符 awk 支持几乎所有的常规操作符 算术操作符： x+y, x-y, x*y, x/y, x^y, x%y -x +x: 转换为数值； 字符串操作符：没有符号的操作符，字符串连 赋值操作符： =, +=, -=, \\*=, /=, %=, ^= ++, -- 比较操作符: $, $=, \u003c, \u003c=, !=, == 模式匹配符：后接正则表达 ~：是否匹配 !~：是否不匹配 逻辑操作符： \u0026\u0026 || ! 条件表达式：selector?if-true-expression:if-false-expression # 1. 算术运算 $ awk 'BEGIN{i=1;i++;print i^3}' 8 # 5. 模式匹配符 awk -F: '{if($1 ~ /^r/){print $1}}' /etc/passwd # 7. 条件表达式 awk -F: '{$3$=1000?usertype=\"Common User\":usertype=\"Sysadmin or SysUser\";printf \"%15s:%-s\\n\",$1,usertype}' /etc/passwd 2.4 控制语句 过程式编程语言的代码执行顺序有顺序执行，条件判断和循环。awk 中常见的控制语句语法如下所示: if(condition) {statments} if(condition) {statments} else {statements} while(conditon) {statments} do {statements} while(condition) for(expr1;expr2;expr3) {statements} break continue next 代码块使用 {}，控制语句中的条件放置在 ()内，而 代码块内顺序执行的代码使用 ; 分隔。 if-else if(condition) statement [else statement] $ awk -F: '{if($3$=1000) {printf \"Common user: %s\\n\",$1} else {printf \"root or Sysuser: %s\\n\",$1}}' /etc/passwd $ awk -F: '{if($NF==\"/bin/bash\") print $1}' /etc/passwd $ awk '{if(NF$5) print $0}' /etc/fstab $ df -h | awk -F[%] '/^\\/dev/{print $1}' | awk '{if($NF$=20) print $1}' while循环 while(condition) statement 使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用； $ awk '/^[[:space:]]*linux16/{i=1;while(i\u003c=NF) {print $i,length($i); i++}}' /etc/grub2.cfg $ awk '/^[[:space:]]*linux16/{i=1;while(i\u003c=NF) {if(length($i)$=7) {print $i,length($i)}; i++}}' /etc/grub2.cfg do-while循环 do statement while(condition) 意义：至少执行一次循环体 for循环 for(expr1;expr2;expr3) statement: 普通 for 循环 for(var in array) {for-body：遍历数组的特殊语法格式 $ awk '/^[[:space:]]+linuxefi/{for(i=1;i\u003cNF;i++){if(length($i)$5){print $i,length($i)}}}' /boot/grub2/grub.cfg switch语句 switch(expression) {case VALUE1 or /REGEXP/: statement; case VALUE2 or /REGEXP2/: statement; ...; default: statement} next awk 内自动按行进行遍历，awk 内的循环主要用来遍历每行内的所有字段，next 是 awk 特有的，用来提前结束 awk 内对本行的处理而直接进入下一行； $ awk -F: '{if($3%2!=0) next; print $1,$3}' /etc/passwd ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:2","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.5 关联数组 array[index-expression] index-expression: 可使用任意字符串；字符串要使用双引号； 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”，如果用于数值运算，默认为 0； 若要判断数组中是否存在某元素，要使用 index in array 格式进行； 若要遍历数组中的每个元素，要使用for循环，注意 for 循环迭代的是下标不是值； for(var in array) {for-body} $ awk 'BEGIN{weekdays[\"mon\"]=\"Monday\";weekdays[\"tue\"]=\"Tuesday\";for(i in weekdays) {print weekdays[i]}}' $ ss -tan|awk '{stat[$1]+=1;}END{for(i in stat){print i,stat[i]}}' $ awk '{ip[$1]++}END{for(i in ip) {print i,ip[i]}}' /var/log/httpd/access_log # 练习1：统计/etc/fstab文件中每个文件系统类型出现的次数； $ awk '/^UUID/{fs[$3]++}END{for(i in fs) {print i,fs[i]}}' /etc/fstab # 练习2：统计指定文件中每个单词出现的次数； $ awk '{for(i=1;i\u003c=NF;i++){count[$i]++}}END{for(i in count) {print i,count[i]}}' /etc/fstab ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:3","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2.6 函数 函数调用使用 function_name(argu1, argu2, ...) 内置函数 数值处理： rand()：返回0和1之间一个随机数； 字符串处理： length([s])：返回指定字符串的长度； sub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其第一次出现替换为s所表示的内容； gsub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其所有出现均替换为s所表示的内容； split(s,a[,r])：以r为分隔符切割字符s，并将切割后的结果保存至a所表示的数组中； $ netstat -tan | awk '/^tcp\\\u003e/{split($5,ip,\":\");count[ip[1]]++}END{for (i in count) {print i,count[i]}}' ","date":"2018-01-24","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:4","tags":["马哥 Linux"],"title":"7.6 awk使用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/awk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"7.5 sed命令应用与实战","date":"2018-01-23","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/","tags":["马哥 Linux"],"title":"7.5 sed命令应用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"sed命令应用与实战 Linux 中有文本处理三剑客 grep, egrep, fgrep：文本过滤器 sed：Stream EDitor，流编辑器，行 awk：文本格式化工具，报告生成器 前面我们已经介绍了grep 命令的使用，本节我们来讲解 sed 。sed 是基于行的文本处理工具，其处理文件使用的命令与 vim 命令行很相似由，地址定界+编辑命令组成，地址定界用于铆定要处理的行，编辑命令指定编辑操作。相比于 vim，sed 无需将整个文本加载至内存，因此 sed 更适用于文件太大而不便使用 vim 打开的情景。本节我们会详细介绍 sed 命令的使用，内容如下: sed 工作原理 sed 命令的使用 ","date":"2018-01-23","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:0:0","tags":["马哥 Linux"],"title":"7.5 sed命令应用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"1. sed 工作原理 如图是 sed 命令工作流程的示意图。sed 有两个专用的内存空间，一个叫模式空间(Pattern Space)，用于暂存地址定界匹配到的行，这些行会被接下来的 Edit 编辑命令编辑；另一个是保持空间(Hold Space)，我的理解是这就是一个临时的交换空间，可以辅助模式空间完成多行处理。我们会在后面详细介绍如何使用保持空间完成一些高级操作。 整个处理过程是。文件按行被读取，如果不能被地址定界所匹配，默认直接输出到标准输出(1)，被匹配的行进入模式空间，被 Edit 编辑命令处理，然后输出到标准所输出(2)。如果指定了原处修改源文件的 -i 选项，原本输出到标准输出的数据流将被重定向到原文件。编辑命令中有个 p 命令，其作用是将匹配到的行复制一遍再一次输出到标准输出(3) 上述过程中，我们描述了(1)(2)(3) 三种输出到标准输出的情况，sed 的 -n 选项可以禁止(1)(2)输出到标准输出。 ","date":"2018-01-23","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:1:0","tags":["马哥 Linux"],"title":"7.5 sed命令应用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"2 sed 使用 sed [OPTION]… ‘script’ [input-file] … 说明: sed 命令由选项和处理文件的 script 脚本组成 options： -n：不输出模式空间中的内容至屏幕，具体控制见原理部分 -f /PATH： 指定包含 script 的文件，逐行执行内部的编辑命令 -r, --regexp-extended：支持使用扩展正则表达式； -i, --in-place：直接编辑原文件 ； -e script：多点编辑,可使用多次，指定多个编辑脚本，文件将按行被每个命令处理； script： 格式: 地址定界+命令，多个命令使用 “;” 隔开 地址定界 位置表示 作用 空地址 对全文进行处理 # 数字，指定行 #,# 指定行范围，从哪一行开始，哪一行结束 #,+# 从哪一行开始，往下几行；例如：3,+7 $ 最后一行，要使用 ’’ 引用 script，否则 $ 会解释为引用变量值 1,$ 第一行到最后一行 /pattern/ 被此模式所匹配到的每一行 /pat1/,/pat2/ 第一次由pat1匹配到的行，至第一次由pat2匹配到的行之间的所有行 #，/pat1/ # 指定的行到/pat1/匹配到的第一行之间的行 a～b 步进,从 a 行开始，每隔 b 取一行 1~2 所有奇数行 2~2 所有偶数行 编辑命令： d：删除模式空间中的内容 p：额外显示模式空间中的内容； a \\text：在匹配行后面追加文本“text”，支持使用\\n实现多行追加； i \\text：在匹配行前面插入文本“text”，支持使用\\n实现多行插入； c \\text：把匹配到的行替换为此处指定的文本“text”； w /PATH：保存模式空间匹配到的行至指定的文件中； r /PATH：读取指定文件的内容至当前文件被模式匹配到的行后面；文件合并； eg: sed '6r /home/tao/log.csv' /etc/fstab =：为模式匹配到的行打印行号； !：条件取反；位于编辑命令之前，表示地址定界之前的行 格式: 地址定界!编辑命令； eg: sed '/^UUID/!d' /etc/fstab s///：查找替换，其分隔符可自行指定，常用的有s@@@, s###等； 替换标记： g：全局替换； w /PATH/TO/SOMEFILE：将替换成功的结果保存至指定文件中； p：显示替换成功的行； eg: sed '/^UUID/s/UUID/uuid/g' /etc/fstab sed 's@r..t@\u0026er@' /etc/passwd – \u0026 后项引用前面匹配到的内容 sed 's@r..t@\u0026er@p' /etc/passwd – 仅仅打印被替换的行 结合保持空间的高级编辑命令 命令 作用 h 把模式空间中的内容覆盖至保持空间中 H 把模式空间中的内容追加至保持空间中 g 把保持空间中的内容覆盖至模式空间中 G 把保持空间中的内容追加至模式空间中 x 把模式空间中的内容与保持空间中的内容互换 n 覆盖读取匹配到的行的下一行至模式空间中 N 追加读取匹配到的行的下一行至模式空间中 d 删除模式空间中的行 D 删除多行模式空间中的所有行 sed 多点编辑的执行逻辑 # 输出第二行内容 \u003e sed -n -r '6p' fstab \u003e # Accessible filesystems, by reference, are maintained under '/dev/disk' # 对第六行执行替换，但是 -n 禁止了输出 \u003e sed -r -n -e '6s/Access/aaaa/' fstab \u003e # 第六行被第一个 script 执行了替换，替换后的内容被第二个 script 输出 \u003e sed -r -n -e '6s/Access/aaaa/' -e '6p' fstab \u003e # aaaaible filesystems, by reference, are maintained under '/dev/disk' ","date":"2018-01-23","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:2:0","tags":["马哥 Linux"],"title":"7.5 sed命令应用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"3. 示例： 普通用法示例 # 删除/boot/grub/grub2.cfg文件中所有以空白字符开头的行的行首的所有空白字符； \u003e sed 's@^[[:space:]]\\+@@' /etc/grub2.cfg # 删除/etc/fstab文件中所有以#开头的行的行首的#号及#后面的所有空白字符； \u003e sed 's@^#[[:space:]]*@@' /etc/fstab # 输出一个绝对路径给sed命令，取出其目录，其行为类似于dirname； \u003e echo \"/var/log/messages/\" | sed 's@[^/]\\+/\\?$@@' \u003e echo \"/var/log/messages\" | sed -r 's@[^/]+/?$@@' 使用保持空间的高级示例 sed -n 'n;p' FILE：显示偶数行； sed '1!G;h;$!d' FILE：逆序显示文件的内容； sed ’$!d' FILE：取出最后一行； sed '$!N;$!D' FILE：取出文件后两行； sed '/^$/d;G' FILE：删除原有的所有空白行，而后为所有的非空白行后添加一个空白行； sed 'n;d' FILE：显示奇数行； sed 'G' FILE：在原有的每行后方添加一个空白行； sed -n '1!G;h;$p': 逆序显示文件的内容； ","date":"2018-01-23","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/:3:0","tags":["马哥 Linux"],"title":"7.5 sed命令应用与实战","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/sed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98/"},{"categories":["Linux"],"content":"7.4 文本处理命令","date":"2018-01-22","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"7.4 文本处理命令","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"文本处理命令 ","date":"2018-01-22","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"7.4 文本处理命令","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 文本处理工具 tr tr [OPTION]... SET1 [SET2] 作用: 将输入中 SET1中的每个字符替换SET2中的每个字符，字符是顺序替换 如果SET1的字符长度大于SET2，那么将SET1中多出来的字符用SET2中的最后一个字符替换 参数: -t: 将SET2中的每个字符替换SET1中的每个字符，字符字符顺序1对1替换，无论SET1还是SET2哪个长，只替换对应的字符，多出的不替换。 -c: 取反操作，取数据流中SET1中指定字符的补集。 -d: 删除SET1中指定的字符，这里没有SET2 -s: 将SET1中指定的连续的连续重复的字符用单个字符替代，可以使用-s ‘\\n’删除空行。 字符编码集: [:alpha:]：字母，可以用来替代’a-zA-Z’ [:lower:]：小写字母,可以用来替代’a-z' [:upper:]：大写字母,可以用来替代’A-Z' [:digit:]：数字,可以用来替代'0-9' [:alnum:]：字母和数字,可以用来替代’a-zA-Z0-9' [:space:]：空白字符 [:punct:]：标点符号 [:xdigit:]：十六进制字符 [:cntrl:]：控制（非打印）字符 [:print:]：可打印字符 [:graph:]：图形字符 wc wc [-clw] [FILE...] 作用: 用于计算字数，可以计算文件的Byte数、字数、或是列数 若不指定文件名称、或是所给予的文件名为\"-\"，则wc指令会从标准输入设备读取数据 参数: -c, --bytes, --chars; 只显示Bytes数。 -l, --lines: 只显示行数。 -w, --words: 只显示单词数 cut cut [-df] [file] 作用: 从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出 参数： -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示的区域，表示方式如下: n：指定的单个字段 n-m：连续的多个字段 n,m：离散的多个字段 -c ：以字符为单位进行分割 eg: cut -d: -f1,3-5,7 /etc/passwd sort sort [-frtknu] [file] 作用: 针对文本文件的内容，以行为单位来排序 参数: -t: 指定分隔符 -k POS1[,POS2]: 用于排序比较的字段 -f: 排序时，忽略大小写 -r: 逆序排序 -n: 基于数值大小而非字符进行排序 -u: 排序并去重 -b: 忽略每行前面开始出的空格字符 -c: 检查文件是否已经按照顺序排序。 -d: 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -m: 将几个排序好的文件进行合并 -o: 将排序后的结果存入指定的文件 uniq uniq [-cdufsw][输入文件][输出文件] 作用: 检查文本文件中重复出现的行列 只有连续且一致的行才算重复行 参数: -c,--count: 显示每行的重复次数 -d, --repeated: 仅显示重复过的的行 -u, --unique: 仅显示未曾重复过的行 diff 和 patch diff [OPTION]... FILES 作用: 按行比较文件 选项: -u: 使用unfied机制，即显示要修改的行的上下文，默认为3行； 补丁: diff /PATH/TO/OLDFILE /PATH/TO/NEWFILE \u003e /PATH/TO/PATCH_FILE patch -i /PATH/TO/PATCH_FILE /PATH/TO/OLDFILE patch /PATH/TO/OLDFILE \u003c /PATH/TO/PATCH_FILE 作用: 向文件打补丁 patch -R /PATH/TO/PATCH_FILE /PATH/TO/OLDFILE 作用: 撤消补丁 ","date":"2018-01-22","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"7.4 文本处理命令","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"7.3 grep命令与正则表达式","date":"2018-01-21","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","tags":["马哥 Linux"],"title":"7.3 grep命令与正则表达式","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Linux"],"content":"grep命令与正则表达式 Linux 中有文本处理三剑客grep,sed,awk，它们都会用到正则表达式。bash 中正则表达式分为基础正则表达式和扩展的正则表达式。本节我们来学习 grep 命令与基本的正则表达式。 ","date":"2018-01-21","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:0:0","tags":["马哥 Linux"],"title":"7.3 grep命令与正则表达式","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Linux"],"content":"1. grep grep 存在一组相关命令 grep: 支持基本的正则表达式 == grep -G egrep: 支持扩展的正则表达式 == grep -E fgrep: 不支持正则表达式，匹配速度快 == grep -F，无须转义 grep [-acinvAB] pattern filename -o：仅显示匹配到字符串本身 -a：将 binary 文件已 text 文件的方式查找数据 -c：计算找到\"查找字符串\" 的次数 -i：忽略大小写 -n：输出行号 -v：反向匹配 -q：静默模式，不输出匹配的文本，通过 echo $? 获取是否匹配成功 -A：after，后接数字，列出匹配行及之后 n 行 -B：before，后接数字，列出匹配行及之前 n 行 -C：context，上下文，列出匹配前后各 n 行 --color=auto：将找到的关键词高亮显示 ","date":"2018-01-21","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:1:0","tags":["马哥 Linux"],"title":"7.3 grep命令与正则表达式","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Linux"],"content":"2. 基础正则表达式 基础正则表达式大致上可以分为四类: 字符匹配 匹配次数 位置锚定 分组及引用 需要额外说明的是下面的\\转义符是必须的，因为这些元字符在 bash 中有特殊含义，需要转义。 字符匹配 元字符 作用 . 匹配任意单个字符 [] 匹配指定范围内的任意单个字符 [^] 匹配指定范围外的任意单个字符 [[:digit:]] 数字 [[:lower:]] 小写字母 [[:upper:]] 大写字母 [[:alpha:]] 字母 [[:alnum:]] 数字+字母 [[:punct:]] 特殊符号 [[:space:]] 空白字符 匹配次数 用在要指定其出现的次数的字符的后面，用于限制其前面字符出现的次数；默认工作于贪婪模式； 元字符 作用 * 匹配其前面的字符任意次；0,1,多次 .* 匹配任意长度的任意字 \\? 匹配其前面的字符0次或1次；即其前面的字符是可有可无的 \\+ 匹配其前面的字符1次或多次；即其面的字符要出现至少1次 \\{m\\} 匹配其前面的字符m次 \\{m,n\\} 匹配其前面的字符至少m次，至多n次 \\{0,n\\} 至多n次 \\{m,\\} 至少m次 位置锚定 匹配单词或句子的首部或尾部 元字符 作用 ^ 行首锚定；用于模式的最左侧 $ 行尾锚定；用于模式的最右侧 ^PATTERN$ 用于PATTERN来匹配整行 ^$ 匹配空白行 ^[[:space:]]*$ 空行或包含空白字符的行 \\\u003c 或 \\b 词首锚定，用于单词模式的左侧 \\\u003e 或 \\b 词尾锚定，用于单词模式的右侧 \\\u003cPATTERN\\\u003e 匹配完整单词 分组及引用 \\(\\): 将一个或多个字符捆绑在一起，当作一个整体进行处理 分组括号中的模式匹配到的内容会被正则表达式引擎自动记录于内部的变量中，比如： \\1：表示模式从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \\2：表示模式从左侧起，第二个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \\n：其他一次类推，这种引用前面的分组括号中的模式所匹配到的字符叫做后向引用 练习： # 显示/etc/passwd文件中不以/bin/bash结尾的行； \u003e grep -v \"/bin/bash$\" /etc/passwd # 找出/etc/passwd文件中的两位数或三位数； \u003e grep \"\\\u003c[0-9]\\{2,3\\}\\\u003e\" /etc/passwd # 找出/etc/rc.d/rc.sysinit或/etc/grub2.cfg文件中，以至少一个空白字符开头，且后面非空白字符的行； \u003e grep \"^[[:space:]]\\+[^[:space:]]\" /etc/grub2.cfg # 找出\"netstat -tan\"命令的结果中以'LISTEN'后跟0、1或多个空白字符结尾的行； \u003e netstat -tan | grep \"LISTEN[[:space:]]*$\" \u003e vim a.txt He loves his lover. He likes his lover. She likes her liker. She loves her liker. \u003e grep \"\\(l..e\\).*\\1\" a.txt He loves his lover. She likes her liker. ","date":"2018-01-21","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:2:0","tags":["马哥 Linux"],"title":"7.3 grep命令与正则表达式","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Linux"],"content":"3. 扩展正则表达式 扩展正则表达式与基本正则表达式主要有两点区别 不需要额外的转义符\\,词首词尾锚定仍为 \\\u003c,\\\u003e, \\b 支持 | 表示或 a|b：a或者b； C|cat：C或cat (c|C)at：cat或Cat # 练习： # 1. 找出/proc/meminfo文件中，所有以大写或小写S开头的行；至少有三种实现方式； \u003e grep -i \"^s\" /proc/meminfo \u003e grep \"^[sS]\" /proc/meminfo \u003e grep -E \"^(s|S)\" /proc/meminfo # 2. 显示肖前系统上root、centos或user1用户的相关信息； \u003e grep -E \"^(root|centos|user1)\\\u003e\" /etc/passwd # 3. 找出/etc/rc.d/init.d/functions文件中某单词后面跟一个小括号的行； \u003e grep -E -o \"[_[:alnum:]]+\\(\\)\" /etc/rc.d/init.d/functions # 4. 使用echo命令输出一绝对路径，使用egrep取出基名； \u003e echo /etc/sysconfig/ | grep -E -o \"[^/]+/?$\" # 5. 进一步：取出其路径名；类似于对其执行dirname命令的结果； # 6. 找出ifconfig命令结果中的1-255之间的数值； \u003e ifconfig | grep -E -o \"\\\u003c([1-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\\u003e\" # 7. 课外作业：找出ifconfig命令结果中的IP地址； # 8. 添加用户bash, testbash, basher以及nologin(其shell为/sbin/nologin)；找出/etc/passwd文件中用户名同shell名的行； \u003e grep -E \"^([^:]+\\\u003e).*\\1$\" /etc/passwd ","date":"2018-01-21","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/:3:0","tags":["马哥 Linux"],"title":"7.3 grep命令与正则表达式","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/grep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"categories":["Python"],"content":"Python 类元编程","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"本章内容: 类工厂 元类 exec 函数 类装饰器 导入时和运行时 类作为对象 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:0:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"1. 对象之间的关系 元类: 定义: 创建类的类，类是元类的实例 特性: 超类的元类会被子类继承，因此元类可以定制类的层次结构 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:1:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"1.1 类，object，type: 类的角度: 所有类包括 type 都是 object 类的子类 实例角度: Python 中大多数内置的类和用户定义的类都是 type 类的实例，包括 type 和 object object 与 type: object 是 type 的实例，而 type 是 object 的子类 type 是自身的实例 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:1:1","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"1.2 元类与type 所有类都直接或间接地是 type 的实例 只有元类同时也是 type 的子类，从 type 类继承了构建类的能力(如ABCMeta) \u003e\u003e\u003e import collections \u003e\u003e\u003e collections.Iterable.__class__ # 所有抽象基类的元类都是 abc.ABCMeta \u003cclass 'abc.ABCMeta'\u003e \u003e\u003e\u003e import abc \u003e\u003e\u003e abc.ABCMeta.__class__ \u003cclass 'type'\u003e \u003e\u003e\u003e abc.ABCMeta.__mro__ (\u003cclass 'abc.ABCMeta'\u003e, \u003cclass 'type'\u003e, \u003cclass 'object'\u003e) ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:1:2","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"2. 元类的使用 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:2:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"2.1 type 作为函数: 调用 type(my_object)，获取对象所属的类，与 my_object.__class__ 相同 作为类: 调用 type(name,bases,dict) 可以新建一个类 name: 类的名称 base: 超类的元组 dict: 字典，指定新类的属性名和值 # 以下创建类的效果等同 MyClass = type('MyClass', (MySuperClass, MyMixin), {'x': 42, 'x2': lambda self: self.x * 2}) class MyClass(MySuperClass, MyMixin): x = 42 def x2(self): return self.x * 2 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:2:1","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"2.2 自定义元类 # 定义元类 class EntityMeta(type): \"\"\"Metaclass for business entities with validated fields\"\"\" @classmethod def __prepare__(cls, name, bases): return collections.OrderedDict() # \u003c1\u003e def __init__(cls, name, bases, attr_dict): super().__init__(name, bases, attr_dict) cls._field_names = [] for key, attr in attr_dict.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) cls._field_names.append(key) # \u003c4\u003e # 使用元类 class Entity(metaclass=EntityMeta): \"\"\"Business entity with validated fields\"\"\" @classmethod def field_names(cls): # \u003c5\u003e for name in cls._field_names: yield name # 使用元类 class LineItem(Entity): description = model.NonBlank() weight = model.Quantity() price = model.Quantity() __prepare__ 方法详见下 元类继承自 type 类 元类初始化参数: cls: 要初始化的类对象 name、bases、dic: 与构建类时传给 type 的参数相同 把类链接到元类: Python3 中使用 class Entity(metaclass=EntityMeta) Pytohn2 中使用 __metaclass__ = EntityMeta ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:2:2","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"2.3 特殊方法__prepare__ __prepare__(cls, name, bases): 版本: Python3 目的: 知道类的属性定义的顺序 背景: type 构造方法及元类的 __new__ 和 __init__ 方法都会收到类属性名到值的映射 但是映射是字典；也就是说，元类或类装饰器获得映射时，属性在类定义体中的顺序已经丢失了 调用: 解释器调用元类的 __new__ 方法之前会先调用 __prepare__ 方法 元类构建新类时，__prepare__ 返回的映射会传给 __new__ 再传给 __init__ 解释器会在 __prepare__ 返回的映射中填充类属性 语法: 这个特殊方法只在元类中有用 而且必须声明为类方法(即，要使用 @classmethod 装饰器定义) 参数: cls: 元类 name: 类的名称 bases: 基类组成的元组 返回: 必须是映射 实例: 见上 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:2:3","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"3. 类工厂函数 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:3:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"3.1 type def record_factory(cls_name, field_names): try: field_names = field_names.replace(',', ' ').split() # \u003c1\u003e except AttributeError: # no .replace or .split pass # assume it's already a sequence of identifiers field_names = tuple(field_names) # \u003c2\u003e def __init__(self, *args, **kwargs): # \u003c3\u003e attrs = dict(zip(self.__slots__, args)) attrs.update(kwargs) for name, value in attrs.items(): setattr(self, name, value) def __iter__(self): # \u003c4\u003e for name in self.__slots__: yield getattr(self, name) def __repr__(self): # \u003c5\u003e values = ', '.join('{}={!r}'.format(*i) for i in zip(self.__slots__, self)) return '{}({})'.format(self.__class__.__name__, values) cls_attrs = dict(__slots__ = field_names, # \u003c6\u003e __init__ = __init__, __iter__ = __iter__, __repr__ = __repr__) return type(cls_name, (object,), cls_attrs) # \u003c7\u003e ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:3:1","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"3.2 exec collections.namedtuple 实现 实现: 使用了 exec 函数 目的: 为了让生成的类代码能通过 ._source 属性获取 文档: https://hg.python.org/cpython/file/3.4/Lib/collections/__init__.py#l236 https://docs.python.org/3/library/collections.html#collections.somenamedtuple._source 方法: 先声明一个 _class_template 变量，其值是字符串形式的源码模板； 然后在 namedtuple 函数中调用 _class_template.format(…) 方法，填充模板里的空白； 最后，使用内置的 exec 函数计算得到的源码字符串 exec(eval) 缺点: 如果接收的字符串(或片段)来自不可信的源，那么会带来严重的安全风险 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:3:2","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"4. 类装饰器 类装饰器 定义: 参数为类对象的函数，返回原来的类或修改后的类 作用: 创建类时定制类 缺点: 只对直接依附的类有效 被装饰的类的子类可能继承,也可能不继承装饰器所做的改动，具体情况视改动的方式而定 def entity(cls): for key, attr in cls.__dict__.items(): if isinstance(attr, Validated): type_name = type(attr).__name__ attr.storage_name = '_{}#{}'.format(type_name, key) # \u003c4\u003e return cls @model.entity class LineItem: description = model.NonBlank() weight = model.Quantity() price = model.Quantity() ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:4:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"5. 导入时与运行时 Python 解释器什么时候计算各个代码块 导入时，解释器会从上到下一次性解析完 .py 模块的源码，然后生成用于执行的字节码。如果句法有错误，就在此时报告。 如果本地的 __pycache__ 文件夹中有最新的 .pyc 文件，解释器会跳过上述步骤，因为已经有运行所需的字节码 import语句，它不只是声明，在进程中首次导入模块时，还会运行所导入模块中的全部顶层代码 —— 以后导入相同的模块则使用缓存，只做名称绑定 模块中的顶层代码可以做任何事，包括通常在\"运行时\"做的事，例如连接数据库 因此，“导入时\"与\"运行时\"之间的界线是模糊的: import 语句可以触发任何\"运行时\"行为 函数: 导入模块时，解释器会执行顶层的 def 语句，编译函数的定义体，把函数对象绑定到对应的全局名称上， 但不会执行函数的定义体 意味着解释器在导入时定义顶层函数，但是仅当在运行时调用函数时才会执行函数的定义体 类: 解释器会执行每个类的定义体，甚至会执行嵌套类的定义体。 执行类定义体的结果是，定义了类的属性和方法，并构建了类对象。 从这个意义上理解，类的定义体属于\"顶层代码”，因为它在导入时运行 解释器先计算类的定义体，然后调用依附在类上的装饰器函数 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:5:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"6. 类作为对象 文档: https://docs.python.org/3/library/stdtypes.html#special-attributes cls.__bases__ 值: 由类的基类组成的元组 cls.__qualname__ Python 3.3 新引入的属性 值: 类或函数的限定名称，即从模块的全局作用域到类的点分路径 文档: PEP 3155—Qualified name for classes and functions https://www.python.org/dev/peps/pep-3155/ cls.__subclasses__() 返回一个列表，包含内存里现存的子类 实现: 使用弱引用，防止在超类和子类之间出现循环引用 附注: 子类在 __bases__ 属性中储存指向超类的强引用 cls.mro() 构建类时，如果需要获取储存在类属性 __mro__ 中的超类元组，解释器会调用这个方法 元类可以覆盖这个方法，定制要构建的类解析方法的顺序 cls.__init_subclass__() 作用: 让普通的类(即，不是元类)定制子类的初始化 版本: Python36 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:6:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:7:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"Python: Customizing class creation https://docs.python.org/3/reference/datamodel.html#metaclasses type 类 https://docs.python.org/3/library/functions.html#type Special Attributes https://docs.python.org/3/library/stdtypes.html#special-attributes types 模块 https://docs.python.org/3/library/types.html 说明了 Python3.3 引入的两个新函数，这两个函数用于辅助类元编程: types.new_class(…) types.prepare_class(…) Class Decorators https://www.python.org/dev/peps/pep-3129/ __prepare__ - PEP 3115—Metaclasses in Python3000 - https://www.python.org/dev/peps/pep-3115/ __init_subclass__ 作用: 让普通的类(即，不是元类)定制子类的初始化 版本: Python36 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:7:1","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"blog: Class Decorators: Radically Simple 的演讲 https://www.youtube.com/watch?v=cAGliEJV9_o Meta-classes Made Easy: Eliminating self with Metaclasses 副标题(“借助元类去掉 self”) http://www.voidspace.org.uk/python/articles/metaclasses.shtml Unifying types and classes in Python 2.2 https://www.python.org/download/releases/2.2.3/descrintro/ 这篇文章也适用于 Python 3，谈到了后来称为\"新式类\"的语义，包括描述符和元类 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:7:2","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"实用工具 MacroPy https://github.com/lihaoyi/macropy ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:7:3","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"书籍: 《 Python 技术手册(第2版)》 《 Python Cookbook(第 3 版)中文版》 《Putting Metaclasses to Work: a New Dimension in Object-Oriented Programming》 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:7:4","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Python"],"content":"附注 Python 把函数当作一等对象，这为高阶函数铺平了道路。 描述符和高阶函数合在一起实现，使得函数和方法的统一成为可能。 函数的 __get__ 方法能即时生成方法对象，把实例绑定到 self 参数上。这种做法相当优雅 ","date":"2018-01-21","objectID":"/posts/program/python/grammar/fluent-python/21_prepare/:8:0","tags":["python 进阶"],"title":"类元编程","uri":"/posts/program/python/grammar/fluent-python/21_prepare/"},{"categories":["Linux"],"content":"7.2 文件查找工具","date":"2018-01-20","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/","tags":["马哥 Linux"],"title":"7.2 文件查找工具","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"文件查找工具 本节我们学习文件查找工具，主要是两个命令的使用 locate，find。 ","date":"2018-01-20","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/:0:0","tags":["马哥 Linux"],"title":"7.2 文件查找工具","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"1. locate locate [OPTION]... PATTERN... 作用: 依赖于事先构建好的索引库；查找指定模式匹配的文件 规则: 默认使用 pattern 进行全路径模糊匹配 参数: PATTERN: 匹配规则，可多个 选项: -a：所有 pattern 的匹配规则必须同时满足 -b：只匹配路径中的基名，默认匹配整个路径； -c：统计出共有多少个符合条件的文件 -r：使用基本正则表达式进行匹配 特性： 查找速度快； 模糊查找； 非实时查找； updatedb: 作用: 构建 locate 所需的数据库(耗费资源) 附注: 索引构建过程需要遍历整个根文件系统，极消耗资源； ","date":"2018-01-20","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/:1:0","tags":["马哥 Linux"],"title":"7.2 文件查找工具","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"2. find find [OPTION]... [查找起始路径] [查找条件] [处理动作] 查找起始路径：指定具体搜索目标起始路径；默认为当前目录； 查找条件：指定的查找标准，可以根据文件名、大小、类型、从属关系、权限等等标准进行；默认为找出指定路径下的所有文件； 处理动作：对符合查找条件的文件做出的操作，例如删除等操作；默认为输出至标准输出； 查找条件 find 的查找条件可以通过选型或测试进行指定，较为常用的是测试，有如下几种测试条件 文件名: -name \"pattern\": 支持使用通配符，仅仅匹配文件名称，必须是完全匹配文件名而不是部分匹配 -iname \"pattern\": 忽略名称大小，必须是完整匹配文件名 -regex pattern: 使用正则表达式，必须完整匹配整个文件路径，不仅仅是文件名称 根据属主，属组 -user username: 查找属主为指定用户的文件 -group groupname: 查找属组为指定组的文件 -uid userid: 查找属主为指定 uid 的文件 -gid groupid: 查找属组为指定 gid 的文件 -nouser: 查找没有属主的文件 -nogroup: 查找没有属组的文件 eg: find /tmp -user root -ls 根据文件类型查找 -type TYPE: 查找指定类型的文件 f: 普通文件 d: 目录文件 l：符号链接文件 b：块设备 文件 c：字符设备文件 p：管道文件 s：套接字文件 组合条件 -a : and -o : or -not|！ : not eg： find /tmp \\( -nouser -o -nogroup \\) -ls find /tmp -nouser -ls -o -nogoroup -ls find /tmp \\( -not -user root -a -not -name \"fstab\" \\) -ls 附注: 处理动作仅限于位置相关的查找 文件大小 -size [+|-]#UNIT: UNIT: 查找单位，k，M，G eg: find /var -size +3k -exec ls -h {} \\ 3k: 表示范围为 (2k, 3k] -3k: 表示范围为 [0, 2k] +3k: 表示范围为 (3k, ∞) 根据时间戳 以天为单位 -atime [+|-]# -mtime [+|-]# -ctime [+|-]# eg: find /var -atime 3 -ls 3: 表示[3, 4) +3 表示[4, ∞) -3 表示[0, 3） 以分钟为单位 -amin [+|-]# -mmin [+|-]# -cmin [+|-]# 根据权限查找 -perm [/|-]MODE eg: find /var -perm 640 -ls 640: 精确查找，0表示不考虑 /640: 任何一类用户(u,g,o)的权限中的任何一位(r,w,x)符合条件即满足，9位权限之间存在“或”关系； -640: 每一类用户(u,g,o)的权限中的每一位(r,w,x)同时符合条件即满足，9位权限之间存在“与”关系； 处理动作 -print: 默认动作，显示至屏幕 -ls: 类似对查找的文件执行 ls -l 命令 -delete: 删除查到到的文件 -fls /path: 查找到的所有文件的长格式信息保存至指定文件中 -ok COMMAND {} \\; 对查找到的每个文件执行由 COMMAND指定的命令 对每个文件执行命令之前，都会交互式确认 {}：表示find 传递的文件名本身 ;:固定格式符 exec COMMAND {} \\;:作用同 ok,但不会交互式确认 eg: find /tmp -nouser -exec chown root {} ; find /tmp -cmin -5 -exec mv {} {}.new ; {}：表示find 传递的文件名本身 需要注意的是 find 传递查找到的文件路径至后面的命令时，是先查找出所有符合条件的文件路径，并一次性传递给后面的命令；但是有些命令不能接受过长的参数，此时命令执行会失败；使用 find | xargs COMMAND 可规避此问题。xargs 命令可将参数一次一个传递给 COMMAND。 ","date":"2018-01-20","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/:2:0","tags":["马哥 Linux"],"title":"7.2 文件查找工具","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/"},{"categories":["Linux"],"content":"3. 练习 # 查找/var/目录属主为root且属组为mail的所有文件； \u003e find /var -user root -a -group mail # 查找/usr目录下不属于root、bin或hadoop的所用文件； \u003e find /usr -not -user root -a -not -user bin -a -not -user hadoop \u003e find /usr -not \\(-user root -o -user bin -o -user hadoop\\) # 查找/etc/目录下最近一周内其内容修改过的，且不属于root且不属于hadoop的文件； \u003e find /etc -mtime -7 -a -not \\(-user root -o -user hadoop\\) # 查找当前系统上没有属主或属组，且最近1个月内曾被访问过的文件； \u003e find / \\(-nouser -o -nogroup\\) -a -atime -30 # 查找/etc/目录下大于1M且类型为普通文件的所有文件； \u003e find /etc -size +1M -type f # 查找/etc/目录所有用户都没有写权限的文件； \u003e find /etc/ -not -perm /222 # 查找/etc/目录下至少有一类用户没有写权限； \u003e find /etc/ -not -perm -222 # 查找/etc/init.d/目录下，所有用户都有执行权限且其它用户有写权限的文件； \u003e find /etc/init.d/ -perm -113 ","date":"2018-01-20","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/:3:0","tags":["马哥 Linux"],"title":"7.2 文件查找工具","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7/"},{"categories":["Python"],"content":"Python 属性描述符","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"本章内容 描述符协议 描述符与属性覆盖 方法与特性 描述符使用建议 描述符使用示例 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:0:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1. 描述符与描述符协议 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1.1 描述符概述 定义: 是实现了特定协议的类 – 描述符协议 作用: 管理数据属性，是对多个属性运用相同存取逻辑的一种方式 用法: 创建一个描述符类实例，作为另一个类的类属性 应用: property 类，方法， classmethod，staticmethod 装饰器等 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:1","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1.2 相关名词 |名词|定义|示例| |: —|: —|: —| |描述符类|实现描述符协议的类|Quantity 类| |托管类|把描述符实例声明为类属性的类|LineItem 类 |描述符实例|描述符类的各个实例，声明为托管类的类属性|| |托管实例|托管类的实例|LineItem 实例是托管实例| |储存属性|托管实例中存储自身托管属性的属性(存储着实际值的属性) 与描述符属性不同，描述符属性都是类属性|| |托管属性|托管类中由描述符实例处理的公开属性 值存储在储存属性中 描述符实例和储存属性为托管属性建立了基础|..| ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:2","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1.3 描述符协议 __get__(self, instance, owner): 调用: 通过托管类或托管实例获取属性时调用 参数: self: 描述符实例 instance: 托管实例,通过托管类调用时为None owner: 托管类 特性: 如果 __set__ 方法同时存在，会覆盖对实例属性的读值操作 如果 __set__ 方法不存在，无法覆盖对实例属性的读值操作 会覆盖对类属性的读值操作 __set__(self, instance, value): 调用: 为托管属性赋值时调用 作用: 把值存储在托管实例中 参数: self: 描述符实例 – 描述符会成为类属性为所有实例共享 instance: 托管实例 – 应该把值存储在托管实例中 value: 要设定的值 特性: 能覆盖对实例属性的赋值操作 无法覆盖对类属性的赋值操作 __delete__ 调用: 删除托管属性时调用 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:3","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1.4 描述符与属性覆盖 描述符与实例属性 描述符分类: 依据: 是否定义 __set__ 方法，描述符分为非覆盖性描述符和覆盖性描述符 覆盖性描述 - A 没有__get__方法的覆盖型描述符 - B 非覆盖性描述符 - C 附注: 覆盖型描述符也叫数据描述符或强制描述符 非覆盖型描述符也叫非数据描述符或遮盖型描述符 |描述符分类|实现方法|属性覆盖顺序| |: —|: —|: —| |A|__get__ __set__|描述符会同时覆盖实例属性的读值和赋值操作| |B|__set__|会覆盖实例属性的赋值操作 存在同名实例属性时读操作返回实例属性，因为描述符是类属性 不存在同名实例属性时，读值操作返回作为类属性的描述符实例本身 只能直接通过实例的__dict__ 属性创建同名实例属性| |C|__get__|描述符会被同名的实例属性覆盖，属性的读值和赋值操作不会经描述符处理| 描述符与类属性 读类属性的操作可以由依附在托管类上定义有 __get__ 方法的描述符处理 写类属性的操作不会由依附在托管类上定义有 __set__ 方法的描述符处理 类上的描述符无法控制为类属性赋值的操作，为类属性赋值会覆盖描述符 若想控制设置类属性的操作，要把描述符依附在类的类上，即依附在元类上 默认情况下，对用户定义的类来说，其元类是 type，不能为 type 添加属性，但可以自定义元类 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:4","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"1.5 特性工厂函数与描述符类比较 描述符类: 代码复用: 可以使用子类扩展 状态保持: 在类属性和实例属性中保持状态更易于理解 代码逻辑: 描述符涉及了复杂的对象关系，和对象传递，如 self，instance 参数 特性工厂函数: 代码复用: 函数中的代码很难复用 状态保持: 使用函数属性和闭包保持状态，难以理解 代码逻辑: 特性工厂函数的代码不依赖奇怪的对象关系，容易理解 结论: 从某种程度上来讲，特性工厂函数模式较简单，描述符类方式更易扩展，而且应用也更广泛 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:1:5","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"2. 方法和特性 方法: 原理: 用户定义的函数都有 __get__ 方法，所以依附到类上时，就相当于描述符 函数没有实现 __set__ 方法，因此是非覆盖型描述符 定义: 在类中定义的函数属于绑定方法（bound method） 返回: 通过托管类访问时，函数的 __get__ 方法会返回自身的引用 通过实例访问时，函数的 __get__ 方法返回的是绑定方法对象: 一种可调用的对象 self 隐式绑定: 绑定方法的 __self__ 属性是调用这个方法的实例的引用 绑定方法的 __func__ 属性是依附在托管类上那个原始函数的引用 绑定方法对象还有个 __call__ 方法，用于处理真正的调用过程 __call__ 会调用 __func__ 引用的原始函数，把函数的第一个参数设为绑定方法的 __self__ 属性 import collections class Text(collections.UserString): def __repr__(self): return 'Text({!r})'.format(self.data) def reverse(self): return self[: : -1] \u003e\u003e\u003e word = Text('forward') \u003e\u003e\u003e word ➊ Text('forward') \u003e\u003e\u003e word.reverse() ➋ Text('drawrof') \u003e\u003e\u003e Text.reverse(Text('backward')) ➌ Text('drawkcab') \u003e\u003e\u003e type(Text.reverse), type(word.reverse) ➍ (\u003cclass 'function'\u003e, \u003cclass 'method'\u003e) \u003e\u003e\u003e list(map(Text.reverse, ['repaid', (10, 20, 30), Text('stressed')])) ➎ ['diaper', (30, 20, 10), Text('desserts')] \u003e\u003e\u003e Text.reverse.__get__(word) ➏ \u003cbound method Text.reverse of Text('forward')\u003e \u003e\u003e\u003e Text.reverse.__get__(None, Text) ➐ \u003cfunction Text.reverse at 0x101244e18\u003e \u003e\u003e\u003e word.reverse ➑ \u003cbound method Text.reverse of Text('forward')\u003e \u003e\u003e\u003e word.reverse.__self__ ➒ Text('forward') \u003e\u003e\u003e word.reverse.__func__ is Text.reverse ➓ True 示例分析: ➎ Text.reverse 相当于函数，甚至可以处理 Text 实例之外的其他对象 ➏ 函数是非覆盖型描述符,在函数上调用 __get__ 方法时传入实例，得到的是绑定到那个实例上的方法 ➐ 调用函数的 __get__ 方法时，如果 instance 参数的值是 None，那么得到的是函数本身 特性: 特性是覆盖型描述符 如果没提供设值函数，property 类的 __set__ 方法会抛出 AttributeError 异常，指明属性是只读的 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:2:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"3. 描述符用法建议 使用特性以保持简单 内置的 property 类创建的其实是覆盖型描述符 __set__ 方法和 __get__ 方法都实现了，即便不定义设值方法也是如此 特性的 __set__ 方法默认抛出 AttributeError: can’t set attribute 因此创建只读属性最简单的方式是使用特性，这能避免下一条所述的问题 只读描述符必须有 __set__ 方法 如果使用描述符类实现只读属性，要记住， __get__ 和 __set__ 两个方法必须都定义 否则，实例的同名属性会遮盖描述符 只读属性的 __set__ 方法只需抛出 AttributeError 异常，并提供合适的错误消息 用于验证的描述符可以只有 __set__ 方法 对仅用于验证的描述符来说， __set__ 方法应该检查 value 参数获得的值 如果有效，使用描述符实例的名称为键，直接在实例的 __dict__ 属性中设置 从实例中读取同名属性的速度很快，因为不用经过 __get__ 方法处理 仅有 __get__ 方法的描述符可以实现高效缓存 如果只编写了 __get__ 方法，那么创建的是非覆盖型描述符 这种描述符可用于执行某些耗费资源的计算，然后为实例设置同名属性，缓存结果 同名实例属性会遮盖描述符，因此后续访问会直接从实例的 __dict__ 属性中获取值， 而不会再触发描述符的 __get__ 方法 非特殊的方法可以被实例属性遮盖 由于函数和方法只实现了 __get__ 方法，它们不会处理同名实例属性的赋值操作 同名实例属性会遮盖函数和方法，然而，特殊方法不受这个问题的影响 解释器只会在类中寻找特殊的方法 实例的非特殊方法可以被轻松地覆盖，如果要创建大量动态属性，属性名称从不受自己控制的数据中获取， 那么应该实现某种机制，过滤或转义动态属性的名称，以维持数据的健全性 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"4. 描述符使用示例 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:1","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"4.1 基础示例 class Quantity: # 描述符基于协议实现，无需创建子类 def __init__(self, storage_name): self.storage_name = storage_name # 托管实例中存储值的属性的名称 def __set__(self, instance, value): # if value \u003e 0: # 必须直接处理托管实例的 __dict__ 属性，使用内置的 setattr 函数会递归调用 instance.__dict__[self.storage_name] = value # \u003c4\u003e else: raise ValueError('value must be \u003e 0') class LineItem: weight = Quantity('weight') # \u003c5\u003e price = Quantity('price') # \u003c6\u003e def __init__(self, description, weight, price): # \u003c7\u003e self.description = description self.weight = weight self.price = price def subtotal(self): return self.weight * self.price 示例分析 必须直接处理托管实例的 __dict__ 属性；如果使用内置的 setattr 函数，会再 次触发 __set__ 方法，导致无限递归 各个托管属性的名称与储存属性一样，而且读值方法不需要特殊的逻辑， 所以 Quantity 类不需要定义 __get__ 方法 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:2","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"2.2 自动获取储存属性的名称 class Quantity: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): if value \u003e 0: setattr(instance, self.storage_name, value) else: raise ValueError('value must be \u003e 0') class LineItem: weight = Quantity() price = Quantity() 示例分析 __counter 是 Quantity 类的类属性，统计 Quantity 实例的数量 要实现 __get__ 方法，因为托管属性的名称与 storage_name 不同 这里可以使用内置的高阶函数 getattr 和 setattr 存取值，无需使用 instance.__dict__， 因为托管属性和储存属性的名称不同，所以把储存属性传给 getattr 函数不会触发描述符 通过类访问托管属性时，最好让 __get__ 方法返回描述符实例 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:3","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"2.3 描述符扩展 AutoStorage: 自动管理储存属性的描述符类。 Validated: 扩展 AutoStorage 类的抽象子类，覆盖 __set__ 方法，调用必须由子类实现的 validate方法 NonBlank: 继承 Validated 类，只编写 validate 方法 这三个类之间的关系体现了模板方法设计模式 模板方法设计模式: 一个模板方法用一些抽象的操作定义一个算法，而子类将重定义这些操作以提供具体的行为 import abc class AutoStorage: __counter = 0 def __init__(self): cls = self.__class__ prefix = cls.__name__ index = cls.__counter self.storage_name = '_{}#{}'.format(prefix, index) cls.__counter += 1 def __get__(self, instance, owner): if instance is None: return self else: return getattr(instance, self.storage_name) def __set__(self, instance, value): setattr(instance, self.storage_name, value) # 验证除外 class Validated(abc.ABC, AutoStorage): # 抽象类，不过也继承自 AutoStorage 类 def __set__(self, instance, value): value = self.validate(instance, value) # 把验证操作委托给 validate 方法 super().__set__(instance, value) @abc.abstractmethod def validate(self, instance, value): \"\"\"return validated value or raise ValueError\"\"\" class Quantity(Validated): \"\"\"a number greater than zero\"\"\" def validate(self, instance, value): if value \u003c= 0: raise ValueError('value must be \u003e 0') return value class NonBlank(Validated): \"\"\"a string with at least one non-space character\"\"\" def validate(self, instance, value): value = value.strip() if len(value) == 0: raise ValueError('value cannot be empty or blank') return value class LineItem: description = NonBlank() # 用户只需知道，可以使用 NonBlank 自动验证实例属性 weight = Quantity() price = Quantity() ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:4","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"2.4 特性工厂函数 def quantity(): try: quantity.counter += 1 # 定义成工厂函数对象的属性，以便在多次调用之间持续存在 except AttributeError: quantity.counter = 0 storage_name = '_{}: {}'.format('quantity', quantity.counter) # 借助闭包保持值 def qty_getter(instance): return getattr(instance, storage_name) def qty_setter(instance, value): if value \u003e 0: setattr(instance, storage_name, value) else: raise ValueError('value must be \u003e 0') return property(qty_getter, qty_setter) ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:3:5","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:4:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"Python: Data model 一章 https://docs.python.org/3/reference/datamodel.html ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:4:1","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"blog: Descriptor HowTo Guide https://docs.python.org/3/howto/descriptor.html Python 官方文档 HowTo 合集 https://docs.python.org/3/howto/ Python’s Object Model 深入探讨了特性和描述符 幻灯片: http://www.aleax.it/Python/nylug05_om.pdf 视频: https://www.youtube.com/watch?v=VOzvpHoYQoo） ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:4:2","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:4:3","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》有很多说明描述符的诀窍 6.12 读取嵌套型和大小可变的二进制结构 8.10 让属性具有惰性求值的能力 8.13 实现一种数据模型或类型系统 9.9 把装饰器定义成类，解决了函数装饰器、描述符和方法之间相互作用的深层次问题， 说明了如何使用有 __call__ 方法的类实现函数装饰器； 如果既想装饰方法又想装饰函数，还要实现 __get__ 方法 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:4:4","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-20","objectID":"/posts/program/python/grammar/fluent-python/20_descriptor/:5:0","tags":["python 进阶"],"title":"属性描述符","uri":"/posts/program/python/grammar/fluent-python/20_descriptor/"},{"categories":["Linux"],"content":"7.1 vim使用","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"vim使用 本章我们将学习与文本操作相关内容，包括: 文本处理相关命令 文本查找相关命令 正则表达式 vim 编辑器 vim(vi) 是 Linux 下最常用的文本编辑器，拥有众多快捷键和命令，学习曲线很陡峭。下面两幅图是 vim 快捷键的便捷记忆图。本节内容如下: 认识 vim 的三种模式 编辑模式又称命令模式 输入模式 末行模式 vim 编辑模式的常用命令 vim 末行模式的使用 vim 高级用法 vim 配置 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:0:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"1. 认识 vim 的三种模式 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:1:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"1.1 vim 三种模式的转换 默认使用 vim 打开文件后会进入编辑模式，编辑模式下不能使用退格和键盘直接修改文本内容，但是可以使用特定命令实现编辑功能。输入模式即我们通常可以使用键盘直接文本的模式，而末行模式，则是我们可以在 vim 的最后一行输入 vim 特有的命令实现编辑功能。三种模式使用特定命令可以实现转换。 编辑模式 –\u003e 输入模式 命令 作用 i insert, 在光标所在处输入 a append，在光标在处后方输入 o 在光标所在处的下方打开一个新行 I 在光标所在行的行首输入 A 在光标所在行的行尾输入 O 在光标所在处的上方打开一个新行 其他的模式转换 编辑模式 –\u003e 末行模式: : 输入模式 –\u003e 编辑模式: ESC 末行模式 –\u003e 编辑模式: ESC 末行模式与输入模式不能直接转换 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:1:1","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"1.2 使用 vin 打开和关闭文件 使用 vim 打开文件 vim [OPTION] .... FILE ..... +#：打开文件后，光标定位到 # 行，不加行号默认定位到最后一行 +/PATTERN: 打开文件后，光标处于 pattern 匹配到的第一行 vim 中保存文件 ZZ: 在编辑模式下直接保存并退出； :q : 退出 :w： 保存 :q!: 强制退出，不保存此前的编辑操作 :wq: 保存并退出； :x : 保存并退出； :w /PATH/TO/SOMEFILE ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:1:2","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"2. vim 编辑模式的常用命令 vim 编辑模式下的常用命令大体可以分为分为光标跳转，编辑命令，其他命令三类。大多数命令都可以使用类似 nCOMMAND 的方式，即在命令前加上数字，表示重复执行该命令 n 次。对于能这样使用的命令，下面将直接标注为 nCOMMANDA。 Linux 有个vim自带的练习教程叫 vimtutor ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:2:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"2.1 光标跳转 所谓光标跳转即让光标从当前位置迅速跳转到特定位置，包括字符跳转，单词跳转，行首行尾跳转，行间跳转，句间跳转，段落跳转。 字符间跳转 nCOMMAND 跳转由 n 指定的个数的字符； 命令 作用 h 左，支持 nCOMMAND j 下，支持 nCOMMAND k 上，支持 nCOMMAND l 右，支持 nCOMMAND 单词间跳转 命令 作用 w 下一个单词的词首，支持nCOMMAND e 当前或后一个单词的词尾，支持nCOMMAND b 当前或前一个单词的词首，支持nCOMMAND 行首行尾跳转 命令 作用 ^ 跳转至行首的第一个非空白字符 0 跳转至行首 $ 跳转至行尾 行间跳转 命令 作用 nG 跳转至由 n 指定的行 1G, gg 跳转到第一行 G 跳转到最后一行 句间跳转： ): 跳转到句尾 (: 跳转到句首 段间跳转 }: 跳转到段尾 {: 跳转到段首 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:2:1","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"2.2 编辑命令 编辑命令指删除特定字词句，这部分命令可结合跳转命令实现批量修改。 字符编辑： 命令 作用 x 删除光标所在处的字符 nx 删除光标所在处起始的 n 个字符 xp 交换光标所在处的字符与其后面的字符的位置 rCHAR replace,使用 CHAR 字符替换光标所在处的字符 删除命令 d delete 删除命令，可结合光标跳转字符，实现范围删除，支持 nCOMMANDA 命令 作用 d$ 删除光标到行尾 d^ 删除光标到非空白首部 dw 删除光标到下个词词首 ndw 删除光标到下 n 个词词首 de 删除光标到当前词词尾 db 删除光标到当前词词首 dd 删除光标所在处的行 ndd 删除光标所处的行起始的共 n 行 粘贴命令： p (put, paste) 粘贴命令 命令 作用 p 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的下方；否则，则粘贴至当前光标所在处的后方 P 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的上方；否则，则粘贴至当前光标所在处的前方 复制命令 y yank 复制命令，工作行为相似于d命令； 命令 作用 y$ 复制光标到行尾 y^ 复制光标到非空白首部 yw 复制光标到下个词词首 nyw 复制除光标到下 n 个词词首 ye 复制光标到当前词词尾 yb 复制光标到当前词词首 yy 复制光标所在处的行 nyy 复制除光标所处的行起始的共 n 行 改变命令 c change 改变命令，功能同 d 命令，操作完成后会从编辑模式切换到输入模式 命令 作用 c$ 删除光标到行尾 c^ 删除光标到非空白首部 cw 删除光标到下个词词首 ncw 删除光标到下 n 个词词首 ce 删除光标到当前词词尾 cb 删除光标到当前词词首 cc 删除光标所在处的行 ncc 删除光标所处的行起始的共 n 行 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:2:2","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"2.3 其它编辑操作 其他编辑操作如下 可视化模式 可视化模式，可让用户在编辑模式下，非整行扩行选定文本片段 v,箭头: 按住 v 后，使用箭头按字符选定文本； V,箭头: 按住 V 后，使用箭头按行选定文本； 附注: 结合编辑命令 d, c, y，实现选定区域的删除复制 撤销和重复执行 命令 作用 u undo 撤销此前的操作 #u 撤销此前的#个操作 Ctrl+r recover 撤销此前的撤销 . 重复执行前一个编辑操作 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:2:3","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"3. vim 末行模式的使用 vim末行模式，是 vim 内建的命令行接口，通过地址定界和之前介绍的编辑命令，可实现批量操作。所谓地址定界即选择出特定范围的行。除此之外 vim 还能实现保存，查找，替换等诸多功能。 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:3:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"3.1 地址定界 地址定界的格式是 :start_pos[,end_pos]，位置的表示可以是数字也可以是正则表达式，具有多种表达方式 位置表示 作用 # 数字，表示特定的第#行，例如5即第5行 #,# 指定行范围，左侧为起始行，右侧为结束行 #,+# ：指定行范围，左侧为超始行绝对编号，右侧为相对左侧行号的偏移量；例如：3,+7 . 表示当前行 $ 最后一行 .,$-1 当前行到倒数第二行 1,$ 第一行到最后一行，即全文 % 全文，等同于 1,$ /pattern/ 从光标所在处起始向文件尾部第一次被模式所匹配到的行, 例如/first/,$ /pat1/,/pat2/ 从光标所在处起始，第一次由pat1匹配到的行开始，至第一次由pat2匹配到的行结束之间的所有行 地址定界可同编辑命令 d,y,c一同使用，实现编辑操作。例如 :1,20d 删除 1 到 20 行。 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:3:1","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"3.2 保存和加载 末行模式中保存和加载其他文件的常用命令如下 命令 作用 :q 退出 :w 保存 :q! 强制退出，不保存此前的编辑操 :wq 保存并退出 :x 保存并退出 :w /PATH/TO/SOMEFILE 将文本保存至指定的文件中，可通过地址定界选定保存的文本范围 :r /PATH/FROM/SOMEFILE 将指定的文件中的文本读取并插入至指定位置 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:3:2","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"3.3 查找 通过 / 或 ？ 命令，可在 vim 中实现查找 /PATTERN：从当前光标所在处向文件尾部查找能够被当前模式匹配到的所有字符串； ?PATTERN：从当前光标所在处向文件首部查找能够被当前模式匹配到的所有字符串； 查找后，可使用 n，N 查找下一个 n：查找下一个，表示与命令方向相同的下一个； N：查找上一个，表示与命令方向相反的上一个； ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:3:3","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"3.4 查找并替换 末行模式中通过 s 命令可实现替换功能，s 命令的使用格式如下: :地址定界s/要查找的内容/替换为的内容/修饰符 要查找的内容：可使用基本正则表达式； 替换为的内容：不能使用下则表达式，但可以引用； 修饰符： i：忽略大小写； g：全局替换，意味着一行中如果匹配到多次，则均替换； 分隔符/:可把替换为其它非常用字符@ 或 #： s@@@ s### 引用: 如果\"要查找的内容\"部分在模式中使用了分组符号可在\"替换为的内容\"中使用后向引用； 直接引用查找模式匹配到的全部文本，要使用\u0026符号； 示例: %s@\\\u003ct\\([[:alpha:]]\\+\\)\\\u003e@T\\1@g: 将以小写 t 开头的字母替换为大写 T开头 %s@\\\u003ct[[:alpha:]]\\+\\\u003e@\u0026er@g: 在所哟单词后面加上 er 练习： # 1. 复制/etc/grub2.cfg文件至/tmp目录中，用查找替换命令删除/tmp/grub2.cfg文件中以空白字符开头的行的行首的空白字符； \u003e %s@^[[:space:]]\\+@@ \u003e %s/^[[:space:]]\\+// # 2. 复制/etc/rc.d/init.d/functions文件至/tmp目录中，用查找替换命令为/tmp/functions文件的每个以空白字符开头的行的行首加上#； \u003e %s@^[[:space:]]\\+[^[:space:]]@#\u0026@g \u003e %s/^([[:space:]]\\+)/#\u0026/g # 3. 为/tmp/grub2.cfg文件的前三行的行首加上#号； \u003e 1,3s/.*/#\u0026/g # 4. 将/etc/yum.repos.d/CentOS-Base.repo文件中所有的enabled=0替换为enabled=1，所有gpgcheck=0替换为gpgcheck=1； \u003e %s/\\(enabled\\|gpgcheck\\)=0/\\1=1/g \u003e %s@\\(enabled\\|gpgcheck\\)=0@\\1=1@g ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:3:4","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"4. vim 高级用法 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:4:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"多文件模式 vim /tmp/{file1，file2} :next: 切换至下一文件 :prev: 切换至上一个文件 :last: 切换至最后一个文件 :first: 切换至第一个文件 :wall：保存所有 :qall：退出所有 :wqall: 保存并退出所有 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:4:1","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"窗口分割 vim -o FILE1 FILE2.... 水平分割 vim -O FILE1 FILE2.... 垂直分割 Ctrl + w 松开后，加箭头: 切换窗口 Ctrl + w, s: 水平分割当前文件 Ctrl + w, v: 垂直分割当前文件 ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:4:2","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Linux"],"content":"5. vim 配置 vim 的配置可在末行模式下设定，此时仅对当前vim进程有效；要想永久有效可编辑配置文件 全局配置：/etc/vimrc 用户个人配置：～/.vimrc vim 中常见的配置选项 作用 配置 行号 显示：set number, 简写为set nu 取消显示：set nomber, set nonu 括号匹配高亮 匹配：set showmatch, set sm 取消：set nosm 自动缩进 启用：set ai 禁用：set noai 高亮搜索 启用：set hlsearch 禁用：set nohlsearch 语法高亮 启用：syntax on 禁用：syntax off 忽略字符大小写 启用：set ic 禁用：set noic ","date":"2018-01-19","objectID":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/:5:0","tags":["马哥 Linux"],"title":"7.1 vim使用","uri":"/posts/linux/linux_mt/07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86/vim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3/"},{"categories":["Python"],"content":"Python 自省","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"6.1 Python 术语 属性：数据的属性和处理数据的方法统称属性 特性：property，在不改变类接口的前提下，使用存取方法（即读值方法和设值方法）修改数据属性 本章内容 特性 动态属性 __new__ 与 __init__ ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:0:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2. 特性 特性 - property: 类型：特性是 覆盖性描述符(详见下章)，是实现了描述符协议的类 作用： 特性都是类属性，但是特性管理的其实是实例属性的存取，会覆盖实例属性 把公开属性变成使用读值方法和设值方法管理的属性，在不影响客户端代码的前提下实施业务规则 应用： 特性适用于管理实例属性 私有类属性适合使用读值和设值方法管理 用于修改对象的方法不能实现为特性 抽象方式：详见下节 使用特性工厂函数 使用描述符类 版本差异： Python2： 只有\"新式\"类支持特性 定义新式类的方法是，直接或间接继承 object 类 语法： 作为类使用：property(fget=None, fset=None, fdel=None, doc=None) 所有参数都是可选的 如果没有把函数传给某个参数，那么得到的特性对象就不允许执行相应的操作 作为装饰器： 使用装饰器创建 property 对象时，读值方法的文档字符串作为一个整体，变成特性的文档 class MyObj: @property def my_propety(self): \"\"\"doc\"\"\" pass @my_propety.setter def set_property(self): pass @my_propety.deleter def del_property(self): pass ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:1:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2. __new__ 与 __init__ ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:2:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2.1 __init__: 作用：实例初始化方法 特性：禁止返回任何值 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:2:1","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2.2 __new__(cls, **arg, **kwargs): 作用：实例构造方法 特性： 这是个类方法(使用特殊方式处理，因此不必使用 @classmethod装饰器） 必须返回一个实例，返回的实例作为第一个参数（即 self）传给 __init__ 方法 __new__ 方法也可以返回其他类的实例，此时，解释器不会调用 __init__ 方法 附注：几乎不需要自己编写 __new__ 方法，因为从 object 类继承的实现已经足够了 参数： __new__ 是类方法，第一个参数是类本身 余下的参数与 __init__ 方法一样，只不过没有 self Python 构建对象过程的伪代码 def object_maker(the_class, some_arg): new_object = the_class.__new__(some_arg) if isinstance(new_object, the_class): the_class.__init__(new_object, some_arg) return new_obj # 下述两个语句的作用基本等效 x = Foo('bar') x = object_maker(Foo, 'bar') ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:2:2","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2.3 __new__ 使用示例 class FrozenJSON: \"\"\"A read-only façade for navigating a JSON-like object using attribute notation \"\"\" def __new__(cls, arg): # \u003c1\u003e if isinstance(arg, abc.Mapping): return super().__new__(cls) # \u003c2\u003e elif isinstance(arg, abc.MutableSequence): # \u003c3\u003e return [cls(item) for item in arg] else: return arg super().__new__(cls) 默认的行为是委托给超类的 __new__ 方法 这里是调用 object.__new__(FrozenJSON)， object 类构建的是 FrozenJSON 的实例 真正的构建操作由解释器调用 C 语言实现的 object.__new__ 方法执行 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:2:3","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"2.4 super() 函数 Python2 class super(object) super(type)：返回非绑定的函数 super(type, obj)：调用实例方法，要求 isinstance(obj, type) super(type, type2)：调用类方法，要求 issubclass(type2, type) 典型用法: class C(B): def meth(self, arg): super(C, self).meth(arg) Python3 http://python3-cookbook.readthedocs.io/zh_CN/latest/c08/p07_calling_method_on_parent_class.html ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:2:4","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3. 动态属性 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.1 属性查找顺序： 类中的覆盖性描述符 实例，类，超类 所属类中定义的 __getattr__ 方法， 传入 self 和属性名称的字符串形式 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:1","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.2 处理属性的特殊方法 附注： 使用点号或内置的 getattr、 hasattr 和 setattr 函数存取属性都会触发下述列表中相应的特殊方法 直接通过实例的 __dict__ 属性读写属性不会触发这些特殊方法——如果需要，通常会使用这种方式跳过特殊方法 特殊方法从类上获取，因此不会被同名实例属性遮盖 __delattr__(self, name) 调用：使用 del 语句删除属性时 例如：del obj.attr 语句触发 Class.__delattr__(obj, ‘attr’) 方法 __dir__(self) 调用：使用 dir 函数获取对象属性时 例如：dir(obj) 触发 Class.__dir__(obj) 方法 __getattribute__(self, name) 触发：尝试获取指定的属性时总会调用，包括点号，getattr 和 hasattr 内置函数 特性： 寻找的属性是特殊属性或特殊方法时除外 调用 __getattribute__ 方法且抛出 AttributeError 异常时，才会调用 __getattr__ 方法 使用：为了在获取 obj 实例的属性时不导致无限递归， __getattribute__ 方法的实现要使用 super().__getattribute__(obj, name) __getattr__(self, name) 触发：仅当在 obj、 Class 和超类中找不到指定的属性时才会触发 __setattr__(self, name, value) 触发：尝试设置指定的属性时调用，包括点号和 setattr 内置函数 例如：obj.attr = 42 和 setattr(obj, ‘attr’, 42) 都会触发 Class.__setattr__(obj, “attr” , 42) 方法 说明： 特殊方法 __getattribute__ 和 __setattr__ 不管怎样都会调用，几乎会影响每一次属性存取， 因此比 __getattr__ 方法（只处理不存在的属性名）更难正确使用 与定义这些特殊方法相比，使用特性或描述符相对不易出错 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:2","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.3 影响属性处理方式的特殊属性 __class__ 作用：对象所属类的引用（即 obj.__class__ 与 type(obj) 的作用相同) 特性：Python 的某些特殊方法，例如 __getattr__，只在对象的类中寻找，而不在实例中寻找 __dict__ 作用： 一个映射，存储对象或类的可写属性 有 __dict__ 属性的对象，任何时候都能随意设置新属性 __slots__ 作用：类可以定义这个属性，限制实例能有哪些属性 属性值：一个字符串组成的元组，指明允许有的属性 附注：如果 __slots__ 中没有 ‘__dict__’，那么该类的实例没有 __dict__ 属性，实例只允许有指定名称的属性 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:3","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.4 处理属性的内置函数 dir([object]) 作用： 列出 object 对象的大多数属性 如果没有指定可选的 object 参数， dir 函数会列出当前作用域中的名称 文档： https://docs.python.org/3/library/functions.html#dir 特性： 目的是交互式使用，因此没有提供完整的属性列表，只列出一组“重要的\"属性名 能审查有或没有 __dict__ 属性的对象 不会列出 __dict__ 属性本身，但会列出其中的键。 也不会列出类的几个特殊属性，例如__mro__、 __bases__ 和 __name__ vars([object]) 作用： 返回 object 对象的 __dict__ 属性 如果没有指定参数，var() 与 locals() 函数一样，返回表示本地作用域的字典 特性： 如果实例所属的类定义了 __slots__ 属性，实例没有 __dict__ 属性， 那么 vars 函数不能处理那个实例，相反， dir 函数能处理这样的实例 getattr(object, name[, default]) 作用：从 object 对象中获取 name 字符串对应的属性 返回： 获取的属性可能来自对象所属的类或超类 如果没有指定的属性， getattr 函数抛出 AttributeError 异常， 或者返回 default参数的值（如果设定了的话） hasattr(object, name) 作用：检查 object 对象是否拥有指定的属性，有返回True 原理：调用 getattr(object, name) 函数，检查是否抛出 AttributeError 异常 文档：https://docs.python.org/3/library/functions.html#hasattr setattr(object, name, value) 作用：把 object 对象指定属性的值设为 value 前提：object 对象能接受那个值。 附注：这个函数可能会创建一个新属性，或者覆盖现有的属性 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:4","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.5 动态属性示例 1 from collections import abc class FrozenJSON: def __init__(self, mapping): self.__data = dict(mapping) def __getattr__(self, name): if hasattr(self.__data, name): return getattr(self.__data, name) else: return FrozenJSON(self.__data[name]) # \u003c4\u003e __getattr__: 首先查看 self.__data 字典有没有指定名称的属性（不是键）， 这样 FrozenJSON 实例便可以处理字典的所有方法 如果 self.__data 没有指定名称的属性，那么 __getattr__ 方法以那个名称为键， 从 self.__data 中获取一个元素，并进行实例构造 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:5","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"3.6 动态属性示例 2 class Record: def __init__(self, **kwargs): self.__dict__.update(kwargs) # 快速地在实例中创建一堆属性 # 前提是类中没有声明 __slots__ 属性 # END SCHEDULE2_RECORD self.__dict__.update(kwargs) 快速地在实例中创建一堆属性，前提是类中没有声明 slots 属性 从数据中创建实例属性的名称时肯定有可能会引入缺陷，因为类属性（例如方法）可能被遮盖， 或者由于意外覆盖现有的实例属性而丢失数据 # BEGIN SCHEDULE2_DBRECORD class DbRecord(Record): # __db = None # __db 类属性存储一个打开的 shelve.Shelf 数据库引用。 @staticmethod # \u003c4\u003e def set_db(db): DbRecord.__db = db # __db 是 DbRecord 类的私有属性 @staticmethod def get_db(): return DbRecord.__db @classmethod def fetch(cls, ident): db = cls.get_db() try: return db[ident] except TypeError: if db is None: msg = \"database not set; call '{}.set_db(my_db)'\" raise MissingDatabaseError(msg.format(cls.__name__)) else: # 重新抛出 TypeError 异常 raise def __repr__(self): if hasattr(self, 'serial'): # \u003c11\u003e cls_name = self.__class__.__name__ return '\u003c{} serial={!r}\u003e'.format(cls_name, self.serial) else: return super().__repr__() # \u003c12\u003e # END SCHEDULE2_DBRECORD class Event(DbRecord): @property def speakers(self): if not hasattr(self, '_speaker_objs'): # 从 __dict__ 中获取 'speakers'，防止无限递归，因为特性的公开名称也是 speakers spkr_serials = self.__dict__['speakers'] fetch = self.__class__.fetch # 获取 fetch 类方法的引用，避免被实例同名属性覆盖 self._speaker_objs = [fetch('speaker.{}'.format(key)) for key in spkr_serials] # \u003c6\u003e return self._speaker_objs # BEGIN SCHEDULE2_LOAD def load_db(db): raw_data = osconfeed.load() warnings.warn('loading ' + DB_NAME) for collection, rec_list in raw_data['Schedule'].items(): record_type = collection[:-1] cls_name = record_type.capitalize() cls = globals().get(cls_name, DbRecord) ➌ if inspect.isclass(cls) and issubclass(cls, DbRecord): ➍ factory = cls else: factory = DbRecord for record in rec_list: # \u003c7\u003e key = '{}.{}'.format(record_type, record['serial']) record['serial'] = key db[key] = factory(**record) # \u003c8\u003e ➌ 从模块的全局作用域中获取那个名称对应的对象；如果找不到对象，使用 DbRecord。 ➍ 如果获取的对象是类，而且是 DbRecord 的子类 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:3:6","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:4:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"Python: Builtin Functions 属性处理和内置的内省函数的官方文档 https://docs.python.org/3/library/functions.html 3.3.9. Special method lookup 调用特殊方法会跳过实例的语意原因 https://docs.python.org/3/reference/datamodel.html#special-method-lookup） 4.13. Special Attributes 说明了 __class__ 和 __dict__ 属性 https://docs.python.org/3/library/stdtypes.html#special-attributes） __slots__ 属性 https://docs.python.org/3/reference/datamodel.html#customizing-attribute-access ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:4:1","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"blog: The simple but handy ‘ collector of a bunch of named stuff’class http://code.activestate.com/recipes/52308-the-simple-but-handy-collector-of-a-bunch-of-named/ Class-level read only properties in Python http://stackoverflow.com/questions/1735434/class-level-read-only-properties-in-python 为类中的只读属性提供了解决方案 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:4:2","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"实用工具 keyword 模块 keyword.iskeyword(value): 判断value 是否是 Python 关键字 str.isidentifier(): 根据语言的语法判断 str 是否为有效的 Python 标识符 shelve 模块 作用：提供了 pickle 存储方式 shelve.open: 作用：返回一个 shelve.Shelf 实例，这是简单的键值对象数据库，背后由dbm 模块支持 Shelf: 是 abc.MutableMapping 的子类，因此提供了处理映射类型的重要方法 提供了几个管理 I/O 的方法，如 sync 和 close；也是一个上下文管理器 只要把新值赋予键，就会保存键和值 键必须是字符串。 值必须是 pickle 模块能处理的对象 文档： shelve: https://docs.python.org/3/library/shelve.html dbm: https://docs.python.org/3/library/dbm.html pickle: https://docs.python.org/3/library/pickle.html 以下类实例可以有任意个属性，由传给构造方法的关键字参数构建： multiprocessing.Namespace 类 文档: https://docs.python.org/3/library/multiprocessing.html?highlight=namespace#namespaceobjects 源码: https://hg.python.org/cpython/file/50d581f69a73/Lib/multiprocessing/managers.py#l909 argparse.Namespace 类 文档: https://docs.python.org/3/library/argpa-rse.html#argparse.Namespace 源码: https://hg.python.org/cpython/file/50d581f69a73/Lib/argparse.py#l1196 python -i schedule1.py: 启动加载了 schedule1 模块的控制台 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:4:3","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》 8.8 在子类中扩展属性: 解决了在继承自超类的特性中覆盖方法这个棘手问题 8.15 委托属性的访问: 实现了一个代理类 9.21 避免出现重复的属性方法 《 Python 技术手册（第 2 版）》 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:4:4","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Python"],"content":"附注 统一访问原则(Unifrom Access Principle) 相关文章： http://c2.com/cgi/wiki?UniformAccessPrinciple http://c2.com/cgi/wiki?WelcomeVisitors Python： 在 Python 中还有一处体现了统一访问原则(或者它的变体)：函数调用和对象实例化 使用相同的句法——my_obj = foo()，其中 foo 是类或其他可调用的对象 __new__ 方法 作用：可以把类变成工厂方法，生成不同类型的对象，或者返回事先构建好的实例，而不是每次都创建一个新实例 ","date":"2018-01-19","objectID":"/posts/program/python/grammar/fluent-python/19_dynamic/:5:0","tags":["python 进阶"],"title":"自省","uri":"/posts/program/python/grammar/fluent-python/19_dynamic/"},{"categories":["Linux"],"content":"6.9 脚本示例与练习","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"脚本示例与练习 本节是一些常用的脚本示例，可供我们学习参考 ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:0:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"1. 条件判断练习 ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:1:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"更改主机名 将当前主机名称保存至hostName变量中；主机名如果为空，或者为localhost.localdomain，则将其设置为www.magedu.com； \u003e hostName=$(hostname) \u003e [ -z \"$hostName\" -o \"$hostName\" == \"localhost.localdomain\" -o \"$hostName\" == \"localhost\" ] \u0026\u0026 hostname www.magedu.com ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:1:1","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"比较求大者 通过命令行参数给定两个数字，输出其中较大的数值； #!/bin/bash # if [ $# -lt 2 ]; then echo \"Two integers.\" exit 2 fi declare -i max=$1 if [ $1 -lt $2 ]; then max=$2 fi echo \"Max number: $max.\" ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:1:2","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"2. 命令行参数 ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:2:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"判断用户ID 奇偶 通过命令行参数给定一个用户名，判断其ID号是偶数还是奇数； ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:2:1","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"比较文件行数 通过命令行参数给定两个文本文件名，如果某文件不存在，则结束脚本执行；都存在时返回每个文件的行数，并说明其中行数较多的文件； ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:2:2","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"3. for 循环练习 ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:3:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"添加用户 #!/bin/bash # for username in user21 user22 user23; do if id $username \u0026\u003e /dev/null; then echo \"$username exists.\" else useradd $username if [ $? eq 0 ]; then echo \"$username\" | passwd --stdin \"$username\" \u0026\u003e /dev/null echo \"Add $username finished\" fi fi done ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:3:1","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"求和 #!/bin/bash # 示例：求100以内所有正整数之和； declare -i sum=0 for i in {1..100}; do echo \"\\$sum is $sum, \\$i is $i\" sum=$[$sum+$i] done echo $sum ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:3:2","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"判断文件类型 #!/bin/bash # 示例：判断/var/log目录下的每一个文件的内容类型 for filename in /var/log/*; do if [ -f $filename ]; then echo \"Common file.\" elif [ -d $filename ]; then echo \"Directory.\" elif [ -L $filename ]; then echo \"Symbolic link.\" elif [ -b $filename ]; then echo \"block special file.\" elif [ -c $filename ]; then echo \"character special file.\" elif [ -S $filename ]; then echo \"Socket file.\" else echo \"Unkown.\" fi done #!/bin/bash # 打印成法口诀表 for i in {1..9}; do for j in $(seq 1 $i); do echo -e -n \"${i}X${j}=$[$i*$j]\\t\" done echo done ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:3:3","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"4. 类 C 风格for 循环 ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:4:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"求和 # 示例：求100以内所有正整数之和 #!/bin/bash # declare -i sum=0 for ((i=1;i\u003c=100;i++)); do let sum+=$i done echo \"Sum: $sum.\" ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:4:1","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"打印九九乘法表 # 示例：打印九九乘法表 #!/bin/bash # for ((j=1;j\u003c=9;j++)); do for ((i=1;i\u003c=j;i++)); do echo -e -n \"${i}X${j}=$[${i}*${j}]\\t\" done echo done ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:4:2","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"5. 显示一个菜单给用户 要求 # 显示一个如下的菜单给用户 # cpu) display cpu information # mem) display memory information # disk) display disks information # quit) quit # 要求：(1) 提示用户给出自己的选择； # (2) 正确的选择则给出相应的信息；否则，则提示重新选择正确的选项； bash 脚本 #!/bin/bash # cat \u003c\u003c EOF cpu) display cpu information mem) display memory infomation disk) display disks information quit) quit =============================== EOF read -p \"Enter your option: \" option while [ \"$option\" != \"cpu\" -a \"$option\" != \"mem\" -a \"$option\" != \"disk\" -a \"$option\" != \"quit\" ]; do echo \"cpu, mem, disk, quit\" read -p \"Enter your option again: \" option done if [ \"$option\" == \"cpu\" ]; then lscpu elif [ \"$option\" == \"mem\" ]; then free -m elif [ \"$option\" == \"disk\" ]; then fdisk -l /dev/[hs]d[a-z] else echo \"quit\" exit 0 fi ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:5:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Linux"],"content":"6. 服务框架脚本 要求 # 示例：写一个服务框架脚本； # $lockfile, 值/var/lock/subsys/SCRIPT_NAME # (1) 此脚本可接受start, stop, restart, status四个参数之一； # (2) 如果参数非此四者，则提示使用帮助后退出； # (3) start，则创建lockfile，并显示启动；stop，则删除lockfile，并显示停止；restart，则先删除此文件再创建此文件，而后显示重启完成；status，如果lockfile存在，则显示running，否则，则显示为stopped. bash 脚本 #!/bin/bash # # chkconfig: - 50 50 # description: test service script # prog=$(basename $0) lockfile=/var/lock/subsys/$prog case $1 in start) if [ -f $lockfile ]; then echo \"$prog is running yet.\" else touch $lockfile [ $? -eq 0 ] \u0026\u0026 echo \"start $prog finshed.\" fi ;; stop) if [ -f $lockfile ]; then rm -f $lockfile [ $? -eq 0 ] \u0026\u0026 echo \"stop $prog finished.\" else echo \"$prog is not running.\" fi ;; restart) if [ -f $lockfile ]; then rm -f $lockfile touch $lockfile echo \"restart $prog finished.\" else touch -f $lockfile echo \"start $prog finished.\" fi ;; status) if [ -f $lockfile ]; then echo \"$prog is running\" else echo \"$prog is stopped.\" fi ;; *) echo \"Usage: $prog {start|stop|restart|status}\" exit 1 esac ","date":"2018-01-18","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/:6:0","tags":["马哥 Linux"],"title":"6.9 脚本示例与练习","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0/"},{"categories":["Python"],"content":"Python asyncio 处理并发","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"1. 操作系统知识 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:1:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"1.1 并发与并行 并行: 在某一时间点, 存在多于一个进程在运行 并发: 在某一段时间, 存在多于一个进程在运行 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:1:1","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"1.2 I/O 模型 同步阻塞I/O 同步非阻塞I/O 异步阻塞I/O – I/O多路复用 异步非阻塞I/O – I/O操作在操作系统内核中完成, 完成后通过应用程序 信号驱动I/O - 向程序发送信号, I/O操作在用户空间完成 epoll - I/O多路复用的改进版本, 又称为事件驱动模型 附注: 普通文件的读写不支持 epoll, 基于 epoll的 tornado 不适合大量的 文件系统I/O, 耗时的任务只能通过采用异步 httpclient 交给后端server处理 asyncio 也不支持异步文件系统I/O, 只能通过多线程解决普通文件读写导致的阻塞 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:1:2","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"I/O模型对比 详细见 18.5节 信号驱动I/O 实现：通过sigaction系统调用注册一个SIGIO信号处理程序 特点： 通常，在UDP编程中使用信号驱动I/O，此时SIGIO信号产生于下面两种情况： 套接字收到一个数据报 套接字上发生了异步错误 对于TCP编程，信号驱动I/O没有太大意义 因为对于流式套接字而言，有很多情况都可以导致SIGIO产生 而应用又无法区分是什么具体情况导致该信号产生的 基于回调的事件驱动模型： 缺点: 执行分成多步的异步任务时丢失上下文，共享状态管理困难 不等待响应, 而是注册一个函数, 在发生某件事时调用 每个函数做一部分工作, 设置下一个回调, 然后返回, 让事件循环继续运行, 所有本地的上下文都会丢失 缺少处理错误所需的上下文，错误处理困难 一连串的回调构成一个完整的调用链,其中任意一个异常整个调用链断掉，接力传递的状态也会丢失 为了防止栈撕裂，异常必须以数据的形式返回，而不是直接抛出异常， 然后每个回调中需要检查上次调用的返回值，以防错误吞没 基于协程的事件驱动模型： 协程： 是协作式的例程 是非抢占式的多任务子例程的概括，允许有多个入口点在例程中确定的位置来控制程序的暂停与恢复执行 例程是编程语言定义的可被调用的代码段，为了完成某个特定功能而封装在一起的一系列指令 特点： 每个协程具有自己的栈帧，保留了程序执行的上下文 协程之间相互合作，相互通知，能将程序状态在不同的回调之间延续下去 运行过程： 所有I/O操作都是异步的，并在 yield 处暂停 事件循环监听所有I/O事件，并在I/O事件发生时，调用send方法激活暂停协程继续运行 总结: 两种模型都是基于回调，只不过协程中的事件循环回调的是 send 方法，激活暂停的协程 应用： Node.js 是基于回调的事件 Node.js 不支持使用 JavaScript 编写的用户级线程, 但是在背后却借助 libeio 库使用 C 语言实现了线程池, 以此提供基于回调的文件 API 从 2014 年起, 大多数操作系统都不提供稳定且便携的异步文件处理 API 了， Node 提供了异步文件系统 API asyncio 是基于协程的 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:1:3","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"1.3 协程与线程 线程： 因为调度程序任何时候都能中断线程。 所以必须保留锁，保护程序中的重要部分，防止多步操作在执行的过程中中断，导致数据处于无效状态 协程： 协程默认会做好全方位保护，以防止中断，必须显式产出才能让程序的余下部分运行 对协程来说，无需保留锁，协程自身就会同步，因为在任意时刻只有一个协程运行 想交出控制权时，可以使用 yield 或 yield from 把控制权交还调度程序 协程只能在暂停的 yield 处取消，因此可以处理 CancelledError 异常，执行清理操作， 这就是能够安全地取消协程的原因 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:1:4","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"2. asyncio ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:2:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"2.1 asyncio 简介 asyncio: 实现: 使用 事件循环驱动 的协程实现并发, 注意不是实现并行 版本: python3: asyncio - http://docs.python.org/3/library/asyncio.html python2: trollius - http://trollius.readthedocs.io/using.html import asyncio 替换成 import trollius as asyncio yield from … 替换成 yield From(…) yield from [] 替换成 yield From(None) 协程需要返回结果, return result 替换成 raise Return(result) 讨论组: http://groups.google.com/forum/#!forum/python-tulip ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:2:1","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"2.2 异步原理: 事件循环基于 I/O 多路复用 委派链的底端是可以被 I/O 多路复用监听的 I/O 操作 yield from foo 能防止阻塞, 因为当前协程(委派生成器)因等待I/O操作暂停后, 控制权回到事件循环手中, 再去驱动其他协程 – 异步阻塞的 事件循环监听期物或协程是否运行完毕, 并把结果返回给暂停的协程, 将其恢复, 即调用 send 方法发送响应重启协程 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:2:2","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"2.3 语法: Python3.4: asyncio 处理的协程 要使用 @asyncio.coroutine 装饰 - 这样能在一众普通的函数中把协程凸显出来， - 有助于调试：如果还没从中产出值，协程就被垃圾回收了(意味着有操作未完成)那就可以发出警告 协程在定义体中必须使用 yield from, 而不能使用 yield 协程要由调用方驱动, 并由调用方通过 yield from 调用, 或者把协程传给 asyncio 包中的某个函数, 例如 asyncio.async(…) Python3.6 新特性: 添加了 async 和 await 关键字, 协程成为新的语法, 而不再是一种生成器类型 async: 作用: 替代 asyncio.coroutine await: 作用: 替代 yield from async with 作用: 异步上下文管理 async for 作用: 异步迭代器语法 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:2:3","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"2.4 调用过程: 使用 asyncio.Task 对象包装协程, 排定协程的运行时间 – 获取 Task 对象 获取一个事件循环 – 替代了操作系统的调度职能 – 获取事件循环 asyncio 事件循环依次激活各个协程 – 激活所有协程 客户代码中的协程使用 yield from 把职责委托给库里的协程(如aiohttp.request)时, 控制权交还事件循环, 事件循环得以执行其他排定的协程 – 执行底层协程 事件循环通过基于回调的低层 API, 在阻塞的操作执行完毕后获得通知 获得通知后, 主循环把结果发给暂停的协程(.send()), 重启暂停的协程 – 获取返回结果 总结: 在一个单线程程序中使用主循环依次激活队列里的协程, 各个协程向前执行几步, 然后把控制权让给主循环, 主循环再激活队列里的下一个协程 调用方式: 只有驱动协程, 协程才能做事 驱动协程要么使用 yield from,要么传给 asyncio包中某个参数为协程或期物的函数, 例如 run_until_complete yeild from: 使用 yield from 链接的多个协程最终必须由不是协程的调用方驱动，调用方显式或隐式 （例如，在 for 循环中）在最外层委派生成器上调用 next(…) 函数或 .send(…) 方法 链条中最内层的子生成器必须是简单的生成器（只使用 yield）或可迭代的对象 使用 asyncio 包时，我们编写的代码不通过调用 next(…) 函数或 .send(…) 方法驱动协程——这一点由 asyncio 包实现的事件循环去做 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:2:4","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3. asyncio API ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.1 asyncio 主要对象 主要对象: asyncio.Future: 期物对象，表示异步执行的操作 与 concurrent.futures.Future 类似 asyncio.Task: Future 对象的子类 与 threading.Thread 对象等效，Task 用于驱动协程， Thread 用于调用可调用的对象 像是实现协作式多任务的库(例如 gevent)中的绿色线程(green thread) BaseEventLoop: I/O 事件循环 其他函数 期物和协程: 文档： https://docs.python.org/3/library/asyncio-task.html 可以使用 yield from 驱动协程，也可以使用 yield from 从 asyncio.Future对象中产出结果 因此如果 foo 是协程函数（调用后返回协程对象）, 抑或是返回 Future 或 Task 实例的普通函数, 都可以写成: res = yield from foo() 这是asyncio 包的 API 中很多地方可以互换协程与期物的原因之一 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:1","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.2 asyncio.Future 作用: 与 concurrent.futures.Future 接口基本一致 类似方法: .done() .add_done_callback(…) 差异方法: .result(): 参数: 方法没有参数, 不能指定超时时间。 作用: 如果调用 .result() 方法时期物还没运行完毕, 不会阻塞去等待结果, 而是抛出 asyncio.InvalidStateError 异常 使用方式: 通常使用 yield from, 获取 asyncio.Future 对象的结果 使用 yield from 处理期物, 等待期物运行完毕这一步无需我们关心, 而且不会阻塞事件循 环, 因为在 asyncio 包中, yield from 的作用是把控制权还给事件循环 通常无需调用 my_future.add_done_callback(…), 因为 可以直接把想在期物运行结束后执行的操作放在协程中 yield from my_future 表达式的后面即可 通常也无需调用 my_future.result(), 因为 yield from 从期物中产出的值就是结果 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:2","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.3 asyncio.Task 作用: Future 的子类, 用于包装协程 特性: 为了执行操作，必须排定协程的运行时间，然后使用 asyncio.Task 对象包装协程 因此Task 实例相当于一个子线程，但已排定运行时间, 可直接运行, 无需显示使用 yeild from 驱动 Thread 实例则必须调用 start 方法，明确告知让它运行 方法： .cancel(): 作用：终止协程, 在协程内部 yeild 处抛出 CancelledError 异常 附注：协程可以捕获这个异常，也可以延迟取消，甚至拒绝取消 def test_task(): a = async(asyncio.sleep(100)) # 协程不会在此处暂停，因为相当于启动了一个新线程 print('-------------') yield from async(asyncio.sleep(1)) # 协程会在此处暂停 yield from asyncio.sleep(1) # 协程会在此暂停，yield from Future() 也是同样效果 print('+++++') # 在上一个 sleep 返回时，输出 a.cancel() # 当前协程运行完毕，a 被销毁，对应的协程也会被销毁，所以整个程序不会运行 100s loop = asyncio.get_event_loop() loop.run_until_complete(test_task()) 附注： 如果想获取 task 实例的返回结果，必需使用 yeild from task 如果只是想启动另一协程，无需使用 yield from Future 对象只是要执行的操作，与协程一样，必需使用 yield from 驱动 实例化方式 asyncio.async(coro_or_future, *, loop=None) coro_or_future: 如果是 Future 或Task 对象, 那就原封不动地返回 如果是协程, 那么 async 函数会调用 loop.create_task(…) 方法创建 Task 对象 loop: 关键字参数是可选的, 用于传入事件循环 默认, async 函数会通过调用 asyncio.get_event_loop() 函数获取循环对象 BaseEventLoop.create_task(…) 参数: 一个协程 作用: 排定协程的执行时间, 返回一个 asyncio.Task 对象 附注: 如果在自定义的 BaseEventLoop 子类上调用, 返回的对象可以是外部库 (如 Tornado)中与 Task 类兼容的某个类的实例 版本：create_task(…) 方法只在 Python 3.4.2 及以上版本中可用。 如果是 Python 3.3 或 Python 3.4 的旧版，要使用 asyncio.async(…) 函数 asyncio.wait(futures, *, loop=None, timeout=None, return_when=ALL_COMPLETED): 参数: futures: 一个由期物或协程构成的可迭代对象 timeout, return_when 如果设定可能会返回未结束的期物 作用: 把各个协程分别包装进一个 Task 对象(内部使用了 async 函数) wait 是协程, 返回一个协程或生成器对象, 会等待传给它的所有协程运行完毕后结束 def download_many(cc_list): loop = asyncio.get_event_loop() # 获取事件循环底层实现的引用 to_do = [download_one(cc) for cc in sorted(cc_list)] # \u003c9\u003e wait_coro = asyncio.wait(to_do) # \u003c10\u003e res, _ = loop.run_until_complete(wait_coro) # 执行事件循环, 直到 wait_coro 运行结束 loop.close() # 关闭事件循环 附注： run_until_complete 只接受一个欺物或协程，驱动多个协程需要先由 asyncio.wait 协程包装 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:3","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.4 BaseEventLoop asyncio.get_event_loop(): 客户代码绝不会直接创建事件循环 而是获取事件循环的引用 BaseEventLoop.run_until_complete(…) 参数: 一个期物或协程, 如果是协程, 把协程包装进一个 Task 对象中 作用: 事件循环运行的过程中, 阻塞主线程直至传入的协程运行结束 否则如果主线程结束，所有的协程都会被垃圾回收程序收回而提前终止 返回: 返回一个元组, 第一个元素是一系列结束的期物, 第二个元素是一系列未结束的期物 返回值中未完成的期物受 wait 函数的 timeout, return_when 参数影响 附注: 因为参数只接受一个协程，同时启动多个协程时，需要使用 wait 函数将多个协程包装进一个 Task 对象 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:4","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.5 其他函数和对象 asyncio.as_completed: 参数: 一个期物列表 作用：获取协程运行的返回结果 返回值: 一个迭代器, 在期物运行结束后产出期物 附注: asyncio.as_completed 函数返回的期物与传给 as_completed 函数的期物可能不同, 在 asyncio 包内部, 我们提供的期物会被替换成生成相同结果的期物，原因参见 Which other futures my come out of asyncio.as_completed? https://groups.google.com/forum/#!msg/python-tulip/PdAEtwpaJHs/7fqbQj2zJoJ 必须使用 yield from 获取 asyncio.as_completed 函数产出的期物的结果， 所以 as_completed 函数必须在协程中调用 asyncio.Semaphore(concur_req): 参数: concur_req - 并发协程数 作用: 同步装置, 用于限制并发请求数量 Semaphore 对象维护着一个内部计数器, 若在对象上调用 .acquire() 协程方法, 计数器则递减; 若在对象上调用 .release() 协程方法, 计数器则递增 如果计数器大于零, 调用 .acquire() 方法不会阻塞; 如果计数器为零, 那.acquire() 方法 会阻塞调用此方法的协程, 直到其他协程在同一个 Semaphore 对象上调用 .release() 方法, 让计数器递增 使用: 可以当作上下文管理器使用 # 在 yield from 表达式中把 semaphore 当成上下文管理器使用 # 这段代码保证, 任何时候都不会有超过 concur_req 个 get_flag 协程启动 with (yield from semaphore): image = yield from get_flag(base_url, cc) ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:5","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.6 使用Executor对象 背景: 问题: asyncio 不支持异步文件系统I/O 访问本地文件系统会阻塞了客户代码与 asyncio 事件循环共用的唯一线程 解决方法: 使用额外的线程进行文件系统操作 loop.run_in_executor(executor, func, *args) loop: asyncio 的事件循环对象, 其维护着一个 ThreadPoolExecutor 对象 作用: 把可调用对象传递给 ThreadPoolExecutor 委托给线程池 参数: executor: Executor 实例; 如果设为 None, 使用事件循环默认的 ThreadPoolExecutor 实例 func: 可调用对象 args: 传递给可调用对象的参数 文档: https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor loop = asyncio.get_event_loop() loop.run_in_executor(None, save_flag, image, cc.lower() + '.gif') ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:6","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.7 asyncio 使用示例 aiohttp import asyncio import collections import contextlib import aiohttp from aiohttp import web import tqdm from flags2_common import main, HTTPStatus, Result, save_flag # default set low to avoid errors from remote site, such as # 503 - Service Temporarily Unavailable DEFAULT_CONCUR_REQ = 5 MAX_CONCUR_REQ = 1000 class FetchError(Exception): # 用于包装其他 HTTP 或网络异常，并获取 country_code，以便报告错误 def __init__(self, country_code): self.country_code = country_code # BEGIN FLAGS3_ASYNCIO @asyncio.coroutine def http_get(url): res = yield from aiohttp.request('GET', url) if res.status == 200: ctype = res.headers.get('Content-type', '').lower() if 'json' in ctype or url.endswith('json'): data = yield from res.json() # \u003c1\u003e else: data = yield from res.read() # \u003c2\u003e return data elif res.status == 404: raise web.HTTPNotFound() else: raise aiohttp.errors.HttpProcessingError( code=res.status, message=res.reason, headers=res.headers) @asyncio.coroutine def get_country(base_url, cc): url = '{}/{cc}/metadata.json'.format(base_url, cc=cc.lower()) metadata = yield from http_get(url) # \u003c3\u003e return metadata['country'] @asyncio.coroutine def get_flag(base_url, cc): url = '{}/{cc}/{cc}.gif'.format(base_url, cc=cc.lower()) # 必须在外层加上括号，直接写 return yield from， Python 解析器会报告句法错误 return (yield from http_get(url)) # \u003c4\u003e 附注: 最内层的子生成器是库中真正执行 I/O 操作的函数, 而不是我们自己编写的函数 使用 asyncio 包时，我们编写的异步代码中包含由 asyncio 本身驱动的协程（即委派生成器）， 而生成器最终把职责委托给 asyncio 包或第三方库（如 aiohttp）中的协程。 这种处理方式相当于架起了管道，让 asyncio 事件循环（通过我们编写的协程） 驱动执行低层异步 I/O 操作的库函数 run_in_executor # BEGIN FLAGS2_ASYNCIO_EXECUTOR @asyncio.coroutine def download_one(cc, base_url, semaphore, verbose): try: # 如果semaphore 计数器的值是所允许的最大值，只有这个协程会阻塞 # 使用 一个 with 和使用 两个 with 有区别么？？？？ with (yield from semaphore): # \u003c5\u003e image = yield from get_flag(base_url, cc) with (yield from semaphore): country = yield from get_country(base_url, cc) except web.HTTPNotFound: status = HTTPStatus.not_found msg = 'not found' except Exception as exc: # raise X from Y 句法链接原来的异常 raise FetchError(cc) from exc else: country = country.replace(' ', '_') filename = '{}-{}.gif'.format(country, cc) loop = asyncio.get_event_loop() loop.run_in_executor(None, save_flag, image, filename) status = HTTPStatus.ok msg = 'OK' if verbose and msg: print(cc, msg) return Result(status, cc) # END FLAGS2_ASYNCIO_EXECUTOR as_completed, Semaphore @asyncio.coroutine def downloader_coro(cc_list, base_url, verbose, concur_req): counter = collections.Counter() # 最多允许激活 concur_req 个使用这个计数器的协程 semaphore = asyncio.Semaphore(concur_req) to_do = [download_one(cc, base_url, semaphore, verbose) for cc in sorted(cc_list)] # 获取一个迭代器，这个迭代器会在期物运行结束后返回期物 to_do_iter = asyncio.as_completed(to_do) if not verbose: to_do_iter = tqdm.tqdm(to_do_iter, total=len(cc_list)) for future in to_do_iter: try: # 获取 asyncio.Future 对象的结果， # 最简单的方法是使用 yield from，而不是调用future.result() 方法 res = yield from future except FetchError as exc: # asyncio.as_completed 函数返回的期物与传给 as_completed 函数的期物可能不同 # 因此通过 FetchError 包装网络异常，并关联相应的国家代码 country_code = exc.country_code try: # 尝试从原来的异常（ __cause__）中获取错误消息 error_msg = exc.__cause__.args[0] except IndexError: # 如果在原来的异常中找不到错误消息，使用所链接异常的类名作为错误消息 error_msg = exc.__cause__.__class__.__name__ if verbose and error_msg: msg = '*** Error for {}: {}' print(msg.format(country_code, error_msg)) status = HTTPStatus.error else: status = res.status counter[status] += 1 return counter run_until_complete def download_many(cc_list, base_url, verbose, concur_req): loop = asyncio.get_event_loop() coro = downloader_coro(cc_list, base_url, verbose, concur_req) counts = loop.run_until_complete(coro) loop.close() return counts ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:7","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"3.8 协程与线程对比 线程版示例程序 def slow_function(): # 假设这是耗时的计算 time.sleep(3) # 调用 sleep 阻塞主线程, 一定要这么做, 以便释放 GIL, 创建从属线程 return 42 def supervisor(): done = threading.Event() spinner = threading.Thread(target=spin, args=('thinking!', done)) print('spinner object: ', spinner) spinner.start() # Thread 实例必须调用 start 方法, 明确告知让它运行 # 相当于耗时操作阻塞了主线程。同时, 从属线程以动画形式显示旋转指针 result = slow_function() done.set() # 向子线程发送终止信号 spinner.join() # 等待 spinner 线程结束 return result 协程版示例程序 @asyncio.coroutine # \u003c1\u003e asyncio 处理的协程要使用 @asyncio.coroutine 装饰 def spin(msg): # \u003c2\u003e 不是强制要求, 但是强烈建议这么做 write, flush = sys.stdout.write, sys.stdout.flush for char in itertools.cycle('|/-\\\\'): status = char + ' ' + msg write(status) flush() write('\\x08' * len(status)) try: yield from asyncio.sleep(.1) # \u003c3\u003e 休眠不会阻塞事件循环 except asyncio.CancelledError: # \u003c4\u003e 发出了取消请求而触发的异常 break write(' ' * len(status) + '\\x08' * len(status)) @asyncio.coroutine def slow_function(): # \u003c5\u003e 假装进行 I/O 操作时, 使用 yield from 继续执行事件循环 # pretend waiting a long time for I/O yield from asyncio.sleep(3) # \u003c6\u003e 控制权交给主循环, 在休眠结束后恢复这个协程 return 42 @asyncio.coroutine def supervisor(): # \u003c7\u003e # 排定 spin 协程的运行时间, 使用一个 Task 对象包装 spin 协程, 并立即返回 spinner = asyncio.async(spin('thinking!')) # 获取的 Task 对象已经排定了运行时间 print('spinner object: ', spinner) # \u003c9\u003e # 使用 yield from 驱动 slow_function 函数, 同时, 事件循环继续运行 result = yield from slow_function() # \u003c10\u003e # Task 对象可以取消; 取消后会在协程当前暂停的 yield 处抛出 asyncio.CancelledError异常 # 协程可以捕获这个异常, 也可以延迟取消, 甚至拒绝取消 spinner.cancel() # \u003c11\u003e return result def main(): loop = asyncio.get_event_loop() # \u003c12\u003e 获取事件循环的引用 # 驱动 supervisor 协程, 让它运行完毕 result = loop.run_until_complete(supervisor()) # \u003c13\u003e loop.close() print('Answer: ', result) 附注: 除非想阻塞主线程, 从而冻结事件循环或整个应用, 否则不要在 asyncio 协程中使用 time.sleep(…) 如果协程需要在一段时间内什么也不做, 应该使用 yield from asyncio.sleep(DELAY) ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:3:8","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"4. 使用asyncio包编写服务器 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:4:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"4.1 编写TCP服务器 #!/usr/bin/env python3 # BEGIN TCP_CHARFINDER_TOP import sys import asyncio from charfinder import UnicodeNameIndex # \u003c1\u003e 构建名称索引, 提供查询方法 CRLF = b'\\r\\n' PROMPT = b'?\u003e ' index = UnicodeNameIndex() # \u003c2\u003e @asyncio.coroutine def handle_queries(reader, writer): # \u003c3\u003e 要传给 asyncio.start_server 的函数 while True: # \u003c4\u003e 两个参数是 asyncio.StreamReader 和 asyncio.StreamWriter 对象 writer.write(PROMPT) # 把数据写入缓冲, 通常不会阻塞, 因此不是协程, 只是普通的函数 yield from writer.drain() # 刷新 writer 缓冲; 执行真正的I/O操作, 所以是协程 data = yield from reader.readline() # \u003c7\u003e 协程, 返回一个 bytes 对象。 try: query = data.decode().strip() except UnicodeDecodeError: # \u003c8\u003e query = '\\x00' client = writer.get_extra_info('peername') # \u003c9\u003e 返回与套接字连接的远程地址 print('Received from {}: {!r}'.format(client, query)) # \u003c10\u003e if query: if ord(query[: 1]) \u003c 32: # \u003c11\u003e 如果收到控制字符或者空字符, 退出循环 break lines = list(index.find_description_strs(query)) # \u003c12\u003e if lines: writer.writelines(line.encode() + CRLF for line in lines) # \u003c13\u003e writer.write(index.status(query, len(lines)).encode() + CRLF) # \u003c14\u003e yield from writer.drain() # \u003c15\u003e 刷新输出缓冲 print('Sent {} results'.format(len(lines))) # \u003c16\u003e print('Close the client socket') # \u003c17\u003e writer.close() # \u003c18\u003e 关闭 StreamWriter 流 # END TCP_CHARFINDER_TOP # BEGIN TCP_CHARFINDER_MAIN def main(address='127.0.0.1', port=2323): # \u003c1\u003e port = int(port) loop = asyncio.get_event_loop() # 返回的协程对象是一个 asyncio.Server 实例, 即一个 TCP 套接字服务器 server_coro = asyncio.start_server(handle_queries, address, port, loop=loop) # \u003c2\u003e # 驱动 server_coro 协程, 启动服务器（ server） server = loop.run_until_complete(server_coro) # \u003c3\u003e host = server.sockets[0].getsockname() # \u003c4\u003e print('Serving on {}. Hit CTRL-C to stop.'.format(host)) # \u003c5\u003e try: loop.run_forever() # \u003c6\u003e 运行事件循环; main 函数在这里阻塞 except KeyboardInterrupt: # CTRL+C pressed pass print('Server shutting down.') server.close() # \u003c7\u003e 关闭服务器 # server.wait_closed() 方法返回一个期物，调用 loop.run_until_complete 方法运行期物 loop.run_until_complete(server.wait_closed()) # \u003c8\u003e loop.close() # \u003c9\u003e 终止事件循环 if __name__ == '__main__': main(*sys.argv[1: ]) # \u003c10\u003e # END TCP_CHARFINDER_MAIN 控制权流动: main 函数几乎会立即显示 Serving on… 消息，然后在调用 loop.run_forever() 时阻塞 控制权流动到事件循环中, 而且一直待在那里 偶尔会回到handle_queries 协程, 这个协程需要等待网络发送或接收数据时, 控制权又交还事件循环 在事件循环运行期间, 只要有新客户端连接服务器就会启动一个 handle_queries 协程实例 asyncio.start_server: 返回: start_server 协程运行结束后，返回的协程对象返回一个 asyncio.Server实例， 即一个 TCP 套接字服务器 高层流 API: asyncio 包提供了高层流 API,有现成的服务器可用 http://docs.python.org/3/library/asyncio-stream.html 底层流API: asyncio 包受 Twisted 框架中抽象的传送和协议启发，还提供了低层传送和协议 API http://docs.python.org/3/library/asyncioprotocol.html loop.run_forever() 运行事件循环； main 函数在这里阻塞，直到在服务器的控制台中按 CTRL-C 键才会关闭 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:4:1","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"4.2 编写Web服务器 index = UnicodeNameIndex() with open(TEMPLATE_NAME) as tpl: template = tpl.read() template = template.replace('{links}', LINKS_HTML) # BEGIN HTTP_CHARFINDER_HOME def home(request): # 一个路由处理函数, 参数是一个 aiohttp.web.Request 实例 query = request.GET.get('query', '').strip() # 获取查询字符串, 去掉首尾的空白 print('Query: {!r}'.format(query)) # \u003c3\u003e if query: # \u003c4\u003e descriptions = list(index.find_descriptions(query)) res = '\\n'.join(ROW_TPL.format(**descr._asdict()) for descr in descriptions) msg = index.status(query, len(descriptions)) else: descriptions = [] res = '' msg = 'Enter words describing characters.' html = template.format(query=query, result=res, # \u003c5\u003e message=msg) print('Sending {} results'.format(len(descriptions))) # \u003c6\u003e return web.Response(content_type=CONTENT_TYPE, text=html) # \u003c7\u003e # END HTTP_CHARFINDER_HOME # BEGIN HTTP_CHARFINDER_SETUP @asyncio.coroutine def init(loop, address, port): # init 协程产出一个服务器, 交给事件循环驱动 app = web.Application(loop=loop) # aiohttp.web.Application 类表示 Web 应用 app.router.add_route('GET', '/', home) # 通过路由把 URL 模式映射到处理函数上 # 返回一个 aiohttp.web.RequestHandler 实例, 根据 app 对象设置的路由处理 HTTP 请求 handler = app.make_handler() # create_server 方法创建服务器, 以 handler 为协议处理程序 server = yield from loop.create_server(handler, address, port) # \u003c5\u003e return server.sockets[0].getsockname() # \u003c6\u003e def main(address=\"127.0.0.1\", port=8888): port = int(port) loop = asyncio.get_event_loop() # 运行 init 函数, 启动服务器, 获取服务器的地址和端口 host = loop.run_until_complete(init(loop, address, port)) # \u003c7\u003e print('Serving on {}. Hit CTRL-C to stop.'.format(host)) try: loop.run_forever() # \u003c8\u003e main 函数会在这里阻塞 except KeyboardInterrupt: # CTRL+C pressed pass print('Server shutting down.') loop.close() # \u003c9\u003e Server 对象: asyncio.start_server函数和loop.create_server方法都是协程, 返回的结果都是 asyncio.Server对象 为了启动服务器并返回服务器的引用, 这两个协程都要由他人驱动, 完成运行 在 TCP 示例中，做法是调用 loop.run_until_complete(server_coro)， 其中 server_coro 是 asyncio.start_server 函数返回的结果 在 HTTP 示例中， create_server 方法在 init 协程中的一个 yield from 表达式里调用， 而 init 协程则由 main 函数中的 loop.run_until_complete(init(…)) 调用驱动 web.Application.add_route: 文档: http://aiohttp.readthedocs.org/en/v0.14.4/web_reference.html#aiohttp.web.UrlDispatcher.add_route 附注: 如果处理程序是普通的函数, 在内部会将其转换成协程 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:4:2","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"4.3 服务器设计可用工具 aiopg: 作用: 提供了一个异步 PostgreSQL 驱动 与 asyncio 包兼容, 支持使用 yield from 发送查询和获取结果 文档: http://aiopg.readthedocs.org/en/stable/ ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:4:3","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:5:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"Python: asyncio: 主页: http://www.kancloud.cn/kindjeff/asyncio-zh/217030 使用模式介绍: http://docs.python.org/3/library/asyncio-dev.html asyncio 学习资源: http://haypo-notes.readthedocs.org/asyncio.html http://asyncio.org/ http://github.com/aio-libs 说明: 在这两个网站中能找到 PostgreSQL、 MySQL 和多种 NoSQL 数据库的异步驱动 aiohttp: 文档: http://aiohttp.readthedocs.org/en/ Vaurien 作用: 在程序与后端服务器（eg: 数据库和Web 服务提供方）之间的 TCP 流量中引入延迟和随机错误 为 Mozilla Services 项目开发 文档: http://vaurien.readthedocs.org/en/1.8/ Mozilla Services 项目: http://mozilla-services.github.io/ ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:5:1","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"blog: 演讲视频: http://speakerdeck.com/pycon2014/fan-in-and-fan-out-the-crucial-components-of-concurrency-bybrett-slatkin http://www.youtube.com/watch?v=CWmq-jtkemY http://pyvideo.org/video/1667/keynote-1 http://www.youtube.com/watch?v=1coLC-MUCJc http://www.youtube.com/watch?v=MS1L2RGKYyY ppt: http://www.slideshare.net/saghul/asyncio http://pyvideo.org/video/1762/using-futures-for-async-guiprogramming-in-python 文章: 标题: Python’s asyncio Is for Composition, Not Raw 链接: http://www.onebigfluke.com/2015/02/asyncio-is-for-composition.html Using futures for asyncGUI programming in Python 3.3” 说明: 如何把 asyncio 包集成到 Tkinter 事件循环中 http://pyvideo.org/video/1762/using-futures-for-async-guiprogramming-in-python http://github.com/fluentpython/asyncio-tkinter ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:5:2","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:5:3","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"文章: 相关文章: https://mp.weixin.qq.com/s/E-7bMIdmzerr7xpSqD0YXg http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:5:4","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Python"],"content":"附注 Python 异步库 Twisted 是 Node.js 的灵感来源之一 Tornado 拥护使用协程做面向事件编程 异步库兼容: 设计 asyncio 包时考虑到了使用外部包替换自身的事件循环, 因此才有 asyncio.get_event_loop 和 set_event_loop 函数——二者是抽象的事件循环策略API http://docs.python.org/3/library/asyncio-eventloops.html#event-loop-policies-and-thedefault-policy Tornado 已经有实现 asyncio.AbstractEventLoop 接口的类 AsyncIOMainLoop http://tornado.readthedocs.org/en/latest/asyncio.html 因此在同一个事件循环中可以使用这两个库运行异步代码 Quamash 项目: 文档: http://pypi.python.org/pypi/Quamash/ 把 asyncio 包集成到 Qt 事件循环中, 以便使用 PyQt 或 PySide 开发 GUI 应用 Django: 传统框架的目的是渲染完整的 HTML 网页, 而且不支持异步访问数据库 WebSockets 协议: 作用是为始终连接的客户端（例如游戏和流式应用）提供实时更新 asyncio 包的架构能很好地支持 WebSockets, 以下包在 asyncio 基础上实现了 WebSockets - Autobahn|Python: http://autobahn.ws/python/ - WebSockets: http://aaugustin.github.io/websockets/ 异步数据库 API 3.0: http://www.python.org/dev/peps/pep-0249/ asyncio.Future 类与 Twisted 中的Deferred 类不同的原因: http://groups.google.com/forum/#!msg/python-tulip/ut4vTG-08k8/PWZzUXX9HYIJ ","date":"2018-01-18","objectID":"/posts/program/python/grammar/fluent-python/18_asyncio/:6:0","tags":["python 进阶"],"title":"asyncio","uri":"/posts/program/python/grammar/fluent-python/18_asyncio/"},{"categories":["Linux"],"content":"6.8 bash 配置文件","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"bash 配置文件 bash 的配置文件也是 shell 脚本，用于定义环境变量，别名或运行一些特殊用途的脚本。比如一些特殊用途的别名，我们不想每次登陆 shell 后都重新设置，可以定义在配置文件中；又比如想将一些特定目录添加到 PATH 环境变量中等等。要理解 bash 的配置文件，我们首先需要明白 bash 的两种登陆类型，它们会分别读取不同的配置文件，所以本节的内容如下: bash 中的登陆类型 bash 配置文件类型 配置文件的生效过程 ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:0:0","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"1. bash 中的登陆类型 bash 中配置文件大致分为交互式登录和非交互式登录 两种类型。每种类型发生的情景对应如下: 交互式登录shell进程： 直接通过某终端输入账号和密码后登录打开的shell进程； 使用su命令：su - USERNAME, 或 su -l USERNAME 执行的登录切换； 非交互式登录shell进程： su USERNAME执行的登录切换； 图形界面下打开的终端； 运行脚本 ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:1:0","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"2. bash的配置文件类型 针对两种登陆类型，配置文件也分成了两类： profile类：为交互式登录的shell进程提供配置 bashrc类：为非交互式登录的shell进程提供配置 ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:0","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"2.1 profile类配置文件 profile: 作用: 用于定义环境变量； 运行命令或脚本； 位置: 全局配置：对所有用户都生效； /etc/profile /etc/profile.d/*.sh 用户个人：仅对当前用户有效； ~/.bash_profile 注意：仅管理员可修改全局配置文件； ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:1","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"2.2 bashrc类配置文件 bashrc: 作用: 定义本地变量； 定义命令别名； 位置: 全局配置：/etc/bashrc 用户个人：~/.bashrc 注意：仅管理员可修改全局配置文件； ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:2:2","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Linux"],"content":"3. 配置文件的生效过程 交互式登录: /etc/profile --\u003e /etc/profile.d/* --\u003e ~/.bash_profile --\u003e ~/.bashrc --\u003e /etc/bashrc 非交互式登录: ~/.bashrc --\u003e /etc/bashrc --\u003e /etc/profile.d/* 需要注意的配置文件和命令行定义的配置具有不同的生效时间: 对于命令行，例如变量和别名作用域为当前shell进程的生命周期； 对于配置文件，虽然可以永久有效，但是只对随后新启动的shell进程才有效，对当前shell 无效； 因此让配置文件定义的特性立即生效需要额外操作，有两种方法可供选择 通过命令行重复定义一次； 让shell进程重读配置文件； source /PATH/FROM/CONF_FILE . /PATH/FROM/CONF_FILE ","date":"2018-01-17","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/:3:0","tags":["马哥 Linux"],"title":"6.8 bash 配置文件","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"categories":["Python"],"content":"Python futrue","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"1. futrue 的概念 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:1:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"1.1 对 futrue 的理解 期物： 包括： concurrent.futures.Future 类 asyncio.Future 类 Twisted 的 Deferred 类 Tornado 的 Future 类 作用： 指一种对象, 表示异步执行的操作 类的实例表示可能已经完成或者尚未完成的延迟计算 理解： 期物封装待完成的操作, 可以放入队列 完成的状态可以查询, 得到结果(或抛出异常)后可以获取结果(或异常) ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:1:1","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2. concurrent.futures 组成： Executor 类： 顶层接口类, 提供了多线程, 多进程并发执行的接口 封装了实例化和操作 Future 对象的接口 Future 类：模块的基本组件, 用于实现并发操作的基本对象 其他函数：直接操作 Future 实例的函数 文档： https://docs.python.org/3/library/concurrent.futures.html https://www.python.org/dev/peps/pep-3148/ ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2.1 Executor 类 ThreadPoolExecutor 类 作用：在不同线程中执行可调用的对象 实现：在内部维护着一个 工作线程池, 以及要执行的任务队列 适用：I/O 密集型应用 初始化： __init__(self, max_workers=None): max_workers:启用线程数 ProcessPoolExecutor 类 作用：在不同进程中执行可调用的对象 实现：在内部维护着一个 工作进程池, 以及要执行的任务队列 适用： CPU 密集型处理, 使用这个模块能绕开 GIL, 利用所有可用的 CPU 核心 初始化： __init__(self, max_workers=None): max_workers:启用进程数, 可选, 默认是os.cpu_count() 函数返回的 CPU 数量 ThreadPoolExecutor 使用示例 from concurrent import futures def download_many(cc_list): workers = min(MAX_WORKERS, len(cc_list)) with futures.ThreadPoolExecutor(workers) as executor: ➎ res = executor.map(download_one, sorted(cc_list)) ➏ return len(list(res)) ➐ ➎ executor.__exit__ 方法 会调用executor.shutdown(wait=True) 方法, 在所有线程都执行完毕前阻塞线程 ➏ map 方法 非阻塞调用, 作用与内置的 map 函数类似 不过 download_one 函数会在多个线程中并发调用 返回一个生成器 ➐ 返回获取的结果数量 隐式调用 next()函数从 map 返回的迭代器中获取相应的返回值 如果有线程抛出异常, 异常会在这里抛出 迭代返回结果的顺序与调用开始的顺序一致 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:1","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2.2 Future 实例化 附注： 通常情况下自己不应该创建期物, 只能由并发框架(concurrent.futures 或 asyncio)实例化 原因是期物表示终将发生的事情, 而确定某件事会发生的唯一方式是执行的时间已经排定, 因此只有排定把某件事交给concurrent.futures.Executor子类处理时, 才会创建concurrent.futures.Future实例 Executor = futures.ThreadPoolExecutor(workers) Executor = futures.ProcessPoolExecutor(workers) workers：并发线程或进程数 从Executor获取 Future 实例 |接口|参数|作用|返回值| |:—|:—|:—| |Executor.submit()|一个可调用的对象|为传入的可调用对象排期|一个期物(Future类实例)| 可用方法 附注： 客户端代码不应该改变期物的状态, 并发框架在期物表示的延迟计算结束后会改变期物的 状态, 而我们无法控制计算何时结束 客户端代码通常不会询问期物是否运行结束, 而是会等待通知 方法： Future.done() 作用：不阻塞, 指明期物链接的可调用对象是否已经执行, 返回一个布尔值 Future.add_done_callback()： 参数：可调用对象 作用：期物运行结束后会调用传入的可调用对象 Future.result(): 在期物运行结束后调用 返回可调用对象的结果 或者重新抛出执行可调用的对象时抛出的异常 期物没有运行结束时调用 会阻塞调用方所在的线程, 直到有结果可返回 result 可以接收可选的 timeout 参数, 如果在指定的时间内期物没有运行完毕, 会抛出 TimeoutError 异常 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:2","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2.3 其他函数 as_completed(): 参数：一个期物列表 返回值：一个迭代器, 在期物运行结束后产出期物 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:3","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2.4 使用示例 def download_many(cc_list): cc_list = cc_list[:5] ➊ with futures.ThreadPoolExecutor(max_workers=3) as executor: ➋ # 创建并排定期物 to_do = [] for cc in sorted(cc_list): ➌ future = executor.submit(download_one, cc) ➍ to_do.append(future) ➎ msg = 'Scheduled for {}: {}' print(msg.format(cc, future)) ➏ # 获取期物的结果 results = [] for future in futures.as_completed(to_do): ➐ res = future.result() ➑ msg = '{} result: {!r}' print(msg.format(future, res)) ➒ results.append(res) return len(results) ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:4","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"2.5 Executor.map 与 as_completed 对比 Executor.map: 返回一个迭代器, 迭代此生成器返回结果的顺序与调用开始的顺序一致, eg：如果第一个调用生成结果用时 10秒, 而其他调用只用 1 秒, 代码会阻塞 10 秒, 获取 map 方法返回的生成器产出的第一个结果 executor.map 只能处理参数不同的同一个可调用对象 Executor.submit 和 futures.as_complete 结合： as_complete 返回的生成器在迭代时，不管提交的顺序, 只要有结果就获取 submit 方法能处理不同的可调用对象和参数 传给 futures.as_completed 函数的期物集合也可以来自多个 Executor 实例 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:2:5","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"3. GIL ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:3:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"3.1 阻塞型I/O和GIL GIL - 全局解释器锁: CPython 解释器本身就不是线程安全的, 因此有全局解释器锁(GIL), 一次只允许使用一 个线程执行 Python 字节码 编写 Python 代码时无法控制 GIL；不过, 执行耗时的任务时, 可以使用一个内置的函数 或一个使用 C 语言编写的扩展释放 GIL 其实, 有个使用 C 语言编写的 Python 库能管理GIL, 自行启动操作系统线程, 利用全部可用的 CPU 核心。这样做会极大地增加库代码的复杂度, 因此大多数库的作者都不这么做 标准库中所有执行阻塞型 I/O 操作的函数, 在等待操作系统返回结果时都会释放GIL 这意味着在 Python 语言这个层次上可以使用多线程, 而 I/O 密集型 Python 程序能从 中受益：一个 Python 线程等待网络响应时, 阻塞型 I/O 函数会释放 GIL, 再运行一个线程 GIL 存在原因： 简化了 CPython 解释器和 C 语言扩展的实现, 得益于 GIL, Python 有很多 C 语言扩展 结论：I/O 密集型应用, 适合使用Python 多线程 附注：sleep 函数总会释放 GIL。因此, 即使休眠 0 秒, Python 也可能会切换到另一个线程 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:3:1","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"3.2 CPU 密集型应用 CPU 密集型应用可用方案： 可以使用多进程绕开 GIL, 利用所有可用的 CPU 核心, eg：ProcessPoolExecutor 使用PyPy(http://pypy.org) Apache Spark:分布式计算引擎 https://spark.apache.org/examples.html JOBS = 12 SIZE = 2**20 STATUS = '{} workers, elapsed time: {:.2f}s' def sha(size): data = bytearray(randrange(256) for i in range(size)) algo = hashlib.new('sha256') algo.update(data) return algo.hexdigest() def main(workers=None): if workers: workers = int(workers) t0 = time.time() with futures.ProcessPoolExecutor(workers) as executor: actual_workers = executor._max_workers to_do = (executor.submit(sha, SIZE) for i in range(JOBS)) for future in futures.as_completed(to_do): res = future.result() print(res) ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:3:2","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"4. 完整示例 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:4:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"4.1 背景 示例说明：2.4 的示例扩展, 增加错误处理和进度条 TQDM： 文档：https://github.com/noamraph/tqdm 作用：实现的文本动画进度条 接口：为了计算预计剩余时间, tqdm 函数要获取一个能使用 len 函数确定大小的可迭代对象, 或者在第二个参数中指定预期的元素数量 def download_many(cc_list, base_url, verbose, max_req): counter = collections.Counter() cc_iter = sorted(cc_list) if not verbose: cc_iter = tqdm.tqdm(cc_iter) # 能使用 len 函数确定大小的可迭代对象 for cc in cc_iter: # 返回一个迭代器, 产出 cc_iter 中的元素, 还会显示进度条动画。 ....... ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:4:1","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"4.2 多线程版本 import collections from concurrent import futures import requests import tqdm # \u003c1\u003e from flags2_common import main, HTTPStatus # \u003c2\u003e from flags2_sequential import download_one # \u003c3\u003e DEFAULT_CONCUR_REQ = 30 # \u003c4\u003e MAX_CONCUR_REQ = 1000 # \u003c5\u003e def download_many(cc_list, base_url, verbose, concur_req): counter = collections.Counter() with futures.ThreadPoolExecutor(max_workers=concur_req) as executor: # \u003c6\u003e # 构建并排定期物 to_do_map = {} # \u003c7\u003e for cc in sorted(cc_list): # \u003c8\u003e future = executor.submit(download_one, cc, base_url, verbose) # \u003c9\u003e to_do_map[future] = cc # 把各个期物映射到其他数据(期物运行结束后可能有用) # 获取期物的结果 done_iter = futures.as_completed(to_do_map) # \u003c11\u003e if not verbose: # done_iter 没有 len 函数, 必须通过 total 参数告诉 tqdm 函数预期的元素数量 done_iter = tqdm.tqdm(done_iter, total=len(cc_list)) # \u003c12\u003e for future in done_iter: # \u003c13\u003e 迭代的是期物, 无法直接知道当前处理的是哪个国家 try: res = future.result() # \u003c14\u003e except requests.exceptions.HTTPError as exc: # \u003c15\u003e error_msg = 'HTTP {res.status_code} - {res.reason}' error_msg = error_msg.format(res=exc.response) except requests.exceptions.ConnectionError as exc: error_msg = 'Connection error' else: error_msg = '' status = res.status if error_msg: status = HTTPStatus.error counter[status] += 1 if verbose and error_msg: cc = to_do_map[future] # \u003c16\u003e print('*** Error for {}: {}'.format(cc, error_msg)) return counter ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:4:2","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"5. 多线程, 多进程实现 concurrent.futures 特点：只不过是使用线程的最新方式 适用：线程或进程之间相互独立, 无需进行线程间或进程间通信(高度并行问题) 缺点：缺乏灵活性 threading 模块： 作用：Python 多线程原生库 文档：https://docs.python.org/3/library/threading.html 接口： 基本组件：Thread、 Lock、 Semaphore 等 通信：可以使用 queue 模块创建线程安全的队列, 在线程之间传递数据 multiprocessing 模块 作用：Python 多进程原生库 文档：https://docs.python.org/3/library/multiprocessing.html 接口： API：threading 模块相仿, 不过作业交给多个进程处理 通信：支持基础设施的锁、队列、管道、共享内存, 等等 lelo 库 文档：https://pypi.python.org/pypi/lelo 作用：使用 多进程 处理并行任务 接口：定义了一个 @parallel 装饰器, 可以应用到任何函数上, 把函数变成非阻塞： 调用被装饰的函数时, 函数在一个新进程中执行 python-parallelize 文档：https://github.com/npryce/python-parallelize 作用：使用 多进程 处理并行任务 接口：提供了一个 parallelize 生成器, 能把 for 循环分配给多个 CPU 执行 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:5:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:6:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"Python: 标准库 queue： 作用：线程安全的队列 文档：https://docs.python.org/3/library/queue.html GIL： 文档：https://docs.python.org/3/faq/library.html#id18 其他： It isn’t Easy to Remove the GIL: http://www.artima.com/weblogs/viewpost.jsp?thread=214235 Python Threadsand the Global Interpreter Lock: http://jessenoller.com/2009/02/01/python-threads-and-the-globalinterpreter-lock/ Understanding the Python GIL: http://www.dabeaz.com/GIL/ ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:6:1","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"blog: ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:6:2","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:6:3","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"书籍: 《Parallel Programming with Python》 《Python Cookbook(第 3 版)中文版》 11.12 理解事件驱动型 I/O 12.7 创建线程池 12.8 实现简单的并行编程 《Effective Python：编写高质量 Python 代码的 59 个有效方法》 协程； 使用 concurrent.futures 库处理线程和进程； 不使用 ThreadPoolExecutor 类, 而使用锁和队列做线程编程 《High Performance Python》 《Python 标准库》 《七周七并发模型》 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:6:4","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Python"],"content":"杂谈 高度并行问题：https://en.wikipedia.org/wiki/Embarrassingly_parallel Elixir 语言 Go 语言 Go 不支持宏, 句法比 Python 简单; 也不支持继承和运算符重载, 而且提 供的元编程支持没有 Python 多 这些限制被认为是 Go 语言的特点, 因为行为和性能更可预料。这对高并发来说是好事 JavaScript： 根本不支持用户层级的线程, 只能通过回调式异步编程实现并发 ","date":"2018-01-17","objectID":"/posts/program/python/grammar/fluent-python/17_future/:7:0","tags":["python 进阶"],"title":"futrue","uri":"/posts/program/python/grammar/fluent-python/17_future/"},{"categories":["Linux"],"content":"6.7 程序交互与信号捕捉","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"程序交互，退出状态与信号捕捉 本节我们开始学习 bash shell 编程的第七部分，包含以下内容: 如何在程序执行过程中与用户交互 bash 编程调试 设置脚本执行的状态返回值 如何在 bash 中使用 ASCII 颜色 dialog 实现窗口化编程 信号捕捉 ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:0:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"1. 用户交互 bash 中与用户交互主要通过 read 命令完成，read 可以输出一段文字提示用户输入指定内容，并将用户输入保存在特定变量中，read 的使用方式如下 read [OPTIONS] [变量名 ...] 作用:从标准输入读取一行并将其分为不同的域 选项: -p 提示符: 用户提示符 -t 超时: 设置等待用户输入的超时时长，单位秒 -a 数组 -d 分隔符 -i 缓冲区文字 -n 读取字符数 -N 读取字符数 -u 文件描述符 \u003e read -p \"enter a disk filename\" -t 5 name \u003e [ -z \"$name\" ] \u0026\u0026 name=\"value\" \u003e read a b jerry mark cd \u003e echo $a jerry \u003e echo $b # 值个数多于变量个数时，所有多余的变量默认保存在最后一个变量中 mark cd ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:1:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"2. bash 调试 bash 命令有两个参数可以帮助我们调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:2:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"3. 脚本的状态返回值 之前我们说过，程序执行有状态返回值，保存在 $? 变量中。shell 脚本的状态返回值有如下特点: 默认是脚本中执行的最后一条件命令的状态返回值 使用 exit [n] 可自定义退出状态码，n 位于 0-255 之间，0 表示执行成功无异常，默认为 0 exit 类似 python 中的return，程序遇到 exit 即终止 ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:3:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"4. 在bash中使用ACSII颜色 \\033[31m hello \\033[0m 格式: \\033[31m 表示颜色控制开始符，\\033[0m 表示颜色控制结束符，中间为要显示的文本 颜色控制: ##m(31m) - 左侧#： - 3：表示前景色 - 4：表示背景色 - 右侧 #: 表示颜色种类, 范围是 1, 2, 3, 4, 5, 6, 7 格式控制: #m(5m) 加粗、闪烁等功能； 组合: 多种控制符，可组合使用，彼此间用分号隔开； tao@hp:shell$ echo -e \"\\033[31m htto \\033[0m\" htto tao@hp:shell$ echo -e \"\\033[41;32m htto \\033[0m\" htto tao@hp:shell$ echo -e \"\\033[42;35;4m htto \\033[0m\" htto ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:4:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"5. dialog 实现窗口化编程 yum install dialog -y dialog --msgbox hello 17 30 本节我们来学习 bash shell 编程的第九部分如何在 shell 中捕捉信号。shell 中捕捉信号主要是使用 shell 内置的 trap 命令。shell 中的信号捕捉有以下几点需要特别注意。 15) SIGTERM 和 9) SIGKILL 信号是不可捕捉的，以防止不能终止进程。 bash 中的命令会以子进程运行，因此信号可能会被子进程捕获，执行脚本的进程因此可能无法捕获到信号。但是如果 trap 在子命令之前优先执行，信号则会优先被执行脚本的进程捕获。 程序执行过程中可能会产生很多临时文件或其他数据，正常结束时，这些临时文件都会被清理；但是如果程序执行过程中被 Ctrl-C 终止可能这些临时数据将无法被清除；因此可能需要捕捉 2) SIGINT 信号以清除执行程序时产生的临时文件。 ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:5:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Linux"],"content":"6. 信号捕捉 trap trap -l: 作用: 等同于 kill -l 列出所有信号 trap 'COMMAND' SIGNALS 作用: 指定在接收到信号后将要采取的动作，常见的用途是在脚本程序被中断时完成清理工作 常可以进行捕捉的信号： 1) SIGHUP 2) SIGINT # 表示当shell收到HUP INT PIPE QUIT TERM这几个命令时，当前执行的程序会读取参数“exit 1”，并将它作为命令执行。 trap \"exit 1\" HUP INT PIPE QUIT TERM 示例 #!/bin/bash # declare -a hosttmpfiles trap 'mytrap' INT mytrap() { echo \"Quit\" rm -f ${hosttmpfiles[@]} exit 1 } for i in {1..50}; do tmpfile=$(mktemp /tmp/ping.XXXXXX) if ping -W 1 -c 1 172.16.$i.1 \u0026\u003e /dev/null; then echo \"172.16.$i.1 is up\" | tee $tmpfile else echo \"172.16.$i.1 is down\" | tee $tmpfile fi hosttmpfiles[${#hosttmpfiles[*]}]=$tmpfile done rm -f ${hosttmpfiles[@]} ","date":"2018-01-16","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/:6:0","tags":["马哥 Linux"],"title":"6.7 程序交互与信号捕捉","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81/"},{"categories":["Python"],"content":"Python 协程","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"1. 协程的概念 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:1:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"1.1 对协程的理解 协程理解： 协程是用户空间的线程，编程语言必需提供接口实现线程调度 python 中 yield 是一种流程控制工具，使用它可以实现协程 生成器的编写风格： 传统的拉取式 - 迭代器 推送式 - 协程 任务式 - 面向事件编程 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:1:1","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"1.2 协程状态 inspect.getgeneratorstate(gen): GEN_CREATED - 等待开始执行 GEN_RUNNING - 解释器正在执行 GEN_SUSPENDED - 在 yield 表达式处暂停 GEN_CLOSED - 执行结束 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:1:2","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2. 协程协议： ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2.1 预激协程 .next(): 作用：预激(prime)协程 效果：让协程向前执行到第一个 yield 表达式，准备好作为活跃的协程使用 == .send(None) \u003e\u003e\u003e my_coro = simple_coroutine() \u003e\u003e\u003e my_coro.send(1729) Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: can not send non-None value to a just-started generator 预激协程的装饰器 from functools import wraps def coroutine(func): \"\"\"装饰器：向前执行到第一个`yield`表达式，预激`func`\"\"\" @wraps(func) def primer(*args,**kwargs): ➊ gen = func(*args,**kwargs) ➋ next(gen) ➌ return gen ➍ return primer 其他预激方式 框架： Tornado - tornado.gen 装饰器 http://tornado.readthedocs.org/en/latest/gen.html yield from: 调用协程时，会自动预激 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:1","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2.2 数据传递 .send(value): 作用：调用方向协程发送数据，value 成为生成器函数中 yield 表达式的值 要求：仅当协程处于暂停状态时才能调用，即必需先调用 next()方法预激协程 eg: b = yield a 协程向调用者返回 a，并在 yeild 处暂停 调用 .send(value)后，value 值被赋给 b，协程向下运行到另一个 yeild 表达式 \u003e\u003e\u003e def simple_coro2(a): print('-\u003e Started: a =', a) b = yield a print('-\u003e Received: b =', b) c = yield a + b print('-\u003e Received: c =', c) \u003e\u003e\u003e my_coro2 = simple_coro2(14) \u003e\u003e\u003e from inspect import getgeneratorstate \u003e\u003e\u003e getgeneratorstate(my_coro2) 'GEN_CREATED' \u003e\u003e\u003e next(my_coro2) # 预激(prime)协程 Started: a = 14 # 协程返回 a 的值 14 14 \u003e\u003e\u003e getgeneratorstate(my_coro2) 'GEN_SUSPENDED' \u003e\u003e\u003e my_coro2.send(28) # b 被赋值 28，协程返回 a+b 的值 Received: b = 28 # 协程暂定在 c = yeild a + b 等号的左边，等待调用者发送值 42 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:2","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2.3 异常处理 协程中的异常： 如果协程内出现未处理异常，协程会终止; 重新激活协程，会抛出StopIteration异常 协程中未处理的异常会向上冒泡，传给 next 函数或 send 方法的调用方 从 Python 2.5 开始，调用方可以通过 .throw 和 .close 方法显式地把异常发给协程 文档：https://docs.python.org/3/reference/expressions.html#generator-iterator-methods .throw(exc_type[, exc_value[, traceback]]) 作用：显式地把异常发给协程，致使生成器在暂停的 yield 表达式处抛出指定的异常 效果： 如果生成器处理了抛出的异常，代码会向前执行到下一个 yield 表达式， 而产出的值会成为调用 generator.throw 方法得到的返回值 如果生成器没有处理抛出的异常，异常会向上冒泡，传到调用方的上下文中 附注：如果不管协程如何结束都想做些清理工作，要把协程定义体中相关的代码放入 try/finally 块中 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:3","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2.4 协程终止 终止方式 发送某个哨符值，让协程发生异常退出，内置的 None 和Ellipsis 等常量经常用作哨符值， 甚至 StopIteration 类本身也可以作为哨符值 通过 .close() 方法协程传递 GeneratorExit 异常终止协程 .close(): 作用：致使生成器在暂停的 yield 表达式处抛出 GeneratorExit 异常 效果： 如果生成器没有处理这个异常，或者抛出了 StopIteration 异常(通常是指运行到结尾)， 调用方不会报错 如果收到 GeneratorExit 异常，生成器一定不能产出值，否则解释器会抛出RuntimeError 异常 生成器抛出的其他异常会向上冒泡，传给调用方 class DemoException(Exception): \"\"\"为这次演示定义的异常类型。\"\"\" def demo_exc_handling(): print('-\u003e coroutine started') try: while True: try: x = yield except DemoException: ➊ print('*** DemoException handled. Continuing...') else: ➋ print('-\u003e coroutine received: {!r}'.format(x)) # 最后一行代码不会执行，因为只有未处理的异常才会中止无限循环， # 而一旦出现未处理的异常，协程会立即终止 raise RuntimeError('This line should never run.') ➌ finally: print('-\u003e coroutine ending') \u003e\u003e\u003e exc_coro = demo_exc_handling() \u003e\u003e\u003e next(exc_coro) coroutine started \u003e\u003e\u003e exc_coro.send(11) coroutine received: 11 \u003e\u003e\u003e exc_coro.close() # 协程关闭 \u003e\u003e\u003e from inspect import getgeneratorstate \u003e\u003e\u003e getgeneratorstate(exc_coro) 'GEN_CLOSED' \u003e\u003e\u003e exc_coro = demo_exc_handling() \u003e\u003e\u003e next(exc_coro) coroutine started \u003e\u003e\u003e exc_coro.throw(DemoException) # 异常管理 - 异常在协程内得到处理 DemoException handled. Continuing \u003e\u003e\u003e getgeneratorstate(exc_coro) 'GEN_SUSPENDED' \u003e\u003e\u003e exc_coro = demo_exc_handling() \u003e\u003e\u003e next(exc_coro) coroutine started \u003e\u003e\u003e exc_coro.throw(ZeroDivisionError) # 异常管理 - 异常在协程内未处理 Traceback (most recent call last): ZeroDivisionError \u003e\u003e\u003e getgeneratorstate(exc_coro) 'GEN_CLOSED' ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:4","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"2.5 让协程返回值 值返回方式： 生成器中的 return expr 表达式会触发 StopIteration(expr)异常 return 表达式的值通过 StopIteration 异常的 value 属性返回给调用方 这样做保留了生成器对象的常规行为 —— 耗尽时抛出 StopIteration 异常 from collections import namedtuple Result = namedtuple('Result', 'count average') def averager(): total = 0.0 count = 0 average = None while True: term = yield if term is None: break # 为了返回值，协程必须正常终止 total += term count += 1 average = total/count # Python 3.3 之前，如果生成器返回值，解释器会报句法错误 return Result(count, average) \u003e\u003e coro_avg = averager() \u003e\u003e\u003e next(coro_avg) \u003e\u003e\u003e coro_avg.send(10) \u003e\u003e\u003e coro_avg.send(30) \u003e\u003e\u003e coro_avg.send(6.5) \u003e\u003e\u003e try: ... coro_avg.send(None) # 发送 None 会终止循环，导致协程结束，返回结果 ... except StopIteration as exc: ... result = exc.value # 生成器对象会抛出StopIteration 异常 ... # 异常对象的 value 属性保存着返回的值 \u003e\u003e\u003e result Result(count=3, average=15.5) ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:2:5","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3. yeild from 新句法 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3.1 语法： yeild from 只能用在函数内部，在函数外部使用（以及 yield）会导致句法出错 await 关键字： 文档：https://www.python.org/dev/peps/pep-0492/ 作用：await 关键字的作用与 yield from 结构类似，不过只能在以 async def 定义的协程 （禁止使用 yield 和 yield from）中使用 async 关键字： 作用：async 与其他现有的关键字结合使用，用于定义新的语言结构 async def 用于定义协程， async for 用于使用异步迭代器（实现 __aiter__ 和 __anext__ 方法， 这是协程版的 __iter__ 和 __next__方法）迭代可迭代的异步对象 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:1","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3.2 控制流程 def gen(): .... yield from x .... yield from x： 首先调用 iter(x)，从中获取迭代器 iter yield from 会把 iter 产出的值传给 gen 的调用方，即调用方可以直接控制 iter gen 会阻塞，等待 iter 终止 iter(x)返回值: 可以是只实现了 __next__ 方法的简单迭代器 – 让协程方便返回值 可以是实现了 __next__、send、 close 和 throw 方法的生成器 – 职责委托 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:2","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3.3 作用： 让协程更方便地返回值 yield from 结构会在内部自动捕获 StopIteration 异常， 并把 value 属性的值变成 yield from 表达式的值 这种处理方式与for 循环处理 StopIteration 异常的方式一样 from collections import Iterable def flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) else: yield x # 只需实现 __next__ 方法的简单迭代器 items = [1, 2, [3, 4, [5, 6], 7], 8] # Produces 1 2 3 4 5 6 7 8 for x in flatten(items): print(x) 职责委派 yeild from 打开了双向通道，把最外层的调用方与最内层的子生成器连接起来 这样二者可以直接发送和产出值，还可以直接传入异常，而不用在位于中间的协程中添加 大量处理异常的样板代码 专用术语： 子生成器：从 yield from 表达式中 部分获取的生成器 委派生成器： 定义：包含yield from 表达式的生成器函数 使用： 因为委派生成器相当于管道，所以可以把任意数量个委派生成器连接在一起 这个链条要以一个只使用 yield 表达式的简单生成器结束，也能以任何可迭代的对象结束 调用方： 定义：调用委派生成器的客户端代码 使用： 任何 yield from 链条都必须由调用方驱动 在最外层委派生成器上调用 next(…) 函数或 .send(…) 方法 也可以隐式调用，例如使用 for 循环 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:3","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3.4 示例说明 委派生成器在 yield from 表达式处暂停时 调用方可以直接把数据发给子生成器 子生成器再把产出的值发给调用方 子生成器返回之后，解释器会抛出 StopIteration 异常，并把返回值附加到异常对象上 yield from 提取出异常中的返回值作为整个表达式的值，委派生成器恢复 如果子生成器不终止，委派生成器会在 yield from 表达式处永远暂停， 因为 yield from（与 yield 一样）把控制权转交给客户代码（即，委派生成器的调用方） # 子生成器 def averager(): # 同上 .... return Result(count, average) # return 值会成为 yeild from 表达式的值 # 委派生成器 def grouper(results, key): while True: # 每次迭代时会新建一个 averager 实例；每个实例都是作为协程使用的生成器对象 results[key] = yield from averager() # grouper 接受值，通过管道传递给 averager 实例 # 客户端代码，即调用方 def main(data): results = {} for key, values in data.items(): group = grouper(results, key) # group 是调用 grouper 函数得到的委派生成器对象 next(group) # 预激委派生成器 group，此时进入 while True 循环，调用子生成 # 器 averager 后，在 yield from 表达式处暂 for value in values: group.send(value) group.send(None) # 重要！ report(results) main 运行说明： 外层 for循环每次迭代会新建一个 grouper实例，赋值给 group变量；group是委派生成器。 调用 next(group)，预激委派生成器 grouper，此时进入 while True 循环，调用子生成 器 averager 后，在 yield from 表达式处暂停。 内层 for 循环调用 group.send(value)，直接把值传给子生成器 averager。同时，当前 的 grouper 实例（ group）在 yield from 表达式处暂停。 内层循环结束后， group 实例依旧在 yield from 表达式处暂停，因此， grouper 函数定 义体中为 results[key] 赋值的语句还没有执行。 如果外层 for 循环的末尾没有 group.send(None)，那么 averager 子生成器永远不会终止， 委派生成器 group 永远不会再次激活，因此永远不会为 results[key] 赋值。 外层 for 循环重新迭代时会新建一个 grouper 实例，然后绑定到 group 变量上。前一个 grouper 实例（以及它创建的尚未终止的 averager 子生成器实例）被垃圾回收程序回收 group 内的 while 循环不是必需，作用是不让 委托生成器终止触发 StopIteration 异常 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:4","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"3.5 总结 子生成器产出的值都直接传给委派生成器的调用方（即客户端代码） 使用 send() 方法发给委派生成器的值都直接传给子生成器 如果发送的值是 None，那么会调用子生成器的 __next__() 方法 如果发送的值不是 None，那么会调用子生成器的 send() 方法 如果调用的方法抛出 StopIteration 异常，那么委派生成器恢复运行 任何其他异常都会向上冒泡，传给委派生成器 生成器退出时，生成器（或子生成器）中的 return expr 表达式会触发 StopIteration(expr)异常 yield from 表达式的值是子生成器终止时传给 StopIteration 异常的第一个参数 传入委派生成器的异常，除了 GeneratorExit 之外都传给子生成器的 throw() 方法， 如果调用 throw() 方法时抛出 StopIteration 异常，委派生成器恢复运行 StopIteration之外的异常会向上冒泡，传给委派生成器 把 GeneratorExit 异常传入委派生成器，或者在委派生成器上调用 close() 方法 如果子生成器有 close() 方法，则调用，如果调用 close() 方法导致异常抛出， 那么异常会向上冒泡，传给委派生成器 子生成器没有 close()方法，或close() 正常终止，委派生成器抛出 GeneratorExit异常 # RESULT = yield from EXPR 伪代码 _i = iter(EXPR) # \u003c1\u003e try: _y = next(_i) # \u003c2\u003e except StopIteration as _e: _r = _e.value # \u003c3\u003e else: while 1: # \u003c4\u003e try: _s = yield _y # \u003c5\u003e except GeneratorExit as _e: # \u003c6\u003e try: _m = _i.close except AttributeError: pass else: _m() raise _e except BaseException as _e: # \u003c7\u003e _x = sys.exc_info() try: _m = _i.throw except AttributeError: raise _e else: # \u003c8\u003e try: _y = _m(*_x) except StopIteration as _e: _r = _e.value break else: # \u003c9\u003e try: # \u003c10\u003e if _s is None: # \u003c11\u003e _y = next(_i) else: _y = _i.send(_s) except StopIteration as _e: # \u003c12\u003e _r = _e.value break RESULT = _r # \u003c13\u003e # END YIELD_FROM_EXPANSION ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:3:5","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"4. 使用案例：使用协程做离散事件仿真 面向事件的编程技术: 包括： 事件循环驱动的回调 事件循环驱动的协程 基于回调 相关框架：Twisted 基于协程: 相关框架：Tornado 和 asyncio 运作方式：在单个线程中使用一个主循环驱动协程执行并发活动 并发特点：协程会不断把控制权让步给主循环，激活并向前运行其他协程，从而执行各个并发活动， 这是一种协作式多任务：协程显式自主地把控制权让步给中央调度程序 对比：多线程实现的是抢占式多任务,调度程序可以在任何时刻暂停线程（即使在执行一个语句的过 程中），把控制权让给其他线程 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:4:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"4.1 背景介绍 事件仿真： 离散事件仿真： 定义：仿真钟向前推进的量不是固定的，而是直接推进到下一个事件 实现：协程为实现离散事件仿真提供了合理的抽象 SimPy 是一个实现离散事件仿真的 Python 包 连续事件仿真： 定义：仿真钟以固定的量（通常很小）不断向前推进 实现：为了实现连续仿真,在多个线程中处理实时并行的操作更自然 示例作用： 增进对使用协程管理并发操作的感性认知 洞悉 asyncio、 Twisted 和 Tornado 等库是如何在单个线程中管理多个并发活动的 说明如何在一个主循环中处理事件，以及如何通过发送数据驱动协程 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:4:1","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"4.2 程序解析 辅助函数： compute_delay 函数:返回单位为分钟的时间间隔 Event = collections.namedtuple(‘Event’, ’time proc action’) time 字段是事件发生时的仿真时间 proc 字段是出租车进程实例的编号 action 字段是描述活动的字符串 taxi_process 作用：一个协程 def taxi_process(ident, trips, start_time=0): ➊ \"\"\"每次改变状态时创建事件，把控制权让给仿真器\"\"\" time = yield Event(start_time, ident, 'leave garage') ➋ for i in range(trips): ➌ time = yield Event(time, ident, 'pick up passenger') ➍ time = yield Event(time, ident, 'drop off passenger') ➎ yield Event(time, ident, 'going home') Simulator: .run：执行仿真主循环 .events:PriorityQueue 对象，保存 Event 实例,能按照时间顺序取出放入队列中的事件 .procs:一个字典，把出租车的编号映射到仿真过程中激活的进程 class Simulator: def __init__(self, procs_map): self.events = queue.PriorityQueue() self.procs = dict(procs_map) def run(self, end_time): ➊ \"\"\"排定并显示事件，直到时间结束\"\"\" # 排定各辆出租车的第一个事件 for _, proc in sorted(self.procs.items()): ➋ first_event = next(proc) ➌ self.events.put(first_event) # 这个仿真系统的主循环 sim_time = 0 ➎ while sim_time \u003c end_time: ➏ if self.events.empty(): ➐ print('*** end of events ***') break current_event = self.events.get() ➑ sim_time, proc_id, previous_action = current_event ➒ print('taxi:', proc_id, proc_id * ' ', current_event) ➓ active_proc = self.procs[proc_id] next_time = sim_time + compute_duration(previous_action) try: next_event = active_proc.send(next_time) except StopIteration: del self.procs[proc_id] else: self.events.put(next_event) else: msg = '*** end of simulation time: {} events pending ***' print(msg.format(self.events.qsize())) \u003e taxis = {i: taxi_process(i, (i + 1) * 2, i * DEPARTURE_INTERVAL) for i in range(num_taxis)} \u003e sim = Simulator(taxis) ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:4:2","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:5:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"Python: 标准库-协程： https://www.python.org/dev/peps/pep-0380/ https://groups.google.com/forum/#!msg/pythontulip/bmphRrryuFk/aB45sEJUomYJ https://mail.python.org/pipermail/python-dev/2009-March/087382.html 协程示例： https://mail.python.org/pipermail/tutor/2015-February/104200.html http://nbviewer.ipython.org/github/wardi/iterables-iterators-generators/blob/master/Iterables,%20Iterators,%20Generators.ipynb Python3 新特性 在 Python 3.3 之前，如果生成器返回值，解释器会报句法错误 离散事件： https://en.wikipedia.org/wiki/Discrete_event_simulation http://www.cs.northwestern.edu/~agupta/_projects/networking/QueueSimulation/mm1.html SimPy: https://simpy.readthedocs.org/en/latest/ ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:5:1","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"blog: Beazley: http://www.dabeaz.com/generators/ http://www.dabeaz.com/finalgenerator/ http://www.dabeaz.com/coroutines/ http://pyvideo.org/video/213 http://pyvideo.org/video/215 http://pyvideo.org/video/214 James Powell: http://seriously.dontusethiscode.com/2013/05/01/greedy-coroutine.html 说明：使用协程重写了经典的算法 ActiveState: https://code.activestate.com/recipes/ https://code.activestate.com/recipes/tags/coroutine/ 说明：ActiveState Code 诀窍数据库 Paul Sokolovsky: https://dl.dropboxusercontent.com/u/44884329/yield-from.pdf http://flupy.org/resources/yield-from.pdf 说明：解说 yield from 结构的工作原理 Greg Ewing http://www.cosc.canterbury.ac.nz/greg.ewing/python/yield-from/yield_from.html 说明： yield from 的使用示例，BinaryTree 类、 一个简单的 XML 解析器和一个任务调度程序 其他： https://groups.google.com/forum/#!msg/pythontulip/bmphRrryuFk/aB45sEJUomYJ 说明：The difference between yield and yield-from ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:5:2","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:5:3","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"书籍: Python Cookbook（第 3 版）中文版 Effective Python：编写高质量 Python 代码的 59 个有效方法 书中的第 40 条短小精辟，题为“考虑用协程来并发地运行多个函数” 代码： https://github.com/bslatkin/effectivepython https://github.com/bslatkin/effectivepython https://gist.github.com/ramalho/da5590bc38c973408839 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:5:4","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-16","objectID":"/posts/program/python/grammar/fluent-python/16_coroutine/:6:0","tags":["python 进阶"],"title":"协程","uri":"/posts/program/python/grammar/fluent-python/16_coroutine/"},{"categories":["Linux"],"content":"6.6 函数和参数传递","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"函数和参数传递 本节我们来学习 bash shell 编程的第六部分参数传递与函数，包括以下内容: 如何向脚本传递参数 bash 函数 局部作用域 ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:0:0","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"1. 参数传递 ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:1:0","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"1.1 位置参数 所谓位置参数是 bash 中，脚本或函数接收参数的形式，除了位置参数，脚本中还内置了一些特殊参数，用于保存特定的值。参数的对应关系如下所示 myscript.sh argu1 argu2.... 位置参数: $1: 表示第一个位置参数 argu1 $2: 表示第二个位置参数 argu2 ${10}:表示第 10 个位置参数 argu10 ${11}:表示第 11 个位置参数 argu10,其他以此类推 特殊变量： $0：脚本文件路径本身； $#：脚本参数的个数； $*：由空格分隔的所有参数的字符串 “$1 $2 $n” $@：所有参数组成的列表 “$1”，\"$2\"，\"$3\"，\"$n\" ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:1:1","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"1.2 参数轮替 shift [n] 作用：造成参数变量的号码偏移，即整体参数的右移 n：数字，默认为1，代表拿掉最前面几个参数的意思 ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:1:2","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"2. 函数 ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:2:0","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"2.1 bash 函数特性 函数是主要作用是实现代码重用，其在每次被调用时创建，返回时终止。bash 中的函数与 bash 脚本的使用方式基本是类似的。 函数的返回值 函数的返回值也包括执行结果返回值和状态返回值 函数的执行结果返回值为代码的输出包括 函数中的打印语句：echo, print 函数中调用的系统命令执行后返回的结果 执行状态返回值： 默认是函数体中最后一次执行的命令状态结果 使用 return [0-255] 自定函数执行状态的返回值，不能使用 exit, exit 会直接退出脚本 函数参数 函数也通过位置接收传递进来的参数，并且表示方法与脚本完全相同。因此函数内的 $n 参数并不是脚本中的 $n 参数。向函数传递参数时，在函数名后跟空白分隔参数列表即可，testfunc arg1 arg2 arg3 ... 函数作用域 bash 函数默认与脚本共享同一作用域，函数内可以直接访问和修改脚本内变量的值。要想创建局部变量必需使用 local VARIABLE=VALUE。因此 bash 中的变量有三种: 局部变量：作用域是函数内；在函数结束时被自动销毁,因此不会影响脚本内同名变量的值 本地变量：作用域是当前shell脚本程序文件，在运行脚本的shell进程结束时被销毁 环境变量：作用域是当前进程及其子进程 因为函数内能直接修改脚本内变量的值，所以函数最好都使用局部变量，以免函数调用非预期的更改脚本内变量的值，引入难以调试的 bug。 ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:2:1","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"2.2 定义语法： # 方式一 function F_NAME { # 函数名后必需要有空格 函数体 } # 方式二 F_NAME() { # ()后必需要有空格 函数体 } ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:2:2","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Linux"],"content":"3. 函数使用示例 # 练习：写一个脚本，完成如下功能(使用函数)： # 1、提示用户输入一个可执行命令； # 2、获取这个命令所依赖的所有库文件(使用ldd命令)； # 3、复制命令至/mnt/sysroot/对应的目录中 # 解释：假设，如果复制的是cat命令，其可执行程序的路径是/bin/cat，那么就要将/bin/cat复制到/mnt/sysroot/bin/目录中，如果复制的是useradd命令，而useradd的可执行文件路径为/usr/sbin/useradd，那么就要将其复制到/mnt/sysroot/usr/sbin/目录中； # 4、复制各库文件至/mnt/sysroot/对应的目录中； #!/bin/bash # target=/mnt/sysroot/ [ -d $target ] || mkdir $target preCommand() { if which $1 \u0026\u003e /dev/null; then commandPath=`which --skip-alias $1` return 0 else echo \"No such command.\" return 1 fi } commandCopy() { commandDir=`dirname $1` [ -d ${target}${commandDir} ] || mkdir -p ${target}${commandDir} [ -f ${target}${commandPath} ] || cp $1 ${target}${commandDir} } libCopy() { for lib in `ldd $1 | egrep -o \"/[^[:space:]]+\"`; do libDir=`dirname $lib` [ -d ${target}${libDir} ] || mkdir -p ${target}${libDir} [ -f ${target}${lib} ] || cp $lib ${target}${libDir} done } read -p \"Plz enter a command: \" command until [ \"$command\" == 'quit' ]; do if preCommand $command \u0026\u003e /dev/null; then commandCopy $commandPath libCopy $commandPath fi read -p \"Plz enter a command: \" command done ","date":"2018-01-15","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/:3:0","tags":["马哥 Linux"],"title":"6.6 函数和参数传递","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92/"},{"categories":["Python"],"content":"上下文管理器和 else 块","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"本章内容 for、while 和 try 语句的 else 子句 EAFP 与 LBYL 上下文管理器协议 with 语句和上下文管理器 contextlib 模块 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:0:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"1. else 子句 作用： 能让代码更易于阅读 不用设置控制标志或者添加额外的 if 语句 控制逻辑： for ：仅当 for 循环运行完毕时（没有被 break 语句中止）才运行 else 块 while：仅当 while 循环因为条件为假值而退出时（没有被 break 语句中止）才运行 else 块 try： 仅当 try 块中没有异常抛出时才运行 else 块 else 子句抛出的异常不会由前面的 except 子句处理 如果异常、return、break 或 continue 导致控制权跳到了复合语句的主块之外，else 子句就会被跳过 try: dangerous_call() # after_call() 不应该放在这 except OSError: log('OSError...') else: after_call() 示例分析： try 块中应该只捕获预期的异常 这里捕获的是 dangerous_call() 可能出现的错误，而不是 after_call() 只有 try 块不抛出异常，才会执行 after_call() ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:1:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2. EAFP 与 LBYL Python 官方词汇表：https://docs.python.org/3/glossary.html#term-eafp EAFP: 取得原谅比获得许可容易（easier to ask for forgiveness than permission）。这是一 种常见的 Python 编程风格，先假定存在有效的键或属性，如果假定不成立，那 么捕获异常。这种风格简单明快，特点是代码中有很多 try 和 except 语句。与 其他很多语言一样（如 C 语言），这种风格的对立面是 LBYL 风格。 LBYL: 三思而后行（look before you leap）。这种编程风格在调用函数或查找属性或键之 前显式测试前提条件。与 EAFP 风格相反，这种风格的特点是代码中有很多 if 语句。在多线程环境中， LBYL 风格可能会在“检查”和“行事”的空当引入条 件竞争。例如，对 if key in mapping: return mapping[key] 这段代码来说，如 果在测试之后，但在查找之前，另一个线程从映射中删除了那个键，那么这段代 码就会失败。这个问题可以使用锁或者 EAFP 风格解决 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:2:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2. 上下文管理器和with 上下文管理器对象存在的目的是管理 with 语句，就像迭代器的存在是为了管理 for 语句一样 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:3:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.1 with 语句 作用： 简化 try/finally 模式 这种模式用于保证一段代码运行完毕后执行某项操作， 即便那段代码由于异常、return 语句或 sys.exit() 调用而中止，也会执行指定的操作 finally 子句中的代码通常用于释放重要的资源，或者还原临时变更的状态 不仅能管理资源，还能用于去掉常规的设置和清理代码，或者在另一个过程前后执行的操作 特性：与函数和模块不同， with 块没有定义新的作用域 原理： with 语句会设置一个临时的上下文，交给上下文管理器对象控制 上下文管理器对象实现了上下文管理器协议，在 with 语句执行的前后执行特定操作 执行过程 执行 with 后面的表达式，得到上下文管理器对象 执行上下文管理器对象的__enter__方法，返回值被绑定到目标变量上(as 子句) 不管控制流程以哪种方式退出 with 块，都会在上下文管理器对象上调用 __exit__ 方法 with 语句的 as 子句是可选的 \u003e\u003e\u003e with open('mirror.py') as fp: ... src = fp.read(60) 示例解析 open() 函数返回的 TextIOWrapper 类实例是上下文管理器对象 该实例的 __enter__ 方法返回 self 赋值给 as 子句中的变量 fp 在 with 块的末尾，调用 TextIOWrapper.__exit__ 方法把文件关闭 __enter__ 方法除了返回上下文管理器之外，还可能返回其他对象 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:3:1","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.2 上下文管理器协议 协议接口 __enter__(self) 运行：with 语句开始运行时，在上下文管理器对象上调用 参数： __exit__ (self, exc_type, exc_value, traceback) 运行：with 语句运行结束后，在上下文管理器对象上调用，扮演着 finally 子句的角色 异常：返回 None，或者 True 之外的值， with 块中的任何异常都会向上冒泡 参数： exc_type:异常类（例如 ZeroDivisionError） exc_value 异常实例。有时会有参数传给异常构造方法，例如错误消息，这些参数可以使用 exc_value.args 获取 traceback：traceback 对象 附注： 如果一切正常， Python 调用 __exit__ 方法时传入的参数是 None, None, None 在finally 块中调用 sys.exc_info()，得到的就是 __exit__ 接收的这三个参数 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:3:2","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.3 上下文管理器的应用 在 sqlite3 模块中用于管理事务 参见“12.6.7.3. Using the connection as a context manager” https://docs.python.org/3/library/sqlite3.html#using-the-connection-as-a-context-manager 在 threading 模块中用于维护锁、条件和信号 参见“17.1.10. Using locks, conditions,and semaphores in the with statement” https://docs.python.org/3/library/threading.html#using-locks-conditions-and-semaphores-in-the-with-statement 为 Decimal 对象的算术运算设置环境 参见 decimal.localcontext 函数的文档 https://docs.python.org/3/library/decimal.html#decimal.localcontext 为了测试临时给对象打补丁 参见 unittest.mock.patch 函数的文档 https://docs.python.org/3/library/unittest.mock.html#patch ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:3:3","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"3. contextlib模块 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:4:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.1 实用工具 文档：https://docs.python.org/3/library/contextlib.html |对象|说明| |: —|: —| |redirect_stdout|只需传入类似文件的对象，用于替代 sys.stdout| |closing|如果对象提供了 close() 方法，但没有实现 __enter__/__exit__ 协议， 那么可以使用这个函数构建上下文管理器| |suppress|构建临时忽略指定异常的上下文管理器| |ContextDecorator|这是个基类，用于定义基于类的上下文管理器 这种上下文管理器也能用于装饰函数，在受管理的上下文中运行整个函数| |ExitStack|这个上下文管理器能进入多个上下文管理器 with 块结束时，按照后进先出的顺序调用栈中各个上下文管理器的 __exit__ 方法 如果事先不知道 with 块要进入多少个上下文管理器，可以使用这个类 例如，同时打开任意一个文件列表中的所有文件| ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:4:1","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.2 @contextmanager 作用： 把简单的生成器函数变成上下文管理器，不用创建类去实现管理器协议 方法： 只需实现有一个 yield 语句的生成器，生成想让__enter__ 方法返回的值 yield 语句的作用是把函数的定义体分成两部分 yield 语句前面的所有代码在 with 块开始时（即解释器调用 __enter__ 方法时）执行 yield 语句后面的代码在 with 块结束时（即调用 __exit__ 方法时）执行 装饰器会把函数包装成实现 __enter__ 和 __exit__ 方法的类 类的 __enter__ : 调用生成器函数，保存生成器对象（这里把它称为 gen）。 调用 next(gen)，执行到 yield 关键字所在的位置。 返回 next(gen) 产出的值，以便把产出的值绑定到 with/as 语句中的目标变量上 __exit__ 方法 检查有没有把异常传给 exc_type；如果有，调用 gen.throw(exception)， 在生成器函数定义体中包含 yield 关键字的那一行抛出异常。 否则，调用 next(gen)，继续执行生成器函数定义体中 yield 语句之后的代码 因此使用 @contextmanager 装饰器时，要把 yield 语句放在 try/finally 语句中（或者放在 with 语句中） 异常管理: 使用 @contextmanager 装饰器时，异常的处理与上下文管理器协议是相反的 装饰器提供的 __exit__ 方法假定发给生成器的所有异常都得到处理了，因此应该压制异常。 如果不想让 @contextmanager 压制异常，必须在被装饰的函数中显式重新抛出异常 附注： 在 @contextmanager 装饰器装饰的生成器中， yield 与迭代没有任何关系 生成器函数的作用更像是协程：执行到某一点时暂停，让客户代码运行，直到客户让协程继续做事 import contextlib @contextlib.contextmanager def looking_glass(): import sys original_write = sys.stdout.write def reverse_write(text): original_write(text[::-1]) sys.stdout.write = reverse_write msg = '' try: yield 'JABBERWOCKY' ➊ except ZeroDivisionError: msg = 'Please DO NOT divide by zero!' finally: sys.stdout.write = original_write if msg: print(msg) \u003e\u003e\u003e with looking_glass() as what: ... print('Alice, Kitty and Snowdrop') ➊ yield ‘JABBERWOCKY’ 这个值会绑定到 with 语句中 as 子句的目标变量上 执行 with 块中的代码时，这个函数会在这一点暂停 控制权跳出 with 块，继续执行 yield 语句之后的代码 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:4:2","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"2.3 原地文件重写 http://www.zopatista.com/python/2013/11/26/inplace-file-rewriting/ 使用 @contextmanager 实现的原地文件重写上下文管理器 # 用于原地重写文件的上下文管理器 import csv with inplace(csvfilename, 'r', newline='') as (infh, outfh): reader = csv.reader(infh) writer = csv.writer(outfh) for row in reader: row += ['new', 'columns'] writer.writerow(row) inplace 函数 是个上下文管理器，为同一个文件提供了两个句柄（这个示例中的 infh 和outfh），以便同时读写同一个文件 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:4:3","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:5:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"Python: Compound statements 全面说明了 if、 for、 while 和 try 语句的 else 子句 https://docs.python.org/3/reference/compound_stmts.html 上下文管理器的类型 Built-in Types https://docs.python.org/3/library/stdtypes.html#typecontextmanager 上下文管里器 PEP 343—The‘ with’ Statement” https://www.python.org/dev/peps/pep-0343/ __enter__/__exit__ 3.3.8. With Statement Context Managers https://docs.python.org/3/reference/datamodel.html#with-statement-context-managers ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:5:1","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"blog: What Makes Python Awesome? http://pyvideo.org/video/1669/keynote-3 Is it a good practice to use try-except-else in Python 讨论了 try/except 语句（有 else 子句，或者没有）是否符合 Python 风格 http://stackoverflow.com/questions/16138232/is-it-a-good-practice-to-use-try-except-else-in-python Transforming Code into Beautiful, Idiomatic Python https://speakerdeck.com/pyconslides/transforming-code-into-beautiful-idiomatic-python-by-raymond-hettinger-1?slide=34 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:5:2","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"实用工具 The Python with Statement by Example http://preshing.com/20110920/the-python-with-statement-by-example/）， 举例说明了 pycairo 图形库中的上下文管理器 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:5:3","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"书籍: 《 Python 技术手册（第 2 版）》 有一章是关于异常的，那一章极好地讨论了 EAFP 风格 《 Python Cookbook（第 3 版）中文版》 8.3 让对象支持上下文管理协议 9.22 以简单的方式定义上下文管理器 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:5:4","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-15","objectID":"/posts/program/python/grammar/fluent-python/15_contextmanager/:6:0","tags":["python 进阶"],"title":"上下文管理器和 else 块","uri":"/posts/program/python/grammar/fluent-python/15_contextmanager/"},{"categories":["Linux"],"content":"6.5 字符串处理","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"字符串处理 本节我们来学习 bash shell 编程的第五部分字符串处理，内容包括: 字符串的切片，基于位置取子穿 基于模式取子串 查找和替换 大小写转换 变量赋值操作 bash 中获取变量的值可以使用 ${VARIABLE},字符串操作就是在此基础上的扩展。 ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"1. 字符串操作 ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"1.1 字符串切片： ${string:offset:length} 作用: 正向切片，offset 表示偏移量，lenght 表示截取的字符个数 注意: bash 中字符串和数组一样，下标从 0 开始 ${string: -length} 作用: 反向切片，取尾部的指定个数的字符，- 前必须要有空格 tao@hp:shell$ a=01234 tao@hp:shell$ echo ${a:1:2} 12 tao@hp:shell$ echo ${a: -2} 34 ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:1:1","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"1.2 基于模式取子串 需要特别注意的是，查找的关键字 word 只支持通配符 语法 作用 ${variable#*word} 自左而右，删除字符开始至第一次出现word ${variable##*word} 自左而右，删除字符开始至最后一次出现word ${variable%word*} 自右而左，删除第一次出现word至字串尾部 ${variable%%world*} 自右而左，删除最后一次出现word至字串尾部 tao@hp:~$ file='/var/log/messages' tao@hp:~$ echo ${file#*/} var/log/messages tao@hp:~$ echo ${file##*/} messages tao@hp:~$ echo ${file%/*} /var/log tao@hp:~$ echo ${file%%/*} tao@hp:~$ phonenumber='010-110-8' tao@hp:~$ echo ${phonenumber%%-*} 010 tao@hp:~$ echo ${phonenumber%-*} 010-110 tao@hp:~$ echo ${phonenumber##*-} 8 ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:1:2","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"1.3 查找替换： 需要注意的是，pattern 只能使用通配符，省略 /SUBSTI 时表示查找删除 语法 作用 ${var/PATTERN/SUBSTI} 查找，第一次被 PATTERN 匹配到的字符串，替换为SUBSTI ${var//PATTERN/SUBSTI} 查找，所有被PATTERN 匹配到的字符串，替换为SUBSTI ${var/#PATTERN/SUBSTI} 查找，行首被PATTERN 匹配到的字符串，替换为SUBSTI ${var/%PATTERN/SUBSTI} 查找，行尾被PATTERN 匹配到的字符串，替换为SUBSTI ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:1:3","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"1.4 大小写转换： ${variable^^}: 小–\u003e大 ${variable,,}: 大–\u003e小 ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:1:4","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Linux"],"content":"2. 变量赋值操作 |变量设定方式|param 没有设定|param 为空|param 为非空字符串| |: —|: —|: —|: —| |var=${param-word}|var=word|var=|var=$param| |var=${param:-word}|var=word|var=word|var=$param| |var=${param+word}|var=|var=word|var=word| |var=${param:+word}|var=|var=|var=word| |var=${param=word}|var=word param=word|var= param=|var=$param param 不变| |var=${param:=word}|var=word param=word|var=word param=word|var=$param param 不变| |var=${param?word}|word 输出到stderr|var=|var=$param| |var=${param:?word}|word 输出到stderr|word 输出到stderr|var=$param| # 为脚本使用配置文件，并确保某变量有可用值的方式 variable=${variable:-default vaule} ","date":"2018-01-14","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"6.5 字符串处理","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/"},{"categories":["Python"],"content":"Python 迭代器和生成器","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"当我在自己的程序中发现用到了模式，我觉得这就表明某个地方出错了。程序的形式应该仅仅反映它所要解决的问题。代码中其他任何外加的形式都是一个信号，(至少对我来说)表明我对问题的抽象还不够深——这通常意味着自己正在手动完成的事情，本应该通过写代码来让宏的扩展自动实现 — Paul Graham 本章涵盖以下话题: 迭代器与迭代协议 生成器 迭代器与生成器 迭代器模式 yield from 语句，生成器和协程 标准库中通用的生成器函数 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:0:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"1. python 的迭代模型 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:1:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"1.1 迭代协议 # abc.Iterator 类，摘自 Lib/_collections_abc.py class Iterable(metaclass=ABCMeta): __slots__ = () @abstractmethod def __iter__(self): while False: yield None @classmethod def __subclasshook__(cls, C): if cls is Iterable: if any(\"__iter__\" in B.__dict__ for B in C.__mro__): return True return NotImplemented class Iterator(Iterable): __slots__ = () @abstractmethod def __next__(self): 'Return the next item from the iterator. When exhausted, raise StopIteration' raise StopIteration def __iter__(self): return self @classmethod def __subclasshook__(cls, C): if cls is Iterator: if (any(\"__next__\" in B.__dict__ for B in C.__mro__) and any(\"__iter__\" in B.__dict__ for B in C.__mro__)): return True return NotImplemented 迭代器 迭代器是这样的对象: 实现了无参数的 __next__ 方法，返回序列中的下一个元素； 如果没有元素了，那么抛出 StopIteration 异常 标准的迭代器接口: __next__: 返回下一个可用的元素，如果没有元素了，抛出 StopIteration 异常 __iter__: Iterator 抽象基类实现 __iter__ 方法的方式是返回实例本身， 以便在需要可迭代对象的地方可以使用迭代器 标准迭代器特性: 因为迭代器只需 __next__ 和 __iter__ 两个方法，所以除了调用 next() 方法， 以及捕获StopIteration 异常之外，没有办法检查是否还有遗留的元素，也没办法还原 想再次迭代，那就要调用 iter(…)，传入之前构建迭代器的可迭代对象 传入迭代器本身没用，因为 Iterator.__iter__ 方法的实现方式是返回实例本身， 所以传入迭代器无法还原已经耗尽的迭代器 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:1:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"1.2 可迭代的对象与迭代器 可迭代的对象: 定义: 使用 iter 内置函数可以获取迭代器的对象 原理: 如果对象实现了能返回迭代器的 __iter__ 方法，那么对象就是可迭代的 实现了 __getitem__ 方法，而且其参数是从零开始的索引，这种对象也可以迭代 二者关系: Python 从可迭代的对象中获取迭代器 可迭代的对象可以迭代，但是可迭代的对象不是迭代器 检查对象是否可迭代: iter(x): - 原理: 通过捕获 TypeError 异常 - 优点: iter(x) 函数会考虑到遗留的 __getitem__ 方法，而 abc.Iterable 类则不考虑 - 适用: 从 Python 3.4 开始，检查对象 x 能否迭代，最准确的方法 isinstance(f, abc.Iterable) - 原理: 如果实现了 __iter__ 方法，那么就认为对象是可迭代的， 因为 abc.Iterable 类实现了 __subclasshook__ 方法 - 适用: 如果要保存对象，等以后再迭代，可以显式检查，因为这种情况可能需要尽早捕获错误 检查对象 x 是否为迭代器: isinstance(x, abc.Iterator) 得益于 Iterator.__subclasshook__ 方法，即使对象 x 所属的类不是 Iterator 类的真实子类或虚拟子类，也能这样检查 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:1:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"1.3 iter() 函数 迭代器用于支持 for 循环 构建和扩展集合类型 逐行遍历文本文件 列表推导、字典推导和集合推导 元组拆包 调用函数时，使用 * 拆包实参 iter(): 触发: 解释器需要迭代对象 x 时，会自动调用 iter(x)，包括上述所有情形 文档: https://docs.python.org/3/library/functions.html#iter 作用: 如果对象实现了 __iter__ 方法，调用它，获取一个迭代器 如果没有实现，但是实现了 __getitem__ 方法 Python 会创建一个迭代器， 尝试按顺序(从索引 0 开始)获取元素 如果尝试失败，Python 抛出 TypeError 异常 说明: 之所以对 __getitem__ 方法做特殊处理，是为了向后兼容，而未来可能不会再这么做 特殊用法: iter(x,y) x: 必须是可调用的对象，用于不断调用（没有参数），产出各个值 y: 哨符，这是个标记值，当可调用的对象返回这个值时，触发迭代器抛出 StopIteration 异常，而不产出哨符 \u003e\u003e\u003e def d6(): ... return randint(1, 6) ... \u003e\u003e\u003e d6_iter = iter(d6, 1) \u003e\u003e\u003e d6_iter \u003ccallable_iterator object at 0x00000000029BE6A0\u003e \u003e\u003e\u003e for roll in d6_iter: ... print(roll) ... 4 3 with open('mydata.txt') as fp: for line in iter(fp.readline, '\\n'): process_line(line) ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:1:3","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"1.4 迭代模式 迭代器模式可用来: 访问一个聚合对象的内容而无需暴露它的内部表示 支持对聚合对象的多种遍历 为遍历不同的聚合结构提供一个统一的接口(即支持多态迭代) 迭代器模式解释: 为了\"支持多种遍历\"，必须能从同一个可迭代的实例中获取多个独立的迭代器，各个迭代器能维护自身的内部状态 可迭代的对象因此必须实现 __iter__ 方法，每次调用 iter(my_iterable) 都返回一个独立的迭代器， 但不能实现 __next__ 方法 迭代器应该一直可以迭代，迭代器的 __iter__ 方法应该返回自身 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:1:4","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"2. 生成器 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:2:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"2.2 生成器对象 创建: 使用含有 yield 关键字的函数，或者生成器表达式 类型: types.GeneratorType (生成器－迭代器对象的类型) 文档: https://docs.python.org/3/library/types.html#types.GeneratorType 特性: 所有生成器都是迭代器，因为 GeneratorType 类型的实例实现了迭代器接口 def __iter__(self): for match in RE_WORD.finditer(self.text): yield match.group() re.finditer: 作用: re.findall 的惰性版本，返回一个生成器，按需生成 re.MatchObject 实例 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:2:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"2.3 生成器与迭代器语义对比 实现方式 生成器: 所有生成器都是迭代器，因为 GeneratorType 类型的实例实现了迭代器接口 迭代器: 可以编写不是生成器的迭代器，方法是实现经典的迭代器模式 eg: 从这方面看 enumerate 对象不是生成器 \u003e\u003e\u003e import types \u003e\u003e\u003e e = enumerate('ABC') \u003e\u003e\u003e isinstance(e, types.GeneratorType) False 接口 迭代器协议定义了两个方法: __next__ 和 __iter__ 生成器对象实现了这两个方法，因此从这方面来看，所有生成器都是迭代器 迭代器设计模式 迭代器: 用于遍历集合，从中产出元素，是从现有的数据源中读取值 调用 next(it) 时，迭代器不能修改从数据源中读取的值，只能原封不动地产出值 eg: 根据迭代器设计模式的原始定义， enumerate 函数返回的生成器不是迭代器， 因为创建的是生成器产出的元组 生成器 可能无需遍历集合就能生成值 即便依附了集合，生成器不仅能产出集合中的元素，还可能会产出派生自元素的其他值。 始终可以使用生成器这个语言结构履行迭代器的基本职责: 遍历集合，并从中产出元素 从概念方面来看，实现方式无关紧要，不使用 Python 生成器对象也能编写生成器 class Fibonacci: def __iter__(self): return FibonacciGenerator() class FibonacciGenerator: def __init__(self): self.a = 0 self.b = 1 def __next__(self): result = self.a self.a, self.b = self.b, self.a + self.b return result def __iter__(self): return self Python 社区 迭代器的完整定义: https://docs.python.org/3/glossary.html#term-iterator 生成器的完整定义: https://docs.python.org/3/glossary.html#termgenerator 在生成器的的定义中迭代器和生成器是同义词，“生成器\"指代生成器函数，以及生成器函数构建的生成器对象。 因此 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:2:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"2.2 生成器函数 定义: 只要 Python 函数的定义体中有 yield 关键字，该函数就是生成器函数 作用: 返回一个生成器对象 执行过程: 生成器函数会创建一个生成器对象，包装生成器函数的定义体 把生成器传给 next(…)函数时，生成器函数会向前，执行函数定义体中的下一个 yield 语句， 返回产出的值，并在函数定义体的当前位置暂停 最终，函数的定义体返回时，外层的生成器对象会抛出 StopIteration 异常 版本差异: Python\u003c34: 生成器函数中的 return 语句有返回值，那么会报错 Python34: return 语句会导致 StopIteration 异常,调用方可以从异常对象中获取返回值 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:2:3","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"2.3 生成器表达式 理解: 可以理解为列表推导的惰性版本: 不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素 对比: 生成器表达式: 是语法糖，是创建生成器的简洁句法，这样无需先定义函数再调用 生成器函数: 灵活得多，可以使用多个语句实现复杂的逻辑，也可以作为协程使用 生成器函数有名称，因此可以重用 使用: 如果生成器表达式要分成多行写，倾向于定义生成器函数，以便提高可读性 def __iter__(self): return (match.group() for match in RE_WORD.finditer(self.text)) 示例分析: 这里不是生成器函数了(没有 yield)，而是使用生成器表达式构建生成器 最终的效果一样: 调用 __iter__ 方法会得到一个生成器对象 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:2:4","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"3. Python 新特性 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:3:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"3.1 yield from 句法 \u003e\u003e\u003e def chain(*iterables): ... for it in iterables: ... for i in it: ... yield i \u003e\u003e\u003e def chain(*iterables): ... for i in iterables: ... yield from i ... \u003e\u003e\u003e list(chain(s, t)) ['A', 'B', 'C', 0, 1, 2] yield from 作用: 语法糖: 从另一个生成器中产出值，避免使用嵌套 for 循化 协程: 创建通道，把内层生成器直接与外层生成器的客户端联系起来， 不仅能为客户端代码生成值，还能使用客户端代码提供的值。 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:3:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"3.2 协程与迭代器 生成器用于生成供迭代的数据 协程是数据的消费者 虽然在协程中会使用 yield 产出值，但协程与迭代无关，不能这两个概念混为一谈 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:3:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4. 标准库中的生成器函数 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:4:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.1 os 模块 os.walk: https://docs.python.org/3/library/os.html#os.walk ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:4:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.2 用于过滤的生成器函数 |模块|函数|说明| |: —|: —|: —| |itertools|compress(it,selector_it)|并行处理两个可迭代的对象；如果selector_it中的元素是真值，产出 it 中对应的元素 |itertools|dropwhile(predicate,it)|处理 it，跳过 predicate 的计算结果为真值的元素，然后产出剩下的各个元素(不再进一步检查) – 遇到False就直接迭代到最后| |itertools|takewhile(predicate,it)|predicate 返回真值时产出对应的元素，然后立即停止，不再继续检查 – 遇到False就会立即停止| |(内置)|filter(predicate,it)|把 it 中的各个元素传给 predicate，如果 predicate(item) 返回真值，那么产出对应的元素；如果predicate 是 None 那么只产出真值元素| |itertools|filterfalse(predicate,it)|与 filter 函数的作用类似，不过 predicate 的逻辑是相反的: predicate 返回假值时产出对应的元素| |itertools|islice(it, stop) 或 islice(it,start,stop,step=1)|产出it的切片，作用类似于 s[: stop] 或 s[start: stop: step]，不过 it 可以是任何可迭代的对象，而且这个函数实现的是惰性操作| predicate: 布尔函数，有一个参数，会应用到输入中的每个元素上，用于判断元素是否包含在输出中 \u003e\u003e\u003e def vowel(c): ... return c.lower() in 'aeiou' ... \u003e\u003e\u003e list(filter(vowel, 'Aardvark')) ['A', 'a', 'a'] \u003e\u003e\u003e import itertools \u003e\u003e\u003e list(itertools.filterfalse(vowel, 'Aardvark')) ['r', 'd', 'v', 'r', 'k'] \u003e\u003e\u003e list(itertools.dropwhile(vowel, 'Aardvark')) ['r', 'd', 'v', 'a', 'r', 'k'] \u003e\u003e\u003e list(itertools.takewhile(vowel, 'Aardvark')) ['A', 'a'] \u003e\u003e\u003e list(itertools.compress('Aardvark', (1,0,1,1,0,1))) ['A', 'r', 'd', 'a'] \u003e\u003e\u003e list(itertools.islice('Aardvark', 4)) ['A', 'a', 'r', 'd'] \u003e\u003e\u003e list(itertools.islice('Aardvark', 4, 7)) ['v', 'a', 'r'] \u003e\u003e\u003e list(itertools.islice('Aardvark', 1, 7, 2)) ['a', 'd', 'a'] ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:4:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.3 用于映射的生成器函数 |模块|函数|说明| |: —|: —|: —| |itertools| accumulate(it, [func]) |产出累积的总和；如果提供了 func，那么把前两个元素传给它，然后把计算结果和下一个元素传给它，以此类推，最后产出结果 |(内置)|enumerate(iterable, start=0)|产出由两个元素组成的元组，结构是 (index, item)，其中index 从 start 开始计数， item 则从 iterable 中获取 |(内置)|map(func, it1, [it2, …, itN])|把 it 中的各个元素传给 func，产出结果；如果传入 N 个可迭代的对象，那么 func 必须能接受 N 个参数，而且要并行处理各个可迭代的对象 |itertools|starmap(func, it)|把 it 中的各个元素传给 func，产出结果；输入的可迭代对象应该产出可迭代的元素 iit，然后以 func(*iit) 这种形式调用 func 附注: 如果输入来自多个可迭代的对象，第一个可迭代的对象到头后就停止输出 \u003e\u003e\u003e sample = [5, 4, 2, 8, 7, 6, 3, 0, 9, 1] \u003e\u003e\u003e list(itertools.accumulate(sample, operator.mul)) # ➍ [5, 20, 40, 320, 2240, 13440, 40320, 0, 0, 0] \u003e\u003e\u003e list(enumerate('albatroz', 1)) # ➊ [(1, 'a'), (2, 'l'), (3, 'b'), (4, 'a'), (5, 't'), (6, 'r'), (7, 'o'), (8, 'z')] \u003e\u003e\u003e import operator \u003e\u003e\u003e list(map(operator.mul, range(11), range(11))) # ➋ [0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100] \u003e\u003e\u003e list(itertools.starmap(operator.mul, enumerate('albatroz', 1))) # ➎ ['a', 'll', 'bbb', 'aaaa', 'ttttt', 'rrrrrr', 'ooooooo', 'zzzzzzzz'] ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:5:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.4 用于合并的生成器函数 |模块|函数|说明| |: —|: —|: —| |itertools|chain(it1, …, itN)|先产出 it1 中的所有元素，然后产出 it2 中的所有元素，以此类推，无缝连接在一起| |itertools|chain.from_iterable(it)|产出 it 生成的各个可迭代对象中的元素，一个接一个，无缝连接在一起； it 应该产出可迭代的元素，例如可迭代的对象列表 |itertools|product(it1, …,itN, repeat=1)|计算笛卡儿积: 从输入的各个可迭代对象中获取元素，合并成由 N个元素组成的元组，与嵌套的 for 循环效果一样； repeat 指明重复 N 次处理输入的各个可迭代对象| |(内置)|zip(it1, …, itN)|并行从输入的各个可迭代对象中获取元素，产出由 N 个元素组成的元组，只要有一个可迭代的对象到头了，就默默地停止 |itertools|zip_longest(it1, …,itN, fillvalue=None)|并行从输入的各个可迭代对象中获取元素，产出由 N 个元素组成的元组，等到最长的可迭代对象到头后才停止，空缺的值使用 fillvalue 填充| \u003e\u003e\u003e list(itertools.chain('ABC', range(2))) # ➊ ['A', 'B', 'C', 0, 1] \u003e\u003e\u003e list(itertools.chain.from_iterable(enumerate('ABC'))) # ➌ [0, 'A', 1, 'B', 2, 'C'] \u003e\u003e\u003e list(itertools.product('ABC', repeat=2)) # ➍ [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] \u003e\u003e\u003e rows = itertools.product('AB', range(2), repeat=2) \u003e\u003e\u003e for row in rows: print(row) ... ('A', 0, 'A', 0) ('A', 0, 'A', 1) ('A', 0, 'B', 0) ... ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:5:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.5 扩展可迭代对象的生成器函数 把各个元素扩展成多个输出元素的生成器函数 |模块|函数|说明| |: —|: —|: —| |itertools|combinations(it,out_len)|把 it 产出的 out_len 个元素组合在一起，然后产出| |itertools|combinations_with_replacement(it, out_len)|把 it 产出的 out_len 个元素组合在一起，然后产出，包含相同元素的组合| |itertools|count(start=0, step=1)|从 start 开始不断产出数字，按 step 指定的步幅增加| |itertools|cycle(it)|从 it 中产出各个元素，存储各个元素的副本，然后按顺序重复不断地产出各个元素| |itertools|permutations(it,out_len=None)|把 out_len 个 it 产出的元素排列在一起，然后产出这些排列； out_len 的默认值等于 len(list(it))| |itertools|repeat(item, [times])|重复不断地产出指定的元素，除非提供 times，指定次数| \u003e\u003e\u003e list(itertools.islice(itertools.count(1, .3), 3)) # ➍ [1, 1.3, 1.6] \u003e\u003e\u003e cy = itertools.cycle('ABC') # ➎ \u003e\u003e\u003e next(cy) 'A' \u003e\u003e\u003e list(itertools.islice(cy, 7)) # ➏ ['B', 'C', 'A', 'B', 'C', 'A', 'B'] \u003e\u003e\u003e list(map(operator.mul, range(11), itertools.repeat(5))) # ➒ [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50] # 组合学生成器 \u003e\u003e\u003e list(itertools.combinations('ABC', 2)) # 每两个元素的各种组合，顺序无关紧要 [('A', 'B'), ('A', 'C'), ('B', 'C')] \u003e\u003e\u003e list(itertools.combinations_with_replacement('ABC', 2)) # 包括相同元素的组合 [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')] \u003e\u003e\u003e list(itertools.permutations('ABC', 2)) # 元素的顺序有重要意义 [('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'C'), ('C', 'A'), ('C', 'B')] \u003e\u003e\u003e list(itertools.product('ABC', repeat=2)) # 笛卡儿积 [('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'A'), ('B', 'B'), ('B', 'C'), ('C', 'A'), ('C', 'B'), ('C', 'C')] ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:5:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"4.6 重新排列元素的生成器函数 |模块|函数|说明| |: —|: —|: —| |itertools|groupby(it,key=None)|产出由两个元素组成的元素，形式为 (key, group)，其中 key 是分组标准，group 是生成器，用于产出分组里的元素 |itertools|tee(it, n=2)|产出一个由 n 个生成器组成的元组，每个生成器用于单独产出输入的可迭代对象中的元素| |(内置)|reversed(seq)|从后向前，倒序产出seq中的元素；seq必须是序列，或者是实现了 __reversed__ 特殊方法的对象 reversed 函数从后向前产出元素，而只有序列的长度已知时才能工作 这个函数会按需产出各个元素，因此无需创建反转的副本 \u003e\u003e\u003e list(itertools.groupby('LLLLAAGGG')) # ➊ [('L', \u003citertools._grouper object at 0x102227cc0\u003e), ('A', \u003citertools._grouper object at 0x102227b38\u003e), ('G', \u003citertools._grouper object at 0x102227b70\u003e)] \u003e\u003e\u003e for char, group in itertools.groupby('LLLLAAAGG'): # ➋ ... print(char, '-\u003e', list(group)) ... L -\u003e ['L', 'L', 'L', 'L'] A -\u003e ['A', 'A',] G -\u003e ['G', 'G', 'G'] \u003e\u003e\u003e animals = ['duck', 'eagle', 'rat', 'giraffe', 'bear', ... 'bat', 'dolphin', 'shark', 'lion'] \u003e\u003e\u003e animals.sort(key=len) # 为了使用 groupby 函数，要排序输入 \u003e\u003e\u003e for length, group in itertools.groupby(animals, len): # ➍ ... print(length, '-\u003e', list(group)) ... 3 -\u003e ['rat', 'bat'] 4 -\u003e ['duck', 'bear', 'lion'] 5 -\u003e ['eagle', 'shark'] 7 -\u003e ['giraffe', 'dolphin'] \u003e\u003e\u003e list(itertools.tee('ABC')) [\u003citertools._tee object at 0x10222abc8\u003e, \u003citertools._tee object at 0x10222ac08\u003e] \u003e\u003e\u003e list(zip(*itertools.tee('ABC'))) [('A', 'A'), ('B', 'B'), ('C', 'C')] ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:5:3","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"5. 可迭代的归约函数 归约函数: 接受一个可迭代的对象，然后返回单个结果 |模块|函数|说明| |: —|: —|: —| |(内置)|all(it)|it 中的所有元素都为真值时返回 True，否则返回 False； all([]) 返回 True| |(内置)|any(it)|只要 it 中有元素为真值就返回 True，否则返回 False； any([]) 返回 False| |(内置)|max(it, [key=,][default=])|返回 it 中值最大的元素； key 是排序函数，与 sorted 函数中的一样；如果可迭代的对象为空，返回 default| |(内置)|min(it, [key=,][default=])|返回 it 中值最小的元素； key 是排序函数，与 sorted 函数中的一样；如果可迭代的对象为空，返回 default| |functools|reduce(func, it,[initial])|把前两个元素传给 func，然后把计算结果和第三个元素传给 func，以此类推，返回最后的结果；如果提供了 initial，把它当作第一个元素传入| |(内置)|sum(it, start=0)| it 中所有元素的总和，如果提供可选的 start，会把它加上(计算浮点数的加法时，可以使用 math.fsum 函数提高精度)| 附注: 也可以像这样调用: max(arg1, arg2, …, [key=?])， 此时返回参数中的最大值。 也可以像这样调用: min(arg1, arg2, …, [key=?])， 此时返回参数中的最小值。 sorted: 接受一个可迭代的对象 构建并返回真正的列表。 \u003e\u003e\u003e g = (n for n in [0, 0.0, 7, 8]) \u003e\u003e\u003e any(g) True \u003e\u003e\u003e next(g) 8 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:6:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:7:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"Python: Yield expressions 从技术层面深入说明了生成器 https://docs.python.org/3/reference/expressions.html#yieldexpr 定义生成器函数的 PEP 是 \" PEP 255—Simple Generators” https://www.python.org/dev/peps/pep-0255/ itertools https://docs.python.org/3/library/itertools.html “Itertools Recipes” https://docs.python.org/3/library/itertools.html#itertools-recipes 说明如何使用 itertools 模块中的现有函数实现额外的高性能函数 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:7:1","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"blog: 协程: 作者: David Beazley（可能是 Python 社区中在协程方面最多产的作者和演讲者） URL: http://www.dabeaz.com/coroutines/ yeild from \" What’s New in Python 3.3\"通过示例说明了 yield from 句法 参见\" PEP 380: Syntax for Delegating to a Subgenerator\"， https://docs.python.org/3/whatsnew/3.3.html#pep-380-syntax-for-delegating-to-a-subgenerator） ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:7:2","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"实用工具 文档数据库 \" From ISIS to CouchDB: Databases and Data Models for Bibliographic Records\" http://journal.code4lib.org/articles/4893 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:7:3","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》 第 4章有 16 个诀窍涵盖了这个话题 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:7:4","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Python"],"content":"附注 def f(): def do_yield(n): yield n x = 0 while True: x += 1 do_yield(x) def f(): def do_yield(n): yield n x = 0 while True: x += 1 yeild from do_yield(x) 示例分析: 如果调用示例 14-24 中的 f()，会得到一个无限循环，而不是生成器，因为 yield 关键字只能把最近的外层函数变成生成器函数。 虽然生成器函数看起来像函数，可是我们不能通过简单的函数调用把职责委托给另一个生成器函数 Python 新引入的 yield from 句法允许生成器或协程把工作委托给第三方完成 沿用 def 声明生成器犯了可用性方面的错误，而 Python 2.5 引入的协程（也写成包含 yield 关键字的函数）把这个问题进一步恶化了。 尽管有一些相同之处，但是生成器和协程基本上是两个不同的概念 协程经常会用到特殊的装饰器，这样就能与其他的函数区分开。可是，生成器函数不常使用装饰器，因此我们不 得不扫描函数的定义体，看有没有 yield 关键字，以此判断它究竟是普通的函数，还是完全不同的洪水猛兽 ","date":"2018-01-14","objectID":"/posts/program/python/grammar/fluent-python/14_iterator/:8:0","tags":["python 进阶"],"title":"迭代器和生成器","uri":"/posts/program/python/grammar/fluent-python/14_iterator/"},{"categories":["Linux"],"content":"6.4 数组与算数运算","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"数组与算数运算 本节我们来学习 bash shell 编程的第四部分内容数组与算数运算。 ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:0:0","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"1. 数组 数组和字典是编程中非常常用的数据结构，但是 bash 对它们支持都比较有限。原因我们在本章第一节就说过，bash 本质上并不能算一种语言，因此也很少被拿来做复杂的编程。它更适合利用 Linux 中已有的命令完成特定功能。所以 bash 对复杂数据结构的支持很有限。bash 4.0 之后才开始支持字典，默认也只支持一维数组。下面我们将通过数组的声明，赋值和引用来讲解数组的使用。 bash 中字典又称为关联数组，使用方式与数组基本一致，只是将数字索引改为，字符串索引即可 ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:1:0","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"1.1 数组声明 数组和字典的声明: 数组声明: declare -a 字典声明: declare -A， bash 4.0及以上才支持，必需显示声明 ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:1:1","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"1.2 数组的赋值 bash 中的数组有多种赋值方式，常用的如下所示 赋值方式 语法 一次只赋值一个元素 a[0]=$RANDOM 一次赋值全部元素 a=(red blue yellow green) 只赋值特定元素 a=([0]=green [3]=red [2]=blue [6]=yellow) 用户输入 read -a ARRAY # 数组赋值支持通配符 logs=(/var/log/*.log) # 字典赋值 declare -A world world[us]=\"america\" echo \"${world['us']}\" # 向非稀疏数组追加元素 ARRAY[${#ARRAY[*]}]=value ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:1:2","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"1.3 数组的访问 变量引用可以使用 ${VARIABLE},而数组的访问就是在此基础上添加上要访问的索引。需要特别注意的是数组引用 {}不可省略，否则[index] 会被当作普通字符对待 用索引访问: ${ARRAY[index]} ${ARRAY}: 没有下标时，默认引用索引为 0 的元素 访问整个数组： ${ARRAY[@]}: 每个参数是一个独立的串 ${ARRAY[*]}: 所有参数是一个串 数组切片: ${ARRAY[@]:offset:number}: 取出偏移两之后特定数量的元素 ${ARRAY[@]:offset}：取出偏移量后的所有元素 ${ARRAY[@]}: 取出所有元素 说明: offset是偏移的元素个数,number 是取出的元素的个数 # 获取数组的长度: echo ${#ARRAY[*]}` echo ${#ARRAY[@]}` # 获取数组第 0 个元素的字符串长度 echo ${#ARRAY} tao@hp$ world[0]=us tao@hp$ echo ${#world[*]} # 数组长度 1 tao@hp$ echo ${#world} # 数组 0 元素的字符长度 2 ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:1:3","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"1.4 从数组中删除元素： unset ARRAY[index] ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:1:4","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Linux"],"content":"2. 数组使用示例 示例 1 定义一个数组，数组中的元素是/var/log目录下所有以.log结尾的文件；统计其下标为偶数的文件中的行数之和； #!/bin/bash # declare -a files files=(/var/log/*.log) declare -i lines=0 for i in $(seq 0 $[${#files[*]}-1]); do if [ $[$i%2] -eq 0 ]; then let lines+=$(wc -l ${files[$i]} | cut -d' ' -f1) fi done echo \"Lines: $lines.\" 示例 2 生成10个随机数，升序排序 #!/bin/bash # for((i=0;i\u003c10;i++)) do rnd[$i]=$RANDOM done echo -e \"total=${#rnd[@]}\\n${rnd[@]}\\nBegin to sort\" for((i=9;i\u003e=1;i--)) do for((j=0;j\u003ci;j++)) do if [ ${rnd[$j]} -gt ${rnd[$[$j+1]]} ] ;then swapValue=${rnd[$j]} rnd[$j]=${rnd[$[$j+1]]} rnd[$[$j+1]]=$swapValue fi done done echo ${rnd[@]} 2. 算术运算 bash 是弱类型编程语言，所有变量的默认类型是字符串。因此算术运算必需借助特定的命令来实现。同时 bash 中默认也不支持浮点数，当然也几乎用不到 常见的算术运算符包括 +，-，*，/, **, %，bash中实现算术运算有如下几种方式: let var=3+4: let 不会打印输出，只能使用变量进行保存 let count+=2: let 支持增量赋值 +=，-=，*=, /=, %= let count++: let 支持自增运算 var=$[$var+1] var=$(($var+1)) var=$(expr 3 \\* 4): 运算符和操作数之间必须使用空格分割，* 需要转义 $RANDOM: bash 内置的随机数生成器，表示 1-32767 的随机数 echo $[$RANDOM%60] 注意：乘法符号在有些场景中需要使用转义符； 脚本练习： # 计算/etc/passwd文件中的第10个用户和第20个用户的id号之和； id1=$(head -10 /etc/passwd | tail -1 | cut -d: -f3) id2=$(head -20 /etc/passwd | tail -1 | cut -d: -f3) # 计算/etc/rc.d/init.d/functions和/etc/inittab文件的空白行数之和； grep \"^[[:space:]]*$\" /etc/rc.d/init.d/functions | wc -l ","date":"2018-01-13","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/:2:0","tags":["马哥 Linux"],"title":"6.4 数组与算数运算","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E6%95%B0%E7%BB%84/"},{"categories":["Python"],"content":"Python 运算符重载","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"本章将讨论: Python 如何处理中缀运算符中不同类型的操作数 使用鸭子类型或显式类型检查处理不同类型的操作数 中缀运算符如何表明自己无法处理操作数 众多比较运算符（如 ==、 \u003e、 \u003c=，等等）的特殊行为 增量赋值运算符（如 +=）的默认处理方式和重载方式 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:0:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"1. 运算符重载基础 Python 限制: 不能重载内置类型的运算符 不能新建运算符，只能重载现有的 某些运算符不能重载——is、 and、 or 和 not（不过位运算符 \u0026、 | 和 ~ 可以） 运算符的基本规则: 就地运算符(增量赋值运算符)必须返回 self 除就地运算符外，其他运算符始终返回一个新对象，即要创建并返回合适类型的新实例 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:1:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"2. 一元运算符 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:2:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"2.1 一元运算符简介 文档: Python 语言参考手册，“6.6. Unary arithmetic and bitwise operations\"一节 链接: https://docs.python.org/3/reference/expressions.html#unary-arithmetic-and-bitwise-operations |运算符|方法|说明|示例| |: —|: —|: —|: —| |-|__neg__|一元取负算术运算符|如果 x 是 -2，那么 -x == 2| |+|__pos__|一元取正算术运算符|通常 x == +x，但也有一些例外| |~|__invert__|对整数按位取反，定义为 ~x == -(x+1)|如果 x 是 2，那么 ~x == -3| |abs()|__abs__|取绝对值|…| ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:2:1","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"2.2 x 和 +x 何时不相等 decimal.Decimal 类: 场景: 在不同精度的上下文中计算 +x，那么 x != +x 原因: 虽然每个 +one_third 表达式都会使用 one_third 创建一个新 Decimal 实例，但是 会使用当前算术运算上下文的精度 \u003e\u003e\u003e import decimal \u003e\u003e\u003e ctx = decimal.getcontext() # 获取当前全局算术运算的上下文引用 \u003e\u003e\u003e ctx.prec = 40 \u003e\u003e\u003e one_third = decimal.Decimal('1') / decimal.Decimal('3') \u003e\u003e\u003e one_third Decimal('0.3333333333333333333333333333333333333333') \u003e\u003e\u003e one_third == +one_third True \u003e\u003e\u003e ctx.prec = 28 \u003e\u003e\u003e one_third == +one_third False \u003e\u003e\u003e +one_third Decimal('0.3333333333333333333333333333') collections.Counter: 加法运算符: Counter 相加时，负值和零值计数会从结果中剔除 一元运算符: 等同于加上一个空Counter，因此产生一个新的 Counter 且仅保留大于零的计数器 文档: https://docs.python.org/3/library/collections.html#collections.Counter \u003e\u003e\u003e ct = Counter('abracadabra') \u003e\u003e\u003e ct Counter({'a': 5, 'r': 2, 'b': 2, 'd': 1, 'c': 1}) \u003e\u003e\u003e ct['r'] = -3 \u003e\u003e\u003e ct['d'] = 0 \u003e\u003e\u003e ct Counter({'a': 5, 'b': 2, 'c': 1, 'd': 0, 'r': -3}) \u003e\u003e\u003e +ct Counter({'a': 5, 'b': 2, 'c': 1}) ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:2:2","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"3. 中缀运算符 |运算符|正向方法|反向方法|就地方法|说明| |: —|: —|: —|: —|: —| |+|__add__|__radd__|__iadd__|加法或拼接| |-|__sub__|__rsub__|__isub__|减法| |*|__mul__|__rmul__|__imul__|乘法或重复复制| |/|__truediv__|__rtruediv__|__itruediv__|除法| |//|__floordiv__|__rfloordiv__|__ifloordiv__|整除| |%|__mod__|__rmod__|__imod__|取模| |divmod()|__divmod__|__rdivmod__|__idivmod__|返回由整除的商和模数组成的元组| |**,pow()|__pow__|__rpow__|__ipow__|取幂 *| |@|__matmul__|__rmatmul__|__imatmul__|矩阵乘法 #| |\u0026|__and__|__rand__|__iand__|位与| ||__or__|__ror__|__ior__|位或| |^|__xor__|__rxor__|__ixor__|位异或| |«|__lshift__|__rlshift__|__ilshift__|按位左移| |»|__rshift__|__rrshift__|__irshift__|按位右移| ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:3:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"3.1 中缀运算符分派机制 ** a + b 执行步骤** 如果 a 有 __add__ 方法，且返回值不是 NotImplemented，调用 a.__add__(b)返回结果 如果 a 没有 __add__ 方法，或者调用 __add__ 方法返回 NotImplemented，检查 b 有没有 __radd__ 方法，如果有，而且没有返回 NotImplemented，调用 b.__radd__(a)，然后返回结果 如果 b 没有 __radd__ 方法，或者调用 __radd__ 方法返回 NotImplemented，抛出 TypeError， 并在错误消息中指明操作数类型不支持 说明: 右向（right）特殊方法(又称反向方法)提供了一种后备机制 如果中缀运算符方法抛出异常，就会终止运算符分派机制 一般来说，如果中缀运算符的正向方法只处理与 self 属于同一类型的操作数， 那就无需实现对应的反向方法，因为按照定义，反向方法是为了处理类型不同的操作数 NotImplemented 和 NotImplementedError NotImplemented: 特殊的单例值 如果中缀运算符特殊方法不能处理给定的操作数，那么要把它返回(return)给解释器 NotImplementedError: 是一种异常 抽象类中的占位方法把它抛出(raise)，提醒子类必须覆盖 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:3:1","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"3.2 加法运算符 + 示例 def __add__(self, other): try: pairs = itertools.zip_longest(self, other, fillvalue=0.0) return Vector(a + b for a, b in pairs) except TypeError: return NotImplemented def __radd__(self, other): return self + other 示例分析: __radd__ 直接委托 __add__，前提是运算符可交换 如果由于类型不兼容而导致运算符特殊方法无法返回有效的结果，那么应该返回 NotImplemented， 而不是抛出 TypeError，这样另一个操作数所属的类型还有机会执行运算，即Python 会尝试调用反向方法 如果反向方法返回 NotImplemented，那么 Python 会抛出 TypeError，并返回一个标准的错 误消息，例如” unsupported operand type(s) for +: Vector and str\" 为了遵守鸭子类型精神，不能测试 other 操作数的类型，或者它的元素的类型。应该要捕获异常， 然后返回 NotImplemented ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:3:2","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"3.2 乘法运算符 * 示例 def __mul__(self, scalar): if isinstance(scalar, numbers.Real): return Vector(n * scalar for n in self) else: return NotImplemented def __rmul__(self, scalar): return self * scalar 示例分析: 白鹅类型的实际运用: 显式检查抽象类型 numbers.Real 抽象基类 numbers.Real 抽象基类涵盖了我们所需的全部数值类型，而且还支持以后声明为 numbers.Real 抽象基类的真实子类或虚拟子类的数值类型 鸭子类型更灵活，但显式检查更能预知结果，通过检查抽象基类在灵活性和安全性之间做了很好的折中 decimal.Decimal 没有把自己注册为 numbers.Real 的虚拟子类。 因此， Vector 类不会处理 decimal.Decimal 数字 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:3:3","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"3.3 特殊运算符说明 pow(x, y[, z]) 两个参数 == x**y 三个参数 == (x**y) % z，但 pow() 函数更高效 @ 运算符 版本: Python35 引入 作用: 矩阵乘法，点积 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:3:4","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"4. 比较运算符 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:4:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"4.1 比较运算符分派机制 分派机制对比: 相似: 与中缀运算符分配机制类似，正向方法返回NotImplemented，调用反向方法 区别: 正向和反向调用使用的是同一系列方法 __eq__ 方法，只是把参数对调了； 正向的 __gt__ 方法调用的是反向的 __lt__ 方法，并把参数对调 对 == 和 != 来说，如果反向调用失败， Python 会比较对象的 ID，而不抛出 TypeError |分组|中缀运算符|正向方法调用|反向方法调用|后备机制| |: —|: —|: —|: —|: —| |相等性|a == b|a.__eq__(b)|b.__eq__(a)|返回 id(a)==id(b)| |相等性|a != b|a.__ne__(b)|b.__ne__(a)|返回 not(a==b)| |排序|a \u003e b|a.__gt__(b)|b.__lt__(a)|抛出 TypeError| |排序|a \u003c b|a.__lt__(b)|b.__gt__(a)|抛出 TypeError| |排序|a \u003e= b|a.__ge__(b)|b.__le__(a)|抛出 TypeError| |排序|a \u003c= b|a.__le__(b)|b.__ge__(a)|抛出 TypeError| 版本差异: __ne__ Python 3 的后备机制是对 __eq__ 结果的取反，因此对于 != 运算符，无需重载 Python 2 不是如此 比较运算符 Python 3 抛出 TypeError，并把错误消息设为 ‘unorderable types: int() \u003c tuple() Python 2 中，这些比较的结果很怪异，会考虑对象的类型和 ID，而且无规律可循 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:4:1","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"5. 就地运算符 分派机制: 如果类没有实现就地运算符，增量赋值运算符只是语法糖: a += b 的作用与 a = a + b 一样， 对不可变类型来说，这是预期的行为，而且，如果定义了__add__ 方法，不用编写额外的代码， += 就能使用 如果类实现了就地运算符方法，会就地修改左操作数，而不会创建新对象作为结果， 不可变类型，一定不能实现就地特殊方法 + 与 +=: + 必需返回类的新实例，+= 必须返回 self，即实例本身 与 + 相比， += 运算符对第二个操作数更宽容，因为 + 运算符的两个操作数必须是相同类型，如若不然，结果的类型可能让人摸不着头脑 而 += 的情况更明确，因为就地修改左操作数，所以结果的类型是确定的 \u003e\u003e\u003e a = [1,2] \u003e\u003e\u003e a + (3, 4) # + 要求两个操作数属于同一类型 Traceback (most recent call last): File \"/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File \"\u003cipython-input-24-6ab1cfc1ec6f\u003e\", line 1, in \u003cmodule\u003e a + (3, 4) TypeError: can only concatenate list (not \"tuple\") to list \u003e\u003e\u003e a += (3, 4) # += 的右操作数可以是任何可迭代对象 \u003e\u003e\u003e a [1, 2, 3, 4] ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:5:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:6:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"Python: 运算符特殊方法 Data Model https://docs.python.org/3/reference/datamodel.html numbers 模块 9.1.2.2. Implementing the arithmeticoperations 一节 https://docs.python.org/3/library/numbers.html#implementing-the-arithmeticoperations functools.total_ordering 作用: 能为只定义了几个比较运算符的类自动生成全部比较运算符 文档: https://docs.python.org/3/library/functools.html#functools.total_ordering ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:6:1","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"blog: What’s New inPython 3.0 https://docs.python.org/3/whatsnew/3.0.html#operators-and-specialmethods 运算符方法分派机制 这两篇论文深入分析了动态类型语言（如 Smalltalk、 Python 和 Ruby）的多态 A Simple Technique for Handling Multiple Polymorphism https://wiki.illinois.edu//wiki/download/attachments/273416327/ingalls.pdf Arithmetic and Double Dispatching in Smalltalk-80 https://wiki.illinois.edu//wiki/download/attachments/273416327/double-dispatch.pdf Python 没有使用这两篇论文中所述的双重分配处理运算符， Python 使用的正向运算符和反 向运算符更便于用户定义的类支持双重分派，但是这种方式需要解释器做些特殊处理 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:6:2","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:6:3","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》 “9.20 通过函数注解来实现方法重载\"秘笈使用一些高级元编程（涉及元类）通过函数注解实现了基于类型的分派 《 Python Cookbook（第 2 版）中文版》 2.13 节，展示了如何重载 « 运算符，在 Python 中模仿 C++ 的 iostream 句法 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:6:4","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Python"],"content":"附注 运算符重载 对极为重视性能和安全的低级系统语言而言，不支持运算符重载这无疑是正确的决定 但是，重载的运算符，如果使用得当，的确能让代码更易于阅读和编写。对现代的高级语言来说，这是个好功能 ","date":"2018-01-13","objectID":"/posts/program/python/grammar/fluent-python/13_overload/:7:0","tags":["python 进阶"],"title":"运算符重载","uri":"/posts/program/python/grammar/fluent-python/13_overload/"},{"categories":["Linux"],"content":"6.3 循环","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"循环 本节我们来学习 bash shell 编程的第三部分循环，包括以下内容: for 循环 while 循环 until 循环 循环体内的控制语句 continue, break ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:0:0","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"1. for 循环 for 循环通过遍历列表的方式执行循环，列表生成有如下几种方式 ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:1:0","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"1.1 列表生成方式 直接给出:user1 user2 user3 整数列表 {start..end}: 使用内置关键字{} 生成整数列表 $(seq [start [incremtal]] last): 使用 seq 命令生成整数列表 返回列表的命令，例如 ls 命令 glob 通配符，例如 for file in /var/*; do; done 变量引用，例如 $*, $@ ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:1:1","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"1.2 for 循环语法 for 循环的语法，及其使用示例如下所示 for VARAIBLE in LIST; do 循环体 done #!/bin/bash # declare -i uphosts=0 declare -i downhosts=0 for i in {1..17}; do if ping -W 1 -c 1 172.16.$i.1 \u0026\u003e /dev/null; then echo \"172.16.$i.1 is up.\" let uphosts+=1 else echo \"172.16.$i.1 is down.\" let downhosts+=1 fi done echo \"Up hosts: $uphosts, Down hosts: $downhosts.\" ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:1:2","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"1.3 类 C 风格for 循环 for 循环除通常的列表遍历外，还有一种类 C 风格使用方法，其语法如下 控制变量初始化：仅在循环代码开始运行时执行一次； 控制变量的修正语句：每轮循环结束会先进行控制变量修正运算，而后再做条件判断； for ((控制变量初始化;条件判断表达式;控制变量的修正语句)); do 循环体 done # 示例：求100以内所有正整数之和 #!/bin/bash # declare -i sum=0 for ((i=1;i\u003c=100;i++)); do let sum+=$i done echo \"Sum: $sum.\" ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:1:3","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"2. while 循环 ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:2:0","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"2.1 while 条件循环 while 循环只要条件满足，就会一直执行 while CONDITION1; do 循环体 done #!/bin/bash # declare -i i=1 declare uphosts=0 declare downhosts=0 net=\"172.169.250\" while [ $i -le 20 ]; do if ping -c 1 -w $net.$i \u0026\u003e/dev/null; then echo \"$net.$i is up\" let uphosts++ fi done ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:2:1","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"2.2 while 文件遍历 while循环还有一种特殊用法，可用于文件遍历。如下所示 while 将依次读取/PATH/FROM/SOMEFILE 文件中的每一行，且将其赋值给VARIABLE变量 while read VARIABLE; do 循环体； done \u003c /PATH/FROM/SOMEFILE # 示例：找出ID号为偶数的用户，显示其用户名、ID及默认shell； #!/bin/bash # while read line; do userid=$(echo $line | cut -d: -f3) username=$(echo $line | cut -d: -f1) usershell=$(echo $line | cut -d: -f7) if [ $[$userid%2] -eq 0 ]; then echo \"$username, $userid, $usershell.\" fi done \u003c /etc/passwd ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:2:2","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"2.3 创建死循环 while true 可以创建死循环， sleep 命令可以让进程休眠一段时间 sleep NUMBER[SUFFIX]: 作用: 让程序在 sleep 处休眠 NUMBER 秒 SUFFIX: 默认为 s, 指暂停的秒数, m 指分钟, h 指小时, d 代表天数 #!/bin/bash # 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出； while true; do if who | grep \"^logstash\\\u003e\" \u0026\u003e /dev/null; then break fi sleep 3 done echo \"$(date +\"%F %T\") logstash logged on\" \u003e\u003e /tmp/users.log ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:2:3","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"3. until 循环 until 循环只要条件满足，就会退出循环 until CONDITION; do 循环体 done #!/bin/bash # 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出； until who | grep \"^logstash\\\u003e\" \u0026\u003e /dev/null; do sleep 3 done echo \"$(date +\"%F %T\") logstash logged on\" \u003e\u003e /tmp/users.log ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:3:0","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"4. 循环控制语句 ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:3:1","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"4.1 continue continue 可提前结束本轮循环，直接进入下一轮循环判断； # 示例：求100以内所有偶数之和； #!/bin/bash # declare -i evensum=0 declare -i i=0 while [ $i -le 100 ]; do let i++ if [ $[$i%2] -eq 1 ]; then continue fi let evensum+=$i done echo \"Even sum: $evensum\" ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:3:2","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Linux"],"content":"3.2 break break 可提前跳出整个循环。在下面的示例中 while true 将创建死循环，达到满足的条件时，break 将跳出循环。 # 示例：求100以内所奇数之和 #!/bin/bash # declare -i oddsum=0 declare -i i=1 while true; do let oddsum+=$i let i+=2 if [ $i -gt 100 ]; then break fi done ","date":"2018-01-12","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/:3:3","tags":["马哥 Linux"],"title":"6.3 循环","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/%E5%BE%AA%E7%8E%AF/"},{"categories":["Python"],"content":"Python 继承","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"本章重点 子类化内置类型的缺点 多重继承和方法解析顺序 讨论构建类层次结构方面好的做法和不好的做法 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:0:0","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"1. 子类化内置类型 版本差异: 在 Python 2.2 之前，内置类型（如 list 或 dict）不能子类化。 在 Python 2.2 之后，内置类型可以子类化了， 子类化内置类型: 问题: 内置类型的原生方法使用 C 语言实现，不会调用子类中覆盖的特殊方法 内置类型的特殊方法不会隐式调用子类覆盖的特殊方法，__missing__ 是个特例 类实例内部调用的其他特殊方法，如果被覆盖也不会被调用 （self.get() 不调用 self.__getitem__()) 原因： 与这些内置类型有关的任何性能问题几乎都会对其他所有代码产生重大影响 于是，CPython 走了捷径，故意让内置类型的方法行为不当，即不调用被子类覆盖的方法 影响: 原生类型的这种行为违背了面向对象编程的一个基本原则: 始终应该从实例（self）所 属的类开始搜索方法，即使在超类实现的类中调用也是如此 解决: 不要子类化内置类型，用户自己定义的类应该继承 collections 模块中的类， 例如 UserDict、 UserList 和 UserString 它们其实是对内置类型的包装，会把操作委托给内置类型 参考说明: Differences between PyPy andCPython 中 Subclasses of built-in types 一节 http://pypy.readthedocs.io/en/latest/cpython_differences.html#subclasses-of-built-in-types # 内置类型的方法不会隐式调用子类覆盖的方法 \u003e\u003e\u003e class DoppelDict(dict): ... def __setitem__(self, key, value): ... super().__setitem__(key, [value] * 2) # ➊ ... \u003e\u003e\u003e dd = DoppelDict(one=1) # 问题1: __init__ 方法忽略了覆盖的 __setitem__ 方法 \u003e\u003e\u003e dd {'one': 1} \u003e\u003e\u003e dd['two'] = 2 # [] 运算符调用了覆盖的 __setitem__ 方法 \u003e\u003e\u003e dd {'one': 1, 'two': [2, 2]} \u003e\u003e\u003e dd.update(three=3) # 问题2: update 方法也没有使用覆盖的 __setitem__ 方法 \u003e\u003e\u003e dd {'three': 3, 'one': 1, 'two': [2, 2]} ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:0:1","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"2. 多重继承和方法解析顺序 方法解析顺序 名称：Method Resolution Order， MRO， 解析算法：C3 算法 __mro__ 类属性: 一个元组，按照方法解析顺序列出各个超类，从当前类一直向上，直到object 类 超类方法调用 直接调用某个超类的方法 - 可以绕过方法解析顺序 - 必须显式传入 self 参数，因为这样访问的是未绑定方法（unbound method） super() 函数: - 会遵守方法解析顺序，最安全，也不易过时 - 调用框架或不受自己控制的类层次结构中的方法时，尤其适用 class D(B, C): def ping(self): super().ping() print('post-ping: ', self) \u003e super().ping() # Python3 中的super()函数 \u003e super(D, self).ping() # Python2 中的super()函数 \u003e C.ping(self) # 直接在类上调用实例方法时，必须显式传入 self 参数 \u003e\u003e\u003e def print_mro(cls): ➋ ... print(', '.join(c.__name__ for c in cls.__mro__)) ... \u003e\u003e\u003e print_mro(bool) bool, int, object \u003e\u003e\u003e print_mro(io.BytesIO) BytesIO, _BufferedIOBase, _IOBase, object ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:1:0","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"3. 正确构建类层次结构 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:2:0","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"3.1 避免把类图搅乱的建议 把接口继承和实现继承区分开 继承接口: 创建子类型，实现\"是什么\"关系，是框架的支柱 继承实现: 通过重用避免代码重复，是实现细节，通常可以换用组合和委托模式 使用抽象基类显式表示接口 如果类的作用是定义接口，应该明确把它定义为抽象基类 通过混入重用代码 如果一个类的作用是为多个不相关的子类提供方法实现，从而实现重用，但不体现\"是什么\"关系， 应该把那个类明确地定义为混入类（mixin class） 混入不定义新类型，只是打包方法，便于重用 混入类绝对不能实例化，而且具体类不能只继承混入类。混入类应该提供某方面的特定行为， 只实现少量关系非常紧密的方法 在名称中明确指明混入 在混入类名称中加入 …Mixin后缀 抽象基类可以作为混入， 反过来则不成立 抽象基类: 可以定义类型，作为其他类的唯一基类 可以实现具体方法，因此可以作为混入使用 但实现的具体方法只能与抽象基类及其超类中的方法协作，因此只是一种便利措施 混入类: 不能定义类型，不能作为唯一的超类，除非继承另一个更具体的混入——很少这样做 不要子类化多个具体类 具体类的超类中最多只能有一个具体超类，其余的都应该是抽象基类或混入 为用户提供聚合类 定义: 如果一个类的结构主要继承自混入，自身没有添加结构或行为，那么这样的类称为聚合类 作用: 打包有用的服务，便于用户使用 优先使用对象组合， 而不是类继承 优先使用对象组合，通过委托使用相关方法，实现代码复用 因为子类化是一种紧耦合，而且较高的继承树容易倒 附注: 组合和委托可以代替混入，把行为提供给不同的类，但不能取代接口继承去定义类型层次结构 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:2:1","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"3.2 Django通用视图中的混入 Django 视图: 视图: 可调用的对象，参数是表示 HTTP 请求的对象，返回值是一个表示 HTTP 响应的对象 视图实现: 通用视图: Django 提供的一系列函数，实现常见的用例 缺点是函数不能扩展，如果需求与列表视图相似但不完全一样，那么不得不自己从头实现 基于类的视图: 通过基类、混入和拿来即用的具体类提供了可扩展的视图逻辑 附注: http://ccbv.co.uk – Django 类层次结构详解 优点: 混入类易于理解，各个混入的目的明确，而且名称的后缀都是 …Mixin Django 类视图展示 View 是所有视图（可能是个抽象基类）的基类，提供核心功能 View 的具体子类应该实现处理方法，但它们为什么不在 View 接口中呢？原因是: 子类只 需实现它们想支持的处理方法 TemplateResponseMixin 提供的功能只针对需要使用模板的视图 ListView 聚合类，不含任何代码 ListView 实例有个 object_list 属性，模板会迭代它显示页面的内容 生成这个可迭代对象列表的相关功能由 MultipleObjectMixin 提供。这个混入还提供了分页逻辑 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:2:2","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:3:0","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"Python: ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:3:1","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"blog: Python’s Super is nifty, but you can’t use it https://fuhm.net/super-harmful/ Python’s super() considered super! https://rhettinger.wordpress.com/2011/05/26/super-considered-super/ 从积极的角度解说了 Python 的 super 和多重继承的运作原理 也是对上文的一个回应 Setting Multiple Inheritance Straight http://www.artima.com/weblogs/viewpost.jsp?thread=246488 实现了性状（trait），这是一种受限的混入 Simionato 写的有关Python 多继承的文章 “The wonders of cooperative inheritance, or using super in Python 3” http://www.artima.com/weblogs/viewpost.jsp?thread=281127） “Mixinsconsidered harmful” 第一部分 http://www.artima.com/weblogs/viewpost.jsp?thread=246341 第二部分 http://www.artima.com/weblogs/viewpost.jsp?thread=246483 “Things to KnowAbout Python Super” 第一部分 http://www.artima.com/weblogs/viewpost.jsp?thread=236275 第二部分 http://www.artima.com/weblogs/viewpost.jsp?thread=236278 第三部分 http://www.artima.com/weblogs/viewpost.jsp?thread=237121 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:3:2","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"实用工具 GUI 编程 Tkinter 和 Tcl/Tk Python 3.1提供的 tkinter.ttk 包 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:3:3","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"书籍: 《面向对象分析与设计（第 3 版）》 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:3:4","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Python"],"content":"附注 哪些类是真正需要的 编写应用程序时，我们通常不用设计类的层次结构。我们至多会编写子类、 继承抽象基类或框架提供的其他类 作为应用程序开发者，我们极少需要编写作为其他类的超类的类 内置类型 与这些内置类型有关的任何性能问题几乎都会对其他所有代码产生重大影响。于是， CPython 走了 捷径，故意让内置类型的方法行为不当，即不调用被子类覆盖的方法 解决这一困境的可能方式之一是，为这些类型分别提供两种实现: 一种供内部使用，为解释器做了 优化；另一种供外部使用，便于扩展 我们也要在自己的应用程序中使用做了优化但是难以子类化的实现 其他语言对继承的支持 C++: 是第一门实现多重继承的流行语言，但是这一功能被滥用了 Java: 意欲取代 C++的 Java 不支持多重继承 Java 8 引入了默认方法，这使得接口与 C++ 和 Python 用于定义接口的抽象类十分相似 但是它们之间有个关键的区别: Java 的接口没有状态 Scala: - 实现了性状， - 支持性状的其他语言还有最新稳定版 PHP 和 Groovy，以及正在开发的 Rust 和Perl 6 - 因此可以说，性状是目前的趋势 Ruby: 对多重继承的态度很明确: 对其不支持，但是引入了混入 Ruby 类的定义体中可以包含模块，这样模块中定义的方法就变成了类实现的一部分。 这是\"纯粹\"的混入，不涉及继承，因此 Ruby 混入显然不会影响所在类的类型 GO: 完全不支持继承，但是它实现的接口与静态鸭子类型相似 Julia: 有类型层次结构，但是子类型不能继承结构，只能继承行为， 而且只能为抽象类型创建子类型。此外， Julia 的方法使用多重分派 ","date":"2018-01-12","objectID":"/posts/program/python/grammar/fluent-python/12_inherit/:4:0","tags":["python 进阶"],"title":"继承","uri":"/posts/program/python/grammar/fluent-python/12_inherit/"},{"categories":["Linux"],"content":"6.2 if 和条件判断","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"if 和条件判断 本节我们来学习 bash shell 编程的第二部分条件判断，包括以下内容: 条件测试的实现 测试表达式 数值测试 字符串测试 文件测试 组合测试 条件判断语句 if 和 case ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:0:0","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"1. 条件测试的实现 bash 中测试的实现有两种方式，一是执行命令，并利用命令状态返回值来判断；二是所谓的测试表达式。但是所谓的测试表达式本质上仍然是由特定的测试命令执行，并通过命令状态返回值来判断测试是否满足。条件表达式我的理解只不过是为某些通用的测试目的提供便利。 因此测试是否满足，需要在执行测试命令后，使用 echo $? 查看测试结果。后面讲解的 if 语句则会自动判断命令执行状态，做出判断无需通过 $?。 bash 中的条件测试有如下三种使用方式，EXPRESSION 表示测试表达式 test EXPRESSION: bash 命令 [ EXPRESSION ]: [] 是 test 的同义词，使用方式与 test 完全一样 因为是命令，所有 bash 中的元字符如\u003e \u003c () 在表达式中使用时需要转义 命令的操作数不能为空，所以表达式中如果引用变量，需要使用 “$var”，否在当 var 不存在或为空时，会因为缺少操作数报语法错误 EXPRESSION两端必须有空白字符，否则为语法错误 [[ EXPRESSION ]] bash 内置关键字，[[]] 是 [] 的改进，大多数情况下可等同使用 因为不是命令，所以 bash 的元字符在表达式中使用无需转义 非命令，所以操作数为空时也能自动识别，但是在引用变量时，为防止变量包含空格，仍然建议使用 “$var” EXPRESSION两必须有空白字符，否则为语法错误 需要特别注意的是 bash 是通过 空格分隔运算符和操作数的，因此无论上述哪种形式，运算符和操作数之间必需要有空格。除了字符转义外，[] 和 [[]] 在支持的测试表达式范围上也略有不同，二者的区别可以参考此篇文章 http://mywiki.wooledge.org/BashFAQ/031 。一个实现 a 和 b 两个字符比较的示例如下。 \u003e test a \\\u003e b \u003e [ a \\\u003e b ] \u003e [[ a \u003e b ]] \u003e echo $? ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:1:0","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"2. 测试表达式 ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:0","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"2.1 数值测试 -eq：是否等于； [ $num1 -eq $num2 ] -ne：是否不等于； -gt：是否大于； -ge：是否大于等于； -lt：是否小于； -le：是否小于等于； ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:1","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"2.2 字符串测试 ==：是否等于； \u003e：是否大于； \u003c：是否小于； !=：是否不等于； =~：左侧字符串是否能够被右侧的PATTERN所匹配； -z \"STRING\"：判断指定的字串是否为空；空则为真，不空则假； -n \"STRING\"：判断指定的字符串是否不空；不空则真，空则为假； 注意: 字符串比较的操作数，都应该使用引号括住 [ -z \"$name\" ] [ \"$name\" = \"$myname\" ] ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:2","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"2.3 文件测试 文件存在测试 -a FILE: 等同于 -e FILE -e FILE: 存在则为真；否则则为假； -s FILE: 存在并且为非空文件则为值，否则为假； 存在及文件类型测试 -f FILE: 存在并且为 普通文件，则为真；否则为假； -d FILE: 存在并且为 目录文件，则为真；否则为假； -L/-h FILE: 存在并且为 符号链接文件，则为真；否则为假； -b: 是否存在并且为 块设备文件，则为真；否则为假； -c: 是否存在并且为 字符设备文件，则为真；否则为假； -S: 是否存在且为 套接字文件，则为真；否则为假； -p: 是否存在且为 命名管道文件，则为真；否则为假； 文件权限测试 -r FILE:在并且对当前用户可读； -w FILE:存在并且对当前用户可写； -x FILE:存在并且对当前用户可执行； -g sgid:存在并且 拥有sgid权限； -u suid:存在并且 拥有suid权限； -k sticky:存在并且 拥有sticky权限； 丛属关系测试 -t fd：文件是否打开且与某终端有关 -O FILE 当前用户是否为文件的属主 -G FILE 当前用户是否为文件的属组 更改及新旧对比测试 -N FILE: 文件自从上一次读操作后是否被修改过； file1 -nt file2: file1的mtime新于file2则为真，否则为假； file1 -ot file2: file1的mtime旧于file2则为真，否则为假； file1 -ef file2: 两文件是否是指向同一设备的 inode 的硬链接 ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:3","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"2.4 组合测试条件 bash 中表示逻辑运算有两种方式，一是使用命令的逻辑运算符，连接两个命令；另一个是表达式的逻辑符号，连接两个表达式。不过 [] 与 [[]]的使用方式有所不同 逻辑与： [ condition1 -a condition2 ] [[ condition1 \u0026\u0026 condition2 ]] command1 \u0026\u0026 command2 逻辑或： [ condition1 -o condition2 ] [[ condition1 || condition2 ]] command1 || command2 逻辑非： [ ! condition ] [[ ! condition ]] ! command eg： [ -O FILE ] \u0026\u0026 [ -r FILE ] 或 [ -O FILE -a -r FILE ] ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:2:4","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"3. 条件判断语句 ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:3:0","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"3.1 if 语句 语法 if 语句会自动通过判断条件测试命令的执行状态来判断测试条件是否满足 if condition; then pass else pass fi if condition then pass else pass fi # 将 if 写在一行，命令行中常用 if condition; then command1;command2; else command3; fi if [[ a \u003e b ]]; then echo \"aaaa\"; else echo \"bbbb\"; fi 示例 通过参数传递一个用户名给脚本，此用户不存时，则添加之； #!/bin/bash # if [ $# -lt 1 ]; then echo \"At least one username.\" exit 2 fi if grep \"^$1\\\u003e\" /etc/passwd \u0026\u003e /dev/null; then echo \"User $1 exists.\" else useradd $1 echo $1 | passwd --stdin $1 \u0026\u003e /dev/null echo \"Add user $1 finished.\" fi ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:3:1","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Linux"],"content":"3.2 case 语句 语法 case $VARAIBLE in PAT1) 分支1 ;; PAT2) 分支2 ;; ... *) 默认分支 ;; esac case PAT 支持glob风格的通配符： *：任意长度的任意字符； ?：任意单个字符； []：范围内任意单个字符； a|b：a或b ","date":"2018-01-11","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/:3:2","tags":["马哥 Linux"],"title":"6.2 if 和条件判断","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/if%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD/"},{"categories":["Python"],"content":"从协议到抽象基类","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"本章首先介绍了非正式接口（称为协议）的高度动态本性，然后讲解了抽象基类的静态接口声明，最后指出了抽象基类的动态特性：虚拟子类，以及使用 __subclasshook__ 方法动态识别子类 鸭子类型: 非正式接口 可部分实现，动态实现 抽象基类: 正式接口 必需完全实现 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:0:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"1. Python文化中的接口和协议 对 Python 程序员来说，“X 类对象”, “X 协议”, “X 接口” 都是一个意思 接口: 定义: 对象公开方法的子集，让对象在系统中扮演特定的角色,是 实现特定角色的方法集合 eg: Python 文档中的\"文件类对象\",指的不是特定的类，而是实现文件读写方法的集合 协议: 定义: 非正式的接口(只由文档和约定定义) 特点：不能像正式接口一样施加限制 作用: 是让Python 这种动态类型语言实现多态的方式 应用: Python 数据模型的哲学是尽量支持基本协议 因此如果遵守既定协议，很有可能增加利用现有的标准库和第三方代码的可能性 Python 支持的协议 序列协议 - 不可变的序列协议: __getitem__， __len__ - 可变的序列协议: 添加 __setitem__ 缓冲协议 迭代协议 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:1:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"2. 协议的理解 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:2:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"2.1 协议与继承没有关系 \u003e\u003e\u003e class Foo: ... def __getitem__(self, pos): ... return range(0, 30, 10)[pos] ... \u003e\u003e\u003e f = Foo() \u003e\u003e\u003e f[1] 10 \u003e\u003e\u003e for i in f: print(i) 0 10 20 \u003e\u003e\u003e 20 in f True 协议后备机制: 如果没有 __iter__ 和 __contains__ 方法， Python 会调用 __getitem__ 方法，让迭代和 in 运算符可用 Python 中的迭代是鸭子类型的一种极端形式: 为了迭代对象，解释器会尝试调用两个不同的方法 协议与继承没有关系: Foo 类没有继承 abc.Sequence，只实现了序列协议的一个方法: __getitem__， 这样足够访问元素、迭代和使用 in 运算符 一个类可能会实现多个接口，以实现多个协议 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:2:1","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"2.2 协议是动态的 协议是动态的: 即对象的类型无关紧要，只要实现了特定的协议(特定方法集合)即可 猴子补丁: 在运行时修改类或模块，而不改动源码，可为对象动态添加协议所需方法 random.shuffle 函数 作用: 就地打乱序列 x 要求：传入对象部分实现可变序列协议 – 协议是动态的 文档: https://docs.python.org/3/library/random.html#random.shuffle ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:3:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"2. 抽象基类的理解 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:4:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"2.1 引入抽象基类的原因 生物学类比 属和种的分类: 表型系统学: 关注的是表型系统学特征，即形态和举止的相似性 支序系统学: 关注的是从共同祖先继承的特征，而不是单独进化的特征 程序接口: 鸭子类型，关注是否实现了特定方法的集合，类似表型系统学 白鹅类型，关注是否是否具有内在的一致性，类似支序系统学 引入原因: x.draw() 和 y.draw() 只因为 x 和 y 两个对象刚好都有一个名为 draw 的方法，而且调用时不用传入参数， 远远不能确保二者可以相互调用，或者具有相同的抽象 也就是说，从这样的调用中不能推导出语义相似性，需要程序员主动把这种等价维持在一定层次上 抽象基类 定义: 正式的接口(由抽象基类规定) 特点: 严格的接口规定和类型检查 作用: 将相似对象维持在同一抽象层次上 应用: 不应该在程序中过度使用它。 Python 的 核心在于它是一门动态语言，它带来了极大的灵活性。如果处处都强制实行类型约束， 那么会使代码变得更加复杂，而本不应该如此 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:4:1","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"3. 标准库中的抽象基类 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:5:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"3.1 collections.abc |抽象基类|说明|支持的特殊方法| |: —|: —|: —| |Iterable |集合应该继承的抽象基类|通过 __iter__方法支持迭代| |Container|集合应该继承的抽象基类|通过 __contains__ 方法支持 in 运算符| |Sized |集合应该继承的抽象基类|通过 __len__方法支持 len() 函数| |Sequence Mapping Set |主要的不可变集合类型|| |MutableSequence MutableMapping MutableSet |不可变集合类型的可变子类|| |MappingView||| |ItemsView KeysView ValuesView|Python3 中映射方法 .items()、 .keys() 和 .values() 返回的对象|| |Callable Hashable|为内置函数 isinstance 提供支持，以一种安全的方式判断对象能不能调用或散列|与集合没有太大的关系| |Iterator|Iterable的子类|…| 附注: ItemsView、KeysView 还从 Set 类继承了丰富的接口，包含 3.8.3 节所述的全部运算符 若想检查是否能调用，可以使用内置的 callable() 函数； 没有类似的 hashable() 函数，因此测试对象是否可散列，可使用 isinstance(my_obj, Hashable) 序列的抽象基类 字典的抽象基类 集合的抽象基类 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:5:1","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"3.2 numbers 文档: https://docs.python.org/3/library/numbers.html 数字塔: 数值抽象基类的层次结构是线性的 Number – 最顶端的超类 Complex – 复数 Real – 浮点型 Rational – 有理数 Integral – 最底端的超类 isinstance(x, numbers.Integral) 作用: 检查一个数是不是整数 验证: 能接受 int、 bool（int 的子类），或者外部库使用 numbers 抽象基类注册的其他类型 扩展: 为了满足检查的需要，API 用户始终可以把兼容的类型注册为 numbers.Integral 的虚拟子类 isinstance(x, numbers.Real) 作用: 检查一个数是不是浮点数 验证: 能接受 bool、 int、 float、 fractions.Fraction，或者其他注册的非复数类型 附注: decimal.Decimal 没有注册为 numbers.Real 的虚拟子类 如果程序需要 Decimal 的精度，要防止与其他低精度数字类型混淆，尤其是浮点数 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:5:2","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"4. 抽象基类的使用 用法: 如何自定义抽象基类 如何检查具体子类是否符合接口定义 如何使用注册机制声明一个类实现了某个接口，而不进行子类化操作 如何让抽象基类自动“识别”任何符合接口的类——不进行子类化或注册 应用： 创建现有抽象基类的子类 使用现有的抽象基类注册 如果必须检查参数的类型，使用 isinstance(the_arg, collections.abc.Sequence) 需要从头编写新抽象基类的情况少之又少 如果觉得需要创建新的抽象基类，先试着通过常规的鸭子类型来解决问题 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:6:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"4.1 自定义抽象基类 抽象基类的实现 语法要求: 因版本而异，见下 抽象方法: 使用 @abstractmethod 装饰器标记，而且定义体中通常只有文档字符串 也可以有实现代码，即便有子类也必须覆盖，此时子类中可以使用 super() 函数调用抽象方法， 为它添加功能，而不是从头开始实现 具体方法: 抽象基类可以包含具体方法，但具体方法只能依赖抽象基类定义的接口(即只能使用抽象基类中的 其他具体方法、抽象方法或特性) 具体子类知晓数据的存储结构，可以覆盖具体方法，以提供更高效的实现，但这不是强制要求 Python 版本差异 Python34 方法: 直接继承 abc.ABC 或其他抽象基类 附注: abc.ABC 是 Python 3.4 新增的类 Python3 方法: 必须在 class 语句中使用 metaclass= 关键字，把值设为 abc.ABCMeta(元类) eg: class Tombola(metaclass=abc.ABCMeta): 附注: 旧版 Python，无法继承现有的抽象基类 metaclass= 关键字参数是 Python 3 引入的 Python2 方法: 必须使用 __metaclass__ 类属性 class Tombola(object): # 这是Python 2！！！ __metaclass__ = abc.ABCMeta abc 模块的其他装饰器 @abstractmethod 用法参见 https://docs.python.org/3/library/abc.html 其他装饰器: 包括: @abstractclassmethod，@abstractstaticmethod，@abstractproperty 状态: 从 Python 3.3 起废弃了，因为装饰器可以在 @abstractmethod 上堆叠 使用: 与其他方法描述符一起使用时， abstractmethod() 应该放在最里层， 即在 @abstractmethod 和 def 语句之间不能有其他装饰器 # 声明抽象类方法的推荐方式是 class MyABC(abc.ABC): @classmethod @abc.abstractmethod # 在 @abstractmethod 和 def 语句之间不能有其他装饰器 def an_abstract_classmethod(cls, ...): pass 自定义抽象基类示例 抽象基类 Tombola # Tombola 是抽象基类，有两个抽象方法和两个具体方法 import abc class Tombola(abc.ABC): # \u003c1\u003e @abc.abstractmethod def load(self, iterable): # \u003c2\u003e \"\"\"从可迭代对象中添加元素。\"\"\" @abc.abstractmethod def pick(self): # \u003c3\u003e \"\"\"随机删除元素，然后将其返回。 如果实例为空，这个方法应该抛出`LookupError`。 \"\"\" def loaded(self): # \u003c4\u003e \"\"\"如果至少有一个元素，返回`True`，否则返回`False`。\"\"\" return bool(self.inspect()) # \u003c5\u003e def inspect(self): \"\"\"返回一个有序元组，由当前元素构成。\"\"\" items = [] while True: # 抽象基类可以提供具体方法，只要依赖接口中的其他方法就行 try: items.append(self.pick()) except LookupError: # self.pick() 抛出 LookupError 这一事实也是接口的一部分， break # 但是在 Python 中没办法声明，只能在文档中说明 self.load(items) # \u003c7\u003e return tuple(sorted(items)) 子类 BingoCage import random from tombola import Tombola class BingoCage(Tombola): def __init__(self, items): self._randomizer = random.SystemRandom() self._items = [] self.load(items) # 委托 .load(...) 方法实现初始加载 def load(self, items): self._items.extend(items) # 使用 SystemRandom 实例的 .shuffle() 方法 self._randomizer.shuffle(self._items) def pick(self): # \u003c5\u003e try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') def __call__(self): # \u003c7\u003e self.pick() random.SystemRandom() 使用 os.urandom(…) 函数实现 random API 根据 os 模块的文档 http://docs.python.org/3/library/os.html#os.urandom , os.urandom(…) 函数生成“适合用于加密”的随机字节序列 BingoCage 从 Tombola 中继承了耗时的 loaded 方法和笨拙的 inspect 方法,这两个方法都可以覆盖 我们可以偷懒，直接从抽象基类中继承不是那么理想的具体方法 不过只要 Tombola 的子类正确实现 pick 和 load 方法，就能提供正确的结果 子类 LotteryBlower import random from tombola import Tombola class LotteryBlower(Tombola): def __init__(self, iterable): self._balls = list(iterable) # 初始化方法接受任何可迭代对象 def load(self, iterable): self._balls.extend(iterable) def pick(self): try: position = random.randrange(len(self._balls)) except ValueError: # 为了兼容 Tombola，我们捕获它，抛出 LookupError raise LookupError('pick from empty BingoCage') return self._balls.pop(position) def loaded(self): # 覆盖 loaded 方法，避免调用 inspect 方法,从而提升速度 return bool(self._balls) def inspect(self): return tuple(sorted(self._balls)) ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:6:1","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"4.2 检查具体子类 导入时(加载并编译),不会检查 在运行时实例化类时，Python 才会真正检查抽象方法的实现 \u003e\u003e\u003e from tombola import Tombola \u003e\u003e\u003e class Fake(Tombola): def pick(self): return 13 \u003e\u003e\u003e Fake \u003cclass '__main__.Fake'\u003e \u003e\u003e\u003e f = Fake() #实例化类时检查抽象方法是否实现 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: Can't instantiate abstract class Fake with abstract methods load ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:6:2","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"4.3 使用 register 方法声明虚拟子类 注册虚拟子类 语法: abstract_abc.register - 在抽象基类上调用 register 方法 效果: issubclass 和 isinstance 等函数都能识别继承关系， 但是注册的类不会从抽象基类中继承任何方法或属性 检查: Python 不作检查，即便是在实例化时 被注册的类必须满足抽象基类对方法名称和签名的要求，最重要的是要满足底层语义契约 .register: 版本: Python34: 通常作为普通的函数调用，也可以作为装饰器使用 Python\u003c34: 只能作为普通函数调用 附注: 更常见的做法是当作函数使用，用于注册其他地方定义的类 使用示例: 注册内置类型 https://hg.python.org/cpython/file/3.4/Lib/_collections_abc.py # 把内置类型 tuple、 str、 range 和 memoryview 注册为 Sequence 的虚拟子类 Sequence.register(tuple) Sequence.register(str) Sequence.register(range) Sequence.register(memoryview) 注册示例 from random import randrange from tombola import Tombola @Tombola.register # 把 Tombolist 注册为 Tombola 的虚拟子类 class TomboList(list): # Tombolist 扩展 list def pick(self): if self: # Tombolist 从 list 中继承 __bool__ 方法 position = randrange(len(self)) return self.pop(position) # 调用继承自 list 的 self.pop 方法 else: raise LookupError('pop from empty TomboList') load = list.extend def loaded(self): return bool(self) # loaded 方法委托 bool 函数 def inspect(self): return tuple(sorted(self)) # Tombola.register(TomboList) \u003e\u003e\u003e issubclass(TomboList, Tombola) True \u003e\u003e\u003e t = TomboList(range(100)) \u003e\u003e\u003e isinstance(t, Tombola) True \u003e\u003e\u003e TomboList.__mro__ # (\u003cclass 'tombolist.TomboList'\u003e, \u003cclass 'list'\u003e, \u003cclass 'object'\u003e) 分析: loaded 方法不能采用 load 方法的那种方式，因为 list 类型没有实现 loaded 方法所需的 __bool__ 方法。而内置的 bool 函数不需要 __bool__ 方法，因为它还可以使用 __len__ 方法 如果是 Python\u003c34，不能把 .register 当作类装饰器使用，必须使用标准的调用句法 __mro__ 作用：此类属性指定了类的继承关系，即方法解析顺序 说明： 这个属性的作用很简单，按顺序列出类及其超类， Python 会按照这个顺序搜索方法 Tombolist.__mro__ 中没有 Tombola，因此 Tombolist 没有从 Tombola 中继承任何方法 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:6:3","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"4.4 抽象基类自动识别虚拟子类 __subclasshook__ 作用: 子类检查的钩子，实现抽象基类的动态接口检查 返回: True: 表示是抽象基类的子类 NotImplemented: 让子类检查 限制: 只限于抽象基类 理解: 抽象基类的本质就是几个特殊方法，因此可以不继承或注册虚拟子类，而只要实现特定的方法即可 只要实现的特殊方法能让 __subclasshook__ 返回 True 就可以判定为抽象基类的子类 注意只有提供了 __subclasshook__ 方法的抽象基类才能这么做 源码： 在 Python源码中只只有 Sized 这一个抽象基类实现了 __subclasshook__ 方法， 而 Sized 只声明了一个特殊方法，因此只用检查这么一个特殊方法。鉴于 __len__ 方法的“特殊性”，我们基 本可以确定它能做到该做的事。但是对其他特殊方法和基本的抽象基类来说，很难这么肯定 自定义： 自己编写的抽象基类中实现 __subclasshook__ 方法，可靠性很低 自己实现的 __subclasshook__ 方法还可以检查方法签名和其他特性，但我觉得不值得这么做 class Sized(metaclass=ABCMeta): __slots__ = () @abstractmethod def __len__(self): return 0 @classmethod def __subclasshook__(cls, C): if cls is Sized: if any(\"__len__\" in B.__dict__ for B in C.__mro__): # ➊ return True # 返回 True，表明 C 是 Sized 的虚拟子类 return NotImplemented # 否则，返回 NotImplemented，让子类检查 \u003e\u003e\u003e class Struggle: ... def __len__(self): return 23 ... \u003e\u003e\u003e from collections import abc \u003e\u003e\u003e isinstance(Struggle(), abc.Sized) True \u003e\u003e\u003e issubclass(Struggle, abc.Sized) True 示例分析: C.__mro__: C 及其超类 子类检查的细节: ABCMeta.__subclasscheck__方法的源码 https://hg.python.org/cpython/file/3.4/Lib/abc.py#l194 Sized: 文档: https://hg.python.org/cpython/file/3.4/Lib/_collections_abc.py#l127 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:6:4","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"5. 利用抽象基类的 API 编写 doctest 内省类的继承关系: __subclasses__(): 返回类的直接子类列表，不含虚拟子类 _abc_registry: 只有抽象基类有这个数据属性， 值是一个 WeakSet 对象，即抽象类注册的虚拟子类的弱引用 # tombola_runner.py: Tombola 子类的测试运行程序 import doctest from tombola import Tombola import bingo, lotto, tombolist, drum # 用不到也要导入，因为要把那些类载入内存 TEST_FILE = 'tombola_tests.rst' TEST_MSG = '{0: 16} {1.attempted: 2} tests, {1.failed: 2} failed - {2}' def main(argv): verbose = '-v' in argv real_subclasses = Tombola.__subclasses__() # 内存中存在的直接子代 virtual_subclasses = list(Tombola._abc_registry) # 虚拟子类 for cls in real_subclasses + virtual_subclasses: test(cls, verbose) def test(cls, verbose=False): res = doctest.testfile( TEST_FILE, globs={'ConcreteTombola': cls}, verbose=verbose, optionflags=doctest.REPORT_ONLY_FIRST_FAILURE) tag = 'FAIL' if res.failed else 'OK' print(TEST_MSG.format(cls.__name__, res, tag)) if __name__ == '__main__': import sys main(sys.argv) ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:7:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:8:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"Python: 异常的层次结构: 参见 Python 标准库文档中的 5.4. Exception hierarchy https://docs.python.org/dev/library/exceptions.html#exception-hierarchy # 异常类的部分层次结构 BaseException ├── SystemExit ├── KeyboardInterrupt ├── GeneratorExit └── Exception ├── StopIteration ├── ArithmeticError │ ├── FloatingPointError │ ├── OverflowError │ └── ZeroDivisionError ├── AssertionError ├── AttributeError ├── BufferError ├── EOFError ├── ImportError ├── LookupError ➊ │ ├── IndexError ➋ │ └── KeyError ➌ ├── MemoryError ... etc. PEP 3119—Introducing Abstract Base Classes https://www.python.org/dev/peps/pep-3119） 讲解了抽象基类的基本原理 PEP 3141—A Type Hierarchy for Numbers https://www.python.org/dev/peps/pep-3141/） 提出了 numbers 模块 https://docs.python.org/3/library/numbers.html 中的抽象基类 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:8:1","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"blog: PyMOTW.com Python Module of the Week, http://pymotw.com abc 模块: https://pymotw.com/2/abc/index.html#why-use-abstract-base-classes 动态类型的优缺点 http://www.artima.com/intv/pycontract.html ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:8:2","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"实用工具 zope.interface 包 文档：http://docs.zope.org/zope.interface/ 作用：提供了一种声明接口的方式(检查对象是否实现了接口，注册提供方，然后查询指定接口的提供方) 应用：这个包为大型 Python 项目（如 Twisted、 Pyramid 和 Plone）的组件式架构提供了灵活的基础 blog：A Python Component Architecture 一 文 https://regebro.wordpress.com/2007/11/16/a-python-component-architecture/ 对 zope.interface 包做了介绍 相关书籍：A Comprehensive Guide to Zope Component Architecture http://muthukadan.net/docs/zca.html ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:8:3","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》 8.12 节定义了一个抽象基类 《 Python 标准库》 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:8:4","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Python"],"content":"附注 函数注解： 目的：让程序员在函数定义中使用注解声明参数和返回值的类型，但这是可选的 特性：仅当你想得到注解的好处和限制时才需要添加注解，而且可以在一些函数中添加，在另一些函数中不添加 应用：这个功能主要供 lint 程序、 IDE 和文档生成工具使用。这些工具有个共同点： 即使类型检查失败了，程序仍能运行 类型提示： PEP 484—Type Hints” https://www.python.org/dev/peps/pep-0484/ PEP 482—Literature Overview for Type Hints” https://www.python.org/dev/peps/pep-0482/ 概述了第三方 Python 工具和其他语言实现类型提示的方式 支持 PEP 484 的 typing 模块已经纳入Python 3.5 语言类型： Python 是动态强类型语言 强类型和弱类型： 如果一门语言很少隐式转换类型，说明它是强类型语言；如果经常这么做，说明它是弱类型语言 强类型能及早发现缺陷 Java、 C++ 和 Python 是强类型语言。 PHP、 JavaScript 和 Perl 是弱类型语言 静态类型和动态类型 在编译时检查类型的语言是静态类型语言，在运行时检查类型的语言是动态类型语言 静态类型需要声明类型 静态类型使得一些工具（编译器和 IDE）便于分析代码、找出错误和提供其他服务（优化、重构，等) 动态类型便于代码重用，代码行数更少，而且能让接口自然成为协议而不提早实行 猴子补丁 优缺点： 补丁通常与目标紧密耦合，因此很脆弱 打了猴子补丁的两个库可能相互牵绊，因为第二个库可能撤销了第一个库的补丁 不过猴子补丁也有它的作用，例如可以在运行时让类实现协议。适配器设计模式通过实现全新的类解决这种问题 python：不允许为内置类型打猴子补丁，这一局限能减少外部库打的补丁有冲突的概率 Java、 Go 和 Ruby 的接口 java： 不支持类的多重继承，排除了使用抽象类作为接口规范的可能性，因为一个类通常会实现多个接口 但是 Java 添加了 interface 语言结构，而且允许一个类实现多个接口——这是一种多重继承。 以更为明确的方式定义接口是 Java 的一大贡献 在 Java 8 中，接口可以提供方法实现，这叫默认方法，有了这个功能， Java 的接口与 C++ 和Python 中的抽象类更像了 https://docs.oracle.com/javase/tutorial/java/IandI/defaultmethods.html GO： 与 Python 相比，对 Go 来说就好像每个抽象基类都实现了 __subclasshook__ 方法， 它会检查函数的名称和签名，而我们自己从不需要继承或注册抽象基类。如果想让 Python 更像 Go，可以对所有函数参数做类型检查。 ","date":"2018-01-11","objectID":"/posts/program/python/grammar/fluent-python/11_abstract/:9:0","tags":["python 进阶"],"title":"抽象基类","uri":"/posts/program/python/grammar/fluent-python/11_abstract/"},{"categories":["Linux"],"content":"6.1 shell 脚本简介","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"shell 脚本简介 本章我们将开始学习 bash shell 编程。bash shell 是一门编程语言，内容庞大，按照课程的设计应该循序渐进逐步深入。但是为便于以后复查参考，会将所有 bash shell 相关的知识放在此章节中。本章我们将学习以下内容: 变量与逻辑运算 循环与条件判断 函数和位置参数 程序的学习不言而喻是为了提高运维的效率，如果我们是管理几台主机不会shell 编程可能无所谓，但是当我们管理的主机达到几百甚至几千台时，如果没有自动化运维工具和编程的基础的化，可能就只能睡在公司了。Python 和 bash shell 都是自动化运维非常常用的脚本语言，希望大家多多学习。有两本书推荐给大家 《Linux命令行和shell编程宝典》 《abs-guide》 《高级bash编程指南》 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:0:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1. 程序的分类 shell 脚本是一个比较特殊的编程语言，组成脚本的基本内容并不是通常意义上的函数或库而是 Linux 上的所有命令，所以即便只是将一条条 bash 命令堆砌在一起也可以称为 shell 脚本。因此可以将 shell 脚本看作只是在 bash 命令上添加了编程语言的特性而以。本节我们将对 shell 脚本做一个简单概述，让大家对编程能有个概括性的了解。 按照不同的分类标准，程序可以做不同的分类。根据运行方式，程序可以分为: 编译运行：源代码 –\u003e 由编译器编译成可执行的二进制文件，然后运行； 解释运行：源代码 –\u003e 运行时启动解释器，由解释器边解释边运行； 程序=指令+数据，按照程序是以指令为中心组织的，还是按照数据为中心组织，将程序分为: 过程式编程语言：以指令为中心来组织代码，数据是服务于代码； 面向对象的编程语言：以数据为中心来组织代码，围绕数据来组织指令； 我们的 shell脚本则属于过程式，解释运行的，利用系统上的命令及编程组件进行编程的编程语言。即脚本的基本组件是系统上的所有命令以及用户自定的函数，通过顺序，判断和循环来组织命令按照特定的逻辑运行即可。 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:1:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"2. 如何学习编程 网络上有个很有争议性的人物叫王垠，写过一篇文章叫《如何掌握所有的程序语言》。其核心的观念是学习程序语言重要的是学习语言特性而且是重要的语言特性，而不是语言本身。什么是语言特性，我从中摘录了他列举的示例 变量定义 算术运算 for 循环语句，while 循环语句 函数定义，函数调用 递归 静态类型系统 类型推导 lambda 函数 面向对象 垃圾回收 指针算术 goto 语句 按照他所说重要的语言特性就像是计算机的基本组件，而程序语言则是在选择不同的语言特性的基础上组装起来的计算机。作为初学者，可能很难深刻理解他表述的含义，但是他列举的语言特性，却可以给我们学习程序语言提供一个很好的思路。我们也将按照类似的顺序学习 sell 脚本编程。本节我们来讲解 shell 中的变量，以及如何创建一个简单的 shell 脚本并运行。 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:2:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1. 变量 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.1 变量的语言特性 在静态的编译语言和动态的脚本语言中，变量的概念并不完全相同。暂时大家可以理解为，变量是命名的内存空间，有类型之分。变量的类型有非常重要的作用，用于确定变量内容的 存储格式、数据范围和能参与的运算 等等。 与变量有关的语言特性包括 变量在使用前是否需要声明 强类型变量还是弱类型变量 强类型变量: 变量类型一旦确定不能改变，也不能将不同类型的变量相互运算 弱类型变量: 变量类型转换没有限制，不同类型之间的运算可能发生隐式转换 变量的作用域，这通常与变量的第一次出现的位置或声明方式有关。 变量引用，及如何获取变量的值。shell 比较特殊，需要特定的方式才能引用到变量的值 变量的命名规则，这在所有编程语言中大体是相同的。 变量名只能包含数字、字母和下划线，而且不能以数字开头 不能够使用程序的保留字 变量名最好能见名知义，并遵循某种命名法则，比如驼峰或者下划线； ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:1","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.2 shell 变量的语言特性 shell 中的变量则具有以下语言特性 变量无需声明，可直接使用 弱类型变量,无特殊声明默认把所有变量统统视作字符型； 变量引用：${var_name}, $var_name 有只读变量，只读变量无法重新赋值，无法撤销；存活时间为当前shell进程的生命周期，随shell进程终止而终止 变量赋值时，\"=\" 两边不能有空格，否则最左侧的变量名将被当作命令被解释并执行 \u003e ls=1 \u003e ls = 1 ls: 无法访问=: 没有那个文件或目录 ls: 无法访问1: 没有那个文件或目录 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:2","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.3 shell 变量的作用域 bash 中变量有三种不同的作用域: 本地变量：作用域仅为当前shell进程；除非特殊声明，所有变量均为本地变量 环境变量：作用域为当前shell进程及其子进程；需要特殊声明 局部变量：作用域仅为某代码片断(函数上下文)； ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:3","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.4 查看与销毁 shell 中变量的查看和销毁有如下几个命令: 查看环境变量 export declare -x printenv, env 查看所有变量：set 撤销变量：unset name ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:4","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.5 变量声明 bash 中变量声明的命令有 declare, export, readonly，它们都是 bash 的内置命令，用法如下 export [name[=value] 不带参数显示所有变量及其内容 带参数用于声明环境变量 readonly [-aAf] [name[=value] ...] 不带参数显示所有只读变量 带参数用于声明只读变量 declare/typeset [-aixr] [variable=[value]]: 默认：显示所有的变量及其内容，类似于 set -x：与export 一样，将后面的变量转换成环境变量 +x：将 - 变成 + 可以进行取消操作 -a：声明数组类型 array -i：声明整数类型 interger -r：将变量设置成只读类型 -p：后接变量，单独列出变量的类型 # 声明环境变量 export name=value name=value export name declare -x name=value name=value declare -x name # 声明只读变量，声明和赋值可同时进行 declare -r name[=value] readonly name[=value] ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:5","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"1.5 shell 中的特殊变量 shell 还有一些特殊变量，有特殊公用，列示如下: 位置参数变量: 保存了传递给 shell 脚本的参数； shell内置的有特殊功用的环境变量，通常为全大写字符，用于定义bash的工作环境，比如 PATH: 命令查找路经 HISTFILE, HISTSIZE, HISTFILESIZE, HISTCONTROL: 命令历史的控制参数 SHELL, HOME, UID: 当前用户的 shell类型，家目录以及UID 号 PWD, OLDPWD: 当前以及之前的工作目录 特殊变量： $?: 上一条命令的执行状态 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:3:6","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"2. 如何写shell脚本 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:4:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"2.1 hello world 的 shell 脚本 脚本文件的第一行顶格，给出解释器路径，用于指明解释执行当前脚本的解释器程序文件。常见的解释器包括 #!/bin/bash: bash shell 的解释器 #!/usr/bin/python: python 的解释器 #!/usr/bin/perl: perl 的解释器 一个 hello world 的shell 脚本如下: #!/bin/bash echo \"hello world\" ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:4:1","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"2.2 运行脚本 bash 中运行脚本有两种方式： 赋予执行权限，并直接运行此程序文件； 直接运行解释器，将脚本以命令行参数传递给解释器程序； # 方法一: 赋予可执行权限，直接运行 \u003e chmod +x /PATH/TO/SCRIPT_FILE \u003e /PATH/TO/SCRIPT_FILE # 方法二: 调用 bash 运行 \u003e bash /PATH/TO/SCRIPT_FILE ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:4:2","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"2.3 bash 调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:4:3","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Linux"],"content":"3. 练习 练习1：写一个脚本，实现如下功能； (1) 显示/etc目录下所有以大写p或小写p开头的文件或目录本身； (2) 显示/var目录下的所有文件或目录本身，并将显示结果中的小写字母转换为大写后显示； (3) 创建临时文件/tmp/myfile.XXXX; ","date":"2018-01-10","objectID":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/:5:0","tags":["马哥 Linux"],"title":"6.1 shell 脚本简介","uri":"/posts/linux/linux_mt/06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B/bash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C/"},{"categories":["Python"],"content":"Python 的序列的散列和切片","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"1. 协议和鸭子类型 协议: 理解: 在面向对象编程中，协议是非正式的接口，即按照所需的行为实现所需的方法 协议是非正式的，没有强制力，因此如果知道类的具体使用场景，通常只需要实现一个协议的部分 eg: 为了支持迭代，只需实现 __getitem__ 方法，没必要提供 __len__ 方法 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:1:0","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2. 符合Python风格的序列 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:0","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2.1 对象表示形式 from array import array import reprlib import math import numbers import functools import operator import itertools # \u003c1\u003e class Vector: typecode = 'd' def __init__(self, components): # self._components 是“受保护的”实例属性 self._components = array(self.typecode, components) # 分量保存在一个数组中 def __iter__(self): return iter(self._components) # 支持迭代协议 def __repr__(self): components = reprlib.repr(self._components) # reprlib.repr()获取有限长度表示 components = components[components.find('['): -1] return 'Vector({})'.format(components) def __str__(self): return str(tuple(self)) def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(self._components)) def __abs__(self): return math.sqrt(sum(x * x for x in self)) def __bool__(self): return bool(abs(self)) @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1: ]).cast(typecode) return cls(memv) reprlib 作用: 可以生成长度有限的表示形式 版本: Pythno3 - reprlib Python2 - repr 附注: 2to3 工具能自动重写 repr 导入的内容 接口: reprlib.repr(): 用于生成大型结构或递归结构的安全表示形式， 它会限制输出字符串的长度，用 ‘…’ 表示截断的部分 __repr__ 调用 repr() 函数的目的是调试，因此绝对不能抛出异常。如果 __repr__ 方 法的实现有问题，那么必须处理，尽量输出有用的内容，让用户能够识别目标对象 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:1","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2.2 可散列对象 def __eq__(self, other): return (len(self) == len(other) and all(a == b for a, b in zip(self, other))) # 归约函数 all def __hash__(self): hashes = (hash(x) for x in self) return functools.reduce(operator.xor, hashes, 0) # 归约各分量散列值 reduce(function, iterable,initializer) initializer 如果 iterable 为空， initializer 是返回的结果；否则，在归约中使用它作为第一个参数 因此应该使用恒等值。比如，对 +、 | 和 ^ 来说，initializer 应该是 0；而对 * 和 \u0026 来说，应该是 1 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:2","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2.3 序列协议 def __len__(self): return len(self._components) # 委托给对象中的序列属性，以支持序列协议 def __getitem__(self, index): # 切片得到的应该是当前类型的新实例，而不是其他类型 cls = type(self) # 所以不能把切片简单地委托给数组切片 if isinstance(index, slice): return cls(self._components[index]) elif isinstance(index, numbers.Integral): return self._components[index] else: msg = '{.__name__} indices must be integers' raise TypeError(msg.format(cls)) 序列协议: 只需实现 __len__ 和 __getitem__ 两个方法 切片原理 \u003e\u003e\u003e class MySeq: def __getitem__(self, index): return index # ➊ \u003e\u003e\u003e s = MySeq() \u003e\u003e\u003e s[1] 1 \u003e\u003e\u003e s[1: 4] slice(1, 4, 2) \u003e\u003e\u003e s[1: 4: 2, 9] # 如果 [] 中有逗号，那么 __getitem__ 收到的是元组 (slice(1, 4, 2), 9) \u003e\u003e\u003e s[1: 4: 2, 7: 9] # 元组中甚至可以有多个切片对象 (slice(1, 4, 2), slice(7, 9, None)) \u003e\u003e help(slice.indices) S.indices(len) -\u003e (start, stop, stride) # 给定长度为 len 的序列，计算 S 表示的扩展切片的起始（ start）和结尾（ stop）索 # 引，以及步幅（ stride）。超出边界的索引会被截掉，这与常规切片的处理方式一样 # 假设有个长度为 5 的序列，例如 'ABCDE' \u003e\u003e\u003e slice(None, 10, 2).indices(5) # 'ABCDE'[: 10: 2] 等同于 'ABCDE'[0: 5: 2] (0, 5, 2) \u003e\u003e\u003e slice(-3, None, None).indices(5) # 'ABCDE'[-3: ] 等同于 'ABCDE'[2: 5: 1] (2, 5, 1) Slice.indices 说明: https://docs.python.org/3/reference/datamodel.html?highlight=indices#slice.indices 作用: 如果不能把切片委托给底层序列类型，那么使用这个方法能节省大量时间 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:3","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2.4 动态存取属性 shortcut_names = 'xyzt' def __getattr__(self, name): cls = type(self) if len(name) == 1: pos = cls.shortcut_names.find(name) if 0 \u003c= pos \u003c len(self._components): return self._components[pos] msg = '{.__name__!r} object has no attribute {!r}' raise AttributeError(msg.format(cls, name)) def __setattr__(self, name, value): cls = type(self) if len(name) == 1: # \u003c1\u003e if name in cls.shortcut_names: # \u003c2\u003e error = 'readonly attribute {attr_name!r}' elif name.islower(): # \u003c3\u003e error = \"can't set attributes 'a' to 'z' in {cls_name!r}\" else: error = '' # \u003c4\u003e if error: # \u003c5\u003e msg = error.format(cls_name=cls.__name__, attr_name=name) raise AttributeError(msg) # 在超类上调用 __setattr__ 方法，提供标准行为 super().__setattr__(name, value) # \u003c6\u003e my_obj.x Python会检查 my_obj 实例有没有名为 x 的属性； 如果没有，到类 my_obj.__class__ 中查找； 如果还没有，顺着继承树继续查找。 如果依旧找不到，调用 my_obj 所属类中定义的 __getattr__ 方法， 传入 self 和属性名称的字符串形式 super() 作用: 用于动态访问超类的方法 程序员经常使用这个函数把子类方法的某些任务委托给超类中适当的方法 __getattr__ 多数时候，如果实现了 __getattr__ 方法，那么也要定义 __setattr__ 方法，以防对象的行为不一致 如果想允许修改分量，可以使用 __setitem__ 方法，以支持 v[0] = 1.1 或者实现 __setattr__ 方法，以支持 v.x = 1.1 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:4","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"2.5 自定义格式 def angle(self, n): # \u003c2\u003e r = math.sqrt(sum(x * x for x in self[n: ])) a = math.atan2(r, self[n-1]) if (n == len(self) - 1) and (self[-1] \u003c 0): return math.pi * 2 - a else: return a def angles(self): # \u003c3\u003e return (self.angle(n) for n in range(1, len(self))) def __format__(self, fmt_spec=''): if fmt_spec.endswith('h'): # hyperspherical coordinates fmt_spec = fmt_spec[: -1] coords = itertools.chain([abs(self)], self.angles()) # \u003c4\u003e outer_fmt = '\u003c{}\u003e' # \u003c5\u003e else: coords = self outer_fmt = '({})' # \u003c6\u003e components = (format(c, fmt_spec) for c in coords) # \u003c7\u003e return outer_fmt.format(', '.join(components)) # \u003c8\u003e ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:2:5","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:3:0","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"Python: reprlib 作用: 可以生成长度有限的表示形式 版本: Pythno3 - reprlib Python2 - repr 附注: 2to3 工具能自动重写 repr 导入的内容 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:3:1","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"blog: 函数式语言 维基百科- Fold (higher-order function) https://en.wikipedia.org/wiki/Fold_(higher-order_function) 这篇文章展示了高阶函数的用途，着重说明了具有递归数据结构的函数式语言 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:3:2","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:3:3","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"书籍: ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:3:4","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Python"],"content":"附注 向量空间模型 介绍: https://en.wikipedia.org/wiki/Vector_space_model 相关包: 向量运算: 应该使用 NumPy 和 SciPy。 gensim包: https://pypi.python.org/pypi/gensim 作用: 使用 NumPy 和 SciPy 实现了用于处理自然语言和检索信息的向量空间模型 把协议当作非正式的接口 模仿内置类型实现类时，记住一点: 模仿的程度对建模的对象来说合理即可， 例如，有些序列可能只需要获取单个元素，而不必提取切片 不要为了满足过度设计的接口契约和让编译器开心，而去实现不需要的方法，我们要 遵守 KISS 原则 http://en.wikipedia.org/wiki/KISS_principle ","date":"2018-01-10","objectID":"/posts/program/python/grammar/fluent-python/10_slice/:4:0","tags":["python 进阶"],"title":"鸭子类型","uri":"/posts/program/python/grammar/fluent-python/10_slice/"},{"categories":["Linux"],"content":"5.4 Linux特殊权限及facl扩展","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"Linux特殊权限及facl扩展 Linux 默认的访问控制模型是通过将用户划分为三类，每类用户都可设置读写执行权限实现的。但是某些特殊情况下，此模型可能不太适用，因为其控制的粒度不够。所谓特殊权限及facl 扩展就是用来扩展Linux 的访问控制模型的。本节内容包括: 安全上下文，即程序的访问控制执行环节 SUID SGID STICKY facl ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:0:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"1. 安全上下文： 所谓安全上下文即怎么决定一个用户是否某一文件具有什么权限: 进程以某用户的身份运行； 进程是发起此进程用户的代理，因此以此用户的身份和权限完成所有操作； 权限匹配模型： 判断进程的属主，是否为被访问的文件属主；如果是，则应用属主的权限；否则进入第2步； 判断进程的属主，是否属于被访问的文件属组；如果是，则应用属组的权限；否则进入第3步； 应用other的权限； ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:1:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"2. SUID 默认情况下，用户发起的进程，进程的属主是其发起者；因此，其以发起者的身份在运行。存在 SUID时，用户运行某程序时，如果此程序拥有SUID权限，那么程序运行为进程时，进程的属主不是发起者，而程序文件自己的属主； SUID 特性 进程发起者对程序文件具有可执行权限 进程的属主为程序文件的属主，而非程序发起者 SUID 权限展示在属主的执行权限位上 rws——:小写 s 表示属主原有 x 权限 rwS——:大写 S 表示属主原没有 x 权限 SUID 权限管理 chmod u+s FILE.....: 添加 SUID 权限 chmod u-s FILE.....: 删除 SUID 权限 ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:2:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"2. SGID： 默认情况下，新创建文件的数组为用户的有效用户组。当文件目录的属组有写权限，且有SGID权限时，那么所有属于此目录的属组，且以属组身份在此目录中新建文件或目录时，新文件的属组不是用户的基本组，而是此目录的属组； SGID 特性 默认情况下，用户创建文件时，其属组为此用户的基本组 一旦目录具有 SGID 权限，则对此目录具有写权限的用户，在此目录中创建的文件所属的组为目录的属组 SGID 权限展示在属组的执行权限位 —rws—: 小写 s 表示属组有 x 权限 —rwS—: 大写 S 表示属组没有 x 权限 SGID 权限管理 chmod g+s DIR.....: 添加 SGID 权限 chmod g-s DIR.....: 删除 SGID 权限 ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:3:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"3. Sticky 对于属组或全局可写的目录，组内的所有用户或系统上的所有用户对在此目录中都能创建新文件或删除所有的已有文件；如果为此类目录设置Sticky权限，则每个用户能创建新文件，且只能删除自己的文件； Sticky 特性 对于一个多人可写目录，如果此目录设置了 Sticky 权限，则每个用户仅能删除自己的文件 Sticky 权限展示在其它用户的执行权限位 ——rwt: other 拥有 x 权限 ——rwT: other 没有 x 权限 系统上的/tmp和/var/tmp目录默认均有sticky权限； Sticky 权限管理 chmod o+t DIR....: 添加 Sticky 权限 chmod o-t DIR....: 删除 Sticky 权限 基于八进制方式赋权时，可于默认的三位八进制数字左侧再加一位八进制数字 chmod 1777 ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:4:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Linux"],"content":"4. facl facl - file access control lists 指的是文件的额外赋权机制，在原来的u,g,o之外，另一层让普通用户能控制赋权给另外的用户或组的赋权机制。facl 包含两个命令，getfacl 用于查看文件访问控制列表，setfacl 用户设置文件访问控制列表 getfacl命令 getfacl FILE... \u003e getfacl README.md # file: README.md # owner: tao # group: 197121 \u003cunknown\u003e user::rw- # 属主 user:centos:rw- # facl 赋权给 centos 的权限 group::r-- # 属组 other:r-- # 其他 setfacl命令： 赋权: 赋权给用户：setfacl -m u:USERNAME:MODE FILE... 赋权给组 ：setfacl -m g:GROUPNAME:MODE FILE... 撤权： 撤销用户赋权: setfacl -x u:USERNAME FILE... 撤销组赋权: setfacl -x g:GROUPNAME FILE... ","date":"2018-01-09","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/:5:0","tags":["马哥 Linux"],"title":"5.4 Linux特殊权限及facl扩展","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/linux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95/"},{"categories":["Python"],"content":"Python 的对象引用与垃圾回收","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"内容概要: 如何使用特殊方法和约定的结构，定义行为良好且符合 Python 风格的类 符合 Python 风格的对象应该正好符合所需，而不是堆砌语言特性 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:0:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"1. 对象表示形式 |特殊方法|调用函数|作用| |: —|: —|: —| |__str__|str()|以用户理解的方式返回对象的字符串表示形式| |__repr__|repr()|以开发者理解的方式返回对象的字符串表示形式| |__bytes__|bytes()|获取对象的字节序列表示形式| |__format__|format() str.format()|使用特殊的格式代码显示对象的字符串表示形式| |__int__ |int()|在某些情况下用于强制转换类型| |__float__|float()|在某些情况下用于强制转换类型| |__complex__|complex()|对象的复数形式| Python 3: __repr__、 __str__ 和 __format__ 都必须返回 Unicode 字符串（str 类型） __bytes__ 方法应该返回字节序列（bytes 类型） __index__: 作用: 强制把对象转换成整数索引 应用: 特定的序列切片场景中使用，以及满足 NumPy 的一个需求 在实际编程中，不用实现 __index__ 方法，除非决定新建一种数值类型， 并想把它作为参数传给 __getitem__ 方法 参考: What’s New in Python 2.5 https://docs.python.org/2.5/whatsnew/pep-357.html PEP 357—Allowing Any Object to be Used for Slicing https://www.python.org/dev/peps/pep-0357/ ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:1:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"2. 类的两个装饰器 classmethod: 作用: 定义操作类，而不是操作实例的方法 参数: 类方法的第一个参数是类本身，而不是实例 用途: 最常见的用途是定义备选构造方法 staticmethod: 作用: 静态方法就是普通的函数，在类的定义体中，而不是在模块层定义 用法: The Definitive Guide on How to Use Static, Class or Abstract Methods inPython https://julien.danjou.info/blog/2013/guide-python-static-class-abstract-methods） ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:2:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"3. 字符串格式化 格式字符串句法: 作用: 字符串格式化使用的语法，又称代换字段表示法 文档: Format String Syntax https://docs.python.org/3/library/string.html#formatspec 语法: {字段名称: 格式说明符} 字段名称: 与格式说明符无关，用于决定把 .format() 的哪个参数传给代换字段 格式说明符: 使用的表示法叫格式规范微语言(Format Specification Mini-Language) 附注: format() 函数，只使用格式规范微语言 str.format() 使用格式字符串句法 格式规范微语言 文档: https://docs.python.org/3/library/string.html#formatspec 特性: 为一些内置类型提供了专用的表示代码 浮点数使用的格式代码 ’eEfFgGn%’， f 表示 float 类型，% 表示百分数形式 整数使用的格式代码有 ‘bcdoxXn’，b 和 x 分别表示二进制和十六进制的 int 类型 字符串使用的是 ’s’ 是可扩展的，方法是实现 __format__ 方法，对提供给内置函数 format(obj, format_spec) 的 format_spec，或者提供给 str.format 方法的 ‘{: «format_spec»}’ 位于代换字段中的 «format_spec» 做简单的解析 # datetime 模块中的类的 __format__ 方法使用的格式代码与 strftime() 函数一样 \u003e\u003e\u003e from datetime import datetime \u003e\u003e\u003e now = datetime.now() \u003e\u003e\u003e format(now, '%H: %M: %S') # %H 等是 datetime __format__ 扩展的规则 '18: 49: 05' \u003e\u003e\u003e \"It's now {: %I: %M %p}\".format(now) \"It's now 06: 49 PM\" ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:3:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"4. 可散列对象 需实现方法: __hash__: 实现: 应该返回一个整数 还要考虑对象属性的散列值，因为相等的对象应该具有相同的散列值 最好使用位运算符异或（ ^）混合各分量的散列值 文档: https://docs.python.org/3/reference/datamodel.html __eq__: 检测相等性，若 a == b 为真，则 hash(a) == hash(b) 也为真 对象不可变: 实现: 要想创建可散列的类型，不一定要实现特性，也不一定要保护实例属性。只 需正确地实现 __hash__ 和 __eq__ 方法即可。但是，实例的散列值绝不应该变 化以保证散列值不可变，因此需要实现只读特性保证对象不可变 方法: 将属性值保存在私有属性中,再以只读特性公开 使用 @property 装饰器把读取私有属性的读值方法标记为特性,读值方法与公开属性同名 私有属性 定义: 两个前导下划线，尾部没有或最多有一个下划线命名的实例属性 特性: Python 会把属性名存入实例的 __dict__ 属性中，而且会在前面加上一个下划线和类名 又称为名称改写，eg: __mood 会变成 _Dog__mood 目的: 避免子类意外覆盖“私有”属性，不能防止故意做错事 附注: Python 解释器不会对使用单个下划线的属性名做特殊处理 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:4:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"5. __slots__ 实例属性: 默认 Python 在实例中名为 __dict__ 的字典里存储实例属性 __slots__: 让解释器在元组中存储实例属性，而不用字典 继承自超类的 __slots__ 属性没有效果,Python 只会使用各个类中定义的 slots 属性 __slots__: 语法: 创建一个类属性 __slots__ eg: __slots__ = ('__x', '__y') 类型: 值为一个字符串构成的可迭代对象，其中各个元素表示各个实例属性 作用: 告诉解释器，这个类中的所有实例属性都在这儿了，Python 会在各个实例中使用类似元组的 结构存储实例变量，从而避免使用消耗内存的 __dict__ 属性 特性: 定义 __slots__ 属性之后，实例不能再有 __slots__ 中所列名称之外的其他属性 如果把 __dict__ 添加到 __slots__中，实例会在元组中保存各个实例的属性， 此外还支持动态创建属性，这些属性存储在常规的 __dict__ 中 把 ‘__dict__’ 添加到 __slots__ 中可能完全违背了初衷，这取决于各个实例的 静态属性和动态属性的数量及其用法 应用: 处理列表数据时 __slots__ 属性最有用，例如模式固定的数据库记录，以及特大型数据集 如果要处理数百万个数值对象，应该使用 NumPy 数组 NumPy 数组能高效使用内存，而且提供了高度优化的数值处理函数，其中很多都一次操作整个数组 __slots__问题: 每个子类都要定义 __slots__ 属性，因为解释器会忽略继承的 __slots__ 属性 实例只能拥有 __slots__ 中列出的属性，除非把 ‘__dict__’ 加入 __slots__ 中 如果不把 ‘__weakref__’ 加入 __slots__，实例就不能作为弱引用的目标 不要使用 __slots__ 属性禁止类的用户新增实例属性,__slots__ 是用于优化的，不是为了约束程序员 仅当权衡当下的需求并仔细搜集资料后证明确实有必要时，才应该使用 __slots__ 属性 __weakref__: 为了让对象支持弱引用，必须有这个属性 用户定义的类中默认就有 __weakref__ 属性 如果类中定义了 __slots__ 属性，而且想把实例作为弱引用的目标， 那么要把 ‘__weakref__‘添加到 __slots__ 中 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:5:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6. 符合 Python 风格的对象 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6.1 __slots__ from array import array import math class Vector2d: __slots__ = ('__x', '__y') typecode = 'd' ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:1","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6.2 可散列与公开只读属性 def __init__(self, x, y): self.__x = float(x) # 把 x 和 y 转换成浮点数，尽早捕获错误 self.__y = float(y) # 实现对象不可变 @property # 使用 @property 装饰器把读取私有属性的读值方法标记为特性 def x(self): # 读值方法与公开属性同名，都是 x return self.__x # 使用两个前导下划线，把属性标记为私有的 @property def y(self): return self.__y def __eq__(self, other): # 若 a == b 为真，则 hash(a) == hash(b) 也为真 return tuple(self) == tuple(other) def __hash__(self): # 通过 self.x 和 self.y 读取公开特性 return hash(self.x) ^ hash(self.y) # 位运算符异或 (^) 混合各分量的散列值 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:2","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6.3 对象表示形式 def __iter__(self): # 把 Vector2d 实例变成可迭代的对象，这样才能拆包 return (i for i in (self.x, self.y)) def __repr__(self): class_name = type(self).__name__ # 为支持类继承 return '{}({!r}, {!r})'.format(class_name, *self) # 拆包 def __str__(self): return str(tuple(self)) # 从可迭代的 Vector2d 实例中可以轻松地得到一个元组 def __bytes__(self): return (bytes([ord(self.typecode)]) + bytes(array(self.typecode, self))) # 迭代 Vector2d 实例，得到一个数组 def __abs__(self): return math.hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) # 可以直接使用 abs() ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:3","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6.4 自定义格式代码 def angle(self): return math.atan2(self.y, self.x) def __format__(self, fmt_spec=''): if fmt_spec.endswith('p'): fmt_spec = fmt_spec[: -1] coords = (abs(self), self.angle()) outer_fmt = '\u003c{}, {}\u003e' else: coords = self outer_fmt = '({}, {})' components = (format(c, fmt_spec) for c in coords) return outer_fmt.format(*components) __format__ 如果类没有定义 __format__ 方法 会从 object 继承的方法会返回 str(my_object) 如果传入格式说明符， object.__format__ 方法会抛出 TypeError \u003e\u003e\u003e v1 = Vector2d(3, 4) \u003e\u003e\u003e format(v1) # 等同于调用 Vector2d 类的 \\_\\_str\\_\\_ '(3.0, 4.0)' \u003e\u003e\u003e format(v1, '.3f') Traceback (most recent call last): ... TypeError: non-empty format string passed to object.__format__ ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:4","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"6.5 备选构造方法 @classmethod def frombytes(cls, octets): typecode = chr(octets[0]) memv = memoryview(octets[1: ]).cast(typecode) return cls(*memv) ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:6:5","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"7. 覆盖类属性 类属性可用于为实例属性提供默认值 实例属性会覆盖同名类属性 类属性是公开的，因此会被子类继承，可以通过创建子类，用于定制类属性 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:7:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:8:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"Python: NumPy: http://www.numpy.org Pandas: http://pandas.pydata.org ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:8:1","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"blog: ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:8:2","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:8:3","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"书籍: Python 语言参考手册中 “ Data Model” 一章 https://docs.python.org/3/reference/datamodel.html 3.3.1. Basic customization” https://docs.python.org/3/reference/datamodel.html#basic-customization 《 Python 技术手册（第 2 版）》 《 Python Cookbook（第 3 版）中文版》 《 Python 参考手册（第 4 版）》 ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:8:4","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Python"],"content":"附注 特性: 可以先以最简单的方式定义类，也就是使用公开属性 如果以后需要对读值方法和设值方法增加控制，那就可以实现特性 这样做对一开始通过公开属性的名称与对象交互的代码没有影响 Java: 没有特性 API 不能从简单的公开属性变成读值方法和设值方法，同时又不影响使用那些属性的代码 私有属性的安全性和保障性 Java 的 private 和 protected 修饰符往往只是为了防止意外 （即一种安全措施）。只有使用安全管理器部署应用时才能保障绝对安全，防止恶意访 问；但是，实际上很少有人这么做，即便在企业中也少见 import importlib import sys import resource NUM_VECTORS = 10**7 if len(sys.argv) == 2: module_name = sys.argv[1].replace('.py', '') module = importlib.import_module(module_name) else: print('Usage: {} \u003cvector-module-to-test\u003e'.format()) sys.exit(1) fmt = 'Selected Vector2d type: {.__name__}.{.__name__}' print(fmt.format(module, module.Vector2d)) mem_init = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss print('Creating {:,} Vector2d instances'.format(NUM_VECTORS)) vectors = [module.Vector2d(3.0, 4.0) for i in range(NUM_VECTORS)] mem_final = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss print('Initial RAM usage: {:14,}'.format(mem_init)) print(' Final RAM usage: {:14,}'.format(mem_final)) ","date":"2018-01-09","objectID":"/posts/program/python/grammar/fluent-python/09_py_object/:9:0","tags":["python 进阶"],"title":"Python风格对象","uri":"/posts/program/python/grammar/fluent-python/09_py_object/"},{"categories":["Linux"],"content":"5.3 用户权限管理","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"Linux 用户与组管理命令 本节我们将学习用户权限以及权限管理。包括以下内容： Linux 的权限模型 Linux 权限管理 Linux 属主属组管理 umask 文件权限的遮罩码设置 ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:0:0","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"1. Linux权限模型 Linux 权限模型包括: Linux 按照属主，属组，其他三类用户，分别设置了r(读)，w(写)，x(执行) 三个权限 进程对文件的访问权限，取决于进程的发起者 权限的匹配按照属主，属组，其他的顺序，如果进程的发起者是文件的属主，则进程对此文件具有属主权限 \u003e ls /etc/passwd # rwxrwxrwx # 左三位：定义user(owner)的权限 # 中三位：定义group的权限； # 右三位：定义other的权限 ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:0","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"1.1 文件与目录权限的含义 权限 文件 目录 r 可获取文件的数据 可使用ls命令获取其下的所有文件列表 w 可修改文件的数据 可修改此目录下的文件列表；即创建或删除文件 x 可将此文件运行为进程 可cd至此目录中，且可使用ls -l来获取所有文件的详细属性信息 ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:1","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"1.2 权限的数字标识 rwx 权限分别对应数字 421。这种以 2 的幂次递增的表示方式可以使得，任一一个总数都可以唯一表示一种权限类型。比如 5 表示 r-x ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:1:2","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"2.权限管理命令 chmod 命令中用户可以使用如下代号表示 u：属主 g：属组 o：其它 a: 所有 chmod [OPTION]... MODE[,MODE]... FILE... 赋权表示法，直接操作一类用户的所有权限位rwx； \u003e chmod ug=rwx /etc/fstab \u003e chmod ug=rwx,o= /etc/fstab \u003e chmod go= /etc/fstab # 数字权限设置，每个用户的权限不能省略 \u003e chmod 666 /etc/fstab chmod [OPTION]... OCTAL-MODE FILE... 授权表示法：直接操作一类用户的一个权限位r,w,x； u+, u- g+, g- o+, o- a+, a- \u003e chmod ug+x /etc/fstab \u003e chmod u-w /etc/fstab \u003e chmod +x /etc/fstab == chmod a+x /etc/fstab \u003e chmod +w /etc/fstab == /chmod u+w /etc/fstab # w 权限比较特殊 \u003e chmod u+x,g+w /etc/fstab chmod [OPTION]... --reference=RFILE FILE... 引用表示法: 引用其他文件的权限为目标设置权限 --reference: 参考的文件 chmod --reference=/var/log/message /etc/fstab chmod 的可用选项如下: 选项: -R, --recursive: 递归修改 注意：用户仅能修改属主为自己的那些文件的权限； install install 作用: copy files and set attributes 用法: 单源复制： install [OPTION]... [-T] SOURCE DEST 多源复制： install [OPTION]... SOURCE... DIRECTORY install [OPTION]... -t DIRECTORY SOURCE... 创建目录： install [OPTION]... -d DIRECTORY... 常用选项： -m, --mode=MODE：设定目标文件权限，默认为755； -o, --owner=OWNER：设定目标文件属主； -g, --group=GROUP：设定目标文件属组； mktemp mktemp [OPTION]... [TEMPLATE] 作用: create a temporary file or directory 常用选项： -d：创建临时目录 注意：mktemp会将创建的临时文件名直接返回，因此，可直接通过命令引用保存起来； \u003e mktemp /tmp/mytext.XXXXXX # 有几个 X 就有几个随机字符 ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:2:0","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"3. 从属关系管理命令 chown命令： chown [OPTION]... [OWNER][:[GROUP]] FILE... chown [OPTION]... --reference=RFILE FILE... 作用: 修改文件的属主属组 选项： -R：递归修改 注意：仅管理员可修改文件的属主和属组； \u003e chown -R tao:tao /etc/fstab # 同时更改属主属组 \u003e chown -R tao.tao /etc/fstab # 同时更改属主属组 \u003e chown -R tao /etc/fstab # 仅更改属主 \u003e chown -R :tao /etc/fstab # 仅更改属组，.与: 均可 \u003e chown -R --reference=/var/log/message /etc/fstab chgrp chgrp [OPTION]... GROUP FILE... chgrp [OPTION]... --reference=RFILE FILE... ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:2:1","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"4. umask umask [MASK] 作用: 查看或设置文件的权限反向掩码，遮罩码； 默认查看当前 umask 后跟 MASK 设置 umask 效果: 文件默认权限 = 666-umask 目录默认权限 = 777-umask 注意： 文件用666去减，表示文件默认不能拥有执行权限；如果减得的结果中有执行权限，需要将其加1； 此类设定仅对当前shell进程有效； umask: 023 666-023=644 777-023=754 ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:2:2","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Linux"],"content":"练习 # 新建系统组mariadb, 新建系统用户mariadb, 属于mariadb组，要求其没有家目录，且shell为/sbin/nologin；尝试root切换至用户，查看其命令提示符； # 新建GID为5000的组mageedu，新建用户gentoo，要求其家目录为/users/gentoo，密码同用户名； # 新建用户fedora，其家目录为/users/fedora，密码同用户名； # 新建用户www, 其家目录为/users/www；删除www用户，但保留其家目录； # 为用户gentoo和fedora新增附加组mageedu; # 复制目录/var/log至/tmp/目录，修改/tmp/log及其内部的所有文件的属组为mageedu，并让属组对目录本身拥有写权限； ","date":"2018-01-08","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/:3:0","tags":["马哥 Linux"],"title":"5.3 用户权限管理","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/"},{"categories":["Python"],"content":"Python 的对象引用与垃圾回收","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"变量保存的是引用: 简单的赋值不创建副本 对 += 或 *= 所做的增量赋值来说，如果左边的变量绑定的是不可变对象，会创建新对象；如果是可变对象，会就地修改 为现有的变量赋予新值，不会修改之前绑定的变量 – 重新绑定 函数的参数以别名的形式传递,函数可能会修改通过参数传入的可变对象 使用可变类型作为函数参数的默认值有危险，因为如果就地修改了参数，默认值也就变了，这会影响以后使用默认值的调用 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:0:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"1. 变量与对象 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:1:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"1.1 引用式变量 理解: 引用式变量不是存储数据的盒子，而是附加在对象上的标注 a=[]: Python 中赋值语句的右边先执行，对象在右边创建或获取，在此之后左边的变量才会绑定到对象上，就像为对象贴上标注 说把变量分配给对象更合理，反过来说有问题，因为对象在赋值之前就创建了 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:1:1","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"1.2 标识、 相等性和别名 标识: 每个变量都有标识、类型和值。对象一旦创建，它的标识绝不会变； 你可以把标识理解为对象在内存中的地址。 is 运算符比较两个对象的标识； id() 函数返回对象标识的整数表示 别名: 即两个变量绑定同一个对象 is 与 ==: == 运算符比较两个对象的值（对象中保存的数据），而 is 比较对象的标识 在变量和单例值之间比较时，应该使用 is, eg: x is None is 运算符比 == 速度快，因为它不能重载，Python 不用寻找并调用特殊方法，而是直接比较对象 ID a == b 是语法糖，等同于 a.__eq__(b)。继承自 object 的 __eq__ 方法比较两个对象的 ID，结果与 is 一样，多数内置类型会覆盖__eq__ 方法 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:1:2","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"1.3 元组的相对不可变性 相对不可变性: 元组(和frozenset)与多数 Python 集合（列表、字典、集，等等）一样，保存的是对象的引用 元组的不可变性其实是指 tuple 数据结构的物理内容（即保存的引用）不可变，与引用的对象无关， 即元组本身不可变，元素依然可变 而 str、 bytes 和 array.array 等单一类型序列是扁平的，它们保存的不是引用，而是 在连续的内存中保存数据本身 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:1:3","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"2. 浅层与深层复制 浅复制: 即复制了最外层容器，副本中的元素是源容器中元素的引用 构造方法(list(a))或 a[: ] 都是浅复制 copy 模块: 文档: http://docs.python.org/3/library/copy.html copy.copy(): 浅层复制 copy.deepcopy(): 深层复制 deepcopy 函数会记住已经复制的对象，因此能优雅地处理循环引用 可以实现特殊方法 __copy__() 和 __deepcopy__()，控制 copy 和 deepcopy 的行为 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:2:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"3. Python 传参方式 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:3:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"3.1 共享传参 定义: 指函数的各个形式参数获得实参中各个 引用的副本。也就是说，函数内部的形参是实参的别名 影响: 函数可能会修改作为参数传入的可变对象，但是无法修改那些对象的标识 （即不能把一个对象替换成另一个对象） 附注: 这是 Python 唯一支持的参数传递模式 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:3:1","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"3.2 可变值作为默认值 class HauntedBus: \"\"\"A bus model haunted by ghost passengers\"\"\" def __init__(self, passengers=[]): ➊ self.passengers = passengers ➋ def pick(self, name): self.passengers.append(name) ➌ def drop(self, name): self.passengers.remove(name) \u003e\u003e\u003e bus2 = HauntedBus() \u003e\u003e\u003e bus2.pick('Carrie') \u003e\u003e\u003e bus3 = HauntedBus() \u003e\u003e\u003e bus3.passengers ['Carrie'] \u003e\u003e\u003e bus3.pick('Dave') \u003e\u003e\u003e dir(HauntedBus.__init__) # doctest: +ELLIPSIS ['__annotations__', '__call__', ..., '__defaults__', ...] \u003e\u003e\u003e HauntedBus.__init__.__defaults__ # 默认值变成了函数对象的属性 (['Carrie', 'Dave'],) \u003e\u003e\u003e HauntedBus.__init__.__defaults__[0] is bus2.passengers True 分析: ➊ 如果没传入 passengers 参数，使用默认绑定的列表对象，一开始是空列表。 ➋ 这个赋值语句把 self.passengers 变成 passengers 的别名，而没有传入 passengers 参 数时，后者又是默认列表的别名。 ➌ 在 self.passengers 上调用 .remove() 和 .append() 方法时，修改的其实是默认列表， 它是函数对象的一个属性 问题在于，没有指定初始乘客的 HauntedBus 实例会共享同一个乘客列表 默认值: 默认值在定义函数时计算（通常在加载模块时），因此默认值变成了函数对象的属性 如果默认值是可变对象，而且修改了它的值，那么后续的函数调用都会受到影响 通常使用 None 作为接收可变值的参数的默认值 防御可变参数: 除非确实想修改通过参数传入的对象，否则一定要创建参数的副本 class TwilightBus: \"\"\"A bus model that makes passengers vanish\"\"\" def __init__(self, passengers=None): if passengers is None: self.passengers = [] else: self.passengers = list(passengers) # 创建并引用参数的副本，而不是别名 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:3:2","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"4. del 和垃圾回收 del: del 语句删除名称，而不是对象 仅当删除的变量保存的是对象的最后一个引用，或者无法得到对象时,对象才会被删除 重新绑定也可能会导致对象的引用数量归零，导致对象被销毁 __del__: 将销毁实例时， Python 解释器会调用 __del__ 方法，给实例最后的机会，释放外部资源 无论程序因什么原因终止，所有对象都会被回收，定义在对象上的 __del__ 方法会被调用 文档: https://docs.python.org/3/reference/datamodel.html#object.__del__ Jesse Jiryu Davis 写的“ PyPy, Garbage Collection, and a Deadlock” 对 __del__ 方法的恰当用法和不当用法做了讨论 https://emptysqua.re/blog/pypy-garbage-collection-and-a-deadlock/ CPython对象删除: 垃圾回收使用的主要算法是引用计数。每个对象都会统计有多少引用指向自己。当引用计数归零时，立即就被销毁 CPython 会在对象上调用 __del__ 方法（如果定义了），然后释放分配给对象的内存 CPython 2.0 增加了分代垃圾回收算法，用于检测引用循环中涉及的对象组 CPython 3.4 改进了处理有 __del__ 方法的对象的方式， 参见 PEP 442—Safe object finalization（https://www.python.org/dev/peps/pep-0442/） ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:4:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"4. 弱引用 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:5:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"4.1 基础概念 弱引用: 定义: 弱引用不会增加对象的引用数量 应用: 弱引用在缓存应用中很有用 概念: 引用的目标对象称为所指对象 局限: 不是每个 Python 对象都可以作为弱引用的目标（或称所指对象） 基本的 list 和 dict 实例不能作为所指对象，但是它们的子类可以 set 实例可以作为所指对象，用户定义的类型也没问题 int 和 tuple 实例不能作为弱引用的目标，甚至它们的子类也不行 原因: 与CPython 实现细节有关 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:5:1","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"4.2 weak 模块: weak简介: 文档: http://docs.python.org/3/library/weakref.html 底层接口: 供高级接口使用，不要手动创建并处理 weakref.ref 实例 wref = weak.ref(obj): 获取所指对象 wref(): 返回被引用对象，如果所指对象不存在了，返回 None 高层接口: WeakKeyDictionary、 WeakValueDictionary、 WeakSet 和 finalize \u003e\u003e\u003e import weakref \u003e\u003e\u003e a_set = {0, 1} \u003e\u003e\u003e wref = weakref.ref(a_set) ➊ \u003e\u003e\u003e wref() ➋ {0, 1} \u003e\u003e\u003e import weakref \u003e\u003e\u003e s2 = {1, 2, 3} \u003e\u003e\u003e def bye(): ➋ print('Gone with the wind...') \u003e\u003e\u003e ender = weakref.finalize(s1, bye) # 在 s1 引用的对象上注册 bye 回调 \u003e\u003e\u003e ender.alive ➍ True \u003e\u003e\u003e s2 = 'spam' # 对象被销毁了，调用了 bye 回调 Gone with the wind... \u003e\u003e\u003e ender.alive False WeakValueDictory: 作用: 一种可变映射，里面的值是对象的弱引用 被引用的对象被当作垃圾回收后，对应的键会自动从 WeakValueDictionary 中删除 经常用于缓存 \u003e\u003e\u003e import weakref \u003e\u003e\u003e stock = weakref.WeakValueDictionary() \u003e\u003e\u003e catalog = [Cheese('Red Leicester'), Cheese('Tilsit'), ... Cheese('Brie'), Cheese('Parmesan')] ... \u003e\u003e\u003e for cheese in catalog: # stock 把奶酪的名称映射到 catalog 中 Cheese 实例的弱引用上 ... stock[cheese.kind] = cheese ... \u003e\u003e\u003e sorted(stock.keys()) ['Brie', 'Parmesan', 'Red Leicester', 'Tilsit'] \u003e\u003e\u003e del catalog \u003e\u003e\u003e sorted(stock.keys()) ['Parmesan'] \u003e\u003e\u003e del cheese \u003e\u003e\u003e sorted(stock.keys()) [] WeakKeyDictionary: 键是弱引用 用途: 可以为应用中其他部分拥有的对象附加数据，这样就无需为对象添加属性。 这对覆盖属性访问权限的对象尤其有用？？ 文档: https://docs.python.org/3/library/weakref.html?highlight=weakref#weakref.WeakKeyDictionary WeakSet 作用: 保存元素弱引用的集合类。元素没有强引用时，集合会把它删除 应用: 如果一个类需要知道所有实例，一种好的方案是创建一个 WeakSet 类型的类属性，保存实例的引用 附注: 如果使用常规的 set，实例永远不会被垃圾回收，因为类中有实例的强引用， 而类存在的时间与 Python 进程一样长，除非显式删除类 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:5:2","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"5. Python对不可变类型施加的把戏 tuple: t[: ] 不创建副本，而是返回同一个对象的引用 tuple(t) 获得的也是同一个元组的引用 str、 bytes 和 frozenset: 与元组类似 frozenset 实例不是序列，因此不能使用 fs[: ] 但是， fs.copy() 具有相同的效果，返回同一个对象的引用 字符串字面量可能会创建共享的对象 共享字符串字面量是一种优化措施，称为驻留（ interning） CPython 还会在小的整数上使用这个优化措施，防止重复创建“热门”数字，如 0、 -1 和 42 注意， CPython 不会驻留所有字符串和整数，驻留的条件是实现细节，而且没有文档说明 \u003e\u003e\u003e t1 = (1, 2, 3) \u003e\u003e\u003e t3 = (1, 2, 3) # ➊ \u003e\u003e\u003e t3 is t1 # ➋ False \u003e\u003e\u003e s1 = 'ABC' \u003e\u003e\u003e s2 = 'ABC' # ➌ \u003e\u003e\u003e s2 is s1 # ➍ True ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:6:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:7:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"Python: Python 语言参考手册: Data Model 一章的开头清楚解释了对象的标识和值 https://docs.python.org/3/reference/datamodel.html gc 模块 作用: 为可选的垃圾回收程序提供接口 文档: https://docs.python.org/3/library/gc.html ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:7:1","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"blog: Wesley Chun 在 OSCON 2013 的演讲: PPT: http://conferences.oreilly.com/oscon/oscon2013/public/schedule/detail/29374 视频: https://www.youtube.com/watch?v=HHFCFJSPWrI Doug Hellmann: Python Module of the Week – 后来集结成书，即《 Python 标准库》 https://pymotw.com/3/ Fredrik Lundh: How Does Python Manage Memory? http://effbot.org/pyfaq/how-does-python-manage-memory.htm 字符串驻留: https://en.wikipedia.org/wiki/String_interning ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:7:2","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"实用工具 Python Tutor 网站: http://www.pythontutor.com ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:7:3","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"书籍: 《 Python 标准库》 copy – Duplicate Objects http://pymotw.com/2/copy/ weakref – Garbage-Collectable References to Objects http://pymotw.com/2/weakref/ 《程序设计语言——实践之路（第 3版）》 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:7:4","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Python"],"content":"杂谈 __eq__ 方法: 作用: 决定 == 如何比较实例 从 object 继承的方法比较对象的 ID 用户定义的类: 实例默认可变 如果需要不可变的对象，此时对象的每个属性都必须是不可变的 可变对象还是导致多线程编程难以处理的主要原因，因为某个线程改动对象后，如果 不正确地同步，那就会损坏数据。但是过度同步又会导致死锁 对象析构和垃圾回收: Python 没有直接销毁对象的机制 CPython 中的垃圾回收主要依靠引用计数 这意味着，在 CPython 中，这样写是安全的（至少目前如此）: open('test.txt', 'wt', encoding='utf-8').write('1, 2, 3') 这行代码是安全的，因为文件对象的引用数量会在 write 方法返回后归零， Python 在销毁内存中表示文件的对象之前，会立即关闭文件，这行代码在 Jython 或IronPython 中却不安全， 因为它们使用的是宿主运行时（ Java VM 和 .NET CLR）中的垃圾回收程序， 那些回收程序更复杂，但是不依靠引用计数，而且销毁对象和关闭文件的时间可能更长 在任何情况下，包括 CPython，最好显式关闭文件；而关闭文件的最可靠方式是使用 with 语句 参数传递模式 有按值传递: 函数得到参数的副本 按引用传递: 函数得到参数的指针 共享传参: 按值传递指针副本？？ 函数得到参数的副本，但是参数始终是引用 因为函数得到的是参数引用的副本，所以重新绑定对函数外部没有影响 ","date":"2018-01-08","objectID":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/:8:0","tags":["python 进阶"],"title":"对象引用与垃圾回收","uri":"/posts/program/python/grammar/fluent-python/08_rubbish_collection/"},{"categories":["Linux"],"content":"5.2 用户与组管理命令","date":"2018-01-07","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"5.2 用户与组管理命令","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"Linux 用户与组管理命令 本节我们将详细讲解用户与组管理的相关命令，包括以下内容: 用户的管理 用户组的管理 ","date":"2018-01-07","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"5.2 用户与组管理命令","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 用户组管理 groupadd groupadd [选项] group_name 作用: 创建新组 选项: -g GID：指定GID；默认是上一个组的GID+1； -r: 创建系统组； groupmod groupmod [选项] GROUP 作用: 修改组属性 参数: GROUP 指定要修改的组的组名 选项: -g GID：修改GID； -n new_name：修改组名； groupdel groupdel [选项] GROUP 作用: 删除组 gpasswd命令： gpasswd [选项] group 组密码文件：/etc/gshadow 作用: 设置组密码或向组添加或删除用户 选项: -a USERNAME：向组中添加用户 -d USERNAME：从组中移除用户 ","date":"2018-01-07","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"5.2 用户与组管理命令","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 用户管理 Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells useradd useradd -D： 作用: 显示创建用户的默认配置； useradd -D 选项: 作用: 修改创建用户选项的默认值； 修改的结果保存于/etc/default/useradd文件中； 选项: s: 设置默认 shell useradd [选项] 登录名 作用: 创建新用户 选项: -u, --uid UID：指定UID； -g, --gid GROUP：指定基本组ID，此组得事先存在； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：指明用户所属的附加组，多个组之间用逗号分隔； -c, --comment COMMENT：指明注释信息； -d, --home HOME_DIR：以指定的路径为用户的家目录；通过复制/etc/skel此目录并重命名实现；指定的家目录路径如果事先存在，则不会为用户复制环境配置文件； -M: 不为用户创建主目录 -s, --shell SHELL：指定用户的默认shell，可用的所有shell列表存储在/etc/shells文件中； -r, --system：创建系统用户； 注意：创建用户时的诸多默认设定配置文件为/etc/login.defs usermod命令 usermod [选项] 登录名 作用: 修改用户属性 选项: -u, --uid UID：修改用户的ID为此处指定的新UID； -g, --gid GROUP：修改用户所属的基本组； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：修改用户所属的附加组；原来的附加组会被覆盖； -a, --append：与-G一同使用，用于为用户追加新的附加组； -c, --comment COMMENT：修改注释信息； -d, --home HOME_DIR：修改用户的家目录；用户原有的文件不会被转移至新位置； -m, --move-home：只能与-d选项一同使用，用于将原来的家目录移动为新的家目录； -l, --login NEW_LOGIN：修改用户名； -s, --shell SHELL：修改用户的默认shell； -L, --lock：锁定用户密码；即在用户原来的密码字符串之前添加一个\"!\"； -U, --unlock：解锁用户的密码； userdel命令 userdel [选项] 登录 作用：删除用户 选项: -r：删除用户时一并删除其家目录； passwd passwd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username] 作用: passwd：修改用户自己的密码； passwd USERNAME：修改指定用户的密码，但仅root有此权限； 选项: -l, -u：锁定和解锁用户； -d：清除用户密码串； -e DATE: expire 过期期限，日期； -i DAYS：inactive 非活动期限； -n DAYS：minimum 密码的最短使用期限； -x DAYS：maximum 密码的最长使用期限； -w DAYS：warning 警告期限； --stdin：echo \"PASSWORD\" | passwd --stdin USERNAME newgrp命令 newgrp [-] [group] 作用: 临时切换指定的组为基本组； 选项: -: 会模拟用户重新登录以实现重新初始化其工作环境； 附注: 如果用户不属于切换的目标组，则需要输入目标组组密码 chage chage [选项] 登录名 作用: 更改用户密码过期信息 选项: -d, --lastday DAYS: 修改最近一次更改时间 -E, --exporedate DATE: 过期期限 -W: -m: -M: id id [OPTION]... [USER] 作用: 显示用户的真和有效ID; 选项: -u: 仅显示有效的UID； -g: 仅显示用户的基本组ID; -G: 仅显示用户所属的所有组的ID； -n: 显示名字而非ID； eg: id docker 练习1：创建用户gentoo，UID为4001，基本组为gentoo，附加组为distro(GID为5000)和peguin(GID为5001)； 练习2：创建用户fedora，其注释信息为\"Fedora Core\"，默认shell为/bin/tcsh； 练习3：修改gentoo用户的家目录为/var/tmp/gentoo；要求其原有文件仍能被用户访问； 练习4：为gentoo新增附加组netadmin； ","date":"2018-01-07","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"5.2 用户与组管理命令","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 用户切换 su su 用法: su -l USERNAME|su - USERNAME: 登录式切换, 会通过读取目标用户的配置文件来重新初始化 su USERNAME: 非登录式切换：不会读取目标用户的配置文件进行初始化 注意：管理员可无密码切换至其它任何用户； 选项: -c \"COMMAND\"：仅以指定用户的身份运行此处指定的命令； ","date":"2018-01-07","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"5.2 用户与组管理命令","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Python"],"content":"Python 的函数装饰器和闭包","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"函数装饰器: 用于在源码中“标记”函数，以某种方式增强函数的行为 闭包: 函数装饰器，回调式异步编程，函数式编程风格的基础 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:0:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"1. 装饰器基础 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:1:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"1.1 装饰器简介 语法: 装饰器是可调用的对象，其参数是另一个函数(被装饰的函数) 作用: 可能会处理被装饰的函数，然后把它返回 或者将其替换成另一个函数或可调用对象 使用: 装饰器通常在一个模块中定义，然后应用到其他模块中的函数上 大多数装饰器会在内部定义一个函数，然后将其返回 # 以下两种写法的最终结果一样 @decorate def target(): print('running target()') def target(): print('running target()') target = decorate(target) ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:1:1","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"1.2 装饰器执行 装饰器: 通常是在导入时，在被装饰的函数定义之后立即运行 – 导入时 被装饰函数: 只在明确调用时运行 – 运行时 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:1:2","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"1.3 使用装饰器改进“策略”模式 # 示例 7-3 promos 列表中的值使用 promotion 装饰器填充 promos = [] # \u003c1\u003e def promotion(promo_func): # \u003c2\u003e promos.append(promo_func) return promo_func @promotion # \u003c3\u003e def fidelity(order): \"\"\"5% discount for customers with 1000 or more fidelity points\"\"\" return order.total() * .05 if order.customer.fidelity \u003e= 1000 else 0 @promotion def bulk_item(order): \"\"\"10% discount for each LineItem with 20 or more units\"\"\" discount = 0 for item in order.cart: if item.quantity \u003e= 20: discount += item.total() * .1 return discount def best_promo(order): # \u003c4\u003e \"\"\"Select best discount available \"\"\" return max(promo(order) for promo in promos) ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:1:3","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"2. 变量作用域 \u003e\u003e\u003e def f2(a): ... print(a) ... print(b) ... b = 9 ... \u003e\u003e\u003e f2(3) 3 Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e File \"\u003cstdin\u003e\", line 3, in f2 UnboundLocalError: local variable 'b' referenced before assignment \u003e\u003e\u003e from dis import dis \u003e\u003e\u003e dis(f2) # 生成的字节码 作用域确定: Python 编译函数的定义体时，会将 b 判定为局部变量，因为在它在函数体中赋值 这不是缺陷，而是设计选择: Python 不要求声明变量，但假定在函数定义体中赋值的变量是局部变量 dis 模块 作用: 为反汇编 Python 函数字节码提供了简单的方式 文档: http://docs.python.org/3/library/dis.html ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:2:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"3. 闭包 \u003e\u003e\u003e avg = make_averager() \u003e\u003e\u003e avg.__code__.co_varnames ('new_value', 'total') \u003e\u003e\u003e avg.__code__.co_freevars ('series',) \u003e\u003e\u003e avg.__closure__ (\u003ccell at 0x107a44f78: list object at 0x107a91a48\u003e,) \u003e\u003e\u003e avg.__closure__[0].cell_contents [10, 11, 12] 自由变量(free variable): 指未在本地作用域中绑定的变量 闭包: 定义: 闭包指延伸了作用域的函数，其中包含在函数定义体中引用、但是不在定义体中定义的非全局变量 函数是不是匿名的没有关系，关键是它能访问定义体之外定义的非全局变量 原理: 闭包是一种函数，它会保留定义函数时，存在的自由变量的绑定 这样调用函数时，虽然定义作用域不可用了，但是仍能使用那些绑定 __code__ 属性: 表示编译后的函数定义体 __code__.co_freevars: 保存着自由变量的名称 __closure__属性: cell 对象的列表，表示自由变量，一一对应于 co_freevars cell.co_freevars: 保存着自由变量真正的值 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:3:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"4. 作用域转换 global var: 把局部变量转换为全局变量 nonlocal var: 把变量标记为自由变量 def make_averager(): count = 0 total = 0 def averager(new_value): # nonlocal count, total count += 1 total += new_value return total / count return averager \u003e\u003e\u003e avg = make_averager() \u003e\u003e\u003e avg(10) Traceback (most recent call last): ... UnboundLocalError: local variable 'count' referenced before assignment 说明: 当 count 是数字或任何不可变类型时， (count += 1) == (count =count + 1) count=count+1，会隐式创建局部变量 count, count 就不是自由变量，因此不会保存在闭包中 为了解决这个问题， Python 3 引入了 nonlocal 声明。它的作用是把变量标记为自由变量 Python 2处理方式: PEP 3104—Access to Names in Outer Scopes ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:3:1","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"5. 装饰器进阶 装饰器典型行为: 把被装饰的函数替换成新函数，二者接受相同的参数， 通常返回被装饰的函数本该返回的值，同时还会做些额外操作 即动态地给一个对象添加一些额外的职责 装饰器实现: 函数装饰器 通过实现 __call__ 方法的类实现 – 最佳方式 构建工业级装饰器的技术， 参见Graham Dumpleton 的博客和 wrapt 模块 装饰器扩展模块 wrapt: 文档: http://wrapt.readthedocs.org/en/latest/ 作用: 简化装饰器和动态函数包装器的实现，即使多层装饰也支持内省， 而且行为正确，既可以应用到方法上，也可以作为描述符使用 decorator 文档: http://pypi.python.org/pypi/decorator 作用: 简化普通程序员使用装饰器的方式，并且通过各种复杂的示例推广装饰器 装饰器用法： Graham Dumpleton 写了一系列博客文章，深入剖析了如何实现行为良好的装饰器 http://github.com/GrahamDumpleton/wrapt/blob/develop/blog/README.md Python Decorator Library 维基页面 http://wiki.python.org/moin/PythonDecoratorLibrary Guido van Rossum Five-Minute Multimethods in Python 详细说明了如何使用装饰器实现泛函数（也叫多方法） http://www.artima.com/weblogs/viewpost.jsp?thread=101605 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:4:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"5.1 简单装饰器 import time import functools def clock(func): @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time() result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -\u003e %r ' % (elapsed, name, arg_str, result)) return result return clocked functools.wraps 装饰器 作用: 把 func 的 __name__ 和 __doc__ 等相关属性复制到 clocked 中 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:4:1","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"5.2 标准库中的装饰器 functools.lru_cache(maxsize, typed): 作用: 备忘(memoization)功能，把耗时的函数的结果保存起来，避免传入相同的参数时重复计算 lru: Least Recently Used 的缩写，表明缓存不会无限增长，一段时间不用的缓存条目会被扔掉 参数: maxsize: 指定存储多少个调用的结果,为了得到最佳性能， maxsize 应该设为 2 的幂 typed:=True，把不同参数类型得到的结果分开保存，即把通常认为相等的浮点数和整数参数区分开 应用: 优化递归算法 在从 Web 中获取信息的应用中也能发挥巨大作用 附注: 因为 lru_cache 使用字典存储结果，而且键根据调用时传入的定位参数和关键字参数创建， 所以被 lru_cache 装饰的函数，它的所有参数都必须是可散列的 import functools from clockdeco import clock @functools.lru_cache() # lru_cache 可以接受配置参数 @clock # @lru_cache() 应用到 @clock 返回的函数上 def fibonacci(n): if n \u003c 2: return n return fibonacci(n-2) + fibonacci(n-1) if __name__=='__main__': print(fibonacci(6)) functools.singledispatch: 作用: 将普通函数变成泛函数(generic function), 泛函数: 根据第一个参数的类型，以不同方式执行相同操作的一组函数 特性: 可以在系统的任何地方和任何模块中注册专门函数 如果后来在新的模块中定义了新的类型，可以轻松地添加一个新的专门函数来处理那个类型 还可以为不是自己编写的或者不能修改的类添加自定义函数 文档: http://www.python.org/dev/peps/pep-0443/ 版本: python34: functools.singledispatch python\u003c34: singledispatch包 特性对比: Python 不支持 重载方法或函数，所以不能使用不同的签名定义函数的变体， 也无法使用不同的方式处理不同的数据类型 @singledispatch 不是为了把 Java 的那种方法重载带入 Python 在一个类中为同一个方法定义多个重载变体，比在一个函数中使用一长串 if/elif/elif/elif 块要更好 但是这两种方案都有缺陷，因为它们让代码单元（类或函数）承担的职责太多 @singledispath 的优点是支持模块化扩展: 各个模块可以为它支持的各个类型注册一个专门函数 from functools import singledispatch from collections import abc import numbers import html @singledispatch ➊ # @singledispatch 标记处理 object 类型的基函数 def htmlize(obj): content = html.escape(repr(obj)) return '\u003cpre\u003e{}\u003c/pre\u003e'.format(content) @htmlize.register(str) ➋ # 各个专门函数使用 @«base_function».register(«type») 装饰 def _(text): ➌ content = html.escape(text).replace('\\n', '\u003cbr\u003e\\n') return '\u003cp\u003e{0}\u003c/p\u003e'.format(content) @htmlize.register(numbers.Integral) ➍ # numbers.Integral 是 int 的虚拟超类 def _(n): return '\u003cpre\u003e{0} (0x{0: x})\u003c/pre\u003e'.format(n) @htmlize.register(tuple) ➎ # 可以叠放多个 register 装饰器，让同一个函数支持不同类型 @htmlize.register(abc.MutableSequence) def _(seq): inner = '\u003c/li\u003e\\n\u003cli\u003e'.join(htmlize(item) for item in seq) return '\u003cul\u003e\\n\u003cli\u003e' + inner + '\u003c/li\u003e\\n\u003c/ul\u003e' 分析: ➊ @singledispatch 标记处理 object 类型的基函数 ➋ 各个专门函数使用 @«base_function».register(«type») 装饰 ➍ 为每个需要特殊处理的类型注册一个函数, numbers.Integral 是 int 的虚拟超类 ➎ 可以叠放多个 register 装饰器，让同一个函数支持不同类型 只要可能，注册的专门函数应该处理抽象基类（如 numbers.Integral，abc.MutableSequence） 不要处理具体实现（如 int 和 list）。这样，代码支持的兼容类型更广泛 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:4:2","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"5.3 叠放装饰器 @d1 @d2 def f(): print('f') #等同于 def f(): print('f') f = d1(d2(f)) ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:4:3","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"5.4 参数化装饰器 实现方式: 创建一个 装饰器工厂函数，把参数传给它， 返回一个装饰器，然后再把它应用到要装饰的函数上 示例1: 一个参数化的注册装饰器 # 示例 7-23 为了接受参数，新的 register 装饰器必须作为函数调用 registry = set() # set 对象，这样添加和删除函数的速度更快 def register(active=True): def decorate(func): # 内部函数是真正的装饰器；注意，它的参数是一个函数 print('running register(active=%s)-\u003edecorate(%s)' % (active, func)) if active: registry.add(func) else: registry.discard(func) return func # decorate 是装饰器，必须返回一个函数 return decorate # register 是装饰器工厂函数，因此返回 decorate @register(active=False) # @register 工厂函数必须作为函数调用，并且传入所需的参数 def f1(): print('running f1()') @register() # 即使不传入参数， register 也必须作为函数调用 def f2(): print('running f2()') \u003e\u003e\u003e from registration_param import * \u003e\u003e\u003e register()(f3) \u003e\u003e\u003e register(active=False)(f2) 示例2: 参数化clock装饰器 import time DEFAULT_FMT = '[{elapsed: 0.8f}s] {name}({args}) -\u003e {result}' def clock(fmt=DEFAULT_FMT): def decorate(func): def clocked(*_args): t0 = time.time() _result = func(*_args) elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) # 使用 **locals() 是为了在 fmt 中引用 clocked 的局部变量 print(fmt.format(**locals())) return _result return clocked return decorate if __name__ == '__main__': @clock() # \u003c11\u003e def snooze(seconds): time.sleep(seconds) for i in range(3): snooze(.123) 示例3: 通过实现__call__方法的类实现装饰器 # BEGIN CLOCKDECO_CLS import time DEFAULT_FMT = '[{elapsed: 0.8f}s] {name}({args}) -\u003e {result}' class clock: def __init__(self, fmt=DEFAULT_FMT): self.fmt = fmt def __call__(self, func): def clocked(*_args): t0 = time.time() _result = func(*_args) elapsed = time.time() - t0 name = func.__name__ args = ', '.join(repr(arg) for arg in _args) result = repr(_result) print(self.fmt.format(**locals())) return _result return clocked ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:4:4","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"6. 泛函数用法 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:5:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"6.1 单分派泛函数 原理解析： 文档: http://www.python.org/dev/peps/pep-0443/ 文档说明：对单分派泛函数的基本原理和细节做了说明 使用示例： Guido van Rossum 写的博客 Five-Minute Multimethods in Python， 详细说明了如何使用装饰器实现泛函数（也叫多方法） http://www.artima.com/weblogs/viewpost.jsp?thread=101605 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:5:1","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"6.2 泛函数扩展模块 Reg 文档: http://reg.readthedocs.io/en/latest/ 作用: 使用现代的技术实现多分派泛函数，并支持在生产环境中使用 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:5:2","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:6:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"Python: wrapt: 文档: http://wrapt.readthedocs.org/en/latest/ 作用: 简化装饰器和动态函数包装器的实现，即使多层装饰也支持内省， 而且行为正确，既可以应用到方法上，也可以作为描述符使用 decorator 文档: http://pypi.python.org/pypi/decorator 作用: 简化普通程序员使用装饰器的方式，并且通过各种复杂的示例推广装饰器 单分派泛函数 文档: http://www.python.org/dev/peps/pep-0443/ 文档说明：对单分派泛函数的基本原理和细节做了说明 Reg 文档: http://reg.readthedocs.io/en/latest/ 作用: 使用现代的技术实现多分派泛函数，并支持在生产环境中使用 nonlocal 声明 文档: http://www.python.org/dev/peps/pep-3104/ 文档作用: 说明了引入 nonlocal 声明的原因: 重新绑定既不在本地作用域中也不在全局作用域中的名称 这份 PEP 还概述了其他动态语言（ Perl、 Ruby、 JavaScript，等等）解决这个问题的方 式，以及 Python 中可用设计方案的优缺点 词法作用域 文档: PEP 227—Statically Nested Scopes http://www.python.org/dev/peps/pep-0227/ 文档说明: 更偏重于理论，说明了 Python 2.1 引入的词法作用域。 词法作用域在这一版里是一种方案，到Python 2.2 就变成了标准 这份 PEP 还说明了 Python 中闭包的基本原理和实现方式的选择 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:6:1","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"blog: Graham Dumpleton 写了一系列博客文章，深入剖析了如何实现行为良好的装饰器 http://github.com/GrahamDumpleton/wrapt/blob/develop/blog/README.md Python Decorator Library 维基页面 http://wiki.python.org/moin/PythonDecoratorLibrary Guido van Rossum Five-Minute Multimethods in Python 详细说明了如何使用装饰器实现泛函数（也叫多方法） http://www.artima.com/weblogs/viewpost.jsp?thread=101605 Fredrik Lundh Closures in Python 解说了闭包这个术语 http://effbot.org/zone/closure.htm ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:6:2","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"实用工具 Morepath 作用: 模型驱动型 REST 式 Web 框架 http://morepath.readthedocs.org/en/latest/ ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:6:3","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"书籍: 《 Python Cookbook（第 3 版）中文版》: 第 9 章“元编程”有几个诀窍构建了基本的装饰器和特别复杂的装饰器 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:6:4","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Python"],"content":"附注 一等函数 任何把函数当作一等对象的语言，它的设计者都要面对一个问题: 作为一等对象的函 数在某个作用域中定义，但是可能会在其他作用域中调用 问题是，如何计算自由变量？ 如何计算自由变量 动态作用域: - 定义: 根据函数调用所在的环境计算自由变量 - 缺点: 对动态作用域来说，如果函数使用自由变量，程序员必须知道函数的内部细节， 这样才能搭建正确运行所需的环境 - 优点: 动态作用域易于实现 - 应用: Lisp http://www.paulgraham.com/rootsoflisp.html http://www-formal.stanford.edu/jmc/recursive/recursive.html 词法作用域: - 定义: 根据定义函数的环境计算自由变量。 - 缺点: 词法作用域让人更难实现支持一等函数的语言，因为需要支持闭包 - 优点: 词法作用域让代码更易于阅读 - 应用: Algol 之后出现的语言大都使用词法作用域 Python 装饰器和装饰器设计模式 功能: Python 函数装饰器符合 Gamma 等人在《设计模式: 可复用面向对象软件的基础》一 书中对“装饰器”模式的一般描述: “动态地给一个对象添加一些额外的职责。就扩展 功能而言，装饰器模式比子类化更灵活 实现: Python 装饰器与“装饰器”设计模式不同 在设计模式中: Decorator 和 Component 是抽象类。 为了给具体组件添加行为，具体装饰器的实例要包装具体组件的实例 在 Python 中: 装饰器函数相当于 Decorator 的具体子类， 而装饰器返回的内部函数相当于装饰器实例。 返回的函数包装了被装饰的函数，这相当于“装饰器”设计模式中的组件。 返回的函数是透明的，因为它接受相同的参数，符合组件的接口 返回的函数把调用转发给组件，可以在转发前后执行额外的操作 不是建议在 Python 程序中使用函数装饰器实现“装饰器”模式。在特定情况下确实可以这么做， 但是一般来说，实现“装饰器”模式时最好 使用类表示装饰器和要包装的组件 ","date":"2018-01-07","objectID":"/posts/program/python/grammar/fluent-python/07_decorator/:7:0","tags":["python 进阶"],"title":"函数装饰器和闭包","uri":"/posts/program/python/grammar/fluent-python/07_decorator/"},{"categories":["Linux"],"content":"5.1 系统用户与组","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"Linux 中的用户与用户组 本章我们将学习 Linux 中的用户，用户组及权限。这些都是Linux 运维的基础知识，并不难。通过四节我们将学习以下内容: Linux 中的用户及用户组 Linux 权限及权限的管理 用户及用户组的管理命令 对于 Linux 的用户及用户组，主要是学习 /etc/passwd, /etc/shadow, /etc/group 三个文件，它们保存着 Linux 用户、用户组及密码。用户管理相关命令的核心，也只是操作这几个文件而已。 有关用户包括三个方面的内容，简称 3A 用户认证 - Authentication: 用户登录时需要输入用户名和密码 用户授权 - Authorization: Linux 上文件有属主和属组，并为属组属组以及其他第三方定义了权限 授权审计 - Audition: 登录和认证会记录到日志文件中，以便于日后审计 本节我们将围绕第一方面，讲述如下内容: Linux 用户与组的基本概念，包括用户的分类，与ID标识 Linxu 用户的认证 ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:0:0","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"1. Linux 用户基础 计算机容易识别的是数字，因此用户和组在Linux 都标识为 16 位二进制数字，称为 UserID(UID)，GroupID,(GID)，范围是0-65535 Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:1:0","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"1.1 用户基础 Linux 中的用户具有如下特征 用户标识: UserID(UID) 用户分类与 ID 范围: 管理员: 0 普通用户：1-65535 系统用户: 1-499(CentOS6), 1-999(CentOS7) 作用: 为了能够让那后台进程或服务类进程以非管理员的身份运行，通常需要为此创建多个普通用户；这类用户从不用登录系统； 登录用户: 500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/passwd: 名称解析库，保存了用户名，UID等基础信息 /etc/shadow: 保存了用户的密码 ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:1:1","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"1.2 Linux 用户组 Linux 用户组 组标识：GroupID, GID 组分类与 ID 范围: 管理员组：0 通用户组：1-65635 系统用户组：1-499(CentOS6), 1-999(CentOS7) 登录用户组：500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/group: 保存了组名，组ID，组员等基本信息 /etc/gshadow: 保存了组的密码 组的其他分类: 从单个用户出发，分为： 用户的基本组 用户的附加组 按照名称: 私有组：组名同用户名，且只包含一个用户； 公共组：组内包含了多个用户； ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:1:2","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"1.3 密码的使用策略： 使用随机密码； 最短长度不要低于8位； 应该使用大写字母、小写字母、数字和标点符号四类字符中至少三类； 定期更换； 加密算法： 对称加密：加密和解密使用同一个密码； 非对称加密：加密和解密使用的一对儿密钥； 公钥：public key 私钥: private key 单向加密：只能加密，不能解密；提取数据特征码； 定长输出 雪崩效应 单向加密算法及对应命令: md5: message digest, 128bits – md5sum sha：secure hash algorithm, 160bits – shasum sha224 – sha224sum sha256 – sha256sum sha384 – sha284sum sha512 – sha512sum ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:1:3","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"2. 用户相关文件解析 ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:2:0","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"2.1 /etc/passwd 用户信息库 name:password:UID:GID:GECOS:directory:shell name: 用户名 password：可以是加密的密码，也可是占位符x； UID： GID：用户所属的主组的ID号； GECOS：注释信息 directory：用户的家目录； shell：用户的默认shell，登录时默认shell程序； ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:2:1","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"2.2 /etc/shadow：用户密码 用户名:加密的密码:最近一次修改密码的时间:最短使用期限:最长使用期限:警告期段:非活动期限:过期期限:保留字段 加密的密码: 使用 $ 符分割为 3 段分别表示: 数字，表示使用的加密算法 salt，表示加密过程中添加的随机数 加密之后的密码文本 ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:2:2","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Linux"],"content":"2.3 /etc/group：组的信息库 group_name:password:GID:user_list user_list：该组的用户成员；以此组为附加组的用户的用户列表； ","date":"2018-01-06","objectID":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/:2:3","tags":["马哥 Linux"],"title":"5.1 系统用户与组","uri":"/posts/linux/linux_mt/05-linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84/"},{"categories":["Python"],"content":"Python 中的设计模式","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"Norvig 建议在有一等函数的语言中重新审视\"策略\", “命令”, “模板方法\"和\"访问者\"模式; 即把实现单方法接口的类的实例替换成可调用对象, 因为每个 Python 可调用对象都实现了单方法接口， 这个方法就是 __call__ ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:0:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"1. 重构\"策略\"模式 策略模式: 定义：定义一系列算法，把它们一一封装起来，并且使它们可以相互替换。 本模式使得算法可以独立于使用它的客户而变化 UML： 上下文：把一些计算委托给实现不同算法的可互换组件，它提供服务 – Order 策略：实现不同算法的组件共同的接口 – Promotion 抽象基类 具体策略：策略的具体子类，实现特定的算法 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:1:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"1.1 经典策略模式示例 示例分析： 每个具体策略都是一个类，而且都只定义了一个方法，即 discount 策略实例没有状态（没有实例属性），它们看起来像是普通的函数 # 示例 6-1　实现 Order 类，支持插入式折扣策略 from abc import ABC, abstractmethod from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: # the Context def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion.discount(self) ## promotion 接受 order return self.total() - discount def __repr__(self): fmt = '\u003cOrder total: {:.2f} due: {:.2f}\u003e' return fmt.format(self.total(), self.due()) class Promotion(ABC): # the Strategy: an Abstract Base Class @abstractmethod def discount(self, order): \"\"\"Return discount as a positive dollar amount\"\"\" class FidelityPromo(Promotion): # first Concrete Strategy \"\"\"5% discount for customers with 1000 or more fidelity points\"\"\" def discount(self, order): return order.total() * .05 if order.customer.fidelity \u003e= 1000 else 0 class BulkItemPromo(Promotion): # second Concrete Strategy \"\"\"10% discount for each LineItem with 20 or more units\"\"\" def discount(self, order): discount = 0 for item in order.cart: if item.quantity \u003e= 20: discount += item.total() * .1 return discount class LargeOrderPromo(Promotion): # third Concrete Strategy \"\"\"7% discount for orders with 10 or more distinct items\"\"\" def discount(self, order): distinct_items = {item.product for item in order.cart} if len(distinct_items) \u003e= 10: return order.total() * .07 return 0 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:1:1","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"1.2 重构策略模式示例 示例分析： 把具体策略换成了简单的函数，而且去掉了 Promo抽象类 没必要在新建订单时实例化新的促销对象，函数拿来即用 享元: 定义：享元是可共享的对象，可以同时在多个上下文中使用 作用：共享是推荐的做法，这样不必在每个新的上下文 （这里是 Order 实例）中使用相同的策略时不断新建具体策略对象，从而减少消耗 优化：具体策略一般没有内部状态，只是处理上下文中的数据。此时，一定要使用普 通的函数，别去编写只有一个方法的类，再去实现另一个类声明的单函数接口。函数比用户 定义的类的实例轻量，而且无需使用\"享元\"模式，因为各个策略函数在 Python 编译模块 时只会创建一次。普通的函数也是\"可共享的对象，可以同时在多个上下文中使用” # 示例 6-3 Order 类和使用函数实现的折扣策略 from collections import namedtuple Customer = namedtuple('Customer', 'name fidelity') class LineItem: def __init__(self, product, quantity, price): self.product = product self.quantity = quantity self.price = price def total(self): return self.price * self.quantity class Order: # the Context def __init__(self, customer, cart, promotion=None): self.customer = customer self.cart = list(cart) self.promotion = promotion def total(self): if not hasattr(self, '__total'): self.__total = sum(item.total() for item in self.cart) return self.__total def due(self): if self.promotion is None: discount = 0 else: discount = self.promotion(self) # \u003c1\u003e return self.total() - discount def __repr__(self): fmt = '\u003cOrder total: {:.2f} due: {:.2f}\u003e' return fmt.format(self.total(), self.due()) # \u003c2\u003e def fidelity_promo(order): # \u003c3\u003e \"\"\"5% discount for customers with 1000 or more fidelity points\"\"\" return order.total() * .05 if order.customer.fidelity \u003e= 1000 else 0 def bulk_item_promo(order): \"\"\"10% discount for each LineItem with 20 or more units\"\"\" discount = 0 for item in order.cart: if item.quantity \u003e= 20: discount += item.total() * .1 return discount def large_order_promo(order): \"\"\"7% discount for orders with 10 or more distinct items\"\"\" distinct_items = {item.product for item in order.cart} if len(distinct_items) \u003e= 10: return order.total() * .07 return 0 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:1:2","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"1.3 选择最佳策略 模块对象： 在 Python 中，模块也是一等对象 模块对象的使用: http://wiki.jikexueyuan.com/project/the-python-study-notes-second-edition/module.html 模块自省： globals() 返回：一个字典，表示当前的全局符号表 说明：这个符号表始终针对当前模块（对函数或方法来说，是指定义它们的模块，而不是调用它们的模块） inspect.getmembers() 作用：用于获取对象的属性 参数：第二个参数是可选的判断条件（一个布尔值函数） # 示例 6-7　内省模块的全局命名空间，构建 promos 列表 promos = [globals()[name] for name in globals() # \u003c1\u003e if name.endswith('_promo') # \u003c2\u003e and name != 'best_promo'] # \u003c3\u003e def best_promo(order): \"\"\"Select best discount available \"\"\" return max(promo(order) for promo in promos) # \u003c4\u003e # 示例 6-8　内省单独的 promotions 模块，构建 promos 列表 # 唯一重要的是， promotions 模块只能包含计算订单折扣的函数。当然，这是对代码的隐性假设 # 可以添加更为严格的测试，审查传给实例的参数，进一步过滤函数 import promotions promos = [func for name, func in inspect.getmembers(promotions, inspect.isfunction)] def best_promo(order): \"\"\"Select best discount available \"\"\" return max(promo(order) for promo in promos) ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:1:3","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"2. 重构\"命令\"模式 命令模式: 目的：解耦调用操作的对象（调用者）和提供实现的对象（接收者） 对比：命令模式是回调机制的面向对象替代品 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:2:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"2.1 重构命令模式示例 示例分析： 调用者：是图形应用程序中的菜单项 接收者：是被编辑的文档或应用程序自身 实现： 在二者之间放一个 Command 对象，让它实现只有一个方法(execute)的接口， 调用接收者中的方法执行所需的操作； 调用者有一个具体的命令，通过调用 execute 方法执行 优化： 可以不为调用者提供一个 Command 实例，而是给它一个函数。 此时，调用者不用调用command.execute()，直接调用 command() 即可 MacroCommand 可以实现成定义了 __call__ 方法的类。这样， MacroCommand 的实例 就是可调用对象，各自维护着一个函数列表，供以后调用 复杂命令模式替代方案： 可调用实例，可以保存任何所需的状态，而且除了 __call__ 之外还可以提供其他方法 使用闭包在调用之间保存函数的内部状态 # 示例 6-9 MacroCommand 的各个实例都在内部存储着命令列表 class MacroCommand: \"\"\"一个执行一组命令的命令\"\"\" def __init__(self, commands): self.commands = list(commands) # ➊ def __call__(self): for command in self.commands: # ➋ command() ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:2:1","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:3:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"Python: Python 拥有一等函数和一等类型 Python 还有泛函数（ 7.8.2 节）。泛函数与 CLOS 中的多方法（ multimethod）类似 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:3:1","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"blog: Design Patterns in Dynamic Languages ： Peter Norvig 展示了如何使用一等函数（和其他动态特性）简化几个经典的设计模式， 或者根本不需要使用设计模式 http://www.norvig.com/design-patterns/index.htm） http://norvig.com/design-patterns/ Alex Martelli 关于 Python 设计模式的演讲 http://pyvideo.org/europython-2011/python-design-patterns.html http://www.aleax.it/gdd_pydp.pdf ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:3:2","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"实用工具 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:3:3","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"书籍: 《设计模式：可复用面向对象软件的基础》 “对接口编程，而不是对实现编程” “优先使用对象组合，而不是类继承” 《 Python Cookbook（第 3 版）中文版》 “8.21 实现访问者模式\"使用优雅的方式实现了\"访问者\"模式，其中的 NodeVisitor 类把方法当作一等对象处理 《Learning Python Design Patterns》 《 Python 高级编程》 第 14 章\"有用的设计模式\"从 Python 程序员的视角介绍了 7 种经典模式 《Python 3 Patterns,Recipes and Idioms》 http://www.mindviewinc.com/Books/Python3Patterns/Index.php 《 Head First 设计模式》 有关 java 设计模式的书 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:3:4","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"《 Ruby 设计模式》 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:4:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-06","objectID":"/posts/program/python/grammar/fluent-python/06_design/:5:0","tags":["python 进阶"],"title":"设计模式","uri":"/posts/program/python/grammar/fluent-python/06_design/"},{"categories":["Linux"],"content":"4.3 文件管理命令","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"bash常见特性 本节我们将学习与文件目录管理相关的命令，包括 目录管理类命令 文件查看类命令 文件管理工具 ","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 目录管理类的命令： mkdir mkdir [OPTION]... DIRECTORY... 作用: 创建目录 选项: -p: 父目录不存在时，自动按需创建父目录； -v: verbose，显示详细过程； -m: MODE：直接给定权限； rmdir rmdir [OPTION]... DIRECTORY... 作用: 删除空目录 选项: -p：删除某目录后，如果其父目录为空，则一并删除之； -v: 显示过程； ","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"tree： tree [options] [directory] 作用: 以层级方式展开显示目录 选项: -L level：指定要显示的层级； ","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:1:1","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. 文件查看类命令： cat： cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac： tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； more more FILE 作用: 分屏查看文件内容，没有 less 常用，了解即可 特点：翻屏至文件尾部后自动退出； less less FILE 作用: 分屏查看文件内容, man 手册页即是调用 less 命令显示的结果 可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit) head head [options] FILE 作用: 查看文件的前n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 tail tail [options] FILE 作用: 查看文件的后n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 -f: 查看文件尾部内容结束后不退出，跟随显示新增的行； stat stat FILE... 作用: display file or file system status \u003e stat SUMMARY.md 文件：\"SUMMARY.md\" 大小：16876 块：40 IO 块：4096 普通文件 设备：fd03h/64771d Inode：603785 硬链接：1 权限：(0664/-rw-rw-r--) Uid：( 1000/ tao) Gid：( 1000/ tao) 环境：unconfined_u:object_r:user_home_t:s0 最近访问：2018-07-06 09:04:02.197198385 +0800 # access time 最近更改：2018-07-06 09:04:02.185198436 +0800 # modify time 最近修改文件内容的时间 最近改动：2018-07-06 09:04:02.185198436 +0800 # change time 最近文件元数据发生更改的时间 创建时间：- touch： touch [OPTION]... FILE... 作用: 更改文件的时间戳 选项: -c: 指定的文件路径不存在时不予创建； -a: 仅修改access time； -m: 仅修改modify time； -t: STAMP 格式为 [[CC]YY]MMDDhhmm[.ss] ","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. 文件管理工具 copy 命令式使用: 单源复制：cp [OPTION]... [-T] SOURCE DEST 如果DEST不存在：则事先创建此文件，并复制源文件的数据流至DEST中； 如果DEST存在： 如果DEST是非目录文件：则覆盖目标文件； 如果DEST是目录文件：则先在DEST目录下创建一个与源文件同名的文件，并复制其数据流； 多源复制： cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 如果DEST不存在：错误； 如果DEST存在： 如果DEST是非目录文件：错误； 如果DEST是目录文件：分别复制每个文件至目标目录中，并保持原名； 常用选项： -i：交互式复制，即覆盖之前提醒用户确认； -f：强制覆盖目标文件； -r, -R：递归复制目录； -d：== --no-dereference --preserve=links复制符号链接文件本身，而非其指向的源文件； -a, -- archive：相当于-dR --preserve=all，用于实现归档； --preserv=:保留源文件哪些属性，可用值如下 mode：权限 ownership：属主和属组 timestamps: 时间戳 context：安全标签 xattr：扩展属性 links：符号链接 all：上述所有属性 mv mv [OPTION]... [-T] SOURCE DEST mv [OPTION]... SOURCE... DIRECTORY mv [OPTION]... -t DIRECTORY SOURCE.. 使用: 同 cp 作用: 移动文件或目录 选项： -i：交互式； -f：force rm rm [OPTION]... FILE... 作用: 删除文件或目录 选项： -i：interactive，交互 -f：force，强制删除 -r: recursive，递归删除 删除目录：rm -rf /PATH/TO/DIR 危险操作：rm -rf /* 注意：所有不用的文件建议不要直接删除，而是移动至某个专用目录；（模拟回收站） tr tr [OPTION]... SET1 [SET2] 作用: 把输入的数据当中的字符，凡是在SET1定义范围内出现的，通过对位转换为SET2出现的字符 用法1：tr SET1 SET2 \u003c /PATH/FROM/SOMEFILE – 用 SET2 替换 SET1 用法2：tr -d SET1 \u003c /PATH/FROM/SOMEFILE – 删除 SET 1中出现的字符 注意：不修改原文件 # 把/etc/passwd文件的前6行的信息转换为大写字符后输出； \u003e head -n 6 /etc/passwd | tr 'a-z' 'A-Z' \u003e tr [a-z] [A-Z] how are you HOW ARE YOU ","date":"2018-01-05","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/:2:1","tags":["马哥 Linux"],"title":"4.3 文件管理命令","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4/"},{"categories":["Python"],"content":"Python 一等函数","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"1. 函数简介 一等对象: 在运行时创建 能赋值给变量或数据结构中的元素 能作为参数传给函数 能作为函数的返回结果 一等函数: Python 函数是一等对象，又称一等函数 函数对象本身是 function 类 的实例 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:1:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"2. 函数式风格编程 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:2:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"2.1 高阶函数 简介: 定义: 接受函数为参数，或者把函数作为结果返回的函数是高阶函数 典型函数: map、 filter、 reduce 替代操作: 列表推导或生成器表达式具有 map 和 filter 两个函数的功能，而且更易于阅读 版本特性: Python 3 中， map 和 filter 返回生成器（一种迭代器） Python 2 中，这两个函数返回列表 Python 2 中， reduce 是内置函数，Python 3 中放到 functools 模块 常用函数: reduce(function, iterable,initializer) 作用：把某个操作连续应用到序列的元素上，累计之前的结果，把一系列值归约成一个值 initializer： 如果 iterable 为空， initializer 是返回的结果；否则，在归约中使用它作为第一个参数 因此应该使用恒等值，对 +、 | 和 ^ 来说，initializer 应该是 0；而对 * 和 \u0026 来说，应该是 1 all(iterable): 如果 iterable 的每个元素都是真值，返回 True； all([]) 返回 True any(iterable): 只要 iterable 中有元素是真值，就返回 True； any([]) 返回 False ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:2:1","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"2.2 匿名函数 lambda: 语法: Python 简单的句法限制了 lambda 函数的定义体只能使用纯表达式 换句话说，lambda 函数的定义体中不能赋值，也不能使用 while 和 try 等 Python 语句 应用: 作为参数传给高阶函数，除此之外 Python 很少使用匿名函数 限制: 由于句法上的限制，非平凡的 lambda 表达式要么难以阅读，要么无法写出 附注: lambda 句法只是语法糖，与 def 语句一样， lambda 表达式会创建函数对象 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:2:2","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"2.3 支持函数式编程的包 operator \u003e\u003e\u003e [name for name in dir(operator) if not name.startswith('_')] ['abs', 'add', 'and_', 'attrgetter', 'concat', 'contains','countOf', 'delitem', 'eq', 'floordiv', 'ge', 'getitem', 'gt', 'iadd', 'iand', 'iconcat', 'ifloordiv', 'ilshift', 'imod', 'imul', 'index', 'indexOf', 'inv', 'invert', 'ior', 'ipow', 'irshift', 'is_', 'is_not', 'isub', 'itemgetter', 'itruediv', 'ixor', 'le', 'length_hint', 'lshift', 'lt', 'methodcaller', 'mod', 'mul', 'ne', 'neg', 'not_', 'or_', 'pos', 'pow', 'rshift', 'setitem', 'sub', 'truediv', 'truth', 'xor'] 算术运算符函数: 以 i 开头、后面是另一个运算符的那些名称（如iadd、 iand 等），对应的是增量赋值运算符 如果第一个参数是可变的，那么这些运算符函数会就地修改它； 否则，作用与不带 i 的函数一样，直接返回运算结果。 工厂函数 itemgetter: 序列元素获取，会自行构建函数 itemgetter(1) == lambda fields: fields[1] itemgetter(1, 0) == lambda fields: fields[1]，fields[0] itemgetter 使用 [] 运算符，因此不仅支持序列， 还支持映射和任何实现 __getitem__ 方法的类 attrgetter: 对象属性获取，会自行构建函数 attrgetter 与 itemgetter 作用类似，创建的函数根据名称提取对象的属性(使用 .运算符) 如果把多个属性名传给 attrgetter，它也会返回提取的值构成的元组 此外，如果参数名中包含 .（点号）， attrgetter 会深入嵌套对象，获取指定的属性 methodcaller: 对象方法调用，会自行创建函数 methodcaller 创建的函数会在对象上调用参数指定的方法 \u003e\u003e\u003e from operator import methodcaller \u003e\u003e\u003e s = 'The time has come' \u003e\u003e\u003e upcase = methodcaller('upper') \u003e\u003e\u003e upcase(s) 'THE TIME HAS COME' \u003e\u003e\u003e hiphenate = methodcaller('replace', ' ', '-') # 冻结某些参数，也就是部分应用 \u003e\u003e\u003e hiphenate(s) 'The-time-has-come' functools functools.partial 作用: 冻结参数，部分应用一个函数 参数: 第一个参数是一个可调用对象，后面跟着任意个要绑定的定位参数和关键字参数 functools.partialmethod 作用: Python 3.4 新增，与 partial 一样，不过是用于处理方法 \u003e\u003e\u003e from tagger import tag \u003e\u003e\u003e tag \u003cfunction tag at 0x10206d1e0\u003e \u003e\u003e\u003e from functools import partial \u003e\u003e\u003e picture = partial(tag, 'img', cls='pic-frame') \u003e\u003e\u003e picture(src='wumpus.jpeg') '\u003cimg class=\"pic-frame\" src=\"wumpus.jpeg\" /\u003e' \u003e\u003e\u003e picture functools.partial(\u003cfunction tag at 0x10206d1e0\u003e, 'img', cls='pic-frame') \u003e\u003e\u003e picture.func # functools.partial 对象提供了访问原函数和固定参数的属性 \u003cfunction tag at 0x10206d1e0\u003e \u003e\u003e\u003e picture.args ('img',) \u003e\u003e\u003e picture.keywords {'cls': 'pic-frame'} ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:2:3","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"3. 可调用对象 判定: 判断对象能否调用，可以使用内置的 callable() 函数 Python 7 种可调用对象: 用户定义的函数: 使用 def 语句或 lambda 表达式创建 内置函数: 使用 C 语言（CPython）实现的函数，如 len 或 time.strftime 内置方法: 使用 C 语言实现的方法，如 dict.get 方法: 在类的定义体中定义的函数 类: - 调用类时会运行类的 __new__ 方法创建一个实例，然后运行 __init__ 方法， 初始化实例，最后把实例返回给调用方 - 因为 Python 没有 new 运算符，所以调用类相当于调用函数 - 通常，调用类会创建那个类的实例，不过覆盖 __new__ 方法的话，也可能出现其他行为 类的实例: 如果类定义了 __call__ 方法，那么它的实例可以作为函数调用 生成器函数: - 使用 yield 关键字的函数或方法 - 调用生成器函数返回的是生成器对象 - 生成器函数在很多方面与其他可调用对象不同 自定义的可调用类型 实现: 只需实现实例方法 __call__ 实践: 实现 __call__ 方法的类是创建函数类对象的简便方式 import random class BingoCage: def __init__(self, items): self._items = list(items) # \u003c1\u003e random.shuffle(self._items) # \u003c2\u003e def pick(self): # \u003c3\u003e try: return self._items.pop() except IndexError: raise LookupError('pick from empty BingoCage') # \u003c4\u003e def __call__(self): # \u003c5\u003e return self.pick() ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:3:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"4. 函数自省 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:4:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"4.1 函数特有的属性 \u003e\u003e\u003e class C: pass # ➊ \u003e\u003e\u003e obj = C() # ➋ \u003e\u003e\u003e def func(): pass # ➌ \u003e\u003e\u003e sorted(set(dir(func)) - set(dir(obj))) # ➍ ['__annotations__', '__call__', '__closure__', '__code__', '__defaults__', '__get__', '__globals__', '__kwdefaults__', '__name__', '__qualname__'] \u003e\u003e\u003e 表5-1: 类的实例没有而函数有的属性列表 名称 类型 说明 __annotations__ dict 参数和返回值的注解 __call__ method-wrapper 实现 () 运算符；即可调用对象协议 __closure__ tuple 函数闭包，即自由变量的绑定（通常是 None） __code__ code 编译成字节码的函数元数据和函数定义体 __defaults__ tuple 形式参数的默认值 __get__ method-wrapper 实现只读描述符协议（参见第 20 章） __globals__ dict 函数所在模块中的全局变量 __kwdefaults__ dict 仅限关键字形式参数的默认值 __name__ str 函数名称 __qualname__ str 函数的限定名称 (https://www.python.org/dev/peps/pep-3155/ ） __dict__: 存储用户自定义的属性 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:4:1","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"4.2 获取函数参数信息 参数内省: __defaults__: 元组，保存着定位参数和关键字参数的默认值 __kwdefaults__: 元组，保存着仅限关键字参数的默认值 __code__: code 对象引用，有很多属性，包括参数的名称 使用示例: def clip(text, max_len=80): \"\"\"Return text clipped at the last space before or after max_len \"\"\" \u003e\u003e\u003e from clip import clip \u003e\u003e\u003e clip.__defaults__ (80,) \u003e\u003e\u003e clip.__code__ # doctest: +ELLIPSIS \u003ccode object clip at 0x...\u003e \u003e\u003e\u003e clip.__code__.co_varnames # 包括参数名称和函数内创建的局部边量 ('text', 'max_len', 'end', 'space_before', 'space_after') \u003e\u003e\u003e clip.__code__.co_argcount # 参数数量 2 __code__.co_varnames 包括参数名称和函数内创建的局部边量 参数名称是前 N 个字符串， N 的值由__code__.co_argcount 确定 不包含前缀为 * 或 ** 的变长参数 参数的默认值只能通过它们在 __defaults__ 元组中的位置确定， 因此要从后向前扫描才能把参数和默认值对应起来 inspect 模块 \u003e\u003e\u003e from clip import clip \u003e\u003e\u003e from inspect import signature \u003e\u003e\u003e sig = signature(clip) # 返回一个 inspect.Signature 对象， \u003e\u003e\u003e sig # \u003cinspect.Signature object at 0x...\u003e \u003e\u003e\u003e str(sig) '(text, max_len=80)' \u003e\u003e\u003e for name, param in sig.parameters.items(): ... print(param.kind, ': ', name, '=', param.default) POSITIONAL_OR_KEYWORD : text = \u003cclass 'inspect._empty'\u003e POSITIONAL_OR_KEYWORD : max_len = 80 inspect: 作用: 函数参数自省 附注: 特殊的 inspect._empty 值表示没有默认值 inspect 接口: signature 函数: 返回一个 inspect.Signature 对象 Signature 对象: 有一个 parameters属性，这是一个有序映射， 把参数名和 inspect.Parameter 对象对应起来 有个 bind 方法，它可以把任意个参数绑定到签名中的形参上,所 用的规则与实参到形参的匹配方式一样。框架可以使用这个方法在真正调用函数前验证参数 Parameter 对象: 有 name、 default 和 kind 属性 kind是 _ParameterKind 类中的 5 个值之一 POSITIONAL_OR_KEYWORD: 可以通过定位参数和关键字参数传入的形参 VAR_POSITIONAL: 定位参数元组 VAR_KEYWORD: 关键字参数字典 KEYWORD_ONLY: 仅限关键字参数（ Python 3 新增） POSITIONAL_ONLY: 仅限定位参数；目前， Python 声明函数的句法不支持， 但是有些使用 C 语言实现且不接受关键字参数的函数（如 divmod）支持 Parameter 对象还有一个 annotation（注解）属性，值通常是 inspect._empty， 但是可能包含 Python 3 新的注解句法提供的函数签名元数据 Signature.bind 用法 # 展示了 Python 数据模型把实参绑定给函数调用中的形参的机制，这与解释器使用的机制相同 # 框架和 IDE 等工具可以使用这些信息验证代码 \u003e\u003e\u003e import inspect \u003e\u003e\u003e sig = inspect.signature(tag) # 获取 tag 函数（见示例 5-10）的签名 \u003e\u003e\u003e my_tag = {'name': 'img', 'title': 'Sunset Boulevard', ... 'src': 'sunset.jpg', 'cls': 'framed'} \u003e\u003e\u003e bound_args = sig.bind(**my_tag) ➋ \u003e\u003e\u003e bound_args # 得到一个 inspect.BoundArguments 对象 \u003cinspect.BoundArguments object at 0x...\u003e # 迭代 bound_args.arguments（一个 OrderedDict 对象） \u003e\u003e\u003e for name, value in bound_args.arguments.items(): ➍ ... print(name, '=', value) ... name = img cls = framed attrs = {'title': 'Sunset Boulevard', 'src': 'sunset.jpg'} \u003e\u003e\u003e del my_tag['name'] # 把必须指定的参数 name 从 my_tag 中删除 \u003e\u003e\u003e bound_args = sig.bind(**my_tag) Traceback (most recent call last): ... TypeError: 'name' parameter lacking default value 框架应用 import bobo @bobo.query('/') def hello(person): return 'Hello %s!' % person HTTP 微框架 Bobo bobo.query 装饰器把一个普通的函数与框架的请求处理机制集成起来了 内省 hello 函数，发现它需要一个名为 person 的参数，然后从请求中获取那个名称对应的参数， 将其传给hello 函数 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:4:2","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"5. 函数参数传递与解析 def tag(name, *content, cls=None, **attrs): \"\"\"Generate one or more HTML tags\"\"\" \u003e\u003e\u003e my_tag = {'name': 'img', 'title': 'Sunset Boulevard', ... 'src': 'sunset.jpg', 'cls': 'framed'} \u003e\u003e\u003e tag(**my_tag) \u003e\u003e\u003e def f(a, *, b): # b 仅限关键词参数，同时不支持数量不定的定位参数 ... return a, b 参数传递与解析: 调用函数时使用 * 和 ** “展开” 可迭代对象，映射到单个参数 *content 将捕获所有多余的定位参数 **attrs 将捕获所有多余的关键词参数 cls 参数只能作为关键字参数传入 – python3 新特性 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:5:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"6. 函数注解 注解: 版本: Python 3 作用: 为函数声明中的参数和返回值附加元数据 注解不会做任何处理，只是存储在函数的 __annotations__ 属性 注解对Python 解释器没有任何意义。注解只是元数据 为 IDE 和 lint 程序等工具中的静态类型检查功能提供额外的类型信息 语法: 函数声明中的各个参数可以在 : 之后增加注解表达式 如果参数有默认值，注解放在参数名和 = 号之间 如果想注解返回值，在 ) 和函数声明末尾的 : 之间添加 -\u003e 和一个表达式 注解中最常用的类型是类（如 str 或 int）和字符串（如’int \u003e 0’） def clip(text: str, max_len: 'int \u003e 0'=80) -\u003e str: # \u003c1\u003e \"\"\"Return text clipped at the last space before or after max_len \"\"\" \u003e\u003e\u003e from clip_annot import clip \u003e\u003e\u003e clip.__annotations__ # return 键保存的是返回值注解 {'text': \u003cclass 'str'\u003e, 'max_len': 'int \u003e 0', 'return': \u003cclass 'str'\u003e} ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:6:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"6.2 提取注解 \u003e\u003e\u003e from clip_annot import clip \u003e\u003e\u003e from inspect import signature \u003e\u003e\u003e sig = signature(clip) \u003e\u003e\u003e sig.return_annotation \u003cclass 'str'\u003e \u003e\u003e\u003e for param in sig.parameters.values(): ... note = repr(param.annotation).ljust(13) ... print(note, ': ', param.name, '=', param.default) \u003cclass 'str'\u003e : text = \u003cclass 'inspect._empty'\u003e 'int \u003e 0' : max_len = 80 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:6:1","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:7:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"Python: Python3 专有特性: PEP 3102—Keyword-Only Arguments https://www.python.org/dev/peps/pep-3102/ PEP 3107—Function Annotations https://www.python.org/dev/peps/pep-3107/ 注解的使用: What are good uses for Python3’s‘ Function Annotations’ http://stackoverflow.com/questions/3038033/what-are-good-uses-for-python3s-function-annotations What good are Python function annotations? http://stackoverflow.com/questions/13784713/what-good-are-python-function-annotations functools.partial: Python: Why is functools.partial necessary? http://stackoverflow.com/questions/3252228/python-why-is-functools-partial-necessary inspect: PEP 362—Function Signature Object https://www.python.org/dev/peps/pep-0362/ ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:7:1","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"blog: Python 函数式编程: Python Functional Programming HOWTO http://docs.python.org/3/howto/functional.html ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:7:2","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"实用工具 fn.py: https://github.com/kachayev/fn.py 是为 Python 2 和 Python 3 提供函数式编程支持的包 提供了 Python“所缺少的函数式特性 这个包提供的 @recur.tco 装饰器为 Python 中的无限递归实现了尾调用优化 此外， fn.py 还提供了很多其他函数、数据结构和诀窍 Bobo: 或许是第一个称得上是面向对象的 Web 框架 进一步学习它最近的重写版本，先从“ Introduction” http://bobo.readthedocs.io/en/latest/ 入手 Bobo 的一些早期历史 http://discuss.fogcreek.com/joelonsoftware/default.asp?cmd=show\u0026ixPost=94006 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:7:3","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"书籍: 《Python 语言参考手册》: https://docs.python.org/3/reference/datamodel.html#the-standard-type-hierarchy 对 7 种可调用类型和其他所有内置类型做了介绍 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:7:4","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Python"],"content":"杂谈 关于 Bobo 1997 年， Bobo 开创了对象发布概念: 直接把 URL 映射到对象层次结构上，无需配置路由 Bobo 还能通过分析处理请求的方法或函数的签名来自动处理 HTTP 查询 Zope: Zope 是 Plone CMS、 SchoolTool、 ERP5 和其他大型Python 项目的基础 ZODB（ Zope Object Database） 事务型对象数据库，提供了 ACID（atomicity, consistency, isolation, and durability， 原子性、一致性、隔离性和耐久性），它的设计目的是简化 Python 的使用 Krishnamurthi 指出，不要试图把语言归为某一类；相反，把它们视作特性的聚合更有用 Python 函数式编程 从另一门函数式语言（ Haskell）中借用列表推导之后， Python 对 map、 filter，以及 lambda 表达式的需求极大地减少了 除了匿名函数句法上的限制之外，影响函数式编程惯用法在 Python 中广泛使用的最大 障碍是缺少尾递归消除（ tail-recursion elimination），这是一项优化措施，在函数的定义体 “末尾”递归调用，从而提高计算函数的内存使用效率 Guido 在另一篇博客文章（TailRecursion Elimination， http://neopythonic.blogspot.com/2009/04/tail-recursion-elimination.html） 中解释了为什么这种优化措施不适合 Python 这篇文章详细讨论了技术论证，不过前三个也是最重要的原因与易用性有关 Python 作为一门易于使用、学习和教授的语言并非偶然，有 Guido 在为我们把关 综上，从设计上看，不管函数式语言的定义如何， Python 都不是一门函数式语言。 Python 只是从函数式语言中借鉴了一些好的想法 匿名函数缺陷: 匿名函数都有一个严重的缺点: 没有名称 匿名函数嵌套的层级太深，不利于调试和处理错误 ","date":"2018-01-05","objectID":"/posts/program/python/grammar/fluent-python/05_func_object/:8:0","tags":["python 进阶"],"title":"函数","uri":"/posts/program/python/grammar/fluent-python/05_func_object/"},{"categories":["Linux"],"content":"4.2 bash常见特性","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"bash常见特性 bash 作为外壳程序的一种，为我们提供了与操作系统内核交互的接口。bash 本身具有丰富的特性，为我们执行和管理应用提供了便利。本节我们将学习 bash 的如下特性 命令历史 命令与路径补全 命令行展开 获取命令的执行状态和执行结果 引用与快捷键 通配符 IO重定向及管道 命令 hash 多命令执行 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:0:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"1. bash 命令历史 命令历史指的是 shell 进程会其会话中保存此前用户提交执行过的命令；于此同时 bash 提供了快捷方式，以便我们能快速执行历史命令 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:1:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"1.1 命令历史控制相关的环境变量 HISTSIZE：shell进程可保留的命令历史的条数； HISTFILE: 持久保存命令历史的文件，默认为 ~/.bash_history HISTFILESIZE: 命令历史文件的大小； HISTCONTROL: 控制命令历史记录的方式，可选值如下 ignoredups：忽略重复的命令； ignorespace：忽略以空白字符开头的命令； ignoreboth：以上两者同时生效； ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:1:1","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"1.2 命令用法： history [-c] [-d 偏移量] [n] history -anrw [文件名] history -ps 参数 [参数...] -c: 清空命令历史； -d offset：删除指定命令历史 -r: 从文件读取命令历史至历史列表中； -w：把历史列表中的命令追加至历史文件中； history n：显示最近的 n 条命令； ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:1:2","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"1.3 快捷方式 常见的历史命令的快捷方式如下 调用命令历史列表中的命令： !#：再一次执行历史列表中的第#条命令； !!：再一次执行上一条命令； !STRING：再一次执行命令历史列表中最近一个以STRING开头的命令； 调用上一条命令的最后一个参数： 快捷键：ESC, . - 表示先按 ESC，在按 . 字符串：!$ ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:1:3","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"2. 命令补全： 所谓命令补全，就是在bash 中按下 tab 键之后，bash 会自动查找以当前输入字符开头的命令。如果给定的打头字符串如果能惟一标识某命令程序文件，则直接补全；不能惟一标识某命令程序文件，再击tab键一次，会给出列表。命令查找机制 如下： 优先查找内部命令； 根据PATH环境变量中设定的目录，自左而右逐个搜索目录下的文件名； 路径补全 与命令补全功能类似，只是路径补全只会在给定的起始路径下，逐一匹配起始路径下的每个文件。道理很简单，如果匹配到别处的文件名，在起始目录也还是查找不到，所以补全也没什么用。 命令和路径补全是 bash 中非常好用的功能，没事多敲击几次 tab 就好。 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:2:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"3. 命令行展开 Linux 中有如下特殊字符，用于扩展命令的输入方式: ~: 自动展开为用户的家目录，或指定的用户的家目录； {}: 可承载一个以逗号分隔的路径列表，并能够将其展开为多个路径； \u003e /tmp/{a,b} # 相当于 \u003e /tmp/a /tmp/b \u003e mkdir -pv /tmp/x/{y1/{a,b},y2} \u003e mkdir -v {a,b}_{c,d} \u003e mkdir -pv /tmp/mysysroot/{bin,sbin,etc/sysconfig/network-scripts,usr/{bin,sbin,local/{bin,sbin,etc,lib},lib,lib64},var/{cache,log,run}} ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:3:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"4. 获取命令的执行状态和执行结果 命令的执行状态: 表示命令执行成功还是失败 命令执行完成之后，其状态返回值保存于bash的 $? 特殊变量中； 命令返回值: 表示命令的返回结果，或者是命令的输出内容 bash 中可以通过如下方式引用命令的执行结果，这在 bash 编程中非常有用 $(COMMAND) COMMAND ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:4:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"5. 引用与快捷键 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:5:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"5.1 Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:5:1","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"5.2 快捷键 Ctrl+a：跳转至命令行行首 Ctrl+e：跳转至命令行行尾 Ctrl+u：删除行首至光标所在处之间的所有字符； Ctrl+k：删除光标所在处至行尾的所有字符； Ctrl+l：清屏，相当于clear ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:5:2","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"6. globbing - 文件名通配 通配符指的是 bash 中的特殊字符，称为元字符，元字符不表示字符本身而是表示一定范围内的或符合匹配条件的一类字符。通过元字符达到模糊匹配的作用。需要注意的是通配符跟正则表达式是完全不同的东西，不同软件，程序中的通配符也不会完全相同。需要特别注意的是bash 中的通配机制 匹配的是整体文件名，而非部分 bash 中的元字符如下 *：匹配任意长度的任意字符 ?：匹配任意单个字符 []：匹配指定范围内的任意单个字符，有如下几种特殊格式： `[a-z], [A-Z]: 不会区分文件名大小写，二者表示范围相同 [0-9], [a-z0-9]`: [[:upper:]]：所有大写字母 [[:lower:]]：所有小写字母 [[:alpha:]]：所有字母 [[:digit:]]：所有数字 [[:alnum:]]：所有的字母和数字 [[:space:]]：所有空白字符 [[:punct:]]：所有标点符号 [^]：匹配指定范围外的任意单个字符 [^[:upper:]] [^0-9] [^[:alnum:]] # 练习 # 显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现一位任意字符的文件或目录； \u003e ls -d /var/l?[[:lower:]] # 显示/etc目录下，以任意一位数字开头，且以非数字结尾的文件或目录； \u003e ls -d /etc/[0-9]*[^0-9] # 显示/etc目录下，以非字母开头，后面跟一个字母及其它任意长度任意字符的文件或目录； \u003e ls -d /etc/[^a-z][a-z]* # 复制/etc目录下，所有以m开头，以非数字结尾的文件或目录至/tmp/magedu.com目录； \u003e cp -r /etc/m*[^0-9] /tmp/magedu.com/ # 复制/usr/share/man目录下，所有以man开头，后跟一个数字结尾的文件或目录至/tmp/man/目录下； \u003e cp -r /usr/share/man/man[0-9] /tmp/man/ # 复制/etc目录下，所有以.conf结尾，且以m,n,r,p开头的文件或目录至/tmp/conf.d/目录下； \u003e cp -r /etc/[mnrp]*.conf /tmp/conf.d/ ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:6:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"7. IO重定向及管道 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:7:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"7.1 IO重定向： IO 我的理解就是文本流，所谓 IO 重定向就是将原本输入输出一个地方的文件流重新导向另一个地方。与输入输出相关的概念如下 可用于输入的设备包括：文件、键盘设备、文件系统上的常规文件、网卡等； 可用于输出的设备包括：文件、显示器、文件系统上的常规文件、网卡等； 默认情况下，bash 为程序提供了三种标准数据流： 输入的数据流；\u003c– 标准输入(stdin)，键盘； 输出的数据流：–\u003e 标准输出(stdout)，显示器； 错误输出流： –\u003e 标准错误输出(stderr)，显示器； IO 重定可分为覆盖重定向和追加重定向，所谓覆盖就是如果重定向的目标是文件，会先清空文件中的内容，而追加只是在文件的结尾继续写入。IO重定向的实现如下: 输入重定向： \u003c \u003c\u003c: 表示创建文档，使用方式见下 cat命令 输出重定向 \u003e: 覆盖重定向 == 1\u003e \u003e\u003e: 追加重定向 == 1\u003e\u003e 错误输出重定向： 2\u003e: 覆盖重定向 2\u003e\u003e: 追加重定向 合并正常输出流和错误输出流： \u0026\u003e \u0026\u003e\u003e # 合并正常输出流和错误输出流 COMMAND \u003e /path/to/somefile 2\u003e\u00261 # 方法一 COMMAND \u0026\u003e /path/to/somefile # 方法二 COMMAND \u003e\u003e /path/to/somefile 2\u003e\u00261 # 方法一 COMMAND \u0026\u003e\u003e /path/to/somefile # 方法二 需要注意的是上述中 1,2 指代的是标准输入输出对应的文件描述符(fd, file descriptor)。文件描述符是操作系统的一个抽象概念，表示打开的文件。大家可以理解为 Linux中一切皆文件，如果要操作文件必须将文件关联到某个文件描述符。bash 在开启时，会自动做如下关联 标准输入：0 标准输出：1 错误输出：2 Linux 中有一个特殊设备/dev/null，它会丢弃接收到的所有输入，又称数据黑洞。通常在 shell 编程中，我们只需要知道命令的执行状态，而无需命令的执行结果时，可以将输出重定向至此设备 \u003e head -1 /etc/passwd \u0026\u003e /dev/null # 判断 /etc/passwd 是否有内容 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:7:1","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"7.2 管道 管道是 Linux 提供的一种进程间交互(IPC)的一种方法。大家不必过于纠结它是个什么东西，只要知道的是，它可以把一个程序的输入变成另一个程序的输入，就像一根管道一样连接着程序与程序。管道的使用方式类似 COMMAND | COMMAND | COMMAND....,使用 | 链接多个命令即可。 # 管道与 IO重定向定义 \u003e cat /etc/issue | tr 'a-z' 'A-Z' \u003e /tmp/issue \u003e who | head -2 | tr 'a-z' 'A-Z' | tr -d '0-9' \u003e /tmp/who.txt ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:7:2","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"7.3 bash 中对IO重定向的控制 set 作用: 设置或撤销，shell 选项或位置参数的值 set -C 作用: 禁止覆盖输出重定向至已存在的文件； 附注: 此时可使用强制覆盖输出：\u003e| set +C 作用: 关闭上述特性 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:7:3","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"7.4 重定向相关命令 cat cat \u003e /PATH/TO/SOMEFILE \u003c\u003c EOF # EOF 表示文档创建的结束符 # 通过屏幕的输入将保存至 /PATH/TO/SOMEFILE \u003e cat \u003e /PATH/TO/SOMEFILE \u003c\u003c EOF how are you yes it is me EOF \u003e cat /PATH/TO/SOMEFILE how are you yes it is me tee命令： tee [OPTION]... [FILE] 作用: 把标准输入的数据复制到每一个文件FILE,同时送往标准输出, 参数: FILE: 可以有多个 选项: -a: 追加到给出的文件, 而不是覆盖 eg：COMMAND | tee /PATH/TO/SOMEFILE ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:7:4","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"8.命令 hash 所谓命令 hash 是指 bash 会缓存此前命令的查找结果。哈希是一种数据结构，通常也称为字典存储着键值对，能通过键快速的查找到对应的值。bash 内置的 hash 命令能显示和管理 bash 命令的缓存结果。 hash [options] [COMMAND] 用法: - hash：列出所有的缓存结果 - hash -d COMMAND：删除 COMMAND 命令的缓存 - hash -r：清空所有缓存 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:8:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Linux"],"content":"9. 多命令执行 bash 中可以同时执行多条命令，命令之间可以没有关系顺序执行，也可以逻辑关系。可以理解为写在命令行的单行脚本。 COMMAND1; COMMAND2;....: 多条命令互不影响，顺序执行 COMMAND1 \u0026\u0026 COMMAND2: \u0026\u0026 表示逻辑与，只有在第一条命令执行成功时，才会执行第二条命令 COMMAND1 || COMMAND2: || 表示逻辑或，只有在第一条命令执行失败时，才会执行第二条命令 id $username || useradd $username 这里可以将 COMMAND1，COMMAND2 想象成一个逻辑判断表达式，\u0026\u0026 表示逻辑与，如果 COMMAND1 为False，整个表达式一定为 False，因此也就没有必要执行 COMMAND2，从样如果COMMAND1 为真，在逻辑或下，整个表达式肯定为真，也没有必要执行第二个表达式。这就是逻辑运算中短路逻辑。 ","date":"2018-01-04","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/:9:0","tags":["马哥 Linux"],"title":"4.2 bash常见特性","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/bash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7/"},{"categories":["Python"],"content":"Python 文本和字节序列","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"1. 字符与字节 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:1:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"1.1 字符的理解 字符: “字符\"的最佳定义是 Unicode 字符 Unicode 标准把 字符的标识 和 具体的字节表述 进行了如下的明确区分 字符的标识 字符的标识，即码位，是 0~1 114 111 的数字（十进制） Unicode 标准中以 4~6 个十六进制数字表示，而且加前缀\"U+” 在 Unicode 6.3 中（这是 Python 3.4 使用的标准），约 10% 的有效码位有对应的字符 字符的字节表述 字符的具体表述取决于所用的编码 编码是在码位和字节序列之间转换时使用的算法 编码: 把码位转换成字节序列的过程 解码: 把字节序列转换成码位的过程 \u003e\u003e\u003e s = 'café' \u003e\u003e\u003e len(s) 4 # café' 字符串有 4 个 Unicode 字符 \u003e\u003e\u003e b = s.encode('utf8') # 使用 UTF-8 把 str 对象编码成 bytes 对象 \u003e\u003e\u003e b b'caf\\xc3\\xa9' # bytes 字面量以 b 开头 \u003e\u003e\u003e len(b) 5 # 字节序列 b 有 5 个字节 \u003e\u003e\u003e b.decode('utf8') # ➎ 'café' ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:1:1","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"1.2 Python 中的字符对象 类型 Python2.7 Python3.4 unicdoe 字符的标识 无 str 字符的字节表示 各个元素是单个的字符 不可变类型 字符的标识 相当于Python2.7 中的unicode bytes str类型的别名 字符的字节表示 各个元素是介于 0~255（含）之间的整数 不可变类型 bytearray 字符的字节表示 各个元素是介于 0~255（含）之间的整数 可变类型 同Python2.7 附注: s[0] == s[:1] 只对 python3-str, python2-(str, unicode) 成立 对其他各个序列类型来说， s[i]返回一个元素，而 s[i:i+1] 返回一个相同类型的序列 # python2 str 与 python3 bytes 对比 # python27 \u003e\u003e\u003e a=\"中国\" \u003e\u003e\u003e a '\\xe4\\xb8\\xad\\xe5\\x9b\\xbd' \u003e\u003e\u003e type(a[1]) # 各个元素是单个的字符 str \u003e\u003e\u003e a[1] == a[1:2] # 切片和对应位置的元素相同 # python34 \u003e\u003e\u003e b=b\"中国\" \u003e\u003e\u003e b b'\\xe4\\xb8\\xad\\xe5\\x9b\\xbd' \u003e\u003e\u003e b[1] # 各个元素是介于 0~255（含）之间的整数 184 \u003e\u003e\u003e b[1] == b[1:2] False ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:1:2","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"2. 二进制序列类型 二进制序列: 包括: bytes 和 bytearray, memoryview \u003e\u003e\u003e cafe = bytes('café', encoding='utf_8') ➊ \u003e\u003e\u003e cafe b'caf\\xc3\\xa9' \u003e\u003e\u003e cafe[0] # 各个元素是 range(256) 内的整数 99 \u003e\u003e\u003e cafe[:1] # 切片还是 bytes 对象 b'c' \u003e\u003e\u003e cafe_arr = bytearray(cafe) \u003e\u003e\u003e cafe_arr # bytearray 对象没有字面量句法 bytearray(b'caf\\xc3\\xa9') \u003e\u003e\u003e cafe_arr[-1:] # bytearray 对象的切片还是 bytearray 对象 bytearray(b'\\xa9') ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:2:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"2.1 bytes 和 bytearray 字面量表示法 可打印的 ASCII 范围内的字节（从空格到 ~），使用 ASCII 字符本身 制表符、换行符、回车符和 \\ 对应的字节，使用转义序列 \\t、 \\n、 \\r 和 \\ 其他字节的值，使用十六进制转义序列（例如， \\x00 是空字节） 可用方法 类 str 方法 除以下str类型方法外，都支持bytes和bytearray 格式化方法 format和format_map 处理Unicode数据的方法(包括casefold、isdecimal、isidentifier、isnumeric、 isprintable和encode) 如果正则表达式编译自二进制列而不是字符串， re 模块中的正则表达式函数也能处理二进制序列 实例构建方法 bytes.fromhex():解析十六进制数字对(数字对之间的空格是可选的)，构建二进制序列 \u003e\u003e\u003e bytes.fromhex('31 4B CE A9') b'1K\\xce\\xa9' 向构造函数传入以下参数: 一个 str 对象和一个 encoding 关键字参数 一个可迭代对象，提供 0~255 之间的数值 一个整数，使用空字节创建对应长度的二进制序列 - python3.6将过时 一个实现了缓冲协议的对象（如 bytes、 bytearray、 memoryview、 array.array） 此时，把源对象中的字节序列 复制 到新建的二进制序列中 \u003e\u003e\u003e cafe = bytes('café', encoding='utf_8') \u003e\u003e\u003e import array \u003e\u003e\u003e numbers = array.array('h', [-2, -1, 0, 1, 2]) \u003e\u003e\u003e octets = bytes(numbers) # 指定类型代码 h，创建一个短整数（ 16 位）数组 \u003e\u003e\u003e octets b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00' # 表示那 5 个短整数的 10 个字节 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:2:1","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"2.2 内存视图 memoryview memoryview 作用: 允许在二进制数据结构之间共享内存, 通过其他二进制序列、打包的数组构建 memoryvideo对象时，不会复制字节序列 对 memoryview 对象的切片，也不会复制字节序列 介绍: http://stackoverflow.com/questions/4845418/when-should-a-memoryview-be-used/ https://docs.python.org/3/library/stdtypes.html#memory-views memoryview.cast 类似于类型转换，能用不同的方式读写同一块内存数据 # 通过改变数组中的一个字节来更新数组里某个元素的值 44 页 \u003e\u003e\u003e numbers = array.array('h', [-2, -1, 0, 1, 2]) \u003e\u003e\u003e memv = memoryview(numbers) ➊ \u003e\u003e\u003e len(memv) 5 \u003e\u003e\u003e memv[0] ➋ -2 \u003e\u003e\u003e memv_oct = memv.cast('B') ➌ \u003e\u003e\u003e memv_oct.tolist() ➍ [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] \u003e\u003e\u003e memv_oct[5] = 4 ➎ \u003e\u003e\u003e numbers array('h', [-2, -1, 1024, 1, 2]) struct 模块 作用: 从二进制序列中提取结构化信息 介绍: https://docs.python.org/3/library/struct.html 功能: 一些函数，把打包的字节序列转换成不同类型字段组成的元组 一些函数用于执行反向转换，把元组转换成打包的字节序列 能处理 bytes、bytearray 和 memoryview 对象 \u003e\u003e\u003e import struct # 结构体的格式: \u003c 是小字节序， 3s3s 是两个 3 字节序列， HH 是两个 16 位二进制整数 \u003e\u003e\u003e fmt = '\u003c3s3sHH' \u003e\u003e\u003e with open('filter.gif', 'rb') as fp: ... img = memoryview(fp.read()) # 创建一个 memoryview 对象 ... \u003e\u003e\u003e header = img[:10] # 使用它的切片再创建一个 memoryview 对象; 这里不会复制字节序列 \u003e\u003e\u003e bytes(header) # 转换成字节序列，这只是为了显示 b'GIF89a+\\x02\\xe6\\x00' \u003e\u003e\u003e struct.unpack(fmt, header) (b'GIF', b'89a', 555, 230) # 拆包 memoryview 对象，得到一个元组，包含类型、版本、宽度和高度 \u003e\u003e\u003e del header # ➏ \u003e\u003e\u003e del img ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:2:2","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"3. 编解码问题 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:3:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"3.1 编解码异常 异常类型: UnicodeEncodeError: 编码错误 UnicodeDecodeError: 解码异常 SyntaxError: 源码的编码与预期不符，加载 Python 模块触发的异常 SyntaxError: Python 3 默认使用 UTF-8 编码源码 Python 2（从 2.5 开始）则默认使用 ASCII 如果加载的 .py 模块中包含默认编码之外的数据，而且没有声明编码，会触发SyntaxError: 异常 SyntaxError: Non-UTF-8 code starting with '\\xe1' in file ola.py on line 1, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details 编码声明 - # coding: cp1252 errors参数: 说明: 编码方法或函数中的参数，用于指明对错误进行处理的方式 error=‘struct’: 默认值，出现错误则触发异常 error=‘ignore’: 跳过无法编码的字符，通常很是不妥 error=‘replace’，把无法编码的字符替换成 ‘?’ error=‘xmlcharrefreplace’: 把无法编码的字符替换成 XML 实体 错误处理方式是可扩展的，为 errors 参数注册额外的字符串: 方法是把一个名称和一个错误处理函数传给 codecs.register_error 函数 参考 https://docs.python.org/3/library/codecs.html#codecs.register_error ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:3:1","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"3.2 编码识别 Chardet: 作用: 编码侦测包, 能识别所支持的 30 种编码 文档: https://pypi.python.org/pypi/chardet 介绍: Chardet 是一个 Python 库, 也提供了命令行工具 chardetect $ chardetect 04-text-byte.asciidoc 04-text-byte.asciidoc: utf-8 with confidence 0.99 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:3:2","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"3.3 BOM - 鬼符 \u003e\u003e\u003e u16 = 'El Niño'.encode('utf_16') \u003e\u003e\u003e u16 b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00' b’\\xff\\xfe’: 这是 BOM，即字节序标记（ byte-order mark） 指明编码时使用Intel CPU 的小字节序 小字节序设备中，各个码位的最低有效字节在前面 UTF-16: 为了避免混淆， UTF-16 编码在要编码的文本前面加上特殊的不可见字符 ZERO WIDTH NOBREAK SPACE(U+FEFF)在小字节序系统中，这个字符编码为 b’\\xff\\xfe’(十进制数255, 254) UTF-16LE，显式指明使用小字节序 UTF-16BE，显式指明使用大字节序 如果使用这两个变种，不会生成 BOM 根据标准，如果文件使用 UTF-16 编码，而且没有 BOM， 那么应该假定使用的是 UTF-16BE（大字节序）编码 附注: 与字节序有关的问题只对一个字占多个字节的编码(如 UTF-16 和 UTF-32)有影响 UTF-8 的一大优势是，不管设备使用哪种字节序，生成的字节序列始终一致，因此不需要 BOM 但是某些应用依旧会在 UTF-8 编码的文件中添加 BOM Excel 会根据有没有 BOM 确定文件是不是 UTF-8 编码，否则， 假设内容使用 Windows 代码页(codepage)编码 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:3:3","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"4. 文本处理 要尽早把输入（例如读取文件时）的字节序列解码成字符串 程序的业务逻辑，只处理字符串对象 对输出来说，则要尽量晚地把字符串编码成字节序列 打开文件时始终应该明确传入 encoding= 参数 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:4:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"5. 文本规范化和排序 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"5.1 文本规范化 内容太多，详见数 99-105 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:1","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"5.2 Unicode文本排序 PyUCA: 作用: Unicode 排序算法(UCA)的纯 Python 实现 文档: https://pypi.python.org/pypi/pyuca/ 附注: PyUCA 没有考虑区域设置 定制排序方式，可以把自定义的排序表路径传给Collator()构造方法 默认使用项目自带的allkeys.txt 即Unicode 6.3.0 的副本 http://www.unicode.org/Public/UCA/6.3.0/allkeys.txt \u003e\u003e\u003e import pyuca \u003e\u003e\u003e coll = pyuca.Collator() \u003e\u003e\u003e fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola'] \u003e\u003e\u003e sorted_fruits = sorted(fruits, key=coll.sort_key) \u003e\u003e\u003e sorted_fruits ['açaí', 'acerola', 'atemoia', 'cajá', 'caju'] ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:2","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"5.3 Unicode数据库 数据库内容: 码位与字符名称之间的映射 各个字符的元数据 字符之间的关系 eg: 字符是否可以打印、是不是字母、是不是数字，或者是不是其他数值符号 字符串的 isidentifier、 isprintable、 isdecimal 等方法就是靠这些信息作判断 unicodedata 作用: 获取字符的元数据 文档: https://docs.python.org/3/library/unicodedata.html import unicodedata import re re_digit = re.compile(r'\\d') sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285' for char in sample: print('U+%04x' % ord(char), char.center(6), 're_dig' if re_digit.match(char) else '-', 'isdig' if char.isdigit() else '-', 'isnum' if char.isnumeric() else '-', format(unicodedata.numeric(char), '5.2f'), unicodedata.name(char), sep='\\t') ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:3","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"5.4 双模式 API 能接受字符串或字节序列为参数，然后根据类型进行特殊处理的函数 re 双模式: 如果使用字节序列构建正则表达式， \\d 和 \\w 等模式只能匹配 ASCII 字符 如果是字符串模式，就能匹配 ASCII 之外的 Unicode 数字或字母 字节序列只能用字节序列正则表达式搜索 字符串正则表达式有个 re.ASCII 标志，它让 \\w、 \\W、 \\b、 \\B、 \\d、 \\D、 \\s 和 \\S 只匹配ASCII 字符 附注: re 模块对 Unicode 的支持并不充分 PyPI 中新开发的regex 模块，用以取代 re 模块，以提供更好的 Unicode 支持 import re re_numbers_str = re.compile(r'\\d+') # 前两个正则表达式是字符串类型 re_words_str = re.compile(r'\\w+') re_numbers_bytes = re.compile(rb'\\d+') # 后两个正则表达式是字节序列类型 re_words_bytes = re.compile(rb'\\w+') text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\" ➌ \" as 1729 = 1³ + 12³ = 9³ + 10³.\") ➍ text_bytes = text_str.encode('utf_8') # 字节序列只能用字节序列正则表达式搜索。 print('Text', repr(text_str), sep='\\n ') print('Numbers') print(' str :', re_numbers_str.findall(text_str)) ➏ print(' bytes:', re_numbers_bytes.findall(text_bytes)) ➐ print('Words') print(' str :', re_words_str.findall(text_str)) ➑ print(' bytes:', re_words_bytes.findall(text_bytes)) ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:4","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"os函数中的字符串和字节序列？？ 背景: GNU/Linux 内核不理解 Unicode，对任何合理的编码方案来说，在文 件名中使用字节序列都是无效的，无法解码成字符串 为解决这个问题，os模块中的所有函数、文件名或路径名参数既能使用字符 串，也能使用字节序列 如果函数使用字符串参数调用，该参数会使用 sys.getfilesystemencoding() 得到的编解码器自动编码，然后操作系统会使用相同的编解码器解码 如果必须处理（也可能是修正）那些无法使用上述方式自动处理的文件名，可以把 字节序列参数传给 os 模块中的函数，得到字节序列返回值 \u003e\u003e\u003e os.listdir('.') # ➊ ['abc.txt', 'digits-of-π.txt'] \u003e\u003e\u003e os.listdir(b'.') # 参数是字节序列， listdir 函数返回的文件名也是字节序列 [b'abc.txt', b'digits-of-\\xcf\\x80.txt'] 可用函数 fsencode(filename): 如果 filename 是 str 类型（此外还可能是 bytes 类型），使用 sys.getfilesystemencoding()返回的编解码器把 filename 编码成字节序列; 否则，返回未经修改的 filename 字节序列 fsdecode(filename): 如果 filename 是 bytes 类型（此外还可能是 str 类型），使用 sys.getfilesystemencoding() 返回的编解码器把 filename 解码成字符串; 否则，返回未经修改的 filename字符串 在 Unix 衍生平台中，上述函数使用 surrogateescape 错误处理方式 作用: 是处理意外字节序列或未知编码的一种方式, 可以避免遇到意外字节序列时卡住 文档: https://www.python.org/dev/peps/pep-0383/ 实现: 把每个无法解码的字节替换成 Unicode 中 U+DC00 到 U+DCFF 之间的码位 这些码位是保留的，没有分配字符，供应用程序内部使用 编码时，这些码位会还原成被替换的字节值 \u003e\u003e\u003e os.listdir('.') ['abc.txt', 'digits-of-π.txt'] \u003e\u003e\u003e os.listdir(b'.') # 假设我们不知道编码，获取文件名的字节序列形式。 [b'abc.txt', b'digits-of-\\xcf\\x80.txt'] \u003e\u003e\u003e pi_name_bytes = os.listdir(b'.')[1] # 使用 'ascii' 编解码器和 'surrogateescape' 错误处理方式把它解码成字符串 \u003e\u003e\u003e pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape') \u003e\u003e\u003e pi_name_str # 非 ASCII 字节替换成代替码位: '\\xcf\\x80' 变成了 '\\udccf\\udc80' 'digits-of-\\udccf\\udc80.txt' \u003e\u003e\u003e pi_name_str.encode('ascii', 'surrogateescape') ➏ b'digits-of-\\xcf\\x80.txt' # 编码成 ASCII 字节序列: 各个代替码位还原成被替换的字节 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:5:5","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"延伸阅读 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:6:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"Python: 标准库 mmap: 作用: 将文件打开为内存映射文件 url: https://docs.python.org/3/library/mmap.html unicode: https://docs.python.org/3/howto/unicode.html codecs: https://docs.python.org/3/library/codecs.html#standard-encodings https://hg.python.org/cpython/file/6dcc96fa3970/Tools/unicode/listcodecs.py Python3.5新特性 二进制序列引入新的构造方法和方法 https://www.python.org/dev/peps/pep-0467/ Adding % formatting to bytes https://www.python.org/dev/peps/pep-0461/ ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:6:1","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"blog: unicode 文本规范 http://nedbatchelder.com/text/unipain.html http://www.slideshare.net/fischertrav/character-encoding-unicode-how-towith-dignity-33352863 http://pyvideo.org/pycon-us-2014/character-encoding-and-unicodein-python.html https://regebro.wordpress.com/2011/03/23/unconfusing-unicode-what-is-unicode/ python 版本差异: https://docs.python.org/3.0/whatsnew/3.0.html#text-vs-data-instead-ofunicode-vs-8-bit http://lucumr.pocoo.org/2013/7/2/theupdated-guide-to-unicode/ 文本与二进制序列 http://python-notes.curiousefficiency.org/en/latest/python3/binary_protocols.html http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html sys.getdefaultencoding() http://blog.startifact.com/posts/older/changing-the-python-default-encoding-considered-harmful.html http://blog.ziade.org/2008/01/08/syssetdefaultencoding-isevil/ ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:6:2","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"实用工具 AsciiDoc: http://www.methods.co.nz/asciidoc/ ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:6:3","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"书籍: Dive into Python: http://www.diveintopython3.net http://www.diveintopython3.net/strings.html http://getpython3.com/diveintopython3/case-study-porting-chardet-to-python-3.html Programming with Unicode: http://unicodebook.readthedocs.org/index.html unicdoe规范化: https://www.w3.org/International/wiki/Case_folding https://www.w3.org/TR/charmod-norm/ http://unicode.org/reports/tr15/ http://www.unicode.org/faq/normalization.htm http://www.macchiato.com/unicode/nfc-faq ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:6:4","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Python"],"content":"杂谈 在RAM 中如何表示字符串 详细介绍: https://www.python.org/dev/peps/pep-0393/ 在 Python 3.3 之前，编译 CPython 时可以配置在内存中使用 16 位或 32 位存储各个码位 从 Python 3.3 起，创建 str 对象时，解释器会检查里面的字符， 然后为该字符串选择最经济的内存布局 灵活的字符串表述类似于 Python 3 对 int 类型的处理方式: 如果一个整数在一个机器 字中放得下，那就存储在一个机器字中; 否则解释器切换成变长表述，类似于 Python 2中的 long 类型 ","date":"2018-01-04","objectID":"/posts/program/python/grammar/fluent-python/04_string/:7:0","tags":["python 进阶"],"title":"文本和字节序列","uri":"/posts/program/python/grammar/fluent-python/04_string/"},{"categories":["Linux"],"content":"4.1 Linux目录结构","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"Linux 目录结构 接下来，我们将学习 Linux 下的目录结构和Linux Bash 的基础特性。通过三节内容，我们将学习以下内容: Linux 文件系统及文件的组织结构 Linux 常见的文件类型 Bash 常见特性和快捷键使用 常用基础命令与命令历史 基础的文件管理命令与系统变量 文件系统同样是很复杂的东西，具体原理后面会介绍。当前，只要知道文件系统是操作系统对磁盘的抽象，为用户提供了管理磁盘文件的接口。开机启动时，内核加载完毕之后，内核就会挂载用户在开机启动配置文件中设置的根文件系统。Linux 上的文件系统必需挂载到根文件系统上才能被使用。开机启动流程，文件系统会在之后详细介绍。当前我们需要重点了解的是，Linux 上目录和文件的组织结构。 如同在 Windows 上创建目录和文件上一样，我们可以在Linux 上随意的创建和删除文件。但是就像我们很难在别人的Windows 系统上查找文件一样，如果各Linux 发行厂商随意的组织 Linux 的文件，当我们更换一个 Linux 发行版时，我们可能就很难找到配置文件，应用程序；程序开发者也很难统一配置程序的安装目录。所以 Linux 标准委员会为避免这种情况发生，指定了一个标准，叫 FHS(filesystem hierarchy standard)。 FHS 主要对 /, /usr, /var 的使用进行了规范，我们将按照这三个层次进行介绍。在本文的结尾，我们将对Linxu 上的文件系统类型作详细介绍。 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:0:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"1. FHS 简介 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:1:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"1.1 官方文档简介 This standard enables: Software to predict the location of installed files and directories, and Users to predict the location of installed files and directories. We do this by: Specifying guiding principles for each area of the filesystem, Specifying the minimum files and directories required, Enumerating exceptions to the principles, and Enumerating specific cases where there has been historical conflict. The FHS document is used by: Independent software suppliers to create applications which are FHS compliant, and work with distributions which are FHS complaint, OS creators to provide systems which are FHS compliant, and Users to understand and maintain the FHS compliance of a system. The FHS document has a limited scope: Local placement of local files is a local issue, so FHS does not attempt to usurp system administrators. FHS addresses issues where file placements need to be coordinated between multiple parties such as local sites, distributions, applications, documentation, etc. ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:1:1","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"1.2 FHS 标准内容概述 /, /usr, /var 必需包含的目录，及目录作用如下: / bin/: 所有用户可用的基本命令程序文件 sbin/: 供系统管理使用的工具程序 boot/: 引导加载器必须用到的各静态文件，包括 kernal, initramfs(initrd), grub 等 dev/: 存储特殊文件或设备文件，设备包括如下两种类型 字符设备，又称线性设备 块设备，又称随机设备 etc/: 系统程序的配置文件，只能为静态 home/: 普通用户家目录的集中位置 root/: 管理员家目录 lib: 为系统启动或根文件系统上的应用程序(/bin, /sbin等)提供共享库，以及为内核提供内核模块 libc.so.*： 动态链接的 C库 ld*: 运行时链接器或加载器 modules/: 用于存储内核模块的目录 lib64: 同lib，64 位系统特有的存放 64 位共享库的目录 media/: 便携式设备挂载点 mnt/: 其他文件系统的临时挂载点 opt/: 附加应用程序的安装位置，可选路径 srv/: 当前主机为服务提供的数据 tmp: 为哪些会产生临时文件的程序提供的用于存储临时文件的目录 usr/: shareable, read-only data，独立的层级目录，存放全局共享的只读数据路径 bin/: sbin/: 非管理或维护系统运行所必须的，额外添加的管理命令 lib: lib64: includ/: C 程序头文件 share/: 命令手册页和自带文档等框架特有的文件的存储位置 X11R6: X-Window 程序的安装位置 src: 程序源码文件的存储位置 local/: Local hierarchy 独立的层级目录，让系统管理员安装本地应用程序，也通常用于安装第三方程序 应用程序多版本共存时，新版程序通常安装于此目录 层级结构与 /usr 类似 var/: var Hierarchy, 独立的层级目录，用于存储常发生变化的数据的目录 cache/: Application cache data lib/: Variable state information local/: Variable data for /usr/local lock/: Lock files log: Log files and directories opt/: Variable data for /opt run/: Data relevant to running processes spool/: Application spool data tmp/: Temporary files preserved between system reboots proc/: 基于内存的虚拟文件系统，用于为内核及进程存储其相关信息； 它们多为内核参数，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径； 其主要作用在于为管理Linux设备提供一种统一模型的的接口； 参考: https://www.ibm.com/developerworks/cn/linux/l-cn-sysfs/ ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:1:2","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"2. / 根目录 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:2:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"3. /usr 目录 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:3:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"4. /var 目录 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:4:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"5. Linux 系统上的文件类型 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:5:0","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"5.1 常见文件类型： \u003e ll drwxrwxr-x. 2 tao tao 158 2月 25 18:32 anki drwxrwxr-x. 3 tao tao 43 2月 24 18:36 coding drwxrwxr-x. 4 tao tao 53 1月 30 14:11 linux ls -l 命令显示结果第一列的首子母即表示文件类型，Linux 中的文件类型如下 -：常规文件；即f； d: directory，目录文件(路径映射) b: block device，块设备文件，支持以“block”为单位进行随机访问 c：character device，字符设备文件，支持以“character”为单位进行线性访问 l：symbolic link，符号链接文件 p: pipe，命名管道 s: socket，套接字文件 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:5:1","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Linux"],"content":"5.2 设备文件的设备号 \u003e ll /dev # 10, 58 表示设备的设备号 crw-------. 1 root root 10, 58 6月 19 21:35 network_latency crw-------. 1 root root 10, 57 6月 19 21:35 network_throughput 设备文件还有设备号，其作用如下: major number：主设备号，用于标识设备类型，进而确定要加载的驱动程序; 8位二进制：0-255 minor number：次设备号，用于标识同一类型中的不同的设备; 8位二进制：0-255 ","date":"2018-01-03","objectID":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/:5:2","tags":["马哥 Linux"],"title":"4.1 Linux目录结构","uri":"/posts/linux/linux_mt/04-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/linux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/"},{"categories":["Python"],"content":"Python 字典和集合","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"1. 内置散列类型概览 抽象基类: 作用: 作为形式化的文档，定义了构建一个映射类型所需要的最基本的接口 跟 isinstance 一起被用来判定某个数据是不是广义上的映射类型 \u003e\u003e\u003e my_dict = {} \u003e\u003e\u003e isinstance(my_dict, abc.Mapping) True 非抽象映射类型: 一般不会直接继承抽象基类，而是直接对 dict 或是 collections.User.Dict 进行扩展 标准库里的所有映射类型都是利用 dict 来实现的，因此它们有个共同的限制， 只有 可散列的数据类型 才能用作这些映射里的键 可散列的数据类型: 定义: 在这个对象的生命周期中，散列值不可变 支持 hash() 函数，并且通过 __hash__() 方法所得到的散列值是不变的 支持通过 __eq__() 方法来检测相等性 若 a == b 为真，则 hash(a) == hash(b) 也为真 分类: 原子不可变数据类型（ str、 bytes 和数值类型）都是可散列类型 frozenset 也是可散列的，只能容纳可散列类型 元组只有当所包含的所有元素都是可散列类型的情况下，才是可散列的 自定义类: 用户自定义的类型的对象默认都是可散列的，散列值是它们的 id() 函数返回值， 所以所有对象在比较的时候都是不相等的 如果一个对象实现了 __eq__ 方法，并且在方法中用到了这个对象的内部状态的话， 那么只有当所有这些内部状态都是不可变的情况下，这个对象才是可散列的 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:1:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"2. 字典用法 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:2:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"2.1 常见的映射方法 表3-1: dict、 collections.defaultdict 和 collections.OrderedDict 方法 dict default Ordered 作用 d.clear() • • • 移除所有元素 d.__contains__(k) • • • 检查 k 是否在 d 中 d.copy() • • • 浅复制 d.__copy__() • 用于支持 copy.copy d.default_factory • 在 __missing__ 函数中被调用的函数，用以给未找到的元素设置值 * d.__delitem__(k) • • • del d[k]，移除键为 k 的元素 d.fromkeys(it, [initial]) • • • 将迭代器 it 里的元素设置为映射里的键，如果有 initial 参数，就把它作为这些键对应的值（默认是 None） d.get(k, [default]) • • • 返回键 k 对应的值，如果字典里没有键k，则返回 None 或者 default d.__getitem__(k) • • • 让字典 d 能用 d[k] 的形式返回键 k 对应的值 d.items() • • • 返回 d 里所有的键值对 d.__iter__() • • • 获取键的迭代器 d.keys() • • • 获取所有的键 d.__len__() • • • 可以用 len(d) 的形式得到字典里键值对的数量 d.__missing__(k) • 当 __getitem__ 找不到对应键的时候，这个方法会被调用 d.move_to_end(k, [last]) • 把键为 k 的元素移动到最靠前或者最靠后的位置（ last 的默认值是 True） d.pop(k, [defaul] • • • 返回键 k 所对应的值，然后移除这个键值对。如果没有这个键，返回 None 或者default d.popitem() • • • 随机返回一个键值对并从字典里移除它 # d.__reversed__() • 返回倒序的键的迭代器 d.setdefault(k, [default]) • • • 若字典里有键 k，则把它对应的值设置为default，然后返回这个值; 若无，则让d[k] = default，然后返回 default d.__setitem__(k, v) • • • 实现 d[k] = v 操作，把 k 对应的值设为 v d.update(m, [**kargs]) • • • m 可以是映射或者键值对迭代器，用来更新 d 里对应的条目 d.values() • • • 返回字典里的所有值 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:2:1","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"2.2 映射的弹性键查询 collections.defaultdict 实例化 defaultdict 时，需要提供一个可调用对象,这个可调用对象会在 __getitem__ 碰到找不到的键的时候被调用，让 __getitem__ 返回某种默认值 可调用对象存放在名为 default_factory 的实例属性里 eg: dd = defaultdict(list); dd[’new-key’]: 调用 list() 来建立一个新列表 把这个新列表作为值， ’new-key’ 作为它的键，放到 dd 中 返回这个列表的引用 附注: 创建 defaultdict 的时候没有指定 default_factory，查询不存在的键会触发KeyError default_factory 只在 __getitem__ 里被调用; eg: dd[’new-key’] 返回 [], dd.get(’new-key’) 返回None __missing__方法 作用: 如果存在，在 __getitem__ 碰到不存在键时会自动调用，而不是抛出KeyError 异常 特性: __missing__ 方法只会被 __getitem__ 调用 对 get 或者 __contains__的使用没有影响 # BEGIN STRKEYDICT0 class StrKeyDict0(dict): # \u003c1\u003e def __missing__(self, key): # 测试时必需的，防止递归调用 if isinstance(key, str): # \u003c2\u003e raise KeyError(key) return self[str(key)] # \u003c3\u003e def get(self, key, default=None): try: return self[key] # \u003c4\u003e except KeyError: return default # \u003c5\u003e def __contains__(self, key): # 使用self.keys() 是必需的，防止递归调用 return key in self.keys() or str(key) in self.keys() # \u003c6\u003e # END STRKEYDICT0 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:2:2","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"3. 字典的变种 collections.OrderedDict: 作用: 在添加键的时候会保持顺序，因此键的迭代次序总是一致的 popitem 方法默认删除并返回的是字典里的最后一个元素 popitem(last=False) 删除并返回第一个被添加进去的元素 collections.ChainMap: 作用: 可以容纳数个不同的映射对象，在进行键查找时，这些对象 会被当作一个整体被逐个查找，直到键被找到为止 应用: 给有嵌套作用域的语言做解释器的时候很有用， 可以用一个映射对象来代表一个作用域的上下文 文档: https://docs.python.org/3/library/collections.html#collections.ChainMap import builtins pylookup = ChainMap(locals(), globals(), vars(builtins)) collections.Counter: 作用: 给键准备一个整数计数器，每次更新一个键的时候都会增加这个计数器 应用: 给可散列表对象计数，或者是当成多重集 文档: https://docs.python.org/3/library/collections.html#collections.Counter 方法: 实现了 + 和 - 运算符用来合并记录 most_common(n): 按照次序返回映射里最常见的 n 个键和它们的计数 \u003e\u003e\u003e ct = collections.Counter('abracadabra') \u003e\u003e\u003e ct Counter({'a': 5, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) \u003e\u003e\u003e ct.update('aaaaazzz') \u003e\u003e\u003e ct Counter({'a': 10, 'z': 3, 'b': 2, 'r': 2, 'c': 1, 'd': 1}) \u003e\u003e\u003e ct.most_common(2) # 按照次序返回映射里最常见的 n 个键和它们的计数 [('a', 10), ('z', 3)] colllections.UserDict: 作用: 把标准 dict 用纯 Python 又实现了一遍，是让用户继承写子类的 collections.TransformDict: 文档: https://www.python.org/dev/peps/pep-0455/ ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:3:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"4. 子类化UserDict UserDict: 优势: 就创造自定义映射类型来说，以 UserDict 为基类，总比以普通的 dict 为基类更方便 原因: dict 有时会在某些方法的实现上走一些捷径，导致不得不在它的子类中重写这些方法， 但是 UserDict 就不会带来这些问题 特性: UserDict 继承的是 MutableMapping, 而不是 dict UserDict 有一个叫作data 的属性，是 dict 的实例， 这个属性实际上是 UserDict 存储数据的地方 import collections class StrKeyDict(collections.UserDict): # \u003c1\u003e def __missing__(self, key): # \u003c2\u003e if isinstance(key, str): raise KeyError(key) return self[str(key)] def __contains__(self, key): return str(key) in self.data # \u003c3\u003e def __setitem__(self, key, item): self.data[str(key)] = item # \u003c4\u003e ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:4:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"5. 不可变映射类型 type.MappingProxyType: 版本: python \u003e=3.3 作用: 给这个类一个映射，返回一个只读的映射视图 如果对原映射做出了改动，可以通过这个视图观察到 但是无法通过这个视图对原映射做出修改 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:5:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"6. 集合 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:6:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"6.1 集合概论 set: 像 {1, 2, 3} 的字面量， Python 会利用一个专门的叫作 BUILD_SET 的字节码来创建集合 因此 {1, 2, 3} 的字面量句法比构造方法(set([1, 2, 3])）更快且更易读 集合内元素可修改，不可散列 frozenset 没有特殊的字面量句法，只能采用构造方法 集合内元素不可修改，可散列 \u003e\u003e\u003e frozenset(range(10)) frozenset({0, 1, 2, 3, 4, 5, 6, 7, 8, 9}) 集合推导 \u003e\u003e\u003e from unicodedata import name ➊ \u003e\u003e\u003e {chr(i) for i in range(32, 256) if 'SIGN' in name(chr(i),'')} ➋ {'§', '=', '¢', '#', '¤', '\u003c', '¥', 'μ', '×', '$', '¶', '£', '©', '°', '+', '÷', '±', '\u003e', '¬', '®', '%'} ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:6:1","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"6.2 集合操作 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:6:2","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"7. dict和set的实现 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:7:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"7.1 散列表 散列表原理: 散列表其实是一个稀疏数组，散列表里的单元通常叫作表元 散列表用空间换时间，Python 会保证大概还有三分之一的表元是空的，快要达到这个阈值的时候， 原有的散列表会被复制到一个更大的空间里面 dict, set 的实现都依赖于散列表 字典的散列表当中，一个键值对占用一个表元，每个表元分为两个部分， 一个是对键的引用，另一个是对值的引用 集合的散列表里存放的只有元素的引用 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:7:1","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"7.2 散列表算法 https://docs.python.org/3/reference/datamodel.html#object.__hash__ 插入: 插入新值时， Python 可能会按照散列表的拥挤程度来决定是否要重新分配内存为它扩容 如果散列表的大小增加，散列值所占的位数和用作索引的位数也会随之增加，以减少散列冲突 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:7:2","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"7.2 dict 特性 依赖于散列表： 键查询很快 键必须是可散列的 键的次序取决于添加顺序 字典在内存上的开销巨大 如果需要存放数量巨大的记录，那么元组或是具名元组构成的列表中会是比较好的选择 自定义的类型中， __slots__ 属性可以改变实例属性的存储方式，由 dict 变成tuple 往字典里添加新键可能会改变已有键的顺序，如果在迭代一个字典的所有键的过程中 同时对字典进行修改，那么这个循环很有可能会跳过一些键——甚至是跳过那些字典中已经有的键 扫描并修改字典: 首先对字典迭代，以得出需要添加的内容，把这些内容放在一个新字典里 迭代结束之后再对原有字典进行更新 字典视图: Python 3 中， .keys()、 .items() 和 .values() 方法返回的都是字典视图 视图还有动态的特性，它们可以实时反馈字典的变化 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:7:3","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"7.3 set的特性 依赖于散列表： 集合里的元素必须是可散列的。 集合很消耗内存 可以很高效地判断元素是否存在于某个集合。 元素的次序取决于被添加到集合里的次序。 往集合里添加元素，可能会改变集合里已有元素的次序 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:7:4","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:8:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"Python 版本差异 dict.keys(): python3 中返回值是一个“视图”，视图就像一个集合，与字典类似在视图里查找一个元素的速度很快 https://docs.python.org/3/library/stdtypes.html#dictionaryview-objects Python2 中返回值时一个列表 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:8:1","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"常用模块 ChainMap:https://docs.python.org/3/library/collections.html#collections.ChainMap ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:9:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"延伸阅读 书籍:《代码之美》第 18 章 blog: http://pyvideo.org/video/276/the-mightydictionary-55 Dictionary view objects: https://docs.python.org/3/library/stdtypes.html#dictionaryview-objects CPython dictobject.c https://hg.python.org/cpython/file/tip/Objects/dictobject.c ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:10:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Python"],"content":"杂谈 ","date":"2018-01-03","objectID":"/posts/program/python/grammar/fluent-python/03_mapping/:11:0","tags":["python 进阶"],"title":"字典和集合","uri":"/posts/program/python/grammar/fluent-python/03_mapping/"},{"categories":["Linux"],"content":"3.2 Linux 命令帮助","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"Linux 中获取命令帮助 通过之前的学习我们了解到 Linux 命令分为两类，一类是 shell 内置的内嵌命令，另一类是外部命令。这两种命令获取帮助的并不相同，对于内部命令使用 help command 即可。而对于外部命令有很多方式，其中最重要也是最便捷的就是使用 man 帮助手册。本节我们将学习如何获取外部命令的使用帮助，以及了解 man 手册的使用方式。 ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:0:0","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"1. 获取命令的使用帮助 内部命令：help COMMAND 外部命令： COMMAND --help: 命令自带简要格式的使用帮助 man COMMAND: 使用手册：manual info COMMAND: 获取命令的在线文档； 很多应用程序会自带帮助文档：/usr/share/doc/APP-VERSION，包括不限于 README：程序的相关的信息； INSTALL: 安装帮助； CHANGES：版本迭代时的改动信息； 主流发行版官方文档: eg：http://www.redhat.com/doc 程序官方的文档：官方站点上的\"Document\" 搜索引擎 # google 搜索引擎的使用技巧 keyword filetype:pdf keyword site:domain.tld ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:1:0","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"2. man 帮助手册的使用简述 ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:2:0","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"2.1 man 手册页组成 关于man的简介如下列表所示: man手册的原始文档位于 /usr/share/man中， 使用手册为压缩格式的文件，有章节之分,包括 ls /usr/share/man man1：用户命令； man2：系统调用； man3：C库调用； man4：设备文件及特殊文件； man5：文件格式；（配置文件格式） man6：游戏使用帮助； man7：杂项； man8：管理工具及守护进行； 当我们 man COMMAND 进入man手册后，其由如下几个部分组成。界面示例如下 SECTION：组成部分 NAME：功能性说明 SYNOPSIS：语法格式 DESCRIPTION：描述 OPTIONS：选项 EXAMPLES：使用示例 AUTHOR: 作者 BUGS: 报告程序bug的方式 SEE ALSO: 参考 SYNOPSIS: 命令使用 []：可选内容； \u003c\u003e：必须提供的内容； a|b|c：多选一； ...：同类内容可出现多个； \u003e man ifconfig IFCONFIG(8) Linux System Administrator's Manual IFCONFIG(8) NAME ifconfig - configure a network interface SYNOPSIS ifconfig [-v] [-a] [-s] [interface] ifconfig [-v] interface [aftype] options | address ... NOTE This program is obsolete! For replacement check ip addr and ip link. For statistics use ip -s link. DESCRIPTION Ifconfig is used to configure the kernel-resident network interfaces. It is used at boot time to set up interfaces as necessary. After that, it is usually only needed when debugging or when system tuning is needed. ............. ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:2:1","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"1.2 man 命令使用 man [CHAPTER] COMMAND 作用: 在特定章节中搜索命令的帮助手册, CHAPTER 参数可选 注意： 并非每个COMMAND在所有章节下都有手册； 可通过 whatis COMMAND 查看哪些章节中存在COMMAND 的帮助手册 whatis的执行过程是查询数据库进行的，必要时可通过 makewhatis 手动更新数据库 ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:2:2","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Linux"],"content":"1.2 man 手册查看操作 进入man手册页之后，其界面环境就是调用 less 命令的执行结果，可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit) ","date":"2018-01-02","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/:2:3","tags":["马哥 Linux"],"title":"3.2 Linux 命令帮助","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/"},{"categories":["Python"],"content":"Python 序列，迭代器与生成器","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"1. 内置序列类型概览 容器序列: 能存放不同类型的数据 序列内存放的是它们所包含的任意类型的对象的引用 包括 list tuple collections.deque 这些序列 扁平序列: 只能容纳一种类型 序列里存放的是值而不是引用 扁平序列是一段连续的内存空间，更加紧凑 但只能存放诸如字符、字节和数值这种基础类型 包括 str、 bytes、 bytearray memoryview array.array 可变序列 包括 list、 bytearray、 array.array、 collections.deque memoryview 不可变序列 包括 tuple、 str 和 bytes ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:1:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"2. 内置序列类型 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:2:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"2.1 列表 列表推导 list comprehension 简称为 listcomps 适用: 只用列表推导来创建新的列表，并且尽量保持简短 特点: Python3 列表推导有局部作用域，不会有变量泄漏的问题 Python2 在列表推导中 for 关键词之后的赋值操作可能会影响列表推导上下文中的同名变量 Python 2.7.6 (default, Mar 22 2014, 22: 59: 38) [GCC 4.8.2] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e x = 'my precious' \u003e\u003e\u003e dummy = [x for x in 'ABC'] \u003e\u003e\u003e x 'C' 生成器表达式 generator expression 简称为 genexps 语法: 与列表推导类似，把方括号换成圆括号 特点: 遵守了迭代器协议，可以逐个地产出元素 \u003e\u003e\u003e symbols = '$¢£¥€¤' \u003e\u003e\u003e tuple(ord(symbol) for symbol in symbols) ➊ (36, 162, 163, 165, 8364, 164) \u003e\u003e\u003e import array \u003e\u003e\u003e array.array('I', (ord(symbol) for symbol in symbols)) ➋ array('I', [36, 162, 163, 165, 8364, 164]) ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:2:1","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"2.2 元组 元组拆包 适用: 可以应用到任何可迭代对象上 要求: 被可迭代对象中的元素数量必须要跟接受这些元素的空档数一致 语法: Python3 * 表示忽略多余元素 平行赋值中， * 前缀只能用在一个变量名前面，但是这个变量可以出现在赋值表达式的任意位置 可以是嵌套的，只要接受元组的嵌套结构符合表达式本身的嵌套结构 \u003e\u003e\u003e lax_coordinates = (33.9425, -118.408056) \u003e\u003e\u003e latitude, longitude = lax_coordinates # 元组拆包 \u003e\u003e\u003e t = (20, 8) \u003e\u003e\u003e divmod(*t) \u003e\u003e\u003e import os \u003e\u003e\u003e _, filename = os.path.split('/home/luciano/.ssh/idrsa.pub') \u003e\u003e\u003e a, b, *rest = range(5) \u003e\u003e\u003e a, b, rest (0, 1, [2, 3, 4]) \u003e\u003e\u003e a, *body, c, d = range(5) \u003e\u003e\u003e a, body, c, d (0, [1, 2], 3, 4) \u003e\u003e\u003e metro_areas = ('Tokyo','JP',36.933,(35.689722,139.691667)) \u003e\u003e\u003e a, b, c, (d, e) = metro_areas 具名元组 collections.namedtuple 作用: 工厂函数，用来构建一个带字段名的元组和一个有名字的类 特点: 实例所消耗的内存跟元组是一样的,因为字段名都被存在对应的类里面 实例跟普通的对象实例比起来也要小一些，因为Python 不会用 __dict__ 来存放这些实例的属性 专有属性: 类属性 _fields: 包含这个类所有字段名称的元组 类方法 _make(iterable): 接受一个可迭代对象来生成这类的实例 实例方法 _asdict(): 把具名元组以 collections.OrderedDict 的形式返回 \u003e\u003e\u003e from collections import namedtuple \u003e\u003e\u003e City = namedtuple('City', 'name country population coordinates') ➊ \u003e\u003e\u003e tokyo = City('Tokyo', 'JP', 36.933, (35.689722, 139.691667)) ➋ \u003e\u003e\u003e tokyo City(name='Tokyo', country='JP', population=36.933, coordinates=(35.689722, 139.691667)) \u003e\u003e\u003e tokyo.population ➌ 36.933 \u003e\u003e\u003e City._fields ➊ ('name', 'country', 'population', 'coordinates') \u003e\u003e\u003e delhi_data = ('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)) \u003e\u003e\u003e delhi = City._make(delhi_data) ➋ \u003e\u003e\u003e delhi._asdict() ➌ OrderedDict([('name', 'Delhi NCR'), ('country', 'IN'), ('population', 21.935), ('coordinates', (lat=28.613889, long=77.208889))]) 列表与元组对比 |方法|列表|元组|作用| |: —|: —|: —|: —| |s.__add__(s2) |•| • |s + s2，拼接| |s.__iadd__(s2)|•| |s += s2，就地拼接| |s.append(e) |•| |在尾部添加一个新元素| |s.clear() |•| |删除所有元素| |s.__contains__(e)| •| •| s 是否包含 e| |s.copy() |•| |列表的浅复制| |s.count(e) |• |• |e 在 s 中出现的次数| |s.__delitem__(p) |•| |把位于 p 的元素删除| |s.extend(it) |•| |把可迭代对象 it 追加给 s| |s.__getitem__(p) |•| •| s[p]，获取位置 p 的元素| |s.__getnewargs__()| |•| 在 pickle 中支持更加优化的序列化| |s.index(e) |•| •| 在 s 中找到元素 e 第一次出现的位置| |s.insert(p, e) |•| |在位置 p 之前插入元素 e| |s.__iter__() |•| •| 获取 s 的迭代器| |s.__len__() |•| •| len(s)，元素的数量| |s.__mul__(n) |•| •| s * n， n 个 s 的重复拼接| |s.__imul__(n) |•| |s *= n，就地重复拼接| |s.__rmul__(n) |•| •| n * s，反向拼接 *| |s.pop([p]) |• | |删除最后或者是（可选的）位于 p 的元素，并返回它的值| |s.remove(e) |•| |删除 s 中的第一次出现的 e| |s.reverse() |•| |就地把 s 的元素倒序排列| |s.__reversed__() |•| |返回 s 的倒序迭代器| |s.__setitem__(p, e) |• | |s[p] = e，把元素 e放在位置 p，替代已经在那个位置的元素| |s.sort([key], [reverse]) |•| |就地对 s 中的元素进行排序，可选的参数有键（ key）和是否倒序（ reverse）| ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:2:2","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3. 序列用法 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3.1 切片用法 实现概览 seq[a: b: c] a: b: c - 只能作为索引或者下标用在 [] 中来返回一个切片对象: slice(a, b, c) 求值的时候， Python会调用 seq.__getitem__(slice(start, stop, step)) 用法概览 可以给切片命名,比用硬编码的数字区间要方便得多 多维切片 - 以逗号分开的多个索引或者是切片 实现: 要得到 a[i, j] 的值， Python 会调用 a.__getitem__((i, j)) 附注: Python 内置的序列类型都是一维的，只支持单一的索引 省略 语法: 正确书写方法是三个英语句号（…） 实现: 省略在 Python 解析器眼里是一个符号，而实际上它是 Ellipsis 对 象的别名，而 Ellipsis 对象又是 ellipsis 类的单一实例; 可以当作切片规范的一部分， 也可以用在函数的参数清单中，比如 f(a, …, z)，或 a[i: …] 应用: numpy eg: 如果 x 是四维数组，那么 x[i, …] 就是 x[i, : , : , : ] 附注: 还未发现 Python 标准库里有任何 Ellipsis 或者是多维索引的用法 给切片赋值 用法: 把切片放在赋值语句的左边，或把它作为 del 操作的对象 语法: 如果赋值的对象是一个切片，那么赋值语句的右侧必须是个可迭代对象 \u003e\u003e\u003e l = list(range(10)) \u003e\u003e\u003e l [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] \u003e\u003e\u003e l[2: 5] = [20, 30] \u003e\u003e\u003e l [0, 1, 20, 30, 5, 6, 7, 8, 9] \u003e\u003e\u003e del l[5: 7] \u003e\u003e\u003e l [0, 1, 20, 30, 5, 8, 9] \u003e\u003e\u003e l[3: : 2] = [11, 22] \u003e\u003e\u003e l [0, 1, 20, 11, 5, 22, 9] \u003e\u003e\u003e l[2: 5] = 100 ➊ Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: can only assign an iterable \u003e\u003e\u003e l[2: 5] = [100] \u003e\u003e\u003e l [0, 1, 100, 22, 9] ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:1","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3.2 对序列使用+和* \u003e\u003e\u003e board = [['_'] * 3 for i in range(3)] \u003e\u003e\u003e board[1][2] = 'X' \u003e\u003e\u003e board [['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']] \u003e\u003e\u003e weird_board = [['_'] * 3] * 3 \u003e\u003e\u003e weird_board[1][2] = 'O' \u003e\u003e\u003e weird_board [['_', '_', 'O'], ['_', '_', 'O'], ['_', '_', 'O']] ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:2","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3.3 序列的增量赋值 增量的实现 seq+=a: 实现: 如果seq实现了 __iadd__(就地加法)， 调用此方法 未实现，表达式相当于 seq = seq + a，调用seq.__add__(a) 返回一个新对象 并赋值给seq 可变序列: 一般都实现了 __iadd__ 方法，因此 += 是就地加法 不可变序列: 不支持这个操作，使用__add__方法返回一个新对象 性能问题 对不可变序列进行重复拼接操作的话，效率会很低，因为每次都有一个新对象，而解释器 需要把原来对象中的元素先复制到新的对象里，然后再追加新的元素 str 是一个例外，因为对字符串做 += 实在是太普遍了，所以 CPython 对它做了优化; 为 str 初始化内存的时候，程序会为它留出额外的可扩展空间，因此进行增量操作的时候， 并不会涉及复制原有字符串到新位置这类操作 关于+=的谜题 \u003e\u003e\u003e t = (1, 2, [30, 40]) \u003e\u003e\u003e t[2] += [50, 60] Traceback (most recent call last): File \"\u003cstdin\u003e\", line 1, in \u003cmodule\u003e TypeError: 'tuple' object does not support item assignment \u003e\u003e\u003e t (1, 2, [30, 40, 50, 60]) \u003e\u003e\u003e dis.dis('s[a] += b') 1 0 LOAD_NAME 0(s) 3 LOAD_NAME 1(a) 6 DUP_TOP_TWO 7 BINARY_SUBSCR ➊ # 将 s[a] 的值存入 TOS（ Top Of Stack，栈的顶端） 8 LOAD_NAME 2(b) 11 INPLACE_ADD ➋ # 计算 TOS += b。这一步能够完成，是因为 TOS 指向的是一个可变对象 12 ROT_THREE 13 STORE_SUBSCR ➌ # s[a] = TOS 赋值。这一步失败，是因为 s 是不可变的元组 14 LOAD_CONST 0(None) 17 RETURN_VALUE 注意: 不要把可变对象放在元组里面 增量赋值不是一个原子操作 写成 t[2].extend([50, 60]) 就能避免这个异常 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:3","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3.4 list.sort方法和 sorted函数 list.sort 方法 就地排序列表，不会把原列表复制一份，返回 None 内置函数 sorted 新建一个列表作为返回值 可以接受任何形式的可迭代对象作为参数，甚至包括不可变序列或生成器 不管接受的是怎样的参数，最后都会返回一个列表 可选参数(二者都有) reverse - 默认为False，升序输出; True 降序输出 key - 只有一个参数的函数，用于产生排序比较的对比关键字，默认用元素自己的值来排序 附注: 排序算法是稳定的 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:4","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"3.5 用bisect来管理已排序的序列 bisect(a, x[, lo[, hi]]) a: 一个有序的序列 x: 待查找元素 lo: 默认值是 0，用于限定搜索的下线 hi: 默认值是序列的长度，用于限定搜索的上线 作用: 返回一个位置，该位置前面的 a 的值，都小于或等于 needle 的值 应用: 在很长的有序序列中作为 index 的替代，用来更快地查找一个元素的位置 bisect_right==bisect - 返回跟它相等的元素之后的位置 bisect_left - 返回跟它相等的元素之前的位置 \u003e\u003e\u003e def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'): ... i = bisect.bisect(breakpoints, score) ... return grades[i] ... \u003e\u003e\u003e [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]] ['F', 'A', 'C', 'C', 'B', 'A', 'A'] insort(seq, item[, lo[, hi]]): 作用: 有序插入，把变量 item 插入到序列 seq 中，并能保持 seq 的升序顺序 insort_right == insort - 在 insect_right 返回的位置插入 insort_left - 在bisect_left 返回的位置插入 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:3:5","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4. 列表的可替换类型 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4.1 数组 array.array: 只允许存放指定类型数字，通过构造函数中的类型码参数指定 直接存放的数字的字节，而不是对象的引用，效率更高，内存更小 支持所有跟可变序列有关的操作 表2-2: 列表和数组的属性和方法 |方法|列表|数组|作用| |: —|: —|: —|: —| |s.__add(s2)__ |•| •| s + s2 ，拼接| |s.__iadd(s2)__ |•| •| s += s2 ，就地拼接| |s.append(e) |• |• |在尾部添加一个元素| |s.byteswap ||• |翻转数组内每个元素的字节序列，转换字节序| |s.clear() |• | |删除所有元素| |s.__contains__(e) |• |• |s 是否含有 e| |s.copy() |• | |对列表浅复制| |s.__copy__() | |•| 对 copy.copy 的支持| |s.count(e) |• |• |s 中 e 出现的次数| |s.__deepcopy__() |•| |对 copy.deepcopy 的支持| |s.__delitem__(p) |•| •| 删除位置 p 的元素| |s.extend(it) |• |• |将可迭代对象 it 里的元素添加到尾部| |s.frombytes(b) | |• |将压缩成机器值的字节序列读出来添加到尾部| |s.fromfile(f, n) ||•| 将二进制文件 f 内含有机器值读出来添加到尾部，最多添加 n 项| |s.fromlist(l) | |•| 将列表里的元素添加到尾部，如果其中任何一个元素导致了TypeError 异常，那么所有的添加都会取消| |s.__getitem__(p) |• |• |s[p]，读取位置 p 的元素| |s.index(e) |• |• |找到 e 在序列中第一次出现的位置| |s.insert(p, e) |• |• |在位于 p 的元素之前插入元素 e| |s.itemsize | |• |数组中每个元素的长度是几个字节| |s.__iter__() |• |• |返回迭代器| |s.__len__() |• |• |len(s)，序列的长度| |s.__mul__(n) |• |•| s * n，重复拼接| |s.__imul__(n) |• |• |s *= n ，就地重复拼接| |s.__rmul__(n) |• |• |n * s ，反向重复拼接 *| |s.pop([p]) |• |• |删除位于 p 的值并返回这个值， p 的默认值是最后一个元素的位置| |s.remove(e) |• |• |删除序列里第一次出现的 e 元素| |s.reverse() |• |• |就地调转序列中元素的位置| |s.__reversed__() |• | |返回一个从尾部开始扫描元素的迭代器| |s.__setitem__(p, e) |•| •| s[p] = e，把位于 p 位置的元素替换成 e| |s.sort([key], [revers]) |•| | 就地排序序列，可选参数有 key 和 reverse| |s.tobytes() ||• | 把所有元素的机器值用 bytes 对象的形式返回| |s.tofile(f) | |• | 把所有元素以机器值的形式写入一个文件| |s.tolist() | |•| 把数组转换成列表，列表里的元素类型是数字对象| |s.typecode | |• | 返回只有一个字符的字符串，代表数组元素| 附注: python3.4 后数组不再支持 array.sort()方法 a = array.array(a.typecode, sorted(a)) \u003e\u003e\u003e from array import array ➊ \u003e\u003e\u003e from random import random \u003e\u003e\u003e floats = array('d', (random() for i in range(10**7))) ➋ \u003e\u003e\u003e floats[-1] ➌ 0.07802343889111107 \u003e\u003e\u003e fp = open('floats.bin', 'wb') \u003e\u003e\u003e floats.tofile(fp) \u003e\u003e\u003e fp.close() \u003e\u003e\u003e floats2 = array('d') ➎ \u003e\u003e\u003e fp = open('floats.bin', 'rb') \u003e\u003e\u003e floats2.fromfile(fp, 10**7) ➏ \u003e\u003e\u003e fp.close() \u003e\u003e\u003e floats2[-1] ➐ 0.07802343889111107 \u003e\u003e\u003e floats2 == floats ➑ True ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:1","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4.2 内存视图 memoryview: 作用：允许在二进制数据结构之间共享内存, 通过其他二进制序列、打包的数组构建 memoryvideo对象时，不会复制字节序列 对 memoryview 对象的切片，也不会复制字节序列 介绍: http://stackoverflow.com/questions/4845418/when-should-a-memoryview-be-used/ https://docs.python.org/3/library/stdtypes.html#memory-views memoryview.cast 类似于类型转换，能用不同的方式读写同一块内存数据 # 通过改变数组中的一个字节来更新数组里某个元素的值 44 页 \u003e\u003e\u003e numbers = array.array('h', [-2, -1, 0, 1, 2]) \u003e\u003e\u003e memv = memoryview(numbers) ➊ \u003e\u003e\u003e len(memv) 5 \u003e\u003e\u003e memv[0] ➋ -2 \u003e\u003e\u003e memv_oct = memv.cast('B') ➌ \u003e\u003e\u003e memv_oct.tolist() ➍ [254, 255, 255, 255, 0, 0, 1, 0, 2, 0] \u003e\u003e\u003e memv_oct[5] = 4 ➎ \u003e\u003e\u003e numbers array('h', [-2, -1, 1024, 1, 2]) ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:2","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4.3 Numpy 和 Scipy Numpy: 实现了多维同质数组(homogeneous array)和矩阵 这些数据结构不但能处理数字，还能存放其他由用户定义的记录 \u003e\u003e\u003e import numpy \u003e\u003e\u003e floats = numpy.loadtxt('floats-10M-lines.txt') ➊ \u003e\u003e\u003e floats[-3: ] ➋ array([ 3016362.69195522, 535281.10514262, 4566560.44373946]) \u003e\u003e\u003e floats *= .5 ➌ \u003e\u003e\u003e floats[-3: ] array([ 1508181.34597761, 267640.55257131, 2283280.22186973]) \u003e\u003e\u003e from time import perf_counter as pc ➍ # 导入精度和性能都比较高的计时器 \u003e=3.3 \u003e\u003e\u003e t0 = pc(); floats /= 3; pc() - t0 ➎ 0.03690556302899495 \u003e\u003e\u003e numpy.save('floats-10M', floats) ➏ # 把数组存入后缀为 .npy 的二进制文件 # load 方法利用了一种叫作内存映射的机制，在内存不足的情况下仍然可以对数组做切片 \u003e\u003e\u003e floats2 = numpy.load('floats-10M.npy', 'r+') ➐ \u003e\u003e\u003e floats2 *= 6 \u003e\u003e\u003e floats2[-3: ] ➑ memmap([3016362.69195522, 535281.10514262, 4566560.44373946]) Scipy: 提供了很多跟科学计算有关的算法，专为线性代数、数值积分和统计学而设计 Netlib: \u003chttp: //www.netlib.org\u003e SciPy 把基于C 和 Fortran 的工业级数学计算功能用交互式且高度抽象的 Python 包装起来 扩展包: pandas: \u003chttp: //pandas.pydata.org\u003e Blaze: \u003chttp: //blaze.pydata.org\u003e ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:3","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4.4 队列 collections.deque: 双向队列 优势: 线程安全，可以快速从两端添加或者删除元素 新建一个双向队列时，可指定队列的大小，队列满时在一端新增元素会自动删除另一端的顶端元素 append 和 popleft 都是原子操作 即 deque 可以在多线程程序中安全地当作先进先出的栈使用，无需担心资源锁的问题 劣势: 从队列中间删除元素的操作会慢一些，因为它只对在头尾的操作进行了优化 \u003e\u003e\u003e from collections import deque \u003e\u003e\u003e dq = deque(range(10), maxlen=10) ➊ # maxlen 一旦设定，不能修改 \u003e\u003e\u003e dq deque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10) \u003e\u003e\u003e dq.rotate(3) ➋ \u003e\u003e\u003e dq deque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10) \u003e\u003e\u003e dq.rotate(-4) \u003e\u003e\u003e dq deque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10) \u003e\u003e\u003e dq.appendleft(-1) ➌ \u003e\u003e\u003e dq deque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10) \u003e\u003e\u003e dq.extend([11, 22, 33]) ➍ \u003e\u003e\u003e dq deque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10) \u003e\u003e\u003e dq.extendleft([10, 20, 30, 40]) ➎ # 逐个添加到双向队列的左边 \u003e\u003e\u003e dq deque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10) 表2-3: 列表和双向队列的方法 |方法|列表|双向队列|作用| |: —|: —|: —|: —| |s.__add__(s2) |•| |s + s2，拼接| |s.__iadd__(s2) |• |•| s += s2，就地拼接| |s.append(e) |•| • |添加一个元素到最右侧（到最后一个元素之后）| |s.appendleft(e) | |• |添加一个元素到最左侧（到第一个元素之前）| |s.clear() |•| •| 删除所有元素| |s.__contains__(e) |•| |s 是否含有 e| |s.copy() |•| |对列表浅复制| |s.__copy__() | |•|对 copy.copy（浅复制）的支持| |s.count(e) |•| •| s 中 e 出现的次数| |s.__delitem__(p) |• |• |把位置 p 的元素移除| |s.extend(i) |• |• |将可迭代对象 i 中的元素添加到尾部| |s.extendleft(i) ||•|将可迭代对象 i 中的元素添加到头部| |s.__getitem__(p) |• |• |s[p]，读取位置 p 的元素| |s.index(e) |• | |找到 e 在序列中第一次出现的位置| |s.insert(p, e) |• | |在位于 p 的元素之前插入元素 e| |s.__iter__() |• |•| 返回迭代器| |s.__len__() |• |•| len(s)，序列的长度| |s.__mul__(n) |•| |s * n，重复拼接| |s.__imul__(n) |•| |s *= n，就地重复拼接| |s.__rmul__(n) |•| |n * s，反向重复拼接 *| |s.pop() |• |• |移除最后一个元素并返回它的值 #| |s.popleft() ||•| 移除第一个元素并返回它的值| |s.remove(e) |• |• |移除序列里第一次出现的 e 元素| |s.reverse() |• |• |调转序列中元素的位置| |s.__reversed__() |• |• |返回一个从尾部开始扫描元素的迭代器| |s.rotate(n) | |• | 把 n 个元素从队列的一端移到另一端| |s.__setitem__(p, e) |• |• |s[p] = e，把位于 p 位置的元素替换成 e| |s.sort([key], [revers]) |• | |就地排序序列，可选参数有 key 和 reverse| ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:4","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"4.5 其他队列 queue: 提供了同步（线程安全）类 Queue、 LifoQueue 和PriorityQueue， 不同的线程可以利用这些数据类型来交换信息 可选参数 maxsize用来限定队列的大小 队列满了，它就会被锁住，直到另外的线程移除了某个元素而腾出了位置 特性让这些类很适合用来控制活跃线程的数量 multiprocessing: 实现了自己的 Queue，与 queue.Queue 类似，用于进程间通信用 专门的 multiprocessing.JoinableQueue 类型，可以让任务管理更方便 asyncio: Python 3.4 新提供的包，里面有 Queue、 LifoQueue、 PriorityQueue 和 JoinableQueue 受 queue 和 multiprocessing 模块影响，但是为异步编程里的任务管理提供了专门的便利 heapq: heapq 没有队列类，而是提供了 heappush 和 heappop 方法 让用户可以把可变序列当作堆队列或者优先队列来使用 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:4:5","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"附注 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:5:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"Python 版本差异 Python3 之前，元组可以作为形参放在函数声明中， 例如 def fn(a, (b,c), d)，Python 3 不再支持这种格式 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:5:1","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"常用模块 bisect: url: \u003chttps: //docs.python.org/3/library/bisect.html\u003e 介绍: 二分查找 sortedcollection: url: \u003c http: //code.activestate.com/recipes/577197-sortedcollection/\u003e 介绍: 排序集合模块。集成了 bisect 功能，比独立的 bisect 更易用 pickle: url: \u003chttps: //docs.python.org/3/library/pickle.html\u003e 介绍: 快速序列化数字类型 eg: pickle.dump 附注: 可以处理几乎所有的内置数字类型，包含复数、嵌套集合，甚至用户自定义的类 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:6:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"延伸阅读 Python: sorted 用法: \u003chttps: //docs.python.org/3/howto/sorting.html\u003e *extra 句法: \u003chttps: //www.python.org/dev/peps/pep-3132/\u003e 可迭代对象拆包: \u003chttp: //bugs.python.org/issue2292\u003e \u003chttps: //www.python.org/dev/peps/pep-0448/\u003e collections: \u003chttps: //docs.python.org/3/library/collections.html\u003e blog: memoryview: \u003chttp: //eli.thegreenplace.net/2011/11/28/less-copies-in-python-with-the-buffer-protocol-and-memoryviews/\u003e 实用工具 Python Tutor: url: \u003chttp: //www.pythontutor.com\u003e 介绍: 对 Python 运行原理进行可视化分析的工具 IPython: url: \u003chttp: //ipython.org/notebook.html\u003e 书籍: 《 Python Cookbook（第 3 版）中文版》重点放在了 Python 的语义上 《 Python Cookbook（第 2 版）中文版》把重点放在如何解决实际问题上 ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:7:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Python"],"content":"杂谈 扁平序列和容器序列 容器序列可以嵌套着使用，因为容器里的引用可以针对包括自身类型在内的任何类型 扁平序列因为只能包含原子数据类型，比如整数、浮点数或字符，所以不 能嵌套使用 混合类型列表 我们之所以用列表来存放东西，是期待在稍后使用它的时候，其中的元素有一些通用的特性 元组则恰恰相反，它经常用来存放不同类型的的元素,也符合它的本质，元组就是用作存放彼此之间没有关系的数据的记录 Timesort sorted 和 list.sort 背后的排序算法是 Timsort 它是一种自适应算法，会根据原始数据的顺序特点交替使用插入排序和归并排序，以达到最佳效率 \u003chttps: //en.wikipedia.org/wiki/Timsort\u003e ","date":"2018-01-02","objectID":"/posts/program/python/grammar/fluent-python/02_sequence/:8:0","tags":["python 进阶"],"title":"序列","uri":"/posts/program/python/grammar/fluent-python/02_sequence/"},{"categories":["Linux"],"content":"3.1 Linux 命令基础","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"Linux 基础命令 在安装完 Centos 之后，我们开始正式学习 Linux。在深入学习 Linux 之前，我们需要学习一些最基本命令的使用。我们将分成两节来学习下面内容: Linux 中的命令类型 Linux 命令的标准使用格式 Linux 常见基础命令的使用 如何使用 Linux 帮助文档 Linux 各个部分大多都有标准进行规范，以降低在不同发行版之间的迁移难度，命令也不例外。本节我们首先将学习命令的语法通用格式，然后了解 Linu 中命令的分类；最后介绍 Linux 常用的基础命令。 ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:0:0","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"1. 命令的语法通用格式： COMMAND OPTIONS ARGUMENTS COMMAND: 命令名，发起一命令，请求内核将某个二进制程序运行为一个进程； 命令本身是一个可执行的程序文件：二进制格式的文件，有可能会调用共享库文件； 多数系统程序文件都存放在：/bin, /sbin, /usr/bin, /usr/sbin，/usr/local/bin, /usr/local/sbin 普通命令：/bin, /usr/bin, /usr/local/bin 管理命令：/sbin, /usr/sbin, /usr/local/sbin 共享库：/lib, /lib64, /usr/lib, /usr/lib64, /usr/local/lib, /usr/local/lib64 32bits的库：/lib, /usr/lib, /usr/local/lib 64bits的库：/lib64, /usr/lib64, /usr/local/lib64 注意：并非所有的命令都有一个在某目录与之对应的可执行程序文件 命令必须遵循特定格式规范：exe, msi, ELF(Linux) 查看命令类型: file /bin/ls OPTIONS： 作用: 命令选项，指定命令的运行特性； 类型: 选项有两种表现形式： 短选项：-C, 例如-l, -d 注意：有些命令的选项没有-； 如果同一命令同时使用多个短选项，多数可合并：-l -d = -ld 长选项：–word, 例如–help, –human-readable 注意：长选项不能合并； 注意：有些选项可以带参数，此称为选项参数； ARGUMENTS： 命令的作用对象；命令对什么生效； 注意：不同的命令的参数；有些命令可同时带多个参数，多个之间以空白字符分隔； 例如：ls -ld /var /etc ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:1:0","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"2. Linxu 的命令类型 命令分为两类： 内置命令(builtin): 由shell程序的自带的命令： 外部命令: 独立的可执行程序文件，文件名即命令名： 查看命令类型：type COMMAND 内部命令显示为 builtin 外部命令显示为命令文件路径； 注意：命令可以有别名；别名可以与原名相同，此时原名被隐藏；此时如果要运行原命令，则使用\\COMMAND； ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:2:0","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3. Linxu 的常用命令 ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:0","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.1 文件与目录查看命令 pwd: 作用: 显示工作目录 cd： cd [/PATH/TO/SOMEDIR] 作用: change directory 改变当前工作目录 选项: cd: 切换回家目录；注意： cd ~：切换回自己的家目录，bash中, ~表示家目录； cd ~USERNAME：切换至指定用户的家目录； cd -：在上一次所在目录与当前目录之间来回切换； 附注: 相关的环境变量 $PWD：当前工作目录 $OLDPWD：上一次的工作目录 ls ls [OPTION] [FILE] 作用: list, 列出指定目录下的内容 选项: -a: 显示所有文件，包括隐藏文件； -A: 显示除.和..之外的所有文件； -l: –long, 长格式列表，即显示文件的详细属性信息； -h: –human-readable：对文件大小单位换算；换算后结果可能会非精确值； -d: 查看目录自身而非其内部的文件列表； -r: reverse, 逆序显示； -R: recursive，递归显示； cat： cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac： tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； file file [FILE] 作用: 查看文件内容类型； echo echo [SHORT-OPTION] [STRING] 作用: 回显 选项: -n: 不进行换行； -e：让转义符生效； Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:1","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.2 关机与重启命令 shutdown shutdown [OPTIONS] [TIME] [WALL] 作用: 关机或重启命令 OPTIONS: -h: halt -r: reboot -c: cancel TIME： now: 立刻马上 hh:mm: 指定几时几秒 +m: m 分钟后 +0 ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:2","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.3 日期相关的命令： Linux 系统启动时从硬件读取日期和时间信息；读取完成以后，就不再与硬件相关联；此时系统时钟与硬件时钟是相互独立的 date date [OPTION] [+FORMAT] 作用: 显示系统时钟日期时间： 选项: -d String|-d @timestamp: 显示指定的时间字符串或时间戳表示的时间 -s, --set=STRING: 设置系统时间 FORMAT：格式符 %F:= %Y-%m-%d %T:直接显示时间 (24 小时制) %Y:完整年份 (0000-9999) %m:月份 (01-12) %d:日 (01-31) %H:小时(00-23) %M:分钟(00-59) %S:秒(00-60) %s:从1970年1月1号(unix元年)0点0分0秒到命令执行那一刻经过的秒数； # 按特定格式显示时间 \u003e date +%s 1531134611 \u003e date -d @1531134611 +%F 2018-07-09 \u003e date -d \"2017-10-13 23:00:00\" +%F 2017-10-13 \u003e date # 设置系统时间 \u003e date -s \"2018-10-13 23:10:12\" \u003e date -s \"2018/10/13 23:10:12\" hwclock / clock hwclock [function] [option] 作用:显示或设定硬件时钟 选项: -s: –hctosys,以硬件为准，把系统调整为与硬件时间相同； -w: –systohc：以系统为准，把硬件时间调整为与系统时钟相同； cal： cal [[month] year] 作用: 显示日历 ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:3","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.4 命令别名与查找 alias [alias-name[=string] 作用: 查看或定义命令别名： 常用: alias: 获取所有可用别名的定义： alias NAME='COMMAND'： 定义别名： 注意：仅对当前shell进程有效 unalias NAME: 撤销别名： which which [options] programname 作用: shows the full path of (shell) commands 选项: --skip-alias：忽略别名 whereis命令： whereis [options] name 作用: locate the binary, source, and manual page files for a command 选项: -b: 仅搜索二进制程序路径； -m：仅搜索使用手册文件路径； ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:4","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Linux"],"content":"3.5 登录用户查看 who who [OPTION] 作用: show who is logged on 选项: -b: 系统此次启动的时间； -r: 显示系统运行级别； w w [user] 作用: Show who is logged on and what they are doing. 增强版的 who tty tty 作用: 显示当前终端 ","date":"2018-01-01","objectID":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/:3:5","tags":["马哥 Linux"],"title":"3.1 Linux 命令基础","uri":"/posts/linux/linux_mt/03-linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9/%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/"},{"categories":["Python"],"content":"这个系列我们开始学习 Python 语言的第二部分-进阶","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"1. 语言特性 Python 最好的品质之一是一致性，体现在 Python 的数据模型上 ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:1:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"2. 数据模型 定义：是对 Python 框架的描述 作用：规范了这门语言自身构建模块的接口(API) 包括：不限于序列、迭代器、函数、类和上下文管理器 数据模型接口： 实现： Python 解释器碰到特殊的句法时，会使用特殊方法去激活一些基本的对象操作 特殊方法：以两个下划线开头，以两个下划线结尾 通过特殊方法可以实现的语言框架： 迭代 集合类 属性访问 运算符重载 函数和方法的调用 对象的创建和销毁 字符串表示形式和格式化 管理上下文（即 with 块） 通过实现特殊方法来利用 Python 数据模型的好处： 作为你的类的用户，他们不必去记住标准操作的各式名称 可以更加方便地利用 Python的标准库 eg:random.choice ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:2:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"3. 使用特殊方法 特殊方法调用： 特殊方法的存在是为了被 Python 解释器调用的，不需要直接调用它们 最好的选择是通过内置的函数（例如 len、 iter、 str，等等） eg：len(obj) 会自动调用 obj.__len__()方法 Python 内置的类型， CPython可能直接从一个 C 结构体里读取数据 ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:3:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"__repr__ 作用： 方便程序员调试和记录日志 所返回的字符串应该准确、无歧义，并且尽可能表达出如何用代码创建出这个被打印的对象 调用： repr() 函数 “%r” % obj format(’{name!r}’, obj) 交互式控制台和调试程序(debugger)用 repr 函数获取字符串表示形式 如果对象没有 __str__ 函数，解释器会用 __repr__ 作为替代 ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:3:1","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"__str__ 作用: 终端用户使用 调用: str() print ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:3:2","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"__bool__ 调用: bool() python 真假判断： 为了判定值 x 真假， Python会调用 bool(x)，这个函数只能返回 True 或者 False bool(x)默认调用 x.__bool__()，__bool__ 必须返回布尔型 如果不存在，bool(x) 尝试调用 x.__len__()返回 0则 bool 返回 False；否则返回 True 两个方法都不存在，默认情况下，自定义的类的实例总是返回True ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:3:3","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"特殊方法概览 1. 跟运算符无关的特殊方法 类别 方法名 字符串/字节序列表示形式 __repr__、 __str__、 __format__、 __bytes__ 数值转换 __abs__、 __bool__、 __complex__、 __int__、 __float__、 __hash__、 __index__ 集合模拟 __len__、 __getitem__、 __setitem__、 __delitem__、 __contains__ 迭代枚举 __iter__、 __reversed__、 __next__ 可调用模拟 __call__ 上下文管理 __enter__、 __exit__ 实例创建和销毁 __new__、 __init__、 __del__ 属性管理 __getattr__、 __getattribute__、 __setattr__、 __delattr__、 __dir__ 属性描述符 __get__、 __set__、 __delete__ 跟类相关的服务 __prepare__、 __instancecheck__、 __subclasscheck__ 2. 跟运算符相关的特殊方法 类别 方法名和对应的运算符 一元运算符 __neg__ -、 __pos__ +、 __abs__ abs() 众多比较运算符 __lt__ \u003c、 __le__ \u003c=、 __eq__ ==、 __ne__ !=、 __gt__ \u003e、 __ge__ \u003e= 算术运算符 __add__ +、 __sub__ -、 __mul__ *、 __truediv__ /、 __floordiv__ //、 __mod__ %、 __divmod__ divmod()、 __pow__ ** 或 pow()、 __round__ round() 反向算术运算符 __radd__、 __rsub__、 __rmul__、 __rtruediv__、 __rfloordiv__、 __rmod__、__rdivmod__、 __rpow__ 增量赋值算术运算符 __iadd__、 __isub__、 __imul__、 __itruediv__、 __ifloordiv__、 __imod__、__ipow__ 位运算符 __invert__ ~、 __lshift__ «、 __rshift__ »、 __and__ \u0026、 __or__ 、 __xor__ ^ 反向位运算符 __rlshift__、 __rrshift__、 __rand__、 __rxor__、 __ror__ 增量赋值位运算符 __ilshift__、 __irshift__、 __iand__、 __ixor__、 __ior__ ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:3:4","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"附注 len 为什么不是普通方法 对于内置类型，len() 直接从C 结构体里读取对象长度，完全不会调用任何方法 len 之所以不是一个普通方法，是为了让 Python 自带的数据结构 可以走后门，其他内置函数也是同样道理 同时由于它是特殊方法，也可以把 len 用于自定义数据类型 这种处理方式在保持内置类型的效率和保证语言的一致性之间找到了一个平衡点 ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:4:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"4. 常用模块 模块 作用 collection.namedtuple() 构建只有少数属性但是没有方法的对象，比如数据库条目 random.choice(seq) 从一个序列中随机选出一个元素 sorted() 内置排序函数 decimal.Decimal 高精度浮点数 fractions.Fraction 分数数值类型 ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:5:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"延伸阅读 Python: Data Model:https://docs.python.org/3/reference/datamodel.html format: https://docs.python.org/2/library/string.html#formatstring-syntax __str__:http://stackoverflow.com/questions/1436703/difference-between-str-and-repr-in-python 书籍： 《 Python 技术手册（第 2 版）》- 对属性访问机制的描述 《 Python 参考手册（第 4 版）》 《 Python Cookbook（第 3版）中文版》 《The Art of the Metaobject Protocol》 - 元对象协议(metaobject protocol， MOP) blog: Alex Martelli: http://stackoverflow.com/users/95810/alex-martelli ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:6:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"杂谈 元对象协议 元对象所指的是那些对建构语言本身来讲很重要的对象， 以此为前提， 协议也可以看作接口 也就是说，元对象协议是对象模型的同义词，它们的意思都是构建核心语言的 API 面向方面编程 java: AspectJ pyhton: zope.interface http://docs.zope.org/zope.interface/ ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:7:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["Python"],"content":"示例代码 from math import hypot class Vector: def __init__(self, x=0, y=0): self.x = x self.y = y def __repr__(self): return 'Vector(%r, %r)' % (self.x, self.y) def __abs__(self): return hypot(self.x, self.y) def __bool__(self): return bool(abs(self)) def __add__(self, other): x = self.x + other.x y = self.y + other.y return Vector(x, y) def __mul__(self, scalar): return Vector(self.x * scalar, self.y * scalar) ","date":"2018-01-01","objectID":"/posts/program/python/grammar/fluent-python/01_data_module/:8:0","tags":["python 进阶"],"title":"Python 数据模型","uri":"/posts/program/python/grammar/fluent-python/01_data_module/"},{"categories":["loveit"],"content":"了解如何在 LoveIt 主题中快速, 直观地创建和组织内容.","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"了解如何在 LoveIt 主题中快速, 直观地创建和组织内容. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:0:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"1 内容组织 以下是一些方便你清晰管理和生成文章的目录结构建议: 保持博客文章存放在 content/posts 目录, 例如: content/posts/我的第一篇文章.md 保持简单的静态页面存放在 content 目录, 例如: content/about.md 本地资源组织 本地资源引用 有三种方法来引用图片和音乐等本地资源: 使用页面包中的页面资源. 你可以使用适用于 Resources.GetMatch 的值或者直接使用相对于当前页面目录的文件路径来引用页面资源. 将本地资源放在 assets 目录中, 默认路径是 /assets. 引用资源的文件路径是相对于 assets 目录的. 将本地资源放在 static 目录中, 默认路径是 /static. 引用资源的文件路径是相对于 static 目录的. 引用的优先级符合以上的顺序. 在这个主题中的很多地方可以使用上面的本地资源引用, 例如 链接, 图片, image shortcode, music shortcode 和前置参数中的部分参数. 页面资源或者 assets 目录中的图片处理会在未来的版本中得到支持. 非常酷的功能! ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:1:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"2 前置参数 Hugo 允许你在文章内容前面添加 yaml, toml 或者 json 格式的前置参数. 注意 不是所有的以下前置参数都必须在你的每篇文章中设置. 只有在文章的参数和你的 网站设置 中的 page 部分不一致时才有必要这么做. 这是一个前置参数例子: --- title: \"我的第一篇文章\" subtitle: \"\" date: 2020-03-04T15:58:26+08:00 lastmod: 2020-03-04T15:58:26+08:00 draft: true author: \"\" authorLink: \"\" description: \"\" license: \"\" images: [] tags: [] categories: [] featuredImage: \"\" featuredImagePreview: \"\" hiddenFromHomePage: false hiddenFromSearch: false twemoji: false lightgallery: true ruby: true fraction: true fontawesome: true linkToMarkdown: true rssFullText: false toc: enable: true auto: true code: copy: true # ... math: enable: true # ... mapbox: accessToken: \"\" # ... share: enable: true # ... comment: enable: true # ... library: css: # someCSS = \"some.css\" # 位于 \"assets/\" # 或者 # someCSS = \"https://cdn.example.com/some.css\" js: # someJS = \"some.js\" # 位于 \"assets/\" # 或者 # someJS = \"https://cdn.example.com/some.js\" seo: images: [] # ... --- title: 文章标题. subtitle: 文章副标题. date: 这篇文章创建的日期时间. 它通常是从文章的前置参数中的 date 字段获取的, 但是也可以在 网站配置 中设置. lastmod: 上次修改内容的日期时间. draft: 如果设为 true, 除非 hugo 命令使用了 --buildDrafts/-D 参数, 这篇文章不会被渲染. author: 文章作者. authorLink: 文章作者的链接. description: 文章内容的描述. license: 这篇文章特殊的许可. images: 页面图片, 用于 Open Graph 和 Twitter Cards. tags: 文章的标签. categories: 文章所属的类别. featuredImage: 文章的特色图片. featuredImagePreview: 用在主页预览的文章特色图片. hiddenFromHomePage: 如果设为 true, 这篇文章将不会显示在主页上. hiddenFromSearch: 如果设为 true, 这篇文章将不会显示在搜索结果中. twemoji: 如果设为 true, 这篇文章会使用 twemoji. lightgallery: 如果设为 true, 文章中的图片将可以按照画廊形式呈现. ruby: 如果设为 true, 这篇文章会使用 上标注释扩展语法. fraction: 如果设为 true, 这篇文章会使用 分数扩展语法. fontawesome: 如果设为 true, 这篇文章会使用 Font Awesome 扩展语法. linkToMarkdown: 如果设为 true, 内容的页脚将显示指向原始 Markdown 文件的链接. rssFullText: 如果设为 true, 在 RSS 中将会显示全文内容. toc: 和 网站配置 中的 params.page.toc 部分相同. code: 和 网站配置 中的 params.page.code 部分相同. math: 和 网站配置 中的 params.page.math 部分相同. mapbox: 和 网站配置 中的 params.page.mapbox 部分相同. share: 和 网站配置 中的 params.page.share 部分相同. comment: 和 网站配置 中的 params.page.comment 部分相同. library: 和 网站配置 中的 params.page.library 部分相同. seo: 和 网站配置 中的 params.page.seo 部分相同. 技巧 featuredImage 和 featuredImagePreview 支持本地资源引用的完整用法. 如果带有在前置参数中设置了 name: featured-image 或 name: featured-image-preview 属性的页面资源, 没有必要在设置 featuredImage 或 featuredImagePreview: resources: - name: featured-image src: featured-image.jpg - name: featured-image-preview src: featured-image-preview.jpg ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:2:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"3 内容摘要 LoveIt 主题使用内容摘要在主页中显示大致文章信息。Hugo 支持生成文章的摘要. 文章摘要预览 ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"自动摘要拆分 默认情况下, Hugo 自动将内容的前 70 个单词作为摘要. 你可以通过在 网站配置 中设置 summaryLength 来自定义摘要长度. 如果您要使用 CJK中文/日语/韩语 语言创建内容, 并且想使用 Hugo 的自动摘要拆分功能，请在 网站配置 中将 hasCJKLanguage 设置为 true. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:1","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"手动摘要拆分 另外, 你也可以添加 \u003c!--more--\u003e 摘要分割符来拆分文章生成摘要. 摘要分隔符之前的内容将用作该文章的摘要. 注意 请小心输入\u003c!--more--\u003e ; 即全部为小写且没有空格. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:2","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"前置参数摘要 你可能希望摘要不是文章开头的文字. 在这种情况下, 你可以在文章前置参数的 summary 变量中设置单独的摘要. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:3","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"使用文章描述作为摘要 你可能希望将文章前置参数中的 description 变量的内容作为摘要. 你仍然需要在文章开头添加 \u003c!--more--\u003e 摘要分割符. 将摘要分隔符之前的内容保留为空. 然后 LoveIt 主题会将你的文章描述作为摘要. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:4","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"摘要选择的优先级顺序 由于可以通过多种方式指定摘要, 因此了解顺序很有用. 如下: 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 但分隔符之前没有内容, 则使用描述作为摘要. 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 则将按照手动摘要拆分的方法获得摘要. 如果文章前置参数中有摘要变量, 那么将以该值作为摘要. 按照自动摘要拆分方法. 注意 不建议在摘要内容中包含富文本块元素, 这会导致渲染错误. 例如代码块, 图片, 表格等. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:3:5","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"4 Markdown 基本语法 这部分内容在 Markdown 基本语法页面 中介绍. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:4:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"5 Markdown 扩展语法 LoveIt 主题提供了一些扩展的语法便于你撰写文章. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:0","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"Emoji 支持 这部分内容在 Emoji 支持页面 中介绍. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:1","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"数学公式 LoveIt 基于 $ \\KaTeX $ 提供数学公式的支持. 在你的 网站配置 中的 [params.math] 下面设置属性 enable = true, 并在文章的前置参数中设置属性 math: true来启用数学公式的自动渲染. 技巧 有一份 $ \\KaTeX $ 中支持的 $ \\TeX $ 函数 清单. 公式块 默认的公式块分割符是 $$/$$ 和 \\\\[/\\\\]: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\\\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\\\] 呈现的输出效果如下: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\] 行内公式 默认的行内公式分割符是 $/$ 和 \\\\(/\\\\): $ c = \\pm\\sqrt{a^2 + b^2} $ 和 \\\\( f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\\\) 呈现的输出效果如下: $ c = \\pm\\sqrt{a^2 + b^2} $ 和 \\( f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\) 技巧 你可以在 网站配置 中自定义公式块和行内公式的分割符. Copy-tex Copy-tex 是一个 $ \\KaTeX $ 的插件. 通过这个扩展, 在选择并复制 $ \\KaTeX $ 渲染的公式时, 会将其 $ \\LaTeX $ 源代码复制到剪贴板. 在你的 网站配置 中的 [params.math] 下面设置属性 copyTex = true 来启用 Copy-tex. 选择并复制上一节中渲染的公式, 可以发现复制的内容为 LaTeX 源代码. mhchem mhchem 是一个 $ \\KaTeX $ 的插件. 通过这个扩展, 你可以在文章中轻松编写漂亮的化学方程式. 在你的 网站配置 中的 [params.math] 下面设置属性 mhchem = true 来启用 mhchem. $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ 呈现的输出效果如下: $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:2","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"字符注音或者注释 LoveIt 主题支持一种 字符注音或者注释 Markdown 扩展语法: [Hugo]^(一个开源的静态网站生成工具) 呈现的输出效果如下: Hugo一个开源的静态网站生成工具 ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:3","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"分数 LoveIt 主题支持一种 分数 Markdown 扩展语法: [浅色]/[深色] [99]/[100] 呈现的输出效果如下: 浅色/深色 90/100 ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:4","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"Font Awesome LoveIt 主题使用 Font Awesome 作为图标库. 你同样可以在文章中轻松使用这些图标. 从 Font Awesome 网站 上获取所需的图标 class. 去露营啦! :(fas fa-campground fa-fw): 很快就回来. 真开心! :(far fa-grin-tears): 呈现的输出效果如下: 去露营啦!  很快就回来. 真开心! ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:5","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"转义字符 在某些特殊情况下 (编写这个主题文档时 ), 你的文章内容会与 Markdown 的基本或者扩展语法冲突, 并且无法避免. 转义字符语法可以帮助你渲染出想要的内容: {?X} -\u003e X 例如, 两个 : 会启用 emoji 语法. 但有时候这不是你想要的结果. 可以像这样使用转义字符语法: {?:}joy: 呈现的输出效果如下: :joy: 而不是 😂 技巧 这个方法可以间接解决一个还未解决的 Hugo 的 issue. 另一个例子是: [link{?]}(#escape-character) 呈现的输出效果如下: [link](#escape-character) 而不是 link. ","date":"2020-03-05","objectID":"/posts/hugo/loveit_content/:5:6","tags":["loveit"],"title":"Loveit 内容组织","uri":"/posts/hugo/loveit_content/"},{"categories":["loveit"],"content":"Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁.","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁. Hugo 使用 Markdown 为其简单的内容格式. 但是, Markdown 在很多方面都无法很好地支持. 你可以使用纯 HTML 来扩展可能性. 但这恰好是一个坏主意. 大家使用 Markdown, 正是因为它即使不经过渲染也可以轻松阅读. 应该尽可能避免使用 HTML 以保持内容简洁. 为了避免这种限制, Hugo 创建了 shortcodes. shortcode 是一个简单代码段, 可以生成合理的 HTML 代码, 并且符合 Markdown 的设计哲学. Hugo 附带了一组预定义的 shortcodes, 它们实现了一些非常常见的用法. 提供这些 shortcodes 是为了方便保持你的 Markdown 内容简洁. ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:0:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"1 figure figure 的文档 一个 figure 示例: {{\u003c figure src=\"/images/hugo/lighthouse.jpg\" title=\"Lighthouse (figure)\" \u003e}} 呈现的输出效果如下: Lighthouse (figure) 输出的 HTML 看起来像这样: \u003cfigure\u003e \u003cimg src=\"/images/hugo/lighthouse.jpg\"/\u003e \u003cfigcaption\u003e \u003ch4\u003eLighthouse (figure)\u003c/h4\u003e \u003c/figcaption\u003e \u003c/figure\u003e ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:1:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"2 gist gist 的文档 一个 gist 示例: {{\u003c gist spf13 7896402 \u003e}} 呈现的输出效果如下: 输出的 HTML 看起来像这样: \u003cscript type=\"application/javascript\" src=\"https://gist.github.com/spf13/7896402.js\"\u003e\u003c/script\u003e ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:2:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"3 highlight highlight 的文档 一个 highlight 示例: {{\u003c highlight html \u003e}} \u003csection id=\"main\"\u003e \u003cdiv\u003e \u003ch1 id=\"title\"\u003e{{ .Title }}\u003c/h1\u003e {{ range .Pages }} {{ .Render \"summary\"}} {{ end }} \u003c/div\u003e \u003c/section\u003e {{\u003c /highlight \u003e}} 呈现的输出效果如下: \u003csection id=\"main\"\u003e \u003cdiv\u003e \u003ch1 id=\"title\"\u003e{{ .Title }}\u003c/h1\u003e {{ range .Pages }} {{ .Render \"summary\"}} {{ end }} \u003c/div\u003e \u003c/section\u003e ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:3:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"4 instagram instagram 的文档 Instagram’s API was deprecated since October 24th, 2020 The instagram-shortcode refers an endpoint of Instagram’s API, that’s deprecated since October 24th, 2020. Thus, no images can be fetched from this API endpoint, resulting in an error when the instagram-shortcode is used. For more information please have a look at GitHub issue #7879. ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:4:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"5 param param 的文档 一个 param 示例: {{\u003c param description \u003e}} 呈现的输出效果如下: Hugo 提供了多个内置的 Shortcodes, 以方便作者保持 Markdown 内容的整洁. ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:5:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"6 ref 和 relref ref 和 relref 的文档 ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:6:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"7 tweet tweet 的文档 一个 tweet 示例: {{\u003c tweet 917359331535966209 \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:7:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"8 vimeo vimeo 的文档 一个 vimeo 示例: {{\u003c vimeo 146022717 \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:8:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["loveit"],"content":"9 youtube youtube 的文档 一个 youtube 示例: {{\u003c youtube w7Ft2ymGmfc \u003e}} 呈现的输出效果如下: ","date":"2020-03-04","objectID":"/posts/hugo/loveit_shortcodes/:9:0","tags":["loveit"],"title":"Loveit 内置 Shortcodes","uri":"/posts/hugo/loveit_shortcodes/"},{"categories":["Linux"],"content":"Linux profiling - eBPF","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"这个系列我们来学习 Linux profiling 的另一款大杀器 - eBPF，学习资源来自于极客时间倪朋飞老师专栏-eBPF 核心技术与实战。 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:0:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"1. eBPF 简介 eBPF 是什么呢？ 从它的全称“扩展的伯克利数据包过滤器 (Extended Berkeley Packet Filter)” 来看，它是一种数据包过滤技术，是从 BPF (Berkeley Packet Filter) 技术扩展而来的。不同于内核模块直接注入到内核的运行方式，eBPF 借助即时编译器（JIT），在内核中运行了一个虚拟机，保证了只有被验证安全的 eBPF 指令才会被内核执行。同时，因为 eBPF 指令依然运行在内核中，无需向用户态复制数据，这就大大提高了事件处理的效率。 eBPF 现如今已经有了大量的实战应用: Facebook 开源的高性能网络负载均衡器 Katran Isovalent 开源的容器网络方案 Cilium 著名的内核跟踪排错工具 BCC 和 bpftrace 等 最流行的网络解决方案之一 Calico，就在最近的版本中引入了 eBPF 数据面网络，大大提升了网络的性能。 下图（来自 ebpf.io）是对 eBPF 技术及其应用的一个概览： ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:1:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"2. eBPF 发展历程 eBPF 有 BPF 发展而来，时至今日 eBPF 经历如下重大的时间节点: 1992 年的 USENIX 会议上，Steven McCanne 和 Van Jacobson 发布的论文“The BSD Packet Filter: A New Architecture for User-level Packet Capture” 为 BSD 操作系统带来了革命性的包过滤机制 BSD Packet Filter（简称为 BPF） 1997 年，在 BPF 诞生五年后，Linux 2.1.75 首次引入了 BPF 技术 2011 年，Linux 3.0 中增加的 BPF 即时编译器，替换掉了原本性能更差的解释器，进一步优化了 BPF 指令运行的效率。 2014 年，为了研究新的软件定义网络方案，Alexei Starovoitov 为 BPF 带来了第一次革命性的更新，将 BPF 扩展为一个通用的虚拟机，也就是 eBPF。eBPF 不仅扩展了寄存器的数量，引入了全新的 BPF 映射存储，还在 4.x 内核中将原本单一的 数据包过滤事件 逐步扩展到了 内核态函数、用户态函数、跟踪点、性能事件（perf_events） 以及安全控制等。 2015 年，iovisor 带来的 BCC、bpftrace 等工具，成为 eBPF 在跟踪和排错领域的最佳实践 2016 年 Linux 4.7-4.10 带来了 跟踪点、perf 事件、XDP 以及 cgroups 的支持 ，丰富了 eBPF 的事件源 2017 年，BPF 成为内核独立子模块，并支持了 KTLS、bpftool、libbpf 等 2018 年，BPF 新增了轻量级调试信息格式 BTF 以及新的 AF_XDP 类型，bpftrace 和 bpffilter 项目也正是发布 2019 年，BPF 新增了尾调用和热更新支持，GCC 也开始支持 BPF 编译，童年 Cilium1.6 发布基于 BPF的服务发现代理，完全替代基于 iptables 的 kube-proxy 2020 Google 和 Facebook 为 BPF 新增 LSM 和 TCP 拥塞控制的支持，主流云厂商开始通过 SRIOV 支持 XDP 2021 EPBFacebook 软件基金会成立，BPF 开始支持内核函数调用，Cilium 发布基于 eBPF 的 Service Mesh 取代代理。 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:2:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"3. eBPF 工作过程 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:3:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"3.1 eBPF 执行过程 eBPF 程序并不像常规的线程那样，启动后就一直运行在那里，它需要事件触发后才会执行。这些事件包括系统调用、内核跟踪点、内核函数和用户态函数的调用退出、网络事件，等等。借助于强大的内核态插桩（kprobe）和用户态插桩（uprobe），eBPF 程序几乎可以在内核和应用的任意位置进行插桩。 那 eBPF 到底是如何工作的呢？如下图（图片来自brendangregg.com）所示，通常我们借助 LLVM 把编写的 eBPF 程序转换为 BPF 字节码，然后再通过 bpf 系统调用提交给内核执行。内核在接受 BPF 字节码之前，会首先通过验证器对字节码进行校验，只有校验通过的 BPF 字节码才会提交到即时编译器执行。 确保安全和稳定一直都是 eBPF 的首要任务，如果 BPF 字节码中包含了不安全的操作，验证器会直接拒绝 BPF 程序的执行。比如，下面就是一些典型的验证过程： 只有特权进程才可以执行 bpf 系统调用； BPF 程序不能包含无限循环； BPF 程序不能导致内核崩溃； BPF 程序必须在有限时间内完成 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:3:1","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"3.2 eBPF 交互 BPF 程序可以利用 BPF 映射(map) 进行存储，而用户程序通常也需要通过 BPF 映射同运行在内核中的 BPF 程序进行交互。如下图（图片来自ebpf.io）所示，在性能观测中，BPF 程序收集内核运行状态存储在映射中，用户程序再从映射中读出这些状态。 可以看到，eBPF 程序的运行需要历经编译、加载、验证和内核态执行等过程，而用户态程序则需要借助 BPF 映射来获取内核态 eBPF 程序的运行状态。 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:3:2","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"3.3 eBPF 局限 eBPF 不是万能的: eBPF 程序必须被验证器校验通过后才能执行，且不能包含无法到达的指令； eBPF 程序不能随意调用内核函数，只能调用在 API 中定义的辅助函数； eBPF 程序栈空间最多只有 512 字节，想要更大的存储，就必须要借助映射存储； 在内核 5.2 之前，eBPF 字节码最多只支持 4096 条指令，而 5.2 内核把这个限制提高到了 100 万条； 由于内核的快速变化，在不同版本内核中运行时，需要访问内核数据结构的 eBPF 程序很可能需要调整源码，并重新编译。 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:3:3","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"4. eBPF 学习路线 最后附上 eBPF 的学习路径思维导图: ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:4:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Linux"],"content":"参考 本文内容摘录自: 极客时间倪朋飞老师专栏-eBPF 核心技术与实战 ","date":"2022-03-01","objectID":"/posts/linux/profiling/ebpf/01_ebpf/:5:0","tags":["profiling"],"title":"eBPF 简介","uri":"/posts/linux/profiling/ebpf/01_ebpf/"},{"categories":["Go"],"content":"Go 提供的并发冲突以及死循环检测","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"Go 语言提供了一些并发调试工具，这些工具可以帮我们有效的发现并发编程中的 bug ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:0:0","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"1. Go race detector Go race detector可以帮助我们自动发现程序有没有数据竞争(data race)，它是基于 Google 的 C/C++ sanitizers 技术实现的，编译器通过探测所有的内存访问，加入代码能监视对这些内存地址的访问（读还是写）。在代码运行的时候，race detector 就能监控到对共享变量的非同步访问，出现 race 时，就会打印出警告信息。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:1:0","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"1.1 使用 在编译（compile）、测试（test）或者运行（run）Go 代码的时候，加上 race 参数，就有可能发现并发问题。 // -race 启动 data race 检测 go run -race counter.go 虽然这个工具使用起来很方便，但是，因为它的实现方式，只能通过真正对实际地址进行读写访问的时候才能探测，所以它不能再编译的时候发现 data race 问题，而且只有在运行时出现 data race 才能检测到。如果碰巧没有出现 data race 是检测不出来的。而且，把开启了 race 的程序部署在线上，还是比较影响性能的。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:1:1","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"1.2 race 编译后代码 运行 go tool compile -race -S counter.go，可以查看计数器例子的代码，下面是一个编译后代码示例: // 显示添加 -race 后编译的 go 代码 go tool compile -race -S counter.go 0x002a 00042 (counter.go:13) CALL runtime.racefuncenter(SB) ...... 0x0061 00097 (counter.go:14) JMP 173 0x0063 00099 (counter.go:15) MOVQ AX, \"\".j+8(SP) 0x0068 00104 (counter.go:16) PCDATA $0, $1 0x0068 00104 (counter.go:16) MOVQ \"\".\u0026count+128(SP), AX 0x0070 00112 (counter.go:16) PCDATA $0, $0 0x0070 00112 (counter.go:16) MOVQ AX, (SP) 0x0074 00116 (counter.go:16) CALL runtime.raceread(SB) 0x0079 00121 (counter.go:16) PCDATA $0, $1 0x0079 00121 (counter.go:16) MOVQ \"\".\u0026count+128(SP), AX 0x0081 00129 (counter.go:16) MOVQ (AX), CX 0x0084 00132 (counter.go:16) MOVQ CX, \"\"..autotmp_8+16(SP) 0x0089 00137 (counter.go:16) PCDATA $0, $0 0x0089 00137 (counter.go:16) MOVQ AX, (SP) 0x008d 00141 (counter.go:16) CALL runtime.racewrite(SB) 0x0092 00146 (counter.go:16) MOVQ \"\"..autotmp_8+16(SP), AX ...... 0x00b6 00182 (counter.go:18) CALL runtime.deferreturn(SB) 0x00bb 00187 (counter.go:18) CALL runtime.racefuncexit(SB) 0x00c0 00192 (counter.go:18) MOVQ 104(SP), BP 0x00c5 00197 (counter.go:18) ADDQ $112, SP 在编译的代码中，增加了 runtime.racefuncenter、runtime.raceread、runtime.racewrite、runtime.racefuncexit 等检测 data race 的方法。通过这些插入的指令，Go race detector 工具就能够成功地检测出 data race 问题了。 总结一下，通过在编译的时候插入一些指令，在运行时通过这些插入的指令检测并发读写从而发现 data race 问题，就是这个工具的实现机制。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:1:2","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"2. go vet 复制检测 Package sync 的同步原语在使用后是不能复制的。原因在于，Mutex 是一个有状态的对象，它的 state 字段记录这个锁的状态。如果你要复制一个已经加锁的 Mutex 给一个新的变量，那么新的刚初始化的变量居然被加锁了，这显然不符合你的期望，因为你期望的是一个零值的 Mutex。关键是在并发环境下，你根本不知道要复制的 Mutex 状态是什么，因为要复制的 Mutex 是由其它 goroutine 并发访问的，状态可能总是在变化。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:2:0","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"2.1 go vet 使用 Go 在运行时，有死锁的检查机制（checkdead 方法），它能够发现死锁的 goroutine。但是显然我们不想运行的时候才发现这个因为复制 Mutex 导致的死锁问题。我们可以使用 vet 工具: go vet counter.go，把检查写在 Makefile 文件中，在持续集成的时候跑一跑，这样可以及时发现问题，及时修复。 go vet counter.go 报错信息清楚提示了发生了 lock value 复制的情况，并且显示出了出问题的代码行数以及 copy lock 导致的错误。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:2:1","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"2.2 检测原理 vet 检查是通过copylock分析器静态分析实现的。这个分析器会分析函数调用、range 遍历、复制、声明、函数返回值等位置，有没有锁的值 copy 的情景，以此来判断有没有问题。可以说，只要是实现了 Locker 接口，就会被分析。 我们看到，下面的代码就是确定什么类型会被分析，其实就是实现了 Lock/Unlock 两个方法的 Locker 接口： var lockerType *types.Interface // Construct a sync.Locker interface type. func init() { nullary := types.NewSignature(nil, nil, nil, false) // func() methods := []*types.Func{ types.NewFunc(token.NoPos, nil, \"Lock\", nullary), types.NewFunc(token.NoPos, nil, \"Unlock\", nullary), } lockerType = types.NewInterface(methods, nil).Complete() } ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:2:2","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"2.3 noCopy 辅助 vet 检查 其实，有些没有实现 Locker 接口的同步原语，也能被分析，比如 WaitGroup。WaitGroup 的结构如下所示: type WaitGroup struct { // 避免复制使用的一个技巧，可以告诉vet工具违反了复制使用的规则 noCopy noCopy // 64bit(8bytes)的值分成两段，高32bit是计数值，低32bit是waiter的计数 // 另外32bit是用作信号量的 // 因为64bit值的原子操作需要64bit对齐，但是32bit编译器不支持，所以数组中的元素在不同的架构中不一样，具体处理看下面的方法 // 总之，会找到对齐的那64bit作为state，其余的32bit做信号量 state1 [3]uint32 } // 得到state的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { if uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { // 如果地址是64bit对齐的，数组前两个元素做state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1)), \u0026wg.state1[2] } else { // 如果地址是32bit对齐的，数组后两个元素用来做state，它可以用来做64bit的原子操作，第一个元素32bit用来做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1[1])), \u0026wg.state1[0] } } 它有一个 noCopy 的辅助字段，它的作用就是指示 vet 工具在做检查的时候，这个数据结构不能做值复制使用。更严谨地说，是不能在第一次使用之后复制使用 ( must not be copied after first use)。 通过给 WaitGroup 添加一个 noCopy 字段，我们就可以为 WaitGroup 实现 Locker 接口，这样 vet 工具就可以做复制检查了。而且因为 noCopy 字段是未输出类型，所以 WaitGroup 不会暴露 Lock/Unlock 方法。 noCopy 字段的类型是 noCopy，它只是一个辅助的、用来帮助 vet 检查用的类型: type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} noCopy 是一个通用的计数技术，其他并发原语中也会用到。同样的，如果你想要自己定义的数据结构不被复制使用，或者说，不能通过 vet 工具检查出复制使用的报警，就可以通过嵌入 noCopy 这个数据类型来实现。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:2:3","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"3. 死锁检测 前面我们提到Go 在运行时，有死锁的检查机制（checkdead 方法），能够检查出是否出现了死锁的情况。 Go 死锁探测工具只能探测整个程序是否因为死锁而冻结了，不能检测出一组 goroutine 死锁导致的某一块业务冻结的情况。你还可以通过 Go 运行时自带的死锁检测工具，或者是第三方的工具（比如go-deadlock、go-tools）进行检查，这样可以尽早发现一些死锁的问题。不过，有些时候，死锁在某些特定情况下才会被触发，所以，如果你的测试或者短时间的运行没问题，不代表程序一定不会有死锁问题。 并发程序最难跟踪调试的就是很难重现，死锁的 Bug 可能会在极端的情况下出现。通过搜索日志、查看日志，我们能够知道程序有异常了，比如某个流程一直没有结束。这个时候，可以通过 Go pprof 工具分析，它提供了一个 block profiler 监控阻塞的 goroutine。除此之外，我们还可以查看全部的 goroutine 的堆栈信息，通过它，你可以查看阻塞的 groutine 究竟阻塞在哪一行哪一个对象上了。 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:3:0","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"参考 上面这些调试工具的使用，参考自: 极客专栏-鸟叔的 Go 并发编程实战01 极客专栏-鸟叔的 Go 并发编程实战03 ","date":"2021-07-01","objectID":"/posts/program/go/tools/go_exe/race_check/:4:0","tags":["go 工具集"],"title":"Go 并发调试工具","uri":"/posts/program/go/tools/go_exe/race_check/"},{"categories":["Go"],"content":"基于 etcd 的分布式队列、栅栏和 STM","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"1. 分布式队列 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:1:0","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"1.1 基础使用 etcd 通过 github.com/coreos/etcd/contrib/recipes 包提供了分布式队列这种数据结构。其类型和方法的签名如下: // 创建队列 func NewQueue(client *v3.Client, keyPrefix string) *Queue // 入队 func (q *Queue) Enqueue(val string) error //出队 func (q *Queue) Dequeue() (string, error) 需要注意的是，如果这个分布式队列当前为空，调用 Dequeue 方法的话，会被阻塞，直到有元素可以出队才返回。 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:1:1","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"1.2 使用示例 我们可以启动多个下面的程序来模拟分布式的环境，进行测试: package main import ( \"bufio\" \"flag\" \"fmt\" \"log\" \"os\" \"strings\" \"github.com/coreos/etcd/clientv3\" recipe \"github.com/coreos/etcd/contrib/recipes\" ) var ( addr = flag.String(\"addr\", \"http://127.0.0.1:2379\", \"etcd addresses\") queueName = flag.String(\"name\", \"my-test-queue\", \"queue name\") ) func main() { flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, \",\") // 创建etcd的client cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() // 创建/获取队列 q := recipe.NewQueue(cli, *queueName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() { action := consolescanner.Text() items := strings.Split(action, \" \") switch items[0] { case \"push\": // 加入队列 if len(items) != 2 { fmt.Println(\"must set value to push\") continue } q.Enqueue(items[1]) // 入队 case \"pop\": // 从队列弹出 v, err := q.Dequeue() // 出队 if err != nil { log.Fatal(err) } fmt.Println(v) // 输出出队的元素 case \"quit\", \"exit\": //退出 return default: fmt.Println(\"unknown action\") } } } ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:1:2","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"1.3 优先级队列 etcd 还提供了优先级队列（PriorityQueue）,用法和队列类似，只不过，在入队的时候，我们还需要提供 uint16 类型的一个整数，作为值的优先级，优先级高的元素会优先出队。 type PriorityQueue struct { // contains filtered or unexported fields } func NewPriorityQueue(client *v3.Client, key string) *PriorityQueue func (q *PriorityQueue) Dequeue() (string, error) func (q *PriorityQueue) Enqueue(val string, pr uint16) error ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:1:3","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"2. 分布式栅栏 循环栅栏 CyclicBarrie 和 WaitGroup 本质上是同一类并发原语，都是等待同一组 goroutine 同时执行或者等待同一组 goroutine 都完成。分布式环境中，我们也会遇到这样的场景：一组节点协同工作，共同等待一个信号，在信号未出现前，这些节点会被阻塞住，而一旦信号出现，这些阻塞的节点就会同时开始继续执行下一步的任务。 etcd 也提供了相应的分布式并发原语: Barrier：分布式栅栏。如果持有 Barrier 的节点释放了它，所有等待这个 Barrier 的节点就不会被阻塞，而是会继续执行。 DoubleBarrier：计数型栅栏。在初始化计数型栅栏的时候，我们就必须提供参与节点的数量，当这些数量的节点都 Enter 或者 Leave 的时候，这个栅栏就会放开。所以，我们把它称为计数型栅栏。 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:2:0","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"2.1 Barrier type Barrier func NewBarrier(client *v3.Client, key string) *Barrier func (b *Barrier) Hold() error func (b *Barrier) Release() error func (b *Barrier) Wait() error Hold 方法是创建一个 Barrier。如果 Barrier 已经创建好了，有节点调用它的 Wait 方法，就会被阻塞。 Release 方法是释放这个 Barrier，也就是打开栅栏。如果使用了这个方法，所有被阻塞的节点都会被放行，继续执行。 Wait 方法会阻塞当前的调用者，直到这个 Barrier 被 release。如果这个栅栏不存在，调用者不会被阻塞，而是会继续执行。 package main import ( \"bufio\" \"flag\" \"fmt\" \"log\" \"os\" \"strings\" \"github.com/coreos/etcd/clientv3\" recipe \"github.com/coreos/etcd/contrib/recipes\" ) var ( addr = flag.String(\"addr\", \"http://127.0.0.1:2379\", \"etcd addresses\") barrierName = flag.String(\"name\", \"my-test-queue\", \"barrier name\") ) func main() { flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, \",\") // 创建etcd的client cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() // 创建/获取栅栏 b := recipe.NewBarrier(cli, *barrierName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() { action := consolescanner.Text() items := strings.Split(action, \" \") switch items[0] { case \"hold\": // 持有这个barrier b.Hold() fmt.Println(\"hold\") case \"release\": // 释放这个barrier b.Release() fmt.Println(\"released\") case \"wait\": // 等待barrier被释放 b.Wait() fmt.Println(\"after wait\") case \"quit\", \"exit\": //退出 return default: fmt.Println(\"unknown action\") } } } ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:2:1","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"2.2 DoubleBarrier DoubleBarrier 在初始化时提供了一个计数的 count type DoubleBarrier func NewDoubleBarrier(s *concurrency.Session, key string, count int) *DoubleBarrier func (b *DoubleBarrier) Enter() error func (b *DoubleBarrier) Leave() error Enter: 当调用者调用 Enter 时，会被阻塞住，直到一共有 count（初始化这个栅栏的时候设定的值）个节点调用了 Enter，这 count 个被阻塞的节点才能继续执行。所以，你可以利用它编排一组节点，让这些节点在同一个时刻开始执行任务。 Leave: 节点调用 Leave 方法的时候，会被阻塞，直到有 count 个节点，都调用了 Leave 方法，这些节点才能继续执行。 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:2:2","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"3. STM ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:3:0","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"3.1 etcd 事务 etcd 提供了在一个事务中对多个 key 的更新功能，这一组 key 的操作要么全部成功，要么全部失败。etcd 的事务实现方式是基于 CAS 方式实现的，融合了 Get、Put 和 Delete 操作。 etcd 的事务操作如下，分为条件块、成功块和失败块，条件块用来检测事务是否成功，如果成功，就执行 Then(…)，如果失败，就执行 Else(…)： Txn().If(cond1, cond2, ...).Then(op1, op2, ...,).Else(op1’, op2’, …) 下面是利用 etcd 实现转账的例子: func doTxnXfer(etcd *v3.Client, from, to string, amount uint) (bool, error) { // 一个查询事务 getresp, err := etcd.Txn(ctx.TODO()).Then(OpGet(from), OpGet(to)).Commit() if err != nil { return false, err } // 获取转账账户的值 fromKV := getresp.Responses[0].GetRangeResponse().Kvs[0] toKV := getresp.Responses[1].GetRangeResponse().Kvs[1] fromV, toV := toUInt64(fromKV.Value), toUint64(toKV.Value) if fromV \u003c amount { return false, fmt.Errorf(“insufficient value”) } // 转账事务 // 条件块 txn := etcd.Txn(ctx.TODO()).If( v3.Compare(v3.ModRevision(from), “=”, fromKV.ModRevision), v3.Compare(v3.ModRevision(to), “=”, toKV.ModRevision)) // 成功块 txn = txn.Then( OpPut(from, fromUint64(fromV - amount)), OpPut(to, fromUint64(toV + amount)) //提交事务 putresp, err := txn.Commit() // 检查事务的执行结果 if err != nil { return false, err } return putresp.Succeeded, nil } 虽然可以利用 etcd 实现事务操作，但是逻辑还是比较复杂的。所以 etcd 又在这些基础 API 上进行了封装，新增了一种叫做 STM 的操作，提供了更加便利的方法。要使用 STM，你需要先编写一个 apply 函数，这个函数的执行是在一个事务之中的：apply func(STM) error。这个方法包含一个 STM 类型的参数，它提供了对 key 值的读写操作。 STM 提供了 4 个方法，分别是 Get、Put、Receive 和 Delete，代码如下： type STM interface { Get(key ...string) string Put(key, val string, opts ...v3.OpOption) Rev(key string) int64 Del(key string) } 我们通过下面这个例子来看看如何使用 STM package main import ( \"context\" \"flag\" \"fmt\" \"log\" \"math/rand\" \"strings\" \"sync\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/clientv3/concurrency\" ) var ( addr = flag.String(\"addr\", \"http://127.0.0.1:2379\", \"etcd addresses\") ) func main() { flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, \",\") cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() // 设置5个账户，每个账号都有100元，总共500元 totalAccounts := 5 for i := 0; i \u003c totalAccounts; i++ { k := fmt.Sprintf(\"accts/%d\", i) if _, err = cli.Put(context.TODO(), k, \"100\"); err != nil { log.Fatal(err) } } // STM的应用函数，主要的事务逻辑 exchange := func(stm concurrency.STM) error { // 随机得到两个转账账号 from, to := rand.Intn(totalAccounts), rand.Intn(totalAccounts) if from == to { // 自己不和自己转账 return nil } // 读取账号的值 fromK, toK := fmt.Sprintf(\"accts/%d\", from), fmt.Sprintf(\"accts/%d\", to) fromV, toV := stm.Get(fromK), stm.Get(toK) fromInt, toInt := 0, 0 fmt.Sscanf(fromV, \"%d\", \u0026fromInt) fmt.Sscanf(toV, \"%d\", \u0026toInt) // 把源账号一半的钱转账给目标账号 xfer := fromInt / 2 fromInt, toInt = fromInt-xfer, toInt+xfer // 把转账后的值写回 stm.Put(fromK, fmt.Sprintf(\"%d\", fromInt)) stm.Put(toK, fmt.Sprintf(\"%d\", toInt)) return nil } // 启动10个goroutine进行转账操作 var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() for j := 0; j \u003c 100; j++ { if _, serr := concurrency.NewSTM(cli, exchange); serr != nil { log.Fatal(serr) } } }() } wg.Wait() // 检查账号最后的数目 sum := 0 accts, err := cli.Get(context.TODO(), \"accts/\", clientv3.WithPrefix()) // 得到所有账号 if err != nil { log.Fatal(err) } for _, kv := range accts.Kvs { // 遍历账号的值 v := 0 fmt.Sscanf(string(kv.Value), \"%d\", \u0026v) sum += v log.Printf(\"account %s: %d\", kv.Key, v) } log.Println(\"account sum is\", sum) // 总数 } 使用 etcd STM 的时候，我们只需要定义一个 apply 方法(上面的 exchange函数)，然后通过 concurrency.NewSTM(cli, exchange)，就可以完成转账事务的执行了。总结一下，当你利用 etcd 做存储时，是可以利用 STM 实现事务操作的，一个事务可以包含多个账号的数据更改操作，事务能够保证这些更改要么全成功，要么全失败。 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:3:1","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-20","objectID":"/posts/program/go/sync/go_sync_21/:4:0","tags":["go 并发"],"title":"go 分布式并发原语二","uri":"/posts/program/go/sync/go_sync_21/"},{"categories":["Go"],"content":"Leader 选举、互斥锁、读写锁","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"1. 分布式并发原语概述 在前面的课程里，我们学习的并发原语都是在进程内使用的，即一个运行程序为了控制共享资源、实现任务编排和进行消息传递而提供的控制类型。布式的并发原语实现更加复杂，因为在分布式环境中，网络不可靠、时钟不一致、以及不可预测的程序暂停，使得节点之间的通信相对于内存具有非常的不确定性。不过还好有相应的软件系统去做这些事情。这些软件系统会专门去处理这些节点之间的协调和异常情况，并且保证数据的一致性。我们要做的就是在它们的基础上实现我们的业务。etcd 就提供了非常好的分布式并发原语，比如分布式互斥锁、分布式读写锁、Leader 选举，等等。所以，今天，我就以 etcd 为基础，给你介绍几种分布式并发原语。 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:1:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"2. etcd 单节点集群安装 etcd 集群的安装配置参考其官方文档。本地独立集群的安装如下: yum install etcd etcd -listen-client-urls=http://192.168.108.55:2379 --advertise-client-urls=http://192.168.108.55:2379 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:2:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"2.1 etcd go 模块安装 # 1. 安装 gRPC go get -u google.golang.org/grpc go get github.com/grpc-ecosystem/go-grpc-middleware ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:2:1","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"3. Leader 选举 Leader 选举常常用在主从架构的系统中。主从架构中的服务节点分为主（Leader、Master）和从（Follower、Slave）两种角色，实际节点包括 1 主 n 从，一共是 n+1 个节点。主节点常常执行写操作，从节点常常执行读操作，如果读写都在主节点，从节点只是提供一个备份功能的话，那么，主从架构就会退化成主备模式架构。 主从架构中最重要的是如何确定节点的角色，在同一时刻，系统中不能有两个主节点，否则，如果两个节点都是主，都执行写操作的话，就有可能出现数据不一致的情况，所以，我们需要一个选主机制，选择一个节点作为主节点，这个过程就是 Leader 选举。当主节点宕机或者是不可用时，就需要新一轮的选举，从其它的从节点中选择出一个节点，让它作为新主节点，宕机的原主节点恢复后，可以变为从节点，或者被摘掉。 接下来，我们将介绍业务开发中跟 Leader 选举相关的选举、查询、Leader 变动监控等功能。 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:3:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"3.1 选举 如果业务集群还没有主节点，或者主节点宕机了，就需要发起新一轮的选主操作，主要会用到 Campaign 和 Proclaim。如果你需要主节点放弃主的角色，让其它从节点有机会成为主节点，就可以调用 Resign 方法。 Campaign: 作用：把一个节点选举为主节点，并且会设置一个值 签名: func (e *Election) Campaign(ctx context.Context, val string) error 说明: 这是一个阻塞方法，在调用它的时候会被阻塞，直到满足下面的三个条件之一，才会取消阻塞 成功当选为主； 此方法返回错误； ctx 被取消 Proclaim: 作用: 重新设置 Leader 的值，但是不会重新选主 返回: 新值设置成功或者失败的信息 签名: func (e *Election) Proclaim(ctx context.Context, val string) error Resign: 作用: 开始新一次选举 返回: 新的选举成功或者失败的信息 签名: func (e *Election) Resign(ctx context.Context) (err error) ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:3:1","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"3.2 查询 程序在启动的过程中，或者在运行的时候，还有可能需要查询当前的主节点是哪一个节点？主节点的值是什么？此外查询主节点以便把读写请求发往相应的主从节点上。etcd 提供了查询当前主几点的 Leader 的方法 Leader: 作用：查询当前的主节点 返回: 如果当前还没有 Leader，就返回一个错误 签名: func (e *Election) Leader(ctx context.Context) (*v3.GetResponse, error) Rev: 作用: 查询版本号信息 说明: 每次主节点的变动都会生成一个新的版本号 签名: func (e *Election) Rev() int64 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:3:2","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"3.3 监控 有了选举和查询方法，我们还需要一个监控方法。毕竟，如果主节点变化了，我们需要得到最新的主节点信息。我们可以通过 Observe 来监控主的变化： Observe 作用: 监控主节点的变化 签名: func (e *Election) Observe(ctx context.Context) \u003c-chan v3.GetResponse 返回: 一个 chan，显示主节点的变动信息，它不会返回主节点的全部历史变动信息，而是只返回最近的一条变动信息以及之后的变动信息。 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:3:3","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"3.4 使用示例 package main import ( \"bufio\" \"context\" \"flag\" \"fmt\" \"log\" \"os\" \"strings\" \"go.etcd.io/etcd/client/v3/concurrency\" \"go.etcd.io/etcd/clientv3\" ) var ( nodeID = flag.Int(\"id\", 0, \"node ID\") addr = flag.String(\"addr\", \"http://192.168.108.55:2379\", \"etcd address\") electName = flag.String(\"name\", \"my-test-elect\", \"election name\") count int ) func main() { endpoints := strings.Split(*addr, \",\") cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() session, err := concurrency.NewSession(cli) defer session.Close() el := concurrency.NewElection(session, *electName) consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() { action := consolescanner.Text() switch action { case \"elect\": go elect(el, *electName) case \"proclaim\": proclaim(el, *electName) case \"resign\": resign(el, *electName) case \"watch\": go watch(el, *electName) case \"query\": query(el, *electName) case \"rev\": rev(el, *electName) default: fmt.Println(\"unkonw error\") } } } // 选主 func elect(e1 *concurrency.Election, electName string) { log.Println(\"acampaigning for ID:\", *nodeID) // 调用Campaign方法选主,主的值为value-\u003c主节点ID\u003e-\u003ccount\u003e if err := e1.Campaign(context.Background(), fmt.Sprintf(\"value-%d-%d\", *nodeID, count)); err != nil { log.Println(err) } log.Println(\"campaigned for ID:\", *nodeID) count++ } // 为主设置新值 func proclaim(e1 *concurrency.Election, electName string) { log.Println(\"proclaiming for ID:\", *nodeID) // 调用Proclaim方法设置新值,新值为value-\u003c主节点ID\u003e-\u003ccount\u003e if err := e1.Proclaim(context.Background(), fmt.Sprintf(\"value-%d-%d\", *nodeID, count)); err != nil { log.Println(err) } log.Println(\"proclaimed for ID:\", *nodeID) count++ } // 重新选主，有可能另外一个节点被选为了主 func resign(e1 *concurrency.Election, electName string) { log.Println(\"resigning for ID:\", *nodeID) // 调用Resign重新选主 if err := e1.Resign(context.TODO()); err != nil { log.Println(err) } log.Println(\"resigned for ID:\", *nodeID) } // 查询主的信息 func query(e1 *concurrency.Election, electName string) { // 调用Leader返回主的信息，包括key和value等信息 resp, err := e1.Leader(context.Background()) if err != nil { log.Printf(\"failed to get the current leader: %v\", err) } log.Println(\"current leader:\", string(resp.Kvs[0].Key), string(resp.Kvs[0].Value)) } // 可以直接查询主的rev信息 func rev(e1 *concurrency.Election, electName string) { rev := e1.Rev() log.Println(\"current rev:\", rev) } // 监控主节点的变化 func watch(e1 *concurrency.Election, electName string) { ch := e1.Observe(context.TODO()) log.Println(\"start to watch for ID:\", *nodeID) for i := 0; i \u003c 10; i++ { resp := \u003c-ch log.Println(\"leader changed to\", string(resp.Kvs[0].Key), string(resp.Kvs[0].Value)) } } ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:3:4","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"4. 互斥锁 前面说的互斥锁都是用来保护同一进程内的共享资源的，今天我们要重点学习下分布在不同机器中的不同进程内的 goroutine，如何利用分布式互斥锁来保护共享资源。 互斥锁的应用场景和主从架构的应用场景不太一样。使用互斥锁的不同节点是没有主从这样的角色的，所有的节点都是一样的，只不过在同一时刻，只允许其中的一个节点持有锁。 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:4:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"4.1 Locker etcd 提供了一个简单的 Locker 原语，它类似于 Go 标准库中的 sync.Locker 接口，也提供了 Lock/UnLock 的机制： func NewLocker(s *Session, pfx string) sync.Locker 下面的代码是一个使用 Locker 并发原语的例子： package main import ( \"flag\" \"log\" \"math/rand\" \"strings\" \"time\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/clientv3/concurrency\" ) var ( addr = flag.String(\"addr\", \"http://127.0.0.1:2379\", \"etcd addresses\") lockName = flag.String(\"name\", \"my-test-lock\", \"lock name\") ) func main() { flag.Parse() rand.Seed(time.Now().UnixNano()) // etcd地址 endpoints := strings.Split(*addr, \",\") // 生成一个etcd client cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() useLock(cli) // 测试锁 } func useLock(cli *clientv3.Client) { // 为锁生成session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() //得到一个分布式锁 locker := concurrency.NewLocker(s1, *lockName) // 请求锁 log.Println(\"acquiring lock\") locker.Lock() log.Println(\"acquired lock\") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(30)) * time.Second) locker.Unlock() // 释放锁 log.Println(\"released lock\") } ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:4:1","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"4.2 Mutex Locker 是基于 Mutex 实现的，只不过，Mutex 提供了查询 Mutex 的 key 的信息的功能 func useMutex(cli *clientv3.Client) { // 为锁生成session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, *lockName) //在请求锁之前查询key log.Printf(\"before acquiring. key: %s\", m1.Key()) // 请求锁 log.Println(\"acquiring lock\") if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err) } log.Printf(\"acquired lock. key: %s\", m1.Key()) //等待一段时间 time.Sleep(time.Duration(rand.Intn(30)) * time.Second) // 释放锁 if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } log.Println(\"released lock\") } 可以看到，Mutex 并没有实现 sync.Locker 接口，它的 Lock/Unlock 方法需要提供一个 context.Context 实例做参数，这也就意味着，在请求锁的时候，你可以设置超时时间，或者主动取消请求。 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:4:2","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"5. 读写锁 etcd 也提供了分布式的读写锁。不过，互斥锁 Mutex 是在 github.com/coreos/etcd/clientv3/concurrency 包中提供的，读写锁 RWMutex 却是在 github.com/coreos/etcd/contrib/recipes 包中提供的。 etcd 提供的分布式读写锁的功能和标准库的读写锁的功能是一样的。只不过，etcd 提供的读写锁，可以在分布式环境中的不同的节点使用。它提供的方法也和标准库中的读写锁的方法一致，分别提供了 RLock/RUnlock、Lock/Unlock 方法。 package main import ( \"bufio\" \"flag\" \"fmt\" \"log\" \"math/rand\" \"os\" \"strings\" \"time\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/clientv3/concurrency\" recipe \"github.com/coreos/etcd/contrib/recipes\" ) var ( addr = flag.String(\"addr\", \"http://127.0.0.1:2379\", \"etcd addresses\") lockName = flag.String(\"name\", \"my-test-lock\", \"lock name\") action = flag.String(\"rw\", \"w\", \"r means acquiring read lock, w means acquiring write lock\") ) func main() { flag.Parse() rand.Seed(time.Now().UnixNano()) // 解析etcd地址 endpoints := strings.Split(*addr, \",\") // 创建etcd的client cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } defer cli.Close() // 创建session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := recipe.NewRWMutex(s1, *lockName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() { action := consolescanner.Text() switch action { case \"w\": // 请求写锁 testWriteLocker(m1) case \"r\": // 请求读锁 testReadLocker(m1) default: fmt.Println(\"unknown action\") } } } func testWriteLocker(m1 *recipe.RWMutex) { // 请求写锁 log.Println(\"acquiring write lock\") if err := m1.Lock(); err != nil { log.Fatal(err) } log.Println(\"acquired write lock\") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(10)) * time.Second) // 释放写锁 if err := m1.Unlock(); err != nil { log.Fatal(err) } log.Println(\"released write lock\") } func testReadLocker(m1 *recipe.RWMutex) { // 请求读锁 log.Println(\"acquiring read lock\") if err := m1.RLock(); err != nil { log.Fatal(err) } log.Println(\"acquired read lock\") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(10)) * time.Second) // 释放写锁 if err := m1.RUnlock(); err != nil { log.Fatal(err) } log.Println(\"released read lock\") } ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:5:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-19","objectID":"/posts/program/go/sync/go_sync_20/:6:0","tags":["go 并发"],"title":"go 分布式并发原语一","uri":"/posts/program/go/sync/go_sync_20/"},{"categories":["Go"],"content":"go 分组操作的并发控制","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"1. 分组操作概述 共享资源保护、任务编排和消息传递是 Go 并发编程中常见的场景，而分组执行一批相同的或类似的任务则是任务编排中一类情形，本节我们来介绍一下分组编排的一些常见场景和并发原语，包括: ErrGroup gollback Hunch schedgroup 这些分组执行的并发原语相比于 WaitGroup 目的是为了增加获取子任务的错误信息，以及子任务的并发数。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:1:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2. ErrGroup ErrGroup: 包位置: golang.org/x/sync/errgroup 适用场景: 将一个通用的父任务拆成几个小任务并发执行的场景 底层实现: 基于 WaitGroup 提供功能: 和 Context 集成 error 向上传播，可以把子任务的错误传递给 Wait 的调用者 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2.1 ErrGroup 实现 package errgroup import ( \"context\" \"sync\" ) // A Group is a collection of goroutines working on subtasks that are part of // the same overall task. // // A zero Group is valid and does not cancel on error. type Group struct { cancel func() wg sync.WaitGroup errOnce sync.Once err error } // WithContext returns a new Group and an associated Context derived from ctx. // // The derived Context is canceled the first time a function passed to Go // returns a non-nil error or the first time Wait returns, whichever occurs // first. func WithContext(ctx context.Context) (*Group, context.Context) { ctx, cancel := context.WithCancel(ctx) return \u0026Group{cancel: cancel}, ctx } // Wait blocks until all function calls from the Go method have returned, then // returns the first non-nil error (if any) from them. func (g *Group) Wait() error { g.wg.Wait() if g.cancel != nil { g.cancel() } return g.err } // Go calls the given function in a new goroutine. // // The first call to return a non-nil error cancels the group; its error will be // returned by Wait. func (g *Group) Go(f func() error) { g.wg.Add(1) go func() { defer g.wg.Done() if err := f(); err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel() } }) } }() } ErrGroup 有三个方法分别是 WithContext、Go 和 Wait。 WithContext: 作用: 创建一个 Group 对象 签名: func WithContext(ctx context.Context) (*Group, context.Context) 返回: Group 实例和使用 context.WithCancel(ctx) 生成的新 Context，一旦有一个子任务返回错误，或者 Wait 调用返回，新的 Context 就会被 cancel 注意: Group 的零值也是合法的，只不过，你就没有一个可以监控是否 cancel 的 Context 了 如果传递给 WithContext 的 ctx 参数，是一个可以 cancel 的 Context 的话，那么，它被 cancel 的时候，并不会终止正在执行的子任务 Go 方法: 作用: 执行子任务 签名: func (g *Group) Go(f func() error) 执行: 子任务函数 f 是类型为 func() error 的函数，如果任务执行成功，就返回 nil，否则就返回 error，并且会 cancel 那个新的 Context 注意: 可能有多个子任务执行失败返回 error，Wait 方法只会返回第一个错误，所以，如果想返回所有的错误，需要特别的处理 处理方式是使用全局的 result slice 保存子任务的执行结果 Wait: 作用: 所有的子任务都完成后，它才会返回，否则只会阻塞等待 签名: func (g *Group) Wait() error 返回: 如果有多个子任务返回错误，它只会返回第一个出现的错误，如果所有的子任务都执行成功，就返回 nil 说明: 要获取所有任务返回的 error，可以使用一个 result slice 保存子任务的执行结果 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:1","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2.2 使用示例 使用 20 goroutine 计算传入目录下所有文件的 md5 值: package main import ( \"context\" \"crypto/md5\" \"fmt\" \"io/ioutil\" \"log\" \"os\" \"path/filepath\" \"golang.org/x/sync/errgroup\" ) // Pipeline demonstrates the use of a Group to implement a multi-stage // pipeline: a version of the MD5All function with bounded parallelism from // https://blog.golang.org/pipelines. func main() { m, err := MD5All(context.Background(), \".\") if err != nil { log.Fatal(err) } for k, sum := range m { fmt.Printf(\"%s:\\t%x\\n\", k, sum) } } type result struct { path string sum [md5.Size]byte } // MD5All reads all the files in the file tree rooted at root and returns a map // from file path to the MD5 sum of the file's contents. If the directory walk // fails or any read operation fails, MD5All returns an error. func MD5All(ctx context.Context, root string) (map[string][md5.Size]byte, error) { // ctx is canceled when g.Wait() returns. When this version of MD5All returns // - even in case of error! - we know that all of the goroutines have finished // and the memory they were using can be garbage-collected. g, ctx := errgroup.WithContext(ctx) paths := make(chan string) // 文件路径channel // 1. 遍历目录下的所有文件，发送到 channel paths 中 g.Go(func() error { defer close(paths) return filepath.Walk(root, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if !info.Mode().IsRegular() { return nil } select { case paths \u003c- path: case \u003c-ctx.Done(): return ctx.Err() } return nil }) }) // 启动20个goroutine执行计算md5的任务，计算的文件由上一阶段的文件遍历子任务生成. c := make(chan result) const numDigesters = 20 for i := 0; i \u003c numDigesters; i++ { g.Go(func() error { for path := range paths { data, err := ioutil.ReadFile(path) if err != nil { return err } select { case c \u003c- result{path, md5.Sum(data)}: case \u003c-ctx.Done(): return ctx.Err() } } return nil }) } go func() { g.Wait() // 20个goroutine以及遍历文件的goroutine都执行完 close(c) }() m := make(map[string][md5.Size]byte) for r := range c { m[r.path] = r.sum } // Check whether any of the goroutines failed. Since g is accumulating the // errors, we don't need to send them (or check for them) in the individual // results sent on the channel. // 再次调用Wait，依然可以得到group的error信息 if err := g.Wait(); err != nil { return nil, err } return m, nil } 通过这个例子，你可以学习到多阶段 pipeline 的实现（这个例子是遍历文件夹和计算 md5 两个阶段），还可以学习到如何控制执行子任务的 goroutine 数量。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:2","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2.3 bilibili ErrGroup 扩展 如果我们无限制地直接调用 ErrGroup 的 Go 方法，就可能会创建出非常多的 goroutine，太多的 goroutine 会带来调度和 GC 的压力，就像go#34457指出的那样，当前 Go 运行时创建的 g 对象只会增长和重用，不会回收，所以在高并发的情况下，也要尽可能减少 goroutine 的使用。 常用的一个手段就是使用 worker pool(goroutine pool)，或者是类似containerd/stargz-snapshotter的方案，使用前面我们讲的信号量，信号量的资源的数量就是可以并行的 goroutine 的数量。 bilibili 实现了一个扩展的 ErrGroup bilibili/errgroup，可以使用一个固定数量的 goroutine 处理子任务。如果不设置 goroutine 的数量，那么每个子任务都会比较“放肆地”创建一个 goroutine 并发执行。 除了可以控制并发 goroutine 的数量，它还提供了 2 个功能： cancel，失败的子任务可以 cancel 所有正在执行任务； recover，而且会把 panic 的堆栈信息放到 error 中，避免子任务 panic 导致的程序崩溃。 是，有一点不太好的地方就是，一旦你设置了并发数，超过并发数的子任务需要等到调用者调用 Wait 之后才会执行，而不是只要 goroutine 空闲下来，就去执行。如果不注意这一点的话，可能会出现子任务不能及时处理的情况，这是这个库可以优化的一点。 另外，这个库其实是有一个并发问题的。在高并发的情况下，如果任务数大于设定的 goroutine 的数量，并且这些任务被集中加入到 Group 中，这个库的处理方式是把子任务加入到一个数组中，但是，这个数组不是线程安全的，有并发问题，问题就在于，下面图片中的标记为 96 行的那一行，这一行对 slice 的 append 操作不是线程安全的： 我们可以写一个简单的测试程序，运行这个程序的话，你就会发现死锁问题 package main import ( \"context\" \"fmt\" \"sync/atomic\" \"time\" \"github.com/bilibili/kratos/pkg/sync/errgroup\" ) func main() { var g errgroup.Group g.GOMAXPROCS(1) // 只使用一个goroutine处理子任务 var count int64 g.Go(func(ctx context.Context) error { time.Sleep(time.Second) //睡眠5秒，把这个goroutine占住 return nil }) total := 10000 for i := 0; i \u003c total; i++ { // 并发一万个goroutine执行子任务，理论上这些子任务都会加入到Group的待处理列表中 go func() { g.Go(func(ctx context.Context) error { atomic.AddInt64(\u0026count, 1) return nil }) }() } // 等待所有的子任务完成。理论上10001个子任务都会被完成 if err := g.Wait(); err != nil { panic(err) } got := atomic.LoadInt64(\u0026count) if got != int64(total) { panic(fmt.Sprintf(\"expect %d but got %d\", total, got)) } } bilibili errgroup 源码如下 // Copyright 2016 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package errgroup provides synchronization, error propagation, and Context // cancelation for groups of goroutines working on subtasks of a common task. package errgroup import ( \"context\" \"fmt\" \"runtime\" \"sync\" ) // A Group is a collection of goroutines working on subtasks that are part of // the same overall task. // // A zero Group is valid and does not cancel on error. type Group struct { err error wg sync.WaitGroup errOnce sync.Once workerOnce sync.Once ch chan func(ctx context.Context) error chs []func(ctx context.Context) error ctx context.Context cancel func() } // WithContext create a Group. // given function from Go will receive this context, func WithContext(ctx context.Context) *Group { return \u0026Group{ctx: ctx} } // WithCancel create a new Group and an associated Context derived from ctx. // // given function from Go will receive context derived from this ctx, // The derived Context is canceled the first time a function passed to Go // returns a non-nil error or the first time Wait returns, whichever occurs // first. func WithCancel(ctx context.Context) *Group { ctx, cancel := context.WithCancel(ctx) return \u0026Group{ctx: ctx, cancel: cancel} } func (g *Group) do(f func(ctx context.Context) error) { ctx := g.ctx if ctx == nil { ctx = context.Background() } var err error defer func() { if r := recover(); r != nil { buf := make([]byte, 64\u003c\u003c10) buf = buf[:runtime.Stack(buf, false)] err = fmt.Errorf(\"errgroup: panic recovered: %s\\n%s\", r, buf) } if err != nil { g.errOnce.Do(func() { g.err = err if g.cancel != nil { g.cancel() } }) } g.wg.Done() }() err = f(ctx) } // GOMAXPROCS set max goroutine to work. func (g *Group) GOMAXPROCS(n int) { if n \u003c= 0 { panic(\"errgroup: GOMAXPROCS must great than 0\") } g.workerOnce.Do(func() { g.ch = make(chan func(context.Context) error, n) for i := 0; i \u003c n; i++ { go func() { for f := range g.ch { g.do(f) } }() } }) } // Go calls the given function in a new goroutine. // // The first call to return a non-nil error cancels the group; its error will be // returned by Wait. func (g *Group) Go(f func(ctx context.Context) error) { g.wg.Add(1) if g.ch != nil { select { case g.ch \u003c- f: default: g.chs = append(g.chs, f) } return } go g.do(f) } // Wait blocks until all functi","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:3","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2.4 neilotoole/errgroup 扩展 neilotoole/errgroup 是今年年中新出现的一个 ErrGroup 扩展库，它可以直接替换官方的 ErrGroup，方法都一样，原有功能也一样，只不过增加了可以控制并发 goroutine 的功能。它的方法集如下： type Group func WithContext(ctx context.Context) (*Group, context.Context) func WithContextN(ctx context.Context, numG, qSize int) (*Group, context.Context) func (g *Group) Go(f func() error) func (g *Group) Wait() error 新增加的方法 WithContextN，可以设置并发的 goroutine 数，以及等待处理的子任务队列的大小。当队列满的时候，如果调用 Go 方法，就会被阻塞，直到子任务可以放入到队列中才返回。如果你传给这两个参数的值不是正整数，它就会使用 runtime.NumCPU 代替你传入的参数。 neilotoole/errgroup 源码如下: // Package neilotoole/errgroup is an extension of the sync/errgroup // concept, and much of the code herein is descended from // or directly copied from that sync/errgroup code which // has this header comment: // // Copyright 2016 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. // Package errgroup is a drop-in alternative to sync/errgroup but // limited to N goroutines. In effect, neilotoole/errgroup is // sync/errgroup but with a worker pool of N goroutines. package errgroup import ( \"context\" \"runtime\" \"sync\" \"sync/atomic\" ) // A Group is a collection of goroutines working on subtasks that are part of // the same overall task. // // A zero Group is valid and does not cancel on error. // // This Group implementation differs from sync/errgroup in that instead // of each call to Go spawning a new Go routine, the f passed to Go // is sent to a queue channel (qCh), and is picked up by one of N // worker goroutines. The number of goroutines (numG) and the queue // channel size (qSize) are args to WithContextN. The zero Group and // the Group returned by WithContext both use default values (the value // of runtime.NumCPU) for the numG and qSize args. A side-effect of this // implementation is that the Go method will block while qCh is full: in // contrast, errgroup.Group's Go method never blocks (it always spawns // a new goroutine). type Group struct { cancel func() wg sync.WaitGroup errOnce sync.Once err error // numG is the maximum number of goroutines that can be started. numG int // qSize is the capacity of qCh, used for buffering funcs // passed to method Go. qSize int // qCh is the buffer used to hold funcs passed to method Go // before they are picked up by worker goroutines. qCh chan func() error // qMu protects qCh. qMu sync.Mutex // gCount tracks the number of worker goroutines. gCount int64 } // WithContext returns a new Group and an associated Context derived from ctx. // It is equivalent to WithContextN(ctx, 0, 0). func WithContext(ctx context.Context) (*Group, context.Context) { return WithContextN(ctx, 0, 0) // zero indicates default values } // WithContextN returns a new Group and an associated Context derived from ctx. // // The derived Context is canceled the first time a function passed to Go // returns a non-nil error or the first time Wait returns, whichever occurs // first. // // Param numG controls the number of worker goroutines. Param qSize // controls the size of the queue channel that holds functions passed // to method Go: while the queue channel is full, Go blocks. // If numG \u003c= 0, the value of runtime.NumCPU is used; if qSize is // also \u003c= 0, a qSize of runtime.NumCPU is used. func WithContextN(ctx context.Context, numG, qSize int) (*Group, context.Context) { ctx, cancel := context.WithCancel(ctx) return \u0026Group{cancel: cancel, numG: numG, qSize: qSize}, ctx } // Wait blocks until all function calls from the Go method have returned, then // returns the first non-nil error (if any) from them. func (g *Group) Wait() error { g.qMu.Lock() if g.qCh != nil { // qCh is typically initialized by the first call to method Go. // qCh can be nil if Wait is invoked before the first // call to Go, hence this check before we close qCh. close(g.qCh) } // Wait for the worker goroutines to finish. g.wg.Wait() // All of the worker goroutines have finished, // so it's safe to set qCh to nil. g.qCh = nil g","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:4","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"2.5 facebookgo/errgroup facebookgo/errgroup Facebook 提供的这个 ErrGroup，其实并不是对 Go 扩展库 ErrGroup 的扩展，而是对标准库 WaitGroup 的扩展。 标准库的 WaitGroup 只提供了 Add、Done、Wait 方法，而且 Wait 方法也没有返回子 goroutine 的 error。而 Facebook 提供的 ErrGroup 提供的 Wait 方法可以返回 error，而且可以包含多个 error。子任务在调用 Done 之前，可以把自己的 error 信息设置给 ErrGroup。接着，Wait 在返回的时候，就会把这些 error 信息返回给调用者。 type Group func (g *Group) Add(delta int) func (g *Group) Done() func (g *Group) Error(e error) // 设置 error 给 ErrorGroup，Wait 返回时会返回这些 error func (g *Group) Wait() error facebookgo/errgroup 源码如下: // Package errgroup provides a Group that is capable of collecting errors // as it waits for a collection of goroutines to finish. package errgroup import ( \"bytes\" \"sync\" ) // MultiError allows returning a group of errors as one error. type MultiError []error // Error returns a concatenated string of all contained errors. func (m MultiError) Error() string { l := len(m) if l == 0 { panic(\"MultiError with no errors\") } if l == 1 { panic(\"MultiError with only 1 error\") } var b bytes.Buffer b.WriteString(\"multiple errors: \") for i, e := range m { b.WriteString(e.Error()) if i != l-1 { b.WriteString(\" | \") } } return b.String() } // NewMultiError returns nil if all input errors passed in are nil. Otherwise, // it coalesces all input errors into a single error instance. Useful for // code like this: // // func doThisAndThat() error { // err1 := tryThis() // err2 := tryThat() // return errgroup.NewMultiError(err1, err2) // } // func NewMultiError(errs ...error) error { var multiErr MultiError for _, err := range errs { if err != nil { multiErr = append(multiErr, err) } } if len(multiErr) == 1 { return multiErr[0] } else if len(multiErr) \u003e 1 { return multiErr } return nil } // Group is similar to a sync.WaitGroup, but allows for collecting errors. // The collected errors are never reset, so unlike a sync.WaitGroup, this Group // can only be used _once_. That is, you may only call Wait on it once. type Group struct { wg sync.WaitGroup mu sync.Mutex errors MultiError } // Add adds delta, which may be negative. See sync.WaitGroup.Add documentation // for details. func (g *Group) Add(delta int) { g.wg.Add(delta) } // Done decrements the Group counter. func (g *Group) Done() { g.wg.Done() } // Error adds an error to return in Wait. The error must not be nil. func (g *Group) Error(e error) { if e == nil { panic(\"error must not be nil\") } g.mu.Lock() defer g.mu.Unlock() g.errors = append(g.errors, e) } // Wait blocks until the Group counter is zero. If no errors were recorded, it // returns nil. If one error was recorded, it returns it as is. If more than // one error was recorded it returns a MultiError which is a slice of errors. func (g *Group) Wait() error { g.wg.Wait() g.mu.Lock() defer g.mu.Unlock() errors := g.errors l := len(errors) if l == 0 { return nil } if l == 1 { return errors[0] } return errors } 下面这些并发原语都是控制一组子 goroutine 执行的面向特定场景的并发原语，当你遇见这些特定场景时，就可以参考这些库。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:2:5","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"3. go-pkgz/syncs go-pkgz/syncs 提供了两个 Group 并发原语，分别是 SizedGroup 和 ErrSizedGroup: ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:3:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"3.1 SizedGroup SizedGroup 内部是使用信号量和 WaitGroup 实现的，它通过信号量控制并发的 goroutine 数量，或者是不控制 goroutine 数量，只控制子任务并发执行时候的数量（通过）。 默认情况下，SizedGroup 控制的是子任务的并发数量，而不是 goroutine 的数量。在这种方式下，每次调用 Go 方法都不会被阻塞，而是新建一个 goroutine 去执行。如果想控制 goroutine 的数量，你可以使用 syncs.Preemptive 设置这个并发原语的可选项。如果设置了这个可选项，但在调用 Go 方法的时候没有可用的 goroutine，那么调用者就会等待，直到有 goroutine 可以处理这个子任务才返回，这个控制在内部是使用信号量实现的。 SizedGroup 使用示例 package main import ( \"context\" \"fmt\" \"sync/atomic\" \"time\" \"github.com/go-pkgz/syncs\" ) func main() { // 设置goroutine数是10 swg := syncs.NewSizedGroup(10) // swg := syncs.NewSizedGroup(10, syncs.Preemptive) var c uint32 // 执行1000个子任务，只会有10个goroutine去执行 for i := 0; i \u003c 1000; i++ { swg.Go(func(ctx context.Context) { time.Sleep(5 * time.Millisecond) atomic.AddUint32(\u0026c, 1) }) } // 等待任务完成 swg.Wait() // 输出结果 fmt.Println(c) } SizedGroup 实现 package syncs import ( \"context\" \"sync\" ) // SizedGroup has the same role as WaitingGroup but adds a limit of the amount of goroutines started concurrently. // Uses similar Go() scheduling as errgrp.Group, thread safe. // SizedGroup interface enforces constructor usage and doesn't allow direct creation of sizedGroup type SizedGroup struct { options wg sync.WaitGroup sema sync.Locker } // NewSizedGroup makes wait group with limited size alive goroutines func NewSizedGroup(size int, opts ...GroupOption) *SizedGroup { res := SizedGroup{sema: NewSemaphore(size)} res.options.ctx = context.Background() for _, opt := range opts { opt(\u0026res.options) } return \u0026res } // Go calls the given function in a new goroutine. // Every call will be unblocked, but some goroutines may wait if semaphore locked. func (g *SizedGroup) Go(fn func(ctx context.Context)) { canceled := func() bool { select { case \u003c-g.ctx.Done(): return true default: return false } } if canceled() { return } g.wg.Add(1) if g.preLock { g.sema.Lock() } go func() { defer g.wg.Done() if canceled() { return } if !g.preLock { g.sema.Lock() } fn(g.ctx) g.sema.Unlock() }() } // Wait blocks until the SizedGroup counter is zero. // See sync.WaitGroup documentation for more information. func (g *SizedGroup) Wait() { g.wg.Wait() } SizedGroup 使用到的信号量实现: package syncs import \"sync\" // Semaphore implementation, counted lock only. Implements sync.Locker interface, thread safe. type semaphore struct { sync.Locker ch chan struct{} } // NewSemaphore makes Semaphore with given capacity func NewSemaphore(capacity int) sync.Locker { if capacity \u003c= 0 { capacity = 1 } return \u0026semaphore{ch: make(chan struct{}, capacity)} } // Lock acquires semaphore, can block if out of capacity. func (s *semaphore) Lock() { s.ch \u003c- struct{}{} } // Unlock releases semaphore, can block if nothing acquired before. func (s *semaphore) Unlock() { \u003c-s.ch } ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:3:1","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"3.2 ErrSizedGroup ErrSizedGroup 为 SizedGroup 提供了 error 处理的功能，它的功能和 Go 官方扩展库的功能一样，就是等待子任务完成并返回第一个出现的 error。不过，它还提供了额外的功能 可以控制并发的 goroutine 数量，这和 SizedGroup 的功能一样 如果设置了 termOnError，子任务出现第一个错误的时候会 cancel Context，而且后续的 Go 调用会直接返回，Wait 调用者会得到这个错误，这相当于是遇到错误快速返回。如果没有设置 termOnError，Wait 会返回所有的子任务的错误 不过，ErrSizedGroup 和 SizedGroup 设计得不太一致的地方是，SizedGroup 可以把 Context 传递给子任务，这样可以通过 cancel 让子任务中断执行，但是 ErrSizedGroup 却没有实现。ErrsizedGroup 的实现类似，但是增加了收集 Error 的能力: ErrSizedGroup 实现 package syncs import ( \"fmt\" \"strings\" \"sync\" ) // ErrSizedGroup is a SizedGroup with error control. Works the same as errgrp.Group, i.e. returns first error. // Can work as regular errgrp.Group or with early termination. Thread safe. // ErrSizedGroup interface enforces constructor usage and doesn't allow direct creation of errSizedGroup type ErrSizedGroup struct { options wg sync.WaitGroup sema sync.Locker err *multierror errLock sync.RWMutex errOnce sync.Once } // NewErrSizedGroup makes wait group with limited size alive goroutines. // By default all goroutines will be started but will wait inside. For limited number of goroutines use Preemptive() options. // TermOnErr will skip (won't start) all other goroutines if any error returned. func NewErrSizedGroup(size int, options ...GroupOption) *ErrSizedGroup { res := ErrSizedGroup{ sema: NewSemaphore(size), err: new(multierror), } for _, opt := range options { opt(\u0026res.options) } return \u0026res } // Go calls the given function in a new goroutine. // The first call to return a non-nil error cancels the group if termOnError; its error will be // returned by Wait. If no termOnError all errors will be collected in multierror. func (g *ErrSizedGroup) Go(f func() error) { g.wg.Add(1) if g.preLock { g.sema.Lock() } go func() { defer g.wg.Done() // terminated will be true if any error happened before and g.termOnError terminated := func() bool { if !g.termOnError { return false } g.errLock.RLock() defer g.errLock.RUnlock() return g.err.errorOrNil() != nil } if terminated() { return // terminated due prev error, don't run anything in this group anymore } if !g.preLock { g.sema.Lock() } if err := f(); err != nil { g.errLock.Lock() g.err = g.err.append(err) g.errLock.Unlock() g.errOnce.Do(func() { // call context cancel once if g.cancel != nil { g.cancel() } }) } g.sema.Unlock() }() } // Wait blocks until all function calls from the Go method have returned, then // returns all errors (if any) wrapped with multierror from them. func (g *ErrSizedGroup) Wait() error { g.wg.Wait() if g.cancel != nil { g.cancel() } return g.err.errorOrNil() } type multierror struct { errors []error lock sync.Mutex } func (m *multierror) append(err error) *multierror { m.lock.Lock() m.errors = append(m.errors, err) m.lock.Unlock() return m } func (m *multierror) errorOrNil() error { m.lock.Lock() defer m.lock.Unlock() if len(m.errors) == 0 { return nil } return m } // Error returns multierror string func (m *multierror) Error() string { m.lock.Lock() defer m.lock.Unlock() if len(m.errors) == 0 { return \"\" } errs := []string{} for n, e := range m.errors { errs = append(errs, fmt.Sprintf(\"[%d] {%s}\", n, e.Error())) } return fmt.Sprintf(\"%d error(s) occurred: %s\", len(m.errors), strings.Join(errs, \", \")) } ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:3:2","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"4. gollback gollback也是用来处理一组子任务的执行的，不过它解决了 ErrGroup 收集子任务返回结果的痛点。它的方法会把结果和 error 信息都返回。 gollback 提供了如下三个方法: All, Race, Retry ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:4:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"4.1 All All: 签名: func All(ctx context.Context, fns ...AsyncFunc) ([]interface{}, []error) 执行: 它会等待所有的异步函数（AsyncFunc）都执行完才返回，而且返回结果的顺序和传入的函数的顺序保持一致。 返回: 第一个返回参数是子任务的执行结果，第二个参数是子任务执行时的错误信息 异步函数: type AsyncFunc func(ctx context.Context) (interface{}, error) ctx 会被传递给子任务。如果你 cancel 这个 ctx，可以取消子任务 package main import ( \"context\" \"errors\" \"fmt\" \"github.com/vardius/gollback\" \"time\" ) func main() { rs, errs := gollback.All( // 调用All方法 context.Background(), func(ctx context.Context) (interface{}, error) { time.Sleep(3 * time.Second) return 1, nil // 第一个任务没有错误，返回1 }, func(ctx context.Context) (interface{}, error) { return nil, errors.New(\"failed\") // 第二个任务返回一个错误 }, func(ctx context.Context) (interface{}, error) { return 3, nil // 第三个任务没有错误，返回3 }, ) fmt.Println(rs) // 输出子任务的结果 fmt.Println(errs) // 输出子任务的错误信息 } ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:4:1","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"4.2 Race Race: 签名: func Race(ctx context.Context, fns ...AsyncFunc) (interface{}, error) 返回: 跟 All 方法类似，只不过，在使用 Race 方法的时候，只要一个异步函数执行没有错误，就立马返回，而不会返回所有的子任务信息。如果所有的子任务都没有成功，就会返回最后一个 error 信息 注意: 如果有一个正常的子任务的结果返回，Race 会把传入到其它子任务的 Context cancel 掉，这样子任务就可以中断自己的执行 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:4:2","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"4.3 Retry Retry: 签名: func Retry(ctx context.Context, retires int, fn AsyncFunc) (interface{}, error) 作用: Retry 不是执行一组子任务，而是执行一个子任务 返回: 如果子任务执行失败，它会尝试一定的次数， 如果一直不成功 ，就会返回失败错误 如果执行成功，它会立即返回 如果 retires 等于 0，它会永远尝试，直到成功 package main import ( \"context\" \"errors\" \"fmt\" \"github.com/vardius/gollback\" \"time\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() // 尝试5次，或者超时返回 res, err := gollback.Retry(ctx, 5, func(ctx context.Context) (interface{}, error) { return nil, errors.New(\"failed\") }) fmt.Println(res) // 输出结果 fmt.Println(err) // 输出错误信息 } ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:4:3","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"4.4 gollback 实现 package gollback import ( \"context\" \"errors\" \"sync\" ) var ErrNoCallbacks = errors.New(\"no callback to run\") // AsyncFunc represents asynchronous function type AsyncFunc func(ctx context.Context) (interface{}, error) type response struct { res interface{} err error } // Race method returns a response as soon as one of the callbacks executes without an error, // otherwise last error is returned // will panic if context is nil func Race(ctx context.Context, fns ...AsyncFunc) (interface{}, error) { if ctx == nil { panic(\"nil context provided\") } if len(fns) == 0 { return nil, ErrNoCallbacks } ctx, cancel := context.WithCancel(ctx) defer cancel() out := make(chan *response, 1) defer close(out) responses := make(chan *response, len(fns)) defer close(responses) var responded bool var lock sync.Mutex var errCount int go func() { for { select { case \u003c-ctx.Done(): lock.Lock() if !responded { responded = true out \u003c- \u0026response{ err: ctx.Err(), } lock.Unlock() return } lock.Unlock() case r, more := \u003c-responses: lock.Lock() if !more || (!responded \u0026\u0026 r.err == nil) || (errCount == len(fns)) { responded = true out \u003c- r lock.Unlock() return } lock.Unlock() } } }() for _, fn := range fns { go func(f AsyncFunc) { var r response r.res, r.err = f(ctx) lock.Lock() defer lock.Unlock() if r.err != nil { errCount ++ } if !responded { responses \u003c- \u0026r } }(fn) } r := \u003c-out return r.res, r.err } // All method returns when all the callbacks passed as an iterable have finished, // returned responses and errors are ordered according to callback order // will panic if context is nil func All(ctx context.Context, fns ...AsyncFunc) ([]interface{}, []error) { if ctx == nil { panic(\"nil context provided\") } rs := make([]interface{}, len(fns)) errs := make([]error, len(fns)) var wg sync.WaitGroup wg.Add(len(fns)) for i, fn := range fns { go func(index int, f AsyncFunc) { defer wg.Done() var r response r.res, r.err = f(ctx) rs[index] = r.res errs[index] = r.err }(i, fn) } wg.Wait() return rs, errs } // Retry method retries callback given amount of times until it executes without an error, // when retries = 0 it will retry infinitely // will panic if context is nil func Retry(ctx context.Context, retires int, fn AsyncFunc) (interface{}, error) { if ctx == nil { panic(\"nil context provided\") } i := 1 for { select { case \u003c-ctx.Done(): return nil, ctx.Err() default: var r response r.res, r.err = fn(ctx) if r.err == nil || i == retires { return r.res, r.err } i++ } } } ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:4:4","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5. Hunch Hunch 提供的功能和 gollback 类似，不过它提供的方法更多包括: All Take Last Retry Waterfall 它定义了执行子任务的函数，这和 gollback 的 AyncFunc 是一样的： type Executable func(context.Context) (interface{}, error) ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.1 All All: 签名: func All(parentCtx context.Context, execs ...Executable) ([]interface{}, error) 作用: 传入一组可执行的函数（子任务），返回子任务的执行结果 区别: 和 gollback 的 All 方法不一样的是，一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:1","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.2 Take Take: 签名: func Take(parentCtx context.Context, num int, execs ...Executable) ([]interface{}, error) 作用: 可以指定 num 参数，只要有 num 个子任务正常执行完没有错误，这个方法就会返回这几个子任务的结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:2","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.3 Last Last: 签名: func Last(parentCtx context.Context, num int, execs ...Executable) ([]interface{}, error) 作用: 只返回最后 num 个正常执行的、没有错误的子任务的结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:3","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.4 Retry Retry: 签名: func Retry(parentCtx context.Context, retries int, fn Executable) (interface{}, error) 作用: 它的功能和 gollback 的 Retry 方法的功能一样，如果子任务执行出错，就会不断尝试，直到成功或者是达到重试上限。 如果达到重试上限，就会返回错误 如果 retries 等于 0，它会不断尝试 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:4","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.5 Waterfall Waterfall: 签名: func Waterfall(parentCtx context.Context, execs ...ExecutableInSequence) (interface{}, error) 作用: 它其实是一个 pipeline 的处理方式，所有的子任务都是串行执行的， 前一个子任务的执行结果会被当作参数传给下一个子任务，直到所有的任务都完成，返回最后的执行结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil Hunch 的源码如下: // Package hunch provides functions like: `All`, `First`, `Retry`, `Waterfall` etc., that makes asynchronous flow control more intuitive. package hunch import ( \"context\" \"fmt\" \"sort\" \"sync\" ) // Executable represents a singular logic block. // It can be used with several functions. type Executable func(context.Context) (interface{}, error) // ExecutableInSequence represents one of a sequence of logic blocks. type ExecutableInSequence func(context.Context, interface{}) (interface{}, error) // IndexedValue stores the output of Executables, // along with the index of the source Executable for ordering. type IndexedValue struct { Index int Value interface{} } // IndexedExecutableOutput stores both output and error values from a Excetable. type IndexedExecutableOutput struct { Value IndexedValue Err error } func pluckVals(iVals []IndexedValue) []interface{} { vals := []interface{}{} for _, val := range iVals { vals = append(vals, val.Value) } return vals } func sortIdxVals(iVals []IndexedValue) []IndexedValue { sorted := make([]IndexedValue, len(iVals)) copy(sorted, iVals) sort.SliceStable( sorted, func(i, j int) bool { return sorted[i].Index \u003c sorted[j].Index }, ) return sorted } // Take returns the first `num` values outputted by the Executables. func Take(parentCtx context.Context, num int, execs ...Executable) ([]interface{}, error) { execCount := len(execs) if num \u003e execCount { num = execCount } // Create a new sub-context for possible cancelation. ctx, cancel := context.WithCancel(parentCtx) defer cancel() output := make(chan IndexedExecutableOutput, 1) go runExecs(ctx, output, execs) fail := make(chan error, 1) success := make(chan []IndexedValue, 1) go takeUntilEnough(fail, success, min(len(execs), num), output) select { case \u003c-parentCtx.Done(): // Stub comment to fix a test coverage bug. return nil, parentCtx.Err() case err := \u003c-fail: cancel() if parentCtxErr := parentCtx.Err(); parentCtxErr != nil { return nil, parentCtxErr } return nil, err case uVals := \u003c-success: cancel() return pluckVals(uVals), nil } } func runExecs(ctx context.Context, output chan\u003c- IndexedExecutableOutput, execs []Executable) { var wg sync.WaitGroup for i, exec := range execs { wg.Add(1) go func(i int, exec Executable) { val, err := exec(ctx) if err != nil { output \u003c- IndexedExecutableOutput{ IndexedValue{i, nil}, err, } wg.Done() return } output \u003c- IndexedExecutableOutput{ IndexedValue{i, val}, nil, } wg.Done() }(i, exec) } wg.Wait() close(output) } func takeUntilEnough(fail chan error, success chan []IndexedValue, num int, output chan IndexedExecutableOutput) { uVals := make([]IndexedValue, num) enough := false outputCount := 0 for r := range output { if enough { continue } if r.Err != nil { enough = true fail \u003c- r.Err continue } uVals[outputCount] = r.Value outputCount++ if outputCount == num { enough = true success \u003c- uVals continue } } } // All returns all the outputs from all Executables, order guaranteed. func All(parentCtx context.Context, execs ...Executable) ([]interface{}, error) { // Create a new sub-context for possible cancelation. ctx, cancel := context.WithCancel(parentCtx) defer cancel() output := make(chan IndexedExecutableOutput, 1) go runExecs(ctx, output, execs) fail := make(chan error, 1) success := make(chan []IndexedValue, 1) go takeUntilEnough(fail, success, len(execs), output) select { case \u003c-parentCtx.Done(): // Stub comment to fix a test coverage bug. return nil, parentCtx.Err() case err := \u003c-fail: cancel() if parentCtxErr := parentCtx.Err(); parentCtxErr != nil { return nil, parentCtxErr } return nil, err case uVals := \u003c-success: cancel() return pluckVals(sortIdxVals(uVals)), nil } } /* Last returns the last `num` values outputted by the Executables. */ func ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:5","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"5.6 总结 gollback 和 Hunch 是属于同一类的并发原语，对一组子任务的执行结果，可以选择一个结果或者多个结果 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:5:6","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"6. schedgroup schedgroup 是一个和时间相关的处理一组 goroutine 的并发原语，是 Matt Layher 开发的 worker pool，可以指定任务在某个时间或者某个时间之后执行。他在 GopherCon Europe 2020 大会上专门介绍了这个并发原语：schedgroup: a timer-based goroutine concurrency primitive schedgroup 包含的方法如下： type Group func New(ctx context.Context) *Group func (g *Group) Delay(delay time.Duration, fn func()) func (g *Group) Schedule(when time.Time, fn func()) func (g *Group) Wait() error Delay 和 Schedule: 功能其实是一样的，都是用来指定在某个时间或者之后执行一个函数。 Wait: 会阻塞调用者，直到之前安排的所有子任务都执行完才返回。如果 Context 被取消，那么，Wait 方法会返回这个 cancel error 如果调用了 Wait 方法，你就不能再调用它的 Delay 和 Schedule 方法，否则会 panic。 Wait 方法只能调用一次，如果多次调用的话，就会 panic 你可能认为，简单地使用 timer 就可以实现这个功能。其实，如果只有几个子任务，使用 timer 不是问题，但一旦有大量的子任务，而且还要能够 cancel，那么，使用 timer 的话，CPU 资源消耗就比较大了。所以，schedgroup 在实现的时候，就使用 container/heap，按照子任务的执行时间进行排序，这样可以避免使用大量的 timer，从而提高性能。 sg := schedgroup.New(context.Background()) // 设置子任务分别在100、200、300之后执行 for i := 0; i \u003c 3; i++ { n := i + 1 sg.Delay(time.Duration(n)*100*time.Millisecond, func() { log.Println(n) //输出任务编号 }) } // 等待所有的子任务都完成 if err := sg.Wait(); err != nil { log.Fatalf(\"failed to wait: %v\", err) } schedgroup 源码如下: package schedgroup import ( \"container/heap\" \"context\" \"sync\" \"sync/atomic\" \"time\" ) // Although unnecessary, explicit break labels should be used in all select // statements in this package so that test coverage tools are able to identify // which cases have been triggered. // A Group is a goroutine worker pool which schedules tasks to be performed // after a specified time. A Group must be created with the New constructor. // Once Wait is called, New must be called to create a new Group to schedule // more tasks. type Group struct { // Atomics must come first per sync/atomic. waiting uint32 // Context/cancelation support. ctx context.Context cancel func() // Task runner and a heap of tasks to be run. wg sync.WaitGroup mu sync.Mutex tasks tasks // Signals for when a task is added and how many tasks remain on the heap. addC chan struct{} lenC chan int } // New creates a new Group which will use ctx for cancelation. If cancelation // is not a concern, use context.Background(). func New(ctx context.Context) *Group { // Monitor goroutine context and cancelation. mctx, cancel := context.WithCancel(ctx) g := \u0026Group{ ctx: ctx, cancel: cancel, addC: make(chan struct{}), lenC: make(chan int), } g.wg.Add(1) go func() { defer g.wg.Done() g.monitor(mctx) }() return g } // Delay schedules a function to run at or after the specified delay. Delay // is a convenience wrapper for Schedule which adds delay to the current time. // Specifying a negative delay will cause the task to be scheduled immediately. // // If Delay is called after a call to Wait, Delay will panic. func (g *Group) Delay(delay time.Duration, fn func()) { g.Schedule(time.Now().Add(delay), fn) } // Schedule schedules a function to run at or after the specified time. // Specifying a past time will cause the task to be scheduled immediately. // // If Schedule is called after a call to Wait, Schedule will panic. func (g *Group) Schedule(when time.Time, fn func()) { if atomic.LoadUint32(\u0026g.waiting) != 0 { panic(\"schedgroup: attempted to schedule task after Group.Wait was called\") } g.mu.Lock() defer g.mu.Unlock() heap.Push(\u0026g.tasks, task{ Deadline: when, Call: fn, }) // Notify monitor that a new task has been pushed on to the heap. select { case g.addC \u003c- struct{}{}: break default: break } } // Wait waits for the completion of all scheduled tasks, or for cancelation of // the context passed to New. Wait will only returns errors due to context // cancelation. If no context is associated the the Group, wait never returns // an error. // // Once Wait is called, any further calls to Delay or Schedule will panic. If // Wait is called more than once, Wait will panic. func (g *Group) Wait() error { if v := atomic.SwapUint32(\u0026g.waiting, 1); v != 0 { panic(\"schedgroup: multiple calls to Group.Wait\") } // Context cancelation takes priority. if err := g.ctx.Err(); err != nil { return err } // See if th","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:6:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"7. go-waitgroup go-waitgroup 是一个带并发控制的 waitGroup。功能上跟 SizedGroup 差不多，这里不再赘述。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:7:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"8. 个人理解 今天这篇文章，内容很多，看着有些乱，但是核心就是对分组执行的任务的并发控制。可以看成是对 WaitGroup 的扩展。扩展的点主要是针对 WaitGroup 的不足之处: 并发数没有控制，包括: go-waitgroup，SizedGroup，neilotoole/errgroup，Go 官方的 ErrGroup 无法收集子 goroutine 返回的错误，包括: facebookgo/errgroup，ErrSizedGroup 而 Hunch、gollback、schedgroup 则是对分组任务执行语义上的扩展: 等待全部执行完成，等待某一个执行完成，定时执行。 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:8:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-18","objectID":"/posts/program/go/sync/go_sync_19/:9:0","tags":["go 并发"],"title":"go 分组操作的并发控制","uri":"/posts/program/go/sync/go_sync_19/"},{"categories":["Go"],"content":"go CyclicBarrier 循环栅栏","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"1. CyclicBarrier 概述 CyclicBarrier 是一个可重用的栅栏并发原语，常常应用于重复进行一组 goroutine 同时执行的场景中。 CyclicBarrier允许一组 goroutine 彼此等待，到达一个共同的执行点。同时，因为它可以被重复使用，所以叫循环栅栏。具体的机制是，大家都在栅栏前等待，等全部都到齐了，就抬起栅栏放行。 ","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/:1:0","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"1.1 CyclicBarrier 与 WaitGroup 你可能会觉得，CyclicBarrier 和 WaitGroup 的功能有点类似，确实是这样。不过还是有区别的: CyclicBarrier 更适合用在“固定数量的 goroutine 等待同一个执行点”的场景中， 而且在放行 goroutine 之后，CyclicBarrier 可以重复利用， 不像 WaitGroup 重用的时候，必须小心翼翼避免 panic。 处理可重用的多 goroutine 等待同一个执行点的场景的时候，CyclicBarrier 和 WaitGroup 方法调用的对应关系如下： 如果使用 WaitGroup 实现的话，调用比较复杂，不像 CyclicBarrier 那么清爽。更重要的是，如果想重用 WaitGroup，你还要保证，将 WaitGroup 的计数值重置到 n 的时候不会出现并发问题。WaitGroup 更适合用在“一个 goroutine 等待一组 goroutine 到达同一个执行点”的场景中，或者是不需要重用的场景中。 ","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/:1:1","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"1.2 CyclicBarrier 使用 CyclicBarrier 有两个初始化方法： 第一个是 New 方法，它只需要一个参数，来指定循环栅栏参与者的数量； 第二个方法是 NewWithAction 它额外提供一个函数，可以在每一次到达执行点的时候执行一次 执行具体的时间点是在最后一个参与者到达之后，但是其它的参与者还未被放行之前。我们可以利用它，做放行之前的一些共享状态的更新等操作。 func New(parties int) CyclicBarrier func NewWithAction(parties int, barrierAction func() error) CyclicBarrier CyclicBarrier 是一个接口，定义的方法如下： type CyclicBarrier interface { // 等待所有的参与者到达，如果被ctx.Done()中断，会返回ErrBrokenBarrier Await(ctx context.Context) error // 重置循环栅栏到初始化状态。如果当前有等待者，那么它们会返回ErrBrokenBarrier Reset() // 返回当前等待者的数量 GetNumberWaiting() int // 参与者的数量 GetParties() int // 循环栅栏是否处于中断状态 IsBroken() bool } 循环栅栏的使用也很简单。循环栅栏的参与者只需调用 Await 等待，等所有的参与者都到达后，再执行下一步。当执行下一步的时候，循环栅栏的状态又恢复到初始的状态了，可以迎接下一轮同样多的参与者。下面是一个使用示例: 生产水原子，每生产一个水分子，就会打印出 HHO、HOH、OHH 三种形式的其中一种。 package water import ( \"context\" \"github.com/marusama/cyclicbarrier\" \"golang.org/x/sync/semaphore\" ) // 定义水分子合成的辅助数据结构 type H2O struct { semaH *semaphore.Weighted // 氢原子的信号量 semaO *semaphore.Weighted // 氧原子的信号量 b cyclicbarrier.CyclicBarrier // 循环栅栏，用来控制合成 } func New() *H2O { return \u0026H2O{ semaH: semaphore.NewWeighted(2), //氢原子需要两个 semaO: semaphore.NewWeighted(1), // 氧原子需要一个 b: cyclicbarrier.New(3), // 需要三个原子才能合成 } } func (h2o *H2O) hydrogen(releaseHydrogen func()) { h2o.semaH.Acquire(context.Background(), 1) releaseHydrogen() // 输出H h2o.b.Await(context.Background()) //等待栅栏放行 h2o.semaH.Release(1) // 释放氢原子空槽 } func (h2o *H2O) oxygen(releaseOxygen func()) { h2o.semaO.Acquire(context.Background(), 1) releaseOxygen() // 输出O h2o.b.Await(context.Background()) //等待栅栏放行 h2o.semaO.Release(1) // 释放氢原子空槽 } 下面是对应的单元测试 package water import ( \"math/rand\" \"sort\" \"sync\" \"testing\" \"time\" ) func TestWaterFactory(t *testing.T) { //用来存放水分子结果的channel var ch chan string releaseHydrogen := func() { ch \u003c- \"H\" } releaseOxygen := func() { ch \u003c- \"O\" } // 300个原子，300个goroutine,每个goroutine并发的产生一个原子 var N = 100 ch = make(chan string, N*3) h2o := New() // 用来等待所有的goroutine完成 var wg sync.WaitGroup wg.Add(N * 3) // 200个氢原子goroutine for i := 0; i \u003c 2*N; i++ { go func() { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) h2o.hydrogen(releaseHydrogen) wg.Done() }() } // 100个氧原子goroutine for i := 0; i \u003c N; i++ { go func() { time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) h2o.oxygen(releaseOxygen) wg.Done() }() } //等待所有的goroutine执行完 wg.Wait() // 结果中肯定是300个原子 if len(ch) != N*3 { t.Fatalf(\"expect %d atom but got %d\", N*3, len(ch)) } // 每三个原子一组，分别进行检查。要求这一组原子中必须包含两个氢原子和一个氧原子，这样才能正确组成一个水分子。 var s = make([]string, 3) for i := 0; i \u003c N; i++ { s[0] = \u003c-ch s[1] = \u003c-ch s[2] = \u003c-ch sort.Strings(s) water := s[0] + s[1] + s[2] if water != \"HHO\" { t.Fatalf(\"expect a water molecule but got %s\", water) } } } 如果你没有学习 CyclicBarrier，你可能只会想到，用 WaitGroup 来实现这个水分子制造工厂的例子。 type H2O struct { semaH *semaphore.Weighted semaO *semaphore.Weighted wg sync.WaitGroup //将循环栅栏替换成WaitGroup } func New() *H2O { var wg sync.WaitGroup wg.Add(3) return \u0026H2O{ semaH: semaphore.NewWeighted(2), semaO: semaphore.NewWeighted(1), wg: wg, } } func (h2o *H2O) hydrogen(releaseHydrogen func()) { h2o.semaH.Acquire(context.Background(), 1) releaseHydrogen() // 标记自己已达到，等待其它goroutine到达 h2o.wg.Done() h2o.wg.Wait() h2o.semaH.Release(1) } func (h2o *H2O) oxygen(releaseOxygen func()) { h2o.semaO.Acquire(context.Background(), 1) releaseOxygen() // 标记自己已达到，等待其它goroutine到达 h2o.wg.Done() h2o.wg.Wait() //都到达后重置wg h2o.wg.Add(3) h2o.semaO.Release(1) } 使用 WaitGroup 非常复杂，而且，重用和 Done 方法的调用有并发的问题，程序可能 panic，远远没有使用循环栅栏更加简单直接。 ","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/:1:2","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"1.3 CyclicBarrier 的实现 CyclicBarrier 的数据结构 // round type round struct { count int // count of goroutines for this roundtrip waitCh chan struct{} // wait channel for this roundtrip brokeCh chan struct{} // channel for isBroken broadcast isBroken bool // is barrier broken } // cyclicBarrier impl CyclicBarrier intf type cyclicBarrier struct { parties int barrierAction func() error lock sync.RWMutex round *round } // New initializes a new instance of the CyclicBarrier, specifying the number of parties. func New(parties int) CyclicBarrier { if parties \u003c= 0 { panic(\"parties must be positive number\") } return \u0026cyclicBarrier{ parties: parties, lock: sync.RWMutex{}, round: \u0026round{ waitCh: make(chan struct{}), brokeCh: make(chan struct{}), }, } } Await func (b *cyclicBarrier) Await(ctx context.Context) error { var ( ctxDoneCh \u003c-chan struct{} ) if ctx != nil { ctxDoneCh = ctx.Done() } // check if context is done select { case \u003c-ctxDoneCh: return ctx.Err() default: } b.lock.Lock() // check if broken if b.round.isBroken { b.lock.Unlock() return ErrBrokenBarrier } // increment count of waiters b.round.count++ // saving in local variables to prevent race waitCh := b.round.waitCh brokeCh := b.round.brokeCh count := b.round.count b.lock.Unlock() if count \u003e b.parties { panic(\"CyclicBarrier.Await is called more than count of parties\") } if count \u003c b.parties { // wait other parties select { case \u003c-waitCh: return nil case \u003c-brokeCh: return ErrBrokenBarrier case \u003c-ctxDoneCh: b.breakBarrier(true) return ctx.Err() } } else { // we are last, run the barrier action and reset the barrier if b.barrierAction != nil { err := b.barrierAction() if err != nil { b.breakBarrier(true) return err } } b.reset(true) return nil } } func (b *cyclicBarrier) reset(safe bool) { b.lock.Lock() defer b.lock.Unlock() if safe { // broadcast to pass waiting goroutines close(b.round.waitCh) } else if b.round.count \u003e 0 { b.breakBarrier(false) } // create new round b.round = \u0026round{ waitCh: make(chan struct{}), brokeCh: make(chan struct{}), } } func (b *cyclicBarrier) breakBarrier(needLock bool) { if needLock { b.lock.Lock() defer b.lock.Unlock() } if !b.round.isBroken { b.round.isBroken = true // broadcast close(b.round.brokeCh) } } ","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/:1:3","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-17","objectID":"/posts/program/go/sync/go_sync_18/:2:0","tags":["go 并发"],"title":"go CyclicBarrier 循环栅栏","uri":"/posts/program/go/sync/go_sync_18/"},{"categories":["Go"],"content":"go SingleFlight 请求合并","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"1. SingleFlight 栅栏概述 SingleFlight 的作用是将并发请求合并成一个请求，以减少对下层服务的压力。当多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果的时候，再把结果返回给这几个同时调用的 goroutine，这样可以减少并发调用的数量。 如果你学会了 SingleFlight，在面对秒杀等大并发请求的场景，而且这些请求都是读请求时，你就可以把这些请求合并为一个请求，这样，你就可以将后端服务的压力从 n 降到 1。尤其是在面对后端是数据库这样的服务的时候，采用 SingleFlight 可以极大地提高性能。 Go 标准库的代码中就有一个 SingleFlight 的实现，而扩展库中的 SingleFlight(golang.org/x/sync/singleflight) 就是在标准库的代码基础上改的，逻辑几乎一模一样。 ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:1:0","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"1.1 SingleFlight 与 Sync.Once 标准库中的 sync.Once 也可以保证并发的 goroutine 只会执行一次函数 f，那么，SingleFlight 和 sync.Once 有什么区别呢？ sync.Once 不是只在并发的时候保证只有一个 goroutine 执行函数 f，而是会保证永远只执行一次 SingleFlight 是每次调用都重新执行，并且在多个请求同时调用的时候只有一个执行。 它们两个面对的场景是不同的，sync.Once 主要是用在单次初始化场景中，而 SingleFlight 主要用在合并并发请求的场景中，尤其是缓存场景。 ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:1:1","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"2. 实现原理 SingleFlight 使用互斥锁 Mutex 和 Map 来实现。Mutex 提供并发时的读写保护，Map 用来保存同一个 key 的正在处理（in flight）的请求。SingleFlight 的数据结构是 Group，它提供了三个方法： import \"golang.org/x/sync/singleflight\" type Group func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) func (g *Group) DoChan(key string, fn func() (interface{}, error)) \u003c-chan Result func (g *Group) Forget(key string) Do： 这个方法执行一个函数，并返回函数执行的结果 需要提供一个 key，对于同一个 key，在同一时间只有一个在执行，同一个 key 并发的请求会等待。第一个执行的请求返回的结果，就是它的返回结果 函数 fn 是一个无参的函数，返回一个结果或者 error，而 Do 方法会返回函数执行的结果或者是 error shared 会指示 v 是否返回给多个请求。 DoChan： 类似 Do 方法，只不过是返回一个 chan，等 fn 函数执行完，产生了结果以后，就能从这个 chan 中接收这个结果 Forget： 告诉 Group 忘记这个 key 这样一来，之后这个 key 请求会执行 f，而不是等待前一个未完成的 fn 函数的结果 ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:2:0","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"2.1 辅助 call 对象 SingleFlight 定义一个辅助对象 call，这个 call 就代表正在执行 fn 函数的请求或者是已经执行完的请求。Group 代表 SingleFlight。 // 代表一个正在处理的请求，或者已经处理完的请求 type call struct { wg sync.WaitGroup // 这个字段代表处理完的值，在waitgroup完成之前只会写一次 // waitgroup完成之后就读取这个值 val interface{} err error // 指示当call在处理时是否要忘掉这个key forgotten bool dups int chans []chan\u003c- Result } // group代表一个singleflight对象 type Group struct { mu sync.Mutex // protects m m map[string]*call // lazily initialized } ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:2:1","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"2.2 Do 方法 我们只需要查看一个 Do 方法，DoChan 的处理方法是类似的。 func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok {//如果已经存在相同的key c.dups++ g.mu.Unlock() c.wg.Wait() //等待这个key的第一个请求完成 return c.val, c.err, true //使用第一个key的请求结果 } c := new(call) // 第一个请求，创建一个call c.wg.Add(1) g.m[key] = c //加入到key map中 g.mu.Unlock() g.doCall(c, key, fn) // 调用方法 return c.val, c.err, c.dups \u003e 0 } func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { c.val, c.err = fn() c.wg.Done() g.mu.Lock() // 在默认情况下，forgotten==false，所以第 8 行默认会被调用 // 也就是说，第一个请求完成后，后续的同一个 key 的请求又重新开始新一次的 fn 函数的调用 if !c.forgotten { // 已调用完，删除这个key delete(g.m, key) } for _, ch := range c.chans { ch \u003c- Result{c.val, c.err, c.dups \u003e 0} } g.mu.Unlock() } ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:2:2","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"3. 应用场景 Go 代码库中有两个地方用到了 SingleFlight: 第一个是在net/lookup.go中，如果同时有查询同一个 host 的请求，lookupGroup 会把这些请求 merge 到一起，只需要一个请求就可以了 第二个是 Go 在查询仓库版本信息时，将并发的请求合并成 1 个请求： func metaImportsForPrefix(importPrefix string, mod ModuleMode, security web.SecurityMode) (*urlpkg.URL, []metaImport, error) { // 使用缓存保存请求结果 setCache := func(res fetchResult) (fetchResult, error) { fetchCacheMu.Lock() defer fetchCacheMu.Unlock() fetchCache[importPrefix] = res return res, nil // 使用 SingleFlight请求 resi, _, _ := fetchGroup.Do(importPrefix, func() (resi interface{}, err error) { fetchCacheMu.Lock() // 如果缓存中有数据，那么直接从缓存中取 if res, ok := fetchCache[importPrefix]; ok { fetchCacheMu.Unlock() return res, nil } fetchCacheMu.Unlock() ...... 设计缓存问题时，我们常常需要解决缓存穿透、缓存雪崩和缓存击穿问题。缓存击穿问题是指，在平常高并发的系统中，大量的请求同时查询一个 key 时，如果这个 key 正好过期失效了，就会导致大量的请求都打到数据库上。这就是缓存击穿。用 SingleFlight 来解决缓存击穿问题再合适不过了。因为，这个时候，只要这些对同一个 key 的并发请求的其中一个到数据库中查询，就可以了，这些并发的请求可以共享同一个结果。因为是缓存查询，不用考虑幂等性问题。在 Go 生态圈知名的缓存框架 groupcache 中，就使用了较早的 Go 标准库的 SingleFlight 实现。 ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:3:0","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-16","objectID":"/posts/program/go/sync/go_sync_17/:4:0","tags":["go 并发"],"title":"go SingleFlight 请求合并","uri":"/posts/program/go/sync/go_sync_17/"},{"categories":["Go"],"content":"go 信号量","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1. 信号量概述 信号量（Semaphore）是用来控制多个 goroutine 同时访问多个资源的并发原语。最简单的信号量就是一个变量加一些并发控制的能力，更复杂的信号量类型，就是使用抽象数据类型代替变量，用来代表复杂的资源类型。实际上，大部分的信号量都使用一个整型变量来表示一组资源，并没有实现太复杂的抽象数据类型。 信号量这个并发原语在多资源共享的并发控制的场景中被广泛使用，有时候也会被 Channel 类型所取代，因为一个 buffered chan 也可以代表 n 个资源。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1.1 P/V 操作 信号量包含两个操作 P 和 V: P 操作（descrease、wait、acquire）是减少信号量的计数值 V 操作（increase、signal、release）是增加信号量的计数值 初始化信号量 S 有一个指定数量（n）的资源，它就像是一个有 n 个资源的池子。P 操作相当于请求资源，如果资源可用，就立即返回；如果没有资源或者不够，那么，它可以不断尝试或者阻塞等待。V 操作会释放自己持有的资源，把资源返还给信号量。信号量的值除了初始化的操作以外，只能由 P/V 操作改变。 所以信号量的实现包括： 初始化信号量：设定初始的资源的数量。 P 操作：将信号量的计数值减去 1，如果新值已经为负，那么调用者会被阻塞并加入到等待队列中，否则获取一个资源继续执行 V 操作：将信号量的计数值加 1，如果先前的计数值为负，就说明有等待的 P 操作的调用者。它会从等待队列中取出一个等待的调用者，唤醒它，让它继续执行。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:1","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1.2 信号量和互斥锁 信号量可以分为计数信号量（counting semaphre）和二进位信号量（binary semaphore）。在特殊的情况下，如果计数值只能是 0 或者 1，那么，这个信号量就是二进位信号量，提供了互斥的功能（要么是 0，要么是 1），所以，有时候互斥锁也会使用二进位信号量来实现。我们一般用信号量保护一组资源，如果信号量蜕变成二进位信号量，那么，它的 P/V 就和互斥锁的 Lock/Unlock 一样了。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:2","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1.3 Go 运行时实现 在运行时，Go 内部使用信号量来控制 goroutine 的阻塞和唤醒，在 Mutex 的实现上就使用了信号量 type Mutex struct { state int32 sema uint32 } // 信号量的 P/V 操作 func runtime_Semacquire(s *uint32) func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int) func runtime_Semrelease(s *uint32, handoff bool, skipframes int) 遗憾的是，它是 Go 运行时内部使用的，并没有封装暴露成一个对外的信号量并发原语，原则上我们没有办法使用。Go 在它的扩展包中提供了信号量semaphore，不过这个信号量的类型名并不叫 Semaphore，而是叫 Weighted。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:3","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1.4 Weighted type Weighted func NewWeighted(n int64) *Weighted func (s *Weighted) Acquire(ctx context.Context, n int64) error func (s *Weighted) Release(n int64) func (s *Weighted) TryAcquire(n int64) bool Acquire 方法： 相当于 P 操作，你可以一次获取多个资源，如果没有足够多的资源，调用者就会被阻塞 第一个参数是 Context，可以通过 Context 增加超时或者 cancel 的机制。如果是正常获取了资源，就返回 nil；否则，就返回 ctx.Err()，信号量不改变。 Release 方法：相当于 V 操作，可以将 n 个资源释放，返还给信号量。 TryAcquire 方法：尝试获取 n 个资源，但是它不会阻塞，要么成功获取 n 个资源，返回 true，要么一个也不获取，返回 false 下面是 Weighted 使用示例，我们创建和 CPU 核数一样多的 Worker，让它们去处理一个 4 倍数量的整数 slice。每个 Worker 一次只能处理一个整数，处理完之后，才能处理下一个。当然，这个问题的解决方案有很多种，这一次我们使用信号量，代码如下： import \"golang.org/x/sync/semaphore\" var ( maxWorkers = runtime.GOMAXPROCS(0) // worker数量 sema = semaphore.NewWeighted(int64(maxWorkers)) //信号量 task = make([]int, maxWorkers*4) // 任务数，是worker的四倍 ) func main() { ctx := context.Background() for i := range task { // 如果没有worker可用，会阻塞在这里，直到某个worker被释放 if err := sema.Acquire(ctx, 1); err != nil { break } // 启动worker goroutine go func(i int) { defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 }(i) } // 请求所有的worker,这样能确保前面的worker都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil { log.Printf(\"获取所有的worker失败: %v\", err) } fmt.Println(task) } 在这个例子中，还有一个值得我们学习的知识点，就是最后的那一段处理（第 25 行）。如果在实际应用中，你想等所有的 Worker 都执行完，就可以获取最大计数值的信号量。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:4","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"1.5 常见错误 在使用信号量时，最常见的几个错误如下： 请求了资源，但是忘记释放它； 释放了从未请求的资源； 长时间持有一个资源，即使不需要它； 不持有一个资源，却直接使用它。 不过，即使你规避了这些坑，在同时使用多种资源，不同的信号量控制不同的资源的时候，也可能会出现死锁现象，比如哲学家就餐问题。 就 Go 扩展库实现的信号量来说，在调用 Release 方法的时候，你可以传递任意的整数。但是，如果你传递一个比请求到的数量大的错误的数值，程序就会 panic。如果传递一个负数，会导致资源永久被持有。如果你请求的资源数比最大的资源数还大，那么，调用者可能永远被阻塞。 所以，使用信号量遵循的原则就是请求多少资源，就释放多少资源。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:1:5","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"2. semaphore/Weighted 实现 Go 扩展库中的信号量是使用互斥锁 +List 实现的。互斥锁实现其它字段的保护，而 List 实现了一个等待队列，等待者的通知是通过 Channel 的通知机制实现的。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:2:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"2.1 Weighted 数据结构 我们来看一下信号量 Weighted 的数据结构： type Weighted struct { size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，对字段的保护 waiters list.List // 等待队列 } ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:2:1","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"2.2 Acquire 方法 在信号量的几个实现方法里，Acquire 是代码最复杂的一个方法，它不仅仅要监控资源是否可用，而且还要检测 Context 的 Done 是否已关闭。 func (s *Weighted) Acquire(ctx context.Context, n int64) error { s.mu.Lock() // fast path, 如果有足够的资源，都不考虑ctx.Done的状态，将cur加上n就返回 if s.size-s.cur \u003e= n \u0026\u0026 s.waiters.Len() == 0 { s.cur += n s.mu.Unlock() return nil } // 如果是不可能完成的任务，请求的资源数大于能提供的最大的资源数 if n \u003e s.size { s.mu.Unlock() // 依赖ctx的状态返回，否则一直等待 \u003c-ctx.Done() return ctx.Err() } // 否则就需要把调用者加入到等待队列中 // 创建了一个ready chan,以便被通知唤醒 ready := make(chan struct{}) w := waiter{n: n, ready: ready} elem := s.waiters.PushBack(w) s.mu.Unlock() // 等待 select { case \u003c-ctx.Done(): // context的Done被关闭 err := ctx.Err() s.mu.Lock() select { case \u003c-ready: // 如果被唤醒了，忽略ctx的状态 err = nil default: 通知waiter isFront := s.waiters.Front() == elem s.waiters.Remove(elem) // 通知其它的waiters,检查是否有足够的资源 if isFront \u0026\u0026 s.size \u003e s.cur { s.notifyWaiters() } } s.mu.Unlock() return err case \u003c-ready: // 被唤醒了 return nil } } ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:2:2","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"2.3 Release Release 方法将当前计数值减去释放的资源数 n，并唤醒等待队列中的调用者，看是否有足够的资源被获取。 func (s *Weighted) Release(n int64) { s.mu.Lock() s.cur -= n if s.cur \u003c 0 { s.mu.Unlock() panic(\"semaphore: released more than held\") } s.notifyWaiters() s.mu.Unlock() } notifyWaiters 方法就是逐个检查等待的调用者，如果资源不够，或者是没有等待者了，就返回： func (s *Weighted) notifyWaiters() { for { next := s.waiters.Front() if next == nil { break // No more waiters blocked. } w := next.Value.(waiter) if s.size-s.cur \u003c w.n { //避免饥饿，这里还是按照先入先出的方式处理 break } s.cur += w.n s.waiters.Remove(next) close(w.ready) } } notifyWaiters 方法是按照先入先出的方式唤醒调用者。这样做的目的是避免饥饿，否则的话，资源可能总是被那些请求资源数小的调用者获取，这样一来，请求资源数巨大的调用者，就没有机会获得资源了。 2.4 总结 官方扩展的信号量最大的优势是可以一次获取多个资源。在批量获取资源的场景中，建议使用此官方扩展的信号量。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:2:3","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"3. Channel 实现的信号量 除了官方扩展库的实现，还有很多方法实现信号量，比较典型的就是使用 Channel 来实现。使用一个 buffer 为 n 的 Channel 很容易实现信号量: // Semaphore 数据结构，并且还实现了Locker接口 type semaphore struct { sync.Locker ch chan struct{} } // 创建一个新的信号量 func NewSemaphore(capacity int) sync.Locker { if capacity \u003c= 0 { capacity = 1 // 容量为1就变成了一个互斥锁 } return \u0026semaphore{ch: make(chan struct{}, capacity)} } // 请求一个资源 func (s *semaphore) Lock() { s.ch \u003c- struct{}{} } // 释放资源 func (s *semaphore) Unlock() { \u003c-s.ch } 官方的实现方式有这样一个功能：它可以一次请求多个资源，这是通过 Channel 实现的信号量所不具备的。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:3:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"4. 其他实现 除了 Channel，marusama/semaphore也实现了一个可以动态更改资源容量的信号量，也是一个非常有特色的实现。如果你的资源数量并不是固定的，而是动态变化的，可以考虑使用这个库。 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:4:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"5. 信号量 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:5:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-15","objectID":"/posts/program/go/sync/go_sync_16/:6:0","tags":["go 并发"],"title":"go 信号量","uri":"/posts/program/go/sync/go_sync_16/"},{"categories":["Go"],"content":"go 内存模型","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"1. Go 内存模型概述 Go 内存模型 描述的是并发环境中多 goroutine 读相同变量的时候，变量的可见性条件。具体点说，就是指，在什么条件下，goroutine 在读取一个变量的值的时候，能够看到其它 goroutine 对这个变量进行的写的结果。 由于 CPU 指令重排和多级 Cache 的存在，保证多核访问同一个变量这件事儿变得非常复杂。编程语言需要一个规范，来明确多线程同时访问同一个变量的可见性和顺序（ Russ Cox 在麻省理工学院 6.824 分布式系统 Distributed Systems 课程 的一课，专门介绍了相关的知识）。在编程语言中，这个规范被叫做内存模型。 为什么这些编程语言都要定义内存模型呢？在我看来，主要是两个目的。 向广大的程序员提供一种保证，以便他们在做设计和开发程序时，面对同一个数据同时被多个 goroutine 访问的情况，可以做一些串行化访问的控制，比如使用 Channel 或者 sync 包和 sync/atomic 包中的并发原语。 允许编译器和硬件对程序做一些优化。这一点其实主要是为编译器开发者提供的保证，这样可以方便他们对 Go 的编译器做优化。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:1:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"1.1 重排和可见性的问题 首先，我们要先弄明白重排和可见性的问题，因为它们影响着程序实际执行的顺序关系。 由于指令重排，代码并不一定会按照你写的顺序执行。举个例子: 当两个 goroutine 同时对一个数据进行读写时 假设 goroutine g1 对这个变量进行写操作 w，goroutine g2 同时对这个变量进行读操作 r， 如果 g2 在执行读操作 r 的时候，已经看到了 g1 写操作 w 的结果，那么，也不意味着 g2 能看到在 w 之前的其它的写操作 // 重排以及多核 CPU 并发执行导致程序的运行和代码的书写顺序不一样的情况 var a, b int func f() { a = 1 // w之前的写操作 b = 2 // 写操作w } func g() { // 即使这里打印出的值是 2，但是依然可能在打印 a 的值时，打印出初始值 0，而不是 1 // 因为，程序运行的时候，不能保证 g2 看到的 a 和 b 的赋值有先后关系。 print(b) // 读操作r print(a) // ??? } func main() { go f() //g1 g() //g2 } g() 函数内要打印 b 的值。需要注意的是，即使这里打印出的值是 2，但是依然可能在打印 a 的值时，打印出初始值 0，而不是 1。这是因为，程序运行的时候，不能保证 g2 看到的 a 和 b 的赋值有先后关系。 var a string var done bool func setup() { a = \"hello, world\" done = true } func main() { go setup() for !done { } print(a) } 在这段代码中，主 goroutine main 即使观察到 done 变成 true 了，最后读取到的 a 的值仍然可能为空。 更糟糕的情况是，main 根本就观察不到另一个 goroutine 对 done 的写操作，这就会导致 main 程序一直被 hang 住。甚至可能还会出现半初始化的情况，比如： type T struct { msg string } var g *T func setup() { t := new(T) t.msg = \"hello, world\" g = t } func main() { go setup() for g == nil { } print(g.msg) } 即使 main goroutine 观察到 g 不为 nil，也可能打印出空的 msg（第 17 行）。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:1:1","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"2. hanppen-before 刚刚说了，程序在运行的时候，两个操作的顺序可能不会得到保证，怎么办呢？接下来，我们要了解一下 Go 内存模型中很重要的一个概念：happens-before，这是用来描述两个时间的顺序关系的。如果某些操作能提供 happens-before 关系，那么，我们就可以 100% 保证它们之间的顺序。 在一个 goroutine 内部，程序的执行顺序和它们的代码指定的顺序是一样的，即使编译器或者 CPU 重排了读写顺序，从行为上来看，也和代码指定的顺序一样。 在下面的代码中，即使编译器或者 CPU 对 a、b、c 的初始化进行了重排，但是打印结果依然能保证是 1、2、3，而不会出现 1、0、0 或 1、0、1 等情况。 func foo() { var a = 1 var b = 2 var c = 3 println(a) println(b) println(c) } 但是，对于另一个 goroutine 来说，重排却会产生非常大的影响。因为 Go 只保证 goroutine 内部重排对读写的顺序没有影响。 如果两个 action（read 或者 write）有明确的 happens-before 关系，你就可以确定它们之间的执行顺序（或者是行为表现上的顺序）。Go 内存模型通过 happens-before 定义两个事件（读、写 action）的顺序： 如果事件 e1 happens before 事件 e2，那么，我们就可以说事件 e2 在事件 e1 之后发生（happens after）。 如果 e1 不是 happens before e2， 同时也不 happens after e2，那么，我们就可以说事件 e1 和 e2 是同时发生的。 如果要保证对“变量 v 的读操作 r”能够观察到一个对“变量 v 的写操作 w”，并且 r 只能观察到 w 对变量 v 的写，没有其它对 v 的写操作，也就是说，我们要保证 r 绝对能观察到 w 操作的结果，那么就需要同时满足两个条件： w happens before r； 其它对 v 的写操作（w2、w3、w4, …） 要么 happens before w，要么 happens after r，绝对不会和 w、r 同时发生，或者是在它们之间发生。 对于单个的 goroutine 来说，它有一个特殊的 happens-before 关系: 在单个的 goroutine 内部， happens-before 的关系和代码编写的顺序是一致的。即在 goroutine 内部对一个局部变量 v 的读，一定能观察到最近一次对这个局部变量 v 的写。如果要保证多个 goroutine 之间对一个共享变量的读写顺序，在 Go 语言中，可以使用并发原语为读写操作建立 happens-before 关系，这样就可以保证顺序了。 说到这儿，先补充三个 Go 语言中和内存模型有关的小知识: 在 Go 语言中对变量进行零值的初始化就是一个写操作。 如果对超过机器 word（64bit、32bit 或者其它）大小的值进行读写，那么，就可以看作是对拆成 word 大小的几个读写无序进行。 Go 并不提供直接的 CPU 屏障（CPU fence）来提示编译器或者 CPU 保证顺序性，而是使用不同架构的内存屏障指令来实现统一的并发原语。 接下来，我们就来学习 Go 语言中提供的 happens-before 关系保证，包括: init 函数 goroutine Channel Mutex/RWMutex WaitGroup Once ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:2:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"2. init 函数 应用程序的初始化是在单一的 goroutine 执行的。如果包 p 导入了包 q，那么，q 的 init 函数的执行一定 happens before p 的任何初始化代码。而main 函数一定在导入的包的 init 函数之后执行。 Go 采用依赖分析技术，确定包的初始化顺序: 包级别的变量在同一个文件中是按照声明顺序逐个初始化的，除非初始化它的时候依赖其它的变量 同一个包下的多个文件，会按照文件名的排列顺序进行初始化。这个顺序被定义在Go 语言规范中，而不是 Go 的内存模型规范中。 可以看看下面的例子中各个变量的值： var ( a = c + b // == 9 b = f() // == 4 c = f() // == 5 d = 3 // == 5 全部初始化完成后 ) func f() int { d++ return d } 依赖分析技术保证的顺序只是针对同一包下的变量，而且，只有引用关系是本包变量、函数和非接口的方法，才能保证它们的顺序性。下面举一个具体的例子，把这些内容串起来: 这个例子是一个 main 程序，它依赖包 p1，包 p1 依赖包 p2，包 p2 依赖 p3。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:3:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"3. goroutine 下面，我们再来看看 goroutine 对 happens-before 关系的保证情况。首先，我们需要明确一个规则： 启动 goroutine 的 go 语句的执行，一定 happens before 此 goroutine 内的代码执行。 根据这个规则，我们就可以知道，如果 go 语句传入的参数是一个函数执行的结果，那么，这个函数一定先于 goroutine 内部的代码被执行。 我们看下面这个例子: 第 8 行 a 的赋值和第 9 行的 go 语句是在同一个 goroutine 中执行的，所以，在主 goroutine 看来，第 8 行肯定 happens before 第 9 行 又由于刚才的保证，第 9 行子 goroutine 的启动 happens before 第 4 行的变量输出 我们就可以推断出，第 8 行 happens before 第 4 行。也就是说，在第 4 行打印 a 的值的时候，肯定会打印出“hello world” var a string func f() { print(a) // 4 } func hello() { a = \"hello, world\" // 8 go f() } 刚刚说的是启动 goroutine 的情况，goroutine 退出的时候，是没有任何 happens-before 保证的。所以，如果你想观察某个 goroutine 的执行效果，你需要使用同步机制建立 happens-before 关系，比如 Mutex 或者 Channel。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:4:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"4. channel 通用的 Channel happens-before 关系保证有 4 条规则，如下: 往 Channel 中的发送操作，happens before 从该 Channel 接收相应数据的动作完成之前，即第 n 个 send 一定 happens before 第 n 个 receive 的完成 对于 unbuffered 的 Channel，也就是容量是 0 的 Channel，从此 Channel 中读取数据的调用一定 happens before 往此 Channel 发送数据的调用完成，注意是读操作肯定是发生了，但是有没有执行完成不一定 如果 Channel 的容量是 m（m\u003e0），那么，第 n 个 receive 一定 happens before 第 n+m 个 send 的完成 close 一个 Channel 的调用，肯定 happens before 从关闭的 Channel 中读取出一个零值 var ch = make(chan struct{}, 10) // buffered或者unbuffered var s string func f() { s = \"hello, world\" // 5 ch \u003c- struct{}{} // 6 } func main() { go f() \u003c-ch // 11 print(s) } 在这个例子中： s 的初始化（第 5 行）happens before 往 ch 中发送数据 往 ch 发送数据 happens before 从 ch 中读取出一条数据（第 11 行）， 第 12 行打印 s 的值 happens after 第 11 行 所以，打印的结果肯定是初始化后的 s 的值“hello world” 如果你把第 6 行替换成 close(ch)，也能保证同样的执行顺序。因为第 11 行从关闭的 ch 中读取出零值后，第 6 行肯定被调用了。 var ch = make(chan int) var s string func f() { s = \"hello, world\" \u003c-ch // 6 } func main() { go f() ch \u003c- struct{}{} // 11 print(s) } 这个例子中: 如果第 11 行发送语句执行成功（完毕），那么根据规则 3，第 6 行 （接收）的调用肯定发生了（执行完成不完成不重要，重要的是这一句“肯定执行了”） ，那么 s 也肯定初始化了，所以一定会打印出“hello world”。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:5:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"5. Mutex/RWMutex 对于互斥锁 Mutex m 或者读写锁 RWMutex m，有 3 条 happens-before 关系的保证: 第 n 次的 m.Unlock 一定 happens before 第 n+1 m.Lock 方法的返回； 对于读写锁 RWMutex m，如果它的第 n 个 m.Lock 方法的调用已返回，那么它的第 n 个 m.Unlock 的方法调用一定 happens before 任何一个 m.RLock 方法调用的返回，只要这些 m.RLock 方法调用 happens after 第 n 次 m.Lock 的调用的返回。这就可以保证，只有释放了持有的写锁，那些等待的读请求才能请求到读锁。 对于读写锁 RWMutex m，如果它的第 n 个 m.RLock 方法的调用已返回，那么它的第 k （k\u003c=n）个成功的 m.RUnlock 方法的返回一定 happens before 任意的 m.Lock 方法调用，只要这些 m.Lock 方法调用 happens after 第 n 次 m.RLock。这样就可以保证，只有 m.Lock 调用前，所有的读锁释放了，写锁才能请求到锁。 var mu sync.Mutex var s string func foo() { s = \"hello, world\" mu.Unlock() } func main() { mu.Lock() go foo() mu.Lock() print(s) 在这个例子中，第 6 行第一次的 Unlock 一定 happens before 第二次的 Lock（第 12 行），所以这也能保证正确地打印出“hello world”。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:6:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"6. WaitGroup 对于一个 WaitGroup 实例 wg，在某个时刻 t0 时，它的计数值已经不是零了，假如 t0 时刻之后调用了一系列的 wg.Add(n) 或者 wg.Done()，并且只有最后一次调用 wg 的计数值变为了 0，那么，可以保证这些 wg.Add 或者 wg.Done() 一定 happens before t0 时刻之后调用的 wg.Wait 方法的返回。 这个保证的通俗说法，就是 Wait 方法等到计数值归零之后才返回。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:7:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"7. Once Once 提供的保证是：对于 once.Do(f) 调用，f 函数的那个单次调用一定 happens before 任何 once.Do(f) 调用的返回。换句话说，就是函数 f 一定会在 Do 方法返回之前执行。 var s string var once sync.Once func foo() { s = \"hello, world\" } func twoprint() { once.Do(foo) print(s) } 这个例子中: 第 5 行的执行一定 happens before 第 9 行的返回 所以执行到第 10 行的时候，sd 已经初始化了，所以会正确地打印“hello world”。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:8:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"8. atomic 其实，Go 内存模型的官方文档并没有明确给出 atomic 的保证，有一个相关的 issue go# 5045记录了相关的讨论。Russ Cox 想让 atomic 有一个弱保证，这样可以为以后留下充足的可扩展空间，所以，Go 内存模型规范上并没有严格的定义。 对于 Go 1.15 的官方实现来说，可以保证使用 atomic 的 Load/Store 的变量之间的顺序性。在下面的例子中，打印出的 a 的结果总是 1，但是官方并没有做任何文档上的说明和保证。 func main() { var a, b int32 = 0, 0 go func() { atomic.StoreInt32(\u0026a, 1) atomic.StoreInt32(\u0026b, 1) }() for atomic.LoadInt32(\u0026b) == 0{ runtime.Gosched() } fmt.Println(atomic.LoadInt32(\u0026a)) } 依照 Ian Lance Taylor 的说法，Go 核心开发组的成员几乎没有关注这个方向上的研究，因为这个问题太复杂，有很多问题需要去研究，所以，现阶段还是不要使用 atomic 来保证顺序性。 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:9:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-14","objectID":"/posts/program/go/sync/go_sync_15/:10:0","tags":["go 并发"],"title":"go 内存模型","uri":"/posts/program/go/sync/go_sync_15/"},{"categories":["Go"],"content":"channel 的应用","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"1. 使用反射操作 Channel 在学习如何使用 Channel 之前，我们来看看如何通过反射的方式执行 select 语句，这在处理很多的 case clause，尤其是不定长的 case clause 的时候，非常有用。 为了便于操作 Select，reflect 提供了如下几个函数: func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool): 参数: SelectCase 表示 Select 语句的一个分支 返回值: chosen: select 是伪随机的，它在执行的 case 中随机选择一个 case，并把选择的这个 case 的索引（chosen）返回 recv: 如果 select 选中的 recv case，recvValue 表示接收的元素 recvOK: 表示是否有 case 成功被选择，false 表示没有可用的 case 返回 SelectCase: struct 表示一个 select case 分支 const ( SelectSend // case Chan \u003c- Send SelectRecv // case \u003c-Chan: SelectDefault // default ) type SelectCase struct { Dir SelectDir // case的方向 Chan Value // 使用的通道（收/发） Send Value // 用于发送的值 } type SelectDir int func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool) 下面是动态创建 Select 的一个示例: func main() { var ch1 = make(chan int, 10) var ch2 = make(chan int, 10) // 创建SelectCase var cases = createCases(ch1, ch2) // 执行10次select for i := 0; i \u003c 10; i++ { chosen, recv, ok := reflect.Select(cases) if recv.IsValid() { // recv case fmt.Println(\"recv:\", cases[chosen].Dir, recv, ok) } else { // send case fmt.Println(\"send:\", cases[chosen].Dir, ok) } } } func createCases(chs ...chan int) []reflect.SelectCase { var cases []reflect.SelectCase // 创建recv case for _, ch := range chs { cases = append(cases, reflect.SelectCase{ Dir: reflect.SelectRecv, Chan: reflect.ValueOf(ch), }) } // 创建send case for i, ch := range chs { v := reflect.ValueOf(i) cases = append(cases, reflect.SelectCase{ Dir: reflect.SelectSend, Chan: reflect.ValueOf(ch), Send: v, }) } return cases } 上一节我们说了 Channel 的五种使用场景: 数据交流：当作并发的 buffer 或者 queue，解决生产者 - 消费者问题。多个 goroutine 可以并发当作生产者（Producer）和消费者（Consumer） 数据传递：一个 goroutine 将数据交给另一个 goroutine，相当于把数据的拥有权 (引用) 托付出去。 信号通知：一个 goroutine 可以将信号 (closing、closed、data ready 等) 传递给另一个或者另一组 goroutine 任务编排：可以让一组 goroutine 按照一定的顺序并发或者串行的执行，这就是编排的功能 锁：利用 Channel 也可以实现互斥锁的机制 接下来我们一一举例说明。 ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:1:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"2.消息交流 从 chan 的内部实现看，它是以一个循环队列的方式存放数据，所以，它有时候也会被当成线程安全的队列和 buffer 使用。我们来看几个例子。 ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:2:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"2.1 worker 池 Marcio Castilho 在 使用 Go 每分钟处理百万请求 这篇文章中，就介绍了他们应对大并发请求的设计。他们将用户的请求放在一个 chan Job 中，这个 chan Job 就相当于一个待处理任务队列。除此之外，还有一个 chan chan Job 队列，用来存放可以处理任务的 worker 的缓存队列。具体的实现参见 Go Work Pool ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:2:1","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"3. 数据传递 下面是一个数据传递(任务编排)的例子，让四个 goroutine 顺序打印 1,2,3,4 type Token struct{} func newWorker(id int, ch chan Token, nextCh chan Token) { for { token := \u003c-ch // 取得令牌 fmt.Println((id + 1)) // id从1开始 time.Sleep(time.Second) nextCh \u003c- token } } func main() { chs := []chan Token{make(chan Token), make(chan Token), make(chan Token), make(chan Token)} // 创建4个worker for i := 0; i \u003c 4; i++ { go newWorker(i, chs[i], chs[(i+1)%4]) } //首先把令牌交给第一个worker chs[0] \u003c- struct{}{} select {} } 这类场景有一个特点，就是当前持有数据的 goroutine 都有一个信箱，信箱使用 chan 实现，goroutine 只需要关注自己的信箱中的数据，处理完毕后，就把结果发送到下一家的信箱中。 ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:3:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"4. 信号通知 chan 类型有这样一个特点：chan 如果为空，那么，receiver 接收数据的时候就会阻塞等待，直到 chan 被关闭或者有新的数据到来。利用这个机制，我们可以实现 wait/notify 的设计模式。 除了正常的业务处理时的 wait/notify，我们经常碰到的一个场景，就是程序关闭的时候，我们需要在退出之前做一些清理（doCleanup 方法）的动作。这个时候，我们经常要使用 chan。 比如，使用 chan 实现程序的 graceful shutdown，在退出之前执行一些连接关闭、文件 close、缓存落盘等一些动作。 func main() { go func() { ...... // 执行业务处理 }() // 处理CTRL+C等中断信号 termChan := make(chan os.Signal) signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) \u003c-termChan // 执行退出之前的清理动作 doCleanup() fmt.Println(\"优雅退出\") } 有时候，doCleanup 可能是一个很耗时的操作，我们需要设置一个最长的等待时间。只要超过了这个时间，程序就不再等待，可以直接退出。所以，退出的时候分为两个阶段： closing，代表程序退出，但是清理工作还没做； closed，代表清理工作已经做完。 func main() { var closing = make(chan struct{}) var closed = make(chan struct{}) go func() { // 模拟业务处理 for { select { case \u003c-closing: return default: // ....... 业务计算 time.Sleep(100 * time.Millisecond) } } }() // 处理CTRL+C等中断信号 termChan := make(chan os.Signal) signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) \u003c-termChan close(closing) // 执行退出之前的清理动作 go doCleanup(closed) select { case \u003c-closed: case \u003c-time.After(time.Second): fmt.Println(\"清理超时，不等了\") } fmt.Println(\"优雅退出\") } func doCleanup(closed chan struct{}) { time.Sleep((time.Minute)) close(closed) } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:4:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"5. 锁 使用 chan 也可以实现互斥锁。在 chan 的内部实现中，就有一把互斥锁保护着它的所有字段。从外在表现上，chan 的发送和接收之间也存在着 happens-before 的关系，保证元素放进去之后，receiver 才能读取到。 要想使用 chan 实现互斥锁，至少有两种方式。一种方式是先初始化一个 capacity 等于 1 的 Channel，然后再放入一个元素。这个元素就代表锁，谁取得了这个元素，就相当于获取了这把锁。另一种方式是，先初始化一个 capacity 等于 1 的 Channel，它的“空槽”代表锁，谁能成功地把元素发送到这个 Channel，谁就获取了这把锁。 我们以第一种为例实现一个锁: // 使用chan实现互斥锁 type Mutex struct { ch chan struct{} } // 使用锁需要初始化 func NewMutex() *Mutex { mu := \u0026Mutex{make(chan struct{}, 1)} mu.ch \u003c- struct{}{} return mu } // 请求锁，直到获取到 func (m *Mutex) Lock() { \u003c-m.ch } // 解锁 func (m *Mutex) Unlock() { select { case m.ch \u003c- struct{}{}: default: panic(\"unlock of unlocked mutex\") } } // 尝试获取锁 func (m *Mutex) TryLock() bool { select { case \u003c-m.ch: return true default: } return false } // 加入一个超时的设置 func (m *Mutex) LockTimeout(timeout time.Duration) bool { timer := time.NewTimer(timeout) select { case \u003c-m.ch: timer.Stop() return true case \u003c-timer.C: } return false } // 锁是否已被持有 func (m *Mutex) IsLocked() bool { return len(m.ch) == 0 } func main() { m := NewMutex() ok := m.TryLock() fmt.Printf(\"locked v %v\\n\", ok) ok = m.TryLock() fmt.Printf(\"locked %v\\n\", ok) } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:5:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6. 任务编排 消息交流的场景是一个特殊的任务编排的场景： 前面我们介绍的顺序答应1,2,3,4 s 也被称为流水线模式 WaitGroup 可以实现等待模式，Channel 也可以实现这种等待模式 任务编排既指安排 goroutine 按照指定的顺序执行，也指多个 chan 按照指定的方式组合处理的方式。我们通过编排数据在 channel 之间的流转，就可以控制 goroutine 的执行。接下来我们着重介绍 channel 编排的五种典型模式L Or-Done 扇入 扇出 Stream map-reduce ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6.1 Or-Done 模式 Or-Done 模式是信号通知模式中更宽泛的一种模式。我们会使用“信号通知”实现某个任务执行完成后的通知机制，在实现时: 我们为这个任务定义一个类型为 chan struct{}类型的 done 变量 等任务结束后，我们就可以 close 这个变量，然后，其它 receiver 就会收到这个通知。 这是有一个任务的情况，如果有多个任务，只要有任意一个任务执行完，我们就想获得这个信号，这就是 Or-Done 模式。比如发送同一个请求到多个微服务节点，只要任意一个微服务返回结果就算成功。下面是Or-Done 的一个实现: func or(channels ...\u003c-chan interface{}) \u003c-chan interface{} { // 特殊情况，只有零个或者1个chan switch len(channels) { case 0: return nil case 1: return channels[0] } orDone := make(chan interface{}) go func() { defer close(orDone) switch len(channels) { case 2: // 2个也是一种特殊情况 select { case \u003c-channels[0]: case \u003c-channels[1]: } default: //超过两个，二分法递归处理 m := len(channels) / 2 select { case \u003c-or(channels[:m]...): case \u003c-or(channels[m:]...): } } }() return orDone } 这里的实现使用了一个巧妙的方式，当 chan 的数量大于 2 时，使用递归的方式等待信号。在 chan 数量比较多的情况下，递归并不是一个很好的解决方式，根据这一讲最开始介绍的反射的方法，我们也可以实现 Or-Done 模式： func or(channels ...\u003c-chan interface{}) \u003c-chan interface{} { //特殊情况，只有0个或者1个 switch len(channels) { case 0: return nil case 1: return channels[0] } orDone := make(chan interface{}) go func() { defer close(orDone) // 利用反射构建SelectCase var cases []reflect.SelectCase for _, c := range channels { cases = append(cases, reflect.SelectCase{ Dir: reflect.SelectRecv, Chan: reflect.ValueOf(c), }) } // 随机选择一个可用的case reflect.Select(cases) }() return orDone } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:1","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6.2 扇入 Channel 扇入模式来说，是指有多个源 Channel 输入、一个目的 Channel 输出的情况。每个源 Channel 的元素都会发送给目标 Channel，相当于目标 Channel 的 receiver 只需要监听目标 Channel，就可以接收所有发送给源 Channel 的数据。即合并多个 channel 为一个 channel 扇入模式也可以使用反射、递归，或者是用最笨的每个 goroutine 处理一个 Channel 的方式来实现。 反射实现 func fanInReflect(chans ...\u003c-chan interface{}) \u003c-chan interface{} { out := make(chan interface{}) go func() { defer close(out) // 构造SelectCase slice var cases []reflect.SelectCase for _, c := range chans { cases = append(cases, reflect.SelectCase{ Dir: reflect.SelectRecv, Chan: reflect.ValueOf(c), }) } // 循环，从cases中选择一个可用的 for len(cases) \u003e 0 { i, v, ok := reflect.Select(cases) if !ok { // 此channel已经close cases = append(cases[:i], cases[i+1:]...) continue } out \u003c- v.Interface() } }() return out } 递归实现 func fanInRec(chans ...\u003c-chan interface{}) \u003c-chan interface{} { switch len(chans) { case 0: c := make(chan interface{}) close(c) return c case 1: return chans[0] case 2: return mergeTwo(chans[0], chans[1]) default: m := len(chans) / 2 return mergeTwo( fanInRec(chans[:m]...), fanInRec(chans[m:]...)) } } func mergeTwo(a, b \u003c-chan interface{}) \u003c-chan interface{} { c := make(chan interface{}) go func() { defer close(c) for a != nil || b != nil { //只要还有可读的chan select { case v, ok := \u003c-a: if !ok { // a 已关闭，设置为nil a = nil continue } c \u003c- v case v, ok := \u003c-b: if !ok { // b 已关闭，设置为nil b = nil continue } c \u003c- v } } }() return c } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:2","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6.3 扇出 扇出模式只有一个输入源 Channel，有多个目标 Channel，经常用在设计模式中的观察者模式中，将一个一个对象的状态变化通知到多个观察者中。扇入模式也可以使用反射、递归，或者是用最笨的每个 goroutine 处理一个 Channel 的方式来实现。即消息的广播。 func fanOut(ch \u003c-chan interface{}, out []chan interface{}, async bool) { go func() { defer func() { //退出时关闭所有的输出chan for i := 0; i \u003c len(out); i++ { close(out[i]) } }() for v := range ch { // 从输入chan中读取数据 v := v for i := 0; i \u003c len(out); i++ { // 注意这里的赋值 i := i if async { //异步 go func() { out[i] \u003c- v // 放入到输出chan中,异步方式 }() } else { out[i] \u003c- v // 放入到输出chan中，同步方式 } } } }() } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:3","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6.4 Stream 把 Channel 当作流式管道使用，提供跳过几个元素，或者是只取其中的几个元素等方法。在下面的实现中，我们首先创建流，然后为流定义以下方法: takeN：只取流中的前 n 个数据； takeFn：筛选流中的数据，只保留满足条件的数据； takeWhile：只取前面满足条件的数据，一旦不满足条件，就不再取； skipN：跳过流中前几个数据； skipFn：跳过满足条件的数据； skipWhile：跳过前面满足条件的数据，一旦不满足条件，当前这个元素和以后的元素都会输出给 Channel 的 receiver。 这些方法的实现很类似，我们以 takeN 为例。 创建流 func asStream(done \u003c-chan struct{}, values ...interface{}) \u003c-chan interface{} { s := make(chan interface{}) //创建一个unbuffered的channel go func() { // 启动一个goroutine，往s中塞数据 defer close(s) // 退出时关闭chan for _, v := range values { // 遍历数组 select { case \u003c-done: return case s \u003c- v: // 将数组元素塞入到chan中 } } }() return s } 流上的方法 func takeN(done \u003c-chan struct{}, valueStream \u003c-chan interface{}, num int) \u003c-chan interface{} { takeStream := make(chan interface{}) // 创建输出流 go func() { defer close(takeStream) for i := 0; i \u003c num; i++ { // 只读取前num个元素 select { case \u003c-done: return case takeStream \u003c- \u003c-valueStream: //从输入流中读取元素 } } }() return takeStream } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:4","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"6.5 map-reduce 这里我们要讲的是单机单进程的 map-reduce 方法。map-reduce 分为两个步骤，第一步是映射（map），处理队列中的数据，第二步是规约（reduce），把列表中的每一个元素按照一定的处理方式处理成结果，放入到结果队列中。 map func mapChan(in \u003c-chan interface{}, fn func(interface{}) interface{}) \u003c-chan interface{} { out := make(chan interface{}) //创建一个输出chan if in == nil { // 异常检查 close(out) return out } go func() { // 启动一个goroutine,实现map的主要逻辑 defer close(out) for v := range in { // 从输入chan读取数据，执行业务操作，也就是map操作 out \u003c- fn(v) } }() return out } reduce func reduce(in \u003c-chan interface{}, fn func(r, v interface{}) interface{}) interface{} { if in == nil { // 异常检查 return nil } out := \u003c-in // 先读取第一个元素 for v := range in { // 实现reduce的主要逻辑 out = fn(out, v) } return out } 应用 // 生成一个数据流 func asStream(done \u003c-chan struct{}) \u003c-chan interface{} { s := make(chan interface{}) values := []int{1, 2, 3, 4, 5} go func() { defer close(s) for _, v := range values { // 从数组生成 select { case \u003c-done: return case s \u003c- v: } } }() return s } func main() { in := asStream(nil) // map操作: 乘以10 mapFn := func(v interface{}) interface{} { return v.(int) * 10 } // reduce操作: 对map的结果进行累加 reduceFn := func(r, v interface{}) interface{} { return r.(int) + v.(int) } sum := reduce(mapChan(in, mapFn), reduceFn) //返回累加结果 fmt.Println(sum) } ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:6:5","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-13","objectID":"/posts/program/go/sync/go_sync_14/:7:0","tags":["go 并发"],"title":"Channel 应用","uri":"/posts/program/go/sync/go_sync_14/"},{"categories":["Go"],"content":"Channel 是 Go 语言内建的 first-class 类型，也是 Go 语言与众不同的特性之一","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"1. Channel 概述 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:1:0","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"1.1 CSP 模型 要想了解 Channel，我们要先追溯到 CSP 模型。CSP 是 Communicating Sequential Process 的简称，中文直译为通信顺序进程，或者叫做交换信息的循序进程，是用来描述并发系统中进行交互的一种模式。CSP 允许使用进程组件来描述系统，它们独立运行，并且只通过消息传递的方式通信。有关Go 中如何通过 Channel 实现 CSP 参见这边文章CSP 的发展。 Channel 类型是 Go 语言内置的类型，Channel 和 Go 的另一个独特的特性 goroutine 一起为并发编程提供了优雅的、便利的、与传统并发控制不同的方案，并演化出很多并发模式。 Go 语言的 Channel 设计精巧简单，以至于也有人用其它语言编写了类似 Go 风格的 Channel 库，比如docker/libchan、tylertreat/chan ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:1:1","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"1.2 Channel 的应用场景 Go 语言的哲学: Don’t communicate by sharing memory, share memory by communicating – 执行业务处理的 goroutine 不要通过共享内存的方式通信，而是要通过 Channel 通信的方式分享数据。 “communicate by sharing memory”和“share memory by communicating”是两种不同的并发处理模式: communicate by sharing memory 是传统的并发编程处理方式，就是指，共享的数据需要用锁进行保护，goroutine 需要获取到锁，才能并发访问数据。 share memory by communicating 则是类似于 CSP 模型的方式，通过通信的方式，一个 goroutine 可以把**数据的“所有权”**交给另外一个 goroutine 综合起来，Channel 的应用场景分为五种类型: 数据交流：当作并发的 buffer 或者 queue，解决生产者 - 消费者问题。多个 goroutine 可以并发当作生产者（Producer）和消费者（Consumer） 数据传递：一个 goroutine 将数据交给另一个 goroutine，相当于把数据的拥有权 (引用) 托付出去。 信号通知：一个 goroutine 可以将信号 (closing、closed、data ready 等) 传递给另一个或者另一组 goroutine 任务编排：可以让一组 goroutine 按照一定的顺序并发或者串行的执行，这就是编排的功能 锁：利用 Channel 也可以实现互斥锁的机制 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:1:2","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"1.3 Channel 使用 Channel 类型和声明 Channel 分为只能接收、只能发送、既可以接收又可以发送三种类型: // 1. 语法定义 ChannelType = ( \"chan\" | \"chan\" \"\u003c-\" | \"\u003c-\" \"chan\" ) ElementType . // 2. 类型声明 chan string // 可以发送接收string chan\u003c- struct{} // 只能发送struct{} \u003c-chan int // 只能从chan接收int 类型声明中 “\u003c-”表示单向的 chan，这个箭头总是射向左边的，元素类型总在最右边。如果箭头指向 chan，就表示可以往 chan 中塞数据；如果箭头远离 chan，就表示 chan 会往外吐数据。 chan 中的元素是任意的类型，所以也可能是 chan 类型，下面的 chan 类型都是合法的: chan\u003c- chan int chan\u003c- \u003c-chan int \u003c-chan \u003c-chan int chan (\u003c-chan int) 怎么判定箭头符号属于哪个 chan 呢？其实，“\u003c-”有个规则，总是尽量和左边的 chan 结合.因此，上面的定义和下面的使用括号的划分是一样的： chan\u003c- （chan int） // \u003c- 和第一个chan结合 chan\u003c- （\u003c-chan int） // 第一个\u003c-和最左边的chan结合，第二个\u003c-和左边第二个chan结合 \u003c-chan （\u003c-chan int） // 第一个\u003c-和最左边的chan结合，第二个\u003c-和左边第二个chan结合 chan (\u003c-chan int) // 因为括号的原因，\u003c-和括号内第一个chan结合 Channel 初始化 通过 make，我们可以初始化一个 chan，未初始化的 chan 的零值是 nil。可以设置它的容量，设置容量的 chan 叫做 buffered chan；如果没有设置，它的容量是 0，这样的 chan 叫做 unbuffered chan。 make(chan int, 9527) Channel 阻塞与 panic 向 chan 读写数据时: 如果 chan 中还有数据，那么，从这个 chan 接收数据的时候就不会阻塞 如果 chan 还未满（“满”指达到其容量），给它发送数据也不会阻塞，否则就会阻塞 unbuffered chan 只有读写都准备好之后才不会阻塞 nil 是 chan 的零值，是一种特殊的 chan，对值是 nil 的 chan 的发送接收调用者总是会阻塞。 close channel 时: 如果 chan 为 nil，close 会 panic； 如果 chan 已经 closed，再次 close 也会 panic 如果 chan 不为 nil，chan 也没有 closed，就把等待队列中的 sender（writer）和 receiver（reader）从队列中全部移除并唤醒。 值得注意的点是，只要一个 chan 还有未读的数据，即使把它 close 掉，你还是可以继续把这些未读的数据消费完，之后才是读取零值数据。 Channel 常见操作 chan 常见操作分为: 发送数据: ch \u003c- value 接受数据: \u003c-ch，可以返回两个值 第一个值是返回的 chan 中的元素 第二个值是 bool 类型，代表是否成功地从 chan 中读取到一个值 如果第二个参数是 false，chan 已经被 close 而且 chan 中没有缓存的数据，这个时候，第一个值是零值 所以，如果从 chan 读取到一个零值，可能是 sender 真正发送的零值，也可能是 closed 的并且没有缓存元素产生的零值 关闭: close(ch) 其他: cap 返回 chan 的容量，len 返回 chan 中缓存的还未被取走的元素数量 // 往 chan 中发送一个数据使用“ch\u003c-”，发送数据是一条语句 ch \u003c- 200 // 从 chan 中接收一条数据使用“\u003c-ch”，接收数据也是一条语句： x := \u003c-ch // 把接收的一条数据赋值给变量x foo(\u003c-ch) // 把接收的一个的数据作为参数传给函数 \u003c-ch // 丢弃接收的一条数据 // ch 可以作为 select 语句的 case clause func main() { var ch = make(chan int, 10) for i := 0; i \u003c 10; i++ { select { case ch \u003c- i: case v := \u003c-ch: fmt.Println(v) } } } // chan 还可以用在 for-range 语句中: for v:= range ch { fmt.Println(v) } // 清空 chan for range ch { } ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:1:3","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2. Channel 的实现 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:0","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2.1 Channel 数据结构 chan 类型的数据结构如下图所示，它的数据类型是runtime.hchan qcount：代表 chan 中已经接收但还没被取走的元素的个数。内建函数 len 可以返回这个字段的值。 dataqsiz：队列的大小。chan 使用一个循环队列来存放元素，循环队列很适合这种生产者 - 消费者的场景 buf：存放元素的循环队列的 buffer elemtype 和 elemsize：chan 中元素的类型和 size， chan 一旦声明，它的元素类型是固定的 sendx：处理发送数据的指针在 buf 中的位置。一旦接收了新的数据，指针就会加上 elemsize，移向下一个位置。buf 的总大小是 elemsize 的整数倍，而且 buf 是一个循环列表。 ecvx：处理接收请求时的指针在 buf 中的位置。一旦取出数据，此指针会移动到下一个位置。 recvq：chan 是多生产者多消费者的模式，如果消费者因为没有数据可读而被阻塞了，就会被加入到 recvq 队列中。 sendq：如果生产者因为 buf 满了而阻塞，会被加入到 sendq 队列中。 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:1","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2.1 初始化 Go 在编译的时候，会根据容量的大小选择调用 makechan64，还是 makechan。 makechan64 只是做了 size 检查，底层还是调用 makechan 实现的。makechan 的目标就是生成 hchan 对象。 makechan 会根据 chan 的容量的大小和元素的类型不同，初始化不同的存储空间: func makechan(t *chantype, size int) *hchan { elem := t.elem // 略去检查代码 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) // var c *hchan switch { case mem == 0: // chan的size或者元素的size是0，不必创建buf c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.ptrdata == 0: // 元素不是指针，分配一块连续的内存给hchan数据结构和buf c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) // hchan数据结构后面紧接着就是buf c.buf = add(unsafe.Pointer(c), hchanSize) default: // 元素包含指针，那么单独分配buf c = new(hchan) c.buf = mallocgc(mem, elem, true) } // 元素大小、类型、容量都记录下来 c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026c.lock, lockRankHchan) return c } ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:2","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2.2 send Go 在编译发送数据给 chan 的时候，会把 send 语句转换成 chansend1 函数，chansend1 函数会调用 chansend，我们分段学习它的逻辑： 最开始，第一部分是进行判断：如果 chan 是 nil 的话，就把调用者 goroutine park（阻塞休眠）， 调用者就永远被阻塞住了，所以，第 11 行是不可能执行到的代码。 func chansend1(c *hchan, elem unsafe.Pointer) { chansend(c, elem, true, getcallerpc()) } func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // 第一部分 if c == nil { if !block { return false } gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\"unreachable\") } ...... } 第二部分的逻辑是当你往一个已经满了的 chan 实例发送数据时，并且想不阻塞当前调用，那么这里的逻辑是直接返回。chansend1 方法在调用 chansend 的时候设置了阻塞参数，所以不会执行到第二部分的分支里。 // 第二部分，如果chan没有被close,并且chan满了，直接返回 if !block \u0026\u0026 c.closed == 0 \u0026\u0026 full(c) { return false } 第三部分显示的是，如果 chan 已经被 close 了，再往里面发送数据的话会 panic。 // 第三部分，chan已经被close的情景 lock(\u0026c.lock) // 开始加锁 if c.closed != 0 { unlock(\u0026c.lock) panic(plainError(\"send on closed channel\")) } 第四部分，如果等待队列中有等待的 receiver，那么这段代码就把它从队列中弹出，然后直接把数据交给它（通过 memmove(dst, src, t.size)），而不需要放入到 buf 中。(注: 队列中有等待的 receiver 说明buf 中没有数据，所以不会影响消息的顺序性) // 第四部分，从接收队列中出队一个等待的receiver if sg := c.recvq.dequeue(); sg != nil { // send(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true } 第五部分说明当前没有 receiver，需要把数据放入到 buf 中，放入之后，就成功返回了。 // 第五部分，buf还没满 if c.qcount \u003c c.dataqsiz { qp := chanbuf(c, c.sendx) if raceenabled { raceacquire(qp) racerelease(qp) } typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(\u0026c.lock) return true } 第六部分是处理 buf 满的情况。如果 buf 满了，发送者的 goroutine 就会加入到发送者的等待队列中，直到被唤醒。这个时候，数据或者被取走了，或者 chan 被 close 了。 // 第六部分，buf满。 // chansend1不会进入if块里，因为chansend1的block=true if !block { unlock(\u0026c.lock) return false } ...... ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:3","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2.3 recv 在处理从 chan 中接收数据时，Go 会把代码转换成 chanrecv1 函数，如果要返回两个返回值，会转换成 chanrecv2，chanrecv1 函数和 chanrecv2 会调用 chanrecv。 chanrecv1 和 chanrecv2 传入的 block 参数的值是 true，都是阻塞方式，所以我们分析 chanrecv 的实现的时候，不考虑 block=false 的情况。第一部分是 chan 为 nil 的情况。和 send 一样，从 nil chan 中接收（读取、获取）数据时，调用者会被永远阻塞。 func chanrecv1(c *hchan, elem unsafe.Pointer) { chanrecv(c, elem, true) } func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) { _, received = chanrecv(c, elem, true) return } func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // 第一部分，chan为nil if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\"unreachable\") } 第二部分你可以直接忽略，因为chanrecv1 和 chanrecv2 传入的 block 参数的值是 true // 第二部分, block=false且c为空 if !block \u0026\u0026 empty(c) { ...... } 第三部分是 chan 已经被 close 的情况。如果 chan 已经被 close 了，并且队列中没有缓存的元素，那么返回 true、false。 // 加锁，返回时释放锁 lock(\u0026c.lock) // 第三部分，c已经被close,且chan为空empty if c.closed != 0 \u0026\u0026 c.qcount == 0 { unlock(\u0026c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } 第四部分是处理 buf 满的情况。这个时候，如果是 unbuffer 的 chan，就直接将 sender 的数据复制给 receiver，否则就从队列头部读取一个值，并把这个 sender 的值加入到队列尾部。 // 第四部分，如果sendq队列中有等待发送的sender if sg := c.sendq.dequeue(); sg != nil { recv(c, sg, ep, func() { unlock(\u0026c.lock) }, 3) return true, true } 第五部分是处理没有等待的 sender 的情况。这个是和 chansend 共用一把大锁，所以不会有并发的问题。如果 buf 有元素，就取出一个元素给 receiver。 // 第五部分, 没有等待的sender, buf中有数据 if c.qcount \u003e 0 { qp := chanbuf(c, c.recvx) if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026c.lock) return true, true } if !block { unlock(\u0026c.lock) return false, false } // 第六部分， buf中没有元素，阻塞 ...... 第六部分是处理 buf 中没有元素的情况。如果没有元素，那么当前的 receiver 就会被阻塞，直到它从 sender 中接收了数据，或者是 chan 被 close，才返回。 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:4","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"2.3 close 通过 close 函数，可以把 chan 关闭，编译器会替换成 closechan 方法的调用。 close chan 的主要逻辑是: 如果 chan 为 nil，close 会 panic； 如果 chan 已经 closed，再次 close 也会 panic 如果 chan 不为 nil，chan 也没有 closed，就把等待队列中的 sender（writer）和 receiver（reader）从队列中全部移除并唤醒。 func closechan(c *hchan) { if c == nil { // chan为nil, panic panic(plainError(\"close of nil channel\")) } lock(\u0026c.lock) if c.closed != 0 {// chan已经closed, panic unlock(\u0026c.lock) panic(plainError(\"close of closed channel\")) } c.closed = 1 var glist gList // 释放所有的reader for { sg := c.recvq.dequeue() ...... gp := sg.g ...... glist.push(gp) } // 释放所有的writer (它们会panic) for { sg := c.sendq.dequeue() ...... gp := sg.g ...... glist.push(gp) } unlock(\u0026c.lock) for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } } ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:2:5","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"3. Channel 采坑点 使用 Channel 最常见的错误是 panic 和 goroutine 泄漏。panic 的情况，总共有 3 种： close 为 nil 的 chan； send 已经 close 的 chan； close 已经 close 的 chan。 goroutine 泄漏的问题也很常见，下面的代码也是一个实际项目中的例子： func process(timeout time.Duration) bool { ch := make(chan bool) go func() { // 模拟处理耗时的业务 time.Sleep((timeout + time.Second)) ch \u003c- true // block fmt.Println(\"exit goroutine\") }() select { case result := \u003c-ch: return result case \u003c-time.After(timeout): return false } } 在上面的代码中如果发生超时，process 函数就返回了，这就会导致 unbuffered 的 chan 从来就没有被读取。unbuffered chan 必须等 reader 和 writer 都准备好了才能交流，否则就会阻塞。超时导致未读，结果就是子 goroutine 就阻塞在第 7 行永远结束不了，进而导致 goroutine 泄漏。解决这个 Bug 的办法很简单，就是将 unbuffered chan 改成容量为 1 的 chan。 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:3:0","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"4. 如何选择 Channel 并不是处理并发问题的“银弹”，有时候使用并发原语更简单，下面是一套如何选择的简化方法: 共享资源的并发访问使用传统并发原语 复杂的任务编排和消息传递使用 Channel； 消息通知机制使用 Channel，除非只想 signal 一个 goroutine，才使用 Cond； 简单等待所有任务的完成用 WaitGroup 需要和 Select 语句结合，使用 Channel； 需要和超时配合时，使用 Channel 和 Context。 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:4:0","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-12","objectID":"/posts/program/go/sync/go_sync_13/:5:0","tags":["go 并发"],"title":"Channel 使用与实现","uri":"/posts/program/go/sync/go_sync_13/"},{"categories":["Go"],"content":"go 的原子操作","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"1. Atomic 概述 ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:1:0","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"1.1 原子操作 Package sync/atomic 实现了同步算法底层的原子的内存操作原语。之所以叫原子操作，是因为一个原子在执行的时候，其它线程不会看到执行一半的操作结果。在其它线程看来，原子操作要么执行完了，要么还没有执行，就像一个最小的粒子 - 原子一样，不可分割。 CPU 提供了基础的原子操作，不过，不同架构的系统的原子操作是不一样的: 对于单处理器单核系统: 如果一个操作是由一个 CPU 指令来实现的，那么它就是原子操作 如果操作是基于多条指令来实现的，那么，执行的过程中可能会被中断，并执行上下文切换，这样的话，原子性的保证就会被打破 在多处理器多核系统中: 由于 cache 的存在，单个核上的单个指令进行原子操作的时候，要确保其它处理器或者核不访问此原子操作的地址，或者是确保其它处理器或者核总是访问原子操作之后的最新的值 不同的 CPU 架构提供了不同的 CPU 指令来完成原子操作 因为不同的 CPU 架构甚至不同的版本提供的原子操作的指令是不同的，所以，要用一种编程语言实现支持不同架构的原子操作是相当有难度的，Go 语言为我们做好了这一切 Go 提供了一个通用的原子操作的 API，将更底层的不同的架构下的实现封装成 atomic 包，提供了修改类型的原子操作（atomic read-modify-write，RMW）和加载存储类型的原子操作（Load 和 Store）的 API ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:1:1","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"1.2 原子操作应用场景 原子操作适用以下场景: 首先 atomic 原子操作适用于\"不涉及到对资源复杂的竞争逻辑\"，比如 并发地读写某个标志变量 - 对应 read-modify-write API 配置对象的更新和加载 - 对应 Load and Store API 基于 atomic 可以实现自定义的基本并发原语，原子操作是解决并发问题的根本 atomic 原子操作还是实现 lock-free 数据结构的基石，lock-freeze 数据结构的实现可以参考这篇文章Lockless Programming Considerations for Xbox 360 and Microsoft Windows ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:1:2","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"1.3 atomic 的使用 目前的 Go 的泛型的特性还没有发布，多个类型会实现很多类似的方法，尤其是 atomic 包。 atomic 为了支持 int32、int64、uint32、uint64、uintptr、Pointer（Add 方法不支持）类型，分别提供了 AddXXX、CompareAndSwapXXX、SwapXXX、LoadXXX、StoreXXX 等方法。 atomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法。下面我们就来看看 atomic 提供的方法。 Add func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) Add 方法: Add 方法就是给第一个参数地址中的值增加一个 delta 值 对于有符号的整数来说，delta 可以是一个负数，相当于减去一个值 对于无符号的整数和 uinptr 类型来，减去一个值需要利用计算机补码规则，吧减法编程加法 // 以 uint32/unit64 类型为例，实现减 c 操作 AddUint32(\u0026x, ^uint32(c-1)) AddUint32(\u0026x, ^uint32(c-1)) CSA(CompareAndSwap) func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) CSA 方法: 这个方法会比较当前 addr 地址里的值是不是 old，如果不等于 old，就返回 false；如果等于 old，就把此地址的值替换成 new 值，返回 true Swap func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) Swap 方法: 不需要比较旧值，直接将 addr 地址内的值替换为 new，并返回旧值 Load func LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) Load 方法: 取出 addr 地址中的值，即使在多处理器、多核、有 CPU cache 的情况下，这个操作也能保证 Load 是一个原子操作 LoadPointer 保证的是原子的读取 Pointer 指针的值，而不是保证原子的读取 Pointer 指向的对象 Store func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) Store 方法: 把一个值存入到指定的 addr 地址中，即使在多处理器、多核、有 CPU cache 的情况下，这个操作也能保证 Store 是一个原子操作。 别的 goroutine 通过 Load 读取出来，不会看到存取了一半的值。 Value 类型 type Value func (v *Value) Load() (x interface{}) func (v *Value) Store(x interface{}) // go1.8 之后 Value 已经直至 CAS 操作 type Value func (v *Value) CompareAndSwap(old, new any) (swapped bool) func (v *Value) Load() (val any) func (v *Value) Store(val any) func (v *Value) Swap(new any) (old any) ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:1:3","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"2. atomic.Value 的实现和使用 ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:2:0","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"2.1 atomic.Value 的实现 相比于其他原子操作直接与 CPU 指令相关，atomic.Value 的实现是基于其他更基本原子操作实现的。 package atomic import ( \"unsafe\" ) // A Value provides an atomic load and store of a consistently typed value. // The zero value for a Value returns nil from Load. // Once Store has been called, a Value must not be copied. // // A Value must not be copied after first use. type Value struct { v any } // ifaceWords is interface{} internal representation. type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } // Load returns the value set by the most recent Store. // It returns nil if there has been no call to Store for this Value. func (v *Value) Load() (val any) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026vp.typ) if typ == nil || typ == unsafe.Pointer(\u0026firstStoreInProgress) { // First store not yet completed. return nil } data := LoadPointer(\u0026vp.data) vlp := (*ifaceWords)(unsafe.Pointer(\u0026val)) vlp.typ = typ vlp.data = data return } var firstStoreInProgress byte // Store sets the value of the Value to x. // All calls to Store for a given Value must use values of the same concrete type. // Store of an inconsistent type panics, as does Store(nil). func (v *Value) Store(val any) { if val == nil { panic(\"sync/atomic: store of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) vlp := (*ifaceWords)(unsafe.Pointer(\u0026val)) for { typ := LoadPointer(\u0026vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion. runtime_procPin() if !CompareAndSwapPointer(\u0026vp.typ, nil, unsafe.Pointer(\u0026firstStoreInProgress)) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026vp.data, vlp.data) StorePointer(\u0026vp.typ, vlp.typ) runtime_procUnpin() return } if typ == unsafe.Pointer(\u0026firstStoreInProgress) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != vlp.typ { panic(\"sync/atomic: store of inconsistently typed value into Value\") } StorePointer(\u0026vp.data, vlp.data) return } } // Swap stores new into Value and returns the previous value. It returns nil if // the Value is empty. // // All calls to Swap for a given Value must use values of the same concrete // type. Swap of an inconsistent type panics, as does Swap(nil). func (v *Value) Swap(new any) (old any) { if new == nil { panic(\"sync/atomic: swap of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) np := (*ifaceWords)(unsafe.Pointer(\u0026new)) for { typ := LoadPointer(\u0026vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion; and so that // GC does not see the fake type accidentally. runtime_procPin() if !CompareAndSwapPointer(\u0026vp.typ, nil, unsafe.Pointer(\u0026firstStoreInProgress)) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026vp.data, np.data) StorePointer(\u0026vp.typ, np.typ) runtime_procUnpin() return nil } if typ == unsafe.Pointer(\u0026firstStoreInProgress) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != np.typ { panic(\"sync/atomic: swap of inconsistently typed value into Value\") } op := (*ifaceWords)(unsafe.Pointer(\u0026old)) op.typ, op.data = np.typ, SwapPointer(\u0026vp.data, np.data) return old } } // CompareAndSwap executes the compare-and-swap operation for the Value. // // All calls to CompareAndSwap for a given Value must use values of the same // concrete type. CompareAndSwap of an inconsistent type panics, as does // CompareAndSwap(old, nil). func (v *Value) CompareAndSwap(old, new any) (swapped bool) { if new == nil { panic(\"sync/atomic: compare and swap of nil value into Value\") } vp := (*ifaceWords)(unsafe.Pointer(v)) np := (*ifaceWords)(unsafe.P","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:2:1","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"2.2 atomic.Value 的使用 Value 类型: 可以原子地存取对象类型，但也只能存取，不能 CAS 和 Swap，常常用在配置变更等场景中 接下来，我们以一个配置变更的例子，来演示 Value 类型的使用。 type Config struct { NodeName string Addr string Count int32 } func loadNewConfig() Config { return Config{ NodeName: \"北京\", Addr: \"10.77.95.27\", Count: rand.Int31(), } } func main() { var config atomic.Value config.Store(loadNewConfig()) var cond = sync.NewCond(\u0026sync.Mutex{}) // 设置新的config go func() { for { time.Sleep(time.Duration(5+rand.Int63n(5)) * time.Second) config.Store(loadNewConfig()) cond.Broadcast() // 通知等待着配置已变更 } }() go func() { for { cond.L.Lock() cond.Wait() // 等待变更信号 c := config.Load().(Config) // 读取新的配置 fmt.Printf(\"new config: %+v\\n\", c) cond.L.Unlock() } }() select {} } ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:2:2","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"3. Atomic 的扩展 atomic 的 API 已经算是很简单的了，它提供了包一级的函数，可以对几种类型的数据执行原子操作。有些人就对这些函数做了进一步的包装，跟 atomic 中的 Value 类型类似，这些类型也提供了面向对象的使用方式，比如关注度比较高的uber-go/atomic。 uber-go/atomic 定义和封装了几种与常见类型相对应的原子操作类型，这些类型提供了原子操作的方法。这些类型包括 Bool、Duration、Error、Float64、Int32、Int64、String、Uint32、Uint64 等。s var running atomic.Bool running.Store(true) running.Toggle() fmt.Println(running.Load()) // false atomic.Value 只有 Load/Store 方法，可以参考这篇文章为其增加 Swap 和 CompareAndSwap 方法。 ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:3:0","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"4. 使用 atomic 实现 Lock-Free queue atomic 常常用来实现 Lock-Free 的数据结构，这里我们实现一个 Lock-Free queue。(sync.Pool 的实现中就包含了一个 lock-free queue 的实现 poolDequeue) package queue import ( \"sync/atomic\" \"unsafe\" ) // lock-free的queue type LKQueue struct { head unsafe.Pointer tail unsafe.Pointer } // 通过链表实现，这个数据结构代表链表中的节点 type node struct { value interface{} next unsafe.Pointer } func NewLKQueue() *LKQueue { n := unsafe.Pointer(\u0026node{}) return \u0026LKQueue{head: n, tail: n} } // 入队 func (q *LKQueue) Enqueue(v interface{}) { n := \u0026node{value: v} for { tail := load(\u0026q.tail) next := load(\u0026tail.next) if tail == load(\u0026q.tail) { // 尾还是尾 if next == nil { // 还没有新数据入队 if cas(\u0026tail.next, next, n) { //增加到队尾 cas(\u0026q.tail, tail, n) //入队成功，移动尾巴指针 return } } else { // 已有新数据加到队列后面，需要移动尾指针 cas(\u0026q.tail, tail, next) } } } } // 出队，没有元素则返回nil func (q *LKQueue) Dequeue() interface{} { for { head := load(\u0026q.head) tail := load(\u0026q.tail) next := load(\u0026head.next) if head == load(\u0026q.head) { // head还是那个head if head == tail { // head和tail一样 if next == nil { // 说明是空队列 return nil } // 只是尾指针还没有调整，尝试调整它指向下一个 cas(\u0026q.tail, tail, next) } else { // 读取出队的数据 v := next.value // 既然要出队了，头指针移动到下一个 if cas(\u0026q.head, head, next) { return v // Dequeue is done. return } } } } } // 将unsafe.Pointer原子加载转换成node func load(p *unsafe.Pointer) (n *node) { return (*node)(atomic.LoadPointer(p)) } // 封装CAS,避免直接将*node转换成unsafe.Pointer func cas(p *unsafe.Pointer, old, new *node) (ok bool) { return atomic.CompareAndSwapPointer( p, unsafe.Pointer(old), unsafe.Pointer(new)) } ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:3:1","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"5. 对一个地址的赋值是原子操作吗？ 对一个地址的赋值是原子操作吗？这是一个很有趣的问题，如果是原子操作，还要 atomic 包干什么(Value 类型的 Store Load 方法)？如何理解 atomic 和直接内存操作的区别？(参见Dave Cheney) 在现在的系统中，write 的地址基本上都是对齐的（aligned），对齐地址的写，不会导致其他人看到只写了一半的数据，因为它通过一个指令就可以实现对地址的操作 如果地址不是对齐的话，那么，处理器就需要分成两个指令去处理，如果执行了一个指令，其它人就会看到更新了一半的错误的数据，这被称做撕裂写（torn write） 所以，你可以认为赋值操作是一个原子操作，这个“原子操作”可以认为是保证数据的完整性。 对于现代的多处理多核的系统来说，由于 cache、指令重排，可见性等问题，我们对原子操作的意义有了更多的追求。在多核系统中，一个核对地址的值的更改，在更新到主内存中之前，是在多级缓存中存放的。这时，多个核看到的数据可能是不一样的，其它的核可能还没有看到更新的数据，还在使用旧的数据。 多处理器多核心系统为了处理这类问题，使用了一种叫做**内存屏障（memory fence 或 memory barrier）**的方式。一个写内存屏障会告诉处理器，必须要等到它管道中的未完成的操作（特别是写操作）都被刷新到内存中，再进行操作。此操作还会让相关的处理器的 CPU 缓存失效，以便让它们从主存中拉取最新的值。 atomic 包提供的方法会提供内存屏障的功能，所以，atomic 不仅仅可以保证赋值的数据完整性，还能保证数据的可见性，一旦一个核更新了该地址的值，其它处理器总是能读取到它的最新值。但是，需要注意的是，因为需要处理器之间保证数据的一致性，atomic 的操作也是会降低性能的。 ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:4:0","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-11","objectID":"/posts/program/go/sync/go_sync_12/:5:0","tags":["go 并发"],"title":"Atomic 原子操作","uri":"/posts/program/go/sync/go_sync_12/"},{"categories":["Go"],"content":"go 的上下文管理器","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"1. Context 概述 所谓上下文指的是在 API 之间或者方法调用之间，所传递的除了业务参数之外的额外信息，比如服务追踪。Go 标准库中的 Context 不仅仅传递上下文信息还提供了超时（Timeout）和取消（Cancel）的机制。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:1:0","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"1.1 Context 来历 最初提供了 golang.org/x/net/context 库用来提供上下文信息，Go 在 1.7 的版本中才正式把 Context 加入到标准库中。 Go 1.7 发布之后，出现了标准库 Context 和 golang.org/x/net/context 并存的状况。新的代码使用标准库 Context 的时候，没有办法使用这个标准库的 Context 去调用旧有的使用 x/net/context 实现的方法。 所以，在 Go1.9 中，还专门实现了一个叫做 type alias 的新特性，然后把 x/net/context 中的 Context 定义成标准库 Context 的别名，以解决新旧 Context 类型冲突问题 // +build go1.9 package context import \"context\" type Context = context.Context type CancelFunc = context.CancelFunc ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:1:1","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"1.2 Context 的问题 Context 包含了太多了功能，导致它也出现了一些争议: Go 布道师 Dave Cheney 还专门写了一篇文章讲述这个问题：Context isn’t for cancellation 有批评者专门写了一篇文章 Context should go away for Go 2 Go 核心开发者 Ian Lance Taylor 专门开了一个issue 28342，用来记录当前的 Context 的问题： Context 包名导致使用的时候重复 ctx context.Context； Context.WithValue 可以接受任何类型的值，非类型安全； Context 包名容易误导人，实际上，Context 最主要的功能是取消 goroutine 的执行； Context 漫天飞，函数污染。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:1:2","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"1.3 Context 适用场景 尽管有很多的争议，但是，在很多场景下，使用 Context 其实会很方便，比如下面这些场景: 上下文信息传递 （request-scoped），比如处理 http 请求、在请求处理链路上传递信息； 控制子 goroutine 的运行； 超时控制的方法调用； 可以取消的方法调用。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:1:3","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2. Context 使用 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:0","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.1 接口定义 包 context 定义了 Context 接口，Context 的具体实现包括 4 个方法，分别是 Deadline、Done、Err 和 Value，如下所示： type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u003c-chan struct{} Err() error Value(key interface{}) interface{} } Deadline 方法 返回这个 Context 被取消的截止日期。如果没有设置截止日期，ok 的值是 false 后续每次调用这个对象的 Deadline 方法时，都会返回和第一次调用相同的结果 Done 方法 返回一个 Channel 对象 在 Context 被取消时，此 Channel 会被 close，如果没被取消，可能会返回 nil 后续的 Done 调用总是返回相同的结果。当 Done 被 close 的时候，你可以通过 ctx.Err 获取错误信息。 即: 如果 Done 没有被 close，Err 方法返回 nil；如果 Done 被 close，Err 方法会返回 Done 被 close 的原因。 Value 返回此 ctx 中和指定的 key 相关联的 value ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:1","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.2 生成函数 Context 中实现了 2 个常用的生成顶层 Context 的方法。 context.Background()： 返回一个非 nil 的、空的 Context，没有任何值，不会被 cancel，不会超时，没有截止日期 一般用在主函数、初始化、测试以及创建根 Context 的时候 context.TODO()： 返回一个非 nil 的、空的 Context，没有任何值，不会被 cancel，不会超时，没有截止日期 当你不清楚是否该用 Context，或者目前还不知道要传递一些什么上下文信息的时候，就可以使用这个方法 其实，你根本不用费脑子去考虑，可以直接使用 context.Background。事实上，它们两个底层的实现是一模一样的： var ( background = new(emptyCtx) todo = new(emptyCtx) ) func Background() Context { return background } func TODO() Context { return todo } ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:2","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.3 使用约定 在使用 Context 的时候，有一些约定俗成的规则: 一般函数使用 Context 的时候，会把这个参数放在第一个参数的位置。 从来不把 nil 当做 Context 类型的参数值，可以使用 context.Background() 创建一个空的上下文对象，也不要使用 nil。 Context 只用来临时做函数之间的上下文透传，不能持久化 Context 或者把 Context 长久保存。把 Context 持久化到数据库、本地文件或者全局变量、缓存中都是错误的用法。 key 的类型不应该是字符串类型或者其它内建类型，否则容易在包之间使用 Context 时候产生冲突。使用 WithValue 时，key 的类型应该是自己定义的类型。 常常使用 struct{}作为底层类型定义 key 的类型。对于 exported key 的静态类型，常常是接口或者指针。这样可以尽量减少内存分配。 如果你能保证别人使用你的 Context 时不会和你定义的 key 冲突，那么 key 的类型就比较随意，因为你自己保证了不同包的 key 不会冲突，否则建议你尽量采用保守的 unexported 的类型。 Context 包中有几种创建特殊用途 Context 的方法：WithValue、WithCancel、WithTimeout 和 WithDeadline，包括它们的功能以及实现方式。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:3","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.4 WithValue WithValue 基于 parent Context 生成一个新的 Context，保存了一个 key-value 键值对。它常常用来传递上下文。WithValue 方法其实是创建了一个类型为 valueCtx 的 Context，它的类型定义如下： type valueCtx struct { Context key, val interface{} } 它覆盖了 Value 方法，优先从自己的存储中检查这个 key，不存在的话会从 parent 中继续检查。Go 标准库实现的 Context 还实现了链式查找。如果不存在，还会向 parent Context 去查找，如果 parent 还是 valueCtx 的话，还是遵循相同的原则：valueCtx 会嵌入 parent，所以还是会查找 parent 的 Value 方法的。 ctx = context.TODO() ctx = context.WithValue(ctx, \"key1\", \"0001\") ctx = context.WithValue(ctx, \"key2\", \"0001\") ctx = context.WithValue(ctx, \"key3\", \"0001\") ctx = context.WithValue(ctx, \"key4\", \"0004\") fmt.Println(ctx.Value(\"key1\")) ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:4","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.5 WithCancel WithCancel 方法返回 parent 的副本，只是副本中的 Done Channel 是新建的对象，它的类型是 cancelCtx。返回值中的第二个值是一个 cancel 函数。 我们常常在一些需要主动取消长时间的任务时，创建这种类型的 Context，然后把这个 Context 传给长时间执行任务的 goroutine。当需要中止任务时，我们就可以 cancel 这个 Context，长时间执行任务的 goroutine，就可以通过检查这个 Context，知道 Context 已经被取消了。 记住，不是只有你想中途放弃，才去调用 cancel，只要你的任务正常完成了，就需要调用 cancel，这样，这个 Context 才能释放它的资源（通知它的 children 处理 cancel，从它的 parent 中把自己移除，甚至释放相关的 goroutine）。很多同学在使用这个方法的时候，都会忘记调用 cancel，切记切记，而且一定尽早释放。 func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, \u0026c)// 把c朝上传播 return \u0026c, func() { c.cancel(true, Canceled) } } // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } propagateCancel 方法会顺着 parent 路径往上找，直到找到一个 cancelCtx，或者为 nil。如果不为空，就把自己加入到这个 cancelCtx 的 child，以便这个 cancelCtx 被取消的时候通知自己。如果为空，会新起一个 goroutine，由它来监听 parent 的 Done 是否已关闭。 当这个 cancelCtx 的 cancel 函数被调用的时候，或者 parent 的 Done 被 close 的时候，这个 cancelCtx 的 Done 才会被 close。 cancel 是向下传递的，如果一个 WithCancel 生成的 Context 被 cancel 时，如果它的子 Context（也有可能是孙，或者更低，依赖子的类型）也是 cancelCtx 类型的，就会被 cancel，但是不会向上传递。parent Context 不会因为子 Context 被 cancel 而 cancel。cancelCtx 被取消时，它的 Err 字段就是下面这个 Canceled 错误： var Canceled = errors.New(\"context canceled\") 下面是 cancelCtx 的使用示例: func main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\"goroutine exit\") }() for { select { case \u003c-ctx.Done(): return default: time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:5","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"2.6 WithTimeout/WithDeadline WithTimeout 其实是和 WithDeadline 一样，只不过一个参数是超时时间，一个参数是截止时间。 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { // 当前时间+timeout就是deadline return WithDeadline(parent, time.Now().Add(timeout)) } WithDeadline 会返回一个 parent 的副本，并且设置了一个不晚于参数 d 的截止时间，类型为 timerCtx（或者是 cancelCtx）。 如果它的截止时间晚于 parent 的截止时间，那么就以 parent 的截止时间为准，并返回一个类型为 cancelCtx 的 Context，因为 parent 的截止时间到了，就会取消这个 cancelCtx。 如果当前时间已经超过了截止时间，就直接返回一个已经被 cancel 的 timerCtx。否则就会启动一个定时器，到截止时间取消这个 timerCtx。 综合起来，timerCtx 的 Done 被 Close 掉，主要是由下面的某个事件触发的： 截止时间到了； cancel 函数被调用； parent 的 Done 被 close。 func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { // 如果parent的截止时间更早，直接返回一个cancelCtx即可 if cur, ok := parent.Deadline(); ok \u0026\u0026 cur.Before(d) { return WithCancel(parent) } c := \u0026timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } propagateCancel(parent, c) // 同cancelCtx的处理逻辑 dur := time.Until(d) if dur \u003c= 0 { //当前时间已经超过了截止时间，直接cancel c.cancel(true, DeadlineExceeded) return c, func() { c.cancel(false, Canceled) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { // 设置一个定时器，到截止时间后取消 c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded) }) } return c, func() { c.cancel(true, Canceled) } } 和 cancelCtx 一样，WithDeadline（WithTimeout）返回的 cancel 一定要调用，并且要尽可能早地被调用，这样才能尽早释放资源。，不要单纯地依赖截止时间被动取消。 func slowOperationWithTimeout(ctx context.Context) (Result, error) { ctx, cancel := context.WithTimeout(ctx, 100*time.Millisecond) defer cancel() // 一旦慢操作完成就立马调用cancel return slowOperation(ctx) } 如果你要为 Context 实现一个带超时功能的调用，比如访问远程的一个微服务，超时并不意味着你会通知远程微服务已经取消了这次调用，大概率的实现只是避免客户端的长时间等待，远程的服务器依然还执行着你的请求。 所以，有时候，Context 并不会减少对服务器的请求负担。如果在 Context 被 cancel 的时候，你能关闭和服务器的连接，中断和数据库服务器的通讯、停止对本地文件的读写，那么，这样的超时处理，同时能减少对服务调用的压力，但是这依赖于你对超时的底层处理机制。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:2:6","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3. Context 的实现 前面的内容，鸟叔基本已经把 Context 讲的非常清楚。但如果是第一次看这个内容可能还是比较蒙。所以接下来我们就看看源码，看看 Context 的设计与实现。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:0","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3.1 ctx 的几种类型 Background、WithValue、WithCancel、WithTimeout 对应了如下几种 ctx struct。 type emptyCtx int type cancelCtx struct { Context mu sync.Mutex // protects following fields done chan struct{} // created lazily, closed by first cancel call children map[canceler]struct{} // set to nil by the first cancel call err error // set to non-nil by the first cancel call } type canceler interface { cancel(removeFromParent bool, err error) Done() \u003c-chan struct{} } type timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } type valueCtx struct { Context key, val interface{} } func WithValue(parent Context, key, val interface{}) Context { if parent == nil { panic(\"cannot create context from nil parent\") } if key == nil { panic(\"nil key\") } if !reflectlite.TypeOf(key).Comparable() { panic(\"key is not comparable\") } return \u0026valueCtx{parent, key, val} } func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { c := newCancelCtx(parent) propagateCancel(parent, \u0026c)// 把c朝上传播 return \u0026c, func() { c.cancel(true, Canceled) } } // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } 除了 empty Ctx，cancleCtx，valueCtx 都有 Context 成员，其指向了当前 Context 的 parent Context，构成了一个 Context 的链表((timerCtx 可以看成 cancelCtx 的扩展)。valueCtx.Value() 在进行值查找以及 cancelCtx 在创建时都会沿着 Context 向上查找。我们依次来看看这两个过程。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:1","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3.2 valueCtx.Value() func (c *valueCtx) Value(key interface{}) interface{} { if c.key == key { return c.val } // 除了 emptyCtx 所有类型的 Value() 方法都会调用 c.Context.Value 向上查找，所以会递归向上查找 return c.Context.Value(key) } ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:2","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3.3 propagateCancel var cancelCtxKey int var closedchan = make(chan struct{}) func (c *cancelCtx) Value(key interface{}) interface{} { if key == \u0026cancelCtxKey { return c } return c.Context.Value(key) } func (c *cancelCtx) Done() \u003c-chan struct{} { c.mu.Lock() if c.done == nil { c.done = make(chan struct{}) } d := c.done c.mu.Unlock() return d } func propagateCancel(parent Context, child canceler) { // 1. // emptyCtx.Done 返回 nil // valueCtx 的 Done 调用的是 parent.Done() 如果 调用链上一直是 valueCtx 就会一直递归向上调用 // cancleCtx 和 timerCtx Done() 返回的是 非 nil // 综上所述，propagateCancel 方法会顺着 parent 路径往上找，直到找到一个 cancelCtx 并返回它的 done，或者为 nil done := parent.Done() if done == nil { return // parent is never canceled } select { // parent 已经被 cancle 了，直接 cancle case \u003c-done: // parent is already canceled child.cancel(false, parent.Err()) return default: } // 2. 沿着 Context 链，向上查找第一个 cancelCtx if p, ok := parentCancelCtx(parent); ok { p.mu.Lock() if p.err != nil { // parent has already been canceled child.cancel(false, p.err) } else { // 4. // 如果不为空，就把自己加入到这个 cancelCtx 的 child if p.children == nil { p.children = make(map[canceler]struct{}) } p.children[child] = struct{}{} } p.mu.Unlock() } else { // 5. // 如果为空，会新起一个 goroutine，由它来监听 parent 的 Done 是否已关闭 atomic.AddInt32(\u0026goroutines, +1) go func() { select { case \u003c-parent.Done(): child.cancel(false, parent.Err()) case \u003c-child.Done(): } }() } } // parentCancelCtx returns the underlying *cancelCtx for parent. // It does this by looking up parent.Value(\u0026cancelCtxKey) to find // the innermost enclosing *cancelCtx and then checking whether // parent.Done() matches that *cancelCtx. (If not, the *cancelCtx // has been wrapped in a custom implementation providing a // different done channel, in which case we should not bypass it.) func parentCancelCtx(parent Context) (*cancelCtx, bool) { done := parent.Done() if done == closedchan || done == nil { return nil, false } // 3. // 查找的方法很简单，cancelCtx.Value() 方法里面会判断 key== \u0026cancelCtxKey // 因为只有 cancelCtx 会这么判断，所以判断成功肯定是 cancelCtx // 除了 emptyCtx 所有类型的 Value() 方法都会调用 c.Context.Value 向上查找，所以会递归向上查找 p, ok := parent.Value(\u0026cancelCtxKey).(*cancelCtx) if !ok { return nil, false } // 判断到此处 p 已经是一个 cancelCtx 了 p.mu.Lock() // 7. context 的 value 和 done 方法都会沿着 Context 链向上查找，所以 p.done 应该等于 done // 如果不相等，说明 cancleCtx 的 done 对应的 channel 值被更改过 ok = p.done == done p.mu.Unlock() if !ok { return nil, false } return p, true } ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:3","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3.4 cancelCtx.cancel // cancel closes c.done, cancels each of c's children, and, if // removeFromParent is true, removes c from its parent's children. func (c *cancelCtx) cancel(removeFromParent bool, err error) { if err == nil { panic(\"context: internal error: missing cancel error\") } c.mu.Lock() if c.err != nil { c.mu.Unlock() return // already canceled } c.err = err if c.done == nil { c.done = closedchan } else { close(c.done) } // 递归 cancel 子 cancelCtx for child := range c.children { // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err) } c.children = nil c.mu.Unlock() if removeFromParent { // 把当前 Context 从父 cancelCtx 的 childrens 中删除 removeChild(c.Context, c) } } // removeChild removes a context from its parent. func removeChild(parent Context, child canceler) { p, ok := parentCancelCtx(parent) if !ok { return } p.mu.Lock() if p.children != nil { delete(p.children, child) } p.mu.Unlock() } ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:4","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"3.5 个人总结 Context 的实现并不复杂，我们需要注入以下几个核心的点: Context 的 Done 方法，由于结构体嵌入会形成递归调用关系，特别是 valueCtx 会一直向上调用 parent.Done 方法直至 parent 不是 valueCtx Context 的 Value 方法中，会递归调用 parent.Value 方法，形成沿着 Context 链的向上递归调用 如果你理解了这几个点，看懂 Context 的代码就比较容易了。 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:3:5","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-10","objectID":"/posts/program/go/sync/go_sync_11/:4:0","tags":["go 并发"],"title":"go Context","uri":"/posts/program/go/sync/go_sync_11/"},{"categories":["Go"],"content":"go 对象池化","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"1. Pool 概述 Go 是一个自动垃圾回收的编程语言，采用三色并发标记算法标记对象并回收。但是，如果你想使用 Go 开发一个高性能的应用程序的话，就必须考虑垃圾回收给性能带来的影响。对象池化， 可以有效地减少新对象的创建次数，是性能优化的重要方式。 Go 标准库中提供了一个通用的 Pool 数据结构，也就是 sync.Pool，我们使用它可以创建池化的对象。但是 sync.Pool 有一个缺陷，就是它池化的对象可能会被垃圾回收掉，这对于数据库长连接等场景是不合适的。因此接下来我们将介绍: sync.Pool 的使用、实现和采坑点 其他 Pool 包括 TCP 连接池、数据库连接池 Worker Pool: goroutine pool，使用有限的 goroutine 资源去处理大量的业务数据 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:1:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"1.1 sync.Pool 使用 sync.Pool 用来保存一组可独立访问的临时对象，临时两个字表明\"它池化的对象会在未来的某个时候被毫无预兆地移除掉\"。如果没有别的对象引用这个被移除的对象的话，这个被移除的对象就会被垃圾回收掉。 sync.Pool 有两个知识点需要记住: sync.Pool 本身就是线程安全的，多个 goroutine 可以并发地调用它的方法存取对象； sync.Pool 使用之后不可再复制使用 sync.Pool 只提供了三个对外方法: New 字段: 类型为func() interface{} 当 Get 方法从池中获取元素，没有更多空闲元素可返回时，就会调用 New 方法来创建新的元素。 如果你没有设置 New 字段，没有更多的空闲元素可返回时，Get 方法将返回 nil，表明当前没有可用的元素 New 是可变的字段，这意味着可以在程序运行的时候改变创建元素的方法，但是没必要这么做 Get 方法: 调用这个方法，就会从 Pool取走一个元素(从 Pool 中移除)，并返回给调用者 除了正常实例化的元素，Get 方法的返回值还可能会是一个 nil（Pool.New 字段没有设置，又没有空闲元素可以返回），使用时需要判断 Put 方法: 用于将一个元素返还给 Pool，Pool 会把这个元素保存到池中，并且可以复用 如果 Put 一个 nil 值，Pool 就会忽略这个值 下面是 sync.Pool 实现的 buffer 池(缓冲池)。注意下面这段代码是有问题的，你一定不要将这段代码应用到实际的产品中，它可能会有内存泄漏的问题。 import bytes var buffers = sync.Pool{ New: func() interface{} { return new(bytes.Buffer) } } func GetBuffer() *bytes.Buffer { return buffers.Get().(*bytes.Buffer) } func PutBuffer(* bytes.Buffer){ buf.Reset() buffer.Put(buf) } ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:1:1","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"1.2 适用场景 对象池化适用于以下几个场景: 如果你发现程序中有一种 GC 耗时特别高，有大量的相同类型的临时对象，不断地被创建销毁，这时就可以考虑是不是可以通过池化的手段重用这些对象 在分布式系统或者微服务框架中，可能会有大量的并发 Client 请求，如果 Client 的耗时占比很大，你也可以考虑池化 Client，以便重用 如果你发现系统中的 goroutine 数量非常多，程序的内存资源占用比较大，而且整体系统的耗时和 GC 也比较高，这时就可以考虑是否能够通过 Worker Pool 解决大量 goroutine 的问题，从而降低这些指标 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:1:2","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"2. Pool 实现 Go 1.13 之前的 sync.Pool 的实现有 2 大问题： 每次 GC 都会回收创建的对象: 如果缓存元素数量太多，就会导致 STW 耗时变长；缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层实现使用了 Mutex，对这个锁并发请求竞争激烈的时候，会导致性能的下降 在 Go 1.13 中，sync.Pool 做了大量的优化。优化的方式就是避免使用锁，同时将加锁的 queue 改成 lock-free 的 queue 的实现，给即将移除的元素再多一次“复活”的机会。sync.Pool 的数据结构如下图所示： Pool 实现中: 每次垃圾回收的时候，Pool 会把 victim 中的对象移除，然后把 local 的数据给 victim victim 就像一个垃圾分拣站，里面的东西可能会被当做垃圾丢弃了，但是里面有用的东西也可能被捡回来重新使用 victim 中的元素如果被 Get 取走，他就会被重用；没有被 Get 取走，那么就会被移除掉，因为没有别人引用它的话，就会被垃圾回收掉 Pool 的数据结构相对于其他同步原语是比较复杂的，其中: local 字段包含一个 poolLocalInternal 字段: poolLocalInternal 提供 CPU 缓存对齐，从而避免 false sharing poolLocalInternal 包含两个字段：private 和 shared private: 代表一个缓存的元素，而且只能由相应的一个 P 存取 因为一个 P 同时只能执行一个 goroutine，所以不会有并发的问题 shared: 可以由任意的 P 访问，但是只有本地的 P 才能 pushHead/popHead，其它 P 可以 popTail 相当于只有一个本地的 P 作为生产者（Producer），多个 P 作为消费者（Consumer） 它是使用一个 local-free 的 queue 列表实现的，即 poolDequeue poolChain: 实现的是一个链表 poolChainElt: 是 poolChain 链表中的每个 Item poolDequeue: 是一个双向队列保存了缓存的池化对象 type Pool struct { noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface{} } func (p *Pool) Put(x interface{}) {} func (p *Pool) Get() interface{} {} // Local per-P Pool appendix. type poolLocalInternal struct { private any // Can be used only by the respective P. shared poolChain // Local P can pushHead/popHead; any P can popTail. } type poolLocal struct { poolLocalInternal // Prevents false sharing on widespread platforms with // 128 mod (cache line size) = 0 . pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte } // poolChain is a dynamically-sized version of poolDequeue. // // This is implemented as a doubly-linked list queue of poolDequeues // where each dequeue is double the size of the previous one. Once a // dequeue fills up, this allocates a new one and only ever pushes to // the latest dequeue. Pops happen from the other end of the list and // once a dequeue is exhausted, it gets removed from the list. type poolChain struct { // head is the poolDequeue to push to. This is only accessed // by the producer, so doesn't need to be synchronized. head *poolChainElt // tail is the poolDequeue to popTail from. This is accessed // by consumers, so reads and writes must be atomic. tail *poolChainElt } type poolChainElt struct { poolDequeue // next and prev link to the adjacent poolChainElts in this // poolChain. // // next is written atomically by the producer and read // atomically by the consumer. It only transitions from nil to // non-nil. // // prev is written atomically by the consumer and read // atomically by the producer. It only transitions from // non-nil to nil. next, prev *poolChainElt } 我们先从 pool 的垃圾回收看起，这能反映出上面所说 victim 与 local 之间的关系。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:2:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"2.1 Pool 的垃圾回收 下面的代码是垃圾回收时 sync.Pool 的处理逻辑： var ( allPoolsMu Mutex // allPools is the set of pools that have non-empty primary // caches. Protected by either 1) allPoolsMu and pinning or 2) // STW. allPools []*Pool // oldPools is the set of pools that may have non-empty victim // caches. Protected by STW. oldPools []*Pool ) func poolCleanup() { // 丢弃当前victim, STW所以不用加锁 for _, p := range oldPools { p.victim = nil p.victimSize = 0 } // 将local复制给victim, 并将原local置为nil for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil } func init() { runtime_registerPoolCleanup(poolCleanup) } ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:2:1","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"2.2 Get 方法 func (p *Pool) Get() interface{} { // 把当前goroutine固定在当前的P上，l 就是 local 对象 l, pid := p.pin() x := l.private // 1. 优先从local的private字段取，快速 l.private = nil if x == nil { // 2. 从当前的local.shared弹出一个，注意是从head读取并移除 x, _ = l.shared.popHead() if x == nil { // 3. 如果没有，则去偷一个 x = p.getSlow(pid) } } runtime_procUnpin() // 如果没有获取到，尝试使用New函数生成一个新的 if x == nil \u0026\u0026 p.New != nil { x = p.New() } return x } 这里的重点是 getSlow 方法，它首先要遍历所有的 local，尝试从它们的 shared 弹出一个元素。如果还没找到一个，那么，就开始对 victim 下手了。在 vintim 中查询可用元素的逻辑还是一样的，先从对应的 victim 的 private 查找，如果查不到，就再从其它 victim 的 shared 中查找。 func (p *Pool) getSlow(pid int) interface{} { size := atomic.LoadUintptr(\u0026p.localSize) locals := p.local // 从其它proc中尝试偷取一个元素 for i := 0; i \u003c int(size); i++ { l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // 如果其它proc也没有可用元素，那么尝试从vintim中获取 size = atomic.LoadUintptr(\u0026p.victimSize) if uintptr(pid) \u003e= size { return nil } locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil { // 同样的逻辑，先从vintim中的local private获取 l.private = nil return x } for i := 0; i \u003c int(size); i++ { // 从vintim其它proc尝试偷取 l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil { return x } } // 如果victim中都没有，则把这个victim标记为空，以后的查找可以快速跳过了 atomic.StoreUintptr(\u0026p.victimSize, 0) return nil } func indexLocal(l unsafe.Pointer, i int) *poolLocal { lp := unsafe.Pointer(uintptr(l) + uintptr(i)*unsafe.Sizeof(poolLocal{})) return (*poolLocal)(lp) } 这里没列出 pin 代码的实现，你只需要知道，pin 方法会将此 goroutine 固定在当前的 P 上，避免查找元素期间被其它的 P 执行。固定的好处就是查找元素期间直接得到跟这个 P 相关的 local。有一点需要注意的是，pin 方法在执行的时候，如果跟这个 P 相关的 local 还没有创建，或者运行时 P 的数量被修改了的话，就会新创建 local。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:2:2","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"2.4 Put 方法 func (p *Pool) Put(x interface{}) { if x == nil { // nil值直接丢弃 return } l, _ := p.pin() if l.private == nil { // 如果本地private没有值，直接设置这个值即可 l.private = x x = nil } if x != nil { // 否则加入到本地队列中 l.shared.pushHead(x) } runtime_procUnpin() } // pin pins the current goroutine to P, disables preemption and // returns poolLocal pool for the P and the P's id. // Caller must call runtime_procUnpin() when done with the pool. func (p *Pool) pin() (*poolLocal, int) { pid := runtime_procPin() // In pinSlow we store to local and then to localSize, here we load in opposite order. // Since we've disabled preemption, GC cannot happen in between. // Thus here we must observe local at least as large localSize. // We can observe a newer/larger local, it is fine (we must observe its zero-initialized-ness). s := runtime_LoadAcquintptr(\u0026p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u003c s { return indexLocal(l, pid), pid } return p.pinSlow() } func (p *Pool) pinSlow() (*poolLocal, int) { // Retry under the mutex. // Can not lock the mutex while pinned. runtime_procUnpin() allPoolsMu.Lock() defer allPoolsMu.Unlock() pid := runtime_procPin() // poolCleanup won't be called while we are pinned. s := p.localSize l := p.local if uintptr(pid) \u003c s { return indexLocal(l, pid), pid } if p.local == nil { allPools = append(allPools, p) } // If GOMAXPROCS changes between GCs, we re-allocate the array and lose the old one. size := runtime.GOMAXPROCS(0) local := make([]poolLocal, size) atomic.StorePointer(\u0026p.local, unsafe.Pointer(\u0026local[0])) // store-release runtime_StoreReluintptr(\u0026p.localSize, uintptr(size)) // store-release return \u0026local[pid], pid } Put 的逻辑相对简单，优先设置本地 private，如果 private 字段已经有值了，那么就把此元素 push 到本地队列中。注意: poolLocal 对象在 pinSlow 方法中创建。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:2:3","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"3. Pool 采坑点 使用 Once 有两个常见错误:分别是内存泄漏和内存浪费。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:3:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"3.1 内存泄漏 文章开始，我们用 sync.Pool 实现了一个 buffer pool，这个实现可能存在内存泄漏。取出来的 bytes.Buffer 在使用的时候，我们可以往这个元素中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变，所占的空间依然很大。而且，因为 Pool 回收的机制，这些大的 Buffer 可能不被回收(被重复使用，但只使用了很小一部分)，而是会一直占用很大的空间，这属于内存泄漏的问题。 在使用 sync.Pool 回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就不要回收了，否则就太浪费了。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:3:1","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"3.2 内存浪费 除了内存泄漏以外，还有一种浪费的情况，就是池子中的 buffer 都比较大，但在实际使用的时候，很多时候只需要一个小的 buffer，这也是一种浪费现象。 要做到物尽其用，尽可能不浪费的话，我们可以将 buffer 池分成几层，比如分成 512byte，1k，2k，4k 的多层 buffer 池。获取 buffer 时根据需要，到所需大小的池子中获取 buffer 即可。在标准库 net/http/server.go中的代码中，就提供了 2K 和 4K 两个 writer 的池子。 YouTube 开源的知名项目 vitess 中提供了bucketpool的实现，它提供了更加通用的多层 buffer 池。你在使用的时候，只需要指定池子的最大和最小尺寸，vitess 就会自动计算出合适的池子数。而且，当你调用 Get 方法的时候，只需要传入你要获取的 buffer 的大小，就可以了。 type Pool func New(minSize, maxSize int) *Pool func (p *Pool) Get(size int) *[]bytes func (p *Pool) Put(b *[]bytes) ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:3:2","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"4. buffer 的其他第三方库 除了这种分层的为了节省空间的 buffer 设计外，还有其它的一些第三方的库也会提供 buffer 池的功能: bytebufferpool 基本功能和 sync.Pool 相同，它的底层也是使用 sync.Pool 实现的 包括会检测最大的 buffer，超过最大尺寸的 buffer，就会被丢弃 提供了校准（calibrate，用来动态调整创建元素的权重）的机制，可以“智能”地调整 Pool 的 defaultSize 和 maxSize 一般来说，我们使用 buffer size 的场景比较固定，所用 buffer 的大小会集中在某个范围里。有了校准的特性，bytebufferpool 就能够偏重于创建这个范围大小的 buffer，从而节省空间。 oxtoacart/bpool 提供了以下几种类型的 buffer: bpool.BufferPool： 提供一个固定元素数量的 buffer 池，元素类型是 bytes.Buffer 如果超过这个数量，Put 的时候就丢弃 如果池中的元素都被取光了，会新建一个返回 Put 回去的时候，不会检测 buffer 的大小 bpool.BytesPool： 提供一个固定元素数量的 byte slice 池，元素类型是 byte slice Put 回去的时候不检测 slice 的大小 bpool.SizedBufferPool： 提供一个固定元素数量的 buffer 池 如果超过这个数量，Put 的时候就丢弃 如果池中的元素都被取光了，会新建一个返回 Put 回去的时候，会检测 buffer 的大小，超过指定的大小的话，就会创建一个新的满足条件的 buffer 放回去 bpool 最大的特色就是能够保持池子中元素的数量，一旦 Put 的数量多于它的阈值，就会自动丢弃，而 sync.Pool 是一个没有限制的池子，只要 Put 就会收进去。bpool 是基于 Channel 实现的，不像 sync.Pool 为了提高性能而做了很多优化，所以，在性能上比不过 sync.Pool。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:4:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5. 连接池 Pool 的另一个很常用的一个场景就是保持 TCP 的连接。我们很少会使用 sync.Pool 去池化连接对象，原因就在于，sync.Pool 会无通知地在某个时候就把连接移除垃圾回收掉了，而我们的场景是需要长久保持这个连接，所以，我们一般会使用其它方法来池化连接，包括: 标准库中的 http client 池 TCP 连接池 数据库连接池 Memcached Client 连接池 Worker Pool ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5.1 标准库中的 http client 池 标准库的 http.Client 是一个 http client 的库，可以用它来访问 web 服务器。http.Client 实现连接池的代码是在 Transport 类型中，它使用 idleConn 保存持久化的可重用的长连接： ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:1","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5.2 TCP 连接池 最常用的一个 TCP 连接池是 fatih 开发的fatih/pool。 // 工厂模式，提供创建连接的工厂方法 factory := func() (net.Conn, error) { return net.Dial(\"tcp\", \"127.0.0.1:4000\") } // 创建一个tcp池，提供初始容量和最大容量以及工厂方法 p, err := pool.NewChannelPool(5, 30, factory) // 获取一个连接 conn, err := p.Get() // Close并不会真正关闭这个连接，而是把它放回池子，所以你不必显式地Put这个对象到池子中 conn.Close() // 通过调用MarkUnusable, Close的时候就会真正关闭底层的tcp的连接了 if pc, ok := conn.(*pool.PoolConn); ok { pc.MarkUnusable() pc.Close() } // 关闭池子就会关闭=池子中的所有的tcp连接 p.Close() // 当前池子中的连接的数量 current := p.Len() 虽说是 TCP，但是它管理的是更通用的 net.Conn，不局限于 TCP 连接。它通过把 net.Conn 包装成 PoolConn，实现了拦截 net.Conn 的 Close 方法，避免了真正地关闭底层连接，而是把这个连接放回到池中。 type PoolConn struct { net.Conn mu sync.RWMutex c *channelPool unusable bool } //拦截Close func (p *PoolConn) Close() error { p.mu.RLock() defer p.mu.RUnlock() if p.unusable { if p.Conn != nil { return p.Conn.Close() } return nil } return p.c.put(p.Conn) } 它的 Pool 是通过 Channel 实现的，空闲的连接放入到 Channel 中，这也是 Channel 的一个应用场景： type channelPool struct { // 存储连接池的channel mu sync.RWMutex conns chan net.Conn // net.Conn 的产生器 factory Factory } ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:2","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5.3 数据库连接池 标准库 sql.DB 还提供了一个通用的数据库的连接池，通过 MaxOpenConns 和 MaxIdleConns 控制最大的连接数和最大的 idle 的连接数。默认的 MaxIdleConns 是 2，这个数对于数据库相关的应用来说太小了，我们一般都会调整它。 type DB struct { // Atomic access only. At top of struct to prevent mis-alignment // on 32-bit platforms. Of type time.Duration. waitDuration int64 // Total time waited for new connections. connector driver.Connector // numClosed is an atomic counter which represents a total number of // closed connections. Stmt.openStmt checks it before cleaning closed // connections in Stmt.css. numClosed uint64 mu sync.Mutex // protects following fields freeConn []*driverConn connRequests map[uint64]chan connRequest nextRequest uint64 // Next key to use in connRequests. ..... stop func() // stop cancels the connection opener. } type DB func Open(driverName, dataSourceName string) (*DB, error) func OpenDB(c driver.Connector) *DB func (db *DB) Close() error func (db *DB) Conn(ctx context.Context) (*Conn, error) func (db *DB) Driver() driver.Driver func (db *DB) SetConnMaxIdleTime(d time.Duration) func (db *DB) SetConnMaxLifetime(d time.Duration) func (db *DB) SetMaxIdleConns(n int) func (db *DB) SetMaxOpenConns(n int) func (db *DB) Stats() DBStats DB 的 freeConn 保存了 idle 的连接，这样，当我们获取数据库连接的时候，它就会优先尝试从 freeConn 获取已有的连接（conn）。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:3","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5.4 Memcached Client 连接池 Brad Fitzpatrick 是知名缓存库 Memcached 的原作者，gomemcache是他使用 Go 开发的 Memchaced 的客户端，其中也用了连接池。 gomemcache Client 有一个 freeconn 的字段，用来保存空闲的连接。当一个请求使用完之后，它会调用 putFreeConn 放回到池子中，请求的时候，调用 getFreeConn 优先查询 freeConn 中是否有可用的连接。它采用 Mutex+Slice 实现 Pool： // 放回一个待重用的连接 func (c *Client) putFreeConn(addr net.Addr, cn *conn) { c.lk.Lock() defer c.lk.Unlock() if c.freeconn == nil { // 如果对象为空，创建一个map对象 c.freeconn = make(map[string][]*conn) } freelist := c.freeconn[addr.String()] //得到此地址的连接列表 if len(freelist) \u003e= c.maxIdleConns() {//如果连接已满,关闭，不再放入 cn.nc.Close() return } c.freeconn[addr.String()] = append(freelist, cn) // 加入到空闲列表中 } // 得到一个空闲连接 func (c *Client) getFreeConn(addr net.Addr) (cn *conn, ok bool) { c.lk.Lock() defer c.lk.Unlock() if c.freeconn == nil { return nil, false } freelist, ok := c.freeconn[addr.String()] if !ok || len(freelist) == 0 { // 没有此地址的空闲列表，或者列表为空 return nil, false } cn = freelist[len(freelist)-1] // 取出尾部的空闲连接 c.freeconn[addr.String()] = freelist[:len(freelist)-1] return cn, true } ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:4","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"5.4 Worker Pool goroutine 是一个很轻量级的“纤程”，一个 goroutine 初始的栈大小是 2048 个字节，并且在需要的时候可以扩展到 1GB(不同架构的配置)。 所以，大量的 goroutine 还是很耗资源的。同时，大量的 goroutine 对于调度和垃圾回收的耗时还是会有影响的，因此，goroutine 并不是越多越好。特别是在网络请求处理中，我们需要一个 Worker pool，即 goroutine 的池。由这一组 Worker 去处理连接，比如 fasthttp 中的Worker Pool。 大部分的 Worker Pool 都是通过 Channel 来缓存任务的，因为 Channel 能够比较方便地实现并发的保护，有的是多个 Worker 共享同一个任务 Channel，有些是每个 Worker 都有一个独立的 Channel。 下面三款比较常用的 Worker Pool 库: gammazero/workerpool：gammazero/workerpool 可以无限制地提交任务，提供了更便利的 Submit 和 SubmitWait 方法提交任务，还可以提供当前的 worker 数和任务数以及关闭 Pool 的功能。 ivpusic/grpool：grpool 创建 Pool 的时候需要提供 Worker 的数量和等待执行的任务的最大数量，任务的提交是直接往 Channel 放入任务。 dpaks/goworkers：dpaks/goworkers 提供了更便利的 Submi 方法提交任务以及 Worker 数、任务数等查询方法、关闭 Pool 的方法。它的任务的执行结果需要在 ResultChan 和 ErrChan 中去获取，没有提供阻塞的方法，但是它可以在初始化的时候设置 Worker 的数量和任务数。 类似的 Worker Pool 的实现非常多，比如还有panjf2000/ants、Jeffail/tunny 、benmanns/goworker、go-playground/pool、Sherifabdlnaby/gpool等第三方库。pond也是一个非常不错的 Worker Pool，关注度目前不是很高，但是功能非常齐全。 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:5:5","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-09","objectID":"/posts/program/go/sync/go_sync_10/:6:0","tags":["go 并发"],"title":"go Pool","uri":"/posts/program/go/sync/go_sync_10/"},{"categories":["Go"],"content":"线程安全的 map","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"线程安全的 map ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:0:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"1. 线程安全的 map 概述 ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:1:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"1.1 map 的基本使用 键类型 Go 内建的 map 类型如下： map[K]V 其中，key 类型的 K 必须是可比较的（comparable），在 Go 语言中，bool、整数、浮点数、复数、字符串、指针、Channel、接口都是可比较的，包含可比较元素的 struct 和数组，这俩也是可比较的，而 slice、map、函数值都是不可比较的。通常情况下，我们会选择内建的基本类型，比如整数、字符串做 key 的类型，因为这样最方便。 这里有一点需要注意，如果使用 struct 类型做 key 其实是有坑的，因为如果 struct 的某个字段值修改了，查询 map 时无法获取它 add 进去的值，如下面的例子。如果要使用 struct 作为 key，我们要保证 struct 对象在逻辑上是不可变的，这样才会保证 map 的逻辑没有问题。 type mapKey struct { key int } func main() { var m = make(map[mapKey]string) var key = mapKey{10} m[key] = \"hello\" fmt.Printf(\"m[key]=%s\\n\", m[key]) // 修改key的字段的值后再次查询map，无法获取刚才add进去的值 key.key = 100 fmt.Printf(\"再次查询m[key]=%s\\n\", m[key]) } 索引返回值 在 Go 中，map[key]函数返回结果可以是一个值，也可以是两个值。原因在于，如果获取一个不存在的 key 对应的值时，会返回零值。为了区分真正的零值和 key 不存在这两种情况，可以根据第二个返回值来区分 func main() { var m = make(map[string]int) m[\"a\"] = 0 fmt.Printf(\"a=%d; b=%d\\n\", m[\"a\"], m[\"b\"]) av, aexisted := m[\"a\"] bv, bexisted := m[\"b\"] fmt.Printf(\"a=%d, existed: %t; b=%d, existed: %t\\n\", av, aexisted, bv, bexisted) } 遍历无序 map 是无序的，如果我们想要保证遍历 map 时元素有序，可以使用辅助的数据结构，比如orderedmap。 常见错误 map 最常犯的两个错误，就是未初始化和并发读写。 map 对象必须在使用之前初始化。如果不初始化就直接赋值的话，会出现 panic 异常。但是从一个 nil 的 map 对象中获取值不会 panic，而是会得到零值。map 作为一个 struct 字段的时候，就很容易忘记初始化了，这个要特别注意。 func main() { var m map[int]int fmt.Println(m[100]) // 返回 0 m[100] = 100 // panic } Go 内建的 map 对象不是线程（goroutine）安全的，并发读写的时候运行时会有检查，遇到并发问题就会导致 panic。解决方法就是实现一个线程安全的 map。 ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:1:1","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"2. 线程安全 map 实现 线程安全 map 有多种实现方式: 利用读写锁：map 对象的操作，分为读和写两类，其中，查询和遍历可以看做读操作，增加、修改和删除可以看做写操作。 分片加锁：降低加锁的粒度，具有更高的并发性 sync.Map: 适用于特殊场景 如何选择线程安全的 map，建议通过性能测试来决定。sync.Map 甚至其他并发 map 的实现存在的原因是在某些特殊场景下，通过特殊的优化来降低锁的粒度，从而调高并发度。 ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:2:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"2.1 加读写锁的 map type RWMap struct { // 一个读写锁保护的线程安全的map sync.RWMutex // 读写锁保护下面的map字段 m map[int]int } // 新建一个RWMap func NewRWMap(n int) *RWMap { return \u0026RWMap{ m: make(map[int]int, n), } } func (m *RWMap) Get(k int) (int, bool) { //从map中读取一个值 m.RLock() defer m.RUnlock() v, existed := m.m[k] // 在锁的保护下从map中读取 return v, existed } func (m *RWMap) Set(k int, v int) { // 设置一个键值对 m.Lock() // 锁保护 defer m.Unlock() m.m[k] = v } func (m *RWMap) Delete(k int) { //删除一个键 m.Lock() // 锁保护 defer m.Unlock() delete(m.m, k) } func (m *RWMap) Len() int { // map的长度 m.RLock() // 锁保护 defer m.RUnlock() return len(m.m) } func (m *RWMap) Each(f func(k, v int) bool) { // 遍历map m.RLock() //遍历期间一直持有读锁 defer m.RUnlock() for k, v := range m.m { if !f(k, v) { return } } } ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:2:1","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"2.2 分片加锁 虽然使用读写锁可以提供线程安全的 map，但是在大量并发读写的情况下，锁的竞争会非常激烈。在并发编程中，我们的一条原则就是尽量减少锁的使用。即尽量减少锁的粒度和锁的持有时间。你可以优化业务处理的代码，以此来减少锁的持有时间，比如将串行的操作变成并行的子任务执行。这是业务相关的优化，在线程安全 map 的实现上，重点是如何减少锁的粒度 减少锁的粒度常用的方法就是分片（Shard），将一把锁分成几把锁，每个锁控制一个分片。Go 比较知名的分片并发 map 的实现是orcaman/concurrent-map。其中 GetShard 是一个关键的方法，能够根据 key 计算出分片索引。 var SHARD_COUNT = 32 // 分成SHARD_COUNT个分片的map type ConcurrentMap []*ConcurrentMapShared // 通过RWMutex保护的线程安全的分片，包含一个map type ConcurrentMapShared struct { items map[string]interface{} sync.RWMutex // Read Write mutex, guards access to internal map. } // 创建并发map func New() ConcurrentMap { m := make(ConcurrentMap, SHARD_COUNT) for i := 0; i \u003c SHARD_COUNT; i++ { m[i] = \u0026ConcurrentMapShared{items: make(map[string]interface{})} } return m } // 根据key计算分片索引 func (m ConcurrentMap) GetShard(key string) *ConcurrentMapShared { return m[uint(fnv32(key))%uint(SHARD_COUNT)] } func (m ConcurrentMap) Set(key string, value interface{}) { // 根据key计算出对应的分片 shard := m.GetShard(key) shard.Lock() //对这个分片加锁，执行业务操作 shard.items[key] = value shard.Unlock() } func (m ConcurrentMap) Get(key string) (interface{}, bool) { // 根据key计算出对应的分片 shard := m.GetShard(key) shard.RLock() // 从这个分片读取key的值 val, ok := shard.items[key] shard.RUnlock() return val, ok } ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:3:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"2.3 sync.Map Go 内建的 map 类型不是线程安全的，所以 Go 1.9 中增加了一个线程安全的 map，也就是 sync.Map。但是，这个 sync.Map 并不是用来替换内建的 map 类型的，它只能被应用在一些特殊的场景里。 官方的文档中指出，在以下两个场景中使用 sync.Map，会比使用 map+RWMutex 的方式，性能要好得多： 只会增长的缓存系统中，一个 key 只写入一次而被读很多次； 多个 goroutine 为不相交的键集读、写和重写键值对。 官方建议针对自己的场景做性能评测，如果确实能够显著提高性能，再使用 sync.Map。我们能用到 sync.Map 的场景确实不多。即便使用不多，也不妨碍我们去研究 sync.Map 的实现。 sync.Map 的实现有几个优化点，我们先列出来: 空间换时间。通过冗余的两个数据结构（只读的 read 字段、可写的 dirty），来减少加锁对性能的影响。对只读字段（read）的操作不需要加锁。 优先从 read 字段读取、更新、删除(不包括新增)，因为对 read 字段的读取不需要锁。 动态调整。miss 次数多了之后，将 dirty 数据提升为 read，避免总是从 dirty 中加锁读取。 double-checking。加锁之后先还要再检查 read 字段，确定真的不存在才操作 dirty 字段。 延迟删除。删除一个键值只是打标记，只有在提升 dirty 字段为 read 字段的时候才清理删除的数据。 个人理解 sync.Map 的实现看了好几遍，始终不太理解为什么 sync.Map 要区分新增、删除。后来重读时思考了一下，个人理解是这样的: sync.Map 是为了实现支持并发的 map，实际保存数据的还是底层的 map，所以增删操作最后修改的还是底层的 map，map 不是并发安全的，所以增删操作无论如何都需要加锁。 对于更新操作，key 和 value 已经存在，更新操作修改是 value 对应内存中的值，可使用 atomic 原子操作完成 删除操作会在 dirty 中直接删除，但是 read 中只是将 value 设置为 nil 标记删除，这样可以避免对 read 加锁，但是这样 map 使用的内存会一直增长无法收缩，read 中真正的数据删除发生在 dirty 提升为 read 时 新加的元素需要放入到 dirty 中，如果 dirty 为 nil，那么需要从 read 字段中复制出来一个 dirty 对象。在数据从 read 往 dirty 迁移的过程中只迁移没有被标记为删除的KV，同时把 value 为 nil 的 value 重置为 expunged，表示 key 只存在于readonly之中，不存在于dirty中。所以 nil 和 expunged 都代表元素被删除了，只不过expunged比较特殊，如果被删除的元素是expunged,代表它只存在于readonly之中，不存在于dirty中。这样如果重新设置这个key的话，需要往dirty增加key 下面我们就来看看 sync.Map 的设计与实现 sync.Map 数据结构 type Map struct { mu Mutex // 基本上你可以把它看成一个安全的只读的map // 它包含的元素其实也是通过原子操作更新的，但是已删除的entry就需要加锁操作了 read atomic.Value // readOnly // 包含需要加锁才能访问的元素 // 包括所有在read字段中但未被expunged（删除）的元素以及新加的元素 dirty map[interface{}]*entry // 记录从read中读取miss的次数，一旦miss数和dirty长度一样了，就会把dirty提升为read，并把dirty置空 misses int } type readOnly struct { m map[interface{}]*entry amended bool // 当dirty中包含read没有的数据时为true，比如新增一条数据 } // expunged是用来标识此项已经删掉的指针 // 当map中的一个项目被删除了，只是把它的值标记为expunged，以后才有机会真正删除此项 var expunged = unsafe.Pointer(new(interface{})) // entry代表一个值 type entry struct { p unsafe.Pointer // *interface{} } func (e *entry) load() (value interface{}, ok bool) { p := atomic.LoadPointer(\u0026e.p) if p == nil || p == expunged { return nil, false } return *(*interface{})(p), true } func newEntry(i interface{}) *entry { return \u0026entry{p: unsafe.Pointer(\u0026i)} } 通过 go doc 可以轻松看到 sync.Map 具有如下方法: type Map func (m *Map) Delete(key interface{}) func (m *Map) Load(key interface{}) (value interface{}, ok bool) func (m *Map) LoadAndDelete(key interface{}) (value interface{}, loaded bool) func (m *Map) LoadOrStore(key, value interface{}) (actual interface{}, loaded bool) func (m *Map) Range(f func(key, value interface{}) bool) func (m *Map) Store(key, value interface{}) Store、Load 和 Delete 这三个核心函数的操作都是先从 read 字段中处理的，因为读取 read 字段的时候不用加锁。 Store 方法 func (m *Map) Store(key, value interface{}) { read, _ := m.read.Load().(readOnly) // 如果read字段包含这个项，说明是更新，cas更新项目的值即可 if e, ok := read.m[key]; ok \u0026\u0026 e.tryStore(\u0026value) { return } // read中不存在，或者cas更新失败，就需要加锁访问dirty了 m.mu.Lock() read, _ = m.read.Load().(readOnly) if e, ok := read.m[key]; ok { // 双检查，看看read是否已经存在了 if e.unexpungeLocked() { // 此项目先前已经被删除了，通过将它的值设置为nil，标记为unexpunged // 注: 属于重用删除的对象，必须先把 read 中的 unexpunged 重置为 nil，否则重用的 key 会一直被标记为已经删除 // e.unexpungeLocked 执行后，read 和 dirty 中 e.p 的指向就不一样了， // read 中 e.p 已经被置为 nil，所以这里需要设置 dirty m.dirty[key] = e } e.storeLocked(\u0026value) // 更新 } else if e, ok := m.dirty[key]; ok { // 如果dirty中有此项 e.storeLocked(\u0026value) // 直接更新 } else { // 否则就是一个新的key if !read.amended { //如果dirty为nil // 需要创建dirty对象，并且标记read的amended为true, // 说明有元素它不包含而dirty包含 m.dirtyLocked() m.read.Store(readOnly{m: read.m, amended: true}) } m.dirty[key] = newEntry(value) //将新值增加到dirty对象中 } m.mu.Unlock() } // 新加的元素需要放入到 dirty 中，如果 dirty 为 nil，那么需要从 read 字段中复制出来一个 dirty 对象： func (m *Map) dirtyLocked() { if m.dirty != nil { return } read, _ := m.read.Load().(readOnly) m.dirty = make(map[interface{}]*entry, len(read.m)) for k, e := range read.m { if !e.tryExpungeLocked() { m.dirty[k] = e } } } // unexpungeLocked ensures that the entry is not marked as expunged. // // If the entry was previously expunged, it must be added to the","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:3:1","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"3. map 的扩展 还有一些扩展其它功能的 map 实现，比如 带有过期功能的timedmap 使用红黑树实现的 key 有序的treemap等。 ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:4:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-08","objectID":"/posts/program/go/sync/go_sync_9/:5:0","tags":["go 并发"],"title":"线程安全的 map","uri":"/posts/program/go/sync/go_sync_9/"},{"categories":["Go"],"content":"go Once 实现单例","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"Once 有且仅有一次执行 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:0:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"1. Once 概述 Once 可以用来执行且仅仅执行一次动作：Once 常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:1:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"1.1 单例对象初始化 初始化单例资源有很多方法，比如定义 package 级别的变量: package abc import time var startTime = time.Now() 或者在 init 函数中 package abc var startTime time.Time func init() { startTime = time.Now() } 又或者在 main 函数开始执行的时候: package abc var startTime time.Time func initApp() { startTime = time.Now() } func main() { initApp() } 这三种方法都是线程安全的，并且后两种方法还可以根据传入的参数实现定制化的初始化操作。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:1:1","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"1.2 延迟初始化 但是很多时候我们是要延迟进行初始化，比如下面初始化网络连接的示例: package main import ( \"net\" \"sync\" \"time\" ) var connMu sync.Mutex var conn net.Conn func getConn() net.Conn { connMu.Lock() defer connMu.Unlock() if conn != nil { return conn } conn, _ = net.DialTimeout(\"tcp\", \"baidu.com:80\", 10*time.Second) return conn } func main(){ conn:=getConn() if conn == nil{ panic(\"conn is nil\") } } 这种方式虽然实现起来简单，但是有性能问题。一旦连接创建好，每次请求的时候还是得竞争锁才能读取到这个连接。这时候我们就需要 Once 并发原语了。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:1:2","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"1.3 Once 的使用 sync.Once 只暴露了一个方法 Do: 你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数 因为当且仅当第一次调用 Do 方法的时候参数 f 才会执行，即使第二次、第三次、第 n 次调用时 f 参数的值不一样，也不会被执行 因为这里的 f 参数是一个无参数无返回的函数，所以你可能会通过闭包的方式引用外面的参数 func (o *Once) Do(f func()) package main import ( \"net\" \"sync\" ) var addr = \"baidu.com\" var conn net.Conn var err error var once sync.Once once.Do(func(){ conn, err = net.Dial(\"tcp\", addr) }) 有很多标准库中都有 Once 的身影，典型的 math/big/sqrt.go 中实现的一个数据结构，它通过 Once 封装了一个只初始化一次的值： // 值是3.0或者0.0的一个数据结构 var threeOnce struct { sync.Once v *Float } // 返回此数据结构的值，如果还没有初始化为3.0，则初始化 func three() *Float { threeOnce.Do(func() { // 使用Once初始化 threeOnce.v = NewFloat(3.0) }) return threeOnce.v } 当你使用 Once 的时候，你也可以尝试采用这种结构，将值和 Once 封装成一个新的数据结构，提供只初始化一次的值。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:1:3","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"2. Once 实现 很多人觉得 Once 只需要使用一个 flag 标记是否初始化即可，最多使用 atomic 原子操作这个 flag 比如下面这个实现: type Once struct { done uint32 } func (o *Once) Do(f func()) { if !atomic.CompareAndSwapUint32(\u0026o.done, 0, 1) { return } f() } 但是，这个实现有一个很大的问题，就是如果参数 f 执行很慢的话，后续调用 Do 方法的 goroutine 虽然看到 done 已经设置为执行过了，但是获取某些初始化资源的时候可能会得到空的资源，因为 f 还没有执行完。 所以一个正确的 Once 实现同事需要互斥锁和 flag 的双重检测机制: 互斥锁的机制保证只有一个 goroutine 进行初始化，并在 f() 未执行完成时，其他 goroutine 等待 flag 用于 f() 执行之后快速成功，以及保证只有一次初始化 type Once struct { done uint32 m Mutex } func (o *Once) Do(f func()) { // 1. flag 用于快速成功，不用在 f() 完成后，仍去竞争锁 if atomic.LoadUint32(\u0026o.done) == 0 { o.doSlow(f) } } func (o *Once) doSlow(f func()) { // 2. f() 未执行完时，多个 goroutine 都会争抢锁，从而等待 f() 执行完成 o.m.Lock() defer o.m.Unlock() // 3. 双检查机制保证只有 f() 只执行一次 if o.done == 0 { defer atomic.StoreUint32(\u0026o.done, 1) f() } } 所谓的双检查就是，即便进入 doSlow 后获取到锁，也要判断初始化是否已经完成。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:2:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"3.Once 采坑点 使用 Once 有两个常见错误: 死锁: Do 方法会执行一次 f，但是如果 f 中再次调用这个 Once 的 Do 方法的话，就会导致死锁的情况出现 初始化未完成: 如果 f 方法执行的时候 panic，或者 f 执行初始化资源的时候失败了，这个时候，Once 还是会认为初次执行已经成功了，即使再次调用 Do 方法，也不会再次执行 f。 Once 有一个比较典型的采坑案例，场景是这样的: Once Do 方法只能初始化一次，有时候我们需要能够重新初始化，即为 Once 增加一个 Reset 方法，Reset 之后再调用 once.Do 就又可以初始化了。Go 的核心开发者 Ian Lance Taylor 给了一个简单的解决方案，即 Reset 的时候将 原有的 Once 变量(例如变量ponce)赋值一个新的 Once 实例即可 (ponce = new(sync.Once))。这样在新的 ponce 就可以再次执行初始化。但是我们不能像这样: ponce.Do(ponce.Reset()) 在 Do 方法中，重新给 ponce 赋值。原因在于 在执行 ponce.Reset 的时候 Once 内部的 Mutex 首先会加锁， 在 Reset 中更改了 Once 指针的值之后，结果在执行完 Reset 释放锁的时候，释放的是一个刚初始化未加锁的 Mutex，所以就 panic 了 下面的 doSlow 方法就演示了这个错误: package main import ( \"sync\" ) type Once struct { m sync.Mutex } func (o *Once) doSlow() { o.m.Lock() defer o.m.Unlock() // 这里更新的o指针的值!!!!!!!, 会导致上一行Unlock出错 *o = Once{} } func main() { var once Once once.doSlow() } Ian Lance Taylor 介绍的 Reset 方法没有错误，但是你在使用的时候千万别再初始化函数中 Reset 这个 Once，否则势必会导致 Unlock 一个未加锁的 Mutex 的错误。这里再多补充一下这个 panic 的触发逻辑: Once doSlow 实现中有 o.m.Lock; defer o.m.Unlock() 如果调用 Do(Reset()) 就会导致这样的调用顺序: 初始 o.m.Lock() -\u003e Reset 设置新的 o.m -\u003e 调用新的 o.m.Unlock()，释放未加锁的锁，导致 panic。 使用 Once 真的不容易犯错，想犯错都很困难，因为很少有人会傻傻地在初始化函数 f 中递归调用 f，这种死锁的现象几乎不会发生。另外如果函数初始化不成功，我们一般会 panic，或者在使用的时候做检查，会及早发现这个问题，在初始化函数中加强代码。 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:3:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"4. Once 的扩展 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:4:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"4.1 可多次初始化的 Once 针对初始化未完成的情况，我们可以自己实现一个类似 Once 的并发原语，既可以返回当前调用 Do 方法是否正确完成，还可以在初始化失败后调用 Do 方法再次尝试初始化，直到初始化成功才不再初始化了。 // 一个功能更加强大的Once type Once struct { m sync.Mutex done uint32 } // 传入的函数f有返回值error，如果初始化失败，需要返回失败的error // Do方法会把这个error返回给调用者 func (o *Once) Do(f func() error) error { if atomic.LoadUint32(\u0026o.done) == 1 { //fast path return nil } return o.slowDo(f) } // 如果还没有初始化 func (o *Once) slowDo(f func() error) error { o.m.Lock() defer o.m.Unlock() var err error if o.done == 0 { // 双检查，还没有初始化 err = f() if err == nil { // 初始化成功才将标记置为已初始化 atomic.StoreUint32(\u0026o.done, 1) } } return err } ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:4:1","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"4.2 可获取是否初始化的 Once 目前的 Once 实现可以保证你调用任意次数的 once.Do 方法，它只会执行这个方法一次。但是，有时候我们需要一个是否初始化的标记。标准库的 Once 并不会告诉你是否初始化完成了。所以通常我们需要一个辅助变量，自己去检查是否初始化完成: type AnimalStore struct {once sync.Once;inited uint32} func (a *AnimalStore) Init() // 可以被并发调用 a.once.Do(func() { longOperationSetupDbOpenFilesQueuesEtc() atomic.StoreUint32(\u0026a.inited, 1) }) } func (a *AnimalStore) CountOfCats() (int, error) { // 另外一个goroutine if atomic.LoadUint32(\u0026a.inited) == 0 { // 初始化后才会执行真正的业务逻辑 return 0, NotYetInitedError } //Real operation } 另一个解决方案是，我们可以自己去扩展 Once 的并发原语，为其提供一个返回是否已初始化的 Done 方法: // Once 是一个扩展的sync.Once类型，提供了一个Done方法 type Once struct { sync.Once } // Done 返回此Once是否执行过 // 如果执行过则返回true // 如果没有执行过或者正在执行，返回false func (o *Once) Done() bool { return atomic.LoadUint32((*uint32)(unsafe.Pointer(\u0026o.Once))) == 1 } func main() { var flag Once fmt.Println(flag.Done()) //false flag.Do(func() { time.Sleep(time.Second) }) fmt.Println(flag.Done()) //true } 注: 相信有人跟我一样看到 atomic.LoadUint32((*uint32)(unsafe.Pointer(\u0026o.Once))) == 1 时怀疑人生路，这个怎么能判断 Once是否执行过了呢。这是因为你看的是鸟哥扩展的 Once 实现，done 字段在后: type Once struct { m sync.Mutex done uint32 } go Once 源码里面，done 字段是在前的: type Once struct { done uint32 m Mutex } ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:4:2","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-07","objectID":"/posts/program/go/sync/go_sync_8/:5:0","tags":["go 并发"],"title":"Once 实现单例","uri":"/posts/program/go/sync/go_sync_8/"},{"categories":["Go"],"content":"go Cond 条件变量","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"Cond 条件变量 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:0:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"1. Cond 概述 Go 标准库提供 Cond 原语的目的是，为等待 / 通知场景下的并发问题提供支持。Cond 通常应用于等待某个条件的一组 goroutine，等条件变为 true 的时候，其中一个 goroutine 或者所有的 goroutine 都会被唤醒执行。顾名思义，Cond 是和某个条件相关: 条件没有满足时，所有等待这个条件的 goroutine 都被阻塞 条件满足时，等待的 goroutine 可以继续进行执行 顾名思义，Cond 是和某个条件相关，而使用 Cond 的是两组协程: 第一组 goroutine 共同协作完成条件 第二组 goroutine 等待直至条件完成 Cond 在实际项目中被使用的机会比较少，原因总结起来有两个: 因为一旦遇到需要使用 Cond 的场景，我们更多地会使用 Channel 的方式去实现，因为 channel 才是更地道的 Go 语言的写法 对于简单的 wait/notify 场景，比如等待一组 goroutine 完成之后继续执行余下的代码，我们会使用 WaitGroup 来实现 但是 Cond 有三点特性是 Channel 无法替代的： Cond 和一个 Locker 关联，可以利用这个 Locker 对相关的依赖条件更改提供保护 Cond 可以同时支持 Signal 和 Broadcast 方法，而 Channel 只能同时支持其中一种 Cond 的 Broadcast 方法可以被重复调用。等待条件再次变成不满足的状态后，我们又可以调用 Broadcast 再次唤醒等待的 goroutine。这也是 Channel 不能支持的，Channel 被 close 掉了之后不支持再 open 本质上 WaitGroup 和 Cond 是有区别的: WaitGroup 是主 goroutine 等待确定数量的子 goroutine 完成任务； Cond 是等待某个条件满足，这个条件的修改可以被任意多的 goroutine 更新，而且 Cond 的 Wait 不关心也不知道其他 goroutine 的数量，只关心等待条件 而且 Cond 还有单个通知的机制，也就是 Signal 方法 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:1:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"1.1 Cond 使用 标准库中的 Cond 并发原语初始化的时候，需要关联一个 Locker 接口的实例，一般我们使用 Mutex 或者 RWMutex。Cond 初始化和提供的方法如下: type Cond func NeWCond(l Locker) *Cond func (c *Cond) Broadcast() func (c *Cond) Signal() func (c *Cond) Wait() 首先，Cond 关联的 Locker 实例可以通过 c.L 访问，它内部维护着一个先入先出的等待队列 Signal 方法: 允许调用者 Caller 唤醒一个等待此 Cond 的 goroutine Cond 等待队列中有多个等待的 goroutine 时，需要从等待队列中移除第一个 goroutine 并唤醒 调用 Signal 方法时，不强求你一定要持有 c.L 的锁 Broadcast 方法: 允许调用者 Caller 唤醒所有等待此 Cond 的 goroutine 如果 Cond 等待队列中有一个或者多个等待的 goroutine，则清空所有等待的 goroutine，并全部唤醒 调用 Broadcast 方法时，也不强求你一定持有 c.L 的锁 Wait 方法: 把调用者 Caller 放入 Cond 的等待队列中并阻塞 调用 Wait 方法时必须要持有 c.L 的锁 至于为什么调用 Wait() 必须要持有锁，我的理解是，所有调用 Wait() 的方法都需要检查条件是否满足，甚至会改变检查条件，它们彼此应该是互斥的，需要使用锁保护检查条件 下面是 Cond 的使用示例: func main() { c := sync.NewCond(\u0026sync.Mutex{}) var ready int for i := 0; i \u003c 10; i++ { go func(i int) { time.Sleep(time.Duration(rand.Int63n(10)) * time.Second) // 加锁更改等待条件 // 注意点一: 条件变量的更改，其实是需要原子操作或者互斥锁保护的 c.L.Lock() ready++ c.L.Unlock() log.Printf(\"运动员#%d 已准备就绪\\n\", i) // 广播唤醒所有的等待者 c.Broadcast() }(i) } // 注意点三: Wait() 方法调用前需要先获取锁 c.L.Lock() // 注意点二: Wait 唤醒后需要检查条件 // 我们一定要记住，waiter goroutine 被唤醒不等于等待条件被满足 for ready != 10 { c.Wait() log.Println(\"裁判员被唤醒一次\") } c.L.Unlock() //所有的运动员是否就绪 log.Println(\"所有运动员都准备就绪。比赛开始，3，2，1, ......\") } ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:1:1","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"2. Cond 实现 Cond 的实现非常简单，或者说复杂的逻辑已经被 Locker 或者 runtime 的等待队列实现了。 type Cond struct { noCopy noCopy // 当观察或者修改等待条件的时候需要加锁 L Locker // 等待队列 notify notifyList checker copyChecker } func NewCond(l Locker) *Cond { return \u0026Cond{L: l} } func (c *Cond) Wait() { c.checker.check() // 增加到等待队列中 t := runtime_notifyListAdd(\u0026c.notify) // 把当前调用者加入到 notify 队列之中后会释放锁 c.L.Unlock() // 阻塞休眠直到被唤醒 // 等调用者被唤醒之后，又会去争抢这把锁 runtime_notifyListWait(\u0026c.notify, t) c.L.Lock() } func (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026c.notify) } func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026c.notify） } 在 Cond 实现中: runtime_notifyListXXX 是运行时实现的方法，实现了一个等待 / 通知的队列，代码位于 runtime/sema.go 中 copyChecker 是一个辅助结构，可以在运行时检查 Cond 是否被复制使用 Signal 和 Broadcast 只涉及到 notifyList 数据结构，不涉及到锁 Wait 把调用者加入到等待队列时会释放锁，在被唤醒之后还会请求锁。在阻塞休眠期间，调用者是不持有锁的，这样能让其他 goroutine 有机会检查或者更新等待变量。 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:2:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"2.1 开源项目的应用 开源项目中使用 sync.Cond 的代码少之又少，Kubernetes 中有一个使用 Cond 的例子。Kubernetes 项目中定义了优先级队列 PriorityQueue 这样一个数据结构，用来实现 Pod 的调用。它内部有三个 Pod 的队列，即 activeQ、podBackoffQ 和 unschedulableQ，其中 activeQ 就是用来调度的活跃队列（heap）。Pop 方法调用的时候，如果这个队列为空，并且这个队列没有 Close 的话，会调用 Cond 的 Wait 方法等待。 // 从队列中取出一个元素 func (p *PriorityQueue) Pop() (*framework.QueuedPodInfo, error) { p.lock.Lock() defer p.lock.Unlock() for p.activeQ.Len() == 0 { // 如果队列为空 if p.closed { return nil, fmt.Errorf(queueClosed) } p.cond.Wait() // 等待，直到被唤醒 } ...... return pInfo, err } 当 activeQ 增加新的元素时，会调用条件变量的 Boradcast 方法，通知被 Pop 阻塞的调用者。 // 增加元素到队列中 func (p *PriorityQueue) Add(pod *v1.Pod) error { p.lock.Lock() defer p.lock.Unlock() pInfo := p.newQueuedPodInfo(pod) if err := p.activeQ.Add(pInfo); err != nil {//增加元素到队列中 klog.Errorf(\"Error adding pod %v to the scheduling queue: %v\", nsNameForPod(pod), err) return err } ...... p.cond.Broadcast() //通知其它等待的goroutine，队列中有元素了 return nil } 这个优先级队列被关闭的时候，也会调用 Broadcast 方法，避免被 Pop 阻塞的调用者永远 hang 住。 func (p *PriorityQueue) Close() { p.lock.Lock() defer p.lock.Unlock() close(p.stop) p.closed = true p.cond.Broadcast() //关闭时通知等待的goroutine，避免它们永远等待 } 对于需要重复调用 Broadcast 的场景，比如这里的 Kubernetes 的例子，每次往队列中成功增加了元素后就需要调用 Broadcast 通知所有的等待者，使用 Cond 就再合适不过了。 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:2:1","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"3. Cond 采坑点 使用 Cond 时有两个常见错误 一个是调用 Wait 的时候没有加锁 另一个是没有检查条件是否满足程序就继续执行了 我们一定要记住，waiter goroutine 被唤醒不等于等待条件被满足，只是有 goroutine 把它唤醒了而已，等待条件有可能已经满足了，也有可能不满足，我们需要进一步检查。你也可以理解为，等待者被唤醒，只是得到了一次检查的机会而已。 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:3:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"4. Cond 使用上的理解 Cond 在使用 Wait() 方法前需要调用 Lock() 这一点，在使用上的确很容易让人迷惑，我个人的理解是这样的。Cond 的核心是对条件的判断，改变条件相当于写，是需要加锁的，那同时判断条件是否满足是读，同样也需要加锁。调用 Wait 方法前，肯定已经判断了条件不满足，此时必定是加锁了。所以在 Wait 方法内，先释放锁，唤醒后在加锁，是读条件必须加锁这个场景要求的。Wait 释放锁再加锁是果，而不是因，我们要牢记的是在读写条件的时候都必须加锁。于此同时也正是因为 Cond 的条件是在实现之外维护的，所以 Cond 支持条件比 Channel 和 WaitGroup 更加灵活。 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:4:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-06","objectID":"/posts/program/go/sync/go_sync_7/:5:0","tags":["go 并发"],"title":"Cond 条件变量","uri":"/posts/program/go/sync/go_sync_7/"},{"categories":["Go"],"content":"go WaitGroup 任务编排","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"WaitGroup 任务编排 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:0:0","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"1. WaitGroup 使用 WaitGroup 很简单，就是 package sync 用来做任务编排的一个并发原语。它要解决的就是并发 - 等待的问题: goroutine A 等待一组 goroutine 全部完成。 很多操作系统和编程语言都提供了类似的并发原语。比如，Linux 中的 barrier、Pthread（POSIX 线程）中的 barrier、C++ 中的 std::barrier、Java 中的 CyclicBarrier 和 CountDownLatch 等。 WaitGroup 非常适用于此类场景: 需要启动多个 goroutine 执行任务，主 goroutine 需要等待子 goroutine 都完成后才继续执行。 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:1:0","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"1.1 WaitGroup 使用 Go 标准库中的 WaitGroup 提供了三个方法: func (wg *WaitGroup) Add(delta int) func (wg *WaitGroup) Done() func (wg *WaitGroup) Wait() Add，用来设置 WaitGroup 的计数值； Done，用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)； Wait，调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0 下面是 WaitGroup 的使用示例: // 线程安全的计数器 type Counter struct { mu sync.Mutex count uint64 } // 对计数值加一 func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } // 获取当前的计数值 func (c *Counter) Count() uint64 { c.mu.Lock() defer c.mu.Unlock() return c.count } // sleep 1秒，然后计数值加1 func worker(c *Counter, wg *sync.WaitGroup) { defer wg.Done() time.Sleep(time.Second) c.Incr() } func main() { var counter Counter var wg sync.WaitGroup wg.Add(10) // WaitGroup的值设置为10 for i := 0; i \u003c 10; i++ { // 启动10个goroutine执行加1任务 go worker(\u0026counter, \u0026wg) } // 检查点，等待goroutine都完成任务 wg.Wait() // 输出当前计数器的值 fmt.Println(counter.Count()) } ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:1:1","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2. WaitGroup 实现 type WaitGroup struct { // 避免复制使用的一个技巧，可以告诉vet工具违反了复制使用的规则 noCopy noCopy // 64bit(8bytes)的值分成两段，高32bit是计数值，低32bit是waiter的计数 // 另外32bit是用作信号量的 // 因为64bit值的原子操作需要64bit对齐，但是32bit编译器不支持，所以数组中的元素在不同的架构中不一样，具体处理看下面的方法 // 总之，会找到对齐的那64bit作为state，其余的32bit做信号量 state1 [3]uint32 } // 得到state的地址和信号量的地址 func (wg *WaitGroup) state() (statep *uint64, semap *uint32) { // %8 表示 8 个字节，注意不是位 // 32位还是64位计算机不是关键点，关键点是 state1 有没有按照 64 位对齐，32位计算机上 state1 也可能刚好对齐到 64 位上 if uintptr(unsafe.Pointer(\u0026wg.state1))%8 == 0 { // 如果地址是64bit对齐的，数组前两个元素做state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1)), \u0026wg.state1[2] } else { // 如果地址是32bit对齐的，数组后两个元素用来做state，它可以用来做64bit的原子操作，第一个元素32bit用来做信号量 return (*uint64)(unsafe.Pointer(\u0026wg.state1[1])), \u0026wg.state1[0] } } WaitGroup 的数据结构包括两个字段: noCopy noCopy: 辅助字段，主要就是辅助 vet 工具检查是否通过 copy 赋值这个 WaitGroup 实例 state1 [3]uint32: 一个具有复合意义的字段，包含 WaitGroup 的计数、阻塞在检查点的 waiter 数和信号量。 因为64bit值的原子操作需要64bit对齐，但是32bit编译器不支持，所以数组中的元素在不同的架构中不一样，处理方法在 state() 方法中 在 64 位环境下，state1 的第一个元素是 waiter 数，第二个元素是 WaitGroup 的计数值，第三个元素是信号量 在 32 位环境下，如果 state1 不是 64 位对齐的地址，那么 state1 的第一个元素是信号量，后两个元素分别是 waiter 数和计数值 接下来我们来看 Add、Done 和 Wait 这三个方法的实现。在查看这部分源码实现时，除了这些方法本身的实现外，还会有一些额外的代码，主要是 race 检查和异常检查的代码。其中，有几个检查非常关键，如果检查不通过，会出现 panic。我们在介绍完这三个方法的实现之后再来统一介绍。 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:0","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.1 Add 方法实现 Add 方法主要操作的是 state 的计数部分，可以为计数值增加一个 delta 值，内部通过原子操作把这个值加到计数值上，delta 也可以是个负数，相当于为计数值减去一个值，Done 方法内部其实就是通过 Add(-1) 实现的。 func (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() // 高32bit是计数值v，所以把delta左移32，增加到计数上 state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter count if v \u003e 0 || w == 0 { return } // 如果计数值v为0并且waiter的数量w不为0，那么state的值就是waiter的数量 // 将waiter的数量设置为0，因为计数值v也是0,所以它们俩的组合*statep直接设置为0即可。此时需要并唤醒所有的waiter // Add(-n) 的处理逻辑 *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } // Done方法实际就是计数器减1 func (wg *WaitGroup) Done() { wg.Add(-1) } ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:1","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.2 Wait 方法实现 Wait 方法的实现逻辑是： 不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回 如果计数值大于 0，说明此时还有任务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。 func (wg *WaitGroup) Wait() { statep, semap := wg.state() for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) // 当前计数值 w := uint32(state) // waiter的数量 if v == 0 { // 如果计数值为0, 调用这个方法的goroutine不必再等待，继续执行它后面的逻辑即可 return } // 否则把waiter数量加1。期间可能有并发调用Wait的情况，所以最外层使用了一个for循环 if atomic.CompareAndSwapUint64(statep, state, state+1) { // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return } } } ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:2","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.3 异常检测 前面我们分析 Add 和 Wait 实现的时候删除了异常检测的代码，这些异常检测的逻辑就是我们使用 WaitGroup 的避坑指南。通常使用 WaitGroup 时会出现以下三个问题: 计数器设置为负值: 检查点: WaitGroup 的计数器的值必须大于等于 0。我们在更改这个计数值的时候，WaitGroup 会先做检查，如果计数值被设置为负数，就会导致 panic。 错误点: 一般情况下，有两种方法会导致计数器设置为负数 调用 Add 的时候传递一个负数，导致计数器加上这个负值后小于 0 调用 Done 方法的次数过多，超过了 WaitGroup 的计数值 建议: 使用 WaitGroup 的正确姿势是，预先确定好 WaitGroup 的计数值，然后调用相同次数的 Done 完成相应的任务 不期望的 Add 时机: 在使用 WaitGroup 的时候，你一定要遵循的原则就是，等所有的 Add 方法调用之后再调用 Wait，否则就可能导致 panic 或者不期望的结果 前一个 Wait 还没结束就重用 WaitGroup WaitGroup 是可以重用的。只要 WaitGroup 的计数值恢复到零值的状态，那么它就可以被看作是新创建的 WaitGroup，被重复使用。 但是，如果我们在 WaitGroup 的计数值还没有恢复到零值的时候就重用，就会导致程序 panic 这个并发的 Data Race 在于: Add() 方法在将计数器归零时，需要唤醒所有被 Wait 住的协程，在这个过程中间是不能有并发的 Add 和 Wait 方法调用的 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:3","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.4 错误示例 在这个例子中，我们原本设想的是，等四个 goroutine 都执行完毕后输出 Done 的信息，但是它的错误之处在于，将 WaitGroup.Add 方法的调用放在了子 gorotuine 中。等主 goorutine 调用 Wait 的时候，因为四个任务 goroutine 一开始都休眠，所以可能 WaitGroup 的 Add 方法还没有被调用，WaitGroup 的计数还是 0，所以它并没有等待四个子 goroutine 执行完毕才继续执行，而是立刻执行了下一步。 // 不期望的 Add 时机 func main() { var wg sync.WaitGroup // 解决方法一: // wg.Add(4) // 预先设定WaitGroup的计数值 go dosomething(100, \u0026wg) // 启动第一个goroutine go dosomething(110, \u0026wg) // 启动第二个goroutine go dosomething(120, \u0026wg) // 启动第三个goroutine go dosomething(130, \u0026wg) // 启动第四个goroutine wg.Wait() // 主goroutine等待完成 fmt.Println(\"Done\") } func dosomething(millisecs time.Duration, wg *sync.WaitGroup) { duration := millisecs * time.Millisecond time.Sleep(duration) // 故意sleep一段时间 wg.Add(1) fmt.Println(\"后台执行, duration:\", duration) wg.Done() } 在下面的例子中，第 6 行虽然让 WaitGroup 的计数恢复到 0，但是因为第 9 行有个 waiter 在等待，如果等待 Wait 的 goroutine，刚被唤醒就和 Add 调用（第 7 行）有并发执行的冲突，所以就会出现 panic。 // 前一个 Wait 还没结束就重用 WaitGroup func main() { var wg sync.WaitGroup wg.Add(1) go func() { time.Sleep(time.Millisecond) wg.Done() // 计数器减1 wg.Add(1) // 计数值加1 }() wg.Wait() // 主goroutine等待，有可能和第7行并发执行 } 总结一下：WaitGroup 虽然可以重用，但是是有一个前提的，那就是必须等到上一轮的 Wait 完成之后，才能重用 WaitGroup 执行下一轮的 Add/Wait，如果你在 Wait 还没执行完的时候就调用下一轮 Add 方法，就有可能出现 panic。 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:4","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.4 WaitGroup 的 Race Check WaitGroup 的异常检查，我看几遍，都没能彻底理解 WaitGroup 重用导致 panic 的根本原因。其实 WaitGroup 代码很少，直接看代码可能更容易帮助理解 panic 发生确切时机。 Add 的 Race Check // Copyright 2011 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. package sync import ( \"internal/race\" \"sync/atomic\" \"unsafe\" ) func (wg *WaitGroup) Add(delta int) { statep, semap := wg.state() if race.Enabled { _ = *statep // trigger nil deref early if delta \u003c 0 { // Synchronize decrements with Wait. race.ReleaseMerge(unsafe.Pointer(wg)) } race.Disable() defer race.Enable() } state := atomic.AddUint64(statep, uint64(delta)\u003c\u003c32) v := int32(state \u003e\u003e 32) w := uint32(state) if race.Enabled \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { // The first increment must be synchronized with Wait. // Need to model this as a read, because there can be // several concurrent wg.counter transitions from 0. race.Read(unsafe.Pointer(semap)) } if v \u003c 0 { panic(\"sync: negative WaitGroup counter\") } if w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta) { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } if v \u003e 0 || w == 0 { return } // This goroutine has set counter to 0 when waiters \u003e 0. // Now there can't be concurrent mutations of state: // - Adds must not happen concurrently with Wait, // - Wait does not increment waiters if it sees counter == 0. // Still do a cheap sanity check to detect WaitGroup misuse. if *statep != state { panic(\"sync: WaitGroup misuse: Add called concurrently with Wait\") } // Reset waiters count to 0. *statep = 0 for ; w != 0; w-- { runtime_Semrelease(semap, false, 0) } } 从代码可以看到 Add 是触发 panic 有三个地方: v \u003c 0: 即计数器设置为负值 w != 0 \u0026\u0026 delta \u003e 0 \u0026\u0026 v == int32(delta): waiter 数不为 0, 此时添加了 Add，并且 state 字段记录的计数器等于此次 Add 的值，说明上一次 Wait() 还没有结束就 Add 了新值。这是并发修改的场景一 *statep != state: 执行到此处，经过前面的判断条件过滤，此处 v 只能等于 0，此时需要做的只有唤醒所有 Wait 住的协程，不能有并发的 Add() 和 Wait() 方法调用，这是并发修改的场景二。 同时正如注释里面所说的这是一个\"连接的检查\"，如果并发是发生在 这个检查和下面触发 Wait 住的协程之间是不会异常的，但是程序已经出现了意料之外的结果。 Wait 的 Race Check // Done decrements the WaitGroup counter by one. func (wg *WaitGroup) Done() { wg.Add(-1) } // Wait blocks until the WaitGroup counter is zero. func (wg *WaitGroup) Wait() { statep, semap := wg.state() if race.Enabled { _ = *statep // trigger nil deref early race.Disable() } for { state := atomic.LoadUint64(statep) v := int32(state \u003e\u003e 32) w := uint32(state) if v == 0 { // Counter is 0, no need to wait. if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(wg)) } return } // Increment waiters count. if atomic.CompareAndSwapUint64(statep, state, state+1) { if race.Enabled \u0026\u0026 w == 0 { // Wait must be synchronized with the first Add. // Need to model this is as a write to race with the read in Add. // As a consequence, can do the write only for the first waiter, // otherwise concurrent Waits will race with each other. race.Write(unsafe.Pointer(semap)) } runtime_Semacquire(semap) if *statep != 0 { panic(\"sync: WaitGroup is reused before previous Wait has returned\") } if race.Enabled { race.Enable() race.Acquire(unsafe.Pointer(wg)) } return } } } 从代码可以看到 Wait() 触发的异常只有一个地方: *statep != 0: 因为在 Add 唤醒阻塞的 Wait 协程前，已经将 *statep = 0，而如果此时 *statep != 0 说明在 Add() 触发被 Wait 住协程之后，有其他 Add() 和 Wait() 方法调用，是并发修改的场景。 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:5","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.5 noCopy 辅助 vet 检查 noCopy 就是指示 vet 工具在做检查的时候，这个数据结构不能做值复制使用。更严谨地说，是不能在第一次使用之后复制使用 ( must not be copied after first use)。noCopy 是一个通用的计数技术，其他并发原语中也会用到。 我们在前面学习 Mutex 的时候用到了 vet 工具。vet 会对实现 Locker 接口的数据类型做静态检查，一旦代码中有复制使用这种数据类型的情况，就会发出警告。WaitGroup 同步原语不就是 Add、Done 和 Wait 方法吗？vet 能检查出来吗？其实是可以的。通过给 WaitGroup 添加一个 noCopy 字段，我们就可以为 WaitGroup 实现 Locker 接口，这样 vet 工具就可以做复制检查了。而且因为 noCopy 字段是未输出类型，所以 WaitGroup 不会暴露 Lock/Unlock 方法。 noCopy 字段的类型是 noCopy，它只是一个辅助的、用来帮助 vet 检查用的类型: type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} 如果你想要自己定义的数据结构不被复制使用，或者说，不能通过 vet 工具检查出复制使用的报警，就可以通过嵌入 noCopy 这个数据类型来实现。 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:6","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"2.6 总结 关于如何避免错误使用 WaitGroup 的情况，我们只需要尽量保证下面 5 点就可以了： 不重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源开销，重用反而更容易出错 保证所有的 Add 方法调用都在 Wait 之前 不传递负数给 Add 方法，只通过 Done 来给计数值减 1 不做多余的 Done 方法调用，保证 Add 的计数值和 Done 方法调用的数量是一样的 不遗漏 Done 方法的调用，否则会导致 Wait hang 住无法返回 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:2:7","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-05","objectID":"/posts/program/go/sync/go_sync_6/:3:0","tags":["go 并发"],"title":"WaitGroup","uri":"/posts/program/go/sync/go_sync_6/"},{"categories":["Go"],"content":"go 读写锁 RWMutex","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"读写锁 RWMutex ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:0:0","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"1. RWMutex 使用 标准库中的 RWMutex 是一个 reader/writer 互斥锁，用来解决并发读写问题，特别适用于读多写少的场景。RWMutex 在某一时刻只能由任意数量的 reader 持有，或者是只被单个的 writer 持有。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:1:0","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"1.1 RWMutex RWMutex 的方法也很少，总共有 5 个: Lock/Unlock： 写操作时调用的方法 如果锁已经被 reader 或者 writer 持有，那么，Lock 方法会一直阻塞，直到能获取到锁； Unlock 则是配对的释放锁的方法 RLock/RUnlock： 读操作时调用的方法 如果锁已经被 writer 持有的话，RLock 方法会一直阻塞，直到能获取到锁，否则就直接返回 RUnlock 是 reader 释放锁的方法 RLocker：这个方法的作用是为读操作返回一个 Locker 接口的对象。它的 Lock 方法会调用 RWMutex 的 RLock 方法，它的 Unlock 方法会调用 RWMutex 的 RUnlock 方法 下面是使用 RWMutex 的简单示例: func main() { var counter Counter for i := 0; i \u003c 10; i++ { // 10个reader go func() { for { counter.Count() // 计数器读操作 time.Sleep(time.Millisecond) } }() } for { // 一个writer counter.Incr() // 计数器写操作 time.Sleep(time.Second) } } // 一个线程安全的计数器 type Counter struct { mu sync.RWMutex count uint64 } // 使用写锁保护 func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } // 使用读锁保护 func (c *Counter) Count() uint64 { c.mu.RLock() defer c.mu.RUnlock() return c.count } 在实际使用 RWMutex 的时候，如果我们在 struct 中使用 RWMutex 保护某个字段，一般会把它和这个字段放在一起，用来指示两个字段是一组字段。除此之外，我们还可以采用匿名字段的方式嵌入 struct，这样，在使用这个 struct 时，我们就可以直接调用 Lock/Unlock、RLock/RUnlock 方法了。 同样的，RWMutex 的零值是未加锁的状态，使用时不必显式地初始化。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:1:1","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"2. RWMutex 实现 RWMutex 一般都是基于互斥锁、条件变量（condition variables）或者信号量（semaphores）等并发原语来实现。Go 标准库中的 RWMutex 是基于 Mutex 实现的。 readers-writers 问题一般有三类，基于对读和写操作的优先级，读写锁的设计和实现也分成三类: Read-preferring： 读优先的设计可以提供很高的并发性，但是，在竞争激烈的情况下可能会导致写饥饿 这是因为，如果有大量的读，这种设计会导致只有所有的读都释放了锁之后，写才可能获取到锁 Write-preferring： 写优先的设计意味着，如果已经有一个 writer 在等待请求锁的话，它会阻止新来的请求锁的 reader 获取到锁，所以优先保障 writer。 当然，如果有一些 reader 已经请求了锁的话，新请求的 writer 也会等待已经存在的 reader 都释放锁之后才能获取。 所以，写优先级设计中的优先权是针对新来的请求而言的。这种设计主要避免了 writer 的饥饿问题。 不指定优先级： 这种设计比较简单，不区分 reader 和 writer 优先级 某些场景下这种不指定优先级的设计反而更有效，因为第一类优先级会导致写饥饿，第二类优先级可能会导致读饥饿，这种不指定优先级的访问不再区分读写，大家都是同一个优先级，解决了饥饿的问题 Go 标准库中的 RWMutex 设计是 Write-preferring 方案。一个正在阻塞的 Lock 调用会排除新的 reader 请求到锁。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:2:0","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"2.1 RWMutex 的定义 type RWMutex struct { w Mutex // 互斥锁解决多个writer的竞争 writerSem uint32 // writer信号量 readerSem uint32 // reader信号量 readerCount int32 // reader的数量 readerWait int32 // writer等待完成的reader的数量 } const rwmutexMaxReaders = 1 \u003c\u003c 30 RWMutex 包含如下几个字段: 字段 w：为 writer 的竞争锁而设计； 字段 readerCount：记录当前 reader 的数量（以及是否有 writer 竞争锁）； readerWait：记录 writer 请求锁时需要等待 read 完成的 reader 的数量； writerSem 和 readerSem：都是为了阻塞设计的信号量。 常量 rwmutexMaxReaders，定义了最大的 reader 数量。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:2:1","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"2.2 RLock/RUnlock 的实现 func (rw *RWMutex) RLock() { if atomic.AddInt32(\u0026rw.readerCount, 1) \u003c 0 { // rw.readerCount是负值的时候，意味着此时有writer等待请求锁，因为writer优先级高，所以把后来的reader阻塞休眠 runtime_SemacquireMutex(\u0026rw.readerSem, false, 0) } } func (rw *RWMutex) RUnlock() { if r := atomic.AddInt32(\u0026rw.readerCount, -1); r \u003c 0 { rw.rUnlockSlow(r) // 有等待的writer } } func (rw *RWMutex) rUnlockSlow(r int32) { if atomic.AddInt32(\u0026rw.readerWait, -1) == 0 { // 最后一个reader了，writer终于有机会获得锁了 runtime_Semrelease(\u0026rw.writerSem, false, 1) } } 在上面的实现，要注意 readerCount 可能为负数，这是因为 readerCount 这个字段有双重含义： 没有 writer 竞争或持有锁时，readerCount 和我们正常理解的 reader 的计数是一样的； 有 writer 竞争锁或者持有锁时，那么，readerCount 不仅仅承担着 reader 的计数功能，还能够标识当前是否有 writer 竞争或持有锁 当 writer 请求锁的时候，是无法改变既有的 reader 持有锁的现实的，也不会强制这些 reader 释放锁，它的优先权只是限定后来的 reader 不要和它抢。 所以，rUnlockSlow 将持有锁的 reader 计数减少 1 的时候，会检查既有的 reader 是不是都已经释放了锁，如果都释放了锁，就会唤醒 writer，让 writer 持有锁。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:2:2","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"2.3 Lock 为了避免 writer 之间的竞争，RWMutex 就会使用一个 Mutex 来保证 writer 的互斥。一旦一个 writer 获得了内部的互斥锁，就会反转 readerCount 字段，把它从原来的正整数 readerCount(\u003e=0) 修改为负数（readerCount-rwmutexMaxReaders），让这个字段保持两个含义（既保存了 reader 的数量，又表示当前有 writer）。 这样做的目的是为了将减少 reader 数量和判断是否有 writer 实现在一个原子操作内。 func (rw *RWMutex) Lock() { // 首先解决其他writer竞争问题 rw.w.Lock() // 反转readerCount，告诉reader有writer竞争锁 // 还会记录当前活跃的 reader 数量，所谓活跃的 reader，就是指持有读锁还没有释放的那些 reader r := atomic.AddInt32(\u0026rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 如果当前有reader持有锁，那么需要等待 // 并把当前 readerCount 赋值给 readerWait 字段 if r != 0 \u0026\u0026 atomic.AddInt32(\u0026rw.readerWait, r) != 0 { // 这里应该加一个 readerWait == 0 的判断，毕竟在 mutex 的实现中都有这种异常的判断 runtime_SemacquireMutex(\u0026rw.writerSem, false, 0) } } 在 RWMutex Lock 方法实现中: rw.w.Lock(): 保证了同时只有一个 writer 在竞争锁，并可能修改 RWMutex 的状态字段 一旦有 writer 获取了这个锁，就会反转 readerCount 字段，表示当前已经有 writer 在竞争锁了 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:2:3","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"2.4 Unlock func (rw *RWMutex) Unlock() { // 告诉reader没有活跃的writer了 r := atomic.AddInt32(\u0026rw.readerCount, rwmutexMaxReaders) // 唤醒阻塞的reader们 for i := 0; i \u003c int(r); i++ { runtime_Semrelease(\u0026rw.readerSem, false, 0) } // 释放内部的互斥锁 rw.w.Unlock() } 在 RWMutex Unlock 方法实现中: 是先释放读锁，后释放写锁，我的理解调过来也是可以，但是调过来会导致读饥饿。 最后，在 Lock 方法中，是先获取内部互斥锁，才会修改的其他字段；而在 Unlock 方法中，是先修改的其他字段，才会释放内部互斥锁，这样才能保证字段的修改也受到互斥锁的保护。 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:2:4","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"3. RWMutex 采坑点 RWMutex有三个采坑点: 不可复制: 原因: 互斥锁是不可复制的，再加上四个有状态的字段，RWMutex 就更加不能复制使用了 解决方案也和互斥锁一样。你可以借助 vet 工具检查是否有读写锁隐式复制的情景 重入导致死锁 writer 重入调用 Lock 的时候，就会出现死锁的现象 有活跃 reader 的时候，writer 会等待，如果我们在 reader 的读操作时调用 writer 的写操，此时Reader 想等待 writer 完成后再释放锁，而 writer 需要这个 reader 释放锁之后，才能不阻塞地继续执行，导致死锁 writer 依赖活跃的 reader -\u003e 活跃的 reader 依赖新来的 reader -\u003e 新来的 reader 依赖 writer 释放未加锁的 RWMutex: Lock 和 Unlock 的调用总是成对出现的，RLock 和 RUnlock 的调用也必须成对出现 使用读写锁最需要注意的一点就是尽量避免重入，重入带来的死锁非常隐蔽，而且难以诊断。 另外我们也可以扩展 RWMutex，不过实现方法和互斥锁 Mutex 差不多，在技术上是一样的，都是通过 unsafe 来实现。大体的技巧如下: // 获取 readerCount readerCount := atomic.LoadInt32((*int32)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026m)) + unsafe.Sizeof(sync.Mutex{}) + 2*unsafe.Sizeof(uint32(0))))) ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:3:0","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-04","objectID":"/posts/program/go/sync/go_sync_5/:4:0","tags":["go 并发"],"title":"RWMutex","uri":"/posts/program/go/sync/go_sync_5/"},{"categories":["Go"],"content":"go Mutex 扩展，实现可重入锁，获取等待锁的协程数","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"如何基于 Mutex 实现一个可重入锁 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:0:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"1. Mutex 的扩展 上一节我们介绍了 Mutex 的实现原理，这一节我们来看看如何基于标准库的 Mutex 来扩展 Mutex 提供的并发原语，包括: 实现一个可重入锁 TryLock 获取等待者的数量 实现一个线程安全的队列 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:1:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"2. 可重入锁 实现可重入锁的关键是要锁能记住当前哪个 goroutine 持有锁，这里有两个方案: 通过 hacker 的方式获取到 goroutine id，记录下获取锁的 goroutine id，它可以实现 Locker 接口 调用 Lock/Unlock 方法时，由 goroutine 提供一个 token，用来标识它自己，而不是我们通过 hacker 的方式获取到 goroutine id，但是，这样一来，就不满足 Locker 接口了 可重入锁（递归锁）解决了代码重入或者递归调用带来的死锁问题，同时它也带来了另一个好处: 只有持有锁的 goroutine 才能 unlock 这个锁。接下来我们来看看这两个方案具体如何实现。 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:2:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"2.1 goroutine id 这个方案的关键第一步是获取 goroutine id，方式有两种，分别是 简单方式：通过 runtime.Stack 方法获取栈帧信息，栈帧信息里包含 goroutine id hacker 方式: 原理: 我们获取运行时的 g 指针，反解出对应的 g 的结构。每个运行的 goroutine 结构的 g 指针保存在当前 goroutine 的一个叫做 TLS 对象中 第一步：我们先获取到 TLS 对象 第二步：再从 TLS 中获取 goroutine 结构的 g 指针 第三步：再从 g 指针中取出 goroutine id。 需要注意的是，不同 Go 版本的 goroutine 的结构可能不同，所以需要根据 Go 的不同版本进行调整。没必要重复造轮子，直接使用第三方库就可以: petermattis/goid import ( \"fmt\" \"runtime\" \"strconv\" \"strings\" \"sync\" \"sync/atomic\" \"github.com/petermattis/goid\" // 使用第三方包通过 hacker 方式获取 goroutine id ) // 简单方式 func GoID() int { var buffer [64]byte n := runtime.Stack(buffer[:], false) idField := strings.Fields(strings.TrimPrefix(string(buffer[:n]), \"goroutine \"))[0] d, err := strconv.Atoi(idField) if err != nil { panic(fmt.Sprintf(\"can not get goroutine id %v\", err)) } return d } // RecursiveMutex 包装一个Mutex,实现可重入 type RecursiveMutex struct { sync.Mutex owner int64 // 当前持有锁的goroutine id recursion int32 // 这个goroutine 重入的次数 } func (m *RecursiveMutex) Lock() { gid := goid.Get() // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入 if atomic.LoadInt64(\u0026m.owner) == gid { m.recursion++ return } m.Mutex.Lock() // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1 atomic.StoreInt64(\u0026m.owner, gid) m.recursion = 1 } func (m *RecursiveMutex) Unlock() { gid := goid.Get() // 非持有锁的goroutine尝试释放锁，错误的使用 if atomic.LoadInt64(\u0026m.owner) != gid { panic(fmt.Sprintf(\"wrong the owner(%d): %d!\", m.owner, gid)) } // 调用次数减1 m.recursion-- if m.recursion != 0 { // 如果这个goroutine还没有完全释放，则直接返回 return } // 此goroutine最后一次调用，需要释放锁 atomic.StoreInt64(\u0026m.owner, -1) m.Mutex.Unlock() } ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:2:1","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"2.2 token 通过 token 的实现方式需要调用者自己提供一个 token，获取锁的时候把这个 token 传入，释放锁的时候也需要把这个 token 传入。通过用户传入的 token 替换方案一中 goroutine id，其它逻辑和方案一一致。 // Token方式的递归锁 type TokenRecursiveMutex struct { sync.Mutex token int64 recursion int32 } // 请求锁，需要传入token func (m *TokenRecursiveMutex) Lock(token int64) { if atomic.LoadInt64(\u0026m.token) == token { //如果传入的token和持有锁的token一致，说明是递归调用 m.recursion++ return } m.Mutex.Lock() // 传入的token不一致，说明不是递归调用 // 抢到锁之后记录这个token atomic.StoreInt64(\u0026m.token, token) m.recursion = 1 } // 释放锁 func (m *TokenRecursiveMutex) Unlock(token int64) { if atomic.LoadInt64(\u0026m.token) != token { // 释放其它token持有的锁 panic(fmt.Sprintf(\"wrong the owner(%d): %d!\", m.token, token)) } m.recursion-- // 当前持有这个锁的token释放锁 if m.recursion != 0 { // 还没有回退到最初的递归调用 return } atomic.StoreInt64(\u0026m.token, 0) // 没有递归调用了，释放锁 m.Mutex.Unlock() } ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:2:2","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"3. TryLock 我们可以为 Mutex 添加一个 TryLock 请求锁的方法: 如果 goroutine 获取锁成功，则持有锁，并返回 true 如果这把锁已经被其他 goroutine 所持有，或者是正在准备交给某个被唤醒的 goroutine，那么 TryLock 直接返回 false，不会阻塞在方法调用上 TryLock 在不是必需要获取锁去更新共享资源时非常有用，它可以提升程序的并发度。具体实现如下: // 复制Mutex定义的常量 const ( mutexLocked = 1 \u003c\u003c iota // 加锁标识位置 mutexWoken // 唤醒标识位置 mutexStarving // 锁饥饿标识位置 mutexWaiterShift = iota // 标识waiter的起始bit位置 ) // 扩展一个Mutex结构 type Mutex struct { sync.Mutex } // 尝试获取锁 func (m *Mutex) TryLock() bool { // 如果能成功抢到锁 if atomic.CompareAndSwapInt32((*int32)(unsafe.Pointer(\u0026m.Mutex)), 0, mutexLocked) { return true } // 如果处于唤醒、加锁或者饥饿状态，这次请求就不参与竞争了，返回false old := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) if old\u0026(mutexLocked|mutexStarving|mutexWoken) != 0 { return false } // 尝试在竞争的状态下请求锁 new := old | mutexLocked return atomic.CompareAndSwapInt32((*int32)(unsafe.Pointer(\u0026m.Mutex)), old, new) } ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:3:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"4. 获取等待者的数量 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:4:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"4.1 应用场景 如果我们要监控锁的竞争情况，一个监控指标就是，等待这把锁的 goroutine 数量。我们可以把这个指标推送到时间序列数据库中，再通过一些监控系统（比如 Grafana）展示出来。要知道，锁是性能下降的“罪魁祸首”之一，所以，有效地降低锁的竞争，就能够很好地提高性能。因此，监控关键互斥锁上等待的 goroutine 的数量，是我们分析锁竞争的激烈程度的一个重要指标。 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:4:1","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"4.2 实现 Mutex 结构中的 state 字段有很多个含义，通过 state 字段，你可以知道锁是否已经被某个 goroutine 持有、当前是否处于饥饿状态、是否有等待的 goroutine 被唤醒、等待者的数量等信息。但是要想获取这些信息，我们需要将他们从 state 字段中一一解析出来，代码如下: const ( mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota ) type Mutex struct { sync.Mutex } func (m *Mutex) Count() int { // 获取state字段的值 v := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) isLock = v \u0026 mutexLocked v = v \u003e\u003e mutexWaiterShift //得到等待者的数值 v = v + isLock //再加上锁持有者的数量，0或者1 return int(v) } // 锁是否被持有 func (m *Mutex) IsLocked() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexLocked == mutexLocked } // 是否有等待者被唤醒 func (m *Mutex) IsWoken() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexWoken == mutexWoken } // 锁是否处于饥饿状态 func (m *Mutex) IsStarving() bool { state := atomic.LoadInt32((*int32)(unsafe.Pointer(\u0026m.Mutex))) return state\u0026mutexStarving == mutexStarving } 需要注意的是在获取 state 字段的时候，并没有通过 Lock 获取这把锁，所以获取的这个 state 的值是一个瞬态的值。 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:4:2","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"5. 实现一个线程安全的队列 Mutex 经常会和其他非线程安全（对于 Go 来说，我们其实指的是 goroutine 安全）的数据结构一起，组合成一个线程安全的数据结构。新数据结构的业务逻辑由原来的数据结构提供，而 Mutex 提供了锁的机制，来保证线程安全。 type SliceQueue struct { data []interface{} mu sync.Mutex } func NewSliceQueue(n int) (q *SliceQueue) { return \u0026SliceQueue{data: make([]interface{}, 0, n)} } // Enqueue 把值放在队尾 func (q *SliceQueue) Enqueue(v interface{}) { q.mu.Lock() q.data = append(q.data, v) q.mu.Unlock() } // Dequeue 移去队头并返回 func (q *SliceQueue) Dequeue() interface{} { q.mu.Lock() if len(q.data) == 0 { q.mu.Unlock() return nil } v := q.data[0] q.data = q.data[1:] q.mu.Unlock() return v } ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:5:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-03","objectID":"/posts/program/go/sync/go_sync_4/:6:0","tags":["go 并发"],"title":"Mutex 扩展","uri":"/posts/program/go/sync/go_sync_4/"},{"categories":["Go"],"content":"go Mutex 使用与实现原理","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"Go 第一个并发原语 Mutex 互斥锁 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:0:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"1. Mutex 的使用 互斥锁是最基本的并发原语，使用互斥锁，限定临界区只能同时由一个线程持有。基本上所有编程语言都会提供，Go 中互斥锁为 Mutex，Mutex 位于标准库 sync 中，其实现了 sync 中的 Locker 接口: type Locker interface{ Lock() Unlock() } 简单来说，互斥锁 Mutex 就提供了这两个方法 Lock 和 Unlock：进入临界区之前调用 Lock 方法，退出临界区的时候调用 Unlock 方法。很多时候 Mutex 会嵌入到其他 struct 中，比如: type Counter struct{ Mutex Count uint64 } var c Counter c.Lock() c.Unlock() 如果嵌入的 struct 有多个字段，我们一般会把 Mutex 放在要控制的字段上面，然后使用空格把字段分隔开来。以便于代码更容易理解和维护。甚至，你还可以把获取锁、释放锁、计数加一的逻辑封装成一个方法，对外不需要暴露锁等。 // 将锁封装不暴露锁 type Counter struct { CounterType int Name string mu sync.Mutex count uint64 } func (c *Counter) Incr() { c.mu.Lock() c.count++ c.mu.Unlock() } Mutex 的零值是还没有 goroutine 等待的未加锁的状态，所以你不需要额外的初始化，直接声明变量（如 var mu sync.Mutex）即可 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:1:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"1.1 并发冲突检测 对共享资源不加保护的并发会导致 data race 数据竞争。很多时候，并发问题隐藏得非常深不太容易发现。Go 提供了一个检测并发访问共享资源是否有问题的工具： race detector，它可以帮助我们自动发现程序有没有 data race 的问题。它的实现和使用我放到了 Go 并发调试工具。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:1:1","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"2. Mutex 实现 Mutex 的实现经过了一个由简单到考虑公平，性能，复杂度复杂实现过程，整个实现过程大体分成了如下四个阶段: 接下来我们会一一介绍 Mutex 各个版本的实现，我觉得下面几点对理解 Mutex 的实现会有所帮助: 调用 Mutext.Lock 和 Mutex.Unlock 是独立的 Goroutine，他们内部会维护一些变量来记录当前的 Goroutine 的状态，比如是被唤醒的，或者已处于饥饿状态，不要把这些协程内部的变量与 Mutex 的状态字段搞混。 Mutex 中的字段类似于共享内存，每个 Goroutine 都会根据自身的状态更新 Mutex 的值，因此对 Mutex 的修改都需要借助原子操作，来避免数据竞争 协程的调度时通过 go 内部的信号量调度的，信号量实现的是一个先进先出队列，位于队列头部的 Goroutine 如果排除\"插队\"一定是第一个优先获取到锁的。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:2:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"3. 初版 Mutex 初版 Mutex 实现如下: // CAS操作，当时还没有抽象出atomic包 func cas(val *int32, old, new int32) bool func semacquire(*int32) func semrelease(*int32) // 互斥锁的结构，包含两个字段 type Mutex struct { key int32 // 锁是否被持有的标识 sema int32 // 信号量专用，用以阻塞/唤醒goroutine } // 保证成功在val上增加delta的值 // xadd 方法通过循环执行 CAS 操作直到成功，保证对 key 加 1 的操作成功完成。 func xadd(val *int32, delta int32) (new int32) { for { v := *val if cas(val, v, v+delta) { return v + delta } } panic(\"unreached\") } // 请求锁 func (m *Mutex) Lock() { if xadd(\u0026m.key, 1) == 1 { //标识加1，如果等于1，成功获取到锁 return } semacquire(\u0026m.sema) // 否则阻塞等待 } func (m *Mutex) Unlock() { if xadd(\u0026m.key, -1) == 0 { // 将标识减去1，如果等于0，则没有其它等待者 return } // 如果还有等待此锁的其它 goroutine，那么，它会调用 semrelease 方法 semrelease(\u0026m.sema) // 唤醒其它阻塞的goroutine } Mutex 结构体包含两个字段： key： 是一个 flag，用来标识这个排外锁是否被某个 goroutine 所持有 如果 key 大于等于 1，说明这个排外锁已经被持有； key 不仅仅标识了锁是否被 goroutine 所持有，还记录了当前持有和等待获取锁的 goroutine 的数量 sema：是个信号量变量，用来控制等待 goroutine 的阻塞休眠和唤醒。 在这个实现的版本里，协程只会执行一次\"抢锁\"操作，抢锁失败就会休眠。当协成再被唤醒后，默认就获取锁。锁由谁获取完全有信号量决定，信号量内部是排队的，所以新加入的协成是无法获取到锁的。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:3:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"3.1 如何释放锁 初版Mutex 的整体设计非常简洁，但是 Unlock 方法可以被任意的 goroutine 调用释放锁，即使是没持有这个互斥锁的 goroutine，也可以进行这个操作。这是因为，Mutex 本身并没有包含持有这把锁的 goroutine 的信息，所以，Unlock 也不会对此进行检查。Mutex 的这个设计一直保持至今。 所以，我们在使用 Mutex 的时候，必须要保证 goroutine 尽可能不去释放自己未持有的锁，一定要遵循“谁申请，谁释放”的原则。从 1.14 版本起，Go 对 defer 做了优化，采用更有效的内联方式，取代之前的生成 defer 对象到 defer chain 中，defer 对耗时的影响微乎其微，基本上都可以将锁的释放放在 defer 中，像下面这样: func (f *Foo) Bar() { f.mu.Lock() defer f.mu.Unlock() if f.count \u003c 1000 { f.count += 3 return } f.count++ return } 但是，如果临界区只是方法中的一部分，为了尽快释放锁，还是应该第一时间调用 Unlock，而不是一直等到方法返回时才释放。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:3:1","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"3.3 缺陷 初版的 Mutex 实现有一个问题：请求锁的 goroutine 会排队等待获取互斥锁。虽然这貌似很公平，但是从性能上来看，却不是最优的。因为如果我们能够把锁交给正在占用 CPU 时间片的 goroutine 的话，那就不需要做上下文的切换，在高并发的情况下，可能会有更好的性能。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:3:2","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"4. 给新人机会 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:4:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"4.1 state 字段 第一次大调整之后，Mutex 实现如下: type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexWaiterShift = iota ) 新的 Mutex 中 state 是一个复合型字段: 第一位（最小的一位）来表示这个锁是否被持有 第二位代表是否有唤醒的 goroutine 剩余的位数代表的是等待此锁的 goroutine 数 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:4:1","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"4.2 Lock state 变得复杂，请求锁的方法 Lock 也变得复杂。 func (m *Mutex) Lock() { // Fast path: 幸运case，能够直接获取到锁 // 1. state 为 0，表示 如果没有 goroutine 持有锁，也没有等待持有锁的 gorutine if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } // 2. for 循环是不断尝试获取锁，如果获取不到，就通过 runtime.Semacquire(\u0026m.sema) 休眠， // 休眠醒来之后 awoke 置为 true，尝试争抢锁。 // 个人理解: 调用 Mutex.Lock() 是每个 goroutine，这个 awoke 是 goroutine 的局部变量 awoke := false for { old := m.state new := old | mutexLocked // 新状态加锁 // 3. 如果旧锁已经被持有，增加 waiter if old\u0026mutexLocked != 0 { new = old + 1\u003c\u003cmutexWaiterShift //等待者数量加一 } if awoke { // goroutine是被唤醒的， // 4. 新状态清除唤醒标志 // 个人理解: go 一次只会唤醒一个协程，当前协程在运行说明就是那个被唤醒的， // 接下来无论他是获取到锁，还是被阻塞，都代表了没有协程处于唤醒中，所以要清楚唤醒状态 new \u0026^= mutexWoken } // 5. 过 CAS 把这个新值赋予 state，尝试抢锁 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) {//设置新状态 if old\u0026mutexLocked == 0 { // 锁原状态未加锁 break } // 锁原状态已经加锁，休眠 runtime.Semacquire(\u0026m.sema) // 请求信号量 // 唤醒后标识 goroutine 是被唤醒的 awoke = true } } } 在上面的实现中: “抢锁\"是在一个循环中不断进行的，已睡眠的 goroutine 被唤醒后并不能像先前一样直接获取到锁，还是要和正在请求锁的 goroutine 进行竞争，这就给 CPU 中正在执行的 goroutine 更多的机会获取锁 请求锁的 goroutine 有两类，一类是新来请求锁的 goroutine，另一类是被唤醒的等待请求锁的 goroutine。锁的状态也有两种：加锁和未加锁，下面是 goroutine 不同来源不同状态下的处理逻辑 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:4:2","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"4.3 Unlock 释放锁的逻辑如下: func (m *Mutex) Unlock() { // Fast path: drop lock bit. new := atomic.AddInt32(\u0026m.state, -mutexLocked) //去掉锁标志 if (new+mutexLocked)\u0026mutexLocked == 0 { //本来就没有加锁 panic(\"sync: unlock of unlocked mutex\") } // 个人理解: m.state 去掉锁标识后，其他 goroutine 就已经可以尝试获取锁和释放锁了 old := new for { // 没有等待者，或者有唤醒的waiter，或者锁原来已加锁 // 第一次进入循环时，old 的 mutexLocked 位肯定是 0，但是之后的循环就不一定了 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken) != 0 { return } new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken // 新状态，准备唤醒goroutine，并设置唤醒标志 // 对 state 状态的更新始终通过原子操作，保证不会数据竞争 // 如果没有设置成功，说明有新的 goroutine 已经获取到锁了，需要重新获取锁的状态继续执行 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { runtime.Semrelease(\u0026m.sema) return } // for 循环重试必须更新 old 变量 old = m.state } } 将加锁置为未加锁的状态，这个方法也不能直接返回，因为还可能有一些等待这个锁的 goroutine(成为 waiter) 需要通过信号量唤醒，所以接下来的逻辑有4种种情况： 如果没有其它的 waiter 如果有其他 waiter 并且有被唤醒的 waiter 直接返回 如果有其他 waiter 但此时锁已经被其他 goroutine 加锁直接返回 如果有等待者，并且没有唤醒的 waiter，锁仍然处于未加锁状态，需要唤醒一个等待的 waiter；在唤醒之前，需要将 waiter 数量减 1，并且将 mutexWoken 标志设置上 前三种情况就对应条件 // // 没有等待者，或者有唤醒的 waiter，或者锁原来已加锁 if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken) != 0 { return } 所有对 state 的操作都通过原子操作完成，保证了不会发生数据竞争，其余通过快速失败逻辑，快速结束。需要注意的是 for 循环重试必须更新 old 变量。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:4:3","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"4.4 改进 相对于初版的设计，这次的改动主要就是，新来的 goroutine 也有机会先获取到锁，甚至一个 goroutine 可能连续获取到锁，打破了先来先得的逻辑。但是，代码复杂度也显而易见。 这一版的 Mutex 已经给新来请求锁的 goroutine 一些机会，让它参与竞争，没有空闲的锁或者竞争失败才加入到等待队列中。但是其实还可以进一步优化。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:4:4","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"5. 多给些机会 在 2015 年 2 月的改动中，如果新来的 goroutine 或者是被唤醒的 goroutine 首次获取不到锁，它们就会通过自旋（spin，通过循环不断尝试，spin 的逻辑是在runtime 实现的）的方式，尝试检查锁是否被释放。在尝试一定的自旋次数后，再执行原来的逻辑。 func (m *Mutex) Lock() { // Fast path: 幸运之路，正好获取到锁 if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } awoke := false iter := 0 for { // 不管是新来的请求锁的goroutine, 还是被唤醒的goroutine，都不断尝试请求锁 old := m.state // 先保存当前锁的状态 new := old | mutexLocked // 新状态设置加锁标志 // ################## 新增的自旋逻辑 ####################### if old\u0026mutexLocked != 0 { // 锁还没被释放 if runtime_canSpin(iter) { // 还可以自旋 if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ continue // 自旋，再次尝试请求锁 } // ################## 新增的自旋逻辑 ####################### new = old + 1\u003c\u003cmutexWaiterShift } if awoke { // 唤醒状态 // new\u0026mutexWoken == 0 成立只可能发生在，未发生自旋，但是 old\u0026mutexLocked == 1 的情况 // 但是此时肯定发生了自旋 if new\u0026mutexWoken == 0 { panic(\"sync: inconsistent mutex state\") } new \u0026^= mutexWoken // 新状态清除唤醒标记 } if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { if old\u0026mutexLocked == 0 { // 旧状态锁已释放，新状态成功持有了锁，直接返回 break } runtime_Semacquire(\u0026m.sema) // 阻塞等待 awoke = true // 被唤醒 iter = 0 } } } 对于临界区代码执行非常短的场景来说，新增的自旋逻辑是一个非常好的优化，因为临界区的代码耗时很短，锁很快就能释放，而抢夺锁的 goroutine 不用通过休眠唤醒方式等待调度，直接 spin 几次，可能就获得了锁。 这里我们来详细介绍一下自旋里面的判断逻辑: if old\u0026mutexLocked != 0 { // 锁还没被释放 if runtime_canSpin(iter) { // 还可以自旋 if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ continue // 自旋，再次尝试请求锁 } // ################## 新增的自旋逻辑 ####################### new = old + 1\u003c\u003cmutexWaiterShift runtime_canSpin(iter): 表示 goroutine 可以继续执行持续抢锁 !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0: 当前协程是第一次尝试抢锁，并且旧锁并没有设置唤醒状态，等待锁的 goroutine 大于 0 此时将锁的 mutexWoken 和 awoke 设为 1，表示有 goroutine 处于唤醒状态 continue: 自旋，再次尝试请求锁，如果此时锁被释放，可以执行下面的抢锁逻辑 new = old + 1\u003c\u003cmutexWaiterShift: 如果 goroutine 已经不能自旋，将等待的 waiter 加一，符合 mutexWaiterShift 表示的当前等待锁的 goroutine 数的含义 因为新来的 goroutine 也参与竞争，有可能每次都会被新来的 goroutine 抢到获取锁的机会，在极端情况下，等待中的 goroutine 可能会一直获取不到锁，这就是饥饿问题。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:5:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"6. 解决饥饿 2016 年 Go 1.9 中 Mutex 增加了饥饿模式，让锁变得更公平，不公平的等待时间限制在 1 毫秒，并且修复了一个大 Bug：总是把唤醒的 goroutine 放在等待队列的尾部，会导致更加不公平的等待时间。之后 2018 年，Go 开发者将 fast path 和 slow path 拆成独立的方法，以便内联，提高性能。2019 年也有一个 Mutex 的优化，虽然没有对 Mutex 做修改，但是，对于 Mutex 唤醒后持有锁的那个 waiter，调度器可以有更高的优先级去执行，这已经是很细致的性能优化了。 当前 Mutex 代码已经复杂得接近不可读的状态了，而且代码也非常长，我们慢慢来看。整个实现的逻辑大概是: 正常模式下，waiter 都是进入先入先出队列，因此阻塞在信号量中的第一个 goroutine 就是等待最久的那个。 所以在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine 不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin，它会乖乖地加入到等待队列的尾部。 因为等待最久的 goroutine 总是处于信号量队列中的第一个，所以他总是被第一个唤醒，所以饥饿模式下，处于运行中的 goroutine 只能是新的 goroutine 和当前饥饿的 goroutine，只有处于饥饿的 goroutine 才能将锁的饥饿位设置为 1 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:6:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"6.1 state 字段 state 在原有的基础上增加了饥饿模式: type Mutex struct { state int32 sema uint32 } const ( mutexLocked = 1 \u003c\u003c iota // mutex is locked mutexWoken mutexStarving // 从state字段中分出一个饥饿标记 mutexWaiterShift = iota starvationThresholdNs = 1e6 ) ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:6:1","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"6.2 Lock 添加饥饿模式后，Lock 增加了如下逻辑: 自旋部分: old\u0026(mutexLocked|mutexStarving) == mutexLocked 锁是非饥饿状态，锁还没被释放，才尝试自旋 是否去抢锁: 如果存在饥饿 goroutine ，即便当前未加锁，goroutine 也直接等待，不抢锁 if old\u0026(mutexLocked|mutexStarving) != 0 {new += 1 \u003c\u003c mutexWaiterShift} 只有在未加锁并且非饥饿条件下，协程才能正常获取锁 if old\u0026(mutexLocked|mutexStarving) == 0 {break} 保持等待最久的 goroutine 始终处于信号量队列的队首: runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) 在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter 饥饿状态设置: 协程在发生饥饿时，是不会立马就获取到锁的，而是进入到下一次for循环先设置锁的饥饿状态，以此来告诉所有其他协程我当前是饥饿状态，此时如果有锁释放，你们都不要抢锁，所以才有了后面的判断逻辑 if old\u0026mutexStarving != 0 饥饿状态的清楚: 锁只要有饥饿状态就会一直让队列首部的协程获取，饥饿状态的清除是在队首协程非饥饿进行的 if !starving || old\u003e\u003emutexWaiterShift == 1 func (m *Mutex) Lock() { // Fast path: 幸运之路，一下就获取到了锁 // 1. 1. state 为 0，表示 如果没有 goroutine 持有锁，也没有等待持有锁的 gorutine，直接加锁 if atomic.CompareAndSwapInt32(\u0026m.state, 0, mutexLocked) { return } // Slow path：缓慢之路，尝试自旋竞争或饥饿状态下饥饿goroutine竞争 m.lockSlow() } func (m *Mutex) lockSlow() { var waitStartTime int64 starving := false // 此goroutine的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前的锁的状态 for { // 锁是非饥饿状态，锁还没被释放，尝试自旋 if old\u0026(mutexLocked|mutexStarving) == mutexLocked \u0026\u0026 runtime_canSpin(iter) { if !awoke \u0026\u0026 old\u0026mutexWoken == 0 \u0026\u0026 old\u003e\u003emutexWaiterShift != 0 \u0026\u0026 atomic.CompareAndSwapInt32(\u0026m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，之后会检查是否锁被释放了 continue } new := old if old\u0026mutexStarving == 0 { new |= mutexLocked // 非饥饿状态，加锁 } // 如果存在饥饿 goroutine ，当前 goroutine 直接等待，不抢锁 if old\u0026(mutexLocked|mutexStarving) != 0 { new += 1 \u003c\u003c mutexWaiterShift // waiter数量加1 } // 对于 Mutex 唤醒后持有锁的那个 waiter，调度器可以有更高的优先级去执行 if starving \u0026\u0026 old\u0026mutexLocked != 0 { new |= mutexStarving // 设置饥饿状态 } if awoke { if new\u0026mutexWoken == 0 { throw(\"sync: inconsistent mutex state\") } new \u0026^= mutexWoken // 新状态清除唤醒标记 } // 成功设置新状态 if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // 原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old\u0026(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // 处理饥饿状态 // 如果以前就在队列里面，加入到队列头 queueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } // 阻塞等待，queueLifo == True 表示非首次，加入到队首 runtime_SemacquireMutex(\u0026m.sema, queueLifo, 1) // 唤醒之后检查锁是否应该处于饥饿状态 starving = starving || runtime_nanotime()-waitStartTime \u003e starvationThresholdNs old = m.state // 如果锁已经处于饥饿状态，直接抢到锁，返回 if old\u0026mutexStarving != 0 { // 运行到这里不可能再有协程占有锁 if old\u0026(mutexLocked|mutexWoken) != 0 || old\u003e\u003emutexWaiterShift == 0 { throw(\"sync: inconsistent mutex state\") } // 有点绕，加锁并且将waiter数减1 // - 1\u003c\u003cmutexWaiterShift 表示 waiter 减去 1 // mutexLocked 表示加锁 delta := int32(mutexLocked - 1\u003c\u003cmutexWaiterShift) if !starving || old\u003e\u003emutexWaiterShift == 1 { delta -= mutexStarving // 最后一个waiter或者已经不饥饿了，清除饥饿标记 } atomic.AddInt32(\u0026m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } } ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:6:2","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"6.3 Unlock func (m *Mutex) Unlock() { // Fast path: drop lock bit. new := atomic.AddInt32(\u0026m.state, -mutexLocked) if new != 0 { m.unlockSlow(new) } } func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026mutexLocked == 0 { throw(\"sync: unlock of unlocked mutex\") } if new\u0026mutexStarving == 0 { old := new for { if old\u003e\u003emutexWaiterShift == 0 || old\u0026(mutexLocked|mutexWoken|mutexStarving) != 0 { return } new = (old - 1\u003c\u003cmutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026m.state, old, new) { // false 时，好像也总是唤醒队首 waiter runtime_Semrelease(\u0026m.sema, false, 1) return } old = m.state } } else { // 如果 Mutex 处于饥饿状态，直接唤醒等待队列中的 waiter runtime_Semrelease(\u0026m.sema, true, 1) } } ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:6:3","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"7. Mutex 采坑记录 使用 Mutex 常见的错误场景有 4 类，分别是 Lock/Unlock 不是成对出现 Copy 已使用的 Mutex 重入 死锁 手误和重入导致的死锁，是最常见的使用 Mutex 的 Bug。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:7:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"7.1 Lock/Unlock 不是成对出现 Lock/Unlock 不是成对出现Lock/Unlock 没有成对出现，就意味着会出现死锁，或者是因为 Unlock 一个未加锁的 Mutex 而导致 panic。保证 Lock/Unlock 成对出现，尽可能采用 defer mutex.Unlock 的方式，把它们成对、紧凑地写在一起。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:7:1","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"7.2 Copy 已使用的 Mutex Package sync 的同步原语在使用后是不能复制的。原因在于，Mutex 是一个有状态的对象，它的 state 字段记录这个锁的状态。如果你要复制一个已经加锁的 Mutex 给一个新的变量，那么新的刚初始化的变量居然被加锁了，这显然不符合你的期望，因为你期望的是一个零值的 Mutex。关键是在并发环境下，你根本不知道要复制的 Mutex 状态是什么，因为要复制的 Mutex 是由其它 goroutine 并发访问的，状态可能总是在变化。 Go 在运行时，有死锁的检查机制（checkdead 方法），它能够发现死锁的 goroutine。但是显然我们不想运行的时候才发现这个因为复制 Mutex 导致的死锁问题。我们可以使用 vet 工具: go vet counter.go，把检查写在 Makefile 文件中，在持续集成的时候跑一跑，这样可以及时发现问题，及时修复。go vet 原理参见:Go 并发调试工具。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:7:2","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"7.3 重入 Mutex 不是可重入的锁，因为 Mutex 的实现中没有记录哪个 goroutine 拥有这把锁。理论上，任何 goroutine 都可以随意地 Unlock 这把锁，所以没办法计算重入条件。所以，一旦误用 Mutex 的重入，就会导致报错。下一节我们将介绍如何基于 Mutex 实现一个可重入锁。 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:7:3","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"7.4 死锁 要产生死锁必须具备以下几个条件： 互斥： 至少一个资源是被排他性独享的，其他线程必须处于等待状态，直到资源被释放 持有和等待：goroutine 持有一个资源，并且还在请求其它 goroutine 持有的资源 不可剥夺：资源只能由持有它的 goroutine 来释放 环路等待：一般来说，存在一组等待进程，P={P1，P2，…，PN}，P1 等待 P2 持有的资源，P2 等待 P3 持有的资源，依此类推，最后是 PN 等待 P1 持有的资源，这就形成了一个环路等待的死结 Go 运行时，有死锁探测的功能，能够检查出是否出现了死锁的情况。但是 Go 死锁探测工具只能探测整个程序是否因为死锁而冻结了，不能检测出一组 goroutine 死锁导致的某一块业务冻结的情况。你还可以通过 Go 运行时自带的死锁检测工具，或者是第三方的工具（比如go-deadlock、go-tools）进行检查，这样可以尽早发现一些死锁的问题。不过，有些时候，死锁在某些特定情况下才会被触发，所以，如果你的测试或者短时间的运行没问题，不代表程序一定不会有死锁问题。 如果发现线上可能出现了死锁，我们可以通过 Go pprof 工具进行分析，它提供了一个 block profiler 监控阻塞的 goroutine。除此之外，我们还可以查看全部的 goroutine 的堆栈信息，通过它，你可以查看阻塞的 groutine 究竟阻塞在哪一行哪一个对象上了。 最后，Mutex 知识图谱如下: ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:7:4","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"参考 本文内容摘录自: 极客专栏-鸟叔的 Go 并发编程实战 ","date":"2021-05-02","objectID":"/posts/program/go/sync/go_sync_2/:8:0","tags":["go 并发"],"title":"Go Mutex 设计与实现","uri":"/posts/program/go/sync/go_sync_2/"},{"categories":["Go"],"content":"这个系列我们开始学习 go 语言的并发","date":"2021-05-01","objectID":"/posts/program/go/sync/go_sync_1/","tags":["go 并发"],"title":"go 并发编程入门指南","uri":"/posts/program/go/sync/go_sync_1/"},{"categories":["Go"],"content":"这个系列我们开始学习 Go 语言的第四个部分: 并发编程。 ","date":"2021-05-01","objectID":"/posts/program/go/sync/go_sync_1/:0:0","tags":["go 并发"],"title":"go 并发编程入门指南","uri":"/posts/program/go/sync/go_sync_1/"},{"categories":["Go"],"content":"1. 学习内容 Go 语言的并发编程，我们学习的核心内容来自于极客时间的专栏Go 并发编程实战课，作者网名鸟窝。这个专栏在极客时间上的订阅并不多，但绝对是五星推荐。 ","date":"2021-05-01","objectID":"/posts/program/go/sync/go_sync_1/:1:0","tags":["go 并发"],"title":"go 并发编程入门指南","uri":"/posts/program/go/sync/go_sync_1/"},{"categories":["Go"],"content":"2. 内容大纲 鸟叔的专栏设计了 5 个模块： 基本并发原语: 包括 Mutex，RWMutex，WaitGroup，Cond，Pool，Context，这些都是传统的并发原语在其他语言中也很常见 原子操作: Go 标准库提供的原子操作 Channel: Go 语言独有的类型，是 Go 实现消息传递的核心数据结构 扩展并发原语： 包括信号量，SingleFlight，循环栅栏，ErrGroup 分布式并发原语: 使用 etcd 实现一些分布式并发原语，比如 Leader选举，分布式互斥锁，分布式读写锁，分布式队列 我们基本上会按照这样的顺序循序渐进。并发编程的核心就是解决并发编程中的资源管理问题，通常包括如下场景: 共享资源: 并发地读写共享资源，会出现数据竞争（data race）的问题，所以需要 Mutex、RWMutex 任务编排: 需要 goroutine 按照一定的规律执行，而 goroutine 之间有相互等待或者依赖的顺序关系，常常使用 WaitGroup 或者 Channel 来实现 消息传递: 信息交流以及不同的 goroutine 之间的线程安全的数据交流，常常使用 Channel 来实现 我们学习这些并发原语，除了要深入学习它们的实现原理，更要搞清楚它们的使用场景，这样才能做到活学活用。 注: 并发原语和同步原语往往会同时出现，但是并发原语的通常指代的范围更大，包括任务的编排，这一点需要注意。 ","date":"2021-05-01","objectID":"/posts/program/go/sync/go_sync_1/:2:0","tags":["go 并发"],"title":"go 并发编程入门指南","uri":"/posts/program/go/sync/go_sync_1/"},{"categories":["Go"],"content":"Go 工程化实践-API设计","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"前面我们介绍 Go 项目工程化提到了 /api 目录。这目录是协议定义目录，用于存放约定项目接口的 IDL 文件。按照现在的主流基本都是 Protobuf 文件。Protobuf 的管理和共享就是今天的话题。 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:0:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"1. Api 仓库 参考: (googleapis)[https://github.com/googleapis/googleapis] (envoyproxy data-plane-api)[https://github.com/envoyproxy/data-plane-api] (istio api)[https://github.com/istio/api] 为了统一检索和规范 API，建议在公司内部建立一个统一的 bapis 仓库，整合所有对内对外 API。这种方式由如下好处: API 仓库，方便跨部门协作。 版本管理，基于 git 控制。 规范化检查，API lint。 API design review，变更 diff。 权限管理，目录 OWNERS。 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:1:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"2. Api Project Layout 这个 Api 仓库按照不同的组织方式由不同结构。 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:2:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"2.1 项目中定义的 API 单独项目中定义 proto，以 api 为包名根目录: application_name api helloworld v1 demo.proto annotation // 注解定义 options third_part // 第三方引用 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:2:1","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"2.2 统一 Api 仓库 在统一仓库中管理 proto ，以仓库为包名根目录: api // api 定义 application_name helloworld v1 demo.proto annotation // 注解定义 options third_part // 第三方引用 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:2:2","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"3. Api 命名 对于一个 gRPC 接口，比较好的接口命名规范是 // RequestURL: /\u003cpackage_name\u003e.\u003cversion\u003e.\u003cservice_name\u003e/{method} 其中: package_name 为应用的标识(APP_ID)，用于生成 gRPC 请求路径，或者 proto 之间进行引用 Message。 带有版本的 API 的软件包名称必须以此版本结尾。 protobuf 文件中声明的包名称应该与产品和服务名称保持一致: package \u003cpackage_name\u003e.\u003cversion\u003e; 命名 我们以 google/bigtable/v2/bigtable.proto 定义为例: syntax = \"proto3\"; package google.bigtable.v2; service Bigtable { option (google.api.default_host) = \"bigtable.googleapis.com\"; } 其中: google.bigtable 就是 package_name，这个 package_name 与服务名一致 v2 就是 api 的版本信息 最后推荐阅读谷歌API设计指南 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:3:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"4. Api 错误处理 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:4:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"4.1 错误定义 首先我们需要统一错误得定义得标准和入口。使用一小组标准错误配合大量资源。例如，服务器没有定义不同类型的“找不到”错误，而是使用一个标准 google.rpc.Code.NOT_FOUND 错误代码并告诉客户端找不到哪个特定资源。状态空间变小降低了文档的复杂性，在客户端库中提供了更好的惯用映射，并降低了客户端的逻辑复杂性，同时不限制是否包含可操作信息(/google/rpc/error_details)。 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:4:1","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"4.1 错误传播 如果您的 API 服务依赖于其他服务，则不应盲目地将这些服务的错误传播到您的客户端。在翻译错误时，我们建议执行以下操作： 隐藏实现详细信息和机密信息。 调整负责该错误的一方。例如，从另一个服务接收 INVALID_ARGUMENT 错误的服务器应该将 INTERNAL 传播给它自己的调用者。 全局错误码，是松散、易被破坏契约的，基于我们上述讨论的，在每个服务传播错误的时候，做一次翻译，这样保证每个服务 + 错误枚举，应该是唯一的，而且在 proto 定义中是可以写出来文档的。 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:4:2","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"5. Api Design ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:5:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"6. Proto 管理 Proto 管理方式有如下几种: 代码仓库 独立仓库 集中仓库 镜像仓库 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:6:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"参考 极客时间-毛剑老师的 Go 工程化实践 Go项目标准布局 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_api/:7:0","tags":["go 惯例"],"title":"go API 设计","uri":"/posts/program/go/practice/engineering/project_api/"},{"categories":["Go"],"content":"Go 工程化实践-项目配置","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_config/","tags":["go 惯例"],"title":"go 配置管理","uri":"/posts/program/go/practice/engineering/project_config/"},{"categories":["Go"],"content":"参考 极客时间-毛剑老师的 Go 工程化实践 Go项目标准布局 ","date":"2021-04-03","objectID":"/posts/program/go/practice/engineering/project_config/:1:0","tags":["go 惯例"],"title":"go 配置管理","uri":"/posts/program/go/practice/engineering/project_config/"},{"categories":["Go"],"content":"Go 工程化实践-项目结构","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"最近几篇文章与 Go 工程化方面有关，算是我们 Go 语言学习的第二部分，了解一门语言的惯例，即最佳实践。无论是做什么开发，在做之前先 google 一下 best practice 是一个非常好的习惯。今天这篇文章与 go 工程化项目结构有关，知识来自于 极客时间-毛剑老师的 Go 工程化实践。 按照不同的应用场景，目的不同，代码就会有不同的组织方式，因而也就由了不同的项目结构。按场景大体上分成如下几种: Application Project: 包含的是业务代码 Multi Application Project: 在项目非常庞大时，为了便于管理，可能会把一类相关的应用放到一个 git 仓库下，这时候就有了多 Application 的项目 kit 库: 基础框架 在介绍这些项目的结构之前，我们先来看看Go 标准应用的项目结构。相比于项目结构，这个标准应用更大的意义在于，约定了特定名称的文件夹下应该存放什么文件的语义。不同场景下的项目结构都应该只使用标准应用里约定的文件夹，但是可以根据自身目的，按照不同的结构去组织。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:0:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1. 标准应用的项目结构 一个标准的 Go 项目通常会包含下面这些目录: ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1.1 /cmd /cmd 作用: 存放应用程序的启动入口 内容: /cmd/myapp /cmd/myapp-build 说明: go 在编译时默认生成二进制文件与文件夹同名，因此为了生成有意义的二进制文件，通常需要在 cmd 在创建一个与项目同名的目录，存放程序的入口 main.go main.go 内通常只做这么几个事情: 资源初始化，包括数据连接等等 启动监听 信号拦截 服务发现和注册 main.go 里面所做的事情就是一个应用的生命周期管理，可以参考 kratos 里面的设计 . └── cmd ├── demo │ ├── demo │ └── main.go └── myapp ├── main.go └── myapp ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:1","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1.2 /pkg /pkg 作用: 应用程序对外暴露的代码，可以其他应用和库导入使用 /pkg 目录可以显式地表示该目录中的代码对于其他人来说是可以安全使用的 说明: └── pkg ├── cache │ ├── memcache │ └── redis └── conf ├── dsn ├── env ├── flagvar └── paladin ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:2","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1.3 /internal /internal 作用: 应用程序私有的库代码，存放不希望被其他应用或库导入的代码 说明: internal 是 Go1.4 提供的机制隔离机制 internal 内的第一层目录通常是与 /cmd 定义的应用相对的，比如像下面这样，表示每个服务私有的代码库 └── internal ├── demo ├── myapp 同时 internal 下也可以有 pkg 目录(/internal/pkg)，表示跨应用的私有库共享库目录。具体到 /internal/myapp 下具体应用包含的内容与应用在编写时所采纳的编程思想有关，后面我们在着重介绍微服务时，会更详细的探讨这一层级的目录应该如何组织。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:3","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1.4 其他文件夹 除了前面介绍了两个重要的顶级目录 /internal 和 /pkg 外，一个标准应用通常还会包含如下目录: /init: 系统初始化（systemd、upstart、sysv）和进程管理（runit、supervisord）配置。 /scripts: 用于执行各种构建，安装，分析等操作的脚本。 这些脚本使根级别的Makefile变得更小更简单（例如 Makefile ）。 更多样例查看/scripts。 /build: 打包和持续集成 将云（AMI），容器（Docker），操作系统（deb，rpm，pkg）软件包配置和脚本放在/build/package目录中 将CI（travis、circle、drone）配置文件和就脚本放在build/ci目录中。 请注意，有一些CI工具（如，travis CI）对于配置文件的位置有严格的要求。尝试将配置文件放在/build/ci目录，然后链接到CI工具想要的位置 /deploy IaaS，PaaS，系统和容器编排部署配置和模板（docker-compose，kubernetes/helm，mesos，terraform，bosh） 请注意，在某些存储库中（尤其是使用kubernetes部署的应用程序），该目录的名字是/deploy /test 外部测试应用程序和测试数据。随时根据需要构建/test目录。 对于较大的项目，有一个数据子目录更好一些。 例如，如果需要Go忽略目录中的内容，则可以使用/test/data或/test/testdata这样的目录名字。 请注意，Go还将忽略以“.”或“_”开头的目录或文件，因此可以更具灵活性的来命名测试数据目录。 更多样例查看/test。 /docs: 设计和用户文档（除了godoc生成的文档） 更多样例查看/docs。 /tools 此项目的支持工具 请注意，这些工具可以从/pkg和/internal目录导入代码。 更多样例查看/tools。 /examples 应用程序或公共库的示例。 更多样例查看/examples。 /third_party 外部辅助工具，fork的代码和其他第三方工具（例如Swagger UI）。 /githooks Git的钩子 /assets 项目中使用的其他资源（图像，Logo等）。 /website 如果不使用Github pages，则在这里放置项目的网站数据。 更多样例查看/website。 最后不要再项目中包含 /src 目录。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:4","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"1.5 多应用的项目的目录结构 上面描述的标准应用目录结构式针对的是单应用的，如果你公司内部有很多 app，如果为每个 app 都创建一个 git 仓库，可能也会难以管理。而且有些应用在领域驱动的划分中虽然属于不同的服务但是彼此之间又有比较密切的联系，这时候我们就可以在一个 git 仓库中存放多个 app。此时我们可以在顶层目录中加一个 /app 目录，如下图所示。然后每个 /app/account 子应用的目录内是一个标准应用的目录结构，包含上面介绍的多个目录。 ├── app │ ├── account # account 服务应用目录 │ │ ├── pkg │ │ ├── internal │ ├── video # video 服务应用目录 │ │ ├── pkg │ │ ├── internal └── pkg ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:1:5","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"2. 基础库/框架的项目结构 每个公司应该为不同的微服务项目建立一个统一的 kit 工具包项目(基础库和框架)。统一的 kit 工具可以对微服务的项目结构、配置管理等做统一的强制性约束，避免管理上的混乱。基础库 kit 为独立项目，公司级建议只有一个，因为按照功能目录来拆分会带来不少的管理工作，因此建议合并整合。kit 项目必须具备如下的特点: 统一 标准库方式布局 高度抽象 支持插件 kit 库的项目结构以及功能可以参考 B 站开源的 kratos 框架，后面我们会有专门的系列来解析这个库的源码。下面是其目录结构: tree . -L 2 . tree -L 1 -s . ├── [ 37] api ├── [ 4403] app.go ├── [ 4722] app_test.go ├── [ 71] cmd ├── [ 39] codecov.yml ├── [ 5219] CODE_OF_CONDUCT.md ├── [ 4096] config ├── [ 73] contrib ├── [ 4402] CONTRIBUTING.md ├── [ 48] docs ├── [ 4096] encoding ├── [ 4096] errors ├── [ 653] go.mod ├── [ 18279] go.sum ├── [ 4096] hack ├── [ 104] internal ├── [ 1066] LICENSE ├── [ 4096] log ├── [ 2795] Makefile ├── [ 47] metadata ├── [ 39] metrics ├── [ 4096] middleware ├── [ 2129] options.go ├── [ 3091] options_test.go ├── [ 8096] README.md ├── [ 7111] README_zh.md ├── [ 40] registry ├── [ 1510] ROADMAP.md ├── [ 560] SECURITY.md ├── [ 4096] selector ├── [ 63] third_party ├── [ 71] transport └── [ 83] version.go ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:2:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"3. 服务类应用的项目结构 服务类应用相对于标准应用，会多出如下几个目录 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:2:1","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"3.1 /api /api 作用: api 协议定义目录，例如存放 OpenAPI/Swagger规范，JSON模式文件，xxxapi.protobuf 示例: /api 说明: 如果有项目依赖 /api 里面定义的 protobuf 文件，项目应该把这个 pb 文件拷贝到自己的项目中，并自己生成访问的 client 代码 /api pb 生成的 server 代码则应该放到 /internel 目录中，从而避免其他人可以依赖生成的 server 代码 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:2:2","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"3.2 /cmd 对于微服务，/cmd 内服务的入口，有一些特殊的约定的命名规范。微服务中的 app 服务类型分为4类： interface: 对外的 BFF 服务，接受来自用户的请求，比如暴露了 HTTP/gRPC 接口 service: 对内的微服务，仅接受来自内部其他服务或者网关的请求，比如暴露了gRPC 接口只对内服务 job: 流式任务处理的服务，上游一般依赖 message broker admin: 区别于 service，更多是面向运营测的服务，通常数据权限更高，隔离带来更好的代码级别安全 task: 定时任务，类似 cronjob，部署到 task 托管平台中 └── cmd └── myapp ├── myapp-admin ├── myapp-interface ├── myapp-job ├── myapp-services └── myapp-task ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:2:3","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"3.2 /web /web: 作用: 存放 Web 应用程序特定的组件：静态Web资源，服务器端模板和单页应用（Single-Page App，SPA） ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:2:4","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"4. 微服务的项目结构 前面我们介绍了标准应用和服务类应用的标注项目结构。这个结构对于一个项目来说通常是固定，也通常不会有太大的变化。而唯一会变化的则是需要结合应用需求设计的 /internal 目录。这里我们就不讨论一些特殊应用的设计，而专注于微服务的业务项目结构设计。 微服务的项目结构与微服务背后的设计思想密切相关，也在不断的演化中，下面将分成几个阶段来介绍微服务的项目结构的演化过程。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:3:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"4.1 微服务的 /cmd 微服务中的 app 服务类型分为4类：interface、service、job、admin。 interface: 对外的 BFF 服务，接受来自用户的请求，比如暴露了 HTTP/gRPC 接口。 service: 对内的微服务，仅接受来自内部其他服务或者网关的请求，比如暴露了gRPC 接口只对内服务。 admin：区别于 service，更多是面向运营测的服务，通常数据权限更高，隔离带来更好的代码级别安全。 job: 流式任务处理的服务，上游一般依赖 message broker。 task: 定时任务，类似 cronjob，部署到 task 托管平台中。 所以微服务应用的 /cmd 目录会包含如下几个入口: myapp-interface myapp-service myapp-admin myapp-job myapp-task ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:3:1","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"4.1 微服务项目结构 V1 V1 版本的项目结构采用的是典型的 MVCC 三层架构，/internal/myapp 下包含了如下几个目录: /model: 作用: 公共模型层，面向数据库表，即服务层 说明: 放对应“存储层”的结构体，是对存储的一一隐射 /dao: 作用: 数据访问层，面向业务需求，即展示层 说明: 数据读写层，数据库和缓存全部在这层统一处理，包括 cache miss 处理。 /service: 作用: 业务逻辑层 说明: 组合各种数据访问来构建业务逻辑 /server: 作用: 存放路由以及一些 DTO 对象转换的代码，依赖 proto 定义的服务作为入参，提供快捷的启动服务全局方法 在 MVCC 的模型中，项目的依赖路径为: model -\u003e dao -\u003e service -\u003e api，model struct 串联各个层，直到 api 需要做 DTO 对象转换。 /api 定义了 API proto 文件，和生成的 stub 代码，它生成的 interface，其实现者在 service 中。service 的方法签名因为实现了 API 的 接口定义，DTO 直接在业务逻辑层直接使用了，更有 dao 直接使用，最简化代码。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:3:2","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"4.2 微服务项目结构 V2 V2 版本的项目结构采用的是领域编程的思想，/internal/myapp 下包含了如下几个目录: biz: 作用: 业务逻辑的组装层，类似 DDD 的 domain 领域层 说明: data 类似 DDD的 repo，repo 接口在这里定义，使用依赖倒置的原则 目的: 由业务层去定义数据访问的接口，data 去实现业务定义的接口，抽象数据的访问 data: 作用: 业务数据访问，包含 cache、db 等封装，实现了 biz 的 repo接口 说明: 我们可能会把 data 与 dao 混淆在一起，data 偏重业务的含义，它所要做的是将领域对象重新拿出来，我们去掉了 DDD 的 infra 层。 service: 作用: 实现了 api 定义的服务层，类似 DDD 的 application 层，处理 /api 内定义的 grpc 到 biz 领域实体的转换(DTO -\u003e DO)，同时协同各类 biz 交互，但是不应处理复杂逻辑。 注: DO(Domain Object): 领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。 PO(Persistent Object): 持久化对象，它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么数据表中的每个字段（或若干个）就对应 PO 的一个（或若干个）属性。https://github.com/facebook/ent 设计思想 V2 的结构设计就是将 DDD 设计中的一些思想和工程结构做了一些简化，映射到 api、service、biz、data 各层。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:3:3","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"5. 应用的声明周期 LifeCycle Lifecycle 需要考虑服务应用的对象初始化以及生命周期的管理，所有 HTTP/gRPC 依赖的前置资源初始化，包括 data、biz、service，之后再启动监听服务。我们可以使用 https://github.com/google/wire ，来管理所有资源的依赖注入。 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:4:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"参考 极客时间-毛剑老师的 Go 工程化实践 Go项目标准布局 DDD 设计思想 洋葱架构/整洁架构 ","date":"2021-04-01","objectID":"/posts/program/go/practice/engineering/project_structure/:5:0","tags":["go 惯例"],"title":"go 工程化项目结构","uri":"/posts/program/go/practice/engineering/project_structure/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"K8S Visitor 模式，这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:0:0","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"1. K8S Visitor 模式 本篇文章主要想讨论一下，Kubernetes 的 kubectl 命令中的使用到到的一个编程模式 – Visitor 。本来，Visitor 是面向对象设计模式中一个很重要的设计模式，这个模式是一种将算法与操作对象的结构分离的一种方法。这种分离的实际结果是能够在不修改结构的情况下向现有对象结构添加新操作，是遵循开放/封闭原则的一种方法。这篇文章我们重点看一下 kubelet 中是怎么使用函数式的方法来实现这个模式的。 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:1:0","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"1.1 简单示例 package main import ( \"encoding/json\" \"encoding/xml\" \"fmt\" ) type Visitor func(shape Shape) type Shape interface { accept(Visitor) } type Circle struct { Radius int } func (c Circle) accept(v Visitor) { v(c) } type Rectangle struct { Width, Heigh int } func (r Rectangle) accept(v Visitor) { v(r) } 在上面的示例中: 有一个 Visitor 的函数定义，还有一个Shape接口 Shape 需要使用 Visitor函数做为参数，Visitor 则接受 Shape 整个调用过程是 Shape 通过 accept 方法接收 Visitor，并调用 Visitor(Shape) 然后，我们实现两个Visitor，一个是用来做JSON序列化的，另一个是用来做XML序列化的: func JsonVisitor(shape Shape) { bytes, err := json.Marshal(shape) if err != nil { panic(err) } fmt.Println(string(bytes)) } func XmlVisitor(shape Shape) { bytes, err := xml.Marshal(shape) if err != nil { panic(err) } fmt.Println(string(bytes)) } 下面是我们的使用Visitor这个模式的代码： func main() { c := Circle{10} r := Rectangle{100, 200} shapes := []Shape{c, r} for _, s := range shapes { s.accept(JsonVisitor) s.accept(XmlVisitor) } } 其实，这段代码的目的就是想解耦 数据结构和 算法，使用 Strategy 模式也是可以完成的，而且会比较干净。但是在有些情况下，多个Visitor是来访问一个数据结构的不同部分，这种情况下，数据结构有点像一个数据库，而各个Visitor会成为一个个小应用。 kubectl就是这种情况。 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:1:1","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2. K8S Visitor ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:0","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.1 k8s 背景知识 接下来，我们再来了解一下相关的知识背景： 对于Kubernetes，其抽象了很多种的Resource，比如：Pod, ReplicaSet, ConfigMap, Volumes, Namespace, Roles …. 种类非常繁多，这些东西构成为了Kubernetes的数据模型（点击 Kubernetes Resources 地图 查看其有多复杂） kubectl 是Kubernetes中的一个客户端命令，操作人员用这个命令来操作Kubernetes。kubectl 会联系到 Kubernetes 的API Server，API Server会联系每个节点上的 kubelet ，从而达到控制每个结点。 kubectl 主要的工作是处理用户提交的东西（包括，命令行参数，yaml文件等），然后其会把用户提交的这些东西组织成一个数据结构体，然后把其发送给 API Server。 相关的源代码在 src/k8s.io/cli-runtime/pkg/resource/visitor.go 中 下面我们来看看 kubectl 的实现(示例实现，而不是直接分析复杂的源码）。 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:1","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.2 Visitor 模式定义 首先，kubectl 主要是用来处理 Info结构体，下面是相关的定义： type VisitorFunc func(*Info, error) error type Visitor interface { Visit(VisitorFunc) error } type Info struct { Namespace string Name string OtherThings string } func (info *Info) Visit(fn VisitorFunc) error { return fn(info, nil) } 我们可以看到: 有一个 VisitorFunc 的函数类型的定义 一个 Visitor 的接口，其中需要 Visit(VisitorFunc) error 的方法（这就像是我们上面那个例子的 Shape ） 最后，为Info 实现 Visitor 接口中的 Visit() 方法，实现就是直接调用传进来的方法（与前面的例子相仿） 我们再来定义几种不同类型的 Visitor。 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:2","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.3 Name Visitor 这个Visitor 主要是用来访问 Info 结构中的 Name 和 NameSpace 成员: type NameVisitor struct { visitor Visitor } func (v NameVisitor) Visit(fn VisitorFunc) error { return v.visitor.Visit(func(info *Info, err error) error { fmt.Println(\"NameVisitor() before call function\") err = fn(info, err) if err == nil { fmt.Printf(\"==\u003e Name=%s, NameSpace=%s\\n\", info.Name, info.Namespace) } fmt.Println(\"NameVisitor() after call function\") return err }) } 重点在这，上面的代码： 声明了一个 NameVisitor 的结构体，这个结构体里有一个 Visitor 接口成员，这里意味着多态 在实现 Visit() 方法时，其调用了自己结构体内的那个 Visitor的 Visitor() 方法*，这其实是一种修饰器的模式，用另一个Visitor修饰了自己 个人觉得跟组合模式也很像 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:3","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.4 Other Visitor 和 Log Visitor Other Visitor主要用来访问 Info 结构中的 OtherThings 成员， Log Visitor 是做日志记录的。 type OtherThingsVisitor struct { visitor Visitor } func (v OtherThingsVisitor) Visit(fn VisitorFunc) error { return v.visitor.Visit(func(info *Info, err error) error { fmt.Println(\"OtherThingsVisitor() before call function\") err = fn(info, err) if err == nil { fmt.Printf(\"==\u003e OtherThings=%s\\n\", info.OtherThings) } fmt.Println(\"OtherThingsVisitor() after call function\") return err }) } type LogVisitor struct { visitor Visitor } func (v LogVisitor) Visit(fn VisitorFunc) error { return v.visitor.Visit(func(info *Info, err error) error { fmt.Println(\"LogVisitor() before call function\") err = fn(info, err) fmt.Println(\"LogVisitor() after call function\") return err }) } ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:4","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.5 使用方代码 现在我们看看如果使用上面的代码： func main() { info := Info{} var v Visitor = \u0026info v = LogVisitor{v} v = NameVisitor{v} v = OtherThingsVisitor{v} loadFile := func(info *Info, err error) error { info.Name = \"Hao Chen\" info.Namespace = \"MegaEase\" info.OtherThings = \"We are running as remote team.\" return nil } v.Visit(loadFile) } 我们可以看到 Visitor们一层套一层 我用 loadFile 假装从文件中读如数据 最后一条 v.Visit(loadfile) 我们上面的代码就全部开始激活工作了。 上面的代码输出如下的信息，你可以看到代码的执行顺序是怎么执行起来了: LogVisitor() before call function NameVisitor() before call function OtherThingsVisitor() before call function ==\u003e OtherThings=We are running as remote team. OtherThingsVisitor() after call function ==\u003e Name=Hao Chen, NameSpace=MegaEase NameVisitor() after call function LogVisitor() after call function 我们可以看到，上面的代码有以下几种功效： 解耦了数据和程序。 使用了装饰器模式 还做出来pipeline的模式 所以，其实，我们是可以把上面的代码重构一下的。 ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:5","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"2.6 Visitor装饰器 下面，我们用修饰器模式来重构一下上面的代码。 type DecoratedVisitor struct { visitor Visitor decorators []VisitorFunc } func NewDecoratedVisitor(v Visitor, fn ...VisitorFunc) Visitor { if len(fn) == 0 { return v } return DecoratedVisitor{v, fn} } // Visit implements Visitor func (v DecoratedVisitor) Visit(fn VisitorFunc) error { return v.visitor.Visit(func(info *Info, err error) error { if err != nil { return err } if err := fn(info, nil); err != nil { return err } for i := range v.decorators { if err := v.decorators[i](info, nil); err != nil { return err } } return nil }) } 上面的代码并不复杂， 用一个 DecoratedVisitor 的结构来存放所有的VistorFunc函数 NewDecoratedVisitor 可以把所有的 VisitorFunc转给它，构造 DecoratedVisitor 对象。 DecoratedVisitor实现了 Visit() 方法，里面就是来做一个for-loop，顺着调用所有的 VisitorFunc 这个DecoratedVisitor 同样可以成为一个Visitor来使用 最终，我们的代码就可以这样运作了： info := Info{} var v Visitor = \u0026info v = NewDecoratedVisitor(v, NameVisitor, OtherVisitor) v.Visit(LoadFile) ","date":"2021-03-08","objectID":"/posts/program/go/practice/design/go_design_8/:2:6","tags":["go 惯例"],"title":"Go Visitor 模式","uri":"/posts/program/go/practice/design/go_design_8/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-07","objectID":"/posts/program/go/practice/design/go_design_7/","tags":["go 惯例"],"title":"Go PIPELINE","uri":"/posts/program/go/practice/design/go_design_7/"},{"categories":["Go"],"content":"Go 流处理编程模式，这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-07","objectID":"/posts/program/go/practice/design/go_design_7/:0:0","tags":["go 惯例"],"title":"Go PIPELINE","uri":"/posts/program/go/practice/design/go_design_7/"},{"categories":["Go"],"content":"1. Pipeline 模式 对于Pipeline用过Unix/Linux命令行的人都不会陌生，他是一种把各种命令拼接起来完成一个更强功能的技术方法。在今天，流式处理，函数式编程，以及应用网关对微服务进行简单的API编排，其实都是受pipeline这种技术方式的影响。 Pipeline 可以很容易的把代码按单一职责的原则拆分成多个高内聚低耦合的小模块，然后方便地拼装起来去完成比较复杂的功能。 接下来我们就来介绍 Go Pipeline 的实现。Rob Pike在 Go Concurrency Patterns: Pipelines and cancellation 这篇blog中介绍了如下的一种编程模式。 ","date":"2021-03-07","objectID":"/posts/program/go/practice/design/go_design_7/:1:0","tags":["go 惯例"],"title":"Go PIPELINE","uri":"/posts/program/go/practice/design/go_design_7/"},{"categories":["Go"],"content":"1.1 Channel 管理 首先，我们需一个 echo()函数，其会把一个整型数组放到一个Channel中，并返回这个Channel func echo(nums []int) \u003c-chan int { out := make(chan int) go func() { for _, n := range nums { out \u003c- n } close(out) }() return out } 然后，我们依照这个模式，我们可以写出下面这些函数: 平方函数 func sq(in \u003c-chan int) \u003c-chan int { out := make(chan int) go func() { for n := range in { out \u003c- n * n } close(out) }() return out } 过滤奇数函数 func odd(in \u003c-chan int) \u003c-chan int { out := make(chan int) go func() { for n := range in { if n%2 != 0 { out \u003c- n } } close(out) }() return out } 求和函数 func sum(in \u003c-chan int) \u003c-chan int { out := make(chan int) go func() { var sum = 0 for n := range in { sum += n } out \u003c- sum close(out) }() return out } 客户端代码 我们的用户端的代码如下所示： var nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} for n := range sum(sq(odd(echo(nums)))) { fmt.Println(n) } 上面的代码类似于我们执行了Unix/Linux命令： echo $nums | sq | sum。 同样，如果你不想有那么多的函数嵌套，你可以使用一个代理函数来完成。 type EchoFunc func ([]int) (\u003c- chan int) type PipeFunc func (\u003c- chan int) (\u003c- chan int) func pipeline(nums []int, echo EchoFunc, pipeFns ... PipeFunc) \u003c- chan int { ch := echo(nums) for i := range pipeFns { ch = pipeFns[i](ch) } return ch } var nums = []int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10} for n := range pipeline(nums, gen, odd, sq, sum) { fmt.Println(n) } ","date":"2021-03-07","objectID":"/posts/program/go/practice/design/go_design_7/:1:1","tags":["go 惯例"],"title":"Go PIPELINE","uri":"/posts/program/go/practice/design/go_design_7/"},{"categories":["Go"],"content":"1.2 Fan in/Out Go语言的 Go Routine和 Channel还有一个好处，就是可以写出1对多，或多对1的pipeline，也就是Fan In/ Fan Out。下面，我们来看一个Fan in的示例： 我们想通过并发的方式来对一个很长的数组中的质数进行求和运算，我们想先把数组分段求和，然后再把其集中起来。 // 1. 数组生成 func makeRange(min, max int) []int { a := make([]int, max-min+1) for i := range a { a[i] = min + i } return a } // 2. 主函数 func main() { nums := makeRange(1, 10000) in := echo(nums) const nProcess = 5 var chans [nProcess]\u003c-chan int // 生成 5 个 Channel，然后都调用 sum(prime(in)) ，于是每个Sum的Go Routine都会开始计算和 for i := range chans { chans[i] = sum(prime(in)) } for n := range sum(merge(chans[:])) { fmt.Println(n) } } // 3. 判断是否为质数 func is_prime(value int) bool { for i := 2; i \u003c= int(math.Floor(float64(value) / 2)); i++ { if value%i == 0 { return false } } return value \u003e 1 } // 4. 质数筛选 Pipeline func prime(in \u003c-chan int) \u003c-chan int { out := make(chan int) go func () { for n := range in { if is_prime(n) { out \u003c- n } } close(out) }() return out } 最后再把所有的结果再求和拼起来，得到最终的结果。其中的merge代码如下： func merge(cs [] \u003c-chan int) \u003c-chan int { var wg sync.WaitGroup out := chan int wg.Add(len(cs)) for _, c := range cs{ go func(c \u003c-chan int) { for n := range c { out \u003c- n } wg.Done() }(c) } go func(){ wg.Wait() close(out) } return out } 用图片表示一下，整个程序的结构如下所示： ","date":"2021-03-07","objectID":"/posts/program/go/practice/design/go_design_7/:1:2","tags":["go 惯例"],"title":"Go PIPELINE","uri":"/posts/program/go/practice/design/go_design_7/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"Go 的装饰器，这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/:0:0","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"1. 装饰器 装饰器是一种函数式编程的玩法——用一个高阶函数来包装一下。所以，Go语言的修饰器编程模式，其实也就是函数式编程的模式。 不过，Go 语言的“糖”不多，而且又是强类型的静态无虚拟机的语言，所以，无法做到像 Java 和 Python 那样优雅的装饰代码。 ","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/:1:0","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"1.1 简单示例 我们先来看一个示例: package main import \"fmt\" func decorator(f func(s string)) func(s string) { return func(s string) { fmt.Println(\"Started\") f(s) fmt.Println(\"Done\") } } func Hello(s string) { fmt.Println(s) } func main() { decorator(Hello)(\"Hello, World!\") } 有些遗憾的是，Go 并不支持像 Python 那样的 @decorator 语法糖。所以代码调用上有些难看。 ","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/:1:1","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"1.2 多个修饰器的 Pipeline 如果一个函数被装饰了多次，需要对函数一层层的调用，看上去不是很好看。我们可以使用一个工具函数，来辅助一一遍历并调用各个 decorator: type HttpHandlerDecorator func(http.HandlerFunc) http.HandlerFunc func Handler(h http.HandlerFunc, decors ...HttpHandlerDecorator) http.HandlerFunc { for i := range decors { d := decors[len(decors)-1-i] // iterate in reverse h = d(h) } return h } // pipeline 的功能也就出来了 http.HandleFunc(\"/v4/hello\", Handler(hello, WithServerHeader, WithBasicAuth, WithDebugLog)) ","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/:1:2","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"1.3 泛型的装饰器 对于 Go 的修饰器模式，还有一个小问题 —— 好像无法做到泛型，其代码耦合了需要被修饰的函数的接口类型，无法做到非常通用。 因为 Go 语言不像 Python 和 Java，Python是动态语言，而 Java 有语言虚拟机，所以他们可以干好些比较变态的事，然而 Go 语言是一个静态的语言，这意味着其类型需要在编译时就要搞定，否则无法编译。不过，Go 语言支持的最大的泛型是 interface{} 还有比较简单的 reflection 机制，在上面做做文章，应该还是可以搞定的。 下面是用 reflection 机制写的一个比较通用的修饰器（为了便于阅读，我删除了出错判断代码） func Decorator(decoPtr, fn interface{}) (err error) { var decoratedFunc, targetFunc reflect.Value decoratedFunc = reflect.ValueOf(decoPtr).Elem() targetFunc = reflect.ValueOf(fn) v := reflect.MakeFunc(targetFunc.Type(), func(in []reflect.Value) (out []reflect.Value) { fmt.Println(\"before\") out = targetFunc.Call(in) fmt.Println(\"after\") return }) decoratedFunc.Set(v) return } 上面的代码动用了 reflect.MakeFunc() 函数制出了一个新的函数其中的 targetFunc.Call(in) 调用了被修饰的函数。上面这个 Decorator() 需要两个参数： 第一个是出参 decoPtr ，就是完成修饰后的函数 第二个是入参 fn ，就是需要修饰的函数 好的，让我们来看一下使用效果。首先假设我们有两个需要修饰的函数： func foo(a, b, c int) int { fmt.Printf(\"%d, %d, %d \\n\", a, b, c) return a + b + c } func bar(a, b string) string { fmt.Printf(\"%s, %s \\n\", a, b) return a + b } 然后我们可以这样使用: type MyFoo func(int, int, int) int var myfoo MyFoo Decorator(\u0026myfoo, foo) myfoo(1, 2, 3) 你会发现，使用 Decorator() 时，还需要先声明一个函数签名，感觉好傻啊。一点都不泛型，不是吗？ 嗯。如果你不想声明函数签名，那么你也可以这样： mybar := bar Decorator(\u0026mybar, bar) mybar(\"hello,\", \"world!\") 看上去依然不是那么的漂亮，但是可用。看样子 Go 语言目前本身的特性无法做成像 Java 或 Python 那样，对此，我们只能多求 Go 语言多放糖了！ 最后 Go 的泛型编程参见 laws-of-reflection ","date":"2021-03-06","objectID":"/posts/program/go/practice/design/go_design_6/:1:3","tags":["go 惯例"],"title":"Go 装饰器","uri":"/posts/program/go/practice/design/go_design_6/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"Go 的泛型和代码生成，这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:0:0","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"1. 泛型 接下来我们学习一下Go语言的代码生成的玩法。Go语言代码生成主要还是用来解决编程泛型的问题，泛型编程主要解决的问题是因为静态类型语言有类型，所以，相关的算法或是对数据处理的程序会因为类型不同而需要复制一份，这样导致数据类型和算法功能耦合的问题。泛型编程可以解决这样的问题，就是说，在写代码的时候，不用关心处理数据的类型，只需要关心相当处理逻辑。泛型编程是静态语言中非常非常重要的特征，如果没有泛型，我们很难做到多态，也很难完成抽象，会导致我们的代码冗余量很大。 ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:1:0","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"2. Go 语言的类型检查 Go语言目前并不支持真正的泛型，所以只能用 interface{} 这样的类似于 void 这种过度泛型* 来玩这就导致了我们在实际过程中就需要进行类型检查。Go语言的类型检查有两种技术，一种是 Type Assert，一种是Reflection。 ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:2:0","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"2.1 Type Assert Type Assert 在 Go 语言中称为断言，一般是对某个变量进行 .(type) 的转型操作，其会返回两个值， variable, error，第一个返回值是被转换好的类型，第二个是如果不能转换类型，则会报错。我们看下面这个示例: //Container is a generic container, accepting anything. type Container []interface{} //Put adds an element to the container. func (c *Container) Put(elem interface{}) { *c = append(*c, elem) } //Get gets an element from the container. func (c *Container) Get() interface{} { elem := (*c)[0] *c = (*c)[1:] return elem } intContainer := \u0026Container{} intContainer.Put(7) intContainer.Put(42) Container 是一个通用类型的容器，Put 和 Get 操作使用了 interface{}作泛型，这样我们就可以操作所有类型。 但是，在把数据取出来时，因为类型是 interface{} ，所以，你还要做一个转型，如果转型成功能才能进行后续操作（因为 interface{}太泛了，泛到什么类型都可以放）。下面是一个Type Assert的示例： // assert that the actual type is int elem, ok := intContainer.Get().(int) if !ok { fmt.Println(\"Unable to read an int from intContainer\") } fmt.Printf(\"assertExample: %d (%T)\\n\", elem, elem) ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:2:1","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"2.2 Reflection 对于反射，我们需要把上面的代码修改如下： type Container struct { s reflect.Value } func NewContainer(t reflect.Type, size int) *Container { if size \u003c=0 { size=64 } return \u0026Container{ s: reflect.MakeSlice(reflect.SliceOf(t), 0, size), } } func (c *Container) Put(val interface{}) error { if reflect.ValueOf(val).Type() != c.s.Type().Elem() { return fmt.Errorf(\"Put: cannot put a %T into a slice of %s\", val, c.s.Type().Elem())) } c.s = reflect.Append(c.s, reflect.ValueOf(val)) return nil } func (c *Container) Get(refval interface{}) error { if reflect.ValueOf(refval).Kind() != reflect.Ptr || reflect.ValueOf(refval).Elem().Type() != c.s.Type().Elem() { return fmt.Errorf(\"Get: needs *%s but got %T\", c.s.Type().Elem(), refval) } reflect.ValueOf(refval).Elem().Set( c.s.Index(0) ) c.s = c.s.Slice(1, c.s.Len()) return nil } 这是完全使用 reflection的玩法，其中 在 NewContainer()会根据参数的类型初始化一个Slice 在 Put()时候，会检查 val 是否和Slice的类型一致。 在 Get()时，我们需要用一个入参的方式，因为我们没有办法返回 reflect.Value 或是 interface{}，不然还要做Type Assert 但是有类型检查，所以，必然会有检查不对的道理 ，因此，需要返回 error 于是在使用上面这段代码的时候，会是下面这个样子： f1 := 3.1415926 f2 := 1.41421356237 c := NewMyContainer(reflect.TypeOf(f1), 16) if err := c.Put(f1); err != nil { panic(err) } if err := c.Put(f2); err != nil { panic(err) } g := 0.0 if err := c.Get(\u0026g); err != nil { panic(err) } fmt.Printf(\"%v (%T)\\n\", g, g) //3.1415926 (float64) fmt.Println(c.s.Index(0)) //1.4142135623 我们可以看到，Type Assert是不用了，但是用反射写出来的代码还是有点复杂的。那么有没有什么好的方法？ ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:2:2","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"2.3 Template 对于泛型编程最牛的语言 C++ 来说，这类的问题都是使用 Template来解决的。 //用\u003cclass T\u003e来描述泛型 template \u003cclass T\u003e T GetMax (T a, T b) { T result; result = (a\u003eb)? a : b; return (result); } int i=5, j=6, k; //生成int类型的函数 k=GetMax\u003cint\u003e(i,j); long l=10, m=5, n; //生成long类型的函数 n=GetMax\u003clong\u003e(l,m); C++的编译器会在编译时分析代码，根据不同的变量类型来自动化的生成相关类型的函数或类。C++叫模板的具体化。这个技术是编译时的问题，所以，不需要我们在运行时进行任何的运行的类型识别，我们的程序也会变得比较的干净。 go 里面我们同样可以这么做，只不过 Go 的编译器目前不会帮我们，我们需要自己实现。 ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:2:3","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"2.4 Go Generator 要玩 Go的代码生成，你需要三件事： 一个函数模板，其中设置好相应的占位符。 一个脚本，用于按规则来替换文本并生成新的代码。 一行注释代码 函数模板 我们把我们之前的示例改成模板。取名为 container.tmp.go 放在 ./template/下 package PACKAGE_NAME type GENERIC_NAMEContainer struct { s []GENERIC_TYPE } func NewGENERIC_NAMEContainer() *GENERIC_NAMEContainer { return \u0026GENERIC_NAMEContainer{s: []GENERIC_TYPE{}} } func (c *GENERIC_NAMEContainer) Put(val GENERIC_TYPE) { c.s = append(c.s, val) } func (c *GENERIC_NAMEContainer) Get() GENERIC_TYPE { r := c.s[0] c.s = c.s[1:] return r } 我们可以看到函数模板中我们有如下的占位符： PACKAGE_NAME – 包名 GENERIC_NAME – 名字 GENERIC_TYPE – 实际的类型 函数生成脚本 然后，我们有一个叫gen.sh的生成脚本，如下所示： #!/bin/bash set -e SRC_FILE=${1} PACKAGE=${2} TYPE=${3} DES=${4} #uppcase the first char PREFIX=\"$(tr '[:lower:]' '[:upper:]' \u003c\u003c\u003c ${TYPE:0:1})${TYPE:1}\" DES_FILE=$(echo ${TYPE}| tr '[:upper:]' '[:lower:]')_${DES}.go sed 's/PACKAGE_NAME/'\"${PACKAGE}\"'/g' ${SRC_FILE} | \\ sed 's/GENERIC_TYPE/'\"${TYPE}\"'/g' | \\ sed 's/GENERIC_NAME/'\"${PREFIX}\"'/g' \u003e ${DES_FILE} 其需要4个参数： 模板源文件 包名 实际需要具体化的类型 用于构造目标文件名的后缀 生成代码 接下来，我们只需要在代码中打一个特殊的注释： //go:generate ./gen.sh ./template/container.tmp.go gen uint32 container func generateUint32Example() { var u uint32 = 42 c := NewUint32Container() c.Put(u) v := c.Get() fmt.Printf(\"generateExample: %d (%T)\\n\", v, v) } //go:generate ./gen.sh ./template/container.tmp.go gen string container func generateStringExample() { var s string = \"Hello\" c := NewStringContainer() c.Put(s) v := c.Get() fmt.Printf(\"generateExample: %s (%T)\\n\", v, v) } 其中， 第一个注释是生成包名为 gen 类型为 uint32 目标文件名以 container 为后缀 第二个注释是生成包名为 gen 类型为 string 目标文件名以 container 为后缀 然后，在工程目录中直接执行 go generate 命令，就会生成如下两份代码，一份文件名为uint32_container.go 这两份代码可以让我们的代码完全编译通过，所付出的代价就是需要多执行一步 go generate 命令。 第三方工具 我们并不需要自己手写 gen.sh 这样的工具类，已经有很多第三方的已经写好的可以使用。下面是一个列表： Genny – https://github.com/cheekybits/genny Generic – https://github.com/taylorchu/generic GenGen – https://github.com/joeshaw/gengen Gen – https://github.com/clipperhouse/gen ","date":"2021-03-05","objectID":"/posts/program/go/practice/design/go_design_5/:2:4","tags":["go 惯例"],"title":"Go 代码生成和泛型","uri":"/posts/program/go/practice/design/go_design_5/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"反转控制，这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/:0:0","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"1. 嵌入和委托 ","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/:1:0","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"1.1 反转控制 反转控制IoC – Inversion of Control 是一种软件设计的方法，其主要的思想是把控制逻辑与业务逻辑分享，不要在业务逻辑里写控制逻辑，这样会让控制逻辑依赖于业务逻辑，而是反过来，让业务逻辑依赖控制逻辑。 在《IoC/DIP其实是一种管理思想》中的那个开关和电灯的示例一样，开关是控制逻辑，电器是业务逻辑，不要在电器中实现开关，而是把开关抽象成一种协议，让电器都依赖之。 接下来我们看看 Go 语言里面委托的实现方式。 ","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/:1:1","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"1.1 嵌入 Go 语言通过结构体嵌入实现了面向对象的一些特性，我们看下面这个例子: type Painter interface { Paint() } type Clicker interface { Click() } type Widget struct { X, Y int } // 结构体嵌入 type Label struct { Widget // Embedding (delegation) Text string // Aggregation X // 1. 重名属性 } type Button struct { Label // Embedding (delegation) } func (label Label) Paint() { fmt.Printf(\"%p:Label.Paint(%q)\\n\", \u0026label, label.Text) } // 2. 方法重载 // Paint 接口可以通过 Label 的嵌入带到新的结构体， // Button 中也可以重载这个接口方法 func (button Button) Paint() { // Override fmt.Printf(\"Button.Paint(%s)\\n\", button.Text) } func (button Button) Click() { fmt.Printf(\"Button.Click(%s)\\n\", button.Text) } // 3. 多态 // 可以使用接口来多态 // 也可以使用 泛型的 interface{} 来多态，但是需要有一个类型转换。 label := Label{Widget{10, 10}, \"State:\"} button1 := Button{Label{Widget{10, 70}, \"OK\"}} for _, painter := range []Painter{label, button1} { painter.Paint() } for _, widget := range []interface{}{label, button1} { widget.(Painter).Paint() if clicker, ok := widget.(Clicker); ok { clicker.Click() } fmt.Println() // print a empty line } 可以看到: 我们把 Widget嵌入到了 Label 中，并且存在重名的成员 X，可以用 label.X表明 是自己的X ，用 label.Wedget.X 表示嵌入过来的。 Button.Paint() 接口可以通过 Label 的嵌入带到新的结构体，如果 Button.Paint() 不实现的话，会调用 Label.Paint() ，所以，在 Button 中声明 Paint() 方法，相当于Override。 我们可以使用接口来多态，也可以使用 泛型的 interface{} 来多态，但是需要有一个类型转换。 结构体嵌入是 Go 语言中实现 23 种设计模式的基础，接下来我们来看看如何在 Go 语言中实现反转控制。 ","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/:1:2","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"1.3 反转控制 我们来看这样一个示例，我们有一个存放整数的数据结构： type IntSet struct { data map[int]bool } func NewIntSet() IntSet { return IntSet{make(map[int]bool)} } func (set *IntSet) Add(x int) { set.data[x] = true } func (set *IntSet) Delete(x int) { delete(set.data, x) } func (set *IntSet) Contains(x int) bool { return set.data[x] } IntSet 实现了 Add() 、Delete() 和 Contains() 三个操作。现在我们想实现一个 Undo 的功能。我们可以把把 IntSet 再包装一下变成 UndoableIntSet。 type UndoableIntSet struct { // Poor style IntSet // Embedding (delegation) functions []func() } func NewUndoableIntSet() UndoableIntSet { return UndoableIntSet{NewIntSet(), nil} } func (set *UndoableIntSet) Add(x int) { // Override if !set.Contains(x) { set.data[x] = true set.functions = append(set.functions, func() { set.Delete(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoableIntSet) Delete(x int) { // Override if set.Contains(x) { delete(set.data, x) set.functions = append(set.functions, func() { set.Add(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoableIntSet) Undo() error { if len(set.functions) == 0 { return errors.New(\"No functions to undo\") } index := len(set.functions) - 1 if function := set.functions[index]; function != nil { function() set.functions[index] = nil // For garbage collection } set.functions = set.functions[:index] return nil } 在上面的代码中，我们可以看到 我们在 UndoableIntSet 中嵌入了IntSet ，然后Override了 它的 Add()和 Delete() 方法。 Contains() 方法没有Override，所以，会被带到 UndoableInSet 中来了。 在Override的 Add()中，记录 Delete 操作 在Override的 Delete() 中，记录 Add 操作 在新加入 Undo() 中进行Undo操作。 通过这样的方式来为已有的代码扩展新的功能是一个很好的选择，这样，可以在重用原有代码功能和重新新的功能中达到一个平衡。但是，这种方式最大的问题是，Undo操作其实是一种控制逻辑，并不是业务逻辑，所以，在复用 Undo这个功能上是有问题。因为其中加入了大量跟 IntSet 相关的业务逻辑。 反转依赖 现在我们来看另一种方法：我们先声明一种函数接口，表现我们的Undo控制可以接受的函数签名是什么样的： type Undo []func() 有了上面这个协议后，我们的Undo控制逻辑就可以写成如下： func (undo *Undo) Add(function func()) { *undo = append(*undo, function) } func (undo *Undo) Undo() error { functions := *undo if len(functions) == 0 { return errors.New(\"No functions to undo\") } index := len(functions) - 1 if function := functions[index]; function != nil { function() functions[index] = nil // For garbage collection } *undo = functions[:index] return nil } 然后，我们在我们的IntSet里嵌入 Undo，然后，再在 Add() 和 Delete() 里使用上面的方法，就可以完成功能。 type IntSet struct { data map[int]bool undo Undo } func NewIntSet() IntSet { return IntSet{data: make(map[int]bool)} } func (set *IntSet) Undo() error { return set.undo.Undo() } func (set *IntSet) Contains(x int) bool { return set.data[x] } func (set *IntSet) Add(x int) { if !set.Contains(x) { set.data[x] = true set.undo.Add(func() { set.Delete(x) }) } else { set.undo.Add(nil) } } func (set *IntSet) Delete(x int) { if set.Contains(x) { delete(set.data, x) set.undo.Add(func() { set.Add(x) }) } else { set.undo.Add(nil) } } 这个就是控制反转，不再由 控制逻辑 Undo 来依赖业务逻辑 IntSet，而是由业务逻辑 IntSet 来依赖 Undo 。其依赖的是其实是一个协议，这个协议是一个没有参数的函数数组。我们也可以看到，我们 Undo 的代码就可以复用了。 个人理解: 委托和反转控制的核心是将控制逻辑实现为一种协议，让业务逻辑依赖于协议，而不是让控制逻辑依赖于业务逻辑，从而抽象控制逻辑达到复用。 ","date":"2021-03-04","objectID":"/posts/program/go/practice/design/go_design_4/:1:3","tags":["go 惯例"],"title":"委托和反转控制","uri":"/posts/program/go/practice/design/go_design_4/"},{"categories":["Go"],"content":"Builder模式与Function Options","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"Go 语言中的可选参数与创建型模式。这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:0:0","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1. Function Options Functional Options 编程模式是一个函数式编程的应用案例，与传统的 Builder 模式有关，编程技巧也很好，是目前在Go语言中最流行的一种编程模式。不多在讨论这个模式之前，我们先来看看要解决什么样的问题。 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:0","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1.1 配置选项问题 编程中，我们经常需要对一个对象进行相关配置，比如: type Server struct { Addr string Port int Protocol string Timeout time.Duration MaxConns int TLS *tls.Config } 在这个 Server 对象中 IP地址 Addr 和端口号 Port 是必填的(假设) 协议 Protocol 、 Timeout 和MaxConns 字段，不能为空，但是有默认值 TLS 需要配置证书和密钥，可以为空 所以，针对于上述这样的配置，我们需要有多种不同的创建不同配置 Server 的函数签名，如下所示 func NewDefaultServer(addr string, port int) (*Server, error) { return \u0026Server{addr, port, \"tcp\", 30 * time.Second, 100, nil}, nil } func NewTLSServer(addr string, port int, tls *tls.Config) (*Server, error) { return \u0026Server{addr, port, \"tcp\", 30 * time.Second, 100, tls}, nil } func NewServerWithTimeout(addr string, port int, timeout time.Duration) (*Server, error) { return \u0026Server{addr, port, \"tcp\", timeout, 100, nil}, nil } func NewTLSServerWithMaxConnAndTimeout(addr string, port int, maxconns int, timeout time.Duration, tls *tls.Config) (*Server, error) { return \u0026Server{addr, port, \"tcp\", 30 * time.Second, maxconns, tls}, nil } 因为Go语言不支持重载函数，所以，你得用不同的函数名来应对不同的配置选项。 这个问题按照简介程度有不同的解决方案: 使用一个单独的配置对象 Builder 构建者模式 Functional Options 下面我们一一来介绍。 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:1","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1.2 配置对象方案 配置对象方案是将所有的非必须选项移动到一个独立的配置对象中: type Config struct { Protocol string Timeout time.Duration Maxconns int TLS *tls.Config } type Server struct { Addr string Port int Conf *Config } 于是我们只需要一个 NewServer() 构造函数，但在使用前需要构建 Config 对象。 func NewServer(addr string, port int, conf *Config) (*Server, error) { //... } //Using the default configuratrion srv1, _ := NewServer(\"localhost\", 9000, nil) conf := ServerConfig{Protocol:\"tcp\", Timeout: 60*time.Duration} srv2, _ := NewServer(\"locahost\", 9000, \u0026conf) 但是这个方案有这么一些缺点: Config 并不是必需的 代码内需要判断 conf 是否为 nil 或者 Empty-Config{}，代码不是非常简洁 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:2","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1.3 Builder 模式 如果熟悉设计模式，我们很容易想到 Builder 模式: User user = new User.Builder() .name(\"Hao Chen\") .email(\"haoel@hotmail.com\") .nickname(\"左耳朵\") .build(); 仿照上面，我们可以把 Server 的创建改写成这样(这里面忽略了异常处理的部分): //使用一个builder类来做包装 type ServerBuilder struct { Server } func (sb *ServerBuilder) Create(addr string, port int) *ServerBuilder { sb.Server.Addr = addr sb.Server.Port = port //其它代码设置其它成员的默认值 return sb } func (sb *ServerBuilder) WithProtocol(protocol string) *ServerBuilder { sb.Server.Protocol = protocol return sb } func (sb *ServerBuilder) WithMaxConn( maxconn int) *ServerBuilder { sb.Server.MaxConns = maxconn return sb } func (sb *ServerBuilder) WithTimeOut( timeout time.Duration) *ServerBuilder { sb.Server.Timeout = timeout return sb } func (sb *ServerBuilder) WithTLS( tls *tls.Config) *ServerBuilder { sb.Server.TLS = tls return sb } func (sb *ServerBuilder) Build() (Server) { return sb.Server } 于是我们就可以按照如下方式来使用了: sb := ServerBuilder{} server, err := sb.Create(\"127.0.0.1\", 8080). WithProtocol(\"udp\"). WithMaxConn(1024). WithTimeOut(30*time.Second). Build() 上面这个代码结构优点是: 上面这样的方式也很清楚，不需要额外的Config类 使用链式的函数调用的方式来构造一个对象，只需要多加一个Builder类 但是似乎: 这个Builder类似乎有点多余，我们似乎可以直接在Server 上进行这样的 Builder 构造 在处理错误的时候可能就有点麻烦（需要为Server结构增加一个error 成员，破坏了Server结构体的“纯洁”），不如一个包装类更好一些 如果我们想省掉这个包装的结构体，那么就轮到我们的Functional Options上场了，函数式编程。 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:3","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1.3 Functional Options 首先，我们先定义一个函数类型：type Option func(*Server) 然后，我们可以使用函数式的方式定义一组如下的函数： func Protocol(p string) Option { return func(s *Server) { s.Protocol = p } } func Timeout(timeout time.Duration) Option { return func(s *Server) { s.Timeout = timeout } } func MaxConns(maxconns int) Option { return func(s *Server) { s.MaxConns = maxconns } } func TLS(tls *tls.Config) Option { return func(s *Server) { s.TLS = tls } } 上面这些函数接收一个参数，返回一个可以配置 Server 的另一个函数。例如: 当我们调用其中的一个函数用 MaxConns(30) 时 其返回值是一个 func(s* Server) { s.MaxConns = 30 } 的函数。 好了，现在我们再定一个 NewServer()的函数，其中，有一个可变参数 options 其可以传入多个上面的返回值函数，然后使用一个for-loop来设置我们的 Server 对象。 func NewServer(addr string, port int, options ...func(*Server)) (*Server, error) { srv := Server{ Addr: addr, Port: port, Protocol: \"tcp\", Timeout: 30 * time.Second, MaxConns: 1000, TLS: nil, } for _, option := range options { option(\u0026srv) } //... return \u0026srv, nil } 于是，我们在创建 Server 对象的时候，我们就可以这样来了。 s1, _ := NewServer(\"localhost\", 1024) s2, _ := NewServer(\"localhost\", 2048, Protocol(\"udp\")) s3, _ := NewServer(\"0.0.0.0\", 8080, Timeout(300*time.Second), MaxConns(1000)) 高度舒适: 不但解决了使用 Config 对象方式 的需要有一个config参数，但在不需要的时候，是放 nil 还是放 Config{}的选择困难 也不需要引用一个Builder的控制对象 直接使用函数式编程，在代码阅读上也很优雅 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:4","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"1.4 个人体会 不同的编程语言，因为语法上的差异，在设计模式或者说特定功能的实现上还是存在着一些明显的差异。所以要想写出特定语言的专业代码，去研究特定语言的23种设计模式实现还是很有必要的。随着软件编程的不断进步，更新的更优雅的编程模式也在不断出现，需要我们与时俱进。 但是想保持与时俱进并不容易，就拿 23 中设计模式来说，网上有关 Go 语言的实现，很多都是简单的复刻，而不是基于 Go 的最佳实践。作为互联网人，有效的获取我们需要的知识其实一个非常重要的能力。 ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:1:5","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"2. grpc 中的配置处理 Functional Options 在众多的 go package 中都被使用。我们就以 grpc 中的 ServerOption 作为示例，简单介绍一下他的使用: type ServerOption interface { apply(*serverOptions) } // 1. 服务端所有的配置选项 type serverOptions struct { creds credentials.TransportCredentials codec baseCodec cp Compressor dc Decompressor unaryInt UnaryServerInterceptor streamInt StreamServerInterceptor chainUnaryInts []UnaryServerInterceptor chainStreamInts []StreamServerInterceptor ... } // 2. 默认的参数配置 var defaultServerOptions = serverOptions{ maxReceiveMessageSize: defaultServerMaxReceiveMessageSize, maxSendMessageSize: defaultServerMaxSendMessageSize, connectionTimeout: 120 * time.Second, writeBufferSize: defaultWriteBufSize, readBufferSize: defaultReadBufSize, } // 3. Functional Options，不过这里多了一层包装 // funcServerOption wraps a function that modifies serverOptions into an // implementation of the ServerOption interface. type funcServerOption struct { f func(*serverOptions) } func (fdo *funcServerOption) apply(do *serverOptions) { fdo.f(do) } // f func(*serverOptions) 就是 Functional Options，不过 grpc 多了一层包装 func newFuncServerOption(f func(*serverOptions)) *funcServerOption { return \u0026funcServerOption{ f: f, } } // 4. Function Options 配置 func WriteBufferSize(s int) ServerOption { return newFuncServerOption(func(o *serverOptions) { o.writeBufferSize = s }) } // 5. 服务初始化 func NewServer(opt ...ServerOption) *Server { // 默认参数 opts := defaultServerOptions // funcServerOption.apply(\u0026opts) // f(\u0026opts) for _, o := range opt { o.apply(\u0026opts) } s := \u0026Server{ lis: make(map[net.Listener]bool), opts: opts, conns: make(map[string]map[transport.ServerTransport]bool), services: make(map[string]*serviceInfo), quit: grpcsync.NewEvent(), done: grpcsync.NewEvent(), czData: new(channelzData), } // 处理拦截器的链式调用 // chainUnaryServerInterceptors chains all unary server interceptors into one. chainUnaryServerInterceptors(s) chainStreamServerInterceptors(s) s.cv = sync.NewCond(\u0026s.mu) if EnableTracing { _, file, line, _ := runtime.Caller(1) s.events = trace.NewEventLog(\"grpc.Server\", fmt.Sprintf(\"%s:%d\", file, line)) } if s.opts.numServerWorkers \u003e 0 { s.initServerWorkers() } s.channelzID = channelz.RegisterServer(\u0026channelzServer{s}, \"\") channelz.Info(logger, s.channelzID, \"Server created\") return s } ","date":"2021-03-03","objectID":"/posts/program/go/practice/design/go_design_3/:2:0","tags":["go 惯例"],"title":"Builder模式与Function Options","uri":"/posts/program/go/practice/design/go_design_3/"},{"categories":["Go"],"content":"Go 错误处理","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"Go 错误处理。这篇文章摘录自耗子哥博客-Go编程模式 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:0:0","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.错误处理 错误处理一直以一是编程必需要面对的问题，不同的语言有不同的出现处理的方式，Go语言也一样。接下来我们来讨论一下Go语言的出错出处，尤其是那令人抓狂的 if err != nil 。不过在这之前，我们先来看看编程中的错误处理。这样可以在更高的层面理解编程中的错误处理。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:0","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.1 C语言的错误检查 首先，我们知道，处理错误最直接的方式是通过错误码，这也是传统的方式，在过程式语言中通常都是用这样的方式处理错误的。比如 C 语言，基本上来说，其通过函数的返回值标识是否有错，然后通过全局的 errno 变量并配合一个 errstr 的数组来告诉你为什么出错。 为什么是这样的设计？道理很简单，除了可以共用一些错误，更重要的是这其实是一种妥协。比如：read(), write(), open() 这些函数的返回值其实是返回有业务逻辑的值。也就是说，这些函数的返回值有两种语义，一种是成功的值，比如 open() 返回的文件句柄指针 FILE* ，或是错误 NULL。这样会导致调用者并不知道是什么原因出错了，需要去检查 errno 来获得出错的原因，从而可以正确地处理错误。 这种用 返回值 + errno 的错误检查方式会有一些问题: 程序员一不小心就会忘记返回值的检查，从而造成代码的 Bug； 函数接口非常不纯洁，正常值和错误值混淆在一起，导致语义有问题。 所以，后来，有一些类库就开始区分这样的事情。比如，Windows 的系统调用开始使用 HRESULT 的返回来统一错误的返回值，这样可以明确函数调用时的返回值是成功还是错误。但这样一来，函数的 input 和 output 只能通过函数的参数来完成，于是出现了所谓的 入参 和 出参 这样的区别。 然而，这又使得函数接入中参数的语义变得复杂，一些参数是入参，一些参数是出参，函数接口变得复杂了一些。而且，依然没有解决函数的成功或失败可以被人为忽略的问题。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:1","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.2 Java的错误处理 Java语言使用 try-catch-finally 通过使用异常的方式来处理错误，其实，这比起C语言的错处理进了一大步，使用抛异常和抓异常的方式可以让我们的代码有这样的一些好处： 函数接口在 input（参数）和 output（返回值）以及错误处理的语义是比较清楚的。 正常逻辑的代码可以与错误处理和资源清理的代码分开，提高了代码的可读性。 异常不能被忽略（如果要忽略也需要 catch 住，这是显式忽略）。 在面向对象的语言中（如 Java），异常是个对象，所以，可以实现多态式的 catch。 与状态返回码相比，异常捕捉有一个显著的好处是，函数可以嵌套调用，或是链式调用。比如： int x = add(a, div(b,c)); Pizza p = PizzaBuilder().SetSize(sz).SetPrice(p)…; ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:2","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.3 Go语言的错误处理 Go 语言的函数支持多返回值，所以，可以在返回接口把 业务语义（业务返回值） 和 控制语义（出错返回值） 区分开来。Go 语言的很多函数都会返回 result, err 两个值，于是: 参数上基本上就是入参，而返回接口把结果和错误分离，这样使得函数的接口语义清晰； 而且，Go 语言中的错误参数如果要忽略，需要显式地忽略，用 _ 这样的变量来忽略； 另外，因为返回的 error 是个接口（其中只有一个方法 Error()，返回一个 string ），所以你可以扩展自定义的错误处理。 另外，如果一个函数返回了多个不同类型的 error，你也可以使用下面这样的方式： if err != nil { switch err.(type) { case *json.SyntaxError: ... case *ZeroDivisionError: ... case *NullPointerError: ... default: ... } } Go语言的错误处理的的方式，本质上是返回值检查，但是也兼顾了异常的一些好处 – 对错误的扩展。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:3","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.4 资源清理 出错后是需要做资源清理的，不同的编程语言有不同的资源清理的编程模式： C语言 – 使用的是 goto fail; 的方式到一个集中的地方进行清理（有篇有意思的文章可以看一下《由苹果的低级BUG想到的》） C++语言- 一般来说使用 RAII模式，通过面向对象的代理模式，把需要清理的资源交给一个代理类，然后在析构函数来解决。 Java语言 – 可以在finally 语句块里进行清理。 Go语言 – 使用 defer 关键词进行清理。 下面是一个Go语言的资源清理的示例： func Close(c io.Closer) { err := c.Close() if err != nil { log.Fatal(err) } } func main() { r, err := Open(\"a\") if err != nil { log.Fatalf(\"error opening 'a'\\n\") } defer Close(r) // 使用defer关键字在函数退出时关闭文件。 r, err = Open(\"b\") if err != nil { log.Fatalf(\"error opening 'b'\\n\") } defer Close(r) // 使用defer关键字在函数退出时关闭文件。 } ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:4","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.5 Error Check Hell 我们先看如下的一个令人崩溃的代码。if err !=nil 的代码的确能让人写到吐。 func parse(r io.Reader) (*Point, error) { var p Point if err := binary.Read(r, binary.BigEndian, \u0026p.Longitude); err != nil { return nil, err } if err := binary.Read(r, binary.BigEndian, \u0026p.Latitude); err != nil { return nil, err } if err := binary.Read(r, binary.BigEndian, \u0026p.Distance); err != nil { return nil, err } if err := binary.Read(r, binary.BigEndian, \u0026p.ElevationGain); err != nil { return nil, err } if err := binary.Read(r, binary.BigEndian, \u0026p.ElevationLoss); err != nil { return nil, err } } 解决这个问题的一种方法是函数式编程的方式，比如: func parse(r io.Reader) (*Point, error) { var p Point var err error // 函数式编程，对错误处理的代码进行抽象 read := func(data interface{}) { if err != nil { return } err = binary.Read(r, binary.BigEndian, data) } read(\u0026p.Longitude) read(\u0026p.Latitude) read(\u0026p.Distance) read(\u0026p.ElevationGain) read(\u0026p.ElevationLoss) if err != nil { return \u0026p, err } return \u0026p, nil } Closure 的方式把相同的代码给抽出来重新定义一个函数，这样大量的 if err!=nil 处理的很干净了。但是会带来一个问题，那就是有一个 err 变量和一个内部的函数，感觉不是很干净。那么，我们还能不能搞得更干净一点呢，我们从Go 语言的 bufio.Scanner()中似乎可以学习到一些东西： scanner := bufio.NewScanner(input) for scanner.Scan() { token := scanner.Text() // process token } if err := scanner.Err(); err != nil { // process the error } scanner在操作底层的I/O的时候，那个for-loop中没有任何的 if err !=nil 的情况，退出循环后有一个 scanner.Err() 的检查。看来使用了结构体的方式。模仿它，我们可以把我们的代码重构成下面这样： type Reader struct { r io.Reader err error // 错误收集 } func (r *Reader) read(data interface{}) { if r.err == nil { r.err = binary.Read(r.r, binary.BigEndian, data) } } func parse(input io.Reader) (*Point, error) { var p Point r := Reader{r: input} r.read(\u0026p.Longitude) r.read(\u0026p.Latitude) r.read(\u0026p.Distance) r.read(\u0026p.ElevationGain) r.read(\u0026p.ElevationLoss) if r.err != nil { return nil, r.err } return \u0026p, nil } 有了上面这个技术，我们的“流式接口 Fluent Interface”，也就很容易处理了。如下所示： package main import ( \"bytes\" \"encoding/binary\" \"fmt\" ) // 长度不够，少一个Weight var b = []byte {0x48, 0x61, 0x6f, 0x20, 0x43, 0x68, 0x65, 0x6e, 0x00, 0x00, 0x2c} var r = bytes.NewReader(b) type Person struct { Name [10]byte Age uint8 Weight uint8 err error } func (p *Person) read(data interface{}) { if p.err == nil { p.err = binary.Read(r, binary.BigEndian, data) } } func (p *Person) ReadName() *Person { p.read(\u0026p.Name) return p } func (p *Person) ReadAge() *Person { p.read(\u0026p.Age) return p } func (p *Person) ReadWeight() *Person { p.read(\u0026p.Weight) return p } func (p *Person) Print() *Person { if p.err == nil { fmt.Printf(\"Name=%s, Age=%d, Weight=%d\\n\",p.Name, p.Age, p.Weight) } return p } func main() { p := Person{} p.ReadName().ReadAge().ReadWeight().Print() fmt.Println(p.err) // EOF 错误 } 但是，其使用场景也就只能在对于同一个业务对象的不断操作下可以简化错误处理，对于多个业务对象的话，还是得需要各种 if err != nil的方式。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:5","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"1.5 包装错误 错误的传递，我们们需要包装一下错误，而不是干巴巴地把err给返回到上层，我们需要把一些执行的上下文加入。通常来说，我们会使用 fmt.Errorf()来完成这个事，比如： if err != nil { return fmt.Errorf(\"something failed: %v\", err) } 另外，在Go语言的开发者中，更为普遍的做法是将错误包装在另一个错误中，同时保留原始内容： type authorizationError struct { operation string err error // original error } func (e *authorizationError) Error() string { return fmt.Sprintf(\"authorization failed during %s: %v\", e.operation, e.err) } 当然，更好的方式是通过一种标准的访问方法，这样，我们最好使用一个接口，比如 causer接口中实现 Cause() 方法来暴露原始错误，以供进一步检查： type causer interface { Cause() error } func (e *authorizationError) Cause() error { return e.err } 有一个第三方的错误库（github.com/pkg/errors）已经帮我做了这个事情，这个库基本上来说就是事实上的标准了: import \"github.com/pkg/errors\" //错误包装 if err != nil { return errors.Wrap(err, \"read failed\") } // Cause接口 switch err := errors.Cause(err).(type) { case *MyError: // handle specifically default: // unknown error } ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:1:6","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2. Go Error 最佳实践 前面我们对 Go 的 Error 处理有了一个全面的介绍。除了这些还有一些最佳实践我们关注。由于在 Go 中 Error are values，Go 语言中 Error 也有多种处理方式: sentinel error: 预定义错误 error types: 实现了 error 接口的自定义类型并结合断言进行使用 error wrapt: 错误包装 错误行为特征检视策略: 将某个包中的错误类型归类，统一提取出一些公共的错误行为特征（behaviour），并将这些错误行为特征放入一个公开的接口类型 接下来我们会一一比较这几种处理方式得优劣，得出最佳得 Error 得处理实践。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:0","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.2 sentinel error 预定义的特定错误，我们叫为 sentinel error，这个名字来源于计算机编程中使用一个特定值来表示不可能进行进一步处理的做法。所以对于 Go，我们使用特定的值来表示错误。if err == ErrSomething { … } 标准库中得 io.EOF，更底层的 syscall.ENOENT 都是 sentinel error 得用法。但是 sentinel error 有如下缺点: 使用 sentinel 值是最不灵活的错误处理策略，因为调用方必须使用 == 将结果与预先声明的值进行比较。当您想要提供更多的上下文时，这就出现了一个问题，因为返回一个不同的错误将破坏相等性检查。甚至是一些有意义的 fmt.Errorf 携带一些上下文，也会破坏调用者的 == ，调用者将被迫查看 error.Error() 方法的输出，以查看它是否与特定的字符串匹配。 而依赖 error.Error() 得字符串输出，是一种非常弱的协议，很容易被破坏。Error 方法存在于 error 接口主要用于方便程序员使用，但不是程序（编写测试可能会依赖这个返回）。这个输出的字符串用于记录日志、输出到 stdout 等。所以不应该依赖检测 error.Error 的输出 Sentinel errors 成为你 API 公共部分。 如果您的公共函数或方法返回一个特定值的错误，那么该值必须是公共的，当然要有文档记录，这会增加 API 的表面积。 如果 API 定义了一个返回特定错误的 interface，则该接口的所有实现都将被限制为仅返回该错误，即使它们可以提供更具描述性的错误。 你的接口表面积越大，接口就越脆弱 Sentinel errors 在两个包之间创建了依赖。sentinel errors 最糟糕的问题是它们在两个包之间创建了源代码依赖关系。例如，检查错误是否等于 io.EOF，您的代码必须导入 io 包。这个特定的例子听起来并不那么糟糕，因为它非常常见，但是想象一下，当项目中的许多包导出错误值时，存在耦合，项目中的其他包必须导入这些错误值才能检查特定的错误条件（in the form of an import loop）。 所以 sentinel errors 可以在标准库中使用，因为每一个标注库的功能相对单一，不会形成复杂依赖，但不适合在一个业务层的 application 中使用。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:1","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.3 error types 使用自定义错误类型，并结合类型断言，可以提供更多的上下文信息: type MyErr struct { Line string Msg string } func main() { err := test() switch err := err.(type) { case nil: // success case *MyErr: // handler MyErr default: // unkown err } } 调用者要使用类型断言和类型 switch，就要让自定义的 error 变为 public。这种模型会导致和调用者产生强耦合，从而导致 API 变得脆弱。虽然错误类型比 sentinel errors 更好，因为它们可以捕获关于出错的更多上下文，但是 error types 共享 error values 许多相同的问题。因此应该避免使用错误类型，或者至少避免将它们作为公共 API 的一部分。同样的 error types 在标准库中有使用，但是在业务层的 application 中也不适合使用。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:2","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.4 error wrap 错误包装就是我们前面介绍的内容，除了 Cause 方法，github.com/pkg/errors 还提供了其他 Error 处理的方法。再明白为什么要这么做之前，我们需要明白 Error 处理中的痛点。我们经常会写出下面这样的代码: func step2() error { } func step1() error{ _, err := step2() if err != nil { log.Printf(\"print error in step1: %v\", err) return err } return nil } func main() { _, err := step1() if err != nil { log.Printf(\"print error in main: %v\", err) } } 在函数的调用链中，每一 error 处理的地方都打印了日志，最终的结果就是日志中，写满了相同错误的日志。显然理想的情况下，我们的错误应该时这样的，日志中只记录一次错误处理的完整信息。所以像上面的代码，要么直接抛出 err，要么将error记录到日志中，并对 error 进行处理。 理想情况下，错误处理应该满足以下几个目标: 满足程序员的需求: 能够打印 error 的完整日志以及调用的堆栈信息 满足程序的需求: 对底层的异常，包括 sentinel error 和 sentinel error 进行特定异常的判断，从而完成对特定异常的处理 github.com/pkg/errors 提供的错误包装如何实现这两个目的呢，我们看下面这个简单示例: import \"github.com/pkg/errors\" func Readfile(path string) ([]byte, error) { f, err := os.Open(path) if err != nil { // 1. 包装错误，附加错误信息，并且 Wrap 方法会包含调用的堆栈信息 return nil, errors.Wrap(err, \"open failed\") } defer f.Close() return io.ReadAll(f) } func ReadConfig() ([]byte, error) { home := os.Getenv(\"HOME\") config, err := Readfile(filepath.Join(home, \"setting.yaml\")) // 2. WithMessage 同样会包装错误，但是并不会包含堆栈信息，避免重复打印堆栈 return config, errors.WithMessage(err, \"can not read config\") } func ReadMe() { _, err := ReadConfig() if err != nil { // 3. %T 打印错误类型，%v 打印错误值，Cause() 函数用于获取包装错误的根因 // 函数的根因可以用于底层的错误判定 fmt.Printf(\"origin error %T %v\\n\", errors.Cause(err), errors.Cause(err)) // %+v 打印 wrap error 中包含的堆栈信息 fmt.Printf(\"stack trace: \\n %+v\\n\", err) } } github.com/pkg/errors 使用技巧 github.com/pkg/errors 提供了丰富的接口，有很多使用上的技巧: 在你的应用代码中自己触发的 error，使用 errors.New 或者 errros.Errorf 返回错误，这两个方法都会携带上堆栈信息 func parseArg(args string[]) { if len(args) \u003c 3 { return errors.Errorf(\"not enough args\") } } 如果调用其他包内的函数，通常简单的直接返回，无需包装，因为在约定好大家都使用错误包装的情况下，重复的错误包装会打印重复的堆栈信息 if err != nil { return err } 如果和其他库进行协作，考虑使用 errors.Wrap 或者 errors.Wrapf 保存堆栈信息。同样适用于和标准库协作的时候 f, err := os.Open(path) if err != nil { return errors.Wrapf(err, \"failed to open %q\", path) } 在长的函数调用链中，直接返回错误，而不是每个错误产生的地方到处打日志。最后在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。 func main() { err := app.Run() if err != nil { fmt.Printf(\"Fatal: %+v\\n\", err) os.Exit(1) } } 使用 errors.Cause 获取 root error，再进行和 sentinel error 判定。 github.com/pkg/errors 使用限制 上面所有的一套错误包装，在使用上是由一定限制的。试想一下，一个第三方库也使用上面的方法进行错误包装，那么在应用层也以同样的方法包装错误时，就会重复打印堆栈信息。所以只有 applications 可以选择错误包装。具有可重用性的基础包只能返回根错误值，即 sentinel error 或者自定义错误。此机制与 Go 标准库中使用的相同。 最后一单错误已经被处理了，这个错误就不应该被继续上抛给调用方，应该只返回 nil。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:3","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.5 错误行为特征检视策略 以标准库中的net包为例，它将包内的所有错误类型的公共行为特征抽象并放入net.Error这个接口中。而错误处理方仅需依赖这个公共接口即可检视具体错误值的错误行为特征信息，并根据这些信息做出后续错误处理分支选择的决策。 // $GOROOT/src/net/net.go type Error interface { error Timeout() bool // 是超时类错误吗？ Temporary() bool // 是临时性错误吗？ } 下面是http包使用错误行为特征检视策略进行错误处理的代码： // $GOROOT/src/net/http/server.go func (srv *Server) Serve(l net.Listener) error { ... for { rw, e := l.Accept() if e != nil { select { case \u003c-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok \u0026\u0026 ne.Temporary() { // 这里对临时性错误进行处理 ... time.Sleep(tempDelay) continue } return e } ... } Accept方法实际上返回的错误类型为*OpError，它是net包中的一个自定义错误类型，实现了错误公共特征接口net.Error，因此可以被错误处理方通过net.Error接口的方法判断其行为是否满足Temporary或Timeout特征。 // $GOROOT/src/net/net.go type OpError struct { ... // Err is the error that occurred during the operation. Err error } type temporary interface { Temporary() bool } func (e *OpError) Temporary() bool { if ne, ok := e.Err.(*os.SyscallError); ok { t, ok := ne.Err.(temporary) return ok \u0026\u0026 t.Temporary() } t, ok := e.Err.(temporary) return ok \u0026\u0026 t.Temporary() } ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:4","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.6 错误判定 前面我们提到了两种错误判定的方法: 使用 == 进行 sentinel error 的错误判定 通过断言进行自定义错误的判定 go1.13为 errors 和 fmt 标准库包引入了新特性，以简化处理包含其他错误的错误。其中最重要的是: 包含另一个错误的 error 可以实现返回底层错误的 Unwrap 方法。如果 e1.Unwrap() 返回 e2，那么我们说 e1 包装 e2，您可以展开 e1 以获得 e2。 结合 Unwrap() 方法 go1.13 errors 包提供了两个用于检查错误的新函数：Is 和 As。这两个方法会循环判断 err 是否有 Unwrap() 方法，返回错误的根因，并于传入的错误进行比较。 if err == NotFound {} // 相比于等值判定，强依赖特定的错误值，Is 的判定方法更加灵活，我们可以对错误进行包装，添加更多的上下文信息，但是不影响错误的等值判定 if errors.Is(err, NotFound) {} if e, ok := err.(*QueryError); ok {} var e *QueryError if errors.As(err, \u0026e) {} 为了便于错误包装，go13 还扩展了 fmt 包，fmt.Errorf 支持新的 %w 谓词，用于包装错误。内部的实现方式类似于: type wrapError { msg string err error } func (e *wrapError) Error() string { return e.msg } func (e *wrapError) Unwrap() string { return e.err } 使用新的 %w 谓词，就可以结合 Is/As 进行错误判定了: err := fmt.Errorf(\"access defined: %v: %w\", name, ErrPermission) .... if errors.Is(err, ErrPermission) { } Is/As 实现 Is/As 的实现并不复杂: package errors import ( \"internal/reflectlite\" ) // Unwrap returns the result of calling the Unwrap method on err, if err's // type contains an Unwrap method returning error. // Otherwise, Unwrap returns nil. func Unwrap(err error) error { u, ok := err.(interface { Unwrap() error }) if !ok { return nil } return u.Unwrap() } func Is(err, target error) bool { if target == nil { return err == target } isComparable := reflectlite.TypeOf(target).Comparable() for { if isComparable \u0026\u0026 err == target { return true } // 自定义 error 如果实现了 Is 方法可以，实现自定义的 Is 错误判定逻辑 if x, ok := err.(interface{ Is(error) bool }); ok \u0026\u0026 x.Is(target) { return true } // 循环调用 Unwrap 方法获取根因 if err = Unwrap(err); err == nil { return false } } } func As(err error, target any) bool { if target == nil { panic(\"errors: target cannot be nil\") } val := reflectlite.ValueOf(target) typ := val.Type() if typ.Kind() != reflectlite.Ptr || val.IsNil() { panic(\"errors: target must be a non-nil pointer\") } targetType := typ.Elem() if targetType.Kind() != reflectlite.Interface \u0026\u0026 !targetType.Implements(errorType) { panic(\"errors: *target must be interface or implement error\") } for err != nil { if reflectlite.TypeOf(err).AssignableTo(targetType) { val.Elem().Set(reflectlite.ValueOf(err)) return true } if x, ok := err.(interface{ As(any) bool }); ok \u0026\u0026 x.As(target) { return true } err = Unwrap(err) } return false } var errorType = reflectlite.TypeOf((*error)(nil)).Elem() 自定义 error 如果实现了 Is 方法可以，实现自定义的 Is 错误判定逻辑，比如像下面这样: type MeError struct { Name string Path string } func (e *Merror) Is(target error) bool { t, ok := target.(*MeError) if !ok { return False } return e.User == t.User } 虽然 go errors 标准库实现了错误包装的功能，但是不支持获取堆栈信息。同时在 go13 发布之后，github.com/pkg/errors 也兼容了 go13 这种 Unwrap 处理方式。所以目前我们还是要继续使用 github.com/pkg/errors。 // +build go1.13 package errors import ( stderrors \"errors\" ) func Is(err, target error) bool { return stderrors.Is(err, target) } func As(err error, target interface{}) bool { return stderrors.As(err, target) } func Unwrap(err error) error { return stderrors.Unwrap(err) } // Unwrap provides compatibility for Go 1.13 error chains. type withMessage struct { cause error msg string } func (w *withMessage) Unwrap() error { return w.cause } ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:5","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"2.7 错误处理的总结 Go社区中关于如何进行错误处理的讨论有很多，但唯一正确的结论是没有哪一种错误处理策略适用于所有项目或场合。综合上述的构造错误值方法及错误处理策略，请记住如下几点： 尽量使用透明错误处理策略降低错误处理方与错误值构造方之间的耦合； 如果可以通过错误值类型的特征进行错误检视，那么尽量使用错误行为特征检视策略； 在上述两种策略无法实施的情况下，再用“哨兵”策略和错误值类型检视策略； 在Go 1.13及后续版本中，尽量用errors.Is和errors.As方法替换原先的错误检视比较语句。 ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:2:6","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"3. Go 的异常处理 Go的正常错误处理与异常处理之间是泾渭分明的，这与其他主流编程语言使用结构化错误处理统一处理错误与异常是两种不同的理念。Go提供了panic专门用于处理异常。 panic是一个Go内置函数，它用来停止当前常规控制流并启动panicking过程。当函数F调用panic函数时，函数F的执行停止，函数F中已进行了求值的defer函数都将得到正常执行，然后函数F将控制权返还给其调用者。对于函数F的调用者而言，函数F之后的行为就如同调用者调用的函数是panic一样，该panicking过程将继续在栈上进行下去，直到当前goroutine中的所有函数都返回为止，此时程序将崩溃退出。 在Go中，panic则是“不得已而为之”，即所有引发panic的情形，无论是显式的（我们主动调用panic函数引发的）还是隐式的（Go运行时检测到违法情况而引发的），都是我们不期望看到的。对这些引发的panic，我们很少有预案应对，更多的是让程序快速崩溃掉。因此一旦发生panic，就意味着我们的代码很大可能出现了bug。 使用recover可以捕获panic，防止goroutine意外退出 func (s *ss) Token(skipSpace bool, f func(rune) bool) (tok []byte, err error) { defer func() { if e := recover(); e != nil { if se, ok := e.(scanError); ok { err = se.err } else { panic(e) } } }() if f == nil { f = notSpace } s.buf = s.buf[:0] tok = s.token(skipSpace, f) return } ","date":"2021-03-02","objectID":"/posts/program/go/practice/design/go_design_2/:3:0","tags":["go 惯例"],"title":"go 错误处理","uri":"/posts/program/go/practice/design/go_design_2/"},{"categories":["Go"],"content":"Go 面向接口编程","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"这个系列是 Go 语言设计模式的系列，掌握如何使用编程语言实现 23 种常见设计模式是精通一门语言的\"捷径\"。这个系列我们就来学习 Go 设计模式的最佳实践。 ","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/:0:0","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"1. 学习资料 到目前为止为了学习设计模式，我已经看过不少的书和视频，其中我觉得很好的有下面这些: 王铮老师在极客时间的专栏-设计模式之美: 以 Java 为基础，非常详细的讲解了设计模式和编程设计思想的方方面面 JavaScript设计模式与开发实践: JavaScript 如何实现常见的设计模式 耗子哥博客系列 深入设计模式 目前还没找到一本专门讲解 Go 设计模式的书，网上包括 github 虽然有不少人已经将 23 中设计模式使用 Go 总结实现了一遍，但基本上都是照\"葫芦画瓢\"，看不出实现方式与其他语言有什么不同。 这个系列的目的就是为了收集 Go 语言设计模式中的最佳实践，写出更优雅的 Go 代码。这一节我们先来介绍 Go 语言中最常用的面向接口编程。 ","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/:1:0","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"2. 面向接口编程 Go 语言不支持传统的面向对象编程，结构体嵌入看似是面向对象，其实只是 Go 实现的语法糖。而接口才是 Go 语言中实现多态和泛型的主要方式。这就带来了 Go 语言与其他面向对象语言在实现 23 种设计模式上的差异。那 Go 语言中面向接口编程体现在哪呢？ ","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/:2:0","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"2.1 何为接口编程 我们来看段代码，其中是两个方法，它们都是要输出一个结构体，其中一个使用一个函数，另一个使用一个“成员函数”。 func PrintPerson(p *Person) { fmt.Printf(\"Name=%s, Sexual=%s, Age=%d\\n\", p.Name, p.Sexual, p.Age) } func (p *Person) Print() { fmt.Printf(\"Name=%s, Sexual=%s, Age=%d\\n\", p.Name, p.Sexual, p.Age) } func main() { var p = Person{ Name: \"Hao Chen\", Sexual: \"Male\", Age: 44, } PrintPerson(\u0026p) p.Print() } 这两种方式，你更喜欢哪一种？在 Go 语言中，使用 “成员函数”的方式叫“Receiver”，这种方式是一种封装 ，因为 PrintPerson()本来就是和 Person强耦合的，所以，理应放在一起。更重要的是，这种方式可以进行接口编程，对于接口编程来说，也就是一种抽象，主要是用在“多态”。 那面向接口的编程应该怎么写呢？我们来看一下这段代码: type Country struct { Name string } type City struct { Name string } type Printable interface { PrintStr() } func (c Country) PrintStr() { fmt.Println(c.Name) } func (c City) PrintStr() { fmt.Println(c.Name) } c1 := Country {\"China\"} c2 := City {\"Beijing\"} c1.PrintStr() c2.PrintStr() 我们使用了一个 Printable 的接口，而 Country 和 City 都实现了接口方法 PrintStr() 而把自己输出。然而，这些代码都是一样的。能不能省掉呢？我们可以使用“结构体嵌入”的方式来完成这个事。(我的理解，这里代表的思想与面向对象类似，将公共代码提升到父类中，以达到代码复用的目的。) type WithName struct { Name string } type Country struct { WithName } type City struct { WithName } type Printable interface { PrintStr() } func (w WithName) PrintStr() { fmt.Println(w.Name) } c1 := Country {WithName{ \"China\"}} c2 := City { WithName{\"Beijing\"}} c1.PrintStr() c2.PrintStr() 引入一个叫 WithName的结构体，然而，所带来的问题就是，在初始化的时候，变得有点乱。那么，我们有没有更好的方法？下面是另外一个解。 type Country struct { Name string } type City struct { Name string } type Stringable interface { ToString() string } func (c Country) ToString() string { return \"Country = \" + c.Name } func (c City) ToString() string{ return \"City = \" + c.Name } func PrintStr(p Stringable) { fmt.Println(p.ToString()) } d1 := Country {\"USA\"} d2 := City{\"Los Angeles\"} PrintStr(d1) PrintStr(d2) 上面这段代码，我们可以看到: 我们使用了一个叫Stringable 的接口，我们用这个接口把“业务类型” Country 和 City 和“控制逻辑” Print() 给解耦了。 于是，只要实现了Stringable 接口，都可以传给 PrintStr() 来使用。 这就是面向对象编程方法的黄金法则：面向接口编程而不是实现。这里我的理解是: 所有的控制逻辑都面向接口编程，这样对象仅需实现接口。 ","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/:2:1","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"1.2 接口完整性检查 Go 语言中的接口检查是一种运行时检查，只有我们在作多态赋值时，才会进行接口完整性检查。否则 Go语言的编译器不会严格检查一个对象是否实现了某接口所有的接口方法，比如下面这个示例: type Shape interface { Sides() int Area() int } type Square struct { len int } func (s* Square) Sides() int { return 4 } func main() { s := Square{len: 5} fmt.Printf(\"%d\\n\",s.Sides()) } 这里的 Shape 接口和 Square 结构没有任何关系，Go 编译器不会去检查 Square 是否实现了 Shape 接口的所有方法。如果我们需要强制实现接口的所有方法，那么我们应该怎么办呢？ 在Go语言编程圈里有一个比较标准的作法： var _ Shape = (* Square)(nil) 声明一个 _ 变量（没人用），其会把一个 nil 的空指针，从 Square 转成 Shape，这样，如果没有实现完相关的接口方法，编译器就会报错，这样就做到了个强验证的方法。 ","date":"2021-03-01","objectID":"/posts/program/go/practice/design/go_design_1/:2:2","tags":["go 惯例"],"title":"go 面向接口编程","uri":"/posts/program/go/practice/design/go_design_1/"},{"categories":["Go"],"content":"go 语言值得花时间的优秀资源","date":"2021-01-01","objectID":"/posts/program/go/go_resources/","tags":["学习资源"],"title":"go 学习资源","uri":"/posts/program/go/go_resources/"},{"categories":["Go"],"content":"1. Go 语法 Go 圣经 ","date":"2021-01-01","objectID":"/posts/program/go/go_resources/:1:0","tags":["学习资源"],"title":"go 学习资源","uri":"/posts/program/go/go_resources/"},{"categories":["Go"],"content":"2. Go 进阶 《Go专家编程》: 在 GitBook 中找到一本书，可能太受欢迎了，作者已经初版了书，对 Go 基本上所有部分的实现都做了解释，深入浅出 《Go RPC 开发指南》: 重点介绍高性能的分布式全功能的RPC框架 rpcx Go夜读: Go 夜读是面向 Go 语言的专业分享组织，每期都会邀请很多 Go 方面的大牛做一些分享，我抽选了如下几期作为示例: 一个介绍了Go语言方方面面的Gitbook 除了上面这些，我还找到一些其他相关的学习材料，还没深入读过，先记录于此: 《Go 语言设计与实现》：本书的主要内容可以分成四个主要部分，分别是编译原理、运行时、基础知识和进阶知识 《Go 语言原本》：也有一本有关 Go 实现很深的书 《Go语法树入门》：Go 编译原理的书，详细介绍了Go语言语法树结构 《Go2编程指南》：重点讲解Go2新特性 GitHup 上还有很多类似的收集了很多学习资源的仓库，列在下面供大家学习参考 https://github.com/KeKe-Li/books ","date":"2021-01-01","objectID":"/posts/program/go/go_resources/:2:0","tags":["学习资源"],"title":"go 学习资源","uri":"/posts/program/go/go_resources/"},{"categories":["Go"],"content":"3. Go 标准库和第三方库 想搜索 Go 有那些库，可以访问下面这些链接: go标准库的中文网 pkg.go Go Doc Go语言标准库翻译 Go标准库中文文档 Go 标准库翻译 ","date":"2021-01-01","objectID":"/posts/program/go/go_resources/:3:0","tags":["学习资源"],"title":"go 学习资源","uri":"/posts/program/go/go_resources/"},{"categories":["Go"],"content":"3. Go runtime 码农桃花源 探索golang程序启动过程 golang runtime 源码阅读 ","date":"2021-01-01","objectID":"/posts/program/go/go_resources/:3:1","tags":["学习资源"],"title":"go 学习资源","uri":"/posts/program/go/go_resources/"},{"categories":["Linux"],"content":"Linux profiling - perf","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"这是大神 Brendangregg perf Examples 一文的翻译。ftrace，perf，dtrace，systemtap等等追踪工具依赖的底层技术是类似的，深入了解一个工具，有助于我们学习其他的技术。本人英文能力一般，大家将就着看。 These are some examples of using the perf Linux profiler, which has also been called Performance Counters for Linux (PCL), Linux perf events (LPE), or perf_events. Like Vince Weaver, I’ll call it perf_events so that you can search on that term later. Searching for just “perf” finds sites on the police, petroleum, weed control, and a T-shirt. This is not an official perf page, for either perf_events or the T-shirt. 这些是使用perf Linux分析器的一些示例，它也被称为Linux性能计数器(PCL)、Linux perf事件(LPE)或perf_events。和Vince Weaver一样，我将它命名为perf_events，这样以后就可以搜索这个词了。搜索“perf”可以找到关于警察、石油、除草和t恤的网站。这不是一个官方的表演页面，无论是表演事件还是t恤。 perf_events is an event-oriented observability tool, which can help you solve advanced performance and troubleshooting functions. Questions that can be answered include: Why is the kernel on-CPU so much? What code-paths? Which code-paths are causing CPU level 2 cache misses? Are the CPUs stalled on memory I/O? Which code-paths are allocating memory, and how much? What is triggering TCP retransmits? Is a certain kernel function being called, and how often? What reasons are threads leaving the CPU? perf_events是一个面向事件的可观察性工具，它可以帮助您解决高级性能和故障诊断功能。可以回答的问题包括: 为什么内核占用cpu这么多?代码路径是什么? 哪些代码路径会导致CPU二级缓存丢失? cpu在内存I/O上停止了吗? 哪些代码路径正在分配内存，分配多少? 是什么触发TCP重传? 是否调用某个内核函数，调用频率是多少? 线程离开CPU的原因是什么? perf_events is part of the Linux kernel, under tools/perf. While it uses many Linux tracing features, some are not yet exposed via the perf command, and need to be used via the ftrace interface instead. My perf-tools collection (github) uses both perf_events and ftrace as needed. perf_events是Linux内核的一部分，位于tools/perf之下。虽然它使用了许多Linux跟踪特性，但是有些特性还没有通过perf命令公开，需要通过ftrace接口来使用。我的perf-tools集合(perf-tool)根据需要同时使用perf_events和ftrace。 This page includes my examples of perf_events. A table of contents: Screenshot One-Liners Presentations Background 4.1. Prerequisites 4.2. Symbols 4.3. JIT Symbols (Java, Node.js) 4.4. Stack Traces 4.5. Audience 4.6. Usage 4.7. Usage Examples 4.8. Special Usage Events 5.1. Software Events 5.2. Hardware Events (PMCs) 5.3. Kernel Tracepoints 5.4. USDT 5.5. Dynamic Tracing Examples 6.1. CPU Statistics 6.2. Timed Profiling 6.3. Event Profiling 6.4. Static Kernel Tracing 6.5. Static User Tracing 6.6. Dynamic Tracing 6.7. Scheduler Analysis 6.8. eBPF Visualizations 7.1. Flame Graphs 7.2. Heat Maps Targets More Building Troubleshooting Other Tools Resources Key sections to start with are: Events, One-Liners, Presentations, Prerequisites, CPU statistics, Timed Profiling, and Flame Graphs. Also see my Posts about perf_events, and Links for the main (official) perf_events page, awesome tutorial, and other links. The next sections introduce perf_events further, starting with a screenshot, one-liners, and then background. 上面是博客的大纲和写作顺序的一个简介。 This page is under construction, and there’s a lot more to perf_events that I’d like to add. Hopefully this is useful so far. 这个页面还在构建中，我还想添加更多的perf_events，希望到目前为止这是有用的。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:0:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"1. Screenshot(总览) Starting with a screenshot, here’s perf version 3.9.3 tracing disk I/O: 下面是perf 3.9.3 版本跟踪磁盘I/O的一个示例: \u003e perf record -e block:block_rq_issue -ag \u003e ls -l perf.data -rw------- 1 root root 3458162 Jan 26 03:03 perf.data perf report [...] # Samples: 2K of event 'block:block_rq_issue' # Event count (approx.): 2216 # # Overhead Command Shared Object Symbol # ........ ............ ................. .................... # 32.13% dd [kernel.kallsyms] [k] blk_peek_request | --- blk_peek_request virtblk_request __blk_run_queue | |--98.31%-- queue_unplugged | blk_flush_plug_list | | | |--91.00%-- blk_queue_bio | | generic_make_request | | submit_bio | | ext4_io_submit | | | | | |--58.71%-- ext4_bio_write_page | | | mpage_da_submit_io | | | mpage_da_map_and_submit | | | write_cache_pages_da | | | ext4_da_writepages | | | do_writepages | | | __filemap_fdatawrite_range | | | filemap_flush | | | ext4_alloc_da_blocks | | | ext4_release_file | | | __fput | | | ____fput | | | task_work_run | | | do_notify_resume | | | int_signal | | | close | | | 0x0 | | | | | --41.29%-- mpage_da_submit_io [...] A perf record command was used to trace the block:block_rq_issue probe, which fires when a block device I/O request is issued (disk I/O). Options included -a to trace all CPUs, and -g to capture call graphs (stack traces). Trace data is written to a perf.data file, and tracing ended when Ctrl-C was hit. A summary of the perf.data file was printed using perf report, which builds a tree from the stack traces, coalescing common paths, and showing percentages for each path. 上面的 perf record 命令用于跟踪 block:block_rq_issue 探针，它在块设备I/O请求发出时触发(磁盘I/O)。选项 -a 用于跟踪所有cpu， -g用于捕获调用图(堆栈跟踪)。跟踪数据被写入perf.data 文件。当按Ctrl-C时，数据文件和跟踪结束。使用 perf report 命令可以打印 perf.data 内的追踪信息，perf record 从堆栈跟踪构建一个树，合并公共路径，并显示每个路径的百分比。 The perf report output shows that 2,216 events were traced (disk I/O), 32% of which from a dd command. These were issued by the kernel function blk_peek_request(), and walking down the stacks, about half of these 32% were from the close() system call. perf report 输出显示跟踪了2,216个事件(磁盘I/O)，其中32%来自dd命令。这些是由内核函数blk_peek_request()发出的，在堆栈中查找，其中大约一半来自 close() 系统调用。 Note that I use the “#” prompt to signify that these commands were run as root, and I’ll use “$” for user commands. Use sudo as needed. 注意，我使用“#”提示符来表示这些命令是以根用户身份运行的，对于用户命令，我将使用“$”。根据需要使用sudo。说明: 我改成了 “\u003e” 不然命令会跟 perf 的输出混淆。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:1:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"2. One-Liners(常用命令) Some useful one-liners I’ve gathered or written. Terminology I’m using, from lowest to highest overhead: statistics/count: increment an integer counter on events sample: collect details (eg, instruction pointer or stack) from a subset of events (once every …) trace: collect details from every event 我收集并编写了一些有用的一行程序。并使用了如下的术语进行说明 statistics/count: 对事件增加一个整数计数器 sample: 从事件子集收集细节(例如，指令指针或堆栈)(每…一次) trace: 收集每个事件的细节 Listing Events(列出所有事件) # Listing all currently known events: # 列出所有事件 perf list # Listing sched tracepoints: # 列出 sched 静态探针 perf list 'sched:*' Counting Events(事件计数) # CPU counter statistics for the specified command: # 为特定命令进行 CPU 计数 perf stat command # Detailed CPU counter statistics (includes extras) for the specified command: # 为特定命令进行详细的 CPU 计数 perf stat -d command # CPU counter statistics for the specified PID, until Ctrl-C: # 为指定的 PID 进程进行 CPU 计数 perf stat -p PID # CPU counter statistics for the entire system, for 5 seconds: # 整个系统的CPU计数器统计信息，持续5秒 perf stat -a sleep 5 # Various basic CPU statistics, system wide, for 10 seconds: # 指定范围，进行整个系统的 CPU 计数 perf stat -e cycles,instructions,cache-references,cache-misses,bus-cycles -a sleep 10 # Various CPU level 1 data cache statistics for the specified command: # 一级缓存统计 perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores command # Various CPU data TLB statistics for the specified command: # TLB 统计 perf stat -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses command # Various CPU last level cache statistics for the specified command: # 最后一级缓存统计 perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches command # Using raw PMC counters, eg, counting unhalted core cycles: # PMC 计数器 perf stat -e r003c -a sleep 5 # PMCs: counting cycles and frontend stalls via raw specification: perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5 # Count syscalls per-second system-wide: # 系统级每秒系统调用计数: perf stat -e raw_syscalls:sys_enter -I 1000 -a # Count system calls by type for the specified PID, until Ctrl-C: # 指定 PID 统计每秒系统调用计数: perf stat -e 'syscalls:sys_enter_*' -p PID # Count system calls by type for the entire system, for 5 seconds: # 按整个系统的类型计数系统调用，持续5秒: perf stat -e 'syscalls:sys_enter_*' -a sleep 5 # Count scheduler events for the specified PID, until Ctrl-C: # 计算指定PID的调度程序事件 perf stat -e 'sched:*' -p PID # Count scheduler events for the specified PID, for 10 seconds: # 计算指定PID的调度程序事件，持续 10s perf stat -e 'sched:*' -p PID sleep 10 # Count ext4 events for the entire system, for 10 seconds: # 计算整个系统的ext4事件 perf stat -e 'ext4:*' -a sleep 10 # Count block device I/O events for the entire system, for 10 seconds: # 计算整个系统的块设备I/O事件 perf stat -e 'block:*' -a sleep 10 # Count all vmscan events, printing a report every second: # 计算所有vmscan事件，每秒打印一个报告 perf stat -e 'vmscan:*' -a -I 1000 Profiling(剖析) # Sample on-CPU functions for the specified command, at 99 Hertz: perf record -F 99 command # Sample on-CPU functions for the specified PID, at 99 Hertz, until Ctrl-C: perf record -F 99 -p PID # Sample on-CPU functions for the specified PID, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID sleep 10 # Sample CPU stack traces (via frame pointers) for the specified PID, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID -g -- sleep 10 # Sample CPU stack traces for the PID, using dwarf (dbg info) to unwind stacks, at 99 Hertz, for 10 seconds: perf record -F 99 -p PID --call-graph dwarf sleep 10 # Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (\u003c Linux 4.11): perf record -F 99 -ag -- sleep 10 # Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (\u003e= Linux 4.11): perf record -F 99 -g -- sleep 10 # If the previous command didn't work, try forcing perf to use the cpu-clock event: perf record -F 99 -e cpu-clock -ag -- sleep 10 # Sample CPU stack traces for a container identified by its /sys/fs/cgroup/perf_event cgroup: # 一个由其/sys/fs/cgroup/perf_event cgroup标识的容器的示例CPU堆栈跟踪: perf reco","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:2:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"3. Presentations Kernel Recipes (2017) At Kernel Recipes 2017 I gave an updated talk on Linux perf at Netflix, focusing on getting CPU profiling and flame graphs to work. This talk includes a crash course on perf_events, plus gotchas such as fixing stack traces and symbols when profiling Java, Node.js, VMs, and containers. A video of the talk is on youtube and the slides are on slideshare: There’s also an older version of this talk from 2015, which I’ve posted about. brendangregg 就 Linux perf 发表过两次演讲，下面是视频的链接: 2017 2015 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:3:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4. Background The following sections provide some background for understanding perf_events and how to use it. I’ll describe the prerequisites, audience, usage, events, and tracepoints. 下面几节提供了一些背景知识，帮助您理解perf_events以及如何使用它。内容包括: prerequisites 先决条件 audience 受众 usage 用法 events 事件 tracepoints 跟踪点 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.1. Prerequisites 先决条件 The perf tool is in the linux-tools-common package. Start by adding that, then running “perf” to see if you get the USAGE message. It may tell you to install another related package (linux-tools-kernelversion). perf工具位于linux-tools-common包中。安装 linux-tools-common ，然后运行“perf”，提示信息可能会告诉您需要安装另一个相关的包(linux-tools-kernelversion)。 You can also build and add perf from the Linux kernel source. See the Building section. 您还可以从Linux内核源代码构建和添加perf。 To get the most out perf, you’ll want symbols and stack traces. These may work by default in your Linux distribution, or they may require the addition of packages, or recompilation of the kernel with additional config options. 为了获得最大的性能，您需要符号和堆栈跟踪。这些可能在Linux发行版中默认工作，或者可能需要额外的包，或者使用其他配置选项重新编译内核。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.2. Symbols 符号表 perf_events, like other debug tools, needs symbol information (symbols). These are used to translate memory addresses into function and variable names, so that they can be read by us humans. Without symbols, you’ll see hexadecimal numbers representing the memory addresses profiled. 与其他调试工具一样，perf_events需要符号信息(符号)。它们被用来将内存地址转换成函数和变量名，以便我们人类能够读取它们。如果没有符号，您将看到十六进制数字表示所分析的内存地址。 The following perf report output shows stack traces, however, only hexadecimal numbers can be seen: 下面的perf报告输出显示了堆栈跟踪，但是，只能看到十六进制数: 57.14% sshd libc-2.15.so [.] connect | --- connect | |--25.00%-- 0x7ff3c1cddf29 | |--25.00%-- 0x7ff3bfe82761 | 0x7ff3bfe82b7c | |--25.00%-- 0x7ff3bfe82dfc --25.00%-- [...] If the software was added by packages, you may find debug packages (often “-dbgsym”) which provide the symbols. Sometimes perf report will tell you to install these, eg: “no symbols found in /bin/dd, maybe install a debug package?”. 如果软件是通过包添加的，您可能会发现提供这些符号的调试包(通常是“-dbgsym”)。有时perf 会提示去安装这些调试包。 Here’s the same perf report output seen earlier, after adding openssh-server-dbgsym and libc6-dbgsym (this is on ubuntu 12.04): 下面是添加了 openssh-server-dbgsym和libc6-dbgsym(这是在ubuntu 12.04上)之后，看到的 perf 报告输出: 57.14% sshd libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--25.00%-- add_one_listen_addr.isra.0 | |--25.00%-- __nscd_get_mapping | __nscd_get_map_ref | |--25.00%-- __nscd_open_socket --25.00%-- [...] I find it useful to add both libc6-dbgsym and coreutils-dbgsym, to provide some symbol coverage of user-level OS codepaths. 我发现同时添加libc6-dbgsym和coreutils-dbgsym很有用，可以提供用户级 OS 代码页的一些符号表。 Another way to get symbols is to compile the software yourself. For example, I just compiled node (Node.js): 另一种获取符号的方法是自己编译软件。例如，编译 node (node.js): # file node-v0.10.28/out/Release/node node-v0.10.28/out/Release/node: ELF 64-bit LSB executable, ... not stripped This has not been stripped, so I can profile node and see more than just hex. If the result is stripped, configure your build system not to run strip(1) on the output binaries. Kernel-level symbols are in the kernel debuginfo package, or when the kernel is compiled with CONFIG_KALLSYMS. 内核级符号位于内核debuginfo包中，或者在内核编译时启用 CONFIG_KALLSYMS 选项 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.3. JIT Symbols (Java, Node.js) JIT 符号表 Programs that have virtual machines (VMs), like Java’s JVM and node’s v8, execute their own virtual processor, which has its own way of executing functions and managing stacks. If you profile these using perf_events, you’ll see symbols for the VM engine, which have some use (eg, to identify if time is spent in GC), but you won’t see the language-level context you might be expecting. Eg, you won’t see Java classes and methods. 拥有虚拟机(VMs)的程序(如Java的JVM和node的v8)执行它们自己的虚拟处理器，它有自己执行函数和管理堆栈的方式。如果使用perf_events对它们进行分析，只能看到 VM 引擎的符号，这些符号有一些用途(例如，用于确定是否在GC中花费了时间)，但通常不是期望的语言级上下文。不可能不会看到Java类和方法。 perf_events has JIT support to solve this, which requires the VM to maintain a /tmp/perf-PID.map file for symbol translation. Java can do this with perf-map-agent, and Node.js 0.11.13+ with –perf_basic_prof. See my blog post Node.js flame graphs on Linux for the steps. perf_events支持JIT来解决这个问题，这需要VM维护一个 /tmp/perf-PID.map 的符号表转义文件。Java可以使用perf-map-agent实现这一点，而Node.js 0.11.13+可以使用–perf_basic_prof 。请参阅我的博客文章Node.js火焰图在Linux上的步骤。 Note that Java may not show full stacks to begin with, due to hotspot on x86 omitting the frame pointer (just like gcc). On newer versions (JDK 8u60+), you can use the -XX:+PreserveFramePointer option to fix this behavior, and profile fully using perf. See my Netflix Tech Blog post, Java in Flames, for a full writeup, and my Java flame graphs section, which links to an older patch and includes an example resulting flame graph. I also summarized the latest in my JavaOne 2016 talk Java Performance Analysis on Linux with Flame Graphs. 注意，由于hotspot在x86上省略了帧指针(就像gcc一样)，Java可能一开始就没有显示完整的堆栈。在较新的版本(JDK 8u60+)上，您可以使用-XX:+PreserveFramePointer选项来修复此行为，并使用perf完全配置文件。请参阅我的Netflix技术博客文章，Java in flame，以获得完整的描述，以及我的Java火焰图部分，其中链接到一个较老的补丁，并包括一个生成火焰图的示例。我还在我的演讲中总结了最新的用法 Java Performance Analysis on Linux with Flame Graphs. ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:3","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.4 Stack Traces 堆栈追踪 Always compile with frame pointers. Omitting frame pointers is an evil compiler optimization that breaks debuggers, and sadly, is often the default. Without them, you may see incomplete stacks from perf_events, like seen in the earlier sshd symbols example. There are three ways to fix this: either using dwarf data to unwind the stack, using last branch record (LBR) if available (a processor feature), or returning the frame pointers. 总是使用框架指针进行编译。省略帧指针是一种糟糕的编译器优化，它会破坏调试器，不幸的是，它通常是默认的。如果没有它们，您可能会从perf_events中看到不完整的堆栈，就像前面的sshd符号示例中看到的那样。有三种方法可以解决这个问题:要么使用dwarf数据展开堆栈，要么使用可用的最后一个分支记录(LBR)(如果处理器特性支持)，要么返回帧指针。 There are other stack walking techniques, like BTS (Branch Trace Store), and the new ORC unwinder. I’ll add docs for them at some point (and as perf support arrives). 还有其他堆栈遍历技术，比如BTS(分支跟踪存储)和新的ORC解卷器。我将在某个时候为它们添加文档。 Frame Pointers 帧指针 The earlier sshd example was a default build of OpenSSH, which uses compiler optimizations (-O2), which in this case has omitted the frame pointer. Here’s how it looks after recompiling OpenSSH with -fno-omit-frame-pointer: 早期的sshd示例是OpenSSH的默认构建，它使用编译器优化(-O2)，省略了帧指针。下面是用-fno-omit-frame-pointer(省略帧指针)重新编译OpenSSH后，进行剖析的结果: 100.00% sshd libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--30.00%-- add_one_listen_addr.isra.0 | add_listen_addr | fill_default_server_options | main | __libc_start_main | |--20.00%-- __nscd_get_mapping | __nscd_get_map_ref | |--20.00%-- __nscd_open_socket --30.00%-- [...] Now the ancestry from add_one_listen_addr() can be seen, down to main() and __libc_start_main(). 现在可以看到来自 add_one_listen_addr() 的祖先，一直到main()和libc_start_main()。意思是省略帧指针后，堆栈信息显示不完整 The kernel can suffer the same problem. Here’s an example CPU profile collected on an idle server, with stack traces (-g): 内核也有类似省略帧指针的问题。下面是一个在空闲服务器上收集的带有堆栈跟踪(-g)的 CPU 剖析信息: 99.97% swapper [kernel.kallsyms] [k] default_idle | --- default_idle 0.03% sshd [kernel.kallsyms] [k] iowrite16 | --- iowrite16 __write_nocancel (nil) The kernel stack traces are incomplete. Now a similar profile with CONFIG_FRAME_POINTER=y: 内核堆栈跟踪是不完整的。下面是启用 CONFIG_FRAME_POINTER=y 编译选项后类似的剖析结果: 99.97% swapper [kernel.kallsyms] [k] default_idle | --- default_idle cpu_idle | |--87.50%-- start_secondary | --12.50%-- rest_init start_kernel x86_64_start_reservations x86_64_start_kernel 0.03% sshd [kernel.kallsyms] [k] iowrite16 | --- iowrite16 vp_notify virtqueue_kick start_xmit dev_hard_start_xmit sch_direct_xmit dev_queue_xmit ip_finish_output ip_output ip_local_out ip_queue_xmit tcp_transmit_skb tcp_write_xmit __tcp_push_pending_frames tcp_sendmsg inet_sendmsg sock_aio_write do_sync_write vfs_write sys_write system_call_fastpath __write_nocancel Much better – the entire path from the write() syscall (__write_nocancel) to iowrite16() can be seen. 效果好很多，可以看到 write() 系统调用的完整信息。 Dwarf Since about the 3.9 kernel, perf_events has supported a workaround for missing frame pointers in user-level stacks: libunwind, which uses dwarf. This can be enabled using “–call-graph dwarf” (or “-g dwarf”). 从3.9内核开始，perf_events就支持用户级栈中缺少帧指针的解决方案:libunwind，叫做 dwarf。可以使用\"–call-graph dwarf\"(或“-g dwarf”)启用此功能。 Also see the Building section for other notes about building perf_events, as without the right library, it may build itself without dwarf support. perf 可以在没有 dwarf 支持的情况下构建。因此是否支持 dwarf 要查阅安装信息。 LBR You must have Last Branch Record access to be able to use this. It is disabled in most cloud environments, where you’ll get this error: 您必须拥有最后一个分支记录访问权才能使用它。它在大多数云环境中是禁用的，你会得到这个错误: \u003e perf record -F 99 -a --call-graph lbr Error: PMU Hardware doesn't support sampling/overflow-interrupts. Here’s an example of it working: 下面是它能工作的一个例子: \u003e perf record -F 99 -a --call-graph lbr ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.903 MB perf.data (163 samples) ] \u003e perf script [...] stackcollapse-p 23867 [007] 4762187.971824: 29003297 cycles:ppp: 1430c0 Perl_re_intuit_start (/usr/bin/perl) 144118 Perl_regexec_f","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:4","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.5. Audience To use perf_events, you’ll either: Develop your own commands Run example commands Developing new invocations of perf_events requires the study of kernel and application code, which isn’t for everyone. Many more people will use perf_events by running commands developed by other people, like the examples on this page. This can work out fine: your organization may only need one or two people who can develop perf_events commands or source them, and then share them for use by the entire operation and support groups. 开发新的perf_events调用需要研究内核和应用程序代码，这并不适合所有人。更多的人将通过运行其他人开发的命令来使用perf_events，就像本文中的示例一样。这可以很好地解决问题:您的组织可能只需要一到两个人，他们可以开发perf_events命令或获取它们的源代码，然后共享它们供整个操作和支持组使用。 Either way, you need to know the capabilities of perf_events so you know when to reach for it, whether that means searching for an example command or writing your own. One goal of the examples that follow is just to show you what can be done, to help you learn these capabilities. You should also browse examples on other sites (Links). 无论使用哪种方法，您都需要了解perf_events的功能，这样才能有效的搜索。下面的示例的一个目标就是向您展示可以做什么，以帮助您学习这些功能。您还应该在其他站点(链接)上浏览示例。 If you’ve never used perf_events before, you may want to test before production use (it has had kernel panic bugs in the past). My experience has been a good one (no panics). 如果您以前从未使用过perf_events，那么您可能希望在生产环境使用之前进行测试(它以前出现过内核故障)。我的经历很好(不用恐慌)。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:5","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.6. Usage perf_events provides a command line tool, perf, and subcommands for various profiling activities. This is a single interface for the different instrumentation frameworks that provide the various events. perf_events为各种分析活动提供了 perf 密令。这是用于提供各种事件的不同工具框架的单个接口。 The perf command alone will list the subcommands; here is perf version 4.10 (for the Linux 4.10 kernel): 不带参数的 perf 命令将会列出所有子命令;下面是perf 4.10版本的输出(适用于Linux 4.10内核): # perf usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS] The most commonly used perf commands are: annotate Read perf.data (created by perf record) and display annotated code archive Create archive with object files with build-ids found in perf.data file bench General framework for benchmark suites buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file config Get and set variables in a configuration file. data Data file related processing diff Read perf.data files and display the differential profile evlist List the event names in a perf.data file inject Filter to augment the events stream with additional information kmem Tool to trace/measure kernel memory properties kvm Tool to trace/measure kvm guest os list List all symbolic event types lock Analyze lock events mem Profile memory accesses record Run a command and record its profile into perf.data report Read perf.data (created by perf record) and display the profile sched Tool to trace/measure scheduler properties (latencies) script Read perf.data (created by perf record) and display trace output stat Run a command and gather performance counter statistics test Runs sanity tests. timechart Tool to visualize total system behavior during a workload top System profiling tool. probe Define new dynamic tracepoints trace strace inspired tool See 'perf help COMMAND' for more information on a specific command. Apart from separate help for each subcommand, there is also documentation in the kernel source under tools/perf/Documentation. perf has evolved, with different functionality added over time, so on an older kernel you may be missing some subcommands or functionality. Also, its usage may not feel consistent as you switch between activities. It’s best to think of it as a multi-tool. 除了每个子命令的单独帮助之外，在工具/perf/Documentation下的内核源代码中也有文档。perf不断发展，随着时间的推移添加了不同的功能，因此在较老的内核中，您可能会丢失一些子命令或功能。而且，当您在活动之间切换时，它的用法可能感觉不一致。最好将其视为一个多工具。 perf_events can instrument in three ways (now using the perf_events terminology): counting events in-kernel context, where a summary of counts is printed by perf. This mode does not generate a perf.data file. sampling events, which writes event data to a kernel buffer, which is read at a gentle asynchronous rate by the perf command to write to the perf.data file. This file is then read by the perf report or perf script commands. bpf programs on events, a new feature in Linux 4.4+ kernels that can execute custom user-defined programs in kernel space, which can perform efficient filters and summaries of the data. Eg, efficiently-measured latency histograms. perf_events有三种使用方式(现在使用perf_events术语): 计数模式: 对应 perf stat 命令，其在内核上下文中计数事件，其中计数的摘要由perf打印。此模式不生成perf.data文件 采样事件：将事件数据写入内核缓冲区，由perf 以缓慢的异步速率读取内核缓冲区，以便写入到perf.data 文件。然后，perf report 或perf script 命令读取此文件。 事件上的bpf程序，这是Linux 4.4+内核中的一个新特性，它可以在内核空间中执行自定义用户定义的程序，可以执行高效的数据筛选和总结。 Try starting by counting events using the perf stat command, to see if this is sufficient. This subcommand costs the least overhead. 尝试从使用perf stat命令计算事件开始，看看这是否足够。这个子命令开销最小。 When using the sampling mode with perf record, you’ll need to be a little careful about the overheads, as the capture files can quickly become hundreds of Mbytes. It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size. 在使用perf记录的采样模式时，您需要注意开销，因为捕获文件可能很快就会变成数百兆字节。这取决于您正在跟踪的事件的频率:频率越高，开销越大，性能越大，数据越多 To really cut down overhead and generate more advanced summaries, write BPF programs executed by perf. See the eBPF section. 要真正减少开销并生成更高级的摘要，可以编","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:6","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.7. Usage Examples These example sequences have been chosen to illustrate some different ways that perf is used, from gathering to reporting. 选择这些示例序列是为了说明使用perf的一些不同方式，从收集到报告。 Performance counter summaries, including IPC, for the gzip command: gzip命令的性能计数器总结，包括IPC: # perf stat gzip largefile Count all scheduler process events for 5 seconds, and count by tracepoint: 按照静态探针对进程调度事件进行计数，持续 5s # perf stat -e 'sched:sched_process_*' -a sleep 5 Trace all scheduler process events for 5 seconds, and count by both tracepoint and process name: 按照静态探针跟踪进程调度事件，持续 5s # perf record -e 'sched:sched_process_*' -a sleep 5 # perf report Trace all scheduler process events for 5 seconds, and dump per-event details: 按照静态探针跟踪进程调度事件，持续 5s，并转储事件信息信息 # perf record -e 'sched:sched_process_*' -a sleep 5 # perf script Trace read() syscalls, when requested bytes is less than 10: 跟踪请求的字节小于10 的 read() 系统调用 # perf record -e 'syscalls:sys_enter_read' --filter 'count \u003c 10' -a Sample CPU stacks at 99 Hertz, for 5 seconds: 以 99hz 的频率抽样CPU堆栈 # perf record -F 99 -ag -- sleep 5 # perf report Dynamically instrument the kernel tcp_sendmsg() function, and trace it for 5 seconds, with stack traces: 添加 tcp_sendmsg 动态探针，追踪 5s，并记录堆栈 # perf probe --add tcp_sendmsg # perf record -e probe:tcp_sendmsg -ag -- sleep 5 # perf probe --del tcp_sendmsg # perf report Deleting the tracepoint (–del) wasn’t necessary; I included it to show how to return the system to its original state. 没有必要删除跟踪点(–del);我包含它是为了说明如何将系统返回到其原始状态。 Caveats The use of -p PID as a filter doesn’t work properly on some older kernel versions (Linux 3.x): perf hits 100% CPU and needs to be killed. It’s annoying. The workaround is to profile all CPUs (-a), and filter PIDs later. 警告使用-p PID作为过滤器在一些较老的内核版本(Linux 3.x)上不能正常工作。解决方法是配置所有cpu (-a)，然后 filter 选项过滤出所需的 PID 信息。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:7","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"4.8. Special Usage There’s a number of subcommands that provide special purpose functionality. These include: perf c2c (Linux 4.10+): cache-2-cache and cacheline false sharing analysis. perf kmem: kernel memory allocation analysis. perf kvm: KVM virtual guest analysis. perf lock: lock analysis. perf mem: memory access analysis. perf sched: kernel scheduler statistics. Examples. These make use of perf’s existing instrumentation capabilities, recording selected events and reporting them in custom ways. 有许多子命令提供特殊用途的功能。这些包括: perf c2c (Linux 4.10+): cache-2-cache and cacheline false 共享分析 perf kmem: 内核内存分配分析。 perf kvm：KVM虚拟客户端分析。 perf lock: 锁分析 perf mem: 内存访问分析。 perf sched: 内核调度器的统计数据。示例 它们利用perf现有的检测功能，记录选定的事件并以定制的方式报告它们。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:4:8","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5. Events perf_events instruments “events”, which are a unified interface for different kernel instrumentation frameworks. The following map (from my SCaLE13x talk) illustrates the event sources: perf_events工具“事件”，它是不同内核工具框架的统一接口。下面的地图(来自我的SCaLE13x演讲)说明了事件来源: The types of events are: Hardware Events: CPU performance monitoring counters. Software Events: These are low level events based on kernel counters. For example, CPU migrations, minor faults, major faults, etc. Kernel Tracepoint Events: This are static kernel-level instrumentation points that are hardcoded in interesting and logical places in the kernel. User Statically-Defined Tracing (USDT): These are static tracepoints for user-level programs and applications. Dynamic Tracing: Software can be dynamically instrumented, creating events in any location. For kernel software, this uses the kprobes framework. For user-level software, uprobes. Timed Profiling: Snapshots can be collected at an arbitrary frequency, using perf record -FHz. This is commonly used for CPU usage profiling, and works by creating custom timed interrupt events. event 有如下类型: Hardware Events: CPU性能监视计数器 Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点， User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 使用perf -FHz 选项以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 Details about the events can be collected, including timestamps, the code path that led to it, and other specific details. The capabilities of perf_events are enormous, and you’re likely to only ever use a fraction. 可以收集事件的详细信息，包括时间戳、导致事件的代码路径和其他特定细节。perf_events的功能非常强大，您可能只会使用一小部分。 Currently available events can be listed using the list subcommand: 可以使用list子命令列出当前可用的事件: # perf list List of pre-defined events (to be used in -e): cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] cpu-clock [Software event] task-clock [Software event] page-faults OR faults [Software event] context-switches OR cs [Software event] cpu-migrations OR migrations [Software event] minor-faults [Software event] major-faults [Software event] alignment-faults [Software event] emulation-faults [Software event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event] [...] rNNN [Raw hardware event descriptor] cpu/t1=v1[,t2=v2,t3 ...]/modifier [Raw hardware event descriptor] (see 'man perf-list' on how to encode it) mem:\u003caddr\u003e[:access] [Hardware breakpoint] probe:tcp_sendmsg [Tracepoint event] [...] sched:sched_process_exec [Tracepoint event] sched:sched_process_fork [Tracepoint event] sched:sched_process_wait [Tracepoint event] sched:sched_wait_task [Tracepoint event] sched:sched_process_exit [Tracepoint event] [...] # perf list | wc -l 657 When you use dynamic tracing, you are extending this list. The probe:tcp_sendmsg tracepoint in this list is an example, which I added by instrumenting tcp_sendmsg(). Profiling (sampling) events are not listed. 当您使用动态跟踪时，您是在扩展这个列表。这个列表中的 probe:tcp_sendmsg 探针就是我动态插入 tcp_sendmsg() 的例子。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5.1. Software Events There is a small number of fixed software events provided by perf: perf提供了少量固定的软件事件: # perf list List of pre-defined events (to be used in -e): alignment-faults [Software event] bpf-output [Software event] context-switches OR cs [Software event] cpu-clock [Software event] cpu-migrations OR migrations [Software event] dummy [Software event] emulation-faults [Software event] major-faults [Software event] minor-faults [Software event] page-faults OR faults [Software event] task-clock [Software event] [...] These are also documented in the man page perf_event_open(2): 这些也记录在手册页perf_event_open(2): [...] PERF_COUNT_SW_CPU_CLOCK This reports the CPU clock, a high-resolution per- CPU timer. PERF_COUNT_SW_TASK_CLOCK This reports a clock count specific to the task that is running. PERF_COUNT_SW_PAGE_FAULTS This reports the number of page faults. PERF_COUNT_SW_CONTEXT_SWITCHES This counts context switches. Until Linux 2.6.34, these were all reported as user-space events, after that they are reported as happening in the kernel. PERF_COUNT_SW_CPU_MIGRATIONS This reports the number of times the process has migrated to a new CPU. PERF_COUNT_SW_PAGE_FAULTS_MIN This counts the number of minor page faults. These did not require disk I/O to handle. [...] The kernel also supports traecpoints, which are very similar to software events, but have a different more extensible API. 内核也支持traecpoints，它与软件事件非常相似，但具有不同的更具可扩展性的API。 Software events may have a default period. This means that when you use them for sampling, you’re sampling a subset of events, not tracing every event. You can check with perf record -vv: 软件事件可能有一个默认的周期。这意味着当您使用它们进行抽样时，您是在对事件的子集进行抽样，而不是跟踪每个事件。你可以通过 perf record -vv 查看: # perf record -vv -e context-switches /bin/true Using CPUID GenuineIntel-6-55 ------------------------------------------------------------ perf_event_attr: type 1 size 112 config 0x3 { sample_period, sample_freq } 4000 sample_type IP|TID|TIME|PERIOD disabled 1 inherit 1 mmap 1 comm 1 freq 1 enable_on_exec 1 [...] See the perf_event_open(2) man page for a description of these fields. This default means is that the kernel adjusts the rate of sampling so that it’s capturing about 4,000 context switch events per second. If you really meant to record them all, use -c 1: 有关这些字段的描述，请参见perf_event_open(2)手册页。这个默认的意思是内核调整采样率，以便它每秒捕获大约4000个上下文切换事件。如果你真的想把它们全部记录下来，请使用-c1: # perf record -vv -e context-switches -c 1 /bin/true Using CPUID GenuineIntel-6-55 ------------------------------------------------------------ perf_event_attr: type 1 size 112 config 0x3 { sample_period, sample_freq } 1 sample_type IP|TID|TIME disabled 1 inherit 1 mmap 1 comm 1 enable_on_exec 1 Check the rate of events using perf stat first, so that you can estimate the volume of data you’ll be capturing. Sampling a subset by default may be a good thing, especially for high frequency events like context switches. 首先使用perf stat检查事件的速率，这样您就可以估计将要捕获的数据量。在默认情况下对子集进行采样可能是一件好事，特别是对于上下文切换这样的高频率事件。 Many other events (like tracepoints) have a default of 1 anyway. You’ll encounter a non-1 default for many software and hardware events. 许多其他事件(比如跟踪点)的默认值都是1。对于许多软件和硬件事件，您将遇到非1的缺省值。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5.2. Hardware Events (PMCs) perf_events began life as a tool for instrumenting the processor’s performance monitoring unit (PMU) hardware counters, also called performance monitoring counters (PMCs), or performance instrumentation counters (PICs). These instrument low-level processor activity, for example, CPU cycles, instructions retired, memory stall cycles, level 2 cache misses, etc. Some will be listed as Hardware Cache Events. perf_events最初作为一种工具用于检测处理器的性能监视单元 PMU，PMU 被称为硬件计数器，也叫做性能监视计数器(pmmc)或性能仪表计数器(PICs)。它监测低层次的处理器活动，例如，CPU周期，指令退役，内存失速周期，二级缓存丢失，等等。其中一些将作为硬件缓存事件列出。 PMCs are documented in the Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 3B: System Programming Guide, Part 2 and the BIOS and Kernel Developer’s Guide (BKDG) For AMD Family 10h Processors. There are thousands of different PMCs available. pmc在Intel 64和IA-32架构软件开发人员手册卷3B:系统编程指南，第2部分和AMD家族10h处理器的BIOS和内核开发人员指南(BKDG)中有文档记录。有数千种不同的pmc可用。 A typical processor will implement PMCs in the following way: only a few or several can be recorded at the same time, from the many thousands that are available. This is because they are a fixed hardware resource on the processor (a limited number of registers), and are programmed to begin counting the selected events. 典型的处理器将以以下方式实现pmc:在可用的数千个pmc中，只能同时记录几个pmc。这是因为它们是处理器上的固定硬件资源(寄存器的有限数量)，并且被编程为开始计算所选事件。 For examples of using PMCs, see CPU Statistics. 有关使用pmc的示例，请参见CPU统计信息。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5.3. Kernel Tracepoints These tracepoints are hard coded in interesting and logical locations of the kernel, so that higher-level behavior can be easily traced. For example, system calls, TCP events, file system I/O, disk I/O, etc. These are grouped into libraries of tracepoints; eg, “sock:” for socket events, “sched:” for CPU scheduler events. A key value of tracepoints is that they should have a stable API, so if you write tools that use them on one kernel version, they should work on later versions as well. 这些跟踪点被硬编码在内核的有用的位置上，以便更高层次的行为可以很容易地被跟踪。例如，系统调用、TCP事件、文件系统I/O、磁盘I/O等等。它们被分组到跟踪点库中;例如，“sock:”表示套接字事件，“sched:”表示CPU调度器事件。跟踪点的一个关键价值是它们应该有一个稳定的API，因此如果您编写的工具在一个内核版本上使用它们，那么它们也应该适用于以后的版本。 Tracepoints are usually added to kernel code by placing a macro from include/trace/events/. XXX cover implementation. 跟踪点通常通过放置在 include/trace/events/.XXX 中的宏添加到内核代码中来实现。 Summarizing the tracepoint library names and numbers of tracepoints, on my Linux 4.10 system: 下面是 Linux4.10 系统上对 tracepoint 库和数量的统计。 \u003e perf list | awk -F: '/Tracepoint event/ { lib[$1]++ } END { for (l in lib) { printf \" %-16.16s %d\\n\", l, lib[l] } }' | sort | column alarmtimer 4 i2c 8 page_isolation 1 swiotlb 1 block 19 iommu 7 pagemap 2 syscalls 614 btrfs 51 irq 5 power 22 task 2 cgroup 9 irq_vectors 22 printk 1 thermal 7 clk 14 jbd2 16 random 15 thermal_power_ 2 cma 2 kmem 12 ras 4 timer 13 compaction 14 libata 6 raw_syscalls 2 tlb 1 cpuhp 3 mce 1 rcu 1 udp 1 dma_fence 8 mdio 1 regmap 15 vmscan 15 exceptions 2 migrate 2 regulator 7 vsyscall 1 ext4 95 mmc 2 rpm 4 workqueue 4 fib 3 module 5 sched 24 writeback 30 fib6 1 mpx 5 scsi 5 x86_fpu 14 filelock 10 msr 3 sdt_node 1 xen 35 filemap 2 napi 1 signal 2 xfs 495 ftrace 1 net 10 skb 3 xhci-hcd 9 gpio 2 nmi 1 sock 2 huge_memory 4 oom 1 spi 7 These include: block: block device I/O ext4: file system operations kmem: kernel memory allocation events random: kernel random number generator events sched: CPU scheduler events syscalls: system call enter and exits task: task events 这些包括: block: 块设备I/O ext4: 文件系统操作 kmem: 内核内存分配事件 random: 内核随机数生成器事件 sched: CPU调度器事件 random: 系统调用的进入和返回 task: 任务事件 It’s worth checking the list of tracepoints after every kernel upgrade, to see if any are new. The value of adding them has been debated from time to time, with it wondered how many people will use them (I do). There is a balance to aim for: I’d include the smallest number of probes that sufficiently covers common needs, and anything unusual or uncommon can be left to dynamic tracing. 在每次内核升级之后，都有必要检查跟踪点列表，看看是否有新的跟踪点。添加它们是经过充分考虑的，包括评估有多少人会使用它们。需要实现一个平衡:我将包括尽可能少的探测，以充分满足常见需求，任何不寻常或不常见的情况都可以留给动态跟踪。 For examples of using tracepoints, see Static Kernel Tracing. 有关使用跟踪点的示例，请参见静态内核跟踪。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:3","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5.4. User-Level Statically Defined Tracing (USDT) Similar to kernel tracepoints, these are hardcoded (usually by placing macros) in the application source at logical and interesting locations, and presented (event name and arguments) as a stable API. Many applications already include tracepoints, added to support DTrace. However, many of these applications do not compile them in by default on Linux. Often you need to compile the application yourself using a –with-dtrace flag. 与内核跟踪点类似，这些跟踪点是硬编码的(通常通过将宏放置在应用程序源代码中)，并作为稳定的API呈现(事件名称和参数)。许多应用程序已经包括跟踪点，这些跟踪点是为了支持DTrace而添加的。然而，许多这些应用程序在Linux上默认情况下并不编译它们。通常需要使用—with-dtrace标志自己编译应用程序。 For example, compiling USDT events with this version of Node.js: 例如，用这个版本的Node.js编译USDT事件: $ sudo apt-get install systemtap-sdt-dev # adds \"dtrace\", used by node build $ wget https://nodejs.org/dist/v4.4.1/node-v4.4.1.tar.gz $ tar xvf node-v4.4.1.tar.gz $ cd node-v4.4.1 $ ./configure --with-dtrace $ make -j 8 To check that the resulting node binary has probes included: 检查产生的二进制程序是否包含了 USDT 探测点: $ readelf -n node Displaying notes found at file offset 0x00000254 with length 0x00000020: Owner Data size Description GNU 0x00000010 NT_GNU_ABI_TAG (ABI version tag) OS: Linux, ABI: 2.6.32 Displaying notes found at file offset 0x00000274 with length 0x00000024: Owner Data size Description GNU 0x00000014 NT_GNU_BUILD_ID (unique build ID bitstring) Build ID: 1e01659b0aecedadf297b2c56c4a2b536ae2308a Displaying notes found at file offset 0x00e70994 with length 0x000003c4: Owner Data size Description stapsdt 0x0000003c NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: gc__start Location: 0x0000000000dc14e4, Base: 0x000000000112e064, Semaphore: 0x000000000147095c Arguments: 4@%esi 4@%edx 8@%rdi stapsdt 0x0000003b NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: gc__done Location: 0x0000000000dc14f4, Base: 0x000000000112e064, Semaphore: 0x000000000147095e Arguments: 4@%esi 4@%edx 8@%rdi stapsdt 0x00000067 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__server__response Location: 0x0000000000dc1894, Base: 0x000000000112e064, Semaphore: 0x0000000001470956 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000061 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: net__stream__end Location: 0x0000000000dc1c44, Base: 0x000000000112e064, Semaphore: 0x0000000001470952 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000068 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: net__server__connection Location: 0x0000000000dc1ff4, Base: 0x000000000112e064, Semaphore: 0x0000000001470950 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000060 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__client__response Location: 0x0000000000dc23c5, Base: 0x000000000112e064, Semaphore: 0x000000000147095a Arguments: 8@%rdx 8@-1144(%rbp) -4@%eax -4@-1152(%rbp) stapsdt 0x00000089 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__client__request Location: 0x0000000000dc285e, Base: 0x000000000112e064, Semaphore: 0x0000000001470958 Arguments: 8@%rax 8@%rdx 8@-2184(%rbp) -4@-2188(%rbp) 8@-2232(%rbp) 8@-2240(%rbp) -4@-2192(%rbp) stapsdt 0x00000089 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__server__request Location: 0x0000000000dc2e69, Base: 0x000000000112e064, Semaphore: 0x0000000001470954 Arguments: 8@%r14 8@%rax 8@-4344(%rbp) -4@-4348(%rbp) 8@-4304(%rbp) 8@-4312(%rbp) -4@-4352(%rbp) For examples of using USDT events, see Static User Tracing. 有关使用USDT事件的示例，请参见静态用户跟踪。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:4","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"5.5. Dynamic Tracing The difference between tracepoints and dynamic tracing is shown in the following figure, which illustrates the coverage of common tracepoint libraries: 跟踪点和动态跟踪之间的区别如下图所示，它说明了通用跟踪点库的覆盖范围: While dynamic tracing can see everything, it’s also an unstable interface since it is instrumenting raw code. That means that any dynamic tracing tools you develop may break after a kernel patch or update. Try to use the static tracepoints first, since their interface should be much more stable. They can also be easier to use and understand, since they have been designed with a tracing end-user in mind. 虽然动态跟踪可以看到所有东西，但它也是一个不稳定的接口，因为它检测的是原始代码。这意味着您开发的任何动态跟踪工具在内核补丁或更新之后可能会中断。首先尝试使用静态跟踪点，因为它们的接口应该更加稳定。它们也更容易使用和理解，因为它们是为跟踪最终用户而设计的。 One benefit of dynamic tracing is that it can be enabled on a live system without restarting anything. You can take an already-running kernel or application and then begin dynamic instrumentation, which (safely) patches instructions in memory to add instrumentation. That means there is zero overhead or tax for this feature until you begin using it. One moment your binary is running unmodified and at full speed, and the next, it’s running some extra instrumentation instructions that you dynamically added. Those instructions should eventually be removed once you’ve finished using your session of dynamic tracing. 动态跟踪的一个好处是，它可以在活动的系统上启用，而不需要重新启动任何东西。您可以使用一个已经运行的内核或应用程序，然后开始动态检测，它(安全地)在内存中修补指令以添加检测。这意味着在您开始使用此功能之前，此功能的开销或税收为零。这一刻，您的二进制文件还在以全速运行，而下一刻，它又在运行一些您动态添加的额外的检测指令。当您使用完动态跟踪会话后，这些指令最终应该被删除。 The overhead while dynamic tracing is in use, and extra instructions are being executed, is relative to the frequency of instrumented events multiplied by the work done on each instrumentation. 在使用动态跟踪和执行额外指令时的开销，与插装事件的频率乘以在每个插装上所做的工作有关。 For examples of using dynamic tracing, see 6.5. Dynamic Tracing. 有关使用动态跟踪的示例，请参见 6.5. Dynamic Tracing ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:5:5","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6. Examples These are some examples of perf_events, collected from a variety of 3.x Linux systems. 下面是 Linux3.x perf_events的一些示例。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.1. CPU Statistics The perf stat command instruments and summarizes key CPU counters (PMCs). This is from perf version 3.5.7.2: 下面是 3.5.7.2版本的 perf stat 子命令输出的 PMCs 计数器统计值。 # perf stat gzip file1 Performance counter stats for 'gzip file1': 1920.159821 task-clock # 0.991 CPUs utilized 13 context-switches # 0.007 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.134 K/sec 5,649,595,479 cycles # 2.942 GHz [83.43%] 1,808,339,931 stalled-cycles-frontend # 32.01% frontend cycles idle [83.54%] 1,171,884,577 stalled-cycles-backend # 20.74% backend cycles idle [66.77%] 8,625,207,199 instructions # 1.53 insns per cycle # 每周期指令数 # 0.21 stalled cycles per insn [83.51%] 1,488,797,176 branches # 775.351 M/sec [82.58%] 53,395,139 branch-misses # 3.59% of all branches [83.78%] 1.936842598 seconds time elapsed This includes instructions per cycle (IPC), labled “insns per cycle”, or in earlier versions, “IPC”. This is a commonly examined metric, either IPC or its invert, CPI. Higher IPC values mean higher instruction throughput, and lower values indicate more stall cycles. I’d generally interpret high IPC values (eg, over 1.0) as good, indicating optimal processing of work. However, I’d want to double check what the instructions are, in case this is due to a spin loop: a high rate of instructions, but a low rate of actual work completed. 这包括每个周期的指令(IPC)，标签为“每个周期的insns”，或者在早期版本中为“IPC”。这是一个经常被检验的指标，无论是IPC还是它的倒数 CPI 。更高的IPC值意味着更高的指令吞吐量，更低的值表示更多的停顿周期。一般来说，我认为IPC值越高(例如，超过1.0)就越好，表示工作的最佳处理。但是，需要检查执行指令是什么，以防这是一个旋转循环: 指令率高，但实际完成的工作率低。 There are some advanced metrics now included in perf stat: frontend cycles idle, backend cycles idle, and stalled cycles per insn. To really understand these, you’ll need some knowledge of CPU microarchitecture. 现在perf stat中包含了一些高级指标:frontend cycles idle, backend cycles idle, 和 stalled cycles per insn.。要真正理解这些，您需要一些CPU微架构的知识。 CPU Microarchitecture CPU 微内核架构 The frontend and backend metrics refer to the CPU pipeline, and are also based on stall counts. The frontend processes CPU instructions, in order. It involves instruction fetch, along with branch prediction, and decode. The decoded instructions become micro-operations (uops) which the backend processes, and it may do so out of order. For a longer summary of these components, see Shannon Cepeda’s great posts on frontend and backend. 前端和后端指标指的是CPU管道，统计的是它们的停顿次数。前端按顺序处理CPU指令。它包括指令获取，以及分支预测和解码。解码后的指令成为后端处理的微操作(uops)，并且可能会乱序地执行。对于这些组件的更长的总结，请参阅Shannon Cepeda关于前端和后端的优秀文章。 The backend can also process multiple uops in parallel; for modern processors, three or four. Along with pipelining, this is how IPC can become greater than one, as more than one instruction can be completed (“retired”) per CPU cycle. 后台也可以并行处理多个uops;对于现代处理器来说，有三到四个。与流水线操作一起，IPC可以变得大于1，因为每个CPU周期可以完成多条指令(“已退役”)。 Stalled cycles per instruction is similar to IPC (inverted), however, only counting stalled cycles, which will be for memory or resource bus access. This makes it easy to interpret: stalls are latency, reduce stalls. I really like it as a metric, and hope it becomes as commonplace as IPC/CPI. Lets call it SCPI. 每条指令的停滞周期类似于IPC(反向)，但是，只计算停滞周期，这将用于内存或资源总线访问。这很容易解释:档位是延迟，减少档位。我真的很喜欢把它作为一个度量标准，并希望它能像IPC/CPI一样普及。我们叫它SCPI。 Detailed Mode There is a “detailed” mode for perf stat: 下面是 perf stat 的详细输出模式 # perf stat -d gzip file1 Performance counter stats for 'gzip file1': 1610.719530 task-clock # 0.998 CPUs utilized 20 context-switches # 0.012 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.160 K/sec 5,491,605,997 cycles # 3.409 GHz [40.18%] 1,654,551,151 stalled-cycles-frontend # 30.13% frontend cycles idle [40.80%] 1,025,280,350 stalled-cycles-backend # 18.67% backend cycles idle [40.34%] 8,644,643,951 instructions # 1.57 insns per cycle # 0.19 stalled cycles per insn [50.89%] 1,492,911,665 branches # 926.860 M/sec [50.69%] 53,471,580 branch-misses # 3.58% of all branches [51.21%] 1,938,889,736 L1-dcache-loads # 1203.741 M/sec [49.68%] 154,380,395 L1-dcache-load-misses # 7.96% of all L1-dcac","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.2. Timed Profiling perf_events can profile CPU usage based on sampling the instruction pointer or stack trace at a fixed interval (timed profiling). perf_events可以基于对指令指针或堆栈跟踪的固定间隔采样(定时分析)来分析CPU使用情况。 Sampling CPU stacks at 99 Hertz (-F 99), for the entire system (-a, for all CPUs), with stack traces (-g, for call graphs), for 10 seconds: 以99赫兹(-F 99)，对整个系统(-a，对所有CPU)采样CPU堆栈，采样10秒，并记录堆栈(-g，调用图): # perf record -F 99 -a -g -- sleep 30 [ perf record: Woken up 9 times to write data ] [ perf record: Captured and wrote 3.135 MB perf.data (~136971 samples) ] # ls -lh perf.data -rw------- 1 root root 3.2M Jan 26 07:26 perf.data The choice of 99 Hertz, instead of 100 Hertz, is to avoid accidentally sampling in lockstep with some periodic activity, which would produce skewed results. This is also coarse: you may want to increase that to higher rates (eg, up to 997 Hertz) for finer resolution, especially if you are sampling short bursts of activity and you’d still like enough resolution to be useful. Bear in mind that higher frequencies means higher overhead. 选择99赫兹而不是100赫兹，是为了避免偶然地与某些周期性活动同步采样，以免产生扭曲的结果。这也是粗糙的:你可能想要增加到更高的速率(例如，高达997赫兹)以获得更好的分辨率，特别是当你采样活动的短脉冲时，你仍然希望有足够的分辨率。请记住，更高的频率意味着更高的开销。 The perf.data file can be processed in a variety of ways. On recent versions, the perf report command launches an ncurses navigator for call graph inspection. Older versions of perf (or if you use –stdio in the new version) print the call graph as a tree, annotated with percentages: perf.data 文件可以用多种方法处理。在最近的版本中，perf report命令启动ncurses导航器来检查调用图。旧版本的perf(或者如果你在新版本中使用–stdio)将调用图打印成树状，并标注百分比: # perf report --stdio # ======== # captured on: Mon Jan 26 07:26:40 2014 # hostname : dev2 # os release : 3.8.6-ubuntu-12-opt # perf version : 3.8.6 # arch : x86_64 # nrcpus online : 8 # nrcpus avail : 8 # cpudesc : Intel(R) Xeon(R) CPU X5675 @ 3.07GHz # cpuid : GenuineIntel,6,44,2 # total memory : 8182008 kB # cmdline : /usr/bin/perf record -F 99 -a -g -- sleep 30 # event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = ... # HEADER_CPU_TOPOLOGY info available, use -I to display # HEADER_NUMA_TOPOLOGY info available, use -I to display # pmu mappings: software = 1, breakpoint = 5 # ======== # # Samples: 22K of event 'cpu-clock' # Event count (approx.): 22751 # # Overhead Command Shared Object Symbol # ........ ....... ................. ............................... # 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--96.67%-- extract_buf | extract_entropy_user | urandom_read | vfs_read | sys_read | system_call_fastpath | read | |--1.69%-- account | | | |--99.72%-- extract_entropy_user | | urandom_read | | vfs_read | | sys_read | | system_call_fastpath | | read | --0.28%-- [...] | |--1.60%-- mix_pool_bytes.constprop.17 [...] This tree starts with the on-CPU functions and works back through the ancestry. This approach is called a “callee based call graph”. This can be flipped by using -G for an “inverted call graph”, or by using the “caller” option to -g/–call-graph, instead of the “callee” default. 这个树从on-CPU函数开始，并通过祖先开始工作。这种方法称为“基于调用者的调用图”。这可以通过使用-G来反转调用关系图，对于 -g/–call-graph 记录的调用图，也可以使用 caller 来代替 默认值callee，以反转调用关系图。默认是用 -g 选项记录的是“基于调用者的调用图”，使用 -g caller 或者 –children 将反转调用关系图。 The hottest (most frequent) stack trace in this perf call graph occurred in 90.99% of samples, which is the product of the overhead percentage and top stack leaf (94.12% x 96.67%, which are relative rates). perf report can also be run with “-g graph” to show absolute overhead rates, in which case “90.99%” is directly displayed on the stack leaf: 上面的perf调用图显示采样中最热(最频繁)的堆栈跟踪发生频率是 90.99%，它是Overhead列的百分比和顶部堆栈叶(94.12% x 96.67%，它们是相对比率)的乘积。perf报告也可以用“-g graph”运行，直接显示绝对的开销占比。此时将像下面这样，“90.99%”直接显示在堆栈叶上: 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--90.99%-- extract_buf [...] If user-level stacks look incomplete, you can try perf record with “–call-graph dwarf” as a different tech","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.3. Event Profiling Apart from sampling at a timed interval, taking samples triggered by CPU hardware counters is another form of CPU profiling, which can be used to shed more light on cache misses, memory stall cycles, and other low-level processor events. The available events can be found using perf list: 除了按时间间隔采样外，由CPU硬件计数器触发的采样是CPU分析的另一种形式，它可以用来更清楚地了解缓存丢失、内存停滞周期和其他低级处理器事件。可用事件可以找到使用perf列表: # perf list | grep Hardware cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event] L1-dcache-store-misses [Hardware cache event] [...] For many of these, gathering a stack on every occurrence would induce far too much overhead, and would slow down the system and change the performance characteristics of the target. It’s usually sufficient to only instrument a small fraction of their occurrences, rather than all of them. This can be done by specifying a threshold for triggering event collection, using “-c” and a count. 对于其中的许多情况，在每次出现时都收集堆栈会导致过多的开销，并会降低系统速度并改变目标的性能特征。通常，只测量它们出现的一小部分，而不是全部，就足够了。这可以通过使用“-c” 指定触发事件收集的阈值来实现。 For example, the following one-liner instruments Level 1 data cache load misses, collecting a stack trace for one in every 10,000 occurrences: 例如，下面的一行程序统计 1级数据缓存加载失败次数，每10000次失败收集一次堆栈跟踪: # perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5 The mechanics of “-c count” are implemented by the processor, which only interrupts the kernel when the threshold has been reached. “-c count”机制是由处理器实现的，它只在达到阈值时中断内核。 See the earlier Raw Counters section for an example of specifying a custom counter, and the next section about skew. 有关指定自定义计数器的示例，请参阅前面的Raw计数器部分，和下一节。 Skew and PEBS There’s a problem with event profiling that you don’t really encounter with CPU profiling (timed sampling). With timed sampling, it doesn’t matter if there was a small sub-microsecond delay between the interrupt and reading the instruction pointer (IP). Some CPU profilers introduce this jitter on purpose, as another way to avoid lockstep sampling. But for event profiling, it does matter: if you’re trying to capture the IP on some PMC event, and there’s a delay between the PMC overflow and capturing the IP, then the IP will point to the wrong address. This is skew. Another contributing problem is that micro-ops are processed in parallel and out-of-order, while the instruction pointer points to the resumption instruction, not the instruction that caused the event. I’ve talked about this before. 事件分析存在一个CPU分析不会遇到的问题(定时采样)。对于定时采样，在中断和读取指令指针(IP)之间是否有一个亚微秒的延迟并不重要。一些CPU分析器故意引入这种抖动，作为避免同步采样的另一种方法。但是对于事件分析来说，这确实很重要:如果您试图捕获某个PMC事件上的IP，并且在PMC溢出和捕获IP之间存在延迟，那么IP将指向错误的地址。这是倾斜。另一个问题是微操作是并行和无序处理的，而指令指针指向的是恢复指令，而不是导致事件的指令。我之前讲过这个。· The solution is “precise sampling”, which on Intel is PEBS (Precise Event-Based Sampling), and on AMD it is IBS (Instruction-Based Sampling). These use CPU hardware support to capture the real state of the CPU at the time of the event. perf can use precise sampling by adding a :p modifier to the PMC event name, eg, “-e instructions:p”. The more p’s, the more accurate. Here are the docs from tools/perf/Documentation/perf-list.txt: 解决方案是“精确采样”，在英特尔上是PEBS(基于事件的精确采样)，在AMD上是IBS(基于指令的采样)。它们使用CPU硬件支持来捕获事件发生时CPU的真实状态。perf可以通过在PMC事件名称中添加一个:p修饰符来使用精确的采样，例如，“-e instructions:p”。p越多，越准确。以下是tools/perf/Documentation/perf-list.txt提供的文档: The 'p' modifier can be used for specifying how precise the instruction address should be. The 'p' modifier can be specified multiple times: 'p'修饰符可以用来指定指令地址的精确程度。“p”修饰符可以被指定多次: 0 - SAMPLE_IP can have arbitrary skid SAMPLE_IP可以任意滑动 1 - SAMPLE_IP must have constant","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:3","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.4. Static Kernel Tracing The following examples demonstrate static tracing: the instrumentation of tracepoints and other static events. 下面的示例演示了如何进行静态跟踪: 跟踪点和其他静态事件。 Counting Syscalls The following simple one-liner counts system calls for the executed command, and prints a summary (of non-zero counts): 下面是一个统计系统调用并打印摘要(非零计数)的简单命令: # perf stat -e 'syscalls:sys_enter_*' gzip file1 2\u003e\u00261 | awk '$1 != 0' Performance counter stats for 'gzip file1': 1 syscalls:sys_enter_utimensat 1 syscalls:sys_enter_unlink 5 syscalls:sys_enter_newfstat 1,603 syscalls:sys_enter_read 3,201 syscalls:sys_enter_write 5 syscalls:sys_enter_access 1 syscalls:sys_enter_fchmod 1 syscalls:sys_enter_fchown 6 syscalls:sys_enter_open 9 syscalls:sys_enter_close 8 syscalls:sys_enter_mprotect 1 syscalls:sys_enter_brk 1 syscalls:sys_enter_munmap 1 syscalls:sys_enter_set_robust_list 1 syscalls:sys_enter_futex 1 syscalls:sys_enter_getrlimit 5 syscalls:sys_enter_rt_sigprocmask 14 syscalls:sys_enter_rt_sigaction 1 syscalls:sys_enter_exit_group 1 syscalls:sys_enter_set_tid_address 14 syscalls:sys_enter_mmap 1.543990940 seconds time elapsed In this case, a gzip command was analyzed. The report shows that there were 3,201 write() syscalls, and half that number of read() syscalls. Many of the other syscalls will be due to process and library initialization. 在本例中，分析了gzip命令。报告显示有3201个write()系统调用，而read()系统调用只有这个数量的一半。许多其他系统崩溃都是由于进程和库的初始化。 A similar report can be seen using strace -c, the system call tracer, however it may induce much higher overhead than perf, as perf buffers data in-kernel. 使用系统调用跟踪程序strace -c可以看到类似的报告，但是它可能导致比perf高得多的开销，因为perf在内核中缓冲数据。 perf vs strace To explain the difference a little further: the current implementation of strace uses ptrace(2) to attach to the target process and stop it during system calls, like a debugger. This is violent, and can cause serious overhead. To demonstrate this, the following syscall-heavy program was run by itself, with perf, and with strace. I’ve only included the line of output that shows its performance: 为了进一步解释这种差异:strace的当前实现使用ptrace(2)附加到目标进程并在系统调用期间停止它，就像调试器一样。这是暴力的，并可能导致严重的开销。为了演示这一点，下面使用perf和strace单独运行具有大量系统调用的程序。我只包含了显示其性能的输出行: # dd if=/dev/zero of=/dev/null bs=512 count=10000k 5242880000 bytes (5.2 GB) copied, 3.53031 s, 1.5 GB/s # perf stat -e 'syscalls:sys_enter_*' dd if=/dev/zero of=/dev/null bs=512 count=10000k 5242880000 bytes (5.2 GB) copied, 9.14225 s, 573 MB/s # strace -c dd if=/dev/zero of=/dev/null bs=512 count=10000k 5242880000 bytes (5.2 GB) copied, 218.915 s, 23.9 MB/s With perf, the program ran 2.5x slower. But with strace, it ran 62x slower. That’s likely to be a worst-case result: if syscalls are not so frequent, the difference between the tools will not be as great. 使用perf，程序运行速度慢了2.5倍。但使用strace时，它的运行速度慢了62倍。这可能是最糟糕的结果:如果系统调用不那么频繁，那么工具之间的差异就不会那么大。 Recent version of perf have included a trace subcommand, to provide some similar functionality to strace, but with much lower overhead. perf的最新版本包含了一个跟踪子命令，以提供一些与strace类似的功能，但开销要低得多。 New Processes Tracing new processes triggered by a “man ls”: 下面跟踪man ls命令创建的新进程 # perf record -e sched:sched_process_exec -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ] # perf report -n --sort comm --stdio [...] # Overhead Samples Command # ........ ............ ....... # 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff Nine different commands were executed, each once. I used -n to print the “Samples” column, and “–sort comm” to customize the remaining columns. 可以看到执行了9个不同的命令，每个命令执行一次。我使用-n来打印“Samples”列，使用—sort comm来定制其余的列。 This works by tracing sched:sched_process_exec, when a process runs exec() to execute a different binary. This is often how new processes are created, but not always. An application may fork() to create a pool of worker processes, but not exec() a different binary. An application may also reexec","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:4","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.5. Static User Tracing Support was added in later 4.x series kernels. The following demonstrates Linux 4.10 (with an additional patchset), and tracing the Node.js USDT probes: 在4.x 的内核中，添加了用户态静态追踪机制。下面演示了Linux 4.10(附加了一个补丁集)，如何跟踪Node.js 的USDT探针: # perf buildid-cache --add `which node` # perf list | grep sdt_node sdt_node:gc__done [SDT event] sdt_node:gc__start [SDT event] sdt_node:http__client__request [SDT event] sdt_node:http__client__response [SDT event] sdt_node:http__server__request [SDT event] sdt_node:http__server__response [SDT event] sdt_node:net__server__connection [SDT event] sdt_node:net__stream__end [SDT event] # perf record -e sdt_node:http__server__request -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.446 MB perf.data (3 samples) ] # perf script node 7646 [002] 361.012364: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.204718: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.363043: sdt_node:http__server__request: (dc2e69) XXX fill me in, including how to use arguments. XXX告诉我，包括如何使用参数。 If you are on an older kernel, say, Linux 4.4-4.9, you can probably get these to work with adjustments (I’ve even hacked them up with ftrace for older kernels), but since they have been in development, I haven’t seen documentation outside of lkml, so you’ll need to figure it out. (On this kernel range, you might find more documentation for tracing these with bcc/eBPF, including using the trace.py tool.) 如果您使用的是一个较老的内核，比如Linux 4.4-4.9，你可以做相应的调整来使用用户态追踪(我甚至用ftrace对较老的内核进行了分解)，但是由于它们已经在开发中，我还没有看到lkml之外的文档，所以您需要弄清楚它。(在这个内核范围内，您可能会找到更多使用bcc/eBPF跟踪这些文件的文档，包括使用trace.py工具。) ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:5","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.6. Dynamic Tracing For kernel analysis, I’m using CONFIG_KPROBES=y and CONFIG_KPROBE_EVENTS=y, to enable kernel dynamic tracing, and CONFIG_FRAME_POINTER=y, for frame pointer-based kernel stacks. For user-level analysis, CONFIG_UPROBES=y and CONFIG_UPROBE_EVENTS=y, for user-level dynamic tracing. 对于内核分析，使用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y来启用内核动态跟踪，对于基于框架指针的内核堆栈，使用CONFIG_FRAME_POINTER=y。对于用户级分析，CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y用于启用用户级动态跟踪。 Kernel: tcp_sendmsg() This example shows instrumenting the kernel tcp_sendmsg() function on the Linux 3.9.3 kernel: 下面的例子展示了在Linux 3.9.3内核上检测内核tcp_sendmsg()函数: # perf probe --add tcp_sendmsg Failed to find path of kernel module. Added new event: probe:tcp_sendmsg (on tcp_sendmsg) You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1 This adds a new tracepoint event. It suggests using the -R option, to collect raw sample records, which is already the default for tracepoints. Tracing this event for 5 seconds, recording stack traces: 这将添加一个新的跟踪点事件。它建议使用-R选项来收集原始示例记录，这已经是跟踪点的默认值。-R 用于设置跟踪事件5秒，并记录堆栈跟踪: # perf record -e probe:tcp_sendmsg -a -g -- sleep 5 [ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.228 MB perf.data (~9974 samples) ] And the report: 下面是输出报告 # perf report --stdio # ======== # captured on: Fri Jan 31 20:10:14 2014 # hostname : pgbackup # os release : 3.9.3-ubuntu-12-opt # perf version : 3.9.3 # arch : x86_64 # nrcpus online : 8 # nrcpus avail : 8 # cpudesc : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz # cpuid : GenuineIntel,6,45,7 # total memory : 8179104 kB # cmdline : /lib/modules/3.9.3/build/tools/perf/perf record -e probe:tcp_sendmsg -a -g -- sleep 5 # event : name = probe:tcp_sendmsg, type = 2, config = 0x3b2, config1 = 0x0, config2 = 0x0, ... # HEADER_CPU_TOPOLOGY info available, use -I to display # HEADER_NUMA_TOPOLOGY info available, use -I to display # pmu mappings: software = 1, tracepoint = 2, breakpoint = 5 # ======== # # Samples: 12 of event 'probe:tcp_sendmsg' # Event count (approx.): 12 # # Overhead Command Shared Object Symbol # ........ ....... ................. ............... # 100.00% sshd [kernel.kallsyms] [k] tcp_sendmsg | --- tcp_sendmsg sock_aio_write do_sync_write vfs_write sys_write system_call_fastpath __write_nocancel | |--8.33%-- 0x50f00000001b810 --91.67%-- [...] This shows the path from the write() system call to tcp_sendmsg(). 这显示了从write()系统调用到tcp_sendmsg()的路径。 You can delete these dynamic tracepoints if you want after use, using perf probe –del. 如果需要，可以在使用后删除这些动态跟踪点，使用perf probe –del。 Kernel: tcp_sendmsg() with size If your kernel has debuginfo (CONFIG_DEBUG_INFO=y), you can fish out kernel variables from functions. This is a simple example of examining a size_t (integer), on Linux 3.13.1. 如果内核有debuginfo (CONFIG_DEBUG_INFO=y)，那么可以从函数中提取内核变量。这是在Linux 3.13.1上检查size_t(整数)的一个简单示例。 Listing variables available for tcp_sendmsg(): 列出tcp_sendmsg()可用的变量: # perf probe -V tcp_sendmsg Available variables at tcp_sendmsg @\u003ctcp_sendmsg+0\u003e size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk Creating a probe for tcp_sendmsg() with the “size” variable: 使用变量“size”为tcp_sendmsg()创建一个探针: # perf probe --add 'tcp_sendmsg size' Added new event: probe:tcp_sendmsg (on tcp_sendmsg with size) You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1 Tracing this probe: 跟踪此探针 # perf record -e probe:tcp_sendmsg -a ^C[ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.052 MB perf.data (~2252 samples) ] # perf script # ======== # captured on: Fri Jan 31 23:49:55 2014 # hostname : dev1 # os release : 3.13.1-ubuntu-12-opt # perf version : 3.13.1 # arch : x86_64 # nrcpus online : 2 # nrcpus avail : 2 # cpudesc : Intel(R) Xeon(R) CPU E5645 @ 2.40GHz # cpuid : GenuineIntel,6,44,2 # total memory : 1796024 kB # cmdline : /usr/bin/perf record -e probe:tcp_sendmsg -a # event : name = probe:tcp_sendmsg, type = 2, config = 0x1dd, c","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:6","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.7. Scheduler Analysis The perf sched subcommand provides a number of tools for analyzing kernel CPU scheduler behavior. You can use this to identify and quantify issues of scheduler latency. perf sched子命令提供了许多用于分析内核CPU调度器行为的工具。您可以使用它来识别和量化调度器延迟的问题。 The current overhead of this tool (as of up to Linux 4.10) may be noticeable, as it instruments and dumps scheduler events to the perf.data file for later analysis. For example: 这个工具的当前开销(从Linux 4.10开始)可能是显而易见的，因为它将调度器事件转储到perf。供以后分析使用。例如: # perf sched record -- sleep 1 [ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 1.886 MB perf.data (13502 samples) ] That’s 1.9 Mbytes for one second, including 13,502 samples. The size and rate will be relative to your workload and number of CPUs (this example is an 8 CPU server running a software build). How this is written to the file system has been optimized: it only woke up one time to read the event buffers and write them to disk, which greatly reduces overhead. That said, there are still significant overheads with instrumenting all scheduler events and writing event data to the file system. These events: 一秒是1.9兆字节，包括13502个样本。大小和速率将与您的工作负载和CPU数量相关(本例是运行软件构建的8 CPU服务器)。如何将其写入文件系统已经进行了优化:它只唤醒一次来读取事件缓冲区并将其写入磁盘，这大大减少了开销。也就是说，在检测所有调度器事件和向文件系统写入事件数据方面仍然存在很大的开销。 # perf script --header # ======== # captured on: Sun Feb 26 19:40:00 2017 # hostname : bgregg-xenial # os release : 4.10-virtual # perf version : 4.10 # arch : x86_64 # nrcpus online : 8 # nrcpus avail : 8 # cpudesc : Intel(R) Xeon(R) CPU E5-2680 v2 @ 2.80GHz # cpuid : GenuineIntel,6,62,4 # total memory : 15401700 kB # cmdline : /usr/bin/perf sched record -- sleep 1 # event : name = sched:sched_switch, , id = { 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759 }, type = 2, size = 11... # event : name = sched:sched_stat_wait, , id = { 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767 }, type = 2, size =... # event : name = sched:sched_stat_sleep, , id = { 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775 }, type = 2, size ... # event : name = sched:sched_stat_iowait, , id = { 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783 }, type = 2, size... # event : name = sched:sched_stat_runtime, , id = { 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791 }, type = 2, siz... # event : name = sched:sched_process_fork, , id = { 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799 }, type = 2, siz... # event : name = sched:sched_wakeup, , id = { 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807 }, type = 2, size = 11... # event : name = sched:sched_wakeup_new, , id = { 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815 }, type = 2, size ... # event : name = sched:sched_migrate_task, , id = { 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823 }, type = 2, siz... # HEADER_CPU_TOPOLOGY info available, use -I to display # HEADER_NUMA_TOPOLOGY info available, use -I to display # pmu mappings: breakpoint = 5, power = 7, software = 1, tracepoint = 2, msr = 6 # HEADER_CACHE info available, use -I to display # missing features: HEADER_BRANCH_STACK HEADER_GROUP_DESC HEADER_AUXTRACE HEADER_STAT # ======== # perf 16984 [005] 991962.879966: sched:sched_wakeup: comm=perf pid=16999 prio=120 target_cpu=005 [...] If overhead is a problem, you can use my eBPF/bcc Tools including runqlat and runqlen which use in-kernel summaries of scheduler events, reducing overhead further. An advantage of perf sched dumping all events is that you aren’t limited to the summary. If you caught an intermittent event, you can analyze those recorded events in custom ways until you understood the issue, rather than needing to catch it a second time. 如果开销是一个问题，您可以使用我的eBPF/bcc工具，包括runqlat和runqlen，它们使用内核内的调度器事件摘要，进一步减少开销。perf sched转储所有事件的一个优点是您不局限于摘要。如果捕捉到一个间歇事件，您可以用自定义的方式分析那些记录的事件，直到您理解问题为止，而不需要再次捕捉它。 The captured trace file can be reported in a number of ways, summarized by the help message: 捕获的跟踪文件可以用多种方式报告，通过帮助可以查看这些处理方式 : # perf sched -h Usage: perf sched [] {record|latency|map|replay|script|timehist} -D, --dump-raw-trace dump raw trace i","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:7","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"6.8. eBPF As of Linux 4.4, perf has some enhanced BPF support (aka eBPF or just “BPF”), with more in later kernels. BPF makes perf tracing programmatic, and takes perf from being a counting \u0026 sampling-with-post-processing tracer, to a fully in-kernel programmable tracer. 从Linux 4.4开始，perf已经增强了对BPF的支持(又名eBPF或简称为“BPF”)，在以后的内核中会有更多的增强。BPF使perf跟踪成为可编程的，并使perf从一个计数和取样与后处理跟踪程序，成为一个完全在内核内可编程跟踪程序。 eBPF is currently a little restricted and difficult to use from perf. It’s getting better all the time. A different and currently easier way to access eBPF is via the bcc Python interface, which is described on my eBPF Tools page. On this page, I’ll discuss perf. eBPF目前在 perf 上有限制，并且难以使用。不过情况一直在好转。一种不同的、目前更容易的访问eBPF的方法是通过bcc Python接口，它在我的eBPF工具页面上被描述。当前只讨论perf。 Prerequisites Linux 4.4 at least. Newer versions have more perf/BPF features, so the newer the better. Also clang (eg, apt-get install clang). 至少是Linux 4.4。较新的版本有更多的perf/BPF特性，所以越新越好。还有 clang (eg，apt-get install clang)。 kmem_cache_alloc from Example This program traces the kernel kmem_cache_alloc() function, only if its calling function matches a specified range, filtered in kernel context. You can imagine doing this for efficiency: instead of tracing all allocations, which can be very frequent and add significant overhead, you filter for just a range of kernel calling functions of interest, such as a kernel module. I’ll loosely match tcp functions as an example, which are in memory at these addresses: 这个程序跟踪内核kmem_cache_alloc()函数，仅当它的调用函数匹配指定的范围(在内核上下文中过滤)。您可以想象这样做是为了提高效率:您不必跟踪所有的分配(这可能非常频繁并增加显著的开销)，而是只过滤感兴趣的一系列内核调用函数，比如内核模块。我将松散匹配tcp函数作为一个例子，这是在内存在这些地址: # grep tcp /proc/kallsyms | more [...] ffffffff817c1bb0 t tcp_get_info_chrono_stats ffffffff817c1c60 T tcp_init_sock ffffffff817c1e30 t tcp_splice_data_recv ffffffff817c1e70 t tcp_push ffffffff817c20a0 t tcp_send_mss ffffffff817c2170 t tcp_recv_skb ffffffff817c2250 t tcp_cleanup_rbuf [...] ffffffff818524f0 T tcp6_proc_exit ffffffff81852510 T tcpv6_exit ffffffff818648a0 t tcp6_gro_complete ffffffff81864910 t tcp6_gro_receive ffffffff81864ae0 t tcp6_gso_segment ffffffff8187bd89 t tcp_v4_inbound_md5_hash I’ll assume these functions are contiguous, so that by tracing the range 0xffffffff817c1bb0 to 0xffffffff8187bd89, I’m matching much of tcp. 我假设这些函数是连续的，因此通过跟踪范围0xffffffffffff817c1bb0到0xffffffff8187bd89，我匹配了大部分tcp。 Here is my BPF program, kca_from.c: 这是我的BPF程序，kca_from.c: #include \u003cuapi/linux/bpf.h\u003e #include \u003cuapi/linux/ptrace.h\u003e #define SEC(NAME) __attribute__((section(NAME), used)) /* * Edit the following to match the instruction address range you want to * sample. Eg, look in /proc/kallsyms. The addresses will change for each * kernel version and build. */ #define RANGE_START 0xffffffff817c1bb0 #define RANGE_END 0xffffffff8187bd89 struct bpf_map_def { unsigned int type; unsigned int key_size; unsigned int value_size; unsigned int max_entries; }; static int (*probe_read)(void *dst, int size, void *src) = (void *)BPF_FUNC_probe_read; static int (*get_smp_processor_id)(void) = (void *)BPF_FUNC_get_smp_processor_id; static int (*perf_event_output)(void *, struct bpf_map_def *, int, void *, unsigned long) = (void *)BPF_FUNC_perf_event_output; struct bpf_map_def SEC(\"maps\") channel = { .type = BPF_MAP_TYPE_PERF_EVENT_ARRAY, .key_size = sizeof(int), .value_size = sizeof(u32), .max_entries = __NR_CPUS__, }; SEC(\"func=kmem_cache_alloc\") int func(struct pt_regs *ctx) { u64 ret = 0; // x86_64 specific: probe_read(\u0026ret, sizeof(ret), (void *)(ctx-\u003ebp+8)); if (ret \u003e= RANGE_START \u0026\u0026 ret \u003c RANGE_END) { perf_event_output(ctx, \u0026channel, get_smp_processor_id(), \u0026ret, sizeof(ret)); } return 0; } char _license[] SEC(\"license\") = \"GPL\"; int _version SEC(\"version\") = LINUX_VERSION_CODE; Now I’ll execute it, then dump the events: 现在我将执行它，然后转储事件: # perf record -e bpf-output/no-inherit,name=evt/ -e ./kca_from.c/map:channel.event=evt/ -a -- sleep 1 bpf: builtin compilation failed: -95, try external compiler [ perf record: Woken up 1 times to write data ] [ per","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:6:8","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"7. Visualizations(可视化) perf_events has a builtin visualization: timecharts, as well as text-style visualization via its text user interface (TUI) and tree reports. The following two sections show visualizations of my own: flame graphs and heat maps. The software I’m using is open source and on github, and produces these from perf_events collected data. perf_events有一个内置的可视化:timecharts，以及通过文本用户界面(TUI)和树状报告的文本风格的可视化。下面两个部分展示了我自己的可视化:火焰图和热图。我使用的软件是开源的，并且在github上，并从perf_events收集的数据中生成这些数据。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:7:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"7.1. Flame Graphs Flame Graphs can be produced from perf_events profiling data using the FlameGraph tools software. This visualizes the same data you see in perf report, and works with any perf.data file that was captured with stack traces (-g). 火焰图可以使用FlameGraph工具软件从perf_events分析数据生成。这将可视化您在perf报告中看到的相同数据，并与任何perf一起工作。用堆栈跟踪捕获的数据文件(-g)。 Example This example CPU flame graph shows a network workload for the 3.2.9-1 Linux kernel, running as a KVM instance (SVG, PNG): 这个示例CPU火焰图显示了3.2.9-1 Linux内核的网络工作负载，它作为一个KVM实例运行(SVG， PNG): Flame Graphs show the sample population across the x-axis, and stack depth on the y-axis. Each function (stack frame) is drawn as a rectangle, with the width relative to the number of samples. See the CPU Flame Graphs page for the full description of how these work. 火焰图在x轴上显示样本总体，在y轴上显示堆栈深度。每个函数(堆栈框架)被绘制成一个矩形，宽度与样本的数量相关。请查看CPU火焰图页面，以获得如何工作的完整描述。 You can use the mouse to explore where kernel CPU time is spent, quickly quantifying code-paths and determining where performance tuning efforts are best spent. This example shows that most time was spent in the vp_notify() code-path, spending 70.52% of all on-CPU samples performing iowrite16(), which is handled by the KVM hypervisor. This information has been extremely useful for directing KVM performance efforts. 您可以使用鼠标探索内核CPU时间花在哪里，快速量化代码路径，并确定性能调优工作最好花在哪里。这个示例显示，大部分时间都花在vp_notify()代码路径上，所有cpu上的示例中有70.52%的时间执行iowrite16()，它由KVM管理程序处理。这些信息对于指导KVM性能工作非常有用。 A similar network workload on a bare metal Linux system looks quite different, as networking isn’t processed via the virtio-net driver, for a start. 裸机Linux系统上类似的网络工作负载看起来非常不同，因为首先网络不是通过virtio-net驱动程序处理的。 Generation The example flame graph was generated using perf_events and the FlameGraph tools: 示例火焰图是使用perf_events和FlameGraph工具生成的: # git clone https://github.com/brendangregg/FlameGraph # or download it from github # cd FlameGraph # perf record -F 99 -ag -- sleep 60 # perf script | ./stackcollapse-perf.pl \u003e out.perf-folded # cat out.perf-folded | ./flamegraph.pl \u003e perf-kernel.svg The first perf command profiles CPU stacks, as explained earlier. I adjusted the rate to 99 Hertz here; I actually generated the flame graph from a 1000 Hertz profile, but I’d only use that if you had a reason to go faster, which costs more in overhead. The samples are saved in a perf.data file, which can be viewed using perf report: 第一个perf命令配置CPU堆栈，如前所述。我把频率调到99赫兹;实际上，我从1000赫兹的数据中生成了火焰图，但只应该在你有理由更快的时候使用更高的频率，这样会花费更多的开销。样本保存在一个perf.data 文件，可使用perf报告查看: # perf report --stdio [...] # Overhead Command Shared Object Symbol # ........ ............... ..................... ................................... # 72.18% iperf [kernel.kallsyms] [k] iowrite16 | --- iowrite16 | |--99.53%-- vp_notify | virtqueue_kick | start_xmit | dev_hard_start_xmit | sch_direct_xmit | dev_queue_xmit | ip_finish_output | ip_output | ip_local_out | ip_queue_xmit | tcp_transmit_skb | tcp_write_xmit | | | |--98.16%-- tcp_push_one | | tcp_sendmsg | | inet_sendmsg | | sock_aio_write | | do_sync_write | | vfs_write | | sys_write | | system_call | | 0x369e40e5cd | | | --1.84%-- __tcp_push_pending_frames [...] This tree follows the flame graph when reading it top-down. When using -g/–call-graph (for “caller”, instead of the “callee” default), it generates a tree that follows the flame graph when read bottom-up. The hottest stack trace in the flame graph (@70.52%) can be seen in this perf call graph as the product of the top three nodes (72.18% x 99.53% x 98.16%). 堆栈树与火焰图一样，遵循从上到下的查看逻辑，即子函数在上，复函数在下。如果使用 -g/--call-graph caller 替代默认的 callee 选项。调用栈和火焰图会倒置。在这个火焰图中个，火焰图(@70.52%)中最热的堆栈轨迹是前三个节点(72.18% x 99.53% x 98.16%)的乘积。 The perf report tree (and the ncurses navigator) do an excellent job at presenting this information as text. However, with text there are limitations. The output often does not fit in one screen (you could say it doesn’t need to, if the bulk of the samples are identified on the first page). Also, identifying the hottest code paths requires reading the percentag","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:7:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"7.2. Heat Maps Since perf_events can record high resolution timestamps (microseconds) for events, some latency measurements can be derived from trace data. 由于perf_events可以记录事件的高分辨率时间戳(微秒)，因此可以从跟踪数据中度量延迟。 Example The following heat map visualizes disk I/O latency data collected from perf_events (SVG, PNG): 以下热图显示了从perf_events (SVG、PNG收集的磁盘I/O延迟数据: Mouse-over blocks to explore the latency distribution over time. The x-axis is the passage of time, the y-axis latency, and the z-axis (color) is the number of I/O at that time and latency range. The distribution is bimodal, with the dark line at the bottom showing that many disk I/O completed with sub-millisecond latency: cache hits. There is a cloud of disk I/O from about 3 ms to 25 ms, which would be caused by random disk I/O (and queueing). Both these modes averaged to the 9 ms we saw earlier. 将鼠标移到块上，以研究延时随时间的分布。x轴是时间的流逝，y轴是延迟，z轴(颜色)是此时的I/O数量和延迟范围。分布是双峰的，底部的暗线显示许多磁盘I/O在亚毫秒级的延迟下完成:缓存命中。磁盘I/O的云大约在3 ms到25 ms之间，这可能是由随机磁盘I/O(和排队)造成的。这两种模式的平均频率为9毫秒。 The following iostat output was collected at the same time as the heat map data was collected (shows a typical one second summary): 下面的iostat输出是在收集热图数据的同时收集的(显示一个典型的一秒摘要): # iostat -x 1 [...] Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %util vda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 vdb 0.00 0.00 334.00 0.00 2672.00 0.00 16.00 2.97 9.01 9.01 0.00 2.99 100.00 This workload has an average I/O time (await) of 9 milliseconds, which sounds like a fairly random workload on 7200 RPM disks. The problem is that we don’t know the distribution from the iostat output, or any similar latency average. There could be latency outliers present, which is not visible in the average, and yet are causing problems. The heat map did show I/O up to 50 ms, which you might not have expected from that iostat output. There could also be multiple modes, as we saw in the heat map, which are also not visible in an average. 这个工作负载的平均I/O时间(等待)为9毫秒，这听起来像是在7200 RPM磁盘上相当随机的工作负载。问题是我们不知道iostat输出的分布情况，也不知道任何类似的延迟平均值。可能存在延迟异常值，这在一般情况下是不可见的，但却会导致问题。热图显示I/O最高可达50毫秒，这可能是iostat输出所没有预料到的。也可以有多种模式，正如我们在热图中看到的那样，在平均模式中也不可见。 Gathering I used perf_events to record the block request (disk I/O) issue and completion static tracepoints: 我使用perf_events 记录 block_rq_issue(磁盘I/O)和 block_rq_complete 跟踪点: # perf record -e block:block_rq_issue -e block:block_rq_complete -a sleep 120 [ perf record: Woken up 36 times to write data ] [ perf record: Captured and wrote 8.885 MB perf.data (~388174 samples) ] # perf script [...] randread.pl 2522 [000] 6011.824759: block:block_rq_issue: 254,16 R 0 () 7322849 + 16 [randread.pl] randread.pl 2520 [000] 6011.824866: block:block_rq_issue: 254,16 R 0 () 26144801 + 16 [randread.pl] swapper 0 [000] 6011.828913: block:block_rq_complete: 254,16 R () 31262577 + 16 [0] randread.pl 2521 [000] 6011.828970: block:block_rq_issue: 254,16 R 0 () 70295937 + 16 [randread.pl] swapper 0 [000] 6011.835862: block:block_rq_complete: 254,16 R () 26144801 + 16 [0] randread.pl 2520 [000] 6011.835932: block:block_rq_issue: 254,16 R 0 () 5495681 + 16 [randread.pl] swapper 0 [000] 6011.837988: block:block_rq_complete: 254,16 R () 7322849 + 16 [0] randread.pl 2522 [000] 6011.838051: block:block_rq_issue: 254,16 R 0 () 108589633 + 16 [randread.pl] swapper 0 [000] 6011.850615: block:block_rq_complete: 254,16 R () 108589633 + 16 [0] [...] The full output from perf script is about 70,000 lines. I’ve included some here so that you can see the kind of data available. perf脚本的完整输出约为70,000行。我在这里添加了一些这样你就能看到可用的数据。 Processing To calculate latency for each I/O, I’ll need to pair up the issue and completion events, so that I can calculate the timestamp delta. The columns look straightforward (and are in include/trace/events/block.h), with the 4th field the timestamp in seconds (with microsecond resolution), the 6th field the disk device ID (major, minor), and a later field (which varies based on the tracepoint) has the disk offset","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:7:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"8. Targets Notes on specific targets. Under construction. ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:8:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"8.1. Java ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:8:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"8.2. Node.js Node.js V8 JIT internals with annotation support https://twitter.com/brendangregg/status/755838455549001728 js V8 JIT内部注释支持 https://twitter.com/brendangregg/status/755838455549001728 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:8:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"9. More There’s more capabilities to perf_events than I’ve demonstrated here. I’ll add examples of the other subcommands when I get a chance. perf_events的功能比我在这里演示的更多。如果有机会，我将添加其他子命令的示例。 Here’s a preview of perf trace, which was added in 3.7, demonstrated on 3.13.1: 下面是perf trace的预览，它是在3.7中添加的，在3.13.1中演示: # perf trace ls 0.109 ( 0.000 ms): ... [continued]: read()) = 1 0.430 ( 0.000 ms): ... [continued]: execve()) = -2 0.565 ( 0.051 ms): execve(arg0: 140734989338352, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.697 ( 0.051 ms): execve(arg0: 140734989338353, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.797 ( 0.046 ms): execve(arg0: 140734989338358, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.915 ( 0.045 ms): execve(arg0: 140734989338359, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 1.030 ( 0.044 ms): execve(arg0: 140734989338362, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 1.414 ( 0.311 ms): execve(arg0: 140734989338363, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 2.156 ( 1.053 ms): ... [continued]: brk()) = 0xac9000 2.319 ( 1.215 ms): ... [continued]: access()) = -1 ENOENT No such file or directory 2.479 ( 1.376 ms): ... [continued]: mmap()) = 0xb3a84000 2.634 ( 0.052 ms): access(arg0: 139967406289504, arg1: 4, arg2: 139967408408688, arg3: 13996740839... 2.787 ( 0.205 ms): ... [continued]: open()) = 3 2.919 ( 0.337 ms): ... [continued]: fstat()) = 0 3.049 ( 0.057 ms): mmap(arg0: 0, arg1: 22200, arg2: 1, arg3: 2, arg4: 3, arg5: 0 ) = 0xb3a... 3.177 ( 0.184 ms): ... [continued]: close()) = 0 3.298 ( 0.043 ms): access(arg0: 139967406278152, arg1: 0, arg2: 6, arg3: 7146772199173811245, arg4... 3.432 ( 0.049 ms): open(arg0: 139967408376811, arg1: 524288, arg2: 0, arg3: 139967408376810, arg4:... 3.560 ( 0.045 ms): read(arg0: 3, arg1: 140737350651528, arg2: 832, arg3: 139967408376810, arg4: 14... 3.684 ( 0.042 ms): fstat(arg0: 3, arg1: 140737350651216, arg2: 140737350651216, arg3: 354389249727... 3.814 ( 0.054 ms): mmap(arg0: 0, arg1: 2221680, arg2: 5, arg3: 2050, arg4: 3, arg5: 0 ) = 0xb36... [...] An advantage is that this is buffered tracing, which costs much less overhead than strace, as I described earlier. The perf trace output seen from this 3.13.1 kernel does, however, looks suspicious for a number of reasons. I think this is still an in-development feature. It reminds me of my dtruss tool, which has a similar role, before I added code to print each system call in a custom and appropriate way. 一个优点是这是缓冲跟踪，它的开销比我前面描述的strace小得多。但是，这个3.13.1内核的perf跟踪输出看起来很可疑，原因有很多。我认为这仍然是一个正在开发的特性。这让我想起了dtruss工具，它具有类似的作用，在添加代码以自定义和适当的方式打印每个系统调用之前。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:9:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"10. Building The steps to build perf_events depends on your kernel version and Linux distribution. In summary: 构建perf_events的步骤取决于您的内核版本和Linux发行版。总而言之: Get the Linux kernel source that matches your currently running kernel (eg, from the linux-source package, or kernel.org). Unpack the kernel source. cd tools/perf make Fix all errors, and most warnings, from (4). The first error may be that you are missing make, or a compiler (gcc). Once you have those, you may then see various warnings about missing libraries, which disable perf features. I’d install as many as possible, and take note of the ones you are missing. 第一个错误可能是您缺少make或编译器(gcc)。一旦有了这些，您可能会看到各种关于丢失库的警告，这些库会禁用perf特性。我会安装尽可能多的，并注意那些你没有安装的。 These perf build warnings are really helpful, and are generated by its Makefile. Here’s the makefile from 3.9.3: 这些perf构建警告非常有用，是由它的Makefile生成的。下面是来自3.9.3的makefile: # grep found Makefile msg := $(warning No libelf found, disables 'probe' tool, please install elfutils-libelf-devel/libelf-dev); msg := $(error No gnu/libc-version.h found, please install glibc-dev[el]/glibc-static); msg := $(warning No libdw.h found or old libdw.h found or elfutils is older than 0.138, disables dwarf support. Please install new elfutils-devel/libdw-dev); msg := $(warning No libunwind found, disabling post unwind support. Please install libunwind-dev[el] \u003e= 0.99); msg := $(warning No libaudit.h found, disables 'trace' tool, please install audit-libs-devel or libaudit-dev); msg := $(warning newt not found, disables TUI support. Please install newt-devel or libnewt-dev); msg := $(warning GTK2 not found, disables GTK2 support. Please install gtk2-devel or libgtk2.0-dev); $(if $(1),$(warning No $(1) was found)) msg := $(warning No bfd.h/libbfd found, install binutils-dev[el]/zlib-static to gain symbol demangling) msg := $(warning No numa.h found, disables 'perf bench numa mem' benchmark, please install numa-libs-devel or libnuma-dev); Take the time to read them. This list is likely to grow as new features are added to perf_events. 花点时间来阅读它们。随着perf_events添加新特性，这个列表很可能会增长。 The following notes show what I’ve specifically done for kernel versions and distributions, in case it is helpful. 下面的说明展示了我针对内核版本和发行版所做的具体操作，如果有帮助的话。 Packages: Ubuntu, 3.8.6 Packages required for key functionality: gcc make bison flex elfutils libelf-dev libdw-dev libaudit-dev. You may also consider python-dev (for python scripting) and binutils-dev (for symbol demangling), which are larger packages. 关键功能所需的包:gcc make bison flex elfutils libelf-dev libdwi -dev libaudit-dev。您还可以考虑python-dev(用于python脚本)和binutil-dev(用于符号拆分)，它们是更大的包。 Kernel Config: 3.8.6 Here are some kernel CONFIG options for perf_events functionality: 下面是perf_events功能的一些内核配置选项: # for perf_events: CONFIG_PERF_EVENTS=y # for stack traces: CONFIG_FRAME_POINTER=y # kernel symbols: CONFIG_KALLSYMS=y # tracepoints: CONFIG_TRACEPOINTS=y # kernel function trace: CONFIG_FTRACE=y # kernel-level dynamic tracing: CONFIG_KPROBES=y CONFIG_KPROBE_EVENTS=y # user-level dynamic tracing: CONFIG_UPROBES=y CONFIG_UPROBE_EVENTS=y # full kernel debug info: CONFIG_DEBUG_INFO=y # kernel lock tracing: CONFIG_LOCKDEP=y # kernel lock tracing: CONFIG_LOCK_STAT=y # kernel dynamic tracepoint variables: CONFIG_DEBUG_INFO=y You may need to build your own kernel to enable these. The exact set you need depends on your needs and kernel version, and list is likely to grow as new features are added to perf_events. 您可能需要构建自己的内核来启用这些功能。您需要的具体设置取决于您的需求和内核版本，随着perf_events添加新特性，列表可能会增长。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:10:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"10.1. Static Builds I’ve sometimes done this so that I have a single perf binary that can be copied into Docker containers for execution. Steps, given the Linux source: 我有时这样做，以便我有一个单一的perf二进制文件，可以复制到Docker容器中执行。Steps, given the Linux source: cd tools/perf vi Makefile.perf LDFLAGS=-static make clean; make ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:10:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"11. Troubleshooting If you see hexadecimal numbers instead of symbols, or have truncated stack traces, see the Prerequisites section. 如果您看到的是十六进制数字而不是符号，或已截断堆栈跟踪，请参阅先决条件部分。 Here are some rough notes from other issues I’ve encountered. 以下是我遇到的其他问题的一些梗概。 This sometimes works (3.5.7.2) and sometimes throws the following error (3.9.3): 这有时工作(3.5.7.2)，有时抛出以下错误(3.9.3): ubuntu# perf stat -e 'syscalls:sys_enter_*' -a sleep 5 Error: Too many events are opened. Try again after reducing the number of events. This can be fixed by increasing the file descriptor limit using ulimit -n. 这可以通过使用ulimit -n增加文件描述符限制来解决。 Type 3 errors: ubuntu# perf report 0xab7e48 [0x30]: failed to process type: 3 # ======== # captured on: Tue Jan 28 21:08:31 2014 # hostname : pgbackup # os release : 3.9.3-ubuntu-12-opt # perf version : 3.9.3 # arch : x86_64 # nrcpus online : 8 # nrcpus avail : 8 # cpudesc : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz # cpuid : GenuineIntel,6,45,7 # total memory : 8179104 kB # cmdline : /lib/modules/3.9.3-ubuntu-12-opt/build/tools/perf/perf record -e sched:sched_process_exec -a # event : name = sched:sched_process_exec, type = 2, config = 0x125, config1 = 0x0, config2 = 0x0, excl_usr = 0, excl_kern = 0, excl_host = 0, excl_guest = 1, precise_ip = 0 # HEADER_CPU_TOPOLOGY info available, use -I to display # HEADER_NUMA_TOPOLOGY info available, use -I to display # pmu mappings: software = 1, tracepoint = 2, breakpoint = 5 # ======== # Warning: Timestamp below last timeslice flush ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:11:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"12. Other Tools perf_events has the capabilities from many other tools rolled into one: strace(1), for tracing system calls, tcpdump(8), for tracing network packets, and blktrace(1), for tracing block device I/O (disk I/O), and other targets including file system and scheduler events. Tracing all events from one tool is not only convenient, it also allows direct correlations, including timestamps, between different instrumentation sources. Unlike these other tools, some assembly is required, which may not be for everyone (as explained in Audience). perf_events可以将许多其他工具的功能集成在一起:strace(1)用于跟踪系统调用，tcpdump(8)用于跟踪网络包，blktrace(1)用于跟踪块设备I/O(磁盘I/O)，以及其他目标，包括文件系统和调度器事件。跟踪来自一个工具的所有事件不仅方便，而且还允许不同检测源之间的直接关联，包括时间戳。与这些其他工具不同，需要进行一些组装，这可能不适用于每个人(就像在Audience解释的那样)。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:12:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"13. Resources Resources for further study. 用于进一步研究的资源。 ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:13:0","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"13.1. Posts I’ve been writing blog posts on specific perf_events topics. My suggested reading order is from oldest to newest (top down): 我一直在写关于特定perf_events主题的博客文章。我建议的阅读顺序是从老到新(自上而下): 22 Jun 2014: perf CPU Sampling 29 Jun 2014: perf Static Tracepoints 01 Jul 2014: perf Heat Maps 03 Jul 2014: perf Counting 10 Jul 2014: perf Hacktogram 11 Sep 2014: Linux perf Rides the Rocket: perf Kernel Line Tracing 17 Sep 2014: node.js Flame Graphs on Linux 26 Feb 2015: Linux perf_events Off-CPU Time Flame Graph 27 Feb 2015: Linux Profiling at Netflix 24 Jul 2015: Java Mixed-Mode Flame Graphs (PDF) 30 Apr 2016: Linux 4.5 perf folded format And posts on ftrace: 和关于ftrace的文章 13 Jul 2014: Linux ftrace Function Counting 16 Jul 2014: iosnoop for Linux 23 Jul 2014: Linux iosnoop Latency Heat Maps 25 Jul 2014: opensnoop for Linux 28 Jul 2014: execsnoop for Linux: See Short-Lived Processes 30 Aug 2014: ftrace: The Hidden Light Switch 06 Sep 2014: tcpretrans: Tracing TCP retransmits 31 Dec 2014: Linux Page Cache Hit Ratio 28 Jun 2015: uprobe: User-Level Dynamic Tracing 03 Jul 2015: Hacking Linux USDT ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:13:1","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["Linux"],"content":"13.2. Links perf_events: perf-tools (github), a collection of my performance analysis tools based on Linux perf_events and ftrace. perf Main Page. The excellent perf Tutorial, which focuses more on CPU hardware counters. The Unofficial Linux Perf Events Web-Page by Vince Weaver. The perf user mailing list. Mischa Jonker’s presentation Fighting latency: How to optimize your system using perf (PDF) (2013). The OMG SO PERF T-shirt (site has coarse language). Shannon Cepeda’s great posts on pipeline speak: frontend and backend. Jiri Olsa’s dwarf mode callchain patch. Linux kernel source: tools/perf/Documentation/examples.txt. Linux kernel source: tools/perf/Documentation/perf-record.txt. … and other documentation under tools/perf/Documentation. A good case study for Transparent Hugepages: measuring the performance impact using perf and PMCs. Julia Evans created a perf cheatsheet based on my one-liners (2017). ftrace: perf-tools (github), a collection of my performance analysis tools based on Linux perf_events and ftrace. Ftrace: The hidden light switch, by myself for lwn.net, Aug 2014. Linux kernel source: Documentation/trace/ftrace.txt. lwn.net Secrets of the Ftrace function tracer, by Steven Rostedt, Jan 2010. lwn.net Debugging the kernel using Ftrace - part 1, by Steven Rostedt, Dec 2009. lwn.net Debugging the kernel using Ftrace - part 2, by Steven Rostedt, Dec 2009. ","date":"2020-06-18","objectID":"/posts/linux/profiling/brendangregg/01_perf_example/:13:2","tags":["profiling"],"title":"[译]perf Examples","uri":"/posts/linux/profiling/brendangregg/01_perf_example/"},{"categories":["loveit"],"content":"LoveIt 主题在 Hugo 内置的 shortcode 的基础上提供多个扩展的 shortcode.","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"LoveIt 主题在 Hugo 内置的 shortcode 的基础上提供多个扩展的 shortcode. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:0:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"1 style 注意 Hugo extended 版本对于 style shortcode 是必需的. style shortcode 用来在你的文章中插入自定义样式. style shortcode 有两个位置参数. 第一个参数是自定义样式的内容. 它支持  SASS 中的嵌套语法, 并且 \u0026 指代这个父元素. 第二个参数是包裹你要更改样式的内容的 HTML 标签, 默认值是 div. 一个 style 示例: {{\u003c style \"text-align:right; strong{color:#00b1ff;}\" \u003e}} This is a **right-aligned** paragraph. {{\u003c /style \u003e}} 呈现的输出效果如下: This is a right-aligned paragraph. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:1:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"2 link link shortcode 是 Markdown 链接语法 的替代. link shortcode 可以提供一些其它的功能并且可以在代码块中使用. 支持本地资源引用的完整用法. link shortcode 有以下命名参数: href [必需] (第一个位置参数) 链接的目标. content [可选] (第二个位置参数) 链接的内容, 默认值是 href 参数的值. 支持 Markdown 或者 HTML 格式. title [可选] (第三个位置参数) HTML a 标签 的 title 属性, 当悬停在链接上会显示的提示. rel [可选] HTML a 标签 的 rel 补充属性. class [可选] HTML a 标签 的 class 属性. 一个 link 示例: {{\u003c link \"https://assemble.io\" \u003e}} 或者 {{\u003c link href=\"https://assemble.io\" \u003e}} {{\u003c link \"mailto:contact@revolunet.com\" \u003e}} 或者 {{\u003c link href=\"mailto:contact@revolunet.com\" \u003e}} {{\u003c link \"https://assemble.io\" Assemble \u003e}} 或者 {{\u003c link href=\"https://assemble.io\" content=Assemble \u003e}} 呈现的输出效果如下: https://assemble.io mailto:contact@revolunet.com Assemble 一个带有标题的 link 示例: {{\u003c link \"https://github.com/upstage/\" Upstage \"Visit Upstage!\" \u003e}} 或者 {{\u003c link href=\"https://github.com/upstage/\" content=Upstage title=\"Visit Upstage!\" \u003e}} 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:2:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"3 image image shortcode 是 figure shortcode 的替代. image shortcode 可以充分利用 lazysizes 和 lightgallery.js 两个依赖库. 支持本地资源引用的完整用法. image shortcode 有以下命名参数: src [必需] (第一个位置参数) 图片的 URL. alt [可选] (第二个位置参数) 图片无法显示时的替代文本, 默认值是 src 参数的值. 支持 Markdown 或者 HTML 格式. caption [可选] (第三个位置参数) 图片标题. 支持 Markdown 或者 HTML 格式. title [可选] 当悬停在图片上会显示的提示. class [可选] HTML figure 标签的 class 属性. src_s [可选] 图片缩略图的 URL, 用在画廊模式中, 默认值是 src 参数的值. src_l [可选] 高清图片的 URL, 用在画廊模式中, 默认值是 src 参数的值. height [可选] 图片的 height 属性. width [可选] 图片的 width 属性. linked [可选] 图片是否需要被链接, 默认值是 true. rel [可选] HTML a 标签 的 rel 补充属性, 仅在 linked 属性设置成 true 时有效. 一个 image 示例: {{\u003c image src=\"/images/hugo/lighthouse.jpg\" caption=\"Lighthouse (`image`)\" src_s=\"/images/hugo/lighthouse-small.jpg\" src_l=\"/images/hugo/lighthouse-large.jpg\" \u003e}} 呈现的输出效果如下: Lighthouse (image) ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:3:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"4 admonition admonition shortcode 支持 12 种 帮助你在页面中插入提示的横幅. 支持 Markdown 或者 HTML 格式. 注意 一个 注意 横幅 摘要 一个 摘要 横幅 信息 一个 信息 横幅 技巧 一个 技巧 横幅 成功 一个 成功 横幅 问题 一个 问题 横幅 警告 一个 警告 横幅 失败 一个 失败 横幅 危险 一个 危险 横幅 Bug 一个 Bug 横幅 示例 一个 示例 横幅 引用 一个 引用 横幅 admonition shortcode 有以下命名参数: type [必需] (第一个位置参数) admonition 横幅的类型, 默认值是 note. title [可选] (第二个位置参数) admonition 横幅的标题, 默认值是 type 参数的值. open [可选] (第三个位置参数) 横幅内容是否默认展开, 默认值是 true. 一个 admonition 示例: {{\u003c admonition type=tip title=\"This is a tip\" open=false \u003e}} 一个 **技巧** 横幅 {{\u003c /admonition \u003e}} 或者 {{\u003c admonition tip \"This is a tip\" false \u003e}} 一个 **技巧** 横幅 {{\u003c /admonition \u003e}} 呈现的输出效果如下: This is a tip 一个 技巧 横幅 ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:4:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5 mermaid mermaid 是一个可以帮助你在文章中生成图表和流程图的库, 类似 Markdown 的语法. 只需将你的 mermaid 代码插入 mermaid shortcode 中即可. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.1 流程图 一个 流程图 mermaid 示例: {{\u003c mermaid \u003e}} graph LR; A[Hard edge] --\u003e|Link text| B(Round edge) B --\u003e C{Decision} C --\u003e|One| D[Result one] C --\u003e|Two| E[Result two] {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:1","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.2 时序图 一个 时序图 mermaid 示例: {{\u003c mermaid \u003e}} sequenceDiagram participant Alice participant Bob Alice-\u003e\u003eJohn: Hello John, how are you? loop Healthcheck John-\u003eJohn: Fight against hypochondria end Note right of John: Rational thoughts \u003cbr/\u003eprevail... John--\u003eAlice: Great! John-\u003eBob: How about you? Bob--\u003eJohn: Jolly good! {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:2","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.3 甘特图 一个 甘特图 mermaid 示例: {{\u003c mermaid \u003e}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:3","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.4 类图 一个 类图 mermaid 示例: {{\u003c mermaid \u003e}} classDiagram Class01 \u003c|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u003e C2 : Where am i? Class09 --* C3 Class09 --|\u003e Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u003c--\u003e C2: Cool label {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:4","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.5 状态图 一个 状态图 mermaid 示例: {{\u003c mermaid \u003e}} stateDiagram [*] --\u003e Still Still --\u003e [*] Still --\u003e Moving Moving --\u003e Still Moving --\u003e Crash Crash --\u003e [*] {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:5","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.6 Git 图 一个 Git 图 mermaid 示例: {{\u003c mermaid \u003e}} gitGraph: options { \"nodeSpacing\": 100, \"nodeRadius\": 10 } end commit branch newbranch checkout newbranch commit commit checkout master commit commit merge newbranch {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:6","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"5.7 饼图 一个 饼图 mermaid 示例: {{\u003c mermaid \u003e}} pie \"Dogs\" : 386 \"Cats\" : 85 \"Rats\" : 15 {{\u003c /mermaid \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:5:7","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"6 echarts ECharts 是一个帮助你生成交互式数据可视化的库. ECharts 提供了常规的 折线图, 柱状图, 散点图, 饼图, K线图, 用于统计的 盒形图, 用于地理数据可视化的 地图, 热力图, 线图, 用于关系数据可视化的 关系图, treemap, 旭日图, 多维数据可视化的 平行坐标, 还有用于 BI 的 漏斗图, 仪表盘, 并且支持图与图之间的混搭. 只需在 echarts shortcode 中以 JSON/YAML/TOML格式插入 ECharts 选项即可. 一个 JSON 格式的 echarts 示例: {{\u003c echarts \u003e}} { \"title\": { \"text\": \"折线统计图\", \"top\": \"2%\", \"left\": \"center\" }, \"tooltip\": { \"trigger\": \"axis\" }, \"legend\": { \"data\": [\"邮件营销\", \"联盟广告\", \"视频广告\", \"直接访问\", \"搜索引擎\"], \"top\": \"10%\" }, \"grid\": { \"left\": \"5%\", \"right\": \"5%\", \"bottom\": \"5%\", \"top\": \"20%\", \"containLabel\": true }, \"toolbox\": { \"feature\": { \"saveAsImage\": { \"title\": \"保存为图片\" } } }, \"xAxis\": { \"type\": \"category\", \"boundaryGap\": false, \"data\": [\"周一\", \"周二\", \"周三\", \"周四\", \"周五\", \"周六\", \"周日\"] }, \"yAxis\": { \"type\": \"value\" }, \"series\": [ { \"name\": \"邮件营销\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [120, 132, 101, 134, 90, 230, 210] }, { \"name\": \"联盟广告\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [220, 182, 191, 234, 290, 330, 310] }, { \"name\": \"视频广告\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [150, 232, 201, 154, 190, 330, 410] }, { \"name\": \"直接访问\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [320, 332, 301, 334, 390, 330, 320] }, { \"name\": \"搜索引擎\", \"type\": \"line\", \"stack\": \"总量\", \"data\": [820, 932, 901, 934, 1290, 1330, 1320] } ] } {{\u003c /echarts \u003e}} 一个 YAML 格式的 echarts 示例: {{\u003c echarts \u003e}} title: text: 折线统计图 top: 2% left: center tooltip: trigger: axis legend: data: - 邮件营销 - 联盟广告 - 视频广告 - 直接访问 - 搜索引擎 top: 10% grid: left: 5% right: 5% bottom: 5% top: 20% containLabel: true toolbox: feature: saveAsImage: title: 保存为图片 xAxis: type: category boundaryGap: false data: - 周一 - 周二 - 周三 - 周四 - 周五 - 周六 - 周日 yAxis: type: value series: - name: 邮件营销 type: line stack: 总量 data: - 120 - 132 - 101 - 134 - 90 - 230 - 210 - name: 联盟广告 type: line stack: 总量 data: - 220 - 182 - 191 - 234 - 290 - 330 - 310 - name: 视频广告 type: line stack: 总量 data: - 150 - 232 - 201 - 154 - 190 - 330 - 410 - name: 直接访问 type: line stack: 总量 data: - 320 - 332 - 301 - 334 - 390 - 330 - 320 - name: 搜索引擎 type: line stack: 总量 data: - 820 - 932 - 901 - 934 - 1290 - 1330 - 1320 {{\u003c /echarts \u003e}} 一个 TOML 格式的 echarts 示例: {{\u003c echarts \u003e}} [title] text = \"折线统计图\" top = \"2%\" left = \"center\" [tooltip] trigger = \"axis\" [legend] data = [ \"邮件营销\", \"联盟广告\", \"视频广告\", \"直接访问\", \"搜索引擎\" ] top = \"10%\" [grid] left = \"5%\" right = \"5%\" bottom = \"5%\" top = \"20%\" containLabel = true [toolbox] [toolbox.feature] [toolbox.feature.saveAsImage] title = \"保存为图片\" [xAxis] type = \"category\" boundaryGap = false data = [ \"周一\", \"周二\", \"周三\", \"周四\", \"周五\", \"周六\", \"周日\" ] [yAxis] type = \"value\" [[series]] name = \"邮件营销\" type = \"line\" stack = \"总量\" data = [ 120.0, 132.0, 101.0, 134.0, 90.0, 230.0, 210.0 ] [[series]] name = \"联盟广告\" type = \"line\" stack = \"总量\" data = [ 220.0, 182.0, 191.0, 234.0, 290.0, 330.0, 310.0 ] [[series]] name = \"视频广告\" type = \"line\" stack = \"总量\" data = [ 150.0, 232.0, 201.0, 154.0, 190.0, 330.0, 410.0 ] [[series]] name = \"直接访问\" type = \"line\" stack = \"总量\" data = [ 320.0, 332.0, 301.0, 334.0, 390.0, 330.0, 320.0 ] [[series]] name = \"搜索引擎\" type = \"line\" stack = \"总量\" data = [ 820.0, 932.0, 901.0, 934.0, 1290.0, 1330.0, 1320.0 ] {{\u003c /echarts \u003e}} 呈现的输出效果如下: echarts shortcode 还有以下命名参数: width [可选] (第一个位置参数) 数据可视化的宽度, 默认值是 100%. height [可选] (第二个位置参数) 数据可视化的高度, 默认值是 30rem. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:6:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"7 mapbox Mapbox GL JS 是一个 JavaScript 库，它使用 WebGL, 以 vector tiles 和 Mapbox styles 为来源, 将它们渲染成互动式地图. mapbox shortcode 有以下命名参数来使用 Mapbox GL JS: lng [必需] (第一个位置参数) 地图初始中心点的经度, 以度为单位. lat [必需] (第二个位置参数) 地图初始中心点的纬度, 以度为单位. zoom [可选] (第三个位置参数) 地图的初始缩放级别, 默认值是 10. marked [可选] (第四个位置参数) 是否在地图的初始中心点添加图钉, 默认值是 true. light-style [可选] (第五个位置参数) 浅色主题的地图样式, 默认值是前置参数或者网站配置中设置的值. dark-style [可选] (第六个位置参数) 深色主题的地图样式, 默认值是前置参数或者网站配置中设置的值. navigation [可选] 是否添加 NavigationControl, 默认值是前置参数或者网站配置中设置的值. geolocate [可选] 是否添加 GeolocateControl, 默认值是前置参数或者网站配置中设置的值. scale [可选] 是否添加 ScaleControl, 默认值是前置参数或者网站配置中设置的值. fullscreen [可选] 是否添加 FullscreenControl, 默认值是前置参数或者网站配置中设置的值. width [可选] 地图的宽度, 默认值是 100%. height [可选] 地图的高度, 默认值是 20rem. 一个简单的 mapbox 示例: {{\u003c mapbox 121.485 31.233 12 \u003e}} 或者 {{\u003c mapbox lng=121.485 lat=31.233 zoom=12 \u003e}} 呈现的输出效果如下: 一个带有自定义样式的 mapbox 示例: {{\u003c mapbox -122.252 37.453 10 false \"mapbox://styles/mapbox/streets-zh-v1\" \u003e}} 或者 {{\u003c mapbox lng=-122.252 lat=37.453 zoom=10 marked=false light-style=\"mapbox://styles/mapbox/streets-zh-v1\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:7:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"8 music music shortcode 基于 APlayer 和 MetingJS 提供了一个内嵌的响应式音乐播放器. 有三种方式使用 music shortcode. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:8:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"8.1 自定义音乐 URL 支持本地资源引用的完整用法. music shortcode 有以下命名参数来使用自定义音乐 URL: server [必需] 音乐的链接. type [可选] 音乐的名称. artist [可选] 音乐的创作者. cover [可选] 音乐的封面链接. 一个使用自定义音乐 URL 的 music 示例: {{\u003c music url=\"/music/Wavelength.mp3\" name=Wavelength artist=oldmanyoung cover=\"/images/hugo/Wavelength.jpg\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:8:1","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"8.2 音乐平台 URL 的自动识别 music shortcode 有一个命名参数来使用音乐平台 URL 的自动识别: auto [必需]] (第一个位置参数) 用来自动识别的音乐平台 URL, 支持 netease, tencent 和 xiami 平台. 一个使用音乐平台 URL 的自动识别的 music 示例: {{\u003c music auto=\"https://music.163.com/#/playlist?id=60198\" \u003e}} 或者 {{\u003c music \"https://music.163.com/#/playlist?id=60198\" \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:8:2","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"8.3 自定义音乐平台, 类型和 ID music shortcode 有以下命名参数来使用自定义音乐平台: server [必需] (第一个位置参数) [netease, tencent, kugou, xiami, baidu] 音乐平台. type [必需] (第二个位置参数) [song, playlist, album, search, artist] 音乐类型. id [必需] (第三个位置参数) 歌曲 ID, 或者播放列表 ID, 或者专辑 ID, 或者搜索关键词, 或者创作者 ID. 一个使用自定义音乐平台的 music 示例: {{\u003c music server=\"netease\" type=\"song\" id=\"1868553\" \u003e}} 或者 {{\u003c music netease song 1868553 \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:8:3","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"8.4 其它参数 music shortcode 有一些可以应用于以上三种方式的其它命名参数: theme [可选] 音乐播放器的主题色, 默认值是 #448aff. fixed [可选] 是否开启固定模式, 默认值是 false. mini [可选] 是否开启迷你模式, 默认值是 false. autoplay [可选] 是否自动播放音乐, 默认值是 false. volume [可选] 第一次打开播放器时的默认音量, 会被保存在浏览器缓存中, 默认值是 0.7. mutex [可选] 是否自动暂停其它播放器, 默认值是 true. music shortcode 还有一些只适用于音乐列表方式的其它命名参数: loop [可选] [all, one, none] 音乐列表的循环模式, 默认值是 none. order [可选] [list, random] 音乐列表的播放顺序, 默认值是 list. list-folded [可选] 初次打开的时候音乐列表是否折叠, 默认值是 false. list-max-height [可选] 音乐列表的最大高度, 默认值是 340px. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:8:4","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"9 bilibili bilibili shortcode 提供了一个内嵌的用来播放 bilibili 视频的响应式播放器. 如果视频只有一个部分, 则仅需要视频的 BV id, 例如: https://www.bilibili.com/video/BV1Sx411T7QQ 一个 bilibili 示例: {{\u003c bilibili BV1Sx411T7QQ \u003e}} 或者 {{\u003c bilibili id=BV1Sx411T7QQ \u003e}} 呈现的输出效果如下: 如果视频包含多个部分, 则除了视频的 BV id 之外, 还需要 p, 默认值为 1, 例如: https://www.bilibili.com/video/BV1TJ411C7An?p=3 一个带有 p 参数的 bilibili 示例: {{\u003c bilibili BV1TJ411C7An 3 \u003e}} 或者 {{\u003c bilibili id=BV1TJ411C7An p=3 \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:9:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"10 typeit typeit shortcode 基于 TypeIt 提供了打字动画. 只需将你需要打字动画的内容插入 typeit shortcode 中即可. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:10:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"10.1 简单内容 允许使用 Markdown 格式的简单内容, 并且 不包含 富文本的块内容, 例如图像等等… 一个 typeit 示例: {{\u003c typeit \u003e}} 这一个带有基于 [TypeIt](https://typeitjs.com/) 的 **打字动画** 的 *段落*... {{\u003c /typeit \u003e}} 呈现的输出效果如下: 另外, 你也可以自定义 HTML 标签. 一个带有 h4 标签的 typeit 示例: {{\u003c typeit tag=h4 \u003e}} 这一个带有基于 [TypeIt](https://typeitjs.com/) 的 **打字动画** 的 *段落*... {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:10:1","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"10.2 代码内容 代码内容也是允许的, 并且通过使用参数 code 指定语言类型可以实习语法高亮. 一个带有 code 参数的 typeit 示例: {{\u003c typeit code=java \u003e}} public class HelloWorld { public static void main(String []args) { System.out.println(\"Hello World\"); } } {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:10:2","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"10.3 分组内容 默认情况下, 所有打字动画都是同时开始的. 但是有时你可能需要按顺序开始一组 typeit 内容的打字动画. 一组具有相同 group 参数值的 typeit 内容将按顺序开始打字动画. 一个带有 group 参数的 typeit 示例: {{\u003c typeit group=paragraph \u003e}} **首先**, 这个段落开始 {{\u003c /typeit \u003e}} {{\u003c typeit group=paragraph \u003e}} **然后**, 这个段落开始 {{\u003c /typeit \u003e}} 呈现的输出效果如下: ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:10:3","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"11 script script shortcode 用来在你的文章中插入  Javascript 脚本. 注意 脚本内容可以保证在所有的第三方库加载之后按顺序执行. 所以你可以自由地使用第三方库. 一个 script 示例: {{\u003c script \u003e}} console.log('Hello LoveIt!'); {{\u003c /script \u003e}} 你可以在开发者工具的控制台中看到输出. ","date":"2020-03-03","objectID":"/posts/hugo/loveit_extend_shortcodes/:11:0","tags":["loveit"],"title":"Loveit 扩展 Shortcodes","uri":"/posts/hugo/loveit_extend_shortcodes/"},{"categories":["loveit"],"content":"这篇文章展示了基本的 Markdown 语法和格式.","date":"2019-12-01","objectID":"/posts/hugo/markdown/","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"这篇文章提供了可以在 Hugo 的文章中使用的基本 Markdown 语法示例. 注意 这篇文章借鉴了一篇很棒的来自 Grav 的文章. 如果你想了解 Loveit 主题的扩展 Markdown 语法, 请阅读扩展 Markdown 语法页面. 事实上, 编写 Web 内容很麻烦. WYSIWYG所见即所得 编辑器帮助减轻了这一任务. 但通常会导致代码太糟, 或更糟糕的是, 网页也会很丑. 没有通常伴随的所有复杂和丑陋的问题, Markdown 是一种更好的生成 HTML 内容的方式. 一些主要好处是: Markdown 简单易学, 几乎没有多余的字符, 因此编写内容也更快. 用 Markdown 书写时出错的机会更少. 可以产生有效的 XHTML 输出. 将内容和视觉显示保持分开, 这样就不会打乱网站的外观. 可以在你喜欢的任何文本编辑器或 Markdown 应用程序中编写内容. Markdown 使用起来很有趣! John Gruber, Markdown 的作者如是说: Markdown 格式的首要设计目标是更具可读性. 最初的想法是 Markdown 格式的文档应当以纯文本形式发布, 而不会看起来像被标签或格式说明所标记. 虽然 Markdown 的语法受到几种现有的文本到 HTML 转换工具的影响, 但 Markdown 语法的最大灵感来源是纯文本电子邮件的格式. – John Gruber 话不多说, 我们来回顾一下 Markdown 的主要语法以及生成的 HTML 样式! 技巧  将此页保存为书签，以备将来参考! ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:0:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"1 标题 从 h2 到 h6 的标题在每个级别上都加上一个 ＃: ## h2 标题 ### h3 标题 #### h4 标题 ##### h5 标题 ###### h6 标题 输出的 HTML 看起来像这样: \u003ch2\u003eh2 标题\u003c/h2\u003e \u003ch3\u003eh3 标题\u003c/h3\u003e \u003ch4\u003eh4 标题\u003c/h4\u003e \u003ch5\u003eh5 标题\u003c/h5\u003e \u003ch6\u003eh6 标题\u003c/h6\u003e 标题 ID 要添加自定义标题 ID, 请在与标题相同的行中将自定义 ID 放在花括号中: ### 一个很棒的标题 {#custom-id} 输出的 HTML 看起来像这样: \u003ch3 id=\"custom-id\"\u003e一个很棒的标题\u003c/h3\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:1:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"2 注释 注释是和 HTML 兼容的： \u003c!-- 这是一段注释 --\u003e 不能看到以下的注释: ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:2:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"3 水平线 HTML 中的 \u003chr\u003e 标签是用来在段落元素之间创建一个 “专题间隔” 的. 使用 Markdown, 你可以用以下方式创建一个 \u003chr\u003e 标签: ___: 三个连续的下划线 ---: 三个连续的破折号 ***: 三个连续的星号 呈现的输出效果如下: ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:3:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"4 段落 按照纯文本的方式书写段落, 纯文本在呈现的 HTML 中将用 \u003cp\u003e/\u003c/p\u003e 标签包裹. 如下段落: Lorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad. 输出的 HTML 看起来像这样: \u003cp\u003eLorem ipsum dolor sit amet, graecis denique ei vel, at duo primis mandamus. Et legere ocurreret pri, animal tacimates complectitur ad cum. Cu eum inermis inimicus efficiendi. Labore officiis his ex, soluta officiis concludaturque ei qui, vide sensibus vim ad.\u003c/p\u003e 可以使用一个空白行进行换行. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:4:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"5 内联 HTML 元素 如果你需要某个 HTML 标签 (带有一个类), 则可以简单地像这样使用: Markdown 格式的段落. \u003cdiv class=\"class\"\u003e 这是 \u003cb\u003eHTML\u003c/b\u003e \u003c/div\u003e Markdown 格式的段落. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:5:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"6 强调 ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:6:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"加粗 用于强调带有较粗字体的文本片段. 以下文本片段会被 渲染为粗体. **渲染为粗体** __渲染为粗体__ 输出的 HTML 看起来像这样: \u003cstrong\u003e渲染为粗体\u003c/strong\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:6:1","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"斜体 用于强调带有斜体的文本片段. 以下文本片段被 渲染为斜体. *渲染为斜体* _渲染为斜体_ 输出的 HTML 看起来像这样: \u003cem\u003e渲染为斜体\u003c/em\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:6:2","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"删除线 按照 GFMGitHub flavored Markdown 你可以使用删除线. ~~这段文本带有删除线.~~ 呈现的输出效果如下: 这段文本带有删除线. 输出的 HTML 看起来像这样: \u003cdel\u003e这段文本带有删除线.\u003c/del\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:6:3","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"组合 加粗, 斜体, 和删除线可以 组合使用. ***加粗和斜体*** ~~**删除线和加粗**~~ ~~*删除线和斜体*~~ ~~***加粗, 斜体和删除线***~~ 呈现的输出效果如下: 加粗和斜体 删除线和加粗 删除线和斜体 加粗, 斜体和删除线 输出的 HTML 看起来像这样: \u003cem\u003e\u003cstrong\u003e加粗和斜体\u003c/strong\u003e\u003c/em\u003e \u003cdel\u003e\u003cstrong\u003e删除线和加粗\u003c/strong\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e删除线和斜体\u003c/em\u003e\u003c/del\u003e \u003cdel\u003e\u003cem\u003e\u003cstrong\u003e加粗, 斜体和删除线\u003c/strong\u003e\u003c/em\u003e\u003c/del\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:6:4","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"7 引用 用于在文档中引用其他来源的内容块. 在要引用的任何文本之前添加 \u003e: \u003e **Fusion Drive** combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 呈现的输出效果如下: Fusion Drive combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. 输出的 HTML 看起来像这样: \u003cblockquote\u003e \u003cp\u003e \u003cstrong\u003eFusion Drive\u003c/strong\u003e combines a hard drive with a flash storage (solid-state drive) and presents it as a single logical volume with the space of both drives combined. \u003c/p\u003e \u003c/blockquote\u003e 引用也可以嵌套: \u003e Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. \u003e\u003e Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. 呈现的输出效果如下: Donec massa lacus, ultricies a ullamcorper in, fermentum sed augue. Nunc augue augue, aliquam non hendrerit ac, commodo vel nisi. Sed adipiscing elit vitae augue consectetur a gravida nunc vehicula. Donec auctor odio non est accumsan facilisis. Aliquam id turpis in dolor tincidunt mollis ac eu diam. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:7:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"8 列表 ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:8:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"无序列表 一系列项的列表, 其中项的顺序没有明显关系. 你可以使用以下任何符号来表示无序列表中的项: * 一项内容 - 一项内容 + 一项内容 例如: * Lorem ipsum dolor sit amet * Consectetur adipiscing elit * Integer molestie lorem at massa * Facilisis in pretium nisl aliquet * Nulla volutpat aliquam velit * Phasellus iaculis neque * Purus sodales ultricies * Vestibulum laoreet porttitor sem * Ac tristique libero volutpat at * Faucibus porta lacus fringilla vel * Aenean sit amet erat nunc * Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Phasellus iaculis neque Purus sodales ultricies Vestibulum laoreet porttitor sem Ac tristique libero volutpat at Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003cul\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit \u003cul\u003e \u003cli\u003ePhasellus iaculis neque\u003c/li\u003e \u003cli\u003ePurus sodales ultricies\u003c/li\u003e \u003cli\u003eVestibulum laoreet porttitor sem\u003c/li\u003e \u003cli\u003eAc tristique libero volutpat at\u003c/li\u003e \u003c/ul\u003e \u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ul\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:8:1","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"有序列表 一系列项的列表, 其中项的顺序确实很重要. 1. Lorem ipsum dolor sit amet 2. Consectetur adipiscing elit 3. Integer molestie lorem at massa 4. Facilisis in pretium nisl aliquet 5. Nulla volutpat aliquam velit 6. Faucibus porta lacus fringilla vel 7. Aenean sit amet erat nunc 8. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem 输出的 HTML 看起来像这样: \u003col\u003e \u003cli\u003eLorem ipsum dolor sit amet\u003c/li\u003e \u003cli\u003eConsectetur adipiscing elit\u003c/li\u003e \u003cli\u003eInteger molestie lorem at massa\u003c/li\u003e \u003cli\u003eFacilisis in pretium nisl aliquet\u003c/li\u003e \u003cli\u003eNulla volutpat aliquam velit\u003c/li\u003e \u003cli\u003eFaucibus porta lacus fringilla vel\u003c/li\u003e \u003cli\u003eAenean sit amet erat nunc\u003c/li\u003e \u003cli\u003eEget porttitor lorem\u003c/li\u003e \u003c/ol\u003e 技巧 如果你对每一项使用 1., Markdown 将自动为每一项编号. 例如: 1. Lorem ipsum dolor sit amet 1. Consectetur adipiscing elit 1. Integer molestie lorem at massa 1. Facilisis in pretium nisl aliquet 1. Nulla volutpat aliquam velit 1. Faucibus porta lacus fringilla vel 1. Aenean sit amet erat nunc 1. Eget porttitor lorem 呈现的输出效果如下: Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Faucibus porta lacus fringilla vel Aenean sit amet erat nunc Eget porttitor lorem ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:8:2","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"任务列表 任务列表使你可以创建带有复选框的列表. 要创建任务列表, 请在任务列表项之前添加破折号 (-) 和带有空格的方括号 ([ ]). 要选择一个复选框，请在方括号之间添加 x ([x]). - [x] Write the press release - [ ] Update the website - [ ] Contact the media 呈现的输出效果如下: Write the press release Update the website Contact the media ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:8:3","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"9 代码 ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:9:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"行内代码 用 ` 包装行内代码段. 在这个例子中, `\u003csection\u003e\u003c/section\u003e` 会被包裹成 **代码**. 呈现的输出效果如下: 在这个例子中, \u003csection\u003e\u003c/section\u003e 会被包裹成 代码. 输出的 HTML 看起来像这样: \u003cp\u003e 在这个例子中, \u003ccode\u003e\u0026lt;section\u0026gt;\u0026lt;/section\u0026gt;\u003c/code\u003e 会被包裹成 \u003cstrong\u003e代码\u003c/strong\u003e. \u003c/p\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:9:1","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"缩进代码 将几行代码缩进至少四个空格，例如: // Some comments line 1 of code line 2 of code line 3 of code 呈现的输出效果如下: // Some comments line 1 of code line 2 of code line 3 of code 输出的 HTML 看起来像这样: \u003cpre\u003e \u003ccode\u003e // Some comments line 1 of code line 2 of code line 3 of code \u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:9:2","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"围栏代码块 使用 “围栏” ``` 来生成一段带有语言属性的代码块. ```markdown Sample text here... ``` 输出的 HTML 看起来像这样: \u003cpre language-html\u003e \u003ccode\u003eSample text here...\u003c/code\u003e \u003c/pre\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:9:3","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"语法高亮 GFMGitHub Flavored Markdown 也支持语法高亮. 要激活它，只需在第一个代码 “围栏” 之后直接添加你要使用的语言的文件扩展名, ```js, 语法高亮显示将自动应用于渲染的 HTML 中. 例如, 在以下 JavaScript 代码中应用语法高亮: ```js grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; ``` 呈现的输出效果如下: grunt.initConfig({ assemble: { options: { assets: 'docs/assets', data: 'src/data/*.{json,yml}', helpers: 'src/custom-helpers.js', partials: ['src/partials/**/*.{hbs,md}'] }, pages: { options: { layout: 'default.hbs' }, files: { './': ['src/templates/pages/index.hbs'] } } } }; 注意 Hugo 文档中的 语法高亮页面 介绍了有关语法高亮的更多信息, 包括语法高亮的 shortcode. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:9:4","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"10 表格 通过在每个单元格之间添加竖线作为分隔线, 并在标题下添加一行破折号 (也由竖线分隔) 来创建表格. 注意, 竖线不需要垂直对齐. | Option | Description | | ------ | ----------- | | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. 输出的 HTML 看起来像这样: \u003ctable\u003e \u003cthead\u003e \u003ctr\u003e \u003cth\u003eOption\u003c/th\u003e \u003cth\u003eDescription\u003c/th\u003e \u003c/tr\u003e \u003c/thead\u003e \u003ctbody\u003e \u003ctr\u003e \u003ctd\u003edata\u003c/td\u003e \u003ctd\u003epath to data files to supply the data that will be passed into templates.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eengine\u003c/td\u003e \u003ctd\u003eengine to be used for processing templates. Handlebars is the default.\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003eext\u003c/td\u003e \u003ctd\u003eextension to be used for dest files.\u003c/td\u003e \u003c/tr\u003e \u003c/tbody\u003e \u003c/table\u003e 文本右对齐或居中对齐 在任何标题下方的破折号右侧添加冒号将使该列的文本右对齐. 在任何标题下方的破折号两边添加冒号将使该列的对齐文本居中. | Option | Description | |:------:| -----------:| | data | path to data files to supply the data that will be passed into templates. | | engine | engine to be used for processing templates. Handlebars is the default. | | ext | extension to be used for dest files. | 呈现的输出效果如下: Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:10:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"11 链接 ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:11:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"基本链接 \u003chttps://assemble.io\u003e \u003ccontact@revolunet.com\u003e [Assemble](https://assemble.io) 呈现的输出效果如下 (将鼠标悬停在链接上，没有提示): https://assemble.io contact@revolunet.com Assemble 输出的 HTML 看起来像这样: \u003ca href=\"https://assemble.io\"\u003ehttps://assemble.io\u003c/a\u003e \u003ca href=\"mailto:contact@revolunet.com\"\u003econtact@revolunet.com\u003c/a\u003e \u003ca href=\"https://assemble.io\"\u003eAssemble\u003c/a\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:11:1","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"添加一个标题 [Upstage](https://github.com/upstage/ \"Visit Upstage!\") 呈现的输出效果如下 (将鼠标悬停在链接上，会有一行提示): Upstage 输出的 HTML 看起来像这样: \u003ca href=\"https://github.com/upstage/\" title=\"Visit Upstage!\"\u003eUpstage\u003c/a\u003e ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:11:2","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"定位标记 定位标记使你可以跳至同一页面上的指定锚点. 例如, 每个章节: ## Table of Contents * [Chapter 1](#chapter-1) * [Chapter 2](#chapter-2) * [Chapter 3](#chapter-3) 将跳转到这些部分: ## Chapter 1 \u003ca id=\"chapter-1\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 2 \u003ca id=\"chapter-2\"\u003e\u003c/a\u003e Content for chapter one. ## Chapter 3 \u003ca id=\"chapter-3\"\u003e\u003c/a\u003e Content for chapter one. 注意 定位标记的位置几乎是任意的. 因为它们并不引人注目, 所以它们通常被放在同一行了. ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:11:3","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"12 脚注 脚注使你可以添加注释和参考, 而不会使文档正文混乱. 当你创建脚注时, 会在添加脚注引用的位置出现带有链接的上标编号. 读者可以单击链接以跳至页面底部的脚注内容. 要创建脚注引用, 请在方括号中添加插入符号和标识符 ([^1]). 标识符可以是数字或单词, 但不能包含空格或制表符. 标识符仅将脚注引用与脚注本身相关联 - 在脚注输出中, 脚注按顺序编号. 在中括号内使用插入符号和数字以及用冒号和文本来添加脚注内容 ([^1]：这是一段脚注). 你不一定要在文档末尾添加脚注. 可以将它们放在除列表, 引用和表格等元素之外的任何位置. 这是一个数字脚注[^1]. 这是一个带标签的脚注[^label] [^1]: 这是一个数字脚注 [^label]: 这是一个带标签的脚注 这是一个数字脚注1. 这是一个带标签的脚注2 ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:12:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"13 图片 图片的语法与链接相似, 但包含一个在前面的感叹号. ![Minion](https://octodex.github.com/images/minion.png) 或者: ![Alt text](https://octodex.github.com/images/stormtroopocat.jpg \"The Stormtroopocat\") The Stormtroopocat 像链接一样, 图片也具有脚注样式的语法: ![Alt text][id] The Dojocat 稍后在文档中提供参考内容, 用来定义 URL 的位置: [id]: https://octodex.github.com/images/dojocat.jpg \"The Dojocat\" 技巧 LoveIt 主题提供了一个包含更多功能的 图片的 shortcode. 这是一个数字脚注 ↩︎ 这是一个带标签的脚注 ↩︎ ","date":"2019-12-01","objectID":"/posts/hugo/markdown/:13:0","tags":["loveit"],"title":"Markdown 基本语法","uri":"/posts/hugo/markdown/"},{"categories":["loveit"],"content":"Hugo 和 LoveIt 中的 Emoji 的用法指南.","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"Emoji 可以通过多种方式在 Hugo 项目中启用. emojify 方法可以直接在模板中调用, 或者使用行内 Shortcodes. 要全局使用 emoji, 需要在你的网站配置中设置 enableEmoji 为 true, 然后你就可以直接在文章中输入 emoji 的代码. 它们以冒号开头和结尾，并且包含 emoji 的 代码: 去露营啦! :tent: 很快就回来. 真开心! :joy: 呈现的输出效果如下: 去露营啦! ⛺ 很快就回来. 真开心! 😂 以下符号清单是 emoji 代码的非常有用的参考. ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:0:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"表情与情感 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"笑脸表情 图标 代码 图标 代码 😀 grinning 😃 smiley 😄 smile 😁 grin 😆 laughing satisfied 😅 sweat_smile 🤣 rofl 😂 joy 🙂 slightly_smiling_face 🙃 upside_down_face 😉 wink 😊 blush 😇 innocent ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"爱意表情 图标 代码 图标 代码 😍 heart_eyes 😘 kissing_heart 😗 kissing ☺️ relaxed 😚 kissing_closed_eyes 😙 kissing_smiling_eyes ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"吐舌头表情 图标 代码 图标 代码 😋 yum 😛 stuck_out_tongue 😜 stuck_out_tongue_winking_eye 😝 stuck_out_tongue_closed_eyes 🤑 money_mouth_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"带手的表情 图标 代码 图标 代码 🤗 hugs 🤔 thinking ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"中性表情 图标 代码 图标 代码 🤐 zipper_mouth_face 😐 neutral_face 😑 expressionless 😶 no_mouth 😏 smirk 😒 unamused 🙄 roll_eyes 😬 grimacing 🤥 lying_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"困倦的表情 图标 代码 图标 代码 😌 relieved 😔 pensive 😪 sleepy 🤤 drooling_face 😴 sleeping ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"不适的表情 图标 代码 图标 代码 😷 mask 🤒 face_with_thermometer 🤕 face_with_head_bandage 🤢 nauseated_face 🤧 sneezing_face 😵 dizzy_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"戴帽子的表情 图标 代码 图标 代码 🤠 cowboy_hat_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"戴眼镜的表情 图标 代码 图标 代码 😎 sunglasses 🤓 nerd_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:9","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"担心的表情 图标 代码 图标 代码 😕 confused 😟 worried 🙁 slightly_frowning_face ☹ frowning_face 😮 open_mouth 😯 hushed 😲 astonished 😳 flushed 😦 frowning 😧 anguished 😨 fearful 😰 cold_sweat 😥 disappointed_relieved 😢 cry 😭 sob 😱 scream 😖 confounded 😣 persevere 😞 disappointed 😓 sweat 😩 weary 😫 tired_face ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:10","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"否定的表情 图标 代码 图标 代码 😤 triumph 😡 pout rage 😠 angry 😈 smiling_imp 👿 imp 💀 skull ☠️ skull_and_crossbones ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:11","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"特殊打扮的表情 图标 代码 图标 代码 💩 hankey poop shit 🤡 clown_face 👹 japanese_ogre 👺 japanese_goblin 👻 ghost 👽 alien 👾 space_invader 🤖 robot ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:12","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"猫脸表情 图标 代码 图标 代码 😺 smiley_cat 😸 smile_cat 😹 joy_cat 😻 heart_eyes_cat 😼 smirk_cat 😽 kissing_cat 🙀 scream_cat 😿 crying_cat_face 😾 pouting_cat ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:13","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"猴脸表情 图标 代码 图标 代码 🙈 see_no_evil 🙉 hear_no_evil 🙊 speak_no_evil ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:14","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"情感 图标 代码 图标 代码 💋 kiss 💌 love_letter 💘 cupid 💝 gift_heart 💖 sparkling_heart 💗 heartpulse 💓 heartbeat 💞 revolving_hearts 💕 two_hearts 💟 heart_decoration ❣️ heavy_heart_exclamation 💔 broken_heart ❤️ heart 💛 yellow_heart 💚 green_heart 💙 blue_heart 💜 purple_heart 🖤 black_heart 💯 100 💢 anger 💥 boom collision 💫 dizzy 💦 sweat_drops 💨 dash 🕳️ hole 💣 bomb 💬 speech_balloon 👁️‍🗨️ eye_speech_bubble 🗯️ right_anger_bubble 💭 thought_balloon 💤 zzz ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:1:15","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"人与身体 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"张开手掌的手势 图标 代码 图标 代码 👋 wave 🤚 raised_back_of_hand 🖐️ raised_hand_with_fingers_splayed ✋ hand raised_hand 🖖 vulcan_salute ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"部分手指的手势 图标 代码 图标 代码 👌 ok_hand ✌️ v 🤞 crossed_fingers 🤘 metal 🤙 call_me_hand ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"一根手指的手势 图标 代码 图标 代码 👈 point_left 👉 point_right 👆 point_up_2 🖕 fu middle_finger 👇 point_down ☝️ point_up ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"握紧的手势 图标 代码 图标 代码 👍 +1 thumbsup 👎 -1 thumbsdown ✊ fist fist_raised 👊 facepunch fist_oncoming punch 🤛 fist_left 🤜 fist_right ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"两只手 图标 代码 图标 代码 👏 clap 🙌 raised_hands 👐 open_hands 🤝 handshake 🙏 pray ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"握住东西的手势 图标 代码 图标 代码 ✍️ writing_hand 💅 nail_care 🤳 selfie ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"身体部位 图标 代码 图标 代码 💪 muscle 👂 ear 👃 nose 👀 eyes 👁️ eye 👅 tongue 👄 lips ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"人 图标 代码 图标 代码 👶 baby 👦 boy 👧 girl :blonde_man: blonde_man person_with_blond_hair 👨 man 👩 woman 👱‍♀️ blonde_woman 👴 older_man 👵 older_woman ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"身体动作 图标 代码 图标 代码 🙍‍♀️ frowning_woman person_frowning 🙍‍♂️ frowning_man 🙎‍♀️ person_with_pouting_face pouting_woman 🙎‍♂️ pouting_man 🙅‍♀️ ng_woman no_good no_good_woman 🙅‍♂️ ng_man no_good_man 🙆‍♀️ ok_woman 🙆‍♂️ ok_man 💁‍♀️ information_desk_person sassy_woman tipping_hand_woman 💁‍♂️ sassy_man tipping_hand_man 🙋‍♀️ raising_hand raising_hand_woman 🙋‍♂️ raising_hand_man 🙇 bow bowing_man 🙇‍♀️ bowing_woman 🤦‍♂️ man_facepalming 🤦‍♀️ woman_facepalming 🤷‍♂️ man_shrugging 🤷‍♀️ woman_shrugging ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:9","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"人物角色 图标 代码 图标 代码 👨‍⚕️ man_health_worker 👩‍⚕️ woman_health_worker 👨‍🎓 man_student 👩‍🎓 woman_student 👨‍🏫 man_teacher 👩‍🏫 woman_teacher 👨‍⚖️ man_judge 👩‍⚖️ woman_judge 👨‍🌾 man_farmer 👩‍🌾 woman_farmer 👨‍🍳 man_cook 👩‍🍳 woman_cook 👨‍🔧 man_mechanic 👩‍🔧 woman_mechanic 👨‍🏭 man_factory_worker 👩‍🏭 woman_factory_worker 👨‍💼 man_office_worker 👩‍💼 woman_office_worker 👨‍🔬 man_scientist 👩‍🔬 woman_scientist 👨‍💻 man_technologist 👩‍💻 woman_technologist 👨‍🎤 man_singer 👩‍🎤 woman_singer 👨‍🎨 man_artist 👩‍🎨 woman_artist 👨‍✈️ man_pilot 👩‍✈️ woman_pilot 👨‍🚀 man_astronaut 👩‍🚀 woman_astronaut 👨‍🚒 man_firefighter 👩‍🚒 woman_firefighter 👮‍♂️ cop policeman 👮‍♀️ policewoman 🕵 detective male_detective 🕵️‍♀️ female_detective 💂‍♂️ guardsman 💂‍♀️ guardswoman 👷‍♂️ construction_worker construction_worker_man 👷‍♀️ construction_worker_woman 🤴 prince 👸 princess 👳‍♂️ man_with_turban 👳‍♀️ woman_with_turban 👲 man_with_gua_pi_mao 🤵‍♂️ man_in_tuxedo 👰 bride_with_veil 🤰 pregnant_woman ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:10","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"幻想的人物 图标 代码 图标 代码 👼 angel 🎅 santa 🤶 mrs_claus ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:11","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"人物活动 图标 代码 图标 代码 💆‍♀️ massage massage_woman 💆‍♂️ massage_man 💇‍♀️ haircut haircut_woman 💇‍♂️ haircut_man 🚶‍♂️ walking walking_man 🚶‍♀️ walking_woman 🏃‍♂️ runner running running_man 🏃‍♀️ running_woman 💃 dancer 🕺 man_dancing 🕴️ business_suit_levitating 👯‍♀️ dancers dancing_women 👯‍♂️ dancing_men ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:12","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"体育 图标 代码 图标 代码 🤺 person_fencing 🏇 horse_racing ⛷️ skier 🏂 snowboarder 🏌️‍♂️ golfing_man 🏌️‍♀️ golfing_woman 🏄‍♂️ surfer surfing_man 🏄‍♀️ surfing_woman 🚣‍♂️ rowboat rowing_man 🚣‍♀️ rowing_woman 🏊‍♂️ swimmer swimming_man 🏊‍♀️ swimming_woman ⛹️‍♂️ basketball_man ⛹️‍♀️ basketball_woman 🏋️‍♂️ weight_lifting_man 🏋️‍♀️ weight_lifting_woman 🚴‍♂️ bicyclist biking_man 🚴‍♀️ biking_woman 🚵‍♂️ mountain_bicyclist mountain_biking_man 🚵‍♀️ mountain_biking_woman 🤸‍♂️ man_cartwheeling 🤸‍♀️ woman_cartwheeling 🤼‍♂️ men_wrestling 🤼‍♀️ women_wrestling 🤽‍♂️ man_playing_water_polo 🤽‍♀️ woman_playing_water_polo 🤾‍♂️ man_playing_handball 🤾‍♀️ woman_playing_handball 🤹‍♂️ man_juggling 🤹‍♀️ woman_juggling ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:13","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"休息 图标 代码 图标 代码 🛀 bath 🛌 sleeping_bed ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:14","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"家庭 图标 代码 图标 代码 👭 two_women_holding_hands 👫 couple 👬 two_men_holding_hands 👩‍❤️‍💋‍👨 couplekiss_man_woman 👨‍❤️‍💋‍👨 couplekiss_man_man 👩‍❤️‍💋‍👩 couplekiss_woman_woman 💑 couple_with_heart couple_with_heart_woman_man 👨‍❤️‍👨 couple_with_heart_man_man 👩‍❤️‍👩 couple_with_heart_woman_woman 👨‍👩‍👦 family family_man_woman_boy 👨‍👩‍👧 family_man_woman_girl 👨‍👩‍👧‍👦 family_man_woman_girl_boy 👨‍👩‍👦‍👦 family_man_woman_boy_boy 👨‍👩‍👧‍👧 family_man_woman_girl_girl 👨‍👨‍👦 family_man_man_boy 👨‍👨‍👧 family_man_man_girl 👨‍👨‍👧‍👦 family_man_man_girl_boy 👨‍👨‍👦‍👦 family_man_man_boy_boy 👨‍👨‍👧‍👧 family_man_man_girl_girl 👩‍👩‍👦 family_woman_woman_boy 👩‍👩‍👧 family_woman_woman_girl 👩‍👩‍👧‍👦 family_woman_woman_girl_boy 👩‍👩‍👦‍👦 family_woman_woman_boy_boy 👩‍👩‍👧‍👧 family_woman_woman_girl_girl 👨‍👦 family_man_boy 👨‍👦‍👦 family_man_boy_boy 👨‍👧 family_man_girl 👨‍👧‍👦 family_man_girl_boy 👨‍👧‍👧 family_man_girl_girl 👩‍👦 family_woman_boy 👩‍👦‍👦 family_woman_boy_boy 👩‍👧 family_woman_girl 👩‍👧‍👦 family_woman_girl_boy 👩‍👧‍👧 family_woman_girl_girl ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:15","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"人物符号 图标 代码 图标 代码 🗣 speaking_head 👤 bust_in_silhouette 👥 busts_in_silhouette 👣 footprints ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:2:16","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"动物与自然 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"哺乳动物 图标 代码 图标 代码 🐵 monkey_face 🐒 monkey 🦍 gorilla 🐶 dog 🐕 dog2 🐩 poodle 🐺 wolf 🦊 fox_face 🐱 cat 🐈 cat2 🦁 lion 🐯 tiger 🐅 tiger2 🐆 leopard 🐴 horse 🐎 racehorse 🦄 unicorn 🦌 deer 🐮 cow 🐂 ox 🐃 water_buffalo 🐄 cow2 🐷 pig 🐖 pig2 🐗 boar 🐽 pig_nose 🐏 ram 🐑 sheep 🐐 goat 🐪 dromedary_camel 🐫 camel 🐘 elephant 🦏 rhinoceros 🐭 mouse 🐁 mouse2 🐀 rat 🐹 hamster 🐰 rabbit 🐇 rabbit2 🐿️ chipmunk 🦇 bat 🐻 bear 🐨 koala 🐼 panda_face 🐾 feet paw_prints ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"鸟类 图标 代码 图标 代码 🦃 turkey 🐔 chicken 🐓 rooster 🐣 hatching_chick 🐤 baby_chick 🐥 hatched_chick 🐦 bird 🐧 penguin 🕊 dove 🦅 eagle 🦆 duck 🦉 owl ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"两栖动物 icon code icon code 🐸 frog ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"爬虫类 图标 代码 图标 代码 🐊 crocodile 🐢 turtle 🦎 lizard 🐍 snake 🐲 dragon_face 🐉 dragon ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"海洋动物 图标 代码 图标 代码 🐳 whale 🐋 whale2 🐬 dolphin flipper 🐟 fish 🐠 tropical_fish 🐡 blowfish 🦈 shark 🐙 octopus 🐚 shell ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"虫类 图标 代码 图标 代码 🐌 snail 🦋 butterfly 🐛 bug 🐜 ant 🐝 bee honeybee 🪲 beetle 🕷️ spider 🕸️ spider_web 🦂 scorpion ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"花类植物 图标 代码 图标 代码 💐 bouquet 🌸 cherry_blossom 💮 white_flower 🏵️ rosette 🌹 rose 🥀 wilted_flower 🌺 hibiscus 🌻 sunflower 🌼 blossom 🌷 tulip ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"其它植物 图标 代码 图标 代码 🌱 seedling 🌲 evergreen_tree 🌳 deciduous_tree 🌴 palm_tree 🌵 cactus 🌾 ear_of_rice 🌿 herb ☘️ shamrock 🍀 four_leaf_clover 🍁 maple_leaf 🍂 fallen_leaf 🍃 leaves ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:3:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"食物与饮料 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"水果 图标 代码 图标 代码 🍇 grapes 🍈 melon 🍉 watermelon 🍊 mandarin orange tangerine 🍋 lemon 🍌 banana 🍍 pineapple 🍎 apple 🍏 green_apple 🍐 pear 🍑 peach 🍒 cherries 🍓 strawberry 🥝 kiwi_fruit 🍅 tomato ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"蔬菜 图标 代码 图标 代码 🥑 avocado 🍆 eggplant 🥔 potato 🥕 carrot 🌽 corn 🌶️ hot_pepper 🥒 cucumber 🍄 mushroom 🥜 peanuts 🌰 chestnut ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"快餐 图标 代码 图标 代码 🍞 bread 🥐 croissant 🥖 baguette_bread 🥞 pancakes 🧀 cheese 🍖 meat_on_bone 🍗 poultry_leg 🥓 bacon 🍔 hamburger 🍟 fries 🍕 pizza 🌭 hotdog 🌮 taco 🌯 burrito 🥙 stuffed_flatbread 🥚 egg 🍳 fried_egg 🥘 shallow_pan_of_food 🍲 stew 🥗 green_salad 🍿 popcorn ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"亚洲食物 图标 代码 图标 代码 🍱 bento 🍘 rice_cracker 🍙 rice_ball 🍚 rice 🍛 curry 🍜 ramen 🍝 spaghetti 🍠 sweet_potato 🍢 oden 🍣 sushi 🍤 fried_shrimp 🍥 fish_cake 🍡 dango ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"海鲜 图标 代码 图标 代码 🦀 crab 🦐 shrimp 🦑 squid ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"甜点 图标 代码 图标 代码 🍦 icecream 🍧 shaved_ice 🍨 ice_cream 🍩 doughnut 🍪 cookie 🎂 birthday 🍰 cake 🍫 chocolate_bar 🍬 candy 🍭 lollipop 🍮 custard 🍯 honey_pot ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"饮料 图标 代码 图标 代码 🍼 baby_bottle 🥛 milk_glass ☕ coffee 🍵 tea 🍶 sake 🍾 champagne 🍷 wine_glass 🍸 cocktail 🍹 tropical_drink 🍺 beer 🍻 beers 🥂 clinking_glasses 🥃 tumbler_glass ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"餐具 图标 代码 图标 代码 🍽️ plate_with_cutlery 🍴 fork_and_knife 🥄 spoon 🔪 hocho knife 🏺 amphora ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:4:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"旅游与地理 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"地图 图标 代码 图标 代码 🌍 earth_africa 🌎 earth_americas 🌏 earth_asia 🌐 globe_with_meridians 🗺️ world_map 🗾 japan ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"地理现象 图标 代码 图标 代码 🏔 mountain_snow ⛰️ mountain 🌋 volcano 🗻 mount_fuji 🏕️ camping ⛱ beach_umbrella 🏜️ desert 🏝️ desert_island 🏞️ national_park ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"建筑物 图标 代码 图标 代码 🏟️ stadium 🏛️ classical_building 🏗️ building_construction 🏘 houses 🏚 derelict_house 🏠 house 🏡 house_with_garden 🏢 office 🏣 post_office 🏤 european_post_office 🏥 hospital 🏦 bank 🏨 hotel 🏩 love_hotel 🏪 convenience_store 🏫 school 🏬 department_store 🏭 factory 🏯 japanese_castle 🏰 european_castle 💒 wedding 🗼 tokyo_tower 🗽 statue_of_liberty ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"宗教建筑 图标 代码 图标 代码 ⛪ church 🕌 mosque 🕍 synagogue ⛩️ shinto_shrine 🕋 kaaba ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"其它地点 图标 代码 图标 代码 ⛲ fountain ⛺ tent 🌁 foggy 🌃 night_with_stars 🏙️ cityscape 🌄 sunrise_over_mountains 🌅 sunrise 🌆 city_sunset 🌇 city_sunrise 🌉 bridge_at_night ♨️ hotsprings 🎠 carousel_horse 🎡 ferris_wheel 🎢 roller_coaster 💈 barber 🎪 circus_tent ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"陆路运输 图标 代码 图标 代码 🚂 steam_locomotive 🚃 railway_car 🚄 bullettrain_side 🚅 bullettrain_front 🚆 train2 🚇 metro 🚈 light_rail 🚉 station 🚊 tram 🚝 monorail 🚞 mountain_railway 🚋 train 🚌 bus 🚍 oncoming_bus 🚎 trolleybus 🚐 minibus 🚑 ambulance 🚒 fire_engine 🚓 police_car 🚔 oncoming_police_car 🚕 taxi 🚖 oncoming_taxi 🚗 car red_car 🚘 oncoming_automobile 🚙 blue_car 🚚 truck 🚛 articulated_lorry 🚜 tractor 🏎️ racing_car 🏍 motorcycle 🛵 motor_scooter 🚲 bike 🛴 kick_scooter 🚏 busstop 🛣️ motorway 🛤️ railway_track 🛢️ oil_drum ⛽ fuelpump 🚨 rotating_light 🚥 traffic_light 🚦 vertical_traffic_light 🛑 stop_sign 🚧 construction ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"水路运输 图标 代码 图标 代码 ⚓ anchor ⛵ boat sailboat 🛶 canoe 🚤 speedboat 🛳️ passenger_ship ⛴️ ferry 🛥️ motor_boat 🚢 ship ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"空中运输 图标 代码 图标 代码 ✈️ airplane 🛩️ small_airplane 🛫 flight_departure 🛬 flight_arrival 💺 seat 🚁 helicopter 🚟 suspension_railway 🚠 mountain_cableway 🚡 aerial_tramway 🛰️ artificial_satellite 🚀 rocket ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"旅馆 icon code icon code 🛎️ bellhop_bell ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:9","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"时间 图标 代码 图标 代码 ⌛ hourglass ⏳ hourglass_flowing_sand ⌚ watch ⏰ alarm_clock ⏱️ stopwatch ⏲️ timer_clock 🕰️ mantelpiece_clock 🕛 clock12 🕧 clock1230 🕐 clock1 🕜 clock130 🕑 clock2 🕝 clock230 🕒 clock3 🕞 clock330 🕓 clock4 🕟 clock430 🕔 clock5 🕠 clock530 🕕 clock6 🕡 clock630 🕖 clock7 🕢 clock730 🕗 clock8 🕣 clock830 🕘 clock9 🕤 clock930 🕙 clock10 🕥 clock1030 🕚 clock11 🕦 clock1130 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:10","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"天空与天气 图标 代码 图标 代码 🌑 new_moon 🌒 waxing_crescent_moon 🌓 first_quarter_moon 🌔 moon waxing_gibbous_moon 🌕 full_moon 🌖 waning_gibbous_moon 🌗 last_quarter_moon 🌘 waning_crescent_moon 🌙 crescent_moon 🌚 new_moon_with_face 🌛 first_quarter_moon_with_face 🌜 last_quarter_moon_with_face 🌡️ thermometer ☀️ sunny 🌝 full_moon_with_face 🌞 sun_with_face ⭐ star 🌟 star2 🌠 stars 🌌 milky_way ☁️ cloud ⛅ partly_sunny ⛈ cloud_with_lightning_and_rain 🌤 sun_behind_small_cloud 🌥 sun_behind_large_cloud 🌦 sun_behind_rain_cloud 🌧 cloud_with_rain 🌨 cloud_with_snow 🌩 cloud_with_lightning 🌪️ tornado 🌫️ fog 🌬 wind_face 🌀 cyclone 🌈 rainbow 🌂 closed_umbrella ☂️ open_umbrella ☂️ umbrella ⛱️ parasol_on_ground ⚡ zap ❄️ snowflake ☃️ snowman_with_snow ☃️ snowman ☄️ comet 🔥 fire 💧 droplet 🌊 ocean ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:5:11","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"活动 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"事件 图标 代码 图标 代码 🎃 jack_o_lantern 🎄 christmas_tree 🎆 fireworks 🎇 sparkler ✨ sparkles 🎈 balloon 🎉 tada 🎊 confetti_ball 🎋 tanabata_tree 🎍 bamboo 🎎 dolls 🎏 flags 🎐 wind_chime 🎑 rice_scene 🎀 ribbon 🎁 gift 🎗️ reminder_ribbon 🎟 tickets 🎫 ticket ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"奖杯与奖牌 图标 代码 图标 代码 🎖️ medal_military 🏆 trophy 🏅 medal_sports 🥇 1st_place_medal 🥈 2nd_place_medal 🥉 3rd_place_medal ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"体育运动 图标 代码 图标 代码 ⚽ soccer ⚾ baseball 🏀 basketball 🏐 volleyball 🏈 football 🏉 rugby_football 🎾 tennis 🎳 bowling 🦗 cricket 🏑 field_hockey 🏒 ice_hockey 🏓 ping_pong 🏸 badminton 🥊 boxing_glove 🥋 martial_arts_uniform 🥅 goal_net ⛳ golf ⛸️ ice_skate 🎣 fishing_pole_and_fish 🎽 running_shirt_with_sash 🎿 ski ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"游戏 图标 代码 图标 代码 🎯 dart 🎱 8ball 🔮 crystal_ball 🎮 video_game 🕹️ joystick 🎰 slot_machine 🎲 game_die ♠️ spades ♥️ hearts ♦️ diamonds ♣️ clubs 🃏 black_joker 🀄 mahjong 🎴 flower_playing_cards ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"艺术与工艺 图标 代码 图标 代码 🎭 performing_arts 🖼 framed_picture 🎨 art ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:6:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"物品 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"服装 图标 代码 图标 代码 👓 eyeglasses 🕶️ dark_sunglasses 👔 necktie 👕 shirt tshirt 👖 jeans 👗 dress 👘 kimono 👙 bikini 👚 womans_clothes 👛 purse 👜 handbag 👝 pouch 🛍️ shopping 🎒 school_satchel 👞 mans_shoe shoe 👟 athletic_shoe 👠 high_heel 👡 sandal 👢 boot 👑 crown 👒 womans_hat 🎩 tophat 🎓 mortar_board ⛑️ rescue_worker_helmet 📿 prayer_beads 💄 lipstick 💍 ring 💎 gem ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"声音 图标 代码 图标 代码 🔇 mute 🔈 speaker 🔉 sound 🔊 loud_sound 📢 loudspeaker 📣 mega 📯 postal_horn 🔔 bell 🔕 no_bell ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"音乐 图标 代码 图标 代码 🎼 musical_score 🎵 musical_note 🎶 notes 🎙️ studio_microphone 🎚️ level_slider 🎛️ control_knobs 🎤 microphone 🎧 headphones 📻 radio ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"乐器 图标 代码 图标 代码 🎷 saxophone 🎸 guitar 🎹 musical_keyboard 🎺 trumpet 🎻 violin 🥁 drum ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"电话 图标 代码 图标 代码 📱 iphone 📲 calling ☎️ phone telephone 📞 telephone_receiver 📟 pager 📠 fax ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"电脑 图标 代码 图标 代码 🔋 battery 🔌 electric_plug 💻 computer 🖥️ desktop_computer 🖨️ printer ⌨️ keyboard 🖱 computer_mouse 🖲️ trackball 💽 minidisc 💾 floppy_disk 💿 cd 📀 dvd ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"灯光与影像 图标 代码 图标 代码 🎥 movie_camera 🎞️ film_strip 📽️ film_projector 🎬 clapper 📺 tv 📷 camera 📸 camera_flash 📹 video_camera 📼 vhs 🔍 mag 🔎 mag_right 🕯️ candle 💡 bulb 🔦 flashlight 🏮 izakaya_lantern lantern ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"书与纸张 图标 代码 图标 代码 📔 notebook_with_decorative_cover 📕 closed_book 📖 book open_book 📗 green_book 📘 blue_book 📙 orange_book 📚 books 📓 notebook 📒 ledger 📃 page_with_curl 📜 scroll 📄 page_facing_up 📰 newspaper 🗞️ newspaper_roll 📑 bookmark_tabs 🔖 bookmark 🏷️ label ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"钱 图标 代码 图标 代码 💰 moneybag 💴 yen 💵 dollar 💶 euro 💷 pound 💸 money_with_wings 💳 credit_card 💹 chart ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:9","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"邮件 图标 代码 图标 代码 ✉️ email envelope 📧 📧 📨 incoming_envelope 📩 envelope_with_arrow 📤 outbox_tray 📥 inbox_tray 📦 package 📫 mailbox 📪 mailbox_closed 📬 mailbox_with_mail 📭 mailbox_with_no_mail 📮 postbox 🗳 ballot_box ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:10","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"书写 图标 代码 图标 代码 ✏️ pencil2 ✒️ black_nib 🖋 fountain_pen 🖊 pen 🖌 paintbrush 🖍 crayon 📝 memo pencil ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:11","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"办公 图标 代码 图标 代码 💼 briefcase 📁 file_folder 📂 open_file_folder 🗂️ card_index_dividers 📅 date 📆 calendar 🗒 spiral_notepad 🗓 spiral_calendar 📇 card_index 📈 chart_with_upwards_trend 📉 chart_with_downwards_trend 📊 bar_chart 📋 clipboard 📌 pushpin 📍 round_pushpin 📎 paperclip 🖇 paperclips 📏 straight_ruler 📐 triangular_ruler ✂️ scissors 🗃️ card_file_box 🗄️ file_cabinet 🗑️ wastebasket ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:12","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"锁 图标 代码 图标 代码 🔒 lock 🔓 unlock 🔏 lock_with_ink_pen 🔐 closed_lock_with_key 🔑 key 🗝️ old_key ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:13","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"工具 图标 代码 图标 代码 🔨 hammer ⛏️ pick ⚒️ hammer_and_pick 🛠️ hammer_and_wrench 🗡 dagger ⚔️ crossed_swords 🔫 gun 🏹 bow_and_arrow 🛡️ shield 🔧 wrench 🔩 nut_and_bolt ⚙️ gear 🗜 clamp ⚖ balance_scale 🔗 link ⛓️ chains ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:14","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"科学 图标 代码 图标 代码 ⚗️ alembic 🔬 microscope 🔭 telescope 🛰️ satellite ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:15","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"医疗 图标 代码 图标 代码 💉 syringe 💊 pill ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:16","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"生活用品 图标 代码 图标 代码 🚪 door 🛏️ bed 🛋️ couch_and_lamp 🚽 toilet 🚿 shower 🛁 bathtub 🛒 shopping_cart ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:17","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"其它物品 图标 代码 图标 代码 🚬 smoking ⚰️ coffin ⚱️ funeral_urn 🗿 moyai ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:7:18","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"符号 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"交通标识 图标 代码 图标 代码 🏧 atm 🚮 put_litter_in_its_place 🚰 potable_water ♿ wheelchair 🚹 mens 🚺 womens 🚻 restroom 🚼 baby_symbol 🚾 wc 🛂 passport_control 🛃 customs 🛄 baggage_claim 🛅 left_luggage ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"警告 图标 代码 图标 代码 ⚠️ warning 🚸 children_crossing ⛔ no_entry 🚫 no_entry_sign 🚳 no_bicycles 🚭 no_smoking 🚯 do_not_litter 🚱 🚱 🚷 no_pedestrians 📵 no_mobile_phones 🔞 underage ☢ radioactive ☣ biohazard ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"箭头 图标 代码 图标 代码 ⬆️ arrow_up ↗️ arrow_upper_right ➡️ arrow_right ↘️ arrow_lower_right ⬇️ arrow_down ↙️ arrow_lower_left ⬅️ arrow_left ↖️ arrow_upper_left ↕️ arrow_up_down ↔️ left_right_arrow ↩️ leftwards_arrow_with_hook ↪️ arrow_right_hook ⤴️ arrow_heading_up ⤵️ arrow_heading_down 🔃 arrows_clockwise 🔄 arrows_counterclockwise 🔙 back 🔚 end 🔛 on 🔜 soon 🔝 top ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:3","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"宗教 图标 代码 图标 代码 🛐 place_of_worship ⚛️ atom_symbol 🕉 om ✡️ star_of_david ☸️ wheel_of_dharma ☯️ yin_yang ✝️ latin_cross ☦️ orthodox_cross ☪️ star_and_crescent ☮️ peace_symbol 🕎 menorah 🔯 six_pointed_star ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:4","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"生肖 图标 代码 图标 代码 ♈ aries ♉ taurus ♊ gemini ♋ cancer ♌ leo ♍ virgo ♎ libra ♏ scorpius ♐ sagittarius ♑ capricorn ♒ aquarius ♓ pisces ⛎ ophiuchus ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:5","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"影像符号 图标 代码 图标 代码 🔀 twisted_rightwards_arrows 🔁 repeat 🔂 repeat_one ▶️ arrow_forward ⏩ fast_forward ⏭ next_track_button ⏯ play_or_pause_button ◀️ arrow_backward ⏪ rewind ⏮️ previous_track_button 🔼 arrow_up_small ⏫ arrow_double_up 🔽 arrow_down_small ⏬ arrow_double_down ⏸ pause_button ⏹ stop_button ⏺ record_button 🎦 cinema 🔅 low_brightness 🔆 high_brightness 📶 signal_strength 📳 vibration_mode 📴 mobile_phone_off ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:6","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"数学 图标 代码 图标 代码 ✖️ heavy_multiplication_x ➕ heavy_plus_sign ➖ heavy_minus_sign ➗ heavy_division_sign ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:7","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"标点符号 图标 代码 图标 代码 ‼️ bangbang ⁉️ interrobang ❓ question ❔ grey_question ❕ grey_exclamation ❗ exclamation heavy_exclamation_mark 〰️ wavy_dash ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:8","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"货币 图标 代码 图标 代码 💱 currency_exchange 💲 heavy_dollar_sign ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:9","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"按键符号 图标 代码 图标 代码 #️⃣ hash *️⃣ asterisk 0️⃣ zero 1️⃣ one 2️⃣ two 3️⃣ three 4️⃣ four 5️⃣ five 6️⃣ six 7️⃣ seven 8️⃣ eight 9️⃣ nine 🔟 keycap_ten ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:10","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"字母符号 图标 代码 图标 代码 🔠 capital_abcd 🔡 abcd 🔢 1234 🔣 symbols 🔤 abc 🅰️ a 🆎 ab 🅱️ b 🆑 cl 🆒 cool 🆓 free ℹ️ information_source 🆔 id ⓜ️ m 🆕 new 🆖 ng 🅾️ o2 🆗 ok 🅿️ parking 🆘 sos 🆙 up 🆚 vs 🈁 koko 🈂️ sa 🈷️ u6708 🈶 u6709 🈯 u6307 🉐 ideograph_advantage 🈹 u5272 🈚 u7121 🈲 u7981 🉑 accept 🈸 u7533 🈴 u5408 🈳 u7a7a ㊗️ congratulations ㊙️ secret 🈺 u55b6 🈵 u6e80 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:11","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"几何符号 图标 代码 图标 代码 🔴 red_circle 🔵 large_blue_circle ⚫ black_circle ⚪ white_circle ⬛ black_large_square ⬜ white_large_square ◼️ black_medium_square ◻️ white_medium_square ◾ black_medium_small_square ◽ white_medium_small_square ▪️ black_small_square ▫️ white_small_square 🔶 large_orange_diamond 🔷 large_blue_diamond 🔸 small_orange_diamond 🔹 small_blue_diamond 🔺 small_red_triangle 🔻 small_red_triangle_down 💠 diamond_shape_with_a_dot_inside 🔘 radio_button 🔳 white_square_button 🔲 black_square_button ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:12","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"其它符合 图标 代码 图标 代码 ♻️ recycle ⚜️ fleur_de_lis 🔱 trident 📛 name_badge 🔰 beginner ⭕ o ✅ white_check_mark ☑️ ballot_box_with_check ✔️ heavy_check_mark ❌ x ❎ negative_squared_cross_mark ➰ curly_loop ➿ loop 〽️ part_alternation_mark ✳️ eight_spoked_asterisk ✴️ eight_pointed_black_star ❇️ sparkle ©️ copyright ®️ registered ™️ tm ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:8:13","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"旗帜 ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:9:0","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"常用旗帜 图标 代码 图标 代码 🏁 checkered_flag 🚩 triangular_flag_on_post 🎌 crossed_flags 🏴 black_flag 🏳 white_flag 🏳️‍🌈 rainbow_flag ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:9:1","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"},{"categories":["loveit"],"content":"国家和地区旗帜 图标 代码 图标 代码 🇦🇩 andorra 🇦🇪 united_arab_emirates 🇦🇫 afghanistan 🇦🇬 antigua_barbuda 🇦🇮 anguilla 🇦🇱 albania 🇦🇲 armenia 🇦🇴 angola 🇦🇶 antarctica 🇦🇷 argentina 🇦🇸 american_samoa 🇦🇹 austria 🇦🇺 australia 🇦🇼 aruba 🇦🇽 aland_islands 🇦🇿 azerbaijan 🇧🇦 bosnia_herzegovina 🇧🇧 barbados 🇧🇩 bangladesh 🇧🇪 belgium 🇧🇫 burkina_faso 🇧🇬 bulgaria 🇧🇭 bahrain 🇧🇮 burundi 🇧🇯 benin 🇧🇱 st_barthelemy 🇧🇲 bermuda 🇧🇳 brunei 🇧🇴 bolivia 🇧🇶 caribbean_netherlands 🇧🇷 brazil 🇧🇸 bahamas 🇧🇹 bhutan 🇧🇼 botswana 🇧🇾 belarus 🇧🇿 belize 🇨🇦 canada 🇨🇨 cocos_islands 🇨🇩 congo_kinshasa 🇨🇫 central_african_republic 🇨🇬 congo_brazzaville 🇨🇭 switzerland 🇨🇮 cote_divoire 🇨🇰 cook_islands 🇨🇱 chile 🇨🇲 cameroon 🇨🇳 cn 🇨🇴 colombia 🇨🇷 costa_rica 🇨🇺 cuba 🇨🇻 cape_verde 🇨🇼 curacao 🇨🇽 christmas_island 🇨🇾 cyprus 🇨🇿 czech_republic 🇩🇪 de 🇩🇯 djibouti 🇩🇰 denmark 🇩🇲 dominica 🇩🇴 dominican_republic 🇩🇿 algeria 🇪🇨 ecuador 🇪🇪 estonia 🇪🇬 egypt 🇪🇭 western_sahara 🇪🇷 eritrea 🇪🇸 es 🇪🇹 ethiopia 🇪🇺 eu european_union 🇫🇮 finland 🇫🇯 fiji 🇫🇰 falkland_islands 🇫🇲 micronesia 🇫🇴 faroe_islands 🇫🇷 fr 🇬🇦 gabon 🇬🇧 gb uk 🇬🇩 grenada 🇬🇪 georgia 🇬🇫 french_guiana 🇬🇬 guernsey 🇬🇭 ghana 🇬🇮 gibraltar 🇬🇱 greenland 🇬🇲 gambia 🇬🇳 guinea 🇬🇵 guadeloupe 🇬🇶 equatorial_guinea 🇬🇷 greece 🇬🇸 south_georgia_south_sandwich_islands 🇬🇹 guatemala 🇬🇺 guam 🇬🇼 guinea_bissau 🇬🇾 guyana 🇭🇰 hong_kong 🇭🇳 honduras 🇭🇷 croatia 🇭🇹 haiti 🇭🇺 hungary 🇮🇨 canary_islands 🇮🇩 indonesia 🇮🇪 ireland 🇮🇱 israel 🇮🇲 isle_of_man 🇮🇳 india 🇮🇴 british_indian_ocean_territory 🇮🇶 iraq 🇮🇷 iran 🇮🇸 iceland 🇮🇹 it 🇯🇪 jersey 🇯🇲 jamaica 🇯🇴 jordan 🇯🇵 jp 🇰🇪 kenya 🇰🇬 kyrgyzstan 🇰🇭 cambodia 🇰🇮 kiribati 🇰🇲 comoros 🇰🇳 st_kitts_nevis 🇰🇵 north_korea 🇰🇷 kr 🇰🇼 kuwait 🇰🇾 cayman_islands 🇰🇿 kazakhstan 🇱🇦 laos 🇱🇧 lebanon 🇱🇨 st_lucia 🇱🇮 liechtenstein 🇱🇰 sri_lanka 🇱🇷 liberia 🇱🇸 lesotho 🇱🇹 lithuania 🇱🇺 luxembourg 🇱🇻 latvia 🇱🇾 libya 🇲🇦 morocco 🇲🇨 monaco 🇲🇩 moldova 🇲🇪 montenegro 🇲🇬 madagascar 🇲🇭 marshall_islands 🇲🇰 macedonia 🇲🇱 mali 🇲🇲 myanmar 🇲🇳 mongolia 🇲🇴 macau 🇲🇵 northern_mariana_islands 🇲🇶 martinique 🇲🇷 mauritania 🇲🇸 montserrat 🇲🇹 malta 🇲🇺 mauritius 🇲🇻 maldives 🇲🇼 malawi 🇲🇽 mexico 🇲🇾 malaysia 🇲🇿 mozambique 🇳🇦 namibia 🇳🇨 new_caledonia 🇳🇪 niger 🇳🇫 norfolk_island 🇳🇬 nigeria 🇳🇮 nicaragua 🇳🇱 netherlands 🇳🇴 norway 🇳🇵 nepal 🇳🇷 nauru 🇳🇺 niue 🇳🇿 new_zealand 🇴🇲 oman 🇵🇦 panama 🇵🇪 peru 🇵🇫 french_polynesia 🇵🇬 papua_new_guinea 🇵🇭 philippines 🇵🇰 pakistan 🇵🇱 poland 🇵🇲 st_pierre_miquelon 🇵🇳 pitcairn_islands 🇵🇷 puerto_rico 🇵🇸 palestinian_territories 🇵🇹 portugal 🇵🇼 palau 🇵🇾 paraguay 🇶🇦 qatar 🇷🇪 reunion 🇷🇴 romania 🇷🇸 serbia 🇷🇺 ru 🇷🇼 rwanda 🇸🇦 saudi_arabia 🇸🇧 solomon_islands 🇸🇨 seychelles 🇸🇩 sudan 🇸🇪 sweden 🇸🇬 singapore 🇸🇭 st_helena 🇸🇮 slovenia 🇸🇰 slovakia 🇸🇱 sierra_leone 🇸🇲 san_marino 🇸🇳 senegal 🇸🇴 somalia 🇸🇷 suriname 🇸🇸 south_sudan 🇸🇹 sao_tome_principe 🇸🇻 el_salvador 🇸🇽 sint_maarten 🇸🇾 syria 🇸🇿 swaziland 🇹🇨 turks_caicos_islands 🇹🇩 chad 🇹🇫 french_southern_territories 🇹🇬 togo 🇹🇭 thailand 🇹🇯 tajikistan 🇹🇰 tokelau 🇹🇱 timor_leste 🇹🇲 turkmenistan 🇹🇳 tunisia 🇹🇴 tonga 🇹🇷 tr 🇹🇹 trinidad_tobago 🇹🇻 tuvalu 🇹🇼 taiwan 🇹🇿 tanzania 🇺🇦 ukraine 🇺🇬 uganda 🇺🇸 us 🇺🇾 uruguay 🇺🇿 uzbekistan 🇻🇦 vatican_city 🇻🇨 st_vincent_grenadines 🇻🇪 venezuela 🇻🇬 british_virgin_islands 🇻🇮 us_virgin_islands 🇻🇳 vietnam 🇻🇺 vanuatu 🇼🇫 wallis_futuna 🇼🇸 samoa 🇽🇰 kosovo 🇾🇪 yemen 🇾🇹 mayotte 🇿🇦 south_africa 🇿🇲 zambia 🇿🇼 zimbabwe ","date":"2019-10-01","objectID":"/posts/hugo/loveit_emoji/:9:2","tags":["loveit"],"title":"Loveit Emoji 支持","uri":"/posts/hugo/loveit_emoji/"}]