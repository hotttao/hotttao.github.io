<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[字符编码]]></title>
    <url>%2F2019%2F02%2F11%2Fgo%2Fgo_grammar%2Findex_1%2F</url>
    <content type="text"><![CDATA[UTF8编码使用1到4个字节来表示每个Unicode码点，ASCII部分字符只使用1个字节，常用字符部分使用2或3个字节表示。每个符号编码后第一个字节的高端bit位用于表示总共有多少编码个字节。如果第一个字节的高端bit为0，则表示对应7bit的ASCII字符，ASCII字符每个字符依然是一个字节，和传统的ASCII编码兼容。更大的Unicode码点采用如下前缀表示: 12340xxxxxxx runes 0‐127 (ASCII)110xxxxx 10xxxxxx 128‐2047 (values &lt;128 unused)1110xxxx 10xxxxxx 10xxxxxx 2048‐65535 (values &lt;2048 unused)11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 65536‐0x10ffff (other values unused) UTF8 的变长的编码无法直接通过索引来访问第n个字符，但是UTF8编码获得了很多额外的优点。 首先UTF8编码比较紧凑，完全兼容ASCII码，并且可以自动同步：它可以通过向前回朔最多2个字节就能确定当前字符编码的开始字节的位置 它也是一个前缀编码，所以当从左向右解码时不会有任何歧义也并不需要向前查看，像GBK之类的编码，如果不知道起点位置则可能会出现歧义，即没有任何字符的编码是其它字符编码的子串，或是其它编码序列的字串，因此搜索一个字符时只要搜索它的字节编码序列即可，不用担心前后的上下文会对搜索结果产生干扰。 UTF8编码的顺序和Unicode码点的顺序一致，因此可以直接排序UTF8编码序列。同时因为没有嵌入的NUL(0)字节，可以很好地兼容那些使用NUL作为字符串结尾的编程语言]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 go 的委托模式]]></title>
    <url>%2F2019%2F01%2F08%2Fgo%2Fgo_grammar%2Fgo_8%2F</url>
    <content type="text"><![CDATA[Go 接口的应用]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 go 接口]]></title>
    <url>%2F2019%2F01%2F07%2Fgo%2Fgo_grammar%2Fgo_7%2F</url>
    <content type="text"><![CDATA[Go 的泛型编程 1. 接口接口类型是对其它类型行为的抽象和概括。接口类型具体描述了一系列方法的集合，一个实现了这些方法的具体类型是这个接口类型的实例。从这一点来看，接口与Python 中广泛使用的“鸭子类型”很相似，只通过行为来约束对象的适用范围。 接口类型只包含方法声明，与结构体嵌入类似，我们也可以通过类似的方式进行接口嵌入，实现接口组合。 1234567891011121314151617package iotype Reader interface &#123; Read(p []byte) (n int, err error)&#125;type Closer interface &#123; Close() error&#125;type Writer interface &#123; Write(p []byte) (n int, err error)&#125;type ReadWriter interface &#123; Reader Writer&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 go 方法]]></title>
    <url>%2F2019%2F01%2F06%2Fgo%2Fgo_grammar%2Fgo_6%2F</url>
    <content type="text"><![CDATA[Go 的对象组合技术 1. 方法方法是面向对象编程(OOP)中的概念。有关 OOP 的定义我也说不清楚。但是与概念相比，更重要的是OOP的两个关键点:封装和组合。我们的目的是看看 Go 语言如何通过结构体嵌入等技术实现这两个关键点。 Go 语言中的方法和接口密切相关，接口是 Go 语言提供的用来支持泛型编程的核心组件，我们会在下一章详细讨论。现在我们只需要明白: 方法是与特定类型关联的函数，可以被声明到任意命名类型，包括 Go 的内置类型;但不能是一个指针或者一个接口类型 方法分为值方法和指针方法两类，这会影响到类型是否属于特定接口的判断 2. 方法2.1 方法声明在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。 123456789101112type Point struct&#123; X, Y float64 &#125;// 1. 为 Point 定义一个值方法// 参数p，叫做方法的接收器(receiver)func (p Point) Distance(q Point) float64 &#123; return math.Hypot(q.X‐p.X, q.Y‐p.Y)&#125;// 2. 调用方法p := Point&#123;1, 2&#125;q := Point&#123;4, 6&#125;fmt.Println(p.Distance(q)) // "5", method call 从上面的示例可以看出来，在方法的定义和调用等行为上，Go 与 Python 并没有什么太大差别。有一点不同的是，当出现命名冲突时，Python 的默认行为是覆盖，而 Go 在编译阶段就直接失败。此外需要注意的是方法和属性在同一命名空间，因此它们之间的命名冲突也是不允许的。 2.2 值方法与指针方法前面函数的部分我们说过，Go 中实参通过值的方式传递。类似的，传递给方法接收器的对象也是按值传递。在上面的 Distance 内接收器 p 是外部 p 对象的拷贝。相对应的我们可以像下面这样，用其指针而不是对象来声明方法。 1234func (p *Point) ScaleBy(factor float64) &#123; p.X *= factor p.Y *= factor&#125; 2.3 接收器限制只有类型(Point)和指向他们的指针(*Point)，才是可能会出现在接收器声明里的两种接收器。为了避免歧义，在声明方法时，如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的，比如下面这个例子。即我们不能为指针定义方法。 12type P *intfunc (P) f() &#123; /* ... */ &#125; // compile error: invalid receiver type 2.4 方法调用中的隐式转换原则上，类型 Point只能调用其值方法，*Point只能调用其指针方法。这样在方法的调用中会有很多转换操作。幸运的是，Go 为我们提供了隐示的转换，就像我们直接通过指针去访问结构的成员变量一样。 12345678910p := Point&#123;1, 2&#125;pptr := &amp;p// type --&gt; *typep.ScaleBy(2) // 等同于(&amp;p).ScaleBy(2)// *type --&gt; typepptr.Distance(q) // 等同于(*pptr).Distance(q) 需要特别注意的是 type --&gt; *type 转换的前提是对象是可取址的。我们不能通过一个无法取到地址的接收器来调用指针方法，比如临时变量： 1Point&#123;1, 2&#125;.ScaleBy(2) // compile error: can't take address of Point literal 3. 结构体嵌入3.1 结构体嵌入与类的继承在结构体一节中，我们就已经提到了，结构体中通过匿名字段嵌入的不仅仅是结构体的成员还是其方法。以下面嵌入了 Point 的 ColoredPoint 为例，我们可以把ColoredPoint类型当作接收器来调用Point里的方法，即使ColoredPoint里没有声明这些方法。 12345678910111213141516import "image/color"type Point struct&#123; X, Y float64 &#125;type ColoredPoint struct &#123; Point Color color.RGBA&#125;red := color.RGBA&#123;255, 0, 0, 255&#125;blue := color.RGBA&#123;0, 0, 255, 255&#125;var p = ColoredPoint&#123;Point&#123;1, 1&#125;, red&#125;var q = ColoredPoint&#123;Point&#123;5, 4&#125;, blue&#125;fmt.Println(p.Distance(q.Point)) // "5"p.ScaleBy(2)q.ScaleBy(2)fmt.Println(p.Distance(q.Point)) // "10" 这种行为看起来跟 OOP 类的继承一样，但是有本质区别。最明显的地方是，在类的继承中，子类的实例也是基类的实例，但是在结构体嵌入中，ColoredPoint 类型的”实例”，并不是 Point 的”实例”。 请注意上面例子中对Distance方法的调用。尽管q有着Point这个内嵌类型，但是q并不是一个Point类，我们必须要显式地选择它。 12p.Distance(q.Point) // rightp.Distance(q) // compile error: cannot use q (ColoredPoint) as Point 在 Go 的结构体嵌入中，我们只能说 ColoredPoint has a Point 而不能说 ColoredPoint 继承自 Point。内嵌可以使我们将复杂类型的定义拆分，将字段先按小类型分组，然后定义小类型的方法，之后再把它们组合起来。 3.2 嵌入命名类型的指针在类型中内嵌的匿名字段也可能是一个命名类型的指针，添加这一层间接关系让我们可以共享通用的结构并动态地改变对象之间的关系。 12345678910111213type ColoredPoint struct &#123; *Point Color color.RGBA&#125;p := ColoredPoint&#123;&amp;Point&#123;1, 1&#125;, red&#125;q := ColoredPoint&#123;&amp;Point&#123;5, 4&#125;, blue&#125;// 注意访问 *q.Point 的区别fmt.Println(p.Distance(*q.Point)) // "5"q.Point = p.Point // p and q now share the same Pointp.ScaleBy(2)fmt.Println(*p.Point, *q.Point) // "&#123;2 2&#125; &#123;2 2&#125;" 3.3 多匿名字段的查找顺序如果结构体中嵌入了多个匿名字段，将遵循下面的字段和方法查找顺序: 直接定义在类型里方法 内嵌字段引入的方法 内嵌字段的内嵌字段引入的方法，然后一直递归向下找 如果在同一级里有两个同名的方法，编译器会报错 上面说的同一级可以理解为，由内嵌所构成的树的同一层。 12345678910111213141516171819202122232425262728293031type A struct &#123; A1&#125;type A1 struct &#123;&#125;type B struct &#123; B1&#125;type B1 struct&#123;&#125;func (a A1) name() &#123; fmt.Println("a1")&#125;func (b B1) name() &#123; fmt.Println("b1")&#125;type C struct &#123; A B&#125;c := C&#123;&#125;// 同一级的 A1，B1 的 同名 name 方法导致编译错误c.name() // ambiguous selector c.name 4. 封装一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。封装有时候也被叫做信息隐藏，同时也是面向对象编程最关键的一个方面。 Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。 这种基于名字的手段使得在语言中最小的封装单元是package。一个struct类型的字段对同一个包的所有代码都有可见性，无论你的代码是写在一个函数还是一个方法里。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 go 函数]]></title>
    <url>%2F2019%2F01%2F05%2Fgo%2Fgo_grammar%2Fgo_5%2F</url>
    <content type="text"><![CDATA[函数，代码封装的基本单元 1. 函数函数通常使用起来并不复杂，定义或声明函数后，直接使用即可。但是为了函数更加易用，编程语言会为函数添加很多特性。在 Python 和 Go 中，函数都是一等”公民”，即函数可以用在任何变量可以使用的地方，并且具有类型。因此接下来我们按照下面的顺序来讲解 Go 函数的相关内容: 第一部分: Go 函数作为基础数据类型的特性: 函数声明 函数的类型 函数的零值 第二部分: Go 函数语言层的特性 匿名函数与闭包 异常处理 Deferred 2. 函数2.1 函数声明Go 函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。函数的参数，返回值以及函数调用时的传值方式是函数的核心。 123func name(parameter‐list) (result‐list) &#123; body&#125; 下面是几个函数声明的示例:1234567891011121314151617func hypot(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y)&#125;// 参数类型相同时，可以合并func f(i, j, k int, s, t string) &#123; /* ... */ &#125;func f(i int, j int, k int, s string, t string) &#123; /* ... */ &#125;//func add(x int, y int) int &#123;return x + y&#125;func sub(x, y int) (z int) &#123; z = x ‐ y; return&#125;func first(x int, _ int) int &#123; return x &#125; // _ 可以强调某个参数未被使用func zero(int, int) int &#123; return 0 &#125;// 在返回值的类型都相同时， 返回值变量名可以传达函数返回值的含义func Size(rect image.Rectangle) (width, height int)func Split(path string) (dir, file string) 返回值与 Python 默认返回 None 不同，Go 有返回值列表，但是没有默认的返回值，返回值列表就是对函数返回值的约束: 返回值列表描述了函数返回值的变量名以及类型 如果没有返回值列表，函数不能返回任何值 如果包含返回值列表，函数必须返回与返回值列表类型相符的值 返回值可以被命名，此时每个返回值被声明成一个局部变量，并根据返回值的类型，被其初始化为 0 当如果函数返回一个无名变量或者没有返回值，返回值列表的括号可以省略。 Go 的函数返回值符合 Go 强变量类型的约束。 参数Go 函数参数没有默认值，也不能通过参数名指定行参。每一次函数调用都必须按照声明顺序为所有参数提供实参（参数值）。因此形参和返回值的变量名对于函数调用者而言没有意义。 为了让函数更加通用，Go 和 Python 都提供了可变参数的特性。在 Go 中声明可变参数时，需要在参数列表的最后一个参数类型之前加上省略符号“…”，这表示该函数会接收任意数量的该类型参数。 123456789101112func sum(vals...int) int &#123;total := 0for _, val := range vals &#123; total += val &#125; return total&#125;//fmt.Println(sum()) // "0"fmt.Println(sum(3)) // "3"fmt.Println(sum(1, 2, 3, 4)) // "10" 在上面的代码中，调用者隐式的创建一个数组，并将原始参数复制到数组中，再把数组的一个切片作为参数传给被调函数。如果原始参数已经是切片类型，可以像下面这样向函数传递参数。 123//values := []int&#123;1, 2, 3, 4&#125;fmt.Println(sum(values...)) // "10" 2.2 函数类型与值Go 中函数的类型被称为函数的标识符，函数的取决于参数和返回值的类型: 如果两个函数形式参数列表和返回值列表中的变量类型一一对应，那么它们有相同的类型和标识符 形参和返回值的变量名不不会影响函数标识符 函数类型的零值是 nil。调用值为nil的函数值会引起panic错误。函数值可以与nil比较，但是函数值之间是不可比较的，也不能用函数值作为map的key。函数之间之所以不可比，是因为函数闭包，函数会保留定义函数时，存在的自由变量的绑定。我们会在下面讲解。 123456789// 此处f的值为nil, 会引起panic错误var f func(int) intf(3)// 函数与 nil 比较var f func(int) intif f != nil &#123; f(3)&#125; 2.3 函数调用的传值方式我们把调用函数时传递给函数的值称为实参，函数接收参数值的变量称为行参。 Go 中实参通过值的方式传递，因此函数的形参是实参的拷贝。对形参进行修改不会影响实参。但是，如果实参包括引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的间接引用被修改。 在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值。函数的形参和有名返回值作为函数最外层的局部变量，被存储在相同的词法块中。我们甚至可以直接修返回值变量，来修改函数的返回值。我们会在讲解 Deffer 时详述。 说完了函数作为基本类型的特性，我们再来看为了方便编程，Go 为函数提供的语言层特性。 3. 函数特性3.1 函数闭包Go 里面一个有意思的地方是拥有函数名的函数只能在包级语法块中被声明。即我们不能在函数内部使用，使用 func name(parameter‐list) (result‐list) 方式定义函数，但不带 name 的 func (parameter‐list) (result‐list) 匿名函数可以。func (parameter‐list) (result‐list) 是 Go 函数的函数字面量。函数值字面量是一种表达式，它的值被成为匿名函数（anonymousfunction） 说起来比较绕，即如果我们想在函数内定义命名函数必须使用下面这种方式；或者直接使用匿名函数。 123456789101112131415161718192021// 1. 函数内定义命名函数func f1(a, b int) (r int) &#123; v := func() &#123; r += b &#125; defer v() return a + b&#125;// 2. 直接使用匿名函数func squares() func() int &#123; var x int return func() int &#123; x++ return x * x &#125;&#125;f := squares()fmt.Println(f()) // "1"fmt.Println(f()) // "4" 注意在上面第二个示例中，squares中定义的匿名内部函数可以访问和更新squares中的局部变量，这意味着匿名函数和squares中存在变量引用。这就是函数闭包，也是函数值属于引用类型和函数值不可比较的原因。 需要注意的是函数闭包内保存的是变量的引用而不是变量的值。我们来看下面删除临时文件的示例: 12345678var rmdirs []func()for _, dir := range tempDirs() &#123; // dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) rmdirs = append(rmdirs, func() &#123; os.RemoveAll(dir) // NOTE: incorrect! &#125;)&#125; 在上面的程序中，for循环语句引入了新的词法块，循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以dir为例，后续的迭代会不断更新dir的值，当删除操作执行时，for循环已完成，dir中存储的值等于最后一次迭代的值。这意味着，每次对os.RemoveAll的调用删除的都是相同的目录。 如果你使用go语句或者defer语句会经常遇到此类问题。这不是go或defer本身导致的，而是因为它们都会等待循环结束后，再执行函数值。 3.2 Defer 机制Go 的 Defer 机制与 Python 的上下文管理器有点类似，都是为了保证某些代码一定要执行，无论代码是否出现了异常。 defer 的语法很简单，只需要在调用普通函数或方法前加上关键字defer。 当defer语句被执行时，跟在defer后面的函数会被延迟执行。 直到包含该defer语句的函数执行完毕时，defer后的函数才会被执行，不论包含defer语句的函数是通过return正常结束，还是由于panic导致的异常结束。 可以在一个函数中执行多条defer语句，它们的执行顺序与声明顺序相反。 通过defer机制，不论函数逻辑多复杂，都能保证在任何执行路径下，资源被释放。释放资源的defer应该直接跟在请求资源的语句后。需要注意的是跟在 defer 之后的是函数调用，而不是函数本身。 12345678910111213141516171819// defer 关闭文件package ioutilfunc ReadFile(filename string) ([]byte, error) &#123; f, err := os.Open(filename) if err != nil &#123; return nil, err &#125; defer f.Close() return ReadAll(f)&#125;// 释放锁var mu sync.Mutexvar m = make(map[string]int)func lookup(key string) int &#123; mu.Lock() defer mu.Unlock() return m[key]&#125; 利用 defer中的函数会在return语句更新返回值变量后再执行，以及在函数中定义的匿名函数可以访问该函数包括返回值变量在内的所有变量，我们就可以上面说到的改变函数返回值的目的。 123456func triple(x int) (result int) &#123; defer func() &#123; result += x &#125;() return double(x)&#125;fmt.Println(triple(4)) // "12 3.3 错误与异常处理严格的区分错误和异常，应该是 Go 编码风格一个最大的特点。在Go中，错误是程序运行的几个预期的结果之一。而异常是未被预料到的错误，即bug，而不是那些在健壮程序中应该被避免的程序错误。正因为如此，在 Go 的代码中你会看到很多类似下面的条件判断。Go 将对错误的处理放在了代码的逻辑控制中，让程序员更多的关注错误。 1234567891011// 导致失败的原因只有一个，额外的返回值可以是一个布尔值，通常被命名为okvalue, ok := cache.Lookup(key) if !ok &#123; // ...cache[key] does not exist…&#125;// 导致失败的原因不止一种时，额外的返回值是error类型，resp, err := http.Get(url)if err != nil&#123; return nill, err&#125; 错误处理对于那些将运行失败看作是预期结果的函数，它们会返回一个额外的返回值，通常是最后一个，来传递错误信息。调用者需要处理程序出现的潜在错误。因此Go中大部分函数的代码结构几乎相同，首先是一系列的初始检查，防止错误发生，之后是函数的实际逻辑。 对于函数返回的错误，通常有以下五种处理方式: 传播错误 重新尝试失败的操作 输出错误信息并结束程序 有时，只输出错误信息就足够了，不需要中断程序的运行 直接忽略掉错误 需要注意的是，输出错误信息并结束程序只应在main中执行。对库函数而言，应仅向上传播错误，除非该错误意味着程序内部包含不一致性，即遇到了bug，才能在库函数中结束程序。 异常处理Go 中的异常称为 Panic。一般而言，当panic异常发生时，程序会中断运行，并立即执行在该goroutine 中被延迟的函数（defer 机制），在Go的panic机制中，延迟函数的调用在释放堆栈信息之前。直接调用内置的panic函数也会引发panic异常，panic函数接受任何值作为参数。 通常来说，不应该对panic异常做任何处理，但有时候我们需要从异常中恢复，此时就需要 Go 的 Recover 机制来捕获异常。 12345678func Parse(input string) (s *Syntax, err error) &#123; defer func() &#123; if p := recover(); p != nil &#123; err = fmt.Errorf("internal error: %v", p) &#125; &#125;()// ...parser...&#125; 如上所示，如果在deferred函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。 通常我们不应该不加区分的恢复所有的panic异常，同时作为被广泛遵守的规范，也不应该试图去恢复其他包引起的panic。安全的做法是有选择性的recover。 为了标识某个panic是否应该被恢复，我们可以将panic value设置成特殊类型。在recover时对panic value进行检查，如果发现panic value是特殊类型，就将这个panic作为errror处理，如果不是，则按照正常的panic进行处理。 123456789101112func soleTitle(doc *html.Node) (title string, err error) &#123; type bailout struct&#123;&#125; defer func() &#123; switch p := recover(); p &#123; case nil: // no panic case bailout&#123;&#125;: // "expected" panic err = fmt.Errorf("multiple title elements") default: panic(p) // unexpected panic; carry on panicking &#125; &#125;()&#125; 最后某些致命错误会导致Go在运行时终止程序，无法恢复，比如内存不足。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 go 复合数据类型]]></title>
    <url>%2F2019%2F01%2F04%2Fgo%2Fgo_grammar%2Fgo_4%2F</url>
    <content type="text"><![CDATA[Go 的类型系统 1. Go 的复合数据类型接着上一篇，我们来继续讨论 Go 里面的复合数据类型，包括数组、slice、map和结构体。数组和结构体是聚合类型；它们的值由许多元素或成员字段的值组成。slice,map 分别与 Python 中的 array.Array,dict 相对应，它们是 Go 提供给我们容器数据类型。 编程语言提供的复合数据类型应该是数据结构与算法的基础内容，如果你熟悉常用的数据结构，对复合类型的特性和支持的操作应该很容易就能理解。因此接下来的内容，我们会先简单说一说数据结构的特点，然后在介绍它们在 Go 中的实现和支持的操作。 2. 数组数组应该是最基本的数据结构，简单来说，数组具有如下特性: 数组是一段连续的内存空间，用来存储一组具有相同类型的数据 数组一经创建，大小便不能更改，连续的内存要求元素之间不能出现空洞 数组的特性决定了数组天然支持基于下标的“随机访问”(索引)。Go 中的数组我们需要关注以下几个知识点: 数组的长度是数组类型的一个组成部分，[3]int和[4]int是两种不同的数组类型 数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定 数组的可比性取决于数组的类型是否相同以及数组元素是否可比，只有当两个数组类型相同并且所有元素都是相等的时候数组才相等 下面是数组常用操作的代码示例: 1234567891011121314151617181920212223242526// 1. 数组字面量var q [3]int = [3]int&#123;1, 2, 3&#125;q := [...]int&#123;1, 2, 3&#125; // “...”省略号，表示数组的长度是根据初始化值的个数来计算r := [...]int&#123;99: ‐1&#125; // 直接按位置初始化，未初始化的为对应类型的零值// 2. 索引和切片fmt.Println(q[0]) // print the first elementfmt.Println(q[len(q)‐1]) // print the last element, q[2]e := [3]int&#123;1, 2, 3&#125;ff := e[0:2] // 对数组切片返回的是 slice 而不是原数组类型if ff == e &#123; // missmatch type []int and [3]int&#125;// 3. for 循环迭代for i, v := range q &#123; fmt.Printf("%d %d\n", i, v)&#125;// 4. 数组可比性a := [2]int&#123;1, 2&#125;d := [3]int&#123;1, 2&#125;fmt.Println(a == d) // compile error: cannot compare [2]int == [3]int 3. slice 切片因为数组的大小固定，类型限定严格，我们通常很少直接使用数组，使用更多的是数组的容器，Go 中数组的容器类型就是 slice (切片)。容器的最主要作用是能够根据元素大小对数组进行扩缩容。因此我们可以从 slice 的组成和扩缩容两个方面去理解 slice。 3.1 slice 组成Go 的 slice由三个部分构成： 指针: 指针指向第一个slice元素对应的底层数组元素的地址 容量: 容量一般是从 slice 的开始位置到底层数据的结尾位置 长度: 对应slice中元素的数目，长度不能超过容量 需要注意的是，因为 slice 底层数组是可以共享(通常是由于切片行为引起的)，因此slice 指针指向的第一个元素并不一定就是数组的第一个元素。内置的len和cap函数分别返回slice的长度和容量。下面是一个 slice 结构示意图: 1234months := [...]string&#123;1: "January", /* ... */, 12: "December"&#125;Q2 := months[4:7]summer := months[6:9] 对数组 months 的切片操作返回的是 slice []int，Q2和summer 共用了底层的 months 数组。 3.2 slice 扩缩容slice 扩缩容策略由 append 函数实现，但 append 只能向slice追加元素，Go 并没有删除 slice 中元素的函数。append扩容的过程大体是这样的: 在每次向 slice 添加时，append 会判断当前数组的大小是否足以容纳新增元素，足够则直接插入 如果数组容量不够，append 将创建一个原有数组两倍大小的新数组，并将原数组中的元素拷贝到新数组中去 最后将 slice 中的指针的指向新的底层数组 append 函数可以向 slice 追加多个元素，甚至追加一个slice: 123456var x []intx = append(x, 1)x = append(x, 2, 3)x = append(x, 4, 5, 6)x = append(x, x...) // append the slice xfmt.Println(x) // "[1 2 3 4 5 6 1 2 3 4 5 6]" 需要注意的是，通常我们要将 append 的返回值直接赋值给输入的slice变量，这么做与 Go 中函数的参数传值方式有关: Go 中的函数参数是按值传递的，因此传入 append 的是 slice 的副本，但是它们的指针指向了相同的底层数组 如果 append 函数发生了扩容，函数内的 slice 副本将指向新的内存数组，此时 append 函数将不会影响到传入的 slice 变量，为了达到修改 slice 的目的，通常要对输入的slice变量重新赋值 3.3 slice 操作说完了 slice 的实现，我们再来看看 slice 支持的操作: slice 的字面量与数组类似，只是去掉长度声明 对 slice 的切片操作如果超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了slice，新slice的长度会变长 为了避免创建 slice 多次内存分配，内置的 make 函数可以创建指定长度和容量的 slice slice之间不能比较，我们不能使用==操作符来判断两个slice是否含有全部相等元素，slice唯一合法的比较操作是和nil比较 因为 Go 没有提供删除 slice 元素的函数，只能采用覆盖的方式进行 slice 元素删除 下面是 slice 常用操作的代码示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243// 1. slice 字面量var m = []int&#123;3: 10&#125;// 2. slice 创建函数// make创建了一个匿名的数组变量，然后返回一个slicemake([]T, len)make([]T, len, cap) // same as make([]T, cap)[:len]// 3. slice 与 nil 的比较和转换if summer == nil &#123; /* ... */ &#125;var s []int // len(s) == 0, s == nils = nil // len(s) == 0, s == nils = []int(nil) // len(s) == 0, s == nil，类型转换s = []int&#123;&#125; // len(s) == 0, s != nil// 4. slice 为空测试，不应该使用 s == nilif len(s) == 0&#123;&#125;// 5. slice 复制// copy函数可以方便地将一个slice复制另一个相同类型的slice// copy函数将返回成功复制的元素的个数，等于两个slice中较小的长度copy(m, s) // 将 s 复制到 m// 6. slice 元素删除//如果要保持 slice 原来顺序func remove(slice []int, i int) []int &#123; copy(slice[i:], slice[i+1:]) return slice[:len(slice)‐1]&#125;//如果不用保持原来顺序的话，使用最后元素覆盖删除元素func remove(slice []int, i int) []int &#123; slice[i] = slice[len(slice)‐1] return slice[:len(slice)‐1]&#125;// 7. slice 模拟栈操作stack = append(stack, v) // push vtop := stack[len(stack)‐1] // top of stackstack = stack[:len(stack)‐1] // pop 4. Map 散列表在Go语言中，一个map就是一个散列表的引用，散列表是映射的一种实现方式，因此要想理清楚散列表，我们要从映射入手。所谓映射就是支持以下方法的键值对: M[k]: 返回键 k 对应的值，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 我列出了 Python 中与之对应的方法，但是 Go 中实现方式有所不同，我们会在下面讲解。散列表是映射高效的实现方式，可以实现 O(1) 时间复杂度的元素查找。那散列表是如何实现的呢？ 4.1 散列表的实现散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，有三个核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 下面是散列表实现映射的示意图: 限于篇幅的原因，有关散列表的实现，我就不过多解释，不了解的同学可以看看这篇文章散列表实现。这里我们需要关注的是散列表在使用上的限制。 首先，由于映射过程以及散列冲突的存在，所有的编程语言的散列表都会有以下两点要求: key 不可变，如果key 可变，元素的哈希值就会变化，查找就会失败 key 之间可比，当发生散列冲突时，要通过比较进行二次查找 而 Go 对散列表使用更加严格: 散列表中所有的key必须是相同的类型，所有的value也必须是相同的类型，但是 key 和 value 的类型可以不同 因为 Go 中可变的元素都是不可比的，所以上面的条件就退化成 key 必须是支持==比较运算符的数据类型,例如整数、数组或结构体等 虽然浮点数类型也是支持相等运算符比较的，但是将浮点数用做key类型则是一个坏的想法，最坏的情况是可能出现的NaN和任何浮点数都不相等 4.2 map 操作说完了散列表的实现，接下来我们看看 Go map 支持的操作。在Go语言中，一个map就是一个哈希表的引用，map类型可以写为map[K]V，其中K和V分别对应key和value。与 slice 类似，我们可以使用字面量和 make 来创建 map。 map 支持上面所说的映射操作，但是与 Python 相比 Go map 有以下两个鲜明特点: key 不存在时，执行 M[key]，不会触发异常，而是返回 value 类型对应的零值 map类型的零值是nil，也就是没有引用任何哈希表，map上的查找、删除、len和range循环都可以安全工作在nil值的map上，它们的行为和一个空的map类似。但是向一个nil值的map存入元素将导致一个panic异常 此外和slice一样，map之间也不能进行相等比较；唯一的例外是和nil进行比较。要判断两个map是否包含相同的key和value，我们必须通过一个循环实现。下面 map 操作的代码示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 1. 字面量ages := map[string]int&#123; "alice": 31, "charlie": 34,&#125;// 2. 初始化函数 makeages := make(map[string]int)ages["alice"] = 31ages["charlie"] = 34// 3. 元素访问与删除ages["alice"] = 32fmt.Println(ages["alice"]) // "32delete(ages, "alice") // remove element ages["alice"]// 元素不存在的判断if age, ok := ages["bob"]; !ok &#123; /* ... */ &#125; // 判断元素是否存在// 4. 迭代和遍历，迭代总是随机和无序的for name, age := range ages &#123; fmt.Printf("%s\t%d\n", name, age)&#125;// 有序遍历import "sort"var names []stringfor name := range ages &#123; names = append(names, name)&#125;sort.Strings(names)for _, name := range names &#123; fmt.Printf("%s\t%d\n", name, ages[name])&#125;// 5. 零值，以及是否为空的比较var ages map[string]intfmt.Println(ages == nil) // "true"fmt.Println(len(ages) == 0) // "true"// 6. 两个相同 map 判等func equal(x, y map[string]int) bool &#123; if len(x) != len(y) &#123; return false&#125; for k, xv := range x &#123; // 注意必须先判断，元素是否存在 if yv, ok := y[k]; !ok || yv != xv &#123; return false &#125; &#125; return true&#125; 最后，Go语言中并没有提供一个set类型，可以通过 map 实现类似set的功能，常用的 map 类型就是map[string]bool。 5. 结构体结构体是一种聚合的数据类型由零个或多个任意类型的值聚合成的实体。每个值称为结构体的成员。结构体是 Go 提供给我们创建自定义类型的载体，下面是一个创建示例: 12345678910type Employee struct &#123; ID int Name, Address string DoB time.Time Position string Salary int ManagerID int&#125;var dilbert Employee struct 定义了一个结构体，type 为这个结构体定义类型别名，便于引用，这种定义方式与 C 很接近。 在结构体的定义上，Go 中还有下面一些特性: 结构体成员的输入顺序也有重要的意义，拥有相同成员但是成员顺序不同的结构体属于不同的结构体类型 如果结构体成员名字是以大写字母开头的，那么该成员就是导出的；这是Go语言导出规则决定的。一个结构体可能同时包含导出和未导出的成员。 结构体的操作稍显复杂，我们分成下面两块来讲解 结构体通用操作，包括成员变量的引用，结构体的创建和比较 结构体的嵌入和匿名变量，这个是 Go 语言的特性，需要重点关注 5.1 结构体通用操作成员引用结构体是一个变量，它所有的成员也同样是变量，可以赋值或者取址，然后通过指针访问。结构体变量的成员可以通过点操作符访问，点操作符也可以和指向结构体的指针一起工作： 123456789101112// 通过点操作直接访问var dilbert Employeedilbert.Salary ‐= 5000// 可以对成员变量取址，然后访问position := &amp;dilbert.Position*position = "Senior " + *position // promoted, for outsourcing to Elbonia// 点操作也可以直接用在结构体指针上var employeeOfTheMonth *Employee = &amp;dilbertemployeeOfTheMonth.Position += " (proactive team player)" // 等同于(*employeeOfTheMonth).Position += " (proactive team player)" 结构体字面量结构体字面值有两种语法格式: 以结构体成员定义的顺序为每个结构体成员指定一个面值，这种方式在结构定义发生变化时就会导致编译错误，因此这种方式只在定义结构体的包内部使用，或者是在较小的结构体中使用，这些结构体的成员排列比较规则 以成员名字和相应的值来初始化，可以包含部分或全部的成员,如果成员被忽略的话将默认用零值 需要注意的是两种不同形式的写法不能混合使用。而且，你不能企图在外部包中用第一种顺序赋值的技巧来偷偷地初始化结构体中未导出的成员。 123456789101112131415// 方式一: 按照成员定义顺序，依次赋值type Point struct&#123; X, Y int &#125;p := Point&#123;1, 2&#125;// 方式二: 以成员名字和相应的值来初始化f := Point&#123;X: 1, Y: 2&#125;// 未导出变量，无法赋值package ptype T struct&#123; a, b int &#125; // a and b are not exportedpackage qimport "p"var _ = p.T&#123;a: 1, b: 2&#125; // compile error: can't reference a, bvar _ = p.T&#123;1, 2&#125; // compile error: can't reference a, b 除了字面量外，我们还可以用前面介绍的 new 函数来创建结构体变量 1234pp := &amp;Point&#123;1, 2&#125;pp := new(Point)*pp = Point&#123;1, 2&#125; 结构体的零值与比较结构体类型的零值是每个成员都是零值。如果结构体没有任何成员的话就是空结构体，写作struct{}。它的大小为0，也不包含任何信息，通常用作占位。 如果结构体的全部成员都是可以比较的，那么结构体也是可以比较的。可比较的结构体类型和其他可比较的类型一样，可以用于map的key类型。 1234567type address struct &#123; hostname string port int&#125;hits := make(map[address]int)hits[address&#123;"golang.org", 443&#125;]++ 5.2 结构体的嵌入与匿名变量结构体嵌入结构体嵌入是 Go 语言提供的类似类继承机制，形式上是让一个命名的结构体包含另一个结构体类型的匿名成员，目的是实现通过简单的点运算符x.f来访问匿名成员链中嵌套的x.d.e.f成员的机制。说起来很复杂，举个例子。考虑一个图形系统，我们需要定义点，线，圆。显然圆可以在点即园心的基础上添加半径来表示。在 Go 中可以使用下面的结构体表示这样的结构。 1234567891011121314151617181920// 点type Point struct &#123; X, Y int&#125;// 圆type Circle struct &#123; Center Point Radius int&#125;type Wheel struct &#123; Circle Circle Spokes int&#125;// 创建圆var w Wheelw.Circle.Center.X = 8w.Circle.Center.Y = 8w.Circle.Radius = 5w.Spokes = 20 如上所示，现在想访问Wheel的结构体成员 X 将变的异常繁琐。而结构嵌入就是为了在满足上面结构不变的情况，实现 w.X 成员快速访问。结构体声明如下所示: 1234567891011121314151617181920type Point struct &#123; X, Y int&#125;type Circle struct &#123; Point // 匿名成员 Radius int&#125;type Wheel struct &#123; Circle // 匿名成员 Spokes int&#125;var w Wheelw.X = 8 // equivalent to w.Circle.Point.X = 8w.Y = 8 // equivalent to w.Circle.Point.Y = 8w.Radius = 5 // equivalent to w.Circle.Radius = 5w.Spokes = 20 Point，Circle 此时为匿名成员。所谓匿名成员，就是只声明一个成员对应的数据类型而不指名成员的名字。匿名成员并不是没有名字，其名字就是命名的类型名字，但是这些名字在点操作符中是可选的。上面 w.Circle.Point.X = 8 这样的访问方式依旧是合法的。 不幸的是，结构体字面值并没有简短表示匿名成员的语法， 因此下面的语句都不能编译通过。结构体字面值必须遵循形状类型声明时的结构 12345678910111213// 错误w = Wheel&#123;8, 8, 5, 20&#125; // compile error: unknown fieldsw = Wheel&#123;X: 8, Y: 8, Radius: 5, Spokes: 20&#125; // compile error: unknown fields// 正确w = Wheel&#123;Circle&#123;Point&#123;8, 8&#125;, 5&#125;, 20&#125;w = Wheel&#123; Circle: Circle&#123; Point: Point&#123;X: 8, Y: 8&#125;, Radius: 5, &#125;, Spokes: 20, // NOTE: trailing comma necessary here (and at Radius)&#125; 匿名变量的使用要求需要注意的是 Go 对匿名成员的使用存在一些约束: 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针 因为匿名成员也有一个隐式的名字，因此不能同时包含两个类型相同的匿名成员，这会导致名字冲突 因为成员的名字是由其类型隐式地决定的，所有匿名成员也有可见性的规则约束 比如将上面改成小写字母开头的point和circle），此时在包内依旧可以使用 w.X = 8；但是在包外部，因为circle和point没有导出不能访问它们的成员，因此简短的匿名成员访问语法也是禁止的。 最后匿名成员并不要求是结构体类型；其实任何命名的类型都可以作为结构体的匿名成员。但是为什么要嵌入一个没有任何子成员类型的匿名成员类型呢？答案是匿名类型的方法集。 简短的点运算符语法可以用于选择匿名成员嵌套的成员，也可以用于访问它们的方法。实际上，外层的结构体不仅仅是获得了匿名成员类型的所有成员，而且也获得了该类型导出的全部的方法。 这个机制可以用于将一个有简单行为的对象组合成有复杂行为的对象。组合是Go语言中面向对象编程的核心。我们在下一章将方法时会再来讨论。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 go 基础数据类型]]></title>
    <url>%2F2019%2F01%2F03%2Fgo%2Fgo_grammar%2Fgo_3%2F</url>
    <content type="text"><![CDATA[Go 的类型系统 1. Go 中的数据类型Go语言将数据类型分为四类：基础类型、复合类型、引用类型和接口类型。基础类型，包括：数字、字符串和布尔型。复合数据类型包括数组和结构体(通过组合简单类型，来表达更加复杂的数据结构)。引用类型包括指针、切片、字典、函数、通道，虽然数据种类很多，但它们都是对程序中一个变量或状态的间接引用。函数和通道并不属于我们通常所说的数据类型，我们放在后面相关章节来介绍。 对于大多数编程语言来说，基础类型以及它们之上的可用运算符都是类似，更加需要我们注意的是，编程语言提供给我们的数据容器以及操作它们的方式。因此我们分成以下几个部分来讲解 Go 的类型系统。 数值与布尔型 字符串与编码 数组与结构体 切片 字典 本节我们先来介绍 Go 中的基本数据类型，即数值，布尔值和字符串。在介绍这些数据类型之前，我们先来谈谈变量类型的含义，这有助于加深我们对编程语言本身的理解。 1.1 变量的类型无论什么数据，在存储器内都是 0-1，那数据是数值还是字符完全取决于我们对这些二进制数据的解释。变量的类型就是用来定义了对应存储值的属性特征，它们在内部是如何表达的，是否支持一些操作符，以及它们自己关联的方法集等。 而在一个编程语言类型系统中，除了内置的变量类型外，还有如下一些问题: 自定义类型 定义新的类型名称(类型重命名) 类型转换 1.2 自定义类型自定义类型允许我们在编程语言底层类型的基础上定义更加复杂的类型，它是面向对象编程的基础。在 Go 中自定义类型就是使用结构体。 1.2 类型重命名在任何程序中都会存在一些变量有着相同的内部结构，但是却表示完全不同的概念。例如，一个int类型的变量可以用来表示一个循环的迭代索引、或者一个时间戳、或者一个文件描述符。类型重命名就是为分隔不同概念的类型。新的类型名称使用类型声明语句创建。Go 的类型声明语法如下所示: 1type 类型名字 底层类型 新的类型和底层类型具有相同的底层结构，支持和底层类型相同的运算符。但是新类型与底层类型以及基于相同底层类型的不同新类型，是完全不不同的数据类型。 12345678import "fmt"type Celsius float64 // 摄氏温度type Fahrenheit float64 // 华氏温度// 因为 Fahrenheit，float64，Celsius 是完全不同的类型，所以它们不能直接比较// compile error: type mismatchfmt.Println(Fahrenheit(1.0) == float64(1.0))fmt.Println(Fahrenheit(1.0) == Celsius(1.0)) 1.2 类型转换对于每一个类型T，都有一个对应的类型转换操作T(x)，用于将x转为T类型。如果T是指针类型，可能会需要用小括弧包装T，比如 (*int)(0)。 在编程语言中，不同类型的变量之间是不能进行直接赋值和比较的，要这样做就需要显示或隐式的类型转换。对于不同编程语言而言，有不同的类型转换规则，但大多数规则都是类似。在 Go 中: 数值之间的转类型转换有一套特定规则，这个规则在不同的编程语言中是一样的，比如将浮点数转换为整数会损失小数部分 显示的类型转换``T(x)要求 T 和 x 具有相同的底层基础类型或指向相同底层结构的指针类型；对于数据容器而言需要它们有类似的实现，比如可以将一个字符串转为 []byte类型 自定义的新类型名称，不会自动应用底层类型的隐式类型转换规则，一个命名类型的变量只能和另一个有相同类型的变量，或有着相同底层类型的未命名类型的值之间做比较；依赖相同底层类型的不同自定义类型之间想要进行比较或赋值必须进行显示的类型转换。 1234567891011121314import "fmt"// 自定义类型与其底层类型不可比较type tt intfmt.Println(tt(1) &gt; int(0)） // compile error: type mismatchvar c Celsiusvar f Fahrenheitfmt.Println(c == 0) // "true"fmt.Println(f &gt;= 0) // "true"// 依赖相同底层类型的不同自定义类型不可比较fmt.Println(c == f) // compile error: type mismatchfmt.Println(c == Celsius(f)) // "true"! 说了这么多，接下来我们开始正式讲解 Go 中的数据类型。 2. 数值Go语言的数值类型包括几种不同大小的整数、浮点数和复数，还有一些为特定用途定义的类型别名。 2.1 整数整数包括如下几种类型及类型别名，其中int是应用最广泛的数值类型。因为内置的len函数返回一个有符号的int，所以尽管Go语言提供了无符号数和运算，并且在数值本身不可能出现负数的情况下，我们还是倾向于使用有符号的int类型，就像数组的长度那样。 出于这个原因，无符号数往往只有在位运算或其它特殊的运算场景才会使用，就像bit集合、分析二进制文件格式或者是哈希和加密操作等。它们通常并不用于仅仅是表达非负数量的场合。 类型 大小 含义 uint8 8 无符号 8 位整型 uint16 16 无符号 16 位整型 uint32 32 无符号 32 位整型 uint64 64 无符号 64 位整型 uint 32 或 64位 平台相关，取决于CPU平台机器字大小 int 32 或 64位 平台相关，取决于CPU平台机器字大小 int8 8 有符号 8 位整型 int16 16 有符号 16 位整型 int32 32 有符号 32 位整型 int64 64 有符号 64 位整型 byte 8, int8的别名 表示原始的二进制数据 rune 32, int32的别名 Unicode字符，表示一个Unicode码点 uintptr 无符号整数，没有明确指定大小 用于存放一个指针，GO 底层使用 2.2 整数的运算符Go 的整数支持如下操作符号，其中大多数与其他语言类似，只有一个比较特殊x &amp;^ y，它表示将 x 中与 y 对应的且 y 中等于 1 的位置为 0，即位清空(AND NOT) 1234567# 优先级递减* / % # 算数运算符&lt;&lt; &gt;&gt; &amp; &amp;^ # 位运算符+ ‐ # 算数运算符| ^ # 位运算符== != &lt; &lt;= &gt; &gt;= # 比较运算符&amp;&amp;(AND) ||(or) # 逻辑运算符 2.3 浮点数Go语言提供了两种精度的浮点数，float32 和 float64 。浮点数的范围极限值可以在math包找到。常量math.MaxFloat32表示float32能表示的最大数值，对应的 float64 为 math.MaxFloat64。 一个float32类型的浮点数可以提供大约6个十进制数的精度，而float64则可以提供约15个十进制数的精度；通常应该优先使用float64类型。小数点前面或后面的数字都可能被省略（例如.707或1.）。很小或很大的数最好用科学计数法书写，通过e或E来指定指数部分。 1234567// float32的有效bit位只有23个，整数大于23bit表示范围时，将出现误差var f float32 = 16777216 // 1 &lt;&lt; 24fmt.Println(f == f+1) // "true"!const a = .909const Avogadro = 6.02214129e23 // 阿伏伽德罗常数const Planck = 6.62606957e‐34 // 普朗克常数 math包中除了提供大量常用的数学函数外，还提供了IEEE754浮点数标准中定义的特殊值的创建和测试。 123456789v := math.Inf(1) // 返回正无穷p := math.Inf(-1) // 返回负无穷n := math.NaN() // 返回 NaN 非数，一般用于表示无效的除法操作结果0/0或Sqrt(­1).t ：= math.IsNaN(n) // 测试是否为 NaN// NaN和任何数都是不相等的nan := math.NaN()fmt.Println(nan == nan, nan &lt; nan, nan &gt; nan) // "false false false" 2.4 复数Go语言提供了两种精度的复数类型：complex64 和 complex128，分别对应 float32 和 float64 两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部。复数的字面量使用 i 后缀。 123456789var x complex128 = complex(1, 2) // 1+2ivar y complex128 = complex(3, 4) // 3+4ifmt.Println(x*y) // "(‐5+10i)"fmt.Println(real(x*y)) // "‐5"fmt.Println(imag(x*y)) // "10"// 复数的字面量x := 1 + 2iy := 3 + 4i 3. 布尔值Go 布尔类型的值只有两种：true 和 false，if 和 for 语句的条件部分都是布尔值。需要特别注意的是 在 Go 中布尔之值不会与其他任何类型作隐式转换，将其他类型的值用在 if 或 for 中作为条件判断时，必须作显示的类型转换。 1234567func itob(i int) bool &#123; return i != 0 &#125;b := 0i := 0if itob(b) &#123; i = 1&#125; 4. 字符串4.1 字符串操作创建字符串最简单的方式是字符串字面量。在 Go 中，单个字符的字面量使用单引号，字符串字面量使用双引号，原生字符串使用反引号。所谓原生字符类似于 Python 中的 r&quot;&quot; 用于消除字符串中的所有转义操作。Go 的原生字符甚至可以消除换行，实现跨行，所以原生字符广泛使用再正则表达式，HTML模板、JSON面值以及命令行提示信息中。 与 Python 将大多数字符串操作作为字符串对象的方法不同，Go 大多数的字符串操作都在 strings 包，我们将这部分内容放在后面专门介绍，先来看看Go 提供的字符串基础操作。下面是一些代码示例: 123456789101112131415161718192021// 原生字符串const GoUsage = `Go is a tool for managing Go source code.Usage:go command [arguments]`s := "hello, world"// 1. len 函数获取字符串长度fmt.Println(len(s)) // "12"// 2. 索引fmt.Println(s[0], s[7]) // "104 119" ('h' and 'w')// 3. 切片fmt.Println(s[0:5]) // "hello// 4. + 拼接fmt.Println("goodbye" + s[5:]) // "goodbye, world"// 5. 不可修改s[0] = 'L' // compile error: cannot assign to s[0] 虽然字符串作为一个基本的数据类型被几乎所有的编程语言所支持，但是字符串本身确是很复杂。而复杂的地方至少有如下两点: 字符串的实现 字符的编码问题 4.1 字符串的实现 上面是字符串以及切片操作结果的示意图，在 Go 中，字符串是一个不可改变的字节序列，底层是一个字符数组，一个字符串可认为由两个部分构成:指针、长度 指针指向第一个字符对应的底层数组元素的地址 长度对应字符串中字符的个数 字符串的底层数组位于受保护的内存中，不能被修改，因此字符串是不可变的 对字符串变量进行重新赋值，不会改变字符串的底层数组，而只是改变了字符串中的指针的指向 不变性意味两个字符串可以安全的共享相同的底层数据，这使得字符串复制和切片不会发生实际的复制行为，而是直接共享原有的底层字符数组，因此操作非常迅速。 4.3 字符集在上面关于字符串的实现中，我们忽略了一个问题，即如何把字符串中的字符保存在一个数组中。我们知道在计算机上保存的数据只有二进制的 0 和 1，显然计算机没办法直接保存每个字符，于是就有了字符集的概念。 对于字符集以及字符的编码和解码，我是这样理解的: 字符集中最重要的概念就是码表，其作用是将每个字符与一个特定的数字对应起来，用特定的数字(又称码点)来表示特定的字符，因此码表就是字符集能表示的字符范围 有了码表，并没有解决保存字符的问题，显然就算是数字也要保存为整数的二进制格式。对于不同字符集而言，码点到特定的二进制也有一套特定的转换规则 因此，字符集实现了字符 --&gt; 码点 ---&gt; 码点二进制值的转换过程，码点 ---&gt; 码点二进制值被称为编码，反过来就是解码 有了上面的说明，就能解释清楚下面两个问题: ASCII 字符集 与 Unicode 字符集区别: ASCII字符集使用7bit来表示一个码点，而 Unicode 使用32bit表示一个 Unicode 码点，Unicode 显然能表示更大的字符范围 UTF8 编码与 UTF32 编码的区别: UTF32 编码直接将每个 Unicode 码点保存为 int32 的整数，而UTF8 会根据Unicode码点变长编码成二进制，它们都表示 Unicode 字符集，但是编码规则不同 4.4 字符串和 []runeGo语言的源文件采用UTF8编码，因此程序运行之后，保存在字符数组内的是 UTF8 编码的二进制值。因此前面我们所讲的字符串基础操作，操作的其实是UTF8 编码的每个字节，并不是我们理解的字符。为了处理真实的字符，我们需要对字符串进行解码。Go 将 Unicode 码点表示为 rune 整数类型，因此字符串解码后的类型就是 []rune。下面就是Go 中字符编码解码的一些代码示例: 1234567891011121314151617181920212223242526272829303132// 1. 字符串基础操作操作的是 UTF8 中的字节import "unicode/utf8"s := "Hello, 世界"fmt.Println(len(s)) // "13"fmt.Println(utf8.RuneCountInString(s)) // "9"// 2. unicode 提供了 UTF8 的解码函数for i := 0; i &lt; len(s); &#123; r, size := utf8.DecodeRuneInString(s[i:]) fmt.Printf("%d\t%c\n", i, r) i += size&#125;// 3. range 会自动对字符串解码for i, r := range "Hello, 世界" &#123; fmt.Printf("%d\t%q\t%d\n", i, r, r)&#125;// 4. []rune 字符串的类型转换s := "プログラム"fmt.Printf("% x\n", s) // "e3 83 97 e3 83 ad e3 82 b0 e3 83 a9 e3 83 a0"// 字符串 --&gt; []runer := []rune(s)fmt.Printf("%x\n", r) // "[30d7 30ed 30b0 30e9 30e0]// string 函数： []rune ---&gt; 字符串fmt.Println(string(r)) // "プログラム// 5. 生成Unicode码点字符的UTF8字符串fmt.Println(string(65)) // "A", not "65"fmt.Println(string(0x4eac)) // "京" 4.5 字符串和 []byte一个字符串是包含的只读字节数组，一旦创建，是不可变的。相比之下，一个字节slice(即 []byte，下一节我们会详述)的元素则可以自由地修改。字符串和字节slice之间可以相互转换： 123s := "abc"b := []byte(s)s2 := string(b) 4.6 字符串相关类型的包标准库中有四个包对字符串处理尤为重要：bytes、strings、strconv和unicode包 strings包提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能。 bytes包也提供了很多类似功能的函数，但是针对和字符串有着相同结构的[]byte类型 strconv包提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换 unicode包提供了IsDigit、IsLetter、IsUpper和IsLower等类似功能，它们用于给字符分类，每个函数有一个单一的rune类型的参数，然后返回一个布尔值 下面是字符串与数值转换的代码示例，我们会在后面专门讲解这些包的实现和使用。 123456789101112// 数值转字符串x := 123y := fmt.Sprintf("%d", x)fmt.Println(y, strconv.Itoa(x)) // "123 123"// 数值的进制转换fmt.Println(strconv.FormatInt(int64(x), 2)) // "1111011"s := fmt.Sprintf("x=%b", x) // "x=1111011// 字符串转数值x, err := strconv.Atoi("123") // x is an inty, err := strconv.ParseInt("123", 10, 64) // base 10, up to 64 bits 5. 常量5.1 常量的类型在讲常量之前，先问大家一个问题，你知道字面量，常量，变量，字面量类型之间的区别么？ 字面量是编程语言提供的用来创建特定值的快捷方式，因此字面量也有类型，特定的字面量代表什么类型，完全有编程语言决定。因此对于像下面的赋值语句来说，在字面量类型和变量类型之间发生了类型转换。 1var f float64 = 3 常量和变量都是变量，但是相比与变量，常量有以下特点: 常量的值不可变，并且常量的类型只能是基础类型：boolean、string或数字 常量表达式的值在编译期计算，而不是在运行期，因此常量可以是构成类型的一部分，例如用于指定数组类型的长度 因为常量也是变量，所以常量通常有确定的类型，但Go语言的常量有个不同寻常之处， Go 中的常量可以没有一个明确的基础类型。 首先在 Go 中，有六种无类型的字面量，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。例如0、0.0、0i和’\u0000’分别对应无类型的整数、无类型的浮点数、无类型的复数和无类型的字符。 其次在如下不带类型声明的常量声明语句中，不会发生隐式类型转换，常量的类型依旧为无类型的整数。 1const deadbeef = 0xdeadbeef // untyped int with value 3735928559 为了便于描述下面我们将无类型的字面量和常量统称为无类型常量，这些无类型常量有诸多好处。 编译器为这些无类型常量提供了比基础类型更高精度的算术运算。通过延迟明确常量的具体类型，无类型的常量不仅可以提供更高的运算精度，而且可以直接用于更多的表达式而不需要显式的类型转换。 只有常量可以是无类型的。当一个无类型的常量被赋值给一个变量的时候，或者出现在有明确类型的变量声明的右边，无类型的常量将会被隐式转换为对应的类型，如果转换合法的话。对于一个没有显式类型的变量声明（包括简短变量声明），字面量的形式将隐式决定变量的默认类型，Go 有一个明确的转换规则。如果要给变量一个不同的类型，我们必须显式地将无类型的常量转化为所需的类型，或给声明的变量指定明确的类型。 123456789101112131415161718192021222324252627282930// 1. 常量可以无类型，无类型常量可以提供更高的精度const ( deadbeef = 0xdeadbeef // untyped int with value 3735928559 a = uint32(deadbeef) // uint32 with value 3735928559 b = float32(deadbeef) // float32 with value 3735928576 (rounded up) c = float64(deadbeef) // float64 with value 3735928559 (exact) d = int32(deadbeef) // compile error: constant overflows int32 e = float64(1e309) // compile error: constant overflows float64 f = uint(‐1) // compile error: constant underflows uint)// 2. 无类型常量，可以直接应用在更多的表达式中，无需显示类型转换var f float64 = 3 + 0i // untyped complex ‐&gt; float64f = 2 // untyped integer ‐&gt; float64f = 1e123 // untyped floating‐point ‐&gt; float64f = 'a' // untyped rune ‐&gt; float64// 3. 有类型声明时，无类型常量将根据类型隐式类性转换var x float32 = math.Pivar y float64 = math.Pivar z complex128 = math.Pi// 4. 无类型声明时，根据字面量形式，决定变量类型i := 0 // untyped integer; implicit int(0) r := '\000' // untyped rune; implicit rune('\000')f := 0.0 // untyped floating‐point; implicit float64(0.0)c := 0i // untyped complex; implicit complex128(0i)var i = int8(0)var i int8 = 0 5.2 常量批量声明最后，Go 为常量的批量声明提供了一些便捷方式，下面是代码示例: 123456789101112131415161718192021222324252627282930313233343536// 1. 批量声明多个常量const ( e = 2.71828182845904523536028747135266249775724709369995957496696763 pi = 3.14159265358979323846264338327950288419716939937510582097494459)const ( a = 1 b // 省略初始化表达式，表示使用前面常量的初始化表达式写法， b=1 c = 2 d // d=2)// 2. iota常量生成器初始化，用于生成一组以相似规则初始化的常量type Weekday int const ( Sunday Weekday = iota // 在第一个声明的常量所在的行，iota将会被置为0， Monday // 然后在每一个有常量声明的行加一， 1 Tuesday // 2 Wednesday // 3 Thursday Friday Saturday)const ( _ = 1 &lt;&lt; (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 &lt;&lt; 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 &lt;&lt; 64) YiB // 1208925819614629174706176)]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 go 变量及流程控制]]></title>
    <url>%2F2019%2F01%2F02%2Fgo%2Fgo_grammar%2Fgo_2%2F</url>
    <content type="text"><![CDATA[Hello World! 1. Hello World抛开数据结构，代码封装和复杂的库文件，我们接触一门新语言的第一步可能就是学会这门语言的基础语法。下面是我写的 go 的一个 “Hello World” 程序。在这个简单的代码中包含了很多 Go 基础语法的内容: 变量及常量的命名，声明和创建 条件判断和循环 变量的生命周期与作用域 下面我们就分成这几块来讲讲 Go 的基础语法。 123456789101112131415161718192021package mainimport "fmt"const defaultUser = "unsigned"func main() &#123; name := "A" if name == defaultUser &#123; fmt.Println("Helll man") &#125; else &#123; fmt.Println("Hey it is you") &#125; num := 100 r := 0 for i := 0; i &lt;= num; i++ &#123; r += i &#125; fmt.Println(r)&#125; 2. 变量及常量的命名，声明和创建2.1 命名规则几乎所有的编程语言变量，常量，函数以及类型的命名规则都是相同的，即一个名字必须以一个字母或下划线开头，后面可以跟任意数量的字母、数字或下划线。 Go 与众不同的是名称中可以包含Unicode字母(不建议使用)，并且使用名字的开头字母的大小写决定了名字在包外的可见性。关于变量的导出我们会在模块的相关内容详述。 习惯上，Go语言程序员推荐使用驼峰式命名。 2.2 声明和创建Go语言主要有四种类型的声明语句：var、const、type和func，分别对应变量、常量、类型和函数实体对象的声明。我们先说变量以及常量。 与 Python 这种动态语言不同的是，Go 是静态语言，变量必须先声名才能使用。Go 中变量可以看成一个“容器”，一个变量对应一个保存了变量对应类型值的内存空间；变量一经声明，其类型就不能再改变。下面是 Go 中声明和创建变量的几种方式: 123456789101112//方式一: var 声明语句var name string = "abc"var i, j, k intvar b, f, s = true, 2.3, "four"//方式二: 函数内的短变量声明，用于局部变量的声明和初始化t := 10i, j := 0, 1//方式三: new 函数，创建变量，并返回对应变量的指针p := new(int) // 此处创建了两个变量: new 函数创建的匿名变量，以及指向匿名变量的指针变量 p*p = 2 varvar声明语句可以创建一个特定类型的变量，然后给变量附加一个名字，并且设置变量的初始值。对于 var 变量名字 类型 = 表达式，“类型”或“= 表达式”两个部分可以省略其中的一个。 如果省略的是类型信息，那么将根据初始化表达式来推导变量的类型信息。 如果初始化表达式被省略，那么将用零值初始化该变量，规则如下 数值类型变量对应的零值是0 布尔类型变量对应的零值是false 字符串类型对应的零值是空字符串 接口或引用类型（包括slice、指针、map、chan和函数）变量对应的零值是nil 数组或结构体等聚合类型对应的零值是每个元素或字段都是对应该类型的零值 常量的声明和创建使用 const 声明语句，用法与 var 类似。 短变量声明短变量声明语句用在函数内，用于声名和初始化局部变量，语法为变量名:=表达式，变量的类型根据表达式自动推导。Go 的短变量声明有一些微妙之处: 首先“:=”是一个变量声明语句，而“=”是一个变量赋值操作 其次，简短变量声明左边的变量可以包含已经声明过的变量，对于这些变量将只是赋值，而不是再声明 最后，简短变量声明语句中必须至少要声明一个新的变量否则无法通过编译 new 函数new 是 Go 预定义的一个函数，new(T)将创建一个T类型的匿名变量，初始化为T类型的零值，然后返回变量地址。 用new创建变量和普通变量声明语句方式创建变量没有什么区别，除了不需要声明一个临时变量的名字外。因为 new 只是一个普通函数，因此可以使用在任何函数可用的地方，甚至new名字可以被重定义其他类型。 3. 条件判断和循环看完了变量创建，我们再来看看 Go 为我们提供的逻辑控制语句: if, switch, for。Go 没有 while 语句，但是 for 语句包含了 while 语句的功能。除了 if 外，switch 和 for 的用法都不简单。 除了这些基础的逻辑控制语句外，Go 还有一个特殊的与 Go 高并发相关的多路复用器 select。 3.1 ifGo 应该是类 C 风格的语言，使用 {} 来分隔代码块。一个完整的 if 语句如下所示:1234567if r == 0 &#123; fmt.Println("aaa")&#125; else if r == 1 &#123; fmt.Println("bbbb")&#125; else &#123; fmt.Println("cccc")&#125; 3.2 switchswitch 是多分支条件判断的便捷语法，用于基于不同条件执行不同动作，Go 的 switch 有如下三种使用方式。 123456789101112131415161718192021222324252627282930//方式一: 变量值判断switch var1 &#123; case v1: // var1 变量与 case 语句中的值类型必须相同 ... case v2,v3: // 逗号分隔表示可匹配多个值 ... default: ...&#125;// 方式二: 条件判断的变形switch &#123; case condition1: ... case condition2, condition3: // 逗号分隔表示可匹配多个条件 ... default: ...&#125;// 方式三: type-switch 用来判断某个 interface 变量中实际存储的变量类型// 我们会在后面讲接口类型时详述switch x.(type) &#123; case type1: .... case type2: .... default: ....&#125; 不同语言的 switch 语句差异很大，Go 的 switch 有如下特点: switch 语句的执行过程是从上直下逐一测试，直到匹配就会停止 每个 case 分支的最后不需要再加break，即默认只会执行第一个匹配到的 case 分支 Python 中没有 switch 语句，shell 脚本则必须在每个 case 分支之后添加 break，否则第一次匹配成功后后，会继续匹配之后的 case 分支。 3.3 selectselect 类似于用于通信的switch语句，它的一个使用示例如下所示:1234567891011func main() &#123; var c1, c2 chan int var i1, i2 int select &#123; case i1 = &lt;-c1: fmt.Printf("received ", i1, " from c1\n") case c2 &lt;- i2: fmt.Printf("sent ", i2, " to c2\n") default: fmt.Printf("no communication\n") &#125; 在 select 中: 每个case必须是一个通信操作，要么是发送要么是接收 所有channel表达式都会被求值，如果有多个 case 可以运行，select会随机执行一个可运行的case 如果没有case可运行，此时 如果有default子句，则执行该语句，defalut 子句应该总是可运行的 如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值 3.3 forGo 的 for 循环有四种常见的使用方式，如下所示。最特殊的是第四种 for 循环的 range 格式，它可以对 slice、map、数组、字符串等进行迭代循环。 12345678910111213141516171819202122232425//方式一: 典型的类 C for 循环for init; condition; post &#123;&#125;//方式二: 类 while 循环for condition &#123;&#125;//方式三: 无限循环for &#123;&#125;//无限循环的另一种方式for true &#123;&#125;//方式四: 类Python 的迭代循环for index, value := range oldMap &#123; // index: 索引 // value: 索引对应的值&#125; 4. 变量的生命周期与作用域变量的生命周期指的是在程序运行期间变量有效存在的时间间隔，变量作用域是指源代码中可以有效使用这个名字的范围。虽然我将变量的生命周期与作用域放在一起，但是其实它们之间并没有什么联系。声明语句的作用域对应的是一个源代码的文本区域；它是一个编译时的属性。一个变量的生命周期是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用；是一个运行时的概念。 Go 与 Python 类似，通过引用计数的方式，解释会自动实现对象内存的分配和释放。变量的生命周期取决于变量是否可达，即其引用计数是否为 0，而与变量的作用域无关。虽然大多数位于函数内的局部变量的生命周期都是函数调用的存续区间，但是函数内的局部变量可以”逃逸”成为全局变量，或者从函数返回，从而延长生命周期。 变量的作用域取决于变量声明语句所在的语法块(又称词法域)，语法块通常由花括号显示限定，除此之外还有一些特殊的语法块。对于 Go 作用域从大到小依次是: 整个源代码，称为全局语法块 每个包的包语法块 每个源文件的源文件级的语法块 由显示花括号限定的由外而内的语法块 对于 if,for,switch,select 还有隐式的语法块 一个程序可能包含多个同名的声明，只要它们在不同的作用域。位于内部作用域的变量声明显然会覆盖外部的同名变量。对于大多数程序的作用于而言，都有类似规则。而 Go 比较特殊的是 if,for,switch,select引入的隐式作用域。 if, for 等的隐式作用域12345678if x := f(); x == 0 &#123; fmt.Println(x)&#125; else if y := g(x); x == y &#123; fmt.Println(x, y)&#125; else &#123; fmt.Println(x, y)&#125;fmt.Println(x, y) // compile error: x and y are not visible here 在上面的示例中存在多个作用域，从大到小依次是: 全局作用域 外层 if 语句条件部分创建隐式词法域 外层 if 语句花括弧包含的显式作用域 内层 if 语句条件部分创建隐式词法域 ….. 因此内层 if 语句的条件测试部分，能访问到外层 if 语句条件部分声明的变量 x。for 语句循环的初始化部分，switch 语句的条件测试部分都会引入类似的隐式作用域。 变量的作用域问题说起来比较复杂，但是大多数情况下，只要我们不在不同的作用域内声明同名变量，导致变量覆盖，基本上都不会现问题。但是在 Go 中要特别注意短变量声明语句的作用域。 在下面的示例中，虽然cwd在外部已经声明过，但是 := 语句还是将cwd和err重新声明为新的局部变量。因为内部声明的cwd将屏蔽外部的声明，因此上面的代码并不会正确更新包级声明的cwd变量。 1234567var cwd stringfunc init() &#123; cwd, err := os.Getwd() // compile error: unused: cwd if err != nil &#123; log.Fatalf("os.Getwd failed: %v", err) &#125;&#125; 最后，Go 变量遵循先声明后使用的规则，但是在包级别，声明的顺序并不会影响作用域范围，因此一个先声明的可以引用它自身或者是引用后面的一个声明，这可以让我们定义一些相互嵌套或递归的类型或函数。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 go 入门开篇]]></title>
    <url>%2F2019%2F01%2F01%2Fgo%2Fgo_grammar%2Fgo_1%2F</url>
    <content type="text"><![CDATA[如果编程的世界是海贼王里的”大航海时代”, go 语言可能就是”草帽海贼团” 1. 要去学 Go 了学习和使用 Python 有三四年,好想学一门新语言,打算学 Go。为什么是 Go，其实更想学 Rust。但是 Go 有谷歌这个大佬，背靠k8s，显然学 Go 好处大大的。其实也无所谓，哪天想学 Rust，就拿来看看对比着学可能更快。当然学 Go 还有另一个重要原因，想转运维开发。 2. 怎么学 Go因为已经不是第一次学编程了，之前也看过一段时间 C，想看看在学习了编程这么长时间之后，在编程领域的学习能力相比于一开始有没有提升。所以这次打算从语言特性的角度出发，有目的性的对比学习，看看能不能以更快的速度学好 Go。下面是我能想到知识面: 基础语法，包括变量，循环，判断以及运算符 Go 语言提供的基本数据结构 异常处理 函数，类与泛型 并发编程 3. 学习资料书选的《Go程序设计语言》，在写博客之前已经翻过一遍，的确是一本可以拿来入门的好书。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[39 最小生成树]]></title>
    <url>%2F2018%2F11%2F21%2Falog%2Fgraph_use4%2F</url>
    <content type="text"><![CDATA[最小生成树 1. 最小生成树所谓最小生成树(简称MST)就是在一个无向，有权图G中，找到一颗连接所有顶点的树，并且树包含的边的权重总和最低。最小生成树有两种常见解法: Prim-Jarnik 算法: 从单个根节点生成 MST，它和 Dijkstra有很多相似之处 Kruskal 算法: 通过按照边的权重的非递减去考虑边来成群的生成 MST 无论是哪种算法，它们都基于最小生成树这样一个事实。即 G 是一个有权重的连通图，另 V1 和 V2 是两个不相交的非空集合G的顶点的一部份。此外另 e 是那些一个顶点在 V1 一个顶点在V2的有最小权重的G的边，则 e 是最小生成树的一条边。 1.1 Prim-JarnikPrim-Jarnik 算法，我们以一某一顶点 s 开始，定义初始集合 C，然后每次迭代中，我们选择一个最小权重的边 e，将 C 中的顶点连接到 C 之外的顶点 v，之后在将 v 加入 C 中。此时 e 就是最小生成树的一条边。 1.2 KruskalKruskal 算法，首先每个顶点本身是单元素集合集权。算法按照权重增加的顺序轮流考察每条边。如果一条边连接了两个不同的集群，那么 e 就是最小生成树的一条边。 2. 实现2.1 Prim-Jarnik12345678910111213141516171819202122232425262728def MST_Prim_Jarnik(g): d = &#123;&#125; tree = [] pq = AdaptableHeapPriorityQueue() # 优先队列 pdlocator = &#123;&#125; # pdlocator 此处还起到判断顶点是否已经迭代过的作用 # 初始化 for v in g.vertices(): if len(d) == 0: d[v] = 0 else: d[v] = float('inf') pdlocator[v] = pq.add(d[v], (v, None)) while not pq.is_empty(): key, value = pq.remove_min() u, edge = value if edge is not None: tree.append(edge) del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) if v in pdlocator: wgt = e.element() if wgt &lt; d[v]: d[v] = wgt pq.update(pdlocator[v], (v, e)) return tree Prim-Jarnik Dijkstra类似，时间复杂度分析也类似。 2.2 Kruskal12345678910111213141516171819202122def MST_Kruskal(g): tree = [] pq = AdaptableHeapPriorityQueue() # 优先队列 forest = Partition() position = &#123;&#125; for v in g.vertices(): position[v] = forest.make_group(v) for e in g.edges(): pq.add(e.element, e) size = g.vertice_count() while len(tree) != size - 1 and pq.is_empty(): wgt, edge = pq.remove_min() u, v = edge.endpoints() a = forest.find(position[u]) b = forest.find(position[v]) if a != b: tree.append(edge) forest.union(a, b) return tree Partition 是一个不相交集合和联合查找结构的实现。 2.3 不相交集合和联合查找结构1234567891011121314151617181920212223242526272829303132class Partition(object): __slots__ = '_container', '_element', '_size', '_parent' class Position(object): def __init__(self, container, e): self._container = container self._element = e self._size = 1 self._parent = self def element(self): return self._element def make_group(self, e): return self.Position(self, e) def find(self, p): if p._parent != p: p._parenet = self.find(p._parent) return p._parent def union(self, p, q): a = self.find(p) b = self.find(q) if a is not b: if a._size &gt; b._size: b._parent = a a._size += b._size else: a._parent = b._parent b._size += a._size]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[38 最短路经]]></title>
    <url>%2F2018%2F11%2F20%2Falog%2Fgraph_use3%2F</url>
    <content type="text"><![CDATA[最短路经 1. 最短路径广度优先算法可以计算连通图中，从一个顶点到另一顶点的最短路径，但前提是图上的每条边的权重相同。那如何计算全重不同的图的最短路径呢？最出名的莫过于 Dijkstra 算法。 1.1 DijkstraDijkstra 算法是贪心算法。贪心算法的递归过程差不多是这样:假设我们计算图 G 上顶点 u 到顶点 v 的最短距离；对于到顶点 v 的所有输入边的顶点集合 S，如果我们知道 u 到 S 中每个顶点的最短距离，那我们就能计算出 u 到 v 的最短距离。整个 Dijkstra 算法计算过程比较复杂，我们结合代码来看。 2. 实现2.1 Dijkstra12345678910111213141516171819202122232425262728293031323334def shortest_search(g, src): d = &#123;&#125; # 从 src 到 顶点的最短距离 cloud = &#123;&#125; # 收集已经计算得到最短距离的所有顶点 pre = &#123;&#125; # 还原最短路径的路径 pdlocator = &#123;&#125; # 定位顶点在优先队列中位置 pq = AdaptableHeapPriorityQueue() # 优先队列 # 初始化 for u in g.vertices(): d[u] = float('inf') d[src] = 0 pre[src] = None pdlocator[src] = pq.add(0, src) # 迭代优先队列，不断从中取出距离最小的顶点 while not pq.is_empty(): k, u = pq.remove_min() # 删除堆顶元素 cloud[u] = k del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) n = k + e.element() if v not in cloud: if v not in pdlocator: d[v] = n # 插入堆 pdlocator[v] = pq.add(d[v], v) src[v] = u else: if n &lt; d[v]: d[v] = n # 更新堆 pq.update(pdlocator[v], n, v) src[v] = u return cloud, pre AdaptableHeapPriorityQueue 是我们在堆中实现的优先队列。之所以使用这个优先队列，是因为我们要不断的在队列中更新顶点的距离，以保证从优先队列取出的是当前距离最小的顶点。 整个代码的时间负载度分成两个部分: 一是 while + for 内对顶点和边的迭代，因为每个顶点和每条边最多被迭代一次，所以时间负载度是O(n+m); 二是对优先队列的操作，包括: add remove_min update 在堆一节中AdaptableHeapPriorityQueue被实现为一个堆，上述所有操作的时间复杂度都是 logn，因此总的时间复杂度是 O((n+m)logn)。 AdaptableHeapPriorityQueue 还有其他实现方式，比如一个未排序的数组，此时 remove_min 为 O(n)，其他两个操作的时间复杂度都是O(1)，此时总体的时间复杂度就是 O(n*n + m)。因此使用哪种实现方式更优取决于图的稀疏程度。 需要注意的是与前面类似，对于 d，pre， pdlocator，cloud 如果顶点可以用 0 到 n-1 进行编号， 它们都可以用数组代替，或者将作为顶点属性来记录。 2.2 重建最短路径树上面我们计算出从 src 到各个顶点的最短距离，但是并没有明确计算出获取最短剧路的路径。最短路径的重建有两种方式: 向上面代码中那样，使用 pre 记录到达每个顶点的前一个顶点。 是直接从 cloud 的返回值进行重建。 1234567891011121314151617181920212223242526272829# 重建最短路径树def shortest_path_tree(g, s, d): """ :param g: :param s: src 顶点 :param d: cloud 的返回值 :return: """ tree = &#123;&#125; for v in d: if v is not s: for e in g.incident_edge(v, False): u = e.opposite(v) wgt = e.element() if d[v] == d[u] + wgt: tree[v] = e return tree # 计算到顶点 v 的最短路径def shortest_path(pre, v): """ :param pre: pre :return: """ p = [v] while v in pre and pre[v] is not None: v = pre[v] p.append(v) return p.reverse()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[37 拓扑排序]]></title>
    <url>%2F2018%2F11%2F19%2Falog%2Fgraph_use2%2F</url>
    <content type="text"><![CDATA[拓扑排序 1. 拓扑排序的背景拓扑排序是一种排序，假设完成一项任务需要 n 个步骤，这 n 个步骤之间存在依赖关系，拓扑排序就是确定一个满足依赖关系的执行步骤。典型的拓扑排序用于解决如下问题: 大学课程之间的选修课的顺序 面向对象编程的类之间的继承 编译器在编译项目，按照编译的依赖关系确定编译顺序 拓扑排序是有向无环图的经典应用，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。其有两种实现方法，分别是Kahn 算法 和 DFS 深度优先搜索算法。 1.1 Kahn 算法Kahn 算法实际上用的是贪心算法思想。 定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。 我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中，并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。 Kahn 算法还能检测图是否存在环，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环 1.2 DFS 深度优先搜索算法使用 DF 实现拓扑排序的方法不好理解。假设图上的一个路径是A--&gt;B--&gt;C--&gt;D，如果我们按照输入边进行 DFS，那么顶点 A 一定在其他顶点之前输出。即所有入度为 0 的顶点一定在其他顶点之前输出，而递归调用的返回相当于对于顶点的入度减 1。最终的结果就是按照输入边对图的 DFS 和Kahn 算法一致。文字描述并不是很清楚，请结合代码查看。 2. 实现2.1 Kahn 算法123456789101112131415161718192021def topologic_sort(g): topo = [] # 拓扑排序的结果 ready = [] # 入度为 0 待加入 topo 的顶点 incount = &#123;&#125; # 记录每个顶点的入度 for u in g.vertices(): c = g.degree(u, False) if c == 0: ready.append(u) else: incount[u] = c while ready: u = ready.pop() topo.append(u) # 获取 u 的输出边，减少对应顶点的入度 for e in g.incident_edge(u): # 迭代所有顶点的传出边 v = e.opposite(u) incount[v] -= 1 if incount[v] == 0: incount.pop(v) ready.append(v) return topo 和图的遍历一样如果顶点可以用 0 到 n-1 进行编号，我们可以用数组代替 incount，或者将入度的计数作为顶点属性来记录。显然整个算法的时间复杂度为 O(n + m) 2.2 DFS 深度优先搜索算法123456789101112131415161718def DFS_income(g, u, discovered, topo): for e in g.incident_edge(u, False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS_income(g, v, discovered, topo) # 类似于后序遍历, 顶点 A 会优先加入 topo topo.append(u)def topologic_dfs(g): discovered = &#123;&#125; topo = [] for u in g.vertices: if u not in discovered: discovered[u] = None DFS_income(g, u, discovered, topo) return topo]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36 图的传递闭包]]></title>
    <url>%2F2018%2F11%2F18%2Falog%2Fgraph_use1%2F</url>
    <content type="text"><![CDATA[解决图可达性的传递闭包]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[35 深度和广度优先搜索]]></title>
    <url>%2F2018%2F11%2F16%2Falog%2Fgraph_search%2F</url>
    <content type="text"><![CDATA[图的深度和广度优先搜索 1. 特性上一节我们讲解了图的存储和表示，这一节我们来介绍图上的搜索算法。图的搜索方法有很多，最常见的就是深度和广度优先搜索，除此之外还有 A、IDA 等启发式搜索算法。因为邻接表更加常用，我们就以邻接表作为图的存储方式来讲解最基础的深度和广度优先算法。 形式上，遍历是通过检查所有的边和顶点来探索图的系统化的步骤。图的遍历算法是回答许多涉及可达性概念的有关图的问题的关键，即在图中决定如何从一个顶点到达另一个顶点。 在无向图中处理可达性的问题包括: 计算从顶点 u 到顶点 v 的路经，或者报告这样的路经不存在 已知 G 的开始顶点，对每个 G 的顶点 v 计算 s 和 v 之间的边的最小数目的路经，或者报告有没有这样的路经 测试 G 是否是连通的 如果 G 是连通的，计算 G 的生成树 计算 G 的连通分支 计算 G 中的循环，或者报告 G 没有循环 在有向图中处理可达性的问题包括: 计算从顶点 u 到顶点 v 的有向路经，或者报告这样的路经不存在 找出 G 中从已知顶点 s 可达的顶点 判断 G 是否是非循环的 判断 G 是否是强连通的 1.1 深度优先搜索深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”，每次迭代时任意选择一个分岔的”顶点”进行搜索，直至没有顶点时退回到上一个顶点重新选择新的顶点继续遍历，直到所有顶点都被遍历结束。下面是一个深度优先搜索的示意图 深度优先搜索对是否从一个顶点到另一个顶点有路径和是否该图是一个连通图非常有用。 1.2 广度优先搜索广度优先搜索（Breadth-First-Search），简称为 BFS，就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。所有的顶点按照从左往右，从上往下的顺序依次迭代。为了保证迭代的次序需要用到队列，整个过程就是从顶点入队开始，将队首元素出队，并将出队顶点的下一层顶点依次入队，迭代直至队列为空的过程。为了防止顶点被重复遍历，需要对已经遍历的顶点进行表识。 2. 应用2.1 深度优先搜索12345678910111213141516def DFS(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered)# u 为开始顶点，值为 None，用于标识其为开始顶点result = &#123;u: None&#125;DFS(g, u, result) discovered 字典这里为两个目的服务，一是提供了用于判断顶点是否已被访问的机制，二是字典内保存的边就是DFS树的边。如果假设顶点可以用 0 到 n-1 进行编号，discovered可以用基于这些数子的数组替代。或者可以直接将所有顶点的发现状态以及顶点的发现边作为顶点的属性，成为顶点的一部分。 顶点 u 到 v 的可达路经基于discovered 字典我们可以很容易基于这个字典来提供从顶点 u 到达顶点 v 的可达路经的顶点列表。 1234567891011def construct_path(u, v, discovered): path = [] if v in discovered: path.append(v) walk = v while walk is not u: parent = discovered[walk].opposite[walk] path.append(parent) walk = parent path.reverse() return path 连通性测试基于 DFS 函数，我们可以很容判断图是否是连通的。在无向图的情况下，我们在任意顶点简单的开始深度有限搜索，然后测试 len(discovered) 和图的顶点数是否相同。如果相等无向图就是连通。 对于有向图，我们可能想测试它是否是强连通的。我们可以对任意顶点 s 执行深度优先搜索。注意在我们的 DFS 实现中，我们是以顶点的输出边为基础的，我们可以重新实现一个深度优先搜索函数 DFS_IN，这次以输入边作为遍历图的基础。对顶点 s 重新执行 DFS_IN。如果两次 DFS 遍历，所有顶点都是可达的则图是强连通的。 12345678910111213def DFS_IN(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ # 以输入边执行反向的深度优先搜索 for e in g.incident_edge(u, outgoing=False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered) 计算所有的连通分支当图是不连通的时候，我们的下一个目标是识别无向图的所有连通分支，或有向图的强连通分支。我们首先来看无向图。 1234567def DFS_complete(g): forest = &#123;&#125; for u in g.vertices(): if u not in forest: forest[u] = None DFS(g, u, forest) return forest DFS_complete 函数返回的发现字典代表了整个图的 DFS 森林。连通分支数可以通过发现字典值为 None 的键的个数来判定。 找到有向图的强连通分支的情况更复杂，存在在 O(n+m)时间内计算这些连通分支的方法，使用两次单独的深度优先搜索遍历，细节我们之后在详述。 判断图是否存在循环循环的存在当且仅当和 DFS 遍历相关的 back 边存在。无向图搜索 back 边是容易的，因为所有的边不是树的边就是 back 边。而无向图比较困难。代码实现如下 12345def is_cycle(): passdef is_cycle_directed(): pass 2.1 广度优先搜索如下两个版本的广度有限搜索代码都是正确的，都是我们常用的形式。 123456789101112131415161718192021222324def BFS(g, s, discovered): queue = deque() queue.append(s) discovered[s] = None while queue: u = queue.popleft() for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e queue.append(v)def BFS_1(g, s, discovered): level = [] while level: next_level = [] for u in level: for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e next_level.append(v) level = next_level 广度优先搜索的应用BFS 可以遍历 s 所有的可达顶点，要探索整个图，可以从另一顶点重新开始，和代码 DFS_complete 类似。同样从顶点 s 到顶点 v 的实际路经可以使用代码段 construct_path 函数重建。 2.3 对比DFS 和 BFS 都能很高效的找到从给定源可达顶点的集合，然后判定到这些顶点的路经。然而 BFS 可保证这些路经尽可能少的使用边。对于无向图，两个算法都能用来测试连通性，识别连通分支或找出循环。对于有向图而言，DFS 可能更适合一些任务，比如在图中寻找有向循环，或识别强连通分支。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[34 图的表示]]></title>
    <url>%2F2018%2F11%2F15%2Falog%2Fgraph%2F</url>
    <content type="text"><![CDATA[如何表示一个图 1. 特性从本节开始，我们将进入图的学习。图是一种比树更复杂的非线性结构，图中有以下一些专用术语: 顶点: 图中的节点被称为顶点 边: 顶点之间存在链接关系，可以有方向，也可以有权重 有向图: 边有方向的图 带权图: 边存在权重的图 度: 顶点包含的边数，在有向图中，度分为出度和入度 出度表示以顶点作为起点的边，该边也称为顶点的输出边 入度表示以顶点作为终点的边，该边也称为顶点的入射边 很显然在表示和存储一个图时，我们需要保存图的顶点，边，以及边的方向和权重。而图的存储有两个常见方法: 邻接矩阵和邻接表 1.1 邻接矩阵邻接矩阵的底层是一个二维数组，A[i][j] 表示从节点 i 指向节点 j 的一条边，A[i][j]元素的值表示是否存在这条边或者在带权图中表示边的权重。 邻接矩阵的存储方式简单、直接，基于数组，在获取两个顶点的关系时，非常高效；可以将很多图的运算转换成矩阵之间的运算，计算方便。但是最大的缺点是浪费空间，在无向图中，有一半的空间是浪费的。如果我们存储的是稀疏图,也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵就更加浪费空间。通常我们遇到的都是稀疏图，所以邻接矩阵的存储方法并不常用。 1.2 邻接表 如上图，在邻接表中每个顶点对应一条链表，链表中存储的是与此顶点直接先连的其他顶点。与邻接矩阵相比，邻接表更加节省空间，但是使用起来就比较耗时，如果我们想确定是否存在从 i 指向 j 的边，我们必需遍历顶点 i 上的整个链表。 为了提高查找效率，我们可以将邻接表中的链表改成红黑树、跳表、散列表，甚至将链表改成有序动态数组，通过二分查找的方法来快速定位两个顶点之间否是存在边。至于如何选择，还需要看具体的业务场景。 1.3 应用示例我们以微博的用户关系为例，假设我们需要支持下面这样几个操作： 判断用户 A 是否关注了用户 B； 判断用户 A 是否是用户 B 的粉丝； 根据用户名称的首字母排序，分页获取用户的粉丝列表； 根据用户名称的首字母排序，分页获取用户的关注列表。 社交网络是一张稀疏图，更适合使用邻接表来存储。不过，此处我们需要两个图: 邻接表和逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系，分别用于关注和粉丝两种关系的判断。因为我们有排序需求，而跳表存储的数据本身就是有序的，所以我们选择用跳表来替代链表。 但是对于拥有亿级别用户的微博，显然我们没法将图存在一台机器的内存上。我们可以通过哈希算法等数据分片方式，通过对顶点的哈希然后分片，将邻接表存储在不同的机器上。当要查询顶点与顶点关系的时候，我们就利用同样的哈希算法，先定位顶点所在的机器，然后再在相应的机器上查找。 此外借助于 mysql 这样的外部存储，我们可以将 (user_id, follower_id) 这样的关注关系存储在 mysql 中。相比于图这可能是更好的解决方案。 2. 实现图是顶点和边的集合，我们将图的抽象模型定义为三种数据类型的组合: Vertex,Edge 和 Graph。 VertexVertex ADT 用来表示顶点对象，有一个用来检索所存储元素的方法 element() EdgeEdge ADT 用来表示边，并具有如下方法: element(): 返回保存的边的值 endpoint(): 返回边对应的(u, v)，u为边起点，v为边的终点 opposite(u): 传入边的一个端点，返回边的另一个端点 GraphGraph ADT 表示图，包含如下方法: vertex_count(): 返回图的顶点数量 vertices(): 迭代返回图中的所有顶点 edge_count(): 返回图的边的数量 edges(): 迭代返回图中的所有边 get_edge(u, v): 返回从顶点 u 到顶点 v 的边，不存在返回 None，对于无向图 get_edge(u, v)，get_edge(v, u) 没有区别 degree(v, out=True): 返回顶点的出度，out=False 返回顶点的出度 incident_edges(v, out=True): 迭代返回顶点 v 的输出边，out=False 迭代返回顶点的输入边 insert_vertex(v=None): 创建并返回一个顶点的 Vertex 对象 insert_edge(u, v, x=None): 创建一个从顶点u 到顶点 v，存储元素 x 的 Edge 边对象 remove_vertex(v): 删除顶点及与顶点关联的边 remove_edge(e): 删除边 e 我们接下来就以邻接表，并使用哈希表代替链表的方式实现上述的抽象数据结构。 2.1 图的邻接表实现Vertext 和 Edge 类1234567891011121314151617181920212223242526272829303132class Vertex(object): __slots__ = '_element' def __init__(self, x): self._element = x def element(self): return self._element def __hash__(self): return hash(id(self))class Edge(object): __slots__ = '_origin', '_destination', '_element' def __init__(self, u, v, x): self._origin = u self._destination = v self._element = x def endpoints(self): return self._origin, self._destination def opposite(self, v): return self._destination if v is self._origin else self._origin def element(self): return self._element def __hash__(self): return hash((self._origin, self._destination)) Graph 类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Graph(object): def __init__(self, directed=False): """ :param directed: 是否创建有向图，默认为 False 表示创建无向图 """ self._outgoing = &#123;&#125; # key 为起点，value 为终点的 # 设计要点: key 为终点，value 为起点的，无向图_incoming 只是 _outgoing 的别名 self._incoming = &#123;&#125; if directed else self._outgoing def is_directed(self): return self._incoming is not self._outgoing def vertex_count(self): return len(self._outgoing) def vertices(self): return self._outgoing.keys() def edge_count(self): total = sum(len(self._outgoing[u]) for u in self._outgoing) if not self.is_directed(): total /= 2 return total def edges(self): result = set() # 对于无向图，需要去重 for u in self._outgoing: result.update(u.values()) return result def get_edge(self, u, v): return self._outgoing[u].get(v) def degree(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming return len(adj[v]) def incident_edge(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming for edge in adj[v].values: yield edge def insert_vertex(self, x=None): v = Vertex(x=x) self._outgoing[v] = &#123;&#125; if self.is_directed(): self._incoming[v] = &#123;&#125; return v def insert_edge(self, u, v, x): e = Edge(u, v, x) self._outgoing[u][v] = e self._incoming[v][u] = e def remove_vertex(self, v): # 有向图: u --&gt; v ---&gt; v1 # 无向图: u---&gt; v ---- u # 删除以 v 为起点的所有边 for v1 in self._outgoing[v].keys(): del self._incoming[v1][v] del self._outgoing[v] # 删除以 v 为终点的所有边 if self.is_directed(): for u in self._incoming[v].keys(): del self._outgoing[u][v] del self._incoming[v] def remove_edge(self, e): u, v = e.endpoints() del self._outgoing[u][v] del self._incoming[v][u]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. k8s集群安装与配置]]></title>
    <url>%2F2018%2F11%2F15%2FK8S%2Fk8s%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8Ek8s%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[k8s集群安装与配置 1. k8s 安装1.1 准备 yum 源12345678910111213141516cd /etc/yum.repo.d/# docker-ce 源wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# kubernetes 源vim kubernetes.repo[kuberneters]name=kuberneters repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1enabled=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 设置 docker kubelet 开机自启动systemctl enable docker kubelet 1.2 安装配置相关组件1234567891011121314151617181920# 安装相关组件yum install docker-ce kubectl kubelet kubeadm# 配置 docer 的 unit file 添加 https 代理，以便能下载相关被墙的镜像# 不过依旧不能用，此步骤省略# vim /usr/lib/systemd/system/docker.service # 添加# Environment="HTTPS_PROXY=http://www.ik8s.io:10080"systemctl daemon-reloadsystemctl restart dockerdocker info # 看到 HTTPS_PROXY 行即可# 配置 kuberneters 不受 swap 分区的影响vim /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS="--fail-swap-on=false"# 系统参数初始化sysctl -w net.bridge.bridge-nf-call-ip6tables=1sysctl -w net.bridge.bridge-nf-call-iptables=1iptables -F 1.3 准备 kubeadm 所需镜像因为某种不可描述的原因，kubeadm 使用到的镜像无法访问，因此需要手动准备 kubeadm 所需的镜像文件。这里有片文章可以指导你去构建相应的 镜像 https://ieevee.com/tech/2017/04/07/k8s-mirror.html 12345678&gt; kubeadm config images listk8s.gcr.io/kube-apiserver:v1.12.2k8s.gcr.io/kube-controller-manager:v1.12.2k8s.gcr.io/kube-scheduler:v1.12.2k8s.gcr.io/kube-proxy:v1.12.2k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.2.24k8s.gcr.io/coredns:1.2.2 我是自己去阿里云自建的镜像，使用下面的脚本对镜像进行重命名12345678910#!/bin/bashbase=k8s.gcr.ioaliyun="registry.cn-qingdao.aliyuncs.com/htttao"images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for i in $&#123;images[@]&#125;do docker pull $aliyun/$i docker tag $aliyun/$i $base/$idone 1.4 初始化 Master 节点12345678910111213141516kubeadm init --kubernetes-version=v1.12.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap# 运行完成之后，会提示将 Node 节点加入集群的命令kubeadm join 192.168.1.106:6443 --token z5fqxu.dn3awhi0u5n2i6eb --discovery-token-ca-cert-hash sha256:dc333a8af6ee0c7cd1e180b43251800685b90d6338929fa508e42f76579ce50c# 按照初始化后的提示，创建一个普通用户，并复制相应文件# user: kubernetesmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 测试kubectl get cskubectl get nodeskubectl get podskubectl get ns 1.5 部署网络组件初始化 Master 还有非常重要的一步，就是部署网络组件，否则各个 pod 等组件之间是无法通信的123kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.ymlkubectl get pods 1.6 k8s 集群重至如果配置过程中出现了错误，想重新配置集群， 可以使用 kubeadm reset 对整个集群进行重至，然后重新使用 kubeadm init 进行初始化创建。但是需要注意的时，kubeadm reset 不会重至 flannel 网络，想要完全重至可使用以下脚本 12345678910111213#!/bin/bashkubeadm resetsystemctl stop kubeletsystemctl stop dockerrm -rf /var/lib/cni/rm -rf /var/lib/kubelet/*rm -rf /etc/cni/ifconfig cni0 downifconfig flannel.1 downifconfig docker0 downip link delete cni0ip link delete flannel.1systemctl start docker 2. 安装脚本整个集群安装比较复杂，因此我将上述过程写成了两个脚本。因此按次序执行下面脚本然后进行 kubeadm init 进行集群初始化即可完成配置。 2.1 基础环境配置脚本1234567891011121314151617181920212223242526272829#!/bin/bash# 1. 设置系统参数mount /dev/cdrom /cdromiptables -F# 2. 准备 yum 源wget -P /etc/yum.repos.d/ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repocat &lt;&lt; EOF &gt;&gt; /etc/yum.repos.d/kubernetes.repo[kuberneters]name=kuberneters repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1enabled=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 3. 配置 kuberneters 不受 swap 分区的影响yum install docker-ce kubelet kubeadm kubectl -yecho 'KUBELET_EXTRA_ARGS="--fail-swap-on=false"' &gt; /etc/sysconfig/kubelet# 4. 启动相关服务systemctl start dockersystemctl enable docker kubeletcat &lt;&lt; EOF &gt; /etc/docker/daemon.json&#123; "registry-mirrors": ["https://osafqkzd.mirror.aliyuncs.com"]&#125;EOF 2.2 镜像下载脚本执行下面的下载脚本 /root/kubernetes.sh123456789101112131415161718#!/bin/bashsudo docker login --username=1556824234@qq.com registry.cn-qingdao.aliyuncs.comsysctl net.bridge.bridge-nf-call-ip6tables=1sysctl net.bridge.bridge-nf-call-iptables=1base=k8s.gcr.ioaliyun="registry.cn-qingdao.aliyuncs.com/htttao"images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for i in $&#123;images[@]&#125;do docker pull $aliyun/$i docker tag $aliyun/$i $base/$idoneflannel=flannel:v0.10.0-amd64docker pull $aliyun/$flanneldocker tag $aliyun/$flannel quay.io/coreos/$flannel 2.3 集群初始化1234567891011kubeadm init --kubernetes-version=v1.12.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swapmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# Node 节点的加入集群的命令kubeadm join 192.168.1.184:6443 --token w1b9i6.ryqstfgjmob2z8xp --discovery-token-ca-cert-hash sha256:0d3404f3919116e7efa56b2e0694c1397cd44915ed13f16d9e6e7600ada64c4c --ignore-preflight-errors=Swapkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml 3. Node 节点配置Node 节点的配置与 Master 过程类似，以此执行上述两个脚本即可，唯一的区别是在初始化时执行的是 kubeadm join. 1234# 1. 基础环境配置脚本# 2. 执行镜像下载脚本，准备好相关镜像# 3. 将节点加入集群, 需要注意节点的主机名不能与 Master 节点同名kubeadm join 192.168.1.184:6443 --token w1b9i6.ryqstfgjmob2z8xp --discovery-token-ca-cert-hash sha256:0d3404f3919116e7efa56b2e0694c1397cd44915ed13f16d9e6e7600ada64c4c --ignore-preflight-errors=Swap]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[33 动态规划实战]]></title>
    <url>%2F2018%2F11%2F12%2Falog%2Fdp_3%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划实战 1. 动态规划总结上一篇，我们总结了动态规划的使用场景，以及如何利用动态规划去解决问题了，总结了: 一个模型三个特征: 多阶段决策最优解模型，最优子结构，无后效性，重复子问题 状态转移表法 状态转移方程法 并总结对比了四中编程思想之间的区别。这些东西都非常理论，需要慢慢消化。本文是动态规划的实战篇，也是编程思想系列的最后一篇。 2.应用本节我们核心要解决的问题是如何量化两个字符串之间的相似程度呢？有一个非常著名的量化方法，那就是编辑距离（Edit Distance）。 编辑距离指的就是，将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如增加一个字符、删除一个字符、替换一个字符）。编辑距离越大，说明两个字符串的相似程度越小。 根据所包含的编辑操作种类的不同，编辑距离有多种不同的计算方式，比较著名的有莱文斯坦距离（Levenshtein distance）和最长公共子串长度（Longest common substring length）。其中，莱文斯坦距离允许增加、删除、替换字符这三个编辑操作，最长公共子串长度只允许增加、删除字符这两个编辑操作。莱文斯坦距离的大小，表示两个字符串差异的大小；而最长公共子串的大小，表示两个字符串相似程度的大小。 下面是两个方法的操作示例，我们的问题是如何计算两个字符串的莱文斯坦距离和最长公共子串长度。 2.1 计算莱文斯坦距离首先我们来看回溯的处理过程。如果 a[i] 与 b[j] 匹配，我们递归考察 a[i+1] 和 b[j+1]。如果 a[i] 与 b[j] 不匹配，那我们有多种处理方式可选： 可以删除 a[i]，然后递归考察 a[i+1] 和 b[j]； 可以删除 b[j]，然后递归考察 a[i] 和 b[j+1]； 可以在 a[i] 前面添加一个跟 b[j] 相同的字符，然后递归考察 a[i] 和 b[j+1]; 可以在 b[j] 前面添加一个跟 a[i] 相同的字符，然后递归考察 a[i+1] 和 b[j]； 可以将 a[i] 替换成 b[j]，或者将 b[j] 替换成 a[i]，然后递归考察 a[i+1] 和 b[j+1]。 反过来看状态 (i, j) 可能从 (i-1, j)，(i, j-1)，(i-1, j-1) 三个状态中的任意一个转移过来。我们可以尝试着将把状态转移的过程，用公式写出来。这就是我们前面讲的状态转移方程 1234567如果：a[i]!=b[j]，那么：min_edist(i, j) 就等于：min(min_edist(i-1,j)+1, min_edist(i,j-1)+1, min_edist(i-1,j-1)+1)如果：a[i]==b[j]，那么：min_edist(i, j) 就等于：min(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1))其中，min 表示求三数中的最小值。 2.2 计算最长公共子串长度首先我们先来看回溯的处理思路。我们从 a[0] 和 b[0] 开始，依次考察两个字符串中的字符是否匹配。 如果 a[i] 与 b[j] 互相匹配，我们将最大公共子串长度加一，并且继续考察 a[i+1] 和 b[j+1]。 如果 a[i] 与 b[j] 不匹配，最长公共子串长度不变，这个时候，有两个不同的决策路线： 删除 a[i]，或者在 b[j] 前面加上一个字符 a[i]，然后继续考察 a[i+1] 和 b[j]； 删除 b[j]，或者在 a[i] 前面加上一个字符 b[j]，然后继续考察 a[i] 和 b[j+1]。 反过来也就是说，如果我们要求 a[0…i] 和 b[0…j] 的最长公共长度 max_lcs(i, j)，我们只有可能通过下面三个状态转移过来： (i-1, j-1, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j-1] 的最长公共子串长度； (i-1, j, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j] 的最长公共子串长度； (i, j-1, max_lcs)，其中 max_lcs 表示 a[0…i] 和 b[0…j-1] 的最长公共子串长度。 如果我们把这个转移过程，用状态转移方程写出来，就是下面这个样子： 1234567如果：a[i]==b[j]，那么：max_lcs(i, j) 就等于：max(max_lcs(i-1,j-1)+1, max_lcs(i-1, j), max_lcs(i, j-1))；如果：a[i]!=b[j]，那么：max_lcs(i, j) 就等于：max(max_lcs(i-1,j-1), max_lcs(i-1, j), max_lcs(i, j-1))；其中 max 表示求三数中的最大值。 3. 练习3.1 最长递增子序列我们有一个数字序列包含 n 个不同的数字，如何求出这个序列中的最长递增子序列长度？比如 2, 9, 3, 6, 5, 1, 7 这样一组数字序列，它的最长递增子序列就是 2, 3, 5, 7，所以最长递增子序列的长度是 4。 123456789101112131415def max_seq(nums): mem = [1] * len(nums) for i in range(1, len(nums)): m = 1 j = 0 while j &lt; i: if nums[i] &gt; nums[j]: v = mem[j] + 1 if v &gt; m: m = v j += 1 mem[i] = mmax_seq([2, 9, 3, 6, 5, 3, 7])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[32 动态规划理论]]></title>
    <url>%2F2018%2F11%2F11%2Falog%2Fdp_2%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划理论 1. 再论动态规划动态规划比起其三个算法思想更难懂。上一篇文章我们从实践角度介绍了如何利用动态规划解决问题。有了这个基础，接下来我们来解决如下几个问题: 什么样的问题可以用动态规划解决？ 解决动态规划问题的一般思考过程是什么样的？ 贪心、分治、回溯、动态规划这四种算法思想又有什么区别和联系？ 1.1 适用场景动态规划适合解决的问题可以概括为“一个模型三个特征”。 一个模型: 多阶段决策最优解模型。动态规划通常被用来解决最优问题，而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。 三个特征: 最优子结构 无后效性 重复子问题 最优子结构最优子结构指的是，问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。 无后效性无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。 重复子问题这个概念比较好理解。前面一节，我已经多次提过。如果用一句话概括一下，那就是，不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。 1.2 解题思路解决动态规划问题，一般有两种思路。我把它们分别叫作，状态转移表法和状态转移方程法。 状态转移表法一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。所以，这种方法与回溯算法相关，通常我们需要进行如下几步: 使用回溯算法，定义状态，画出递归树；判断是否存在重复子问题，看是否能用动态规划解决 画出状态转移表，根据递推关系，分阶段填充状态表中的每个状态 最后，将递推填表的过程，翻译成代码，就是动态规划代码了 状态表一般都是二维的，所以可以把它想象成二维数组。其中，每个状态包含三个变量，行、列、数组值。尽管大部分状态表都是二维的，但是如果问题的状态比较复杂，需要很多变量来表示，那对应的状态表可能就是高维的，比如三维、四维。那这个时候，我们就不适合用状态转移表法来解决了。一方面是因为高维状态转移表不好画图表示，另一方面是因为人脑确实很不擅长思考高维的东西。 状态转移方程法状态转移方程法有点类似递归的解题思路。状态转移方程法的大致思路可以概括为，找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码。我们需要分析，某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，我们有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。 状态转移方程是解决动态规划的关键。如果我们能写出状态转移方程，那动态规划问题基本上就解决一大半了，而翻译成代码非常简单。但是很多动态规划问题的状态本身就不好定义，状态转移方程也就更不好想到。 1.3 四种算法思想比较如果我们将这四种算法思想分一下类，那贪心、回溯、动态规划可以归为一类，而分治单独可以作为一类。前三个算法解决问题的模型，都可以抽象成我们今天讲的那个多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但是，大部分都不能抽象成多阶段决策模型。 回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，我们都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。 尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。 贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里我们不怎么强调重复子问题）。其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。 2. 应用有了上面的论述，接下来我们看看如何利用我们所说的动态规划的理论和方法来解决实际问题。 2.1 最小路经假设我们有一个 n 乘以 n 的矩阵 w[n][n]。矩阵存储的都是正整数。棋子起始位置在左上角，终止位置在右下角。我们将棋子从左上角移动到右下角。每次只能向右或者向下移动一位。从左上角到右下角，会有很多不同的路径可以走。我们把每条路径经过的数字加起来看作路径的长度。那从左上角移动到右下角的最短路径长度是多少呢？ 套用上面所讲的一个模型三个特征理论，我们来看看这个是否可以用动态规划来解: 一个模型: 从左上角到右下角可以分成多个步骤移动，显然这是一个多阶段决策问题 三个特征: 首先位置(i, j) 只能由 (i, j-1),(i-1, j) 移动得来，位置(i, j)的最短距离可以从这两个位置的最短距离得来，符合最优子结构， 其次位置(i, j)之后得如何选择与位置(i, j)之前无任何关系符合无后效性特征 最后，一个位置可以由两个位置移动得来，回溯求解中肯定会产生重复子问题因此这个问题能用动态规划解决。 123456789101112131415161718192021222324252627def min_path_in_matrix(matrix): row = len(matrix) column = len(matrix[0]) status = [[0] * column for i in range(row)] s = 0 for c in range(column): s += matrix[0][c] status[0][c] = s s = 0 for r in range(column): s += matrix[r][0] status[r][0] = s for i in range(1, row): for j in range(1, column): status[i][j] = min(status[i][j - 1], status[i - 1][j]) + matrix[i][j] print status return status[-1][-1]ss = [ [1,2,3], [4,5,6], [7,8,9]]min_path_in_matrix(ss) 2.2 硬币找零我们今天来看一个新的硬币找零问题。假设我们有几种不同币值的硬币 v1，v2，……，vn（单位是元）。如果我们要支付 w 元，求最少需要多少个硬币。比如，我们有 3 种不同的硬币，1 元、3 元、5 元，我们要支付 9 元，最少需要 3 个硬币（3 个 3 元的硬币）。 1pass 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30.2 zabbix安装与入门]]></title>
    <url>%2F2018%2F11%2F11%2Flinux_mt%2F33-zabbix%2Fzabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[zabbix安装与入门 前面我们对一个完整的监控系统包含的内容做了一个简单概述，各种监控系统的开源实现无非都是围绕我们介绍的内容展开。在监控系统的众多实现中 zabbix 最为常见，功能也最为强大，本节我们首先对 zabbix 做个详细介绍，内容包括: zabbix 的框架与组成 zabbix 的安装和配置 1. zabbixzabbix 当前长期维护的版本有三个，2.2，3.0，4.0，本节我们就以3.0 为例来讲解。 1.1 zabbix 特性zabbix 支持以下特性: 数据采样: snmp, agent, ipmi, jmv 报警升级功能 数据存储: mysql, pgsql 展示: php 程序，实时绘图，支持 支持模板: 支持网络主机自动发现 通过监控代理，支持分布式监控 支持二次开发 1.2 zabbix 系统架构 agent 监控模式 数据采集的有两种方式: 被动模式: zabbix server 向 zabbix agent pull 数据 主动模式: zabbix agent 主动向 zabbix server push 数据 1.3 zabbix 逻辑组件 2. zabbix 安装配置2.1 zabbix serve 安装配置默认的 epel 在配置 zabbix 过程中出现了问题，因此需要为 zabbix 配置 yum 源。参考 zabbix document 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109# 1. zabbix database - mysql## 1.1 安装配置 mysqlyum install mariadb-servervim /etc/my.cnf [mysqld] skip_name_resolve = ON innodb_file_per_table = ONsystemctl start mariadb-serversystemctl enabled mariadb-servermysql_secure_installation### 1.2 为 zabbix 创建 mysql 用户mysql -uroot -p1234&gt; create database zabbix character set utf8 collate utf8_bin;&gt; grant all on zabbix.* to &apos;zabbix&apos;@&apos;192.168.%.%&apos; identified by &apos;zbxpass&apos;;&gt; grant all on zabbix.* to &apos;zabbix&apos;@&apos;127.0.0.1&apos; identified by &apos;zbxpass&apos;;&gt; flush privileges;# 2. zabbix server## 2.1 配置 zabbix yum 源rpm -i http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm## 2.2 安装 zabbix server$ yum list zabbix-*已安装的软件包zabbix-release.noarch 3.0-1.el7 installed可安装的软件包zabbix-agent.x86_643.0.22-1.el7 zabbix zabbix-get.x86_64 3.0.22-1.el7 zabbix zabbix-java-gateway.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-sqlite3.x86_64 3.0.22-1.el7 zabbix zabbix-sender.x86_64 3.0.22-1.el7 zabbix zabbix-server-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-server-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-web.noarch 3.0.22-1.el7 zabbix zabbix-web-japanese.noarch 3.0.22-1.el7 zabbix zabbix-web-mysql.noarch 3.0.22-1.el7 zabbix zabbix-web-pgsql.noarch 3.0.22-1.el7 zabbixyum install zabbix-server-mysql.x86_64$ rpm -ql zabbix-server-mysql.x86_64/etc/zabbix/zabbix_server.conf # zabbix server 配置文件/usr/lib/systemd/system/zabbix-server.service # unit file/usr/lib/zabbix/alertscripts/usr/lib/zabbix/externalscripts/usr/sbin/zabbix_server_mysql/usr/share/doc/zabbix-server-mysql-3.0.22/usr/share/doc/zabbix-server-mysql-3.0.22/create.sql.gz # zabbix 数据库初始化## 2.3 导入数据库脚本生成数据库环境gzip -d /usr/share/doc/zabbix-server-mysql-3.0.22/create.sql -c &gt;&gt;/root/create.sqlmysql -uroot -p1234 zabbix &lt; /root/create.sql## 2.4 zabbix serve 配置启动$ grep ^##### /etc/zabbix/zabbix_server.conf############ GENERAL PARAMETERS ############################# ADVANCED PARAMETERS ####################### LOADABLE MODULES ############## TLS-RELATED PARAMETERS #######SourceIP=192.168.1.106LogFile=/var/log/zabbix/zabbix_server.logLogFileSize=0PidFile=/var/run/zabbix/zabbix_server.pidDBHost=192.168.1.106DBName=zabbixDBUser=zabbixDBPassword=zbxpassSNMPTrapperFile=/var/log/snmptrap/snmptrap.logTimeout=4AlertScriptsPath=/usr/lib/zabbix/alertscriptsExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000## 2.5 服务启动systemctl start zabbix-server# 3. 安装 zabbix web gui## 3.1 安装 lamp 以及 zabbix webyum install zabbix-web.noarch zabbix-web-mysql.noarchyum install httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml -y## 3.2 zabbix web httpd 配置文件rpm -ql zabbix-web/etc/httpd/conf.d/zabbix.conf/etc/zabbix/web # web 根目录vim /etc/httpd/conf.d/zabbix.conf php_value date.timezone Asia/ShangHai # 根改时区## 3.3 启动 httpdsystemctl start httpd## 3.4 web 初始化http://192.168.1.106/zabbix/setup.php## 3.5 初始化生成的配置文件位于/etc/zabbix/web/zabbix.conf.php## 3.6 登陆，初始化的帐号: Admin 密码: zabbix## 密码保存在 mysql zabbix.users 中## select * from zabbix.users 2.2 zabbix agent 配置123456789101112131415161718192021222324252627282930313233# 1. 安装yum install zabbix-sender.x86_64 zabbix-agent.x86_64 -y# 2. 配置$ rpm -ql zabbix-agent/etc/logrotate.d/zabbix-agent/etc/zabbix/zabbix_agentd.conf # agent 配置文件/etc/zabbix/zabbix_agentd.d/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf/usr/lib/systemd/system/zabbix-agent.service # unit file/usr/lib/tmpfiles.d/zabbix-agent.conf/usr/sbin/zabbix_agentd$ grep -i &quot;^####&quot; /etc/zabbix/zabbix_agentd.conf############ GENERAL PARAMETERS ###################### Passive checks related # 被动监控配置项##### Active checks related # 主动监控配置############ ADVANCED PARAMETERS ######################## USER-DEFINED MONITORED PARAMETERS ####### # 用户自定义的监控参数 UserParamter####### LOADABLE MODULES ############## TLS-RELATED PARAMETERS ############ Passive checks relatedServer=IP1,IP2... # 访问控制授权，允许哪些主机过来采集数据ListenIP=0.0.0.0StartAgents=3##### Active checks relatedServerActive=IP1,IP2... # 主动报告的目标主机地址Hostname=node1 # 当前被监控主机在 zabbix 中的 id# 3. 启动服务systemctl start zabbix-agent 3. 监控配置在 zabbix 中快速配置一个监控需要按照如下顺序: 监控配置: host group--&gt; host--&gt; application--&gt; item--&gt;trriger---&gt;action(conditons, operations) 展示配置: item --&gt; simple graph items --&gt; graphs ---&gt; screen --&gt; slide show 每一个监控项 item 对应着一个 item key，其代表了在被检控主机上要执行的命令。 3.1 zabbix 监控测试12yum install zabbix-get.x86_64zabbix_get -s 192.168.1.155 -k &quot;system.cpu.switches&quot;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[31 初识动态规划]]></title>
    <url>%2F2018%2F11%2F10%2Falog%2Fdp_1%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划初识 1. 动态规划动态规划是几个编程思想中最难的一个，它与回溯密切相关。回溯问题是在一组可能的解中，搜索满足期望的解；采用的方法类似枚举，找出所有解，筛选符合要求的解；而动态规划比较适合用来求解最优问题，比如求最大值、最小值等等。基本上所有的动态规划问题都能用回溯算法解决，但是动态规划能有效避免回溯算法中的重复计算，提高代码执行效率。 1.1 解决思路上一节我们用回溯算法解决了0-1背包问题，并阐述了回溯算法中可能存在重复计算的问题，借助于对子问题的缓存，我们能有效避免重复计算。但是需要注意的是这种方法并不是总是有效。 与回溯算法类似，动态规划中，我们同样把问题分解为多个阶段，每个阶段对应一个决策。我们记录每一个阶段可达的状态集合并去重，然后通过当前阶段的状态集合，来推导下一个阶段的状态集合，直至达到最终状态，并从中选择一个最优解。通过记录每个阶段的所有可达状态并去重来避免重复计算。 尽管动态规划的执行效率提高了，但是动态规划的空间复杂度也提高了，所以，很多时候，我们会说，动态规划是一种空间换时间的算法思想。 2.1 应用2.1 动态规划解0-1背包问题现在我们用动态规划来解决上一节的0-1背包问题，我们把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个物品决策（放入或者不放入背包）完之后，背包中的物品的重量会有多种情况，也就是说，会达到多种不同的状态，对应到递归树中，就是有很多不同的节点。 我们把每一层重复的状态（节点）合并，只记录不同的状态，然后基于上一层的状态集合，来推导下一层的状态集合。我们可以通过合并每一层重复的状态，这样就保证每一层不同状态的个数都不会超过 w 个（w 表示背包的承载重量），也就是例子中的 9。于是，我们就成功避免了每层状态个数的指数级增长。 我们用一个二维数组 states[n][w+1]，来记录每层可以达到的不同状态。n表示第n个物品，w+1 表示当前背包的重量。 12345678910111213141516171819202122232425262728def rucksack_hold(items, weight): status = [[0] * (weight + 1) for i in range(len(items))] status[0][0] = 1 status[0][items[0]] = 1 for i in range(1, len(items)): for j in range(weight + 1): if status[i - 1][j]: status[i][j] = status[i - 1][j] if j + items[i] &lt;= weight: status[i][j + items[i]] = 1 for l in status: print l # 判断可放置的最大重量 j = weight n = len(items) - 1 while j &gt;= 0: if status[n][j]: break print j # 打印最大重量，放置的物品 for i in range(n, 1, -1): if j - items[i] &gt;= 0 and status[i - 1][j - items[i]]: print i, items[i] j -= items[i]rucksack_hold([2, 2, 4, 6, 3], 9) 实际上我们可以有一个比上面空间复杂度更小的解法，代码如下:12345678910111213def rucksack_hold_2(items, weight): status = [0] * (weight + 1) status[0] = 1 status[items[0]] = 1 print status for i in range(1, len(items)): for j in range(weight - items[i], -1, -1): if status[j]: status[j + items[i]] = 1 print statusrucksack_hold_2([2, 2, 4, 6, 3], 9) 2.2 升级的 0-1 背包问题这次我们引入物品价值，要求计算在满足背包最大重量限制的前提下，背包中可装入物品的最大总价值。 使用动态规划的求解过程与上面类似，只不过现在 status 数组记录的不再是0或1，而是当前状态对应的最大总价值。我们把每一层中 (i, cw) 重复的状态（节点）合并，只记录 cv 值最大的那个状态，然后基于这些状态来推导下一层的状态。如果用回溯算法，这个问题就没法再用“备忘录”解决了。 12345678910111213141516171819 def rucksack_hold_3(items, weight, values): status = [[None] * (weight + 1) for i in range(len(items))] status[0][0] = 0 status[0][items[0]] = values[0] for i in range(1, len(items)): for j in range(weight + 1): if status[i - 1][j] &gt;= 0: status[i][j] = status[i - 1][j] if j + items[i] &lt;= weight: v = status[i - 1][j] + values[i] if status[i][j + items[i]] &lt; v: status[i][j + items[i]] = v for l in status: print lprint '------------------'a = [3, 4, 8, 9, 6]# a = [1, 1, 1, 1, 1]rucksack_hold_3([2, 2, 4, 6, 3], 9, a) 3. 练习3.1 练习一杨辉三角我们对杨辉三角进行一些改造。每个位置的数字可以随意填写，经过某个数字只能到达下面一层相邻的两个数字。假设你站在第一层，往下移动，我们把移动到最底层所经过的所有数字之和，定义为路径的长度。请你编程求出从最高层移动到最底层的最短路径长度。 1234567891011121314151617181920212223242526272829303132333435def path_pascal_triangle(pt): """ :param pt: :return: 计算杨辉三角的最短路径 """ n = len(pt) status = [] for i in range(0, n): s = [float('inf')] * (i + 1) row = pt[i] if i == 0: s[0] = row[0] s[-1] = row[-1] else: s[0] = row[0] + status[i - 1][0] s[-1] = row[-1] + status[i - 1][-1] status.append(s) print status for i in range(2, n): for j in range(1, i): left = j - 1 right = j status[i][j] = min(status[i - 1][left], status[i-1][right]) + pt[i][j] print status return min(status[-1])ss = [ [3], [1, 2], [5, 6, 7], [1, 1, 1, 1]]print path_pascal_triangle(ss) 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30.1 运维故障发现与监控系统应用]]></title>
    <url>%2F2018%2F11%2F10%2Flinux_mt%2F33-zabbix%2F%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[运维故障发现思路与监控系统应用 运维领域有一句话”我们不应该允许没有被监控的系统上线的”，显然监控对于我们快速发现问题解决问题至关重要。本章我们就来学习最常用的监控系统 zabbix 的安装，配置和使用。 在学习 zabbix 之前，我们首先需要对 zabbix 本身有所理解，因为无论是 zabbix 还是其他开源实现都是一种特定的解决方案，而不便的是怎样构建监控系统本身。 假设我们从头构建一个监控系统，应该如何做呢？我们需要思考以下几个问题: 监控哪些内容? 如何对监控项进行数据采集 如何判断系统是否处于非稳定状态，并在确定异常之后预警 如何能快速了解当前系统的状态及展示的问题。 这些问题就是我们构建一个监控系统的关键。因此一个完整的监控系统至少应该包含以下几个功能: 数据采集: 定期的采集监控指标的数据 数据存储: 将采集的数据保存起来，以便通过对比了解当前系统的状态 数据展示: 将存储的指标数据，直观的展示出来，以便运维工程师快速的了解整个系统的运行状态 报警: 当系统出现问题时，能发出报警及时通知管理员进行修复 1. 监控系统1.1 监控内容监控包含多个层面: 硬件: 硬件状态是否，硬件设备的资源是否满足业务需要，比如 CPU 使用率是否一直超过 90% 软件: 软件是否正成工作，比如我们的 nginx 服务进程是否正常 业务: 当前系统的并发请求数是否过高 不同的监控内容需要不同的监控设备以帮助我们收集监控数据，我们将监控设备称之为“传感器”(sensor)。 1.2 数据采集监控系统采集数据的通道通常包括 ssh/telnet agent: master/agent IPMI: 英特尔智慧平台接口，允许在硬件层级直接收集系统硬件状态信息 SNMP: Simple Network Management Protocol JMX: java 管理扩展，用于监控 jvm 虚拟机 1yum info net-snmp # linux snmp 协议的实现 1.3 存储系统监控数据分为两类: 历史数据: 每一次的采样数据，保存时间长较短 趋势数据: 一段时间内的聚合数据，保存时间较长 1.4 报警预警有多种方式，包括邮件，短信，微信，除了通用的邮件预警外，其他大多数的预警方式都是通过脚本来实现的。 1.5 展示数据展示有 WebGui，GUI，APP 等方式 1.6 监控系统的实现cactl， nagios: 功能有限zabbix: 功能强大]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.9 ansible 最佳实践]]></title>
    <url>%2F2018%2F11%2F09%2Flinux_mt%2F32-ansible%2Fansible_practice%2F</url>
    <content type="text"><![CDATA[ansible 最佳实践 当我们刚开始学习运用 playbook 时，可能会把 playbook 写成一个很大的文件，到后来可能你会希望这些文件是可以方便去重用的，所以需要重新去组织这些文件。ansible 支持 include 语法对 tasks, handlers, playbook 进行引用，从而我们可以对基础的通用功能进行封装，通过 “include” 对通用的功能进行组装从而实现复用。 1. include1.1 task include123456789101112131415161718tasks: - include: wordpress.yml wp_user=timmy - include: wordpress.yml wp_user=alice - include: wordpress.yml wp_user=bob# Ansible 1.4 及以后的版本tasks: - &#123; include: wordpress.yml, wp_user: timmy, ssh_keys: [ &apos;keys/one.txt&apos;, &apos;keys/two.txt&apos; ] &#125; # 传递结构化变量 tasks: - include: wordpress.yml vars: wp_user: timmy some_list_variable: - alpha - beta - gamma 1.2 playbook include12345678910111213- name: this is a play at the top level of a file hosts: all remote_user: root tasks: - name: say hi tags: foo shell: echo &quot;hi...&quot;- include: load_balancers.yml- include: webservers.yml- include: dbservers.yml 2. ansible 最佳实践2.1 项目目录结构一个完整的 ansible 项目，顶层目录结构应当包括下列文件和目录，如果你正在使用云服务，使用动态清单会更好。 1234567891011121314151617181920212223242526272829303132333435363738production # inventory file for production servers 关于生产环境服务器的清单文件stage # inventory file for stage environment 关于 stage 环境的清单文件group_vars/ group1 # here we assign variables to particular groups 这里我们给特定的组赋值 group2 # &quot;&quot;host_vars/ hostname1 # if systems need specific variables, put them here 如果系统需要特定的变量,把它们放置在这里. hostname2 # &quot;&quot;library/ # if any custom modules, put them here (optional) 如果有自定义的模块,放在这里(可选)filter_plugins/ # if any custom filter plugins, put them here (optional) 如果有自定义的过滤插件,放在这里(可选)site.yml # master playbook 主 playbookwebservers.yml # playbook for webserver tier Web 服务器的 playbookdbservers.yml # playbook for dbserver tier 数据库服务器的 playbookroles/ common/ # this hierarchy represents a &quot;role&quot; 这里的结构代表了一个 &quot;role&quot; tasks/ # main.yml # &lt;-- tasks file can include smaller files if warranted handlers/ # main.yml # &lt;-- handlers file templates/ # &lt;-- files for use with the template resource ntp.conf.j2 # &lt;------- templates end in .j2 files/ # bar.txt # &lt;-- files for use with the copy resource foo.sh # &lt;-- script files for use with the script resource vars/ # main.yml # &lt;-- variables associated with this role defaults/ # main.yml # &lt;-- default lower priority variables for this role meta/ # main.yml # &lt;-- role dependencies webtier/ # same kind of structure as &quot;common&quot; was above, done for the webtier role monitoring/ # &quot;&quot; fooapp/ # &quot;&quot; 2.2 playbook通过 include 将独立分散的 ansible 任务整合在一起 123456789101112---# file: site.yml # 顶层的 site- include: webservers.yml- include: dbservers.yml---# file: webservers.yml # webservers 的配置- hosts: webservers roles: - common - webtierv 理念是我们能够通过 “运行”(running) site.yml 来选择整个基础设施的配置.或者我们能够通过运行其子集 webservers.yml 来配置. 这与 Ansible 的 --limit 类似,而且相对的更为显式: 12ansible-playbook site.yml --limit webserversansible-playbook webservers.yml 2.3 任务执行1234567891011# 想重新配置整个基础设施,如此即可:ansible-playbook -i production site.yml# 那只重新配置所有的 NTP 呢？太容易了.:ansible-playbook -i production site.yml --tags ntp# 只重新配置我的 Web 服务器呢？:ansible-playbook -i production webservers.yml#只重新配置我在波士顿的 Web服务器呢?:ansible-playbook -i production webservers.yml --limit boston]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.8 ansible role]]></title>
    <url>%2F2018%2F11%2F08%2Flinux_mt%2F32-ansible%2Fansible_roles%2F</url>
    <content type="text"><![CDATA[ansible role role 角色，基于一个已知的文件结构，去自动的加载某些 vars_files，tasks 以及 handlers。基于 roles 对内容进行分组，使得我们可以容易地与其他用户分享 roles。 roles 是 playbook 的一个独立自包含目录，包含了执行 playbook 任务所有的配置文件及被操作文件，使得 playbook 的执行不需要依赖于任何外部环境。 1. roles 使用1.1 roles 目录结构一个包含 roles 的典型项目结构如下所示，如果你在 playbook 中同时使用 roles 和 tasks，vars_files 或者 handlers，roles 将优先执行。 1234567891011webservers.ymlroles/ webservers/ # 与 playbook 对应的 roles 目录 files/ # copy tasks，script tasks，引用 roles/x/files/ 中的文件无需指明路经 templates/ # template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径 tasks/ # main.yml 存在, 其中列出的 tasks 将被添加到 webservers.yml 中 handlers/ # main.yml 存在, 其中列出的 handlers 将被添加到 play 中 vars/ # main.yml 存在, 其中列出的 variables 将被添加到 play 中 defaults/ # main.yml 用于定义默认变量，这些变量在所有可用变量中拥有最低优先 meta/ # main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 (1.3 and later) 1.2 roles 使用角色的使用，只需在 playbook 的 roles 语句中添加角色即可 123456# vim webservers.yml---- hosts: webservers roles: - common - webservers 也可以使用参数化的 roles，这种方式通过添加变量来实现 1234567---- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &apos;/opt/a&apos;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &apos;/opt/b&apos;, port: 5001 &#125; 也可以为 roles 设置触发条件 12345---- hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; &#125; 最后，也可以给 roles 分配指定的 tags。比如: 12345---- hosts: webservers roles: - &#123; role: foo, tags: [&quot;bar&quot;, &quot;baz&quot;] &#125; 1.3 执行顺序如果 play 同时包含 tasks 和roles，这些 tasks 将在所有 roles 应用完成之后才被执行。如果你希望定义一些 tasks，让它们在 roles 之前以及之后执行，你可以这样做: 123456789101112131415---- hosts: webservers pre_tasks: - shell: echo &apos;hello&apos; roles: - &#123; role: some_role &#125; tasks: - shell: echo &apos;still busy&apos; post_tasks: - shell: echo &apos;goodbye&apos; 1.4 角色依赖角色依赖可以自动地将其他 roles 拉取到现在使用的 role 中。角色依赖保存在 roles 目录下的 meta/main.yml 文件中。这个文件应包含一列 roles 和 为之指定的参数 12345---dependencies: - &#123; role: common, some_parameter: 3 &#125; - &#123; role: apache, port: 80 &#125; - &#123; role: postgres, dbname: blarg, other_parameter: 12 &#125; “角色依赖” 总是在 role （包含”角色依赖”的role）之前执行，并且是递归地执行。默认情况下，作为 “角色依赖” 被添加的 role 只能被添加一次，如果另一个 role 将一个相同的角色列为 “角色依赖” 的对象，它不会被重复执行。但这种默认的行为可被修改，通过添加 allow_duplicates: yes 到 meta/main.yml 文件中。 1234567891011121314# wheel 角色中---allow_duplicates: yesdependencies:- &#123; role: tire &#125;- &#123; role: brake &#125;# 引用 wheel 的其他角色---dependencies:- &#123; role: wheel, n: 1 &#125;- &#123; role: wheel, n: 2 &#125;- &#123; role: wheel, n: 3 &#125;- &#123; role: wheel, n: 4 &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30 回溯算法]]></title>
    <url>%2F2018%2F11%2F07%2Falog%2Fbacktracking%2F</url>
    <content type="text"><![CDATA[编程思想之回溯算法 1. 回溯算法回溯算法很多时候都应用在“搜索”这类问题上。即在一组可能的解中，搜索满足期望的解。 回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。 很多经典的数学问题都可以用回溯算法解决，比如数独、八皇后、0-1 背包、图的着色、旅行商问题、全排列等等。我们将以其中的几个问题为例来讲解如何使用回溯算法解决问题。 1.1 解决步骤回溯算法非常适合用递归来实现，在实现的过程中，剪枝操作是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。 与递归算法一样，回溯算法容易理解，但是写起来丝毫不容易。个人觉得，相比于找到递归终止条件和递推公式，更难的是确定递归函数的变量和函数的返回值。关于函数变量的选择有一个可参考的经验，就是始终关注的是在计算中会使用到的随着计算不断变动的量；对于函数返回值，回溯算法是枚举所有的解，期望的解通常不是通过函数直接返回，而通常位于递归终止条件中。 2. 应用2.1 八皇后问题所谓八皇后问题是这样的，我们往一个 8x8 的棋盘中放 8 个棋子（皇后），每个棋子所在的行、列、对角线都不能有另一个棋子，找出所有满足要求的摆放方式。下面是一个满足条件和不满足条件的示例。 我们把这个问题划分成 8 个阶段，依次将 8 个棋子放到第一行、第二行、第三行……第八行。在放置的过程中，我们不停地检查当前的方法，是否满足要求。如果满足，则跳到下一行继续放置棋子；如果不满足，那就再换一种方法，继续尝试。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152def queens_eight(num=8): def cal_queens(row): if row == num: output_chessboard(chessboard, num) for column in range(num): if is_ok(chessboard, row, column, num): # print chessboard, row, column chessboard[row] = column cal_queens(row + 1) # 下标表示行，值表示列 chessboard = [0] * num cal_queens(0) return chessboarddef is_ok(chessboard, row, column, num): """ :param chessboard: :param row: :param column: :return: 检查最新的(row, column)摆放是否符合规则 """ left_up, right_up = column - 1, column + 1 last = row - 1 # 从最后一行往上检查 while last &gt;= 0: # 检查同列 if chessboard[last] == column: return False # 检查左上角对角线 if 0 &lt;= left_up == chessboard[last]: return False # 检查右上角对角线 if num &gt; right_up == chessboard[last]: return False last -= 1 left_up -= 1 right_up += 1 return Truedef output_chessboard(result, num): print result for i in range(num): column = result[i] c = ['*'] * num c[column] = '1' print ' '.join(c)queens_eight() 2.2 0-1 背包问题0-1 背包是非常经典的算法问题，这个问题的经典解法是动态规划，不过还有一种简单但没有那么高效的解法，那就是回溯算法。因此这个示例将是我们理解回溯算法和动态规划区别的很重要一个例子。 0-1 背包问题有很多变体，我这里介绍一种比较基础的。背包总的承载重量是 Wkg，有 n 个物品，每个物品的重量不等，并且不可分割。期望在不超过背包所能装载重量的前提下，让背包中物品的总重量最大。 对于每个物品来说，都有两种选择，装或者不装。n 个物品共有 2^n 种装法，去掉超过 Wkg，从剩下的选择种选择总重量最接近 Wkg 的。不过，我们如何才能不重复地穷举出这 2^n 种装法呢？ 我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。下面是代码实现: 1234567891011121314151617181920212223242526class RucksackHold(object): def __init__(self, weight, items): self.weight = weight self.items = items self.hold = 0 def _get_max_hold(self, i, cw): """ :param i: 考察的第 i 个物品 :param cw: 当前背包的总重量 :return: """ if i == len(self.items) or cw == self.weight: if cw &gt; self.hold: self.hold = cw return self._get_max_hold(i + 1, cw) if self.items[i] + cw &lt;= self.weight: self._get_max_hold(i + 1, cw + self.items[i]) def __call__(self, *args, **kwargs): self._get_max_hold(0, 0) return self.holdpk = RucksackHold(items=[1, 2, 4], weight=10)print pk() 回溯中的重复计算在回溯算法中，有些子问题的求解可能是重复的。假设背包的最大承载重量是 9，有 5 个不同的物品，重量分别是 2，2，4，6，3。如果我们把这个例子的回溯求解过程，用递归树画出来，就是下面这个样子： 递归树中的f(i, cw）表示一次函数调用。从递归树中可以发现，有些子问题的求解是重复的，比如图中的 f(2, 2) 和 f(3,4) 都被重复计算了两次。借助于对子问题结果的缓存，我们可以有效避免冗余计算提高计算效率。 2.3 正则表达式正则表达式中，最重要的就是通配符，简单期间，假设正表达式中只包含“*”和“\?”这两种通配符，并且“*”匹配任意多个（大于等于 0 个）任意字符，“\?”匹配零个或者一个任意字符。基于如上假设，如何用回溯算法，判断一个给定的文本，能否跟给定的正则表达式匹配？ 正则表达式中的特殊字符就是所谓的岔路口，比如“*”可以匹配任意个文本串中的字符，我们就先随意的选择一种匹配方案，然后继续考察剩下的字符。如果中途发现无法继续匹配下去了，我们就回到这个岔路口，重新选择一种匹配方案，然后再继续匹配剩下的字符。 12345678910class Pattern(): def __init__(self, pattern): self.pattern = pattern self.is_match = False def _match(self, S, i, j): pass def match(self, S): return self._match(S, 0, 0) 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.7 ansible playbook]]></title>
    <url>%2F2018%2F11%2F07%2Flinux_mt%2F32-ansible%2Fansible_playbook%2F</url>
    <content type="text"><![CDATA[ansible playbook playbook 是 基于 yaml 语法的一种编排 ansible 命令的”脚本”，类似与 shell scritp；但是 playbook 并不是一门语言。我的理解是 playbook 就是一个配置文件，必需按照 ansible 要求的特定格式编排 ansible 的任务，这样 ansible 才能对其进行解释并执行。其能提供的功能是由 ansible 决定的。我们的目的就是学习 playbook 特定的编写要求。 相对于 ad-doc 的好处类似于 shell script 之与 shell 命令，可以重复执行，拥有更加强大的逻辑控制，因此便于执行更复杂的任务。 1. playbook 配置语法下面是一个 playbook 的示例，我们将以这个示例为基础讲解如何编写 playbook。playbook 使用的 yaml 语法，因此在学习接下来的内容之前你需要先了解一下 yaml。 123456789101112131415161718---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 1.1 playbook的核心元素123456789101112131415161718- host: vars: remote_user: tasks: - - - variables: - - - handlers: - -- host:- host: 我们将 playbook 的配置语法分成两个部分来看，第一部分是基本的核心元素，使用这些元素我们就完全可以定义 ansible 的任务，包括 host: 任务要操作的主机，用法与 ansible &lt;host-pattern&gt; 选项相同 remote_user: 登陆的被管控主机的用户 tasks: 任务列表 handlers: 触发器， 第二部分是为了提高任务编排效率而额外提供的扩展语法包括 var: 变量 templates: 模板，模板可以利用 ansible 中的变量，为主机定义配置文件 when: 条件判断，比如可以依据操作系统类型决定安装什么，怎么安装模块，启动服务等 with_item: 循环，比如可以批量安装多个程序包，而不用定义多个任务 roles: 角色，抽象和独立 ansible 任务，使其可以自包含，便于移植。 1.2 核心元素host &amp; remote_userhost &amp; remote_user 定义要操作的主机以及以哪个用户身份去完成要执行的步骤。host 是一个或多个组或主机的 patterns与 ansible 的 &lt;host-pattern&gt; 选项使用完全一致，详细内容已经在上一节阐述在此不再累述。 12345678910---- hosts: webservers remote_user: yourname sudo: yes sudo_user: postgres tasks: - service: name=nginx state=started remote_user: root sudo: yes sudo_user: root tasktask 用于定义任务列表，任务的执行是从上而下顺序执行的，且只有在所有匹配到的 host 均执行完当前的任务之后，才会继续执行下一个任务。如果某一 host 在执行任务中失败，它将会从 host 中移除，不会继续执行接下来的任务。 每个 task 的目标在于执行一个 moudle, 通常是带有特定的参数来执行.在参数中可以使用变量（variables）。 123456789101112131415# 任务用于执行特定的模块，且必需具有 nametasks: - name: make sure apache is running service: name=httpd state=running# shell|command 执行命令的成功返回状态码非 0 时tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true tag: run# 使用命令tasks: - name: create a virtual host file for &#123;&#123; vhost &#125;&#125; template: src=somefile.j2 dest=/etc/httpd/conf.d/&#123;&#123; vhost &#125;&#125; 需要注意的是还可以为每个任务定义标签，在执行 ansible-playbook 时通过 -t TAGS, --tags=TAGS 选项，只运行指定标签对应的任务。 handlersHandlers 也是一些 task 的列表,通过名字来引用,它们和一般的 task 并没有什么区别.Handlers 是由通知者进行 notify, 如果没有被 notify,handlers 不会执行.不管有多少个通知者进行了 notify,等到 play 中的所有 task 执行完成之后,handlers 也只会被执行一次. Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了. 1234567891011tasks - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: # 按名称触发 handlers - restart memcached - restart apachehandlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 2. 变量与模板为了为不同的目标主机自定义配置文件，ansible 引入了 python jinja2 的模板。通过将配置文件中与目标主机相关的配置参数(比如网卡，绑定的 ip 地址)定义成模板中变量，来达到为每个主机自定义配置文件的目的。 2.1 模板ansible 中使用的模板是 python 的 jinja2，因此在创建模板之前，有必要学习一下如何定义 jinja2 模板，而将模板填充为文件，需要使用 ansible template 模块 123task - name: nginx confiure - template: src=/var/template/nginx.j2 dest=/etc/nginx/nginx.conf 2.1 变量的定义ansible 中变量的定义有如下几种方式: Facts中生成的变量: facts 生成的是远程目标主机的所有系统信息，可通过 ansible -m setup 查看 命令行中传递变量： ansible-playbook --extra-vars &quot;name=value name=value&quot; 或 --extra-vars &quot;@some_file.json&quot; 通过 inventory 主机清单传递变量，这种方式我们在 32.5 ansible简介 详细讲解过配置方法 通过 var 在 playbook 中自定义变量，这种定义方式还可以将变量独立到特定的文件中 通过 role 定义的变量，这种定义变量的方式我们会在下一节详细介绍 12345- hosts: webservers vars: - http_port: 80 vars_files: - /vars/external_vars.yml 2.2 变量的作用顺序在 ansible 中最好不要重复定义变量，保持 ansible 配置文件的简洁有助于我们维护和排错，如果相同的变量出现在不同的，其作用顺序由高到低如下所示 123456* extra vars (在命令行中使用 -e)优先级最高* 然后是在inventory中定义的 inventory 参数(比如ansible_ssh_user)* 接着是大多数的其它变量(命令行转换,play中的变量,included的变量,role中的变量等)* 然后是在inventory定义的其它变量* 然后是由系统发现的facts* 然后是 &quot;role默认变量&quot;, 这个是最默认的值,很容易丧失优先权 3. 逻辑控制3.1 判断whenansible 中的条件判断使用 when 语句，而 when 语句的值是 Jinja2 表达式 1234tasks: - name: &quot;shutdown Debian flavored systems&quot; command: /sbin/shutdown -t now when: ansible_os_family == &quot;Debian&quot; 一系列的Jinja2 “过滤器” 也可以在when语句中使用, 但有些是Ansible中独有的. 比如我们想忽略某一错误,通过执行成功与否来做决定,我们可以像这样: 12345678910tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 在playbooks 和 inventory中定义的变量在 when 语句中都可以使用. 下面一个例子,就是基于布尔值来决定一个任务是否被执行: 12345vars: - epic: truetasks: - shell: echo &quot;This certainly is epic!&quot; when: epic 下面是 when 语句的几个常用示例 12345678910111213# 依据变量是否定义进行判断tasks: - shell: echo &quot;I&apos;ve got &apos;&#123;&#123; foo &#125;&#125;&apos; and am not afraid to use it!&quot; when: foo is defined - fail: msg=&quot;Bailing out. this play requires &apos;bar&apos;&quot; when: bar is not defined # 与 with_items 一起使用tasks: - command: echo &#123;&#123; item &#125;&#125; with_items: [ 0, 2, 4, 6, 8, 10 ] when: item &gt; 5 3，2 循环with_itemansible 中标准循环使用 with_item 语句实现，典型的使用方式如下 1234567891011- name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &apos;testuser1&apos;, groups: &apos;wheel&apos; &#125; - &#123; name: &apos;testuser2&apos;, groups: &apos;root&apos; &#125;- name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2 除此之外， ansible 还提供了多种循环方式，迭代包括哈希表，文件列表等诸多内容。 前套循环12345- name: give users access to multiple databases mysql_user: name=&#123;&#123; item[0] &#125;&#125; priv=&#123;&#123; item[1] &#125;&#125;.*:ALL append_privs=yes password=foo with_nested: - [ &apos;alice&apos;, &apos;bob&apos; ] - [ &apos;clientdb&apos;, &apos;employeedb&apos;, &apos;providerdb&apos; ] 对文件列表使用循环123456789101112---- hosts: all tasks: # first ensure our target directory exists - file: dest=/etc/fooapp state=directory # copy each file over that matches the given pattern - copy: src=&#123;&#123; item &#125;&#125; dest=/etc/fooapp/ owner=root mode=600 with_fileglob: - /playbooks/files/fooapp/*]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.6 ansible 常用模块]]></title>
    <url>%2F2018%2F11%2F06%2Flinux_mt%2F32-ansible%2Fansible_module%2F</url>
    <content type="text"><![CDATA[ansible 常用模块 上一节我们对 ansible 做了一个概括性的介绍，本节我们来看看 ansible 主程序与常见模块的使用，模块是我们定义服务配置的关键。 1. ansible 核心程序ansible 的核心程序有三个 ansible: ad-hoc 执行命令 ansible-doc: ansible 插件(模块)文档查看工具 ansible-playbook: playbook 执行命令 1，1 ansibleansible &lt;host-pattern&gt; [-m module_name] [-a args] options 作用: ansible 命令行工具 模块: [-m module_name]: 指定使用的模块 [-a args]: 传递给模块的参数 选项: ansible 命令行工具的选项可分为三类 通用选项 连接选项 权限选项 通用选项: -C, --check: 不实际执行，只显示程序执行可能的结果 -D, --diff: 当执行的命令改变了文件或模板的内容时，显示更改前后的内容比较，最好和 -C, --check 一起使用 -e EXTRA_VARS, --extra-vars=EXTRA_VARS: 向 ansible 传递的额外参数，参数值必需是行如key=value的键值对 -f FORKS, --forks=FORKS: 并发操作的最大机器数 -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY: 定义 inventory 文件位置 --list-hosts: 只显示被操作的主机 --syntax-check:只对 playbook 执行语法检查, 不执行 -t TREE, --tree=TREE: 日志的输出目录 --version: 显示 ansible 的版本信息 连接选项: --private-key=PRIVATE_KEY_FILE: 指定连接的密钥文件 --key-file=PRIVATE_KEY_FILE:指定连接的密钥文件 -u,--user=REMOTE_USER: 连接到被管控主机的帐户，默认为 None -c, --connection=CONNECTION: 连接的类型，默认为 smart -T, --timeout=TIMEOUT: 连接超时时长 权限选项: -b, --become: --become-user=BECOME_USER: 提权限操作切换到的用户，默认为 root --become-method=BECOME_METHOD: 进行权限升级时使用的操作，默认为 sudo，可选值包括sudo | su --ask-become-pass: 使用 sudo 或 su 时，使用的密码 host-patternansible 支持多种主机匹配方式，以便我们能灵活的控制要操作的主机范围。常见的方式有如下几种 12345678910111213141516171819202122232425262728293031# 1. 全部主机all*# 2. IP地址或系列主机名one.example.comone.example.com:two.example.com192.168.1.50192.168.1.*# 3. 一个或多个groupswebservers # 单个组webservers:dbservers # 多个组的并集webservers:&amp;staging # 多个组的交集webservers:!phoenix # ! 表示排除关系，隶属 webservers 组但同时不在 phoenix组# 4. host names, IPs , groups都支持通配符*.example.com*.com# 5. 通配和groups的混合使用one*.com:dbservers# 6. 应用正则表达式，只需要以 ‘~’ 开头~(web|db).*\.example\.com# 7. 通过 --limit 标记来添加排除条件ansible-playbook site.yml --limit datacenter2# 8. 从文件读取hosts,文件名以@为前缀即可ansible-playbook site.yml --limit @retry_hosts.txt 1.2 ansible-docansible-doc options 作用: ansible 文档查看工具 选项: -l, --list: 显示所有可用插件及模块 -s, --snippet=module: 显示指定插件的的帮助信息 -t, --type=TYPE: 指定被选择的插件类型，默认为 module 1234567891011~$ ansible-doc -s shell- name: Execute commands in nodes. shell: chdir: # cd into this directory before running the command creates: # a filename, when it already exists, this step will *not* be run. executable: # change the shell used to execute the command. Should be an absolute path to the executable. free_form: # (required) The shell module takes a free form command to run, as a string. There&apos;s not an actual option named &quot;free form&quot;. See the examples! removes: # a filename, when it does not exist, this step will *not* be run. stdin: # Set the stdin of the command directly to the specified value. warn: # if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false. ansible-doc 显示的参数都是可以在 ansible 命令中 通过 -a 选项中传递给模块的参数 1ansible -m shell -a &quot;echo &apos;test&apos; chdir=/root&quot; ansible-playbookansible-playbook [options] playbook.yml [playbook2 ...] 作用: playbook 的执行命令 参数: playbook.yml... 表示 playbook 的路经 选项: ansible-playbook 与 ansible 命令行工具的选项基本类似 --playbook-dir=BASEDIR: playbook 的根目录，这个根目录的设置会影响 roles/ group_vars/ 等目录的查找路经 -t TAGS, --tags=TAGS: 运行指定标签对应的任务 2.ansible 常用模块ansible 命令的执行是为了达到期望的状态，如果被管控主机的当前状态与命令指定的状态不一致，则执行命令，所以ansible 的命令都是通过 state 参数指定要进行的操作。 2.1 基本模块useransible -m user -a &quot;options&quot; 作用: 用户管理 选项: name: 用户名 uid: 指定创建用户的 uid shell: 设置默认shell group: 设置默认组 groups: 设置附加组，默认操作是替换 append: groups 操作为追加而不是替换 home: 家目录 system: yes|no 是否为系统用户 move: 更新用户家目录时，是否将原有家目录的内容移动到新的目录中去 state: 用户操作 present: 创建用户 absent: 删除用户 12$ ansible-doc -s user$ ansible all -m user -a &quot;name=test uid=3000 shell=/bin/tsh groups=testgrp&quot; groupansible -m user -a &quot;options&quot; 作用: 用户组管理 选项: name: 组名 gid: 指定gid system: yes|no 是否为系统用户 state: 目标状态 present|absent copyansible -m copy -a &#39;options&#39; 作用: 文件复制和创建 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync remote_src: yes|no，指定 scr 参数的源是本机还是远程的被管理主机，no 为本机 owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 12ansible -m copy -a &quot;src=/etc/fstab dest=/tmp/fstab.ansible&quot;ansible -m copy -a &quot;content=&apos;hi ansible\n&apos; dest=/tmp/fstab.ansible mode=600&quot; fileansible -m file -a &quot;options&quot; 作用: 文件属性管理 选项: force：yes|no 是否强制创建软连接 一种是源文件不存在但之后会建立的情况下，强制创建 另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链 group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 123ansible test -m file -a &quot;src=/etc/fstab dest=/tmp/fstab state=link&quot;ansible test -m file -a &quot;path=/tmp/fstab state=absent&quot;ansible test -m file -a &quot;path=/tmp/test state=touch&quot; templateansible -m template -a &#39;option&#39; 作用: 基于 python jinja2 模板生成文件并复制到目标主机 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no src：要被链接的源文件的路径，只应用于state=link的情况 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 2.2 命令执行commandansible -m command -a &#39;option&#39; 作用: 命令执行，但是无法解析 bash 中的特殊字符，比如 |，只能执行简单命令 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 1ansible -m command -a &quot;ifconfig&quot; shellansible -m shell -a &#39;option&#39; 作用: 命令执行，能正常解析 shell 语法 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 1ansible -m command -a &quot;echo pswd|password --stdin tao&quot; scriptansible -m script -a &#39;option&#39; 作用: 将脚本复制到管控主机并执行 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 1ansible -m script -a &quot;mount.sh&quot; pingansible -m ping -a &#39;option&#39; 作用: 测试主机是否是通的 选项：无 12345ansible 10.212.52.252 -m ping10.212.52.252 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 2.3 程序安装yumansible -m yum -a &#39;option&#39; 作用: 文件属性管理 选项： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，可附带版本信息，也可以传递一个url或者一个本地的rpm包的路径 allow_downgrade: 是否允许降级安装，默认为 no；默认的安装操作相当于 yum -y update，如果 name 指定的版本相对于已安装的版本较低，则不会安装 state：状态（present，absent，latest） 123ansible test -m yum -a &apos;name=httpd state=latest&apos;ansible test -m yum -a &apos;name=&quot;@Development tools&quot; state=present&apos;ansible test -m yum -a &apos;name=http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm state=present&apos; pipansible -m pip -a &#39;option&#39; 作用: 文件属性管理 选项： chdir: pip 命令运行前切换到此目录 executable: 指定运行 pip的版本，pip 的名称或绝对路经；不能与virtualenv同时使用 extra_args: 传给 pip的额外参数 name: 安装的程序包名称，可以是一个 url version: 指定的Python库的安装版本 virtualenv：virtualenv 虚拟环境目录，不能与 executable 同时使用，如果虚拟环境不存在，将自动创建 virtualenv_command: 虚拟环境使用的管理命令或绝对路经，eg:pyvenv, ~/bin/virtualenv virtualenv_python: 虚拟环境中的 python 版本，当virtualenv_command使用pyvenv或-m venv模块时，不应使用此参数 state: present:默认的，表示为安装 lastest: 安装为最新的版本 absent：表示删除 forcereinstall：“forcereinstall”选项仅适用于可ansible 2.1及更高版本 12# 支持 pipenv 么？ansible -m pip -a &quot;name=ipython virtualenv=/opt/vdd/project virtualenv_command=pipenv&quot; 2.4 服务管理cronansible -m cron -a &#39;option&#39; 作用: 周期性任务管理 选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日 hour：小时 minute：分钟 month：月 weekday：周 job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数包括 reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除，present or absent user：以哪个用户的身份执行 1234ansible test -m cron -a &apos;name=&quot;a job for reboot&quot; special_time=reboot job=&quot;/some/job.sh&quot;&apos;ansible test -m cron -a &apos;name=&quot;yum autoupdate&quot; weekday=&quot;2&quot; minute=0 hour=12 user=&quot;rootansible 10.212.52.252 -m cron -a &apos;backup=&quot;True&quot; name=&quot;test&quot; minute=&quot;0&quot; hour=&quot;2&quot; job=&quot;ls -alh &gt; /dev/null&quot;&apos;ansilbe test -m cron -a &apos;cron_file=ansible_yum-autoupdate state=absent&apos; serviceansible -m service -a &#39;option&#39; 作用: 管理服务管理 选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 1ansible -m service -a &quot;name=httpd state=started enabled=yes&quot; 2.5 变量获取setupansible -m setup -a &#39;option&#39; 作用: 获取被管控主机的所有系统参数信息 选项： filter: 参数过滤，支持 shell 通配语法 gather_subset: 限制返回的参数范围，可选值包括 all, min, hardware, network, virtual, ohai,值前的 ! 表示取反 gather_timeout: 参数收集的超时时长 123ansible 10.212.52.252 -m setup -a &apos;filter=ansible_*_mb&apos; //查看主机内存信息ansible 10.212.52.252 -m setup -a &apos;filter=ansible_eth[0-2]&apos; //查看地接口为eth0-2的网卡信息ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29 分治算法]]></title>
    <url>%2F2018%2F11%2F05%2Falog%2Fdivide%2F</url>
    <content type="text"><![CDATA[编程思想之分治算法 1. 分治算法分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。 这个定义看起来有点类似递归的定义。关于分治和递归的区别，我们在排序（下）的时候讲过，分治算法是一种处理问题的思想，递归是一种编程技巧。实际上，分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及这样三个操作： 分解：将原问题分解成一系列子问题； 解决：递归地求解各个子问题，若子问题足够小，则直接求解； 合并：将子问题的结果合并成原问题。 1.1 适用情景分治算法能解决的问题，一般需要满足下面这几个条件： 原问题与分解成的小问题具有相同的模式； 原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别，等我们讲到动态规划的时候，会详细对比这两种算法； 具有分解终止条件，也就是说，当问题足够小时，可以直接求解； 可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。 1.2 分治在大数据中的应用我们前面讲的数据结构和算法，大部分都是基于内存存储和单机处理。但是，如果要处理的数据量非常大，没法一次性放到内存中，这个时候，这些数据结构和算法就无法工作了。 要解决这种数据量大到内存装不下的问题，我们就可以利用分治的思想。将海量的数据集合根据某种方法，划分为几个小的数据集合，每个小的数据集合单独加载到内存来解决，然后再将小数据集合合并成大数据集合。实际上，利用这种分治的处理思路，不仅仅能克服内存的限制，还能利用多线程或者多机处理，加快处理的速度。 2.应用归并排序和快速排序是分治算法的典型应用，这两个算法我们在之前的排序章节已经讲过了。所以我们以另一个例子: 如何编程求出一组数据的有序对个数或者逆序对个数，来讲解如何应用分治算法。 2.1 计算数据有序度我们套用分治的思想来求数组 A 的逆序对个数。我们可以将数组分成前后两半 A1 和 A2，分别计算 A1 和 A2 的逆序对个数 K1 和 K2，然后再计算 A1 与 A2 之间的逆序对个数 K3。那数组 A 的逆序对个数就等于 K1+K2+K3。 使用分治算法其中一个要求是，子问题合并的代价不能太大，否则就起不了降低时间复杂度的效果了。那如何快速计算出两个子问题 A1 与 A2 之间的逆序对个数呢？这里就要借助归并排序算法了。 1234567891011121314151617181920212223242526272829303132333435363738def reverse_count(A): """ :param A: :return: 计算数组 A 的逆序度 """ if len(A) &lt;= 1: return 0 mid = len(A) // 2 S1 = A[:mid] c1 = reverse_count(S1) S2 = A[mid:] c2 = reverse_count(S2) c3 = merge(S1, S2, A) return c1 + c2 + c3def merge(S1, S2, S): """ :param S1: :param S2: :param S: :return: 归并排序，并计算两个数组的逆序度 """ c = i = j = 0 while i + j &lt; len(S): if i == len(S1) or (j &lt; len(S2) and S1[i] &gt; S2[j]): S[i + j] = S2[j] j += 1 c += (len(S1) - i) else: S[i + j] = S1[i] i += 1 return cs = [1, 5, 6, 7] + [2, 3, 4]print reverse_count(s)print s 3.练习下面是分治算法的一些典型练习题 3.1 练习一二维平面上有 n 个点，如何快速计算出两个距离最近的点对？1pass 3.2 练习二有两个 n*n 的矩阵 A，B，如何快速求解两个矩阵的乘积 C=A*B？1pass 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.5 ansible简介]]></title>
    <url>%2F2018%2F11%2F05%2Flinux_mt%2F32-ansible%2Fansible%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[ansible简介 在本章的开篇我们说过自动化运维的几个层次 BootStraping: 引导安装操作系统 Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理 Command &amp; Control: 批量运行程序 ansible 正是配置系统，和批量命令执行两个层面的轻量级强大的解决方案。 为了批量的管理主机，我们需要与本管控主机进行通信，目前”通信”存在两种方式。一种是以 saltstack 为代表的 agent 模式，及在被管控主机之上必需部署客户端代理，由其接收指令并在被管控主机之上执行。另一种是以 ansible 为代表的 less agent 模式，通过 ssh 连接直接远程执行命令。本节开始我们就来学习 ansible 的安装配置及使用。 1. ansible 简介1.1 程序框架 上图是 ansible 架构示意图，ansible 是高度模块化，由如下几个部分组成 Ansible： 作用: Ansible的核心程序 Host Inventory： 作用: 记录了每一个由Ansible管理的主机信息，信息包括ssh端口，root帐号密码，ip地址等等 Connection Plugins： 作用: 连接插件，Ansible和Host通信使用 Core Modules： 作用: Ansible执行任何管理任务都不是由Ansible自己完成，而是由核心模块完成；Ansible管理主机之前，先调用core Modules中的模块，然后指明管理Host Inventory中的主机，就可以完成管理主机。 Custom Modules: 作用: 自定义模块，完成Ansible核心模块无法完成的功能，此模块支持任何语言编写。 Playbooks： 作用: YAML格式文件，多个任务定义在一个文件中，使用时可以统一调用，类似于“剧本”用来定义那些主机需要调用那些模块来完成的功能. 模块Ansible 任务的执行则是通过模块实现的，ansible 的模块通常是 Linux 中的命令是或者特定工具是一一对应，要学习 ansible 配置主要内容之一就是学习常见模块的应用。 playbookAnsible提供了两种方式去完成任务,一是 ad-hoc 命令,一是写 Ansible playbook，两者的关系类似于在命令行敲入shell命令和 写shell scripts playbook 中最重要的概念称为role(角色)，角色是一个自包涵的任务集合，不仅包含 playbook，也包含 playbook 内每一个命令所需的文件。role 存在的目的是让 ansible 更加容易移植。 1.2 ansible 安装1234567891011121314151617181920212223242526272829$ sudo yum install ansible$ ansible --version$ rpm -ql ansible |egrep -v &quot;(python|man|doc)&quot;/etc/ansible/etc/ansible/ansible.cfg # ansible 自身的配置文件/etc/ansible/hosts # Host Inventory/etc/ansible/roles # roles 所在目录/usr/bin/ansible # ad-hoc 执行命令/usr/bin/ansible-2/usr/bin/ansible-2.7/usr/bin/ansible-config/usr/bin/ansible-connection /usr/bin/ansible-console/usr/bin/ansible-console-2/usr/bin/ansible-console-2.7/usr/bin/ansible-galaxy/usr/bin/ansible-galaxy-2/usr/bin/ansible-galaxy-2.7/usr/bin/ansible-inventory/usr/bin/ansible-playbook # playbook 执行命令/usr/bin/ansible-playbook-2/usr/bin/ansible-playbook-2.7/usr/bin/ansible-pull/usr/bin/ansible-pull-2/usr/bin/ansible-pull-2.7/usr/bin/ansible-vault/usr/bin/ansible-vault-2/usr/bin/ansible-vault-2.7 1.3 ansible 认证机制使用 ansible 之前最主要的任务是配置 Host Inventory，即定义 ansible 管控的主机。但是在定义 Host Inventory 之前，我们有必要先了解一下 Ansible是如何通过SSH与远程服务器连接。 备注: 参考马哥Linux Ansible 权威教程 Ansible 1.3及之后Ansible 1.3及之后的版本默认会在本地的 OpenSSH可用时会尝试用其进行远程通讯.这会启用ControlPersist(一个性能特性),Kerberos,和在~/.ssh/config中的配置选项如 Jump Host setup。 然而,当你使用Linux企业版6作为主控机(红帽企业版及其衍生版如CentOS),其OpenSSH版本可能过于老旧无法支持ControlPersist. 在这些操作系统中,Ansible将会退回并采用 paramiko (由Python实现的高质量OpenSSH库). 如果你希望能够使用像是Kerberized SSH之类的特性,烦请考虑使用Fedora, OS X, 或 Ubuntu 作为你的主控机直到相关平台上有更新版本的OpenSSH可供使用,或者启用Ansible的“accelerated mode”.参见 Accelerated Mode. Ansible 1.2 及之前在Ansible 1.2 及之前的版本,默认将会使用 paramiko. 本地OpenSSH必须通过-c ssh 或者 在配置文件中设定. 偶尔会遇到不支持SFTP的设备.虽然这很少见,但你会有概率中奖.你可以通过在配置文件(Ansible的配置文件)中切换至 SCP模式来与之链接. 说起远程设备,Ansible会默认假定你使用 SSH Key(我们推荐这种)但是密码也一样可以.通过在需要的地方添加 –ask-pass选项 来启用密码验证.如果使用了sudo 特性,当sudo需要密码时,也同样适当的提供了–ask-sudo-pass选项. 1.4 ansible 初始化配置ansible 初始化配置很容易分为两步: 配置主控机与被管控主机基于 SSH 密钥通信 在 Host Inventory 定义被管控的主机 下面是一个配置示例123456789101112# SSH Key 免密码登陆ssh-kengen -t rsa -P &quot;&quot;ssh-copy-id ~/.ssh/id_rsa.pub root@172.168.0.3# 配置 Host Inventoryvim /etc/ansible/hosts[webservers]172.16.0.3# 测试ansible webservers --list-hostsansible webservers -m ping 2. 配置 Host InventoryHost Inventory 用于定义 ansible 管理的主机及主机组。默认的文件路径为 /etc/ansible/hosts 除默认文件外,你还可以同时使用多个 inventory 文件,也可以从动态源,或云上拉取 inventory 配置信息。下面是 Host Inventory 配置示例 12345mail.example.com[webservers]foo.example.combar.example.com Host Inventory 是 ini 风格的配置文件，使用 [组名] 定义组。组用于对系统进行分类，便于对不同系统进行统一管理。一个主机可以属于不同组。 2.1 主机定义12345678910mail.example.com # 1. 标准形式172.16.0.1badwolf.example.com:5309 # 2. 自定义端口www[01:50].example.com # 3. 扩展形式db-[a:f].example.comjumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 # 4. 通过参数定义[targets]localhost ansible_connection=localother1.example.com ansible_connection=ssh ansible_ssh_user=mpdehaan Host Inventory 内主机有多种定义方式，我的理解核心就是 IP/FQDN [Lnventory 参数] IP/FQDN: 指明管控的主机，可以 ip 地址也可以是域名 Inventory 参数: 控制 ansible 与远程主机的交互方式 在 jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 的示例中 jumper 是主机的别名，通过参数 ansible_ssh_host 设置主机的 IP 地址。 Inventory 参数Inventory 有如下常用参数 12345678910111213141516171819202122232425262728293031323334ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置.ansible_ssh_user 默认的 ssh 用户名ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本)ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko. 1.2 以后默认使用 &apos;smart&apos;,&apos;smart&apos; 方式会根据是否支持 ControlPersist, 来判断&apos;ssh&apos; 方式是否可行.ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 &apos;sh&apos; 语法,可设置为 &apos;csh&apos; 或 &apos;fish&apos;.ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是&quot;/usr/bin/python&quot;, 比如 \*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 &quot;/usr/bin/env&quot; 机制, 因为这要求远程用户的路径设置正确,且要求 &quot;python&quot; 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 2.1 变量定义除了定义主机和组，Inventory 内还能主机和组定义特定的变量。这些变量定义后可在 playbooks 中使用。但是不建议在Inventory 中定义变量。变量定义的其他方式我们会在 playbook 中在详细介绍。 主机变量123[atlanta]host1 http_port=80 maxRequestsPerChild=808host2 http_port=303 maxRequestsPerChild=909 组变量1234567[atlanta]host1host2[atlanta:vars]ntp_server=ntp.atlanta.example.comproxy=proxy.atlanta.example.com 分文件定义 Host 和 Group 变量在 inventory 主文件中保存所有的变量并不是最佳的方式.还可以保存在独立的文件中,这些独立文件与 inventory 文件保持关联. 不同于 inventory 文件(INI 格式),这些独立文件的格式为 YAML。 1234567# 假设 inventory 文件的路径为:/etc/ansible/hosts# 分文件为 groups 和 host 定义的变量文件/etc/ansible/group_vars/raleigh # raleigh 组变量/etc/ansible/group_vars/webservers # webservers 组变量/etc/ansible/host_vars/foosball # foosball 主机变量 还有更进一步的运用,你可以为一个主机,或一个组,创建一个目录,目录名就是主机名或组名.目录中的可以创建多个文件, 文件中的变量都会被读取为主机或组的变量。注意,分文件定义变量的方式只适用于 Ansible 1.4 及以上版本.12/etc/ansible/group_vars/raleigh/db_settings/etc/ansible/group_vars/raleigh/cluster_settings Ansible 1.2 及以上的版本中,group_vars/ 和 host_vars/ 目录可放在 inventory 目录下,或是 playbook 目录下. 如果两个目录下都存在,那么 playbook 目录下的配置会覆盖 inventory 目录的配置。把你的 inventory 文件 和 变量 放入 git repo 中,以便跟踪他们的更新,这是一种非常推荐的方式.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.4 运维自动化入门]]></title>
    <url>%2F2018%2F11%2F04%2Flinux_mt%2F32-ansible%2F%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[运维自动化入门 1. 运维工作]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28 贪心算法]]></title>
    <url>%2F2018%2F11%2F04%2Falog%2Fgreedy%2F</url>
    <content type="text"><![CDATA[编程思想之贪心算法 1. 贪心算法前面我们讲完了字符串匹配相关的算法，接下来的几章与编程思想有关，包括贪心，分治，回溯和动态规划。它们都非常抽象，但是理解透了可以帮我们解决很多问题。这些算法在一定程度上很相近，因此学习过程中，我们首先要搞清楚它们的适用场景，其次是掌握怎么运用它们去解决问题。今天，我们先来学习贪心算法。 1.1 适用场景贪心，回溯，动态规划都适合解决“分阶段决策问题”。而贪心算法不适合前面的选择，会影响后面的选择这类情景。贪心算法的求解过程中，只会保留每个阶段的最优解，不会保留其他非最优状态。对于后面的选择依赖前面选择的分阶段决策问题，如果考虑前面的选择，计算将无法回溯，不可行；如果只考虑每个阶段的最优，最后很可能无法得出最优解。 1.2 解决步骤利用贪心算法，我们可以按照如下步骤去解决问题: 第一步，当我们看到这类问题的时候，首先要联想到贪心算法，贪心算法格外适用于针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。 第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。 第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。 2. 应用贪心算法有很多经典应用包括钱币找零，区间覆盖，霍夫曼编码等等。我们就以其中几个例子来实战贪心算法的应用。 2.1 钱币找零假设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元面额的纸币， 张数分别是: c1、c2、c5、c10、c20、c50、c100。我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？ 思路: 在贡献相同期望值（纸币数目）的情况下，我们希望多贡献点金额，这样就可以让纸币数更少，这就是一种贪心算法的解决思路。 123456789101112def cion(k): coin = [100, 50, 20, 10, 5, 2, 1] coin_map = [(i, 20) for i in coin] i = 0 coin_count = 0 while i &lt; len(coin) and k &gt; 0: use = coin_map[i] c = min(use[1], k // use[0]) k -= use[0] * c coin_count += c i += 1 return coin_count 2.2 区间覆盖假设我们有 n 个区间，区间的起始端点和结束端点分别是 [l1, r1]，[l2, r2]，[l3, r3]，……，[ln, rn]。我们从这 n 个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间呢？lintcode-1242. 无重叠区间就是这个问题的变形。 思路：我们假设这 n 个区间中最左端点是 lmin，最右端点是 rmax。这个问题就相当于，我们选择几个不相交的区间，从左到右将 [lmin, rmax] 覆盖上。我们按照起始端点从小到大的顺序对这 n 个区间排序。我们每次选择的时候，左端点跟前面的已经覆盖的区间不重合的，右端点又尽量小的，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间。这实际上就是一种贪心的选择方法。 12 2.3 霍夫曼编码霍夫曼编码不仅会考察文本中有多少个不同字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。如何给不同频率的字符选择不同长度的编码呢？根据贪心的思想，我们可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。为了避免解压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。 12 3. 练习leetcode 上有很多贪心算法的练习题，下面是一些练习题以及它们的解答 3.1 练习一在一个非负整数 a 中，我们希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？ 12 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.3 pxe与cobbler]]></title>
    <url>%2F2018%2F11%2F03%2Flinux_mt%2F32-ansible%2Fpxe%E4%B8%8Ecobbler%2F</url>
    <content type="text"><![CDATA[pxe与cobbler cobbler 就是 pex 环境的二次封装，为用户提供了一个管理工具，能将多个 pxe 环境整合在一起，让用户自行选择安装的系统。 1， cobbler 安装1.1 rpm 包组成123456789101112131415161718192021222324yum install cobbler$ rpm -ql cobbler|egrep -v &quot;(man|python|doc)&quot;/etc/cobbler # 配置文件/etc/cobbler/settings # 自身运行的配置文件/etc/cobbler/auth.conf/etc/cobbler/cheetah_macros/etc/cobbler/cobbler_bash/etc/cobbler/completions/etc/cobbler/dhcp.template/etc/cobbler/dnsmasq.template/etc/cobbler/import_rsync_whitelist/etc/cobbler/iso/etc/cobbler/iso/buildiso.template/etc/cobbler/ldap/etc/cobbler/ldap/ldap_authconfig.template/etc/cobbler/modules.conf/etc/cobbler/mongodb.conf/etc/cobbler/named.template/etc/cobbler/power # 服务的配置模板/etc/cobbler/power/fence_apc_snmp.template......../etc/cobbler/pxe/etc/cobbler/pxe/bootcfg_esxi5.template........ 2. cobbler 环境配置2.1 cobbler 启动cobbler 配置文件提供了对多种环境的配置，默认配置通常就可以直接使用。我们可以根据 cobbler 启动时的报错信息对必要的参数作出调整即可。 1234567891011121314systemctl restart httpdsystemctl start cobblerd.servicecobbler check #1 : The &apos;server&apos; field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the &apos;next_server&apos; field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.3 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux4 : change &apos;disable&apos; to &apos;no&apos; in /etc/xinetd.d/tftp5 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run &apos;cobbler get-loaders&apos; to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The &apos;cobbler get-loaders&apos; command is the easiest way to resolve these requirements.6 : enable and start rsyncd.service with systemctl7 : debmirror package is not installed, it will be required to manage debian deployments and repositories8 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to &apos;cobbler&apos; and should be changed, try: &quot;openssl passwd -1 -salt &apos;random-phrase-here&apos; &apos;your-password-here&apos;&quot; to generate new one9 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them cobbler 启动之后使用 check 对 cobbler 环境进行检查，会显示当前 cobbler 环境存在的问题，我们只要相应的修改配置文件解决这些问题，我们的 cobbler 环境也就准备好了。现在我们来解决这些问题 2.2 环境配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 1. server 绑定地址，改为外网地址，以便其他主机能访问到vim /etc/cobbler/settingsserver: 172.16.0.2# 2. next server 指向改为 tftp server 地址vim /etc/cobbler/settingsnext_server: 172.16.0.2# 3. SELinux 设置为 Permissive，无影响# 4. 编辑 /etc/xinetd.d/tftp 启动 tftp 服务vim /etc/xinetd.d/tftpservice tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no # disable 改为 no per_source = 11 cps = 100 2 flags = IPv4&#125;# 5. 某些 bootloader 不在 /var/lib/cobbler/loaders 文件夹内yum install syslinuxcp /usr/share/syslinux/&#123;menu.c32, pxelinux.0&#125; /var/lib/cobbler/loaders# 6. 启用 rsync 服务systemctl start rsyncd.servicesystemctl enable rsyncd.service# 7. 安装 debmirror 包yum install debmirror# 8. 修改 default_password_crypted 为超级用户设置的密码# openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'openssl passwd -1 -salt dgea 1234$1$dgea$nPoeNaw5o4mv6kkXjhzVI1vim /etc/cobbler/settingsdefault_password_crypted: $1$dgea$nPoeNaw5o4mv6kkXjhzVI1# 9. 安装 fence-agents，这个是高可用集群所使用的组件，此处可以先忽略 2.3 配置 pxe 所依赖的服务cobbler 虽然依赖于 pxe 环境，但是对 pxe 支持自动配置，只需要提供 pex 对应服务的配置文件，cobbler 能实现自动安装，配置和启动。相比于使用 cobber 自动安装，可能我们手动配置其他服务器可能更熟悉快捷。所以接下来我们也是以手动配置为主。 手动管理 pxe 所需服务，还是由 cobbler 自己管理需要在配置文件中进行配置。如果是由 cobbler 自动配置，还需要在 /etc/cobbler/modules.conf 配置文件内为各服务提供配置参数。 12345678910111213vim /etc/cobbler/settingsmanage_dhcp: 0 # 0 表示手动配置，1 表示 cobbler 自动配置manage_dns: 0manage_tftpd: 1manage_rsync: 0# 为各服务配置服务参数$ cat /etc/cobbler/modules.conf |grep &quot;^\[&quot;[authentication][authorization][dns][dhcp][tftpd] 3. 配置 cobbler 服务3.1 cobbler 服务组成如下图，cobbler 服务由如下几个部分组成，我们的目的就是配置好这几个组成部分。 Disribution : distro, 表示一个发行版，包括内核，initrd Repository: repo 创建仓库，比如yum仓库等，可以直接创建，也可以导入光盘的 yum 仓库 system： system 通过mac地址来定制化系统 profile： profile 对需要安装某个系统的所有配置，包括 kickstart 配置文件 3.2 cobbler 命令使用123456# cobblerusage=====cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help]cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 子命令首先 cobbler 有众多字命令，每一个子命令用于配置 cobbler 服务的一部份 distro: 用于配置 Disribution，核心是定义 kernel 和 initrd profile: 配置 profile repo: 配置 Repository yum 源 system: 配置 system 定制系统 操作其次每个组件都有相关的管理操作: add edit copy getks* list remove rename report 12cobbler distro listcobbler distro add --help 辅助命令最后剩下的部分是 cobbler 的辅助命令，可以基于当前已有的光盘和 yum 仓库快速配置相应组件，也包括其他一些辅助功能 buildiso import: 通过导入光盘自动生成一个 distro sync: cobbler 同步，每次执行新的操作之后最好都同步一次 3.2 distro 管理cobbler import [options] 作用: 通过导入光盘自动生成一个 distro 过程: 会在 /var/www/cobbler/ks_mirror 下自动创建一个--name参数的文件夹，将光盘内的所有内容复制到该目录下 import 会自动为导入的 distro 生成一个 profile Options: -h, --help: 帮助 --arch=ARCH: 被导入操作系统的平台架构 --breed=BREED: the breed being imported --os-version=OS_VERSION: the version being imported --path=PATH: 光盘镜像挂载点 --name=NAME: distro 名称 --available-as=AVAILABLE_AS: tree is here, don’t mirror --kickstart=KICKSTART_FILE: assign this kickstart file --rsync-flags=RSYNC_FLAGS: pass additional flags to rsync 12345678cobbler import --name=Centos-7.1-x86_64 --path=/cdromls /var/www/cobbler/ks_mirrorCentos-7.1-x86_64cobbler distro listcobbler profile listcobbler sync 3.3 profile 管理12345678910111213# cobbler profile --helpusage=====cobbler profile addcobbler profile copycobbler profile dumpvarscobbler profile editcobbler profile findcobbler profile getkscobbler profile listcobbler profile removecobbler profile renamecobbler profile report addcobbler profile add options 作用: 添加 profile options: --name --distro --kickstart 1234cobbler profile add --name=Centos-7.1-x86_64_service --distro=Centos-7.1-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks.cfgcobbler sync # 将新增的 profile 添加到 /var/lib/tfpt/pexlinux.cfg/default 的开机菜单中 editcobbler profile edit options renamecobbler profile rename options --name --newname 4. cobbler webcobbler web 提供了以web 界面供我们配置 cobbler 服务使用。在使用 cobbler web 之前我们需要进行认证配置。其认证分为如下几种形式 4.1 cobbler web 认证auth_pam 认证此配置是基于系统帐户完成认证 123456789101112131415vim /etc/cobbler/modules.conf[authentication]module = authn_pam# 添加帐户useradd cblradminecho cblpass |passwd --stdin cblradmin# 将用户添加至 cobbler user 组中vim /etc/cobbler/users[admins]admin = cblradmin# 重启服务systemctl restart cobblerd authn_configfile此认证是基于帐号密码文件完成认证 123456789vim /etc/cobbler/modules.conf[authentication]module = authn_configfile# 创建认证文件htdigest -c /etc/cobbler/users.digest Cobbler cblradmin# 重启服务systemctl restart cobblerd htdigest [-c] passwordfile realm username 4.2 cobbler web 配置1234567891011121314# 1. 安装yum install cobbler-web# 2. 配置 authn_configfile 认证htdigest -c /etc/cobbler/users.digest Cobbler cblradminAdding password for cblradmin in realm Cobbler.New password:Re-type new password:# 3. 重启 httpdsystemctl restart httpd# 4. 访问http://ip/colbbler_web]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27 AC 自动机]]></title>
    <url>%2F2018%2F11%2F03%2Falog%2Fac%2F</url>
    <content type="text"><![CDATA[敏感词过滤]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.2 PXE 系统自动化部署]]></title>
    <url>%2F2018%2F11%2F02%2Flinux_mt%2F32-ansible%2FPXE%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[PXE 系统自动化部署 PXE 全称是 preboot execute environment 由 Intel 公司开发，用于为完成基于网络的引导安装。 1. PXE 工作过程 pxe 要求客户端主机的网卡必需支持网络引导机制，并将网络设置为第一引导设备。整个过程如上图所示: 未安装操作系统的主机启动时，网卡首先发送一个 rarp 协议报文，从局域网中的 dhcp 服务获取一个 IP 地址，并同时获取引导文件，和引导文件所在的文件服务器(dhcp 的 filename,next-server 参数指定) 主机加载引导文件后，会依据引导文件继续向文件服务器获取内核和 initrd 文件，启动Linux 内核，并依据之前获取的 IP 地址，配置好网络属性 内核加载完成之后，会依据开机启动配置文件中指定的 yum 仓库获取操作系统安装程序 anaconda，并启动安装过程 此后的安装过程就与我们通过硬盘安装操作系统的过程类似，Centos 系可借助 kickstart 文件完成自动安装，这部分请参阅 15.2 Centos安装过程 因此整个 PXE 依赖于以下服务: dhcp: 提供 IP 地址，引导文件和文件服务器的指向(执行 tftp server) tftp: 文件服务器，用于提供引导文件，操作系统内核，initrd yum repository: 一个 yum 仓库，为系统安装提供源，可通过 http,https, ftp,nfs 任意服务提供 2. tftp servertftp 监听在 udp 的 69 号端口上 1234567891011121314151617# 安装yum install tftp-server tftprpm -ql tftp-server|egrep -v "(man|doc)"/etc/xinetd.d/tftp/usr/lib/systemd/system/tftp.service/usr/lib/systemd/system/tftp.socket/usr/sbin/in.tftpd/var/lib/tftpboot # tftp 默认文件目录# centos 7 启动systemctl start tftp.socket# centos 6 启动chkconfig tftp onservice xinetd restart 3. CentOS 7 PXE1234567891011121314151617181920212223242526272829303132# 1. 配置 DHCP 服务，配置见上节# 2. 配置 tftp 服务yum install -y dhcpyum -y install syslinux tftp-server# 2.1 复制内核，开机启动的所需的配置文件mount /dev/cdrom /cdromcp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/cp /cdrom/images/pxelinux/&#123;vmlinuz,initrd.img&#125; /var/lib/tftp/boot/cp /usr/share/syslinux/&#123;chain.c32,mboot.c32,menu.c32,memdisk&#125; /var/lib/tftpboot/# 2.2 配置开机启动菜单mkdir /var/lib/tftpboot/pxelinux.cfg/vim /var/lib/tftpboot/pxelinux.cfg/defaultdefault menu.c32 prompt 5 timeout 30 MENU TITLE CentOS 7 PXE Menu LABEL linux MENU LABEL Install CentOS 7 x86_64 KERNEL vmlinuz APPEND initrd=initrd.img inst.repo=http://172.16.0.2/centos ks=http://172.16.0.2/ks.cfg # 3. 准备 yum 仓库yum install httpdmount -B /cdrom /var/www/html/centos# 4. 准备 kickstart 文件vim /var/www/html/ks.cfg# ks 文件内需要通过 url --url="http://172.16.0.2/centos" 指明 yum 源 4. CentOS 6 PXE12345678910111213141516# 2.1 复制内核，开机启动的所需的配置文件yum -y install syslinux tftp-servercp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/cp /media/cdrom/images/pxelinux/&#123;vmlinuz,initrd.img&#125; /var/lib/tftp/boot/cp /media/cdrom/isolinux/&#123;boot.msg,vesamenu.c32,splash.png&#125; /var/lib/tftp/boot/# 2.2 配置开机启动菜单mkdir /var/lib/tftpboot/pxelinux.cfg/cp /media/cdrom/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/defaultvim /var/lib/tftpboot/pxelinux.cfg/default # 添加label autoinst menu label ^Auto menu default kernel vmlinuz append initrd=initrd.img ks=http://172.16.0.2/ks.cfg]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26 Trie 树]]></title>
    <url>%2F2018%2F11%2F02%2Falog%2Ftrie%2F</url>
    <content type="text"><![CDATA[一组字符串的快速匹配]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25 字符串匹配之 BM 算法]]></title>
    <url>%2F2018%2F11%2F01%2Falog%2Fstr_match2%2F</url>
    <content type="text"><![CDATA[最优匹配的 BM 算法 1. BM 算法本节我们继续介绍另一个高效的字符串匹配算法 BM(Boyer-Moore)。BM 与 KMP 优化思路类似，都是希望尽可能增加发生不匹配时，模式串后移的位数来提高字符串的匹配效率。BM 要想达到更高的匹配效率，必需利用更多的已知信息。 这里依旧推荐阮一峰老师有关 BM算法的博客。因为阮一峰老师讲的已经不能在通俗易懂，这里我就简单总结一下 BM 算法所使用的匹配规则。示例采用博客中的示例，即在”HERE IS A SIMPLE EXAMPLE”，中搜索 “EXAMPLE”。 1.1 坏字符规则 开始匹配时，主串与模式串头部对齐，从尾部开始比较。此时”S”与”E”不匹配。我们称”S”为”坏字符”（bad character），即不匹配的字符。 利用坏字符以及坏字符是否出现在模式串中，BR 算法使用的第一个移位规则被称为坏字符规则: 后移位数 = 坏字符的位置 - 搜索词中的上一次出现位置。如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。道理很显而易见，如果出现坏字符，我们就直接把模式串移动到能跟坏字符匹配的位置上来。 示例中”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位 1.2 好后缀规则借鉴 KMP 算法，利用已经匹配的字符串和已匹配部分是否出现在模式串中，BR 算法使用的第二个移位规则被称为 好后缀规则:后移位数 = 好后缀的位置 - 搜索词中的上一次出现位置 “好后缀”的位置以最后一个字符为准。假定”ABCDEF”的”EF”是好后缀，则它的位置以”F”为准，即5（从0开始计算）。 如果”好后缀”在搜索词中只出现一次，则它的上一次出现位置为 -1。比如，”EF”在”ABCDEF”之中只出现一次，则它的上一次出现位置为-1（即未出现）。 如果”好后缀”有多个，则除了最长的那个”好后缀”，其他”好后缀”的上一次出现位置必须在头部。比如，假定”BABCDAB”的”好后缀”是”DAB”、”AB”、”B”，请问这时”好后缀”的上一次出现位置是什么？回答是，此时采用的好后缀是”B”，它的上一次出现位置是头部，即第0位 道理也很显而易见，如果已经匹配的部分多次出现在模式串，当发生不匹配时，就直接把模式串移动到上一次匹配的位置上。显然 BM 与KMP 不同，BM 不要求后缀匹配的部分必需是模式串的前缀。 “MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。此时，所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”还出现在头部，所以后移 6 - 0 = 6位。 1.3 移位选择Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。更巧妙的是，这两个规则的移动位数，只与模式串有关，与主串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。 2. 实现显然 BR 算法的核心是要先生成《坏字符规则表》和《好后缀规则表》，然后利用这两个规则表进行字符串匹配。 2.1 坏字符规则表2.2 好后缀规则表2.3 字符串匹配参考: 王争老师专栏-数据结构与算法之美 阮一峰-Boyer-Moore算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.1 dhcp服务简介]]></title>
    <url>%2F2018%2F11%2F01%2Flinux_mt%2F32-ansible%2Fdhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[dhcp服务简介 当集群内的主机达到一定规模时，我们就需要由手动运维转向自动化运维，以提高我们运维的效率，同时也是为减少我们平均故障修复时间。自动化运维的最新技术是docker，而更加传统的方法则是以 ansible 为代表的配置系统。配置系统的基础是标准化，我们需要为我们的主机配置同样的操作系统，并为相同服务集群内的主机提供相同的配置文件。 不考虑虚拟技术，我们的自动化运维工具可以如下几个层面: BootStraping: 用于引导安装操作系统的，os isntallation，常用工具就是 pxe，cobbler Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理， 常用工具包括 ansible，puppet,saltstack Command &amp; Control: 批量运行程序，常用工具包括 ansible 本章的内容主要包括两个部分 自动化安装: 基于 PXE 自动化安装系统 配置系统: 基于 ansible 的配置系统 1. DHCP 简介DHCP(Dynamic Host Configuration Protocol) 全称是动态主机配置协议，主要用于为主机配置IP 地址。将一台主机接入互联网时，我们需要为其配置 IP/Netmask,Gateway,DNS Server等等网络参数。我们可以手动配置，也可以借助于 DHCP 协议实现动态分配。dhcp 的前身是 bootp 引导协议，出现于无盘工作站，这种类型的机器没有硬盘，所以操作系统不会安装在本地。此时需要借助网卡的特定功能，它能在开机时被唤醒，并能作为 bootp 协议客户端去请求服务端去获取地址，并加载属于自己的操作系统文件。第一次获取地址时是动态，之后获取的地址则是固定的，因为要实现客户端操作系统与 IP 地址绑定。 1.1 工作过程dhcp 可以理解成引入租约概念的 bootp 协议，能在主机开机时自动分配地址，并在主机关机时收回临时分配的 IP 地址并在分配，同时也保留了 bootp 保留地址的功能。 dhcp 在动态分配地址的过程中，首先在局域网中有一台 dhcp 服务，其维护着一组可用地址列表(地址池)，也包含要为其他主机配置的网关，DNS 服务器等等。某主机开机之后如果其配置了通过 DHCP 动态获取地址，其将发送一个 RARP 的广播报文 arp: address resolving Protocol，IP -&gt; MAC rarp: reverse arp, MAC -&gt; IP 服务器收到，主机的 Rarp 请求之后，就会为其提供一个地址，整个过程如下所示: dhcp 提供的 IP 地址时存在续租期限的，一般主机要在租约期限到一半时进行续租，此时 Client: 向服务器发送一个 dhcp request Server: 如果同意续租则回复 dhcp ack，不同意在回复 dhcp nak 服务器端不允许续租的原因可能是因为管理员更改了可用的地址池，客户端的IP 地址已经不可用。如果不能续租，此时客户端要重新进行广播获取 IP 地址。 如果客户端在续租时服务器端没有响应，客户端会在剩余时间过去一半的时候再次发起续租直至到达一个足够小的时间，此时将认定服务器不可用，客户端将重新广播获取 IP 地址。 需要注意的是开机获取 IP 地址是广播的，续租则是单播的。 1.2 dhcp 中继服务dhcp 服务不能穿越网关(路由器)，所以要为不同物理网络中的主机分配地址时，需要借助于 dhcp 的中继服务。中继的过程如下 dhcp 中继服务用的很少，了解即可。 1.3 dhcp 作用域dhcp 每一个可分配的地址范围称为一个作用域，不同的作用域可以为不同的网络分配地址，还可以定义超级作用域。 dhcp 在分配地址时，还可以告诉客户端一个网络文件服务器地址，并告诉其到这个文件服务器上请求什么文件，这就是通过网络引导系统的基础。 2. dhcp 服务Linux DHCP协议的实现程序 dhcp dnsmasq: 同时实现了dns 和dhcp 服务，用于嵌入式环境中 2.1 程序组成12345678910111213141516171819# rpm -ql dhcp|egrep -v &quot;(share|man)&quot;/etc/NetworkManager/etc/NetworkManager/dispatcher.d/etc/NetworkManager/dispatcher.d/12-dhcpd/etc/dhcp/dhcpd.conf # ipv4 的配置文件/etc/dhcp/dhcpd6.conf # ipv6 地址分配相关的配置文件/etc/dhcp/scripts/etc/dhcp/scripts/README.scripts/etc/openldap/schema/dhcp.schema/etc/sysconfig/dhcpd/usr/bin/omshell/usr/lib/systemd/system/dhcpd.service # ipv4 unit file/usr/lib/systemd/system/dhcpd6.service # ipv6 unit file/usr/lib/systemd/system/dhcrelay.service/usr/sbin/dhcpd # dhcp 服务的主程序/usr/sbin/dhcrelay # dhcp 中继服务的主程序/var/lib/dhcpd/var/lib/dhcpd/dhcpd.leases # 已经分配的的 IP 地址的相关信息/var/lib/dhcpd/dhcpd6.leases dhcp 的服务器端监听在 udp 的 67 号端口，dhcp 的客户端则监听在 68/udp，因为dhcp 协议的客户端与服务器端随时需要相互通信，所以其客户端也必须作为一个守护进程监听在特定端口上。 2.2 服务配置dhcp 的 rpm 包提供了一个dhcp 配置的参考文件 /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example，可复制直接使用 1234567891011121314151617181920212223242526# dhcpd.conf## Sample configuration file for ISC dhcpd## option definitions common to all supported networks...option domain-name &quot;tao.com&quot;; # 搜索域option domain-name-servers 172.16.0.1; # DNS 服务器地址，可指定多个，最多三个，逗号分隔default-lease-time 600; # 默认租约期限max-lease-time 7200; # 最大租约期限log-facility local7;subnet 172.16.0.0 netmask 255.255.255.0 &#123; # subnet 定义一个作用域即一个子网 range 172.16.0.3 172.16.0.10; # 可分配的ip 地址池 option broadcast-address 172.16.0.255; # 广播地址 option routers 172.16.0.1; # 默认网关 filename &quot;pxelinux.0&quot;; # 指明引导文件名称 next-server 172.16.0.2; # 提供引导文件的服务器IP地址；tftp server&#125;host fantasia &#123; # 为特定主机始终分配固定的 IP 地址 hardware ethernet 08:00:07:26:c0:a5; # 主机网卡的 MAC 地址 fixed-address 172.16.100.6; # 为其分配的固定 IP，不能在地址池内&#125; dhcp option 定义的参数可位于子域中，也可以位于全局配置中，子域中的配置优先级更高。 2.3 dhclientdhclient options 作用: dhcp 客户端程序，可手动发起 dhcp 请求 选项: -d: 将 dhclient 工作于前台，显示 dhcp 的工作过程 2.4 已分配地址123456789101112cat /var/lib/dhcpd/dhcpd.leases# The format of this file is documented in the dhcpd.leases(5) manual page.# This lease file was written by isc-dhcp-4.2.5lease 172.16.0.3 &#123; starts 2 2018/09/25 09:34:08; ends 2 2018/09/25 09:44:08; tstp 2 2018/09/25 09:44:08; cltt 2 2018/09/25 09:34:08; binding state free; hardware ethernet 08:00:27:f4:d9:52;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>自动化运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24 字符串匹配之 KMP 算法]]></title>
    <url>%2F2018%2F10%2F31%2Falog%2Fstr_match3%2F</url>
    <content type="text"><![CDATA[优雅的的 KMP 算法 1. KMP 算法BM（Boyer-Moore）和 KMP(Knuth-Morris-Pratt) 都是非常高效的字符串匹配算法。BM 比 KMP 更高效，有实验统计 BM 的性能 是 KMP 3-4 倍。但是他们都非常复杂难懂。除了专栏，我也非常推荐你看一看阮一峰老师有关 BM 和 KMP 算法的介绍。因为 BM 算法利用到了KMP的算法思想，本节我们就先来介绍 KMP 的实现。 1.1 优化思路KMP 算法基于这样一个实现思路: 如下图所示，对于字符串匹配过程中已经匹配的部分，我们是已知的；利用这个已知的信息，我们可以把模式串往后移动更多位，而不是 BR 算法中的一位。而最终移动的位数取决于已匹配部分的&quot;前缀&quot;和&quot;后缀&quot;的最长的共有元素的长度，我们将这个最长的公共子串称为最长可匹配(前缀/后缀)子串 在上面的图例中，已匹配部分是 ABCDAB，前后缀最长匹配的元素是 AB，因此前缀 AB就可以直接来到后缀AB的位置，直接向后移动 4 位继续匹配，如下图所示。 字符串已匹配部分永远是模式串的前缀子串，因此最长可匹配(前缀/后缀)子串我们可以提前计算出来，这个就是 KMP 中的 部分匹配表。因此，整个 KMP 的计算过程就分成了两步: 计算部分匹配表 根据部分匹配表计算每次不匹配时，模式串的移动位数，进行字符串匹配 1.2 部分匹配表部分匹配表，被称为失效函数，又称为 next 数组。在计算 next 数组之前，首先我们需要明确两个概念: “前缀”和”后缀”: “前缀”指除了最后一个字符以外，一个字符串的全部头部组合 “后缀”指除了第一个字符以外，一个字符串的全部尾部组合 12345678以&quot;ABCDAB&quot;为例0. &quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0；1. &quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0；2. &quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0；3. &quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0；4. &quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1；5. &quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2；6. &quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。 即”ABCDAB” 的 next 数组为 [0, 0, 0, 0, 1, 2, 0]。其中 next 数组的下标对应每个前缀子串结尾字符的下标 next 数组的值则是最长可匹配子串的长度 1.3 KMP 复杂度分析KMP 的空间复杂度是 O(m)，时间复杂度为 O(m+n)。分析过程在我们讲解完 KMP 的实现之后再来讲解。 2. KMP 算法实现2.1 计算部分匹配表部分匹配表的计算非常巧妙，下面是代码： 123456789101112131415def kmp_next(P): m = len(P) fail = [0] * m j = 1 # 按照下标从小到大的子串 k = 0 # 上一个子串最长可匹配子串的长度 while j &lt; m: if P[j] == P[k]: fail[j] = k + 1 j += 1 k += 1 elif k &gt; 0: k = fail[k - 1] else: j += 1 return fail 我们以”ABCDAB”为例来讲解计算过程，大家需要牢记的是P[j] 表示当前子串的最后一个字符，P[k] 表示上一个子串的最长可匹配子串的下一个字符，此时分为三种情况: P[j] == P[k]: 对应ABCDAB，前一个子串是ABCDA，最长可匹配子串是 A，此时P[5]==P[1]==B，即AB=AB,所以 ABCDAB的最长可匹配子串长度就是 2 P[j] != P[k] and k &gt; 0: 对应ABCDABD，P[6]!=P[2]，即D!=C，此时可以确定的是ABCDABD的最长可匹配子串，只能从ABD进行匹配，进而问题转换为已知AB的最长可匹配子串，求ABD的最长可匹配子串问题。 P[j] != P[k] and k == 0: 显然此时就没有任何可匹配到的子串。 这个计算过程很巧妙，不多看几次很难明白。 在next 的计算过程中，使用了一个额外的数组，因此这一部份的空间复杂度是 O(m)。在 while 循环中 j 执行的次数一定不会超过 m，而 k 变量无论是增加累计的量，还是减少累计的量都不会超过 m，因此这一部分的时间复杂度为 O(m)。 2.2 KMP 字符串匹配过程字符串匹配的过程中，最重要的一步是确定不匹配时，后移的位数，代码如下: 12345678910111213141516def kmp_match(T, P): fail = kmp_next(P) n, m = len(T), len(P) k = 0 j = 0 while j &lt; n: if T[j] == P[k]: if k == m - 1: return j - (m - 1) k += 1 j += 1 elif k &gt; 0: k = fail[k - 1] # 后移表示为 k 索引的变化 else: j += 1 return -1 整个匹配过程中，j 变量的执行次数不会超过 n，而变量 k，无论是增加的累计量还是减少的累计量都不会超过 n，因此这一部分的时间复杂度不会超过 O(n)。因此总的时间复杂度不会超过O(m+n)。 参考: 王争老师专栏-数据结构与算法之美 阮一峰-KMP算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23 字符串匹配之 BF & RK 算法]]></title>
    <url>%2F2018%2F10%2F30%2Falog%2Fstr_match1%2F</url>
    <content type="text"><![CDATA[粗暴匹配的 BF 与 RK 算法 1. 特性从本节开始我们将学习字符串匹配算法。字符串匹配算法有很多，大体可以分成两类: 单模式串匹配算法: 一个串跟一个串进行匹配，包括BF，RK，KMP，BM 算法 多字符串匹配算法: 一个串中同时查找多个串，包括 Trie 树和 AC 自动机 本节我们先来学习“最简单粗暴的” BF 和 RK 算法。为了便于描述，对于在字符串A中查找 B，我们将 A 称为主串，B 称为模式串，n=len(A), m=len(B)。 1.1 BF 算法BF(Brute Force) 暴力匹配算法，采用的就是我们最容易理解的穷举法。从主串的第一位开始检查主串中所有长度为 m 的子串看是否与模式串相等。主串中有(n-m+1)个长度为 m 的子串，因此总共需要比较(n-m+1)*m次 BF 算法的时间复杂度很高，为 O(m*n)，但却是一个比较常用的字符串匹配算法，而原因有两个: 大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。 算法简单，实现起来不容易出错 1.2 RK 算法RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。RK 算法可以理解为引入了哈希算法的 BF。 RK 算法希望通过计算字符串的哈希值，并通过比较哈希值，而不是比较字符串，来缩小BF算法中主串的子串与模式串的比较时间。要想达到优化的目的，我们必需使得(字符串哈希+哈希值比较的时间) &lt; (m 次字符比较的时间)。因为哈希值是整数，单次整数的比较时间可以忽略不计。但是字符串哈希值的计算也需要遍历每个字符，因此想要优化，必需精心设计此处的哈希函数。 为了减少字串哈希值的计算量，在计算第 i 个字串的哈希值时，需要能用到已经计算的第 i-1 个字串的哈希值，并且平衡好计算过程中空间占用和哈希冲突的概率。因为 RK 算法并不常用，所以这里我不再过多讲述，有兴趣的同学可以自己查看专栏的介绍。 RK 算法的时间复杂度取决于哈希函数，理想情况下，RK 算法的时间复杂度是 O(n)，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，时间复杂度就退化为 O(n*m)。 2. 实现2.1 BF 算法123456789101112131415def find_brute(T, P): """ :param T: 主串 :param P: 模式串 :return: """ n, m = len(T), len(P) for i in range(n - m + 1): j = 0 while j &lt; m and T[i + j] == P[j]: j += 1 if j == m: return i return -1 3. 应用今天讲的一维字符串匹配可以应用到二维空间中。即如下图所示，在一个二维主串中搜索另一个二维模式串。 下面是代码实现:1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22 堆的应用]]></title>
    <url>%2F2018%2F10%2F29%2Falog%2Fheap_use%2F</url>
    <content type="text"><![CDATA[动态 topK 1. 堆的应用2. 实现2.1 合并小文件2.2 高性能定时器2.3 动态 topK2.4 动态求中位数参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 堆]]></title>
    <url>%2F2018%2F10%2F28%2Falog%2Fheap%2F</url>
    <content type="text"><![CDATA[能找到”最好学生”的堆 1. 特性堆是一种特殊的二叉树，它满足如下两个属性: 堆是一完全二叉树 堆中每个节点的值都必需大于等于(或小于等于)其子树中每个节点的值，下称为 Heap-Order 完全二叉树被定义为除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。所以完全二叉树具有如下一些特性: 非常适合使用数组进行存储，不会出现空间浪费 如果下标从 1 开始，下标为 i 的节点的左右子节点的下标是 2*i，2*i+1； 对于一个有 n 个元素的完全二叉树，树的高度为 logn 为了维护堆的Heap-Order，当我们更改堆中的元素时，我们需要在堆中上下交换堆的元素，额外交换的次数不会超过树的高度即 logn，所以堆的更新操作的时间复杂度为 O(logn)。 1.1 支持的操作堆支持以下一些常用操作: 添加一个元素: 将元素添加到数组的末尾，并对其从下往上的堆化，时间复杂度为 logn 删除堆顶元素: 删除堆顶元素，并用数组末尾元素填充堆顶，对新的堆顶元素从上往下的堆化，时间复杂度为 logn 构建堆: 自底向上的构建堆，时间复杂度为O(n) 堆排序: 包括建堆和排序，排序的时间复杂度为O(nlogn) 1.2 堆排序与快速排序堆排序与快速排序都是原地排序算法，排序的平均时间复杂度都是O(nlogn)，甚至堆排序比快排更加稳定。但是快排的性能还是比堆排序要好，原因有两个: 堆排序数据访问的方式没有快排友好。快排中数据是顺序访问的，但是堆排序是按照指数跳越访问的，对 CPU 缓存不友好 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。 2. 实现2.1 小堆的实现我们选择小堆作为堆实现的示例，大堆的实现类似。对于堆而言最核心的就是从下往上和从上往下的堆化操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132class PriorityQueueBase(object): class _Item(object): __slots__ = '_key', '_value' def __init__(self, key, value): self._key = key self._value = value def __gt__(self, other): return self._key &gt; other._key def __lt__(self, other): return self._key &lt; other._key def __eq__(self, other): return self._key == other._keyclass HeapPriorityQueue(PriorityQueueBase): def __init__(self, content=()): """ :return: 构建堆 """ self._data = [self._Item(k,v) for k, v in content] if self._data: self._heap() def _heap(self): """ """ i = self._parent(len(self._data) - 1) while i &gt;= 0: self._downheap(i) i -= 1 def _parent(self, i): """ :param i: :return: 父节点索引 """ return (i - 1) // 2 def _left(self, i): """ :param i: :return: 左子节点索引 """ return i * 2 + 1 def _right(self, i): """ :param i: :return: 右子节点索引 """ return i * 2 + 2 def has_left(self, i): return self._left(i) &lt; len(self._data) def has_right(self, i): return self._right(i) &lt; len(self._data) def _swap(self, i, j): """ :return: 数据交换 """ self._data[i], self._data[i] = self._data[j], self._data[i] def _upheap(self, i): """ :param i: :return: 从下往上堆化 """ parent = self._parent(i) while self._data[parent] &gt; self._data[i] and i &gt; 0: self._swap(parent, i) i = parent parent = self._parent(parent) def _downheap(self, i): """ :param i: :return: 从上往下堆化 """ while self.has_left(i): small_child = self._left(i) if self.has_right(i): right = self._right(i) if self._data[small_child] &gt; self._data[right]: small_child = right if self._data[i] &gt; self._data[small_child]: self._swap(i, small_child) i = small_child else: break def __len__(self): return len(self._data) def is_empty(self): return len(self) == 0 def add(self, key, value): """ :param key: :param value: :return: 向堆中添加元素 """ self._data.append(self._Item(key, value)) self._upheap(len(self._data) - 1) def min(self): """ :return: 获取堆顶元素，但不删除 """ if not self.is_empty(): item = self._data[0] return item._key, item._value raise ValueError('Priority Queue is empty') def remove_min(self): """ :return: 获取并删除堆顶元素 """ if self.is_empty(): ValueError('Priority Queue is empty') item = self._data[0] self._data[0] = self._data.pop() self._downheap(0) return item._key, item._value 2.2 堆的原排序堆的原排序排序包括两个过程: 建堆+排序。建堆就是上面 _heap 方法展示的过程，通过由底向上构建堆，我们可以在 O(n) 的时间复杂度内实现堆构建。 排序时，我们将堆顶元素与数组最后的元素交换，然后对前 n-1 个元素组成的堆堆化，然后再将堆顶元素与数组倒数第二个元素交换，以此类推，当堆中只剩下一个元素时排序即完成。 很可惜的是，我们上面的小堆实现无法实现堆的原地排序，因为我们无法控制堆中的元素个数，以达到缩减堆范围的目的。但是实现起来也很简单，通过添加额外的可控的计数器作为堆元素个数的记录，而不是直接使用 len(self._data) 我们就可以很容易实现。 2.2 可删除和修改任意位置的堆最后我们介绍一种可更新和删除任意位置的堆。我们使用一个叫作定位器 Locator 对象作为堆中的元素，Locator记录了元素在堆中数组的索引，在执行更新和删除操作时，将Locator作为参数传递给函数，就可以直接定位元素位置，并对其执行更新操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class AdaptHeapPriorityQueue(HeapPriorityQueue): class Locator(HeapPriorityQueue._Item): __slots__ = '_index' def __init__(self, key, value, index): super(AdaptHeapPriorityQueue.Locator, self).__init__(key, value) self._index = index def __init__(self): super(AdaptHeapPriorityQueue, self).__init__() def add(self, key, value): token = self.Locator(key, value, len(self._data)) self._data.append(token) self._upheap(len(self._data) - 1) return token def _swap(self, i, j): super(AdaptHeapPriorityQueue, self)._swap(i, j) self._data[i]._index = i self._data[j]._index = j def _bubble(self, j): if j &gt; 0 and self._data[j] &lt; self._data[self._parent(j)]: self._upheap(j) else: self._downheap(j) def update(self, loc, key, value): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') loc._key = key loc._value = value self._bubble(j) def remove(self, loc): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') if j == len(self) - 1: self._data.pop() else: self._data[j] = self._data.pop() self._bubble(j) return loc._key, loc._value 3 算法堆有众多应用，限于篇幅，我们在接下来的一节来专门讲解。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20 递归树]]></title>
    <url>%2F2018%2F10%2F27%2Falog%2Frecursion_tree%2F</url>
    <content type="text"><![CDATA[利用树计算递归函数的时间复杂度 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19 红黑二叉树]]></title>
    <url>%2F2018%2F10%2F26%2Falog%2Fred_black_tree%2F</url>
    <content type="text"><![CDATA[搞不懂的”红黑数”…. 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18 二叉查找树与完全二叉树]]></title>
    <url>%2F2018%2F10%2F25%2Falog%2Fbinary_tree%2F</url>
    <content type="text"><![CDATA[有散列表了，为什么还要”一颗树” 1. 特性2. 实现2.1 二叉搜索树我们实现的二叉搜索树将支持: 标准映射操作: __setitem__ __getitem__ __delitem__ 有序映射操作: find_lt find_range 基于位置操作 after(p) before(p) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244from collections import MutableMappingfrom linked_tree import LinkedBinaryTreeclass MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._keyclass TreeMap(LinkedBinaryTree, MapBase): class Position(LinkedBinaryTree.Position): def key(self): return self.element()._key def value(self): return self.element()._value def _subtree_search(self, p, k): """ :param p: :param k: :return: 在子树中搜索值为 k 的节点，未搜索到返回最后搜索路经的最终位置 """ p_value = p.key() if p_value == k: return p elif p_value &gt; k: if self.left(p): return self._subtree_search(self.left(p), k) else: if self.right(p): return self._subtree_search(self.right(p), k) return p def _subtree_first_position(self, p): """ :return: 返回子树迭代时，第一个位置节点 """ walk = p while self.left(walk): walk = self.left(walk) return walk def _subtree_last_position(self, p): """ :param p: :return: 返回子树迭代时，最后一个位置节点 """ walk = p while self.right(walk): walk = self.right(walk) return walk ################# 引导方法 ####################### def first(self): """ :return: 返回树迭代序列的第一个节点 """ return self._subtree_first_position(self.root()) if len(self) &gt; 0 else None def last(self): """ :return: 返回树迭代序列的最后一个节点 """ return self._subtree_last_position(self.root()) if len(self) &gt; 0 else None def before(self, p): """ :param p: :return: 返回迭代序列中位于 p 之前的，最大节点 """ self._validate(p) if self.left(p): return self._subtree_last_position(self.left(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.left(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def after(self, p): """ :param p: :return: 返回迭代序列中位于 p 之后的，最小节点 """ self._validate(p) if self.right(p): self._subtree_first_position(self.right(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.right(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def find_position(self, k): """ :param k: :return: 查找值等于 k 的位置节点 """ if self.is_empty(): return None else: p = self._subtree_search(self.root(), k) # avl 平衡树的钩子函数 self._rebalance_access(p) return p ####################### 有序映射 ###################### def find_min(self): """ :return: 查找树中的最小值 """ if self.is_empty(): return None else: p = self.first() return p.key(), p.value() def find_ge(self, k): """ :param k: :return: 查找大于等于 k 的最小节点 """ p = self.find_position(k) if p and p.key() &lt; k: p = self.after(p) return p.key(), p.value() if p else None, None def find_range(self, start, stop): """ :param start: :param stop: :return: 查找值位于 start &lt;= k &lt; stop 的节点 """ if not self.is_empty(): if start is None: p = self.first() else: p = self.find_position(start) if p and p.key() &lt; start: p = self.after(p) while p and (stop is None or p.key() &lt; stop): yield p.key(), p.value() p = self.after(p) ########################### 增删改查节点操作 ################ def __getitem__(self, item): """ :param item: :return: 查找 item 映射的值 """ if not self.is_empty(): p = self.find_position(item) self._rebalance_access(p) if p.key() == item: return p.value() raise KeyError('Key Error:' + repr(item)) def __setitem__(self, key, value): """ :param key: :param value: :return: 设置键 key 的值为 value """ if self.is_empty(): leaf = self._add_root(self._Item(key, value)) else: p = self.find_position(key) if p.key() == key: p.element()._value = value self._rebalance_access(p) return else: item = self._Item(key, value) if p.key() &lt; key: leaf = self._add_right(p, item) else: leaf = self._add_left(p, item) self._rebalance_insert(leaf) def __iter__(self): """ :return: 产生键的一个迭代 """ p = self.first() while p: yield p.key() p = self.after(p) def delete(self, p): """ :param p: :return: 删除位置节点 p """ self._validate(p) if self.left(p) and self.right(p): r = self._subtree_last_position(self.left(p)) self._replace(p, r.element()) p = r parent = self.parent(p) self._delete(p) self._rebalance_delete(parent) def __delitem__(self, key): """ :param key: :return: 删除键 key """ if not self.is_empty(): p = self._subtree_search(self.root(), key) if p.key() == key: self.delete(p) return self._rebalance_access(p) raise KeyError('Key Error: ' + repr(key)) ################### 平衡二叉树的钩子函数 ############### def _rebalance_delete(self, p): pass def _rebalance_insert(self, p): pass def _rebalance_access(self, p): pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.3 haproxy 访问控制]]></title>
    <url>%2F2018%2F10%2F24%2Flinux_mt%2F31-haproxy%2Fhaproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[haproxy 访问控制 本节我们来 介绍 haproxy 配置的第二部分，acl 访问控制。 1. aclacl 能分类请求和响应报文，进而根据分类结果作出转发决策和访问控制。 1.1 acl 使用acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] 作用: 根据设置的条件分类请求和响应报文 参数: &lt;aclname&gt;: 作用: acl 的名称标识，以便在后续的访问控制和转发中进行引用 命名: 可用字符包括大小写子母，数字 -，_，.， :，大小写敏感的 说明: 多个 acl 可以使用同一个名字，彼此之间属于 OR 关系 &lt;criterion&gt;: 匹配的标准，表示要检查什么内容 [operator]: 匹配操作，比如等于，小于，或正则表达式匹配 &lt;value&gt;: 标准匹配的目标值 [flags]: 比较控制标识 过程: acl 的匹配过程就是把&lt;criterion&gt;指定的匹配标准和 &lt;value&gt;指定的值基于[operator]指定的操作符作比较操作，如果符合条件则为真，否则为假 valuevalue 值可以是以下类型: boolean integer or integer range IP address / network string，字符串的比较分为如下多种类型 exact: criterion表示的值 与 value 完全匹配 substring: value 是criterion表示值的子串 suffix: value 是criterion表示值的后缀 prefix: value 是criterion表示值的前串 subdir: value 是criterion表示路经中的子路经 domain: value 是criterion表示域名的的子域 regular expression hex block flagsflags 有如下几个选项 -i : 比较时忽略大小写. -m : 使用一个特殊的模式匹配方法，很少用到 -n : 禁止 DNS 反向解析 -u : 禁止两个 acl 使用相同的名称 -- : flag的结束符标记，强制结束 flag operator比较操作有如下几种类型 匹配整数值：eq、ge、gt、le、lt 匹配字符串： exact match (-m str) : 精确匹配 substring match (-m sub) : 字串匹配 prefix match (-m beg) : 前缀匹配 suffix match (-m end) : 后缀匹配 subdir match (-m dir) : 子路经匹配，即是否是/分隔的子串 domain match (-m dom) : 域名匹配，即是否是.分隔的子串 acl作为条件时的逻辑关系 AND: 默认多个条件使用空格分隔即表示逻辑与 OR: 使用 or 或 || 表示逻辑与 Not: 使用 ! 表示取反 123if invalid_src invalid_portif invalid_src || invalid_portif ! invalid_src invalid_port criterioncriterion 用于指定匹配请求报文或响应报文的哪些内容 匹配传输层和网络层报文中的内容 dst: 目标 ip dst_port: 目标端口 integer src: 源ip src_port: 源端口 eg: acl invalid_src src 172.16.200.2 匹配 url 中的路经，即path 部分(/path;&lt;params&gt;)，string path : exact string match path_beg : prefix match path_dir : subdir match path_dom : domain match path_end : suffix match path_len : length match path_reg : regex match path_sub : substring match 匹配整个 url ，string url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match 匹配请求报文首部中的特定字段，相同报文只会匹配最后一次出现，string hdr([[,]]) : exact string match hdr_beg([[,]]) : prefix match hdr_dir([[,]]) : subdir match hdr_dom([[,]]) : domain match hdr_end([[,]]) : suffix match hdr_len([[,]]) : length match hdr_reg([[,]]) : regex match hdr_sub([[,]]) : substring match 匹配响应状态码 status，integer status 123# 示例：acl bad_curl hdr_sub(User-Agent) -i curlblock if bad_curl 预订义的 ACL123456789101112131415161718192021Pre-defined ACLsACL name Equivalent to UsageFALSE always_false never matchHTTP req_proto_http match if protocol is valid HTTPHTTP_1.0 req_ver 1.0 match HTTP version 1.0HTTP_1.1 req_ver 1.1 match HTTP version 1.1HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-lengthHTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with schemeHTTP_URL_SLASH url_beg / match URL beginning with &quot;/&quot;HTTP_URL_STAR url * match URL equal to &quot;*&quot;LOCALHOST src 127.0.0.1/8 match connection from local hostMETH_CONNECT method CONNECT match HTTP CONNECT methodMETH_GET method GET HEAD match HTTP GET or HEAD methodMETH_HEAD method HEAD match HTTP HEAD methodMETH_OPTIONS method OPTIONS match HTTP OPTIONS methodMETH_POST method POST match HTTP POST methodMETH_TRACE method TRACE match HTTP TRACE methodRDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookieREQ_CONTENT req_len gt 0 match data in the request bufferTRUE always_true always matchWAIT_END wait_end wait for end of content analysis 2. 访问控制指令use_backenduse_backend &lt;backend&gt; [{if | unless} &lt;condition&gt;] 作用: 当符合指定的条件时使用特定的backend； blockblock { if | unless } &lt;condition&gt; 作用: 当符合指定的条件时阻止七层 http 的访问 123acl invalid_src src 172.16.200.2block if invalid_srcerrorfile 403 /etc/fstab http-requesthttp-request { allow | deny } [ { if | unless } &lt;condition&gt; ] 作用: 控制七层的访问请求 tcp-requesttcp-request connection {accept|reject} [{if | unless} &lt;condition&gt;] 作用: 四层的连接请求控制 12345678listen ssh bind :22022 balance leastconn acl invalid_src src 172.16.200.2 tcp-request connection reject if invalid_src mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check backup 3. 基于ACL的动静分离示例需要注意的 haproxy 不能作为 fastcgi 的客户端，因此其后端主机不能是 phpfpm 这种 fastcgi 的应用程序服务器。后端服务器只能是 httpd 或者 nginx，并通过它们来反代 fpm。 123456789101112131415161718192021frontend web *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend appsrvsbackend staticsrvs balance roundrobin server stcsrv1 172.16.100.6:80 checkbackend appsrvs balance roundrobin server app1 172.16.100.7:80 check server app1 172.16.100.7:8080 checklisten stats bind :9091 stats enable stats auth admin:admin stats admin if TRUE 4. 配置HAProxy支持https协议：12345678910111213# 1 支持ssl会话bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE# crt后的证书文件要求PEM格式，且同时包含证书和与之匹配的所有私钥；cat demo.crt demo.key &gt; demo.pem# 2 把80端口的请求重向定443；bind *:80redirect scheme https if !&#123; ssl_fc &#125;# 3 如何向后端传递用户请求的协议和端口http_request set-header X-Forwarded-Port %[dst_port]http_request add-header X-Forwared-Proto https if &#123; ssl_fc &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17 树的存储与遍历]]></title>
    <url>%2F2018%2F10%2F24%2Falog%2Ftree_base%2F</url>
    <content type="text"><![CDATA[如何表示和存储一颗树？ 1. 特性树是我们接触的第一种非线性结构，在树中一个”父”元素可以有一个或多个”子”元素，这种组织关系要比一个序列中两个元素之间简单的”前”,”后”关系更加复杂。 最常用的树是二叉树，即一个父节点最多只有两个子节点，在二叉树的基础上如果我们按照特定的数据分布在树的各个节点组织数据，我们就可以得到诸如二叉搜索树，堆，红黑二叉树等多种具有特定用途的数据结构。 下面就是从树到二叉树的抽象层次结构，本节我们就来介绍如何存储和实现一个树。 123 Tree(树) BinaryTree(二叉树) LinkedTreeArrayBinaryTree LinkedBinaryTree 我们将 Tree，BinaryTree 实现为抽象基类，来定义和抽象普通树和二叉树可执行操作，并以二叉树的链式存储为例来实现一颗二叉树。我们会在堆章节中实现一个基于数组的二叉树。一颗普通的链式存储与基于数组的存储与二叉树类似，我们会简单阐述它们的实现方式。 2. 实现2.1 TreeTree 被实现为 Python 抽象基类，我们使用一种叫作 Position 的位置对象作为对树节点访问的代理。通过 Position 对象提供的辅助功能，我们可以验证待操作节点是否属于被操作的树，并抽象树的节点所表达的”父子”，以及迭代过程中的前后关系。 一个普通树能执行的操作有限，通过包括以下几种: 获取和判断树的根节点 获取节点的子节点树，并借此判断节点是否为叶子节点 获取节点的父节点和所有子节点 获取树的所有节点 获取树中节点个数，判断树是否未空 获取树或节点的高度和深度 树的前序遍历和后序遍历 需要注意的是中序是二叉树特有的遍历方式，一颗普通的树没有中序遍历。下面是一个普通树的抽象实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import abcclass Tree(object): __metaclass__ = abc.ABCMeta class Position(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def element(self): """ :return: 返回存储在 p 中的元素值 """ @abc.abstractmethod def __eq__(self, other): pass @abc.abstractmethod def __ne__(self, other): return not self == other @abc.abstractmethod def root(self): """ :return: 返回树的根节点 """ pass @abc.abstractmethod def parent(self, p): """ :param p: :return: 返回 p 节点的父节点 """ pass @abc.abstractmethod def children(self, p): """ :param p: :return: 返回 p 节点孩子的迭代 """ @abc.abstractmethod def num_children(self, p): """ :param p: :return: 返回节点 p 孩子的个数 """ pass @abc.abstractmethod def __len__(self): pass def is_root(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是根节点 """ return self.root() == p def is_leaf(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是叶子节点 """ return self.num_children(p) == 0 def is_empty(self): """ :return: 判断树是否为空 """ return len(self) == 0 def depth(self, p): """ :param p: :return: 返回 p 节点的深度 """ if self.is_root(p): return 0 else: return 1 + self.depth(self.parent(p)) def height(self, p=None): """ :return: 返回树的高度 """ p = p or self.root() return self._height(p) def _height(self, p): if self.is_leaf(p): return 0 else: return 1 + max(self._height(c) for c in self.children(p)) 2.2 BinaryTree相对于普通树，二叉树是具有如下属性的树: 每个节点至多两个节点 每个节点被命名为左右子节点 在顺序上，同一个节点左孩子优于右孩子 因此二叉树与普通的树相比多了如下3个操作: 获取节点的左右孩子 获取节点的兄弟节点 需要注意的是虽然封装原则表名类的外部行为不需要依赖类的内部实现，而操作的效率却极大的依赖实现方式，所以我们更倾向于在 Tree 类的每个更具体的子类中提供合适的更新操作。因此我们不会在基类中限制树的更新操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class BinaryTree(Tree): __metaclass__ = abc.ABCMeta @abc.abstractmethod def left(self, p): """ :param p: :return: 返回节点的左孩子 """ pass @abc.abstractmethod def right(self, p): """ :param p: :return: 返回节点的右孩子 """ pass def slide(self, p): """ :param p: :return: 返回节点的兄弟节点 """ parent = self.parent(p) if parent is not None: left = self.left(parent) right = self.right(parent) if left == p: return right else: return left def children(self, p): """ :param p: :return: 返回节点的所有子节点 """ left = self.left(p) if p is not None: yield left right = self.right(p) if right is not None: yield right 2.3 LinkedBinaryTreeLinkedBinaryTree 是我们第一个具体实现的链式二叉树。除了必需实现的抽象方法，更新操作外，我们还提供了树的四中遍历方式，用来迭代树中的元素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235from collections import dequefrom tree import BinaryTreeclass LinkedBinaryTree(BinaryTree): class _Node(object): __slots__ = "element", "parent", "left", "right" def __init__(self, element, parent=None, left=None, right=None): self.element = element self.parent = parent self.left = left self.right = right class Position(BinaryTree.Position): def __init__(self, container, node): self._node = node self._container = container def element(self): return self._node.element def __eq__(self, other): return type(other) is type(self) and self._node is other._node def _make_position(self, node): if node is not None: return self.Position(self, node) def _validate(self, p): if not isinstance(p, self.Position): raise TypeError('p must be proer Position type') if p._container is not self: raise ValueError('p not belong to this container') if p._node.parent is p._node: raise ValueError('p will no longer valid') return p._node def __init__(self): self._root = None self._size = 0 def __len__(self): return self._size def root(self): return self._make_position(self._root) def parent(self, p): node = self._validate(p) return self._make_position(node.parent) def left(self, p): node = self._validate(p) return self._make_position(node.left) def right(self, p): node = self._validate(p) return self._make_position(node.right) def num_children(self, p): node = self._validate(p) count = 0 if node.left is not None: count += 1 if node.left is not None: count += 1 return count def _add_root(self, e): """ :param e: :return: 向树添加根节点 """ if self._root is not None: raise ValueError('Root exists') self._root = self._Node(e) self._size += 1 return self._make_position(self._root) def _add_left(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.left is not None: raise ValueError('Left child exists') self._size += 1 left_node = self._Node(e, node) node.left = left_node return self._make_position(left_node) def _add_right(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.right is not None: raise ValueError('right child exists') self._size += 1 right_node = self._Node(e, node) node.right = right_node return self._make_position(right_node) def _replace(self, p, e): """ :param p: :param e: :return: 替换节点的元素值 """ node = self._validate(p) old = node.element node.element = e return old def _delete(self, p): """ :param p: :return: 删除节点， 不能通过移动元素值来删除元素，因为 Position 内部是通过 Node 判断是否相等的 """ node = self._validate(p) if node.left and node.right: raise ValueError('p must leaf') child = node.left if node.left else node.right if child is not None: child.parent = node.parent if node is self._root: self._root = child else: if node is node.parent.left: node.parent.left = child else: node.parent.right = child node.parent = node self._size -= 1 return node.element def attach(self, p, t1, t2): """ :param p: :param t1: :param t2: :return: 在叶子节点附加左右子树 """ node = self._validate(p) if not type(self) is type(t1) is type(t2): raise TypeError() if not self.is_leaf(p): raise ValueError('p must leaf') self._size += len(t1) + len(t2) if not t1.is_empty(): node.left = t1._root t1._root.parent = node t1._size = 0 t1._root = None if not t2.is_empty(): node.right = t2._root t2._root.parent = node t2._size = 0 t2._root = None def positions(self): """ :return: 返回树所有位置的一个迭代 """ return self.preorder() def __iter__(self): for p in self.positions(): yield p.element() def preorder(self): """ :return: 树的前序遍历 """ if not self.is_empty(): for p in self._subtree_preorder(self.root()): yield p def _subtree_preorder(self, p): yield p for i in self.children(p): for other in self._subtree_preorder(i): yield other def postorder(self): """ :return: 后序遍历 """ if not self.is_empty(): for p in self._subtree_postorder(self.root()): yield p def _subtree_postorder(self, p): for i in self.children(p): for other in self._subtree_preorder(i): yield other yield p def breadthfirst(self): """ :return: 广度优先遍历 """ if not self.is_empty(): queue = deque() queue.append(self.root()) while len(queue) &gt; 0: p = queue.popleft() for c in self.children(p): queue.append(c) yield p def inorder(self): """ :return: 中序遍历 """ if not self.is_empty(): return self._subtree_inorder(self.root()) def _subtree_inorder(self, p): left = self.left(p) if left is not None: for other in self._subtree_inorder(left): yield other yield p right = self.right(p) if right is not None: for other in self._subtree_inorder(right): yield other 3.相关算法不考虑特殊的树，仅仅是普通的二叉树就有很多应用，比如计算目录的容量，表达式树。与树相关的递归也是经常考的算法题。但是考虑篇幅的原因，我会在讲解完所有的树之后，用几篇单独的文章来说明与树相关的算法。 3.1 表达式树作为二叉树的第一个例子，我们将使用二叉树来表示算数表达式的结构。我们将定义一个 BinaryTree 的子类 ExpressionTree，在其内部的每个节点必需存储一个操作符，每个叶子节点则必需存储一个数字。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677from expression import infix_to_postfixfrom linked_tree import LinkedBinaryTreeclass ExpressionTree(LinkedBinaryTree): def __init__(self, token, left=None, right=None): super(ExpressionTree, self).__init__() if not isinstance(token, (str, unicode)): raise TypeError('Token must be a string') self._add_root(token) if left or right: if token not in '+-*/': raise ValueError('token must be in +-*/') self.attach(self.root(), left, right) def __str__(self): result = [] if not self.is_empty(): self._parenthesize_recur(self.root(), result) return ''.join(result) def _parenthesize_recur(self, p, result): if self.is_leaf(p): result.append(p.element()) else: result.append('(') self._parenthesize_recur(self.left(p), result) result.append(p.element()) self._parenthesize_recur(self.right(p), result) result.append(')') def evaluate(self): """ :return: 计算表达式树的值 """ return self._evaluate_cur(self.root()) def _evaluate_cur(self, p): if self.is_leaf(p): return float(p.element()) else: left = self._evaluate_cur(self.left(p)) op = p.element() right = self._evaluate_cur(self.right(p)) if op == '+': return left + right elif op == '-': return left - right elif op == '/': return left / right else: return left * right @staticmethod def build_expression_tree(expression): """ :param expression: 表达式默认以空格分隔 :return: 构建表达式树 """ stack = [] postfix = infix_to_postfix(expression) for i in postfix: if i not in '+-*/': stack.append(ExpressionTree(i)) else: right = stack.pop() left = stack.pop() stack.append(ExpressionTree(i, left, right)) t = stack.pop() return tif __name__ == '__main__': expression = '10 / 5 + 1 + ( 100 / 10 )' t = ExpressionTree.build_expression_tree(expression) print t print t.evaluate() 在原书 《数据结构与算法：python语言实现》 中，通过 build_expression_tree 方法构建表达式树时，要求传入的表达式必需是完全括号，即形如 2 * 6 + 2 的表达式必需写成(2 * 6) + 2 才能正确执行。对于一般的算数表达式必需先借助栈，将中缀表达式转换为后缀表达式才能正确构建表达式树，整个过程类似于栈中表达式的求值过程。 3.2 树遍历的应用树的遍历有很多应用，但是这些应用都有一个共通的特点，即他们都是在树的遍历过程的前后附加一些特殊操作。利用面向对象编程中的模板方法模式，我们可以将树的遍历过程定义为一个通用的计算机制，并在迭代的过程中定义好钩子函数。所有类似的应用都可以通过继承并自定义钩子函数的方式快速实现。 对于树的遍历而言，通常有四个变量是我们会利用的信息，我们需要在遍历的前后将它们传递给钩子函数: p: 当前节点的位置对象 d: p 的深度 path: 从根到 p 的路经 result: p 所有子节点的遍历结果 下面是树遍历过程的模板方法的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class EulerTour(object): def __init__(self, tree): self._tree = tree def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): """ :param p: :param d: :param path: :param result: :return: """ self._hook_previsit(p, d, path) path.append(0) result = [] for c in self._tree.children(p): result.append(self._tour(c, d + 1, path)) path[-1] += 1 value = self._hook_postvisit(p, d, path, result) path.pop() return value def _hook_previsit(self, p, d, path): pass def _hook_postvisit(self, p, d, path, result): passclass BinaryEulerTour(BinaryEulerTour): def __init__(self, tree): super(BinaryEulerTour, self).__init__(tree) def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): self._hook_previsit(p, d, path) result = [None, None] if self._tree.left(p): path.append(0) result[0] = self._tour(self._tree.left(p), d + 1, path) path.pop() self._hook_invisit(p, d, path) if self._tree.right(p): path.append(1) result[1] = self._tour(self._tree.right(p), d + 1, path) path.pop() value = self._hook_postvisit(p, d, path, result) return value def _hook_invisit(self, p, d, path): pass 此时如果我们想构建一个表示目录结构的目录树，并计算目录的大小，借助于 EulerTour 可以很容易的实现 123456class DiskSpace(EulerTour): def __init__(self, tree): super(DiskSpace, self).__init__(tree) def _hook_postvisit(self, p, d, path, result): return p.element() + sum(result) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 哈希算法]]></title>
    <url>%2F2018%2F10%2F23%2Falog%2Fhash%2F</url>
    <content type="text"><![CDATA[如何使用使用哈希算法？ 1 特性将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。优秀的哈希算法必需满足如下几点要求: 不能反向推导: 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）； 输入数据敏感: 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同； 散列冲突小: 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小； 执行效率高: 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。 1.1 应用哈希算法的应用非常多，最常见的有如下七种: 安全加密: 不能反向推导 + 散列冲突小，无法通过哈希值逆推出原文 唯一标识: 输入数据敏感 + 散列冲突小，可以通过哈希值的比较间接判断，原文是否相等 数据校验: 输入数据敏感 + 散列冲突小，数据损坏，哈希值就会发生变化 散列函数: 散列函数对哈希算法更加看重的是散列的平均性和哈希算法的执行效率 负载均衡: 利用哈希算法的唯一标识功能，可以将同一客户端 IP 或 session 路由到同一服务器 路由的服务器编号=hash(client_ip or session_id) % len(server_list) 数据分片: 利用哈希算法的唯一标识功能，无需比较就可以将相同的数据归类在一起 分配到的机器编号=hash(keyword) / len(server_list) 分布式存储: 数据分片 + 一致性哈希算法 2. 实现2.1 一致性哈希算法 利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题。下面是 Python 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657'''consistent_hashing.py is a simple demonstration of consistenthashing.'''import bisectimport hashlibclass ConsistentHash: '''ConsistentHash(n,r) creates a consistent hash object for a cluster of size n, using r replicas. It has three attributes. num_machines and num_replics are self-explanatory. hash_tuples is a list of tuples (j,k,hash), where j ranges over machine numbers (0...n-1), k ranges over replicas (0...r-1), and hash is the corresponding hash value, in the range [0,1). The tuples are sorted by increasing hash value. The class has a single instance method, get_machine(key), which returns the number of the machine to which key should be mapped.''' def __init__(self, num_machines=1, num_replicas=1): self.num_machines = num_machines self.num_replicas = num_replicas hash_tuples = [(j, k, my_hash(str(j) + "_" + str(k))) \ for j in range(self.num_machines) \ for k in range(self.num_replicas)] # Sort the hash tuples based on just the hash values hash_tuples.sort(lambda x, y: cmp(x[2], y[2])) self.hash_tuples = hash_tuples def get_machine(self, key): '''Returns the number of the machine which key gets sent to.''' h = my_hash(key) # edge case where we cycle past hash value of 1 and back to 0. if h &gt; self.hash_tuples[-1][2]: return self.hash_tuples[0][0] hash_values = map(lambda x: x[2], self.hash_tuples) index = bisect.bisect_left(hash_values, h) return self.hash_tuples[index][0]def my_hash(key): '''my_hash(key) returns a hash in the range [0,1).''' return (int(hashlib.md5(key).hexdigest(), 16) % 1000000) / 1000000.0def main(): ch = ConsistentHash(7, 3) print "Format:" print "(machine,replica,hash value):" for (j, k, h) in ch.hash_tuples: print "(%s,%s,%s)" % (j, k, h) while True: print "\nPlease enter a key:" key = raw_input() print "\nKey %s maps to hash %s, and so to machine %s" \ % (key, my_hash(key), ch.get_machine(key)) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import bisectimport md5class ConsistentHashRing(object): """Implement a consistent hashing ring.""" def __init__(self, replicas=100): """Create a new ConsistentHashRing. :param replicas: number of replicas. """ self.replicas = replicas self._keys = [] self._nodes = &#123;&#125; def _hash(self, key): """Given a string key, return a hash value.""" return long(md5.md5(key).hexdigest(), 16) def _repl_iterator(self, nodename): """Given a node name, return an iterable of replica hashes.""" return (self._hash("%s:%s" % (nodename, i)) for i in xrange(self.replicas)) def __setitem__(self, nodename, node): """Add a node, given its name. The given nodename is hashed among the number of replicas. """ for hash_ in self._repl_iterator(nodename): if hash_ in self._nodes: raise ValueError("Node name %r is " "already present" % nodename) self._nodes[hash_] = node bisect.insort(self._keys, hash_) def __delitem__(self, nodename): """Remove a node, given its name.""" for hash_ in self._repl_iterator(nodename): # will raise KeyError for nonexistent node name del self._nodes[hash_] index = bisect.bisect_left(self._keys, hash_) del self._keys[index] def __getitem__(self, key): """Return a node, given a key. The node replica with a hash value nearest but not less than that of the given name is returned. If the hash of the given name is greater than the greatest hash, returns the lowest hashed node. """ hash_ = self._hash(key) start = bisect.bisect(self._keys, hash_) if start == len(self._keys): start = 0 return self._nodes[self._keys[start]] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.2 haproxy 配置]]></title>
    <url>%2F2018%2F10%2F23%2Flinux_mt%2F31-haproxy%2Fhaproxy%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[haproxy 配置 本节开始我们来学习 haproxy 的配置。haproxy 有众多的配置选项，我打算将其分为两个部分，第一部分为haproxy 的全局配置，以及常用的代理段配置，第二部分为 haproxy 的访问控制。本节为的一部分，内容包括 global 全局配置 进程及安全管理 性能调整 代理段配置 前端服务配置 后端主机配置 haproxy 状态统计及管理页面配置 自定义错误页 首部处理 日志配置 1. global配置参数1.1 进程及安全管理123456789global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon deamon 作用: 以后端服务的方式运行 haproxy log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]] 作用: 定义全局的syslog服务器；最多可以定义两个； nbproc &lt;number&gt; 作用: 要启动的haproxy的进程数量 默认: 启动一个进程，无需修改 ulimit-n &lt;number&gt; 作用: 每个haproxy进程可打开的最大文件数 默认: haproxy 会自动调整，无需配置 1.2 性能调整:maxconn &lt;number&gt; 作用: 设定每个haproxy进程所能接受的最大并发连接数； maxsslconn &lt;number&gt; 作用: 设定每个haproxy进程所能接受的最大 sll 并发连接数； maxconnrate &lt;number&gt; 作用: 设定每个进程每秒种所能创建的最大连接数量； maxsessrate &lt;number&gt; 作用: 设定每个进程每秒种所能创建的最大会话数量； spread-checks &lt;0..50, in percent&gt; 作用: 设置后端服务器状态检测的速率偏斜，以免同时对所有后端主机进行状态检测，占用太多带宽 2. 代理配置段与 nginx 类似，代理配置段内的参数有受限的应用范围，下面是常用的配置参数 2.1 前端服务配置modemode { tcp|http|health } 作用: 定义haproxy的工作模式； 参数: tcp: 基于layer4实现代理；可代理mysql, pgsql, ssh, ssl等协议； http: 仅当代理的协议为http时使用； health: 工作为健康状态检查的响应模式，当连接请求到达时回应“OK”后即断开连接； 123456listen ssh bind :22022 balance leastconn mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check bindbind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] 作用: 定义前端服务监听的地址和端口 1234listen http_proxy bind :80,:443 # 监听多个端口 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy # 监听本地 sock default_backenddefault_backend &lt;backend&gt; 作用: 设定默认的backend，用于frontend中 maxconnmaxconn &lt;conns&gt;: 作用: 为指定的frontend定义其最大并发连接数；默认为2000； 说明: 如果未设置，会继承 global 中的配置 2.2 后端主机配置balancebalance &lt;algorithm&gt; [ &lt;arguments&gt; ]balance url_param &lt;param&gt; [check_post] 作用: 定义后端服务器组内的服务器调度算法 algorithm: 算法 roundrobin: 动态算法, 支持权重的运行时调整，支持慢启动 每个后端中最多支持4095个server； static-rr: 静态算法，不支持权重的运行时调整及慢启动 后端主机数量无上限； leastconn: 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first: 根据服务器在列表中的位置，自上而下进行调度； 前面服务器的连接数达到上限，新请求才会分配给下一台服务； source: 源地址hash，hash 算法下面的 hash-type 选项指定 hash-type map-based:除权取余法，这种方法不支持权重的运行时调整，也不支持慢启动，但资源耗费少 hash-type consistent: 一致性哈希，支持权重运行时调整，也支持慢启动，但是资源耗费多 uri: 目标地址 hash，对URI的左半部分做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 完整 url: `://:@:/;?#`` 左半部分: /&lt;path&gt;;&lt;params&gt; 整个uri: /&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; url_param: 对用户请求的uri的 &lt;params&gt;中的部分的参数的值作hash计算 hash 算法可由 hash-type 指定，默认是 map-based 通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server hdr(&lt;name&gt;): 对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 没有有效值的会被轮询调度； eg: hdr(Cookie) hash-typehash-type &lt;method&gt; &lt;function&gt; &lt;modifier&gt; 作用: 指定 hash 计算的算法 method: map-based: 除权取余法，哈希数据结构是静态的数组； consistent: 一致性哈希，哈希数据结构是一个树； function: 哈希函数，eg: sdbm, djb2, wt6 default-serverdefault-server [param*] 作用: 为backend中的各server设定默认选项 选项: 同 serve serverserver &lt;name&gt; &lt;address&gt;[:[port]] [param*] 作用: 定义后端主机的各服务器及其选项； name: 服务器在haproxy上的内部名称；出现在日志及警告信息 address: 服务器地址，支持使用主机名； [:[port]]: 端口映射；省略时，表示同bind中绑定的端口； [param*]: 参数 maxconn &lt;maxconn&gt;: 当前server的最大并发连接数； backlog &lt;backlog&gt;: 当前server的连接数达到上限后的后援队列长度； backup: 设定当前server为备用服务器； check: 对当前server做健康状态检测； addr : 检测时使用的IP地址； port : 针对此端口进行检测； inter &lt;delay&gt;: 连续两次检测之间的时间间隔，默认为2000ms; rise &lt;count&gt;: 连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall &lt;count&gt;: 连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意: httpchk，”smtpchk”, “mysql-check”, “pgsql-check” and “ssl-hello-chk” 用于定义应用层检测方法； cookie &lt;value&gt;: 为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled: 标记为不可用； redir &lt;prefix&gt;: 将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight &lt;weight&gt;: 权重，默认为1; cookiecookie &lt;name&gt; options 作用: 启用基于 cookie 的用户绑定 参数: &lt;name&gt; 待操作的 cookie 的键 选项: rewirte: 重写 insert: 插入 prefix: 前缀 nocache: 只对非从缓存中响应的值进行操作 indirect: 如果对应的cookie 键已经存在值，则不修改直接发送给客户端 说明: cookie 的值有 server cookie&lt;value&gt; 配置 123456# 基于cookie的session sticky的实现:backend websrvs cookie WEBSRV insert nocache indirect server srv1 172.16.100.6:80 weight 2 check rise 1 fall 2 maxconn 3000 cookie srv1 server srv2 172.16.100.7:80 weight 1 check rise 1 fall 2 maxconn 3000 cookie srv2 ` 2.3 健康状态检测option httpchkoption httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 作用: 对后端服务器做http协议的健康状态检测,基于http协议的7层健康状态检测机制； 参数: uri: 指定检测的链接 method: 指定检测使用的请求方法 version: 指定发送的 http 的协议版本 1234backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www server apache1 192.168.1.1:443 check port 80 http-check expecthttp-check expect [!] &lt;match&gt; &lt;pattern&gt; 作用: 指定健康状态检测的内容 [!]: 表示取反操作 match: status: 完全匹配响应码 rstatus: 以正则表达式匹配响应码 string: 完全匹配响应内容 rstring: 以正则表达式匹配响应内容 pattern: 字符串或正则表达式，表示 match 指定的选项要匹配的内容 1234567http-check expect status 200http-check expect ! string SQL\ Errorhttp-check expect ! rstatus ^5# check that we have a correct hexadecimal tag before /htmlhttp-check expect rstring &lt;!--tag:[0-9a-f]*&lt;/html&gt; 2.4 统计接口stats enable 作用: 启用统计页；基于默认的参数启用stats page； 默认启用参数: stats uri : /haproxy?stats stats realm : “HAProxy Statistics” stats auth : no authentication stats scope : no restriction stats auth &lt;user&gt;:&lt;passwd&gt; 作用: 认证时的账号和密码，可使用多次； stats realm &lt;realm&gt; 作用: 认证时的realm； `stats uri `` 作用: 自定义stats page uri stats refresh &lt;delay&gt; 作用: 设定自动刷新时间间隔； stats admin { if | unless } &lt;cond&gt; 作用: 启用stats page中的管理功能 stats hide-version 作用: 隐藏页面的有关 haproxy 的版本信息 1234567# 配置示例:listen stats bind :9099 stats enable stats realm HAPorxy\ Stats\ Page stats auth admin:admin stats admin if TRUE 2.5 自定义错误页errorfileerrorfile &lt;code&gt; &lt;file&gt; 作用: 自定义错误响应页，响应页的内容由文件指定 &lt;code&gt;: HTTP 响应码， HAProxy 目前支持自定义 200, 400, 403, 408, 500, 502, 503, and 504 &lt;file&gt;: 响应内容所在的位置 1234errorfile 400 /etc/haproxy/errorfiles/400badreq.httperrorfile 408 /dev/null # workaround Chrome pre-connect bugerrorfile 403 /etc/haproxy/errorfiles/403forbid.httperrorfile 503 /etc/haproxy/errorfiles/503sorry.http errorloc &lt;code&gt; &lt;url&gt;errorloc302 &lt;code&gt; &lt;url&gt;errorloc303 &lt;code&gt; &lt;url&gt; 作用: 自定义错误响应页，错误页的内容由 url 指定 说明: errorloc302/303 会以 302/303 响应码响应客户端而不是原本的响应码 2.6 首部处理option forwardforoption forwardfor [except &lt;network&gt;] [header &lt;name&gt;] [if-none] 作用: 用于向后端主发送真实的客户端IP 在由haproxy发往后端主机的请求报文中添加X-Forwarded-For首部，其值为前端客户端的地址 选项: [except &lt;network&gt;]: 请求报文来自此处指定的网络时不予添加此首部； [header &lt;name&gt; ]: 使用自定义的首部名称，而非X-Forwarded-For [if-none]: 只在不存在 X-Forwarded-For 时才添加此报文首部 reqadd/rspaddreqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 作用: 向发送给后端服务器的请求添加首部字段 rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 作用: 向发送给客户端响应中添加首部字段 eg: rspadd X-Via: HAPorxy reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;]reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 作用: 删除正则表达式匹配到的，发往后端服务器的请求的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: reqidel 表示在进行正则表达式匹配时不区分大小写 rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;]rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 作用: 删除正则表达式匹配到的，发往客户端的的响应的的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: rspidel 表示在进行正则表达式匹配时不区分大小写 12345# remove X-Forwarded-For header and SERVER cookiereqidel ^X-Forwarded-For:.*reqidel ^Cookie:.*SERVER=rspidel ^Server:.* 2.7 日志系统loglog global 作用: 从 global 全局配置段继承日志配置 no log 作用: 不记录日志 log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]] 作用: 自定义日志记录 注意: 一个配置段内，log 日志记录只能使用两次，如果使用log global，并且global 配置了两次log，算作两次 12345# 注意：默认发往本机的日志服务器，配置如下vim /etc/rsyslog.conflocal2.* /var/log/local2.log$ModLoad imudp$UDPServerRun 514 log-formatlog-format &lt;string&gt; 作用: 自定义日志记录格式 capturecapture cookie &lt;name&gt; len &lt;length&gt; 作用: 提取并记录请求和响应的 cookie 中特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 capture request header &lt;name&gt; len &lt;length&gt; 作用: 提取并记录请求首部特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 capture response header &lt;name&gt; len &lt;length&gt; 作用: 提取并记录响应首部特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 123capture request header Host len 15capture request header X-Forwarded-For len 15capture request header Referer len 15 2.8 压缩功能compression algocompression algo &lt;algorithm&gt; 作用：启用http协议的压缩机制，指明压缩算法gzip, deflate； compression typecompression type &lt;mime type&gt; 作用: 指明压缩的MIMI类型； 12compression algo gzipcompression type text/html text/plain 2.9 连接超时时长timeout client &lt;timeout&gt; 作用: 客户端非活动状态的超时时长 timeout server &lt;timeout&gt; 作用: 客户端与服务器端建立连接后，等待服务器端的超时时长， timeout http-keep-alive &lt;timeout&gt; 作用: 持久连接的持久时长； timeout http-request &lt;timeout&gt; 作用: 定义保持连接的超时时长 timeout connect &lt;timeout&gt; 作用: haproxy 连接后端主机的超时时长 timeout client-fin &lt;timeout&gt; 作用: 半关闭状态连接，client端非活动超时时间 timeout server-fin &lt;timeout&gt; 作用: 半关闭状态连接，server端非活动超时时间]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.1 haproxy 入门]]></title>
    <url>%2F2018%2F10%2F22%2Flinux_mt%2F31-haproxy%2Fhaproxy%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[haproxy 入门 本章我们来介绍负载均衡集群的另一种实现 haproxy。与 nginx 类似，haproxy 工作于应用层属于七层代理，但是在其 tcp 模式下也能模拟实现四层代理。本章我们就来学习如何使用 haproxy。在学习配置 haproxy 之前我们先来对其做个简单了解，看看其程序与配置文件结构。 1. haproxy 简介1.1 主站与文档对于 haproxy 介绍和性能优势这里就不多介绍，推荐大家多看看 haproxy 的主页和官方文档，特别是官方文档 主站: http://www.haproxy.org http://www.haproxy.com 文档: http://cbonte.github.io/haproxy-dconv/ 1.2 程序结构haproxy 已经被收录至 yum 的 base 仓库，可直接安装，下面是 rpm 包的程序结构1234567891011121314151617181920$ rpm -ql haproxy|egrep -v &quot;(doc|man)&quot;/etc/haproxy/etc/haproxy/haproxy.cfg # 主配置文件/usr/sbin/haproxy # 主程序/usr/sbin/haproxy-systemd-wrapper/usr/bin/halog # 辅助工具/usr/bin/iprange/usr/lib/systemd/system/haproxy.service # Unit file/etc/sysconfig/haproxy # Unit file 的配置文件 /usr/share/haproxy # 错误页/usr/share/haproxy/400.http/usr/share/haproxy/403.http/usr/share/haproxy/408.http/usr/share/haproxy/500.http/usr/share/haproxy/502.http/usr/share/haproxy/503.http/usr/share/haproxy/504.http/usr/share/haproxy/README/var/lib/haproxy/etc/logrotate.d/haproxy 1.3 配置文件结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#---------------------------------------------------------------------# Global settings#---------------------------------------------------------------------global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------frontend main *:80 default_backend app#---------------------------------------------------------------------# static backend for serving up images, stylesheets and such#---------------------------------------------------------------------backend app balance roundrobin server py 127.0.0.1:8888 check haproxy 的配置分成两大配置段 global：全局配置段，用于定义 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxies：代理配置段，包括四小配置段 defaults：为frontend, listen, backend提供默认配置； fronted：定义前端监听的服务，相当于nginx, server {} backend：定义后端服务器组，相当于nginx, upstream {} listen：后端服务器组与前端服务一一对应时的便捷配置方式，可同时定义前端与后端 1.4 haproxy 简单配置示例下面是两个配置示例，我们会在下一节详细介绍 haproxy 各个重要配置选项。123456789101112frontend web bind *:80 default_backend websrvsbackend websrvs balance roundrobin # 定义调度算法 server srv1 172.16.100.6:80 check server srv2 172.16.100.7:80 check listen http-in # listen 同时定义前后端 bind *:3306 server server1 127.0.0.1:3396 maxconn 32]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 散列表与链表]]></title>
    <url>%2F2018%2F10%2F22%2Falog%2Fhash_list%2F</url>
    <content type="text"><![CDATA[“形影不离”的散列表与链表 1. 特性散列表和链表，经常会被放在一起使用。原因是散列表虽然支持高效的数据插入、删除、查找操作，但是散列后的数据都是无序存储的，无法支持按照某种顺序快速地遍历数据。散列表是动态的数据结构，如果每次按序访问都要拷贝到数组，排序然后在遍历，效率太低了。而支持动态创建的链表刚好能解决散列表的有序遍历问题。 3. 应用3.1 LRU 缓存淘汰算法借助于散列表和链表可以实现时间复杂度降为 O(1)的 LRU 缓存淘汰算法。 12 3.2 Redis 的有序集合Redis 的有序集合就是跳表和散列表的结合，支持按照 key（键值）和score（分值）查找，添加和删除成员对象。12 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 散列表]]></title>
    <url>%2F2018%2F10%2F21%2Falog%2Fhash_map%2F</url>
    <content type="text"><![CDATA[散列表原理 1. 特性散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，其由三个核心部分组成: key: 元素的键 hash func: 散列函数，将键隐射为底层数组的下标 table: 底层的数组 散列表通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，下面是我们要关注的核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 1.1 散列函数散列函数在设计上有三点基本要求: 因为数组下标是从 0 开始的的，所以散列函数计算得到的散列值必需是一个非负整数； 如果 key1 = key2，那 hash(key1) == hash(key2)； 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2) 第三点看起来合情合理，但是要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。因此散列过程中会产生散列冲突。而且数组的存储空间有限，也会加大散列冲突的概率。 1.2 散列冲突常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。 开放寻址法开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。重新探测新的位置有很多方法，常见有线性探测，二次探测和双重散列，我们将其统称为探测函数。散列函数和探测函数一起，确定了元素的一系列可存储位置。 插入过程就是按序探测第一个非空位置并存储 查找过程就是按照相同的探测顺序，逐一比较数组中的元素和要查找的元素直至找到相等元素(找到)或一个空位置(不存在)。 因为数组空闲位置是判断是查找的判定条件，所以不能通过直接将数组元素置空来删除散列表中的元素。我们可以将删除的元素，特殊标记为 deleted。当探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。 散列表的装载因子 = 填入表中的元素个数 / 散列表的长度 装载因子越大，说明空闲位置越少，冲突越小，散列表的性能越好。 链表法 链表法是一种更加常用的散列冲突解决办法，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。 插入时，通过散列函数计算出对应的散列槽位，将其插入到对应链表中，时间复杂度是 O(1)。 查找、删除时，通过散列函数计算出对应的槽，然后遍历链表查找或者删除。时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。 2. 实现散列表的性能与散列函数，散列冲突和装载因子有关，要想实现一个工业级的散列表就要从这三个因素入手。 2.1 散列函数设计散列函数的设计遵循以下几个要点: 散列函数不能太复杂 散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突 实际工作中，还需要综合考虑包括关键字的长度、特点、分布、还有散列表的大小等在内的各个因素 2.2 装载因子控制对于没有频繁插入和删除的静态数据集合来说，因为数据是已知的，我们可以根据数据的特点、分布等，设计出完美的、极少冲突的散列函数。 对于动态数据集，我们可以动态扩缩容: 装载因子过大时，重新申请一个更大的散列表，动态扩容。 装载因子过小时，可以启动动态缩容。如果我们更加在意执行效率，能够容忍多消耗一点内存空间，也可以不缩容 需要注意的是动态扩缩容时，因为散列表的大小发生了变化，数据存储的位置就变了，所以需要通过散列函数重新计算每个数据的存储位置。在散列表的动态扩容中，装载因子阈值的设置非常重要，太小会导致内存浪费严重，太大会导致冲突过多，要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。 2.3 避免低效扩容动态扩容一个 1G 的散列表依旧很慢，为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个到多个数据放入到新散列表。将扩容过程分散到每次的插入操作中。 2.4 冲突解决方法选择开放寻址法开放寻址法中，散列表的数据都存储在数组中，所以开放寻址法的优点与使用数组类似 可以有效地利用 CPU 缓存加快查询速度 序列化起来比较简单。 但是缺点也很明显: 删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据 所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。 使用开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。所以比起链表法更浪费内存空间。当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的 ThreadLocalMap使用开放寻址法解决散列冲突的原因. 链表法链表法利用的是链表这种离散的内存空间，因此 对内存的利用率更高。因为链表结点可以在需要的时候再创建，无需像开放寻址法那样事先申请好 对大装载因子的容忍度更高。对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。 但是缺点也很明显，链表对于存储小的数据会浪费很多空间(指针的存在)，离散的内存分布也无法利用 CPU 的缓存加速。 链表法中的链表可以改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。 所以基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。 2.5 java 的 HashMap我们以 java 中的 HashMap 来说一说如何实现一个工业及的散列表: 初始大小: HashMap 默认的初始大小是 16，这个默认值是可以设置的 装载因子和动态扩容: HashMap 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。 散列冲突解决: HashMap 底层采用链表法，在 JDK1.8 版本中引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表 3. Python 的 dict上面我们介绍了散列表的实现原理，但是实现一个工业及的散列表是在大量数学和实验的基础上实现的。因为我主要用的还是 Python ，因此我就以 Python 中的dict 实现来介绍当前工业级的散列表的最佳实践，并着手实现一个简单的散列表。 3.1 散列函数Python 中的散列函数通常有两个部分组成: 哈希码: 将一个键映射到一个整数 压缩函数: 将哈希码映射到散列表内部数组的索引 这么做的目的是将哈希码的计算与具体的散列表大小相独立，这样就可以为每个对象开发一个通用的哈希码，并且可以用于任意大小的散列表，只有压缩函数与散列表的大小有关。 3.2 哈希码不同对象的哈希码有如下几种实现方式: 对于数值类型的对象，我们可以简单的把用于表示数值 X 的各个位所表示的值作为它的哈希码。如果数值的位数超过哈希码的长度，比如将 64 位浮点数哈希为 32 位的整数，可以对前后 32 求和或做异或处理 对于字符串或元组形式表示的可变长度对象，通常使用多项式哈希和循环移位哈希，这两种方式都会考虑字符串中字符的位置 多项式哈希码的计算方式如下，其中 i 表示字符串中第 i 个字符，a 是非 0 常数。在处理英文字符串时 33，37，39，41 是合适选择值。12 循环移位的 Python 算法如下，在处理英文字符串时 5 位移动能产生最少的散列冲突。 1234567def hash_code(s): mask = (1 &lt;&lt; 32) - 1 h = 0 for c in s: h = (h &lt;&lt; 5 &amp; mask) | (h &gt;&gt; 27) h += ord(c) return h Python 中的哈希码Python 中只有不可变的数据类型可以哈希，以确保一个对象的生命周期中其哈希码不变。对于字符串 Python 使用类似于多项式哈希码的技术，精心设计了字符串的哈希码，没有使用异或和相加。使用相似的基于元组每个元素的哈希码的组合技术计算元组的哈希码。对于 frozenset 对象，元素的顺序是无关的，因此一个自然的选择是用异或值计算单个哈希码而不用任何移位。 用户自定义对象默认是不可哈希的，除非自定义 __hash__ 内置函数，hash() 函数会调用此方法获取对象的哈希码。通过计算组合属性的哈希码作为自定义对象的哈希码是常见方法。 123def __hash__(): return hash(self._red, self._green, self._blue) 一个重要的规则是，__eq__ 与 __hash__ 的实现必需一致，即如果x==y，则 hash(x)==hash(y)。比如 hash(1)==hash(1.0) 3.3 压缩函数一个好的压缩函数应该确保两个不同的哈希码映射到相同索引的可能性为 1/N，工业级别最常用的压缩函数是 MAD(Multiply-Add-Divide)。选择这个压缩函数是为了消除在哈希码集合中的重复模式，并且得到更好的哈希函数。 1234[(ai + b) mod p] mod N- N: 散列表内部数组的大小- p: 比 N 大的素数- a，b 是从区间 [0, p-1] 任意选择的整数，并且 a &gt; 0 3.4 散列冲突处理散列冲突解决方案中的开放寻址法，有多个变种。常见的包括线性探测，二次探测，双哈希策略。Python 中采用的是迭代地探测桶。这种方法下散列表的负载因子可以达到 2/3。12345# 迭代地探测桶A[(h(k) + f(i)) mod N]- h(k): 哈希码- f(i): 基于伪随机数产生器的函数，它提供一个基于原始哈希码位的可重复的但是随机 的，连续的地址探测序列 4. 散列表的简单实现最后，我们介绍散列表的两种实现，一种使用链表法，另一种使用包含线性探测的开放寻址。 4.1 公用基类参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.6 varnish 日志查看]]></title>
    <url>%2F2018%2F10%2F21%2Flinux_mt%2F30-varnish%2Fvarnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[varnish 日志查看 varnish 的日志存放在特定的内存区域中，分为计数器和日志信息两个部分，查看日志需要专门的工具。本节我们来学习这部分命令的使用。 1. varnishstatvarnishstat options 作用: 显示 varnish 缓存的计数器 选项: -1: 一次输出所有统计计数 -f field_list: 列出特定的统计字段，field 支持通配符， ^ 开头表示取反 -l: 列出可供 -f 选择的所有字段 -n varnish_name: 从哪个 varnish 实例获取日志 -V: 显示 varnish 的版本信息 -w delay: 间隔输出，可结合-1, -x , -j 使用 -x: 以 xml 格式输出 -j: 以 json 格式输出 12varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_missvarnishstat -l -f MAIN -f MEMPOOL 2. varnishtopvarnishtop options 作用: 对 varnish 日志排序后输出 选项: [-1]: 运行一次，输出所有日志排序后的结果 [-b]: Only display backend records [-c]: Only display client records [-f]: First field only [-i taglist]: Include tags [-I &lt;[taglist:]:regex&gt;]: Include by regex [-x taglist]: Exclude tags [-X &lt;[taglist:]:regex&gt;]: Exclude by regex [-V]: Version 3. varnishlogvarnishlog options 作用: 显示 varnish 日志 4. varnishncsavarnishncsa 作用: 以类似 httpd combined 格式显示 varnish 日志 5. 日志记录服务varnish 的日志只会记录在内存中，空间不够用时，新的日志就会覆盖老的日志。因此需要定期执行 varnishlog 或 varnishncsa 保存日志。yum 安装已经自动为我们配置了 Unit file，启用下面两个服务之一即可: /usr/lib/systemd/system/varnishlog.service /usr/lib/systemd/system/varnishncsa.service]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 跳表]]></title>
    <url>%2F2018%2F10%2F20%2Falog%2Fskip_list%2F</url>
    <content type="text"><![CDATA[跳表: 链表上的“二分查找” 1. 特性跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。实现上跳表使用空间换时间的思想，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。 1.1 跳表的结构跳表就是在有序链表的基础上添加了多层”索引”。通过每隔几个节点提取一个节点形成上层索引，每层索引的节点个数成等比数列分布，从顶向下的每次查询都会将查询区间“折半”，从而达到 O(logN) 的时间复杂度。每次查询对查询区间的缩减取决于索引构建策略，通过改变索引构建策略，有效平衡执行效率和内存消耗。待会我们会看到更加具体的分析过程。 跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树。Redis 中的有序集合（Sorted Set）就是在跳表的基础上实现的。 1.2 跳表的查找假设我们每隔两个节点构建一层索引，最上层有两个节点，总共有 N 个节点。则第 h 层的节点个数为 N/2^h，包含最底层的链表在内总共有 logN 层。如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。对于每隔两个节点构建的索引 m=3。 原因是，假设我们要查找的数据是 x，在第 k 级索引中，我们遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以我们通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以，我们在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。 所以在跳表中查询任意数据的时间复杂度就是 O(logn)。而整个跳表需要额外添加的节点数为n/2+n/4+n/8…+8+4+2=n-2，所以空间复杂度为 O(n)。 如果我们每三个结点或五个结点，抽一个结点到上级索引。总的索引结点大约就是 n/3+n/9+n/27+…+9+3+1=n/2，而查询时间复杂度的系数就会从 3 变成 4。因此通过改变索引构建策略，有效平衡执行效率和内存消耗。 1.3 跳表的插入跳表的插入有两个要点: 要保证原始链表中数据的有序性 要维护索引与原始链表大小之间的平衡，避免复杂度退化 因此在插入前需要先找到插入位置，然后通过一个随机函数，来决定将这个结点插入到哪几级索引中。整个过程的时间复杂度= O(logn)(查找) + O(1)(链表的插入) 1.4 跳表的删除删除的过程只是在查找的基础上多了链表的删除操作，对于双向链表而言删除的时间复杂度也是 O(logn)。需要注意的是删除的节点也可能出现在索引中，需要一并删除。 1.5 跳表与红黑树跳表和红黑树都是非常高效的动态数据结构，在插入、删除、查找以及迭代输出有序序列上，时间复杂度都是 O(logn)。但是存在以下不同: 按照区间来查找数据，跳表比红黑树更加高效，跳表可以在 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历即可 相对于红黑树跳表更加简单灵活，通过改变索引构建策略，可以有效平衡执行效率和内存消耗 红黑树出现的更早，很多编程语言中的 Map 类型都是通过红黑树实现的。可以直接拿来用，但是跳表并没有一个现成的实现，想要使用必须自己实现。 2. 实现下面是 Python 的跳表实现。 12 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.5 varnish 后端主机配置]]></title>
    <url>%2F2018%2F10%2F20%2Flinux_mt%2F30-varnish%2Fvarnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[varnish 后端主机配置 在讲解完 varnish 的缓存配置之后，我们来看看如何配置后端服务器，包括后端服务器组的定义，调度算法，以及健康状态检测。 1. 后端主机配置1.1 定义后端主机定义后端主机使用 backend 关键字，在定义主机的同时，我们可以设置后端主机的多项属性。 123456789backend BE_NAME &#123; .host = .port = .probe = # 指定健康状态检测方法 .connect_timeout = 0.5s; .first_byte_timeout = 20s; .between_bytes_timeout = 5s; .max_connections = 50;&#125; 1.2 读写分离123456789101112131415161718192021# 定义后端主机backend default &#123; .host = &quot;172.16.100.6&quot;; .port = &quot;80&quot;;&#125;backend appsrv &#123; .host = &quot;172.16.100.7&quot;; .port = &quot;80&quot;;&#125;# 对后端主机进行读写分离sub vcl_recv &#123; if (req.url ~ &quot;(?i)\.php$&quot;) &#123; set req.backend_hint = appsrv; &#125; else &#123; set req.backend_hint = default; &#125; ...&#125; 1.2 定义服务器组定义后端服务器组，并配置调度算法需要导入 varnish 的 Director 模块，使用 import directors； 12345678910111213141516171819202122232425262728293031323334353637# 1. 导入模块import directors; # load the directors# 2. 定义后端主机backend server1 &#123; .host = .port =&#125;backend server2 &#123; .host = .port =&#125;# 3. 服务器组定义，并指定调度算法sub vcl_init &#123; new GROUP_NAME = directors.round_robin(); GROUP_NAME.add_backend(server1); GROUP_NAME.add_backend(server2);&#125;# 4. 使用服务器组sub vcl_recv &#123; # send all traffic to the bar director: set req.backend_hint = GROUP_NAME.backend();&#125;# 5. 基于cookie的session sticky：sub vcl_init &#123; new h = directors.hash(); h.add_backend(one, 1); // backend &apos;one&apos; with weight &apos;1&apos; h.add_backend(two, 1); // backend &apos;two&apos; with weight &apos;1&apos;&#125;sub vcl_recv &#123; // pick a backend based on the cookie header of the client set req.backend_hint = h.backend(req.http.cookie);&#125; 1.3 健康状态检测后端服务器的健康状态检测有两种方式 使用专用 probe 关键词，定义检测方式，可复用 在使用 backend 定义后端主机时通过 .probe 单独指定 probe 配置参数12345678910111213probe PB_NAME &#123; .url ：检测时要请求的URL，默认为”/&quot;; .request ：发出的具体请求； .request = &quot;GET /.healthtest.html HTTP/1.1&quot; &quot;Host: www.magedu.com&quot; &quot;Connection: close&quot; .window ：基于最近的多少次检查来判断其健康状态； .threshold ：最近.window次检查中至有.threshhold定义的次数是成功的； .interval ：检测频度； .timeout ：超时时长； .expected_response ：期望的响应码，默认为200；&#125; 示例12345678910111213141516171819202122232425probe check &#123; .url = &quot;/.healthcheck.html&quot;; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s;&#125;backend default &#123; .host = &quot;10.1.0.68&quot;; .port = &quot;80&quot;; .probe = &#123; .url = &quot;/.healthcheck.html&quot;; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s; &#125;&#125;backend appsrv &#123; .host = &quot;10.1.0.69&quot;; .port = &quot;80&quot;; .probe = check;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.4 varnish缓存策略配置]]></title>
    <url>%2F2018%2F10%2F19%2Flinux_mt%2F30-varnish%2Fvarnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[varnish缓存策略配置 前面我们讲解了 VCL 的语法，并通过示例讲解了一部分 varnish 缓存的配置。本节我们来看看 varnish 内置的缓存策略，然后着重来看看如何对缓存进行修剪。 1. VCL 域默认配置1.1 vcl_recv12345678910111213141516171819202122232425262728# vcl_recv 默认配置sub vcl_recv &#123; if (req.method == &quot;PRI&quot;) &#123; /* We do not support SPDY or HTTP/2.0 */ return (synth(405)); &#125; if (req.method != &quot;GET&quot; &amp;&amp; req.method != &quot;HEAD&quot; &amp;&amp; req.method != &quot;PUT&quot; &amp;&amp; req.method != &quot;POST&quot; &amp;&amp; req.method != &quot;TRACE&quot; &amp;&amp; req.method != &quot;OPTIONS&quot; &amp;&amp; req.method != &quot;DELETE&quot;) &#123; /* Non-RFC2616 or CONNECT which is weird. */ return (pipe); &#125; if (req.method != &quot;GET&quot; &amp;&amp; req.method != &quot;HEAD&quot;) &#123; /* We only deal with GET and HEAD by default */ return (pass); &#125; if (req.http.Authorization || req.http.Cookie) &#123; /* Not cacheable by default */ return (pass); &#125; return (hash); &#125;&#125; 2. 缓存修剪varnish 让缓存过期有多种方式，最常见的是通过 purge, 和ban purge: 是在 varnish 内置监视一个特殊的 PURGE 请求方法，并对请求的资源进行缓存请求 ban: 可以使用类似 purge 的方式，更常用的实在 varnishadm 内使用正则表达式对特定一组资源进行缓存处理 2.1 使用 purge12345678910111213141516171819# 1. 添加修剪操作的访问控制acl purgers &#123; &quot;127.0.0.0&quot;/8; &quot;10.1.0.0&quot;/16;&#125;# 2. 如何执行修剪，即能执行purge操作sub vcl_purge &#123; return (synth(200,&quot;Purged&quot;));&#125;# 3.何时执行purge操作sub vcl_recv &#123; if (req.method == &quot;PURGE&quot;) &#123; if (!client.ip ~ purgers) &#123; # 访问控制 return(synth(405,&quot;Purging not allowed for &quot; + client.ip)); &#125; return(purge);&#125; 2.2 使用 Banning在 varnishadm 中使用 ban 子命令，可以使用正则表达式批量修剪 command: ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; eg: ban req.url ~ ^/javascripts 在配置文件中定义，使用ban()函数； 12345if (req.method == &quot;BAN&quot;) &#123; ban(&quot;req.http.host == &quot; + req.http.host + &quot; &amp;&amp; req.url == &quot; + req.url); # Throw a synthetic page so the request won&apos;t go to the backend. return(synth(200, &quot;Ban added&quot;));&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 二分查找]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fbinary_search%2F</url>
    <content type="text"><![CDATA[不简单的简单二分查找 1. 特性二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。 二分查找看似简单，但是二分查找的变体一点都不简单，“你”经常看到的二分查找其实是最简单的二分查找即: 有序数组中不存在重复元素，通过二分查找值等于给定值的数据。注意不重复和等于，这里存在很多的变体。 其次二分查找存在很大的局限性: 二分查找依赖的是顺序表结构，简单点说就是数组。 主要原因是二分查找算法需要按照下标随机访问元素。数组按照下标随机访问数据的时间复杂度是 O(1) 如果是链表，随机访问的时间复杂度是 O(n)。如果数据使用链表存储，二分查找的时间复杂就会变得很高。 其他数据结构存储的数据，则无法应用二分查找。 二分查找针对的是有序数据。如果数据没有序，就要先排序。 所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中 针对频繁插入删除的动态数据集合二分查找将不再适，快速查找需要使用二叉树 数据量太大不适合二分查找: 二分查找依赖数组，而数组为了支持随机访问，需要连续的内存空间，对内存的要求苛刻。 要注意数组要求的连续内存意味着即便系统上有零散的 2G 内存也无法申请到连续的 1G 内存。虽然数组对内存要求苛刻，但是同等条件下数组却是最省内存空间的存储方式，因为除了数据本身之外，不需要额外存储其他信息。 1.1 二分查找的变形如果放开不重复和等于的限制，二分查找有很多变形，典型的包括: 查找第一个值等于给定值的元素 查找最后一个值等于给定值的元素 查找第一个大于等于给定值的元素 查找最后一个小于等于给定值的元素 凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。实际上，“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。比如今天讲的这几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。 2. 实现2.1 最简单的二分查找123456789101112def binary_search(A, value): start = 0 end = len(A) - 1 while start &lt;= end: mid = start + ((end -start) &gt;&gt; 1) if A[mid] == value: return mid elif A[mid] &lt; value: start = mid + 1 else: end = mid -1 最简单的二分查找实现中有以下几个需要注意的点: 循环退出条件是 start &lt;= end 不是 start &lt; end 使用 mid=(low+high)/2 对mid取值是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 low+((high-low)&gt;&gt;1)。因为相比除法运算来说，计算机处理位运算要快得多。 start 和 end 的更新，如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致死循环。 2.2 查找第一个值等于给定值的元素12345678910111213def bs_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为第一个出现的值 if mid == 0 or (A[mid-1] != value): return mid end = mid - 1 2.3 查找最后一个值等于给定值的元素12345678910111213def bs_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为最后一个出现的值 if mid == n or (A[mid + 1] != value): return mid end = mid + 1 2.4 查找第一个大于等于给定值的元素1234567891011def bs_gte_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt;= value: # 判断是否为第一个 if mid == 0 or (A[mid - 1] &lt; value): return mid end = mid - 1 else: start = mid + 1 2.5 查找最后一个小于等于给定值的元素1234567891011def bs_lte_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt; value: end = mid -1 else: # 判断是否为最后一个 if mid == n or (A[mid + 1] &gt; value): return mid start = mid + 1 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 映射]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fmap%2F</url>
    <content type="text"><![CDATA[无处不在的映射 1. 映射前面我们讲解了基于数组和链表最基础的数据结构。在继续下面的内容之前，我们先来说一说映射。因为映射与我们接下来的很多数据结构与算法相关。映射可以看作是搜索或查找的扩展，后面介绍的很多数据结构都是为实现快速的增删改查。因此在继续其他数据结构的介绍之前，我想先介绍一下映射的抽象数据类型以及它的常见几种实现方式。 1.1 映射的抽象数据类型抽象基类Python 中使用抽象基类来表达抽象数据类型。如下所示，抽象基类包含两类方法 一是由 abc.abstractmethod 装饰的抽象方法，这些方法必需由继承自抽象基类的子类来提供具体实现 二是在抽象方法基础上定义的具体方法，基类上的具体方法通过继承可以实现最大化代码复用 123456789101112import abcclass ADT(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def abstract_method(self): pass def specific_method(self): return self.abstract_method() Python 中 映射 map 的 ADT 与 MutableMapping 抽象基类相对应。 映射的抽象方法映射 M 有如下五个抽象方法，这些方法必需由子类提供具体实现: M[k]: 返回键 k 对应的值，键不存在则触发异常，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 映射的具体方法为了方便其他功能实现，映射包含了如下具体方法，子类通过继承 MutableMapping 可以自动获取: K in M M.get(k, d=None) M.setdefault(k, d) M.pop(k, d=None) M.popitem() M.clear() M.keys() M.values() M.items() M.update(M2) M == M2 M ！= M2 因为这些方法很容易做到见名知意，我就不再一一解释了。 1.2 map 的实现层次map ADT 有众多的实现方式，为了方便代码重用，我们使用如下层次结构 MutableMapping 是 Python 提供的映射的抽象，提供了现成的映射具体方法 MapBase: 继承自 MutableMapping，为自定义的映射类型提供扩展支持 UnsortedMap: 基于未排序数组的映射实现 HashMapBase: 映射的散列表实现 SortedTableMap: 基于二分查找的映射实现 SkipList: 映射的跳表实现 TreeMap: 二叉搜索树木及其变种的映射实现 2. 实现本节我们就以最简单的 UnsortedMap 为例，实现一个最简单的映射。更加高级的实现我们会在后面一一讲解。 2.1 MapBaseMapBase 是我们在 MutableMapping 基础上自定义的抽象基类，它提供了一个 _Item 类用于保存键与值的映射关系。12345678910111213141516171819class MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __ne__(self, other): return not (self == other) def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._key 2.2 UnsortedMap1pass]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.3 VCL 语法基础]]></title>
    <url>%2F2018%2F10%2F18%2Flinux_mt%2F30-varnish%2FVCL%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[VCL 语法基础 varnish 的缓存配置，使用的是 VCL，一种与 C 类似的域专有类型的配置语言。本节我们先来对 VCL 做一个介绍。 1. VCL 组成与处理流程1.1 VCL 组成1234567891011121314151617181920vcl 4.0;# Default backend definition. Set this to point to your content server.backend default &#123; .host = &quot;127.0.0.1&quot;; .port = &quot;8080&quot;;&#125;sub vcl_recv &#123; # Happens before we check if we have this in cache already. # # Typically you clean up the request here, removing cookies you don&apos;t need, # rewriting the request, etc.&#125;sub vcl_backend_response &#123; # Happens after we have read the response headers from the backend. # # Here you clean the response headers, removing silly Set-Cookie headers # and other mistakes your backend does. VCL 可以看作是在 C 语言基础上二次开发的子语言，保留了 C 语言基本的语法，并额外附加了特性: 首先作为一门语言 VCL 具有变量，赋值，条件判断等基本语法特性，需要额外提醒的是 VCL 没有循环 为了在更高层级上抽象缓存处理逻辑， VCL 在 C 基础上添加了”状态引擎”(state engine) VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x)指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为 subroutine 1.2 VCL 状态引擎VCL 的状态引擎可以分为三类: Client Side： 作用: 客户端请求的状态引擎 包括: vcl_recv, vcl_pass, vcl_hit, vcl_miss, vcl_pipe, vcl_purge, vcl_synth, vcl_deliver... Backend Side: 作用: 后端服务器响应相关的状态引擎 包括: vcl_backend_fetch, vcl_backend_response, vcl_backend_error 两个特殊的引擎： vcl_init: 在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs； vcl_fini: 所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； 1.2 VCL 处理流程varnish 已经为状态引擎内置了关联逻辑，这种内在逻辑就是缓存的处理流程。varnish 不同版本缓存处理的流程并不相同，下面是 varnish4.0 流程图。 2. VCL 语法2.1 VCL 基础特性VCL的语法格式： vcl 4.0;: 必需位于开头，表示 VCL 的版本 //, #, /* foo */: 注释; sub sub_name {}: 使用 sub 关键字定义状态域,例如sub vcl_recv { ...} return(sub_name): 用于实现状态引擎转换； 没有循环, 并且受限于引擎的内建变量 VCL 有限状态机 每一个请求都会被单独的线程处理，并且在任何时间都与其他请求无关 return(action); 将请求从当前状态引擎传递到一个新的状态引擎 状态引擎存在逻辑上的关联，但是彼此是相互独立的 内置的 VCL 代码总是被附加自定义的 VCL 代码之后 2.2 三类主要语法1234567891011sub subroutine &#123; ...&#125;if CONDITION &#123; ...&#125; else &#123; ...&#125;return(), hash_data() 2.3 变量内建变量： req.*: 作用: request，表示与客户端发来的请求报文相关的变量 req.http.* 作用: http 首部字段相关变量 eg: `req.http.User-Agent, req.http.Referer, …`` bereq.*： 作用: 由varnish发往后端主机的httpd请求相关； bereq.http.* beresp.*: 由BE主机响应给varnish的响应报文相关； beresp.http.* resp.*: 由varnish响应给client相关； obj.*: 存储在缓存空间中的缓存对象的属性；只读； 123456# obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数；if (obj.hits&gt;0) &#123; set resp.http.X-Cache = &quot;HIT via &quot; + server.ip;&#125; else &#123; set resp.http.X-Cache = &quot;MISS via &quot; + server.ip;&#125; 变量组 变量 作用 bereq.* bereq.http.HEADERS bereq.request 请求方法； bereq.url 请求的url； bereq.proto 请求的协议版本； bereq.backend 指明要调用的后端主机； req.* req.http.Cookie 客户端的请求报文中Cookie首部的值 req.http.User-Agent ～ 表示使用正则表达式 beresp.* beresp.http.HEADERS beresp.status 响应的状态码 beresp.backend.name BE主机的主机名； beresp.ttl BE主机响应的内容的余下的可缓存时长 resp.* reresp.proto 协议版本 obj.* obj.hits 此对象从缓存中命中的次数 obj.* obj.ttl 对象的ttl值 server.* server.ip server.hostname client.* client.ip 用户自定义变量使用 set, unset 自定义变量和取消变量 2.3 内置操作内置函数常用内置函数: regsub(str, regex, sub): 把str中被regex第一次匹配到字符串替换为sub；主要用于URL Rewrite regsuball(str, regex, sub): 把str中被regex每一次匹配到字符串均替换为sub； ban(boolean expression): Bans所有的其URL可以被此处的regex匹配到的缓存对象； hash_data(input): 指明哈希计算的数据；减少差异，以提升命中率； synth(status,&quot;STRING&quot;)：purge操作； 关键字常见的内置关键子: call subroutine return(action) new set unset 操作符： 判断: ==, !=, ~, &gt;, &gt;=, &lt;, &lt;= 逻辑操作符: &amp;&amp;, ||, ! 变量赋值: = 正则表达式VCL 使用 ~ 表示使用正则表达式。eg: req.url ~ &quot;(?i)^/(login|admin)&quot;, 其中 (?i) 表示不区分字符大小写。 2.4 示例123456789101112131415161718192021222324252627282930# 示例1：强制对某类资源的请求不检查缓存：vcl_recv &#123; if (req.url ~ &quot;(?i)^/(login|admin)&quot;) &#123; return(pass); &#125;&#125;# 示例2：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的时长；# 定义在 vcl_backend_response 中vcl_backend_response&#123;； if (beresp.http.cache-control !~ &quot;s-maxage&quot;) &#123; if (bereq.url ~ &quot;(?i)\.(jpg|jpeg|png|gif|css|js)$&quot;) &#123; unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; &#125; &#125;&#125;# 示例 3: 向后端主机传递客户端 IP# 定义在vcl_recv中；vcl_recv&#123; if (req.restarts == 0) &#123; if (req.http.X-Fowarded-For) &#123; set req.http.X-Forwarded-For = req.http.X-Forwarded-For + &quot;,&quot; + client.ip; &#125; else &#123; set req.http.X-Forwarded-For = client.ip; &#125; &#125; &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 工业级的排序算法]]></title>
    <url>%2F2018%2F10%2F18%2Falog%2Fsort_4%2F</url>
    <content type="text"><![CDATA[实现一个通用的，高效的工业级排序函数 1. 排序算法对比前面我们我们介绍了最常见最经典的几个排序算法，它们有不同的时间复杂度，空间复杂度与使用情景。那么如何用它们实现一个通用的、高效率的排序函数呢？ 线性排序算法的时间复杂度比较低，但适用场景太过比较特殊，所以几乎不会使用。 为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。 归并排序由于不是原地排序算法，空间复杂度为 O(n)，数剧集大时过于占用内存，所以很少使用。 1.2 快排优化快速排序在最坏情况下的时间复杂度是 O(n2)，原因主要是我们的分区点选择不够合理。有两种比较常用合理的分区算法: 三数取中法: 每间隔某个固定的长度，取数据出来比较，将中间值作为分区点 随机法: 从要排序的区间中，随机选择一个元素作为分区点 此外快速排序是用递归来实现的，递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。 2. 实现2.1 Glibc 的 qsort我们以 Glibc 中的 qsort() 函数为例来说明如何实现一个排序函数: qsort() 会优先使用归并排序来排序输入数据，因为小数据集下，归并排序不会占用多少内存，且排序快 要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序 qsort() 使用“三数取中法”选择分区点 qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决操作系统的堆栈溢出问题 在快速排序的过程中，当排序区间的元素个数小于等于 4 时，qsort() 就退化为插入排序；因为我们前面也讲过，在小规模数据面前，插入排序比递归调用的快排更快 在 qsort() 插入排序的算法实现中，还利用了哨兵技术，来减少判断的次数 2.2 Tim-Sort1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.2 varnish 架构及安装]]></title>
    <url>%2F2018%2F10%2F17%2Flinux_mt%2F30-varnish%2Fvarnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[varnish 架构及安装 varnish 是 http 缓存服务器的”新星势力”，它与 squid的关系，类似于 httpd 与 nginx。varnish 有个最大的问题是，它的配置文件随着版本的变化变化非常大。本节我们以 4.0 系列的版本来讲解 varnish 的架构，安装和程序组成 1. varnish 基础官网: https://www.varnish-cache.org 1.1 varnish 架构图 varnish 由如下几个部分组成 管理进程(The management process) Varnish主要有两个进程，管理进程和子进程，管理进程负责：管理配置的变更（包括VCL和参数）、编译VCL、监控Varnish运行、初始化Varnish，以及提供命令行接口等。管理进程会每隔几秒钟检查一下子进程，如果发现子进程挂了，会kill掉然后重新启动一个。这些操作都会记录在日志里面，以利于你检查错误。 子进程(The child process) 子进程包括几个不同类型的线程，包括但不限于： Acceptor线程：接受新的连接并代表它们 Worker线程：一个会话一个线程，通常会使用数百个Worker线程 Expiry线程：负责从缓存中清除旧的内容 shared memory log: 为提升性能，日志是直接存放在内存中的，因此需要特定的工具查看和保存 varnishlog varnishncsa varnishstat… 1.2 配置文件组成varnish 的配置文件分成两个部分 varnish 自身的配置，用于配置 varnish 自身的功能和特性 缓存策略配置， 用于配置供 Child/cache 进程使用的缓存策略。其配置接口为 VCL(Varnish Configuration Language)，通过 Management 提供的命令行接口进行配置，需要经过 VCL 编译器和 C 编译器编译，最后生成供 Child/cache 使用的共享对象(Share object) 2. varnish 程序结构1234567891011121314151617181920$ rpm -ql varnish|egrep -v &quot;(man|doc)&quot;/etc/varnish/etc/varnish/default.vcl # 配置各Child/Cache线程的缓存策略；/etc/varnish/varnish.params # 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制；/usr/bin/varnishadm # CLI interface/usr/bin/varnishhist # Shared Memory Log交互工具/usr/bin/varnishlog/usr/bin/varnishncsa/usr/bin/varnishstat/usr/bin/varnishtop/usr/bin/varnishtest # 测试工具程序/usr/lib/systemd/system/varnish.service # varnish服务/usr/lib/systemd/system/varnishlog.service # 日志持久的服务/usr/lib/systemd/system/varnishncsa.service/usr/sbin/varnish_reload_vcl # VCL配置文件重载程序：/usr/sbin/varnishd # 主程序/var/lib/varnish/var/log/varnish/run/varnish.pid/etc/logrotate.d/varnish 2.1 varnishdvarnishd [options] 作用: varnish 主程序 配置文件: /etc/varnish/varnish.params 选项: -a address[:port][,address[:port][...]: varnish 监听的地址和端口，默认为6081 -T address[:port]: varnishadm 管理服务监听的地址和端口，默认为6082端口； -s [name=]type[,options]: 定义缓存存储机制； -u user: 运行用户 -g group: 运行用户组 -f config: VCL配置文件； -F：运行于前台； -p param=value：设定运行参数及其值； 可重复使用多次； -r param[,param...]: 设定指定的参数为只读状态； varnish 缓存存储机制varnish 缓存存储机制(Storage Types)，分三种机制通过 -s [name=]type[,options] 指定: malloc[,size]: 内存存储，[,size]用于定义空间大小；重启后所有缓存项失效； file[,path[,size[,granularity]]]: 磁盘文件存储，黑盒；重启后所有缓存项失效； persistent,path,size: 文件存储，黑盒；重启后所有缓存项有效；实验阶段 2.2 varnish_reload_vclvarnish_reload_vcl 作用: 重载vcl配置文件 2.3 varnishadmvarnishadm [-S secretfile] -T [address]:port command [...] 作用: varnish 命令行接口 选项: -S secretfile: 指定链接 varnishadm 服务的密钥文件，通常位于 /etc/varnish/secret -T [address]:port: varnishadm 服务监听的地址和端口 command: varnish 执行命令后则退出，不会进入交互命令行 1234567891011121314151617181920212223242526272829303132333435363738394041$ sudo varnishadm -S /etc/varnish/secret[sudo] tao 的密码：200 -----------------------------Varnish Cache CLI 1.0-----------------------------Linux,3.10.0-862.9.1.el7.x86_64,x86_64,-smalloc,-smalloc,-hcritbitvarnish-4.0.5 revision 07eff4c29Type &apos;help&apos; for command list.Type &apos;quit&apos; to close CLI session.help200 help [&lt;command&gt;]ping [&lt;timestamp&gt;]auth &lt;response&gt;quitbannerstatusstartstop # val 配置相关vcl.load &lt;configname&gt; &lt;filename&gt; # 装载，加载并编译 vcl 配置文件vcl.inline &lt;configname&gt; &lt;quoted_VCLstring&gt;vcl.use &lt;configname&gt; # 激活vcl.discard &lt;configname&gt; # 删除vcl.list # 查看所有 vcl 配置文件vcl.show [-v] &lt;configname&gt; # 查看指定的配置文件的详细信息 # 运行时参数相关param.show [-l] [&lt;param&gt;]param.set &lt;param&gt; &lt;value&gt;panic.showpanic.clearstorage.list # 缓存存储backend.list [&lt;backend_expression&gt;] # 后端服务器backend.set_health &lt;backend_expression&gt; &lt;state&gt; # 手动设置后端服务器状态ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; [&amp;&amp; &lt;field&gt; &lt;oper&gt; &lt;arg&gt;]...ban.list 3. varnish 运行参数varnish 运行时参数用于指定 Child/cache 子进程的工作特性。有三种配置方式: 通过 varnishd -p 选项指定 在 varnishadm 中使用 param.set 子命令配置 /etc/varnish/varnish.params 配置文件中使用 DEAMON_OPTS 选项配置，永久有效 12$ cat /etc/varnish/varnish.params |grep DAEMO#DAEMON_OPTS=&quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300&quot; varnish有众多的运行时参数，通常需要配置包括 线程相关的参数 Timer 与超时相关的参数 3.1 线程相关的参数在线程池内部，其每一个请求由一个线程来处理； 其worker线程的最大数决定了varnish的并发响应能力； thread_pools: 线程池数量，默认值为2，其值取决于 CPU 的核心数 thread_pool_max：每个线程池创建最大线程的数量，默认5000， thread_pool_min：每个线程池保持最少线程的数量；额外意义为“最大空闲线程数”；默认100 thread_pool_timeout： 线程空闲时间，超过阈值则摧毁线程 thread_pool_add_delay：创建一个新线程的延迟时间，默认值为0s thread_pool_destroy_delay：摧毁一个线程的延迟时间，默认值为2s； varnish最大并发连接数=thread_pools * thread_pool_max，最大的并发连接数最好不要超过 3 万，否则 varnish 将不稳定。 3.2 Timer相关的参数Timer 参数用于控制 varnish 内部的各种超时时长： send_timeout：向客户端发送响应的超时时间 timeout_idle：客户端链接最大的空闲时长 timeout_req： 从客户端接收请求的超时时长 cli_timeout：child 子进程向 Management 的命令行接口进行响应的超时时长]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 线性排序]]></title>
    <url>%2F2018%2F10%2F17%2Falog%2Fsort_3%2F</url>
    <content type="text"><![CDATA[非基于比较的三个排序算法: 桶排序，计数排序，基数排序 1. 线性排序桶排序、计数排序、基数排序的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以我们今天学习重点的是掌握这些排序算法的适用场景。 桶排序和计数排序的排序思想是可以对数剧集进行有限分类，都是针对范围不大的数据，将数据划分成不同的桶来实现排序，只不过二者桶的粒度不同。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。 2. 实现2.1 桶排序桶排序的核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 只要桶的数量接近数据的个数，并且数据在所有桶内分配均匀，桶排序的时间复杂度接近 O(n)。显然桶排序对要排序数据有苛刻的限制: 首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。 其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。 1234567891011121314151617181920from collections import dequedef sort_bucket(S): """ :param S: [(v, item)] :return: """ m = max((i[0] for i in S)) bucket_map = [deque() for i in range(m + 1)] for i in S: bucket = bucket_map[i[0]] bucket.append(i) c = 0 for i in range(m + 1): b = bucket_map[i] while len(b) &gt; 0: S[c] = b.popleft() c += 1 桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 2.2 计数排序计数排序可视为桶排序的特殊情况，当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。计数排序之所以叫作计数排序，是因为其特殊的通过“计数”进行排序的算法得名的。 1234567891011121314151617def sort_count(S): if len(S) &lt;= 1: return S m = max(S) bucket = [0] * (m + 1) for i in S: bucket[i] += 1 for i in range(1, m + 1): bucket[i] += bucket[i - 1] tmp = [0] * len(S) for i in S: bucket[i] -= 1 tmp[bucket[i]] = i for i in range(len(S)): S[i] = tmp[i] 计数排序只能用在数据范围不大的场景，如果数据范围 k 比要排序的数据 n 大很多，就不适合用排序了。而且，而且计数排序只能用在给非负整数得排序中，如果要排序的数据是其他类型的，要其在不改变相对大小的情况下，转化为非负整数。 2.3 基数排序基数排序的核心是可以将数据分割出独立的“位”来比较，然后按照从低位到高位依次排序，只要每次按位排序的算法是稳定的就可以得到正确的排序。 根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候基数排序的时间复杂度就近似于 O(n)。 显然基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了 123456789101112131415def sort_base(S, num): if len(S) &lt;= 1: return S T = [(0, i) for i in S] for n in range(num): T = [(i[1] // 10 ** n % 10, i[1]) for i in T] sort_bucket(T) print T for i in range(len(S)): S[i] = T[i][1]aa = [43, 41, 31, 57]sort_base(aa, 2)print aa 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 基于比较的排序(下)]]></title>
    <url>%2F2018%2F10%2F16%2Falog%2Fsort_2%2F</url>
    <content type="text"><![CDATA[基于分治编程思想的归并排序和快速排序 1. 分治前面讲到的三种排序算法，平均时间复杂度都是 O(n2)，只是适合规模较小的数剧集，接下来要讲的归并排序和快速排序，平均时间复杂度都是 O(nlogn)，它们都用到了分治思想。 分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。分治与我们前面提到的递归很像，分治算法一般都是通过递归实现的。 虽然快排和归并排序都采用了分治的思想，但是它们完全不一样。归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，快排的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的但是它是非原地排序算法。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。正因为此，归并排序没有快排应用广泛。 2. 实现2.1 归并排序归并排序的核心是将数组从中间分成前后两个部分，然后对前后两个部分分别排序，再将它们合并起来。 1234567891011121314151617181920def merge(a, b, c): i = j = 0 while i + j &lt; len(c): if i == len(a) or (j &lt; len(b) and a[i] &gt; b[j]): c[i + j] = b[j] j += 1 else: c[i + j] = a[i] i += 1def sort_merge(alist): if len(alist) &lt;= 1: return alist mid = len(alist) // 2 left = alist[:mid] right = alist[mid:] sort_merge(left) sort_merge(right) merge(left, right, alist) 归并排序并不是原地排序算法，原因很简单 merge 函数在合并两个已排序数组时使用了额外的存储空间，其空间复杂度为 O(n)。最好最坏和平均时间复杂度都是 O(nlogn)，在整个比较过程并没有发生数据交换，只要 merge 函数保持元素的相对顺序，归并排序是稳定的排序算法。 2.2 快速排序快排的算法描述快排排序由以下 3 个步骤组成: 分解: 如果待排序列 S 有至少两个元素，从 S 中选择一个特定的元素 x 作为基准，将 S 中的元素分别放置在 3 个序列中: L 存储 S 中小于 x 的元素 E 存储 S 中等于 x 的元素 G 存储 S 中大于 x 的元素 递归: 递归的排序序列 L 和 G 合并: 按照 L,E,G 的顺序将元素放回 S 中 123456789101112131415161718192021222324252627def sort_quick(S): n = len(S) if len(S) &lt;= 1: return x = S.first() # 基准 x L = LinkedQueue() E = LinkedQueue() G = LinkedQueue() # 分解 while not S.empty(): if S.first() &lt; x: L.enqueue(S.dequeue()) elif S.first() &gt; x: G.enqueue(S.dequeue()) else: E.enqueue(S.dequeue()) # 递归 sort_quick(L) sort_quick(G) # 合并 while not L.is_empty(): S.enqueue(L.dequeue()) while not E.is_empty(): S.enqueue(E.dequeue()) while not G.is_empty(): S.enqueue(G.dequeue()) 快排的原地排序快排的原地排序的核心是选择数组中的一个数据项作为分区点 x，然后遍历数组通过数据交换，使得 x 左边的数据都小于 x，x 右边的数据都大于 x。x 将数组分成了两个区间，然后对这两个区间递归执行此过程直至区间长度为 1 ，完成排序。 1234567891011121314151617def sort_quick(alist, left, right): if left &gt;= right: return alist l = left + 1 r = right x = alist[left] while l &lt;= r: while l &lt;= r and alist[l] &lt; x: l += 1 while l &lt;= r and alist[r] &gt; x: r -= 1 if l &lt;= r: alist[l], alist[r] = alist[r], alist[l] alist[left], alist[r] = alist[r], alist[left] sort_quick(alist, left, r - 1) sort_quick(alist, r + 1, right) 显然这个过程发生了数据交换，但是并没有使用额外的存储空间，所以快排并不是稳定的排序算法，但是原地排序算法。 快排的最好和平均时间复杂度都是O(nlogn)，但是极端情况下，如果数组本身是有序的，并且我们选择最大或者最小(两端)的数据作为分区点，我们需要大约 n 次分区才能完成排序过程。快排的时间复杂度就会退化为 O(n2)。但是退化到 O(n2) 的概率非常小，我们可以通过合理的选择分区点来避免这种情况。 3. 算法3.1 求无序数组中的第 K 大元素利用快排的分区思想，我们可以在O(n) 时间复杂度内求无序数组中的第 K 大元素。 我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。如果 p+1=K，那 A[p] 就是要求解的元素；如果 K&gt;p+1, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找。同理，如果 K&lt;p+1，那我们就在 A[0…p-1] 区间查找。 12345678910111213141516171819def quick_select(S, left, right, k): r = right l = left + 1 pivot = S[left] while l &lt;= r: while l &lt;= r and S[l] &lt;= pivot: l += 1 while l &lt;= r and S[r] &gt;= pivot: r -= 1 if l &lt;= r: S[l], S[r] = S[r], S[l] S[left], S[r] = S[r], S[left] if r + 1 == k: return S[r] elif r + 1 &gt; k: return quick_select(S, left, r - 1, k) else: return quick_select(S, r + 1, right, k) 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.1 web架构缓存优化]]></title>
    <url>%2F2018%2F10%2F16%2Flinux_mt%2F30-varnish%2Fweb%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[web架构缓存优化 上一章我们学习了如何使用 keepalived 实现一个高可用集群，接下来我们来继续完善我们的 web 站点架构，本章我们来讲解另一个重要内容，web 站点的缓存系统。 计算机组件衔接中非常常见而且重要策略就是: 两个环节连接起来不是很流畅，加中间层 两个环节连接起来在性能上不匹配，加缓存 缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在”热区”，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 本章我们就来讲解 web 缓存中一种常见实现 varnish，内容包括: web 站点架构演变 varnish 架构与安装配置 varnish 缓存策略配置 varnish 优化与进阶 1. Cache“Cache is Key”，缓存是 web 架构中一个非常重要的组件，因此在学习 varnish 之前，我们必需先了解一下缓存，以及缓存如何影响着我们 web 架构的演变。本节内容包括: 缓存的基本知识 web 架构缓存优化 http 协议的缓存机制 1.1 缓存基础缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在”热区”，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 因此对于缓存有一些基础的必需理解的概念 首先我们缓存的是热区数据而不是所有数据，所以缓存存在空间限制，当缓存空间耗尽时，会基于 LRU(最近最少使用) 算法来更新缓存 缓存存在时效性，需要定期对过期缓存进行清理，因此通常只会对那些读多写少的内容进行缓存 缓存的有效性使用缓存命中率 hit/(hit+miss) 进行衡量，有两个衡量的指标 页面命中率：基于页面数量进行衡量 字节命中率：基于页面的体积进行衡量 1.2 缓存的分级结构缓存存在多级结构，不同缓存级别下，有些缓存是公共的，有些缓存是私有的，公共缓存只能缓存多个用户之间可以共享的公共数据，因此我们需要在服务器指明数据是否可以被公共缓存缓存。通常 私有数据：只能被私有缓存缓存(private，private cache) 公共数据：可同时被公共和私有缓存进行缓存(public, public or private cache) 对于公共缓存，我们在设置缓存键时，应该尽量排除用户的私有信息，以提高缓存的命中率。因此非常有必要组织好缓存键，减少用户私有数据的参与。 1.3 缓存模式缓存的实现分为两种模式 代理缓存: 缓存服务器如果未能命中，缓存服务器自己需要去找后端服务器请求资源并反回给客户端，所以又称为递归缓存 旁挂缓存: 缓存服务器未命中，需要客户端自己发送请求获取结果 memcached 就是典型的旁挂缓存，所有的 http 协议的缓存都是代理。web 缓存的两个重要开源实现是 squid, varnish，它们类似于 web 服务器的 httpd 和 nginx。 2. web 架构缓存优化多看几次视频(34-1:17) 3. HTTP 缓存控制HTTP 协议在 1.1 增强了缓存控制机制，在 HTTP 协议的缓存控制中，服务器会会在响应报文中为资源”打标”，客户端则会根据”标记”来决定是否使用本地缓存以及如何请求。 3.1 响应报文的缓存控制响应报文中有两种缓存控制机制 过期时间机制 Expires: 作用: HTTP/1.0 使用，表示缓存的过期的绝对时间，在缓存未到期之前客户端会直接使用本地缓存不会发起请求 缺陷: 可能由于时区或系统时间问题而提前失效 Cache-Control: maxage=: 作用: HTTP/1.1 可用表示缓存有效时长 说明: Cache-Control 是缓存控制的专用首部，maxage 只是其使用方式之一 条件式请求机制 Last-Modified: 作用: 文件的最近一次修改时间戳，请求报文使用 If-Modified-Since 首部配合使用 局限: Last-Modified 记录的最小单位是秒，如果响应的内容在 1s 内更新了好几次，此首部是无法反映的 Etag: 作用: 基于文件的校验码来判别，请求报文使用 If-None-Match 首部配合使用 12345# 响应报文中的缓存控制首部信息示例Expires:Thu, 13 Aug 2026 02:05:12 GMT # 有效的绝对时间Cache-Control:max-age=315360000 # 有效时长ETag:&quot;1ec5-502264e2ae4c0&quot; # 内容校验码Last-Modified:Wed, 03 Sep 2014 10:00:27 GMT # 文件最近一次修改时间 3.2 条件式请求首部对于时间控制机制，客户端会自动根据 Expires 和 Cache-Control 来判断缓存是否过期，只有缓存过期时客户端才会发起新的请求。 对于条件式请求机制，用户会根据 Last-Modified 或 Etag 发起条件式请求 Last-Modified 对应的条件式请求首部包括: If-Modified-Since：从指定时间开始，内容是否发生变更 If-Unmodified-Since Etag 对应的条件式请求首部: If-Match: 当前缓存资源的 Etag 是否与服务器资源的 Etag 相同 If-None-Match: 以 Etag 为例，条件式请求的整个过程如下: 第一次客户端请求时，服务器会在响应报文的附加 Etag 首部，其值是响应内容的哈希值 客户端需要再次获取同一资源时，将发起条件式请求，请求中 If-Match 首部字段的值就是第一响应的 Etag 首部字段的值 服务器会将请求报文中的 Etag 值与当前资源进行比较 如果原始内容未改变，则仅响应首部（不附带body部分），响应码304 （Not Modified） 如果原始内容发生改变，则正常响应，响应码200； 如果原始内容消失，则响应404，此时缓存中的cache object也应该被删除； 3.3 缓存过程通常情况下，http 的缓存的过期时间和条件式请求会结合使用，客户端接收到响应之后，在过期时间到期之前都会是使用本地缓存，缓存到期之后才会发送条件式请求。这样过期时间机制减少了发送请求的次数，条件式请求减少了传输内容。可以最大程度上提升传输速率。 4. http Cache-Control 首部值http 头中的 Cache-Control 首部有特殊作用 请求报文中用于通知缓存服务如何使用缓存响应请求 no-cache:（不要缓存的实体，要求现在从WEB服务器去取） max-age：（只接受 Age 值小于 max-age 值，并且没有过期的对象） max-stale：（可以接受过去的对象，但是过期时间必须小于 max-stale 值） min-fresh：（接受其新鲜生命期大于其当前 Age 跟 min-fresh 值之和的缓存对象） 响应报文中用于通知缓存服务器如何存储上级服务器响应的内容 public: (可以用 Cached 内容回应任何用户) private:（只能用缓存内容回应先前请求该内容的那个用户） no-cache: 可缓存，但响应给客户端之前需要revalidation，即必须发出条件式请求进行缓存有效性验正 max-age：（本响应包含的对象的过期时间） no-store: 不允许存储响应内容于缓存中 12345678910111213141516171819202122232425# http 协议缓存控制指令Cache-Control = &quot;Cache-Control&quot; &quot;:&quot; 1#cache-directive cache-directive = cache-request-directive | cache-response-directive cache-request-directive = &quot;no-cache&quot; | &quot;no-store&quot; (backup) | &quot;max-age&quot; &quot;=&quot; delta-seconds | &quot;max-stale&quot; [ &quot;=&quot; delta-seconds ] | &quot;min-fresh&quot; &quot;=&quot; delta-seconds | &quot;no-transform&quot; | &quot;only-if-cached&quot; | cache-extension cache-response-directive = &quot;public&quot; | &quot;private&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] | &quot;no-cache&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] | &quot;no-store&quot; | &quot;no-transform&quot; | &quot;must-revalidate&quot; | &quot;proxy-revalidate&quot; | &quot;max-age&quot; &quot;=&quot; delta-seconds | &quot;s-maxage&quot; &quot;=&quot; delta-seconds | cache-extension]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>缓存系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.3 keepalived 配置示例]]></title>
    <url>%2F2018%2F10%2F15%2Flinux_mt%2F29-keepalived%2Fkeepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[keepalived 配置示例 前面我们已经介绍了如何安装和配置 keepalived，本节我们就来看看如何使用 keepalived 对 nginx 的负载均衡集群做高可用。需要提醒大家注意的是无论是学习还是以后工作，当我们配置一个复杂服务时，都应该按照简单到复杂的顺序一步步进行配置，完成一步，验证一次，成功之后在进行下一步，这样便于排错。所以本节的示例我们将按照如下顺序展示，最终完成我们的LVS 双主模型的高可用集群配置。 单主模型下配置 keepalived 完成地址流动 双主模型下配置 keepalived 完成地址流动 单主模型的 LVS 高可用集群配置 双主模型的 LVS 高可用集群配置 双主模型 nginx 高可用集群配置 1. 单主模型下完成地址流动12345678910111213141516171819202122232425262728293031! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 192.168.1.168/24 dev eno16777736 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 通知脚本的使用方式：12345678910111213141516171819202122232425#!/bin/bash#contact='root@localhost'notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125;case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 脚本的调用方法： notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot; 2. 双主模型下完成地址流动双主模型的地址流动，只需在单主模型下额外添加一个 vrrp 实例，在新的实例下: 修改 virtual_router_id 修改 vrrp 认证的密码 修改 virtual_ipaddress 绑定的地址 原来的 MASTER 变成 BACKUP，BACKUP 变成 MASTER 1234567891011121314vrrp_instance VI_2 &#123; state BACKUP interface eno16777736 virtual_router_id 15 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 578f07b2 &#125; virtual_ipaddress &#123; 192.168.1.169/24 dev eno16777736 &#125;&#125; 3. 双主模型的 LVS 高可用集群配置配置步骤如下: 首先要配置 LVS 集群的后端 RS，可参照27.5 LVS 4层负载均衡-DR模型 在”双主模型下完成地址流动”的基础上添加 virtual_server，配置方式如下所示 1234567891011121314151617181920212223242526272829303132333435363738virtual_server 192.168.1.168 80 &#123; delay_loop 3 lb_algo rr lb_kind DR protocol TCP sorry_server 127.0.0.1 80real_server 192.168.1.137 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125;&#125;real_server 192.168.1.107 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125;virtual_server 192.168.1.169 80 &#123; ....... # 配置同上&#125; 4. 单主模型的nginx高可用集群nginx 服务的高可用，我们需要使用 vrrp_script{} 定义 nginx 的检测方式，并将这种检测通过 track_script 添加到 vrrp 实例中去，让 vrrp 能够在检测到 nginx 服务异常时进行主备服务器切换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19&#125;vrrp_script chk_down &#123; script &quot;[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0&quot; interval 1 weight -5&#125;vrrp_script chk_nginx &#123; # 定义 script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 10.1.0.93/16 dev eno16777736 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125; 5. 双主模型的nginx高可用集群双主模型在单主模型基础上添加一个 vrrp 实例即可]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 基于比较的排序(上)]]></title>
    <url>%2F2018%2F10%2F14%2Falog%2Fsort_1%2F</url>
    <content type="text"><![CDATA[基于比较的排序算法: 冒泡排序、插入排序和选择排序 1. 排序算法要点排序算法太多了，因此除了要学习各种算法的原理，代码实现之外；我们还要搞明白如何比较和分析一个排序算法。评价一个算法可以从如下几个方面入手: 算法的执行效率: 算法的执行效率包括最好情况、最坏情况、平均情况的时间复杂度；之所以要区分这三种情况，是因为大多数排序算法在不同有序度的数据集上的时间复杂度不相同 时间复杂度的系数、常数 、低阶；通常我们要排序的数剧集并不大，因此需要将系数、常数 、低阶考虑进来 比较次数和交换（或移动）次数，基于比较的排序算法需要进行数据的比较和移动两个操作，因此需要把这两个操作考虑进来 排序算法的内存消耗，排序算法中，我们将空间复杂度为O(1) 的算法称为原地排序算法 排序算法的稳定性，稳定性指如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 这些方面可以帮助我们分析和更好的理解每种算法的特点。 1.1 排序算法分类排序算法太多了，最经典的、最常用的包括：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。如上图所示按照时间复杂度它们分成了三类。 本节我们先来介绍基于比较的排序算法:冒泡排序、插入排序和选择排序。 这三种时间复杂度为 O(n2) 的排序算法中，冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，我会讲到，有些编程语言中的排序函数的实现原理会用到插入排序算法。 1.2 有序度有序度是数组中具有有序关系的元素对的个数，逆序度恰恰相反，完全有序的数组的有序度叫作满有序度。逆序度的定义正好跟有序度相反显然 逆序度 = 满有序度 - 有序度。排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，排序完成。 在下面的冒泡和插入排序的实现中，我们会发现无论是插入排序还是选择排序，每次数据交换只会增加 1 个有序度(因为它们只会对相邻的元素进行交换)。因此这两种排序的数据交换次数是相同的都是数剧集的逆序度。但是冒泡排序的实现更复杂需要更多次的赋值操作。所以如果将时间复杂度的系数、常数 、低阶考虑进来，冒泡排序并没有插入排序快。 2. 实现2.1 冒泡排序冒泡排序的核心是每次只会操作相临的两个数据，比较它们的大小，并在不满足大小关系时交换；在 n 次操作之后将最大或者最小值移动到最前端。 总共经过 n 次冒泡之后，排序即可完成。冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。 冒泡是原地排序算法，只要我们在代码中不交换相等的元素，冒泡排序就是稳定的排序算法 12345def sort_bubble(alist): for end in range(len(alist), 1, -1): for i in range(1, end): if alist[i] &lt; alist[i-1]: alist[i], alist[i-1] = alist[i-1], alist[i] 2.2 插入排序插入排序将数据分为已排序和未排序两个区间，然后不断取未排序区间中的元素插入到已排序区间中，并保持已排序区间的有序；重复直至未排序区间为空即可。 插入排序是原地排序算法，在插入排序中，对于值相等的元素，我们只要将后出现的元素插入到后出现元素的后面，插入排序就是稳定的排序算法。 12345678def sort_insert(alist): for end in range(1, len(alist)): tmp = alist[end] p = end - 1 while p &gt;= 0 and alist[p] &gt; tmp: alist[p + 1] = alist[p] p -= 1 alist[p + 1] = tmp 2.3 选择排序选择排序将数据分为已排序和未排序两个区间，不同的是选择排序每次会从未排序区间找出最小的元素放到已排序区间的末尾，而不是插入。 选择排序是原地排序算法，最好最坏和平均时间复杂度都是O(n2)，但是选择排序并不是稳定的排序算法。原因是选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。 1234567def sort_select(alist): for start in range(0, len(alist)): m = start for i in range(start + 1, len(alist)): if alist[i] &lt; alist[m]: m = i alist[start], alist[m] = alist[m], alist[start] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.2 keepalived 安装和配置]]></title>
    <url>%2F2018%2F10%2F14%2Flinux_mt%2F29-keepalived%2Fkeepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[keepalived 安装和配置 上一节我们对高可用集群 和 keepalived 做了一个简单介绍，本节我们来学习 keepalived 的安装配置。我们的最终目的是使用 keepalived 对 nginx 的负载均衡集群做高可用，本节内容包括: HA 集群配置的前题 keepalived 安装与组成 keepalived 配置文件格式与参数 1. HA 集群的配置前提HA 集群因为主备节点之间需要通信以协调工作，所以在配置之前需要一些准备工作: 各节点时间必须同步，参考 25.1 Linux时间服务-chrony 确保iptables及selinux不会成为阻碍 各节点之间可通过主机名互相通信 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 建议使用/etc/hosts文件实现，避免 DNS 称为单点故障所在 确保各节点的用于集群服务的网卡接口支持MULTICAST通信，以便进行组播 各节点之间的 root 用户可以基于密钥认证的 ssh 服务完成互相通信。 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 因为 corosync 需要在节点之间复制配置文件 2. keepalivedCentOS 6.4 只有 keepalived 就已经被收录至 base 仓库，因此可通过 yum 直接安装。 2.1 程序环境12345678$ rpm -ql keepalived |grep -v "share"/usr/sbin/keepalived # 主程序文件/etc/keepalived/etc/keepalived/keepalived.conf # 主配置文件/usr/bin/genhash /etc/sysconfig/keepalived # Unit File的环境配置文件/usr/lib/systemd/system/keepalived.service # Unit File/usr/libexec/keepalived 2.2 配置文件格式1234567891011121314151617181920212223242526272829303132333435363738394041# 1. GLOBAL CONFIGURATION# 1.1 Global definitionsglobal_defs &#123;&#125;# 1.2 Static routes/addressesstatic_ipaddress&#123;&#125;static_routes&#123;&#125;static_rules&#123;&#125;# 2. VRRPD CONFIGURATION# 2.1 VRRP synchronization group(s)vrrp_sync_group VG_1 &#123; group &#123; inside_network # name of the vrrp_instance (see below) outside_network # One for each movable IP ...&#125;&#125;# 2.2 VRRP instance(s)vrrp_instance inside_network &#123;&#125;# 3. LVS CONFIGURATION# 3.1 Virtual server group(s)virtual_server_group &lt;STRING&gt; &#123;&#125;# 3.2 Virtual server(s)virtual_server group string&#123;&#125; 上面是 keepalived.conf 的缩略结构，主要由如下几个配置段组成: GLOBAL CONFIGURATION: 全局配置段 Global definitions: 全局参数 Static routes/addresses: 静态地址和静态路由配置 VRRPD CONFIGURATION: vrrp 配置段 VRRP synchronization group(s)：vrrp同步组，同一组内的 vrrp 会同进同退 VRRP instance(s)：每个vrrp instance即一个vrrp路由器； LVS CONFIGURATION: lvs 规则管理配置段 Virtual server group(s): 将一组集群服务进行统一调度 Virtual server(s): ipvs集群的vs和r 3. global_defsglobal_defs 用于全局参数 12345678910111213# 示例一: global_defs 全局配置! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; # 邮件通知的管理员帐户，收件箱 root@localhost &#125; notification_email_from keepalived@localhost # 发件箱 smtp_server 127.0.0.1 smtp_connect_timeout 30 # smtp 链接超时时长 router_id node1 # 当前节点的标识，重要 vrrp_mcast_group4 224.0.100.19 # 组播域，重要&#125; 4. vrrp_instancevrrp_instance 用于定义虚拟路由器 123vrrp_instance &lt;STRING&gt; &#123; ....&#125; 4.1 vrrp_instance 常用参数 vrrp_instance 参数 作用 state MASTER/BACKUP 当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP interface IFACE_NAME 绑定为当前虚拟路由器使用的物理接口 virtual_router_id VRID 当前虚拟路由器的惟一标识，范围是0-255 priority 100 当前主机在此虚拟路径器中的优先级；范围1-254 advert_int 1 vrrp通告的时间间隔； authentication{} vrrp 认证，详细使用见下 virtual_ipaddress{} 虚拟路由器的 IP 地址，详细使用见下 virtual_routes{} 虚拟路由，详细使用见下 track_interface{} 配置要监控的网络接口，一旦接口出现故障，则转为FAULT状态,，详细使用见下 nopreempt 定义工作模式为非抢占模式，默认为抢占模式 preempt_delay 300 抢占式模式下，节点上线后触发新选举操作的延迟时长； notify_master path 当前节点成为主节点时触发的脚本 notify_backup path 当前节点转为备节点时触发的脚本 notify_fault path 当前节点转为“失败”状态时触发的脚本 notify path 通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知 1234567891011121314151617181920212223242526# vrrp 认证authentication &#123; auth_type AH|PASS auth_pass &lt;PASSWORD&gt; &#125;# 虚拟路由器 ipvirtual_ipaddress &#123; &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1&#125;# 虚拟路由virtual_routes &#123; src 192.168.100.1 to 192.168.109.0/24 via 192.168.200.254 dev eth1 192.168.110.0/24 via 192.168.200.254 dev eth1 &#125;# 监控的网络接口track_interface &#123; eth0 eth1 ...&#125; 4.2 vrrp_instance 配置示例12345678910111213141516171819# 示例二: 单主模型下完成地址流动global_defs&#123; # 配置见示例一 .....&#125;vrrp_instance VI_1 &#123; state BACKUP # 节点初始状态 interface eno16777736 # 绑定虚拟地址的网卡接口 virtual_router_id 14 # 虚拟路由器 ID priority 98 # 优先级 advert_int 1 # 组播频率 authentication &#123; # vrrrp 认证 auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; # 虚拟 IP 地址 10.1.0.91/16 dev eno16777736 label eno16777736:0 &#125;&#125; 5. vrrp_sync_group5.1 vrrp_sync_group 作用VRRP synchronization group(s)：用于定义 vrrp 同步组，同一组内的 vrrp 会同进同退。所谓同进同退的意思是 vrrp 组的服务，当某一个服务发生故障转移或故障恢复时，组内的所有服务都会一同进行转移。典型的情景是高可用 NAT 模型的 LVS。 12vip ----------- VS1(100) ------ DIPvip ------------VS2(99) -------DIP 如上，前段我们将 vip 定义为虚拟路由 router1，对外提供服务，后端我们将 DIP 配置为虚拟路由器 router2 向后端服务转发请求。当 router1 因为某种原因从 VS1 转移到 VS2 时，我们的 router2 也必需要转移过去。原因是 NAT 模型的 LVS 后端的 RS 必需将网关指向VS，当 VS 由 VS1 转移到 VS2 时，如果 router2 不随之转移，RS 的报文将将默认发送至 VS1，此时将无法完成目标地址转换。 需要注意的是对于 nginx 我们无需配置 router2，因为请求报文是通过 IP 地址路由的，而 IP 地址是不会变化的。 5.2 vrrp_sync_group 配置示例123456vrrp_sync_group G1 &#123; group &#123; VI_1 # vrrp_instance 定义 vrrp 虚拟路由器名称 VI_2 VI_5&#125; 6. virtual_servervirtual_server 用于定义 ipvs 集群规则123456789virtual_server IP port | # 只支持 tcp 协议virtual_server fwmark int # 防火墙标记&#123; ... real_server &#123; ... &#125; ...&#125; 6.1 virtual_server 常用参数 delay_loop &lt;INT&gt;：健康状态检测的时间间隔 lb_algo rr|wrr|lc|wlc|lblc|sh|dh：调度方法 lb_kind NAT|DR|TUN：集群的类型 persistence_timeout &lt;INT&gt;：持久连接时长 protocol TCP：服务协议，仅支持TCP sorry_server &lt;IPADDR&gt; &lt;PORT&gt;：备用服务器地址 real_server &lt;IPADDR&gt; &lt;PORT&gt;{}：RS 定义 RS 定义1234567real_server &lt;IPADDR&gt; &lt;PORT&gt;&#123; weight &lt;INT&gt; : 权重 notify_up &lt;STRING&gt;|&lt;QUOTED-STRING&gt; : 启动的通知脚本 notify_down &lt;STRING&gt;|&lt;QUOTED-STRING&gt; : 关闭的通知脚本 HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK &#123; ... &#125;：定义当前主机的健康状态检测方法；&#125; 健康状态检测方法: HTTP_GET|SSL_GET{}：应用层检测 TCP_CHECK{}：传输层检测 应用层检测位于 real_server{}配置段内 1234567891011121314HTTP_GET|SSL_GET &#123; url &#123; path &lt;URL_PATH&gt; ：定义要监控的URL； status_code &lt;INT&gt; ：判断上述检测机制为健康状态的响应码； digest &lt;STRING&gt; ：判断上述检测机制为健康状态的响应的内容的校验码； &#125; nb_get_retry &lt;INT&gt; ：重试次数； delay_before_retry &lt;INT&gt; ：重试之前的延迟时长； connect_ip &lt;IP ADDRESS&gt; ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt; ：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt; ：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt; ：发出健康状态检测请求时使用的源端口； connect_timeout &lt;INTEGER&gt;：连接请求的超时时长；&#125; 传输层检测位于 real_server{}配置段内 123456789TCP_CHECK &#123; connect_ip &lt;IP ADDRESS&gt; ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt; ：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt; ：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt; ：发出健康状态检测请求时使用的源端口； nb_get_retry &lt;INT&gt; ：重试次数； delay_before_retry &lt;INT&gt; ：重试之前的延迟时长； connect_timeout &lt;INTEGER&gt; ：连接请求的超时时长；&#125; 6.2 配置示例123456789101112131415161718192021222324252627282930313233virtual_server 10.1.0.93 80 &#123; delay_loop 3 # 健康状态监测时间间隔 lb_algo rr # 调度算法 lb_kind DR # 集群类型 protocol TCP # 服务协议 sorry_server 127.0.0.1 80 # sorry server real_server 10.1.0.69 80 &#123; # RS 配置 weight 1 # 权重 HTTP_GET &#123; # 应用层健康状态监测 url &#123; path / # 检测路经 status_code 200 &#125; connect_timeout 1 # 链接超时时长 nb_get_retry 3 # 重试次数 delay_before_retry 1 # 重试间隔 &#125; &#125; real_server 10.1.0.71 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125; 7. keepalived 高可用 nginxkeepalived 最初的设计目的是为了高可用 LVS，所以要想高可用其他服务需要借助于 keepalived 的脚本调用接口。keepalived 通过调用外部的辅助脚本进行资源监控，并根据监控的结果实现节点的优先调整，以便在主节点发生故障时实现故障转移。 对于 nginx 调度器为例，其最重要的资源是对外提供服务的 IP 地址和 nginx 进程，keepalived 的 vrrp stack 已经能自动完成 IP 转移，但是 keepalived 并没有内置判断 nginx 是否故障，以及故障之后如何转移的功能。nginx 资源的监控，以及如何进行优先级调整只能通过提供辅助脚本进行。并且此时后端服务器的健康状态检测由 nginx 自己进行，与 keepalived 无关。 因此使用 keepalived 高可用 nginx 分两步： 先定义一个 nginx 的监控脚本，使用 keepalived 的 vrrp_script{} 配置段 调用此脚本，在 vrrp_instance{} 配置段内使用 track_script{} 配置段 7.1 vrrp_script12345678vrrp_script &lt;SCRIPT_NAME&gt; &#123; script &quot;&quot; # 脚本路经 interval INT # 脚本执行的时间间隔 weight -INT # 脚本执行失败后，对优先级的调整大小 fall INT # 认定失败的检测次数 rise INT # 认定恢复正常的检测次数 user USERNAME [GROUPNAME] # 执行脚本的用户和用户组&#125; 7.2 track_script12345track_script &#123; SCRIPT_NAME_1 # vrrp_script 定义的脚本名称 SCRIPT_NAME_2 ...&#125; 7.3 配置示例1234567891011121314151617181920212223242526272829303132333435vrrp_script chk_down &#123; script &quot;[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0&quot; interval 1 weight -5&#125;vrrp_script chk_nginx &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 10.1.0.93/16 dev eno16777736 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 递归]]></title>
    <url>%2F2018%2F10%2F13%2Falog%2Frecursion%2F</url>
    <content type="text"><![CDATA[递归是一种应用非常广泛的算法（或者编程技巧）。很多数据结构和算法的编码实现都要用到递归，比如 DFS 深度优先搜索、前中后序二叉树遍历等等。所以，搞懂递归非常重要。 1 特性基本上，所有的递归问题都可以用递推公式来表示。要想使用递归解决问题，必需满足三个前提条件: 一个问题的解可以分解为几个子问题的解，子问题就是规模更小的问题 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 存在递归终止条件 1.1 如何写递归代码写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再找出终止条件，最后将递推公式和终止条件翻译成代码。 编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。 1.2 递归存在的问题使用递归时会存在很多问题，最常见的两个是: 递归代码要警惕堆栈溢出 递归代码要警惕重复计算 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销。 1.3 应用递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现。 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.1 高可用集群介绍以及开源软件应用]]></title>
    <url>%2F2018%2F10%2F13%2Flinux_mt%2F29-keepalived%2F%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[高可用集群介绍以及开源软件应用 我们已经介绍了如何使用 LVS/Nginx 如何搭建一个负载均衡集群。为实现负载均衡我们需要一个前端调度器，同时为了让后端服务器共享 session，我们可能需要使用到 session 服务器，等等。调度器，session 服务器则是整个集群的单点故障所在(SPoF: Single Point of Failure)，它们一旦发生故障整个集群将不可用。 在讲解 LVS 时，我们提到了一个衡量系统可用性的标准(平均无故障时间/平均无故障时间 + 平均修复时间)。要想提升系统可用性，必需降低故障的修复时间。因此我们需要对单点故障实现高可用，以通过冗余来降低系统修复时间提高系统可用性。 本章我们就来讲解高可用集群的其中一种实现方案 keepalived。本章内容包括: 高可用集群的实现方案及原理概述 keepalived 安装配置 keepalived高可用 nginx 高可用集群有众多的解决方案，典型的包括 keepalived: 基于 VRRP 协议的实现 heartbeat/corosync: 通用的HA集群解决方案，corosync 是 heartbeat 的升级版 heartbeat/corosync 是通用的高可用集群解决方案，因此对于特定服务，它能提供了功能是有限的。因此大多数情况下，不同服务通常有各自特定的高可用解决方案。keepalived 最开始是为专门高可用 LVS 的，也可以用来高可用 nginx。本节我们就来简述这两种解决方案的基本原理。 1. 高可用集群面临的问题所谓的高可用集群就是为主服务，又称为主节点提供了一个冗余的备用节点，当主节点不可用时，备用节点能自动替代主节点对外提供服务。但是这个冗余与替换的过程有许多问题需要解决: 1.1 心跳信息首先备用节点如何判断主节点不可用。为此主节点需要不断的向备用节点发送”心跳”信息(heartbeat)，备用节点通过心跳信息判断主节点是否正常。然而我们面对的集群环境，除了主机异常之外，也很有可能出现网络异常。所以备用节点收到心跳信息时，不一定是主节点故障，而有可能是网络异常，我们称此种状况为网络发生分区(Network partition)。 其次高可用集群中的服务器可能不止一台，应该如何同步心跳信息呢？很显然一对一通信效率太低，我们需要借助组播，因此搭建高可用集群很重要的一步就是配置集群的组播域。 1.2 网络分区当网络发生分区时，原本的集群就会划分成多个集群，此时应该如何决定由哪个部分来提供服务呢？按照少数服从多数的原则，应该由包含超过半数节点的分区网络继续提供服务。确定了提供服务器的分区之后还不够，首先如果主节点并不再此分区网络中，需要重新选举一个主节点；其次为防止其他分区网络争抢资源，需要对剩余的其他分区作服务器隔离。 1.3 选举协议中心节点的选举有众多协议，其中最著名的就是分布式网络中的 Paxos，以及再次基础上衍生出来的 Raft 协议。很建议大家多读一读这两个协议相关的论文和文章。 1.4 服务隔离准确来说，高可用集群高可用的是特定的服务。以 nginx 负载均衡集群来说，我们高可用的是 nginx 调度器这个服务，这个服务由两个核心资源组成一是对外提供服务的 IP 地址，另一个是我们的 nginx 进程。对于 nginx 即成我们只需要在备用节点上配置好相同的 nginx 服务即可。因此对于负载均衡集群来说，最重要的资源是对外提供的 IP 地址。当服务发生分区时，如果不进行服务隔离，不同的分区网络就会争抢 IP，导致服务间歇性不可用。当然这种情况并不是很严重。 我们考虑另一个更加严重的情况，假设所有后端服务器都挂载到了一个共享的块存储设备上，比如 SAN 这种块级别的共享存储区域网络。网络分区发生时，如果一个分区对磁盘块做了删除操作，另一个做了修改操作，那么最终的将对导致文件系统的元数据不可用进而导致整个系统不可用。 服务隔离有两种曾经: STONITH(Shooting The Other Node In The Head)：主机级别的隔离，”爆头”直接将服务器停机处理 fence: 资源级别的隔离，限制对特定资源的访问 1.5 相关术语在高可用集群中我们有如下一些专用术语 Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作； Failback：故障移回，即某资源的主节点故障后重新修改上线后，将转移至其它节点的资源重新切回的过程 接下来我们首先来介绍 heartbeat/corosync 架构。 2.heartbeat/corosync 如图是 corosync 的结构图，其由三个部分组成，由下而上是 messaging/infrastructure: 发送心跳信息 ClusterResource Manager(CRM): 资源分配层，用于定义集群服务，包括 Cluster Information Base (CIB): CIB使用XML表示整个集群的配置和当前状态信息。它包含所有集群选项、节点、资源、约束的定义和彼此之间的关系。 并且CIB同步更新至所有的集群节点。在集群内有一个通过DC维护的主CIB节点。其它所有节点存在一个CIB的副本。 Designated Coordinator (DC): 某一个CRM被推选为DC。DC 是群集中唯一可以决定需要在整个群集执行更改（例如节点屏蔽或资源移动）的实体。 其它所有的节点从当前DC获得配置和资源分配信息` Policy Engine (PE): 只要DC需要进行群集范围的更改（对新 CIB 作出反应），PE会根据当前集群状态和配置计算出下一个状态并反馈生成一列指令给DC。 PE通常在DC上运行。 Local Resource Manager (LRM): LRM是CRM的代理，代表 CRM 调用本地RA.它可以执行start/stop/monitor操作并把结果反馈给CRM。 并且可以隐藏不同RA(OCF,LSB)直接的差异。LRM 是其本地节点上所有资源相关信息的权威来源。 Resource Layer: RL包含不同的RA。RA是已写入的用来启动、停止和监视某种服务（资源）的程序（通常是shell脚本），仅能被LRM调用 3. vrrp 协议keepalived 是基于 vrrp 协议的，因此在搞清楚 keepalived 之前我们首先需要了解 vrrp 协议。 3.1 vrrp 协议概述VRRP(Virtual Router Redundancy Protocol) 虚拟路由器冗余协议，是一种容错协议，它保证当主机的下一跳路由器出现故障时，由另一台路由器来代替出现故障的路由器进行工作，从而保持网络通信的连续性和可靠性。 vrrp 架构如上图所示，vrrp 通过将多个路由器组成一个虚拟路由器，对外提供路由服务。虚拟路由器有自己的虚拟IP地址和虚拟MAC地址。局域网内的主机将虚拟路由器的IP地址设置为默认网关，通过虚拟路由器与外部网络进行通信。当主路由器发生故障时，自动选择一个备用路由器继续提供服务。 3.2 VRRP 术语在讲解 VRRP 工作过程之前，我们先来了解一下相关述语: 虚拟路由器： 由一个 Master 路由器和多个 Backup 路由器组成 主机将虚拟路由器当作默认网关。 VRID： 虚拟路由器的标识 有相同 VRID 的一组路由器构成一个虚拟路由器。 Master 路由器： 虚拟路由器中承担报文转发任务的路由器 Backup 路由器： Master 路由器出现故障时，能够代替 Master 路由器工作的路由器 虚拟 IP 地址： 虚拟路由器的 IP 地址 IP 地址拥有者： 接口 IP 地址与虚拟 IP 地址相同的路由器被称为 IP 地址拥有者 虚拟 MAC 地址： 一个虚拟路由器拥有一个虚拟 MAC 地址 3.3 工作流程 VRRP 工作时，首先需要选举出 Master 路由器，并且Master 路由器需要实时同步自己的状态信息，以让备用节点在主节点故障时及时替换，整个详细过程如下: Master 选举: 虚拟路由器中的路由器根据优先级选举出 Master。 Master 路由器通过发送免费 ARP 报文，将自己的虚拟 MAC 地址通知给与它连接的设备或者主机，从而承担报文转发任务 心跳信息: Master 路由器周期性发送 VRRP 报文，以公布其配置信息（优先级等）和工作状况； 故障转移: 如果 Master 路由器出现故障，虚拟路由器中的 Backup 路由器将根据优先级重新选举新的 Master； 虚拟路由器状态切换: Master 路由器由一台设备切换为另外一台设备，新的 Master 路由器只是简单地发送一个携带虚拟路由器的 MAC 地址和虚拟 IP 地址信息的免费 ARP 报文，这样就可以更新与它连接的主机或设备中的ARP 相关信息。网络中的主机感知不到 Master 路由器已经切换为另外一台设备。 抢占/非抢占: Backup 路由器的优先级高于 Master 路由器时，由 Backup 路由器的工作方式（抢占方式和非抢占方式）决定是否重新选举 Master 同时，为了提高安全性， VRRP 还提供了认证功能VRRP提供了三种认证方式： 无认证 简单字符认证：在一个有可能受到安全威胁的网络中，可以将认证方式设置为简单字符认证 MD5 认证：在一个非常不安全的网络中，可以将认证方式设置为 MD5 认证 3.4 工作模式 如果备用的路由只是备用，将会造成资源浪费，我们可以配置多个虚拟路由器组如上图所示: 三个路由器上配置了，三个虚拟路由器，每个虚拟路由器以某一个路由器为主服务器对外提供服务，另外两台路由器作为其备用路由器 前端主机可以将网关平均指向三个虚拟 IP，这样每个路由器都为部分主机提供了路由服务 这种模式我们称为 VRRP N/M 或 N/N 模式，即在一组路由上提供多个虚拟路由器。 4. keepalived4.1 keepalived 功能keepalived 是 vrrp协议的软件实现，原生设计的目的为了高可用ipvs服务，其提供了如下功能: 基于vrrp协议完成地址流动； 为vip地址所在的节点生成ipvs规则（在配置文件中预先定义） 为ipvs集群的各RS做健康状态检测； 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务，正是基于此功能，keepalived 才能实现高可用 nginx 4.2 keepalived 架构 如图，keepalived 由如下几个部分组成: vrrp stack: vrrp 协议的实现 ipvs wrapper: 生成 ipvs 规则 checkers: 后端服务器状态检测 watch dog: 监控进程 smtp: 邮件服务]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>高可用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 队列]]></title>
    <url>%2F2018%2F10%2F12%2Falog%2Fqueue%2F</url>
    <content type="text"><![CDATA[先进者先出，这就是典型的”队列”。 1. 特性我们知道，栈只支持两个基本操作：入栈 push()，出栈 pop()，队列与栈类似基本操作只有两个: 入队 enqueue() 向对尾添加一个数据，出队 dequeue() 从队列头部取出一个数据。 1.1 应用队列的应用非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。 队列可以应用在任何有限资源池中，用于排队请求。对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。 1.2 阻塞队列阻塞队列其实就是在队列基础上增加了阻塞操作。它有两个显著特征: 队列空时，从队头取数据会被阻塞，直到队列中有了数据才能返回 队列满时，向队尾插入数据会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回我们可以使用阻塞队列轻松实现一个“生产者，消费者模型”。 1.3 并发队列线程安全的队列我们叫作并发队列，最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。 实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 1.4 双端对列双端对列是一种类对列数据结构，支持在对列的头部和尾部都能进行插入和删除操作。Python 中的 collections.deque 就是一个双端对列的实现。 2. 实现跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。 2.1 顺序队列顺序队列的实现需要两个指针，head 指针指向队列头部，tail 指针指向队列尾部，即下一个入队元素将被保存的位置索引。显然随着不断的入队，出队 tail 指针出超过数组的索引范围，此时即便数组还有空闲位置也无法继续添加数据。此时借鉴在数组删除中介绍的方法，如果没有空间，我们只需要在下一次入队时集中触发以此数据移动操作，队列中的数据集中移动数组最前方即可。另一种解决方案则是使用循环队列。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class ArrayQueue(object): __CAPACITY__ = 10 def __init__(self): self.head = self.tail = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self.tail - self.head def is_empty(self): return len(self) == 0 def is_end(self): return self.tail == self._capacity def is_full(self): return len(self) == self._capacity def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) elif self.is_end(): self._move() self._buf[self.tail] = value self.tail += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') h = self._buf[self.head] self._buf[self.head] = 0 self.head += 1 if len(self) &lt; self._capacity / 4: self._resize(self._capacity / 2) return h def _resize(self, size): buf = [0] * size base = len(self) for i in range(base): vi = self.head + i buf[i] = self._buf[vi] self._capacity = size self._buf = buf self.head = 0 self.tail = base def _move(self): i = 0 base = len(self) while i &lt; base: self._buf[i] = self._buf[self.head + i] i ++ self.head = 0 self.tail = base 2.2 链式队列基于单链表的队列，我们在链表那一章已经包含在单链表的实现中。这里我们就基于双链表来实现一个队列，也把之前遗留的循环链表的实现补上。 12345678910111213141516171819202122232425262728293031323334353637383940class LinkedCircularQueue(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, nxt=None): self._element = element self._next = nxt def __init__(self): self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') self._size -= 1 node = self._tail._next if self.is_empty(): self._tail = None else: self._tail._next = node._next node._next = None value = node.element return value def enqueue(self, value): node = self._Node(value) if self.is_empty(): node._next = node else: node._next = self._tail._next self._tail._next = node self._tail = node self._size += 1 2.3 循环对列循环对列与顺序队列类似，但是通过循环利用底层的数组有效的避免了数据移动。循环队列实现相比顺序队列更复杂，有以下几点需要注意: 追加到队尾的元素的位置不在是 tail 而是要判断 tail 是否大于 n，如果大于插入位置则为 tail % n，同时更新 tail 应该更新为 tail % n + 1 队空的条件仍然是 tail == head 但是队列满的条件则为 (tail + 1) % n == head 下面是另外一种类似的实现方式，记录头节点和队列中的元素个数，而不是尾节点，个人觉得这种实现方式更加直观。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class ArrayCircularQueue(object): __CAPACITY__ = 10 def __init__(self): self._head = 0 self._size = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self._size def is_empty(self): return self._size == 0 def is_full(self): return self._size == len(self._buf) def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) vi = (self._head + self._size) % self._capacity self._buf[vi] = value self._size += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') value = self._buf[self._head] self._buf[self._head] = 0 self._head = (self._head + 1) % self._capacity if self._size &lt; self._capacity / 4: self._resize(self._capacity / 2) self._size -= 1 return value def _resize(self, size): buf = [0] * size for i in range(self._size): vi = (i + self._head) % self._capacity buf[i] = self._buf[vi] self._capacity = size self._buf = buf self._head = 0 2.4 双端对列链表那一章，我们实现了一个双向链表，在此基础上我们来实现一个双端队列。前面对双向链表的抽象实现是非常重要的，因为我们后面很多数据结构都是建立在双向链表的基础上。 12345678910111213141516171819202122from double_link import DoubleLinkclass LinkedDeque(DoubleLink): def __init__(self): super(LinkedDeque, self).__init__() def insert_first(self, value): self.insert_between(value, self._head, self._head._next) def insert_last(self, value): self.insert_between(value, self._tail._pre, self._tail) def delete_first(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._head._next) def delete_last(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._tail._pre) 2.5 并发对列一个基于 CAS 的无锁并发队列实现起来是很复杂的，我们暂时先把这个放一放，在这个系列的结尾会用专门的一篇文章来讲解实现。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.5 nginx线上部署示例]]></title>
    <url>%2F2018%2F10%2F12%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[nginx线上部署示例 1. nginx 线上部署示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115user nobody nobody;worker_processes 4;worker_rlimit_nofile 51200;error_log logs/error.log notice;pid /var/run/nginx.pid;events &#123; use epoll; worker_connections 51200;&#125;http &#123; server_tokens off; include mime.types; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 20m; client_body_buffer_size 256k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; default_type application/octet-stream; charset utf-8; client_body_temp_path /var/tmp/client_body_temp 1 2; proxy_temp_path /var/tmp/proxy_temp 1 2; fastcgi_temp_path /var/tmp/fastcgi_temp 1 2; uwsgi_temp_path /var/tmp/uwsgi_temp 1 2; scgi_temp_path /var/tmp/scgi_temp 1 2; ignore_invalid_headers on; server_names_hash_max_size 256; server_names_hash_bucket_size 64; client_header_buffer_size 8k; large_client_header_buffers 4 32k; connection_pool_size 256; request_pool_size 64k; output_buffers 2 128k; postpone_output 1460; client_header_timeout 1m; client_body_timeout 3m; send_timeout 3m; log_format main &apos;$server_addr $remote_addr [$time_local] $msec+$connection &apos; &apos;&quot;$request&quot; $status $connection $request_time $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; open_log_file_cache max=1000 inactive=20s min_uses=1 valid=1m; access_log logs/access.log main; log_not_found on; sendfile on; tcp_nodelay on; tcp_nopush off; reset_timedout_connection on; keepalive_timeout 10 5; keepalive_requests 100; gzip on; gzip_http_version 1.1; gzip_vary on; gzip_proxied any; gzip_min_length 1024; gzip_comp_level 6; gzip_buffers 16 8k; gzip_proxied expired no-cache no-store private auth no_last_modified no_etag; gzip_types text/plain application/x-javascript text/css application/xml application/json; gzip_disable &quot;MSIE [1-6]\.(?!.*SV1)&quot;; upstream tomcat8080 &#123; ip_hash; server 172.16.100.103:8080 weight=1 max_fails=2; server 172.16.100.104:8080 weight=1 max_fails=2; server 172.16.100.105:8080 weight=1 max_fails=2; &#125; server &#123; listen 80; server_name www.magedu.com; # config_apps_begin root /data/webapps/htdocs; access_log /var/logs/webapp.access.log main; error_log /var/logs/webapp.error.log notice; location / &#123; location ~* ^.*/favicon.ico$ &#123; root /data/webapps; expires 180d; break; &#125; if ( !-f $request_filename ) &#123; proxy_pass http://tomcat8080; break; &#125; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; server &#123; listen 8088; server_name nginx_status; location / &#123; access_log off; deny all; return 503; &#125; location /status &#123; stub_status on; access_log off; allow 127.0.0.1; allow 172.16.100.71; deny all; &#125; &#125;&#125; 2. tornado 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103upstream pyapi_prod &#123; server 10.80.85.26:9999 max_fails=3 fail_timeout=20s;&#125;upstream pyapi_pre &#123; server 10.81.33.246:9999 max_fails=3 fail_timeout=20s;&#125;upstream prediction_prod &#123; server 10.47.208.181:8083 max_fails=3 fail_timeout=20s;&#125;upstream crawlerLink_prod &#123; server 10.47.208.181:8086 max_fails=3 fail_timeout=20s;&#125;upstream crawlerLink_pre &#123; server 10.47.208.181:8087 max_fails=3 fail_timeout=20s;&#125;server &#123; #include drop.conf; listen 80; server_name pyapi.internal.enlightent.com pyapi.enlightent.com; location /prediction/ &#123; proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /crawlerLink/ &#123; proxy_pass http://crawlerLink_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location / &#123; proxy_pass http://pyapi_prod; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125;&#125;server &#123; #include drop.conf; listen 80; server_name pre.pyapi.internal.enlightent.com pre.pyapi.enlightent.com; location / &#123; proxy_pass http://pyapi_pre; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /prediction/ &#123; proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /crawlerLink/ &#123; proxy_pass http://crawlerLink_pre/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125;&#125; 3. pycgi1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;VirtualHost *:8083&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8084&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8085&gt; ServerName pre.pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8086&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8087&gt; ServerName pre.pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 栈]]></title>
    <url>%2F2018%2F10%2F11%2Falog%2Fstack%2F</url>
    <content type="text"><![CDATA[后进者先出，先进者后出，这就是典型的“栈”结构。 1. 特性栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。 2. 实现栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。 2.1 顺序栈顺序栈依赖一个能自动扩缩容的数组容器，我们可以像数组章节一样，自己实现一个数组容器，也可以直接使用 Python 内置的 list。list 的接口已经包含并大大超过了栈的可操作范围，这里我们采用一种称为”适配器模式”的通用方法，将栈操作委托给一个内部的 list 实例，来实现一个顺序栈。 这个实现起来很简单，就不写的过于复杂了。 1234567891011121314class ArrayStack(object): def __init__(self): self._buf = [] def __len__(self): return len(self._buf) def pop(self): if len(self._buf) &lt; 1: raise ValueError('stack is empty') return self._buf.pop() def push(self, value): self._buf.append(value) 2.2 链式栈在链表的头部插入和删除一个节点的时间复杂度都是 O(1)，因此我们很容易的就可以将链表的头部作为栈顶实现一个链式栈，并且我们的都不管链表的尾，链表只要维护一个指向头节点指针和自身大小的计数即可。 注意不要将链表的尾作为栈顶，虽然可以实现 O(1) 向链尾插入节点，但是删除尾节点需要遍历整个链表。在链表章节，我们已经实现了一个”超纲的”链式栈，这里就不再累述了。 3. 相关算法操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。这种栈被称为函数调用栈。除此之外诸如表达式求值，括号匹配以及实现浏览器的前进后退功能都与栈有关。 3.1 表达式求值对一个类似于 3-(1/4+7)*3 中缀表达式进行求值分成两步: 将中缀表达式转换为后缀表达式 对后缀表达式进行求值 这两步都用到了栈。为了简单起见，我们只处理+ - * / () 四种运算 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from stack import ArrayStackfrom operator import add, div, mul, subop_priority = &#123; '(': 1, '+': 2, '-': 2, '*': 3, '/': 3, ')': 4&#125;op_func = &#123; '+': add, '-': sub, '*': mul, '/': div&#125;def infix_to_postfix(expression): s = ArrayStack() r = [] expression = expression.split(' ') for e in expression: if e not in op_priority: r.append(e) elif e == '(': s.push(e) elif e == ')': if s.top() != '(': r.append(s.pop()) s.pop() else: while len(s) &gt; 0: t = s.top() if op_priority[t] &gt;= op_priority[e]: r.append(s.pop()) else: break s.push(e) while len(s) &gt; 0: r.append(s.pop()) return ''.join(r)def calculate_postfix(expression): s = ArrayStack() expression = expression.split(' ') for e in expression: if e not in op_priority: s.push(e) else: right = float(s.pop()) left = float(s.pop()) # print left, right value = op_func[e](left, right) s.push(value) return s.pop()def main(): print infix_to_postfix('( A + B ) * ( C + D )') print infix_to_postfix('A + B * C') print calculate_postfix('7 8 + 3 2 + /') print infix_to_postfix('6 / 3') print calculate_postfix('15 3 /') 3.2 括号匹配括号匹配有两个类似的问题，一个是类似于对形如 (1 + 2) + (10) 表达式检测括号是否成对出现；另一个更加常用的是检测 HTML 标签是否完整匹配。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from stack import ArrayStack# 括号匹配def per_check(expression): left = '(&#123;[' right = ')&#125;]' s = ArrayStack() expression = expression.replace(' ', '') for e in expression: if e in left: s.push(left.index(e)) elif e in right: i = right.index(e) if len(s) &lt;=0: return False elif i != s.pop(): return False if len(s) &gt; 0: return False return True# html 标签匹配def html_match(html_string): start = 0 s = ArrayStack() while start != -1: start = html_string.find('&lt;', start) if start == -1: break end = html_string.find('&gt;', start + 1) tag = html_string[start + 1: end] print tag if tag.startswith('/'): if len(s) &lt;= 0: return False else: top = s.pop() # print top, tag[1:] if top != tag[1:]: return False else: s.push(tag) start = end if len(s) &gt; 0: return False return Truedef main(): # print per_check('&#123;&#123;([][])&#125;()&#125;') # print per_check('()]') print html_match('&lt;a&gt;&lt;/a&gt;')if __name__ == "__main__": main() 3.3 浏览器的前进后退功能12345678910111213141516171819202122232425262728from stack import ArrayStackclass Browser(object): def __init__(self): self._back = ArrayStack() self._forward = ArrayStack() def back(self): """ :return: 后退 """ if len(self._back) &gt; 0: self._forward.push(self._back.pop()) def forward(self): """ :return: 前进 """ if len(self._forward) &gt; 0: self._back.push(self._forward.pop()) def new_click(self): """ :return: 打开新连接 """ while len(self._forward) &gt; 0: self._forward.pop() 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.4 nginx 四层代理和负载均衡]]></title>
    <url>%2F2018%2F10%2F11%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[nginx 四层代理和负载均衡 新版的 nginx 除了代理 http 服务外，还可以基于 stream 模块来实现四层协议的转发、代理或者负载均衡等等。与 LVS 不同的是，nginx 的四层代理依然工作在用户空间，”一手拖两家”，一边作为服务器接收用户请求，另一边作为客户端向后端服务器发送请求。四层的反代和负载均衡配置与 http 的反代和负载均衡基本类似。 1. 四层反代和负载均衡示例12345678910111213141516171819202122232425262728293031323334353637383940worker_processes auto;error_log /var/log/nginx/error.log info;events &#123; worker_connections 1024;&#125;stream &#123; upstream backend &#123; # stream 模块的 upstream 模块 hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; &#125; upstream dns &#123; server 192.168.0.1:53535; server dns.example.com:53; &#125; server &#123; listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend; &#125; server &#123; listen 127.0.0.1:53 udp reuseport; proxy_timeout 20s; proxy_pass dns; &#125; server &#123; listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; &#125;&#125; 2. ngx_stream_core_modulestream 模块使用 server { ... } 上下文来配置反代的四层服务，有如下特殊的配置指令 listenlisten address:port options Default: — Context: server 作用: nginx 反代服务监听的地址和端口 选项: [udp]: 默认为tcp协议, 指定监听udp协议的端口 [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 123456server &#123; listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend;&#125; 3. ngx_stream_proxy_modulengx_stream_proxy_module 主要来实现四层代理功能，其作用与提供的指令与 ngx_http_proxy_module 基本一致 proxy_pass address;proxy_pass address; Default: — Context: location, if in location 作用: 配置后端服务器 参数: address 为后端服务器的地址，可以 IP，域名, upstream 定义的服务器组 proxy_timeout timeout;proxy_timeout timeout; Default: proxy_timeout 10m; Context: stream, server 作用: 设置 nginx 与客户端和后端服务器，超过多长时间未传输数据时则断开链接 proxy_connect_timeout`proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 4. ngx_stream_upstream_modulengx_stream_proxy_module 主要来实现四层负载均衡功能，其作用与提供的指令与 ngx_http_upstream_module 基本一致 配置示例1234567891011121314stream &#123; upstream sshsrvs &#123; server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; &#125; server &#123; listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; &#125;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.3 nginx负载均衡器]]></title>
    <url>%2F2018%2F10%2F10%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[nginx负载均衡器 nginx http 的负载均衡功能主要由 ngx_http_upstream_module 提供，其作用是将后端服务器定义为 nginx 中的服务器组，然后将服务器组作为反向代理的目标。在反代请求时，服务器组首先通过配置的调度算法选择一个后端服务器，然后向其转发请求。因此服务器组是 nginx 负载均衡功能的核心组件。 服务器组在 nginx 中是通过 upstream 上下文定义的。upstream 上下文内有特定的配置选项，用于定制后端服务器的权重，调度算法，健康状态检测策略等等。 1. ngx_http_upstream_module1.1 定义 upstream 组upstream name { ... } Default: — Context: http 作用: upstream 上下文，用于定义服务器组 应用: 可被 proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, and grpc_pass 使用 12345upstream httpdsrvs &#123; server ... server... ...&#125; 1.2 upstream 服务器配置选项serverserver address [parameters]; Default: — Context: upstream 选项: weight=num : 权重 max_conns=number: 最大并发连接数 max_fails=number: 健康状态监测: 失败多少次将被标记为不可用，为 0 表示不做健康状态检测，默认为 1 fail_timeout=tim: 健康状态检测: 定义失败的超时时长，默认为 10s backup : 指定备用服务器(sorry server) down : 将服务器标记下线，灰度发布使用 slow_start=time : 慢启动，指平滑的将请求迁移到新增的服务器上 …其他商用版本参数 123456789101112131415161718192021222324# eg： upstream 配置示例http&#123; upstream dynamic &#123; ip_hash; zone upstream_dynamic 64k; server backend1.example.com weight=5; server backend2.example.com:8080 fail_timeout=5s slow_start=30s; server 192.0.2.1 max_fails=3; server backend3.example.com resolve; server backend4.example.com service=http resolve; server backup1.example.com:8080 backup; server backup2.example.com:8080 down; server unix:/tmp/backend3; &#125; server &#123; location / &#123; proxy_pass http://dynamic; health_check; &#125; &#125;&#125; keepalivekeepalive connections; Default: — Context: upstream 作用: 激活 nginx 与后端 upstream server 之间的持久连接功能 参数: connections 表示每个 workder 进程与后端服务器总共能保持的长连接数 1234567891011121314151617# eg: memcache 启动keepalive 长连接upstream memcached_backend &#123; server 127.0.0.1:11211; server 10.0.0.2:11211; keepalive 32;&#125;server &#123; ... location /memcached/ &#123; set $memcached_key $uri; memcached_pass memcached_backend; &#125;&#125; health_checkhealth_check [parameters]; Default: — Context: location 作用: 定义对后端主机的健康状态检测机制；只能用于location上下文； 选项: interval=time：检测频率，默认为每隔5秒钟； fails=number：判断服务器状态转为失败需要检测的次数； passes=number：判断服务器状态转为成功需要检测的次数； uri=uri：判断其健康与否时使用的uri； match=name：基于指定的match来衡量检测结果的成败，name 是 match 上下文定义的检测机制 port=number：使用独立的端口进行检测； 说明: 健康状态检测 upstream 内会自动对服务器组进行健康状态检测，但检测的是服务是否存在 health_check 可在特定应用内，按照特定的方式进行额外的健康状态检测 建议在此location 中关闭访问日志 仅Nginx Plus有效； 12345678910111213141516# eg: 健康状态检测http &#123; server &#123; ... location / &#123; proxy_pass http://backend; health_check match=welcome; &#125; &#125; match welcome &#123; status 200; header Content-Type = text/html; body ~ &quot;Welcome to nginx!&quot;; &#125;&#125; matchmatch{} 上下文用来定义衡量某检测结果是否为成功的衡量机制；有如下专用指令： status：期望的响应码； status CODE status ! CODE header：基于响应报文的首部进行判断 header HEADER=VALUE header HEADER ~ VALUE body：基于响应报文的内容进行判断 body ~ &quot;PATTERN&quot; body !~ &quot;PATTERN&quot; 需要注意的是 match{}, health_check 都进在仅Nginx Plus中有效 1.2 upstream 调度算法配置least_connleast_conn Default: — Context: upstream 作用: 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； least_timeleast_time header | last_byte [inflight]; Default: — Context: upstream 作用: 最短平均响应时长和最少连接； 参数: header：response_header; last_byte: full_response; 说明: 仅Nginx Plus有效； ip_haship_hash; Default: — Context: upstream 作用: 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； hashhash key [consistent]; Default: — Context: upstream 作用: 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； 参数: consistent 指定使用一致性hash算法； 123hash $request_uri consistent # 基于请求 url 进行绑定，lvs 的 DH算法hash $remote_addr # == ip_hashhash $cookie_name sticky用于实现基于 cookie的 session 绑定，只在商业版才能使用 1.3 http upstream 内置变量内置变量: $upstream_addr: 挑选的上游服务器地址 $upstream_cache_status: 缓存命中状态 12345# 自定义响应首部http &#123; add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 链表]]></title>
    <url>%2F2018%2F10%2F10%2Falog%2Flinkedlist%2F</url>
    <content type="text"><![CDATA[相比于数组必需使用连续的内存空间，链表通过“指针”将一组零散的内存块串联起来使用，因此更加灵活。 1. 特性我们知道数组受限于保持数据的连续，插入和删除都需要移动大量的数据，而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 1.1 性能比较由于数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 虽然常见的数组容器都支持动态扩容，但是当需要申请更大的内容容纳更多的数据，数据的拷贝操作是非常耗时的。 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 2. 实现链表有多种结构，常见的有单链表，双链表，循环链表。接下来我们就来介绍并实现这三种常见的链表。 2.1 单链表 单链表之所以叫”单”链表，是因为它的每个节点只保存了指向下一个节点的指针，而没有保存指向它自己的前一个节点的指针。因此在插入节点时，我们必需先获取插入位置之前的节点。 为了方便后续用链表去实现栈和队列，我们在单链表中显示的维护一个 _head 和_tail 的指针用于指向链表的首尾节点，并实现下面三个方法: 在链表的头部插入一个节点 删除链表的头节点 在链表尾部添加一个节点 因为我们必需遍历整个链表才能获取尾节点的前一个节点，所以很难高效的从单链表的尾部删除元素，所以我们不会实现一个删除尾节点的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class Link(object): class _Node(object): __slots__ = "_next", "_element" def __init__(self, element, nxt=None): self._next = nxt self._element = element def __str__(self): a = self._next b = [str(self._element)] while a: b.append(str(a._element)) a = a._next return '-&gt;'.join(b) def __init__(self): self._head = None self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def _insert_tail(self, element): """ :param element: :return: 链表尾部追加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: self._tail._next = node self._tail = node self._size += 1 def _remove_head(self): """ :return: 链表首部删除元素 """ if self.is_empty(): raise ValueError('link is empt') answer = self._head._element self._head = self._head._next self._size -= 1 if self.is_empty(): self._tail = None return answer def _insert_head(self): """ :return: 链表首部添加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: node._next = self._head self._head = node self._size += 1 # 栈方法 pop = _remove_head push = _insert_head # 堆方法 enqueue = _insert_tail dequeue = _remove_head 2.4 循环链表 循环链表跟单链表唯一的区别就在尾结点。单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题 双向链表的实现与单向链表大体上相同，除了尾节点的特殊处理。因此，我们暂时忽略循环链表的实现，等到下一章我们使用一个循环链表来实现一个队列，再来展示循环链表的实现。 2.3 双链表 双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。可以支持双向遍历，这样也带来了双向链表操作的灵活性。链表在插入和删除时必需先找到被操作节点的前驱节点，而单链表并不支持直接获取其前驱节点，必需从头开始重新遍历链表。而双向链表支持双向便利可直接获取，所以操作起来更加灵活。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 在双链表的实现中，我们将引入头哨兵和尾哨兵；使用哨兵可以帮助我们避免处理链表中没有节点时的特殊情况帮助我们简化双向链表的实现。这里可以与上面不使用哨兵的单向链表作对比。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class DoubleLink(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, pre=None, nxt=None): self._element = element self._next = nxt self._pre = pre def __init__(self): self._head = self._Node(None) self._tail = self._Node(None) self._head._next = self._tail self._tail._pre = self._head self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def insert_between(self, element, pre_node, next_node): """ :param element: :param pre_node: :param next_node: :return: 在两个节点之间插入一个节点 """ node = self._Node(element, pre=pre_node, nxt=next_node) pre_node._next = node next_node._pre = node self._size += 1 return node def delete_node(self, node): """ :param node: :return: 删除节点 """ element = node._element node._pre._next = node._next node._next._pre = node._pre self._size -= 1 node._pre = node._next = node._element = None return element 3. 相关算法相比与数组，链表写起来就很复杂，有如下一些算法，可以帮助我们练习链表。为了简化代码实现，下面所有函数的参数 link 都是 下面 Node 类的实例 123456789101112class Node(object): def __init__(self, data=None, nxt=None): self.data = data self.nxt = nxt def __str__(self): a = self.nxt b = [str(self.data)] while a: b.append(str(a.data)) a = a.nxt return '-&gt;'.join(b) 3.1 单链表反转123456789def reverse(link): pre = None pwd = link while pwd: # print pre.data, pwd.data # pwd.nxt, pwd, pre = pre, pwd.nxt, pwd pwd.nxt, pre, pwd = pre, pwd, pwd.nxt # pre, pwd.nxt, pwd = pwd, pre, pwd.nxt return pre 3.2 链表中环的检测12345678def has_cycle(link): one = double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if one is double: return True return False 3.3 两个有序链表的合并123456789101112131415161718def merge(link_one, link_two): link = Node() a = link_one b = link_two c = link while a and b: if a.data &lt; b.data: c.nxt = a a = a.nxt else: c.nxt = b b = b.nxt c = c.nxt if a is not None: c.nxt = a if b is not None: c.nxt = b return link.nxt 3.4 删除链表倒数第 n 个节点12345678910111213141516171819def delete_last(link, n): if link is None: return link pre = None first = link second = link for i in range(1, n): second = second.nxt if second is None: return None while second.nxt: second = second.nxt pre = first first = first.nxt if pre is None: return first.nxt else: pre.nxt = first.nxt return link 3.5 求链表的中间节点123456789101112def get_middle(link): if link is None or link.nxt is None: return link, None one = link double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if double.nxt is None: return one, None else: return one, one.nxt 3.6 基于链表实现 LRU 缓存算法实现思路如下: 我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 下面是相关的代码实现: 1234567891011121314151617181920# 基于双向链表 LinkedListclass LRU(object): def __init__(self, capacity=3): self.capacity = capacity self.num = 0 self.link = LinkedList() def cache(self, value): if self.num &lt; self.capacity: self.link.insert(0, value) self.num += 1 else: if self.link.remove(value): self.link.insert(0, value) else: del self.link[-1] self.link.insert(0, value) def __str__(self): return str(self.link) 实际上，我们可以继续优化这个实现思路，比如引入（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 如何在 Python 中进行单元测试]]></title>
    <url>%2F2018%2F10%2F09%2Funittest%2Funittest_01%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/zcabcd123/article/details/54892467]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>unittest</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.2 nginx反向代理facgi]]></title>
    <url>%2F2018%2F10%2F09%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi%2F</url>
    <content type="text"><![CDATA[nginx反向代理facgi 在讲解 httpd 的时候，我们说过通过 php 搭建一个 动态站点时，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 nginx 与 php 结合的话则只能通过 fpm，将 php 运行为独立的应用程序服务器，nginx 通过反代的模式与 fpm 结合起来。nignx 基于 ngx_http_fastcgi_module 模块就能作为 fastcgi 协议的客户端与 fpm 通信。本节我们就来详解 nignx fastcgi 反向代理的相关配置。 1. ngx_http_fastcgi_modulengx_http_fastcgi_module 提供的配置的参数与 ngx_http_proxy_module 提供的参数几乎完全相同，只是将开头的 http 换成的 fastcgi。 1.1 fastcgi 反向代理服务配置fastcgi_passfastcgi_pass address; Default: — Context: location, if in location 参数: address为fastcgi server的地址 fastcgi_indexfastcgi_index name; Default: — Context: http, server, location 作用: fastcgi默认的主页资源; fastcgi_paramfastcgi_param parameter value [if_not_empty]; Default: — Context: http, server, location 作用: 设置传递给后端 fastcgi serve 的参数 1234567891011121314151617# 配置示例1：# 前提：配置好fpm server和mariadb-server服务；location ~* \.php$ &#123; root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html$fastcgi_script_name; include fastcgi_params;&#125;# 配置示例2# 通过/pm_status和/ping来获取fpm server状态信息；location ~* ^/(pm_status|ping)$ &#123; include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;&#125; 1.2 fastcgi 缓存配置fastcgi_cache_pathfastcgi_cache_path path options Default: — Context: http 作用: 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； 选项: levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE keys_zone=name:size: k/v映射的内存空间的名称及大小 inactive=time: 非活动时长 max_size=size: 磁盘上用于缓存数据的缓存空间上限 fastcgi_cachefastcgi_cache zone | off; Default: fastcgi_cache off; Context: http, server, location 作用: 调用指定的缓存空间来缓存数据 fastcgi_cache_keyfastcgi_cache_key string; Default: — Context: http, server, location 作用: 定义用作缓存项的key的字符串； 1fastcgi_cache_key localhost:9000$request_uri; fastcgi_cache_methodsfastcgi_cache_methods GET | HEAD | POST ...; Default: fastcgi_cache_methods GET HEAD; Context: http, server, location 作用: 为哪些请求方法使用缓存； fastcgi_cache_min_uses`fastcgi_cache_min_uses number;`` Default: fastcgi_cache_min_uses 1; Context: http, server, location 作用: 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； fastcgi_cache_valid`fastcgi_cache_valid [code …] time;`` Default: — Context: http, server, location 作用: 不同的响应码各自的缓存时长； fastcgi_keep_connfastcgi_keep_conn on | off; Default: fastcgi_keep_conn off; Context: http, server, location 作用: 是否启动 nginx 于 fastcgi server 之间的长链接 1234567891011121314151617181920示例： fastcgi 缓存配置http &#123; ... fastcgi_cache_path /var/cache/nginx/fastcgi_cache levels=1:2:1 keys_zone=fcgi:20m inactive=120s; ... server &#123; ... location ~* \.php$ &#123; ... fastcgi_cache fcgi; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; ... &#125; ... &#125; ...&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.1 nginx反向代理http]]></title>
    <url>%2F2018%2F10%2F08%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http%2F</url>
    <content type="text"><![CDATA[nginx反向代理http 26 章我们讲解了 nginx 作为 web 服务的应用，除了 web 服务功能，nginx 还能作为七层的反向代理实现负载均衡功能。本章我们就来讲解 nginx 的另两项主要功能: 反向代理服务器 负载均衡调度器 nginx 是高度模块化的，只要nginx 具有实现了相关协议的模块，就可以作为相关的反向代理服务器。ngx_http_proxy_module 是 http 反向代理模块，ngx_http_fastcgi_module 是 fastcgi 协议的反代模块。 在介绍 LVS 的负载均衡集群时，我们对 LVS 和 nginx 的负载均衡能力就进行的比较。nginx 作为七层的负载均衡器，能获取应用层的报文信息，因此提供了更多的功能。但是由于工作于用户空间，需要通过套接字与客户端和后端服务器进行交互，所以并发能力受到系统套接字数量的限制。 在讲解 nginx 之前，我们再来回顾一下 LB集群的软件方式 四层调度: lvs, nginx(stream module), haproxy(mode tcp) 七层调度: nginx(http_up_stream module), haproxy(mode http) nginx 的 http 模块，和 stream 模块都具有 up_stream 模块 http 的 up_stream 主要是用来负载均衡 http 服务的 stream 本身只是一个能基于四层协议的反代模块，stream 的 up_stream 则是用来负载这类服务的 nginx 是高度模块化，http 的反向代理功能主要由 ngx_http_proxy_module 模块提供，本节我们来讲解如何将 nginx 配置成一个 http 的反向代理服务器，内容包括: nginx 七层反向代理原理 反向代理服务器参数配置 后端服务配置 代理缓存配置 http 首部字段配置 超时时长配置 1. nginx 七层反向代理原理2. ngx_http_proxy_module123456# http 反向代理示例location / &#123; proxy_pass http://localhost:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;&#125; 2.1 后端服务配置proxy_passproxy_pass URL 作用: 指定被代理的后端服务器 参数: URL=http://IP:PORT[/PATH] Default: — Context: location, if in location, limit_except 123locations url_pattern&#123; proxy_pass URL&#125; nginx 通过 proxy_pass URL 传递 location 匹配到的 url 时存在一些规则和限制 proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri，效果是 nginx 会将 location 匹配到的剩余部分直接附加在 URL 后，传递给后端服务器，所以 locations 与 URL 通常是要么都以 / 结尾，要么都不以 / 结尾。 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； 1234567891011121314151617181920212223# 1.location /uri/ &#123; proxy http://hos[:port];&#125;http://HOSTNAME/uri --&gt; http://host/uri# 2.location /uri/ &#123; proxy http://host/new_uri/;&#125;http://HOSTNAME/uri/ --&gt; http://host/new_uri/location /uri/ &#123; proxy http://host/new_uri; # 错误，要么都以 `/` 结尾，要么都不以 `/` 结尾。&#125;http://HOSTNAME/uri/test --&gt; http://host/new_uritest# 3.location ~|~* /uri/ &#123; proxy http://host;&#125;http://HOSTNAME/uri/ --&gt; http://host/uri/； 2.2 代理缓存配置proxy_cache_pathproxy_cache_path path options Default: — Context: http 作用: 定义可用于proxy功能的缓存 options: [levels=levels]: 缓存的目录结构层级 keys_zone=name:size: 缓存区域名称即内存大小 [inactive=time]: 非活动链接的检测时间间隔 [max_size=size]: 缓存的文件所占用的最大磁盘大小 proxy_cacheproxy_cache zone | off Default: proxy_cache off; Context: http, server, location 作用: 指明要调用的缓存，或关闭缓存机制 参数: zone: proxy_cache_path 定义的缓存 proxy_cache_keyproxy_cache_key string Default: proxy_cache_key $scheme$proxy_host$request_uri; Context: http, server, location 作用: 缓存中用于“键”的内容； proxy_cache_validproxy_cache_valid [code ...] time; Default: — Context: http, server, location 作用: 定义对特定响应码的响应内容的缓存时长； 参数: code: 响应码 time: 缓存时长 proxy_cache_methodsproxy_cache_methods GET | HEAD | POST ... Default: proxy_cache_methods GET HEAD; Context: http, server, location 作用: 只对哪些方法获取的内容进行缓存 proxy_cache_use_staleproxy_cache_use_stale param Default: proxy_cache_use_stale off; Context: http, server, location 作用: 被代理服务器响应失败时，是否使用过期缓存进行响应 参数: 可选值包括 error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off ...; proxy_cache_min_usesproxy_cache_min_uses number Default: proxy_cache_min_uses 1; Context: http, server, location 作用: proxy_path 定义的 inactive 非活动时间内，最少被访问多少次才不会被清理 proxy_cache_bypassproxy_cache_bypass string ... Default: — Context: http, server, location 作用: 在何种情况下，nginx 将不从缓存中取数据 12345678910111213141516171819202122# 缓存配置示例http &#123; proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; # 配置 server &#123; ... location / &#123; proxy_pass http://backend; proxy_cache cache_zone; # 使用 proxy_cache_key $uri; proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_use_stale error timeout http_500 http_502 http_503; proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment; proxy_cache_bypass $http_pragma $http_authorization; &#125; &#125;&#125; 2.3 代理 header 设置proxy_set_headerproxy_set_header field value Default: proxy_set_header Host $proxy_host; proxy_set_header Connection close; Context: http, server, location 作用: 设定发往后端主机的请求报文的请求首部的值 12proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for proxy_hide_headerproxy_hide_header field; Default: — Context: http, server, location 作用: 禁止 nginx 将哪些从后端服务器接收的响应传递给客户端，默认情况下 nignx 已经禁止将 “Date”, “Server”, “X-Pad”, and “X-Accel-…” 发送给客户端，此选项的配置值会附加到禁止列表中。 2.4 超时设置proxy_connect_timeout`proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 与后端服务器建立链接的超时时长 proxy_read_timeoutproxy_read_timeout time; Default: proxy_read_timeout 60s; Context: http, server, location 作用: nginx 向接收后端服务器响应时，两次报文之间的超时时长 proxy_send_timeoutproxy_send_timeout time; Default: proxy_send_timeout 60s; Context: http, server, location 作用: nginx 向后端服务器发送请求时，两次报文之间的超时时长 3. ngx_http_headers_modulengx_http_headers_module 允许 nginx 配置发给用户的响应报文的 header add_headeradd_header name value [always]; Default: — Context: http, server, location, if in location 作用: 向响应报文中添加自定义首部； 12add_header X-Via $server_addr;add_header X-Accel $server_name; expiresexpires [modified] time;expires epoch | max | off; Default: expires off; Context: http, server, location, if in location 作用: 用于定义Expire或Cache-Control首部的值，或添加其它自定义首部；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 数组]]></title>
    <url>%2F2018%2F10%2F08%2Falog%2Farray%2F</url>
    <content type="text"><![CDATA[数组和链表应该是数据结构与算法中最基础的数据结构。与链表相比，数组更加简单，所以相比于数组的实现和与之相关的算法，充分认识数组的内在特性反而更加重要。 1. 特性数组（Array）是一种线性表数据结构，用一组连续的内存空间，来存储一组具有相同类型的数据。正是由于连续的内存空间和存储相同类型数据的特性，使得数组支持基于下标的“随机访问”。但是也正是为了维持这种连续的特性，使得数组的插入和删除操作必需作大量的数据移动，因为数组内不能”弯曲”也不能出现”空洞”。 1.1 插入如果数组是有序的，插入一个新的元素到第 k 位置则必需移动 k 之后的所有数据；但是如果数组中的数据本身是无序的，我们可以直接将第 k 位的数据移动到数组元素的最后，再把新的元素插入到原来的第 k 位以避免大量的数据移动。 1.2 删除数组的删除与插入类似，如果要删除第 k 位的元素，为了保证数组内的连续行，也需要移动大量的数据，不然数组就会出现空洞，内存就不连续了。如果数据内的数据是有序，则这种移动不可避免，如果是数组是无序的，可以直接用数组最后的元素覆盖第 k 位的元素。 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。我们可以将多次删除操作集中在一起执行，来提高删除的效率。我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。 1.3 动态扩容因为需要为数组分配连续的内存空间，因此数组在使用前就需要预先确定好大小。当需要向满的数组中插入数据时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。数组的插入，删除以及由此待来的动态扩容是非常基础的操作，因此大多数编程语言除了基本的底层数组之外，都提供了包含丰富接口的数组容器，方便程序员编程适用，比如 Python 中的列表(list)。 1.4 数组与数组容器的使用选择何时使用数组何时使用编程语言提供的数组容器，专栏-数据结构与算法之美给了下面的一些建议: 容器都有额外的性能损耗，如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 2. 实现列表和元组是 Python 提供的数组容器，它们都是引用结构，即 list 内部的底层数组存储的不是元素本身，而是列表元素的内存地址，这些内存地址指向每个列表元素。 除了数组容器之外，array 和 ctypes 提供了创建原始底层数组(即保存的不是内存地址而是元素本身的原始数组)的方法。array 模块提供的 array 类只支持基于 C 语言的原始数据类型，不支持用户自定义的数据类型，自定义类型的底层数组由 ctypes 这个底层模块提供。 下面我们就以 ctypes 提供的底层数组为基础创建了一个类似 list 的数组容器。这里的实现并不完备，目的是为了展示 Python list 的底层实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import ctypesclass DynamicArray(object): def __init__(self): self._n = 0 # 列表当中实际存储的元素个数 self._capacity = 1 # 当前分配的底层数组，能存储的元素个数 self._buf = self._make_array(self._capacity) # 底层数组的引用 def __len__(self): return self._n def __getitem__(self, item): """ :param item: :return: 简单起见，只支持简单的正向索引 """ if 0 &lt;= item &lt; self._n: return self._buf[item] raise IndexError('%s out of range' % self.__class__.__name__) def append(self, value): if self._n == self._capacity: self._resize(size= 2 * self._capacity) self._buf[self._n] = value self._n += 1 def _resize(self, size): """ :param c: :return: 底层数组的动态扩容 """ buf = self._make_array(size) for i in xrange(self._n): buf[i] = self._buf[i] self._buf = buf self._capacity = size @staticmethod def _make_array(size): """创建一个指定大小的底层数组""" return (size * ctypes.py_object)() def insert(self, k, value): if self._n == self._capacity: self._resize(2 * self._capacity) for i in xrange(self._n, k, -1): self._buf[i] = self._buf[i - 1] self._buf[k] = value self._n += 1 def remove(self, value): """ :param value: :return: 删除第一值等于 value 的元素 """ for i in xrange(self._n): if self._buf[i] == value: for j in xrange(i, self._n - 1): self._buf[j] = self._buf[j + 1] self._buf[self._n - 1] = None # 删除最后一个元素的引用，以便被回收 self._n -= 1 return raise ValueError('value not found') 3. 相关算法与数组专门相关的算法并不多，因为太底层了。这里我们介绍两个: 用数组实现的位图以及凯撒密码 3.1 位图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import arrayimport numbersclass BitMap(object): def __init__(self): self._buf = array.array('L') # 'L' 表示 32 位无符号的整数 @staticmethod def __check(num): if not (isinstance(num, numbers.Integral) and num &gt;= 0): raise ValueError("num is not unsigned int") return num / 32, num % 32 def __len__(self): return len(self._buf) def __getitem__(self, item): return self._buf[item] def __iter__(self): return iter(self._buf) def __contains__(self, item): i, b = self.__check(item) return i &lt; len(self._buf) and (self._buf[i] &amp; (1 &lt;&lt; b)) def __str__(self): r = [] # print self._buf for i in xrange(len(self._buf)): if self._buf[i]: for j in xrange(32): if self._buf[i] &amp; (1 &lt;&lt; j): r.append(32 * i + j) return str(r) def add(self, num): i, b = self.__check(num) while i &gt;= len(self._buf): self._buf.append(0) self._buf[i] |= (1 &lt;&lt; b) def union(self, bit_map): for i, v in enumerate(bit_map): if i &lt; len(self._buf): self._buf[i] |= v else: self._buf.append(v)def main(): bm = BitMap() bm.add(1) bm.add(144) bm.add(9) bm.add(9) print bm print 9 in bm print 8 in bm y = BitMap() y.add(9) y.add(42) print y bm.union(y) print bm 3.2 凯撒密码有关凯撒密码的说明，大家可以看看百科的说明:凯撒密码 12345678910111213141516171819202122class CaesarCipher(object): def __init__(self, shift): self.encode = [(chr(ord('A') + (i + shift) % 26)) for i in range(26)] self.decode = [(chr(ord('A') + (i - shift) % 26)) for i in range(26)] print self.encode print self.decode def encrypt(self, message): return self._transform(message, self.encode) def decrypt(self, message): return self._transform(message, self.decode) @staticmethod def _transform(message, code): m = list(message) r = [] for i in m: if i.isupper(): t = code[ord(i) - ord('A')] r.append(t) return ''.join(r) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.7 LVS 高可用]]></title>
    <url>%2F2018%2F10%2F07%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[LVS 高可用 前面我们搭建的负载均衡集群，一旦调度器发生故障，整个服务将不可用，我们需要对其进行高可用。keepalived 是 LVS 高可用最简单有效的解决方案，但是本节我们先不会讲解 keepalived，后面有一个章的内容专门讲解。本节的目的是通过对 LVS 高可用的讲解，让大家理解高可用集群中的重要概念，特别是健康状态检测。 1. LVS 的单点故障LVS 的单点故障 Director不可用，整个系统将不可用，这是整个集群的单点故障所在 解决方案: 高可用 实现: keepalived，heartbeat/corosync 某RS不可用时，Director依然会调度请求至此RS； 解决方案：对各RS的健康状态做检查，失败时禁用，成功时启用； 实现: keepalived, heartbeat/corosync, ldirectord 对于后端服务器的健康状态检测应该是调度器本身所具有的功能，但是因为 LVS 工作的太多底层，所以 LVS 本身不具有此功能，其需要借助外部工具来实现。 keepalived 是帮助 LVS 实现高可用的，但是额外也能帮助 LVS 实现健康状态检测，并且在服务器状态发生变化时，完成 ipvs 对服务器的增删操作。ldirectord 则主要就是为了帮助 LVS 做后端状态检测，并且在服务器状态发生变化时，完成对服务器的增删操作，除此之外没有别的功能。 1.1 健康状态检测对服务器的健康状态检测理解，可以从检查机制，检查后的操作进行理解 检查机制检查机制: 又称检查方法，即通过什么方式，怎么判断服务器已经故障或已恢复 检查方法: 网络层检测: ping 主机 传输层检测: 端口探测，检测服务端口是否存在 应用层检测: 某关键资源是否能被请求到 判断方式: 很显然，我们不能因为某一次检测失败就判定后端服务器故障，因为有可能网络出现问题，也有可能服务器繁忙还没来得及响应。因此我们需要经过多次检测结果来判断服务器的状态。 12# 服务器状态转换第一次故障时 --------&gt; 软状态 ----&gt; 多次故障 ------&gt; 硬状态(真正认定为故障) 2. ldirectord2.1 安装ldirectord 的rpm 包下载链接ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/network:/ha-clustering:/Stable/CentOS_CentOS-6/x86_64/ldirectord-3.9.5-3.1.x86_64.rpm 1234567891011$ rpm -ql ldirectord/etc/ha.d # 配置文件目录/etc/ha.d/resource.d/etc/ha.d/resource.d/ldirectord # 主程序链接/etc/init.d/ldirectord/etc/logrotate.d/ldirectord/usr/lib/ocf/resource.d/heartbeat/ldirectord/usr/sbin/ldirectord # 主程序/usr/share/doc/ldirectord-3.9.5/usr/share/doc/ldirectord-3.9.5/COPYING/usr/share/doc/ldirectord-3.9.5/ldirectord.cf # 配置文件示例 2.2 配置需要在注意的是 ldirectord 会自动根据配置文件及后端服务器可用状态生成规则，因此无需在使用 ipvsadm 创建集群。 1234567891011121314151617181920212223242526272829303132cp /usr/share/doc/ldirectord-3.9.5/ldirectord.cf /etc/ha.d/vim /etc/ha.d/ldirectord.cf# 配置示例# Global Directiveschecktimeout=3 # 检测的超时时长checkinterval=1 # 检测的频率，单位秒fallback=127.0.0.1:80 # 所有后端服务器都不可用，最后的备用服务器，sorry serverautoreload=yes # 配置文件修改时，是否自动加载logfile=&quot;/var/log/ldirectord.log&quot;#logfile=&quot;local0&quot;#emailalert=&quot;admin@x.y.z&quot; # 通知管理员#emailalertfreq=3600 # 故障未修复，每隔多长时间发一次邮件#emailalertstatus=all # 对哪些状态改变发送邮件quiescent=no# virtual 对应于 LVS 一个集群virtual=3 real=192.168.1.107:80 gate 2 # RS real=192.168.1.109:80 gate 1 fallback=127.0.0.1:80 gate service=http scheduler=wrr #persistent=600 #netmask=255.255.255.255 checktype=negotiate checkport=80 request=&quot;index.html&quot; #receive=&quot;CentOS&quot; #virtualhost=www.x.y.z # 向哪个 httpd 的虚拟机主机发送请求]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 数据结构与算法学习开篇]]></title>
    <url>%2F2018%2F10%2F07%2Falog%2Falgo_start%2F</url>
    <content type="text"><![CDATA[数据结构与算法前前后后已经学习了很长时间，从一开始看《数据结构与算法分析:C语言描述》，到后来看 Python 相关实现《Problem Solving with Algorithms and Data Structures using Python》，但是一直感觉不得其法。 究其原因，一方面是自己对 C 语言一知半解，所以一开始练习太少；另一方面是工作中使用太少，知识这种东西只有到达一定的熟练程度才能真正发现其作用。现在有幸在极客时间订阅了王争老师的专栏数据结构与算法之美，看过之后感觉很好，相比与之前看的书籍有很好的发散和扩展，恰逢《数据结构与算法：python语言实现》也刚刚面市。所以决定下定决心在 2018 最后三个月好好重新学习数据结构与算法。因此就有了这个系列的博客，希望监督自己多加练习。 本系列博客会按照专栏数据结构与算法之美的结构组织，也会从中摘录部分内容，在此特地申明，也非常推荐大家订阅此专栏。然后会以《数据结构与算法：python语言实现》作为辅助来扩展内容，并且在每篇文章的最后，我会尽可能给出与当篇文章相关的 linkcode 习题。 当然作为自己的博客，目的不是复制别人的内容，是想对常用的数据结构作一个总结，然后督促自己动手实现这些数据结构和算法。最后想说一句，数据结构和算法看起来没用，我们平时大多数使用的都是语言内置好的容器和现成的函数，我们只需要知道它们的功能，无需关注它们的实现细节，我们也能写出我们的程序。但是程序的效率很大程度上依赖锁使用组件的效率，我们不关注这些细节，可能别人已经写好了，但是我们却没正确的使用。Python 就有以本书叫《Python: Faster Way》，如果我们对 Python 常见数据结构有所了解，其时很自然的就会明白它们上面所说明的用法。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.6 防火墙标记和LVS持久链接]]></title>
    <url>%2F2018%2F10%2F06%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8CLVS%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[防火墙标记和LVS持久链接 前面我们演示了如何使用 LVS 创建一个负载均衡服务，然而在生产环境中，我们可能要同时调度两个及以上的集群服务。典型的情景是，同时部署了 http，https 服务，用户浏览网页的时候使用的 http 服务，当用户登陆或支付时因为 http 是明文的不安全，此时必需切换成 https。如果这个两个服务是单独调度，很有可能用户登陆之后被重新调度到其他服务器上，这样用户原有的缓存就会丢失。所以我们必需将 http，https 作为一组服务进行同一调度，这就需要使用到防火墙标记。我们本节我们就来演示如何使用LVS 统一调度 http，https 服务。 1. 防火墙标记 FWM要想将一组RS的集群服务统一进行调度，我们需要借助 iptables 的防火墙标记功能(FWM) 首先在 director iptables 的 mangle 表的 PREROUTING 链上对一组服务标打上同样的防火墙标记 然后基于FWM 定义集群服务，让 ipvs 对相同标记的服务进行统一调度 2. http/https 统一调度示例上一节我们基于 LVS-DR 配置了一个 http 服务，在此基础上我们继续配置一个 https 服务，并将它们统一调度 2.1 RS https 服务https 的负载均衡 首先各个 RS 密钥和证书文件必需一致 ssh 回话会大量的耗费系统资源，因此服务器会对 ssh 会话进行缓存，为了使缓存生效，lvs 必需使用 sh 算法进行调度，但是 sh 算法会影响负载均衡的效果 如果负载均衡器是 nginx 我们可以在调度器上进行 ssh 会话的建立和缓存，发送到后端服务器请求就可以直接基于 http 协议。我们称这种方式为 ssh 会话拆除。但是 LVS 是工作在内核上，无法理解 ssh 会话，也就做不到 ssh 会话拆除。 1234567891011121314151617181920# 1. VS 上私建 CA# CA(umask 077;openssl genrsa -out private/cakey.pem 2048)openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365# 证书(umask 077;openssl genrsa -out /root/http.key 2048)openssl req -new -key /root/http.key -out /root/http.csr -days 365openssl ca -in /root/http.csr -out /root/http.crt -days 365# 2. RS 的 https 服务配置scp /root/http.* root@192.168.1.107:/etc/httpd/sslyum install mod_sslvim /etc/httpd/cond/ssl.conf# 3.验证 https 服务# 在客户端导入证书scp /etc/pki/CA/cacert.pem root@192.168.1.106:/root/vim /etc/hosts # 添加域名curl --cacert /root/cacert.pem "https://www.tao.com/test.html" 2.2 VS 集群服务配置12345678910111213141516case $1 instart) iptables -F ipvsadm -C iptables -t mangle -A PREROUTING -d 192.168.1.99 -p tcp -m multiport --dports 443,80 -j MARK --set-mark 3 ipvsadm -A -f 3 -s sh ipvsadm -a -f 3 -r 192.168.1.107 -g -w 1 ipvsadm -a -f 3 -r 192.168.1.109 -g -w 1 ;;stop) iptables -F ipvsadm -C ;;esac 2.3 测试1for i in &#123;1..10&#125;;do curl --cacert /root/cacert.pem "https://www.tao.com/test.html";curl --cacert /root/cacert.pem "http://www.tao.com/test.html";done 3. lvs persistencelvs 持久连接 功能: 实现无论使用任何调度算法，在一段时间内，能够实现将来自同一个地址的请求始终发往同一个RS； 实现: lvs 的持久连接模板，独立于调度算法存在 类型: PPC: 每个端口对应定义为一个集群服务，每集群服务单独调度； PFWMC: 基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity； PCC: 基于0端口定义集群服务，即将客户端对所有应用的请求统统调度至后端主机，必须定义为持久模式； 启用: ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] -p [timeout]: 使用 -p 参数就可以启用 lvs 持久链接功能，默认为 360 秒 12345678910# PPC:ipvsadm -A -t 192.168.1.99:80 -s rr -p [600]ipvsadm -a -t 192.168.1.99:80 -r 192.168.1.107 -gipvsadm -a -t 192.168.1.99:80 -r 192.168.1.109 -g# PFWMC -- 基于防火墙标记定义集群服务即可ipvsadm -A -f 10 -s rr -p [600]# PCC -- 端口定义为 0，此时必需使用 -p 选项ipvsadm -A -t 192.168.1.99:0 -s rr -p [600]]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.5 LVS DR模型实战]]></title>
    <url>%2F2018%2F10%2F05%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4_DR%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[LVS DR模型实战 本节我们将搭建一个 LVS-DR 的负载均衡集群。 1. 网络拓扑结构 拓扑结构说明: VS， RS1， RS2 在虚拟机内均采用桥接方式，桥接到物理机的网卡上 VIP 配置在 DIP 所在网卡的别名上 2. lvs-dr 配置示例2.1 RS 配置脚本12345678910111213141516171819202122232425262728293031#!/bin/bashvip="192.168.1.99"case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce iptables -F ifconfig lo:0 $vip netmask 255.255.255.255 broadcast $vip up route add -host $vip dev lo:0 ;;stop) ifconfig lo:0 down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esacecho "/proc/sys/net/ipv4/conf/all/arp_ignore:" `cat /proc/sys/net/ipv4/conf/all/arp_ignore`echo "/proc/sys/net/ipv4/conf/lo/arp_ignore:" `cat /proc/sys/net/ipv4/conf/lo/arp_ignore`echo "/proc/sys/net/ipv4/conf/all/arp_announce:" `cat /proc/sys/net/ipv4/conf/all/arp_announce`echo "/proc/sys/net/ipv4/conf/lo/arp_announce:" `cat /proc/sys/net/ipv4/conf/all/arp_announce` 2.2 VS 配置脚本123456789101112131415161718192021222324#!/bin/bashvip="192.168.1.99"ifc="enp0s3:0"port=80rs1="192.168.1.107"rs2="192.168.1.109"case $1 instart) ifconfig $ifc $vip netmask 255.255.255.255 broadcast $vip up iptables -F ipvsadm -A -t $vip:$port -s wrr ipvsadm -a -t $vip:$port -r $rs1 -g -w 1 ipvsadm -a -t $vip:$port -r $rs2 -g -w 1 ;;stop) ipvsadm -C ifconfig $ifc down ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esac]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.4 LVS nat模型实战]]></title>
    <url>%2F2018%2F10%2F04%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4_NAT%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[LVS nat模型实战 本节我们将搭建一个 LVS-NAT 的负载均衡集群。 1. 网络拓扑结构 2. lvs-nat 配置1234567891011121314151617181920212223242526# 1. 配置 RS# - 配置 ip 地址# - 配置 httpd# - 关闭 iptables# - 关闭 SELinux# 2. 配置 Director ipvssysctl net.ipv4.ip_foward=1ipvsadm -A -t 192.168.1.254:80 -s rripvsadm -a -t 192.168.1.254:80 -r 172.16.0.251 -m -w 1ipvsadm -a -t 192.168.1.254:80 -r 172.16.0.252 -m -w 1ipvsadm -L -nipvadm -S -n &gt; /etc/sysconfig/ipvsadmipvsadm-save -n &gt; /etc/sysconfig/ipvsadmipvsadm -Cipvsadm -R &lt; /etc/sysconfig/ipvsadm# 修改规则ipvsadm -E -t 192.168.1.148:80 -s shipvsadm -L -nipvsadm -e -t 192.168.1.148:80 -r 172.16.0.2:8080 -m # 不行ipvsadm -d -t 192.168.1.148:80 -r 172.16.0.2]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.3 LVS 调度算法和 ipvsadmin]]></title>
    <url>%2F2018%2F10%2F03%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[LVS 调度算法和 ipvsadmin 命令使用 上一节我们对 LVS 的工作原理和四种模型下如何实现负载均衡做了简单介绍，本节我们来学习 LVS 种可用的调度算法以及 ipvsadmin 命令的使用。 1. lvs 调度算法LVS 的调度算法分为静态方法和动态方法两类 1.1 静态算法静态方法: 仅根据算法本身进行调度 RR: round robin, 轮调 WRR: weighted rr, 加权轮调 SH: source hash, 源地址哈希，实现 session 保持的机制 – 来自同一个IP的请求始终调度至同一RS DH: destination hash，目标地址哈希，将对同一个目标的请求始终发往同一RS 1.2 动态算法动态方法: 根据算法及各 RS 的当前负载(Overhead)状态进行调度 LC: Least Connection Overhead = Active * 256 + Inactive WLC: Weighted LC Overhead = (Active * 256 + Inactive) / weight SED: Shortest Expection Delay Overhead = (Active + 1) * 256 / weight NQ: Never Queue, 按照 SED 进行调度，但是被调度的主机，在下次调度时不会被选中 – SED 算法改进 LBLC: 定义: Locality-Based LC，即动态的 DH 算法 作用: 正向代理情形下的 cache server 调度 LBLCR: 定义: Locality-Based Least-Connection with Replication 带复制的LBLC算法 特性: 相对于 LBLC，缓存服务器之间可以通过缓存共享协议同步缓存 2. ipvsadm2.1 ipvsadmin 简介使用 ipvsadmin 定义一个负载均衡集群时 首先要定义一个集群，然后向集群内添加 RS。 一个 ipvs 主机可以同时定义多个集群服务 一个 cluster server 上至少应该有一个 real server 在适用 ipvsadmin 定义集群服务之前，首先要确定 ipvs 已在内核中启用。Centos 的 /boot/config-VERSION 文件内记录了编译内核的所有参数，通过此文件查看 ipvs 配置参数即可确定 ipvs 是否启用。 12345678910111213141516171819202122232425262728293031# 查看 ipvs 在内核中是否启用，及其配置$ grep -i -A 10 "IP_VS" /boot/config-3.10.0-514.el7.x86_64CONFIG_IP_VS=mCONFIG_IP_VS_IPV6=y# CONFIG_IP_VS_DEBUG is not setCONFIG_IP_VS_TAB_BITS=12## IPVS transport protocol load balancing support#CONFIG_IP_VS_PROTO_TCP=yCONFIG_IP_VS_PROTO_UDP=yCONFIG_IP_VS_PROTO_AH_ESP=yCONFIG_IP_VS_PROTO_ESP=yCONFIG_IP_VS_PROTO_AH=yCONFIG_IP_VS_PROTO_SCTP=y## IPVS scheduler#CONFIG_IP_VS_RR=mCONFIG_IP_VS_WRR=mCONFIG_IP_VS_LC=mCONFIG_IP_VS_WLC=mCONFIG_IP_VS_LBLC=mCONFIG_IP_VS_LBLCR=mCONFIG_IP_VS_DH=mCONFIG_IP_VS_SH=mCONFIG_IP_VS_SED=mCONFIG_IP_VS_NQ=m 2.2 ipvsadmin 程序包组成1234567$ yum install ipvsadm$ rpm -ql ipvsadm/etc/sysconfig/ipvsadm-config # 默认的规则保存文件/usr/lib/systemd/system/ipvsadm.service # unit file/usr/sbin/ipvsadm # 主程序/usr/sbin/ipvsadm-restore # 规则保存工具/usr/sbin/ipvsadm-save # 规则重载工具 ipvs 直接附加在内核之上，只要内核正常运行，ipvs 即可工作。ipvs 的 Unit file 主要是在启动时加载规则，在关闭时保存规则而已 1234567891011121314151617# cat /usr/lib/systemd/system/ipvsadm.service[Unit]Description=Initialise the Linux Virtual ServerAfter=syslog.target network.target[Service]Type=oneshot# start 加载规则ExecStart=/bin/bash -c &quot;exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm&quot;# stop 保存规则ExecStop=/bin/bash -c &quot;exec /sbin/ipvsadm-save -n &gt; /etc/sysconfig/ipvsadm&quot;ExecStop=/sbin/ipvsadm -CRemainAfterExit=yes[Install]WantedBy=multi-user.target 2.3 ipvsadm 使用ipvsadm命令的核心功能： 集群服务管理：增、删、改； 集群服务的RS管理：增、删、改； 集群的查看 集群服务管理ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 作用: 集群服务的增，改 选项: -A: 添加集群服务 -E: 修改集群服务 -t|u|f service-address: 指定集群的作用的协议，地址和端口，唯一标识一个集群 -t: TCP协议 VIP:TCP_PORT -u: UDP协议，VIP:UDP_PORT -f：firewall MARK，是一个数字 -s scheduler: 调度算法，默认为 wlc ipvsadm -D -t|u|f service-address 作用: 删除集群服务 选项: -t|u|f service-address: 指定删除的集群 ipvsadm -C 作用: 清空定义的所有内容 管理集群服务上的 RSipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 作用: 添加或修改集群服务的 RS 选项: -a: 添加 RS -e: 修改 RS -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 -g|i|m: 指定lvs类型，默认为 m -g: gateway, dr类型 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight: 权重 ipvsadm -d -t|u|f service-address -r server-address 作用: 删除集群服务上的 RS 选项: -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 查看ipvsadm -L|l [options] 作用: 查看集群状态信息 选项: --numeric, -n: 基于数字格式显示ip和端口 --connection，-c: 显示当前的连接 --exact: 显示统计数据精确值 --stats: 显示统计数据 --rate : 显示速率 ipvsadm -Z [-t|u|f service-address] 作用: 清空集群的计数器 选项: -t|u|f service-address:指定管理的集群 规则保存和重载ipvsadm -R 作用: 重载 == ipvsadm-restore ipvsadm -S [-n] 作用: 保存 == ipvsadm-save]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.2 LVS 4层负载均衡原理]]></title>
    <url>%2F2018%2F10%2F02%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[LVS 4层负载均衡原理 本节我们先来讲解 LVS 实现负载均衡的原理，内容包括: LVS nginx 工作层级 LVS 负载均衡原理 LVS 负载均衡的四种模型 1. LVS nginx 工作层级 要想区分 lvs 与 nginx 实现负载均衡的区别，关键是要明白它们工作在TCP/IP 协议哪个层级。12.1 计算机网络基础知识 我们详细讲解过 TCP/IP 协议。计算机网络被分成两个层次，通信子网和资源子网，应用层是资源子网位于用户空间，下四层位于内核空间。应用层想进行网络通信，必需通过套接子接口向内核发起系统调用，而 Linux 上套接子的数量是有数量限制的。 LVSLVS 是四层的负载均衡器又称为四层路由器，四层交换机，位于内核空间，直接附加在 iptables netfilter 的 nat 表的 INPUT 链上。可直接根据请求报文的目标 IP 和 port 向后端服务器转发报文，无需创建套接字，因此没有套接字数量的限制。 LVS 通过修改请求报文的或IP地址或端口或 MAC 地址直接将报文转发至后端服务器，后端服务器看到的请求依然可能是用户的IP而与中间转发的主机无关。 nginxngxin/haproxy 则工作在应用层，同时充当服务器端和客户端，作为服务器接收外部用户请求，再作为客户端向后端服务器发起请求，将用户请求转发给后端服务器。整个过程需要创建套接字以完成网络通信，所以存在套接字数量限制。 应用对比相比于 nginx，LVS 在实际的生产环境中使用相对较少，原因有以下几点: 大多数企业并没有达到使用 LVS 进行负载均衡的规模，通常情况下使用 nginx，haproxy 就可以很好的完整负载均衡任务 LVS 工作于内核，没有很好的用户端工具，也没有操作更高应用级别的能力，比如无法通过 cookie 进行转发，所以没有 nginx/haproxy 易用 当企业的并发请求超过套接子的限制时，更加倾向于通过硬件实现负载均衡。 但是 LVS 仍然不失为高并发下负载均衡的有效解决方案，而且LVS 是我们理解其他负载均衡集群非常重要的组件，同时 LVS 也是面试重点，因此我们还是要学好 LVS。 实际工作环境中，如果并发请求达到了使用 LVS 的级别，通常采用二级调度的方式，第一级是 LVS，第二级是 nginx/haproxy. 2. LVS 负载均衡原理 如上图所示 LVS 由两个部分组成: ipvs: 工作于内核空间中 netfilter INPUT 链上的钩子函数 ipvsadmin: ipvs 的用户空间命令行工具，用于向 ipvs 添加集群服务和规则 我们需要通过ipvsadmin 向 ipvs 添加监听的服务和对应的集群。当请求报文到来时: 经过第一次路由决策，发往本机的报文会由 PREROUTING 到达 INPUT 附加在 INPUT 的 ipvs 会根据 ipvs 上集群服务的IP，协议和端口来判断报文是否需要向后端的集群进行转发 如果是需要转发的报文，LVS 会根据配置的调度算法，选择集群中某一台主机，将请求报文直接送往 POSTROUTING链转，转发至该服务器 LVS 有 4 种工作类型，不同类型下，LVS 会相应的修改请求报文的 ip，端口或 mac 地址，以将报文转发至目标服务器 因此对于 LVS 而言，报文的在内核的流经顺序为 PREROUTING --&gt; INPUT --&gt; POSTROUTING 3. LVS 术语及架构3.1 LVS 组成LVS(Linux Virtual Server) 由 VS, RS 两个部分组成 VS：Virtual Server, 负载均衡的调度器，又称为 Director, Dispatcher, Balancer rs：Real Server, 真正提供服务的集群服务器，又称为 upstream server, backend server 3.2 LVS的类型(架构)LVS 有四种不同的类型，这四中类型的工作流程实现就是我们接下来讲解的重点: lvs-nat: Network Address Translation，多目标IP的DNAT，通过修改请求报文的目标IP完整转发 lvs-dr: Direct Routing，直接路由，通过重新封装新的MAC地址完成转发 lvs-tun:IP Tunneling，在原请求IP报文之外新加一个IP首部 lvs-fullnat:修改请求报文的源和目标IP，非标准实现 3.3 LVS-NAT(MASQUERADE) 附注: IP 命名: VIP：Virtual IP DIP: Director IP RIP: Real Server IP CIP：Client IP LVS-NAT 就是一个多用途的 DNAT(iptables) 通过修改请求报文的目标IP地址(端口)至挑选出的某RS IP 地址实现转发。相比与 DNAT 只能将报文转发至固定主机，LVS-NAT 可以根据调度算法选择转发的后端主机。LVS-NAT 具有如下一些特征: RS(RIP),DIP应该使用私有地址；RS的网关必须指向DIP； 请求和响应都要经过Director；高负载场景中，Director易成为性能瓶颈； 支持端口映射； vs必须是Linux系统，rs可以是任意系统； RS 的 RIP 和 Director 的 DIP 必须在同一 IP 网络 3.4 LVS-DR(GATEWAY) LVS-DR 通过修改请求报文的目标 MAC 地址进行转发。如上图所示，报文经过了如下的转发过程: VS 接收到来自用户的请求报文 VS 通过调度算法选择一个 RS，通过修改请求报文的目标 MAC 地址为该 VS 的 mac 地址直接向其转发请求报文。因为 VS 必需要能获取 RS 的 MAC 地址，所以 RS 与 VS 必需位于同一物理网络中 RS 接收到响应报文后无需经过 VS 直接向客户端进行响应。因为客户端请求的目标地址是 VIP，所以 RS 进行响应的源地址必需是 VIP，否则客户端不会接收响应。 那我们如何确保 RS 响应的源地址是 VIP 呢？ 首先我们需要在所有的 RS 的网卡上添加 VIP 的 IP 地址 因为 VS 和 RS 都绑定了 VIP ，我们需要保证前端路由将目标地址为VIP的报文统统发往 VS，而不能发往 RS Linux 上响应报文的源IP，是由其发出的第一块网卡上的IP 地址决定，因此我们必需设置 RS 的路由条目，让所有的响应报文从 VIP 所在的网卡发出。 那我们如何保证前端路由将目标地址为VIP的报文统统发往 VS，而不能是 RS 呢？有三种方法: 在前端路由器上静态绑定 VS VIP 地址所在网卡的 MAC 地址；问题是未必有路由操作权限，且无法为 VS 实现高可用，因为 VS 发生故障转移时，VS 所在的服务器就会发生变化，VIP 所在的网卡也就发生了变化。 使用 aprtables 在 RS 上拒绝对 VIP 的 arp 响应和通告，aprtables 类似防火墙的工作于物理层，可通过 MAC 过滤，使用复杂不便于配置 修改RS上内核参数，将RS上的VIP配置在lo接口的别名上，并限制lo接口的 arp 通告和响应，这样就能阻断 RS 对 VIP 地址的解析请求，这是最佳的解决方案。 因此 VIP 必需配置的 lo 接口的别名上，同时必需设置路由，强制让响应报文先经过 lo 接口，再通过内核的转发功能从网卡发出。 LVS-DR 具有如下特征: RS可以使用私有地址；但也可以使用公网地址，此时可通过互联网通过RIP对其直接访问； RS跟Directory必须在同一物理网络中，以便能基于物理地址做转发； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS可以是大多数常见的OS； RS的网关绝不允许指向DIP； 3.5 LVS-TUN(IPIP)LVS-NAT 需要 RS 的网关必需指向 DIP，因此 RS 和 VS 必需位于同一网段中，LVS-DR VS 需要能获取到 RS 的 MAC 地址，因此 VS 和 RS 必需位于同一物理网段中；通常的传输介质，比如双绞线最大的传输距离也就只有 100 米，所以 VS 和 RS 必需位于同一机房内，所以如果各 RS 不再同一位置，比如为了灾备在不同地方分别放置了集群服务器，这两种模式就无法使用。 LVS-TUN 类似 LVS-DR 不过其能跨越地理位置的限制。 LVS-TUN 不修改请求报文的 ip 首部，而是通过在原有的 ip 首部之外，在封装一个 ip 首部。真个请求响应过程如下图所示。 与 LVS-DR 相同的是每个 RS 都必须配置 VIP，并将 VIP 所在网卡作为响应报文的出口以确保响应报文的源IP 为 VIP。但是 RS 无需限制 ARP 的通告和响应，因为此时 VS 与 RS 不再同一网络中。RS 上配置的 VIP 不会影响请求报文到达 VS，因为 VIP 不可能位于 RS 的网段中，因此 RS 中 VIP 是不可达网络，不能接收到发送到 VIP 的请求。 因为额外添加一层 IP 首部，因此 RS 必需要支持隧道协议，否则无法解析转发的报文。同时额外增加的 IP 首部会增加报文大小，如果刚好使得报文从小于 MTU 变成大于 MTU，则会发生报文拆分降低传输速度，因此 VS 上最好能针对这种情况自动拆分报文。 LVS-TUN 具有如下特性: RIP、VIP、DIP全部是公网地址； RS的网关不会也不可能指向DIP； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS的OS必须支持隧道功能； 3.6 LVS-FULLNATLVS-TUN 虽然能跨越地理位置的限制，但是配置起来不便，很少使用。为了满足跨越机房的需求，LVS 有第四种非标准实现 LVS-FULLNAT。LVS-FULLNAT 未收录进内核，要使用需要自己编译内核才能使用。 LVS-NAT 只修改了请求报文的目标地址，因此 RS 进行响应时，为了让目标地址为 CIP 经过 VS，必需将 RS 的网关设置为 RS。LVS-FULLNAT 会同时修改请求报文的目标地址和源地址进行转发， 这样 RS 的响应报文的目标地址为 DIP 而不是 CIP，报文经过路由一定到达 VS，因此 就可以跨越同一网络的限制。 LVS-FULLNAT具有如下特性: VIP 是公网地址，RIP 和 DIP 是私网地址，二者无须在同一网络中 RS 接收到的请求报文的源地址为 DIP，因此要响应给 DIP 请求报文和响应报文都必须经由 Director 支持端口映射 RS 可以使用任意 OS 3.7 总结 lvs-nat, lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIP； lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信； lvs-dr, lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun：通过在原IP报文之外封装新的IP首部实现转发，支持远距离通信 4. arp 内核控制参数LVS-DR 模型中，我们说到可以通过内核参数来控制 arp 的通告和响应，arp_ignore, apr_announce 就是控制参数。每个网卡都有对应 arp_ignore, apr_announce 控制参数 123456789101112$ ls /proc/sys/net/ipv4/confall default lo virbr0 virbr0-nic wlp1s0# all 表示所有网卡$ ll /proc/sys/net/ipv4/conf/lo/|grep arp-rw-r--r--. 1 root root 0 9月 7 09:51 arp_accept-rw-r--r--. 1 root root 0 9月 7 09:51 arp_announce-rw-r--r--. 1 root root 0 9月 7 09:51 arp_filter-rw-r--r--. 1 root root 0 9月 7 09:51 arp_ignore-rw-r--r--. 1 root root 0 9月 7 09:51 arp_notify-rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp-rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp_pvlan 4.1 arp_ignorearp_ignore 作用: 控制系统在收到外部的arp请求时，是否要返回arp响应 取值: 主要有0，1，2，3~8较少用到 0: 响应任意网卡上接收到的对本机IP地址的arp请求（包括环回网卡上的地址），而不管该目的IP是否在接收网卡上。 1: 只响应目的IP地址为接收网卡上的本地地址的arp请求 2: 只响应目的IP地址为接收网卡上的本地地址的arp请求，并且arp请求的源IP必须和接收网卡同网段。 3: 如果ARP请求数据包所请求的IP地址对应的本地地址其作用域（scope）为主机（host），则不回应ARP响应数据包，如果作用域为全局（global）或链路（link），则回应ARP响应数据包 4~7: 保留未使用 8: 不回应所有的arp请求 图示 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址允许响应。 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址不允许响应。 4.2 arp_announcearp_announce 作用: 控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址 取值: 0：允许使用任意网卡上的IP地址作为arp请求的源IP，通常就是使用数据包a的源IP。 1：尽量避免使用不属于该发送网卡子网的本地地址作为发送arp请求的源IP地址。 2：忽略IP数据包的源IP地址，选择该发送网卡上最合适的本地地址作为arp请求的源IP地址。 图示 arp_announce=0 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址仍然为 lo 接口的 IP。 arp_announce=1 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址重新选择为 eth1 的IP 地址。 4.3 修改 arp 参数1234echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/eth1/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/eth1/arp_announce]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.1 架构拓展及集群介绍]]></title>
    <url>%2F2018%2F10%2F01%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[架构拓展及集群介绍 前面我们已经介绍了，如何使用 nginx 或 httpd 部署一台 web 服务器，但是受限于单太服务器的资源，一台服务器能提供的响应能力有限。因此从本章开始，我们将从最简单 LAMP/LNMP 出发，不断向其添加组件来扩展我们的 web 服务框架，以提供更快，更稳定的服务。本章我们开始讲解第一个组件，如何使用 LVS 实现一个负载均衡集群，内容包括: web 架构拓展和集群简介 LVS 负载均衡原理 LVS 的 NAT 模型 LVS 的 DR 模型 负载均衡集群除了 LVS 之外还有多种其他实现包括 nginx，haproxy,我们会在后面详细介绍。 1. 架构拓展单台计算受限于本地的存储资源，计算资源等各种资源的额限制，单台服务的响应能力有限。比如我们的单台 nginx 服务最多能并发响应 2 万个用户。当并发请求数超过此限制时，我们有两种优化方式: 换一台计算能力更强的计算机，这种方式我们称之为向上扩展(scale up) 将并发请求按照特定的调度算法分散到多台计算上，这种方式称为向外扩展(scale out)，多台计算的组合就称为集群(cluster) 集群主要分为三类，此处的用于分散用户请求的集群称为负载均衡集群(Loader Balance Cluster)。分散用户请求有一个前提，每个用户请求都是独立可分离的。然后这可能会存在一些问题: 难以完全追踪用户状态，因为用户可能会被调度到不同的机器上 某用户的写操作会被单台服务器所承载，当对新上传资源的请求被调度到其他服务器，将无法获取此资源 对于第一个问题，web 服务通常使用 cookie 和 session 追踪用户，我们需要想办法让集群内的所有服务器能共享 session 信息，这样就能追踪用户状态。session 共享有三种方式: session 绑定，将来自同一用户的请求始终发送同一服务器，这种方式并没有共享 session，当服务器挂机之后 session 可能会丢失，因此需要 session 持久化。用户识别有两种方式，一是 IP，而是用户 cookie，因为 SNAT的存在 cookie 更准确 session 复制集群，每个服务器都拥有集群上所有服务器的 session 会话，因为 session 会在集群内传输，会极大的占用带宽与内存资源。 session 服务器，将 session 保存在共享的内存服务器中，每台服务器从session 服务器中获取 session。但此时 session 服务器是单点故障所在(Single Point of Failure, SPoF) 对于第二个问题，我们可以将用户写操作放到共享存储上。通常用户的数据分为三类，我们可以将其分别存放在不同存储介质中 结构化数据，通常存放在关系型数据库中 半结构化数据，通常存放在 NoSql 中，比如 mongo 非结构化数据，比如图片，我们可以存在分布式文件系统之上 用户的请求需要分散到多台服务器上，负责分散用户请求的服务器称为负载均衡器或分发器或调度器。因此我们的 web 服务框架将如下所示。调度器在分发用户请求时，有不同的调度算法，会依据不同的标准分发请求。 此时负载均衡服务器将是最大的单点故障所在，我们需要对其做冗余。我们需要提供另一台备用服务器，当负载均衡服务器迭机之后，能够取代其继续提供服务。这种提供冗余能力的服务器组合我们称为高可用集群(High Availability)。 2. 集群介绍前面我们提到了两类集群，集群(Cluster) 总共可分为三类: LB：负载均衡集群 Load Balancing HA：高可用集群，High Availability,实现包括 HP：高性能集群 High Performance， HP 集群作用在于集合 CPU，以提供更高的计算能力，最典型应用就是现在的超级计算机。当前企业面临情景主要是海量数据，以及由海量数据引发的大数据计算，HP 只能提供高的计算能力，并没有拓宽计算机的存储能力，所以 HP 集群再企业中应用很少(我是这么理解的)。企业对大数据的计算是通过分布式系统进行的。 2.1 LB 集群LB 有多种实现，包括软件实现和硬件实现: 软件实现有: lvs, haproxy(mode tcp) (传输层) haproxy, nginx (应用层) ats(apache traffic server) 硬件实现有: F5 BIG-IP Citrix Netscaler A10 A10 Array Redware 不同实现工作不同的协议层次上,按照工作的协议层次 LB集群可以划分为 传输层: 通用，包括lvs, nginx(stream), haproxy(mode tcp) 应用层: 专用，只能应用于特定协议，包括 http: nginx(http), httd, haproxy(mode http) fastcgi: nginx, httpd mysql: ProxySQL 2.2 HA 集群HA：高可用集群，常见实现包括 heartbeat corosync + pacemaker RHCS: cman + rgmanager cman + pacemaker keepalived HA 集群主要是提供系统稳定性，衡量系统稳定性有一个评价标准: A=MTBF/(MTBF + MTTR) MTBF: 系统可用时间 MTTR: 平均修复时间 这个计算公式就是我们通常所说的 3个9(99.9%)，4个9(99.99%). 2.3 分布式系统分布式系统包括分布式存储和分布式计算。对于分布式存储依据存储的是海量小文件还是单个大文件，有不同的实现方式。在后面的高级部分，我们会有专门章节来详细讲解。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.5 nginx_http配置段(功能模块)]]></title>
    <url>%2F2018%2F09%2F25%2Flinux_mt%2F26-nginx%2Fnginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx_http配置段(核心模块) 本节是 nginx http 配置的第三部分。上一节我们讲解了 http_core_codule 提供的配置指令，本节我们来讲解 http 的各种功能模块提供的配置指令，内容包括: 功能模块 访问控制 开启状态页 url重写和自定义日志格式 访问日志配置 文本压缩 https 服务配置 fastcgi 配置 1. 功能模块1.1 访问控制12345678910111213141516171819allow IP/Network;deny IP/Netword;# 作用: 基于 ip 的访问控制, all 表示所有# 模块: ngx_http_access_module模块auth_basic string | off;# 作用: 基于用户的访问控制# 模块: ngx_http_auth_basic_module模块auth_basic_user_file# 作用: 账号密码文件# 产生: 建议使用 htppasswd 创建location /admin/ &#123; auth_basic &quot;only for adminor&quot;; auth_basic_user_filer /etc/nginx/user/.httppasswd; &#125;htpasswd -c -m /path/user/.passwd tom 1.2 开启状态页模块: ngx_http_stub_status_module 模块 12345678910111213141516171819location /status &#123; stub_status on; allow 172.16.0.0/16; deny all;&#125;stub_status &#123;on|off&#125;;# 作用: 是否开启状态页，用于输出nginx的基本状态信息# 附注: 仅能用于 location 上下文# 显示:# Active connnections: 当前所有处于打开状态的连接数# server accept handled requests # n1 n2 n3# - n1：已经接受的客户端请求的总数；# - n2：已经处理完成的客户端请求的总数；# - n3：客户端发来的总的请求数；# Reading: n Writing: w Waiting: t# - Reading: 处于读取客户端请求报文首部的连接的连接数；# - Writing: 处于向客户端发送响应报文过程中的连接数；# - Waiting: 处于等待客户端发出请求的空闲连接数； 1.3 url 重写与自定义日志模块: ngx_http_rewrite_module 模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960rewrite regex replacement flag;# 作用: url 重写# eg: rewrite ^/images/(.*\.jpg)$ /imgs/$1 break;# flag:# last: 默认# 一旦被当前规则匹配并重写后立即停止检查后续的其它rewrite的规则，# 然后用重写后的规则再从头开始执行 rewriter 检查；# break:# 一旦被当前规则匹配并重写后立即停止后续的其它rewrite的规则，# 而后通过重写后的规则重新发起请求# 且不会被当前的location 内的任何 rewriter 规则所检查；# redirect: 以302临时重定向返回新的URL；# permanent: 以301永久重定向返回新的URL；# 说明:# last,break 只会发生在 nginx 内部，不会与客户端交互，客户端收到的是正常的响应# redict, permanent 则是直接返回 30x 响应，跨站重写必需使用 redirect或permanent# 如果 last 发生死循环，nginx 会在循环 10 此之后返回 50x 响应return code [text];return code URL;return URL;# 作用: 停止进程并返回特定的响应给客户端，非标准的 444 将直接关闭链接，且不会发送响应rewrite_log on | off;# 作用: 是否开启重写日志；# 示例server &#123; ... rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra last; return 403; ...&#125;location / &#123; rewriter ^/bbs/(.*)$ /forum/$1 break; rewriter ^/bbs/(.*)$ https://www.tao.com/$1 redirect; # http --&gt; https &#125;if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1;&#125;if ($request_method = POST) &#123; return 405;&#125;if ($slow) &#123; limit_rate 10k;&#125;if ($invalid_referer) &#123; return 403;&#125; 1.4 日志配置模块: ngx_http_log_module 模块 12345678910111213141516171819log_format name string ...;# 作用: string可以使用nginx核心模块及其它模块内嵌的变量；access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];# 作用: 访问日志文件路径，格式及相关的缓冲的配置；# buffer=size: 日志缓冲区大小# flush=timeaccess_log off;# 作用: 关闭记录日志功能，open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];open_log_file_cache off;# 作用: 缓存各日志文件相关的元数据信息；# 参数: # max：缓存的最大文件描述符数量；# min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项；# inactive：非活动时长；# valid：验正缓存中各缓存项是否为活动项的时间间隔 1.5 文本压缩模块: ngx_http_gzip_module： 123456789101112131415161718192021222324252627282930313233gzip on | off;# 作用: 是否启用压缩功能gzip_comp_level level;# 作用: 设置压缩级别，1-9gzip_disable regex ...;# 作用: 对哪些浏览器禁用压缩# 参数: regex 用于匹配请求报文 &quot;User-Agent&quot; 头信息gzip_min_length length;# 作用: 启用压缩功能的响应报文大小阈值；gzip_buffers number size;# 作用: 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小；gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...;# 作用: nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的；# 选项:# off：对代理的请求不启用# no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的# Cache-Control的值为此三者中任何一个，则启用压缩功能；gzip_types mime-type ...;# 作用: 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；gzip on;gzip_comp_level 6;gzip_min_length 64;gzip_proxied any;gzip_types text/xml text/css application/javascript; 2. https 服务配置模块: ngx_http_ssl_module模块12345678910111213141516171819202122232425262728293031ssl on | off;# 作用: 是否 sslssl_certificate file;# 作用: 当前虚拟主机使用PEM格式的证书文件；ssl_certificate_key file;# 作用:当前虚拟主机上与其证书匹配的私钥文件；ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];# 作用: 支持ssl协议版本，默认为后三个；ssl_session_cache off | none | [builtin[:size]] [shared:name:size];# 作用: 是否缓存 sll 会话# 选项:# builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有；# [shared:name:size]：在各worker之间使用一个共享的缓存；# 说明: 如果用户请求被不同的 worker 处理时，私有缓存可能时效，因此应该使用公共缓存ssl_session_timeout time;# 作用: 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长；server &#123; listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; # 1m 空间大约能缓存 4000 个会话&#125; 3. 防盗链模块: ngx_http_referer_module模块 1234567891011121314151617181920212223valid_referers none | blocked | server_names | string ...;# 作用: 定义referer首部的合法可用值；# 参数: # none：请求报文首部没有referer首部；# blocked：请求报文的referer首部没有值；# server_names：参数，其可以有值作为主机名或主机名模式；# arbitrary_string：直接字符串，但可使用*作通配符；# regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*\.magedu\.com；$invalid_referer# 作用: 内置的变量，表示当前请求 referer首部是否不符合 valid_referers 定义的规则#配置示例：valid_referers none block server_names *.magedu.com *.mageedu.com magedu.* mageedu.* ~\.magedu\.;if($invalid_referer) &#123; return http://www.magedu.com/invalid.jpg;&#125;valid_referers none blocked server_names *.example.com example.* www.example.org/galleries/ ~\.google\.;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.4 nginx_http配置段(核心模块)]]></title>
    <url>%2F2018%2F09%2F24%2Flinux_mt%2F26-nginx%2Fnginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx_http配置段(核心模块) 本节我们来讲解 http 配置的第二部分，http 配置段的配置。nginx 没有中心主机的概念，所以 web 服务包括默认的都是虚拟主机，直接支持基于ip，端口和主机名的虚拟主机。http 配置段用于配置 ngnix 的 web 服务器，由ngx_http_core_codule 和其他众多的 http 功能模块组成。本节我们首先来讲解 http_core_codule 提供的配置指令，内容包括 http 配置段简介 配置框架 内置变量 if 上下文 http 基础配置 虚拟主机定义 访问路径配置 索引及错误页配置 网络连接相关的设置 客户端请求的限制 文件操作的优化 客户端请求的特殊处理 内存及磁盘资源分配 1. http 配置段简介1.1 http 配置段框架http配置段的框架如下所示，其遵循以下一些原则 必须使用虚拟机来配置站点；每个虚拟主机使用一个server {}段配置； 非虚拟主机的配置或公共配置，需要定义在server之外，http之内； 与 http 相关的指令仅能够放置于 http、server、location、upstream、if 上下文，某些指令只能用于 5 中上下文中的某一种 12345678910111213141516171819202122232425262728http &#123; sendfile on; # 各server的公共配置 tcp_nopush on; ...： upstream &#123; # 配置反向代理 ...... &#125; server &#123; # 定义一个虚拟主机；nginx支持使用基于主机名或IP的虚拟主机 # 每个 server 类似于 httpd 中的一个 &lt;virtualHost&gt; listen; server_name; root; alias; # 类似 http 中的 &lt;location&gt;, 用于定义URL与本地文件系统的关系 location URL &#123; if .... &#123; .... &#125; &#125; &#125; server &#123; &#125; ...&#125; 1.2 http核心模块的内置变量http核心模块常用的内置变量: $uri: 当前请求的uri，不带参数； $request_uri: 请求的uri，带完整参数； $host: http请求报文中host首部； 如果请求中没有host首部，则以处理此请求的虚拟主机的主机名代替； $hostname: nginx服务运行在的主机的主机名； $remote_addr: 客户端IP $remote_port: 客户端Port $remote_user: 使用用户认证时客户端用户输入的用户名； $request_filename: 用户请求中的URI经过本地root或alias转换后映射的本地的文件路径； $request_method: 请求方法 $server_addr: 服务器地址 $server_name: 服务器名称 $server_port: 服务器端口 $server_protocol: 服务器向客户端发送响应时的协议，如http/1.1, http/1.0 $scheme: 在请求中使用scheme, 如https://www.magedu.com/中的https； $http_HEADER: 匹配请求报文中指定的HEADER， $http_host匹配请求报文中的host首部 $sent_http_HEADER: 匹配响应报文中指定的HEADER， 例如$http_content_type匹配响应报文中的content-type首部； $document_root:当前请求映射到的root配置； 1.3 if 上下文http 配置段内的 if 上下文可以根据 nginx 内的变量执行判断逻辑 语法: if (condition) {.....} 应用: 可应用在 server, location 上下文中 condition: 基于 nginx 变量的测试表达式，支持以下几种测试方式 变量是否为空: 变量名为空串，或者以”0”开始，为 false，否则为 true 比较操作: = ！= 正则表达式模式匹配 ~: 区分大小写 ~*: 不区分大小写 !~ !~*: 表示取反 测试是否为文件: -f !-f 测试是否为目录: -d 测试文件存在性: -e 检查文件是否有执行权限: -x 123456# if 使用示例server &#123; if ($http_user_agent ~* MSIE) &#123; rewrite ^(.*)$ /mise/$1 break; &#125;&#125; 2. http 服务配置nginx 中所有路经都是 uri，nginx 会按照配置的 uri，按照当前配置文件重新查找一次，以找到匹配的文件。 2.1 虚拟主机定义123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 8080 default_server; server_name www.httttao.com; root &quot;/vhost/web/&quot;;&#125;# 作用: 定义一个虚拟主机# 特性: nginx支持使用基于主机名或IP的虚拟主机listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILElisten address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] # 作用: 指定监听的地址和端口# 参数:# default_server：设定为默认虚拟主机；# ssl：限制仅能够通过ssl连接提供服务；# backlog=number：后援队列长度；# rcvbuf=size：接收缓冲区大小；# sndbuf=size：发送缓冲区大小；server_name [...];# 作用: 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串；# 过程: 当nginx收到一个请求时，会取出其首部的server的值，而后跟众server_name进行比较，# * 匹配任意长度字符串# ~ 正则表达式模式匹配# 主机名匹配顺序如下：# 先做精确匹配；www.magedu.com# 左侧通配符匹配；*.magedu.com# 右侧通配符匹配；www.abc.com, www.* # 正则表达式匹配: ~^.*\.magedu\.com\$server_name_hash_bucket_size 32|64|128;# 作用: 为了实现快速主机查找，nginx使用hash表来保存主机名； tcp_nodelay on|off;# 在keepalived模式下的连接是否启用TCP_NODELAY选项，建议启用；tcp_nopush on|off;# 在sendfile模式下，是否启用TCP_CORK选项，建议启用；sendfile on | off;# 是否启用sendfile功能，建议启用； 2.2 访问路径配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051root path# 作用:# 设置资源路径映射# 用于指明请求的 URL 所对应的资源所在的文件系统上的起始路径# 位置：http, server, location, if in location；alias path# 作用: 只能用于location中，定义路径别名；# 对比:# root path 用于替换 location URL 中 URL 最左侧的 &quot;/&quot;# alias path 用于替换 location URL 中 URL 最右侧的 &quot;/&quot;location /image &#123; root &apos;/vhost/web1&apos;&apos;&#125;http://www.tao.com/images/a.jpg ---&gt; /vhost/web1/images/a.jpglocation /imapge &#123; alias &quot;/www/pictures&quot;;&#125;http://www.tao.com/images/a.jpg ---&gt; /www/pictures/a.jpg########################################location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name &#123; ... &#125;# 功能：# 允许根据用户请求的URI来匹配指定的各location以进行访问配置；# url被匹配到时，将被location块中的配置所处理；# 匹配类型# =：精确匹配；# ~：正则表达式模式匹配，匹配时区分字符大小写# ~*：正则表达式模式匹配，匹配时忽略字符大小写# ^~: URI前半部分匹配，不检查正则表达式# 不带符号：匹配起始于此uri的所有的url；# 匹配优先级：精确匹配(=) ^~ ~ ~* 不带任何符号的 locationhttp &#123; server &#123; listen 80; server_name www.tao.comm; location / &#123; root &apos;/vhosts/web1&apos;; &#125; location /images/ &#123; root &apos;/vhosts/images&apos;; &#125; location ~* \.php$ &#123; fcgipass &#125; &#125; &#125; 2.2 索引及错误页配置12345678910111213141516171819202122232425262728index uri ...;# 作用: 定义默认页面，可参跟多个值；# 说明: 这里 uri 与 root，文件系统没有任何关系，# nginx 会按照当前配置的匹配逻辑，找到 uri 的位置error_page code ... [=code] uri | @name;# 作用:# 错误页面重定向# 根据 http 响应状态码来指明特用的错误页面# [=code]: 以指明的响应吗进行响应，而是默认的原来的响应error_page 500 502 503 504 =200 /50x.html;location = /50x.html &#123; root html;&#125;try_files path1 [path2 ...] uri;# 作用:# 自左至右尝试读取由path所指定路径，在第一次找到即停止并返回# 如果所有path均不存在，则返回最后一个uri; # eg:# location ~* ^/documents/(.*)\$ &#123;# root /www/htdocs;# try_files \$uri /docu/\$1 /temp.html;# &#125;# http://www.magedu.com/documents/a.html# http://www.magedu.com/docu/a.html# http://www.magedu.com/temp.html 2.3 网络连接相关的设置12345678910111213141516171819202122232425262728293031keepalive_timeout time;# 保持连接的超时时长；默认为75秒；keepalive_requests n;# 在一次长连接上允许承载的最大请求数；keepalive_disable [msie6 | safari | none ]# 对指定的浏览器(User Agent)禁止使用长连接；tcp_nodelay on|off# 对keepalive连接是否使用TCP_NODELAY选项, on 表示不启用；client_header_timeout time;# 读取http请求首部的超时时长；client_body_timeout time;# 读取http请求包体的超时时长；send_timeout time;# 发送响应的超时时长；client_body_buffer_size size;# 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；# 超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置；client_body_temp_path path [level1 [level2 [level3]]];# 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量；client_body_temp_path /var/tmp/client_body 2 1 1# 1：表示用一位16进制数字表示一级子目录；0-f# 2：表示用2位16进程数字表示二级子目录：00-ff# 2：表示用2位16进程数字表示三级子目录：00-ff 2.4 对客户端请求的限制1234567891011121314151617limit_except method ... &#123; ... &#125;# 指定对范围之外的其它方法的访问控制；limit_except GET &#123; allow 172.16.0.0/16; deny all;&#125;client_max_body_size SIZE;# http请求包体的最大值；# 常用于限定客户所能够请求的最大包体；# 根据请求首部中的Content-Length来检测，以避免无用的传输；limit_rate speed;# 限制客户端每秒钟传输的字节数；默认为0，表示没有限制；limit_rate_after time;# nginx向客户发送响应报文时，如果时长超出了此处指定的时长，则后续的发送过程开始限速； 2.5 文件操作的优化1234567891011121314151617181920212223242526272829sendfile on|off# 是否启用sendfile功能；aio on | off | threads[=pool];# 是否启用aio功能；directio size | off;# 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m;open_file_cache max=N [inactive=time]|off# 作用: 是否打开文件缓存功能；# 参数：# max: 缓存条目的最大值；当满了以后将根据LRU算法进行置换；# inactive: 缓存项的非活动时长，某缓存条目在此选项指定时长内没有被访问过或# 访问次数少于open_file_cache_min_uses指令所指定的次数，则为非活动项，# 将自动被删除；默认为60s;# 缓存信息包括：# 文件句柄、文件大小和上次修改时间；# 已经打开的目录结构；# 没有找到或没有访问权限的信息；open_file_cache_min_uses number;# 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项；open_file_cache_valid time;# 多长时间检查一次缓存中的条目是否超出非活动时长，默认为60s;open_file_cache_errors on|off# 是否缓存文件找不到或没有权限访问等相关信息； 2.6 客户端请求的特殊处理123456789101112131415ignore_invalid_headers on|off# 是否忽略不合法的http首部；默认为on;# off意味着请求首部中出现不合规的首部将拒绝响应；只能用于server和http;log_not_found on|off# 是否将文件找不到的信息也记录进错误日志中；resolver address;# 指定nginx使用的dns服务器地址；resover_timeout time;# 指定DNS解析超时时长，默认为30s;server_tokens on|off;# 是否在错误页面中显示nginx的版本号； 2.7 内存及磁盘资源分配123456789101112131415161718192021222324252627client_body_in_file_only on|clean|off# HTTP的包体是否存储在磁盘文件中；# 非off表示存储，即使包体大小为0也会创建一个磁盘文件；# on表示请求结束后包体文件不会被删除，clean表示会被删除；client_body_in_single_buffer on|off;# HTTP的包体是否存储在内存buffer当中；默认为off；cleint_body_buffer_size size;# nginx接收HTTP包体的内存缓冲区大小；client_body_temp_path dir-path [level1 [level2 [level3]]];client_body_temp_path /var/tmp/client/ 1 2# HTTP包体存放的临时目录；client_header_buffer_size size;# 正常情况下接收用户请求的http报文header部分时分配的buffer大小；默认为1k;large_client_header_buffers number size;# 存储超大Http请求首部的内存buffer大小及个数；connection_pool_size size;# nginx对于每个建立成功的tcp连接都会预先分配一个内存池，# 此处即用于设定此内存池的初始大小；默认为256；request_pool_size size;# nginx在处理每个http请求时会预先分配一个内存池，此处即用于设定此内存池的初始大小；默认为4k;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.3 nginx main 配置段]]></title>
    <url>%2F2018%2F09%2F23%2Flinux_mt%2F26-nginx%2Fnginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[nginx main 配置段 nginx 配置文件有众多参数，因此我们按照配置文件的配置段分别讲解 nginx 配置。本节主要是 ngnix 核心配置段。这些参数可分为如下几个类别: 正常运行的必备配置 优化性能相关的配置 事件相关的配置 用于调试、定位问题 nginx 参数的详细配置可参阅 dirindex 1. 基础核心配置最长需要修改的参数: worker_process worker_connections worker_cpu_affinity worker_priority 1.1 正常运行的必备配置：12345678910111213user username [groupname];# 指定运行worker进程的用户和组pid /path/to/pidfile_name;# 指定nginx的pid文件include file | mask;# eg: include /etc/nginx/conf.d/*.conf;# 指明包含进来的其它配置文件片断,mask 表示支持通配符；load_module file;# load_module &quot;/usr/lib64/nginx/modules/ngx_stream_module.so&quot;;# 指明要装载的动态模块； 1.2 优化性能相关的配置：123456789101112131415161718192021222324252627282930worker_processes n;# worker进程的个数；通常其数值应该小于或等于CPU的物理核心数；worker_processes auto;# nginx 将根据 cpu 数量自动选择 worker 进程数worker_cpu_affinity cpumask ...;# 作用: 对 worker 进程进行 CPU 绑定，用于提升缓存命中率 只有在系统上不存在其他耗费资源的进程时才建议开启# eg:# worker_processes 6;# worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000;worker_cpu_affinity auto; # nginx 将根据 cpu 数量自动绑定worker_priority nice;# 作用: 指明 work 进程的 nice 值, -20,19之间的值worker_rlimit_nofile n;# 指定所有worker进程所能够打开的最大文件句柄数；worker_rlimit_sigpending n;# 设定每个用户能够发往worker进程的信号的数量；ssl_engine device; # 在存在ssl硬件加速器的服务器上，指定所使用的ssl硬件加速设备；timer_resolution t# 作用:# 每次内核事件调用返回时，都会使用gettimeofday()来更新nginx缓存时钟；# timer_resolution用于定义每隔多久才会由gettimeofday()更新一次缓存时钟；# x86-64系统上，gettimeofday()代价已经很小，可以忽略此配置； 1.3 事件相关的配置此配置位于 events {} 配置段内 1234567891011121314151617181920212223work_connections nums# 设定单个 worker 进程能处理的最大并发连接数量, 尽可能大，以避免成为限制，eg: 51200use [epoll|rtsig|select|poll]# 作用: 指明使用的IO模型，建议让Nginx 自动选择accept_mutex [on|off]# 作用: 是否打开Ningx的负载均衡锁；# 功能:# 此锁能够让多个worker进轮流地、序列化地与新的客户端建立连接；# 而通常当一个worker进程的负载达到其上限的7/8，master就尽可能不再将请求调度此worker；accept_mutex_delay ms;# 作用:# accept锁模式中，一个worker进程为取得accept锁的等待时长# 如果某worker进程在某次试图取得锁时失败了，至少要等待ms才能再一次请求锁；lock_file /path/to/lock_file;# 作用: accept_mutex 用到的lock文件路径multi_accept on|off;# 作用: 是否允许一次性地响应多个用户请求；默认为Off; 1.4 用于调试、定位问题: 只调试nginx时使用12345678910111213141516daemon on|off;# 作用:# 是否以守护进程让ningx运行后台；默认为on，# 调试时可以设置为off，使得所有信息去接输出控制台；master_process on|off# 作用:# 是否以master/worker模式运行nginx；默认为on；# 调试时可设置off以方便追踪；error_log path level;# 作用:# 错误日志文件及其级别；默认为error级别；调试时可以使用debug级别，# 但要求在编译时必须使用--with-debug启用debug功能；# path: stderr | syslog:server=address[,paramter=value] | memory:size# level: debug | info | notice| warn|crit| alter| emreg]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.2 nginx基础入门]]></title>
    <url>%2F2018%2F09%2F22%2Flinux_mt%2F26-nginx%2Fnginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[nginx基础入门 在学习 nginx 之前，我们首先来对 nginx 做一个入门介绍，后续我们会详细介绍 nginx web server 的配置。本节内容包括: nginx 框架 nginx 安装 nginx 配置文件格式 1. nginx 架构与特性1.1 架构 ngnix 架构如上图所示: Master 进程: 作用: 主控进程负责生成和管理 Worker 进程 特性: 支持动态加载配置文件，平滑升级 Worker: 作用: 作为 web 服务，Worker 进程负责接收和处理用户请求 作为反代服务器，可通过 httpd/FastCGI 等协议向后端服务器(Backend) 转发请求 特性: 支持 http 和 https Workder 内是高度模块化的，新版本 nginx 支持部分模块动态装卸载 支持 epoll，kqueue 等高效的事件驱动的 IO 模型，一个 Worker 进程可同时响应多个用户请求，支持更高的并发链接 Cache: 作用: 支持本地缓存，Cache Loader 缓存加载，Cache manager 缓存管理 特性: 支持 AIO，senfile，mmap 拥有高效的磁盘 IO nginx 高度模块化，但其模块早期不支持DSO机制；近期版本支持动态装载和卸载.模块可分为: 核心模块: core module 标准http模块: Optional HTTP modules 可选的http模块: Standard HTTP modules 邮件模块: Mail modules 传输层代理模块:Stream modules 第三方模块 1.2 nginx 功用nginx 可实现如下功能: 静态资源的web服务器，能缓存打开的文件描述符； http, smtp, pop3 协议的反向代理服务器 缓存、负载均衡； 支持FastCGI(fpm, LNMP), uWSGI(python) 模块化，非DSO机制，过滤器gzip，SSI和图像大小调整等 支持SSL 作为web 服务支持: 基于名称和IP做虚拟主机 支持keepalive 支持平滑配置更新或程序版本升级 定制访问日志，支持使用日志缓存以提高性能 支持url rewrite 支持路径别名 支持基于IP及用户的认证； 支持速率限制，并发限制等； 2. nginx 安装2.1 rpm 包安装默认情况下 epel 仓库与 nginx 官方仓库 rpm 组织 nginx 方式有所不同。 epel 仓库Linux 上 nginx 的 rpm 包由 epel 源提供，因此在安装 nginx 之前需要配置好 epel 的 yum 源1234567891011121314$ sudo vim /etc/yum.repos.d/epel.repo[epel]name=Extra Packages for Enterprise Linux 7 - $basearchbaseurl=http://mirrors.aliyun.com/epel/7/$basearch http://mirrors.aliyuncs.com/epel/7/$basearch#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7$ sudo yum install nginx$ yum info nginx$ rpm -ql nginx nginx 官方仓库使用 nginx 官方仓库，可以安装 nginx 最新的稳定版本，安装之前首先需要配置其 yum 源，可参考 nginx yum 源 12345678910$ sudo vim /etc/yum.repos.d/nginx.repos[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1$ sudo yum install nginx$ yum info nginx$ rpm -ql nginx 2.2 编译安装123456789101112131415161718192021222324# 1. 编译环境准备yum grouplistyum groupinstall "Development Tools" yum install pcre-devel zlib-develyum install openssl openssl-devel # 2. 编译安装cd /usr/localtar xf nginx-1.14.0.tar.gzcd nginx-1.14.0./configure --helpgroupadd -r nginxuseradd -g nginx -r nginx./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aiomake &amp;&amp; make installmkdir -pv /var/tmp/nginx/&#123;client,proxy,fastcgi,uwsgi&#125;# 3. 启动 nginx/usr/local/nginx/sbin/nginx# 4. 可以仿照 rpm 安装时生成的 unit file 为编译安装创建一个服务管理脚本 2.3 nginx 主程序使用nginx 的主程序 nginx, 位于 /usr/sbin/nginx，其使用方式如下: nginx options: 作用: 启动和管理 nginx 服务 选项: ?,-h: 显示命令帮助 v: 显示 nginx 版本 V: 显示 nginx 版本和编译参数 t: 检查配置文件 T: 检查配置文件，并显示配置文件内容 q: nginx 启动测试 s signal: 向 nginx 发送管理信号 stop, quit, reopen, reload c filename: 设置配置文件路经 (default: /etc/nginx/nginx.conf) g directives: 设置 nginx 的全局配置参数，会负载配置文件中同名参数 p prefix: set prefix path (default: /usr/share/nginx/) 3. nginx 配置文件123456789101112# rpm -ql nginx/etc/nginx/ # 配置文件目录/etc/nginx/nginx.conf # 主配置文件/usr/sbin/nginx # 主程序/usr/bin/nginx-upgrade/usr/lib/systemd/system/nginx.service # systemctl 服务管理脚本/usr/lib64/nginx/modules # nginx 模块目录/var/log/nginx # 默认日志存放目录/etc/logrotate.d/nginx 3.1 配置文件结构nginx 配置参数由下面四个个部分组成1234567891011121314151617181920###### main 配置段 ######main block：主配置段，也即全局配置段； event &#123; ... &#125;：事件驱动相关的配置；###### http 配置段 ######http &#123; ...&#125;：http/https 协议相关的配置段；###### mail 配置段 ######mail &#123; ...&#125;###### 传输层代理段 ######stream &#123; ...&#125; main配置段: 基本核心配置，包括 用于调试、定位问题 正常运行的必备配置 优化性能的配置 事件类的配置 http 配置段: 配置 nginx web server mail 配置段: 通常没什么用 3.2 配置文件语法1234user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid; nginx 由如下语法要求: 语法格式: directive value1 [value2....]; 必需以分号结尾 支持使用变量，自定义变量可以覆盖内置变量的值 内置变量: nginx 内置变量索引 自定义变量: set $var_name value 变量引用: $variable_name]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.1 IO模型]]></title>
    <url>%2F2018%2F09%2F21%2Flinux_mt%2F26-nginx%2FIO%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[IO模型 nginx 是一个 web 服务器，同时还能作为 http 协议的反向代理服务器。相比于 http，nginx 使用了更先进的 IO 模型，异步通信以及进程间通信的技术，能支持更多的并发请求，具有更高的性能和稳定性。本章我们首先来学习如何使用 nginx 配置一个 web serve，nginx 的反向代理功能我们留在 28 章再来介绍。本章内容包括 IO 事件模型 nginx 框架与配置 nginx web 服务配置 有关 web 的基础概念和 http 协议的内容将不再此累述，大家可以回看以下几个章节: 20.1 web基础概念 20.2 http协议基础 20.3 http协议进阶 想要讲清楚 IO 模型并不容易，对于没有编程经验的来说这是一个很抽象的概念。想理解这个概念可以从以下几点入手: 我们的 web 需要同时响应多个用户请求，但是我们的程序通常是顺序执行的，一次只能响应一个用户请求 响应的内容通常位于磁盘上，而读取磁盘文件，利用网卡发送数据包都是内核提供的功能，应用程序需要发起系统调用 在系统调用返回结果之前，发起调用的应用程序通常只能等待 总结起来就是，web 程序需要同时处理多个用户请求，但是程序通常是顺序执行的，且经常经常阻塞在磁盘和网络 IO 之上。为能够为多个用户同时提供响应我们需要新的技术，这些技术目的是提高程序的 IO 效率称为 IO 模型。要想明白 IO 模型，我们首先要明白系统调用的过程。 1. IO 系统调用1.1 IO 过程 我们以读取磁盘文件为例: 当我们需要读取文件时，首先发起 read 系统调用 此时会陷入内核，执行内核代码，将数据从磁盘读取到内核缓冲区中 将内核缓冲区中的数据从内核拷贝到应用程序内存空间 1.1 同步/异步同步/异步关注的是 被调用者，如何通知调用者，即被调用者与调用者之间消息通知的机制 在 IO 上就是应用程序与操作系统的交互方式 1.2 阻塞/非阻塞阻塞/非阻塞关注的是 调用者如何等待结果，即调用程序的执行模式 1.3 IO 模型类别 同步阻塞 同步非阻塞 IO复用(事件驱动IO)：select, poll，epoll: 信号驱动I/O 异步IO 参考连接: https://songlee24.github.io/2016/07/19/explanation-of-5-IO-models/ https://blog.csdn.net/wuzhengfei1112/article/details/78242004 https://blog.csdn.net/lijinqi1987/article/details/71214974 2. httpd 的IO 模型 多进程模型：prefork, 一个进程响应一个用户请求，并发使用多个进程实现； 多线程模型：worker, 一个进程生成多个线程，一个线程响应一个用户请求；并发使用多个线程实现；n进程，n*m个线程； 事件模型：event, 一个线程响应多个用户请求，基于事件驱动机制来维持多个用户请求；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.3 sudo]]></title>
    <url>%2F2018%2F09%2F20%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2Fsudo%2F</url>
    <content type="text"><![CDATA[sudo sudo是linux系统管理指令，它允许用户临时以其他用户(通常是root)执行一些或全部指令，其实现的是一种授权机制。普通用户想执行root 用户的特权命令时，可以使用 su 切换到管理员，但是这样做有两个坏处，一是 root 用户会被普通用户知道，二是普通用户切换为 root 后获取的是 root 的所有权限，这些都存在安全风险。而 sudo 可以实现授权普通用户执行部分或全部命令，同时无需 root 密码。本节我们就来介绍 sudo 的使用，内容如下: su 用户切换 sudo 配置 sudo 命令使用 1. su 用户切换su [OPTION]... [-] [USER [ARG]...] 作用: 用户切换 参数: USER，可省，默认为 root 选项: -l: 交互式登录shell进程，su -l user == su - user -c &#39;COMMAND&#39;: 不切换用户只执行命令后，并退出 有关交互式登陆，可以回看 6.10 bash配置文件 2. sudo 配置sudo 能够让获得授权的用户以另外一个用户的身份运行指定的命令。授权文件为 /etc/sudoers，此文件有特定的语法格式，因此有个专用的编辑命令 visudo,其在退出时，可以帮助我们检查语法错误。sudoers 配置如下 2.1 授权机制123456789$ sudo visudoroot ALL=(ALL) ALLtao ALL=(ALL) ALL%wheel ALL=(ALL) ALL# 总结:那个用户 从什么地方 以谁的身份 执行什么命令who where=(whom) commandsusers hosts=(runas) commands 授权选项格式 users: 授权用户 username: 用户名 #uid: 用户ID(UID) %groupname: 用户组名称 %#gid: 用户组ID(GID) user_alias: 用户别名 hosts: 用户登陆限制，只有在限制范围内登陆的用户才能使用授权的命令 ip: ip 地址 hostname: 域名 NetAddr: 子网 host_alias: 网络别名 runas: 以哪些用户的身份执行命令 commands: 授权的命令，必需是全路经 command: 命令 directory: 目录 sudoedit：特殊权限，可用于向其它用户授予sudo权限 cmnd_alias: 命令别名 wheel 组wheel 组是 Linux 中的特殊组即管理员组，属于 wheel 组的成员均具有所有管理员权限 123456789# root 身份执行$ usermod pythoner -a -G wheel$ su - pythoner # 必需要以交互式登陆的方式切换到 pythoner 才能生效$ id pythoneruid=1001(pythoner) gid=1001(pythoner) 组=1001(pythoner),10(wheel)$ sudo cat /etc/shadow 2.2 定义别名的方法suders 支持设置别名，用于简化配置工作。别名类似于变量，可复用，可避免重复输入。别名设置的语法格式为: ALIAS_TYPE NAME=item1, item2, item3, ... NAME：别名名称，必须使用全大写字符； ALIAS_TYPE: 别名类型，分别与上面一一对应 User_Alias Host_Alias Runas_Alias Cmnd_Alias: 包含的命令必需全路经 123456# 别名设置User_Alias NETADMIN=tom, jerryCmnd_Alias NETCMND=/usr/sbin/ip, /usr/sbin/ifconfig# 使用别名进行配置NETADMIN localhost=(root) NETCMND 2.3 sudo命令s使用sudo [options] COMMAND options -l: 列出用户能执行的命令 -k: 清除此前缓存用户成功认证结果； -u: 以哪个用户执行 默认 sudo 有检票机制，即能记录成功认证结果一段时间，默认为5分钟。-k 选项则可以手动取消，下此使用 sudo 时必需输入密码。同时需要提醒大家注意的是，执行 sudo 时输入的是用户自己的密码，不是 root 密码。 2.4 sudoers 配置示例Cmnd_Alias USERADMINCMNDS = /usr/sbin/useradd, /usr/sbin/usermod, /usr/bin/passwd [a-z]*, !/usr/bin/passwd root User_Alias USERADMIN = bob, alice USERADMIN ALL=(root) NOPASSWD:USERADMINCMNDS sudoers 中常用的标签 NOPASSWD: 标识使用命令时，无需输入密码 PASSWD: 默认，使用命令时，需要输入密码 !COMMAND: ! 表示不允许执行 COMMAND 命令]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.2 日志管理系统rsyslog]]></title>
    <url>%2F2018%2F09%2F19%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2F%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog%2F</url>
    <content type="text"><![CDATA[日志管理系统rsyslog rsyslog 是Linux 系统上日志管理系统，应用程序可直接调用 rsyslog 的接口将日志写入到 rsyslog 特定的 facility 中即可完成日志记录。如果应用程序通过 rsyslog 来记录日志，通常在其自己的配置文件中有专门的选项用来定义将日志存入到 rsyslog 哪个 facility。facility 可以理解为 rsyslog 日志收集器的基本单元，rsyslog 内部的配置文件定义了每个 facility 的日志存储于何处。应用程序只需要将日志信息教给 rsyslog，rsyslog 会自动根据日志所属的 facility 将日志存储到对应的位置。本节我们就来详细介绍 rsyslog 的配置使用 1. rsyslog 简介1.1 syslogsyslog 是 rsyslog 的上一版，syslog 服务分成了两个部分: syslogd： system，为 Linux 上的应用程序提供日志记录服务 klogd：kernel，为开机启动，系统内核提供日志记录服务 除了本地服务，syslog 还支持C/S架构，即可通过UDP或TCP协议为网络上的其他主机提供日志记录服务。这种模式下 12345678# C/S rsyslog --------kernel --------&gt; |本机 | | | tcp/utpssh --------&gt; |rsyslog| ------------&gt; rsyslog server | |... ---------&gt; |服务 | --------- 作为 server 的 syslog 服务监听在 tcp/utp 的 514 端口上 作为客户端的应用程序，首先将日志发送到本地的 syslog 服务上，再由 本地的 syslog 服务作为客户端将应用程序的日志发送到 server 端的 syslog 上加以记录，因此 syslog 的客户端与服务器都是 syslog rsyslog server 收到客户端发来的日志后，根据自己 facility 的配置将日志记录到特定位置。 因此应用程序只是将日志写入到特定的 facility，syslog server 只是本地 syslog 记录日志的一种方式。syslog 可定义 facility 的日志存储方式，可以是本地文件，也可以是远程的 syslog server syslog 日志格式无法自定义，统一为事件产生的日期时间 主机 进程[pid] ：事件内容，因此只能记录一些简单的日志。 1.2 rsyslogrsyslog 是 syslog 的升级版本，支持所有 syslog 特定，它只有 rsyslogd 一个服务来完成所有日志的记录功能。相比于 syslog，rsyslog 具有如下新特性: 支持多线程； 支持多种C/S连接协议，UDP，TCP，SSL，TLS，RELP； 可存储日志信息于MySQL、PGSQL、Oracle等数据管理系统； 强大的过滤器，实现过滤日志信息中任何部分的内容； 自定义输出格式 2. rsyslog 组成2.1 日志收集器单元rsyslog日志收集器有两个重要的概念: facility： 作用: 设施，从功能或程序上对日志收集进行分类 内置: rsyslog 上默认的 facility 有 auth, authpriv, cron, daemon, kern, lpr, mail, mark, news, security, user, uucp, local0-local7, syslog priority： 作用: 日志级别，用于定义日志的重要性，facility 可定义记录日志的级别范围 级别: 日志级别从低到高有 debug, info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) 2.2 程序组成12345678910111213141516$ rpm -ql rsyslog/etc/logrotate.d/syslog/etc/pki/rsyslog/etc/rsyslog.conf # 配置文件/etc/rsyslog.d/etc/sysconfig/rsyslog # rsyslog 服务的配置文件/usr/bin/rsyslog-recover-qi.pl/usr/lib/systemd/system/rsyslog.service # 服务脚本/usr/lib64/rsyslog # 模块目录/usr/lib64/rsyslog/im*.so # im 开头的为输入相关模块/usr/lib64/rsyslog/om*.so # om 开头的为输出相关模块/usr/lib64/rsyslog/lm*.so/usr/lib64/rsyslog/mm*.so/usr/lib64/rsyslog/pm*.so 3. rsyslog 配置3.1 配置文件结构12345678910111213141516171819202122$ cat /etc/rsyslog.conf |grep -v &quot;^# &quot;#### MODULES #### # 模块加载$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)$ModLoad imjournal # provides access to the systemd journal#$ModLoad imklog # reads kernel messages (the same are read from journald)#$ModLoad immark # provides --MARK-- message capability$ModLoad imudp # utp 服务$UDPServerRun 514$ModLoad imtcp # tcp 服务$InputTCPServerRun 514#### GLOBAL DIRECTIVES #### # 全局目录配置$WorkDirectory /var/lib/rsyslog$IncludeConfig /etc/rsyslog.d/*.conf#### RULES #### # facility 日志记录配置*.info;mail.none;authpriv.none;cron.none /var/log/messagesmail.* -/var/log/maillog*.emerg :omusrmsg:* 配置文件由三个部分组成 MODULES: 模块加载 GLOBAL DIRECTIVES: 全局变量 RULES: 用于定义 facility 记录日志的级别和位置，格式为 facilty.priority target 1.2 RULES 格式RULES 用于定义 facility 记录日志的级别和位置，其语法为 facilty.priority target priority: 日志级别，有如下几种表示方式 *：所有级别； none：没有级别； priority：此级别以高于此级别的所有级别； =priorty：仅此级别 target: 日志输出的位置，有如下几种格式 /var/log/messages: 记录到特定文件中，默认为同步写入，大量日志记录会拖慢系统性能 -/var/log/maillog: 记录到文件，- 表示异步写入，不重要的日志可异步写入，减少系统 IO :omusrmsg:tao: 调用 omusrmsg 将日志发送到用户登陆的终端，* 表示所有登陆用户； @192.168.1.101: 将日志发送到 rsyslog server | COMMAND: 将日志送入管道 说明: target 中可使用 :module:param 调用 rsyslog 内置的模块，每个模块有自己特定的参数 1.3 默认 facilty12345678910*.info;mail.none;authpriv.none;cron.none /var/log/messagesauthpriv.* /var/log/securemail.* -/var/log/maillogcron.* /var/log/cron*.emerg :omusrmsg:*uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.loglocal2.* /var/log/haproxy.log 1.4 其他日志文件除了 rsyslog 记录的日志外，系统上还有其他一些重要的日志文件 /var/log/wtmp： 作用: 当前系统成功登录系统的日志 查看: last 命令 /var/log/btmp： 作用: 当前系统尝试登录系统失败相关的日志 查看: lastb命令 附注: lastlog命令，能显示当前系统上的所有用户最近一次登录系统的时间； /var/log/dmesg： 作用: 系统引导过程中的日志信息 查看: 也可以使用dmesg命令进行查看 4. rsyslog 高级配置4.1 rsyslog server 配置配置 C/S 架构的 rsyslog 步骤如下所示 1234567891011# 1. 服务器端: 启动 rsyslog server 监听 tcp/udp 的模块# Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514# Provides TCP syslog reception$ModLoad imtcp$InputTCPServerRun 514# 2. 客户端: 配置 facility 将日志发往服务端*.info;mail.none;authpriv.none;cron.none @192.168.1.149 4.2 记录日志于mysql中记录日志于mysql中首先要安装配置 rsyslog mysql 的模块，配置步骤如下:12345678910111213141516171819202122232425262728293031# 1. rsyslog mysql 模块安装$ yum search rsyslog$ sudo yum install rsyslog-mysql.x86_64# 2. mysql 配置$ rpm -ql rsyslog-mysql.x86_64/usr/lib64/rsyslog/ommysql.so/usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql# 通过导入createDB.sql脚本创建依赖到的数据库及表$ mysql -uUSER -hHOST -pPASSWORD &lt; /usr/share/doc/rsyslog-mysql-VERSION/createDB.sql# 登陆 mysql 配置 rsyslog 使用的特定帐户$ mysql -uUSER -hHOST -pPASSWORDMariaDB [(none)]&gt; grant all on Syslog.* to &quot;rsyslog&quot;@&quot;%&quot; identified by &quot;rsyspass&quot;;MariaDB [(none)]&gt; flush privileges;mysql -ursyslog -prsyspass&gt;# 3. 配置rsyslog使用ommysql模块$ sudo vim /etc/rsyslog.conf### MODULES ####$ModLoad ommysql#### RULES ##### facility.priority :ommysql:DBHOST,DB,DBUSER,DBUSERPASSfacility.priority :ommysql:127.0.0.1,Syslog,rsyslog,rsyspass# 重启rsyslog服务$ sudo systemctl restart rsyslog]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.1 Linux时间服务-chrony]]></title>
    <url>%2F2018%2F09%2F18%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2FLinux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony%2F</url>
    <content type="text"><![CDATA[Linux时间服务-chrony Linux 中有一些通用原则，比如如果上下层衔接不通畅，通常的解决方法就是添加一个中间层，虚拟文件系统就是最典型的一例，再比如如果一个功能被很多应用所需要，通常会做成一个公共服务以便，认证功能 pam 还有本节将要介绍的 日志服务 rsyslog 就是典型的示例。本章我们会讲一些类似这些的 Linux 中基础的但是并不复杂的基础服务，包括: 时间同步服务 chrony 日志管理服务 rsyslog sudo 权限管理 Linux 中很多服务在跨主机通信需要保持时间同步，特别是对于一个集群而言，多台主机之间的时间必需严格一致。Linux 在启动时会从硬件中读取时间，在操作系统启动之后，系统时钟就会同硬件时钟相独立。系统始终依赖 CPU 的工作频率更新时间，因此不同主机之间的时间很难保持一致。特别是在虚拟化环境中，每个虚拟机只能获取一部份的 CPU 周期，时间基本不可能保持一致，此时就需要进行时间同步。本节我们就来 Linux 中的时间服务，内容包括: Linux 中时间同步的协议和方式 ntp 和 chrony 1. Linux 中的时间同步1.1 Linux 时间同步的方式ntp(Network Time Protocol) 是 Linux 同步时间的协议。当时间出现偏差时，Linux 不能将当前时间直接调整为准确时间，这是因为 Linux 上很多服务依赖于时间的连续性，时间不能跳越。Linux 只能通过让时间走”更快”或”更慢”来同步时间。 ntp 协议的最早实现是 ntp 服务，但是 ntp 存在一个缺陷，时间同步太慢，在时间相差较大时需要很长时间才能完成时间同步。chrony 服务是 ntp 的改进版本，它采用了一种很精巧的策略，在保证时间连续的同时能在几秒甚至更短的时间内完成时间同步。 1.2 Linux 时间同步服务ntp，chrony 既是客户端也是服务端，这是因为我们的系统需要实时同步时间，因此 ntp，chrony 要作为后台进程实时进行。ntp 和 chrony 都监听在 utp的 123 端口上，因此 chrony 是兼容 ntp 的，即 ntp 的客户端也能从 chrony 服务同步时间。 1.3 时间同步配置在 Linux 中同步时间只需要，安装 chrony，修改其配置文件，更改其同步时间服务器，如果其同时作为服务器使用，需要修改 allow 参数指定允许按些客户端过来同步；配置完成后启动 chrony 的服务，并将其设置为开机自动启动即可。 也可以使用 ntpdate 命令临时进行手动时间同步。下面我们就来详细介绍 ntp 和 chrony 的配置。Linux 上建议使用 chrony。 1234567891011# 1. 安装 chrony 服务yum install chrony# 2. 修改配置文件，详细配置见下vim /etc/chrony.confallow= # 允许同步的客户端server= # 时间同步服务器# 3. 启动服务systemctl start chronydsystemctl enable chronyd 2. ntp12345678910111213141516# rpm -ql ntp/etc/dhcp/dhclient.d/etc/dhcp/dhclient.d/ntp.sh/etc/ntp.conf # 配置文件/etc/ntp/crypto/etc/ntp/crypto/pw/etc/sysconfig/ntpd/usr/bin/ntpstat/usr/lib/systemd/ntp-units.d/60-ntpd.list/usr/lib/systemd/system/ntpd.service/usr/sbin/ntp-keygen/usr/sbin/ntpd/usr/sbin/ntpdc/usr/sbin/ntpq/usr/sbin/ntptime/usr/sbin/tickadj 2.1 配置文件123456789101112# cat /etc/ntp.conf |grep -v &quot;^#&quot;driftfile /var/lib/ntp/driftrestrict default nomodify notrap nopeer noqueryrestrict 127.0.0.1 # 允许哪些主机过来同步时间restrict ::1server 0.centos.pool.ntp.org iburst # 时间服务器地址server 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 2.2 时间同步命令ntpdate server_ip 作用: 手动向 server_ip 指向的服务同步时间 3. chrony123456789101112131415# rpm -ql chrony/etc/NetworkManager/dispatcher.d/20-chrony/etc/chrony.conf # chrony 配置文件/etc/chrony.keys/etc/dhcp/dhclient.d/chrony.sh/etc/logrotate.d/chrony/etc/sysconfig/chronyd /usr/bin/chronyc # chrony 服务管理工具/usr/lib/systemd/ntp-units.d/50-chronyd.list/usr/lib/systemd/system/chrony-dnssrv@.service/usr/lib/systemd/system/chrony-dnssrv@.timer/usr/lib/systemd/system/chrony-wait.service/usr/lib/systemd/system/chronyd.service/usr/libexec/chrony-helper/usr/sbin/chronyd # 客户端亦是服务端程序 3.1 组成chrony 由如下几个部分组成: 配置文件：/etc/chrony.conf 主程序文件：chronyd 工具程序：chronyc unit file: chronyd.service 3.2 配置123456789101112131415161718192021222324252627282930313233343536373839$ cat /etc/chrony.conf# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst# Record the rate at which the system clock gains/losses time.driftfile /var/lib/chrony/drift# Allow the system clock to be stepped in the first three updates# if its offset is larger than 1 second.makestep 1.0 3# Enable kernel synchronization of the real-time clock (RTC).rtcsync# Enable hardware timestamping on all interfaces that support it.#hwtimestamp *# Increase the minimum number of selectable sources required to adjust# the system clock.#minsources 2# Allow NTP client access from local network.#allow 192.168.0.0/16# Serve time even if not synchronized to a time source.#local stratum 10# Specify file containing keys for NTP authentication.#keyfile /etc/chrony.keys# Specify directory for log files.logdir /var/log/chrony# Select which information is logged.#log measurements statistics tracking 核心配置选项包括: server:指明时间服务器地址，本机会向 server指向的机器同步时间 allow NETADD/NETMASK: chrony 作为服务端使用时，允许哪些网络的主机同步时间 allow all:允许所有客户端主机 deny NETADDR/NETMASK: 不允许哪些网络的主机同步时间 deny all:拒绝所有客户端 bindcmdaddress:命令管理接口监听的地址, chronc 命令连接此地址对 chrony进行远程管理，因此不要监听在公网地址上 local stratum 10:即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端 3.3 chroncchronc 是 chrony 服务的管理工具，它能远程连接 chrony 服务，chrony 会监听在 bindcmdaddress 参数配置的地址，等待 chronc 连接。chronc 是一个交互的客户端工具，最常使用的子命令为 sources，sourcestats，sourcestats -v，help。 12345678910111213# chronycchronyc&gt; sources210 Number of sources = 4MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? ns3106355.ip-37-187-100.&gt; 2 7 5 14 +20ms[ +22ms] +/- 236ms^? . 0 8 0 - +0ns[ +0ns] +/- 0ns^? cn.ntp.faelix.net 0 8 0 - +0ns[ +0ns] +/- 0ns^* ntp2.flashdance.cx 2 6 45 15 +3857us[+6412us] +/- 246mschronyc&gt; sourcestatschronyc&gt; sourcestats -vchronyc&gt; help]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.7 网络接口类型]]></title>
    <url>%2F2018%2F09%2F17%2Flinux_mt%2F24-iptables%2F%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[网络接口类型 网络虚拟化我们会在之后的高级篇详细讲解，但是为了方便大家理解，我们在此章节简单描述以下不同虚拟网卡的类型的作用范围。虚拟网卡分为四种主要类型: bridge:桥接，将当前主机的物理网卡与VMware 内部的虚拟交换机进行关联 nat: 在当前物理主机的物理网卡上启动 nat 转发功能，转发内部虚拟主机的网络请求，以连接外部物理主机 host-only: 功能: 虚拟主机能与其他虚拟主机以及当前物理主机进行通信，不能与外部物理主机通信 特征: 与 nat 相比，仅仅是取消了当前物理网卡的 nat 功能 私有网桥(VMnet2) 功能: 仅虚拟主机之间可以通信，不能与当前物理主机通信 1. bridge (图片来自于马哥Linux) 桥接的原理是当前主机的物理网卡与VMware 内部的虚拟交换机进行关联，原本的物理网卡被当作交换机使用，vmware 会再虚拟出一块网卡 VMNate8作为当前物理主机的网卡。所有的虚拟机和当前物理主机(VMNate0网卡)都会连接到虚拟交换机上，这样所有的虚拟主机就可以共享物理主机的网络。 2. nat nat 的原理是 vmware 在当前的物理主机上虚拟出一块网卡 VMNate8，并在其上启动 nat和 DHCP 功能，使用 nat 网络的虚拟主机会处于VMNate8 网卡所在的网络，因此会自动分配 IP 并将网关指向 VMNate8；然后由 VMNate8 做 SNAT 转发内网的主机请求以连接外部物理主机。 3. host-onlyhost-only 与 nat 功能类似，只不过 vmware 虚拟出的网卡不会启动 nat 功能，虚拟机无法与外部物理主机通信，只能当前的物理机通信 4. 私有网络私有网络更简单，vmware 会虚拟出一块网卡，而且此虚拟网卡不会添加在当前的物理主机之上。只有连接到相同私有网络的虚拟机之间才能通信，也无法与当前主机进行通信。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.6 TCP 协议简述]]></title>
    <url>%2F2018%2F09%2F16%2Flinux_mt%2F24-iptables%2Ftcp_protocol%2F</url>
    <content type="text"><![CDATA[TCP 协议简述 tcp 连接是由两个有来有往的半个连接组成的 1. 连接建立与拆除1.1 三此握手 1.2 四次挥手 1.3 连接重置tcp 连接过程中可能因为网络抖动导致双方无法通信，但是连接未拆除，过了一段时间后网络又恢复正常，双方的连接状态依旧存在，此时需要发送 RST 标识位的报文实现 tcp 连接重置。 1.4 连接过程]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.5 nat路由]]></title>
    <url>%2F2018%2F09%2F15%2Flinux_mt%2F24-iptables%2Fnat%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[nat路由 nat (network address translation) 是 iptables 另一功能，起初设计的目的是为了隐藏内网中的主机，后来为解决 ipv4 地址的紧缺问题提供了重要帮助。本节我们就来学习如何使用 nat 来隐藏内网中 主机，内容包括 源地址转换原理 目标地址转换原理 本地端口映射 iptables nat 规则配置 要想使用 nat 首先必需打开 Linux 的核心转发功能。如何修改内核参数详见 14.6 Linux内核功能及模块应用，打开核心转发功能可参考如下 12echo 1 &gt; /proc/sys/net/ipv4/ip_forwardsystcl -w net.ipv4.ip_forward=1 1. 源地址转换 如上图所示: 内部网络的报文经由网关向外部网络转发 网关服务器在 POSTROUTING 上将请求报文源地址转换为网关的外网地址并向外部服务器转发请求 外网服务收到源地址为网关服务器的请求，则向网关服务器返回响应 网关在收到来自服务端的响应时，再将目标地址从本机转换为内网主机，并转发给内网主机。 源地址转换称为 snat，可工作于 POSTROUTING 和 INPUT 链上，绝大多数都是工作于 POSTROUTING 链上。这是因为 POSTROUTING 作用于第二次路由之后，是报文离开主机的最后一个环节，此时 snat 一定是作用在发出的报文，而如果在 INPUT 上，则有可能将由本机发往本机的报文也做了地址转换，这实际上没有必要。 外部服务器，看到的请求始终是网关服务器的外网 IP，因此达到隐藏内网客户端的目的。 2. 目标地址转换 如上图所示: 外网客户端向我们的网关服务器发送请求 网关服务器在 PREROUTING 上将请求报文目标地址转换为内网服务器地址并向其转发请求 内网服务器返回响应，报文经网关服务器向外转发 网关服务将响应报文的源地址从内网服务器转换为本机地址，并向外网客户端转发响应。因为客户端发送的请求的目标地址是网关，所以返回响应的也必需是网关而不能是内网服务器。 目标地址转换称为 dnat，可工作于 PREROUTING 和 OUTPUT 链上，绝大多数都是工作于 PREROUTING 链上。这是因为第一路由决策会决定报文由 INPUT 进入用户空间，还是进入 FORWARD 转发出去，因此应该在第一路由之前就将报文的目标地址为内网服务器地址，否则报文就被送往内核而不是被转发到内网服务器。 外部客户端，发送始终是向网关服务器发送请求，根本不知道网关服务器是否转发的请求报文，因此达到了隐藏内网服务器的目的。 我们可以在内网部署多台 web 服务器，让 iptables 将请求转发到不同的内网服务器上，此时就实现了负载均衡的功能。只不过 iptables 的负载均衡功能已经独立为 lvs，并提供了更加丰富的功能，而不再由 dnat 实现。 3. 本机端口映射还有一种情形，比如本地的 tomcat 监听载 8080 端口上，但是http 默认是 80 端口，为了让客户端可通过 80 端口直接能请求到web 服务而不用修改默认端口，此时我们需要在本机做一个端口映射；将 80 端口的请求转发至 8080 上。本机端口映射是通过 iptables REDIRECT 扩展实现的。 4. iptables nat 实现iptables 实现地址转换，只需要使用 nat 特用的 target(处理动作即可) SNAT: -j SNAT options 作用: 源地址转换 选项: --to-source [ipaddr[-ipaddr]][:port[-port]]: 指定源端口和地址 DNAT: -j DNAT options 作用: 目标地址转换 选项: --to-destination [ipaddr[-ipaddr]][:port[-port]] 指定目标端口和地址 MASQUERADE: -j MASQUERADE 作用: 源地址转换，当主机的 ip 是动态获取时，会自动指定源地址 REDIRECT: -j REDIRECT options 作用: 端口重定向，做端口映射 选项: --to-ports port[-port] 指定源端口 12345678910111213# SNAT示例：&gt; iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j SNAT --to-source 172.16.100.67 # MASQUERADE示例：# 源地址转换：当源地址为动态获取的地址时，MASQUERADE可自行判断要转换为的地址；&gt; iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j MASQUERADE# DNAT示例&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j DNAT --to-destination 192.168.12.77&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 22012 -j DNAT --to-destination 192.168.12.78:22# REDIRECT&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j REDIRECT --to-ports 8080 5. dnat 于 filter在 dnat 的网关服务器上对转发报文做过滤时，由于 dnat 已经在 PREROUTING 上将报文的目标地址转和端口转换为了内网服务器地址和端口，因此在设置过滤条件时应该使用内网服务器地址作为过滤条件，而不是网关地址。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.4 网络防火墙配置]]></title>
    <url>%2F2018%2F09%2F14%2Flinux_mt%2F24-iptables%2F%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[网络防火墙配置 前面我们讲解了 iptables 命令的使用，其中主要是以配置主机防火墙作为示例，本节将来介绍如何配置一个网络防火墙。iptables 命令的使用没变，只是网络防火墙配置载 forward 链上有一些额外注意的事项。 1. 网络防火墙配置在进行网络防火墙配置之前，我们首先需要规划一下网络拓扑结构，好方便解说 iptables 命令的作用。 如上图所示，左半部分是我们模拟的内网，右半部分是模拟的公网，在使用 virtualbox 或 vimware 模拟上述网络时，有以下几点需要注意: 内网的网卡类型选择仅主机或 nat 网络，外网的网卡选择桥接。有关虚拟网卡的几种类型请参考 24.7 虚拟网卡类型 为使得从外网 192.168.1.10 返回的响应能到达我们的内网，需要将其网关指向 192.168.1.168,或者手动添加路由条目将，发往 172.16.0.0/24 的报文的下一跳设置成 192.168.1.168 需要打开中间的网络防火墙的核心转发功能 为测试防火墙，配置，我们需要在 172.16.0.2 和 192.168.1.10 上均配置好 httpd,vsftpd 等服务 12345# 添加路由route add -net 172.16.0.0/24 gw 192.168.1.168# 打开ia核心转发sysctl -w net.ipv4.ip_forward=1 1.1 放行 httpd防火墙 filter 功能只能添加在 INPUT FORWARD OUTPUT 链上，对于网络防火墙而言，报文只会经过 FORWARD 链，因此网络防火墙只能配置在 FORWARD 链上。一次 http 事务包括请求和响应两个过程，因此我们需要在 FORWARD 上同时添加发送请求和接收响应两个方向的规则。下面是配置示例，我们的目的是，内网的主机能访问所有的外网主机，但外网主机仅能访问内网的 httpd,ftp 服务。 1234567891011modprobe nf_conntrack_ftp# 设置默认策略为拒绝$ iptables -A FORWARD -j DROP# 开放 80 端口$ iptables -I FORWARD -s 172.16.0.0/24 -p tcp --dport 80 -j ACCEPT$ iptables -I FORWARD 2 -d 172.16.0.0/24 -p tcp --sport 80 -j ACCEPT# 开放 ftp$ iptables -R FORWARD 3 -s 172.16.0.0/24 -p tcp -m state --stat RELATED -j ACCEPT$ iptables -R FORWARD 4 -p tcp -d 172.16.0.0/24 -m state --state ESTABLISHED -j ACCEPT 1.2 基于连接追踪机制配置使用连接追踪机制，可以让 iptables 规则更加简单1234567891011# 开放内网到外网的所有请求$ iptables -A FORWARD -j DROP# 1. 开放已经建立的连接$ iptables -R FORWARD 1 -p tcp -m state --state ESTABLISHED -j ACCEPT# 2. 开放由内到外的新连接,此时 ftp 也可访问，因为 RELATED 也是 NEW 连接$ iptables -I FORWARD 2 -p tcp -s 172.16.0.0/24 -m state --state NEW -j ACCEPT# 开放外网到内网特定主机的 80 访问$ iptables -I FORWARD 2 -d 172.16.0.10 -p tcp --dport 80 -m state --state NEW -j ACCEPT 2. 利用 iptables 抵御 DOS 攻击利用iptables的recent模块来抵御DOS攻击: 建立一个列表，保存有所有访问过指定的服务的客户端IP ssh: 远程连接， 1234567891011121314# one&gt; iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 3 -j DROP# two&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH# three&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j LOG --log-prefix &quot;SSH Attach: &quot;# four&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP# 也可以使用下面的这句记录日志：&gt; iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --name SSH --second 300 --hitcount 3 -j LOG --log-prefix &quot;SSH Attack&quot; one: two: 利用connlimit模块将单IP的并发设置为3；会误杀使用NAT上网的用户，可以根据实际情况增大该值； 第二句是记录访问tcp 22端口的新连接，记录名称为SSH –set 记录数据包的来源IP，如果IP已经存在将更新已经存在的条目 three 利用recent和state模块限制单IP在300s内只能与本机建立2个新连接。被限制五分钟后即可恢复访问。 four: 第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接。 –update 是指每次建立连接都更新列表； –seconds必须与–rcheck或者–update同时使用 –hitcount必须与–rcheck或者–update同时使用 附注: iptables的记录：/proc/net/xt_recent/SSH]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.3 iptables扩展匹配]]></title>
    <url>%2F2018%2F09%2F13%2Flinux_mt%2F24-iptables%2Fiptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[iptables扩展匹配 上一节我们基本上把 iptables 基本使用方法讲完了，而且我们提到过 iptables 是高度模块化的，为在报文匹配和处理动作提供了很多扩展模块，本节我们就来介绍这些扩展模块的使用。可以使用如下命令查看这些扩展模块的帮助信息 1234567# CentOS 6man iptables# CentOS 7man iptables-extensionsrpm -ql iptables|grep &apos;[[:lower:]]\+\.so$&apos; 1. iptables 可用显示扩展1.1 multiport扩展 作用: 以离散方式定义多端口匹配；最多指定15个端口； 参数: [!] --source-ports,--sports port[,port|,port:port]…：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]…：指定多个目标端口； [!] --ports port[,port|,port:port]…：指明多个端口； 12&gt; iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp -m multiport --sports 22,80 -j ACCEPT 1.2 iprange扩展 作用: 指明连续的（但一般不能扩展为整个网络）ip地址范围； 参数: [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； 12&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 80 -m iprange --src-range 172.16.100.5-172.16.100.10 -j DROP&gt; iptables -I INPUT -d 172.16.100.67 -p tcp -m multiport 22:23,80 -m iprange --src-range 172.16.100.1-172.168.100.120 -j ACCEPT 1.3 string扩展 作用: 对报文中的应用层数据做字符串模式匹配检测； 参数: --algo {bm|kmp}：字符串匹配检测算法； bm：Boyer-Moore kmp：Knuth-Pratt-Morris [!] --string pattern：要检测的字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制格式； 1&gt; iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp --sport 80 -m string --algo bm --string &quot;gay&quot; -j REJECT 1.4 time扩展 作用: 根据将报文到达的时间与指定的时间范围进行匹配； 参数: --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestart hh:mm[:ss] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核上的时区，而非默认的UTC；1&gt; iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP 1.5 connlimit扩展 作用: 根据每客户端IP(也可以是地址块)做并发连接数数量匹配； 参数: --connlimit-upto n：连接的数量小于等于n时匹配； --connlimit-above n：连接的数量大于n时匹配；1&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m connlimit --connlimit-above 2 -j REJECT 1.6 limit扩展 作用: 基于收发报文的速率做匹配，匹配的发送报文数，而不是报文大小 原理: 令牌桶过滤器，进程在发送报文之前必需获取令牌，一个报文一个，通过限制令牌的发放速率达到限制报文发送速率 参数: --limit rate[/second|/minute|/hour|/day]: 报文发送的速率 --limit-burst number: 进程在空闲时可收集的最大令排数 12&gt; iptables -I INPUT -d 172.16.100.67 -p icmp --icmp-type 8 -m limit --limit 30/minute --limit-burst 5 -j ACCEPT&gt; iptables -I INPUT 2 -p icmp -j REJECT 2. state扩展2.1 连接追踪iptables 的 state 会启动内核的连接追踪机制，即内核在会在内存中记录一段时间内与主机通信过的主机，这样在相应主机再次访问本机时，就能追踪其连接状态。iptables 就能根据”连接追踪机制“去检查连接的状态。连接追踪与通信协议没有任何关系，是内核记录连接状态的一种机制，它有如下几种状态: NEW：新发出请求；连接追踪模板中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求； ESTABLISHED：NEW状态之后，连接追踪模板中为其建立的条目失效之前期间内所进行的通信状态； RELATED：相关联的连接；如ftp协议中的数据连接与命令连接之间的关系； INVALID：无效的连接； UNTRACKED：未进行追踪的连接 连接追踪有时长限制，如果一条连接在设置的时长范围内没有再次发生连接，此连接记录就会被删除。下此与对应的主机再次建立连接时就会被当作新连接被重新记录。连接追踪机制非常耗费内容，如果连接追踪占据了所有的内存，新的连接就无法建立，因此不要在连接非常繁忙的反代服务器上开启连接追踪机制。如果一定要开启连接追踪机制，一是要准备足够大的内存，二是调大 nf_conntrack_max 的值。 2.2 连接追踪相关配置内核会在如下文件中记录连接追踪相关的信息: /proc/net/nf_conntrack: 作用: 已经追踪到并记录下来的连接 /proc/sys/net/netfilter/nf_conntrack_max 作用: 连接追踪功能所能够容纳的最大连接数量的配置文件 注意: 在一个非常繁忙的服务器上，一是要准备足够大的内存，二是将此配置调大 /proc/sys/net/netfilter/*timeout*: 不同的协议的连接追踪时长 2.3 state 扩展 作用: 对连接追踪的状态做匹配 参数: [!] --state state 配置: 1234&gt; iptables -A INPUT -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT&gt; iptables -I OUTPUT -m state --state ESTABLISHED -j ACCEPT 2.4 state 扩展相关问题iptables的链接跟踪表最大容量为/proc/sys/net/netfilter/nf_conntrack_max配置的值，链接碰到各种状态的超时后就会从表中删除；当内存满载时，后续的连接可能会超时解決方法一般有两个： 加大 nf_conntrack_max 值 降低 nf_conntrack timeout时间12345678910111213# 加大 nf_conntrack_max 值vi /etc/sysctl.confnet.ipv4.nf_conntrack_max = 393216net.ipv4.netfilter.nf_conntrack_max = 393216# 降低 nf_conntrack timeout时间vi /etc/sysctl.confnet.ipv4.netfilter.nf_conntrack_tcp_timeout_established = 300net.ipv4.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.ipv4.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.ipv4.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120iptables -t nat -L -n 2.5 如何开放被动模式的ftp服务 装载ftp连接追踪的专用模块： 放行命令连接(假设Server地址为172.16.100.67)： 放行数据连接(假设Server地址为172.16.100.67)：1234567891011121314151617181920# 1. 装载ftp连接追踪的专用模块&gt; modinfo /lib/modules/3.10.0-514.el7.x86_64/kernel/net/netfilter/nf_conntrack_ftp&gt; modproble nf_conntrack_ftp&gt; lsmod# 2. 放行请求报文# 命令连接: NEW, ESTABLISHED# 数据连接: RELATED(仅数据连接的第一次连接建立), ESTABLISHED&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state **NEW,ESTABLISHED** -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -p tcp --sport 21 -m state --state ESTABLISHED -j ACCEPT# 3. 放行响应报文 ESTABLISHED&gt; iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state **RELATED,ESTABLISHED** -j ACCEPT&gt; iptables -I OUTPUT -s 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT# 4. 合并 iptables 规则iptables -t filter -A INPUT -m --state ESTABLISHED,RELATED -j ACCEPTiptables -t filter -A INPUT -p tcp -d 192.168.1.108 -m multiport --dports 21,22,80 -m state --state NEW -j ACCEPTiptable -t filter -A OUTPUT -m --state ESTABLISHED -j ACCEPT 3. iptables 规则管理3.1 规则优化我们已经学习了很多 iptables 的扩展模块，有一些通用原则可以帮助我们优化 iptables 的规则 使用自定义链管理特定应用的相关规则，模块化管理 可安全放行所有入站的状态为ESTABLISHED状态的连接； 可安全放行所有出站的状态为ESTABLISHED状态的连接； 谨慎放行入站的新请求 有特殊目的限制访问功能，要于放行规则之前加以拒绝； 载规则的最后自定义默认策略，而不是直接使用 iptables 的默认策略，放置意外将 iptables 规则清空导致 ssh 无法连接至服务器 3.2 自定义链自定义链需要被内置链调用才能生效，且自定义链最后需要定义返回内置链。返回规则使用的处理动作叫做 RETURN，默认自定义链最后会自动 return 到调用链，提前返回需要提前显示 return。下面是自定义链的一个示例 12345678$ iptables -N ping_rule # 创建自定义链# 向自定义链添加规则$ iptables -A ping_rule -d 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT# 被内置链调用$ iptables -A INPUT -d 192.168.1.168 -p icmp -j ping_rule$ iptales -L 3.3 规则的保存及重载使用iptables命令定义的规则，会立刻送往内核，手动删除之前，其生效期限为kernel存活期限。永久保存需要手动保存规则至指定的文件中，需要时可重载保存于文件中的规则。 iptables-saveiptables-save &gt; path: 作用: 输出当前的 iptables 规则至终端，保存至文件需要重定向 iptables-restoreiptables-restore options &lt; path 作用: 重载文件中的 iptables 规则 选项: -n --noflush: 默认会清除已有规则，此选项表示不清除已有规则，只追加 -t --test: 仅分析生成规则集，不提交 1234567891011# 1. 保存规则# CentOS 6：iptables-save &gt; /PATH/TO/SOME_RULES_FILEservice iptables save # 将规则保存至/etc/sysconfig/iptables文件中；# CentOS 7:iptables-save &gt; /PATH/TO/SOME_RULES_FILE# 2. 重载规则: 重新载入预存规则文件中的规则 iptables-restore &lt; /PATH/FROM/SOME_RULES_FILEservice iptables restart # 从 /etc/sysconfig/iptables文件中重载规则，仅限于Centos6 3.4 iptables 规则开机自动载入Centos 6Centos 中 iptables 是独立的服务，其管理配置如下所示123456789101112131415# 开机启动 iptableschkconfig iptables on# iptables 服务启动脚本/etc/rc.d/init.d/iptables# iptables 规则的默认配置文件/etc/sysconfig/iptables# iptables 服务的配置文件/etc/sysconfig/iptables-config IPTABLES_MODULE=&quot; # 此选项配置要装载的模块# 开机自动导入可用脚本保存各iptables命令；让此脚本开机后自动运行；# 或者载自定义脚本中使用 iptables-restore 重载规则文件即可 CentOS 7Centos7 引入了新的iptables前端管理服务工具 firewalld，其包括很多管理工具，比如 firewalld-cmd，firewalld-config。其详细使用方式参见文档: http://www.ibm.com/developerworks/cn/linux/1507_caojh/index.html 所以在 Centos7 中实现规则开机自动载入，可以 编写 Unit 配置文件通过 systemctl 调用 iptables-restore 实现 借助于 firewalld 编写脚本，对于 iptables，最好还是使用此种方式，而且最好不要开机自动载入以免产生问题 5. 练习练习：INPUT和OUTPUT默认策略为DROP；123451、限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机；2、在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.16.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个；3、开放本机的ssh服务给172.16.x.1-172.16.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机；4、拒绝TCP标志位全部为1及全部为0的报文访问本机；5、允许本机ping别的主机；但不开放别的主机ping本机； 练习：判断下述规则的意义：12345678910111213141516171819202122# iptables -N clean_in# iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP# iptables -A clean_in -d 172.16.255.255 -p icmp -j DROP# iptables -A clean_in -p tcp ! --syn -m state --state NEW -j DROP# iptables -A clean_in -p tcp --tcp-flags ALL ALL -j DROP# iptables -A clean_in -p tcp --tcp-flags ALL NONE -j DROP# iptables -A clean_in -d 172.16.100.7 -j RETURN# iptables -A INPUT -d 172.16.100.7 -j clean_in# iptables -A INPUT -i lo -j ACCEPT# iptables -A OUTPUT -o lo -j ACCEPT# iptables -A INPUT -i eth0 -m multiport -p tcp --dports 53,113,135,137,139,445 -j DROP# iptables -A INPUT -i eth0 -m multiport -p udp --dports 53,113,135,137,139,445 -j DROP# iptables -A INPUT -i eth0 -p udp --dport 1026 -j DROP# iptables -A INPUT -i eth0 -m multiport -p tcp --dports 1433,4899 -j DROP# iptables -A INPUT -p icmp -m limit --limit 10/second -j ACCEPT]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.2 iptables使用入门]]></title>
    <url>%2F2018%2F09%2F12%2Flinux_mt%2F24-iptables%2Fiptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[iptables使用入门 iptables 是防火墙规则的管理工具，使用复杂，但是也有规律可循，个人总结起来就是”在哪，对什么报文，作出什么样的处理”。 iptables 有四表五链，首先要确定在iptables 的哪个表，哪个链条添加规则，这取决于要实现的功能和报文的流经途径 规则添加就是要对我们要处理的报文作出处理，因此就要指定报文的匹配条件和处理动作。个人觉得按照这样的逻辑去记忆能比较容易记住 iptables 的使用方式。下面我们就来详细介绍 iptables 的使用 1. iptables 命令简介1.1 规则配置原则iptables 会按照链上的规则每次从上至下依次检查，如果报文匹配并作出处理，那么就不会继续匹配接下来的规则。因此这样的检查次序隐含一定的应用法则： 同类规则（访问同一应用），匹配范围小的放上面； 不同类的规则（访问不同应用），匹配到报文频率较大的放在上面； 将那些可由一条规则描述的多个规则合并起来； 设置默认策略；这些应用原则其实很好懂，将频率高的放在最上面是为了减少匹配的次数，匹配范围小的放上面是为了让范围小的规则优先生效，很容易明白。 1.2 命令组成1234iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 iptables 命令组成如上所示: -t: 指定操作的表，默认为 filter chain: 指定操作的链 [-m matchname [per-match-options]]: 指定匹配条件，根据协议报文特征进行报文筛选，分为 基本匹配条件: iptables 内置，不会使用扩展模块，不需要 -m 选项指定模块 扩展匹配条件: 需要使用 -m 选项指定使用的扩展模块 -j targetname [per-target-options]: 指定处理动作，可分为: 基本处理动作: iptables 内置的处理动作 扩展处理动作: 通过扩展模块扩展的处理动作 自定义处理机制: 通常指的是自定义链 1.3 iptables 的扩展机制iptables 是高度模块化的，可以通过扩展模块更细粒度设置匹配条件和处理动作，这就是上面所说的扩展匹配条件和扩展处理动作。 1234567891011121314151617$ rpm -ql iptables |grep xtables/usr/lib64/xtables/libip6t_MASQUERADE.so # IPv6 的扩展模块/usr/lib64/xtables/libip6t_REDIRECT.so/usr/lib64/xtables/libip6t_REJECT.so/usr/lib64/xtables/libip6t_SNAT.so...../usr/lib64/xtables/libip6t_ah.so/usr/lib64/xtables/libip6t_dst.so/usr/lib64/xtables/libip6t_eui64.so...../usr/lib64/xtables/libipt_MASQUERADE.so # IPv4 扩展模块/usr/lib64/xtables/libipt_MIRROR.so....../usr/lib64/xtables/libxt_CT.so # libxt/usr/lib64/xtables/libxt_DSCP.so/usr/lib64/xtables/libxt_HMARK.so..... iptables 扩展模块的命名机制: 小写子母命名的是匹配条件 大写子母命令的是处理动作 libip6t 开头的对应于 IPv6 协议 libxt 和 libxt 开头的对应于 IPv4 协议 1.4 iptables 自定义链iptables的链分为内置链和自定义链 内置链：对应于netfilter 的勾子函数(hook function) 自定义链接：用于内置链的扩展和补充，可实现更灵活的规则管理机制；但报文不会经过自定义链，只能在内置链上通过规则进行引用后生效 有了这些基本介绍，我们现在开始介绍 iptables 的详细使用。 2. iptables 命令使用1234iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 2.1 基本命令iptables [-t table] COMMAND chain -t: 指定操作的表，默认为 filter (raw, mangle, nat, filter) chain: 指定操作的链(PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING) COMMAND: 字命令 链管理： -N：new, 自定义一条新的规则链； -X：delete，删除自定义的空的规则链，链非空或被其他链引用无法删除 -Z：zero，将规则计数器置零； -F：flush，清空指定的规则链；省略表示清空指定表上的所有链 -P：Policy，为指定链设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 REJECT：拒绝 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除； 规则管理： -A：append，追加； -I：insert, 插入，要指明位置，省略时表示第一条； -D：delete，删除； 指明规则序号； 指明匹配条件； -R：replace，替换指定链上的指定规则； 查看： -L：list, 列出指定鏈上的所有规则； -n：numberic，以数字格式显示地址和端口号(不对ip地址进行反解)； -v：verbose，详细信息，还有-vv, -vvv选项显示更详细的信息 -x：exactly，显示计数器结果的精确值； --line-numbers：显示规则的序号； 注意: -nvL 可以，-Lnv 不可以，因为 -L 是命令，其他的是 -L 的选项 12345$ sudo iptables -L -nvChain INPUT (policy ACCEPT 1368 packets, 8346K bytes) pkts bytes target prot opt in out source destination 0 0 ACCEPT udp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 udp dpt:53 0 0 ACCEPT tcp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:53 iptables的每条规则都有两个计数器： pkts: 统计匹配到的报文的个数； bytes: 匹配到的所有报文的大小之和； COMMAND 子命令格式12345678910111213# rule-specification = [matches...] [target] # match = -m matchname [per-match-options] # target = -j targetname [per-target-options]iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name 2.2 匹配条件：[-m matchname [per-match-options]] 基本匹配条件：无需加载任何模块，由iptables/netfilter自行提供； 扩展匹配条件： 需要加载扩展模块，方可生效； 基本匹配条件 [!] -s, --source address[/mask][,...]： 作用: 检查报文中的源IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -d, --destination address[/mask][,...]： 作用: 检查报文中的目标IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -p, --protocol {tcp|udp|icmp}： 作用: 检查报文中的协议，即ip 首部中的 protocols 所标识的协议 protocol: tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh or “all” [!] -i, --in-interface IFACE： 作用: 数据报文流入的接口；只能应用于数据报文流入的环节，只能应用于PREROUTING，INPUT和FORWARD链； [!] -o, --out-interface IFACE： 作用: 数据报文流出的接口；只能应用于数据报文流出的环节，只能应用于FORWARD、OUTPUT和POSTROUTING链 扩展匹配条件扩展匹配条件可分为显示扩展和隐式扩展两种: 显式扩展：必须要手动加载扩展模块， [-m matchname [per-match-options]]； 隐式扩展：不需要手动加载扩展模块；因为它们是对协议的扩展，所以，但凡使用-p指明了协议，就表示已经指明了要扩展的模块； 常见协议的隐式扩展如下所示: tcp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； [!] --tcp-flags list1 list2 作用: 检查list1 所指明的所有标志位，且这其中，list2 所列出的标志位必须为1，余下的必须为0，没在 list1 指明的，不做检查 例如：--tcp-flags SYN,ACK,FIN,RST SYN表示，要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0； [!] --syn：用于匹配第一次握手，相当于--tcp-flags SYN,ACK,FIN,RST SYN； 说明: 有关 tcp 连接的标识位，详见 24.8 tcp 协议简述 udp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； icmp [!] --icmp-type {type[/code]|typename} echo-request：ping 命令发送的请求的 icmp-type 为 8 echo-reply：ping 命令响应的 icmp-type 为 0 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 允许 ssh 连接&gt; iptables -t filter -A INPUT -d 192.168.1.105 -p tcp [-m tcp] --dport 22 -j ACCEPT&gt; iptables -t filter -A OUTPUT -s 192.168.1.105 -p tcp [-m tcp] --sport 22 -j ACCEPT# 允许 ping 出，不允许 ping 入&gt; iptables -A OUTPUT -s 192.168.1.105 -p icmp --icmp-type 8 -j ACCEPT&gt; iptables -A INPUT -d 192.168.1.105 -p icmp --icmp-type 0 -j ACCEPT# 通过规则设置默认策略&gt; iptables -P INPUT ACCEPT&gt; iptables -P OUTPUT ACCEPT&gt; iptables -F&gt; iptables -A INPUT -d 192.168.1.168 -p tcp --dport 22 -j ACCEPT&gt; iptables -A OUTPUT -s 192.168.1.168 -p tcp --sport 22 -j ACCEPT&gt; iptables -A OUTPUT -s 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT&gt; iptables -A INPUT -d 192.168.1.168 -p icmp --icmp-type 0 -j ACCEPT&gt; iptables -A INPUT -i enp0s3 -j DROP&gt; iptables -A OUTPUT -o enp0s3 -j DROP&gt; # iptables -L -nvChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 659 49584 ACCEPT tcp -- * * 0.0.0.0/0 192.168.1.168 tcp dpt:22 2 168 ACCEPT icmp -- * * 0.0.0.0/0 192.168.1.168 icmptype 0 10 677 DROP all -- enp0s3 * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 311 30248 ACCEPT tcp -- * * 192.168.1.168 0.0.0.0/0 tcp spt:22 2 168 ACCEPT icmp -- * * 192.168.1.168 0.0.0.0/0 icmptype 8 18 1304 DROP all -- * enp0s3 0.0.0.0/0 0.0.0.0/0``` ## 2.3 处理动作：`-j targetname [per-target-options]`- `ACCEPT`: 接受- `DROP`: 丢弃- `REJECT`: 拒绝- `RETURN`: 返回调用链- `REDIRECT`: 端口重定向- `LOG`: 记录日志- `MARK`: 做防火墙标记- `DNAT`: 目标地址转换- `SNAT`: 源地址转换- `MASQUERADE`: 地址伪装- 自定义链: 由自定义链上的规则进行匹配检查- ...... #### REJECT`REJECT --reject-with`- `--reject-with` - 设置拒绝连接的原因 - 可选值: `icmp6-no-route, no-route, icmp6-adm-prohibited, adm-prohibited, icmp6-addr-unreachable, addr-unreach, or icmp6-port-unreachable`, 默认为 `icmp-port-unreach‐able`#### LOG`LOG options`- 作用: 记录日志，默认日志保存于 `/var/log/messages`- 选项: - `--log-level`: 记录的日志级别 - `--log-prefix`: 在日志前增加的前缀 记录 telnet 连接$ iptables -I INPUT -d 192.168.1.168 -p tcp –dport 23 -m state –state NEW -j LOG``` 课后作业开放本机web服务器给非192.168.0.0/24网络中的主机访问禁止本机被非172.16.0.0/16网络中的主机进行ping请求开放本机的dns服务给所有主机]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.1 Linux防火墙基础理论]]></title>
    <url>%2F2018%2F09%2F11%2Flinux_mt%2F24-iptables%2FLinux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux防火墙基础理论 对于大多数人包括我自己在内，在未了解防火墙之前，防火墙是一个非常抽象的存在，只知道它能保护我们的计算机免受入侵；但是对于它是什么怎么工作的完全不知道。本章我们就来学习 Linux 的防火墙，对其一窥究竟。本章我们会首先介绍Linux 防火墙的理论，让大家清楚防火墙是什么，以及其工作原理，然后再来学习怎么写防火墙的过滤规则。本章内容包含如下: Linux 防火墙的理论基础 iptables 命令的使用 实现 nat 功能 要想说清楚防火墙的工作机制并不容易，需要从网络通信说起，我们首先得明白网络通信都是通过 TCP/IP 协议进行得，无论是正常得请求响应还是非法得入侵首先必需与我们得主机建立通信，而我们得防火墙就是在数据包到达本机之后，在报文得必经之地设下”管卡”，利用我们设置得过滤对报文进行检查，放行我们允许得数据报文，阻挡可疑得报文以达到保护主机得目的。所以 Linux 中得防火墙又称为包过滤型的防火墙。下面我们就来详细解释防火墙得工作机制，本节内容包括: Linux 防火墙工作机制 Linux 防火墙 Firewall 简介 iptables 的四表五链 1. 防火墙工作机制 (图一摘录自: http://bubufx.com/detail-1702595.html) (图一摘录自: 原作者不详) 上面两幅图很好的展示了Linux 防火墙的工作机制，说清楚第一幅图也就说清楚了防火墙的工作机制。 报文解析位于内核空间前面我们说过 TCP/IP 协议可分为 4 层，应用层，传输层，网络层和物理层；应用层属于资源子网位于用户空间，用于确定数据的组织形式，其他三层属于传输子网位于内核空间，用于传输数据。网络协议报文的封装，拆封装，路由决策都位于内核空间，由内核提供。 报文流向报文到达我们的主机时，首先经由网卡进入内核，内核解析 IP 报文首部得到报文的目标主机，此时发生第一路由决策。如果目标 IP 与本机 IP 相同，则该报文是发往本机，此时需要进一步拆封装传输层首部得到报文的目标端口，将其发送至注册使用此端口的进程，报文进入用户空间。这是图一中 1-&gt;2 标识的过程。 如果目标 IP 与本机 IP 不同，并且本机打开了路由转发功能，则需要将报文转发至其它主机，此时将发生第次二路由决策，因为本机可能由多块网卡，需要根据路由表决定由哪块网卡发出报文。这是图一中 1-&gt;4-&gt;5 标识的过程。 报文也可能经由本机发出，此时也将发生第二次路由决策，内核需要更据目标 IP和路由表决定报文由哪块网卡发出，这是图一中 3-&gt;5 标识的过程。 防火墙位于报文的必经之处流经本机的报文只有三个方向: 发往本机进入用户空间 流经本机，需要转发至其他主机 由本机发出 而防火墙就是在报本的必经之处设置了勾子(hook)，我们可以在勾子上添加规则，防火墙就可以根据我们设置的规则对报文进行过滤，以达到保护主机的功能。因此防火墙由两个部分组成: netfilter: 提供防火墙框架，位于内核中，提供了钩子函数(hook function),勾子位于图一中1-5标识的五个位置 iptables: 防火墙规则管理工具，便于用户向钩子函数添加规则。这部分是可有可无的，因为 netfilter 提供了系统调用接口，可以直接调用该系统调用向勾子添加规则，iptables 只是一个辅助工具。 netfilter 提供的勾子(hook function)在 iptables 中称为链，勾子跟链是一一对应的，链是勾子名称的大写而已。 勾子–&gt;链 prerouting -&gt; PREROUTING: 报文进入主机，并在第一次路由之前 input -&gt; INPUT: 进入用户空间之前 forward -&gt; FORWARD: 转发 output -&gt; OUTPUT: 由本机发出，并在第二次路由之前 postrouting -&gt; POSTROUTING: 报文离开主机，并在第二次路由之后 总结因此报文的流向可以总结为: 流向 途径的链 流入本机 PREROUTING --&gt; INPUT 由本机流出 OUTPUT --&gt; POSTROUTING 转发 PREROUTING --&gt; FORWARD --&gt; POSTROUTING 而路由发生在： 报文进入本机后：判断目标主机是谁 报文离开本机之前：判断经由哪个接口送往下一站 2. Firewall 简介现在我们可以对防火墙下一个定义了。防火墙是一种隔离工具，工作于主机或网络边缘，对于进出本主机或本网络的报文根据事先定义的检查规则作匹配检测，对于能够被规则匹配到的报文作出相应处理的组件。 2.1 分类和版本Firewall 在 Linux 已经迭代了三个版本，详细的信息大家可以查阅其他资料 ipfw (firewall framework) ipchains (firewall framework) iptables(netfilter) netfilter：位于 kernel，是防火墙框架，提供 hook functions iptables：rules until，防火墙规则管理工具 按照防火墙提供的功能可以将防火墙分为: 主机防火墙: 位于主机上，仅为当前主前主机提供防火墙功能 网络防火墙: 位于默认网关之上，为局域网内的所有主机提供防火墙功能。 也可以按照防火墙实现的方式分成: 软件防火墙（软件逻辑） 硬件防火墙（硬件和软件逻辑) 2.2 功能防火墙除了过滤功能外，还有其他功能，并且不同功能之间具有不同的优先级，优先级从高到低如下所示: filter：过滤，防火墙； nat：network address translation；用于修改源IP或目标IP，也可以改端口； mangle：拆解报文，做出修改，并重新封装起来； raw：关闭nat表上启用的连接追踪机制； 2.3 四表五链防火墙提供的功能在 iptables 中被称为表，不同的功能只能工作于特定的链上，因此就有了 iptables 的四表五链 功能 工作的链 filter INPUT，FORWARD，OUTPUT nat PREROUTING(DNAT)，[INPUT，OUTPUT](少见)，POSTROUTING(SNAT) mangle PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING raw PREROUTING， OUTPUT iptables 规则添加就是要确定在哪个表的何处添加规则 要实现哪种功能: 判断添加在哪张表上 报文流经的路径: 判断添加在哪条链上 3. Centos 的防火墙服务3.1 CentOS 6service iptables {start|stop|restart|status} start：读取事先保存的规则，并应用到netfilter上； stop：清空netfilter上的规则，以及还原默认策略等； status：显示生效的规则； restart：清空netfilter上的规则，再读取事先保存的规则，并应用到netfilter上； 默认的规则文件：/etc/sysconfig/iptables 3.2 CentOS 7Centos7 中默认的防火墙服务是 firewalld，这是在 iptables 基础上使用 python 编写的扩展，又一个图形化节界面，可以更方便的进行防火墙规则管理。因为内部仍然使用的 iptables，想根本的学会使用，还是要学习 iptables 的使用。 12345systemctl start|stop|restart|status firewalld.service# Linux 操作练习时建议关闭systemctl disable firewalld.servicesystemctl stop firewalld.service]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>防火墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20.1 ftp基础入门]]></title>
    <url>%2F2018%2F09%2F10%2Flinux_mt%2F23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1%2Fftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ftp基础入门 计算机上的磁盘设备有 SATA，SAS；IDE，SCSI；USB 等各种接口。以 SCSI 而言，SCSI 接口可以分线，一个接口可连接多个设备，我们的操作系统想要往磁盘上写数据时，需要标识哪块磁盘哪个位置。因此 SCSI 不仅代表一种硬盘，也代表了一种操作系统如和向磁盘读写数据的协议，而且与网络协议类似，这种协议是分层的。SCSI 协议结构如下图所示 因为协议是分层，所以如果将最底下的物理层替换为光纤，并通过 TCP/IP 协议进行网络传输，我们的磁盘设备就可以被互联网上的其他访问，从而达到共享存储的目的。对于 SCSI 大家不用太关心，只需要知道数据传输的协议都是分层的，我们可以通过替换底层的传输协议达到共享存储的目的，具体怎么实现大家无需关心。 类似于磁盘这种直接附加在总线上的的设备通常被称为 DAS(Direct Attached Storage)，DAS 输出给操作系统的接口是块(block),块可以被分区格式化。按照附加到操作系统的方式，我们将存储设备分成以下几个类别: DAS: Direct Attached Storage 接口类型：输出给操作系统的接口是”块” 设备：SATA，SAS；IDE，SCSI；USB； NAS: Network Attached Storage 接口类型: 输出给操作系统的接口是”文件” 依据传输数据的协议可以分为 CIFS: samba NFS: Network File System 说明: 这种方式就是我们可以把别人共享出来的文件系统直接挂载使用 SAN：Storage Area Network 存储区域网络 接口类型：”block” 协议：iSCSI(IP-SAN), FCSAN, FCoE, … 说明: 这种方式的实现方式就是类似与我们上述所说的，将 SCSI 协议底层的物理协议替换成 TCP/IP，让磁盘设备能够通过网络向其他主机输出块接口。而为了能够进行网络传输，原来的 SCSI 磁盘将被替换为一个主机，该主机负责向外输出存储。 ftp 不能视为为一种存储，因为其基本调用接口是不能在文件系统层级进行的，只能使用专门的客户端与其交互。ftp 是应用层协议实现的共享存储。本节我们就来依次介绍这几种服务: vsftpd NFS samba 需要注意的是，如果不是当网管上述几个服务用到的很少，所以我们只需要达到基本应用即可。 1. ftp 简介ftp 全称为 file transfer protocol，文件传输协议。ftp 诞生与互联网的早期，目标是完成文件传输，所以其传输数据的方式比较奇葩，本节我们就来对 ftp 做一个简单介绍。 1.1 ftp 传输过程 如上图所示，ftp 的连接分为两类 命令连接：传输命令 数据连接：传输数据 当需要传输数据时，客户端向 ftp 服务端的 21 端口发起连接请求建立连接，此连接主要用来传输客户端的命令。然后命令的操作不能在当前连接上传输，必需新建一条连接进行数据传输。 数据连接的创建有两种模式(从服务端的角度看) 主动模式(PORT)：Server端向客户端发起连接请求，请求的端口为命令连接使用的端口向后的第一个可用端口发起连接请求 被动模式(PASV): Server端打开一个随机端口，并通过命令连接告知客户端，并等待客户端连接 数据传输完成后，数据连接即断开，下此传输时在重新建立连接。 1.2 ftp 数据传输格式ftp 不会使用 MIME 对数据进行编码，ftp 会自动根据要传输的数据是文本格式还是二进制格式来选择传输机制。 1.3 ftp 的认证机制Linux 上有一个提供认证的共享服务 PAM(Pluggable Authenticate Module),PAM 是一个认证框架包括各种库，是高度模块化的，我们 ftp 就是调用 PAM 的服务提供认证功能的。 12345678910111213141516171819202122232425$ rpm -ql pam/etc/pam.d/etc/pam.d/config-util/etc/pam.d/fingerprint-auth/etc/pam.d/other/etc/pam.d/password-auth/etc/pam.d/postlogin/etc/pam.d/smartcard-auth/etc/pam.d/system-auth/etc/security# pam 的模块目录,每一个模块可以实现一种认证功能/usr/lib64/security /usr/lib64/security/pam_access.so/usr/lib64/security/pam_chroot.so............# 所有调用 pam 进行认证的服务如何进行认证，由此目录下的配置文件配置/etc/pam.d /etc/pam.d/config-util/etc/pam.d/fingerprint-auth/etc/pam.d/other/etc/pam.d/password-auth/etc/pam.d/postlogin...... 1.4 协议实现ftp 是 C/S 架构的服务，其服务端与客户端的常见实现有 Server 端： Windows: Serv-U, IIS, Filezilla 开源：wuftpd, proftpd, pureftpd, vsftpd(Very Secure FTP daemon), … Client 端： Windows：ftp, Filezilla, CuteFTP, FlashFXP, … 开源：lftp, ftp, Filezilla, gftp, … 2. vsftpd 简介vsftpd 全称是非常安全的 ftp 服务，功能有限但是非常安全，是 Linux 上最常用的 ftp 服务的实现。 1234567891011121314rpm -ql vsftpd$ rpm -ql vsftpd/etc/logrotate.d/vsftpd/etc/pam.d/vsftpd # pam 认证配置文件/etc/vsftpd # 配置文件目录/etc/vsftpd/ftpusers/etc/vsftpd/user_list/etc/vsftpd/vsftpd.conf # 配置文件/etc/vsftpd/vsftpd_conf_migrate.sh/usr/lib/systemd/system-generators/vsftpd-generator/usr/lib/systemd/system/vsftpd.service # 作为独立服务/usr/lib/systemd/system/vsftpd.target # 作为托管服务/usr/lib/systemd/system/vsftpd@.service/usr/sbin/vsftpd 2.1 路经映射ftp 也是通过 URL 进行资源定位的 SCHEME://username:password@HOST:PORT/PATH/TO/FILE。每个用户的URL的/映射到当前用户的家目录。yum 安装 vsftpd 时默认会创建 ftp 用户，vsftpd 以 ftp 用户的身份启动进程，默认用户即为ftp用户。匿名访问 ftp 服务时，匿名用户将自动映射为 ftp 用户。匿名用户又可称为 anonymous。所以匿名用户的/ 为 ftp 用户的家目录 /var/ftp/。 123456789101112131415161718192021$ grep &quot;^ftp&quot; /etc/passwdftp:x:14:50:FTP User:/var/ftp:/sbin/nologin$ systemctl start vsftpd.service# 默认就是匿名用户登陆$ lftp 192.168.1.106lftp 192.168.1.106:~&gt; lsdrwxr-xr-x 2 0 0 6 Aug 03 2017 pub# 使用 ftp 匿名登陆$ lftp -u ftp 192.168.1.106口令:lftp ftp@192.168.1.106:~&gt; ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub# 使用 anonymous 匿名登陆$ lftp -u anonymous 192.168.1.106口令:lftp anonymous@192.168.1.106:~&gt; ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub 2.3 ftp 用户的权限一个用户通过文件共享服务访问文件系统上的文件的生效权限为此用户在共享服务上拥有的共享权限与其在本地文件系统上拥有的权限的交集。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文件共享服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.4 MariaDB 权限管理]]></title>
    <url>%2F2018%2F09%2F09%2Flinux_mt%2F22-mysql%2FMariaDB%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MariaDB 权限管理 本节我们来介绍 MariaDB 中的权限管理 1. mysql 状态查询前面我们学习了 DDL 与 DML，下面是 mysql 一些常用的状态查询语句，用于查看mysql 的各种状态和变量。 作用 sql语句 -可用配置查询- ———- 查看支持的所有字符集 SHOW CHARACTER SET 查看支持的所有排序规则 SHOW COLLATION 查看数据库支持的所有存储引擎类型 SHOW ENGINES; -表状态信息- ———— 查看表状态 SHOW TABLES STATUS [LIKE &#39;tbl_name&#39;]\G 查看表上的索引的信息 SHOW INDEXES FROM tbl_name; 查看表结构 desc tbl_name; 查看表创建命令 show create table tbl_name; 查看指定用户所获得的授权 SHOW GRANTS FOR &#39;user&#39;@&#39;host&#39; 查看指定用户所获得的授权 SHOW GRANTS FOR CURRENT_USER; 2. DCL 用户账号及权限管理：2.1 用户账号mysql的用户账号由两部分组成：&#39;USERNAME&#39;@&#39;HOST&#39; USER: 表示用户名称 HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务. HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 12345vim /etc/mysql/my.cnf # 添加三个选项：[mysqld]datadir = /mydata/datainnodb_file_per_table = ONskip_name_resolve = ON # 配置禁止检查主机名 2.2 账号管理 创建用户账号：CREATE USER &#39;username&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; 删除用户账号：DROP USER ’user‘@’host&#39; [, user@host] ... 123mysqlmysql&gt; create user &apos;wpuser&apos;@&apos;%&apos; identified by &apos;wppass&apos;;mysql&gt; select * from mysql.user; 2.3 授权GRANT priv_type,... ON [object_type] db_name.tbl_name TO &#39;user&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; priv_type： 要授权的操作 ALL: 所有操作 db_name.tbl_name： 授权的范围 *.*：所有库的所有表； db_name.*：指定库的所有表； db_name.tbl_name：指定库的特定表； db_name.routine_name：指定库上的存储过程或存储函数 [object_type]: 授权可操作额对象 TABLE，默认 FUNCTION PROCEDURE 123mysqlmysqsl&gt; grant select,delete on testdb.* to &apos;test&apos;@&apos;%&apos; identified by &apos;testpass&apos;mysql&gt; revoke delete on testdb.* from &apos;test&apos;@&apos;%&apos;; 3.4 回收权限：REVOKE priv_type, ... ON db_name.tbl_name FROM &#39;user&#39;@&#39;host&#39;; 注意：MariaDB服务进程启动时，会读取mysql库的所有授权表至内存中； GRANT或REVOKE命令等执行的权限操作会保存于表中，MariaDB此时一般会自动重读授权表，权限修改会立即生效； 其它方式实现的权限修改，要想生效，必须手动运行FLUSH PRIVILEGES命令方可；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.3 SQL DDL 与 DML]]></title>
    <url>%2F2018%2F09%2F08%2Flinux_mt%2F22-mysql%2Fsql_DDL_DML%2F</url>
    <content type="text"><![CDATA[SQL DDL 与 DML SQL 是关系型数据库专用的结构化查询语言，用来管理和查询关系型数据库中的数据。本节我们就来学习基础的 SQL 语言。 1. SQL 的分类123456789101112131415161718192021MariaDB [(none)]&gt; help contentsYou asked for help about help category: &quot;Contents&quot;For more information, type &apos;help &lt;item&gt;&apos;, where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation Data Types Functions Functions and Modifiers for Use with GROUP BY Geographic Features Help Metadata Language Structure Plugins Procedures Table Maintenance Transactions User-Defined Functions Utility 在 mysql 客户端内使用 help contents 可以查看到 SQL 语句的所有类别，最常用的是如下三类: DDL：Data Defined Language 作用: 数据定义语言，主要用于管理数据库组件，例如表、索引、视图、用户、存储过程 命令: CREATE、ALTER、DROP DML：Data Manapulating Language 作用: 数据操纵语言，主要用管理表中的数据，实现数据的增、删、改、查； 命令: INSERT， DELETE， UPDATE， SELECT DCL: 作用: 权限管理命令 命令: GRANT，REVOKE 2 MariaDB 中的数据类型MariaDB 在存储数据之前，我们首先需要创建表，创建表的核心就是定义字段和取定表使用的字符集，而定义字段，关键的一步即为确定其数据类型。 数据类型用于确定数据存储格式、能参与运算种类、可表示的有效的数据范围。字符集就是码表，在字符和二进制数字之间建立映射关系，对于非英语系的国家字符集的设置至关重要。mysql 默认的字符集是 latin1，UTF8 在 mysql 中是 utf8mb4 而不是 utf8 12show character set # 查看 mysql 支持的字符集show collation # 查看字符集支持的排序方法 2.1 数据类型MariaDB 常见的数据类型如下所示: 字符型： 定长字符型： CHAR(#)：不区分字符大小写 BINARY(#)：区分字符大小写 变长字符型： VARCHAR(#)：不区分字符大小写 VARBINARY(#)：区分字符大小写 对象存储： TEXT：不区分字符大小写 BLOB：区分字符大小写 内置类型： SET ENUM 数值型： 精确数值型： INT（TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT) DECIMAL: 十进制数 近似数值型： FLOAT DOBULE 日期时间型： 日期型：DATE 时间型：TIME 日期时间型：DATETIME 时间戳：TIMESTAMP 年份：YEAR(2), YEAR(4)` 2.3 数据类型的修饰符MariaDB 的数据类型还有修饰符的概念，用于限定字段属性，常见的修饰符如下所示: 所有类型修饰符： NOT NULL：非空； DEFAULT value：默认值； primary key unique key 整型修饰符: UNSIGNED：无符号 AUTO_INCREMENT: 自增 3. DDL3.1 数据库管理123456789101112131415# 1. 创建：CREATE &#123;DATABASE | SCHEMA&#125; [IF NOT EXISTS] db_name; [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name # 2. 修改：ALTER &#123;DATABASE | SCHEMA&#125; [db_name] [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name# 3. 删除：DROP &#123;DATABASE | SCHEMA&#125; [IF EXISTS] db_name# 4. 查看：SHOW DATABASES LIKE ’‘; 3.2 表管理：help create table 创建： CREATE TABLE [IF NOT EXISTS] tbl_name (create_defination) [table_options] create_defination: 字段：col_name data_type 键： PRIMARY KEY (col1, col2, …) UNIQUE KEY (col1, col2,…) FOREIGN KEY (column) 索引：KEY|INDEX [index_name] (col1, col2,…) table_options： ENGINE [=] engine_name 修改： ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name [alter_specification [, alter_specification] ...] alter_specification: 字段： 添加：ADD [COLUMN] col_name data_type [FIRST | AFTER col_name ] 删除：DROP [COLUMN] col_name 修改： CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER col_name] – 更改字段名称 MODIFY [COLUMN] col_name column_definition [FIRST | AFTER col_name] – 更改字段属性定义 ALTER [COLUMN] col_name [SETDEFAULT literal | DROP DEFAULT] – 更改字段默认值 键： 添加：ADD {PRIMARY|UNIQUE|FOREIGN} KEY (col1, col2,…) 删除： 主键：DROP PRIMARY KEY 外键：DROP FOREIGN KEY fk_symbol 索引： 添加：ADD {INDEX|KEY} [index_name] (col1, col2,…) 删除：DROP {INDEX|KEY} index_name 表选项：ENGINE [=] engine_name 删除： DROP TABLE [IF EXISTS] tbl_name [, tbl_name] ... 表创建的其他方式12345# 1. 复制表结构；CREATE table like table_name;# 2. 复制表数据；CREATE table select_sql; 3.3 索引管理：索引是特殊的数据结构,定义在查找时作为查找条件的字段上，实现快速查找 创建12CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [BTREE|HASH] ON tbl_name (col1, col2,,...)` 删除DROP INDEX index_name ON tbl_name 4. DML：INSERT， DELETE， UPDATE， SELECT 4.1 INSERT INSERT [INTO] tbl_name [(col1,...)] {VALUES|VALUE} (val1, ...),(...),... 注意： 字符型：引号； 数值型：不能用引号； 4.2 SELECT： SELECT * FROM tbl_name; SELECT col1, col2, ... FROM tbl_name; 显示时，字段可以显示为别名: col_name AS col_alias SELECT col1, ... FROM tbl_name WHERE clause; WHERE clause：用于指明挑选条件； col_name 操作符 value： age &gt; 30; &gt;, &lt;, &gt;=, &lt;=, ==, != 组合条件：and or not BETWEEN … AND … LIKE ‘PATTERN’ %：任意长度的任意字符； _：任意单个字符； RLIKE ‘PATTERN’ 正则表达式对字符串做模式匹配； IS NULL IS NOT NULL SELECT col1, ... FROM tbl_name [WHERE clause] ORDER BY col_name, col_name2, ... [ASC|DESC]; ASC: 升序； DESC： 降序； 4.3 DELETE： DELETE FROM tbl_name [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] DELETE FROM tbl_name WHERE where_condition DELETE FROM tbl_name [ORDER BY ...] [LIMIT row_count] 4.4 UPDATE： UPDATE [LOW_PRIORITY] [IGNORE] table_reference SET col_name1=value1 [, col_name2=value2] ... [WHERE where_condition] [ORDER BY ...] [LIMIT row_count]]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.2 mysql的安装配置]]></title>
    <url>%2F2018%2F09%2F07%2Flinux_mt%2F22-mysql%2Fmariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysql的安装配置 上一节我们对关系型数据库和 mariadb 做了一个简单介绍，接下来我们来学习 mariadb 的安装配置 1. Mariadb 配置1.1 配置文件格式mysql 的配置文件是 ini 风格的配置文件；客户端和服务器端的多个程序可通过一个配置文件进行配置，使用 [program_name] 标识配置的程序即可。 1234567891011vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid# include all files from the config directory!includedir /etc/my.cnf.d 1.2 配置文件读取次序mysql 的各类程序启动时都读取不止一个配置文件，配置文件将按照特定的顺序读取，最后读取的为最终生效的配置。可以使用 my_print_defaults 查看默认的配置文件查找次序。 123$ my_print_defaultsDefault options are read from the following files in the given order:/etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf 配置文件查找次序默认情况下 OS Vendor提供mariadb rpm包安装的服务的配置文件查找次序： /etc/mysql/my.cnf /etc/my.cnf /etc/my.cnf.d/ --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 通用二进制格式安装的服务程序其配置文件查找次序 /etc/my.cnf /etc/my.cnf.d/ /etc/mysql/my.cnf --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 12345678910# os rpm 包安装的 mariadb 配置文件ll -d /etc/my*-rw-r--r--. 1 root root 570 6月 8 2017 /etc/my.cnfdrwxr-xr-x. 2 root root 67 2月 27 09:57 /etc/my.cnf.dll /etc/my.cnf.d总用量 12-rw-r--r--. 1 root root 295 4月 30 2017 client.cnf-rw-r--r--. 1 root root 232 4月 30 2017 mysql-clients.cnf-rw-r--r--. 1 root root 744 4月 30 2017 server.cnf 1.3 初始化配置mysql的用户账号由两部分组成：&#39;USERNAME&#39;@&#39;HOST&#39;; HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务.HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 1234vim /etc/mysql/my.cnf # 添加三个选项：datadir = /mydata/datainnodb_file_per_table = ONskip_name_resolve = ON 1.4 mysql 安全初始化默认安装的情况下 mysql root 帐户是没有密码的，可通过 mysql 提供的安全初始化脚本，快速进行安全初始化。1234567# 查看mysql用户及其密码mysql&gt; use mysql;&gt; select user,host,password from user;# 运行脚本安全初始化脚本/user/local/mysql/bin/mysql_secure_installation 2. MariaDB 安装常见的安装方式有如下三种: rpm包；由OS的发行商提供，或从程序官方直接下载 源码包编译安装: 编译安装，除非需要定制功能，否则一般不推荐编译安装 通用二进制格式的程序包: 展开至特定路径，并经过简单配置后即可使用，这种方式便于部署，无需解决环境依赖 2.1 二进制程序包安装Centos 6： 准备数据目录；以/mydata/data目录为例； 安装配置mariadb 12345678910111213groupadd -r -g 306 mysqluseradd -r -g 306 -u 306 mysqltar xf mariadb-VERSION.tar.xz -C /usr/localcd /usr/localln -sv mariadb-VERSION mysqlcd /usr/local/mysqlchown -R root:mysql ./*scripts/mysql_install_db --user=mysql -datadir=/mydata/datacp support-files/mysql.server /etc/init.d/mysqldchkconfig --add mysqldchkconfig --list mysqld# 跳过名称解析，并进行安全初始化]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.1 mysql 数据库基础]]></title>
    <url>%2F2018%2F09%2F06%2Flinux_mt%2F22-mysql%2Fmariadb%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[mysql 数据库基础 本章我们来学习 MySQL，数据库本身是一个很复杂的内容，有很多的基本概念，想在短篇幅之内把其中的知识点讲清除并不容易。本章博客自我感觉整理的不好，后续会持续更新。本章将包括以下内容: 什么是关系型数据库 mysql 客户端的使用 mysql 的安装与配置 sql 语句的使用 mysql 中的权限管理 mariadb(mysql) 是最常用的开源关系型数据库，本节我们就对关系型数据库和 mysql 做一个简单介绍。 1. 关系型数据库1.1 数据模型数据模型有，层次模型、网状模型、关系模型。关系模型是二维关系表现为表中的列和行。数据库管理系统称为 DBMS(DataBase Management System)，关系型数据库管理系统则称为 RDBMS(Relational DataBase Management System)，常见的 RDMBS: Mysql/MariaDB/Percona-Server PostgreSQL Oracle 1.2 事务(Transaction)事务含义是将多个操作为一个整体，要么全部都执行，要么全部都不执行；其遵循 ACID： A：Atomicity,原子性； C：Consistency,一致性； I：Isolation,隔离性； D：Durability,持久性； 2. RDMBS设计范式设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。目前关系数据库有六种范式： 第一范式（1NF）: 每一列都是原子，不可在分割的 第二范式（2NF）: 每一行都可以使用其有限字段进行唯一标志(不存在重复的行) 第三范式（3NF）、巴德斯科范式（BCNF）: 任何表都不应该有依赖于其他表的非主键字段 第四范式(4NF）和 第五范式（5NF，又称完美范式） 满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。 3. mysql 简介自从 mysql 被 Oracle 收购之后，由于担心版权问题，mysql 的创始人就新建了另一开源分支 mariadb，在 Centos6 中默认安装的是 mysql，而在 Centos7 中默认安装的已经是 mariadb。mariadb 跟 mysql 底层的基础特性是类似的，但是高级特性有很大不同，彼此支持的高级功能也不相同。除了 mariadb，mysql还有很多二次发行版本，比如Percona，AllSQL(阿里的mysql 发行版)以及，TIDB mysql 与 mariadb 的官网分别是： www.mysql.com MariaDB: www.mariadb.org 3.1 mariadb 特性MariaDB的 支持插件式存储引擎，即存储管理器有多种实现版本，彼此间的功能和特性可能略有区别；用户可根据需要灵活选择。存储引擎也称为“表类型”。常见的存储引擎就是 MyISAM:不支持事务和表级锁，奔溃后不保证安全恢复； InnoDB: 支持事务，行级锁，外键和热备份； MyISAM 在 mariadb 中被扩展为 Aria，支持安全恢复, InnoDB 在 Mariadb 中的开源实现为 XtraDB。在 mysql 的客户端中输入 show engines 即可查看 mariadb 支持的所有存储引擎。 123456789101112131415MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| CSV | YES | CSV storage engine | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ 3.2 MariaDB程序的组成mariadb 是 C/S 架构的服务，其命令分为服务器端和客户端两个部分 C：Client mysql：CLI交互式客户端程序； mysqldump：备份工具； mysqladmin：管理工具； mysqlbinlog： … S：Server mysqld mysqld_safe：建议运行的服务端程序； mysqld_multi：多实例； msyql 服务器可监听在两种套接字上 IPV4/6 的 tcp 的 3306 端口上，支持远程通信 Unix Sock，监听在 socket 文件上，仅支持本地通信，套接子文件通常位于 /var/lib/mysql/mysql.sock或 /tmp/mysql.sock 由配置文件指定。 12ll /var/lib/mysql/mysql.socksrwxrwxrwx. 1 mysql mysql 0 8月 21 11:10 /var/lib/mysql/mysql.sock 3.3 mysql 客户端启动命令mysql [OPTIONS] [database] 常用选项： -u, --user=name：用户名，默认为root； -h, --host=name：远程主机（即mysql服务器）地址，默认为localhost; -p, --password：USERNAME所表示的用户的密码； 默认为空； -P, --port: 指定 mysql 服务监听的端口，默认为 3306 -D, --database：连接到服务器端之后，设定其处指明的数据库为默认数据库； -e, --execute=&#39;SQL COMMAND;&#39;：连接至服务器并让其执行此命令后直接返回； -S, --socket: 指定本地通信的套接字路经 mysql 客户端内可输入的命令分为两类: 客户段命令: 只在客户端运行的命令，使用 help 可获取此类命令的帮助 服务段命令: 通过 mysql 的协议送到服务段运行的命令，所以必须要有命令结束符,默认为 ;；使用 help contents 获取服务器端命令使用帮助。 查看本地命令mysql&gt; help \u db_name：设定哪个库为默认数据库 \q：退出 \d CHAR：设定新的语句结束符，默认为 ; \g：语句结束标记，默认就相当于 ; 作用 \G：语句结束标记，结果竖排方式显式 \! COMMAND: 在客户端内运行 shell 命令 \. PATH: 在客户端内执行 sql 脚本(包含 sql 的文本) 12345678910111213141516171819202122232425262728293031323334353637$ mysql -uroot -p1234MariaDB [(none)]&gt; help # help 查看 mysql 的所有命令List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.clear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.For server side help, type &apos;help contents&apos;# 执行 shell 命令MariaDB [(none)]&gt; \! ls /varaccount cache db games iso lib lock mail nis preserve spool tmp ypadm crash empty gopher kerberos local log named opt run target www 查看服务端命令12345678910111213141516171819202122232425262728293031323334MariaDB [(none)]&gt; help contents # 查看 mysql 命令的组成部分For more information, type &apos;help &lt;item&gt;&apos;, where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation.........MariaDB [(none)]&gt; help &apos;Account Management&apos; # 查看特定命令组内的命令topics: CREATE USER DROP USER GRANT RENAME USER REVOKE SET PASSWORDMariaDB [(none)]&gt; help &apos;CREATE USER&apos; # 查看特定命令使用帮助Name: &apos;CREATE USER&apos;Description:Syntax:CREATE USER user_specification [, user_specification] ...user_specification: user [ IDENTIFIED BY [PASSWORD] &apos;password&apos; | IDENTIFIED WITH auth_plugin [AS &apos;auth_string&apos;] ]............... 3.4 mysql 数据库组件mysql 数据库包括如下组件: 数据库: database 表: table: 行: row 列: column 索引: index 视图: view 用户: user 权限: privilege 存储过程: procedure 存储函数: function 触发器: trigger 事件调度器: event scheduler]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.5 编译安装 lamp-fpm]]></title>
    <url>%2F2018%2F09%2F05%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm%2F</url>
    <content type="text"><![CDATA[编译安装 lamp-fpm 1. Centos6 编译安装 lamp-fpm1.1 编译安装步骤 httpd：编译安装，httpd-2.4 mairadb：通用二进制格式，mariadb-5.5 php5：编译安装，php-5.4 xchache 注意：任何一个程序包被编译操作依赖到时，需要安装此程序包的“开发”组件，其包名一般类似于name-devel-VERSION； 1.2 编译安装apache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 准备开发环境yum groupinstall &quot;Development Tools&quot; &quot;Server Platform Development&quot; -y# 1. 编译安装aprtar xf apr-1.5.0.tar.bz2cd apr-1.5.0./configure --prefix=/usr/local/aprmake &amp;&amp; make install# 2. 编译安装apr-utiltar xf apr-util-1.5.3.tar.bz2cd apr-util-1.5.3./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/aprmake &amp;&amp; make install# 3. httpd-2.4.9编译过程也要依赖于pcre-devel软件包，需要事先安装yum install pcre-devel -y# 4. 编译安装httpd-2.4.9tar xf httpd-2.4.9.tar.bz2cd httpd-2.4.9./configure --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --enable-modules=most --enable-mpms-shared=all --with-mpm=event --prefix=/usr/local/apache --sysconfdir=/etc/httpd24 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-utilmake &amp;&amp; make install# 5. 提供SysV服务脚本/etc/rc.d/init.d/httpdcd /etc/rc.d/init.dcp httpd httpd24vim http24 &gt; apachectl=/usr/local/apache/bin/apachectl &gt; httpd=$&#123;HTTPD-/usr/local/apache/bin/httpd&#125; &gt; pidfile= &gt; logfile=chkconfig --add httpd24chkconfig --list httpd24# 6. 配置系统环境vim /etc/profile.d/httpd24.sh &gt; export PATH=/usr/local/apache/bin:$PATH. /etc/profile.d/httpd24.shhttpd -tservice start httpd24# 7. 修改配置文件cd /etc/httpd24vim httpd.conf &gt; PidFile &quot;/var/run/httpd.pid&quot; # 说明:# httpd.conf 中的 PidFile 必须与 init 服务启动脚本中的pidfile 保持一致# 默认 httpd.conf 的PidFile=/usr/local/apache/logs/httpd.pid 1.3 编译安装 Mariadb123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 1. 准备数据存放的文件系统# 新建一个逻辑卷，并将其挂载至特定目录即可# 假设挂载目录为/mydata，/mydata/data 为mysql数据的存放目录# 2. 新建用户以安全方式运行进程：groupadd -r mysqluseradd -g mysql -r -s /sbin/nologin -M -d /mydata/data mysqlchown -R mysql:mysql /mydata/data# 3. 安装并初始化mariadb# 下载通用二进制包 mariadb-5.5.60-linux-systemd-x86_64.tar.gztar xf mysql-5.5.33-linux2.6-i686.tar.gz -C /usr/localcd /usr/local/ln -sv mysql-5.5.33-linux2.6-i686 mysqlcd mysqlchown -R mysql:mysql .scripts/mysql_install_db --user=mysql --datadir=/mydata/datachown -R root .# 4. 为mysql提供主配置文件：cd /usr/local/mysqlcp support-files/my-large.cnf /etc/my.cnfvim /etc/my.cnf &gt; thread_concurrency = cpu * 2 &gt; datadir = /mydata/data &gt; innodb_file_per_table = on &gt; skip_name_resolve = on# 5. 为mysql提供sysv服务脚本：cd /usr/local/mysqlcp support-files/mysql.server /etc/rc.d/init.d/mysqldchmod +x /etc/rc.d/init.d/mysqldchkconfig --add mysqldchkconfig mysqld onservice start mysqld# 6. 删除 mysql 匿名用户cd /usr/local/mysqlscripts/mysql_secure_installation# 7. man，PATH 环境变量# 输出mysql的man手册至man命令的查找路径vim /etc/man.config &gt; MANPATH /usr/local/mysql/man# 输出mysql的头文件至系统头文件路径/usr/includeln -sv /usr/local/mysql/include /usr/include/mysql# 输出mysql的库文件给系统库查找路径echo &apos;/usr/local/mysql/lib&apos; &gt; /etc/ld.so.conf.d/mysql.confldconfig # 让系统重新载入库# 修改PATH环境变量vim /etc/profile.d/mysql.sh &gt; export PATH=/usr/local/mysql/bin:$PATH 1.4 编译安装 php1234567891011121314151617181920212223242526272829303132333435363738394041424344# 1. 解决依赖关系：yum -y groupinstall &quot;X Software Development&quot;# 如果想让编译的php支持mcrypt扩展yum install libmcryptyum install libmcrypt-develyum install mhashyum install mhash-devel# 2. 编译安装 phptar xf php-5.4.26.tar.bz2cd php-5.4.26./configure --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-openssl --with-mysqli=/usr/local/mysql/bin/mysql_config --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --enable-fpm --with-mcrypt --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-bz2# 说明： # fpm 必须启用 --enable-fpm # 需要更改的配置有 # --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.dmakemake intall# 3. 为php提供配置文件：cp php.ini-production /etc/php.ini# 4. 为php-fpm提供SysV init脚本，并将其添加至服务列表：cp sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpmchkconfig --add php-fpmchkconfig php-fpm on# 5. 为php-fpm提供配置文件：cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf# 配置fpm的相关选项为你所需要的值，并启用pid文件（如下最后一行）：vim /usr/local/php/etc/php-fpm.conf &gt; pm.max_children = 50 &gt; pm.start_servers = 5 &gt; pm.min_spare_servers = 2 &gt; pm.max_spare_servers = 8 &gt; pid = /usr/local/php/var/run/php-fpm.pid # 与 init 脚本一致# 启动php-fpm, 默认情况下，fpm监听在127.0.0.1的9000端口service php-fpm start ps aux | grep php-fpm 1.5 配置 httpd1234567891011121314151617181920212223242526272829303132333435# 1. 启用httpd的相关模块vim /etc/httpd/httpd.conf &gt; LoadModule proxy_module modules/mod_proxy.so &gt; LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so# 2. 配置虚拟主机支持使用fcgi# 在相应的虚拟主机中添加类似如下两行。 &gt; ProxyRequests Off &gt; ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1# ProxyRequests Off：关闭正向代理# ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。# 虚拟主机配置示例DirectoryIndex index.php&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 &lt;Directory &quot;/apps/vhosts/b.net&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; # 3. 让apache能识别php格式的页面，并支持php格式的主页,并支持php格式的主页vim /etc/httpd/httpd.conf &gt; AddType application/x-httpd-php .php &gt; AddType application/x-httpd-php-source .phps &gt; DirectoryIndex index.php index.html 1.6 安装 xcache12345678910111213# 1. 安装tar xf xcache-3.0.3.tar.gzcd xcache-3.0.3/usr/local/php/bin/phpize./configure --enable-xcache --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; make install# 安装结束时，会出现类似如下行：# Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-zts-20100525/cp xcache.ini /etc/php.dvim /etc/php.d/xcache.ini &gt; extension=&quot;上述安装结束提示的路径&quot; 1.7 php-fpm 配置vim /usr/local/php/etc/php-fpm.conf pm = static|dynamic static：固定数量的子进程； pm.max_children； dynamic：子进程数据以动态模式管理； pm.start_servers pm.min_spare_servers pm.max_spare_servers ;pm.max_requests = 500 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限；12# mkdir /var/lib/php/session# chown apache.apache /var/lib/php/session]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.4 LAMP部署示例]]></title>
    <url>%2F2018%2F09%2F04%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[LAMP部署示例 本节我们就来部署两个经典的 php 开源项目作为演示部署 LAMP 的示例 1. httpd部署示例1.1 wordpress 部署12345678910111213141516# wordpress 配置unzip wordpress-2.9.2.zipcp -a wordpress /www/htdoccd /www/htdoc/wordpresscp wp-config-sample.php wp-config.phpvim wp-config.php # 更改mysql 连接的账号，密码，数据库# mariadb 配置mysqlmysql&gt; grant all on wpdb.* to "wpuser"@"localhost" identified by "wppasswd"mysql&gt; grant all on wpdb.* to "wpuser"@"127.0.0.1" identified by "wppasswd"mysql&gt; create datebase wpdbmysql&gt; flush privilegesvim /etc/my.cnf.d/server.cnfskip-name-resolve=ON 1.2 phpMyAdmin 部署1234567891011121314151617# 系统环境yum install php-mbstring# phpMyAdmin 配置unzip phpMyAdmin-version.zipcp -a phpMyAdmin-version /www/htdoc/cd /www/htdocln -sv phpMyAdmin-version pmacd pmacp config.sample.inc.php config.inc.phpvim config.inc.php # 修改 $cfg['blowfish_secret'] = ''# mysql 账号配置:mysqlmysql&gt; set password for 'root'@'localhost' = PASSWORD('mageedu')mysql&gt; set password for 'root'@'127.0.0.1' = PASSWORD('mageedu')mysql&gt; flush privileges]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.3 LAMP安装]]></title>
    <url>%2F2018%2F09%2F03%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[LAMP安装 前面我们我们介绍了 LAMP 的原理部分，本节我们就来实践，搭建一个 LAMP。 1. php 配置1.1 httpd 与 php 结合方式前面我们介绍 LAMP 的基本原理时提到过，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 prefork MPM 下需要加载 libphp5.so 模块 event, worker MPM 下需要加载 libphp5-zts.so 模块 modules将 php 作为 http 的 modules 由 php 包提供12345678$ yum info php$ rpm -ql php/etc/httpd/conf.d/php.conf/etc/httpd/conf.modules.d/10-php.conf/usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块/usr/share/httpd/icons/php.gif/var/lib/php/session fpmfpm 由 php-fpm 包提供1234567891011$ yum info php-fpm$ rpm -ql php-fpm/etc/logrotate.d/php-fpm/etc/php-fpm.conf # php-fpm 服务的配置文件/etc/php-fpm.d/etc/php-fpm.d/www.conf/etc/sysconfig/php-fpm/run/php-fpm/usr/lib/systemd/system/php-fpm.service/usr/lib/tmpfiles.d/php-fpm.conf/usr/sbin/php-fpm 1.2 php 相关包与 php 相关的 rpm 包有如下几个: php: 实现 php 作为 httpd 的一个模块 php-fpm: fpm php-common: php 的核心文件 php-mysql: php 的 mysql 驱动模块 php-xcache: php 的加速器 1.3 php核心文件1234567891011$ rpm -ql php-common/etc/php.ini # 配置文件/etc/php.d/etc/php.d/curl.ini/etc/php.d/fileinfo.ini/etc/php.d/json.ini/etc/php.d/phar.ini/etc/php.d/zip.ini/usr/lib64/php/usr/share/php/var/lib/php php 的所有核心文件均由 php-common 包提供，配置文件为: /etc/php.ini /etc/php.d/*.ini php 的配置文件在 php 启动时被读取一次 对于服务器模块存在的 php 仅在web 服务器启动时读取一次 Modules：重启httpd服务生效； FastCGI：重启php-fpm服务生效； 对于cgi 和 cli 版本，每次调用都会读取 php.iniphp 的文档参考如下: php.ini的核心配置选项文档： http://php.net/manual/zh/ini.core.php php.ini配置选项列表：http://php.net/manual/zh/ini.list.php 注释符： 较新的版本中，已经完全使用;进行注释； #：纯粹的注释信息 ;：用于注释可启用的directive 1234# 配置方式类似 yum.respo.d, 采用分段进行# ;(分号) 表示注释符[foo]：Section Headerdirective = value 1.3 php xcache 加速器12345# 安装yum install php-xcache# 配置/etc/php.d/xcache.ini 2. modules 模式的 LAMP 安装首先我们来介绍将 php 作为 httpd 的一作模块这种模式下 LAMP 的安装配置。安装完成后 php 的配置文件位于 /etc/httpd/conf.d/php.conf 2.1 Centos 6Centos 下需要安装 httpd, php, php-mysql, mysql-server，然后启动 httpd 和 mysql 服务 123yum install -y httpd php php-mysql mysql-serverservice httpd startservice mysqld star 2.2 Centos 7Centos7 下需要安装 httpd, php, php-mysql, mariadb-server。需要注意的是 php 在不同的 MPM 下安装的方式不一样，默认 yum install php 安装要求 httpd 使用 prefork MPM。 123456789101112# 1. 安装 LAMPyum install http php php-mysql mariadb-serversystemctl start httpdsystemctl start mariadb# 2. php 的配置$ rpm -ql php/etc/httpd/conf.d/php.conf/etc/httpd/conf.modules.d/10-php.conf/usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块/usr/share/httpd/icons/php.gif/var/lib/php/session 2.3 测试php 程序执行环境123&lt;?php phpinfo()?&gt; php 与mysql 通信12345678910# vim DocumentRoot/a.php&lt;?php $con=mysql_connect(&apos;127.0.0.1&apos;,&apos;&apos;,&apos;&apos;); if ($con) echo &quot;OK&quot;; else echo &quot;faile&quot;; mysql_close(); phpinfo();?&gt; 3. fpm 的 LAMP 安装3.1 Centos6 PHP-5.3.2：默认不支持fpm机制；需要自行打补丁并编译安装； httpd-2.2：默认不支持fcgi协议，需要自行编译此模块； 解决方案：编译安装httpd-2.4, php-5.3.3+； 3.2 Centos7 httpd-2.4：rpm包默认编译支持了fcgi模块； php-fpm包：专用于将php运行于fpm模式； 安装 msyql123456789101112131415# 1. 安装 msyqlyum isntall -y mariadb-servervim /etc/my.cnf.d/server.cnf [mysqld] skip_name_resolve=ON innodb_file_per_table=ON# 安全初始化mysql_secure_installation# 创建普通登陆用户# mysql -uroot -pmysql&gt; grant all on testdb.* to &apos;myuser&apos;@&apos;172.16.0.%&apos; indentified by &quot;mypass&quot;mysql&gt; flush priviledges 安装 php-fpm123456789101112131415161718192021222324# 2. 安装 php-fpm，最好不要与 php 包同时安装yum install php-fpm php-mysql php-mbstring$ rpm -ql php-fpm/etc/logrotate.d/php-fpm/etc/php-fpm.conf/etc/php-fpm.d/etc/php-fpm.d/www.conf# 配置 php-fpmvim /etc/php-fpm.confvim /etc/php-fpm.d/www.conf pm = static|dynamic # - static：固定数量的子进程； # - pm.max_children； # - dynamic：子进程数据以动态模式管理； # - pm.start_servers # - pm.min_spare_servers # - pm.max_spare_servers # - ;pm.max_requests = 500# 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限；mkdir /var/lib/php/sessionchown apache.apache /var/lib/php/session 配置 httpd12345678910111213141516171819202122232425262728293031# 1. 确定是否启用httpd的相关模块httpd -M|grep proxy_module# 未启用则启用代理模块vim /etc/httpd/httpd.conf &gt; LoadModule proxy_module modules/mod_proxy.so &gt; LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so# 2. 配置虚拟主机支持使用fcgi# 在相应的虚拟主机中添加类似如下两行。 &gt; ProxyRequests Off &gt; ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1# ProxyRequests Off：关闭正向代理# ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。# 虚拟主机配置示例DirectoryIndex index.php&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 &lt;Directory &quot;/apps/vhosts/b.net&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 安装 php xcache12345yum install -y php-xcache$ rpm -ql php-xcache/etc/php.d/xcache.ini/usr/lib64/php/modules/xcache.so]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.2 PHP 基础]]></title>
    <url>%2F2018%2F09%2F02%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2Fphp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[PHP 基础 “PHP 是世界上最好的语言”,因为我们后面会以 php 为例配置一个 LAMP，所以本节我们就来先了解一下 php。这里就是一个简单介绍，因为我也没学过 php，所以大多数内容都是摘录自马哥的上课笔记。 1. 关于PHP1.1 PHP 简介PHP是通用服务器端脚本编程语言，其主要用于web开发以实现动态web页面，它也是最早实现将脚本嵌入HTML源码文档中的服务器端脚本语言之一。同时，php还提供了一个命令行接口，因此，其也可以在大多数系统上作为一个独立的shell来使用。 Rasmus Lerdorf于1994年开始开发PHP，它是初是一组被Rasmus Lerdorf称作“Personal Home Page Tool” 的Perl脚本， 这些脚本可以用于显示作者的简历并记录用户对其网站的访问。后来，Rasmus Lerdorf使用C语言将这些Perl脚本重写为CGI程序，还为其增加了运行Web forms的能力以及与数据库交互的特性，并将其重命名为“Personal Home Page/Forms Interpreter”或“PHP/FI”。此时，PHP/FI已经可以用于开发简单的动态web程序了，这即是PHP 1.0。 1995年6月，Rasmus Lerdorf把它的PHP发布于comp.infosystems.www.authoring.cgi Usenet讨论组，从此PHP开始走进人们的视野。1997年，其2.0版本发布。 1997年，两名以色列程序员Zeev Suraski和Andi Gutmans重写的PHP的分析器(parser)成为PHP发展到3.0的基础，而且从此将PHP重命名为PHP: Hypertext Preprocessor。此后，这两名程序员开始重写整个PHP核心，并于1999年发布了Zend Engine 1.0，这也意味着PHP 4.0的诞生。 2004年7月，Zend Engine 2.0发布，由此也将PHP带入了PHP 5时代。PHP5包含了许多重要的新特性，如增强的面向对象编程的支持、支持PDO(PHP Data Objects)扩展机制以及一系列对PHP性能的改进。 1.2 PHP Zend EngineZend Engine是开源的、PHP脚本语言的解释器，它最早是由以色列理工学院(Technion)的学生Andi Gutmans和Zeev Suraski所开发，Zend也正是此二人名字的合称。后来两人联合创立了Zend Technologies公司。 Zend Engine 1.0于1999年随PHP 4发布，由C语言开发且经过高度优化，并能够做为PHP的后端模块使用。Zend Engine为PHP提供了内存和资源管理的功能以及其它的一些标准服务，其高性能、可靠性和可扩展性在促进PHP成为一种流行的语言方面发挥了重要作用。 Zend Engine的出现将PHP代码的处理过程分成了两个阶段： 首先是分析PHP代码并将其转换为称作Zend opcode的二进制格式(类似Java的字节码)，并将其存储于内存中； 第二阶段是使用Zend Engine去执行这些转换后的Opcode。 1.3 PHP的OpcodeOpcode: 是一种PHP脚本编译后的中间语言，就像Java的ByteCode,或者.NET的MSL。PHP执行PHP脚本代码一般经过如下4个步骤(确切的来说，应该是PHP的语言引擎Zend)： Scanning(Lexing): 将PHP代码转换为语言片段(Tokens) Parsing: 将Tokens转换成简单而有意义的表达式 Compilation: 将表达式编译成Opocdes Execution: 顺次执行Opcodes，每次一条，从而实现PHP脚本的功能 总结: 扫描–&gt;分析–&gt;编译–&gt;执行 1.4 php的加速器 原理: 基于PHP的特殊扩展机制如opcode缓存扩展也可以将opcode缓存于php的共享内存中，从而可以让同一段代码的后续重复执行时跳过编译阶段以提高性能。 由此也可以看出，这些加速器并非真正提高了opcode的运行速度，而仅是通过分析opcode后并将它们重新排列以达到快速执行的目的。 常见的php加速器有： APC (Alternative PHP Cache) 遵循PHP License的开源框架，PHP opcode缓存加速器， 目前的版本不适用于PHP 5.4 项目地址，http://pecl.php.net/package/APC。 eAccelerator 源于Turck MMCache，早期的版本包含了一个PHP encoder和PHP loader，目前encoder已经不在支持 项目地址， http://eaccelerator.net/。 XCache 快速而且稳定的PHP opcode缓存，经过严格测试且被大量用于生产环境。 项目地址，http://xcache.lighttpd.net/ yum install php-xcache Zend Optimizer和Zend Guard Loader Zend Optimizer并非一个opcode加速器，它是由Zend Technologies为PHP5.2及以前的版本提供的一个免费、闭源的PHP扩展，其能够运行由Zend Guard生成的加密的PHP代码或模糊代码。 而Zend Guard Loader则是专为PHP5.3提供的类似于Zend Optimizer功能的扩展。 项目地址，http://www.zend.com/en/products/guard/runtime-decoders NuSphere PhpExpress NuSphere的一款开源PHP加速器，它支持装载通过NuSphere PHP Encoder编码的PHP程序文件，并能够实现对常规PHP文件的执行加速。 项目地址，http://www.nusphere.com/products/phpexpress.htm 1.5 PHP源码目录结构其代码根目录中主要包含了一些说明文件以及设计方案，并提供了如下子目录： build: 顾名思义，这里主要放置一些跟源码编译相关的文件，比如开始构建之前的buildconf脚本及一些检查环境的脚本等。 ext: 官方的扩展目录，包括了绝大多数PHP的函数的定义和实现，如array系列，pdo系列，spl系列等函数的实现。 个人开发的扩展在测试时也可以放到这个目录，以方便测试等。 main: 这里存放的就是PHP最为核心的文件了，是实现PHP的基础设施，这里和Zend引擎不一样，Zend引擎主要实现语言最核心的语言运行环境。 Zend: Zend引擎的实现目录，比如脚本的词法语法解析，opcode的执行以及扩展机制的实现等等。 pear: PHP 扩展与应用仓库，包含PEAR的核心文件。 sapi: 包含了各种服务器抽象层的代码，例如apache的mod_php，cgi，fastcgi以及fpm等等接口。 TSRM: PHP的线程安全是构建在TSRM库之上的，PHP实现中常见的*G宏通常是对TSRM的封装，TSRM(Thread Safe Resource Manager)线程安全资源管理器。 tests: PHP的测试脚本集合，包含PHP各项功能的测试文件。 win32: 这个目录主要包括Windows平台相关的一些实现，比如sokcet的实现在Windows下和*Nix平台就不太一样，同时也包括了Windows下编译PHP相关的脚本。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.1 LAMP入门讲解]]></title>
    <url>%2F2018%2F09%2F01%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[LAMP入门讲解 上一章我们讲解了 web 的基本概念，以及如何使用 httpd 搭建一个静态的 web 服务器。本章我们接着上一章的内容，讲解 web 服务框架 LAMP。 1. LAMP1.1 LAMP 简介最早的 web 站点只能提供静态内容，我们的 web 服务只有一个 httpd 服务器，要想展示页面我们必需事先生成静态的 web 页面。但是我们很清楚，不论哪个网站大多数页面都是类似的，只有一小部分不同，大多数页面都可以套用相同的模板动态生成。而填充模板的数组则通常放置在数据库中，最为大家所熟知的也就是 mysql。因此我们的 web 资源就分成了静态资源和动态资源两种 静态资源：原始形式与响应内容一致； 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端 服务器端加载动态资源的方式，按照技术的出现的时间次序分为了: CGI, Common Gateway Interface FCGI, Fast CGI 接下来我们就来详细介绍，这两种动态资源的加载方式 1.1 CGICGI(Common Gateway Interface，通用网关接口)，是一种传输协议，它规范了客户端与服务器端如何传输动态资源以及服务器端如何加载动态资源的方式。它的模型如下图所示 这种模型下并不存在后端的应用程序服务器，由前端 web 服务器完成所有工作。动态资源的请求过程如下所示： httpd 服务接收用户请求(动态资源) httpd 基于cgi 协议，在子进程中自动调用 php 的解释器执行对应的 php 脚本，并获取脚本返回结果作为响应传递给客户端 后端应用程序，无须是一个服务，无须理解 http 协议，全部由 apache 服务器完成 即由 web 服务器理解和解析 url，并由 web 服务自行调用动态资源的解释器，运行该动态资源，并获取结果响应给客户端 CGI 在每响应一个动态资源时，必须创建和销毁子进程，性能很低。 1.2 FCGIFCGI 是 CGI 的增强版本，其动态资源的请求过程如下所示 后端应用程序服务器作为独立的服务监听在特定端口，与 httpd 通过 tcp/udp 协议进行通信 httpd 接收用户请求后，作为客户端向应用程序服务器请求相同的动态资源 后端应用程序服务器加载并执行 php 脚本，并将执行结果作为响应返回给 httpd，httpd 响应给客户端 httpd 起到了反向代理的作用 后端应用程序服务器可以预先创建子进程，这样避免了每次请求都必须创建和销毁子进程带来的开销。 对于 php 而言还存在另一中 FCGI 模式。php 解释功能可作为 httpd 的一个模块存在，httpd 可直接执行 php 脚本，无需创建和销毁子进程。此时 httpd 既是一个静态 web 服务器，也充当应用程序服务器。这种模式也存在一定缺陷: web 服务器和应用程序服务器无法分离开 每个执行 php 的 httpd 进程都必需独自解析 php 脚本，无法利用 php 的加速技术。 此 LAMP 的结构如下所示 1.4 LAMP 架构 一个经典的 LAMP 架构如上图所示，包括: l: Linux a: apache httpd m: 数据库存储系统，可以是 mysql, mariadb，mongo p: 后端应用程序的开发语言，可以是 php, perl, python]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.8 httpd 辅助工具]]></title>
    <url>%2F2018%2F08%2F27%2Flinux_mt%2F20-web-apache%2Fhttpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[httpd 辅助工具 本章的最后一节我们来学习 httpd 提供了辅助工具的使用，包括: httpd: httpd 服务的主程序 apachectl：httpd自带的服务控制脚本，支持start和stop,restart； htpasswd：basic认证基于文件实现时，用到的账号密码文件生成工具； apxs：由httpd-devel包提供，扩展httpd使用第三方模块的工具； rotatelogs：日志滚动工具； suexec：访问某些有特殊权限配置的资源时，临时切换至指定用户身份运行； ab： apache benchmark 1. httpdhttpd[.event|worker] OPTIONS 作用: httpd 主程序 选项: -t: 仅对配置文件执行语法检查。程序在语法解析检查结束后立即退出，或者返回”0”(OK)，或者返回非0的值(Error)。如果还指定了”-D DUMP_VHOSTS”，则会显示虚拟主机配置的详细信息 -l: 输出一个静态编译在服务器中的模块的列表。它不会列出使用LoadModule指令动态加载的模块。 -L: 输出一个指令的列表，并包含了各指令的有效参数和使用区域。 -M: 输出一个已经启用的模块列表，包括静态编译在服务器中的模块和作为DSO动态加载的模块。 -v: 显示httpd的版本，然后退出。 -V: 显示httpd和APR/APR-Util的版本和编译参数，然后退出。 -X: 以调试模式运行httpd 。仅启动一个工作进程，并且服务器不与控制台脱离 -d serverroot: 将ServerRoot指令设置初始值为serverroot。它可以被配置文件中的ServerRoot指令所覆盖。 -f config: 在启动中使用config作为配置文件。如果config不以”/“开头，则它是相对于ServerRoot的路径 -k start|restart|graceful|stop|graceful-stop: 发送信号使httpd启动、重新启动或停止 。 -C directive: 在读取配置文件之前，先处理directive的配置指令。 -c directive: 在读取配置文件之后，再处理directive的配置指令。 -D parameter: 设置参数parameter ，它配合配置文件中的段，用于在服务器启动和重新启动时，有条件地跳过或处理某些命 -e level: 在服务器启动时，设置LogLevel为level 。它用于在启动时，临时增加出错信息的详细程度，以帮助排错。 -E file: 将服务器启动过程中的出错信息发送到文件file 。 -R directory: 当在服务器编译中使用了SHARED_CORE规则时，它指定共享目标文件的目录为directory 。 -h: 输出一个可用的命令行选项的简要说明。 -S: 显示从配置文件中读取并解析的设置结果(目前仅显示虚拟主机的设置) -T: 在启动/重启的时候跳过根文件检查 (该参数在Apache 2.2.17及其以后版本有效) -t 选项的扩展: httpd -t -D DUMP_VHOSTS : 显示虚拟主机的配置 httpd -t -D DUMP_RUN_CFG : show parsed run setting httpd -t -D DUMP_MODULES : 显示所有已经启动的模块 httpd -M : httpd -t -D DUMP_MODULES 的快捷方式 1234567891011121314151617$ httpd -lCompiled in modules: core.c mod_so.c http_core.c$ httpd -MLoaded Modules: core_module (static) so_module (static) http_module (static) access_compat_module (shared) actions_module (shared) .......$ httpd -tSyntax OK 2. apachectlapachectl OPTIONS 作用: 是slackware内附Apache HTTP服务器的script文件，可供管理员控制服务器 选项: configtest: 检查设置文件中的语法是否正确。 fullstatus: 显示服务器完整的状态信息。 graceful: 重新启动Apache服务器，但不会中断原有的连接。 help: 显示帮助信息。 restart: 重新启动Apache服务器。 start: 启动Apache服务器。 status: 显示服务器摘要的状态信息。 stop: 停止Apache服务器 说明: httpd 命令的所有选项， apachectl 均可用 3. htpasswdhtpasswd OPTIONS passwordfile username [password] 作用: 用于创建和更新储存用户名、域和用户基本认证的密码文件 参数: passwordfile: 密码文件的路经，使用 -n 选项时，无需此参数 username: 用户名 password: 密码，使用-b 选项时必需，默认显示提示符让用户输入密码 选项: -c：创建一个加密文件，文件已经存在会删除重建 -b：在命令行中一并输入用户名和密码而不是根据提示输入密码 -D：删除指定的用户 -n：不更新加密文件，只将加密后的用户名密码显示在屏幕上 -m：默认采用MD5算法对密码进行加密 -d：采用CRYPT算法对密码进行加密 -p：不对密码进行进行加密，即明文密码 -s：采用SHA算法对密码进行加密 1234567$ htpasswd -c /tmp/.httpd tao # 首次创建文件，需要使用 -cNew password:Re-type new password:Adding password for user tao$ htpasswd -b /tmp/.httpd pythoner python # 非首次创建不能使用 `-c` 否则会删除已有文件Adding password for user pythoner 3. curlcurl [options] [URL...] 作用: curl是基于URL语法在命令行方式下工作的文件传输工具 支持FTP, FTPS, HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议 支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器， cookies， 用户名/密码认证， 下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）， 甚至它还支持IPv6， socks5代理服务器,，通过http代理服务器上传文件到FTP服务器等等，功能十分强大。 options: -e/--referer &lt;URL&gt;: 来源网址 -A/--user-agent &lt;string&gt;: 设置用户代理发送给服务器 -H/--header &lt;line&gt;: 自定义首部信息传递给服务器 -I/--head 只显示响应报文首部信息 --basic: 使用HTTP基本认证 -u/--user &lt;user[:password]&gt;: 设置服务器的用户和密码 --cacert &lt;file&gt;: CA证书 (SSL) --compressed 要求返回是压缩的格式 --limit-rate &lt;rate&gt;: 设置传输速度 -0/--http1.0: 使用HTTP 1.0 --tcp-nodelay: 使用TCP_NODELAY选项 5. elinkselinks [OPTION]... [URL]... 作用: 文本浏览器 选项: -dump: 不进入交互式模式，而直接将URL的内容输出至标准输出； 6. httpd的压力测试工具市面上常见的 web 压力测试工具有以下几种: 命令行工具: ab, webbench, http_load, seige 图形化工具: jmeter, loadrunner 模拟真实请求: tcpcopy，网易开发，复制生产环境中的真实请求，并将之保存下来； ab [OPTIONS] URL 全称: apache benchmark 选项: -n：总请求数； -c：模拟的并行数； -k：以持久连接模式 测试； 附注: ulimit -n num 调整当前用户能同时打开的文件数]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.7 httpd 配置进阶]]></title>
    <url>%2F2018%2F08%2F26%2Flinux_mt%2F20-web-apache%2Fhttpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[httpd 配置进阶 我们来继续学习 httpd 的配置，本节属于高级配置篇，核心是配置httpd支持https。 1. 指定 httpd 服务的运行身份12User apacheGroup apache User 和 Group 指令用于指定以哪个用户的身份运行httpd服务进程。该帐户决定了 httpd 进程在本机的权限。千万不能以 root 用户运行我们的 httpd 进程，以免 httpd 被劫持导致整个机器被控制。 需要注意的是如果指定的帐户没有权限访问文件系统上的内容，即便 &lt;Directory&gt; 开放了访问接口也一样无法访问。因此 httpd 提供了 SUexec，用于在特定的目录内进行用户切换以便能够方便的访问到受限的文件，而不用更改文件的权限。SUexec有安全风险，一般也很少使用。 2. 页面压缩mod_deflate 模块提供了压缩功能。压缩可以节约带宽，但是会额外消耗CPU；同时，可能有些较老浏览器不支持。是否启用压缩取决于网络带宽与 CPU 哪个更加稀缺。 有些资源是可压缩的，例如文件文件，而有些资源本身已经是压缩的，比如图片，这些则无需压缩。httpd 的压缩功能配置如下: 12345678910111213141516171819202122232425262728293031323334# 1. 首先确认是否加载了 deflate 模块$ httpd -M|grep -i deflate deflate_module (shared)# 2. 没有加载，则在配置文件中加载 deflate_moduleLoadModule deflate_module modules/mod_deflate.so# 3. 配置压缩功能$ vim /etc/httpd/conf.d/compress.conf # 在单独配置文件中配置，方便取消SetOutputFilter DEFLATE # 添加一个过滤器 # mod_deflate configuration # 向过滤器添加压缩哪些内容# Restrict compression to these MIME typesAddOutputFilterByType DEFLATE text/plainAddOutputFilterByType DEFLATE text/htmlAddOutputFilterByType DEFLATE application/xhtml+xmlAddOutputFilterByType DEFLATE text/xmlAddOutputFilterByType DEFLATE application/xmlAddOutputFilterByType DEFLATE application/x-javascriptAddOutputFilterByType DEFLATE text/javascriptAddOutputFilterByType DEFLATE text/css# Level of compression (Highest 9 - Lowest 1)DeflateCompressionLevel 9 # 默认压缩级别# Netscape 4.x has some problems. # 特殊浏览器的特殊处理BrowserMatch ^Mozilla/4 gzip-only-text/html# Netscape 4.06-4.08 have some more problemsBrowserMatch ^Mozilla/4\.0[678] no-gzip# MSIE masquerades as Netscape, but it is fineBrowserMatch \bMSI[E] !no-gzip !gzip-only-text/html 3. 配置httpd支持httpsSSL会话是基于IP地址创建；所以单IP的主机上，仅可以使用一个https虚拟主机 3.1 SSL会话的简化过程 客户端发送可供选择的加密方式，并向服务器请求证书； 服务器端发送证书以及选定的加密方式给客户端； 客户端取得证书并进行证书验正： 验正证书来源的合法性；用CA的公钥解密证书上数字签名； 验正证书的内容的合法性：完整性验正 检查证书的有效期限； 检查证书是否被吊销； 证书中拥有者的名字，与访问的目标主机要一致； 客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器，完成密钥交换； 服务用此密钥加密用户请求的资源，响应给客户端； 3.2 配置httpd支持https配置 https 需要如下几个步骤: 为服务器申请数字证书。本地测试时，可以私建CA发证书 配置httpd支持使用ssl，及使用的证书； 测试基于https访问相应的主机； 私建 CA 发证参见18.4 私建CA.md 配置 ssl123456789# 1. 安装 httpd 的 ssl 功能模块yum -y install mod_ssl# 2. 编辑配置文件$ vim /etc/httpd/conf.d/ssl.conf DocumentRoot &quot;/var/www/html&quot;ServerName &quot;www.magedu.com:443&quot;SSLCertificateFile &quot;/etc/httpd/ssl/http_crt.pem&quot;SSLCertificateKeyFile &quot;/etc/httpd/ssl/http_key.pem&quot; 测试 https 服务我们可以在浏览器导入我们私建的 CA 直接在浏览器中进行测试，也可以通过 openssl 的 s_client 子命令进行测试 openssl s_client OPTIONS 作用: https 连接的客户端工具 选项: [-connect host:port]: 连接的主机和端口 [-CAfile filename]: CA 证书的位置]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.6 httpd2.4 基础配置]]></title>
    <url>%2F2018%2F08%2F25%2Flinux_mt%2F20-web-apache%2Fhttpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[httpd2.4 基础配置 上一节我们详细介绍了httpd2.2 的配置，对比着 httpd2.2 本节我们来讲解 httpd2.4 的配置。 1. httpd-2.41.1 新特性相比于 httpd2.2 httpd2.4 有如下新特性: MPM支持运行为DSO机制；以模块形式按需加载； event MPM生产环境可用； 异步读写机制； 支持每模块及每目录的单独日志级别定义； 每请求相关的专用配置: 增强版的表达式分析器； 毫秒级持久连接时长定义； 基于FQDN的虚拟主机也不再需要 NameVirutalHost 指令； 新指令，AllowOverrideList； 支持用户自定义变量； 新模块： mod_proxy_fcgi mod_raltelimit mod_remoteip 1.2 配置文件12345678ll /etc/httpd/总用量 0drwxr-xr-x. 2 root root 37 8月 17 16:10 confdrwxr-xr-x. 2 root root 151 8月 17 16:08 conf.ddrwxr-xr-x. 2 root root 205 8月 17 15:01 conf.modules.dlrwxrwxrwx. 1 root root 19 2月 10 2018 logs -&gt; ../../var/log/httpdlrwxrwxrwx. 1 root root 29 2月 10 2018 modules -&gt; ../../usr/lib64/httpd/moduleslrwxrwxrwx. 1 root root 10 2月 10 2018 run -&gt; /run/httpd 主配置文件: /etc/httpd/conf/httpd.conf 辅助配置文件: /etc/httpd/conf.d/*.conf 模块配置文件: /etc/httpd/conf.modules.d/*.conf mpm 以DSO机制提供，配置文件为 /etc/httpd/conf.modules.d/00-mpm.conf 2. httpd2.4 配置httpd2.4 官方文档 http://httpd.apache.org/docs/2.4/mod/directives.html 2.1 修改监听的IP和PORTListen [IP-address:]portnumber [protocol] protocol: 限制必需通过 ssl 通信时，protocol 可定义为 https 2.2 持久连续KeepAliveTimeout num[ms] 支持毫秒级持久时间，默认单位为秒 2.3 MPMMPM支持运行为DSO机制，在/etc/httpd/conf.modules.d/00-mpm.conf中进行配置，启用要启用的MPM相关的LoadModule指令即可。1234$ cat /etc/httpd/conf.modules.d/00-mpm.conf|grep LoadModuleLoadModule mpm_prefork_module modules/mod_mpm_prefork.so#LoadModule mpm_worker_module modules/mod_mpm_worker.so#LoadModule mpm_event_module modules/mod_mpm_event.so 3. 访问控制机制3.1 基于IP的访问控制新增访问路径必须添加 Require 进行 ip 授权，否则新增路径不允许访问，所有的IP 访问控制必须放置在 RequireAll 容器中 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all deny 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问； Require not ip IPADDR：拒绝 IPADDR： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 控制特定的主机访问： Require host HOSTNAME：授权指定来源的主机访问； Require not host HOSTNAME：拒绝 HOSTNAME： FQDN：特定主机 domin.tld：指定域名下的所有主机 1234567# IP 访问控制 &lt;Directory &quot;/www/htdoc&quot;&gt; &lt;RequireAll&gt; Require all granted Require not ip 172.16.100.2 &lt;/RequireAll&gt;&lt;/Directory&gt; 4. 虚拟主机 基于FQDN的虚拟主机也不再需要NameVirutalHost指令； 注意：任意目录下的页面只有显式授权才能被访问； 12345678910# 定义虚拟主机&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot &quot;/apps/b.net/htdocs&quot; &lt;Directory &quot;/apps/b.net/htdocs&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 5. status页面1234567LoadModule status_module modules/mod_status.so&lt;Location /server-status&gt; SetHandler server-status &lt;RequireAll&gt; Require ip 172.16 &lt;/RequireAll&gt;&lt;/Location&gt; 练习题：分别使用httpd-2.2和httpd-2.4实现1234567891. 建立httpd服务，要求： (1) 提供两个基于名称的虚拟主机： www1.stuX.com，页面文件目录为/web/vhosts/www1；错误日志为/var/log/httpd/www1/error_log，访问日志为/var/log/httpd/www1/access_log； www2.stuX.com，页面文件目录为/web/vhosts/www2；错误日志为/var/log/httpd/www2/error_log，访问日志为/var/log/httpd/www2/access_log； (2) 通过www1.stuX.com/server-status输出其状态信息，且要求只允许提供账号的用户访问； (3) www1不允许192.168.1.0/24网络中的主机访问； 2. 为上面的第2个虚拟主机提供https服务，使得用户可以通过https安全的访问此web站点； (1) 要求使用证书认证，证书中要求使用国家（CN），州（Beijing），城市（Beijing），组织为(MageEdu)； (2) 设置部门为Ops, 主机名为www2.stuX.com；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.5 httpd2.2 的基础配置]]></title>
    <url>%2F2018%2F08%2F24%2Flinux_mt%2F20-web-apache%2Fhttpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[httpd2.2 的基础配置 本节我们来讲解 httpd2.2 的基础配置 1. httpd-2.2 配置文件格式1234$ grep &quot;^###&quot; /etc/httpd/conf/httpd.conf### Section 1: Global Environment### Section 2: &apos;Main&apos; server configuration### Section 3: Virtual Hosts httpd2.2 的主配置文件是：/etc/httpd/conf/httpd.conf，其分成三个部分: Section 1: Global Environment 全局配置 Section 2: ‘Main’ server configuration 主服务配置段 Section 3: Virtual Hosts 虚拟主机配置段 下面是一段配置示例1234567891011ServerRoot &quot;/etc/httpd&quot;Include conf.modules.d/*.conf&lt;Directory /&gt; # 目录访问权限配置 AllowOverride none Require all denied&lt;/Directory&gt;&lt;IfModule dir_module&gt; # IfModule 判断动态模块是否存在，动态配置 DirectoryIndex index.html&lt;/IfModule&gt; 配置的格式为 directive value directive：配置参数，不区分字符大小写； value：参数值，为路径时，是否区分字符大小写，取决于文件系统； 2. httpd-2.2 常用配置httpd2.2 的官方文档: http://httpd.apache.org/docs/2.2/ 2.1 修改监听的IP和PORTListen [IP:]PORT 省略IP表示监听本地所有地址 Listen指令可重复出现多次，以监听多个IP地址和端口； Listen 80 Listen 8080 修改监听socket(不是新增)，需要重启服务进程才能生效； 2.2 持久连续Persistent Connection1234# 持久链接配置相关参数KeepAlive On|Off # 是否启用持久连接KeepAliveTimeout 15 # 持久链接最大连接时长MaxKeepAliveRequests 100 # 持久链接最多处理的请求数 前面我们说过 tcp 连接有长连接短连接之分 长连接能降低请求响应的时间 但对并发访问量较大的服务器，长连接机制会使得后续某些请求无法得到正常 响应；因此通常的折衷策略是，采用长连接，但是使用较短的持久连接时长，以及较少的请求数量。 http 与长连接相关的参数包括 KeepAlive On|Off: 是否启用持久连接 KeepAliveTimeout time: 持久链接最大连接时长,httpd-2.4 支持毫秒级持久时间 MaxKeepAliveRequests: 单个持久连接能够处理的对大请求数 2.3 MPMMPM(Multipath Process Module) 多道处理模块,用来确定 httpd 响应用户请求的模型。对于 httpd2.2: 不支持同时编译多个MPM模块，所以只能编译选定要使用的那个。 CentOS 6的rpm包为此专门提供了三个应用程序文件，httpd(prefork), httpd.worker, httpd.event，分别用于实现对不同的MPM机制的支持。 默认使用的为/usr/sbin/httpd，其为prefork的MPM模块 查看 httpd2.2 当前使用的 MPM 以及修改默认的 MPM 的方式如下: 1234567891011121314151617# 1. 查看当前使用MPM模式ps aux|grep httpd# 2. 查看httpd程序的模块列表：## 查看静态编译的模块(先确定使用的MPM):httpd -lhttpd.event -lhttpd.worker -l## 查看静态编译及动态编译的模块:httpd -Mhttpd.envent -Mhttpd.woker -M# 3. 更改 service 使用的 httpd 程序vim /etc/sysconfig/httpd HTTPD=/usr/sbin/httpd.&#123;worker,event&#125; # 修改 HTTPD 参数，重启服务进程方可生效 prefork的配置参数123456789# /etc/httpd/conf/httpd.conf&lt;IfModule prefork.c&gt; StartServers 8 ＃ 服务启动时，启动的进程数 MinSpareServers 5 # 最小空闲进程数 MaxSpareServers 20 # 最大空闲进程数 ServerLimit 256 # 为 MaxClients 提供的最大进程数，通常等于 MaxClients MaxClients 256 # 并发的最大客户端请求数 MaxRequestsPerChild 4000 # 一个进程能处理的请求总数，超过会自动销毁&lt;/IfModule&gt; worker的配置参数123456789# /etc/httpd/conf/httpd.conf&lt;IfModule worker.c&gt;StartServers 4 # 服务器启动时启动的进程数MaxClients 300 MinSpareThreads 25 # 最小的空闲线程数MaxSpareThreads 75 # 最大的空闲线程数ThreadsPerChild 25 # 每个进程启动的线程数MaxRequestsPerChild 0 # 每个线成能处理的请求总数，超过会自动销毁，0 表示无限&lt;/IfModule&gt; event 的配置event 在 httpd2.2 中尚且属于测试阶段，不建议在线上使用 2.4 DSOLoadModule mod_name mod_path 作用: 实现模块加载: 参数: mod_name: 模块的名称 mod_path: 模块的路经，可使用相对路径：相对于ServerRoot 123LoadModule alias_module modules/mod_alias.so# modules/mod_alias.so -- &gt; /etc/httpd/modules/mod_alias.so# /etc/httpd/modules ---&gt; /usr/lib64/httpd/modules 2.5 ‘Main’ server配置DocumentRoot Dir 作用: 文档路径映射,DoucmentRoot指向的路径为URL路径的起始位置, 其相当于站点URL的根路径； 12DocumentRoot &quot;/var/www/html&quot;(FileSystem) /var/www/html/index.html --&gt; (URL)/index.html ServerName www.example.com:80 作用: 配置主服务的标识 默认: 未设置此参数时， httpd 会自动反解监听的 IP 地址，反解失败，则默认为当前主机的主机名 可以随意设置，如果没有注册 DNS 域名，也可以设置成 ip 地址 2.6 定义站点主页面DirectoryIndex index.html index.html.var 作用: 配置当用户访问 URL 的指向是一个目录时，httpd 应该默认响应的内容 附注: 找不到主页面时，httpd 通过 /etc/httpd/conf.d/weibocom.conf 提供了一个默认主页面 2.7 定义路径别名Alias /URL/ &quot;/PATH/TO/SOMEDIR/&quot; 作用: 定义 url 访问资源的路经别名 1234567DocumentRoot &quot;/www/htdocs&quot;http://www.magedu.com/download/a.index --&gt; /www/htdocs/download/a.indexAlias /download/ &quot;/rpms/pub/&quot;http://www.magedu.com/download/a.index --&gt; /rpms/pub/a.indexhttp://www.magedu.com/images/logo.png ---&gt; /www/htdocs/images/logo.png 2.8 设定默认字符集AddDefaultCharset UTF-8 作用: 设定默认字符集 2.9 日志设定123456789# 错误日志：ErrorLog logs/error_log # 错误日志的路经LogLevel warn # 日志的级别# 定义日志格式LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combinedLogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; commonCustomLog logs/access_log combined # 访问日志的路经，combined 为 LogFormat 名 LogLevel level 作用: 日志级别 可选值：debug, info, notice, warn, error, crit, alert, emerg LogFormat 格式化字符串http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats 标志宏 作用 %h 客户端IP地址 %l Remote User, 通常为一个减号（“-”） %u Remote user (from auth; may be bogus if return status (%s) is 401)；非为登录访问时，其为一个减号 %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文的http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的 %{User-Agent}i 请求报文中首部“User-Agent”的值；即发出请求的应用程序 3. httpd2.2 访问控制3.1 访问控制机制访问控制值的时允许哪些用户访问哪些站点资源 用户可以通过来源地址 或 账号 指定， 资源可以通过文件系统路径 或 URL 指定 因此 httpd 的访问控制机制有如下四中实现方式: 基于来源地址，通过文件路径实现访问控制机制 基于来源地址，通过 url 实现访问控制机制 基于账号，过文件路径实现访问控制机制 基于账号，通过 url 实现访问控制机制 httpd2.2 与 httpd2.4 最大的不同之处在于，httpd2.4 如果未授权，默认是所有用户都无法访问的，而 http2.2 则默认允许访问。因此当在 httpd2.4 中添加 Alias 路经别名，或更改 DocumentRoot 时，必需配置相应的访问权限。 资源界定资源的文件系统路径由如下几种配置方式1234567891011&lt;Directory &quot;&quot;&gt; # 目录...&lt;/Directory&gt;&lt;File &quot;&quot;&gt; # 单文件...&lt;/File&gt;&lt;FileMatch &quot;PATTERN&quot;&gt; # 文件路经匹配的正则表达式...&lt;/FileMatch&gt; URL 有如下两种配置方式1234567&lt;Location &quot;&quot;&gt; # URL 地址...&lt;/Location&gt;&lt;LocationMatch &quot;&quot;&gt; # URL 匹配的正则表达式...&lt;/LocationMatch&gt; 3.1 Directory 中“基于源地址”实现访问控制：1234&lt;Directory &quot;/var/www/html&quot;&gt;Options All，None，Indexes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViewsAllowOverride None&lt;/Directory&gt; http2.2 访问控制参数如下: Options 作用: 后跟1个或多个以空白字符分隔的“选项”列表； 选项: Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户； – 危险，生产环境不能启用 FollowSymLinks：允许跟踪符号链接文件所指向的源文件；– 危险 None：关闭所有选项 All：启动全部选项 说明: 选项前加上-，表示关闭，但是只能要么都有-，要么都没有 AllowOverride 作用: 与访问控制相关的指令可以放在.htaccess文件，每个目录下都可以有一个；用于自定义每个目录的访问权限 启用 .htaccess 会对性能产生重大影响，不建议启用 Directory 中的配置相当于全局配置 选项: All: Directory 中的全局配置，覆盖 htaccess 中的配置 None：Directory 中的全局配置，不会覆盖 htaccess 中的配置 order和allow、deny 作用: 基于来源地址的访问控制 order：定义生效次序；写在后面的表示默认法则； Order allow，deny: 白名单 Order deny，allow: 黑名单 Allow from IP, Deny from IP: 注明来源IP 来源地址： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 1234567&lt;Directory &quot;/www/htdoc&quot;&gt; AllowOverride None Options Indexes FollowSymLinks Order allow,deny Allow from 192.168.1 # Deny from 192.168.1.104&lt;/Directory&gt; 3.2 基于用户的访问控制WWW-Authenticate（认证质询）是 http 协议早期提供的用户认证机制。当用户请求受控资源时，服务器响应 401，拒绝客户端请求，并说明要求客户端提供账号和密码；浏览器接收到响应时，会弹出认证窗口，客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源。需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因。 WWW-Authenticate 认证方式有两种： basic认证：会明文传输帐号和密码，不安全 digest认证： 用户的账号和密码可存储在文本文件，SQL数据库，ldap目录存储。但是通常都是存在本地的文本文件中，因为 httpd 访问 mysql 的模块是非标准模块，需要单独编译安装。现在 web 站点基本都是通过表单进行身份认证，认证质询因为安全性和便利性的问题，其实很少使用。 basic认证配置示例12345678910111213# 1. 定义安全域&lt;Directory &quot;&quot;&gt; Options None AllowOverride None AuthType Basic AuthName &quot;String“ # 认证提时字符串 AuthUserFile &quot;/PATH/TO/HTTPD_USER_PASSWD_FILE&quot; # 帐号密码文件路经 Require user username1 username2 ... # 允许访问的用户 # Require valid-user # 允许账号文件中的所有用户登录访问&lt;/Directory&gt;# 2. 使用 htpassword 命令创建帐号密码文件$ htpassword -cb /etc/httpd/.httpd tao tao 基于组账号进行认证123456789101112131415161718# 1. 定义安全域&lt;Directory &quot;&quot;&gt; Options None AllowOverride None AuthType Basic AuthName &quot;String“ AuthUserFile &quot;/PATH/TO/HTTPD_USER_PASSWD_FILE&quot; AuthGroupFile &quot;/PATH/TO/HTTPD_GROUP_FILE&quot; Require group grpname1 grpname2 ...&lt;/Directory&gt;# 2. 创建用户账号和组账号文件； # 组文件：每一行定义一个组 # GRP_NAME: username1 username2 ...&gt; htpasswd -m /etc/httpd/conf.d/.http_passwd tom # 创建帐号文件&gt; vim /etc/httpd/conf.d/.http_group # 创建组文件 admin: tom jerry # tom, jerry 为 admin 组 4. 虚拟主机通常如果我们在同一主机上提供了多个彼此毫不相干的服务时，通常是将他们隔离开，放在不同的域名下进行管理，而不是放在同一域名下；以免某一站点被劫持，所有站点都被劫持。虚拟主机就是帮助我们实现一个物理服务器服务多个网站的功能。 web 服务通过 tcp 进行通信，即每个服务都监听在一个特定的套接子socket 上，socket = ip + 端口，所以实现虚拟主机就有如下几种方法: IP相同，但端口不同； IP不同，但端口均为默认端口； FQDN不同: 为不同的 web 服务配置不同的域名 需要注意的是请求报文首部中的 Host 字段会保留浏览器中用户请求的域名，因此服务器端可以通过解析Host 字段来路由请求。httpd 中心主机与虚拟主机不能混用，httpd2.2 中使用虚拟主机必需禁用’main’主机,禁用方法：注释中心主机的DocumentRoot指令即可。http2.4 中启用虚拟主机后，中心主机会自动禁用。 4.1 虚拟主机的配置方法所有能用在中心主机的配置，均可以用在虚拟主机中 123456789101112131415&lt;VirtualHost IP:PORT&gt; ServerName FQDN DocumentRoot &quot;&quot; # 其它可用指令： ServerAlias：虚拟主机的别名；可多次使用； ErrorLog： CustomLog： &lt;Directory &quot;&quot;&gt; ... &lt;/Directory&gt; Alias ...&lt;/VirtualHost&gt; 4.2 基于IP的虚拟主机示例：12345678910111213141516171819&lt;VirtualHost 192.168.1.120:80&gt; ServerName web1.tao.com DocumentRoot &quot;/vhosts/web1/htdocs&quot; &lt;Directory &quot;/vhosts/web1/htdocs&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.7:80&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.8:80&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 4.3 基于端口的虚拟主机：1234567891011121314&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.a.com DocumentRoot &quot;/www/a.com/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:808&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:8080&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 4.4 基于 hostname 的虚拟主机：1234567891011121314151617# 重要，http2.2 中需要指明 NameVirtualHostNameVirtualHost 172.16.100.6:80&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.a.com DocumentRoot &quot;/www/a.com/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 5. status页面123456LoadModule status_module modules/mod_status.so&lt;Location /server-status&gt; SetHandler server-status Order allow,deny Allow from 172.16&lt;/Location&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.4 apache httpd 简介]]></title>
    <url>%2F2018%2F08%2F23%2Flinux_mt%2F20-web-apache%2Fapache-httpd%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[apache httpd 简介 httpd 是 ASF(apache software foundation, apache 软件基金会)下的顶级项目，也是目前市场占有率最高的 web 服务器。本节我们就来对 httpd 做一个概括行的介绍。在之后的章节我们再来详细的学习 httpd 的配置。 1. httpd 简介1.1 httpd 版本httpd 目前有如下主流的版本 httpd 1.3：官方已经停止维护； httpd 2.0： httpd 2.2: Centos6 base 仓库的默认安装版本 httpd 2.4：目前最新稳定版，Centos7 base 仓库的默认安装版本 httpd2.2 和 httpd2.4 目前都有使用，他们之间存在比较大的差异。在介绍 httpd 的配置时，我们将首先介绍 http2.2，然后针对 httpd2.4 的不同之处单独讲解。 1.2 httpd的特性httpd 具有如下的一些关键特性: 高度模块化： core + modules DSO：dynamic shared object 动态共享对象 MPM：Multipath processing Modules (多路处理模块) prefork：多进程模型, 每个进程响应一个请求； 一个主进程：负责生成子进程及回收子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； n个子进程：每个子进程处理一个请求； 工作模型：会预先生成几个空闲进程，随时等待用于响应用户请求；有最大空闲数和最小空闲数； worker：多进程多线程模型，每线程处理一个用户请求； 一个主进程：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 多个子进程：每个子进程负责生成多个线程； 每个线程：负责响应用户请求； 并发响应数量：m*n m：子进程数量 n：每个子进程所能创建的最大线程数量； event：事件驱动模型，多进程模型，每个进程响应多个请求； 一个主进程 ：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 子进程：基于事件驱动机制直接响应多个请求； 适用版本: httpd-2.2: 仍为测试使用模型； httpd-2.4：event可生产环境中使用； 2. httpd安装httpd 可以通过 base 仓库的 rpm 包直接安装，也可以编译安装。通常除非需要定制新功能，或其它原因，不建议采用编译安装的方式。一是对规模部署不便，二是安装过程繁琐，需要准备编译环境，还需要额外的配置。 2.1 httpd2.2 与 httpd2.4 的对比下面是 httpd2.2 httpd2.4 安装，管理，以及配置文件路经的对比 1234567$ ll /etc/httpd/总用量 0drwxr-xr-x. 2 root root 37 5月 22 19:20 confdrwxr-xr-x. 2 root root 151 5月 8 09:35 conf.dlrwxrwxrwx. 1 root root 19 2月 10 2018 logs -&gt; ../../var/log/httpdlrwxrwxrwx. 1 root root 29 2月 10 2018 modules -&gt; ../../usr/lib64/httpd/moduleslrwxrwxrwx. 1 root root 10 2月 10 2018 run -&gt; /run/httpd 配置 httpd2.2 httpd2.4 配置文件 /etc/httpd/conf/httpd.conf/etc/httpd/conf.d/*.conf /etc/httpd/conf/httpd.conf/etc/httpd/conf.d/*.conf/etc/httpd/conf.modules.d/*.conf(模块配置) 服务脚本 /etc/rc.d/init.d/httpd/etc/sysconfig/httpd(脚本配置) /usr/lib/systemd/system/httpd.service 主程序 /usr/sbin/httpd/usr/sbin/httpd.event/usr/sbin/httpd.worker /usr/sbin/httpd支持MPM的动态切换 访问日志 /var/log/httpd/access_log /var/log/httpd/access_log 错误日志 /var/log/httpd/error_log /var/log/httpd/error_log 站点文档 /var/www/html /var/www/html 模块文件 /usr/lib64/httpd/modules /usr/lib64/httpd/modules 服务控制 chkconfig httpd on,off systemctl enable,disable httpd.service service {start,stop,restart,status,reload} httpd systemctl {start,stop,restart,status} httpd 2.2 http2.4 rpm 包123456$ yum list all httpd*httpd.x86_64 2.4.6-80.el7.centos.1 updateshttpd-devel.x86_64 2.4.6-80.el7.centos.1 updateshttpd-itk.x86_64 2.4.7.04-2.el7 epel httpd-manual.noarch 2.4.6-80.el7.centos.1 updateshttpd-tools.x86_64 2.4.6-80.el7.centos.1 updates httpd 相关rmp 包: httpd: httpd web 服务的主程序包 httpd-tools: httpd 相关的辅助工具 httpd-manual: httpd 文档 httpd123456789101112131415161718192021222324252627$ rpm -ql httpd|grep -v share/etc/httpd # 配置文件/etc/httpd/conf /etc/httpd/conf.d/etc/httpd/conf.d/*/etc/httpd/conf.modules.d/etc/httpd/conf/httpd.conf/etc/httpd/modules # httpd 模块所在目录/usr/lib64/httpd/modules/usr/sbin/apachectl # httpd 相关的程序/usr/sbin/fcgistarter/usr/sbin/htcacheclean/usr/sbin/httpd/usr/sbin/rotatelogs/usr/sbin/suexec/var/cache/httpd/var/cache/httpd/proxy/var/cache/httpd # 目录与日志文件/var/cache/httpd/proxy/var/lib/dav/var/log/httpd/var/www/var/www/cgi-bin/var/www/html httpd-tools1234567$ rpm -ql httpd-tools/usr/bin/ab # web 服务测试工具/usr/bin/htdbm/usr/bin/htdigest/usr/bin/htpasswd #/usr/bin/httxt2dbm/usr/bin/logresolve]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.3 http协议进阶]]></title>
    <url>%2F2018%2F08%2F22%2Flinux_mt%2F20-web-apache%2Fhttp%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[http协议进阶 在20.2 http协议基础我们对 http 协议做了简单介绍，本节我们来学 http 协议更深入的细节,包括: http 的状态追踪机制 http 协议的报文 市面上有很多的协议抓包分析工具，常见的有 tcpdump, tshark, wireshark，常见浏览器也提供了 http 协议的网络分析工具，大家可以学习了解了解。 1 http状态追踪http 协议是无状态的(stateless),服务器无法持续追踪访问者来源。因此在 http 协议的基础上有 cookie 和 session 机制用来帮助状态追踪。 2. http 报文请求报文 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 响应报文 1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; http 报文内容http 的报文格式如上图所示，各个字段的含义如下 method: 请求方法，标明客户端希望服务器对资源执行的动作 – GET、HEAD、POST version: HTTP/&lt;major&gt;.&lt;minor&gt;，http 协议的版本 status: 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况； reason-phrase：状态码所标记的状态的简要描述； headers：每个请求或响应报文可包含任意个首部；每个首部都有首部名称，后面跟一个冒号，而后跟上一个可选空格，接着是一个值； entity-body：请求时附加的数据或响应时附加的数据； 2.1 method(方法)：http 协议的请求方法: GET：从服务器获取一个资源； HEAD：只从服务器获取文档的响应首部； POST：向服务器发送要处理的数据； PUT：将请求的主体部分存储在服务器上； DELETE：请求删除服务器上指定的文档； TRACE：追踪请求到达服务器中间经过的代理服务器； OPTIONS：请求服务器返回对指定资源支持使用的请求方法； 3.status(状态码)http 协议的状态码: 1xx：100-101, 信息提示； 2xx：200-206, 成功 3xx：300-305, 重定向 4xx：400-415, 错误类信息，客户端错误 5xx：500-505, 错误类信息，服务器端错误 常用的状态码： 200： 成功，请求的所有数据通过响应报文的entity-body部分发送；OK 301： 永久重定向，请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently 302： 临时重定向，与301相似，但在响应报文中通过Location指明资源现在所处临时新位置; Found 304： 条件式请求，客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端；Not Modified 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 请求被禁止；Forbidden 404： 服务器无法找到客户端请求的资源；Not Found 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应；Bad Gateway 4. headers(首部)http 的首部是形如 Name: Value的键值对，可分为: 通用首部 请求首部 响应首部 实体首部 扩展首部 123456789101112131415161718Cache-Control:public, max-age=600Connection:keep-aliveContent-Type:image/pngDate:Tue, 28 Apr 2015 01:43:54 GMTETag:&quot;5af34e-ce6-504ea605b2e40&quot;Last-Modified:Wed, 08 Oct 2014 14:46:09 GMTAccept:image/webp,*/*;q=0.8Accept-Encoding:gzip, deflate, sdchAccept-Language:zh-CN,zh;q=0.8Cache-Control:max-age=0Connection:keep-aliveHost:access.redhat.comIf-Modified-Since:Wed, 08 Oct 2014 14:46:09 GMTIf-None-Match:&quot;5af34e-ce6-504ea605b2e40&quot;Referer:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/Installation_Guide/index.htmlUser-Agent:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36 4.1 通用首部： Date： 报文的创建时间 Connection：连接状态，如keep-alive, close Via：显示报文经过的中间节点 Cache-Control：控制缓存 Pragma： 4.2 请求首部： 基础请求首部 Accept：通知服务器自己可接受的媒体类型； Accept-Charset： Accept-Encoding：接受编码格式，如gzip Accept-Language：接受的语言 Client-IP： Host： 请求的服务器名称和端口号 Referer：包含当前正在请求的资源的上一级资源； User-Agent：客户端代理 条件式请求首部： Expect： If-Modified-Since：自从指定的时间之后，请求的资源是否发生过修改； If-Unmodified-Since： If-None-Match：本地缓存中存储的文档的ETag标签是否与服务器文档的Etag不匹配； If-Match： 安全请求首部： Authorization：向服务器发送认证信息，如账号和密码； Cookie： 客户端向服务器发送cookie Cookie2： 代理请求首部： Proxy-Authorization： 向代理服务器认证 4.3 响应首部： 信息性： Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多种表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其它首部列表； 安全响应首部： Set-Cookie：向客户端设置cookie； Set-Cookie2： WWW-Authenticate：来自服务器的对客户端的质询认证表单 4.4 实体首部： 基础实体首部 Allow： 列出对此实体可使用的请求方法 Location：告诉客户端真正的实体位于何处 Content-Encoding： 实体的编码方式 eg： gzip Content-Language： Content-Length： 主体的长度 Content-Location： 实体真正所处位置； Content-Type：主体的对象类型，MIME 类型 缓存相关： ETag：实体的扩展标签； Expires：实体的过期时间； Last-Modified：最后一次修改的时间]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.2 http协议基础]]></title>
    <url>%2F2018%2F08%2F21%2Flinux_mt%2F20-web-apache%2Fhttp%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[http协议基础 前面我们了解了 web 的基础概念，本节来对 http 协议做一个更加详细的描述。 1. http 协议http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html，有如下几个版本 http/0.9：原型版本，功能简陋 http/1.0: 增加了 cache, MIME, method, MIME：Multipurpose Internet Mail Extesion 多功能互联网邮件扩展 method：支持多种 http 方法，包括 GET， POST， HEAD，PUT， DELETE，TRACE， OPTIONS http/1.1：增强了缓存功能；spdy http/2.0：rfc 1.2 http 报文格式http 报文有请求报文，响应报文组成，一次http事务包括完整的请求&lt;--&gt;响应 过程。报文格式如下所示。我们会在之后的章节中详细讲解 http 报文中各个字段的含义及作用，目前做了解即可。 请求报文 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 示例如下:1234567Host: ss1.bdstatic.comUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0Accept: text/css,*/*;q=0.1Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3Accept-Encoding: gzip, deflate, brReferer: https://www.baidu.com/Connection: keep-alive 响应报文 1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; 示例如下:1234567891011121314HTTP/1.1 200 OKContent-Encoding: gzipContent-Type: text/html;charset=utf-8&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;this is http response&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 1.1 MIMEMIME: Multipurpose Internet Mail Extesion 作用: 多功能互联网邮件扩展，通过文本协议(http)发送非文本数据 MIME 类型: 媒体类型，由 http header 的 Content-Type 字段标识，决定了资源由哪一个浏览器外部插件打开 格式: major/minor text/html text/plain image/jpeg 1234567BDPAGETYPE: 1BDQID: 0xbbfea62700012a90Cache-Control: privateConnection: Keep-AliveContent-Encoding: gzipContent-Type: text/html # MIME 类型..... 1.3 http 长短链接http请求处理中的有两种连接模式： 非保持连接（短连接）：完成当前 http 事务后即断开 tcp 链接，下次请求需要重新建立链接 保持连接（又称长连接）：keep-alive，http 会复用当前的 tcp 链接。 tcp 链接的建立与拆除需要耗费时间，因此复用 tcp 链接能降低请求响应的时间，但是 tcp 链接会占用 web server 的 socket 文件，当链接过多时，其他客户将无法建立链接。所以是否启用保持链接取决于 tcp 链接的使用状态。通常情况下，http 1.1 中默认就会启动保持链接功能，服务器会在 tcp 链接达到一定时间，或者处理足够多的请求时自动断开链接，以免资源浪费。 1.4 http请求过程一次完整的 http 请求包括了如下过程: 建立或处理连接：接收请求或拒绝请求； 接收请求：接收来自于网络上的主机请求报文中对某特定资源的一次请求的过程； 处理请求：对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； 访问资源：获取请求报文中请求的资源； 构建响应报文： 发送响应报文： 记录日志： 2. 并发访问响应模型web server 面对的时互联网上的所有潜在用户，因此同一时刻可能有多个用户访问我们的主机。面对多用户请求，web server 有如下几种访问响应模型: 单进程I/O模型：启动一个进程处理用户请求；这意味着，一次只能处理一个请求，多个请求被串行响应； 多进程I/O结构：并行启动多个进程，每个进程响应一个请求； 复用的I/O结构：一个进程响应n个请求； 多线程模式：一个进程生成n个线程，一个线程处理一个请求； 事件驱动(event-driven)：一个进程直接n个请求； 复用的多进程I/O结构：启动多个（m）个进程，每个进程生成（n）个线程； 响应的请求的数量：m*n]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.1 web服务基础概念]]></title>
    <url>%2F2018%2F08%2F20%2Flinux_mt%2F20-web-apache%2Fweb%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[web服务基础概念 本章开始，我们将学习 Linux 运维中最重要的 web 服务。我们将学习: web 的基本概念和 http 协议 web 服务器 apache httpd 的安装与配置 web 服务也就是我们常说的网站开发，是构建在 http 协议上的 C/S 架构的应用程序。web serve 监听在 80 端口，浏览器就是我们的客户端。通过浏览器我们就可以访问 web 站点的内容。本节我们就来对 web 框架和浏览器的请求流程做一个概括性的描述。 1. web 架构最简单的 web 应用构建在我们通常称之为 LAMP 的架构上，如下图所示。 静态层称为 web 服务器(又叫静态资源服务器)，动态层称为应用程序服务器。之所以有动态和静态之分，是因为我们 web 资源分为两种类型 静态资源: 无须服务端做出额外处理,比如 .jpg, .png, .gif, .html, txt, .js, .css, .mp3, .avi 动态资源: 服务端需要通过执行程序做出处理，发送给客户端的是程序的运行结果，比如 .php, .jsp。 即我们看到的 web 页面的部分内容不是事先就存在的，而是根据每个访问的客户动态生成的，其中定制了每个人的特定信息。动态资源能根据用户的请求，到数据库中读取用户个人信息，然后执行再生成特定的页面供用户访问。 URL通常一个页面中展示的资源可能有多个，每个资源都需要单独请求。每个资源由 URL(Uniform Resource Locator,统一资源定位符号)进行标识。URL 的格式为: &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; scheme: 协议类型，eg: http,https, ftp host: 主机 ip 地址 port: 端口 path: 资源在主机上的路经 params: 参数 http://www.magedu.com/bbs/hello;gender=f query： http://www.magedu.com/bbs/item.php?username=tom&amp;title=abc frag：https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/ web 服务器常见的 web 服务器与应用程序有以下几种: web 服务器(静态资源服务器) httpd (apache) nginx lighttpd 应用程序服务器： 使用 C# 作为开发语言的 .Net 服务器: IIS 使用 java jsp 作为开发语言的 .jsp 服务器: tomcat, jetty, jboss, webshpere, weblogic 抛开动态层和数据层，客户端和 web 服务器就可以构成简单的 web 站点。 通信过程web 是构建在 http 协议上的应用。http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html 这种超文本的应用层协议， 工作于tcp 的 80。 整个 web 请求和响应会有如下过程: web server 监听在 tcp 80 端口 用户在浏览器中输入网址，经 DNS 解析得到 ip 后，发起对 web server 的链接请求 通信双方基于 tcp 的三次握手建立 tcp 链接 web serve 收到用户的请求报文中对某一特定资源的请求 web server 对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； web server 获取请求的资源，构建响应报文，经 tcp 链接发送响应报文给客户端，并记录日志 浏览器接收响应报文并展示给用户 通信结束后，tcp 四次挥手断开 tcp 链接，通信结束。 web 技术栈web 开发，分为前段和后端开发，前端指的是浏览器展示的页面，后端通常是应用程序部分。后端依所使用的开发语言而异，前端开发运用到的技术有: html：hyper text mark language，超文本标记语言 css: Cascading Style Sheet 样式表 js：JavaScript, 客户端脚本 下面是一个简单的 html 的示例，这些技术如果了解过 web 开发很容易就会明白他们有什么作用。12345678910&lt;html&gt; &lt;head&gt; &lt;title&gt;TITLE&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;/h1&gt; &lt;p&gt; blabla... &lt;a href="http://www.magedu.com/download.html"&gt; bla... &lt;/a&gt; &lt;/p&gt; &lt;h2&gt; &lt;/h2&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.4 bind 高级配置]]></title>
    <url>%2F2018%2F08%2F19%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2Fbind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[bind 高级配置 本节是 bind 配置的高级篇，实现 主从 DNS 服务器配置 DNS 子域授权 定义 DNS 的转发 DNS 访问控制 智能 DNS 1. 主从服务器DNS 的主从配置，是以域名解析的区域为基本单位的，也就是说如果一台主机上配置了多个 DNS 解析域，为哪个区域配置了从域，哪个区域就实现了主从服务器配置。 配置从区域首先要在从服务器上配置 DNS 服务，但配置方法更简单，因为只要定义一个区域即可，无需配置区域解析库文件。然后在主 DNS 的解析库文件中添加从服务器。需要特别注意的是主从服务器的时间要同步否则无法实现主从同步，可使用 ntpdate命令完成时间同步。具体步骤如下 1.1 On Slave从域配置: 定义区域: 定义一个从区域； 配置文件语法检查：named-checkconf 重载配置 12345678910$ vim /etc/named.rfc1912.zones # 追加zone "ZONE_NAME" IN &#123; type slave; file "slaves/ZONE_NAME.zone"; # /var/named 目录是不允许 named 用户写的 masters &#123; MASTER_IP; &#125;; # 主服务器的 ip 地址 &#125;;$ named-checkconf$ rndc reload 1.2 On Master主域配置: 确保区域数据文件中为每个从服务配置NS记录， 并且在正向区域文件需要每个从服务器的NS记录的主机名配置一个A记录，且此A后面的地址为真正的从服务器的IP地址； 123456$ vim /var/named/ZONE_NAME.zone@ IN NS ns2 # 从服务器具的 NS 记录$ vim /var/named/ZONE_FQDN.zone # 必需在正向解析库文件中添加 A 记录@ IN NS ns2 # 从服务器具的 NS 记录ns2 IN A ip_addr # 从服务器的 ip 地址 2. 子域授权正向解析区域授权子域的方法，以在 magedu.com. 的二级域中授权 ops.magedu.com. 三级域为例: 12345$ vim /var/named/ZONE_NAME.zone # 二级域的区域数据文件ops.magedu.com. IN NS ns1.ops.magedu.com. # 子域的 NS 记录ops.magedu.com. IN NS ns2.ops.magedu.com.ns1.ops.magedu.com. IN A IP.AD.DR.ESS # 子域的 A 记录ns2.ops.magedu.com. IN A IP.AD.DR.ESS 3. 定义转发默认情况下，DNS 服务在解析非自己负责的域名时，默认会向根域发起迭代查询。我们可以定义转发域，让 DNS 服务在解析非自己负责的域名时，向被转发服务器发起第归查询而不是向根域迭代查询。因此被转发的服务器必须允许为当前服务做递归。转发可分为区域转发和全局转发: 3.1 区域转发区域转发: 仅转发对某特定区域的解析请求；配置方法如下 123456$ vim /etc/named.rfc1912.zones # 追加zone "ZONE_NAME" IN &#123; type forward; forward &#123;first|only&#125;; forwarders &#123; SERVER_IP; &#125;; &#125;; 参数说明: forward:定义转发的特性 first：首先转发；转发器不响应时，自行去迭代查询； only：只转发； forwarders: 被转发服务器的 IP 3.2 全局转发全局转发：凡本地没有通过zone定义的区域查询请求，通通转给某转发器； 1234567$ vim /etc/named.conf # 追加options &#123; ... ... forward &#123;only|first&#125;; forwarders &#123; SERVER_IP; &#125;; .. ...&#125;; 4. bind 安全配置bind 的配置文件中可以使用 acl(访问控制列表)，把一个或多个地址归并一个命名的集合，随后通过此名称即可对此集全内的所有主机实现统一调用； acl 只能先定义后使用，所以通常位于 /etc/named.conf 最上面，并且是独立的配置段。 4.1 acl12345678910acl acl_name &#123; ip; net/prelen;&#125;;# eg:acl mynet &#123; 172.16.0.0/16; 127.0.0.0/8;&#125;; 4.2 bind内置的aclbind 由四个内置的 acl: none：没有一个主机； any：任意主机； local：本机； localnet：本机所在的IP所属的网络； 4.3 访问控制指令访问控制指令位于 options 表示对全局生效，位于 zone区域段中，表示只对此区域有效，常见的控制指令有 allow-query {} 允许查询的主机；白名单，未在此范围内的不能发起查询 allow-transfer {} 允许向哪些主机做区域传送；默认为向所有主机； 应该配置仅允许从服务器；如果没有从服务器，必需设置为 None allow-recursion {} 允许哪些主机向当前DNS服务器发起递归查询请求； allow-update {} DDNS，允许动态更新区域数据库文件中内容；存在风险，一般都为 none 12345678910111213$ vim /etc/named.confacl "slaves" &#123; 172.168.100.68; 172.168.0.0/16;&#125;$ vim /etc/named.rfc1912.zones # 追加zone "magedu.com." IN &#123; type master; file "magedu.com.zone" allow-transfer &#123; slaves; &#125;; allow-update &#123; none; &#125;;&#125; 5. 智能 DNS - bind view视图主要作用是实现，来自不同的用户的请求，可以返回不同的地址。比如来自内网的用户，得到的是内网的地址，来自公网的用户得到的是公网地址。12345view VIEW_NAME &#123; zone zone zone&#125; 示例12345678910111213141516view internal &#123; # 优先匹配的位于上面 match-clients &#123; 172.16.0.0/8; &#125;; zone &quot;magedu.com&quot; IN &#123; type master; file &quot;magedu.com/internal&quot;; # 内网的解析库文件 &#125;;&#125;;view external &#123; match-clients &#123; any; &#125;; zone &quot;magecdu.com&quot; IN &#123; type master; file magedu.com/external&quot;; # 外网的解析库文件 &#125;;&#125;; whois]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.3 bind安装和配置]]></title>
    <url>%2F2018%2F08%2F18%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2Fbind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[bind安装和配置 bind 全称为 Berkeley Internet Name Domain，是 DNS 协议的一种开源实现。由伯克利分校开发，现由 ISC 维护，也是现在使用最为广泛的DNS服务器软件，本节我们就来介绍如何使用 bind 配置一个 DNS 服务器。 1. BIND1.1 bind 安装rpm 包组成12345678$ yum install bind$ yum list all bind*已安装的软件包bind.x86_64 32:9.9.4-61.el7 @basebind-libs.x86_64 32:9.9.4-61.el7 @basebind-libs-lite.x86_64 32:9.9.4-61.el7 @basebind-license.noarch 32:9.9.4-61.el7 @basebind-utils.x86_64 32:9.9.4-61.el7 @base bind 的 rpm 包主要由以下几个: bind：提供的dns server程序、以及几个常用的测试程序； bind-utils：bind客户端程序集，例如dig, host, nslookup等，可用于测试 dns 服务； bind-libs：被bind和bind-utils包中的程序共同用到的库文件； bind-chroot：选装，让named运行于jail模式下,目的是限定 bind 的运行环境，更加安全 程序文件123456789101112131415161718192021222324$ rpm -ql bind|grep sbin/usr/sbin/arpaname/usr/sbin/ddns-confgen/usr/sbin/dnssec-checkds # DNS 安全扩展/usr/sbin/dnssec-coverage/usr/sbin/dnssec-dsfromkey/usr/sbin/dnssec-importkey/usr/sbin/dnssec-keyfromlabel/usr/sbin/dnssec-keygen/usr/sbin/dnssec-revoke/usr/sbin/dnssec-settime/usr/sbin/dnssec-signzone/usr/sbin/dnssec-verify/usr/sbin/genrandom/usr/sbin/isc-hmac-fixup/usr/sbin/lwresd/usr/sbin/named # bind serve 进程/usr/sbin/named-checkconf # bind 配置文件检查/usr/sbin/named-checkzone # DNS 数据库区域文件检查/usr/sbin/named-compilezone/usr/sbin/named-journalprint/usr/sbin/nsec3hash/usr/sbin/rndc # bind 的远程控制工具/usr/sbin/rndc-confgen bind rpm 包提供了以下核心程序: dnssec-*: Domain Name System Security Extensions,DNS 安全扩展 rndc: named 进程远程控制工具 named: bind server 的核心程序 named-checkconf: 用于检查 named 配置文件是否存在语法错误 named-checkzone: 用于检查 DNS 的区域解析库文件是否存在语法错误 named-checkconfnamed-checkconf [named.conf] 作用: 检查 named 配置文件是否存在语法错误 参数: named.conf 配置文件位置，默认为 /etc/named.conf named-checkzonenamed-checkzone zonename filename 作用: 用于检查 DNS 的区域解析库文件是否存在语法错误 参数: zonename: 区域名称 filename: 区域数据库文件所在位置 1$ named-checkzone magedu.com. /var/named/magedu.com.zone 1.2 bind 配置文件1234567891011121314151617181920$ rpm -ql bind|egrep "etc|var"|grep -v "share"/etc/logrotate.d/named/etc/named /etc/named.conf # 核心配置文件/etc/named.iscdlv.key # 核心配置文件内使用 include 包含的辅助配置文件/etc/named.rfc1912.zones/etc/named.root.key/etc/rndc.conf # rndc 配置文件/etc/rndc.key/etc/rwtab.d/named/etc/sysconfig/named/var/log/named.log # 日志文件/var/named # DNS 数据库区域解析文件默认所在的目录/var/named/data/var/named/dynamic/var/named/named.ca # 顶级域的配置文件/var/named/named.empty/var/named/named.localhost/var/named/named.loopback/var/named/slaves bind 的配置文件包括两个部分: 主配置文件：/etc/named.conf 主配置文件内使用 include 包含进来辅助配置文件: /etc/named.iscdlv.key /etc/named.rfc1912.zones /etc/named.root.key 解析库文件默认存放在 /var/named/目录下；一般名字为：ZONE_NAME.zone。一台DNS服务器可同时为多个区域提供解析，且必需包含如下几个区域解析库文件: 根区域解析库文件： named.ca localhost 的正向解析库：named.localhost 127.0.0.1 的反向解析库：named.loopback 默认情况下，上述的区域解析库文件在 bind 安装时，已由 rpm 包自动提供。 1.3 bind 进程管理123$ rpm -ql bind|grep systemd/usr/lib/systemd/system/named-setup-rndc.service/usr/lib/systemd/system/named.service bind程序安装完成之后，默认即可做缓存名称服务器使用；如果没有专门负责解析的区域，直接即可启动服务。 CentOS 6: service named start CentOS 7: systemctl start named.service named 进程启动后，默认会监听 tcp 的 953 号端口，rndc 可通过此端口对 named 进程进行远程控制。但是 named 进程默认只监听在 127.0.0.1 上，因此仅允许本地使用。 rndcrndc：remote name domain contoller1234567891011121314rndc [-b address] [-c config] [-s server] [-p port] [-k key-file ] [-y key] [-V] commandcommand is one of the following: reload Reload configuration file and zones. reload zone [class [view]] Reload a single zone. refresh zone [class [view]] Schedule immediate maintenance for a zone. stats Write server statistics to the statistics file. status Display status of the server. stop Save pending updates to master files and stop the server. stop -p Save pending updates to master files and stop the server flush Flushes all of the server&apos;s caches. flush [view] Flushes the server&apos;s cache for a view. 2. bind 配置2.1 配置格式1234567891011121314151617181920212223242526272829303132333435363738$ cat /etc/named.confoptions &#123; # 全局配置段 listen-on port 53 &#123; 127.0.0.1; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; # 区域解析库文件的默认存放目录 dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; localhost; &#125;; recursion yes; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;logging &#123; # 日志配置段 channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; # 顶级域解析库配置文件 type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones"; # 包含的辅助配置文件include "/etc/named.root.key"; bind 的主配置 /etc/named.conf 由三个部分组成: 全局配置段：options { ... } 日志配置段: logging { ... } 区域配置段: zone { ... } 配置那些由本机负责解析的区域，或转发的区域 /etc/named.conf有如下语法要求: 每个配置语句必须以分号结尾 {} 左右都必需要有空格 使用 // 或 /* */ 进行注释 2.2 缓存名 DNS 服务器配置named 进程默认启动后，即可作为缓存 DNS 服务器，但是默认配置只允许本地查询，无法对外提供服务，因此需要做如下修改。 更改 named 监听的地址，使其能与外部主机通信的地址； 学习使用时，建议关闭 dnssec 关闭仅允许本地查询配置 配置文件修改后应该使用named-checkconf，检查配置文件语法是否存在错误，在重起 named 进程。下面是配置过程 123456789101112131415$ vim /etc/named.conf # 修改监听地址，使其能与外部主机通信的地址； listen-on port 53; listen-on port 53 &#123; 172.16.100.67; &#125;; # 学习时，建议关闭dnssec dnssec-enable no; dnssec-validation no; dnssec-lookaside no; # 关闭仅允许本地查询： //allow-query &#123; localhost; &#125;;# 检查配置文件语法$ named-checkconf 3. 正反向解析区域配置上一节我们学习过区域解析库文件的语法格式，现在我们就来学习，如何配置正向和反向区域。我们将以配置magedu.com 这个二级域为例。 3.1 正向区域配置配置一个正向解析区域需要: 定义区域: 在主配置文件中或主配置文件辅助配置文件中定义区域，区域名字即为域名 建立区域数据文件，正向区域的主要记录为A或AAAA记录，并更改配置文件属性 重启服务: 检查语法错误，然后让服务器重载配置文件和区域数据文件 下面是配置的详细过程: 定义区域12345$ vim /etc/named.rfc1912.zones # 追加zone "magedu.com." IN &#123; type master; file "magedu.com.zone";&#125;; 区域定义参数: type: 用于定义区域的主机类型，可选值为 master: 主服务器 slave: 从服务器 hint: 根域 forward file: 指定区域数据库文件位置，使用相对路经，则在 /etc/named.conf 配置的默认路经/var/named之下 建立区域数据文件123456789101112131415161718192021222324$ cd /var/named $ touch /var/named/magedu.com.zone # 创建区域数据文件$ chgrp named /var/named/magedu.com.zone # 更改权限及属组$ chmod o= /var/named/magedu.com.zone$ vim /var/named/magedu.com.zone$TTL 3600$ORIGIN magedu.com. # ORIGIN 会自动补全下面 ns，mx1 的域名@ IN SOA ns1.magedu.com. dnsadmin.magedu.com. ( 2017010801 1H 10M 3D 1D) IN NS ns1 IN MX 10 mx1 IN MX 20 mx2ns1 IN A 172.16.100.67mx1 IN A 172.16.100.68mx2 IN A 172.16.100.69www IN A 172.16.100.67web IN CNAME wwwbbs IN A 172.16.100.70bbs IN A 172.16.100.71 重启服务1234567# 检查语法错误$ named-checkzone magedu.com. /var/named/magedu.com.zone$ named-checkconf# 重起服务$ rndc reload # 或$ systemctl reload named.service 3.2 反向解析区域配置配置反向区域与配置正向区域类似，只不过区域名称和区域数据库文件不同: 反向区域的名字格式为: 反写的网段地址.in-addr.arpa, 例如区域 172.16.100 的区域名称为 100.16.172.in-addr.arpa 反向区域没有 MX 资源记录，主要为 PTR 资源记录 定义区域12345$ vim /etc/named.rfc1912.zones # 追加zone "100.16.172.in-addr.arpa" IN &#123; type master; file "172.16.100.zone";&#125;; 建立区域数据文件123456789101112131415161718192021$ cd /var/named $ touch /var/named/172.16.100.zone # 创建区域数据文件$ chgrp named /var/named/172.16.100.zone # 更改权限及属组$ chmod o= /var/named/172.16.100.zone$ vim /var/named/172.16.100.zone$TTL 3600$ORIGIN 100.16.172.in-addr.arpa.@ IN SOA ns1.magedu.com. nsadmin.magedu.com. ( 2017010801 1H 10M 3D 12H ) IN NS ns1.magedu.com. 67 IN PTR ns1.magedu.com. # 域名必需写全，此时 ORIGIN 不能补全68 IN PTR mx1.magedu.com.69 IN PTR mx2.magedu.com.70 IN PTR bbs.magedu.com.71 IN PTR bbs.magedu.com.67 IN PTR www.magedu.com. 重启服务1234567# 检查语法错误$ named-checkzone 100.16.172.in-addr.arpa /var/named/172.16.100.zone$ named-checkconf# 重起服务$ rndc reload # 或$ systemctl reload named.service 4. DNS 测试工具digdig [-t RR_TYPE] name [@SERVER] [query options] 作用: 用于测试dns系统，因此其不会查询hosts文件； 参数: name: DNS 资源记录的名称 @SERVER: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 +[no]trace：跟踪解析过程 +[no]recurse：进行递归解析； -x IP:进行反向解析测试 常用: 反向解析测试 : dig -x IP 模拟完全区域传送： dig -t axfr DOMAIN [@server] 12345678910111213141516171819202122232425# 正向解析测试$ dig -t NS baidu.com.$ dig -t A www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; -t A www.baidu.com +recurse;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36303;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 126 IN CNAME www.a.shifen.com.www.a.shifen.com. 126 IN A 61.135.169.125www.a.shifen.com. 126 IN A 61.135.169.121;; Query time: 47 msec;; SERVER: 192.168.1.1#53(192.168.1.1);; WHEN: 二 8月 14 11:54:53 CST 2018;; MSG SIZE rcvd: 90# 反向解析测试$ dig -x 61.135.169.125 hosthost [-t RR_TYPE] name [SERVER_IP] 作用: 用于测试dns系统，不会查询hosts文件； 参数: name: DNS 资源记录的名称 SERVER_IP: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 1234567$ host -t A www.baidu.comwww.baidu.com is an alias for www.a.shifen.com.www.a.shifen.com has address 61.135.169.125www.a.shifen.com has address 61.135.169.121$ host -t PTR 61.135.169.121Host 121.169.135.61.in-addr.arpa. not found: 3(NXDOMAIN) nslookupnslookup [-options] [name] [server] 作用: 用于测试dns系统，默认进入交互式环境 nslookup&gt; server IP # 指定DNS服务器 set q=RR_TYPE # 要查询的资源记录类型； name # 要查询的名称 $ nslookup &gt; set q=A &gt; www.baidu.com Server: 192.168.1.1 Address: 192.168.1.1#53 Non-authoritative answer: www.baidu.com canonical name = www.a.shifen.com. Name: www.a.shifen.com Address: 61.135.169.121 Name: www.a.shifen.com Address: 61.135.169.125 &gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.2 DNS区域数据库文件格式]]></title>
    <url>%2F2018%2F08%2F17%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2FDNS%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[DNS区域数据库文件格式 DNS 的数据库文件记录了 FQDN 与 IP 的对应关系，有特定格式要求。本节我们就来学习DNS区域数据库文件格式 1. 资源类型DNS区域数据库文件一条记录为一行，被称为资源记录(Resource Record), 简称rr。常见的资源记录类型包括: SOA：Start Of Authority，起始授权记录； 一个区域解析库有且只能有一个SOA记录，而且必须放在第一条； NS：Name Service，域名服务记录；一个区域解析库可以有多个NS记录；其中一个为主的； A： Address, 地址记录，FQDN --&gt; IPv4； AAAA：地址记录， FQDN --&gt; IPv6； CNAME：Canonical Name，别名记录； PTR：Pointer，IP --&gt; FQDN MX：Mail eXchanger，邮件交换器；优先级：0-99，数字越小优先级越高 每种资源记录有特定的格式要求，接下来我们来分别介绍 2. DNS 资源记录的定义格式name [TTL] IN RR_TYPE value 作用: DNS 资源记录定义的语法 参数: name: 名称 value: 名称对应的值与属性 TTL: Time To Live,有效是长 IN: 关键字 RR_TYPE： 资源类型 注意： TTL可以从全局继承； @表示当前区域的名称； 相邻的两条记录其name相同时，后面的可省略； 对于正向区域来说，各MX，NS等类型的记录的value为FQDN，此FQDN应该有一个A记录； 配置文件内 ; 后跟注释 FQDN 最后的根域名.不可省略 下面是各个资源记录的配置示例 12345678910111213141516171819202122232425262728# SOAleistudy.com. 86400 IN SOA ns.leistudy.com. nsadmin.leistudy.com. ( 2018022801 ;序列号 2H ;刷新时间 10M ;重试时间 1W ;过期时间 1D ;否定答案的TTL值)# NSleistudy.com. IN NS ns1.leistudy.com.leistudy.com. IN NS ns2.leistudy.com.# MXleistudy.com. IN MX 10 mx1.leistudy.com. IN MX 20 mx2.leistudy.com.# Awww.leistudy.com. IN A 1.1.1.1www.leistudy.com. IN A 1.1.1.2mx1.leistudy.com. IN A 1.1.1.3mx2.leistudy.com. IN A 1.1.1.3# AAAAwww.leistudy.com. IN AAAA ::1# PTR4.3.2.1.in-addr.arpa. IN PTR www.leistudy.com 2.1 SOAname [TTL] IN RR_TYPE value name: 当前区域的名字；例如mageud.com.，或者2.3.4.in-addr.arpa.； value：有多部分组成 当前区域的区域名称（也可以使用主DNS服务器名称）； 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般使用点号来替代 (主从服务协调属性的定义以及否定答案的TTL) 1234567magedu.com. 86400 IN SOA magedu.com. admin.magedu.com. ( 2017010801 ; serial 主从服务协调属性 2H ; refresh 10M ; retry 1W ; expire 1D ; negative answer ttl 否定答案的 TTL) 2.2 NSname [TTL] IN RR_TYPE value name: 当前区域的区域名称 value: 当前区域的某DNS服务器的名字，例如ns.magedu.com.； 注意： 一个区域可以有多个ns记录； 相邻的两条记录其name相同时，后面的可省略； 12magedu.com. 86400 IN NS ns1.magedu.com. 86400 IN NS ns2.magedu.com. 2.3 MXname [TTL] IN RR_TYPE value name: 当前区域的区域名称 value：当前区域某邮件交换器的主机名； 注意：MX记录可以有多个；但每个记录的value之前应该有一个数字表示其优先级； 123# @ 可表示当前区域的名称@ IN MX 10 mx1.magedu.com.@ IN MX 20 mx2.magedu.com. 2.4 Aname [TTL] IN RR_TYPE value name：某FQDN，例如www.magedu.com. value：某IPv4地址； 123www.magedu.com. IN A 1.1.1.1www.magedu.com. IN A 1.1.1.2bbs.magedu.com. IN A 1.1.1.1 2.5 AAAAname [TTL] IN RR_TYPE value name：FQDN value: IPv6 1www.magedu.com. IN AAAA ::1 2.6 PTRname [TTL] IN RR_TYPE value 作用: 反向解析的资源记录格式 name：IP地址，IP必需反过来写，而且必需加特定后缀；例如 1.2.3.4 的记录应该写为4.3.2.1.in-addr.arpa. value：FQND 14.3.2.1.in-addr.arpa. IN PTR www.magedu.com. 2.7 CNAMEname [TTL] IN RR_TYPE value name: FQDN格式的别名； value: FQDN格式的正式名字； 1web.magedu.com. IN CNAME www.magedu.com.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.1 DNS域名服务原理]]></title>
    <url>%2F2018%2F08%2F16%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2FDNS%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[DNS域名服务原理 本章我们开始学习 Linux 上的第一个服务，也是互联网的基础服务 DNS。之所以存在 DNS 服务是因为相对于数字形式的 ip 地址，人们更容易记住字符串，因此就有了将字符串格式的域名转换为数字格式的 ip 的需求。在互联网诞生的早期，计算机尚且属于稀缺资源，域名与 ip 地址的对应关系，保存在本地的 hosts (/etc/hosts) 文件上。随着连入互联网的主机越来越多，每个主机都保存所有域名与ip 对应的的副本已经不现实，于是就有了 DNS 服务。本节我们就来讲解 DNS 服务，内容包括: DNS 服务的原理 DNS 域名解析的过程 DNS 区域数据库文件 使用 bind 配置 DNS 服务 DNS 虽然是互联网的基础服务，但是实际上很少人会买域名，配置 DNS 服务器的人很少，所以很多人对 DNS 服务并不熟悉。本节我们就来讲解 DNS 服务的基本原理。 1. DNS 概述1.1 DNS 相关概念DNS 全称为 Domain Name Service 属于应用层协议，工作于 udp/tcp 的 53 号端口。DNS 服务工作于 udp 53 号端口，tcp 的 53 端口用于实现主从 DNS 同步。 为了分散 DNS 查询的负载，同时方便域名的管理，DNS 被组织成一个倒置的树结构。如下图所示 根域为 .，其下是顶级域和国家域，每个顶级域由不同的机构进行域名管理。顶级域下是二级域，我们购买的域名不是单个域名而是整个二级域，购买后可根据需要配置子域。比如，我在.com.顶级域下购买了域 tao.com.，可根据需求配置一个域名 web.tao.com.,也可以配置 image.web.tao.com.，对于域名大范围在右边，小范围在左边。 1.2 DNS 服务上面展示的倒置树是 DNS 的结构示意图，在每个域上，都是有一个个 DNS 服务器。DNS 服务由 bind 程序提供。按照提供的服务类型，可将 DNS 服务器分为 负责解析至少一个域的主名称服务器和辅助名称服务器； 不负责哉解析的缓存名称服务器； 1.3 DNS 查询请求流程 12 章中我们讲解了如何配置 Linux 的网络属性，/etc/resolv.conf 配置文件内配置了我们的 DNS 服务器指向。当我们在浏览器内输入 www.baidu.com 时，将按照如下的顺序查询 百度的 ip 地址: 首先会访问本地的 hosts文件，如果有记录则直接返回结果 查询本地的DNS缓存DNS，有则直接返回 向 /etc/resolv.conf 配置的 DNS 服务器发起查询请求 如果域名是自己负责解析的域，DNS 服务器将直接查询数据库并返回结果； 如果不是自己负责解析域，并且服务器内未缓存，DNS 服务器将向发起迭代查询 如上图所式，配置文件指向的 DNS 服务器，将帮助我们按照 DNS 的层级结构从顶至下发起迭代查询，直至查询到结果返回给我们。 因此 DNS 的查询可分为: 递归查询：本机向配置的 DNS 服务器发起的即是递归查询，DNS 服务器返回给我们的是结果 迭代查询：DNS 服务向上层 DNS 服务器发起的则是迭代查询，需要根据返回结果继续迭代查询。 DNS 服务器返回给我们的结果有如下几种情况: 肯定答案：域名的解析结果 否定答案：不存在查询的键，因此，不存在与其查询键对应的值； 权威答案：由直接负责的DNS服务器返回的答案； 非权威答案：由非直接负责的DNS服务器的缓存返回，有可能缓存失效 1.4 DNS 反向解析DNS 除了将域名解析为 ip 外，还能将 ip 解析为主机名 名称 –&gt; IP：正向解析 IP –&gt; 名称：反向解析 但是需要注意的是，正向反向解析的的名称空间，不是同一个空间，即正向反向解析不是同一棵树，使用的是不同的解析库文件 1.5 DNS 中的区域与域域(domain)，FQDN（Full Qualified Domain Name）是一种逻辑概念，包括物理上的 由 FQDN --&gt; IP 的正向解析区域(zone) 由 IP --&gt; FQDN 的反向解析区域(zone) 2. 主从 DNS 服务器为了放置 DNS 单节点故障导致整个服务不可用，也为了平衡负载，DNS 服务器通常为主从模式 主DNS服务器：为维护所负责解析的域数据库的那台服务器；读写操作均可进行； 从DNS服务器：从主DNS服务器那里或其它的从DNS服务器那里“复制”一份解析库；但只能进行读操作； 2.1 主从同步方式DNS 服务器的主从复制有如下特性: 数据库有序列号(serial),即数据库的版本号；主服务器数据库内容发生变化时，其版本号递增 从服务器会按照设置的时间间隔从主服务器同步数据 refresh: 刷新时间间隔,从服务器每多久到主服务器检查序列号更新状况 retry: 重试时间间隔, 从服务器从主服务器请求同步解析库失败时，再次发起尝试请求的时间间隔； expire: 过期时长，从服务器始终联系不到主服务器时，多久之后放弃从主服务器同步数据；停止提供服务； 处理从服务器定时同步外，主服务器会在每次数据发生变更时，通知从服务器随时更新数据 数据传送(区域传送)分为如下两种，通常只会进行增量传送 全量传送：axfr, 传送整个数据库； 增量传送：ixfr, 仅传送变量的数据]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.4 私建 CA]]></title>
    <url>%2F2018%2F08%2F15%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E7%A7%81%E5%BB%BACA%2F</url>
    <content type="text"><![CDATA[私建 CA 很多时候我们为了测试目的，或者不便让用户去申请证书，我们就需要私建 CA，本节我们就来讲解如何私建 CA。 1. 私建 CACA创建的工具有两个，小范围内可直接使用 openssl 命令，如果要维护大量的CA，可以使用完全 CA 创建工具 openCA。 那么如何创建 CA？前面我们知道 PKI 公钥基础设施包括如下几个部分: 签证机构：CA 注册机构：RA 证书吊销列表：CRL 证书存取库： 所以私建 CA 首先要创建出上述的基础设施，然后才能签发证书。而证书的申请及签发大体上包括以下步骤: 申请方生成申请请求 RA 进行核验 CA 签署 证书获取 下面我们就分创建 CA，和签发一个证书两个步骤讲解私建 CA的整个过程。 1.1 创建公钥基础设施创建一个私有 CA非常简单，只要在确定配置为 CA 的服务上生成一个自签证书，并为CA提供所需要的目录及文件即可。CA 所需的目录定义在 CA 的配置文件中 /etc/pki/tls/openssl.cnf 12345678910111213141516171819202122232425# less /etc/pki/tls/openssl.conf####################################################################[ ca ]default_ca = CA_default # The default ca section####################################################################[ CA_default ]dir = /etc/pki/CA # CA 的工作目录certs = $dir/certs # 已经签发的证书目录crl_dir = $dir/crl # 已吊销证书的放置目录database = $dir/index.txt # 已经签发证书的索引#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # default place for new certs.certificate = $dir/cacert.pem # CA自签证书serial = $dir/serial # 当前序列号，表示新签发证书的编号crlnumber = $dir/crlnumber # 新吊销证书的编号 # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRLprivate_key = $dir/private/cakey.pem # CA 私钥RANDFILE = $dir/private/.rand # private random number filedefault_days = 365 # 证书默认的有效时长default_crl_days= 30 # how long before next CRL 1.2 证书申请签发查看openssl req [options] outfile 作用: 生成证书签署请求 选项: -new：生成新证书签署请求； -x509: 生成自签格式证书，专用于创建私有CA时； -key：生成请求时用到的私钥文件,openssl 会自动提取出公钥放置在证书签署请求中； -out：生成的请求文件路径，自签证书将直接生成签署过的证书 -days：证书的有效时长，单位是day； openssl ca 作用: CA 签发证书 选项: -in &lt;file&gt;: 证书签署请求文件路径 -out &lt;file&gt;: 生成的新证书的保存路径 -days：证书的有效时长，单位是day； openssl x509 作用: 查看证书信息 选项: -in：指定输入文件，默认是标准输入。 -out：指定输出文件，默认是标准输出。 -passin：指定私钥密码的来源 -serial：显示序列号。 -subject：打印项目的DN -issuer：打印签发者的DN -email：打印email地址 -startdate：打印开始日期 -enddate：打印结束日期 -purpose：打印证书的用途 -dates：打印开始日期和结束日期 -public：输出公钥 -fingerprint：输出证书的指纹 -noout：没证书输出 -days: 设置证书的有效期时间，默认30天 -req：输入是一个证书请求，签名和输出 -CA：设置CA证书，必须是PEM格式的 -text：以文本格式输出证书 1.3 构建私有CA步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 1. 生成所需要的文件和目录$ dir=/etc/pki/CA$ cd $dir$ touch &#123;serial,index.txt&#125;$ echo 01 $ serial$ mkdir -pv $dir&#123;certs,crl,newcerts&#125;# 2. CA 自签证书# 生成私钥$ (umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096)$ openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655 # new：生成新证书签署请求； # x509：生成自签格式证书，专用于创建私有CA时； # key：生成请求时用到的私钥文件； # out：证书的保存路径 # days：证书的有效时长，单位是day；# 3. 发证# 3.1 要用到证书的主机生成证书请求：# 3.2 把请求文件传输给 CA# 3.3 CA 验证证书合法性，签署证书，并将证书发还给请求者# 3.1 步骤：（以httpd为例）# 用到证书的主机生成私钥$ mkdir /etc/httpd/ssl$ cd /etc/httpd/ssl$ (umask 077; openssl genrsa -out /etc/httpd/ssl/httpd.key 2048)# 生成证书签署请求，(csr - certificate security request)$ openssl req -new -key /etc/httpd/ssl/httpd.key -out /etc/httpd/ssl/httpd.csr -days 365# 3.2 将请求通过可靠方式发送给CA主机；$ scp /etc/httpd/ssl/httpd.csr root@196.168.1.105:/tmp# 3.3 在CA主机上签署证书 (crt - certificate 的简写)$ openssl ca -in /tmp/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365# 3.4 查看证书中的信息：$ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -text# 4. 吊销证书：# 4.1. 客户端获取要吊销的证书的serial：$ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject# 4.2 CA主机吊销证书# 先根据客户提交的serial和subject信息，对比其与本机数据库index.txt中存储的是否一致；# 吊销, 其中的SERIAL要换成证书真正的序列号；$ openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem# 4.3. 生成吊销证书的吊销编号（第一次吊销证书时执行）$ echo 01 $ /etc/pki/CA/crlnumber# 4.4 更新证书吊销列表$ openssl ca -gencrl -out thisca.crl# 4.5 查看crl文件：$ openssl crl -in /PATH/FROM/CRL_FILE.crl -noout -text]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.3 openssl 命令使用]]></title>
    <url>%2F2018%2F08%2F14%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2Fopenssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[openssl 命令使用 OpenSSL 分为三个组成 libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 openssl 命令行工具有多个子命令，大体上分为如下三类 标准命令(standard) 消息摘要命令（dgst子命令） 加密命令（enc子命令） 本节我们就来讲解常见命令的使用 1. openssl 使用概述12345678910111213141516171819202122232425262728293031323334353637383940openssl ?openssl:Error: '?' is an invalid command.Standard commands # 可使用的标准子命令 asn1parse ca ciphers cms crl crl2pkcs7 dgst dh dhparam dsa dsaparam ec ecparam enc engine errstr gendh gendsa genpkey genrsa nseq ocsp passwd pkcs12 pkcs7 pkcs8 pkey pkeyparam pkeyutl prime rand req rsa rsautl s_client s_server s_time sess_id smime speed spkac ts verify version x509 # 消息摘要子命令 dgst, 下面是可用的算法Message Digest commands (see the `dgst' command for more details)md2 md4 md5 rmd160 sha sha1 # 对称加密子命令 enc，下面是可用的算法Cipher commands (see the `enc' command for more details)aes-128-cbc aes-128-ecb aes-192-cbc aes-192-ecb aes-256-cbc aes-256-ecb base64 bf bf-cbc bf-cfb bf-ecb bf-ofb camellia-128-cbc camellia-128-ecb camellia-192-cbc camellia-192-ecb camellia-256-cbc camellia-256-ecb cast cast-cbc cast5-cbc cast5-cfb cast5-ecb cast5-ofb des des-cbc des-cfb des-ecb des-ede des-ede-cbc des-ede-cfb des-ede-ofb des-ede3 des-ede3-cbc des-ede3-cfb des-ede3-ofb des-ofb des3 desx idea idea-cbc idea-cfb idea-ecb idea-ofb rc2 rc2-40-cbc rc2-64-cbc rc2-cbc rc2-cfb rc2-ecb rc2-ofb rc4 rc4-40 rc5 rc5-cbc rc5-cfb rc5-ecb rc5-ofb seed seed-cbc seed-cfb seed-ecb seed-ofb zlib 2. 标准命令1.1 生成用户密码openssl password [OPTIONS] [password] 作用: 生成用户密码 参数: password 用户密码，可省略，默认会提示用户输入 选项: -crypt: standard Unix password algorithm (default) -1: MD5-based password algorithm -salt string: use provided salt -in file: read passwords from file -stdin: read passwords from stdin -reverse: switch table columns 123$ openssl passwd -1 -salt tabcPassword: # 根据提示输入用户密码$1$tabc$dMfThcS/0AhHbG277/5.Y. 1.2 生成随机数openssl rand OPTIONS num 参数: NUM 表示字节数 选项: -out file: write to file -base64: base64 encode output -hex: hex encode output 123456789$ openssl rand -base64 10CyrtOhCwGXySRQ==$ openssl rand -hex 1061fc2a72e000622746f4$ openssl passwd -1 -salt `openssl rand -hex 4`Password:$1$e3a21fb9$Zahip67zta7xJB2QiaVAm0 2. 加密命令2.1 对称加密openssl enc -ciphernam OPTIONS 作用: 使用对称加密算法加密文件 选项: -e: 加密 -d: 解密 -a/-base64: 使用 base64 编码和解码文件 -ciphernam: 指定使用的加密算法 -in &lt;file&gt;: 待加密的明文文件 -out &lt;file&gt;: 加密后的密文输出路径 -pass &lt;arg&gt;: 加密使用的密码 -md: 指定密钥生成的摘要算法，用户输入的口令不能直接作为文件加密的密钥，而是经过摘要算法做转换，此参数指定摘要算法，默认md5 -S: 在把用户密码转换成加密密钥的时候需要使用盐值，默认盐值随机生成 -salt: use a salt in the key derivation routines. This is the default 12345# -e 加密openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertext# -d 解密openssl enc -d -des3 -a -salt -out fstab -in fstab.ciphertext 2.2 单向加密openssl dgst OPTIONS file 作用: 使用单向加密算法，提取摘要信息 参数: file 指定提取摘要的文件 提取算法: -md4 -md5 -ripemd160 -sha -sha1 -sha224 -sha256 -sha384 -sha512 -whirlpool 选项: -c: to output the digest with separating colons -r: to output the digest in coreutils format -d: to output debug info -hex: output as hex dump -binary: output in binary form 12$ openssl dgst -md5 /PATH/TO/SOMEFILE$ md5sum /path/to/somefile 2.3 公钥加密openssl rsautl 作用: 使用RSA密钥进行加密、解密、签名和验证等运算 算法： 加解密: RSA，ELGamal 数字签名：RSA， DSA， ELGamal 密钥交换：DH 3. 生成密钥openssl genrsa OPTIONS numbits 作用: 生成私钥 参数: numbits 私钥的长度，只能是 1024 的证书倍 参数: -out &lt;file&gt;: 输出的文件路径 -passout arg: 指定密钥文件的加密口令，可从文件、环境变量、终端等输入 openssl rsa [options] &lt;infile &gt;outfile 作用: 管理生成的密钥，rsa 默认输出私钥，通过 -pubout 指定输出公钥 选项: -in arg:输入文件 -out arg:输出文件 -passin arg:指定输入文件的加密口令，可来自文件、终端、环境变量等 -passout arg:指定输出文件的加密口令，可来自文件、终端、环境变量等 -pubin:指定输入文件是公钥 -pubout:指定输出文件是公钥 -text:以明文形式输出各个参数值 -check:检查输入密钥的正确性和一致性 123456# 生成私钥# shell 中 () 内的命令会在同一个子 shell 中执行$ (umask 077; openssl genrsa -out /PATH/TO/PRIVATE_KEY_FILE NUM_BITS)# 提出公钥$ openssl rsa -in /PATH/FROM/PRIVATE_KEY_FILE -pubout -out outputfile 4. Linux系统上的随机数生成器Linux 中有如下几个随机数生成器 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞； /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数，非阻塞；伪随机数不安全； 附注: 熵池中随机数的来源： 硬盘IO中断时间间隔； 键盘IO中断时间间隔；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.2 公钥基础设置与ssl会话]]></title>
    <url>%2F2018%2F08%2F13%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[公钥基础设置与ssl会话 上一节我们学习了通信加密的基础知识，常见的加密解密算法，ssl/tls 协议。 还概括性的介绍了在已知公钥和基于公钥基础设施实现安全通信的过程。ssl/tls 正是用来规范如何通过公钥基础设施来进行安全通信的协议，本节我们就来详细讲解公钥基础设施，数字证书以及 ssl 会话建立的过程。 1. 公钥基础设施公钥基础设置，PKI(Public Key Infrastructure)，由以下部分: 签证机构：CA，实际签发数字证书的机构 注册机构：RA，接收证书申请的机构 证书吊销列表：CRL 证书存取库 证书申请方向注册机构发起证书申请请求，注册机构统一提交给签证机构，由签证机构对申请者进行尽责调查，在确认无误后向申请方签发证书。如果申请者私钥丢失等其他原因，可向签证机构申请吊销证书。 2. 数字证书X.509v3 定义了证书的结构以及认证协议标准，数字证书包含了以下内容: 版本号 序列号 签名算法ID: 提取数字证书特征码的单向加密算法 发行者名称 有效期限 主体名称 主体公钥 发行者的惟一标识 主体的惟一标识 扩展 发行者的签名: CA 私钥对数字证书的特征码加密后的结果 2. SSL会话ssl 会话创建需要三个步骤: 客户端向服务器端索要并验正证书； 双方协商生成“会话密钥”； 双方采用“会话密钥”进行加密通信； SSL Handshake Protocol(ssl 握手协议) 就是用来规范客户端与服务器端如何协商生成会话密钥。如下图所示，其分成了四个阶段 第一阶段：ClientHello客户端将向服务器端发送以下信息: 支持的协议版本，比如tls 1.2； 客户端生成一个随机数，稍后用户生成“会话密钥” 支持的加密算法，比如AES、3DES、RSA； 支持的压缩算法； 第二阶段：ServerHello服务器端将向客户端发送以下信息 确认使用的加密通信协议版本，比如tls 1.2； 服务器端生成一个随机数，稍后用于生成“会话密钥” 确认使用的加密方法； 服务器证书； 第三阶段-Client：客户端接收到服务器的证书后，验正服务器证书，在确认无误后取出其公钥；（发证机构、证书完整性、证书持有者、证书有效期、吊销列表）。发送以下信息给服务器端： 一个随机数； 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 客户端握手结束通知； 第四阶段-Server服务器端收到客户端发来的第三个随机数pre-master-key后，计算生成本次会话所有到的“会话密钥”；向客户端发送如下信息： 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 服务端握手结束通知；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.1 通信加密和解密技术入门]]></title>
    <url>%2F2018%2F08%2F12%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[通信加密和解密技术入门 从本章开始，我们进入 Linux 学习的第二部分 Linux 网络服务与安全。第二部分会涉及到以下的内容 网络安全加密，Openssl，Openssh DNS 服务 web 服务，包括构建在 apache httpd 服务上的 LAMP，和构建在 nginx 上的 LNMP 文件服务，包括 nfs，samble，ftp 自动化安装相关的 dhcp，pxe 防火墙 iptables 系统管理相关的一些命令和服务包括 sudo，pam, nsswitch 本章我们将学习网络加密和解密技术，内容分成了三个部分: 基础知识，包括常见的加密算法，ssl 协议，以及安全通信中的基础设施 CA 如何利用我们的加密算法实现安全通信 加密工具 openssl工具的使用 很多互联网的基础协议诞生于互联网产生的初期，那时候能使用互联网的人很少，能实现主机之间的通信就已经很不容易，也就没有安全通信的需求，所以大多数的基础网络通信协议都是明文传输的。随着互联网的普及，安全通信的需求越来越迫切，ssl 协议孕育而生，它位于应用层和传输层之间，为所有的应用层协议提供可选的安全通信服务。安全通信需要各种加密技术，同时也出现了通信安全的基础设施 CA，本节就会介绍这部分的基础知识，内容包括 网络安全概述，包括安全的目标，面临的威胁，以及可能的防范手段 ssl 协议的作用和实现 加密算法和协议 公钥基础设施及安全通信的过程 1. 网络安全概述 安全的目标： 保密性：confidentiality 完整性：integrity 可用性：availability 攻击类型： 威胁保密性的攻击：窃听、通信量分析； 威胁完整性的攻击：更改、伪装、重放、否认 威胁可用性的攻击：拒绝服务（DoS） 解决方案： 技术（加密和解密）、服务（用于抵御攻击的服务，也即是为了上述安全目标而特地设计的安全服务） 加密和解密： 传统加密方法：替代加密方法、置换加密方法 现代加密方法：现代块加密方法 服务： 认证机制 访问控制机制 2. ssl 协议 通信协议栈分为 5 层，最上面是应用层，又称为资源子网，关注的是只关心数据是如何组织起来的，传输层及以下又称为通信子网关注的是如何传输数据。 ssl(Secure Sockets Layer) 协议相当于位于应用层与传输层之间的半层，它是可选的，可为所有的应用协议提供可选的安全通信服务。ssl 有众多实现，最著名的开源实现是 OpenSSL，任何想使用安全通信的服务，只要在进行网络传输时调用 OpenSSL 提供的服务即可。以 https 服务为例 http --&gt; ssl --&gt; https。 通过 OpenSSL 实现安全通信的过程其实是非常复杂的，http 与 https 其实是两个独立的服务，http的服务的默认端口是 80，https 则是 443。 2.1 ssl 版本SSL协议的诞生Netscape（网景通信公司）在1994年创建了SSL协议的原始规范，但是第一个SSL协议版本因为使用弱加密算法受到密码学界的质疑，所以从来没有公开发布过。Netscape在1995年2月修订了规范，并发布了一个大大改进的版本SSL 2.0协议，虽然SSL 2.0版本被认为是一个相当强大和健壮的协议，但仍存在一些易受攻击的漏洞。 SSL协议更名TLS协议在1996年，由Netscape和Paul Kocher共同设计的版本SSL 3.0协议发布。SSL(Secure sockets Layer) 3.0协议获得互联网广泛认可和支持，因特网工程任务组（IETF）接手负责该协议，并将其重命名为传输层安全 TLS(Transport Layer Security) 协议。TLS协议的第一个版本（RFC 2246）于1999年1月发布，实质上就是SSL 3.0协议的适度改进版。虽然TLS协议和SSL协议是同一个协议的迭代升级，但是其重命名后在名称上造成的混淆一直延续到今天，业内通常将二者统称为SSL/TLS协议。 当前正在使用的时 TLS 的 V1.0, V1.1, V1.2, V1.3。TLS 采用分层设计 最底层：基础算法原语的实现，aes, rsa, md5 向上一层：各种算法的实现； 再向上一层：组合算法实现的半成品； 用各种组件拼装而成的各种成品密码学协议软件； 2.2 ssl 开源实现Linux系统上 ssl 有两个开源实现:OpenSSL(ssl) 和 GPG(pgp)。GPG 是商业软件 pgp 的开源实现。更常用的是 OpenSSL，因此我们主要讲解 OpenSSL。OpenSSL 由三个部分组成: libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 3. 加密算法和协议加密算法分为以下几类，它们具有不同的特性，在安全通信中用于不同的安全目标。 对称加密: 数据加密 公钥加密: 数字签名和密钥交换 单向加密: 数据完整性认证 密钥交换: 完成密钥交换的特定协议 3.1 对称加密 定义: 加密和解密使用同一个密钥； 特性： 加密、解密使用同一个密钥； 将原始数据分割成为固定大小的块，逐个进行加密； 缺陷： 密钥过多； 密钥分发困难 算法 DES：Data Encryption Standard; 3DES：Triple DES; AES：Advanced Encryption Standard; (128bits, 192bits, 256bits, 384bits) Blowfish Twofish IDEA RC6 CAST5 3.2 公钥加密： 定义: 密钥分为公钥与私钥 公钥：从私钥中提取产生；可公开给所有人；pubkey 私钥：通过工具创建，使用者自己留存，必须保证其私密性；secret key； 特点：用公钥加密的数据，只能使用与之配对儿的私钥解密；反之亦然； 缺陷：加密时间长 用途： 数字签名：主要在于让接收方确认发送方的身份； 密钥交换：发送方用对方公钥加密一个对称密钥，并发送给对方； 数据加密 算法： RSA， DSA， ELGamal DSS: Digital Signature Standard DSA：Digital Signature Algorithm 3.3 单向加密 定义: 用于提出数据指纹；只能加密，不能解密； 特性：定长输出、雪崩效应； 功能：数据完整性校验； 算法： md5：Message Digest 5, 128bits sha1：Secure Hash Algorithm 1, 160bits sha224, sha256, sha384, sha512 3.4 密钥交换协议密钥交换协议 IKE（Internet Key Exchange）主要作用是如何在不安全的网络环境中实现密钥交换。 主要有以下算法 RSA，使用公钥加密进行密钥交换 DH算法(迪菲-赫尔曼算法) ECDH(椭圆曲线DH算法) ECDHE(临时椭圆曲线DH算法) DH 算法的密钥交换过程如下所示 1234567891011121314公钥加密DH（Deffie-Hellman）A：p, gB：p, gA: x --&gt; p^x%g ==&gt; B A: (p^y%g)^x=p^yx%gB: y --&gt; p^y%g ==&gt; A B: (p^x%g)^y=p^xy%g 4. 公钥基础设施与安全通信过程公钥基础设施主要作用是确保安全的获取通信双方的公钥，要完整了解公钥基础设施与安全通信过程我们得分成两步: 在已知通信双方公钥的情况下，我们如何安全通信 公钥基础设施如何确保我们安全拿到对方的公钥 4.1 已知公钥下安全通信过程A —&gt; B1234567891011A -----&gt; B ----&gt; 作用-----------------------------------------------------B公钥加密的 B 私钥解密 密钥交换对称加密密钥 获取对称密钥------------------------------------------------------对称加密的 ------&gt; 使用对称密钥 -----&gt; 数据保密性传输内容 解密传输内容---------------------------------------------------------A私钥加密的 --------&gt; 使用 A 公钥解密指纹 ---&gt; A 身份验证传输内容的指纹 重算传输内容指纹 对比指纹 ---&gt; 数据完整性 A: A 使用单向加密提取传输内容特征码，并使用自己的私钥加密特征码 A 使用对称密钥加密传输内容 A 使用 B 的公钥加密使用到的对称加密的密钥 B: B 使用自己的私钥解密获取对称加密的密钥 使用对称加密密钥解密整个文件内容 使用 A 的公钥解密获取邮件内容特征码 使用同样的加密算法提取接收内容的特征码，与解密的特征码对比验证数据完整性 4.2 基于CA获取公钥A —&gt; B 数字证书交换及验证 通信双方分别发送 hello 信息给对方，开启 ssl 会化，然后协商后续通信过程使用的加密算法等信息 双方分别获取对方的数字证书 通过发行者名称获取本地已经保存的CA的证书，获取CA公钥 验证CA: 使用 CA 公钥解密发行者签名，认证 CA，并获取数字证书特征码 验证数字证书完整性: 使用数字证书中签名算法ID表明的单向加密算法重新计算特征码，并与 3 中解密出来的特征码进行比对 对于主机数字证书，主体名称必须与访问的主机名称(域名) 必须一致，否则也可能不会通过认证 证书验证包括: 证书内容完整有效 证书名称与访问服务器是否一致 证书是否是信任的CA颁发的 证书是否在有效期内 证书是否在CA的吊销列表中 通信双方通过 CA 以安全方式获取私钥之后，就可以安全性的进行网络通信了。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux进阶</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.5 SELinux简介]]></title>
    <url>%2F2018%2F08%2F11%2Flinux_mt%2F16-selinux%2FSELinux%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[SELinux简介 对于安全性很多人存在误解，觉得 Linux 比 windows 更加安全，其实不然。SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，用于增强 Linux 的安全性。SELinux 在实际生产环境中使用的很少，原因并不是 SELinux 不够好，而是想要做到精准的权限控制，需要明确知道并管理进程需要访问的资源，对这些信息的管理本身有很大负担。所以本节我们只介绍 SELinux 的简单原理和管理，并不会对其做深入介绍。具体内容包括: SELinux 的权限模型 SELinux 工作模型 SELinux 管理 1. SELinux 权限模型Linux传统权限模型下，进程能够访问的哪些资源，取决于进程的发启者能够访问的资源集合。这样存在一些弊端，资源所需访问的资源很少，但是能够访问的资源却很大，一旦进程被不怀好意的人控制，就会对 Linux 安全造成威胁。因此 SELinux 才用最小权限法则，进程只能访问那些它必需访问控制的资源，这样就可以提高 Linux 的安全性。两种权限模型的对比如下: Linux传统权限模型 权限模型: DAC (Discretionary Access Control) 自主访问控制 进程权限: 取决于进程发起者作为属主、属组、其它用户的权限集和 SELinux: 权限模型: MAC (Mandatory Access Control): 强制访问控制 TE (Type Enforcement)：最小权限法则 进程权限: 取决于SELinux 规则库 SELinux 有两种工作级别，不同工作级别下，受控级别的范围不同: strict： 每个进程都收到 selinux 的控制 targeted: 仅有限个进程受到 selinux 的控制，只监控容易被入侵的进程 之所以有 targeted 级别，主要还是受限于管理所有进程能够访问资源的成本太高 2. SELinux 工作模型进程的执行过程可以概括成 “进程对资源执行的操作” 即 subject operation object subject: 进程主体 object: 系统资源，主要是文件 operation: 进程对资源能够执行的操作 SELinux 的核心就是确定”进程能够对哪些资源执行什么操作”。为了将进程与资源关联起来，SELinux 为每个进程及文件提供了安全标签 安全标签: user:role:type:: user: SELinux 的 user role: 角色 type: 类型 进程的 type 称为域 domain,表示一个空间 资源的 type 称为类型，域能访问哪些资源类型取决于 SELinux 规则库 policy domian 包含的 type 即进程能够操作的资源范围，domian 与 type 的对应关系记录在 SELinux 的规则库中 除了对进程访问资源的控制外，SELinux 还对进程的功能作了限制，比如 httpd 进程而言，其有上传和下载等功能，相对于下载而言，上传功能的风险则高的多。因此默认情况下高风险功能在 SELinux 中是禁止的，想要启用必需显示开启。这部分控制又称为 SELinux 的布尔规则设置。 2.1 进程的安全标签如下第一段 LABEL 即为进程的域，由 5 段组成，后两段对于我们了解 SELinux 意义不大 123456[root@hp ~]# ps auxZLABEL USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDsystem_u:system_r:init_t:s0 root 1 0.7 0.1 194440 9048 ? Ss 21:28 0:02 /usr/lib/systemd/systemd --switched-root --system --deserializesystem_u:system_r:kernel_t:s0 root 2 0.0 0.0 0 0 ? S 21:28 0:00 [kthreadd]system_u:system_r:kernel_t:s0 root 3 0.0 0.0 0 0 ? S 21:28 0:00 [ksoftirqd/0]system_u:system_r:kernel_t:s0 root 4 0.0 0.0 0 0 ? S 21:28 0:00 [kworker/0:0] 2.2 文件的类型system_u:object_r:admin_home_t:s0 即为文件的类型 1234[root@hp ~]# ll -Z .-rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfgdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Desktopdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Documents 2.3 SELinux 规则库 policySELinux 的规则遵循“法无授权即禁止不可行”的原则，即如果进程受 SELinux 控制，如果规则库中没有显示定义规则则禁止访问。另外由于所由进程对资源的访问都会读取 SELinux 规则库，因此规则库以二进制格式进行存放，需要专用的命令才能修改。 SELinux 的规则库即按照我们之前所说的模型进行编写: subject operation object ==&gt; domain --&gt; policy --&gt; type subject: 主-进程 domain object: 宾-资源 type Files Directories Porcesses Special files or various types(块设备文件、字符设备、FIFO、socket) FileSystems Links File descriptors operation: 谓-操作 Create Read Write Lock Rename Link Unlink Append Excute I/O Control 2. SELinux 配置文件SELinux 的配置位于 /etc/sysconfig/selinux 1234567891011# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=permissive# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected.# mls - Multi Level Security protection.SELINUXTYPE=targeted 参数: SELINUXTYPE: SELinux 的工作级别 SELINUX: SELinux 启用状态 disabled: 禁用，关闭 SELinux enforcing: 启用，强制，一旦进程不符合 SELinux 的权限控制会禁止进程访问相关资源 permissive: 启用，警告，SELinux 不会禁止进程违规访问资源，仅记录日志 附注: SELinux 日志文件则位于: /var/log/audit/audit.log 需要特别说明的是由 disabled –&gt; enforcing|permissive 需要重启系统才会生效，因为系统要为所有受控的进程和文件打上安全标签 3. SELinux 相关命令3.1 SELinux 启用状态管理getenforcegetenforce 作用: 获取当前 SELinux 状态 12[root@hp ~]# getenforcePermissive 显示: disabled: 禁用 permissive: 警告，仅记录日志 enforcing: 强制 setenforcesetenforce value 作用: 启用SELinux value: 0: 设置为 permissive 1: 设置为 enforcing 效力: 当前有效，开机后无效 附注: 永久有效，需修改配置文件。 需要特别注意的是使用 setenfoce 命令的前提是 SELinux 状态不能为 disabled。如果 SELinux 为 disabled 只能修改配置文件然后重启。 12vim /etc/selinux/config # 或 /etc/sysconfig/selinuxSELINUX=&#123;disabled|enforcing|permissive&#125; 2.3 SELinux type 标签管理ls -Z /path/to/somefile 作用: 查看文件标签 ps auxZ 作用: 查看进程标签 chconchcon OPTIIONS file 作用: change context 修改文件安全标签 OPTIONS -t TYPE: 设置文件 type -R: 递归修改 --reference=file: 参考某文件的标签进行设置 12345678910[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa[root@hp tmp]# chcon -t admin_home_t aa[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 aa[root@hp tmp]# chcon aa --reference bb[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa restoreconrestorecon -R file 作用: 还原默认标签 -R: 递归修改 2.4 SELinux的布尔规则设置getseboolgetsebool [-a] [boolean_name] 作用: 显示 SELinux 布尔型规则 参数: boolean_name 规则名称 选项: -a 显示所有布尔型规则 123456789101112[root@hp ~]# getsebool -a|grep httpdhttpd_anon_write --&gt; offhttpd_builtin_scripting --&gt; onhttpd_can_check_spam --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_can_connect_ldap --&gt; offhttpd_can_connect_mythtv --&gt; offhttpd_can_connect_zabbix --&gt; offhttpd_can_network_connect --&gt; offhttpd_can_network_connect_cobbler --&gt; offhttpd_can_network_connect_db --&gt; offhttpd_can_network_memcache --&gt; off setseboolsetsebool [ -PNV ] boolean value | bool1=val1 bool2=val2 ... 作用: 设置布尔规则 VARIABLE: ={0|off|false}: 关闭功能 ={1|on|true}: 开启功能 选项: P: 将修改写入配置文件中，否则仅仅当前设置有效 123456[root@hp tmp]# getsebool httpd_use_nfshttpd_use_nfs --&gt; off[root@hp tmp]# setsebool httpd_use_nfs 1[root@hp tmp]# getsebool httpd_use_nfshttpd_use_nfs --&gt; on]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.4 通过 ks 自动安装系统]]></title>
    <url>%2F2018%2F08%2F10%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2F%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[通过 ks 自动安装系统 1. 通过 ks 利用光盘的仓库安装操作系统1.1 配置 http 服务器 在 192.168.1.110 配置一个 http 服务器，让局域网内的所有机器都能访问到(http://192.168.1.110/anaconda-ks.cfg) 1.2 修改 kickstart 文件ksvalidator anaconda-ks.cfg: 检查 ks 语法错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&apos;cn&apos;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activatenetwork --hostname=www.tao.com# Root passwordrootpw --iscrypted $6$LZCrSYmUUKgH0NFI$T49uuvCjfCfl/7f87EZUHFBcqIRWjkhGeNuyHhGn/xUzv1o2sHefEH3AwHoMV7eVWY5rg2BarnuzlUkOCLgbL0# System servicesservices --disabled=&quot;chronyd&quot;# System timezonetimezone Asia/Shanghai --isUtc --nontpuser --name=tao --password=$6$wpzzJIpol5z5KHw0$bsn4zRMv1hkBwg2HV8dqeE895i4YdgJU.J6q222HSec/sUBBPZflcdipfn9Z3U96mzlS48gZ5vFBAOG/WjV561 --iscrypted --gecos=&quot;tao&quot;# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda# Partition clearing informationclearpart --initlabel --list=nvme0n1p11,nvme0n1p10,nvme0n1p8# Disk partitioning informationpart /boot/efi --fstype=&quot;efi&quot; --ondisk=nvme0n1 --size=1028 --fsoptions=&quot;umask=0077,shortname=winnt&quot;part pv.1133 --fstype=&quot;lvmpv&quot; --ondisk=nvme0n1 --size=153604part /boot --fstype=&quot;xfs&quot; --ondisk=nvme0n1 --size=1021volgroup cl --pesize=4096 pv.1133logvol /home --fstype=&quot;xfs&quot; --size=25600 --name=home --vgname=cllogvol /var --fstype=&quot;xfs&quot; --size=46080 --name=var --vgname=cllogvol swap --fstype=&quot;swap&quot; --size=2048 --name=swap --vgname=cllogvol / --fstype=&quot;xfs&quot; --size=25600 --name=root --vgname=cllogvol /usr --fstype=&quot;xfs&quot; --size=51200 --name=usr --vgname=cl%packages@^developer-workstation-environment@base@core@debugging@desktop-debugging@development@dial-up@directory-client@fonts@gnome-apps@gnome-desktop@guest-desktop-agents@input-methods@internet-applications@internet-browser@java-platform@multimedia@network-file-system-client@performance@perl-runtime@print-client@ruby-runtime@virtualization-client@virtualization-hypervisor@virtualization-tools@web-server@x11kexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 1.3 创建虚拟机并启动安装进入安装的 boot 界面输入1boot linux text ip=192.168.1.115 netmask=255.255.255.0 ks=http:/192.168.1.110/ks.cfg 2. 通过自制光盘自动安装操作系统2.1 创建 kickstart 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&apos;cn&apos;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=enp0s3 --onboot=off --ipv6=auto --no-activatenetwork --hostname=virtual.tao# Root passwordrootpw --iscrypted $6$oSLEiL/Vx1k1thR7$5oER8NwNYgfdZcegPA6bBLyvMREZ5Pa6gEuikfDR.B09Mv7kWyJAaXAOoIbfBCZXDj91a5rBealE3S17i71.f1# System servicesservices --enabled=&quot;chronyd&quot;# System timezonetimezone Asia/Shanghai --isUtcuser --groups=wheel --name=tao --password=$6$U7NwGZhelPqRaCP5$3VO3wcfzClT/nGXqoQobVN7.jlIfSTHDgUApHjAcwDhxROWK5/s3zZE0zUIaIhZse1OES30roxS1yxEQyydUv. --iscrypted --gecos=&quot;tao&quot;# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda# Partition clearing informationclearpart --none --initlabel# Disk partitioning informationpart pv.157 --fstype=&quot;lvmpv&quot; --ondisk=sda --size=31747part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024volgroup centos --pesize=4096 pv.157logvol / --fstype=&quot;xfs&quot; --size=10240 --name=root --vgname=centoslogvol /var --fstype=&quot;xfs&quot; --size=10240 --name=var --vgname=centoslogvol /home --fstype=&quot;xfs&quot; --size=10240 --name=home --vgname=centoslogvol swap --fstype=&quot;swap&quot; --size=1020 --name=swap --vgname=centos%packages@^gnome-desktop-environment@base@core@desktop-debugging@development@dial-up@directory-client@fonts@gnome-desktop@guest-agents@guest-desktop-agents@input-methods@internet-browser@java-platform@multimedia@network-file-system-client@networkmanager-submodules@print-client@x11chronykexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 2.2 创建磁盘映像文件123456789101112131415161718cd /var/isomkdir cdrommount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/cp -ra cdrom/ mybootvim myboot/ks.cfg # 复制上述的 kickstart 文件# 添加安装菜单vim isolinux/isolinux.cfglabel ks menu label ^Install tao linux kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfg# 创建光盘镜像genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V "CentOS 7 x86_64" -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/# -V "CentOS 7 x86_64" 必需与 hd:LABEL=CentOS\x207\x20x86_64 保持一致 3. 通过自制光盘使用网络仓库安装操作系统3.1 制作镜像文件12345678910111213141516171819cd /var/isomount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/cp -ra cdrom/isolinux/ myiso/vim isolinux/isolinux.cfg # 添加开机菜单label ks menu label Ks Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfgcd myisocp /root/anaconda-ks.cfg ks.cfgvim ks.cfg # Use CDROM installation media 更改为 # cdrom url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/genisoimage -o Net.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V &quot;CentOS 7 x86_64&quot; -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myiso 3.2 修改 kickstart 文件ks 文件与上面的配置类似，但是需要使用 url 命令指定外部仓库的位置，将12345# Use CDROM installation media 更改为cdrom# 更改为url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/ 3.3 创建虚拟机并启动安装创建虚拟机后，选择配置的菜单，启动自动安装过程]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.3 Centos 安装程序 anaconda 配置]]></title>
    <url>%2F2018%2F08%2F09%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2Fanaconda%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Centos 安装程序 anaconda 配置 上一节我们讲解了 Centos 的安装启动过程，下面我们来说一下，anaconda 启动后会进行哪些操作，以及如何配置 anaconda。 1. anaconda的工作过程anaconda 在进行操作系统安装时会经由如下几个步骤: 安装前配置阶段，包括设置如下参数 安装过程使用的语言； 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 Special Storage： iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置； 创建一个普通用户； 选定要安装的程序包； 安装阶段 在目标磁盘创建分区并执行格式化； 将选定的程序包安装至目标位置； 安装bootloader； 首次启动 iptables selinux core dump 2. anaconda的配置方式安装前配置阶段，有两种配置方式 交互式配置方式；利用 anaconda 提供的安装界面，逐项进行选择配置 通过读取配置文件中，事先定义好的配置项，自动完成配置；此文件即为kickstart文件；交互式配置安装完成后，在 root 目录下会生成此次安装的 kickstart 文件 /root/anaconda-ks.cfg kickstart 文件有特定的语法格式 可以直接手动编辑，或依据模板修改 也可以使用创建工具 system-config-kickstart，此命令会提供给我们一个交互界面，类似模拟 anaconda 的安装界面。我们可以打开 root 目录下生成的 kickstart 文件作为模板来生成我们的kickstart 文件。system-config-kickstart 安装与使用界面如所示 12345yum install system-config-kickstartsystem-config-kickstart# ksvalidator 命令可用于检查 ks 文件是否有语法错误ksvalidator /root/kickstart.cfg 3. kickstart 文件格式大体上，kickstart 文件由三个部分组成123456789101112131415161718# 1. 命令段#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical......# 2. 程序包段%packages # 开始标记@group_name # 要安装的包组package # 要安装的单个包-package # 不要安装的单个程序包%end # 结束标记# 3. 脚本段 命令段：指定各种安装前配置选项，如键盘类型等；有一些是必备命令，有一些则是可选命令 程序包段：指明要安装程序包，以及包组，也包括不安装的程序包； 脚本段： %pre：安装前脚本，运行环境：运行安装介质上的微型Linux系统环境； %post：安装后脚本，运行环境：安装完成的系统； 3.1 命令段kickstart 可用命令很多，想深入了解，可以参考官方文档：《Installation Guide》。下面是我安装 Centos7 之后生成的 ks 文件。我们只会介绍最常用的命令的。 123456789101112131415161718192021222324252627282930313233#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts='cn'# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activatenetwork --hostname=localhost.localdomain# Root passwordrootpw --iscrypted $6$ji4or39qLiMVBwAi$E9N78iOYlZw9zzD3g3CGgVvb7MSUgLbsjq9WiwIu6qSGV.y8Sbmx8WtvrWyAPnKkHhdxJKhUAZqXl2zrzjp3t0# System servicesservices --enabled="chronyd"# System timezonetimezone Asia/Shanghai --isUtcuser --groups=wheel --name=tao --password=$6$u/SLeiTrWJUgp.8E$fGCp/IAm01lyGVBkcYMTrutmAFDjdEblCorhX5Kv.cgCZvVpn8PB4LoQ/6.Qn1Tlvq0YqwhzivNqqCSeGpgc5/ --iscrypted --gecos="tao"# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=" crashkernel=auto" --location=mbr --boot-drive=sdaautopart --type=lvm# Partition clearing informationclearpart --none --initlabel 必备命令 authconfig --enableshadow --passalgo=sha512:认证方式配置 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; 作用: 定义bootloader的安装位置及相关配置 --append: 添加到内核的参数 keyboard us: 设置键盘类型 lang zh_CN.UTF-8: 语言类型 part: 创建磁盘分区 clearpart --none --drives=sda：清空磁盘分区 part /boot --fstype=ext4 --size=500: 定义基本磁盘分区 part pv.008002 --size=51200: 创建逻辑卷的物理卷，008002 为物理卷的标识 volgroup myvg --pesize=4096 pv.008002: 创建逻辑卷组 logvol /home --fstype=ext4 --name=lv_home --vgname=myvg --size=5120: 创建逻辑卷 rootpw --iscrypted passwd: 管理员密码 timezone Asia/Shanghai: 时区 12# 生成加密密码的方式(root 密码)openssl passwd -1 -salt `openssl rand -hex 4` 可选命令 install|upgrade：安装或升级； text|graphical：安装界面类型，text为tui，默认为GUI network --onboot yes --device eth0 --bootproto dhcp --noipv6 作用: 配置网络接口 --onboot yes: ifcfg 中的 ON_BOOT 参数，其他参数类似 firewall: 防火墙设置 firewall --disabled: 关闭防火墙 firewall --service ssh: 启动防火墙，放行 ssh 服务 selinux --disabled: 关闭 selinux halt|poweroff|reboot：安装完成之后的行为； repo --name=&quot;CentOS&quot; --baseurl=cdrom:sr0 --cost=100 作用: 指明安装时使用的repository； url --url=http://172.16.0.1/cobbler/ks_mirror/CentOS-6.7-x86_64/ 作用: 指明安装时使用的repository，但为url格式； url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.2 Centos安装过程]]></title>
    <url>%2F2018%2F08%2F08%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2FCentos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos安装过程 本节我们来讲解 Centos 系统的安装过程。 1. 安装程序：anaconda前面我们说过操作系统的层次，如下图所示，因为直接面向硬件编程是一件非常困难的是，所以才有了操作系统。如果有安装过 Centos 系统就会知道，安装过程有一个操作界面供我们进行选择安装，显然这是一个应用程序，那么这个应用程序是直接在硬件之上编写的么？我们说过在硬件之上编写应用程序是极其困难的，且不易移植，所以我们的安装程序也是构建在内核之上，只不过这个内核不是来自我们的计算机，而是我们的安装光盘或U盘上。Centos 的安装程序就是 annaconda。123456789--------------| 库调用接口 |---------------| 系统调用接口 |-------------------------------| 操 作 系 统 |-------------------------------| 底 层 硬 件 |------------------------------- 2. 安装光盘的结构12345678910111213141516mount -r /dev/cdrom /media/cdromcd /media/cdromtree -L 1.├── CentOS_BuildTag├── EFI├── EULA├── GPL├── images├── isolinux # 内核所在目录├── LiveOS├── Packages├── repodata├── RPM-GPG-KEY-CentOS-7├── RPM-GPG-KEY-CentOS-Testing-7└── TRANS.TBL 我们安装光盘的目录结构如上所示，isolinux 就是光盘上操作系统内核所在的目录，其余部分是程序包仓库。 操作系统安装时 首先加载操作系统内核； 光盘安装就是加载位于 isolinux 中的内核 除了光盘，内核还可以来自 U 盘，网络等其他引导设备 通过 PXE 可以实现通过网络自动安装操作系统，这个我们会在后面详述配置过程。 启动 anaconda，进而根据用户选择，安装操作系统 anacona及其安装用到的程序包等来自于程序包仓库，此仓库的位置可以为 本地光盘，光盘中 isolinx 之外的就是目录就是程序包仓库 本地硬盘 ftp server http server nfs server anaconda 提供的安装界面分为: tui：基于cureses的文本配置窗口 gui：图形界面 3. CentOS的安装过程启动流程当前我们就以光盘安装来讲解 Centos 的安装过程1234567891011121314cd /media/cdrom/isolinuxtree -L 1.├── boot.cat # MBR 中的 bootLoader├── boot.msg├── grub.conf├── initrd.img├── isolinux.bin # 提供安装界面├── isolinux.cfg # 配置文件，包含开机菜单├── memtest├── splash.png├── TRANS.TBL├── vesamenu.c32└── vmlinuz 加载并启动 BootLoader Stage1: 执行 isolinux/boot.cat，光盘的 MBR 包含的就是此文件 Stage2: 执行 isolinux/isolinux.bin 提供安装界面和开机启动菜单 BootLoader 引导和加载内核，并装载根文件系统 内核: isolinux/vmlinuz 根文件系统: isolinux/initrd.img 启动anaconda 默认界面是图形界面：512MB+内存空间； 若需要显式指定启动TUI接口： 向启动内核传递一个参数”text”即可； 如果想手动指定安装仓库，也可以通过向内核传递参数更改 3.1 isolinux.binisolinux.bin 其配置文件位于 isolinux/isolinux.cfg，配置文件中包含了开机启动菜单 1234567891011121314151617vim /media/cdrom/isolinux/isolinux.cfg....label linux # 菜单标识 menu label ^Install CentOS 7 # 菜单名称 kernel vmlinuz # 指定内核 # 内核参数，通过 boot 命令行添加的参数会添加在此行后 append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quietlabel rescue menu indent count 5 menu label ^Rescue a CentOS system text help If the system will not boot, this lets you access files and edit config files to try to get it booting again. endtext kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rescue quiet 3.2 向内核传递参数安装启动时，我们可以通过向内核传递参数，来更改 anacoda 的启动方式，那么如何向内核参数传递参数呢？ 首先进入安装界面，这个安装界面就是 isolinux/isolinux.bin 提供的，上面的选项就是 isolinux/isolinux.cfg 配置文件的内容 然后按 ESC 即进入 boot 命令行界面，输入菜单标识 参数即可以向对应菜单的内核传递参数。传递的参数将附加在, isolinux.cfg 对应菜单的 append 行后面。例如通过 boot 界面控制 anaconda 的启动方式: linux text: 指定 anaconda 以tui 方式启动 linux method: 手动指定程序包源 说明: 此处 linux 表示 isolinux.cfg 中的一个菜单标识 也可以在特定的菜单名称上按 TAB 键，就可以编辑特定菜单的参数 3.3 boot 界面的安装引导选项boot 界面有如下选项可供使用: text：文本安装方式 method：手动指定使用的安装方法 与网络相关的引导选项： ip=IPADDR netmask=MASK gateway=GW dns=DNS_SERVER_IP ifname=NAME:MAC_ADDR – 指定上述设置应用在哪个网卡上 远程访问功能相关的引导选项： vnc vncpassword=&#39;PASSWORD&#39; 启动紧急救援模式： rescue 装载额外驱动： dd 指定 kickstart 文件的位置 ks= DVD drive: ks=cdrom:/PATH/TO/KICKSTART_FILE Hard Drive： ks=hd:/DEVICE/PATH/TO/KICKSTART_FILE HTTP Server： ks=http://HOST[:PORT]/PATH/TO/KICKSTART_FILE FTP Server: ks=ftp://HOST[:PORT]/PATH/TO/KICKSTART_FILE HTTPS Server: ks=https://HOST[:PORT]/PATH/TO/KICKSTART_FILE 安装选项文档: www.redhat.com/docs , 《installation guide》 4. 创建引导光盘我们可以创建自己的镜像文件，在镜像文件内创建好 kickstart 文件，并在菜单中配置好 ks 的位置，这样就可以直接进行安装。下面是配置过程1234567891011121314&gt; mkdir /tmp/myiso/isolinux&gt; cp /media/cdrom/isolinux/* /tmp/myiso/isolinux&gt; cp /root/kickstart.cfg /tmp/myiso/isoLinux# centos6&gt; mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V &quot;CentOS 6 x86_64 boot&quot; -c isolinux/boot.cat -b isolinux/isolinux.bin -o /root/boot.iso myiso/# Centos7&gt; sudo genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V &quot;CentOS 7 x86_64&quot; -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/## 配置 isolinux/isolinux.cfg 添加安装项，直接配置 ks 参数label ks menu label ^Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfg mkisofs使用 mkisofs 创建磁盘镜像文件时，有以下几个特别注意的点需要注意: -V 参数指定的标签必需与 isolinux/isolinux.cfg 中的 hd:LABEL=的值相同，否则开机启动时将找不到磁盘镜像文件 如果要在 efi 启动，需要添加如下参数： -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot 不能在 Centos6 的系统上制作 Centos7 因为两者系统的 genisoimage 命令的版本不一样， 6 的系统制作出来的 iso 不能在 efi 环境启动； 详细可参考这边博客 https://www.linuxidc.com/Linux/2015-03/114509.htm]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.1 Linux内核模块功能定制]]></title>
    <url>%2F2018%2F08%2F07%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2FLinux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Linux内核模块功能定制 上一章我们详细讲解了 Linux 启动流程，再此基础上，本章我们来讲解内核的编译和安装。本章内容如下: 编译内核以定制内核功能 Centos 操作系统的安装过程 Centos 安装程序 anaconda 配置 内核编译是一个大工程，需要对硬件，内核各个参数功能都有比较深入了解，才能编译出有特定功能需求的内核。本节主要是带大家了解内核的编译过程，能编译成功即可。本节内容如下: 编译内核的环境准备 根据当前操作系统的编译模板，编译内核 1. 编译内核在编译内核之前，我们需要了解目标主机的功能需求，并准备好开发环境，具体可包括如下几个方面: 准备好开发环境； 获取目标主机上硬件设备的相关信息； 获取到目标主机系统功能的相关信息，例如要启用的文件系统； 获取内核源代码包：http://www.kernel.org 1.1 准备开发环境开发环境主要是准备编译环境，Centos6-7 中安装如下两个包组即可: Development Tools: 中文下叫”开发工具” Server Platform Development: 中文下叫 “服务器平台开发” - Centos7 可能没有此包组 1.2 获取目标主机上硬件设备的相关信息Linux 中有如下命令，可以帮助我们获取硬件设备的相关信息包括: CPU： cat /proc/cpuinfo lscpu x86info -a PCI设备： lspci [-v|-vv] lsusb [-v|-vv]: 显示 usb 信息 lsblk: 显示块设备信息 了解全部硬件设备信息：hal-device(Centos6) 2. 内核编译过程：内核的编译与程序包的编译安装过程类似，遵循./configure ==&gt; make ==&gt; make install。接下来我们将利用现有操作系统的编译安装模板，来编译一个内核。 2.1 简单依据模板文件的制作过程：1234567891011121314151617181920212223#！/bin/bash# 1. 编译内核tar xf linux-3.10.67.tar.xz -C /usr/srccd /usr/srcln -sv linux-3.10.67 linuxcd linux# cp /boot/config-$(uname -r) .config # 复制当前系统的编译模板进行参考make menuconfig # 配置内核选项make [-j \#] # 编译内核，可使用-j指定编译线程数量make modules_install # 安装内核模块make install # 安装内核# make install 会自动完成以下步骤# 2. 安装 bzImage 为 /boot/vmlinuxz-VERSION-RELEASEll arch/x86/boot/bzImagell arch/x86_64/boot/bzImage# 3. 生成 initramfs 文件# 4. 编辑 grub 的配置文件# 5. 重启系统，选择使用新内核 2.2 screen命令：执行 make 命令时，如果是远程连接到服务器，可能因为网络问题而断开连接，此时 make 就会终止。为了避免因为断开连接导致编译过程前功尽弃，可以使用 screen 命令 screen 作用: 终端模拟器，允许在一个终端上打开多个屏幕 特性: screen 的模拟终端不会因为当前物理终端断开连接而丢失，即 screen 内运行的程序不会因为物理终端断开连接而终止 选项: 打开screen： screen 拆除screen： Ctrl+a, d 列出screen： screen -ls 连接至screen：screen -r SCREEN_ID 关闭screen: exit 2.3 编译过程的详细说明： 配置内核选项 支持“更新”模式进行配置：在已有的.config文件的基础之上进行“修改”配置； make config：基于命令行以遍历的方式去配置内核中可配置的每个选项； make menuconfig：基于cureses的文本配置窗口；需要额外安装 ncurses-devel 包 make gconfig：基于GTK开发环境的窗口界面； 包组“桌面平台开发” make xonfig：基于QT开发环境的窗口界面； 支持“全新配置”模式进行配置： make defconfig：基于内核为目标平台提供的“默认”配置为模板进行配置； make allnoconfig：所有选项均为“no”； 编译 多线程编译：make [-j #] 编译内核中的一部分代码： 只编译某子目录中的相关代码： cd /usr/src/linux make path/to/dir/ – 只能在内核源码目录内，基于相对路径编译 只编译一个特定的模块 cd /usr/src/linux make path/to/dir/file.ko 如何交叉编译： 目标平台与当前编译操作所在的平台不同； make ARCH=arch_name 要获取特定目标平台的使用帮助： make ARCH=arch_name help 如何在执行过编译操作的内核源码树上做重新编译： 事先清理操作： make clean：清理编译生成的绝大多数文件，但会保留config，及编译外部模块所需要的文件； make mrproper：清理编译生成的所有文件，包括配置生成的config文件及某些备份文件； make distclean：相当于mrproper，额外清理各种patches以及编辑器备份文件；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.6 Linux内核功能及模块应用]]></title>
    <url>%2F2018%2F08%2F06%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FLinux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux内核功能及模块应用 之前的章节中，我们讲解了 Linux 系统的启动流程，grub，以及 系统启动之后的 init 程序，最后我们来讲解 Linux 内核相关内容，包括 Linux 内核的组成，包括 内核，内核模块，ramdisk 内核模块的管理 ramdisk 文件的制作 内核参数的修改 1. Linux 内核设计体系1.1 内核的组成部分：Linux 是单内核设计，但引入了模块化机制，其组成包括如下几个部分 kernel：内核核心，一般为bzImage，通常位于/boot目录，名称为vmlinuz-VERSION-release； kernel object： 内核对象，即内核模块，一般放置于/lib/modules/VERSION-release/ 内核模块与内核核心版本一定要严格匹配； ramdisk：辅助性文件，并非必须，这取决于内核是否能直接驱动rootfs所在的设备。ramdisk 是一个简装版的根文件系统，可能包括 目标设备驱动，例如SCSI设备的驱动； 逻辑设备驱动，例如LVM设备的驱动； 文件系统，例如xfs文件系统； 1.2 内核信息获取uname命令：uname [OPTION]... 作用: print system information 选项： -a: 显示所有内核信息 -r：内核的release号 -n：主机名，节点名称 2. 模块信息获取和管理2.1 模块信息获取模块信息获取有 lsmod, moinfo 两个命令，它们的用法如下 lsmodlsmod： 作用: 显示内核已经装载的模块 来源: 显示的内容来自于 /proc/modules 文件 modinfomodinfo [-F field] [-k kernel] [modulename|filename...]： 作用: 查看单个模块的详细信息 选项: -F field： 仅显示指定字段的信息； -n：显示模块文件路径； -p：显示模块参数 12&gt; modinfo -F filename btrfs&gt; modinfo -n btrfs depmoddepmod 作用: 内核模块依赖关系文件及系统信息映射文件的生成工具； 2.2 模块管理模块装卸载有两组命令，一组是 modprobe 可以自动解决模块的依赖关系，另一组是 insmod,rmmod 不能自动解决模块的依赖关系，它们的用法如下 modprobemodprobe [ -C config-file] [-r] module_name [module params]： 作用: 装载和卸载模块，会自动解决模块之间的依赖关系 选项: 默认: 动态装载模块 modprobe module_name -r: 动态卸载 modprobe -r module_name -C: 指定模块装载时的配置文件，默认为 /etc/modprobe.conf /etc/modprobe.d/\*.conf insmodinsmod [filename] [module options...]： 作用: 模块的装载的另一命令，不会自动解决模块之间的依赖关系，不常用 filename：模块文件的文件路径； eg: insmod $(modinfo -n xfs) rmmodrmmod [module_name]： 作用: 模块卸载的另一命令 module_name: 模块名称，不需要模块的路径 3. ramdisk文件的制作：ramdisk 的制作有两个命令，Centos5 使用的 mkinitrd，Centos6-7 使用了 dracut，但是同时也提供了 mkinitrd, 其是基于 dracut 的脚本文件，它们的使用说明如下 mkinitrdmkinitrd [OPTION...] [&lt;initrd-image&gt;] &lt;kernel-version&gt; 作用: 为当前使用中的内核重新制作ramdisk文件： 选项: --with=&lt;module&gt;：除了默认的模块之外需要装载至initramfs中的模块； --preload=&lt;module&gt;：initramfs所提供的模块需要预先装载的模块； eg： mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) dracut命令dracut [OPTION...] [&lt;image&gt; [&lt;kernel version&gt;]] 作用: low-level tool for generating an initramfs image eg： dracut /boot/initramfs-$(uname -r).img $(uname -r) 解开 ramdisk 文件12345&gt; mv initramfs-3.10.0-514.el7.x86_64.img initramfs-3.10.0-514.el7.x86_64.img.gz&gt; gzip -d initramfs-3.10.0-514.el7.x86_64.img.gz&gt; mkdir initrd&gt; cd initrd&gt; cpio -id &lt; ../initramfs-3.10.0-514.el7.x86_64.img 4. 系统参数查看和修改Linux 系统的所有参数通过 /proc，/sys 两个伪文件系统输出给用户查看和修改。 4.1 /proc 目录/proc 的作用如下: 作用: 内核把自己内核状态和统计信息，以及可配置参数通过 /proc 伪文件系统加以输出： /proc：内核状态和统计信息的输出接口； /proc/sys: 内核参数的配置接口 ； 内核参数分为 只读：信息输出；例如/proc/#/* 可写：可接受用户指定一个“新值”来实现对内核某功能或特性的配置；/proc/sys/ 4.1 /proc/sys 管理工具Linux 可修改的系统参数都放置在 /proc/sys 目录下，有三种修改方式 通过 sysctl 命令，这是专用修改内核参数的命令 由于 /proc 是伪文件系统，因此可以通过 cat，echo 等文件系统命令利用IO重定向进行修改，需要注意的是不能使用文本编辑器进行修改 上述两种方式只临时有效，要想永久有效，需要修改配置文件 1234# 修改示例&gt; ls /proc/sys/kernel/hostname -l&gt; sysctl -w kernal.hostname=&apos;localhost&apos;&gt; echo &quot;localhost&quot; &gt; /proc/sys/kernel/hostname sysctl命令sysctl [options] [variable[=value]] 作用: 专用于查看或设定/proc/sys目录下参数的值； 查看： sysctl -a: 查看所有参数 sysctl parameter: 查看特定参数 修改：sysctl -w parameter=value 附注：sysctl 的内核参数是相对于 /proc/sys 目录下文件的相对路径而言的，比如 /proc/sys/net/ipv4/ip_forward 相当于 net.ipv4.ip_forward 1234# /proc/sys/net/ipv4/ip_forward# parameter = net.ipv4.ip_forward&gt; sysctl -w net.ipv4.ip_forward=1&gt; echo 1 &gt; /proc/sys/net/ipv4/ip_forward 文件系统命令（cat, echo) 查看： cat /proc/sys/PATH/TO/SOME_KERNEL_FILE 设定： echo &quot;VALUE&quot; &gt; /proc/sys/PATH/TO/SOME_KERNEL_FILE 修改配置文件 默认配置文件: /etc/sysctl.conf /etc/sysctl.d/\*.conf 配置文件立即生效：sysctl -p [/PATH/TO/CONFIG_FILE] 4.2 常用内核参数： net.ipv4.ip_forward：路由核心转发功能； vm.drop_caches：设置值为 1，将回收buffer，cache 的缓存 kernel.hostname：主机名； net.ipv4.icmp_echo_ignore_all：忽略所有ping操作； 5. /sys目录：/sys 目录目前主要的作用是 输出内核识别出的各硬件设备的相关属性信息， 也有内核对硬件特性的可设置参数；对此些参数的修改，即可定制硬件设备工作特性； udev 命令系统上所有的设备文件，都是由 udev 命令生成，这个命令的特点如下: udev 通过读取 /sys 目录下的硬件设备信息按需为各硬件设备创建设备文件； udev是用户空间程序；专用工具：devadmin, hotplug； udev为设备创建设备文件时，会读取其事先定义好的规则文件，一般在/etc/udev/rules.d/目录下，以及/usr/lib/udev/rules.d/目录下； 1234567891011# 1. 修改 vmware 网卡的名称&gt; vim /usr/lib/udev/rules.d/70-persistent-net.rules# 修改特定 mac 地址网卡的名称# 2. 如果网卡有特定的配置信息，需要为网卡重新生成对应名称的配置文件&gt; cd /etc/sysconfig/net-work-script# 卸载网卡并重新装载网卡，让配置生效&gt; modprobe -r e1000&gt; modprobe e1000]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.5 grub2 系统配置与使用]]></title>
    <url>%2F2018%2F08%2F05%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2Fgrub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[grub2 系统配置与使用 上一节我们介绍了 grub 第一版的配置和使用，接下来我们学习 grub2。内容介绍同上一节相同，如下: grub2 概述 认识 grub2 的菜单 grub2 的启动流程 grub2 命令行的使用 grub2 的配置文件 安装 grub2 开机过程中常见问题解决 1. grub2 概述grub2 支持 efi，比 grub 更加复杂，本人对此并不是很懂。关于 grub2 的详细描述可以参考这篇博文Grub 2：拯救你的 bootloader 1.1 认识 grub2 菜单正常开机启动后，我们就会看到一个类似上图的grub2 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。 1.2 设备表示grub2 设备的表示方式与 grub 并不相同 grub2 中设备从 0 开始编号，而分区则是从 1 开始编号 MBR 和 GPT 两种分区格式表示并不相同 (hd0,1)： 一般的默认语法，由 grub2 自动判断分区格式 (hd0,msdos1)： 磁盘分区为传统的 MBR 模式 (hd0,gpt1)：磁盘分区为 GPT 模式 2. grub2 命令行的使用下面是在 grub2 命令行中直接启动操作系统的示例，可以看到 grub2 更加接近我们 bash。 1234567891011grub&gt; ls # 查看当前的磁盘分区设备(hd0), (hd0, msdos1), (hd0, msdos2)grub&gt; set root=(hd0, msdos1) # 设置根设备grub&gt; ls / # 查看当前设备内的文件grub&gt; linux /vmlinux-VERSION-releaser ro root=/dev/mapper/centos-root # 设置内核和跟目录grub&gt; initrd /initramfs-VErSION-releaser # 设置 initramdiskgrub&gt; insmod gizo # 装载必要的驱动模块grub&gt; insmod xfsgrub&gt; insmod part_msdosgrub&gt; boot # 启动开机流程 3. grub2 的配置文件grub2 的配置分成了核心配置和辅助配置两个部分 核心配置文件/boot/grub2/grub.cfg，是 grub2 在开机启动过程中读取的配置文件 辅助配置文件是 grub2-mkconfig 会读取的配置文件，此命令用于生成核心配置文件。辅助配置文件包括 /etc/default/grub文件 与 /etc/grub.d/目录两个部分。 因此 grub2 参数可分成两个步骤: 修改 /etc/default/grub 与 /etc/grub.d/ 内的相关辅助配置文件 使用 grub2-mkconfig -o /boot/grub2/grub.cfg 生成新的 grub.cfg 核心配置文件 通过 grub.cfg 的结构与注释，可以直接看出 辅助配置文件的作用结果。首先我们来看 grub.cfg 的文件结构。 3.1 grub2 配置文件grub.cfg 主要包括两个部分 第一部分是环境配置段，大多是环境设置与默认值设置，对应于 /etc/default/grub 第二部分是菜单选项，/etc/grub.d/内每个配置文件生成的菜单选项，都包含在对应文件的注释中。 12345678910111213141516171819202122232425# 1. 最开始的部份，大多是环境设置与默认值设置set timeout=5set default=&quot;2&quot;### BEGIN /etc/grub.d/10_linux #### 2. /etc/grub.d/10_linux 生成的菜单项menuentry &apos;CentOS Linux (4.9.86-30.el7.x86_64) 7 (Core)&apos; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-4.9.86-30.el7.x86_64-advanced-0afffff8-52f1-4af0-90e5-958f57489518&apos; &#123; load_video set gfxpayload=keep insmod gzio insmod part_gpt insmod xfs if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d else search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d fi linuxefi /vmlinuz-4.9.86-30.el7.x86_64 root=/dev/mapper/cl-root ro crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet initrdefi /initramfs-4.9.86-30.el7.x86_64.img&#125;### END /etc/grub.d/10_linux ###### BEGIN /etc/grub.d/30_os-prober ###### END /etc/grub.d/30_os-prober ### 3.2 grub2 辅助配置文件下面我们来看各个辅助配置文件的组成 /etc/default/grub主要环境配置文件，常见的配置选项如下 12345678910111213141516171819202122232425262728293031GRUB_TIMEOUT=5# 作用: 指定默认倒数读秒的秒数，0 表示直接开机，-1 表示必需用户选择GRUB_TIMEOUT_STYLE# 作用：是否隐藏菜单项目# 选项：menu -- 默认，显示菜单# countdown -- 显示剩余秒数，不显示菜单# hidden -- 什么都不显示GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;#GRUB_DEFAULT=2# 作用： 指定要用哪一个菜单 （menuentry） 来作为默认开机项目# 可选值：包括“ saved, 数字, title 名,ID 名”等等# ID 名值的是 menuentry 后使用 --id 为选项指定的 ID# 默认值：就是以第一个开机菜单来作为默认项目GRUB_DISABLE_SUBMENU=true# 作用：是否要隐藏次菜单，通常是藏起来的好！GRUB_TERMINAL_OUTPUT=&quot;console&quot;# 作用：指定输出的画面应该使用哪一个终端机来显示# 可选值：console, serial, gfxterm, vga_text# 默认值：console 文字终端机GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet&quot;# 作用：为 menuentry 内 linux16 指定的内核追加额外的参数GRUB_DISABLE_RECOVERY=&quot;true&quot;# 作用：取消救援菜单的制作 /etc/grub.d/分段配置，每个文件实现一个特殊功能，grub2-mkconfig 会分析并执行 /etc/grub.d/* 内的文件，来创建 grub.cfg 00_header: 创建初始的显示项目，包括需要载入的模块分析、屏幕终端机的格式、倒数秒数、菜单是否需要隐藏等等，大部分在 /etc/default/grub 里面所设置的变量，大概都会在这个脚本当中被利用来重建 grub.cfg 10_linux: 根据分析 /boot 下面的文件，尝试找到正确的 linux 核心与读取这个核心需要的文件系统模块与参数,将所有在 /boot 下面的核心文件创建为一个独立的菜单选项 30_os-prober: 查看系统其他分区是否存在操作系统，如果存在制作成一个独立的菜单选项，可通过 /etc/default/grub 内的选项 GRUB_DISABLE_OS_PROBER=true 来取消此文件的执行 40_custom: 如果还有其他想要自己手动加上去的菜单项目，或者是其他的需求，那么建议在这里补充 3.3 grub2 中的帐号机制grub2 内将用户分为了两类，超级管理帐号(superusers) 和普通用户(users) 特性 superusers user 作用 设置系统管理员与相关参数还有密码等 设置一般帐号的相关参数与密码，可设置多个用户 权限 将可在 grub2 内具有所有修改的权限 使用这个密码的用户可以选择要进入某些菜单项目 附注 一旦设置了这个 superusers 的参数，则所有的指令修改将会被变成受限制的 菜单项目也要搭配相对的帐号才行 附注 只有系统管理员能够修改参数 一般用户只能选择可用的开机菜单，不能修改菜单 设置 grub 帐号的步骤以设置一个超级管理员帐号 vbird,和一个普通帐号 dmtsai 为例，相关操作如下123456789101112131415161718192021222324252627282930# 1. 先取得 vbird 与 dmtsai 的密码。&gt; grub2-mkpasswd-pbkdf2Enter password: # 输入 vibird 密码Reenter password: # 再一次输入密码PBKDF2 hash of your password is XXXXXXXXXXXXXXXXXXXXX# 2. 将密码与帐号写入到 01_users 文件内# 附注：在 /etc/grub.d/* 下面的文件是“执行脚本”,只能通过 cat 或 echo 来将帐密数据显示出来&gt; vim /etc/grub.d/01_userscat &lt;&lt; eofset superusers=&quot;vbird&quot;password_pbkdf2 vbird XXXXXXXXXXXXXXXXXXXXXpassword_pbkdf2 dmtsai XXXXXXXXXXXXXXXXXXXXXeof# 3. 给 01_users 给予执行权限&gt; chmod a+x /etc/grub.d/01_users# 4. 修改 menuentry，配置用户# --unrestricted：默认不受限制# --users &quot;帐号名称&quot;：限定特定账户使用# 无 --users 无 --unrestricted：一定要系统管理员”才能够进入与修改&gt; vim /etc/grup.d/40_custommenuentry MyLinux --users dmtsai &#123; load_video insmod gzio linux16 ...... .........&#125; 4. 安装 grub2grub2-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 12345678&gt; mkdir /mnt/boot&gt; mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区&gt; grub2-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中&gt; grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 5. 开机过程中常见问题解决5.1 忘记开机密码新版的 systemd 的管理机制中，需要 root 的密码才能以救援模式登陆 Linux，所以无法通过救援模式重新设置 root 密码。我们需要借助 rd.break 核心参数 进入开机画面，按下 e 来进入编辑模式，在 linux16 参数上添加 rd.break 参数 改完之后按下 [crtl]+x 开始开机 开机完成后屏幕会出现如下的类似画面,此时处于 RAM Disk 的环境，正真的根应该被挂载在 /sysroot 12345678910111213141516171819&gt; mount # 检查一下挂载点！一定会发现 /sysroot 才是对的/dev/mapper/centos-root on /sysroot&gt; mount -o remount,rw /sysroot # 挂载成可读写&gt; chroot /sysroot # 实际切换了根目录的所在！取回你的环境了&gt; echo &quot;your_root_new_pw&quot; | passwd --stdin root # 修改root密码&gt; touch /.autorelabel # 如果SELinux=Enforcing，必需，详细说明见下&gt; exit&gt; reboot# touch /.autorelabel 等同操作# 1. 在 rd.break 模式下，修改完 root 密码后，将SELinux 该为 Permissive&gt; vim /etc/selinux/configSELINUX=permissive# 2. 重新开机后，重至 /etc SELinux 安全文本&gt; restorecon -Rv /etc&gt; vim /etc/selinux/configSELINUX=Enforcing&gt; setenforce 1 SELinux 的说明: 在 rd.break 的 RAM Disk 环境下，系统是没有 SELinux 的,更改密码会修改 /etc/shadow， 所以的 shadow 的SELinux 安全本文的特性将会被取消，SELinux 为 Enforcing 的模式下，如果你没有让系统于开机时自动的回复 SELinux 的安全本文，你的系统将产生“无法登陆”的问题。加上 /.autorelabel 就是要让系统在开机的时候自动的使用默认的 SELinux type 重新写入 SELinux 安全本文到每个文件去 5.2 因文件系统错误而无法开机文件系统错误常见原因有两个: 通常就是 /etc/fstab的设置问题，尤其是使用者在实作 Quota/LVM/RAID 时，最容易写错参数， 又没有经过 mount -a 来测试挂载，就立刻直接重新开机 曾经不正常关机后，也可能导致文件系统不一致情况， 也有可能会出现相同的问题 开机启动时，在检查文件系统时会有提示信息，类似下图所示。通常只要输入 root 密码进入救援模式，然后重新挂载根目录即可。 上图属于第二种错误状况。图中的第二行处，fsck 告知其实是 /dev/md0 出错。系统会自动利用 fsck.ext3 去检测 /dev/md0，等到系统发现错误，并且出现“clear [Y/N]”时，输入“ y ”即可。但是需要注意的是 partition 上面的 filesystem 有过多的数据损毁时，即使 fsck/xfs_repair 完成后，可能因为伤到系统盘，导致某些关键系统文件数据的损毁，那么依旧是无法进入 Linux 此时，最好就是将系统当中的重要数据复制出来，然后重新安装，并且检验一下，是否实体硬盘有损伤的现象才好 5.3 进入紧急模式systemd.unit=emergency.target 5.4 通过光盘进入救援模式如果 grub 已经损坏，并已重启，将无法进入 grub，也就无法正常开机，此时需要借助光盘进入救援模式 进入 BIOS 调整开机启动次序 插入光盘或装机U盘，开机启动，进入如下画面 选择”Troubleshooting”, 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 12&gt; chroot /mnt/sysimage/&gt; grub-install /dev/sda]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.4 grub配置与使用]]></title>
    <url>%2F2018%2F08%2F04%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2Fgrub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[grub配置与使用 本节我们我们将学习主流的 BootLoader 程序 grub。这部分内容与开机启动项设置，忘记 root 密码，操作系统修复相关。grub 有两个版本，使用方式几乎完全不一样，本节首先介绍第一个版本，下一节介绍第二个版本。本节内容如下: grub 概述 认识 grub 的菜单 grub 的启动流程 grub 命令行的使用 grub 的配置文件 安装 grub 开机过程中常见问题解决 1. grub 概述grub: 是 GRand Unified Bootloader 的简称，目前包括如下两个版本。 grub 0.x: grub legacy，简称 grub grub 1.x: grub2 1.1 认识 grub 菜单正常开机启动后，我们就会看到一个类似上图的grub 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。上图是我虚拟机上 grub2 的界面。grub 界面类似，操作完全相同。 1.2 启动步骤grub 启动包括三个步骤: stage1: BIOS 读取并加载 mbr 中的 BootLoader stage1_5: 位于 mbr 之后的扇区，作用是让 stage1 中的 bootloader 能识别 stage2 所在的分区上的文件系统 stage2：位于/boot/grub/，stage2及内核等通常放置于一个基本磁盘分区，因为 stage1_5 能识别的文件系统有限，其实现的功用如下： 提供菜单、并提供交互式接口 加载用户选择的内核或操作系统 允许传递参数给内核 可隐藏此菜单 为菜单提供了保护机制 为编辑菜单进行认证 为启用内核或操作系统进行认证 在学习 grub 使用时，我们首先需要了解 grub 是如何识别设备的。grub 中使用 (hd#,#) 表示磁盘设备及分区(hd#,#) hd#: 表示磁盘编号，用数字表示，从0开始编号 #: 表示分区编号，用数字表示; 从0开始编号 例如 (hd0,0) 表示第一块磁盘的第一个分区。 我们知道 grub 的作用就是在没有根文件系统的前提下直接加载内核，因此 grub 的根设备与操作根设备文件系统不是同一个概念。grub 的根设备指的是包含stage2 以及内核文件所在的设备，内核文件的位置也是相对于 grub 根设备的文件系统而言的。 如果 /boot 独立分区，那么 grub 的根设备就是 /boot 所在分区，内核文件直接位于根之下，所以其路径为 /vmlinuz-VERSION 如果 /boot 是 / 下的目录，那么 grub 的根设备就是 / 所在分区，内核文件的路径为 /vmlinuz-VERSION所以 grub 的根对内核文件的路径有着直接影响。 2. grub的命令行接口下面是在 grub 命令行中直接启动操作系统的示例，grub 命令行有很多可用命令，列示如下:12345# 手动在grub命令行接口启动系统grub&gt; root (hd#,#)grub&gt; kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICE selinux=0 init=/bin/bashgrub&gt; initrd /initramfs-VERSION-RELEASE.imggrub&gt; boot help: 获取帮助列表 help COMMAND: command 详细帮助信息 root (hd#,#): 设置根设备 find (hd#,#)/PATH/TO/SOMEFILE：查找特定磁盘分区上的文件，如果使用了 root 指定了根设备可以省略 (hd#,#)，下同 kernel /PATH/TO/KERNEL_FILE: 设定本次启动时用到的内核文件；额外还可以添加许多内核支持使用的cmdline参数 initrd /PATH/TO/INITRAMFS_FILE: 设定为选定的内核提供额外文件的ramdisk boot: 引导启动选定的内核 3. 配置文件：grub 的配置文件在 /boot/grub/grub.conf, /etc/grub.conf 是其软连接。一个最简单的配置文件如下，注释中描述了每一项的含义。grub 中实现了菜单编译和选中特定菜单的两级认证功能。可以使用明文密码，但是建议使用 md5 加密后字串。grub 为我们提供了一个快捷命令 grub-md5-crypt 用于生成密码的 md5 1234567891011# grub 示例配置文件default=0 # 设定默认启动的菜单项，编号从0开始timeout=5 # 指定菜单项等待选项选择的时长splashimage=(hd0,0)/PATH/TO/XPM_PIC_FILE： # 指明菜单背景图片文件路径hiddenmenu # 隐藏菜单，不想隐藏，无须此项即可password --md5 MD5_STRING # 设置菜单编辑密码，--md5 后跟 md5 加密后的密码字符串title My Linux # 定义菜单项“标题”, 可出现多次； root (hd#,#) # grub查找stage2及kernel文件所在设备分区，为grub的“根”; kernel /PATH/TO/VMLINUZ_FILE [PARAMETERS] # 启动的内核 initrd /PATH/TO/INITRAMFS_FILE # 内核匹配的ramfs文件； password --md5 MD5_STRING #启动选定的内核或操作系统时进行认证； 12345# 使用 grub-md5-crypt 生成 md5 密码串&gt; grub-md5-cryptPassword: # 输入两次密码Password:MD5_STRING 4. 安装 grubgrub 正常情况下，不”瞎搞”，不会损坏，毕竟不会有谁没事去覆盖掉磁盘的 MBR，但是不怕一万就怕万一。安装双系统时，如果后安装的 Window，window 的 BootLoader 是没法引导 Linux，但是 grub 能引导 Window，此时我们就需要重新安装 Linux。 安装 grub 有两种方法，如下 方法一 命令行grub-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 12345678&gt; mkdir /mnt/boot&gt; mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区&gt; grub-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中&gt; grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 方法二 grub 命令行123# 前提: 设备上必须存在 grup 目录，里面的文件必须齐全grub&gt; root (hd#,#)grub&gt; setup (hd#) 5. 常见开机问题的解决5.1 进入单用户模式： 编辑grub菜单(选定要编辑的title，而后使用e命令); 在选定的 kernel 后附加 1, s, S或single都可以； 在kernel所在行，键入“b”命令； 5.2 grub 已经损坏，并已重启这种情况下已经无法进入 grub，因此需要使用光盘或装机 U 盘进入救援模式 进入 BIOS 调整开机启动次序 开机启动，进入如下画面 选择”Troubleshooting”, 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 12&gt; chroot /mnt/sysimage/&gt; grub-install /dev/sda]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.3 Centos7 Systemd 启动流程]]></title>
    <url>%2F2018%2F08%2F03%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS7-Systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos7 Systemd 启动流程 本节我们学习 Centos7 的开机启动程序 Systemd，及其服务管理工具 systemctl。我们会与 Centos6 中的 upstart 的启动程序对比来讲解。大家也可以参考阮一峰老师的博客。本节内容如下: Systemd 概述 Systemctl 命令的使用 Systemd 配置文件格式 1. Sysmted 概述：MBR 架构的系统，开机启动过程是 POST --&gt; Boot Sequeue(BIOS) --&gt; Bootloader(MBR) --&gt; Kernel(ramdisk) --&gt; rootfs --&gt; /sbin/init，而 Systemd 正是 Centos7 的/sbin/init 程序 1.2 Systemd的新特性systemd 相比于 Centos5 的 SysV init，和 Centos 的 Upstart，具有如下特性: 新特性 系统引导时实现服务并行启动； 按需激活进程； 系统状态快照； 基于依赖关系定义服务控制逻辑； 关键特性： 基于socket的激活机制：socket与程序分离； 基于bus的激活机制； 基于device的激活机制； 基于Path的激活机制； 系统快照：保存各unit的当前状态信息于持久存储设备中； 向后兼容sysv init脚本；/etc/init.d/ 不兼容： systemctl的命令是固定不变的； 非由systemd启动的服务，systemctl无法与之通信； 1.2 服务配置Sysv init 和 Upstart 中，服务的管理单元是一个个具有特定格式的 shell 脚本，由 service 命令统一进行管理。而 Systemd 中服务的核心单元叫 Unit，unit 由其相关配置文件进行标识、识别和配置，配置文件中主要包含了系统服务、监听的socket、保存的快照以及其它与init相关的信息。systemd 按照功能将 unit 分为了如下几种类型。 unit的常见类型 类型 文件扩展名 作用 Service unit .service 用于定义系统服务 Target unit .target 用于模拟实现运行级别 Device unit .device 用于定义内核识别的设备 Mount unit .mount 定义文件系统挂载点 Socket unit .socket 用于标识进程间通信用到的socket文件 Snapshot unit .snapshot 管理系统快照 Swap unit .swap 用于标识swap设备 Automount unit .automount 文件系统自动点设备 Path unit .path 用于定义文件系统中的一文件或目录 systemd 的配置文件systemd 的配置文件位于以下三个目录中 /usr/lib/systemd/system: 实际配置文件的存存放位置 /run/systemd/system：不常用 /etc/systemd/system: 基本上都是软连接 对于那些支持 Systemd 的软件，安装的时候，会自动在/usr/lib/systemd/system目录添加一个配置文件。如果你想让该软件开机启动，就执行下面的命令（以httpd.service为例）。 12345[root@hp system]# ll /etc/systemd/system/default.targetlrwxrwxrwx. 1 root root 40 3月 5 17:37 /etc/systemd/system/default.target -&gt; /usr/lib/systemd/system/graphical.target[root@hp system]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 上面的命令相当于在 /etc/systemd/system 目录添加一个符号链接，指向 /usr/lib/systemd/system 里面的httpd.service文件。这是因为开机时，Systemd只执行 /etc/systemd/system 目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。 除了使用普通的文本查看命令外查看配置文件外，systemctl cat NAME.service 可通过服务名称直接查看配置文件 123456789101112131415161718192021222324[root@hp system]$ systemctl cat httpd# /usr/lib/systemd/system/httpd.service[Unit]Description=The Apache HTTP ServerAfter=network.target remote-fs.target nss-lookup.targetDocumentation=man:httpd(8)Documentation=man:apachectl(8)[Service]Type=notifyEnvironmentFile=/etc/sysconfig/httpdExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUNDExecReload=/usr/sbin/httpd $OPTIONS -k gracefulExecStop=/bin/kill -WINCH $&#123;MAINPID&#125;# We want systemd to give httpd some time to finish gracefully, but still want# it to kill httpd after TimeoutStopSec if something went wrong during the# graceful stop. Normally, Systemd sends SIGTERM signal right after the# ExecStop, which would kill httpd. We are sending useless SIGCONT here to give# httpd time to finish.KillSignal=SIGCONTPrivateTmp=true[Install]WantedBy=multi-user.target 2. systemctl 命令使用2.1 管理系统服务 (service unit)systemctl [OPTIONS...] COMMAND [NAME...] OPTIONS: -t, --type=: 指定查看的 unit 类型 -a, --all：查看所由服务 服务启动与关闭 作用 init systemctl 启动 service NAME start systemctl start NAME.service 停止 service NAME stop systemctl stop NAME.service 重启 service NAME restart systemctl restart NAME.service 状态 service NAME status systemctl status NAME.service 条件式重启 service NAME condrestart systemctl try-restart NAME.service 重载或重启服务 systemctl reload-or-restart NAME.servcie 重载或条件式重启服务 systemctl reload-or-try-restart NAME.service 12345678910111213141516171819[root@hp system]# systemctl status httpd● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-07 09:14:30 CST; 1s ago Docs: man:httpd(8) man:apachectl(8) Main PID: 6170 (httpd) Status: &quot;Processing requests...&quot; CGroup: /system.slice/httpd.service ├─6170 /usr/sbin/httpd -DFOREGROUND ├─6174 /usr/sbin/httpd -DFOREGROUND ├─6176 /usr/sbin/httpd -DFOREGROUND ├─6177 /usr/sbin/httpd -DFOREGROUND ├─6178 /usr/sbin/httpd -DFOREGROUND ├─6180 /usr/sbin/httpd -DFOREGROUND └─6181 /usr/sbin/httpd -DFOREGROUND8月 07 09:14:28 hp.tao systemd[1]: Starting The Apache HTTP Server...8月 07 09:14:30 hp.tao systemd[1]: Started The Apache HTTP Server. 输出: Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志 服务状态查看 作用 init systemctl 查看某服务当前激活与否的状态 systemctl is-active NAME.service 查看所有已激活的服务 systemctl list-units –type service 查看所有服务（已激活及未激活) systemctl list-units -t service –all 开机自启 作用 init systemctl 设置服务开机自启 chkconfig NAME on systemctl enable NAME.service 禁止服务开机自启 chkconfig NAME off systemctl disable NAME.service 查看某服务是否能开机自启 chkconfig –list NAME systemctl is-enabled NAME.service 查看所有服务的开机自启状态 chkconfig –list systemctl list-unit-files –type service 禁止某服务设定为开机自启 systemctl mask NAME.service 取消此禁止 systemctl unmask NAME.servcie 依赖关系 作用 init systemctl 查看服务的依赖关系 systemctl list-dependencies NAME.service 2.2 管理 target units 作用 init systemctl 运行级别 0 runlevel0.target, poweroff.target 运行级别 1 runlevel1.target, rescue.target 运行级别 2 runlevel2.tartet, multi-user.target 运行级别 3 runlevel3.tartet, multi-user.target 运行级别 4 runlevel4.tartet, multi-user.target 运行级别 5 runlevel5.target, graphical.target 运行级别 6 runlevel6.target, reboot.target 级别切换 init N systemctl isolate NAME.target 查看级别 runlevel systemctl list-units –type target 查看所有级别 systemctl list-units -t target -a 获取默认运行级别 /etc/inittab systemctl get-default 修改默认运行级别 /etc/inittab systemctl set-default NAME.target 切换至紧急救援模式 systemctl rescue 切换至emergency模式 systemctl emergency 2.3 其它常用快捷命令 关机： systemctl halt, systemctl poweroff 重启： systemctl reboot 挂起： systemctl suspend 快照： systemctl hibernate 快照并挂起： systemctl hybrid-sleep 3. service unit file 配置3.1 unit file 组成unit file 通常由如下 三个部分组成: [Unit]： 定义与Unit类型无关的通用选项； 用于提供 unit 的描述信息、unit 行为及依赖关系等； [Service]： 与特定类型相关的专用选项；此处为 Service 类型； [Install]： 定义由systemctl enable以及systemctl disable命令在实现服务启用或禁用时用到的一些选项； 12345678910111213141516171819# systemctl cat sshd# /usr/lib/systemd/system/sshd.service[Unit]Description=OpenSSH server daemonDocumentation=man:sshd(8) man:sshd_config(5)After=network.target sshd-keygen.serviceWants=sshd-keygen.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/sshdExecStart=/usr/sbin/sshd -D $OPTIONSExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target Unit段 Description：当前服务的简单描述 After：定义unit的启动次序；表示当前unit应该晚于哪些unit启动；其功能与Before相反； Before：定义sshd.service应该在哪些服务之前启动 Requies：依赖到的其它units；强依赖，被依赖的units无法激活或异常退出时，当前unit即无法激活； Wants：依赖到的其它units；弱依赖，被依赖的units无法激活时，不影响当 unit 的启动； Conflicts：定义units间的冲突关系； 附注： After和Before字段只涉及启动顺序，不涉及依赖关系 Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的 Service段 Type：用于定义影响ExecStart及相关参数的功能的unit进程启动类型； simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 EnvironmentFile：指定当前服务的环境参数文件 ExecStart：指明启动unit要运行命令或脚本；其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件 ExecReload：重启服务时执行的命令 ExecStop：停止服务时执行的命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 Restart：定义了服务退出后，Systemd 的重启方式 no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 on-abnormal：只有被信号终止和超时，才会重启 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启 附注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal KillMode:定义 Systemd 如何停止服务 control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。 RestartSec：表示 Systemd 重启服务之前，需要等待的秒数 对于 sshd 服务而言将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。 所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误 Install段 Alias： RequiredBy：被哪些units所依赖； WantedBy：表示该服务所在的 Target 3.2 修改配置文件后重启对于新创建的unit文件或修改了的unit文件，要通知systemd重载此配置文件 systemctl daemon-reload 4.Target 的配置文件12345678910111213141516[root@hp system]$ systemctl cat multi-user.target# /usr/lib/systemd/system/multi-user.target# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Multi-User SystemDocumentation=man:systemd.special(7)Requires=basic.targetConflicts=rescue.service rescue.targetAfter=basic.target rescue.service rescue.targetAllowIsolate=yes Target 配置文件里面没有启动命令 Requires：要求basic.target一起运行。 Conflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。 After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。 AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.2 Centos5 init 启动流程]]></title>
    <url>%2F2018%2F08%2F02%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos5 init 启动流程 在上一节我们详细讲解了开机启动流程中内核级部分，接下来我们讲学习内核加载并完成根文件系统之后 init 程序的启动过程。因为内容过多，而且不同Centos 版本并不相同，因此我们将分成两个节，本节将讲解一下内容: CentOS5 SysV init 的启动流程 /etc/inittab 的格式和内容 Centos5 的服务启动方式 chkconfig 设置服务开机启动 /sbin/init 程序执行的操作 CentOS6 Upstart 的启动流程 1.1 CentOS 5： SysV init1.1 运行级别 运行级别：为了系统的运行或维护等目的而设定的机制； 0-6：7个级别； 0: 关机, shutdown 1: 单用户模式(single user)，root用户，无须认证；维护模式； 2: 多用户模式(multi user)，会启动网络功能，但不会启动NFS；维护模式； 3: 多用户模式(mutli user)，完全功能模式；文本界面； 4: 预留级别：目前无特别使用目的，但习惯以同3级别功能使用； 5: 多用户模式(multi user)， 完全功能模式，图形界面； 6: 重启，reboot 默认级别：3, 5 级别切换：init level 级别查看： who -r runlevel 1.2 配置文件：/etc/inittab/etc/inittab 作用: 每行定义一种 action 以及与之对应的 process 格式: id:runlevels:action:process id：一个任务的标识符； runlevels：在哪些级别启动此任务，格式如下: n: 单个数字例如 2，表示仅在第二级别 nnn: 多个数字例如 234，表示在第二三四级别 也可以为空，表示所有级别； action：在什么条件下启动此任务； process：任务； action： wait：等待切换至此任务所在的级别时执行一次； respawn：一旦此任务终止，就自动重新启动之； initdefault：设定默认运行级别；此时，process省略； sysinit：设定系统初始化方式，此处一般为指定/etc/rc.d/rc.sysinit脚本； 12345678910111213id:3:initdefault: -- 设置系统默认启动级别si::sysinit:/etc/rc.d/rc.sysinit -- 系统初始化脚本l0:0:wait:/etc/rc.d/rc 0 -- rc 脚本框架，启动对应级别下的服务l1:1:wait:/etc/rc.d/rc 1…………l6:6:wait:/etc/rc.d/rc 6tty1:2345:respawn:/usr/sbin/mingetty tty1 --- 虚拟终端启动... ...tty6:2345:respawn:/usr/sbin/mingetty tty6 # mingetty会调用login程序；# 打开虚拟终端的程序除了mingetty之外，还有诸如getty等； rc 脚本框架：1234567for srv in /etc/rc.d/rc#.d/K*; do $srv stopdonefor srv in /etc/rc.d/rc#.d/S*; do $srv startdone rc脚本：接受一个运行级别数字为参数； rc 3: 意味着去启动或关闭/etc/rc.d/rc3.d/目录下的服务脚本所控制服务； K*：要停止的服务；K##*，优先级，数字越小，越是优先关闭；依赖的服务先关闭，而后关闭被依赖的； S*：要启动的服务；S##*，优先级，数字越小，越是优先启动；被依赖的服务先启动，而依赖的服务后启动； rc#.d/ 目录下所有文件都是链接文件，连接到 /etc/rc.d/init.d/ 12&gt; ls /etc/rd.d/init.d rc rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local rc.sysinit 1.2 服务启动/etc/init.d/* (/etc/rc.d/init.d/*)脚本执行方式： /etc/init.d/SRV_SCRIPT {start|stop|restart|status} service SRV_SCRIPT {start|stop|restart|status} 1.3 配置服务开机启动chkconfig命令： 作用: 管控/etc/init.d/每个服务脚本在各级别下的启动或关闭状态； 添加：chkconfig --add name 作用: 将 name 脚本添加到service 命令的控制中，并按照脚本中 chkconfig 的配置在对应级别下设置开机启动，其他级别下设置开机关闭 启动/关闭指定级别服务： chkconfig [--level LEVELS] name on|off|reset --level LEVELS：指定要控制的级别；默认为2345； 查看：chkconfig --list [name] 删除：chkconfig --del name 作用: 将服务从 service 管理的范围内删除，并从各个级别的开机启动中删除 注意：正常级别下，最后启动的一个服务S99local 没有链接至/etc/init.d下的某脚本，而是链接至了/etc/rc.d/rc.local （/etc/rc.local）脚本；因此，不便或不需写为服务脚本的程序期望能开机自动运行时，直接放置于此脚本文件中即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445&gt; vim /etc/init.d/testsrv#!/bin/bash# testsrv serviec testing script## chkconfig: 234 50 60# description: testing service# 注解: 必须要有 chkconfig:# chkconfig: LLL NN NN -- 被添加到的级别，启动优先级，关闭优先级# chkconfig: - 50 60 -- 表示没有级别$prog=$(basename $0)if [ $# -lt 1 ]; then echo &quot;Usage: $&#123;prog&#125; &#123;start|stop|status|restart&#125;&quot; exit 1fiif [ &quot;$1&quot; == &quot;start&quot; ]; then echo &quot;start $prog success&quot;elif [ &quot;$1&quot; == &quot;stop&quot; ]; then echo &quot;stop $prog success&quot;elif [ &quot;$1&quot; == &quot;status&quot; ]; then if pidof $prog &amp;&gt; /dev/null; then echo &quot;$prog is running&quot; else echo &quot;$prog is stopped&quot; fielif [ &quot;$1&quot; == &quot;restart&quot; ]; then echo &quot;restart $prog success&quot;else echo &quot;Usage: $&#123;prog&#125; &#123;start|stop|status|restart&#125;&quot; exit 2fi&gt; chkconfig --add testsrv&gt; ls /etc/rc.d/rc3.d/ |grep testsrv&gt; chkconfig --list testsrv&gt; chkconfig --level 23 testsrv off&gt; chkconfig --del testsrv 1.5 总结（用户空间的启动流程）：/sbin/init (/etc/inittab) 设置默认运行级别 运行系统初始化脚本(/etc/rc.d/rc.sysinit)，完成系统初始化 设置主机名 设置欢迎信息 激活udev和selinux 挂载/etc/fstab文件中定义的所有文件系统 检测根文件系统，并以读写方式重新挂载根文件系统 设置系统时钟； 根据/etc/sysctl.conf文件来设置内核参数 激活lvm及软raid设备 激活swap设备 加载额外设备的驱动程序 清理操作 关闭对应级别下需要停止的服务，启动对应级别下需要开启的服务 设置登录终端 [–&gt; 启动图形终端] 2. CentOS 6：Centos 6 中init程序为 upstart，但依然为/sbin/init 配置文件包括如下: /etc/init/*.conf /etc/inittab（仅用于定义默认运行级别） 注意：*.conf为upstart风格的配置文件，需遵循其配置语法； rcS.conf rc.conf start-ttys.conf CentOS 6启动流程： POST –&gt; Boot Sequence(BIOS) –&gt; Boot Loader (MBR) –&gt; Kernel(ramdisk) –&gt; rootfs –&gt; switchroot –&gt; /sbin/init –&gt;(/etc/inittab, /etc/init/*.conf) –&gt; 设定默认运行级别 –&gt; 系统初始化脚本 –&gt; 关闭或启动对应级别下的服务 –&gt; 启动终端]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.1 CentOS系统启动流程介绍]]></title>
    <url>%2F2018%2F08%2F01%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[CentOS系统启动流程介绍 本章我们将学习 Linux 启动流程和内核模块管理相关的内容。通过本章我们将学习如下内容: Linux 系统的组成及特点 CentOS 系统的启动流程 开机启动成 grub 的配置和使用 内核功能与内核模块的加载与使用 在学习本章内容之前，需要对之前学习的操作系统知识做一个简单梳理总结，目的是了解 Linux 系统在启动时面临了哪些问题，怎么去解决这些问题。这样我们才能知道为什么启动流程是”这样”。 123456789--------------| 库调用接口 |---------------| 系统调用接口 |-------------------------------| 操 作 系 统 |-------------------------------| 底 层 硬 件 |------------------------------- 在一个已经开机的计算机上，操作系统位于底层硬件之上，通过加载硬件的驱动程序从而能够管理各种硬件设备。操作系统通过系统调用，将管理底层硬件的接口暴露给各应用程序。应用程序在需要时发起系统调用即可完成对底层硬件的驱动。系统调用接口比较简陋，不便于程序员进行编程，因此在系统调用基础上有各种库，方便程序员进行编程。 操作系统=内核+根文件系统，Linux 中一切皆文件，Linux 的所有设备都表现为根文件系统上的某个文件。因此内核必需首先要加载底层磁盘设备的驱动程序，然后加载该磁盘设备上特定的文件系统，最后挂载根文件系统。 但是在系统启动之前，操作系统和各种驱动程序都是存放在硬盘上的。这样就会出现以下问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 因此开机启动，必需要解决上述两个问题。 本节，我们开始学习 Centos 系统的启动流程，本章开篇我们了解到，开机过程中存在两个问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 本节核心就是讲解如何解决上述两个问题，并在此基础上介绍 Linux 系统的启动。本节将包括以下内容: Linux 系统特性，包括Linux 系统的功能及设计思路 Linux 开机启动流程，包括: Linux 系统组成，Linux 为开机启动准备的额外文件 Linux 系统详细启动过程 1. Linux 系统特性Linux 主要由内核+根文件系统组成，一个运行中的Linux，可以看作是运行在内核之上，由内核负责完成底层硬件管理，从而将硬件接口抽象为系统接口以后，让根文件系统工作为文件系统的一个底层虚拟机。运行中的OS可以分为内核空间和用户空间两个部分，应用程序运行在用户空间，通常表现为一个进程或线程；而内核空间主要运行内核代码，执行特权操作，通过系统调用向用户空间输出接口。用户空间通过发起系统调用执行特权操作。 Linux 需要实现的功能包括: 进程管理，进程创建，调度，销毁 内存管理，将内存抽象为虚拟的线性地址格式，为每个进程提供一份，就好像每个进程单独运行在操作系统之上一样 IPC 机制: 消息队列 semerphor 信号量 share memory 共享内存 网络协议栈 文件系统 驱动程序 《Linux 设备驱动》 安全功能 内核设计有两种流派 单内核设计：把所有功能集成于同一个程序，典型代表为 Linux 微内核设计：每种功能使用一个单独的子系统实现，典型代表为 Windows, Solaris Linux 虽然为单内核设计但是充分吸收了微内核的特点，支持模块化(.ko (kernel object))，支持模块运行时动态装载或卸载。 1. Linux 系统启动流程1.1 Linux 系统的组成首先我们来解决开机启动的第二个问题。内核加载根文件系统需要加载驱动程序，而驱动程序就在根之上。因此我们不能依赖根文件系统上的驱动程序，内核必须自带驱动程序。 一种方法是将设备的驱动程序编译进内核，对于个人用户自编译的系统没有有问题，因为只需要将其特定的驱动程序编译进内核即可，然后对于操作系统发行商而然，它面对的是各种用户的不同驱动设备，如果都将这些驱动程序编译进内核，内核将庞大无比，而每个用户又只会用到其中一个。 另一种方法是借助于中间临时根文件系统，中间临时根文件系统包含了加载根文件系统所在设备的驱动程序，而中间根文件系统放置在一个基于内存的磁盘设备中，内核无须加载其他驱动程序即可访问该设备。内核启动后，先访问基本设备挂载中间的临时根文件系统，并从中装载设备驱动程序，在真正的根文件系统准备完成之后，从临时根切换到真正的根。 用于系统初始化的基于内存的磁盘设备通常称为 ramdisk，内核在启动过程中需要将 ranmdisk 装载进内存 ，并将其识别为一个根文件系统。ramdisk 并不是发行商预先生成，而是在系统安装过程中针对当前设备临时生成了，因此其仅需包含当前设备的驱动程序即可。 因此从编译完成后的视角，Linux 系统由如下部分组成: 核心文件：/boot/vmlinuz-VERSION-release ramdisk： CentOS 5：/boot/initrd-VERSION-release.img # 基于 ram 的磁盘 CentOS 6,7：/boot/initramfs-VERSION-release.img # 基于 ram 的文件系统 模块文件： /lib/modules/VERSION-release 如果内核提供了多个版本，将会有多个内核目录 1234567891011121314151617181920212223242526272829303132333435363738394041424344&gt; uname -r # 内核版本4.9.86-30.el7.x86_64&gt; ls /boot/|grep vmvmlinuz-4.9.86-30.el7.x86_64&gt; ls /lib/modules/$(uname -r)/kernelarch crypto drivers fs lib mm net sound virt&gt; tree -L 2 /lib/modules/$(uname -r)/lib/modules/4.9.86-30.el7.x86_64├── build -&gt; ../../../usr/src/kernels/4.9.86-30.el7.x86_64├── extra├── kernel│ ├── arch│ ├── crypto│ ├── drivers│ ├── fs│ ├── lib│ ├── mm│ ├── net│ ├── sound│ └── virt├── modules.alias├── modules.alias.bin├── modules.block├── modules.builtin├── modules.builtin.bin├── modules.dep├── modules.dep.bin├── modules.devname├── modules.drm├── modules.modesetting├── modules.networking├── modules.order├── modules.softdep├── modules.symbols├── modules.symbols.bin├── source -&gt; build├── updates├── vdso│ ├── vdso32.so│ └── vdso64.so└── weak-updates 1.2 MBR 与 BootSector接下来我们来解决第一个问题，在没有根文件系统的前提下将内核加载进内存。可引导设备的第一个分区叫MBR，MBR 中包含了开机引导程序 BootLoader。开机启动时会先加载 MBR内的BootLoader，由BootLoader 将内核加载到内存。有人可能会问，开机时是如何读取到MBR的，BootLoader又是如何读取到内核文件的。BIOS 通过硬件的 INT 13 中断功能来读取 MBR，也就是说，只要 BIOS 能够侦测的到你的磁盘 （不论磁盘是 SATA 还是 SAS ），那他就有办法通过 INT 13 这条信道来读取该磁盘的第一个扇区内的 MBR 软件，这样 boot loader 也就能够被执行。boot loader 能够识别操作系统的文件格式，也就能加载核心文件。其他分区的第一个扇区叫做 boot sector，也可以安装BootLoader，这样可以实现多系统安装。 有了上述阐述，我们就可以开始讲解开机启动流程了。 1.2 Centos 系统的启动流程(MBR 架构)启动流程: POST: 加电自检。 x86 架构的计算机被设计成，只要通电就会去执行，主板上有个 ROM 芯片内的BOIS程序 通过 BIOS 程序去载入 CMOS 的信息，并且借由 CMOS 内的设置值取得主机的各项硬件参数及设置，例如硬盘的大小与类型 在获取硬件信息后，BIOS 会进行开机自我测试 (Power-on Self Test, POST) ，然后开始执行硬件侦测的初始化，并设置 PnP 设 备，之后再定义出可开机的设备顺序，接下来就会开始进行开机设备的数据读取 Boot Sequence:开机启动次序 家电自检完成后，计算机就会按次序查找各引导设备，第一个有引导程序的设备即为本次启动用到的设备。 引导程序称为 BootLoader，又称引导加载器。 如果是通过U盘安装操作系统，就需要进入 BIOS 设置系统的开机启动次序 bootloader：引导加载器，程序，位于MBR中； 功能： 提供一个菜单，允许用户选择要启动的系统或不同的内核版本； 把用户选定的内核装载到RAM中的特定空间中，解压、展开，而后把系统控制权移交给内核 Windows：ntloader Linux： LILO：LIinux LOader GRUB：Grand Uniform Bootloader GRUB 0.X：Grub Legacy GRUB 1.X：Grub2 MBR/GRUB: MBR：Master Boot Record，512bytes： 446bytes：bootloader 64bytes：fat, 磁盘分区表 2bytes：55AA GRUB：两阶段加载 bootloader：1st stage Partition：filesystem driver, 1.5 stage Partition：/boot/grub, 2nd stage Kernel: 自身初始化： 探测可识别到的所有硬件设备； 加载硬件驱动程序；（有可能会借助于ramdisk加载驱动） 以只读方式挂载根文件系统； 运行用户空间的第一个应用程序：/sbin/init 执行 init 程序： CentOS 5：SysV init 配置文件：/etc/inittab CentOS 6：Upstart init 的升级版，可以并行启动 配置文件: /etc/inittab: 为向前兼容，基本没哟使用 /etc/init/\*.conf CentOS 7：Systemd 配置文件： /usr/lib/systemd/system/ /etc/systemd/system/ ramdisk： Linux内核的特性之一：使用缓冲和缓存来加速对磁盘上的文件访问； 升级: ramdisk –&gt; ramfs 生成工具: CentOS 5: initrd – mkinitrd CentOS 6,7: initramfs – dracut, mkinitrd 1.3 总结:系统初始化流程（内核级别） POST自检， 按照BootSequence(BIOS)查找能开机启动的设备 在设备的 MBR上加载 BootLoader，BootLoader 去磁盘分区上读取内核。 Kernel可能会借助于 ramdisk 加载真正根文件系统所在设备的驱动程序 内核装载 rootfs（readonly，并执行开机启动程序 /sbin/init 需要说明的是无论是下述的 ramdisk 还是 BootLoader 都是在安装操作系统时针对当前硬件生成的。所以 BootLoader 是能够识别当前主机的硬盘设备的。但是需要注意的是BootLoader 是需要和磁盘分区打交道的，而BootLoader 本身一般是无法驱动那些软设备，逻辑设备(LVM),也无法驱动RAID这些复杂的逻辑结构，因此内核只能放在基本的磁盘分区上。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux开机启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.5 作业管理]]></title>
    <url>%2F2018%2F07%2F28%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[作业管理 所谓作业管理就是我们如何在同一终端下执行多个任务。Linux 中作业分为 前台作业(foregroud)：通过终端启动，且启动后会一直占据终端； 后台作业(backgroud)：可以通过终端启动，但启动后即转入后台运行（释放终端）； 如果我们想在同一终端执行多个任务，就必须将当前的前台作业切换为后台作业 1. 将作业运行于后台如何将作业运行于后台呢: 运行中的作业，使用 快捷键 Ctrl+z，作业被送往后台后，会转为停止状态； 尚未启动的作业 使用 COMMAND &amp;，命令后跟 &amp;，进程自动以后台作业运行 需要注意的是，上述作业虽然被送往后台，但其依然与终端相关；如果希望把送往后台的作业剥离与终端的关系使用 nohup 命令，即 nohup COMMAND &amp; 2. 作业控制命令 fg [[%]JOB_NUM]：把指定的作业调回前台； bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行； kill %JOB_NUM：终止指定的作业； jobs：查看所有的作业]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.4 系统状态查看]]></title>
    <url>%2F2018%2F07%2F27%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[系统状态查看 系统状态查看命令，可以查看系统包括磁盘，CPU，内存，缓存，进程，网络等等几乎所有的状态信息。本节我们主要介绍 vmstat,pmap, dstat 三个命令的使用。 1. vmstat命令：vmstat [options] [delay [count]] 作用: 查看虚拟内存使用状况 选项： -s：显示内存统计数据；类似于 cat /proc/meminfo 1234tao@hp:~$ vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 484884 1292 3710880 0 0 179 83 455 865 14 4 82 1 0 输出: procs： r：等待运行的进程的个数；CPU上等待运行的任务的队列长度； b：处于不可中断睡眠态的进程个数；被阻塞的任务队列的长度； memory： swpd：交换内存使用总量； free：空闲的物理内存总量； buffer：用于buffer的内存总量； cache：用于cache的内存总量； swap si：数据进入swap中的数据速率（kb/s） so：数据离开swap的速率(kb/s) io bi：从块设备读入数据到系统的速度（kb/s） bo：保存数据至块设备的速率（kb/s） system in：interrupts，中断速率，即每秒发生的中断次数； cs：context switch, 上下文切换的速率，即每秒发生的进程切换次数； cpu us：user space，用户空间占用 cpu 比例 sy：system，内核空间占用 cpu 比例 id：idle，cpu 空闲比例 wa：wait，等待 I/O 完成，消耗的 cpu 时间比例 st: stolen，被虚拟化技术偷走的 cpu 时间比例 2. pmap命令：pmap [options] pid [...] 作用: 显示进程虚拟内存到物理内存的映射关系表 -x：显示详细格式的信息； 另一种查看方式：cat /proc/PID/maps 3. dstat命令：dstat [-afv] [options..] [delay [count]] 作用: 统计系统资源的使用情况 常用选项： -c， --cpu：显示cpu相关信息； -C 1,3,...,total: 显示指定的cpu相关信息； -d, --disk：显示磁盘的相关信息 -D sda,sdb,...,tobal: 显示指定磁盘的相关信息 -g：显示page相关的速率数据； -m：Memory的相关统计数据 -n：显示network 相关统计数据； -p：显示process的相关统计数据； -r：显示io请求的相关的统计数据； -s：显示swapped的相关统计数据； --tcp --udp --raw --socket --ipc --top-cpu：显示最占用CPU的进程； --top-io：最占用io的进程； --top-mem：最占用内存的进程； --top-lantency：延迟最大的进程； 1234567tao@hp:~$ dstatYou did not select any stats, using -cdngy by default.----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read writ| recv send| in out | int csw 14 3 82 1 1 0|1355k 633k| 0 0 | 0 0 |1788 3408 26 1 73 0 1 0| 0 4096B| 471B 224B| 0 0 |1916 1627 26 0 73 1 0 0| 0 188k| 92B 0 | 0 0 |1950 1744]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.3 进程管理的实时动态命令]]></title>
    <url>%2F2018%2F07%2F26%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[进程管理实时动态命令 下面介绍的 top, htop，glances 都是能实时查看系统状态的动态命令，有众多快捷键可以控制屏幕显示的内容。htop 是 top 命令的升级版，glance 则是另一款 htop 它们实现的功能类似。 1. topuptime 作用: 显示系统时间、运行时长及平均负载； 过去1分钟、5分钟和15分钟的平均负载； 等待运行的进程队列的长度； 注释: 显示内容即 top 命令的首部信息 top options 作用: display Linux processe 选项: -d #: 指定刷新时间间隔，默认为3秒； -b: 以批次方式显示； -n #: 显示多少批次，与 -b 一起使用； 快捷键: 排序: P: 以占据CPU百分比排序； M: 以占据内存百分比排序； T: 累积占用CPU时间排序； 首部信息: uptime信息: l 命令 tasks及cpu信息: t 命令 CPU分别显示使用数字 1 内存信息: m命令 退出命令: q 修改刷新时间间隔: s 终止指定的进程: k 帮助: h 显示COMMAND 详细信息: c 12345678910#快捷键: l# top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40#快捷键: t# Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie#快捷键: 1# %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st#快捷键: m# KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cache KiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4812 tao 20 0 2876852 431600 139652 S 9.5 5.3 49:00.29 atom 2150 root 20 0 447256 122816 71820 S 4.6 1.5 13:42.31 X 4384 tao 20 0 4824324 1.066g 39644 S 3.6 13.8 49:54.58 java top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40 作用: Top 任务队列信息(系统运行状态及平均负载)，与uptime命令结果相同 字段: 系统当前时间 系统运行时间，未重启的时间 当前登录用户数 系统负载，即任务队列的平均长度，3个数值分别统计最近1，5，15分钟的系统平均负载 单核CPU情况下，0.00 表示没有任何负荷，1.00表示刚好满负荷，超过1侧表示超负荷，理想值是0.7； 多核CPU负载：CPU核数 * 理想值0.7 = 理想负荷，例如：4核CPU负载不超过2.8何表示没有出现高负载 Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie 作用: Tasks 进程相关信息 字段: 进程总数，例如：Tasks: 231 total, 表示总共运行231个进程 正在运行的进程数，例如：1 running, 睡眠的进程数，例如：230 sleeping, 停止的进程数，例如：0 stopped, 僵尸进程数，例如：0 zombie %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st 作用: CPU 相关信息 字段: us: 用户空间占用CPU百分比，例如：Cpu(s): 12.7%us, sy: 内核空间占用CPU百分比，例如：8.4%sy, ni: 用户进程空间内改变过优先级的进程占用CPU百分比，例如：0.0%ni, id: 空闲CPU百分比，例如：77.1%id, wa: 等待输入输出的CPU时间百分比，例如：0.0%wa, hi: CPU服务于硬件中断所耗费的时间总额，例如：0.0%hi, si: CPU服务软中断所耗费的时间总额，例如：1.8%si, st: Steal time 虚拟机被hypervisor偷去的CPU时间（如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的） KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cacheKiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem 作用: 内存 相关信息 字段: 物理内存总量，例如：Mem: 12196436k total, 使用的物理内存总量，例如：12056552k used, 空闲内存总量，例如：Mem: 139884k free, 用作内核缓存的内存量，例如：64564k buffers 字段值含义 PID = (Process Id): 进程Id； USER = (User Name): 进程所有者的用户名； PR = (Priority): 优先级 NI = (Nice value): nice值。负值表示高优先级，正值表示低优先级 VIRT = (Virtual Image (kb)): 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES = (Resident size (kb)): 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR = (Shared Mem size (kb)): 共享内存大小，单位kb S = (Process Status): 进程状态。D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程 %CPU = (CPU usage): 上次更新到现在的CPU时间占用百分比 %MEM = (Memory usage (RES)): 进程使用的物理内存百分比 TIME+ = (CPU Time, hundredths): 进程使用的CPU时间总计，单位1/100秒 PPID = (Parent Process Pid): 父进程Id RUSER = (Real user name): UID = (User Id): 进程所有者的用户id GROUP = (Group Name): 进程所有者的组名 TTY = (Controlling Tty): 启动进程的终端名。不是从终端启动的进程则显示为 ? P = (Last used cpu (SMP)): 最后使用的CPU，仅在多CPU环境下有意义 SWAP = (Swapped size (kb)): 进程使用的虚拟内存中，被换出的大小，单位kb TIME = (CPU Time): 进程使用的CPU时间总计，单位秒 CODE = (Code size (kb)): 可执行代码占用的物理内存大小，单位kb DATA = (Data+Stack size (kb)): 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb nFLT = (Page Fault count): 页面错误次数 nDRT = (Dirty Pages count): 最后一次写入到现在，被修改过的页面数 WCHAN = (Sleeping in Function): 若该进程在睡眠，则显示睡眠中的系统函数名 Flags = (Task Flags &lt;sched.h&gt;): 任务标志，参考 sched.h COMMAND = (Command name/line): 命令名/命令行 2. htophtop options 选项: -d #: 指定延迟时间间隔； -u UserName: 仅显示指定用户的进程； -s COLUME: 以指定字段进行排序； 子命令: l: 显示选定的进程打开的文件列表； s: 跟踪选定的进程的系统调用； t: 以层级关系显示各进程状态； a: 将选定的进程绑定至某指定的CPU核心； 3. glances命令：glances options 作用: 动态的系统状态监控工具，使用类似 top 常用选项： -b：以Byte为单位显示网上数据速率； -d：关闭磁盘I/O模块； -m：关闭mount模块； -n：关闭network模块； -t #：刷新时间间隔； -1：每个cpu的相关数据单独显示； -o {HTML|CSV}：输出格式； -f /PATH/TO/SOMEDIR：设定输出文件的位置； C/S模式下运行glances命令： 服务模式：glances -s -B IPADDR IPADDR：本机的某地址，用于监听； 客户端模式： glances -c IPADDR IPADDR：是远程服务器的地址； 附注: C/S 模式下无论是密码还是内容都是明文传输的，容易被截获，glances 不适合 C/S 模式使用]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.2 进程管理命令]]></title>
    <url>%2F2018%2F07%2F25%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[进程管理命令 Linux系统上有众多进程查看及管理工具，不完全列示如下: 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall 进程优先级调整: nice, renice 这些命令在我们以后的运维过程中都能用到，希望大家能熟练掌握。 1. 进程查看1.1 pstreepstree options 作用: 以树状图的方式展现进程之间的派生关系 选项: -p: 显示程序 pid； -u: 显示用户名称； -n: 用 pid 排序,预设是以程序名称来排序； -a: 显示每个程序的完整指令，包含路径，参数或是常驻服务的标示； -c: 不使用精简标示法； -G: 使用VT100终端机的列绘图字符； -h: 列出树状图时，特别标明现在执行的程序； -H&lt;pid&gt;: 此参数的效果和指定”-h”参数类似，但特别标明指定的程序； -l: 采用长列格式显示树状图； -U: 使用UTF-8列绘图字符； -V: 显示版本信息 1.2 psps 命令简介在前面的 4.1 Linux目录机构 我们提到过，Linux 有两个伪文件系统 /proc,/sys /proc/: 是基于内存的虚拟文件系统，保存了内核及进程的相关信息； /proc 内的内核参数分为两类: 状态变量: 其用于输出内核中统计信息或状态信息，仅用于查看 可设置其值从而调整内核运行特性的参数,位于 /proc/sys/，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； /sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径 其主要作用在于为管理Linux设备提供一种统一模型的的接口； Linux 进程的各种状态信息保存在 /proc 中以进程 PID 号命名的文件中。ps 命令即是通过读取 /proc/PID 目录内的文件，显示进程的相关信息。ps 命令选项有三种风格: UNIX 风格的参数，必需使用 - BSD 风格的参数, 不能使用 - GNU 风格的长选项, 使用--开头 ps 使用ps [options]: 作用: report a snapshot of the current processes. BSD 选项: a: 所有与终端相关的进程； x: 所有与终端无关的进程； u: 以用户为中心组织进程状态信息显示； U&lt;uname&gt;: 显示特定用户进程 -o/o field1, field2,...: 可以加 - 也可以不加 用于自定义要显示的字段列表，字段列表以逗号分隔； 常用的field: pid, ni, pri, psr, pcpu, stat, comm, tty, ppid, rtprio UNIX 选项: -e: 显示所有进程 -f: 显示完整格式的进程信息 -F: 显示完整格式的进程信息，与 -f 显示的字段略不同 -H: 以层级结构显示进程的相关信息； -U&lt;uid&gt;: 显示特定用户进程 -u&lt;uid&gt;: 显示特定用户进程 常用组合之一: ps aux ps -ef ps -eFH ps -eo, ps axo ps aux1234567891011tao@hp:~$ ps aux |head -10USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 194436 9136 ? Ss 08:49 0:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 21root 2 0.0 0.0 0 0 ? S 08:49 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 08:49 0:00 [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; 08:49 0:00 [kworker/0:0H]root 7 0.0 0.0 0 0 ? S 08:49 0:03 [rcu_sched]root 8 0.0 0.0 0 0 ? S 08:49 0:00 [rcu_bh]root 9 0.0 0.0 0 0 ? S 08:49 0:01 [rcuos/0]root 10 0.0 0.0 0 0 ? S 08:49 0:00 [rcuob/0]root 11 0.0 0.0 0 0 ? S 08:49 0:00 [migration/0] %CPU: CPU 占用百分比 %MEM: 内存占用百分比 VSZ: 虚拟内存集； RSS: Resident Size，常驻内存集； TTY: 进程所属终端 STAT: 进程状态 R: running，运行中 S: interruptable sleeping，可中断睡眠 D: uninterruptable sleeping，不可中断睡眠 T: Stopped，停止状态 Z: zombie，僵尸进程 +: 前台进程 l: 多线程进程 N: 低优先级进程 &lt;: 高优先级进程 s: session leader，管理着多个其他进程的进程 START: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -ef12345678tao@hp:~$ ps -ef|head -10UID PID PPID C STIME TTY TIME CMDroot 1 0 0 08:49 ? 00:00:04 /usr/lib/systemd/systemd --switched-root --system --deserialize 21root 2 0 0 08:49 ? 00:00:00 [kthreadd]root 3 2 0 08:49 ? 00:00:00 [ksoftirqd/0]root 5 2 0 08:49 ? 00:00:00 [kworker/0:0H]root 7 2 0 08:49 ? 00:00:03 [rcu_sched]root 8 2 0 08:49 ? 00:00:00 [rcu_bh] PPID: 父进程的 pid C: cpu utilization, CPU 占用率 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eFH1234567tao@hp:~$ ps -eFH|head -10UID PID PPID C SZ RSS PSR STIME TTY TIME CMDroot 2 0 0 0 0 2 08:49 ? 00:00:00 [kthreadd]root 3 2 0 0 0 0 08:49 ? 00:00:00 [ksoftirqd/0]root 5 2 0 0 0 0 08:49 ? 00:00:00 [kworker/0:0H]root 7 2 0 0 0 3 08:49 ? 00:00:03 [rcu_sched]root 8 2 0 0 0 0 08:49 ? 00:00:00 [rcu_bh] C: cpu utilization, CPU 占用率 SZ: VSZ 虚拟内存集； RSS: Resident Size，常驻内存集； PSR: 进程运行于哪颗CPU之上 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eo|axo1234567891011tao@hp:~$ ps -eo user,uid,nice,priority,psr,pcpu,stat,rtprio,cmd,tty,ppidUSER UID NI PRI PSR %CPU STAT RTPRIO CMD TT PPIDroot 0 0 20 0 0.0 Ss - /usr/lib/systemd/systemd -- ? 0root 0 0 20 2 0.0 S - [kthreadd] ? 0root 0 0 20 0 0.0 S - [ksoftirqd/0] ? 2root 0 -20 0 0 0.0 S&lt; - [kworker/0:0H] ? 2root 0 0 20 0 0.0 S - [rcu_sched] ? 2root 0 0 20 0 0.0 S - [rcu_bh] ? 2root 0 0 20 2 0.0 S - [rcuos/0] ? 2root 0 0 20 0 0.0 S - [rcuob/0] ? 2root 0 - -100 0 0.0 S 99 [migration/0] ? 2 ps -eo user, uid, nice, priority, psr, pcpu, stat, rtprio, cmd, tty, ppid ni/nice: nice值 priority: priority, 优先级 psr: PSR 进程运行于哪颗CPU之上 pcpu: %CPU cpu 占用百分比 stat: STAT 进程状态 rtprio: real time priority，实时优先级 1.3 pgreppgrep [options] pattern 作用: 通过进程名或其他属性查找进程 参数: pattern 匹配进程名的模式 选项 -l: 显示进程名； -a: 显示完整格式的进程名； -u uid: effective user，有效用户 -U uid: real user，实际用户 -t TERMINAL: 与指定的终端相关的进程； -P pid: 显示此进程的子进程； -o：仅显示找到的最小（起始）进程号； -n：仅显示找到的最大（结束）进程号； 12345678tao@hp:~$ pgrep -la htt*13163 /usr/sbin/httpd -DFOREGROUND13169 /usr/sbin/httpd -DFOREGROUND13172 /usr/sbin/httpd -DFOREGROUND13173 /usr/sbin/httpd -DFOREGROUND13177 /usr/sbin/httpd -DFOREGROUND13178 /usr/sbin/httpd -DFOREGROUND13180 /usr/sbin/httpd -DFOREGROUND 1.4 pidof命令:pidof [options] program [program..] 作用: 根据进程名，取其进程 pid 参数: program 进程名称 选项: -s：仅返回一个进程号； 12tao@hp:~$ pidof httpd13180 13178 13177 13173 13172 13169 13163 2. 进程管理kill 类命令可以向进程发送信号，以实现对进程管理。Linux 中每个信号的标识方法有三种: 信号的数字标识； 信号的完整名称； 信号的简写名称； 12345# HUP = SIGHUP = 1tao@hp:monitor$ kill -l 1HUPtao@hp:monitor$ kill -l SIGHUP1 2.1 kill查看信号类型kill -l [signal] 作用: 查看信号类型 参数: signal 待查看的信号类型，可选，默认显示所有信号 常用信号: 12345678910111213141516171819tao@hp:monitor$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAXtao@hp:monitor$ kill -l 1HUPtao@hp:monitor$ kill -l SIGHUP1 发送信号管理进程kill [-s signal|-SIGNAL] pid... 作用: 用于向进程发送信号，以实现对进程的管理 选项: -s signal|-SIGNAL: 指明要发送的信号 -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -u：指定用户 常用信号: 1） SIGHUP: 无须关闭进程而让其重读配置文件； 2）SIGINT: 终止正在运行的进程，相当于Ctrl+c 9）SIGKILL: 杀死运行中的进程； 15）SIGTERM: 终止运行中的进程； 18）SIGCONT: 启动暂停的进程 19）SIGSTOP: 暂停进程 1234kill -9 1999kill -s 9 1999kill -SIGKILL 1999kill -KILL 1999 2.2 killallkillall [-SIGNAL] program 作用: 使用进程的名称来杀死进程，使用此指令可以杀死一组同名进程 参数: program 进程名称 选项: -e：对长名称进行精确匹配； -l：忽略大小写的不同； -p：杀死进程所属的进程组； -i：交互式杀死进程，杀死进程前需要进行确认； -l：打印所有已知信号列表； -q：如果没有进程被杀死。则不输出任何信息； -r：使用正规表达式匹配要杀死的进程名称； -s signal|-SIGNAL：指定发送的信号 -u：杀死指定用户的进程。 2.3 pkillpkill [options] pattern 作用: 通过进程名或其他属性向进程发送信号，用法与 pgrep 类似 选项: -u uid: effective user，向指定的有效用户发送信号 -U uid: real user，向指定的实际用户发送信号 -t TERMINAL: 向指定的终端相关的进程发送信号； -P pid: 向此进程的子进程发送信号 -g：指定进程组； -o：仅向找到的最小（起始）进程号发送信号； -n：仅向找到的最大（结束）进程号发送信号； 3. 进程优先级调整Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级，Nice值用于调整静态优先级。 需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。进程启动时，nice值默认为0，优先级是120，可通过nice值调整的优先级范围是 100-139，nice值分别对应于-20, 19 诸多命令都可以查看进程的优先级与 nice 值，比如 ps axo pid, ni, priority, comm nicenice [OPTION] [COMMAND [ARGU]...] 作用: 以指定的nice值启动并运行命令 参数: COMMAND： 要执行的命令，如果没给 COMMAND, 显示当前进程的优先级 ARGU: 传递给 COMMAND 的参数 选项： -n NICE: 指定优先级，默认为 5 注意：仅管理员可调低nice值； renicerenice [-n] NICE PID... 作用: 更改已经运行用户的优先级 参数: NICE: 新 nice 值 PID: 进程PID 4. 未涉及到的命令：sar, tsar, iostat, iftop, nethog, …]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.1 Linux进程原理]]></title>
    <url>%2F2018%2F07%2F24%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2FLinux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux进程原理 本章我们来学习 Linux 中的进程管理，这是运维的基本内容，我们需要借此查看 Linux 服务的负载，分析和删除系统上的异常进程等等。首先我们会简单介绍操作系统原理中有关进程，虚拟内存相关的基础知识，这是原理部分；如果对进程一无所知对很多命令的输出结果我们很难明白其含义。然后我们会介绍 Linux 上常用的进程查看和管理工具，这些都是我们分析和管理系统的重要工具，最后我们会说一说 Linux 中的作业管理。本章内容总结如下: 操作系统的基本原理之进程 常用的进程查看和管理工具 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall，nice, renice 实时动态命令的使用，top, glances, htop 系统状态查看,vmstat, pmap, dstat 作业管理 有关 Linux 的实现有两本书推荐大家观阅读 Linux内核设计与实现: 入门级 深入理解Linux内核: 进阶级 当然没那么容易说清楚进程是什么。无论是什么程序员，操作系统，编译原理永远都是谜一样的话题，但是人总是要慢慢进步的，随着我们不断成长，对其的认识也会慢慢深入。好吧，我们开始吧。 现代操作系统都是多任务系统，目前常用的服务器也就 64 个核心，通常要运行的任务一定比操作系统的核心多，那么就存在几个问题。一是我们应该如何给不同任务分配运行时间？二是多个任务如何共享使用我们的存储设备，特别是内存？这就涉及到进程和虚拟内存的概念了。 1. 进程和内存的抽象进程 进程是操作系统对一个独立的运行程序的抽象，是操作系统调度的基本单元(操作系统调度的基本单元应该是线程，但是通常一个进程只有一个线程，可以先这么理解)。每个进程都有一个叫作 task structure 的结构，其包含了该进程能正常运行的所有上下文。什么是程序运行的上下文呢？那我们要从计算机的存储系统说起。 我们都知道我们的计算机有硬盘，内存，缓存。为什么回有这么多存储设备呢？主要是因为不同的存储介质工作频率不相同，工作频率高的造价高。如果我存储介质跟不上 CPU 的频率就会造成 CPU 性能的浪费。因此基于最近被访问的数据很有可能在接下来再次被访问这样一个原理，计算机的存储系统被构建成了如下的层次结构 典型的 CPU 里面有寄存器，它的工作频率几乎和CPU 一致，但是容量很小，仅仅保存了当前指令的操作数和下一次要执行的指令。当发生进程切换时，寄存器就会被新进程的数据所覆盖。所以这些寄存器中的数据都应该被保存起来，以便下此进程再次执行时就好像从没有中断过一样能继续执行。包括 CPU 中寄存器的值，程序打开的文件描述符等等在内的维持程序能正常执行的所有数据就是进程的上下文。 虚拟内存 操作系统的任务是变化的，但是运行中的内存是不变。那么应该如何分配每个进程占用的空间，占用的内存位置，以避免它们相互影响呢？ 操作系统将内存抽象为虚拟内存，所有进程启动时，所见的内存空间均为虚拟内存，进程可以假设为当前系统上只有内核和自己。虚拟内存对于所用程序都是统一的，因此程序无需考虑实际内存的分配问题，直接向虚拟内存空间申请和释放内存即可。虚拟内存和物理内存被划分为一个个页框，当进程需要内存时，其向虚拟内存空间申请内存，然后由操作系统将空闲的物理页框与进程申请到的虚拟页框建立关联关系。进程访问数据时必需将虚拟地址转换实际的内存地址才能访问到数据。计算机上有一个专门的单元 MMU 用于完成虚拟地址的转换。上图 task_structure 中的 mm_struct 保存就是虚拟页框与物理页框的映射关系。 2. 运行中进程 进程的内存空间结构如上图左边所示，包括代码段，数据段，堆栈等。创建进程时，父进程调用 fork() 系统调用创建子进程，此时子进程共享父进程的所有环境，然后子进程调用 exec() 系统调用将自己的代码装载入代码段；最后父子进程各自运行。Linux 使用写时复制，当子进程需要修改父进程的内存空间时，它首先将当前内存中的内容复制到新的空闲空间中，然后在修改。因此父子进程不会相互影响。 进程都是有父进程创建和销毁。Centos 中的第一个进程叫 init ，它是所有进程父进程。Centos567 的 init 程序并不相同。我们会在后面的系统开机启动中详细讲解。 运行中的进程存在优先级的概念，优先级用于控制进程的执行次序Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级； 数字越小，优先级越高，Nice值(-20,19) 用于调整静态优先级。需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。 进程之间可能需要通信，进程间通信叫作 IPC，IPC 有如下方式。 IPC: Inter Process Communication 同一主机上： signal: 信号 shm: shared memory: 共享内存 semerphor: 信号量 不同主机上： rpc: remote procecure call 远程系统调用 socket: 套接子 进程最终必需由父进程收回，如果父进程意外终止而没有收回进程，进程就会成为孤儿进程，在进程执行完成后将称为僵尸进程。 3. 用户空间与内核空间 为了避免用户空间的程序破坏内核，Linux 将操作系统的指令分成了4个不同级别，这些级别的指令被分别放在操作系统抽象的环上。最内存的内核和系统调用属于特权指令，被称为内核空间，外层的指令属于普通指令，被称为用户空间。 当进程需要调用特权指令时，进程需要发出软中断，陷入内核，由内核执行所需的特权执行，并将执行结果交给用户进程。进程获取到结果后继续运行。进程等待系统调用结果而不能执行时，我们称进程处于不可中断睡眠状态。运行中的进程有如下几种状态 运行态：running，正在被CPU 执行 就绪态：ready，程序准备完成，等待内核调度执行 睡眠态： 可中断：interruptable，进程的执行时间耗尽而被换出CPU 不可中断：uninterruptable 停止态：暂停于内存中，但不会被调度，除非手动启动之；stopped 僵死态：zombie 最后Linux 中进程可以分为两类 守护进程: 在系统引导过程中启动的进程，跟终端无关的进程； 前台进程：跟终端相关，通过终端启动的进程，也可把在前台启动的进程送往后台，以守护模式运行；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.6 网络属性配置之 nmcli 系列命令]]></title>
    <url>%2F2018%2F07%2F23%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2FCentos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 nmcli 系列命令 本节我们来介绍 Linux 网络属性配置的第三组系列命令 nm。nm(network management) 是 Centos7 新增的命令，使用方式类似 ip 命令，将网络属性分成了多个 OBJECT，每个 OBJECT 都有众多子命令用于对其进行管理配置。nm 主要包含两个工具: nmcli: nm 的命令行工具 nmtui: nm 的图形客户端 1. nmclinmcli [ OPTIONS ] OBJECT { COMMAND | help } OBJECT: device: 显示和管理网络接口，类似 ip link connection: 启动，停止，管理网络连接，类似 ip addr 1.1 nmcli devicenmcli device COMMAND COMMAND:{status | show | connect | disconnect | delete | wifi | wimax } 1.2 nmcli connectionnmcli connection COMMAND COMMAND: { show | up | down | add | edit | modify | delete | reload | load } nmcli connection modifynmcli connection modify IFACE [+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt; 作用: 如何修改IP地址等属性： 效力: 直接修改 ifcfg-IFACE 文件，修改完成不会生效，需要重启 参数: IFACE: 接口标识 setting.property: 网络属性值 ipv4.address ipv4.gateway ipv4.dns1 ipv4.method manual: 手动配置 dhcp 1234567localectl list-localeslocalectl set-locale LANG=en_US.utf8nmcli g status # 显示网络接口状态nmcli device show ens33nmcli connection modify ens33 ipv4.address 192.168.1.101# 重启以生效修改nmcli con down ens33; nmcli connection up ens33 2. nmtuinmcli 命令的图形化工具]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.7 网络客户端工具]]></title>
    <url>%2F2018%2F07%2F23%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[网络客户端工具 在本章的最后一节，我们来说一说一些常用的网络客户端工具，包括 ping 命令 ftp 客户端工具 wget 下载工具 1. ping1.1 pingping [OPTION] destination 作用: send ICMP ECHO_REQUEST to network hosts 参数: destination 目标主机 选项: -c #：发送的ping包个数； -w #：ping命令超时时长； -W #：一次ping操作中，等待对方响应的超时时长； -s #：指明ping包报文大小； 1.2 hpinghping options 作用: send (almost) arbitrary TCP/IP packets to network hosts 选项: --fast --faster --flood -i uX 1.3 traceroutetraceroute ip/FQDN 作用: 跟踪从源主机到目标主机之间经过的网关； 2. ftp 客户端2.1 lftplftp [-p port] [-u user[,pass]] server_ip 作用: ftp 客户端命令的升级版 子命令: get, mget put, mput rm, mrm help ls 2.2 lftpgetlftpget [-c] [-d] [-v] URL [URL...] 作用: 借助 lftp 下载文件 选项: -c：继续此前的下载； 1234&gt; ftp server_ip# 无密码登录&gt; Name: anonymous&gt; Password: 直接回车 3. wget命令：wget [option]... [URL]... 作用: The non-interactive network downloader. 选项: -b：在后台执行下载操作； -q：静默模式，不显示下载进度； -O file：下载的文件的保存位置； -c：续传； --limit-rate=amount：以指定的速率传输文件；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.5 网络配置文件]]></title>
    <url>%2F2018%2F07%2F22%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[网络配置文件 本节我们来学习如何通过修改配置文件来更改网络属。RHEL系的网络配置文件主要包括两个部分: IP/NETMASK/GW/DNS等属性的配置文件，位于 /etc/sysconfig/network-scripts/ifcfg-IFACE 路由的相关配置文件，位于 /etc/sysconfig/network-scripts/route-IFACE 更改配置后需要重启网络服务以重载配置文件才能让配置的网络属性生效，因此我们会简单的说一说网络服务的管理。Linxu 的服务管理我们会在后面的章节详细介绍。本章将包括以下内容: 配置文件的修改 ifcfg-IFACE 配置参数 route-IFACE 配置参数 Centos 网络服务的管理 给网络接口配置多个地址 网卡名称修改 1. 网络配置的修改所有的配置文件都是文本文件，可通过vim 直接修改，Centos 也提供了专用的修改命令 CentOS 6：system-config-network-tui，setup CentOS 7: nmtui 2. ifcfg-IFACEifcfg-IFACE 常用配置参数 DEVICE：此配置文件对应的设备的名称； HWADDR：设备的MAC地址； UUID：此设备的惟一标识； ONBOOT：在系统引导过程中，是否激活此接口； BOOTPROTO：激活此接口时使用什么协议来配置接口属性，常用的有dhcp、bootp、static、none； TYPE：接口类型，常见的有Ethernet, Bridge； IPADDR： IP地址； NETMASK：子网掩码；CentOS 7支持使用PREFIX以长度方式指明子网掩码； GATEWAY：默认网关； DNS1：第一DNS服务器指向； DNS2：备用DNS服务器指向； DOMAIN：DNS搜索域； IPV6INIT：是否初始化IPv6； IPV4_FAILURE_FATAL: 如果 IPV4 不可用是否关闭此网络接口 USERCTL：是否允许普通用户控制此设备； NM_CONTROLLED：是否使用NetworkManager服务来控制接口；Centos6 上建议为 no PEERDNS：如果BOOTPROTO的值为“dhcp”，是否允许dhcp server分配的dns服务器指向覆盖本地手动指定的DNS服务器指向；默认为允许 1234567891011121314151617181920212223# ifcfg-IFACE 配置示例ESSID="CLOUD3_5G"NAME=CLOUD3_5GHWADDR=00:28:F8:35:06:ECUUID=816cdc8b-e62f-4bdb-9ca8-be2545a5a7e6ONBOOT=yesBOOTPROTO=dhcpMODE=ManagedKEY_MGMT=WPA-PSKTYPE=WirelessDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_ADDR_GEN_MODE=stable-privacySECURITYMODE=openMAC_ADDRESS_RANDOMIZATION=defaultPEERDNS=yesPEERROUTES=yes 3. route-IFACEroute-FACE 支持两种配置方式，但不可混用 方式一: 每行一个路由条目12TARGET via GW192.168.1.101 via 172.168.2.1 方式一: 每三行一个路由条目1234567ADDRESS#=TARGETNETMASK#=MASKGATEWAY#=NEXTHOPADDRESS0=192.168.4.0NETMASK0=255.255.255.0GATEWAY0=172.16.1.1 4. 网络服务管理Centos6 上网络管理的服务有两个 network，NetworkManager，但 NetworkManger 仍处于实验阶段，功能还不完善，比如创建集群或桥接接口 NetworkManger 都不支持。建议在 Centos6 中关闭 NetworkManager 只使用 network；即 将 ifcfg-IFACE 配置文件中的 NM_CONTROL 设置为 No 把 NetworkManager 服务禁止掉 Centos7 中 NetworkManager 已经很完善，并且已经是网络管理的默认服务 12345678910111213141516systemctl status network● network.service - LSB: Bring up/down networking Loaded: loaded (/etc/rc.d/init.d/network; bad; vendor preset: disabled) Active: active (exited) since 三 2018-08-01 10:21:35 CST; 6min ago Docs: man:systemd-sysv-generator(8) Process: 12814 ExecStop=/etc/rc.d/init.d/network stop (code=exited, status=0/SUCCESS) Process: 13126 ExecStart=/etc/rc.d/init.d/network start (code=exited, status=0/SUCCESS)systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-08-01 08:45:21 CST; 1h 43min ago Docs: man:NetworkManager(8) Main PID: 1199 (NetworkManager) CGroup: /system.slice/NetworkManager.service ├─1199 /usr/sbin/NetworkManager --no-daemon 4.1 管理网络服务Centos 6，7服务的启动和管理完全并相同，我们会在后面操作系统的启动流程以及服务管理详细讲解，现在大家只要知道可以使用以下这些命令即可: Centos6: service SERVICE {start|stop|restart|status} /etc/rc.d/init.d/network {start|stop|restart|status} CentOS 7： systemctl {start|stop|restart|status} SERVICE[.service] 网络配置文件修改之后，如果要生效，需要重启网络服务 CentOS 6：service network restart CentOS 7：systemctl restart NetworkManager.service 5. 给网卡配置多个地址给网卡配置多个地址有多种方式: ip addr add ip dev IFACE label label_name ifconfig IFACE_LABEL IPADDR/NETMASK IFACE_LABEL: 地址别名，eth0:0, eth0:1, … eg: ifconfig ens33:1 192.168.1.117/24 up 为别名添加配置文件； cp ifcfg-eth0 ifcfg-eth0:0，然后修改 ifcfg-eth0:0 1234&gt; vim /etc/sysconfig/network-script/ifcfg-eth0:0DEVICE=eth0:0 # DEVICE 修改为地址别名BOOTPROTO=None # 网上别名不支持动态获取地址；只能使用 static, none删除 HWADDR，UUID 6. 网络接口名称修改udev 程序是 Linux 识别各种设备的辅助程序，因此通过修改其配置文件可以修改网络接口的名称。123456# Centos6 修改过程vim /etc/udev/rules.d/70-persistent-ipoib.rules # 更改网络接口名称modprobe -r e1000 # 卸载网卡驱动modprobe e1000 # 装载网卡驱动，会重新读取 70-persistent-ipoib.rules 配置文件# Centos7 由于网卡命名规则变化，所以 Centos6 的规则不适用]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.4 网络属性配置之 ip 系列命令]]></title>
    <url>%2F2018%2F07%2F21%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2Fip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 ip 系列命令 本节我们来介绍 Linux 网络属性配置的第二组系列命令 ip 命令。ip 命令是 Linux 的”新贵”，相比于 ifcfg 它们更加的高效。ip 系列包括如下几个命令 ip 命令: 有众多子命令，拥有配置网络地址，网络接口属性，路由等多种功 能 ss 命令: netstat 命令的优化版，用于查看网络连接状态 1. ipip [ OPTIONS ] OBJECT { COMMAND | help } 作用: show / manipulate routing, devices, policy routing and tunnels. OBJECT: 作用对象 link: 网络接口属性 addr: 网络地址 route: 路由 netns: 网络命名空间 COMMAND: 每个作用对象上的可用子命令 help: 是一个通用子命令，用于显示特定作用对象的可用命令 注意： OBJECT可简写，各OBJECT的子命令也可简写； 通过上面的展示可以看出，ip 将网络地址，路由，网络接口等划分成了一个个独立的对象，每个独立的对象拥有特定的子命令来对其进行管理和配置。 1.1 ip linkip link： network device configuration，是用来配置网络设备的子命令，可用于管理网络接口的各种属性。其常用子命令如下 ip link setip link set [dev] NAME options 作用: 更改网络接口属性 [dev] NAME:指明要管理的设备，dev关键字可省略 参数： up|down：，up 表示启用，down 表示关闭； multicast on|off：启用或禁用多播功能； name NAME：重命名接口 mtu NUMBER：设置MTU的大小，以太网默认为1500； netns PID：ns为namespace，用于将接口移动到指定的网络名称空间 123456789ip link set eth1 downip link set multicast onip link show# 改名ip link set eno1 downip link set name eno8888ip link set eno8888 up ip link show|listip link show|list options 作用: 显示网络接口属性 参数: [dev] NAME：指明要显示的接口，dev关键字可省略； up: 仅仅显示启用状态的接口设备 ip link helpip link help 作用: 显示 ip link 简要使用帮助 1.2 ip netnsip netns：manage network namespaces. 用于管理网络命名空间。网络命名空间在虚拟化中具有重要作用，我们会在虚拟化重新介绍 ip netns 的使用，此处仅作了解即可 ip netns COMMAND: ip netns list：列出所有的netns ip netns add NAME：创建指定的netns ip netns del NAME：删除指定的netns ip netns exec NAME IP_COMMAND 作用: 在指定的netns中运行命令 NAME: 表示指定的命名空间 IP_COMMAND: 任何可使用的 ip 命令 1234567891011ip netns helpip netns add mynetip link set eno1 netns mynet # 将 eno1 添加到 mynet 名称空间中ip link showip netns exec mynet ip link show # 显示 mynet 中的网络设备ip netns del mynetip link show 1.3 ip addressip address:protocol address management. 用于管理网络地址，作用类似于 ifconfig 命令 ip addr addip addr add IP dev IFACE IFADDR 作用: 为网络接口添加 IP 地址 参数: IP: ip/netmask dev IFACE: 指定网络接口 IFADDR: 为地址的添加的额外属性 label NAME：为额外添加的地址指明接口别名； broadcast ADDRESS：广播地址；会根据IP和NETMASK自动计算得到，一般无需指明 scope SCOPE_VALUE：指明网络接口的作用域了解即可 global：全局可用； link：接口可用； host：仅本机可用； 12345ifconfig eth1 0# 一个网卡可添加多个地址ip addr add 192.168.1.101/24 dev eth1ip addr add 192.168.100.100/24 dev eth1 label eth1:0 # 指定接口别名 ip addr deleteip addr add IP dev IFACE 作用: 删除网络接口的 IP 地址，delete 可简写成 del 参数: IP: 指明要删除的 ip/netmask dev IFACE: 指定网络接口 1ip addr del 192.168.1.101/24 dev eth1 ip addr showip addr show|list options 作用: 显示网络接口地址详细信息 选项: [dev] IFACE: 显示特定接口的地址，默认显示所有接口 label PATTERN: 显示指定模式别名的接口 ip addr fluship addr flush dev IFACE options 作用: 清空网络设备的IP地址，不支持简写 选项: label PATTERN: 删除指定模式别名的接口 12ip addr flush dev eth1ip addr show eth1 1.4 ip routeip route routing table management，路由表管理 ip route addip route {add|change|replace} TARGET via GW options 作用: add,change,replace 使用方式类似 add: 添加路由条目，可根据路由信息自动判断是主机路由还是网络路由 change: 更改路由 replace: 更改或添加路由 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK via GW: 网关或路由的下一跳 选项: dev IFACE: 指明从哪个网络接口发送报文 src SOURCE_IP: dev 指明的网卡存在多个地址时，指定出口IP 12345ip addr add 10.0.0.100/8 dev eth1ip addr add 10.0.20.100/8 dev eth1ip route add 192.168.0.0/24 via 10.0.0.1 dev eth1 src 10.0.20.100ip route add default via 192.168.1.1` ip route deleteip route delete TARGET [via GW] 作用: 删除路由条目 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK [via GW]: 如果 TARGET 能唯一指明路由条目则无需指明网管 eg: ip route del 192.168.1.0/24 ip route showip route show options 作用: 查看路由条目 选项: TARGET: 显示特定路由条目 [dev] IFACE: 查看特定网卡的路由条目 via PREFIX: 查看特定网关的路由条目 ip route fluship route flush options 作用: 清空路由条目 选项: prefix/mask: 删除特定前缀的路由条目 [dev] IFACE: 查看网卡的路由条目 via PREFIX: 删除特定网关的路由 12ip route flush 10/8 # 删除前缀为 10，掩码为 8 位的条目ip route flush 192/8 # 指定的 192/8 无法删除 192/24 的路由条目 ip route getip route get TARGET [via GW] 作用: 获取一条特定的路由信息 1ip route get 192.168.0.0/24 2. ss命令：ss [options] [ FILTER ] 作用：类似于 netstat，用于查看网络连接状态 类 netstat 选项： -t：TCP协议的相关连接 -u：UDP相关的连接 -w：raw socket相关的连接 -x：unix socket 相关 -l：监听状态的连接 -a：所有状态的连接 -n：数字格式 -p：相关的程序及其PID -e：扩展格式信息 特有选项: -m：内存用量 -o：计时器信息 FILTER: ss 用于筛选的表达式 格式: [ state TCP-STATE ] [ EXPRESSION ] TCP-STATE： LISTEN：监听 ESTABLISEHD：建立的连接 FIN_WAIT_1： FIN_WAIT_2： SYN_SENT： SYN_RECV： CLOSED： EXPRESSION： dport = 目标端口号 sport = 源端口号 eg：&#39;( dport = :22 or sport = :22 )&#39; - 每个部分都必须有空格隔开 12ss -tan &apos;( dport = :22 or sport = :22 )&apos;ss -tan state ESTABLISHED]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.3 网络属性配置之 ifcfg 系列命令]]></title>
    <url>%2F2018%2F07%2F20%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2Fifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 ifcfg 系列命令 本节我们来介绍 Linux 网络属性配置的第一组系列命令 ifcfg。ifcfg 系列是 Linux 中很古老的命令，几乎存在于所有的Linux 发行版中。ifcfg 系列包括如下几个命令: ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 ifup/ifdown: 启动/关闭接口 1. ifconfigifconfig 的配置会立即送往内核中的TCP/IP协议栈，并生效 查看接口状态 ifconfig：默认显示活跃状态的接口 ifconfig IFACE [up|down]：后跟网络接口名，显示特定接口，up 表示激活接口，down 表示关闭接口 ifconfig -a：显示所有接口，包括inactive状态的接口； 设置接口地址ifconfig IFACE {address [netmask NETMASK]} options ifconfig IFACE IP/MASK ifconfig IFACE IP netmask NETMASK options： up： 激活接口。如果给接口声明了地址，等于隐含声明了这个选项 down: 关闭此接口 [-]promisc: 启用混杂模式，减号表示禁用 add addr/prefixlen：添加 IPV6 地址 del addr/prefixlen：删除 IPV6 地址 12ifconfig eth0 192.168.100.6/24 upifconfig eth0 192.168.100.6 netmask 255.255.255.0 2 route路由表中的路由条目有三种类型，范围越小优先级越高: 主机路由：目标地址为单个IP； 网络路由：目标地址为IP网络； 默认路由：目标为任意网络，0.0.0.0/0.0.0.0 路由查看route -n -n: 以数字形式显示主机名，默认会反解主机名 添加路由route add [-net|-host] target [netmask Nm] [gw GW] [[dev] If] -net: 指定网络路由 -host: 指定主机路由 netmask: 指定掩码, 默认为 255.255.255.255 gw: 指定路由的下一跳 dev: 指定发送数据包的网卡 1234567891011示例：route add -host 192.168.100.6 gw 192.168.0.1 dev eth0route add -net 10.0.0.0/8 gw 192.168.10.1 dev eth1route add -net 10.0.0.0 netmask 255.0.0.0 gw 192.168.10.1 dev eth1route add -net 0.0.0.0/0.0.0.0 gw 192.168.10.1 route add default gw 192.168.10.1 -- 添加默认路由route add -net 0.0.0.0 netmask 0.0.0.0 gw 192.168.10.1 -- 添加默认路由``` #### 删除路由`route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If]` 示例：route del -host 192.168.100.6 gw 192.168.0.1route del -net 10.0.0.0/8 gw 192.168.10.1route del default``` 3. netstatnetstat can print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 显示路由表netstat -rn -r：显示内核路由表 -n：以数字形式显示主机名，默认会反解主机名 显示网络连接netstat [options] 选项: -t, --tcp：显示TCP协议的相关连接，及其链接状态； -u, --udp：显示UDP相关的连接 -U, --udplite：显示udplite 相关的链接 -S, --sctp：显示 sctp 相关的链接 -w, --raw：显示raw socket相关的连接,指不经过传输层，由应用层直接通过 ip 进行的链接 -l, --listening：显示处于监听状态的连接 -a, --all：显示所有状态 -n, --numeric：以数字格式显示IP和Port； -e, --extend：以扩展格式显示 -p, --program：显示相关的进程及PID； 显示接口的统计数据netstat {--interfaces|-I|-i} [options] 选项: -I, --interfaces&lt;iface&gt;: 指定显示的接口 eg: netstat -Ietho -i: 显示所有活跃接口 -a, --all: 与 -i 同时使用显示所有接口，包括未激活的 -e, --extend: 以扩展格式进行显示 4. ifup/ifdownifup|ifdown iface 作用: 启用或关闭接口 注意: 这两个命令是通过配置文件/etc/sysconfig/network-scripts/ifcfg-IFACE来识别接口并完成配置的；如果设备没有对应的配置文件，则无法通过这两个命令启动或关闭]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.2 网络接口命名与配置指南]]></title>
    <url>%2F2018%2F07%2F19%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[网络接口命名与配置指南 上一节我们讲解了网络的基础知识，很推荐大家读一读计算机网络-自顶向下方法。本节我们会介绍 Linux 中网络接口(网卡)的命名方式，以及概括性的说一说 Linux 中进行网络配置的方式；在接下来的章节中，我们会详细讲解每个命令的使用。本节内容如下: 网络配置方式 Linxu 网络接口的命名方式 1. 网络配置方式将一台 Linux 主机接入到网络中，需要为其配置如下几个参数 IP/NETMASK：本地通信 路由（网关）：跨网络通信 DNS服务器地址：基于主机名的通信 这些参数的配置可以通过命令直接修改内核中的网络参数，也可以修改配置文件然后让内核重载配置文件或下次重新启动生效；也可以依赖本地局域网中配置的 DHCP 服务，为局域网中的其他主机动态配置。DHCP(Dynamic Host Configure Procotol) 服务的配置我们会在后面的章节中介绍。Linux 中配置网络属性的命令和相关配置文件如下 1.1 网络属性管理网络属性配置的配置文件不同的发行版有所不同，RedHat及相关发行版的配置文件位于 /etc/sysconfig/network-scripts/ifcfg-NETCARD_NAME，其中 NETCARD_NAME 为特定网络接口的名称。网络属性管理有众多命令家族，概述如下: ifcfg家族： ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 iproute2家族： ip OBJECT：ip 命令下有众多子命令 addr：管理和查看地址和掩码； link：网络接口属性管理 route：路由查看与管理 ss：网络状态及统计数据查看 CentOS 7特有的 nm(Network Manager)家族 nmcli：nm 命令行工具 nmtui：text window 工具 Centos6 特有的: system-config-network-tui setup, setup 拥有专属的配置文件 system-config-netword-tui 1.2 DNS服务DNS 服务配置DNS 服务只能通过修改其配置文件 /etc/resolv.conf 进行配置。Linux 主机最多可指定三个 DNS 服务器 1234# vim /etc/resolv.confnameserver 10.143.22.116 # 主DNS服务器地址nameserver 10.143.22.118 # 备用DNS服务器地址nameserver 10.143.22.116 # 第三备份DNS服务器地址 DNS 服务测试测试 DNS 服务是否正常，可以使用 host, nslookup, dig 三个命令 正解: FQDN(域名)到 IP dig -t A FQDN host -t A FQND 反解: IP 到 FQDN dig -x IP host -t PTR IP DNS 是互联网的基础服务，我们会花一整章节，来详细介绍 DNS 服务。 1.3 本地主机名配置主机名有三种配置方式 hostname, hostnamectl 和修改配置文件 hostname 查看：hostname 配置：hostname HOSTNAME 效力：只对当前系统有效，重启后无效； hostnamectlCentos7 新增的特有命令 hostnamectl status：显示当前主机名信息； hostnamectl set-hostname：设定主机名，永久有效； 效力: 通过 hostnamectl 修改的主机名立即生效，且永久有效 修改配置文件 主机名的配置文件位于 /etc/sysconfig/network 效力：此方法的设置不会立即生效； 但以后会一直有效； 12# vim /etc/sysconfig/networkHOSTNAME=&quot;hostname&quot; 3. 网络接口命名方式网络接口(网卡)的命名在Linux 中有特定设置过程。默认情况下，Centos6 采用传统的命名机制，Centos7 采用可预测命名方案，支持多种不同的命名机制，这种命名机制需要 biosdevname 程序的参与 3.1 命名机制 Centos6 传统命名： 以太网：ethX, [0,oo)，例如eth0, eth1, … PPP网络：pppX, [0,...], 例如，ppp0, ppp1, … CentOS7 可预测命名方案：支持多种不同的命名机制 如果Firmware(固件)或BIOS为主板上集成的设备提供的索引信息可用，则根据此索引进行命名，如eno1, eno2, … 如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名，如ens1, ens2, … 如果硬件接口的物理位置信息可用(硬件接口的拓扑结构)，则根据此信息命名，如enp2s0, … 如果用户显式定义根据MAC地址命名，例如enx122161ab2e10, … 上述均不可用，则仍使用传统方式命名； 3.2 名称组成格式Centos7 中 eno1，ens1，enp2s0 命名组成如下所示: 前缀 en：ethernet 以太网接口 wl：wlan 无线局域网设备 ww：wwan 无线广域网设备 后缀 o&lt;index&gt;: 集成设备的设备索引号；(onbus) s&lt;slot&gt;: 扩展槽的索引号； x: 基于MAC地址的命名； p&lt;bus&gt;s&lt;slot&gt;: 基于总线及槽的拓扑结构进行命名； bus: PCI 总线编号 slot: 总线上的扩展槽编号 3.3 网卡设备的命名过程Centos7 网卡命名经过了以下过程: udev 辅助工具程序 /lib/udev/rename_device 会根据 /usr/lib/udev/rules.d/60-net.rules 中的指示去查询 /etc/sysconfig/network-script/ifcfg-IFACE 配置文件，根据HWADDR 读取设备名称 biosdevname 根据 /user/lib/udev/rules.d/71-boosdevname.rules 通过检查网络接口设备，根据 /usr/lib/udev/rules.d/75-net-description 中 ID_NET_NAME_ONBOARD 和 ID_NET_NAME_SLOT,ID_NET_NAME_PATH 命名 Centos7 也可以设置网络接口回归传统方式的命名方式: vim /etc/default/grub 配置文件，添加 GRUB_CMDLINE_LINUX=&quot;net.ifnames=0 rhgb quiet&quot; 为 grub2 生成配置文件 grub2-mkconfig -o /etc/grub2.cfg 重启系统]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.1 计算机网络基础知识]]></title>
    <url>%2F2018%2F07%2F18%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[程序包编译安装 本章我们开始学习 Linux 网络配置相关知识。计算机网络包含了众多协议和基础设施，大学里一般都有专门的课程来讲解。本章主要还是对网络配置相关命令讲解，对于计算机网络的基础知识，在一章里肯定没法说清道明。不过有几本书推荐给大家，可以作为深入学习的参考资料。计算机网络-自顶向下方法 五星推荐，对计算机网络的整体架构，基础设施，大多数协议都作了详细概述，通俗易懂。TCP/IP详解 这一系列分成了三卷，对 TCP/IP 协议栈原理作了深入讲解。自己还没读过，大神都是力荐。本章将包含以下内容: 网络基础知识 Linux 网络配置的相关命令 ifcfg 系列命令 ip 系列命令 Centos7 特有的 nmcli 命令 网络配置的配置文件 网络客户端工具 本节先来简单说一说网络相关的基础知识。由于网络知识庞大繁杂，此篇文章将会持续更新，希望能以通俗易懂的方式让大家对网络有个基础的认识。 计算机网络协议是一个网络协议栈，目的是将计算机主机之间通信这一复杂问题划分为多个层次，每个层次通过协议进行规范，向上层输出标准 api。一来通过分层降低解决问题的难度，二来特定层次可以有不同的实现，可以变动改进，只要遵守即定的协议，就不会影响到起他层次的使用，提供了最大程度的灵活性。我们学习网络知识，就是要学习计算机网络的层次，每个层次面对的问题，怎么解决问题，涉及到的协议和基础设施；最后对整个网络有个整体性的认识。本节将按照这样的顺序，对计算机网络做一个简述，包括: 计算机网络的分层 计算机网络协议栈 1. 计算机网络的分层我们的数据都是以二进制的格式存放在磁盘上的，至于它是文本，还是视频取决于二进制数据的组织形式。因此我们在通过网络传输数据时，数据仍是以二进制的形式进行传输，只是不同的传输介质表示二进制的方式不同。比如以太网使用高电压表示 1，低电压表示 0。最终数据传输完成后仍然需要按照特定的组织方式还原数据。 因此从宏观上来看，计算机网络被分成两个层次，通信子网和资源子网。通信子网关注的是如何传输数据，资源子网则只关心数据是如何组织起来的。资源子网不必关心通信子网是如何实现的，只调用其提供的标准接口。因此整个过程有点类似于现实世界中寄快递，快递公司帮我们运输物品，我们不必关心快递公司是如何运输，但是我们必需确保我们物品没有损坏，也可以按需选择不同的快递公司。通过这样的分层我们将一个复杂问题分隔成一个个独立的子问题。 资源子网通常由各个应用程序提供，比如我们常用的 httpd，位于操作系统的用户空间中，通信子网由操作系统内核实现，通过套接子 socket，向用户空间的应用程序提供标准接口。 12345 --------------------用户空间 &lt;--- | | ---&gt; 资源子网 |-------------------|内核空间 &lt;--- | | ---&gt; 通信子网 |-------------------| 2. 计算机网络协议栈 计算机网络协议栈目前有两个标准: TCP/IP 协议栈，这是当前事实上的使用标准，在实际生产环境中逐步演化而来，缺点是每个网络层次之间的接口定义并不是非常明确 OSI 协议栈，这是 ISO 组织对 TCP/IP 作出改进之后的版本，各个网络层次之间界限明确，但是各个层次之间功能有所重复，并没有TCP/IP效率高。正因为其定义规范且明确，这是一个我们更容易学习的版本 上图就是两个协议栈的对比示意图，每个层次的作用概述如下: 通信子网: 物理层: 定义传输介质及介质之间的传输协议，比如电压等(网卡标准定义) 数据链路层: 定义局域网内主机之间的通信，比如传输速度等 网络层: 定义网络与网络之间的通信 传输层: 定义进程与进程之间的通信 资源子网: 应用层: 会话层 表示层 应用层 2.1 物理层设备：网桥或交换机寻址：MAC 地址 Media Access Control 48bits，前 24bits 由 ICANN 分配 2.2 网络层设备：路由器寻址：IP 地址 Internet protocol, 由网络号+主机号组成 IPv4：32bits 8bits.8bits.8bits.8bit 2.3 传输层寻址：IP 地址 + 端口端口号:16bits 1-1023：固定分配，而且只有管理员有权限启用； 1024-4W：半固定， 4W+：临时 2.4 数据的传输过程 MAC：本地通信；范围：本地局域网； IP：界定通信主机，源和目标；范围：互联网； Port：界定进程；范围：主机 ； 3. IP地址分类IP 地址用于标识网络及网络中的主机，按照用于表示网络的字节数将 IP 地址分为 ABCDE 五大类: A类： 第一段为网络号，后三段为主机号 网络号：0 000 0000 - 0 111 1111：1-127 网络数量：126，127 每个网络中的主机数量：2^24-2 默认子网掩码：255.0.0.0，/8 私网地址：10.0.0.0/8 B类： 前两段为网络号，后两段为主机号 网络号：10 00 0000 - 10 11 1111：128-191 网络数：2^14 每个网络中的主机数量：2^16-2 默认子网掩码：255.255.0.0，/16 私网地址：172.16.0.0/16-172.31.0.0/16 C类： 前三段为网络号，最后一段为主机号 网络号：110 0 0000 - 110 1 1111：192-223 网络数：2^21 每个网络中的主机数量：2^8-2 默认子网掩码：255.255.255.0, /24 私网地址: 192.168.0.0/24-192.168.255.0/24 D类：组播 网络号: 1110 0000 - 1110 1111：224-239 E类：科研 网络号: 1111 0000 - 1111 1111: 240-255]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.4 程序包编译安装]]></title>
    <url>%2F2018%2F07%2F17%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2F%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[程序包编译安装 前面我们讲解了使用 rpm，yum 安装程序包的方法，相比于编译安装，它们更加便捷，但是由于 rpm 包是编译好的二进制程序，我们就无法根据自己的需求去定制程序特性和功能。所有如果想定制程序，则必需编译安装，在编译时启用需要的特性。本节我们首先会说一说编译安装的过程，然后再来介绍如何在 Linux 中实现编译安装 C/++ 程序。本节内容概括如下: 程序的编译安装过程 如何获取源代码 编译安装C源代码 1. 程序的编译安装过程 如上图所示，C 程序的编译要经过 源代码 --&gt; 预处理 --&gt; 编译(gcc) --&gt; 汇编 --&gt; 链接 四步 预处理: 处理注释，宏替换，头文件 编译: 将预处理之后的源代码编译成汇编代码 汇编: 将汇编代码编译成二进制机器代码 链接: 如果程序用到了其他 C 库的代码，则需要将这部分代码动态链接至二进制机器代码中 上述就是一个简单 C 程序编译过程的概述，如果想了解更多细节，可查阅其他资料。 我们知道现在的大型软件工程都不太可能由一个人完成，同时为了程序的可维护性和扩展性，通常都会将代码放置在多个文件中，文件中的代码之间，很可能存在跨文件依赖关系。因此在编译 C 过程中，必需按照特定的顺序编译才能编译成功。为了辅助程序的编译，因此出现了很多项目管理工具。make,cmake 则时 C 和 C++ 中最常见的项目管理工具。 make 工具的配置文件 makefile 记录了程序编译的详细过程，make 工具根据 makefile 的配置可以自动完成程序的编译安装。通常在程序包中有两个辅助生成 makefile 的文件 – configure 和 Makefile.ini。Makefile.ini 是 makefile 的模板，configure 是一个脚本文件，有众多选项，能根据用户提供的参数，依据 Makefile.ini 模板动态生成 makefile 文件。因此用户可以借助于 configure 提供的选项定制 makefile 文件，从而定制程序包的编译安装。autoconf 工具可以辅助生成configure脚本，而 automake 则用于辅助生成 Makefile.in 顺便说一下，rpm 包中有一种类似 testapp-VERSION-release.src.rpm 的以 src.rpm 结尾的 rpm 源码包，其内部的代码是未编译的，需要使用rpmbuild命令制作成二进制格式的rpm包，而后才能安装，在 rpmbuild 过程中，用户就可以自定义程序的特性和功能。 1.2 C代码编译安装三步骤根据上述的编译过程阐述， C 代码编译安装大体需要如下三个步骤: ： 通过选项传递参数，指定启用特性、安装路径等；执行时会参考用户的指定以及Makefile.in文件生成makefile； 检查依赖到的外部环境； make：根据makefile文件，构建应用程序； make install: 脚本，将构建的应用程序放置到配置的目录中 附注: 安装前建议查看INSTALL，README 1.3 configure 可用选项./configure [options] 的众多选项可以分为如下几类 –help: 获取其支持使用的选项 安装路径设定： --prefix=/PATH/TO/SOMEWHERE: 指定默认安装位置；默认为/usr/local/ `–sysconfdir=``/PATH/TO/SOMEWHERE：配置文件安装位置； System types: 指定目标平台系统结构 Optional Features: 可选特性 --disable-FEATURE: 关闭特性 --enable-FEATURE[=ARG]: 启用特性 Optional Packages: 可选包 --with-PACKAGE[=ARG] --without-PACKAGE 2. 开源程序源代码的获取常见的源代码有如下几个获取途径 官方自建站点： apache.org (ASF) mariadb.org 代码托管： SourceForge Github.com code.google.com 3. 编译安装C源代码完整的编译安装过程还包括安装前的环境准备以及安装后的配置操作，C源代码完整的安装过程如下 提供开发工具及开发环境，通常包含在开发工具的包组中 开发工具包括：make, gcc等 开发环境包括：开发库，头文件, glibc(C 标准库) 开发工具安装: CentOS6: yum groupinstall &quot;Development Tools&quot; &quot;Server Platform Development&quot; Centos7: yum groupinstall &quot;Development Tools&quot; 执行 configure脚本，指定安装位置、指定启用的特性 执行 make make install 安装后的配置： 导出二进制程序目录至PATH环境变量中； 编辑文件/etc/profile.d/NAME.sh，export PATH=/PATH/TO/BIN:$PATH 导出库文件路径： 编辑/etc/ld.so.conf.d/NAME.conf ，添加新的库文件所在目录至此文件中； 让系统重新生成库文件缓存：ldconfig [-v] 导出头文件 基于链接的方式实现：ln -sv /path/include /usr/include/dir 导出帮助手册 编辑/etc/man.config文件，添加一个MANPATH]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.3 yum命令使用]]></title>
    <url>%2F2018%2F07%2F16%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2Fyum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[yum命令使用 yum 是 rpm 的前端工具，在 rpm 基础上能自动解决程序包的依赖问题，管理程序更加的方便。本节我们就来介绍 yum 的使用，包括以下内容: yum 的架构示意图 yum 仓库指向定义 yum 命令的使用 yum 仓库管理 1. yum 概述 上图是 yum 架构的示意图，yum 是 C/S 架构的服务。yum 的 Serve 端就是一个文件服务器，称为 yum 仓库或 yum 源。yum 仓库包含了众多 rpm 包以及包相关的元数据文件。元数据放置在 repodata 目录，其中包含了包之间的依赖关系。 客户端在请求安装某 rpm 包时，首先会下载元数据到本地并缓存，然后分析包之间的依赖关系，分析完成后向 yum 仓库请求下载该 rpm 包及其缺失的依赖包并安装。 通常 rpm 包安装之后就会被删除，但元数据可以重复使用，因此 yum 客户端会在本地缓存yum 仓库的元数据。但缓存有可能失效，因此为及时发现 yum 仓库的变化，yum 仓库会生成元数据的特征码(单向加密算法提取的指纹信息)。yum 客户端在每次请求时首先下载特征码与本地缓存的特征码进行比对，如果不相同说明 yum 仓库发生变动，则重新下载元数据。 yum 的服务器端和客户端具有如下特征 yum Server yum 服务器端就是一个文件服务器，支持 ftp://，http://，nfs://，file:// 四种协议， file:// 表示本地文件系统 yum 仓库存储了众多rpm包，以及包的相关的元数据文件，元数据放置于 repodata 中 yum 客户端 yum 客户端即我们通常使用的 yum 命令 yum 的配置文件 /etc/yum.conf /etc/yum.repo.d/*.conf 用于配置 yum 源的指向 yum 仓库中包含 repodata 目录的路径，就是 yum 源应该指向的路径 接下来，我们就来逐一讲解 yum 的配置文件，yum 命令的使用以及如何创建 yum 仓库 1.1 yum 的配置文件yum 的核心配置文件包括两个部分: /etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 可以使用 whatis/man yum.conf 获取配置文件的帮助信息，yum 仓库配置的常用选项如下所示 12345678910[repositoryID] # yum 源的唯一标识 IDname=Some name for this repository # yum 源的名称baseurl=url://path/to/repository/ # yum 源的地址，可多个 urlenabled=&#123;1|0&#125; # 是否启用，默认为 1 启用gpgcheck=&#123;1|0&#125; # 包来对源合法性进行检验gpgkey=URL # 秘钥文件位置enablegroups=&#123;1|0&#125; # 是否在此仓库上支持组failovermethod=&#123;roundrobin|priority&#125; # baseurl 指向多个时，失败后如何选择下一个连接 # 默认为：roundrobin，意为随机挑选；priority 表示从上至下顺序选取cost=1000 # yum 源的开销，指定仓库优先级，开销越大，优先级越低 1.2 配置文件中的可用变量yum 源的配置文件中有一些可用变量，可以方便根据当前平台特性，选择特定的 yum 源。常用变量包括 变量名称 作用 $releasever 当前OS的发行版的主版本号，即 centos-release 这个 rpm 包的 Version值 通过 rpm -qi centos-release 可查看 $arch 平台，比如 i386，x86, x86_64，通过 arch 命令可查看当前值 $basearch 基础平台，平台分类中的大类，比如 i386，i568，x86都属于 i386 $YUM0-$YUM9 用户可自定义使用的变量 1234567891011# 阿里云 yum 配置示例[base]name=CentOS-$releasever - Base - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7# 附注: 我的Linux 上 baseurl=http://mirrors.aliyun.com/centos/7/os/x86_64/ 2. yum 命令yum 命令有众多子命令，大体上可以分为两个部分 用于安装，卸载，查看，搜索程序包和程序包组 yum 缓存，事务，历史等管理子命令 yum [options] [command] [package ...] 通用选项: --nogpgcheck：禁止进行gpg check； -y: 自动回答为“yes”； -q：静默模式； --disablerepo=repoidglob：临时禁用此处指定的repo； --enablerepo=repoidglob：临时启用此处指定的repo； --noplugins：禁用所有插件 子命令： 程序包管理子命令 install reinstall update update-to downgrade check-update upgrade upgrade-to remove|erase deplist list info search provides | whatprovides 程序包组管理子命令 groupinstall groupupdate grouplist groupremove groupinfo yum 管理子命令 clean makecache repolist version history help 2.1 程序包管理子命令安装 yum install package1 [...]: 安装程序包 yum reinstall package1 [...]: 重新安装程序包 升级 yum update [package1] [...]: 升级程序包 yum downgrade package1 [...]: 降级安装程序包 yum check-update: 检查可用升级 卸载yum remove | erase package1 [package2] [...] 作用: 卸载程序包 附注: 依赖被卸载的包的包也会被卸载 查询 yum search string1 [...]: 查找程序包，会以指定的关键字搜索程序包名及summary信息； yum info [package1]: 查看特定程序包相关信息 yum deplist package1 [...]: 查看指定包所依赖的特性(capabilities) yum provides | whatprovides feature1 [...] 作用: 查看指定的特性(可以是某文件)是由哪个程序包所提供 yum list [all | glob_exp1] [glob_exp2] [...]yum list {available|installed|updates} [glob_exp1] [...] 作用: 查找程序包，支持通配符，只会匹配程序包名称 选项: all: 列出所有包 available: 列出所有可用的包 installed: 列出所有已经安装的包 updates: 列出所有可更新的包 eg: yum list php* 搜索所有以 php 开头的包 2.2 程序包组管理的相关命令 yum groupinstall group1 [group2] [...]: 安装 yum groupupdate group1 [group2] [...]: 升级 yum groupremove group1 [group2] [...]: 卸载 yum grouplist [hidden] [groupwildcard] [...]: 查看所有可用包组 yum groupinfo group1 [...]: 查看特定包组相关信息 2.3 yum 管理命令缓存yum clean [packages | metadata | expire-cache | rpmdb | plugins | all] 作用: 清理本地缓存 选项: 通过参数，可只清除特定内容 yum makecache 作用: 构建缓存 事务历史yum history [PARAM] 作用: 查看yum事务历史 参数: [info|list|packages-list|packages-info|summary|redo|undo|rollback|new|sync|stats] 显示仓库列表yum repolist [all|enabled|disabled] 作用: 显示仓库列表 参数: all: 显示所有仓库 enabled: 显示启用的仓库 disabled: 显示禁用的仓库 3. yum 仓库管理3.1 使用光盘当作本地yum仓库使用光盘当作本地yum仓库的操作步骤如下: 挂载光盘至某目录，例如/media/cdrom mount -r -t iso9660 /dev/cdrom /media/cdrom 创建配置文件 12345[CentOS7]name=baseurl=file:////media/cdromgpgcheck=enabled= 3.2 创建 yum 仓库createrepo [options] &lt;directory&gt; 作用: 创建 yum 仓库所需的 repodata 目录 选项: -u --baseurl &lt;url&gt;：指定Base URL的地址 -o --outputdir &lt;url&gt;: 指定元数据的输出位置 -x --excludes &lt;packages&gt;: 指定在形成元数据时需要排除的包 -q --quiet: 安静模式执行操作，不输出任何信息。 -g --groupfile &lt;groupfile&gt; 作用: 指定本地软件仓库的组划分，范例如下： 注意：组文件需要和rpm包放置于同一路径下 eg: createrepo -g comps.xml /path/to/rpms -v --verbose: 输出详细信息 -c --cachedir &lt;path&gt; 作用: 指定一个目录，用作存放软件仓库中软件包的校验和信息。 附注: 当createrepo在未发生明显改变的相同仓库文件上持续多次运行时，指定cachedir会明显提高其性能。 -d --database: 该选项指定使用SQLite来存储生成的元数据，默认项。 3.3 yum 的使用奇巧 当我们安装一个不在 yum 仓库的本地 rpm 包时，可使用 yum install local_rpm.rpm 安装，如果次包依赖到 yum 仓库中的其他 rpm 包将自动解决依赖关系。 当我们安装一堆不再 yum 仓库的 rpm 包，且这些 rpm 包本身也存在依赖关系时，可将这些 rpm 包制作成一个本地yum 仓库，这样就可以使用 yum 自动解决所有的依赖关系。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.2 软件包管理rpm命令使用]]></title>
    <url>%2F2018%2F07%2F15%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2Frpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[软件包管理rpm命令使用 本节我们主要来讲解 rpm 命令的使用。rpm 可实现程序的安装、卸载和升级。但相比于程序的管理，rpm 的查询命令能帮助我们快速找到文件或二进制程序所属的程序包，及程序包的配置文件等信息，反而更加重要。由于程序之间存在依赖关系，而 rpm 不能自动帮我们解决程序的依赖问题，因此在程序的管理更加常用的命令是 rpm 的前端管理工具 yum。yum 能自动帮我们解决程序的依赖问题，我们会在下个章节介绍 yum 的使用。 1. CentOS rpmrpm 提供了应用程序的安装、升级、卸载、查询、校验和数据库维护，其使用方式如下。我们会分段讲解各个命令的使用 rpm [OPTIONS] [PACKAGE_FILE] 子命令选项: 安装：-i, --install 升级：-U, --update, -F, --freshen 卸载：-e, --erase 查询：-q, --query 校验：-V, --verify 数据库维护：--builddb, --initdb 通用选项: -v：verbose，详细信息 -vv：更详细的输出 1.1 安装rpm {-i|--install} [install-options] PACKAGE_FILE ... [install-options]： -h：hash marks输出进度条；每个#表示2%的进度； --test：测试安装，检查并报告依赖关系及冲突消息等； --nodeps：忽略依赖关系；不建议； --replacepkgs：重新安装 --nosignature：不检查包签名信息，不检查来源合法性； --nodigest：不检查包完整性信息； --noscripts: 不执行程序包脚本片段，包括以下四种类型的脚本 注意：rpm可以自带脚本，包括四类： preinstall：安装过程开始之前运行的脚本，%pre ， --nopre 可禁止执行此类脚本 postinstall：安装过程完成之后运行的脚本，%post , --nopost 可禁止执行此类脚本 preuninstall：卸载过程真正开始执行之前运行的脚本，%preun, --nopreun 可禁止执行此类脚本 postuninstall：卸载过程完成之后运行的脚本，%postun , --nopostun 可禁止执行此类脚本 1.2 升级：rpm {-U|--upgrade} [install-options] PACKAGE_FILE ...rpm {-F|--freshen} [install-options] PACKAGE_FILE ...rpm -Uvh PACKAGE_FILE ...rpm -Fvh PACKAGE_FILE ... -U：升级或安装； -F：升级，不存在旧版程序，不执行任何操作 --oldpackage：降级； --force：强制升级； [install-options]: 所有安装时可用选项，升级亦可用 注意： 不要对内核做升级操作；Linux支持多内核版本并存，因此，直接安装新版本内核； 如果某原程序包的配置文件安装后曾被修改过，升级时，新版本的程序提供的同一个配置文件不会覆盖原有版本的配置文件，而是把新版本的配置文件重命名(FILENAME.rpmnew)后提供； 1.3 卸载：rpm {-e|--erase} [--allmatches] [--nodeps] [--noscripts] [--test] PACKAGE_NAME ... --allmatches：卸载所有匹配指定名称的程序包的各版本； --nodeps：忽略依赖关系 --test：测试卸载，dry run模式 1.4 查询：rpm {-q|--query} [select-options] [query-options] [select-options]: 通过什么查询程序包 PACKAGE_NAME：查询指定的程序包是否已经安装，及其版本； -a, --all：查询所有已经安装过的包； -f FILE：查询指定的文件由哪个程序包安装生成； -g, --group &lt;group&gt;: -p, --package PACKAGE_FILE：用于实现对未安装的程序包执行查询操作； --whatprovides CAPABILITY：查询指定的CAPABILITY由哪个程序包提供； --whatrequires CAPABILITY：查询指定的CAPABILITY被哪个包所依赖； [query-options]: 查询包的哪些信息 --changelog：查询rpm包的changlog； -l, --list：程序安装生成的所有文件列表； -i, --info：程序包相关的信息，版本号、大小、所属的包组，等； -c, --configfiles：查询指定的程序包提供的配置文件； -d, --docfiles：查询指定的程序包提供的文档； --provides：列出指定的程序包提供的所有的CAPABILITY； -R, --requires：查询指定的程序包的依赖关系； --scripts：查看程序包自带的脚本片断； 用法： 查询已安装包: -qi PACKAGE, -qf FILE, -qc PACKAGE, -ql PACKAGE, -qd PACKAGE 查询未安装包: -qpi PACKAGE_FILE, -qpl PACKAGE_FILE, -qpc PACKAGE_FILE, … 1.5 校验：rpm {-V|--verify} [select-options] [verify-options] [select-options]: 同 query [verify-options] 1234567891011121314&gt; vim /usr/share/zsh/5.0.2/functions/tcp_open # 修改了 zsh 包的部分文件&gt; rpm -V zshS.5....T. /usr/share/zsh/5.0.2/functions/tcp_open# 检验结果: - S file Size differs- M Mode differs (includes permissions and file type)- 5 digest (formerly MD5 sum) differs- D Device major/minor number mismatch- L readLink(2) path mismatch- U User ownership differs- G Group ownership differs- T mTime differs- P caPabilities differ 2. 包来源合法性验正和完整性验正网络数据的合法性和完整性验证需要使用到加密技术，在后续的 web 服务章节我们会详细讲解加密算法在数据合法性和完整性上的应用，此处我们简单介绍一下。 加密算法分为对称加密，单向加密和非对称加密三类。 对称加密指的是加密和解密使用的是同一种密钥 单向加密，只要源数据发生微弱变化，加密结果会发生巨大变化，它通常用于提取指纹信息，被用作完整性验证 非对称加密，有公钥和私钥两部分组成，使用私钥加密的数据只能使用公钥解密，反之亦然。如果某人用其私钥加密了某个数据，我们用其私钥能够解密就可以说明数据来自他。 因此在包来源合法性和完整性验证过程中，包的制作者首先使用单向加密获取包的指纹信息，并将其用自己的私钥加密制作成数据签名。由于其公钥所有人都可以获取，包下载者下载包后，使用其公钥解密数字签名，如果能够解密说明包的确来自包制作者。然后在使用同样的单向加密算法，对包进行加密，将加密结果与数字签名内的指纹信息进行比对，如果相同说明包是完整的。 使用 rpm 验证包来源合法性和完整性包括如下两个步骤: 获取并导入信任的包制作者的公钥： rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 对于CentOS发行版来说公钥位于 /etc/pki/rpm-gpg 目录内 验正： 安装此组织签名的程序时，会自动执行验正； 手动验正：rpm -K PACKAGE_FILE 3. rpm 数据库重建rpm 数据库记录了所有包的基本信息，所属文件，及其所属文件的存放路径等信息。rpm 查询操作都是基于此数据库进行的。rpm 管理器数据库在/var/lib/rpm/ 下。如果数据库出现损坏，可使用 rpm 命令进行修复，修复命令如下 rpm {--initdb|--rebuilddb} [--dbpath DIRECTORY] [--root DIRECTORY] --initdb：初始化数据库，当前无任何数据库可实始化创建一个新的；当前存在数据库时不执行任何操作； --rebuilddb：重新构建，通过读取当前系统上所有已经安装过的程序包进行重新创建；无论当前是否存在，都会重新创建数据库 获取帮助： CentOS 6：man rpm CentOS 7：man rpmdb]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.1 Linux程序包管理介绍]]></title>
    <url>%2F2018%2F07%2F14%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2FLinux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Linux程序包管理介绍 本节是 Linux 包管里器的一些背景知识，目的是让大家对为什么会存在包管里器，包管理器本身有个大体上的了解。在这之后我们会详细介绍 Centos 的包管理器 rpm 的使用。本节主要包含以下内容: 为什么会有包管里器 包管理器简介 包管理器的种类 包的命令格式 包依赖关系的解决 包的可能来源 1. 为什么会有包管里器大型程序的构建是一件非常复杂的使用，为了方便的程序的管理，我们不可能将几千甚至几万行的代码放在同一个文件中；如果有 C 程序的使用经验就会知道，在编译 C 的过程，如果程序文件存在依赖关闭，则必须按照依赖顺序进行编译，否则无法编译成功。因此出现了 make,cmake 这样的工具用于帮助实现程序的编译。于此同时编译需要特殊环境和工具，编译环境的准备也不是一件容易的事，因此为方便终端用户在 Linux 上安装使用程序出现了包管理器。 所谓包管理器就是预先将程序编译好；然后将其打包成程序包。程序包的安装过程，就是将编译好的目标程序(我们称之为目标二进制格式) 的二进制程序、库文件、配置文件、帮助文件放置到特定目录中即可，rpm 的数据库会记录每个程序的每个文件及其存放位置，因此通过我们也可以通过 程序包管理器轻松实现对程序的升级，卸载和查询。 二进制的 C 程序是与平台相关的，因此只能安装与自身平台架构相同的程序包。需要注意的是程序的特定功能是在程序编译时就确定的，因此为满足不同人对程序功能的定制需求，程序包通常会按照功能进行分包；即通用的功能放在主包中，其他额外的功能放在分包中。 2. 程序包管理器2.1 程序包管里器的种类不同的主流 Linux 发行版为自家开发了特有的包管里器，目前比较流行的有如下几个，Centos主要使用 rpm，我们的介绍也以 rpm 为主 debian：dpt(dpkg), 后缀名为 .deb redhat：rpm(redhat package manager/rpm is package manager),后缀名为 .rpm S.u.S.E：rpm, “.rpm” Gentoo：ports ArchLinux：dnf 2.1 包命名格式程序包的命名方式遵循特定的规则，包含了很多信息，通过包名我们大体上就可以判断其是否符合我们需要。rpm 的包名由源代码的名称衍生而来。 源代码名称: name-VERSION.tar.gz VERSION：major.minor.release eg: redis-3.0.2.targz rpm 包名称: name-VERSION-ARCH.rpm eg: redis-3.0.2-1.centos7.x64.rpm VERSION：major.minor.release 源代码包的版本号，此处为 3.0.2 ARCH:release.os.arch rpm包的发行号，此处为 1.centos7.x64 release: rpm 包制作的版本号 os: 操作系统平台 arch: archetecture 硬件架构包括i386, x64(amd64), ppc, noarch 等 由于 rpm 存在拆包的可能，支包的命名方式是在主包的基础上添加了支包的功能说明 主包：name-VERSION-ARCH.rpm 支包：name-function-VERSION-ARCH.rpm，function 可以是 devel, utils, libs, … 2.2 依赖关系：包管理不能自动解决程序的依赖关系，因此每个程序包都有与之对应的前端工具，能自动解决安装卸载过程中的依赖关系 yum：rhel系列系统上rpm包管理器的前端工具； apt-get (apt-cache)：deb包管理器的前端工具； zypper：suse的rpm管理器前端工具； dnf：Fedora 22+系统上rpm包管理器的前端工具； lddldd /path/binary_file 作用: 查看二进制文件依赖的库文件 ldconfigldconfig 作用: 管理和查看本机的挂载库文件 -p: 显示本机已经缓存的所有可用库文件及文件路径映射关系 配置文件: /etc/ld.so.conf, /etc/ld.so.conf.d/*.conf 缓存文件: /etc/ld.so.cache 2.3 程序包的组成程序包由如下几个部分组成: 程序包的组成清单（每个程序包都单独 实现）； 文件清单 安装或卸载时运行的脚本 数据库（公共） 程序包的名称和版本； 依赖关系； 功能说明； 安装生成的各文件的文件路径及校验码信息； 等等等 /var/lib/rpm/ 2.4 获取程序包的途径我们的程序包基本都是从网络上下载获取，因此应该尽量从正规途径下载程序包，防止被植入后门。包下载之后应该尽量对其来源合法性，程序包完整性进行检查，确认没有问题后在使用。可靠的包获取途径如下所示: 系统发行版的光盘或官方的文件服务器（或镜像站点） http://mirrors.aliyun.com, http://mirrors.sohu.com, http://mirrors.163.com 项目的官方站点 第三方组织： EPEL 搜索引擎 http://pkgs.org http://rpmfind.net http://rpm.pbone.net 自动动手，丰衣足食]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.2 任务计划和周期性任务]]></title>
    <url>%2F2018%2F07%2F13%2Flinux_mt%2F10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2FLinux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[任务计划和周期性任务 Linux 中定时执行的任务有任务计划和周期性任务两种，所谓任务计划即只在未来的某时间点执行一次某任务，周期性任务则是按照特定的时间规律定期执行某任务。本节我们就来讲解Linux 中这两种任务的实现方式。因为计划任务和周期任务的执行结果会通过邮件发送给用户，因此我们首先来简单说一下邮件服务。本节内容如下所示: 本地邮件服务和使用 mailx 收发邮件 任务计划：at 和 batch 周期性任务计划：cron 1. 本地邮件服务 上图是一个QQ邮箱用户编写一封邮件，发送给一个163邮箱用户，后者接收邮件并阅读的过程。其中 smtp协议: 属于TCP/IP 上的应用层协议，完成跨网络传输邮件，是邮件服务器之间的传输协议 pop3/imap4: 是客户端与邮件服务器之间的传输协议，定义了用户向服务商查询、分组、移动、编辑等方面的操作规范 POP3是比较老的协议，而IMAP稍微新一点 mailxmailx [-s &#39;SUBJECT&#39;] username[@hostname] 作用: Mail User Agent, 用户收发邮件的工具程序； 收邮件: 不带参数使用 mailx 会进入命令行交互客户端，可用于接收邮件 发邮件: -s &#39;SUBJECT&#39;: 指定邮件的主题 username[@hostname]: 指定收件人，本地传送无需域名 附注: 默认进入交互式输入环境，填写邮件正文，也可通过输入重定向或管道指定 123456789101112131415&gt; mail # 不带参数可进入 mail 的交互模式，可查收邮件Heirloom Mail version 12.5 7/5/10. Type ? for help.&quot;/var/spool/mail/tao&quot;: 3 messages 3 new&gt;N 1 root Tue Jul 24 09:59 17/583 N 2 root Tue Jul 24 10:00 18/553 &quot;hellp&quot; N 3 root Tue Jul 24 10:00 18/556 &quot;hellp&quot;&amp; 1 # &amp; 后输入邮件编号，即可查看邮件内容&gt; mail -s &quot;welcome&quot; taothis is jerry , welcome # 交互式输入邮件内容. # 空行后接 . 或使用 ctrl+d 表示结束输入&gt; ls /var/log | mail -s &quot;subject&quot; tao # 通过管道输入邮件正文&gt; mail -s &quot;subject&quot; tao &lt; /etc/fstab # 通过输入重定向输入邮件内容 2. 任务计划2.1 at命令at [OPTION]... TIME 作用: 在 time 指定的时间运行特定命令，默认会进入交互式命令行，用于输入要执行的命令 选项: -l: 查看作业队列，相当于atq -f /PATH/FROM/SOMEFILE: 从指定文件中读取作业任务，而不用再交互式输入； -d at_id: 删除指定的作业，相当于atrm，后跟任务的 id 号，通过 atq 即可查看； -c: 查看指定作业的具体内容； -q QUEUE: 指明队列, at的作业有队列，用单个字母表示，默认都使用a队列； TIME: HH:MM [YYYY-mm-dd]: 指定具体的时间 noon, midnight, teatime, tomorrow: 使用特定的时间标识 now+num[minutes, hours, days, OR weeks]: 使用相对时间 12345678&gt; at now+2minat&gt; echo &quot;abc&quot;at&gt; &lt;EOT&gt; # 按 ctrl+d 表示结束输入job 3 at Tue Jul 24 19:06:00 2018&gt; atq2 Tue Jul 24 19:06:00 2018 a tao3 Tue Jul 24 19:06:00 2018 a tao 2.2 batch命令：batch 会让系统自行选择在系统资源较空闲的时间去执行指定的任务 3. 周期性任务计划：cron3.1 cron 简介123456789$ rpm -ql cronie/etc/cron.d/etc/cron.d/0hourly/etc/cron.deny/etc/pam.d/crond # 守护进程/etc/sysconfig/crond/usr/bin/crontab # 辅助工具/usr/lib/systemd/system/crond.service/usr/sbin/crond 周期性任务计划由 cronie 程序包提供，包括了 crond 守护进程及相关辅助工具。在定义周期性任务之前，首先需要确保crond守护进程(daemon)处于运行状态。centos7 和 centos6 检查服务运行状态的命令如下:123456789101112# centos7 使用 systemctl 查看服务运行状态&gt; systemctl status crond.service● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-07-25 08:59:13 CST; 47min ago Main PID: 1897 (crond) CGroup: /system.slice/crond.service └─1897 /usr/sbin/crond -n# centos6&gt; service crond statuscrond is running. 向crond提交作业的方式不同于at，它需要使用专用的配置文件，此文件有固定格式，不建议使用文本编辑器直接编辑此文件；要使用crontab命令。cron任务分为两类： 系统cron任务，主要用于实现系统自身的维护；需要手动编辑 /etc/crontab 文件进行任务配置 用户cron任务，可通过 crontab 命令，进行配置 3.2 系统cron的配置系统 cron 的配置文件位于 /etc/crontab，其内容如下。1234567891011121314SHELL=/bin/bash # 定义执行命令的 默认 shellPATH=/sbin:/bin:/usr/sbin:/usr/bin # 不同于用户登录后获得的环境，因此，建议命令使用绝对路径，或者自定义PATH环境变量；MAILTO=root # 执行结果邮件发送给MAILTO指定的用户# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 周期性任务定义: 每一行定义一个周期性任务，共7个字段； * * * * * user-name command to be executed * * * * * : 定义周期性时间 user-name : 运行任务的用户身份 command to be executed：要执行的任务 需要特别注意的，cron 周期性任务的执行环境跟用户登陆后的系统环境并不一样，cron 执行时默认的 PATH 为 /sbin:/bin:/usr/sbin:/usr/bin，因此，建议命令使用绝对路径，或者在脚本中自定义PATH环境变量； 3.3 用户cron的配置用户的 cron 配置文件位于 /var/spool/cron/USERNAME 与用户名同名的文件，其配置文件与系统 cron 配置文件类似，唯一的区别是在定义周期性任务时无需指明 user-name，默认是用户自己。建议使用 crontab 命令进行周期性任务的定义，因为其能自动检查语法错误，防止出错。 3.4 cron 中的时间表示法* * * * * 周期性时间有如下定义方式: 特定值: 给定时间点有效取值范围内的值，day of week和day of month一般不同时使用； *: 给定时间点上有效取值范围内的所有值；表“每..” #,#,#:逗号分隔的离散值 #-#: 短线连接开头和结束的连续取值： */#:在指定时间点上，定义步长,表示每隔多少的意思 注意： 指定的时间点不能被步长整除时，其意义将不复存在； 最小时间单位为“分钟”，想完成“秒”级任务，得需要额外借助于其它机制； 123456789# cron 时间定义示例3 * * * * # 每小时执行一次；每小时的第3分钟；3 4 * * 5 # 每周执行一次；每周5的4点3分；5 6 7 * * # 每月执行一次；每月的7号的6点5分；7 8 9 10 * # 每年执行一次；每年的10月9号8点7分；9 8 * * 3,7 # 每周三和周日；0 8,20 * * 3,70 9-18 * * 1-5*/5 * * * * # 每5分钟执行一次某任务； 3.5 crontab命令crontab [-u user] [-l | -r | -e] [-i] 作用: 编辑用户 cron 配置文件 选项 -e：编辑任务； -l：列出所有任务； -r：移除所有任务；即删除/var/spool/cron/USERNAME文件； -i：在使用-r选项移除所有任务时提示用户确认； -u user：root用户可为指定用户管理cron任务； 通知：命令运行结果将以以邮件通知给当前用户；想拒收邮件可通过如下方式实现 COMMAND &gt; /dev/null: 命令正常运行不通知用户，运行出错则通知用户 COMMAND &amp;&gt; /dev/null: 无论命令是否正常运行均不通知用户 转义：定义COMMAND时，如果命令需要用到%，需要对其转义；但放置于单引号中的%不用转义亦可； 注意: 某任务在指定的时间因关机未能执行，下次开机不会自动执行 如果期望某时间因故未能按时执行，下次开机后无论是否到了相应时间点都要执行一次，可使用anacron实现 练习1231、每12小时备份一次/etc目录至/backups目录中，保存文件 名称格式为“etc-yyyy-mm-dd-hh.tar.xz”2、每周2、4、7备份/var/log/secure文件至/logs目录中，文件名格式为“secure-yyyymmdd”；3、每两小时取出当前系统/proc/meminfo文件中以S或M开头的行信息追加至/tmp/meminfo.txt文件中；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.1 压缩打包工具]]></title>
    <url>%2F2018%2F07%2F12%2Flinux_mt%2F10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[压缩打包工具 所谓压缩就是使用精心设计的压缩算法减少文本的容量大小，这对音频与视频无效，因为它们本身就是已压缩的。Linux 有众多的压缩和打包工具，本节我们将介绍如下命令的使用： gzip/gunzip bzip2/bunzip2 xz/unxz zip/unzip 通用的打包压缩工具 tar, cpio Linux 的打包工具 1.1 gzip/gunzip/zcatgzip [OPTION]... FILE... -d：解压缩，相当于gunzip； -#：指定压缩比，默认是6；数字越大压缩比越大（1-9）； -c：将压缩结果输出至标准输出，默认 gzip 会删除源文件，只保留压缩后的文件 gzip -c FILE &gt; /PATH/TO/SOMEFILE.gz zcat GZIP_FILE 作用: 不用解压缩，直接查看压缩文件的内容 1.2 bzip2/bunzip2/bzcatbzip2 [OPTION]... FILE... -d：解压缩，相当于 bunzip2 -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：keep，保留原文件； 1.3 xz/unxz/xzcatxz [OPTION]... FILE... -d：解压缩，相当于 unxz -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：保留原文件； 2. 归档打包工具1.1 tartar [OPTION]... FILE... 选项: 可以带- 可以不带 f: 指定要生成或解包的目标文件 c: 创建归档 x: 展开归档 t: 查看归档文件的文件列表 z: 使用 gzip 压缩 j: 使用 bzip2 压缩 J: 使用 xz 压缩 C: 展开归档时，将文件展开到指定目录 用法: 创建归档 -c -f /PATH/TO/SOMEFILE.tar FILE... -cf /PATH/TO/SOMEFILE.tar FILE... 查看归档文件的文件列表 -tf /PATH/TO/SOMEFILE.tar 归档压缩 -zcf /PATH/TO/SOMEFILE.tar.gz FILE... -jcf /PATH/TO/SOMEFILE.tar.bz2 FILE... -Jcf /PATH/TO/SOMEFILE.tar.xz FILE... 展开归档: -xf /PATH/FROM/SOMEFILE.tar -xf /PATH/FROM/SOMEFILE.tar -C /PATH/TO/SOMEDIR - 解压至指定目录 附注: 无须额外指定，tar 会自动根据文件名后缀使用响应的命令进行解压缩 1.2 zip：zip/unzip 作用: 归档和压缩 后缀: .zip 12&gt; zip pam.d.zip pam.d/* # 必须指定打包压缩包含的文件&gt; unzip pam.d.zip 1.3 cpio]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.5 btrfs文件系统管理与应用]]></title>
    <url>%2F2018%2F07%2F11%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2Fbtrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[btrfs文件系统管理与应用 1. btrfs文件系统：1.1 简介 简介: Btrfs (B-tree, Butter FS, Better FS), GPL, Oracle, 2007, CoW; 核心特性： 多物理卷支持：btrfs可由多个底层物理卷组成；支持RAID，以联机“添加”、“移除”，“修改”； 写时复制更新机制(CoW)：复制、更新及替换指针，而非“就地”更新； 数据及元数据校验码：checksum 子卷：sub_volume 快照：支持快照的快照； 透明压缩： 1.2 文件系统创建：mkfs.btrfs -L ‘LABEL’ -d : raid0, raid1, raid5, raid6, raid10, single -m : raid0, raid1, raid5, raid6, raid10, single, dup -O -O list-all: 列出支持的所有feature； 属性查看： btrfs filesystem show 挂载文件系统： mount -t btrfs /dev/sdb MOUNT_POINT 透明压缩机制： mount -o compress={lzo|zlib} DEVICE MOUNT_POINT 子命令：filesystem, device, balance, subvolume]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘与文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.4 Linux中实现LVM逻辑卷与快照]]></title>
    <url>%2F2018%2F07%2F10%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2FLVM%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7%2F</url>
    <content type="text"><![CDATA[Linux中实现LVM逻辑卷与快照 LVM(Logical Volumn Manager) 逻辑卷，是将一个或多个底层块设备组织一个逻辑的工具。逻辑卷可以在使用过程中动态扩大和收缩，而不影响已经存在的文件。Centos7 默认安装下，会自动将磁盘组织成逻辑卷。本节我们就来介绍如何使用逻辑卷，将包含如下内容 LVM 简介 LVM 的创建和管理 1. LVM 的简介我们知道普通分区一旦确定之后便不能更改大小，想扩大或缩减分区，只能删除分区然后重新创建，但这势必会影响到分区上已经存在的文件。LVM 则是在物理设备(分区)的基础上添加了一层逻辑层，以达到可以动态更改容量的目的。对于那些实现无法确定磁盘使用量的情况，LVM 提供了很大的便利。但是额外的逻辑层使得 LVM 在数据恢复上变的更加困难。因此觉得LVM好的和感觉差的差不多对半开。 LVM 物理结构LVM 的物理结构如下图所示 每个物理设备首先被组织成 PV(Physical Volume) 多个 PV 合并组成 VG(Volume Group) 逻辑卷组，统一进行管理，VG 可以动态增加和删除 PV 以扩大或收缩容量 PE(Physical Extent) 是 VG 容量分配的基本单元 LV(Logical Volume) 包含特定数量的 PE，构成逻辑上的分区，可动态调整包含的PE 数，以达到动态调整分区容量的目的；包含在 LV 中的PE 称为 LE LVM 创建过程因此逻辑卷的创建，首先需要将物理设备创建为 PV，将多个 PV 创建为 VG，然后在 VG 的基础上创建 LV，LV 即是可以用来创建文件系统并挂载使用的逻辑分区。整个过程即 pv --&gt; vg --&gt; lv。LVM 由内核模块 dm, device mapper(设备映射组件)提供。下面是 pv,vg,lv 一众命令的概览。 作用 PV VG LV 创建 pvcreate vgcreate lvcreate 显示 pvdisplay vgdisplay lvdisplay 简要显示 pvs vgs lvs 删除 pvremove vgremove lvremove 降低容量 vgreduce lvreduce 添加容量 vgextend lvextend 搜索 pvscan vgscan lvscan LV 的设备文件一个逻辑卷 LV 的设备有三个，其中两个是便于访问的软连接 /dev/dm-#: LV 实际上的设备文件 /dev/VG_NAME/LV_NAME: 指向 dm-# 的软连接 /dev/mapper/VG_NAME-LV_NAME: 指向 dm-# 的软连接 2. LVM 管理下面我们开始学习pv，vg，lv 一众命令 2.1 PV 管理pvs|pvdisplays [pv_device] 作用: 显示系统上所有 pv 的基本信息 pv_device: pv 所在设备的设备文件名，显示特定 PV 信息；可选，默认显示所有 PV pvcreate /dev/DEVICE 作用: 创建 PV pvremove pv_device 作用: 删除 PV pv_device: pv 所在设备的设备文件名 2.2 VG 管理vgs|vgdisplays [vg_name] 作用: 显示系统上所有 vg 的基本信息 vg_name: 卷组名，可选，默认显示所有卷组 vgcreate [-s #] vg_name pv_device.... 作用: 创建卷组 -s: 指定PE 大小，默认4M，可用单位 kKmMgGtTpPeE vg_name: 卷组名 pv_device: pv 所在设备，可多个 vgextend vg_name pv_device.... 作用: 向 vg 添加 pv vgreduce vg_name pv_device.... 作用: 从 vg 删除 pv vgremove vg_name 作用: 删除整个卷组 2.3 LV 管理lv 的扩大或缩减不仅要调整 lv 自身大小，还需要调整 lv 上的文件系统大小。 lv 创建和删除lvs|lvdisplays [lv_device] 作用: 显示系统上所有 lv 的基本信息 lv_device: 逻辑卷lv 的设备文件；可选，默认显示所有 lv lvcreate -L #[mMgGtT] -n lv_name vg_name: 作用: 在特定卷组内创建 lv -L: 指定 lv 的大小 -n: 指定 lv 的名称 lvremove /dev/VG_NAME/LV_NAME 作用: 删除 lv 附注: 删除前需先卸载文件系统 扩展逻辑卷：扩展逻辑卷，首先需要调整逻辑卷大小，然后需要调整文件系统大小，相关命令如下 lvextend -L [+]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 扩展逻辑卷容量 -L: 指定逻辑卷大小，+ 表示增加多少，没有+直接指定变更后的总大小 eg: lvextend -L 4G /dev/myvg/mylv lvextend -L +2G /dev/myvg/mylv resize2fs /dev/myvg/mylv [size] 作用: 调整文件系统大小 size: 指定调整后大小，默认使用所有分区空间，单位有mMgGtT 缩减逻辑卷缩减逻辑卷很危险，必需离线操作，大体上需要经过如下步骤: 先确定缩减后的目标大小；并确保对应的目标逻辑卷大小中有足够的空间可容纳原有所有数据； 卸载文件系统: umount /dev/VG_NAME/LV_NAME 文件系统强制检测: e2fsck -f 缩减文件系统大小: resize2fs DEVICE # 缩减逻辑卷大小: lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 重新挂载文件系统: mount lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 缩减逻辑卷容量 -L: 指定逻辑卷大小，- 表示减少多少，没有-直接指定变更后的总大小 创建快照卷：lvcreate -L #[mMgGtT] -p r -s -n 快照卷 原卷 作用: 创建 lv 的快照卷 -L #[mMgGtT]: 指定快照卷大小 -n: 指定快照卷名称 -s: 指明创建快照卷 -p r: 设置只读 注意：快照卷是对某逻辑卷进行的，因此必须跟目标逻辑卷在同一个卷组中；无须指明卷组； 练习12345678910111213141516171819202122232425练习1：创建一个至少有两个PV组成的大小为20G的名为testvg的VG；要求PE大小为16MB, 而后在卷组中创建大小为5G的逻辑卷testlv；挂载至/users目录；&gt; pvcreate /dev/sdb&gt; pvcreate /dev/sdc&gt; vgcreate -s 16M testvg /dev/sdb /dev/sdc&gt; lvcreate -L 5G -n testlv testvg&gt; mkfs -t ext4 /dev/testvg/testlv&gt; mount /dev/testvg/testlv /users练习2： 新建用户archlinux，要求其家目录为/users/archlinux，而后su切换至archlinux用户，复制/etc/pam.d目录至自己的家目录；&gt; useradd archlinux -d /users/archlinux&gt; echo &quot;aaaa&quot;|password archlinux --stdin&gt; cp -r /etc/pam /users/archlinux练习3：扩展testlv至7G，要求archlinux用户的文件不能丢失；&gt; lvextend -L +20M /dev/testvg/testlv&gt; resize2fs /dev/testvg/testlv练习4：收缩testlv至3G，要求archlinux用户的文件不能丢失；&gt; umount /user&gt; fsck -t ext4 -f /dev/testvg/testlv&gt; resize2fs /dev/testvg/testlv 30M&gt; lvreduce -L 30M /dev/testvg/testlv&gt; mount /dev/testvg/testlv /user/archlinux练习5：对testlv创建快照，并尝试基于快照备份数据，验正快照的功能；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘与文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.3 Linux RAID]]></title>
    <url>%2F2018%2F07%2F09%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2FLinux_RAID%2F</url>
    <content type="text"><![CDATA[Linux RAID 本章，我们来了解一些更复杂的磁盘使用方式，算是前一章的进阶。本章将包含以下内容: RAID 磁盘阵列 LVM 逻辑卷 btrfs 文件系统 RAID 全称叫廉价冗余磁盘阵列（Redundant Array of Inexpensive Disks)，后因磁盘不再廉价， RAID 咨询委员会将其改名为独立磁盘冗余阵列(Redundant Array of Independent Disks)。其设计初衷是为了将多个容量较小、相对廉价的磁盘进行有机组合，从而以较低的成本获得与昂贵大容量磁盘相当的容量、性能、可靠性。RAID 主要利用数据条带、镜像和数据校验技术来获取高性能、可靠性、容错能力和扩展性。根据运用或组合运用这三种技术的策略和架构，可以把 RAID 分为不同的等级，以满足不同数据应用的需求。本节我们学习的核心就是来了解 RAID 各个等级，包括如下内容 RAID 概述 RAID 各等级的组织结构和特性 软件RAID的实现 1. RAID 概述从实现角度看， RAID 主要分为软 RAID、硬 RAID 以及软硬混合 RAID 三种。软 RAID 所有功能均有操作系统和 CPU 来完成。，没有独立的 RAID 控制 / 处理芯片和 I/O 处理芯片，效率自然最低。硬 RAID 配备了专门的 RAID 控制 / 处理芯片和 I/O 处理芯片以及阵列缓冲，不占用 CPU 资源，但成本很高。生长环境中则主要以硬 RAID为主。 RAID 中主要有三个关键概念和技术：镜像（ Mirroring ）、数据条带（ Data Stripping ）和数据校验（ Data parity ）。 镜像，将数据复制到多个磁盘，一方面可以提高可靠性，另一方面可并发从两个或多个副本读取数据来提高读性能。显而易见，镜像的写性能要稍低， 确保数据正确地写到多个磁盘需要更多的时间消耗。 数据条带，将数据分片保存在多个不同的磁盘，多个数据分片共同组成一个完整数据副本，这与镜像的多个副本是不同的，它通常用于性能考虑。数据条带具有更高的并发粒度，当访问数据时，可以同时对位于不同磁盘上数据进行读写操作， 从而获得非常可观的 I/O 性能提升 。 数据校验，利用冗余数据进行数据错误检测和修复，冗余数据通常采用海明码、异或操作等算法来计算获得。利用校验功能，可以很大程度上提高磁盘阵列的可靠性、鲁棒性和容错能力。不过，数据校验需要从多处读取数据并进行计算和对比，会影响系统性能。 不同等级的 RAID 采用一个或多个以上的三种技术，来获得不同的数据可靠性、可用性和 I/O 性能。至于设计何种 RAID （甚至新的等级或类型）或采用何种模式的 RAID ，需要在深入理解系统需求的前提下进行合理选择，综合评估可靠性、性能和成本来进行折中的选择。 2. RAID 等级在实际应用领域中使用最多的 RAID 等级是 RAID0 、 RAID1 、 RAID4 、 RAID5 、RAID10 、JBOD。接下来将逐一介绍这几个 RAID 等级 2.1 RAID0RAID0 又称条带，将数据分片保存在多个不同的磁盘，以获取读写性能的提升。其组织结构如下图所示，我们以竖向排列的磁盘表示条带。 2.2 RAID1RAID0 又称镜像，多个磁盘保存了数据的相同副本，通过冗余提供高的容错能力。其组织结构如下图所示，我们以横向排列的磁盘表示镜像，以与条带显示区分，介绍 RAID10 时更容易理解。 2.3 RAID10RAID10 指的是，先将磁盘两两分组组成 RAID1,然后将 RAID1 组织成RAID0。其组织结构如下图所示，数据先分片，在冗余保存。 2.4 RAID4RAID4 指的是有一块专门作为校验的磁盘，剩余磁盘组织成 RAID0，由校验盘提供冗余容错能力。其组织结构如下图所示，Ap,Bp等 表示校验数据块。 2.5 RAID5RAID4 有个明显的问题是，专门的校验盘负载过重。所以RAID5 将校验功能分散到了所有磁盘上。其组织结构如下图所示，校验数据块 Ap,Bp等分散在各个磁盘中。 2.6 RAID6RAID6 与 RAID5 类似，只不过有两个校验盘，能允许两块盘出现故障 2.7 JBOD JBOD 是将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘，一个存满了就存下一个。它只是简单提供一种扩展存储空间的机制，不提升存储性能，也没有提供冗余容错能力。其组织结构如下图所示。 2.8 各个 RAID 等级性能比较 级别 读性能 写性能 容错性 最少磁盘数 可用空间 RAID-0 提升 提升 降低 &gt;=2 N*min(S1,S2,..) RAID-1 提升 略有下降 有 &gt;=2 1*min(S1,S2..) RAID-4/5 提升 提升 允许坏1块磁盘 &gt;=3 (N-1)*min(S1,S2,…) RAID-6 提升 提升 允许坏2块磁盘 &gt;=4 (N-2)*min(S1,S2,…) RAID-10 提升 提升 &gt;=4 每组镜像最多只能坏一块 N*min(S1,S2,…)/2 JBOD 不变 不变 降低 &gt;=2 sum(S1,S2,…) 3. 软件RAID的实现CentOS 上软RAID的实现由 md(multi devices)模块，及其提供 mdadm 命令组成 md 模块: multidisks, 一个内核模块，用于支持将任何块设备组织成RAID mdadm 命令: 操作 md 模块的模式化工具 mdadmmdadm [mode] raiddevice [options] component-devices mode: 管理模式 -A: 装配模式，重新识别此前实现的RAID -C：创建模式，创建RAID -F：监控模式 管理模式：-f, -r, -a raiddevice: RAID设备的设备文件,通常为/dev/md#，#表示一个数字 component-devices:成员设备 支持的RAID级别: JBOD, RAID0, RAID1, RAID4, RAID5, RAID10 options: C: 创建模式中专用选项 -n #: 用于创建RAID设备的磁盘个数； -l #: 级别 -a {yes|no}: 自动为创建的RAID生成设备文件; -c Chunk_Size: 指明块大小 -x #: 指明空闲盘的个数 管理模式 mdadm /dev/md# -f /dev/some_device：将/dev/md#中的/dev/some_device手动设置为损坏 mdadm /dev/md# -r /dev/some_device：将/dev/md#中的损坏状态的/dev/some_device移除 mdadm /dev/md# -a /dev/new_device: 新增设备 装配模式 停止软件RAID：mdadm -S /dev/md# 重新启用RAID： mdadm -A /dev/md# /dev/DEVICE... mdadm的配置文件/etc/mdadm.conf RAID 设备查看 cat /proc/mdstat: 当前系统上所有已启用的软件RAID设备及其相关信息 mdadm -D /dev/md#：显示指定的软RAID的详细信息 12345# 创建一个10G空间的RAID0&gt; mdadm -C /dev/md0 -a yes -n 2 -l 0 /dev/sdb&#123;1,2&#125;# 创建大小为10G空间的RAID5 -- 3*5G，6*2G (n-1)*2G&gt; mdadm -C /dev/md1 -a yes -n 3 -l 5 /dev/sda&#123;3,5&#125; /dev/sdb3 练习1234567891011121314151617181920212223242526# centos7 GPT 分区格式练习1：创建一个可用空间为10G的RAID1设备，要求其chunk大小为128k，文件系统为ext4，有一个空闲盘，开机可自动挂载至/backup目录；&gt; fdisk /dev/nvme0n1 # 创建3个大小为 50M 的类型为 13 磁盘分区&gt; mdadm -C /dev/md0 -n 2 -l 1 -c 128K -x 1 /dev/nvme0n1p&#123;12,13,14&#125;&gt; mdadm -D /dev/md0&gt; mke2fs -t ext4 /dev/md0&gt; blkid /dev/md0/dev/md0: UUID=&quot;8d46d667-d3e2-4f5e-b918-4e6d9a576445&quot; TYPE=&quot;ext4&quot;&gt; vim /etc/fstabUUID=&quot;8d46d667-d3e2-4f5e-b918-4e6d9a576445&quot; /backup ext4 defaults,acl 0 0&gt; mount -a# 拆除 RAID&gt; umount /dev/md0&gt; mdadm -S /dev/md0练习2：创建一个可用空间为10G的RAID10设备，要求其chunk大小为256k，文件系统为ext4，开机可自动挂载至/mydata目录；&gt; fdisk /dev/nvme0n1 # 创建4个大小为 50M 的类型为 13 磁盘分区&gt; mdadm -C /dev/md0 -n 4 -l 10 -c 256K /dev/nvme0n1p&#123;12,13,14,15&#125;&gt; mkfs -t ext4 /dev/md0&gt; blkid /dev/md0/dev/md0: UUID=&quot;779bf9e4-846c-443d-970e-6a9b12a235c8&quot; TYPE=&quot;ext4&quot;&gt; vim /etc/fstabUUID=&quot;779bf9e4-846c-443d-970e-6a9b12a235c8&quot; /mydata ext4 defaults 0 0&gt; mount -a]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘与文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.2 磁盘与文件系统的管理命令]]></title>
    <url>%2F2018%2F07%2F08%2Flinux_mt%2F08-Linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[磁盘使用与文件系统管理介绍 本节，我们来学习磁盘和文件系统管理的相关命令，我们将按照从磁盘到创建一个可用的文件系统的顺序，逐步讲解相关命令的使用，内容如下: 磁盘分区 重载内核分区表 文件系统管理 挂在文件系统 其他相关命令 1. 磁盘进行分区磁盘分区管理主要有 fdisk，parted，sfdisk 三个命令。掌握一个即可，我们主要来学习 fdisk。fdisk 提供了一个交互式接口来管理分区，它有许多子命令，分别用于不同的管理功能；所有的操作均在内存中完成，不会直接同步到磁盘，直到使用w命令保存至磁盘上。fdisk 命令的使用方式如下 查看磁盘的分区信息：fdisk -l [device...] 作用: 列出指定磁盘设备上的分区情况，默认列出所有磁盘设备的分区情况 参数: device 设备文件名 cat /proc/partitions 作用: 查看内核分区信息 管理分区fdisk device 作用: 管理分区，进入 fdisk 交互式管理界面 12345678910111213141516171819202122232425# fdisk 使用示例&gt; fdisk /dev/nvme0n1WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：m命令操作 d 删除已有分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l 列出所有的分区类型 m 查看帮助信息 n 创建新分区 o create a new empty DOS partition table p 显示现有分区信息 q 不保存并退出 s create a new empty Sun disklabel t 修改分区类型 v verify the partition table w 保存并退出 x extra functionality (experts only) 2. 重载内存分区表在已经分区并且已经挂载其中某个分区的磁盘设备上创建的新分区，内核可能在创建完成后无法直接识别；需要通知内核强制重读磁盘分区表。可用命令有如下三个: partprobepartprobe [device] 作用: inform the OS of partition table changes 附注: CentOS 5 仅能使用此命令 partxpartx [-a|-u] device 作用: tell the Linux kernel about the presence and numbering of on-disk partitions 选项: -a: 向内核添加所有分区表 -u: 向内核更新分区表 -l: 列出分区表 -s, --show: 显示分区表详细信息 -n, --nr M:N: 与 -s一起使用，限制显示的行 -o, --output list: 与 -s一起使用，限制显示的列 kpartxkpartx -af device 作用: Create device maps from partition tables 3. 文件系统管理3.1 文件系统创建Windows无法识别Linux的文件系统； 因此，存储设备需要两种系统之间交叉使用时，应该使用windows和Linux同时支持的文件系统：fat32(vfat)。mkfs.vfat device mkfsmkfs -t fs_type device 作用: 通用的文件系统创建命令，内部会调用特定文件系统的创建命令 选项: -t 指定要创建的文件系统 eg: mkfs -t ext4 /dev/sda1 == mkfs.ext4 /dev/sda1 12&gt; mkfsmkfs mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.fat mkfs.minix mkfs.msdos mkfs.vfat mkfs.xfs mke2fsmke2fs [OPTIONS] device 作用: ext系列文件系统专用创建工具 选项: -t {ext2|ext3|ext4}： 指明要创建的文件系统类型 mkfs.ext4 = mkfs -t ext4 = mke2fs -t ext4 -b {1024|2048|4096}：指明文件系统的块大小； -L LABEL：指明卷标； -j： 创建有日志功能的文件系统ext3； mke2fs -j = mke2fs -t ext3 = mkfs - t ext3 = mkfs.ext3 -i #：bytes-per-inode，指明inode与字节的比率；即每多少字节创建一个Indode; -N #：直接指明要给此文件系统创建的inode的数量； -m #：指定预留的空间，百分比； -O [^]FEATURE：以指定的特性创建目标文件系统； mkswapmkswap [OPTIONS] device 作用: 创建swap文件系统 选项: -L LABEL：指明卷标 -f：强制创建 附注: Linux上的交换分区必须使用独立的swap文件系统； 且文件系统的System ID必须为82； swapon [OPTION] [DEVICE] 作用: 启用交换分区 选项: -a 启用定义在/etc/fstab文件中的所有swap设备； -p #: 指定此交换设备的优先级 swapoff DEVICE 作用: 禁用交换分区 3.2 文件系统查看和修改e2label 作用: 查看与设定 ext 系列文件系统的卷标 查看: e2label device 设定: e2label device LABEL dumpe2fsdumpe2fs [-h] device 作用: 显示 ext 系列文件系统的属性信息 选项: -h 仅显示超级块信息 tune2fstune2fs [OPTIONS] device 作用: 查看或修改ext系列文件系统的某些属性 注意：块大小创建后不可修改； 选项: -l：查看超级块的内容； -j：启动日志功能，即将 ext2 转换为 ext3； -L LABEL：修改卷标； -m #：调整预留空间百分比，后跟数字标直接表示百分之几； -O [^]FEATHER：开启或关闭某种特性； -o [^]mount_options：开启或关闭某种默认挂载选项 tune2fs -0 acl /dev/sda1: 开启访问控制列表功能 tune2fs -0 ^acl /dev/sda1: 关闭访问控制列表功能 blkidblkid 作用: 显示块设备属性，主要是显示文件系统类型 blkid device: 查看特定设备所有分区文件系统的类型和属性 blkid -L LABEL：根据LABEL定位设备 blkid -U UUID：根据UUID定位设备 3.3 文件系统检查因进程意外中止或系统崩溃等原因导致定稿操作非正常终止时，可能会造成文件损坏；此时，应该检测并修复文件系统。建议离线进行，不能让其他用户在正在修复的文件系统中读写文件。Linux 上的文件系统检测工具 fsck 同 mkfs 一样是一个通用的文件系统修复工具 fsckfsck -t fs_type device 作用: check and repair a Linux file system 选项: -t fstype: 指明文件系统类型； -a：无须交互而自动修复所有错误； -r：交互式修复 eg: fsck -t ext4 = fsck.ext4 e2fscke2fsck [OPTIONS] device 作用: ext系列文件系统的专用工具 选项: -y: 对所有问题自动回答为yes; -f：即使文件系统处于clean状态，也要强制进行检测 4. 文件系统挂载根文件系统这外的其它文件系统要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”；此目录即为“挂载点”。Linux 中用于挂载和卸载的命令是 mount,umount 挂载点，即用于作为另一个文件系统的访问入口,应该具有如下特性: 事先存在； 应该使用未被或不会被其它进程使用到的目录； 挂载点下原有的文件将会被隐藏； 4.1 文件系统挂载mount [option]... [-t fstype] [-o option] 设备 挂载点 作用: 将设备挂载至特定目录 设备: 设备文件: /dev/sda 卷标: -L 卷标 UUID: -U UUID 常用的挂载选项： -r: readonly, 只读挂载 -w: read and write， 读写挂载 -t fstype：指明要挂载的设备上的文件系统的类型；多数情况下可省略，此时mount会通过blkid来判断要挂载的设备的文件系统类型； -L LABEL：以卷标方式指定设备， mount -L MYDATA 挂载点 -U UUID: 以UUID的方式指定设备，mount -U uuid 挂载点 -a: 自动挂载所有(/etc/fstab文件中定义的)支持自动挂载的设备 -n: 默认情况下，设备挂载或卸载的操作会同步更新至/etc/mtab文件中；-n用于禁止此特性； -B --bind: 绑定到目录到另一个目录上 -o option: 挂载文件系统的选项 async：异步I/O，数据写操作先于内存完成，而后再根据某种策略同步至持久设备中 sync: 同步I/O， atime/noatime: 文件和目录被访问时是否更新最近一次的访问时间戳 auto/noauto：设备是否支持mount的-a选项自动挂载 diratime/nodiratime: 目录被访问时是否更新最近一次的访问时间戳 dev/nodev: 是否支持在此设备上使用设备； user/nouser: 是否允许普通用户挂载此文件设备 exec/noexec: 是否允许执行此设备上的二进制程序文件 suid/nosuid: 是否支持在此设备的文件上使用suid ro: 只读 rw: 读写 remount: 重新挂载，通常用于不卸载的情况下重新指定挂载选项 acl: 启用此文件系统的 acl 功能，默认不支持； defaults: 默认选项 rw, suid, dev, exec, auto, nouser, and async eg: mount -o acl DEVICE MOUNT_POINT: 挂载后启动 acl 选型 tune2fs -o acl DEVICE 为设备设定默认挂载选项，启动 acl mount -o remount,ro /dev/sda: 以只读方式重新挂载 4.2 查看已挂载的设备查看已挂载的设备可使用如下三个命令 mount cat /etc/mtab cat /proc/mounts 4.3 特殊设备挂载挂载文件mount --bind 源目录 目标目录: 作用: 可以实现将目录绑定至另一个目录上，作为其临时访问入口； 挂载光盘mount -r /dev/cdrom mount_point 光盘设备文件： IDE 接口的光盘: /dev/hdc SATA接口的光盘: /dev/sr0 符号链接文件： /dev/cdrom /dev/cdrw: rw 表示是可写光盘 /dev/dvd /dev/dvdrw: rw 表示可写 dvd 挂载本地的回环设备mount -o loop /PATH/TO/SOME_LOOP_FILE MOUNT_POINT 4.4 文件系统卸载umount device|dir 作用: 卸载设备 参数: 设备文件或挂载点 注意：正在被进程访问到的挂载点无法被卸载，要想查看设备被哪个或哪些进程所战用，可以使用如下命令 lsof MOUNT_POINT: 查看占用设备的进程 fuser -v MOUNT_POINT: 查看占用设备的用户 fuser -km MOUNT_POINT: 终止所有正在访问某挂载点的进程 4.5 自动挂载/etc/fstab文件可用于配置除根文件系统以外的其它文件系统在开机时自动挂载。每行定义一个要挂载的文件系统及相关属性，每行有 6 个字段，从左往右各个字段的含义如下。使用 mount -a 可自动挂载定义在此文件中的所支持自动挂载的设备。需要额外注意的是swap 分区的挂载点永远是 swap, 且自动使用 swapon 挂载 挂载的设备： 设备文件 LABEL=”” UUID=”” 伪文件系统名称: proc, sysfs, devtmpfs, configfs 挂载点： 文件系统类型 挂载选项： 挂载选项可以有多个，彼此间使用逗号分隔； 转储频率：作用不大，大多数是 0 0：从不转储 1: 每天转储 2: 每隔一天 自检次序： 0：不自检，额外创建的文件系统都无须自动自检 1：首先自检，通常只有根文件系统需要首先自检 2：次级自检，不同的设备可以使用同一个自检次序 3 …. 5. 其他相关命令其他命令主要包括如下几个命令: 手动创建设备文件的 mknod 命令 查看磁盘使用量的 df 命令 查看文件夹大小的 du 命令 mknodmknod [OPTION]... NAME TYPE [MAJOR MINOR] 作用: 可用于手动创建字符或块设备文件 选项: -m MODE：创建后的设备文件的访问权限 dfdf [OPTION]... [FILE]... 作用: 查看已挂载设备的磁盘使用量 选项: -l：仅显示本地挂载设备的相关信息； -h：human-readable，以易读的方式显示磁盘使用量 -i：显示inode的使用状态而非blocks -P, --portability: 使用POSIX格式输出，不会出现换行 dudu [OPTION]... [FILE]... 作用: 查看文件夹的大小 选项: -s: sumary，只显示文件夹的总大小 -h: human-readable 以人类易读方式显示容量大小 1234567练习：1、创建一个10G的分区，并格式化为ext4文件系统； (1) block大小为2048；预留空间为2%，卷标为MYDATA； (2) 挂载至/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳； (3) 可开机自动挂载；2、创建一个大小为1G的swap分区，并启动之；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘与文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.1 磁盘使用与文件系统管理介绍]]></title>
    <url>%2F2018%2F07%2F07%2Flinux_mt%2F08-Linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[磁盘使用与文件系统管理介绍 本章我们开始学习 Linux 磁盘和文件系统管理，这部分内容与操作系统原理，文件系统，磁盘硬件密切相关，内容多而且难。但是对Linux 运维而言，我们需要了解的仅仅是其中的基本概念以及如何使用命令管理分区和文件系统。因此将本章分为两个部分: 磁盘和文件系统的相关原理 磁盘和文件系统管理命令 第一部分讲解原理，属于概括性的数理总结，由于本人理解的有限，所以更加深入的内容还需要同学自己去谷歌相关的文档；第二部分是命令使用，将按照分区创建，文件系统创建管理的顺序，详细讲解管理磁盘和文件系统的所有常用命令。 磁盘是计算的五大基本组件之一，主要提供持久化存储功能。Linux 为管理磁盘，便于程序员扩展系统和用户读写磁盘数据，将磁盘管理划分成了多个层次。如同网络协议栈一样，各层级之间通过协议和接口进行规范，这样就能便于管理和扩展。这是编程领域常用的技术手段，如果两个层次无法衔接，就添加一个中间层。Linux 的磁盘管理大体分成了以下几个层次 123456789--------------------------------| 虚拟文件系统 | ---&gt; 提供了读写文件的统一接口-------------------------------| 特定的文件系统 | ---&gt; 抽象了对不同设备驱动程序的调用接口-------------------------------- ---&gt; 磁盘设备文件，提供了管理磁盘的统一接口| 磁盘设备的驱动程序 | ---&gt; 将对磁盘适配器的机器指令转换为系统调用-------------------------------- |磁盘 | 磁盘适配器| --------------------------------- 本节我们将围绕此结构，逐层讲解各层，内容如下: 抽象层次的理解 磁盘的组成和磁盘分区 文件系统的组成 1. 抽象层次的理解磁盘通常包括两个部分，一是存储数据的磁盘，另一个是与磁盘相对应的磁盘适配器，适配器相当于磁盘的控制单元，可以接收指令，并控制磁盘的寻道和读写。适配器的指令是与硬件相关的简单机器指令，与生产磁盘的硬件厂商密切相关。 所以为管理磁盘，包括其他硬件设备，都需要生产厂商提供与操作系统相适应的驱动程序。需要强调的是硬件的驱动程序是硬件厂商提供的，而不是内核开发者提供，因为硬件设备千千万万，只有厂商才最清楚他们生产的硬件设备是什么样。因此磁盘管理从发送与磁盘相关的机器指令变成了调用了相应驱动程序的系统调用。 我们知道越底层的东西越丑陋，也就越难用，想想如果你想创建一个文件，竟然需要写一个程序去调用系统调用，该多么费劲。文件系统的作用就是帮助我们管理磁盘，我们只需要调用文件系统的一条命令，就可以读写文件，而不用管数据到写到了磁盘何处。 此处还有一个问题，Linux 上的文件系统有很多，他们调用 api 可能都不一样，想想如果换一个文件系统，创建文件的函数就变了，大概编写 touch 命令的程序员就疯了，他要为所有文件系统都写一段代码。因此Linux 为统一管理所有的文件系统，创建了虚拟文件系统 vfs。可以将 vfs 理解为一个统一的框架，比如创建文件的命令就叫做 writer，此时不管什么文件系统，都要将其创建文件的调用向 vfs 注册。这样当我们调用 writer 时，vfs 就知道特定的文件系统创建文件的函数是什么，进而由 vfs 调用该函数创建文件。 因此，程序员只要调用 vfs 提供的标准接口就可以在所有的文件系统上读写文件了。了解了整个层次结构，接下来我们就来了解各个层次结构的细节。 1. 磁盘分区的作用就是将一个完成的磁盘，划分成逻辑上独立的管理单元。由于磁盘特殊的寻址特点，因此分区与磁盘的硬件结构密切相关。所以我们先来了解磁盘的硬件结构，然后再来看磁盘是如何分区的。 1.1 磁盘的类型磁盘按照生产工艺可以分为机械硬盘，固态硬盘，按照接口类型可以分为 IDE(ata)：并口，133MB/s SCSI：并口，Ultrascsi320, 320MB/S, UltraSCSI640, 640MB/S SATA：串口，6gbps SAS：串口，6gbps USB：串口，480MB/s 并口指的是同一线缆可以接多块设备；串口则是同一线缆只可以接一个设备。对于电脑的硬件架构，大家可以找不用的台式机拆开看看，这样就会有更加具体的理解。由于机械硬盘更容易理解，我们首先来看机械式硬盘的硬件结构 1.2 机械式硬盘的硬件结构 1.3 磁盘的分区结构 上面几幅图是机械硬盘结构和分区的示意图，如果不能理解可以参阅此博客 https://blog.csdn.net/u012758088/article/details/76668465 Centos5-6 中分区是以柱面为单位进行划分，而 Centos7 中分区划分的基本单位则是扇区 1.4 磁盘设备文件设备文件的主次设备号Linux 中一切接文件，所有设备都组成了设备文件,放置在 /dev 目录下，用于关联至设备的驱动程序，是设备的访问入口，能利用 Linux 中的统一接口进行管理。设备有主，次设备号 major：主设备号，区分设备类型；用于标明设备所需要的驱动程序； minor：次设备号，区分同种类型下的不同的设备；是特定设备的访问入口； 设备文件命令规则设备文件有统一的命名规则，由ICANN 规定，具体的规则如下；由于设备被检测到的顺序是可能发生变化的，设备的设备文件可能发生变化，因此除了设备文件名，Linux 还提供了其他引用设备的方式，包括卷标，UUID。 centos5 IDE: /dev/hd# SCSI,SATA,SAS,USB: /dev/sd[a-z]# [a-z]: 表示不同设备,为不同设备被检测到的次序 #: 表示不同设备上的不同分区 centos&gt;=6: 统一使用 /dev/sd[a-z]# 123&gt; /dev/nvme0n1p2 # 设备文件# 259, 2 即为设备的主次设备号brw-rw----. 1 root disk 259, 2 7月 17 09:16 /dev/nvme0n1p2 1.4 磁盘分区格式分区格式顾名思义就是如何在磁盘上表示分区。分区格式除了会影响分区的划分，还会影响操作系统的开机启动方式。早期的分区格式是 MBR，这种分区格式有分区数量和磁盘大小有限制，对于超出范围的磁盘容量无法识别。GPT 是最新的磁盘分区技术，比 MBR 更复杂，但是已经没有了 MBR 的种种限制 MBR MBR 是 Master Boot Record 的简称。如图，MBR 是磁盘的的第一个扇区，它包括如下三个部分 446bytes：包含了 bootloader 开机启动程序，用于引导启动操作系统 64bytes：分区表，每16bytes标识一个分区，一共只能有4个分区，其中又一个可作为扩展分区，用于创建其他逻辑分区； 主分区和扩展分区的标识：1-4 逻辑分区：5+ 2bytes：MBR区域的有效性标识；55AA为有效； GPTGPT 暂时我也不是很清楚，大家可以参考此片博文 https://blog.csdn.net/diaoxuesong/article/details/9406015。过段时间会补充此部分，请稍等。 2. 文件系统内核级文件系统由内核提供文件系统驱动和用户空间的文件系统管理工具组成。因为 ext4 文件系统相对容易理解，此处我们 ext4 文件系统为列，讲解文件系统的基本原理 2.1 ext4 组成部分 block inode inode表 inode bitmap, block bitmap 块组 superblock 块组描述符表(GDT) 2.2 文件查找过程2.3 链接文件链接文件值访问同一个文件不同路径，有硬链接和软链接之分 硬链接 硬链接：指向同一个inode的多个文件路径； 特性： 目录不支持硬链接； 硬链接不能跨文件系统； 创建硬链接会增加inode引用计数； 创建： ln src link_file 符号链接 符号链接：指向一个文件路径的另一个文件路径； 特性： 符号链接与文件是两人个各自独立的文件，各有自己的inode；对原文件创建符号链接不会增加引用计数； 支持对目录创建符号链接，可以跨文件系统； 删除符号链接文件不影响原文件；但删除原文件，符号指定的路径即不存在，此时会变成无效链接； 符号链接文件的大小是其指定的文件的路径字符串的字节数； 创建：ln -s src link_file lnln [-s] source dest: 作用: 创建链接文件 选项: -s 创建软链接，默认创建硬链接 2.4 文件管理操作 文件被删除： inode被标记为空闲，此inode指向的磁盘块被标记为空闲； 如果inode被引用了多次，且此次删除未使得其引用计数降低为的话，这意味着文件被删除仅删除了一个访问路径； 文件复制： 创建一个新文件，并原文件中数据在新文件指向的磁盘块中再写一次的过程； 文件移动： 在同一个分区移到：移动文件仅是改变了文件访问路径； 跨分区移到：在新分区创建文件，把数据复制过去，删除原分区数据； 2.5 文件系统挂载2.6 日志文件系统2.7 vfs 虚拟文件系统]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>磁盘与文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.6 awk使用与实战]]></title>
    <url>%2F2018%2F07%2F06%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fawk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[sed命令应用与实战 Linxu 上有文本处理三剑客grep,sed,awk。本节我们来学习最后一个命令 awk 的使用。 awk 算得上是一门编程语言，这个编程语言内有包括变量，条件判断，循环，命令等诸多语言特性。我们将按照类似 bash 脚本的方式，从变量开始逐一讲解 awk 的使用。内容概述如下: awk 命令简介 awk 变量与数组的使用 awk 程序执行逻辑，包括顺序执行，条件判断和循环 awk 内置函数 有关 awk 的使用推荐大家阅读 《sed和awk》 《Linux Shell与脚本编程指南》 1. awk 简介Centos 中的 awk 是 GNU awk即 gawk。awk 是指向 gawk 命令的软连接 12345tao@hp:~$ which awk/usr/bin/awktao@hp:~$ ll /usr/bin/awklrwxrwxrwx. 1 root root 4 5月 8 09:34 /usr/bin/awk -$ gawk 1.1 awk 处理逻辑 如上图，awk 将文件处理分成三个阶段。第一阶段由 BEGIN 标识，第三阶段由 END标志，分别位于文件处理前和文件处理之后。 文本处理位于第二阶段，awk 每次读取文件中的一行，按照内部 FS 变量标识的分割符，将行分割成多个字段。字段按照位置分别保存在 $1,$2,$3…. 等变量中，供 awk 编程使用，$0 表示整行。awk 中的字段变量如下所示 12345-----------------------------------| $0 | # 整行------------------------------------| $1 | $2 | $3 | .......| # $n 表示分隔后的第 n 个字段------------------------------------ 作为一个编程语言，awk 有一些基本的语法特性，如果你有其他编程语言的使用经验，记住这些语法特性基本上很快就能写出 awk 程序。我们以如下例子来说明这些基本特性 awk -F: &#39;/^r/{if ($3$10) {i=1;printf &quot;|%-15s |%-15s|\n&quot;,$1,$7} }&#39; /etc/passwd 使用 {} 分割代码块 控制语句的条件判断放置在 ()内 代码块内的多条语句使用;分割，按顺序从左往右执行 使用 &quot;&quot; 表示字符串 使用/pattern/ 表示使用正则表达式 如果你不懂上面说的什么意思，没有关系，我们接下来会详细介绍 awk 的语法。 1.2 awk 命令使用gawk [options] &#39;program&#39; FILE ... 作用: 文件格式化工具 选项: -F：指明输入时用到的字段分隔符； -v var=value: 自定义变量； 参数: FILE: 待处理的文本文件，可多个 program: awk 编程脚本，必须使用单引号括起 格式: &#39;PATTERN{ACTION STATEMENTS}&#39; PATTERN：过滤出要处理的行 {ACTION STATEMENTS}: 编程语句表达式 12345tao@hp:~$ awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwdrootbindaemonadm 1.3 PATTERNPATTERN 用于过滤出要处理的行，有如下几种过滤方式 empty： 作用: 空模式，匹配每一行 /regular expression/ 作用: 仅处理能够被此处的模式匹配到的行； relational expression: 作用: 关系表达式；结果为“真”才会被处理;非0值，非空均为真； /pat1/,/pat2/： 作用: 从 pat1 匹配首行到 pat2 匹配的首行之间的行 注意: 不支持类似 sed 直接给出数字的格式 startline,endline,只能通过关系表达式实现 BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次； END{}：仅在文本处理完成之后执行一次； pattern 使用示例下面是一些使用 PATTERN 的示例，可以先跳过。 1234567891011121314151617181920212223242526272829# 1. empty# 显示eth0网卡配置文件的配置信息，只显示=号后的内容；$ gawk -F= '&#123;print $2&#125;' /etc/sysconfig/network-scripts/ifcfg-eth0# 2. /regular expression/# 显示默认shell为nologin的用户；$ gawk -F: '$7~/nologin$/&#123;print $1&#125;' /etc/passwd# 显示/etc/sysctl.conf文件定义的内核参数的参数名；$ awk -F= '/^[^#]/&#123;print $1&#125;' /etc/sysctl.conf# 显示eth0网卡的ip地址；$ ifconfig eth0 | awk -F: '/inet addr/&#123;print $2&#125;' | awk '&#123;print $1&#125;'# 3. relational expression# 显示gid小于500的组；$ gawk -F: '$3&lt;500&#123;print $1&#125;' /etc/group# 4. line ranges$ awk -F: '(NR$=2&amp;&amp;NR&lt;=10)&#123;print $1&#125;' /etc/passwd$ awk -F: '/^r/,/^h/&#123;print $1&#125;' /etc/passwd# 5. BEGIN/ENDawk -F: 'BEGIN&#123;printf "%-15s|%-15s\n","user","bash"&#125;&#123;printf "%-15s|%-15s\n",$1,$7&#125;END&#123;print "---------------------------\n"&#125;' /etc/passwd# 6. 指定复杂分隔符$ ifconfig eth0 | awk 'BEGIN&#123;FS="[ :]+"&#125;/inet addr/&#123;print $4&#125;' 2. awk 编程语法2.1 变量变量特性awk 中变量具有如下特性: 区分大小的 变量直接引用，无需使用 $, $1 整体表示一个变量，存储了第一个字段的值 自定义变量可以通过 -v var=value 选项指定，也可以在program中直接定义 1234awk -v FS=: '&#123;print $1&#125;' /etc/passwd # 等同于awk -F: '&#123;print $1&#125;' /etc/passwd# -F 就是指定 FS 变量的值 内置变量awk 有众多内置变量，常见的如下所示: FS：input field seperator，默认为空白字符； OFS：output field seperator，默认为空白字符； RS：input record seperator，输入时的换行符； ORS：output record seperator，输出时的换行符；- NF：number of field，字段数量 {print NF}: 打印当前行列数 {print $NF}: 打印当前行最后一个字段的值 NR：number of record, 行数；如果 awk 后跟多个文件，这个 NR 将是所有行的累计值 FNR：各文件分别计数；行数； FILENAME：当前文件名； ARGC：命令行参数的个数； ARGV：数组，保存的是命令行所给定的各参数； 2.2 输出awk 的输出有 print,printf 两个命令 printprint item1, item2, ... 作用: 输出后跟的内容 特性: 逗号分隔符； 输出的各item可以字符串，也可以是数值；当前记录的字段、变量或awk的表达式； 如省略item，相当于print $0; printfprintf FORMAT, item1, item2, ... 作用: 格式化输出,与 C 语言的 printf 函数的使用方式完全相同，bash中也有同名命令 说明: printf 不会自动换行，需要显式给出换行控制符，\n 参数: FORMAT: 格式化字符串，表示以特定格式显示数据；包括格式符和修饰符两个部分 item1..: 被格式化的数据，FORMAT中需要分别为后面的每个item指定一个格式化符号； 格式符： %c: 显示字符的ASCII码； %d, %i: 显示十进制整数； %e, %E: 科学计数法数值显示； %f: 显示为浮点数； %g, %G：以科学计数法或浮点形式显示数值； %s：显示字符串； %u：无符号整数； %%: 显示%自身； 修饰符： #[.#]：第一个数字控制显示的宽度；第二个数字表示小数点后的精度 -: 左对齐 +：显示数值的符号 12345678$ printf "%-5.2f\n" 3.23.20$ awk 'BEGIN&#123;printf "%-5.3f\n", 32.44456&#125;'32.445$ printf "%+20.2f\n" 3.2 +3.20 2.3 操作符awk 支持几乎所有的常规操作符 算术操作符： x+y, x-y, x*y, x/y, x^y, x%y -x +x: 转换为数值； 字符串操作符：没有符号的操作符，字符串连 赋值操作符： =, +=, -=, \*=, /=, %=, ^= ++, -- 比较操作符: $, $=, &lt;, &lt;=, !=, == 模式匹配符：后接正则表达 ~：是否匹配 !~：是否不匹配 逻辑操作符： &amp;&amp; || ! 条件表达式：selector?if-true-expression:if-false-expression 123456789# 1. 算术运算$ awk 'BEGIN&#123;i=1;i++;print i^3&#125;'8# 5. 模式匹配符awk -F: '&#123;if($1 ~ /^r/)&#123;print $1&#125;&#125;' /etc/passwd# 7. 条件表达式awk -F: '&#123;$3$=1000?usertype="Common User":usertype="Sysadmin or SysUser";printf "%15s:%-s\n",$1,usertype&#125;' /etc/passwd 2.4 控制语句过程式编程语言的代码执行顺序有顺序执行，条件判断和循环。awk 中常见的控制语句语法如下所示: if(condition) {statments} if(condition) {statments} else {statements} while(conditon) {statments} do {statements} while(condition) for(expr1;expr2;expr3) {statements} break continue next 代码块使用 {}，控制语句中的条件放置在 ()内，而 代码块内顺序执行的代码使用 ; 分隔。 if-elseif(condition) statement [else statement] 1234567$ awk -F: '&#123;if($3$=1000) &#123;printf "Common user: %s\n",$1&#125; else &#123;printf "root or Sysuser: %s\n",$1&#125;&#125;' /etc/passwd$ awk -F: '&#123;if($NF=="/bin/bash") print $1&#125;' /etc/passwd$ awk '&#123;if(NF$5) print $0&#125;' /etc/fstab$ df -h | awk -F[%] '/^\/dev/&#123;print $1&#125;' | awk '&#123;if($NF$=20) print $1&#125;' while循环while(condition) statement 使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用； 123$ awk '/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;print $i,length($i); i++&#125;&#125;' /etc/grub2.cfg$ awk '/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;if(length($i)$=7) &#123;print $i,length($i)&#125;; i++&#125;&#125;' /etc/grub2.cfg do-while循环do statement while(condition) 意义：至少执行一次循环体 for循环 for(expr1;expr2;expr3) statement: 普通 for 循环 for(var in array) {for-body：遍历数组的特殊语法格式 1$ awk &apos;/^[[:space:]]+linuxefi/&#123;for(i=1;i&lt;NF;i++)&#123;if(length($i)$5)&#123;print $i,length($i)&#125;&#125;&#125;&apos; /boot/grub2/grub.cfg switch语句switch(expression) {case VALUE1 or /REGEXP/: statement; case VALUE2 or /REGEXP2/: statement; ...; default: statement} nextawk 内自动按行进行遍历，awk 内的循环主要用来遍历每行内的所有字段，next 是 awk 特有的，用来提前结束 awk 内对本行的处理而直接进入下一行； 1$ awk -F: '&#123;if($3%2!=0) next; print $1,$3&#125;' /etc/passwd 2.5 关联数组array[index-expression] index-expression: 可使用任意字符串；字符串要使用双引号； 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”，如果用于数值运算，默认为 0； 若要判断数组中是否存在某元素，要使用 index in array 格式进行； 若要遍历数组中的每个元素，要使用for循环，注意 for 循环迭代的是下标不是值； for(var in array) {for-body} 1234567891011$ awk 'BEGIN&#123;weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";for(i in weekdays) &#123;print weekdays[i]&#125;&#125;'$ ss -tan|awk '&#123;stat[$1]+=1;&#125;END&#123;for(i in stat)&#123;print i,stat[i]&#125;&#125;'$ awk '&#123;ip[$1]++&#125;END&#123;for(i in ip) &#123;print i,ip[i]&#125;&#125;' /var/log/httpd/access_log# 练习1：统计/etc/fstab文件中每个文件系统类型出现的次数；$ awk '/^UUID/&#123;fs[$3]++&#125;END&#123;for(i in fs) &#123;print i,fs[i]&#125;&#125;' /etc/fstab# 练习2：统计指定文件中每个单词出现的次数；$ awk '&#123;for(i=1;i&lt;=NF;i++)&#123;count[$i]++&#125;&#125;END&#123;for(i in count) &#123;print i,count[i]&#125;&#125;' /etc/fstab 2.6 函数函数调用使用 function_name(argu1, argu2, ...) 内置函数 数值处理： rand()：返回0和1之间一个随机数； 字符串处理： length([s])：返回指定字符串的长度； sub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其第一次出现替换为s所表示的内容； gsub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其所有出现均替换为s所表示的内容； split(s,a[,r])：以r为分隔符切割字符s，并将切割后的结果保存至a所表示的数组中； 1$ netstat -tan | awk &apos;/^tcp\&gt;/&#123;split($5,ip,&quot;:&quot;);count[ip[1]]++&#125;END&#123;for (i in count) &#123;print i,count[i]&#125;&#125;&apos;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.5 sed命令应用与实战]]></title>
    <url>%2F2018%2F07%2F05%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fsed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[sed命令应用与实战 Linux 中有文本处理三剑客 grep, egrep, fgrep：文本过滤器 sed：Stream EDitor，流编辑器，行 awk：文本格式化工具，报告生成器 前面我们已经介绍了grep 命令的使用，本节我们来讲解 sed 。sed 是基于行的文本处理工具，其处理文件使用的命令与 vim 命令行很相似由，地址定界+编辑命令组成，地址定界用于铆定要处理的行，编辑命令指定编辑操作。相比于 vim，sed 无需将整个文本加载至内存，因此 sed 更适用于文件太大而不便使用 vim 打开的情景。本节我们会详细介绍 sed 命令的使用，内容如下: sed 工作原理 sed 命令的使用 1. sed 工作原理 如图是 sed 命令工作流程的示意图。sed 有两个专用的内存空间，一个叫模式空间(Pattern Space)，用于暂存地址定界匹配到的行，这些行会被接下来的 Edit 编辑命令编辑；另一个是保持空间(Hold Space)，我的理解是这就是一个临时的交换空间，可以辅助模式空间完成多行处理。我们会在后面详细介绍如何使用保持空间完成一些高级操作。 整个处理过程是。文件按行被读取，如果不能被地址定界所匹配，默认直接输出到标准输出(1)，被匹配的行进入模式空间，被 Edit 编辑命令处理，然后输出到标准所输出(2)。如果指定了原处修改源文件的 -i 选项，原本输出到标准输出的数据流将被重定向到原文件。编辑命令中有个 p 命令，其作用是将匹配到的行复制一遍再一次输出到标准输出(3) 上述过程中，我们描述了(1)(2)(3) 三种输出到标准输出的情况，sed 的 -n 选项可以禁止(1)(2)输出到标准输出。 2 sed 使用sed [OPTION]… ‘script’ [input-file] … 说明: sed 命令由选项和处理文件的 script 脚本组成 options： -n：不输出模式空间中的内容至屏幕，具体控制见原理部分 -f /PATH： 指定包含 script 的文件，逐行执行内部的编辑命令 -r, --regexp-extended：支持使用扩展正则表达式； -i, --in-place：直接编辑原文件 ； -e script：多点编辑,可使用多次，指定多个编辑脚本，文件将按行被每个命令处理； script： 格式: 地址定界+命令，多个命令使用 “;” 隔开 地址定界 位置表示 作用 空地址 对全文进行处理 # 数字，指定行 #,# 指定行范围，从哪一行开始，哪一行结束 #,+# 从哪一行开始，往下几行；例如：3,+7 $ 最后一行，要使用 ‘’ 引用 script，否则 $ 会解释为引用变量值 1,$ 第一行到最后一行 /pattern/ 被此模式所匹配到的每一行 /pat1/,/pat2/ 第一次由pat1匹配到的行，至第一次由pat2匹配到的行之间的所有行 #，/pat1/ # 指定的行到/pat1/匹配到的第一行之间的行 a～b 步进,从 a 行开始，每隔 b 取一行 1~2 所有奇数行 2~2 所有偶数行 编辑命令： d：删除模式空间中的内容 p：额外显示模式空间中的内容； a \text：在匹配行后面追加文本“text”，支持使用\n实现多行追加； i \text：在匹配行前面插入文本“text”，支持使用\n实现多行插入； c \text：把匹配到的行替换为此处指定的文本“text”； w /PATH：保存模式空间匹配到的行至指定的文件中； r /PATH：读取指定文件的内容至当前文件被模式匹配到的行后面；文件合并； eg: sed &#39;6r /home/tao/log.csv&#39; /etc/fstab =：为模式匹配到的行打印行号； !：条件取反；位于编辑命令之前，表示地址定界之前的行 格式: 地址定界!编辑命令； eg: sed &#39;/^UUID/!d&#39; /etc/fstab s///：查找替换，其分隔符可自行指定，常用的有s@@@, s###等； 替换标记： g：全局替换； w /PATH/TO/SOMEFILE：将替换成功的结果保存至指定文件中； p：显示替换成功的行； eg: sed &#39;/^UUID/s/UUID/uuid/g&#39; /etc/fstab sed &#39;s@r..t@&amp;er@&#39; /etc/passwd – &amp; 后项引用前面匹配到的内容 sed &#39;s@r..t@&amp;er@p&#39; /etc/passwd – 仅仅打印被替换的行 结合保持空间的高级编辑命令 命令 作用 h 把模式空间中的内容覆盖至保持空间中 H 把模式空间中的内容追加至保持空间中 g 把保持空间中的内容覆盖至模式空间中 G 把保持空间中的内容追加至模式空间中 x 把模式空间中的内容与保持空间中的内容互换 n 覆盖读取匹配到的行的下一行至模式空间中 N 追加读取匹配到的行的下一行至模式空间中 d 删除模式空间中的行 D 删除多行模式空间中的所有行 sed 多点编辑的执行逻辑1234567891011# 输出第二行内容&gt; sed -n -r &apos;6p&apos; fstab&gt; # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# 对第六行执行替换，但是 -n 禁止了输出&gt; sed -r -n -e &apos;6s/Access/aaaa/&apos; fstab&gt;# 第六行被第一个 script 执行了替换，替换后的内容被第二个 script 输出&gt; sed -r -n -e &apos;6s/Access/aaaa/&apos; -e &apos;6p&apos; fstab&gt; # aaaaible filesystems, by reference, are maintained under &apos;/dev/disk&apos; 3. 示例：普通用法示例123456789# 删除/boot/grub/grub2.cfg文件中所有以空白字符开头的行的行首的所有空白字符；&gt; sed &apos;s@^[[:space:]]\+@@&apos; /etc/grub2.cfg# 删除/etc/fstab文件中所有以#开头的行的行首的#号及#后面的所有空白字符；&gt; sed &apos;s@^#[[:space:]]*@@&apos; /etc/fstab# 输出一个绝对路径给sed命令，取出其目录，其行为类似于dirname；&gt; echo &quot;/var/log/messages/&quot; | sed &apos;s@[^/]\+/\?$@@&apos;&gt; echo &quot;/var/log/messages&quot; | sed -r &apos;s@[^/]+/?$@@&apos; 使用保持空间的高级示例12345678sed -n &apos;n;p&apos; FILE：显示偶数行；sed &apos;1!G;h;$!d&apos; FILE：逆序显示文件的内容；sed ’$!d&apos; FILE：取出最后一行；sed &apos;$!N;$!D&apos; FILE：取出文件后两行；sed &apos;/^$/d;G&apos; FILE：删除原有的所有空白行，而后为所有的非空白行后添加一个空白行；sed &apos;n;d&apos; FILE：显示奇数行；sed &apos;G&apos; FILE：在原有的每行后方添加一个空白行；sed -n &apos;1!G;h;$p&apos;: 逆序显示文件的内容；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.4 文本处理命令]]></title>
    <url>%2F2018%2F07%2F04%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[文本处理命令 1. 文本处理工具trtr [OPTION]... SET1 [SET2] 作用: 将输入中 SET1中的每个字符替换SET2中的每个字符，字符是顺序替换 如果SET1的字符长度大于SET2，那么将SET1中多出来的字符用SET2中的最后一个字符替换 参数: -t: 将SET2中的每个字符替换SET1中的每个字符，字符字符顺序1对1替换，无论SET1还是SET2哪个长，只替换对应的字符，多出的不替换。 -c: 取反操作，取数据流中SET1中指定字符的补集。 -d: 删除SET1中指定的字符，这里没有SET2 -s: 将SET1中指定的连续的连续重复的字符用单个字符替代，可以使用-s ‘\n’删除空行。 字符编码集: [:alpha:]：字母，可以用来替代’a-zA-Z’ [:lower:]：小写字母,可以用来替代’a-z’ [:upper:]：大写字母,可以用来替代’A-Z’ [:digit:]：数字,可以用来替代’0-9’ [:alnum:]：字母和数字,可以用来替代’a-zA-Z0-9’ [:space:]：空白字符 [:punct:]：标点符号 [:xdigit:]：十六进制字符 [:cntrl:]：控制（非打印）字符 [:print:]：可打印字符 [:graph:]：图形字符 wcwc [-clw] [FILE...] 作用: 用于计算字数，可以计算文件的Byte数、字数、或是列数 若不指定文件名称、或是所给予的文件名为”-“，则wc指令会从标准输入设备读取数据 参数: -c, --bytes, --chars; 只显示Bytes数。 -l, --lines: 只显示行数。 -w, --words: 只显示单词数 cutcut [-df] [file] 作用: 从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出 参数： -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示的区域，表示方式如下: n：指定的单个字段 n-m：连续的多个字段 n,m：离散的多个字段 -c ：以字符为单位进行分割 eg: cut -d: -f1,3-5,7 /etc/passwd sortsort [-frtknu] [file] 作用: 针对文本文件的内容，以行为单位来排序 参数: -t: 指定分隔符 -k POS1[,POS2]: 用于排序比较的字段 -f: 排序时，忽略大小写 -r: 逆序排序 -n: 基于数值大小而非字符进行排序 -u: 排序并去重 -b: 忽略每行前面开始出的空格字符 -c: 检查文件是否已经按照顺序排序。 -d: 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -m: 将几个排序好的文件进行合并 -o: 将排序后的结果存入指定的文件 uniquniq [-cdufsw][输入文件][输出文件] 作用: 检查文本文件中重复出现的行列 只有连续且一致的行才算重复行 参数: -c,--count: 显示每行的重复次数 -d, --repeated: 仅显示重复过的的行 -u, --unique: 仅显示未曾重复过的行 diff 和 patchdiff [OPTION]... FILES 作用: 按行比较文件 选项: -u: 使用unfied机制，即显示要修改的行的上下文，默认为3行； 补丁: diff /PATH/TO/OLDFILE /PATH/TO/NEWFILE &gt; /PATH/TO/PATCH_FILE patch -i /PATH/TO/PATCH_FILE /PATH/TO/OLDFILEpatch /PATH/TO/OLDFILE &lt; /PATH/TO/PATCH_FILE 作用: 向文件打补丁 patch -R /PATH/TO/PATCH_FILE /PATH/TO/OLDFILE 作用: 撤消补丁]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.3 grep命令与正则表达式]]></title>
    <url>%2F2018%2F07%2F03%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fgrep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[grep命令与正则表达式 Linux 中有文本处理三剑客grep,sed,awk，它们都会用到正则表达式。bash 中正则表达式分为基础正则表达式和扩展的正则表达式。本节我们来学习 grep 命令与基本的正则表达式。 1. grepgrep 存在一组相关命令 grep: 支持基本的正则表达式 == grep -G egrep: 支持扩展的正则表达式 == grep -E fgrep: 不支持正则表达式，匹配速度快 == grep -F，无须转义 grep [-acinvAB] pattern filename -o：仅显示匹配到字符串本身 -a：将 binary 文件已 text 文件的方式查找数据 -c：计算找到”查找字符串” 的次数 -i：忽略大小写 -n：输出行号 -v：反向匹配 -q：静默模式，不输出匹配的文本，通过 echo $? 获取是否匹配成功 -A：after，后接数字，列出匹配行及之后 n 行 -B：before，后接数字，列出匹配行及之前 n 行 -C：context，上下文，列出匹配前后各 n 行 --color=auto：将找到的关键词高亮显示 2. 基础正则表达式基础正则表达式大致上可以分为四类: 字符匹配 匹配次数 位置锚定 分组及引用 需要额外说明的是下面的\转义符是必须的，因为这些元字符在 bash 中有特殊含义，需要转义。 字符匹配 元字符 作用 . 匹配任意单个字符 [] 匹配指定范围内的任意单个字符 [^] 匹配指定范围外的任意单个字符 [[:digit:]] 数字 [[:lower:]] 小写字母 [[:upper:]] 大写字母 [[:alpha:]] 字母 [[:alnum:]] 数字+字母 [[:punct:]] 特殊符号 [[:space:]] 空白字符 匹配次数用在要指定其出现的次数的字符的后面，用于限制其前面字符出现的次数；默认工作于贪婪模式； 元字符 作用 * 匹配其前面的字符任意次；0,1,多次 .* 匹配任意长度的任意字 \? 匹配其前面的字符0次或1次；即其前面的字符是可有可无的 \+ 匹配其前面的字符1次或多次；即其面的字符要出现至少1次 \{m\} 匹配其前面的字符m次 \{m,n\} 匹配其前面的字符至少m次，至多n次 \{0,n\} 至多n次 \{m,\} 至少m次 位置锚定匹配单词或句子的首部或尾部 元字符 作用 ^ 行首锚定；用于模式的最左侧 $ 行尾锚定；用于模式的最右侧 ^PATTERN$ 用于PATTERN来匹配整行 ^$ 匹配空白行 ^[[:space:]]*$ 空行或包含空白字符的行 \&lt; 或 \b 词首锚定，用于单词模式的左侧 \&gt; 或 \b 词尾锚定，用于单词模式的右侧 \&lt;PATTERN\&gt; 匹配完整单词 分组及引用\(\): 将一个或多个字符捆绑在一起，当作一个整体进行处理 分组括号中的模式匹配到的内容会被正则表达式引擎自动记录于内部的变量中，比如： \1：表示模式从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \2：表示模式从左侧起，第二个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \n：其他一次类推，这种引用前面的分组括号中的模式所匹配到的字符叫做后向引用 12345678910111213141516171819202122练习：# 显示/etc/passwd文件中不以/bin/bash结尾的行；&gt; grep -v &quot;/bin/bash$&quot; /etc/passwd# 找出/etc/passwd文件中的两位数或三位数；&gt; grep &quot;\&lt;[0-9]\&#123;2,3\&#125;\&gt;&quot; /etc/passwd# 找出/etc/rc.d/rc.sysinit或/etc/grub2.cfg文件中，以至少一个空白字符开头，且后面非空白字符的行；&gt; grep &quot;^[[:space:]]\+[^[:space:]]&quot; /etc/grub2.cfg# 找出&quot;netstat -tan&quot;命令的结果中以&apos;LISTEN&apos;后跟0、1或多个空白字符结尾的行；&gt; netstat -tan | grep &quot;LISTEN[[:space:]]*$&quot;&gt; vim a.txtHe loves his lover.He likes his lover.She likes her liker.She loves her liker.&gt; grep &quot;\(l..e\).*\1&quot; a.txtHe loves his lover.She likes her liker. 3. 扩展正则表达式扩展正则表达式与基本正则表达式主要有两点区别 不需要额外的转义符\,词首词尾锚定仍为 \&lt;,\&gt;, \b 支持 | 表示或 a|b：a或者b； C|cat：C或cat (c|C)at：cat或Cat 123456789101112131415161718192021222324# 练习：# 1. 找出/proc/meminfo文件中，所有以大写或小写S开头的行；至少有三种实现方式；&gt; grep -i &quot;^s&quot; /proc/meminfo&gt; grep &quot;^[sS]&quot; /proc/meminfo&gt; grep -E &quot;^(s|S)&quot; /proc/meminfo# 2. 显示肖前系统上root、centos或user1用户的相关信息；&gt; grep -E &quot;^(root|centos|user1)\&gt;&quot; /etc/passwd# 3. 找出/etc/rc.d/init.d/functions文件中某单词后面跟一个小括号的行；&gt; grep -E -o &quot;[_[:alnum:]]+\(\)&quot; /etc/rc.d/init.d/functions# 4. 使用echo命令输出一绝对路径，使用egrep取出基名；&gt; echo /etc/sysconfig/ | grep -E -o &quot;[^/]+/?$&quot;# 5. 进一步：取出其路径名；类似于对其执行dirname命令的结果；# 6. 找出ifconfig命令结果中的1-255之间的数值；&gt; ifconfig | grep -E -o &quot;\&lt;([1-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\&gt;&quot;# 7. 课外作业：找出ifconfig命令结果中的IP地址；# 8. 添加用户bash, testbash, basher以及nologin(其shell为/sbin/nologin)；找出/etc/passwd文件中用户名同shell名的行；&gt; grep -E &quot;^([^:]+\&gt;).*\1$&quot; /etc/passwd]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.2 文件查找工具]]></title>
    <url>%2F2018%2F07%2F02%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2F%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[文件查找工具 本节我们学习文件查找工具，主要是两个命令的使用 locate，find。 1. locatelocate [OPTION]... PATTERN... 作用: 依赖于事先构建好的索引库；查找指定模式匹配的文件 规则: 默认使用 pattern 进行全路径模糊匹配 参数: PATTERN: 匹配规则，可多个 选项: -a：所有 pattern 的匹配规则必须同时满足 -b：只匹配路径中的基名，默认匹配整个路径； -c：统计出共有多少个符合条件的文件 -r：使用基本正则表达式进行匹配 特性： 查找速度快； 模糊查找； 非实时查找； updatedb: 作用: 构建 locate 所需的数据库(耗费资源) 附注: 索引构建过程需要遍历整个根文件系统，极消耗资源； 2. findfind [OPTION]... [查找起始路径] [查找条件] [处理动作] 查找起始路径：指定具体搜索目标起始路径；默认为当前目录； 查找条件：指定的查找标准，可以根据文件名、大小、类型、从属关系、权限等等标准进行；默认为找出指定路径下的所有文件； 处理动作：对符合查找条件的文件做出的操作，例如删除等操作；默认为输出至标准输出； 查找条件find 的查找条件可以通过选型或测试进行指定，较为常用的是测试，有如下几种测试条件 文件名: -name &quot;pattern&quot;: 支持使用通配符，仅仅匹配文件名称，必须是完全匹配文件名而不是部分匹配 -iname &quot;pattern&quot;: 忽略名称大小，必须是完整匹配文件名 -regex pattern: 使用正则表达式，必须完整匹配整个文件路径，不仅仅是文件名称 根据属主，属组 -user username: 查找属主为指定用户的文件 -group groupname: 查找属组为指定组的文件 -uid userid: 查找属主为指定 uid 的文件 -gid groupid: 查找属组为指定 gid 的文件 -nouser: 查找没有属主的文件 -nogroup: 查找没有属组的文件 eg: find /tmp -user root -ls 根据文件类型查找 -type TYPE: 查找指定类型的文件 f: 普通文件 d: 目录文件 l：符号链接文件 b：块设备 文件 c：字符设备文件 p：管道文件 s：套接字文件 组合条件 -a : and -o : or -not|！ : not eg： find /tmp \( -nouser -o -nogroup \) -ls find /tmp -nouser -ls -o -nogoroup -ls find /tmp \( -not -user root -a -not -name &quot;fstab&quot; \) -ls 附注: 处理动作仅限于位置相关的查找 文件大小 -size [+|-]#UNIT: UNIT: 查找单位，k，M，G eg: find /var -size +3k -exec ls -h {} \ 3k: 表示范围为 (2k, 3k] -3k: 表示范围为 [0, 2k] +3k: 表示范围为 (3k, ∞) 根据时间戳 以天为单位 -atime [+|-]# -mtime [+|-]# -ctime [+|-]# eg: find /var -atime 3 -ls 3: 表示[3, 4) +3 表示[4, ∞) -3 表示[0, 3） 以分钟为单位 -amin [+|-]# -mmin [+|-]# -cmin [+|-]# 根据权限查找 -perm [/|-]MODE eg: find /var -perm 640 -ls 640: 精确查找，0表示不考虑 /640: 任何一类用户(u,g,o)的权限中的任何一位(r,w,x)符合条件即满足，9位权限之间存在“或”关系； -640: 每一类用户(u,g,o)的权限中的每一位(r,w,x)同时符合条件即满足，9位权限之间存在“与”关系； 处理动作 -print: 默认动作，显示至屏幕 -ls: 类似对查找的文件执行 ls -l 命令 -delete: 删除查到到的文件 -fls /path: 查找到的所有文件的长格式信息保存至指定文件中 -ok COMMAND {} \; 对查找到的每个文件执行由 COMMAND指定的命令 对每个文件执行命令之前，都会交互式确认 {}：表示find 传递的文件名本身 \;:固定格式符 exec COMMAND {} \;:作用同 ok,但不会交互式确认 eg: find /tmp -nouser -exec chown root {} \; find /tmp -cmin -5 -exec mv {} {}.new \; {}：表示find 传递的文件名本身 需要注意的是 find 传递查找到的文件路径至后面的命令时，是先查找出所有符合条件的文件路径，并一次性传递给后面的命令；但是有些命令不能接受过长的参数，此时命令执行会失败；使用 find | xargs COMMAND 可规避此问题。xargs 命令可将参数一次一个传递给 COMMAND。 3. 练习123456789101112131415161718192021222324# 查找/var/目录属主为root且属组为mail的所有文件；&gt; find /var -user root -a -group mail# 查找/usr目录下不属于root、bin或hadoop的所用文件；&gt; find /usr -not -user root -a -not -user bin -a -not -user hadoop&gt; find /usr -not \(-user root -o -user bin -o -user hadoop\)# 查找/etc/目录下最近一周内其内容修改过的，且不属于root且不属于hadoop的文件；&gt; find /etc -mtime -7 -a -not \(-user root -o -user hadoop\)# 查找当前系统上没有属主或属组，且最近1个月内曾被访问过的文件；&gt; find / \(-nouser -o -nogroup\) -a -atime -30# 查找/etc/目录下大于1M且类型为普通文件的所有文件；&gt; find /etc -size +1M -type f# 查找/etc/目录所有用户都没有写权限的文件；&gt; find /etc/ -not -perm /222# 查找/etc/目录下至少有一类用户没有写权限；&gt; find /etc/ -not -perm -222# 查找/etc/init.d/目录下，所有用户都有执行权限且其它用户有写权限的文件；&gt; find /etc/init.d/ -perm -113]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.1 vim使用]]></title>
    <url>%2F2018%2F07%2F01%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fvim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[vim使用 本章我们将学习与文本操作相关内容，包括: 文本处理相关命令 文本查找相关命令 正则表达式 vim 编辑器 vim(vi) 是 Linux 下最常用的文本编辑器，拥有众多快捷键和命令，学习曲线很陡峭。下面两幅图是 vim 快捷键的便捷记忆图。本节内容如下: 认识 vim 的三种模式 编辑模式又称命令模式 输入模式 末行模式 vim 编辑模式的常用命令 vim 末行模式的使用 vim 高级用法 vim 配置 1. 认识 vim 的三种模式1.1 vim 三种模式的转换默认使用 vim 打开文件后会进入编辑模式，编辑模式下不能使用退格和键盘直接修改文本内容，但是可以使用特定命令实现编辑功能。输入模式即我们通常可以使用键盘直接文本的模式，而末行模式，则是我们可以在 vim 的最后一行输入 vim 特有的命令实现编辑功能。三种模式使用特定命令可以实现转换。 编辑模式 –&gt; 输入模式 命令 作用 i insert, 在光标所在处输入 a append，在光标在处后方输入 o 在光标所在处的下方打开一个新行 I 在光标所在行的行首输入 A 在光标所在行的行尾输入 O 在光标所在处的上方打开一个新行 其他的模式转换 编辑模式 –&gt; 末行模式: : 输入模式 –&gt; 编辑模式: ESC 末行模式 –&gt; 编辑模式: ESC 末行模式与输入模式不能直接转换 1.2 使用 vin 打开和关闭文件使用 vim 打开文件vim [OPTION] .... FILE ..... +#：打开文件后，光标定位到 # 行，不加行号默认定位到最后一行 +/PATTERN: 打开文件后，光标处于 pattern 匹配到的第一行 vim 中保存文件 ZZ: 在编辑模式下直接保存并退出； :q: 退出 :w： 保存 :q!: 强制退出，不保存此前的编辑操作 :wq: 保存并退出； :x: 保存并退出； :w /PATH/TO/SOMEFILE 2. vim 编辑模式的常用命令vim 编辑模式下的常用命令大体可以分为分为光标跳转，编辑命令，其他命令三类。大多数命令都可以使用类似 nCOMMAND 的方式，即在命令前加上数字，表示重复执行该命令 n 次。对于能这样使用的命令，下面将直接标注为 nCOMMANDA。 Linux 有个vim自带的练习教程叫 vimtutor 2.1 光标跳转所谓光标跳转即让光标从当前位置迅速跳转到特定位置，包括字符跳转，单词跳转，行首行尾跳转，行间跳转，句间跳转，段落跳转。 字符间跳转nCOMMAND 跳转由 n 指定的个数的字符； 命令 作用 h 左，支持 nCOMMAND j 下，支持 nCOMMAND k 上，支持 nCOMMAND l 右，支持 nCOMMAND 单词间跳转 命令 作用 w 下一个单词的词首，支持nCOMMAND e 当前或后一个单词的词尾，支持nCOMMAND b 当前或前一个单词的词首，支持nCOMMAND 行首行尾跳转 命令 作用 ^ 跳转至行首的第一个非空白字符 0 跳转至行首 $ 跳转至行尾 行间跳转 命令 作用 nG 跳转至由 n 指定的行 1G, gg 跳转到第一行 G 跳转到最后一行 句间跳转： ): 跳转到句尾 (: 跳转到句首 段间跳转 }: 跳转到段尾 {: 跳转到段首 2.2 编辑命令编辑命令指删除特定字词句，这部分命令可结合跳转命令实现批量修改。 字符编辑： 命令 作用 x 删除光标所在处的字符 nx 删除光标所在处起始的 n 个字符 xp 交换光标所在处的字符与其后面的字符的位置 rCHAR replace,使用 CHAR 字符替换光标所在处的字符 删除命令d delete 删除命令，可结合光标跳转字符，实现范围删除，支持 nCOMMANDA 命令 作用 d$ 删除光标到行尾 d^ 删除光标到非空白首部 dw 删除光标到下个词词首 ndw 删除光标到下 n 个词词首 de 删除光标到当前词词尾 db 删除光标到当前词词首 dd 删除光标所在处的行 ndd 删除光标所处的行起始的共 n 行 粘贴命令：p (put, paste) 粘贴命令 命令 作用 p 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的下方；否则，则粘贴至当前光标所在处的后方 P 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的上方；否则，则粘贴至当前光标所在处的前方 复制命令y yank 复制命令，工作行为相似于d命令； 命令 作用 y$ 复制光标到行尾 y^ 复制光标到非空白首部 yw 复制光标到下个词词首 nyw 复制除光标到下 n 个词词首 ye 复制光标到当前词词尾 yb 复制光标到当前词词首 yy 复制光标所在处的行 nyy 复制除光标所处的行起始的共 n 行 改变命令c change 改变命令，功能同 d 命令，操作完成后会从编辑模式切换到输入模式 命令 作用 c$ 删除光标到行尾 c^ 删除光标到非空白首部 cw 删除光标到下个词词首 ncw 删除光标到下 n 个词词首 ce 删除光标到当前词词尾 cb 删除光标到当前词词首 cc 删除光标所在处的行 ncc 删除光标所处的行起始的共 n 行 2.3 其它编辑操作其他编辑操作如下 可视化模式可视化模式，可让用户在编辑模式下，非整行扩行选定文本片段 v,箭头: 按住 v 后，使用箭头按字符选定文本； V,箭头: 按住 V 后，使用箭头按行选定文本； 附注: 结合编辑命令 d, c, y，实现选定区域的删除复制 撤销和重复执行 命令 作用 u undo 撤销此前的操作 #u 撤销此前的#个操作 Ctrl+r recover 撤销此前的撤销 . 重复执行前一个编辑操作 3. vim 末行模式的使用vim末行模式，是 vim 内建的命令行接口，通过地址定界和之前介绍的编辑命令，可实现批量操作。所谓地址定界即选择出特定范围的行。除此之外 vim 还能实现保存，查找，替换等诸多功能。 3.1 地址定界地址定界的格式是 :start_pos[,end_pos]，位置的表示可以是数字也可以是正则表达式，具有多种表达方式 位置表示 作用 # 数字，表示特定的第#行，例如5即第5行 #,# 指定行范围，左侧为起始行，右侧为结束行 #,+# ：指定行范围，左侧为超始行绝对编号，右侧为相对左侧行号的偏移量；例如：3,+7 . 表示当前行 $ 最后一行 .,$-1 当前行到倒数第二行 1,$ 第一行到最后一行，即全文 % 全文，等同于 1,$ /pattern/ 从光标所在处起始向文件尾部第一次被模式所匹配到的行, 例如/first/,$ /pat1/,/pat2/ 从光标所在处起始，第一次由pat1匹配到的行开始，至第一次由pat2匹配到的行结束之间的所有行 地址定界可同编辑命令 d,y,c一同使用，实现编辑操作。例如 :1,20d 删除 1 到 20 行。 3.2 保存和加载末行模式中保存和加载其他文件的常用命令如下 命令 作用 :q 退出 :w 保存 :q! 强制退出，不保存此前的编辑操 :wq 保存并退出 :x 保存并退出 :w /PATH/TO/SOMEFILE 将文本保存至指定的文件中，可通过地址定界选定保存的文本范围 :r /PATH/FROM/SOMEFILE 将指定的文件中的文本读取并插入至指定位置 3.3 查找通过 / 或 ？ 命令，可在 vim 中实现查找 /PATTERN：从当前光标所在处向文件尾部查找能够被当前模式匹配到的所有字符串； ?PATTERN：从当前光标所在处向文件首部查找能够被当前模式匹配到的所有字符串； 查找后，可使用 n，N 查找下一个 n：查找下一个，表示与命令方向相同的下一个； N：查找上一个，表示与命令方向相反的上一个； 3.4 查找并替换末行模式中通过 s 命令可实现替换功能，s 命令的使用格式如下::地址定界s/要查找的内容/替换为的内容/修饰符 要查找的内容：可使用基本正则表达式； 替换为的内容：不能使用下则表达式，但可以引用； 修饰符： i：忽略大小写； g：全局替换，意味着一行中如果匹配到多次，则均替换； 分隔符/:可把替换为其它非常用字符@ 或 #： s@@@ s### 引用: 如果”要查找的内容”部分在模式中使用了分组符号可在”替换为的内容”中使用后向引用； 直接引用查找模式匹配到的全部文本，要使用&amp;符号； 示例: %s@\&lt;t\([[:alpha:]]\+\)\&gt;@T\1@g: 将以小写 t 开头的字母替换为大写 T开头 %s@\&lt;t[[:alpha:]]\+\&gt;@&amp;er@g: 在所哟单词后面加上 er 123456789101112131415练习：# 1. 复制/etc/grub2.cfg文件至/tmp目录中，用查找替换命令删除/tmp/grub2.cfg文件中以空白字符开头的行的行首的空白字符；&gt; %s@^[[:space:]]\+@@&gt; %s/^[[:space:]]\+//# 2. 复制/etc/rc.d/init.d/functions文件至/tmp目录中，用查找替换命令为/tmp/functions文件的每个以空白字符开头的行的行首加上#；&gt; %s@^[[:space:]]\+[^[:space:]]@#&amp;@g&gt; %s/^([[:space:]]\+)/#&amp;/g# 3. 为/tmp/grub2.cfg文件的前三行的行首加上#号；&gt; 1,3s/.*/#&amp;/g# 4. 将/etc/yum.repos.d/CentOS-Base.repo文件中所有的enabled=0替换为enabled=1，所有gpgcheck=0替换为gpgcheck=1；&gt; %s/\(enabled\|gpgcheck\)=0/\1=1/g&gt; %s@\(enabled\|gpgcheck\)=0@\1=1@g 4. vim 高级用法多文件模式vim /tmp/{file1，file2} :next: 切换至下一文件 :prev: 切换至上一个文件 :last: 切换至最后一个文件 :first: 切换至第一个文件 :wall：保存所有 :qall：退出所有 :wqall: 保存并退出所有 窗口分割vim -o FILE1 FILE2.... 水平分割vim -O FILE1 FILE2.... 垂直分割 Ctrl + w 松开后，加箭头: 切换窗口 Ctrl + w, s: 水平分割当前文件 Ctrl + w, v: 垂直分割当前文件 5. vim 配置vim 的配置可在末行模式下设定，此时仅对当前vim进程有效；要想永久有效可编辑配置文件 全局配置：/etc/vimrc 用户个人配置：～/.vimrc vim 中常见的配置选项 作用 配置 行号 显示：set number, 简写为set nu 取消显示：set nomber, set nonu 括号匹配高亮 匹配：set showmatch, set sm取消：set nosm 自动缩进 启用：set ai禁用：set noai 高亮搜索 启用：set hlsearch禁用：set nohlsearch 语法高亮 启用：syntax on禁用：syntax off 忽略字符大小写 启用：set ic禁用：set noic]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>文本处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.9 脚本示例与练习]]></title>
    <url>%2F2018%2F06%2F29%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[脚本示例与练习 本节是一些常用的脚本示例，可供我们学习参考 1. 条件判断练习更改主机名将当前主机名称保存至hostName变量中；主机名如果为空，或者为localhost.localdomain，则将其设置为www.magedu.com；12&gt; hostName=$(hostname)&gt; [ -z &quot;$hostName&quot; -o &quot;$hostName&quot; == &quot;localhost.localdomain&quot; -o &quot;$hostName&quot; == &quot;localhost&quot; ] &amp;&amp; hostname www.magedu.com 比较求大者通过命令行参数给定两个数字，输出其中较大的数值；1234567891011121314#!/bin/bash#if [ $# -lt 2 ]; then echo "Two integers." exit 2fideclare -i max=$1if [ $1 -lt $2 ]; then max=$2fiecho "Max number: $max." 2. 命令行参数判断用户ID 奇偶通过命令行参数给定一个用户名，判断其ID号是偶数还是奇数； 比较文件行数通过命令行参数给定两个文本文件名，如果某文件不存在，则结束脚本执行；都存在时返回每个文件的行数，并说明其中行数较多的文件； 3. for 循环练习添加用户12345678910111213#!/bin/bash#for username in user21 user22 user23; do if id $username &amp;&gt; /dev/null; then echo "$username exists." else useradd $username if [ $? eq 0 ]; then echo "$username" | passwd --stdin "$username" &amp;&gt; /dev/null echo "Add $username finished" fi fidone 求和123456789#!/bin/bash# 示例：求100以内所有正整数之和；declare -i sum=0for i in &#123;1..100&#125;; do echo "\$sum is $sum, \$i is $i" sum=$[$sum+$i]doneecho $sum 判断文件类型12345678910111213141516171819#!/bin/bash# 示例：判断/var/log目录下的每一个文件的内容类型for filename in /var/log/*; do if [ -f $filename ]; then echo "Common file." elif [ -d $filename ]; then echo "Directory." elif [ -L $filename ]; then echo "Symbolic link." elif [ -b $filename ]; then echo "block special file." elif [ -c $filename ]; then echo "character special file." elif [ -S $filename ]; then echo "Socket file." else echo "Unkown." fi done 12345678#!/bin/bash# 打印成法口诀表for i in &#123;1..9&#125;; do for j in $(seq 1 $i); do echo -e -n "$&#123;i&#125;X$&#123;j&#125;=$[$i*$j]\t" done echodone 4. 类 C 风格for 循环求和1234567891011121314151617181920212223# 示例：求100以内所有正整数之和#!/bin/bash#declare -i sum=0for ((i=1;i&lt;=100;i++)); do let sum+=$idoneecho "Sum: $sum."``` ### 打印九九乘法表```bash# 示例：打印九九乘法表#!/bin/bash#for ((j=1;j&lt;=9;j++)); do for ((i=1;i&lt;=j;i++)); do echo -e -n "$&#123;i&#125;X$&#123;j&#125;=$[$&#123;i&#125;*$&#123;j&#125;]\t" done echodone 5. 显示一个菜单给用户要求12345678# 显示一个如下的菜单给用户# cpu) display cpu information# mem) display memory information# disk) display disks information# quit) quit# 要求：(1) 提示用户给出自己的选择；# (2) 正确的选择则给出相应的信息；否则，则提示重新选择正确的选项； bash 脚本123456789101112131415161718192021222324252627#!/bin/bash#cat &lt;&lt; EOFcpu) display cpu informationmem) display memory infomationdisk) display disks informationquit) quit===============================EOFread -p "Enter your option: " optionwhile [ "$option" != "cpu" -a "$option" != "mem" -a "$option" != "disk" -a "$option" != "quit" ]; do echo "cpu, mem, disk, quit" read -p "Enter your option again: " optiondoneif [ "$option" == "cpu" ]; then lscpuelif [ "$option" == "mem" ]; then free -melif [ "$option" == "disk" ]; then fdisk -l /dev/[hs]d[a-z]else echo "quit" exit 0fi 6. 服务框架脚本要求12345# 示例：写一个服务框架脚本；# $lockfile, 值/var/lock/subsys/SCRIPT_NAME# (1) 此脚本可接受start, stop, restart, status四个参数之一；# (2) 如果参数非此四者，则提示使用帮助后退出；# (3) start，则创建lockfile，并显示启动；stop，则删除lockfile，并显示停止；restart，则先删除此文件再创建此文件，而后显示重启完成；status，如果lockfile存在，则显示running，否则，则显示为stopped. bash 脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash## chkconfig: - 50 50# description: test service script#prog=$(basename $0)lockfile=/var/lock/subsys/$progcase $1 instart) if [ -f $lockfile ]; then echo "$prog is running yet." else touch $lockfile [ $? -eq 0 ] &amp;&amp; echo "start $prog finshed." fi ;;stop) if [ -f $lockfile ]; then rm -f $lockfile [ $? -eq 0 ] &amp;&amp; echo "stop $prog finished." else echo "$prog is not running." fi ;;restart) if [ -f $lockfile ]; then rm -f $lockfile touch $lockfile echo "restart $prog finished." else touch -f $lockfile echo "start $prog finished." fi ;;status) if [ -f $lockfile ]; then echo "$prog is running" else echo "$prog is stopped." fi ;;*) echo "Usage: $prog &#123;start|stop|restart|status&#125;" exit 1esac]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.8 bash 配置文件]]></title>
    <url>%2F2018%2F06%2F28%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fbash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[bash 配置文件 bash 的配置文件也是 shell 脚本，用于定义环境变量，别名或运行一些特殊用途的脚本。比如一些特殊用途的别名，我们不想每次登陆 shell 后都重新设置，可以定义在配置文件中；又比如想将一些特定目录添加到 PATH 环境变量中等等。要理解 bash 的配置文件，我们首先需要明白 bash 的两种登陆类型，它们会分别读取不同的配置文件，所以本节的内容如下: bash 中的登陆类型 bash 配置文件类型 配置文件的生效过程 1. bash 中的登陆类型bash 中配置文件大致分为交互式登录和非交互式登录 两种类型。每种类型发生的情景对应如下: 交互式登录shell进程： 直接通过某终端输入账号和密码后登录打开的shell进程； 使用su命令：su - USERNAME, 或 su -l USERNAME 执行的登录切换； 非交互式登录shell进程： su USERNAME执行的登录切换； 图形界面下打开的终端； 运行脚本 2. bash的配置文件类型针对两种登陆类型，配置文件也分成了两类： profile类：为交互式登录的shell进程提供配置 bashrc类：为非交互式登录的shell进程提供配置 2.1 profile类配置文件profile: 作用: 用于定义环境变量； 运行命令或脚本； 位置: 全局配置：对所有用户都生效； /etc/profile /etc/profile.d/*.sh 用户个人：仅对当前用户有效； ~/.bash_profile 注意：仅管理员可修改全局配置文件； 2.2 bashrc类配置文件bashrc: 作用: 定义本地变量； 定义命令别名； 位置: 全局配置：/etc/bashrc 用户个人：~/.bashrc 注意：仅管理员可修改全局配置文件； 3. 配置文件的生效过程 交互式登录: /etc/profile --&gt; /etc/profile.d/* --&gt; ~/.bash_profile --&gt; ~/.bashrc --&gt; /etc/bashrc 非交互式登录: ~/.bashrc --&gt; /etc/bashrc --&gt; /etc/profile.d/* 需要注意的配置文件和命令行定义的配置具有不同的生效时间: 对于命令行，例如变量和别名作用域为当前shell进程的生命周期； 对于配置文件，虽然可以永久有效，但是只对随后新启动的shell进程才有效，对当前shell 无效；因此让配置文件定义的特性立即生效需要额外操作，有两种方法可供选择 通过命令行重复定义一次； 让shell进程重读配置文件； source /PATH/FROM/CONF_FILE . /PATH/FROM/CONF_FILE]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.7 程序交互与信号捕捉]]></title>
    <url>%2F2018%2F06%2F27%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[程序交互，退出状态与信号捕捉 本节我们开始学习 bash shell 编程的第七部分，包含以下内容: 如何在程序执行过程中与用户交互 bash 编程调试 设置脚本执行的状态返回值 如何在 bash 中使用 ASCII 颜色 dialog 实现窗口化编程 信号捕捉 1. 用户交互bash 中与用户交互主要通过 read 命令完成，read 可以输出一段文字提示用户输入指定内容，并将用户输入保存在特定变量中，read 的使用方式如下 read [OPTIONS] [变量名 ...] 作用:从标准输入读取一行并将其分为不同的域 选项: -p 提示符: 用户提示符 -t 超时: 设置等待用户输入的超时时长，单位秒 -a 数组 -d 分隔符 -i 缓冲区文字 -n 读取字符数 -N 读取字符数 -u 文件描述符 1234567891011&gt; read -p &quot;enter a disk filename&quot; -t 5 name&gt; [ -z &quot;$name&quot; ] &amp;&amp; name=&quot;value&quot;&gt; read a bjerry mark cd&gt; echo $ajerry&gt; echo $b # 值个数多于变量个数时，所有多余的变量默认保存在最后一个变量中mark cd 2. bash 调试bash 命令有两个参数可以帮助我们调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 3. 脚本的状态返回值之前我们说过，程序执行有状态返回值，保存在 $? 变量中。shell 脚本的状态返回值有如下特点: 默认是脚本中执行的最后一条件命令的状态返回值 使用 exit [n] 可自定义退出状态码，n 位于 0-255 之间，0 表示执行成功无异常，默认为 0 exit 类似 python 中的return，程序遇到 exit 即终止 4. 在bash中使用ACSII颜色\033[31m hello \033[0m 格式: \033[31m 表示颜色控制开始符，\033[0m 表示颜色控制结束符，中间为要显示的文本 颜色控制: ##m(31m) - 左侧`#`： - 3：表示前景色 - 4：表示背景色 - 右侧 `#`: 表示颜色种类, 范围是 1, 2, 3, 4, 5, 6, 7 格式控制: #m(5m) 加粗、闪烁等功能； 组合: 多种控制符，可组合使用，彼此间用分号隔开； 12345678tao@hp:shell$ echo -e "\033[31m htto \033[0m" httotao@hp:shell$ echo -e "\033[41;32m htto \033[0m" httotao@hp:shell$ echo -e "\033[42;35;4m htto \033[0m"htto 5. dialog 实现窗口化编程123yum install dialog -ydialog --msgbox hello 17 30 本节我们来学习 bash shell 编程的第九部分如何在 shell 中捕捉信号。shell 中捕捉信号主要是使用 shell 内置的 trap 命令。shell 中的信号捕捉有以下几点需要特别注意。 15) SIGTERM 和 9) SIGKILL 信号是不可捕捉的，以防止不能终止进程。 bash 中的命令会以子进程运行，因此信号可能会被子进程捕获，执行脚本的进程因此可能无法捕获到信号。但是如果 trap 在子命令之前优先执行，信号则会优先被执行脚本的进程捕获。 程序执行过程中可能会产生很多临时文件或其他数据，正常结束时，这些临时文件都会被清理；但是如果程序执行过程中被 Ctrl-C 终止可能这些临时数据将无法被清除；因此可能需要捕捉 2) SIGINT 信号以清除执行程序时产生的临时文件。 6. 信号捕捉traptrap -l: 作用: 等同于 kill -l 列出所有信号 trap &#39;COMMAND&#39; SIGNALS 作用: 指定在接收到信号后将要采取的动作，常见的用途是在脚本程序被中断时完成清理工作 常可以进行捕捉的信号： 1) SIGHUP 2) SIGINT 12# 表示当shell收到HUP INT PIPE QUIT TERM这几个命令时，当前执行的程序会读取参数“exit 1”，并将它作为命令执行。trap "exit 1" HUP INT PIPE QUIT TERM 示例1234567891011121314151617181920212223#!/bin/bash#declare -a hosttmpfilestrap 'mytrap' INTmytrap() &#123; echo "Quit" rm -f $&#123;hosttmpfiles[@]&#125; exit 1&#125;for i in &#123;1..50&#125;; do tmpfile=$(mktemp /tmp/ping.XXXXXX) if ping -W 1 -c 1 172.16.$i.1 &amp;&gt; /dev/null; then echo "172.16.$i.1 is up" | tee $tmpfile else echo "172.16.$i.1 is down" | tee $tmpfile fi hosttmpfiles[$&#123;#hosttmpfiles[*]&#125;]=$tmpfiledonerm -f $&#123;hosttmpfiles[@]&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.6 函数和参数传递]]></title>
    <url>%2F2018%2F06%2F26%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%2F</url>
    <content type="text"><![CDATA[函数和参数传递 本节我们来学习 bash shell 编程的第六部分参数传递与函数，包括以下内容: 如何向脚本传递参数 bash 函数 局部作用域 1. 参数传递1.1 位置参数所谓位置参数是 bash 中，脚本或函数接收参数的形式，除了位置参数，脚本中还内置了一些特殊参数，用于保存特定的值。参数的对应关系如下所示 myscript.sh argu1 argu2.... 位置参数: $1: 表示第一个位置参数 argu1 $2: 表示第二个位置参数 argu2 ${10}:表示第 10 个位置参数 argu10 ${11}:表示第 11 个位置参数 argu10,其他以此类推 特殊变量： $0：脚本文件路径本身； $#：脚本参数的个数； $*：由空格分隔的所有参数的字符串 “$1 $2 $n” $@：所有参数组成的列表 “$1”，”$2”，”$3”，”$n” 1.2 参数轮替shift [n] 作用：造成参数变量的号码偏移，即整体参数的右移 n：数字，默认为1，代表拿掉最前面几个参数的意思 2. 函数2.1 bash 函数特性函数是主要作用是实现代码重用，其在每次被调用时创建，返回时终止。bash 中的函数与 bash 脚本的使用方式基本是类似的。 函数的返回值函数的返回值也包括执行结果返回值和状态返回值 函数的执行结果返回值为代码的输出包括 函数中的打印语句：echo, print 函数中调用的系统命令执行后返回的结果 执行状态返回值： 默认是函数体中最后一次执行的命令状态结果 使用 return [0-255] 自定函数执行状态的返回值，不能使用 exit, exit 会直接退出脚本 函数参数函数也通过位置接收传递进来的参数，并且表示方法与脚本完全相同。因此函数内的 $n 参数并不是脚本中的 $n 参数。向函数传递参数时，在函数名后跟空白分隔参数列表即可，testfunc arg1 arg2 arg3 ... 函数作用域bash 函数默认与脚本共享同一作用域，函数内可以直接访问和修改脚本内变量的值。要想创建局部变量必需使用 local VARIABLE=VALUE。因此 bash 中的变量有三种: 局部变量：作用域是函数内；在函数结束时被自动销毁,因此不会影响脚本内同名变量的值 本地变量：作用域是当前shell脚本程序文件，在运行脚本的shell进程结束时被销毁 环境变量：作用域是当前进程及其子进程 因为函数内能直接修改脚本内变量的值，所以函数最好都使用局部变量，以免函数调用非预期的更改脚本内变量的值，引入难以调试的 bug。 2.2 定义语法：123456789# 方式一function F_NAME &#123; # 函数名后必需要有空格 函数体&#125;# 方式二F_NAME() &#123; # ()后必需要有空格 函数体&#125; 3. 函数使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 练习：写一个脚本，完成如下功能(使用函数)：# 1、提示用户输入一个可执行命令；# 2、获取这个命令所依赖的所有库文件(使用ldd命令)；# 3、复制命令至/mnt/sysroot/对应的目录中# 解释：假设，如果复制的是cat命令，其可执行程序的路径是/bin/cat，那么就要将/bin/cat复制到/mnt/sysroot/bin/目录中，如果复制的是useradd命令，而useradd的可执行文件路径为/usr/sbin/useradd，那么就要将其复制到/mnt/sysroot/usr/sbin/目录中；# 4、复制各库文件至/mnt/sysroot/对应的目录中；#!/bin/bash#target=/mnt/sysroot/[ -d $target ] || mkdir $targetpreCommand() &#123; if which $1 &amp;&gt; /dev/null; then commandPath=`which --skip-alias $1` return 0 else echo &quot;No such command.&quot; return 1 fi&#125;commandCopy() &#123; commandDir=`dirname $1` [ -d $&#123;target&#125;$&#123;commandDir&#125; ] || mkdir -p $&#123;target&#125;$&#123;commandDir&#125; [ -f $&#123;target&#125;$&#123;commandPath&#125; ] || cp $1 $&#123;target&#125;$&#123;commandDir&#125;&#125;libCopy() &#123; for lib in `ldd $1 | egrep -o &quot;/[^[:space:]]+&quot;`; do libDir=`dirname $lib` [ -d $&#123;target&#125;$&#123;libDir&#125; ] || mkdir -p $&#123;target&#125;$&#123;libDir&#125; [ -f $&#123;target&#125;$&#123;lib&#125; ] || cp $lib $&#123;target&#125;$&#123;libDir&#125; done&#125;read -p &quot;Plz enter a command: &quot; commanduntil [ &quot;$command&quot; == &apos;quit&apos; ]; do if preCommand $command &amp;&gt; /dev/null; then commandCopy $commandPath libCopy $commandPath fi read -p &quot;Plz enter a command: &quot; commanddone]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.5 字符串处理]]></title>
    <url>%2F2018%2F06%2F25%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[字符串处理 本节我们来学习 bash shell 编程的第五部分字符串处理，内容包括: 字符串的切片，基于位置取子穿 基于模式取子串 查找和替换 大小写转换 变量赋值操作 bash 中获取变量的值可以使用 ${VARIABLE},字符串操作就是在此基础上的扩展。 1. 字符串操作1.1 字符串切片：${string:offset:length} 作用: 正向切片，offset 表示偏移量，lenght 表示截取的字符个数 注意: bash 中字符串和数组一样，下标从 0 开始 ${string: -length} 作用: 反向切片，取尾部的指定个数的字符，- 前必须要有空格 1234567tao@hp:shell$ a=01234tao@hp:shell$ echo $&#123;a:1:2&#125;12tao@hp:shell$ echo $&#123;a: -2&#125;34 1.2 基于模式取子串需要特别注意的是，查找的关键字 word 只支持通配符 语法 作用 ${variable#*word} 自左而右，删除字符开始至第一次出现word ${variable##*word} 自左而右，删除字符开始至最后一次出现word ${variable%word*} 自右而左，删除第一次出现word至字串尾部 ${variable%%world*} 自右而左，删除最后一次出现word至字串尾部 12345678910111213141516171819tao@hp:~$ file='/var/log/messages'tao@hp:~$ echo $&#123;file#*/&#125;var/log/messagestao@hp:~$ echo $&#123;file##*/&#125;messagestao@hp:~$ echo $&#123;file%/*&#125;/var/logtao@hp:~$ echo $&#123;file%%/*&#125;tao@hp:~$ phonenumber='010-110-8'tao@hp:~$ echo $&#123;phonenumber%%-*&#125;010tao@hp:~$ echo $&#123;phonenumber%-*&#125;010-110tao@hp:~$ echo $&#123;phonenumber##*-&#125;8 1.3 查找替换：需要注意的是，pattern 只能使用通配符，省略 /SUBSTI 时表示查找删除 语法 作用 ${var/PATTERN/SUBSTI} 查找，第一次被 PATTERN 匹配到的字符串，替换为SUBSTI ${var//PATTERN/SUBSTI} 查找，所有被PATTERN 匹配到的字符串，替换为SUBSTI ${var/#PATTERN/SUBSTI} 查找，行首被PATTERN 匹配到的字符串，替换为SUBSTI ${var/%PATTERN/SUBSTI} 查找，行尾被PATTERN 匹配到的字符串，替换为SUBSTI 1.4 大小写转换： ${variable^^}: 小–&gt;大 ${variable,,}: 大–&gt;小 2. 变量赋值操作 变量设定方式 param 没有设定 param 为空 param 为非空字符串 var=${param-word} var=word var= var=$param var=${param:-word} var=word var=word var=$param var=${param+word} var= var=word var=word var=${param:+word} var= var= var=word var=${param=word} var=word param=word var= param= var=$param param 不变 var=${param:=word} var=word param=word var=word param=word var=$param param 不变 var=${param?word} word 输出到stderr var= var=$param var=${param:?word} word 输出到stderr word 输出到stderr var=$param 12# 为脚本使用配置文件，并确保某变量有可用值的方式variable=$&#123;variable:-default vaule&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.4 数组与算数运算]]></title>
    <url>%2F2018%2F06%2F24%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组与算数运算 本节我们来学习 bash shell 编程的第四部分内容数组与算数运算。 1. 数组数组和字典是编程中非常常用的数据结构，但是 bash 对它们支持都比较有限。原因我们在本章第一节就说过，bash 本质上并不能算一种语言，因此也很少被拿来做复杂的编程。它更适合利用 Linux 中已有的命令完成特定功能。所以 bash 对复杂数据结构的支持很有限。bash 4.0 之后才开始支持字典，默认也只支持一维数组。下面我们将通过数组的声明，赋值和引用来讲解数组的使用。 bash 中字典又称为关联数组，使用方式与数组基本一致，只是将数字索引改为，字符串索引即可 1.1 数组声明数组和字典的声明: 数组声明: declare -a 字典声明: declare -A， bash 4.0及以上才支持，必需显示声明 1.2 数组的赋值bash 中的数组有多种赋值方式，常用的如下所示 赋值方式 语法 一次只赋值一个元素 a[0]=$RANDOM 一次赋值全部元素 a=(red blue yellow green) 只赋值特定元素 a=([0]=green [3]=red [2]=blue [6]=yellow) 用户输入 read -a ARRAY 12345678910# 数组赋值支持通配符logs=(/var/log/*.log)# 字典赋值declare -A worldworld[us]="america"echo "$&#123;world['us']&#125;"# 向非稀疏数组追加元素ARRAY[$&#123;#ARRAY[*]&#125;]=value 1.3 数组的访问变量引用可以使用 ${VARIABLE},而数组的访问就是在此基础上添加上要访问的索引。需要特别注意的是数组引用 {}不可省略，否则[index] 会被当作普通字符对待 用索引访问: ${ARRAY[index]} ${ARRAY}: 没有下标时，默认引用索引为 0 的元素 访问整个数组： ${ARRAY[@]}: 每个参数是一个独立的串 ${ARRAY[*]}: 所有参数是一个串 数组切片: ${ARRAY[@]:offset:number}: 取出偏移两之后特定数量的元素 ${ARRAY[@]:offset}：取出偏移量后的所有元素 ${ARRAY[@]}: 取出所有元素 说明: offset是偏移的元素个数,number 是取出的元素的个数 1234567891011# 获取数组的长度: echo $&#123;#ARRAY[*]&#125;`echo $&#123;#ARRAY[@]&#125;`# 获取数组第 0 个元素的字符串长度echo $&#123;#ARRAY&#125;tao@hp$ world[0]=ustao@hp$ echo $&#123;#world[*]&#125; # 数组长度1tao@hp$ echo $&#123;#world&#125; # 数组 0 元素的字符长度2 1.4 从数组中删除元素：unset ARRAY[index] 2. 数组使用示例示例 1定义一个数组，数组中的元素是/var/log目录下所有以.log结尾的文件；统计其下标为偶数的文件中的行数之和； 1234567891011121314#!/bin/bash#declare -a filesfiles=(/var/log/*.log)declare -i lines=0for i in $(seq 0 $[$&#123;#files[*]&#125;-1]); do if [ $[$i%2] -eq 0 ]; then let lines+=$(wc -l $&#123;files[$i]&#125; | cut -d' ' -f1) fidoneecho "Lines: $lines." 示例 2生成10个随机数，升序排序 12345678910111213141516171819202122#!/bin/bash#for((i=0;i&lt;10;i++))do rnd[$i]=$RANDOMdoneecho -e "total=$&#123;#rnd[@]&#125;\n$&#123;rnd[@]&#125;\nBegin to sort"for((i=9;i&gt;=1;i--))do for((j=0;j&lt;i;j++)) do if [ $&#123;rnd[$j]&#125; -gt $&#123;rnd[$[$j+1]]&#125; ] ;then swapValue=$&#123;rnd[$j]&#125; rnd[$j]=$&#123;rnd[$[$j+1]]&#125; rnd[$[$j+1]]=$swapValue fi donedoneecho $&#123;rnd[@]&#125; 2. 算术运算bash 是弱类型编程语言，所有变量的默认类型是字符串。因此算术运算必需借助特定的命令来实现。同时 bash 中默认也不支持浮点数，当然也几乎用不到 常见的算术运算符包括 +，-，*，/, **, %，bash中实现算术运算有如下几种方式: let var=3+4: let 不会打印输出，只能使用变量进行保存 let count+=2: let 支持增量赋值 +=，-=，*=, /=, %= let count++: let 支持自增运算 var=$[$var+1] var=$(($var+1)) var=$(expr 3 \* 4): 运算符和操作数之间必须使用空格分割，* 需要转义 $RANDOM: bash 内置的随机数生成器，表示 1-32767 的随机数 echo $[$RANDOM%60] 注意：乘法符号在有些场景中需要使用转义符； 1234567脚本练习：# 计算/etc/passwd文件中的第10个用户和第20个用户的id号之和；id1=$(head -10 /etc/passwd | tail -1 | cut -d: -f3)id2=$(head -20 /etc/passwd | tail -1 | cut -d: -f3)# 计算/etc/rc.d/init.d/functions和/etc/inittab文件的空白行数之和；grep &quot;^[[:space:]]*$&quot; /etc/rc.d/init.d/functions | wc -l]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.3 循环]]></title>
    <url>%2F2018%2F06%2F23%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[循环 本节我们来学习 bash shell 编程的第三部分循环，包括以下内容: for 循环 while 循环 until 循环 循环体内的控制语句 continue, break 1. for 循环for 循环通过遍历列表的方式执行循环，列表生成有如下几种方式 1.1 列表生成方式 直接给出:user1 user2 user3 整数列表 {start..end}: 使用内置关键字{} 生成整数列表 $(seq [start [incremtal]] last): 使用 seq 命令生成整数列表 返回列表的命令，例如 ls 命令 glob 通配符，例如 for file in /var/*; do; done 变量引用，例如 $*, $@ 1.2 for 循环语法for 循环的语法，及其使用示例如下所示123for VARAIBLE in LIST; do 循环体done 123456789101112131415#!/bin/bash#declare -i uphosts=0declare -i downhosts=0for i in &#123;1..17&#125;; do if ping -W 1 -c 1 172.16.$i.1 &amp;&gt; /dev/null; then echo "172.16.$i.1 is up." let uphosts+=1 else echo "172.16.$i.1 is down." let downhosts+=1 fidoneecho "Up hosts: $uphosts, Down hosts: $downhosts." 1.3 类 C 风格for 循环for 循环除通常的列表遍历外，还有一种类 C 风格使用方法，其语法如下 控制变量初始化：仅在循环代码开始运行时执行一次； 控制变量的修正语句：每轮循环结束会先进行控制变量修正运算，而后再做条件判断； 123for ((控制变量初始化;条件判断表达式;控制变量的修正语句)); do 循环体done 12345678910# 示例：求100以内所有正整数之和#!/bin/bash#declare -i sum=0for ((i=1;i&lt;=100;i++)); do let sum+=$idoneecho "Sum: $sum." 2. while 循环2.1 while 条件循环while 循环只要条件满足，就会一直执行123while CONDITION1; do 循环体done 12345678910111213#!/bin/bash#declare -i i=1declare uphosts=0declare downhosts=0net="172.169.250"while [ $i -le 20 ]; do if ping -c 1 -w $net.$i &amp;&gt;/dev/null; then echo "$net.$i is up" let uphosts++ fidone 2.2 while 文件遍历while循环还有一种特殊用法，可用于文件遍历。如下所示 while 将依次读取/PATH/FROM/SOMEFILE 文件中的每一行，且将其赋值给VARIABLE变量123while read VARIABLE; do 循环体；done &lt; /PATH/FROM/SOMEFILE 123456789101112# 示例：找出ID号为偶数的用户，显示其用户名、ID及默认shell；#!/bin/bash#while read line; do userid=$(echo $line | cut -d: -f3) username=$(echo $line | cut -d: -f1) usershell=$(echo $line | cut -d: -f7) if [ $[$userid%2] -eq 0 ]; then echo "$username, $userid, $usershell." fidone &lt; /etc/passwd 2.3 创建死循环while true 可以创建死循环， sleep 命令可以让进程休眠一段时间 sleep NUMBER[SUFFIX]: 作用: 让程序在 sleep 处休眠 NUMBER 秒 SUFFIX: 默认为 s, 指暂停的秒数, m 指分钟, h 指小时, d 代表天数 1234567891011#!/bin/bash# 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出；while true; do if who | grep "^logstash\&gt;" &amp;&gt; /dev/null; then break fi sleep 3doneecho "$(date +"%F %T") logstash logged on" &gt;&gt; /tmp/users.log 3. until 循环until 循环只要条件满足，就会退出循环 123until CONDITION; do 循环体done 1234567#!/bin/bash# 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出；until who | grep "^logstash\&gt;" &amp;&gt; /dev/null; do sleep 3doneecho "$(date +"%F %T") logstash logged on" &gt;&gt; /tmp/users.log 4. 循环控制语句4.1 continuecontinue 可提前结束本轮循环，直接进入下一轮循环判断； 12345678910111213141516171819202122232425262728293031323334# 示例：求100以内所有偶数之和； #!/bin/bash#declare -i evensum=0declare -i i=0while [ $i -le 100 ]; do let i++ if [ $[$i%2] -eq 1 ]; then continue fi let evensum+=$idoneecho "Even sum: $evensum"``` ### 3.2 breakbreak 可提前跳出整个循环。在下面的示例中 `while true` 将创建死循环，达到满足的条件时，break 将跳出循环。```bash# 示例：求100以内所奇数之和#!/bin/bash#declare -i oddsum=0declare -i i=1while true; do let oddsum+=$i let i+=2 if [ $i -gt 100 ]; then break fidone]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.2 if 和条件判断]]></title>
    <url>%2F2018%2F06%2F22%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fif%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[if 和条件判断 本节我们来学习 bash shell 编程的第二部分条件判断，包括以下内容: 条件测试的实现 测试表达式 数值测试 字符串测试 文件测试 组合测试 条件判断语句 if 和 case 1. 条件测试的实现bash 中测试的实现有两种方式，一是执行命令，并利用命令状态返回值来判断；二是所谓的测试表达式。但是所谓的测试表达式本质上仍然是由特定的测试命令执行，并通过命令状态返回值来判断测试是否满足。条件表达式我的理解只不过是为某些通用的测试目的提供便利。 因此测试是否满足，需要在执行测试命令后，使用 echo $? 查看测试结果。后面讲解的 if 语句则会自动判断命令执行状态，做出判断无需通过 $?。 bash 中的条件测试有如下三种使用方式，EXPRESSION 表示测试表达式 test EXPRESSION: bash 命令 [ EXPRESSION ]: [] 是 test 的同义词，使用方式与 test 完全一样 因为是命令，所有 bash 中的元字符如&gt; &lt; () 在表达式中使用时需要转义 命令的操作数不能为空，所以表达式中如果引用变量，需要使用 “$var”，否在当 var 不存在或为空时，会因为缺少操作数报语法错误 EXPRESSION两端必须有空白字符，否则为语法错误 [[ EXPRESSION ]] bash 内置关键字，[[]] 是 [] 的改进，大多数情况下可等同使用 因为不是命令，所以 bash 的元字符在表达式中使用无需转义 非命令，所以操作数为空时也能自动识别，但是在引用变量时，为防止变量包含空格，仍然建议使用 “$var” EXPRESSION两必须有空白字符，否则为语法错误 需要特别注意的是 bash 是通过 空格分隔运算符和操作数的，因此无论上述哪种形式，运算符和操作数之间必需要有空格。除了字符转义外，[] 和 [[]] 在支持的测试表达式范围上也略有不同，二者的区别可以参考此篇文章 http://mywiki.wooledge.org/BashFAQ/031 。一个实现 a 和 b 两个字符比较的示例如下。 1234&gt; test a \&gt; b&gt; [ a \&gt; b ]&gt; [[ a &gt; b ]]&gt; echo $? 2. 测试表达式2.1 数值测试 -eq：是否等于； [ $num1 -eq $num2 ] -ne：是否不等于； -gt：是否大于； -ge：是否大于等于； -lt：是否小于； -le：是否小于等于； 2.2 字符串测试 ==：是否等于； &gt;：是否大于； &lt;：是否小于； !=：是否不等于； =~：左侧字符串是否能够被右侧的PATTERN所匹配； -z &quot;STRING&quot;：判断指定的字串是否为空；空则为真，不空则假； -n &quot;STRING&quot;：判断指定的字符串是否不空；不空则真，空则为假； 注意: 字符串比较的操作数，都应该使用引号括住 [ -z &quot;$name&quot; ] [ &quot;$name&quot; = &quot;$myname&quot; ] 2.3 文件测试 文件存在测试 -a FILE: 等同于 -e FILE -e FILE: 存在则为真；否则则为假； -s FILE: 存在并且为非空文件则为值，否则为假； 存在及文件类型测试 -f FILE: 存在并且为 普通文件，则为真；否则为假； -d FILE: 存在并且为 目录文件，则为真；否则为假； -L/-h FILE: 存在并且为 符号链接文件，则为真；否则为假； -b: 是否存在并且为 块设备文件，则为真；否则为假； -c: 是否存在并且为 字符设备文件，则为真；否则为假； -S: 是否存在且为 套接字文件，则为真；否则为假； -p: 是否存在且为 命名管道文件，则为真；否则为假； 文件权限测试 -r FILE:在并且对当前用户可读； -w FILE:存在并且对当前用户可写； -x FILE:存在并且对当前用户可执行； -g sgid:存在并且 拥有sgid权限； -u suid:存在并且 拥有suid权限； -k sticky:存在并且 拥有sticky权限； 丛属关系测试 -t fd：文件是否打开且与某终端有关 -O FILE 当前用户是否为文件的属主 -G FILE 当前用户是否为文件的属组 更改及新旧对比测试 -N FILE: 文件自从上一次读操作后是否被修改过； file1 -nt file2: file1的mtime新于file2则为真，否则为假； file1 -ot file2: file1的mtime旧于file2则为真，否则为假； file1 -ef file2: 两文件是否是指向同一设备的 inode 的硬链接 2.4 组合测试条件bash 中表示逻辑运算有两种方式，一是使用命令的逻辑运算符，连接两个命令；另一个是表达式的逻辑符号，连接两个表达式。不过 [] 与 [[]]的使用方式有所不同 逻辑与： [ condition1 -a condition2 ] [[ condition1 &amp;&amp; condition2 ]] command1 &amp;&amp; command2 逻辑或： [ condition1 -o condition2 ] [[ condition1 || condition2 ]] command1 || command2 逻辑非： [ ! condition ] [[ ! condition ]] ! command eg： [ -O FILE ] &amp;&amp; [ -r FILE ] 或 [ -O FILE -a -r FILE ] 3. 条件判断语句3.1 if 语句语法if 语句会自动通过判断条件测试命令的执行状态来判断测试条件是否满足1234567891011121314151617if condition; then passelse passfiif conditionthen passelse passfi# 将 if 写在一行，命令行中常用if condition; then command1;command2; else command3; fiif [[ a &gt; b ]]; then echo "aaaa"; else echo "bbbb"; fi 示例通过参数传递一个用户名给脚本，此用户不存时，则添加之； 1234567891011121314#!/bin/bash#if [ $# -lt 1 ]; then echo "At least one username." exit 2fiif grep "^$1\&gt;" /etc/passwd &amp;&gt; /dev/null; then echo "User $1 exists."else useradd $1 echo $1 | passwd --stdin $1 &amp;&gt; /dev/null echo "Add user $1 finished."fi 3.2 case 语句语法123456789101112case $VARAIBLE in PAT1) 分支1 ;;PAT2) 分支2 ;;...*) 默认分支 ;;esac case PAT 支持glob风格的通配符： *：任意长度的任意字符； ?：任意单个字符； []：范围内任意单个字符； a|b：a或b]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.1 shell 脚本简介]]></title>
    <url>%2F2018%2F06%2F21%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fbash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[shell 脚本简介 本章我们将开始学习 bash shell 编程。bash shell 是一门编程语言，内容庞大，按照课程的设计应该循序渐进逐步深入。但是为便于以后复查参考，会将所有 bash shell 相关的知识放在此章节中。本章我们将学习以下内容: 变量与逻辑运算 循环与条件判断 函数和位置参数 程序的学习不言而喻是为了提高运维的效率，如果我们是管理几台主机不会shell 编程可能无所谓，但是当我们管理的主机达到几百甚至几千台时，如果没有自动化运维工具和编程的基础的化，可能就只能睡在公司了。Python 和 bash shell 都是自动化运维非常常用的脚本语言，希望大家多多学习。有两本书推荐给大家 《Linux命令行和shell编程宝典》 《abs-guide》 《高级bash编程指南》 1. 程序的分类shell 脚本是一个比较特殊的编程语言，组成脚本的基本内容并不是通常意义上的函数或库而是 Linux 上的所有命令，所以即便只是将一条条 bash 命令堆砌在一起也可以称为 shell 脚本。因此可以将 shell 脚本看作只是在 bash 命令上添加了编程语言的特性而以。本节我们将对 shell 脚本做一个简单概述，让大家对编程能有个概括性的了解。 按照不同的分类标准，程序可以做不同的分类。根据运行方式，程序可以分为: 编译运行：源代码 –&gt; 由编译器编译成可执行的二进制文件，然后运行； 解释运行：源代码 –&gt; 运行时启动解释器，由解释器边解释边运行； 程序=指令+数据，按照程序是以指令为中心组织的，还是按照数据为中心组织，将程序分为: 过程式编程语言：以指令为中心来组织代码，数据是服务于代码； 面向对象的编程语言：以数据为中心来组织代码，围绕数据来组织指令； 我们的 shell脚本则属于过程式，解释运行的，利用系统上的命令及编程组件进行编程的编程语言。即脚本的基本组件是系统上的所有命令以及用户自定的函数，通过顺序，判断和循环来组织命令按照特定的逻辑运行即可。 2. 如何学习编程网络上有个很有争议性的人物叫王垠，写过一篇文章叫《如何掌握所有的程序语言》。其核心的观念是学习程序语言重要的是学习语言特性而且是重要的语言特性，而不是语言本身。什么是语言特性，我从中摘录了他列举的示例 变量定义 算术运算 for 循环语句，while 循环语句 函数定义，函数调用 递归 静态类型系统 类型推导 lambda 函数 面向对象 垃圾回收 指针算术 goto 语句 按照他所说重要的语言特性就像是计算机的基本组件，而程序语言则是在选择不同的语言特性的基础上组装起来的计算机。作为初学者，可能很难深刻理解他表述的含义，但是他列举的语言特性，却可以给我们学习程序语言提供一个很好的思路。我们也将按照类似的顺序学习 sell 脚本编程。本节我们来讲解 shell 中的变量，以及如何创建一个简单的 shell 脚本并运行。 1. 变量1.1 变量的语言特性在静态的编译语言和动态的脚本语言中，变量的概念并不完全相同。暂时大家可以理解为，变量是命名的内存空间，有类型之分。变量的类型有非常重要的作用，用于确定变量内容的 存储格式、数据范围和能参与的运算 等等。 与变量有关的语言特性包括 变量在使用前是否需要声明 强类型变量还是弱类型变量 强类型变量: 变量类型一旦确定不能改变，也不能将不同类型的变量相互运算 弱类型变量: 变量类型转换没有限制，不同类型之间的运算可能发生隐式转换 变量的作用域，这通常与变量的第一次出现的位置或声明方式有关。 变量引用，及如何获取变量的值。shell 比较特殊，需要特定的方式才能引用到变量的值 变量的命名规则，这在所有编程语言中大体是相同的。 变量名只能包含数字、字母和下划线，而且不能以数字开头 不能够使用程序的保留字 变量名最好能见名知义，并遵循某种命名法则，比如驼峰或者下划线； 1.2 shell 变量的语言特性shell 中的变量则具有以下语言特性 变量无需声明，可直接使用 弱类型变量,无特殊声明默认把所有变量统统视作字符型； 变量引用：${var_name}, $var_name 有只读变量，只读变量无法重新赋值，无法撤销；存活时间为当前shell进程的生命周期，随shell进程终止而终止 变量赋值时，”=” 两边不能有空格，否则最左侧的变量名将被当作命令被解释并执行 1234&gt; ls=1&gt; ls = 1ls: 无法访问=: 没有那个文件或目录ls: 无法访问1: 没有那个文件或目录 1.3 shell 变量的作用域bash 中变量有三种不同的作用域: 本地变量：作用域仅为当前shell进程；除非特殊声明，所有变量均为本地变量 环境变量：作用域为当前shell进程及其子进程；需要特殊声明 局部变量：作用域仅为某代码片断(函数上下文)； 1.4 查看与销毁shell 中变量的查看和销毁有如下几个命令: 查看环境变量 export declare -x printenv, env 查看所有变量：set 撤销变量：unset name 1.5 变量声明bash 中变量声明的命令有 declare, export, readonly，它们都是 bash 的内置命令，用法如下 export [name[=value] 不带参数显示所有变量及其内容 带参数用于声明环境变量 readonly [-aAf] [name[=value] ...] 不带参数显示所有只读变量 带参数用于声明只读变量 declare/typeset [-aixr] [variable=[value]]: 默认：显示所有的变量及其内容，类似于 set -x：与export 一样，将后面的变量转换成环境变量 +x：将 - 变成 + 可以进行取消操作 -a：声明数组类型 array -i：声明整数类型 interger -r：将变量设置成只读类型 -p：后接变量，单独列出变量的类型 1234567891011121314# 声明环境变量export name=valuename=valueexport namedeclare -x name=valuename=valuedeclare -x name# 声明只读变量，声明和赋值可同时进行declare -r name[=value]readonly name[=value] 1.5 shell 中的特殊变量shell 还有一些特殊变量，有特殊公用，列示如下: 位置参数变量: 保存了传递给 shell 脚本的参数； shell内置的有特殊功用的环境变量，通常为全大写字符，用于定义bash的工作环境，比如 PATH: 命令查找路经 HISTFILE, HISTSIZE, HISTFILESIZE, HISTCONTROL: 命令历史的控制参数 SHELL, HOME, UID: 当前用户的 shell类型，家目录以及UID 号 PWD, OLDPWD: 当前以及之前的工作目录 特殊变量： $?: 上一条命令的执行状态 2. 如何写shell脚本2.1 hello world 的 shell 脚本脚本文件的第一行顶格，给出解释器路径，用于指明解释执行当前脚本的解释器程序文件。常见的解释器包括 #!/bin/bash: bash shell 的解释器 #!/usr/bin/python: python 的解释器 #!/usr/bin/perl: perl 的解释器 一个 hello world 的shell 脚本如下:123#!/bin/bashecho &quot;hello world&quot; 2.2 运行脚本bash 中运行脚本有两种方式： 赋予执行权限，并直接运行此程序文件； 直接运行解释器，将脚本以命令行参数传递给解释器程序； 123456# 方法一: 赋予可执行权限，直接运行&gt; chmod +x /PATH/TO/SCRIPT_FILE&gt; /PATH/TO/SCRIPT_FILE# 方法二: 调用 bash 运行&gt; bash /PATH/TO/SCRIPT_FILE 2.3 bash 调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 3. 练习1234练习1：写一个脚本，实现如下功能；(1) 显示/etc目录下所有以大写p或小写p开头的文件或目录本身；(2) 显示/var目录下的所有文件或目录本身，并将显示结果中的小写字母转换为大写后显示；(3) 创建临时文件/tmp/myfile.XXXX;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>shell脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.4 Linux特殊权限及facl扩展]]></title>
    <url>%2F2018%2F06%2F20%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2FLinux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[Linux特殊权限及facl扩展 Linux 默认的访问控制模型是通过将用户划分为三类，每类用户都可设置读写执行权限实现的。但是某些特殊情况下，此模型可能不太适用，因为其控制的粒度不够。所谓特殊权限及facl 扩展就是用来扩展Linux 的访问控制模型的。本节内容包括: 安全上下文，即程序的访问控制执行环节 SUID SGID STICKY facl 1. 安全上下文：所谓安全上下文即怎么决定一个用户是否某一文件具有什么权限: 进程以某用户的身份运行； 进程是发起此进程用户的代理，因此以此用户的身份和权限完成所有操作； 权限匹配模型： 判断进程的属主，是否为被访问的文件属主；如果是，则应用属主的权限；否则进入第2步； 判断进程的属主，是否属于被访问的文件属组；如果是，则应用属组的权限；否则进入第3步； 应用other的权限； 2. SUID默认情况下，用户发起的进程，进程的属主是其发起者；因此，其以发起者的身份在运行。存在 SUID时，用户运行某程序时，如果此程序拥有SUID权限，那么程序运行为进程时，进程的属主不是发起者，而程序文件自己的属主； SUID 特性 进程发起者对程序文件具有可执行权限 进程的属主为程序文件的属主，而非程序发起者 SUID 权限展示在属主的执行权限位上 rws——:小写 s 表示属主原有 x 权限 rwS——:大写 S 表示属主原没有 x 权限 SUID 权限管理 chmod u+s FILE.....: 添加 SUID 权限 chmod u-s FILE.....: 删除 SUID 权限 2. SGID：默认情况下，新创建文件的数组为用户的有效用户组。当文件目录的属组有写权限，且有SGID权限时，那么所有属于此目录的属组，且以属组身份在此目录中新建文件或目录时，新文件的属组不是用户的基本组，而是此目录的属组； SGID 特性 默认情况下，用户创建文件时，其属组为此用户的基本组 一旦目录具有 SGID 权限，则对此目录具有写权限的用户，在此目录中创建的文件所属的组为目录的属组 SGID 权限展示在属组的执行权限位 —rws—: 小写 s 表示属组有 x 权限 —rwS—: 大写 S 表示属组没有 x 权限 SGID 权限管理 chmod g+s DIR.....: 添加 SGID 权限 chmod g-s DIR.....: 删除 SGID 权限 3. Sticky对于属组或全局可写的目录，组内的所有用户或系统上的所有用户对在此目录中都能创建新文件或删除所有的已有文件；如果为此类目录设置Sticky权限，则每个用户能创建新文件，且只能删除自己的文件； Sticky 特性 对于一个多人可写目录，如果此目录设置了 Sticky 权限，则每个用户仅能删除自己的文件 Sticky 权限展示在其它用户的执行权限位 ——rwt: other 拥有 x 权限 ——rwT: other 没有 x 权限 系统上的/tmp和/var/tmp目录默认均有sticky权限； Sticky 权限管理 chmod o+t DIR....: 添加 Sticky 权限 chmod o-t DIR....: 删除 Sticky 权限 基于八进制方式赋权时，可于默认的三位八进制数字左侧再加一位八进制数字 chmod 1777 4. faclfacl - file access control lists 指的是文件的额外赋权机制，在原来的u,g,o之外，另一层让普通用户能控制赋权给另外的用户或组的赋权机制。facl 包含两个命令，getfacl 用于查看文件访问控制列表，setfacl 用户设置文件访问控制列表 getfacl命令getfacl FILE... &gt; getfacl README.md # file: README.md # owner: tao # group: 197121 &lt;unknown&gt; user::rw- # 属主 user:centos:rw- # facl 赋权给 centos 的权限 group::r-- # 属组 other:r-- # 其他 setfacl命令： 赋权: 赋权给用户：setfacl -m u:USERNAME:MODE FILE... 赋权给组 ：setfacl -m g:GROUPNAME:MODE FILE... 撤权： 撤销用户赋权: setfacl -x u:USERNAME FILE... 撤销组赋权: setfacl -x g:GROUPNAME FILE...]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.3 用户权限管理]]></title>
    <url>%2F2018%2F06%2F19%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux 用户与组管理命令 本节我们将学习用户权限以及权限管理。包括以下内容： Linux 的权限模型 Linux 权限管理 Linux 属主属组管理 umask 文件权限的遮罩码设置 1. Linux权限模型Linux 权限模型包括: Linux 按照属主，属组，其他三类用户，分别设置了r(读)，w(写)，x(执行) 三个权限 进程对文件的访问权限，取决于进程的发起者 权限的匹配按照属主，属组，其他的顺序，如果进程的发起者是文件的属主，则进程对此文件具有属主权限 123456&gt; ls /etc/passwd# rwxrwxrwx # 左三位：定义user(owner)的权限 # 中三位：定义group的权限； # 右三位：定义other的权限 1.1 文件与目录权限的含义 权限 文件 目录 r 可获取文件的数据 可使用ls命令获取其下的所有文件列表 w 可修改文件的数据 可修改此目录下的文件列表；即创建或删除文件 x 可将此文件运行为进程 可cd至此目录中，且可使用ls -l来获取所有文件的详细属性信息 1.2 权限的数字标识rwx 权限分别对应数字 421。这种以 2 的幂次递增的表示方式可以使得，任一一个总数都可以唯一表示一种权限类型。比如 5 表示 r-x 2.权限管理命令chmod 命令中用户可以使用如下代号表示 u：属主 g：属组 o：其它 a: 所有 chmod [OPTION]... MODE[,MODE]... FILE... 赋权表示法，直接操作一类用户的所有权限位rwx； 123456&gt; chmod ug=rwx /etc/fstab&gt; chmod ug=rwx,o= /etc/fstab&gt; chmod go= /etc/fstab# 数字权限设置，每个用户的权限不能省略&gt; chmod 666 /etc/fstab chmod [OPTION]... OCTAL-MODE FILE... 授权表示法：直接操作一类用户的一个权限位r,w,x； u+, u- g+, g- o+, o- a+, a- 12345&gt; chmod ug+x /etc/fstab&gt; chmod u-w /etc/fstab&gt; chmod +x /etc/fstab == chmod a+x /etc/fstab&gt; chmod +w /etc/fstab == /chmod u+w /etc/fstab # w 权限比较特殊&gt; chmod u+x,g+w /etc/fstab chmod [OPTION]... --reference=RFILE FILE... 引用表示法: 引用其他文件的权限为目标设置权限 --reference: 参考的文件 1chmod --reference=/var/log/message /etc/fstab chmod 的可用选项如下: 选项: -R, --recursive: 递归修改 注意：用户仅能修改属主为自己的那些文件的权限； installinstall 作用: copy files and set attributes 用法: 单源复制： install [OPTION]... [-T] SOURCE DEST 多源复制： install [OPTION]... SOURCE... DIRECTORY install [OPTION]... -t DIRECTORY SOURCE... 创建目录： install [OPTION]... -d DIRECTORY... 常用选项： -m, --mode=MODE：设定目标文件权限，默认为755； -o, --owner=OWNER：设定目标文件属主； -g, --group=GROUP：设定目标文件属组； mktempmktemp [OPTION]... [TEMPLATE] 作用: create a temporary file or directory 常用选项： -d：创建临时目录 注意：mktemp会将创建的临时文件名直接返回，因此，可直接通过命令引用保存起来； 1&gt; mktemp /tmp/mytext.XXXXXX # 有几个 X 就有几个随机字符 3. 从属关系管理命令chown命令：chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE... 作用: 修改文件的属主属组 选项： -R：递归修改 注意：仅管理员可修改文件的属主和属组； 12345&gt; chown -R tao:tao /etc/fstab # 同时更改属主属组&gt; chown -R tao.tao /etc/fstab # 同时更改属主属组&gt; chown -R tao /etc/fstab # 仅更改属主&gt; chown -R :tao /etc/fstab # 仅更改属组，.与: 均可&gt; chown -R --reference=/var/log/message /etc/fstab chgrpchgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE... 4. umaskumask [MASK] 作用: 查看或设置文件的权限反向掩码，遮罩码； 默认查看当前 umask 后跟 MASK 设置 umask 效果: 文件默认权限 = 666-umask 目录默认权限 = 777-umask 注意： 文件用666去减，表示文件默认不能拥有执行权限；如果减得的结果中有执行权限，需要将其加1； 此类设定仅对当前shell进程有效； 123umask: 023666-023=644777-023=754 练习123456# 新建系统组mariadb, 新建系统用户mariadb, 属于mariadb组，要求其没有家目录，且shell为/sbin/nologin；尝试root切换至用户，查看其命令提示符；# 新建GID为5000的组mageedu，新建用户gentoo，要求其家目录为/users/gentoo，密码同用户名；# 新建用户fedora，其家目录为/users/fedora，密码同用户名；# 新建用户www, 其家目录为/users/www；删除www用户，但保留其家目录；# 为用户gentoo和fedora新增附加组mageedu;# 复制目录/var/log至/tmp/目录，修改/tmp/log及其内部的所有文件的属组为mageedu，并让属组对目录本身拥有写权限；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.2 用户与组管理命令]]></title>
    <url>%2F2018%2F06%2F18%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 用户与组管理命令 本节我们将详细讲解用户与组管理的相关命令，包括以下内容: 用户的管理 用户组的管理 1. 用户组管理groupaddgroupadd [选项] group_name 作用: 创建新组 选项: -g GID：指定GID；默认是上一个组的GID+1； -r: 创建系统组； groupmodgroupmod [选项] GROUP 作用: 修改组属性 参数: GROUP 指定要修改的组的组名 选项: -g GID：修改GID； -n new_name：修改组名； groupdelgroupdel [选项] GROUP 作用: 删除组 gpasswd命令：gpasswd [选项] group 组密码文件：/etc/gshadow 作用: 设置组密码或向组添加或删除用户 选项: -a USERNAME：向组中添加用户 -d USERNAME：从组中移除用户 2. 用户管理Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells useradduseradd -D： 作用: 显示创建用户的默认配置； useradd -D 选项: 作用: 修改创建用户选项的默认值； 修改的结果保存于/etc/default/useradd文件中； 选项: s: 设置默认 shell useradd [选项] 登录名 作用: 创建新用户 选项: -u, --uid UID：指定UID； -g, --gid GROUP：指定基本组ID，此组得事先存在； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：指明用户所属的附加组，多个组之间用逗号分隔； -c, --comment COMMENT：指明注释信息； -d, --home HOME_DIR：以指定的路径为用户的家目录；通过复制/etc/skel此目录并重命名实现；指定的家目录路径如果事先存在，则不会为用户复制环境配置文件； -M: 不为用户创建主目录 -s, --shell SHELL：指定用户的默认shell，可用的所有shell列表存储在/etc/shells文件中； -r, --system：创建系统用户； 注意：创建用户时的诸多默认设定配置文件为/etc/login.defs usermod命令usermod [选项] 登录名 作用: 修改用户属性 选项: -u, --uid UID：修改用户的ID为此处指定的新UID； -g, --gid GROUP：修改用户所属的基本组； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：修改用户所属的附加组；原来的附加组会被覆盖； -a, --append：与-G一同使用，用于为用户追加新的附加组； -c, --comment COMMENT：修改注释信息； -d, --home HOME_DIR：修改用户的家目录；用户原有的文件不会被转移至新位置； -m, --move-home：只能与-d选项一同使用，用于将原来的家目录移动为新的家目录； -l, --login NEW_LOGIN：修改用户名； -s, --shell SHELL：修改用户的默认shell； -L, --lock：锁定用户密码；即在用户原来的密码字符串之前添加一个”!”； -U, --unlock：解锁用户的密码； userdel命令userdel [选项] 登录 作用：删除用户 选项: -r：删除用户时一并删除其家目录； passwdpasswd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username] 作用: passwd：修改用户自己的密码； passwd USERNAME：修改指定用户的密码，但仅root有此权限； 选项: -l, -u：锁定和解锁用户； -d：清除用户密码串； -e DATE: expire 过期期限，日期； -i DAYS：inactive 非活动期限； -n DAYS：minimum 密码的最短使用期限； -x DAYS：maximum 密码的最长使用期限； -w DAYS：warning 警告期限； --stdin：echo &quot;PASSWORD&quot; | passwd --stdin USERNAME newgrp命令newgrp [-] [group] 作用: 临时切换指定的组为基本组； 选项: -: 会模拟用户重新登录以实现重新初始化其工作环境； 附注: 如果用户不属于切换的目标组，则需要输入目标组组密码 chagechage [选项] 登录名 作用: 更改用户密码过期信息 选项: -d, --lastday DAYS: 修改最近一次更改时间 -E, --exporedate DATE: 过期期限 -W: -m: -M: idid [OPTION]... [USER] 作用: 显示用户的真和有效ID; 选项: -u: 仅显示有效的UID； -g: 仅显示用户的基本组ID; -G: 仅显示用户所属的所有组的ID； -n: 显示名字而非ID； eg: id docker 12345练习1：创建用户gentoo，UID为4001，基本组为gentoo，附加组为distro(GID为5000)和peguin(GID为5001)；练习2：创建用户fedora，其注释信息为&quot;Fedora Core&quot;，默认shell为/bin/tcsh；练习3：修改gentoo用户的家目录为/var/tmp/gentoo；要求其原有文件仍能被用户访问；练习4：为gentoo新增附加组netadmin； 3. 用户切换susu 用法: su -l USERNAME|su - USERNAME: 登录式切换, 会通过读取目标用户的配置文件来重新初始化 su USERNAME: 非登录式切换：不会读取目标用户的配置文件进行初始化 注意：管理员可无密码切换至其它任何用户； 选项: -c &quot;COMMAND&quot;：仅以指定用户的身份运行此处指定的命令；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.1 系统用户与组]]></title>
    <url>%2F2018%2F06%2F17%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Linux 中的用户与用户组 本章我们将学习 Linux 中的用户，用户组及权限。这些都是Linux 运维的基础知识，并不难。通过四节我们将学习以下内容: Linux 中的用户及用户组 Linux 权限及权限的管理 用户及用户组的管理命令 对于 Linux 的用户及用户组，主要是学习 /etc/passwd, /etc/shadow, /etc/group 三个文件，它们保存着 Linux 用户、用户组及密码。用户管理相关命令的核心，也只是操作这几个文件而已。 有关用户包括三个方面的内容，简称 3A 用户认证 - Authentication: 用户登录时需要输入用户名和密码 用户授权 - Authorization: Linux 上文件有属主和属组，并为属组属组以及其他第三方定义了权限 授权审计 - Audition: 登录和认证会记录到日志文件中，以便于日后审计 本节我们将围绕第一方面，讲述如下内容: Linux 用户与组的基本概念，包括用户的分类，与ID标识 Linxu 用户的认证 1. Linux 用户基础计算机容易识别的是数字，因此用户和组在Linux 都标识为 16 位二进制数字，称为 UserID(UID)，GroupID,(GID)，范围是0-65535Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells 1.1 用户基础Linux 中的用户具有如下特征 用户标识: UserID(UID) 用户分类与 ID 范围: 管理员: 0 普通用户：1-65535 系统用户: 1-499(CentOS6), 1-999(CentOS7) 作用: 为了能够让那后台进程或服务类进程以非管理员的身份运行，通常需要为此创建多个普通用户；这类用户从不用登录系统； 登录用户: 500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/passwd: 名称解析库，保存了用户名，UID等基础信息 /etc/shadow: 保存了用户的密码 1.2 Linux 用户组Linux 用户组 组标识：GroupID, GID 组分类与 ID 范围: 管理员组：0 通用户组：1-65635 系统用户组：1-499(CentOS6), 1-999(CentOS7) 登录用户组：500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/group: 保存了组名，组ID，组员等基本信息 /etc/gshadow: 保存了组的密码 组的其他分类: 从单个用户出发，分为： 用户的基本组 用户的附加组 按照名称: 私有组：组名同用户名，且只包含一个用户； 公共组：组内包含了多个用户； 1.3 密码的使用策略： 使用随机密码； 最短长度不要低于8位； 应该使用大写字母、小写字母、数字和标点符号四类字符中至少三类； 定期更换； 加密算法： 对称加密：加密和解密使用同一个密码； 非对称加密：加密和解密使用的一对儿密钥； 公钥：public key 私钥: private key 单向加密：只能加密，不能解密；提取数据特征码； 定长输出 雪崩效应 单向加密算法及对应命令: md5: message digest, 128bits – md5sum sha：secure hash algorithm, 160bits – shasum sha224 – sha224sum sha256 – sha256sum sha384 – sha284sum sha512 – sha512sum 2. 用户相关文件解析2.1 /etc/passwd 用户信息库name:password:UID:GID:GECOS:directory:shell name: 用户名 password：可以是加密的密码，也可是占位符x； UID： GID：用户所属的主组的ID号； GECOS：注释信息 directory：用户的家目录； shell：用户的默认shell，登录时默认shell程序； 2.2 /etc/shadow：用户密码用户名:加密的密码:最近一次修改密码的时间:最短使用期限:最长使用期限:警告期段:非活动期限:过期期限:保留字段 加密的密码: 使用 $ 符分割为 3 段分别表示: 数字，表示使用的加密算法 salt，表示加密过程中添加的随机数 加密之后的密码文本 2.3 /etc/group：组的信息库group_name:password:GID:user_list user_list：该组的用户成员；以此组为附加组的用户的用户列表；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.3 文件管理命令]]></title>
    <url>%2F2018%2F06%2F16%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[bash常见特性 本节我们将学习与文件目录管理相关的命令，包括 目录管理类命令 文件查看类命令 文件管理工具 1. 目录管理类的命令：mkdirmkdir [OPTION]... DIRECTORY... 作用: 创建目录 选项: -p: 父目录不存在时，自动按需创建父目录； -v: verbose，显示详细过程； -m: MODE：直接给定权限； rmdirrmdir [OPTION]... DIRECTORY... 作用: 删除空目录 选项: -p：删除某目录后，如果其父目录为空，则一并删除之； -v: 显示过程； tree：tree [options] [directory] 作用: 以层级方式展开显示目录 选项: -L level：指定要显示的层级； 2. 文件查看类命令：cat：cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac：tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； moremore FILE 作用: 分屏查看文件内容，没有 less 常用，了解即可 特点：翻屏至文件尾部后自动退出； lessless FILE 作用: 分屏查看文件内容, man 手册页即是调用 less 命令显示的结果 可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit) headhead [options] FILE 作用: 查看文件的前n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 tailtail [options] FILE 作用: 查看文件的后n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 -f: 查看文件尾部内容结束后不退出，跟随显示新增的行； statstat FILE... 作用: display file or file system status12345678910&gt; stat SUMMARY.md 文件：&quot;SUMMARY.md&quot; 大小：16876 块：40 IO 块：4096 普通文件设备：fd03h/64771d Inode：603785 硬链接：1权限：(0664/-rw-rw-r--) Uid：( 1000/ tao) Gid：( 1000/ tao)环境：unconfined_u:object_r:user_home_t:s0最近访问：2018-07-06 09:04:02.197198385 +0800 # access time最近更改：2018-07-06 09:04:02.185198436 +0800 # modify time 最近修改文件内容的时间最近改动：2018-07-06 09:04:02.185198436 +0800 # change time 最近文件元数据发生更改的时间创建时间：- touch：touch [OPTION]... FILE... 作用: 更改文件的时间戳 选项: -c: 指定的文件路径不存在时不予创建； -a: 仅修改access time； -m: 仅修改modify time； -t: STAMP 格式为 [[CC]YY]MMDDhhmm[.ss] 3. 文件管理工具copy命令式使用: 单源复制：cp [OPTION]... [-T] SOURCE DEST 如果DEST不存在：则事先创建此文件，并复制源文件的数据流至DEST中； 如果DEST存在： 如果DEST是非目录文件：则覆盖目标文件； 如果DEST是目录文件：则先在DEST目录下创建一个与源文件同名的文件，并复制其数据流； 多源复制： cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 如果DEST不存在：错误； 如果DEST存在： 如果DEST是非目录文件：错误； 如果DEST是目录文件：分别复制每个文件至目标目录中，并保持原名； 常用选项： -i：交互式复制，即覆盖之前提醒用户确认； -f：强制覆盖目标文件； -r, -R：递归复制目录； -d：== --no-dereference --preserve=links复制符号链接文件本身，而非其指向的源文件； -a, -- archive：相当于-dR --preserve=all，用于实现归档； --preserv=:保留源文件哪些属性，可用值如下 mode：权限 ownership：属主和属组 timestamps: 时间戳 context：安全标签 xattr：扩展属性 links：符号链接 all：上述所有属性 mvmv [OPTION]... [-T] SOURCE DESTmv [OPTION]... SOURCE... DIRECTORYmv [OPTION]... -t DIRECTORY SOURCE.. 使用: 同 cp 作用: 移动文件或目录 选项： -i：交互式； -f：force rmrm [OPTION]... FILE... 作用: 删除文件或目录 选项： -i：interactive，交互 -f：force，强制删除 -r: recursive，递归删除 删除目录：rm -rf /PATH/TO/DIR 危险操作：rm -rf /* 注意：所有不用的文件建议不要直接删除，而是移动至某个专用目录；（模拟回收站） trtr [OPTION]... SET1 [SET2] 作用: 把输入的数据当中的字符，凡是在SET1定义范围内出现的，通过对位转换为SET2出现的字符 用法1：tr SET1 SET2 &lt; /PATH/FROM/SOMEFILE – 用 SET2 替换 SET1 用法2：tr -d SET1 &lt; /PATH/FROM/SOMEFILE – 删除 SET 1中出现的字符 注意：不修改原文件 1234567# 把/etc/passwd文件的前6行的信息转换为大写字符后输出；&gt; head -n 6 /etc/passwd | tr &apos;a-z&apos; &apos;A-Z&apos;&gt; tr [a-z] [A-Z]how are youHOW ARE YOU]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.2 bash常见特性]]></title>
    <url>%2F2018%2F06%2F15%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2Fbash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[bash常见特性 bash 作为外壳程序的一种，为我们提供了与操作系统内核交互的接口。bash 本身具有丰富的特性，为我们执行和管理应用提供了便利。本节我们将学习 bash 的如下特性 命令历史 命令与路径补全 命令行展开 获取命令的执行状态和执行结果 引用与快捷键 通配符 IO重定向及管道 命令 hash 多命令执行 1. bash 命令历史命令历史指的是 shell 进程会其会话中保存此前用户提交执行过的命令；于此同时 bash 提供了快捷方式，以便我们能快速执行历史命令 1.1 命令历史控制相关的环境变量 HISTSIZE：shell进程可保留的命令历史的条数； HISTFILE: 持久保存命令历史的文件，默认为 ~/.bash_history HISTFILESIZE: 命令历史文件的大小； HISTCONTROL: 控制命令历史记录的方式，可选值如下 ignoredups：忽略重复的命令； ignorespace：忽略以空白字符开头的命令； ignoreboth：以上两者同时生效； 1.2 命令用法：history [-c] [-d 偏移量] [n]history -anrw [文件名]history -ps 参数 [参数...] -c: 清空命令历史； -d offset：删除指定命令历史 -r: 从文件读取命令历史至历史列表中； -w：把历史列表中的命令追加至历史文件中； history n：显示最近的 n 条命令； 1.3 快捷方式常见的历史命令的快捷方式如下 调用命令历史列表中的命令： !#：再一次执行历史列表中的第#条命令； !!：再一次执行上一条命令； !STRING：再一次执行命令历史列表中最近一个以STRING开头的命令； 调用上一条命令的最后一个参数： 快捷键：ESC, . - 表示先按 ESC，在按 . 字符串：!$ 2. 命令补全：所谓命令补全，就是在bash 中按下 tab 键之后，bash 会自动查找以当前输入字符开头的命令。如果给定的打头字符串如果能惟一标识某命令程序文件，则直接补全；不能惟一标识某命令程序文件，再击tab键一次，会给出列表。命令查找机制 如下： 优先查找内部命令； 根据PATH环境变量中设定的目录，自左而右逐个搜索目录下的文件名； 路径补全 与命令补全功能类似，只是路径补全只会在给定的起始路径下，逐一匹配起始路径下的每个文件。道理很简单，如果匹配到别处的文件名，在起始目录也还是查找不到，所以补全也没什么用。 命令和路径补全是 bash 中非常好用的功能，没事多敲击几次 tab 就好。 3. 命令行展开Linux 中有如下特殊字符，用于扩展命令的输入方式: ~: 自动展开为用户的家目录，或指定的用户的家目录； {}: 可承载一个以逗号分隔的路径列表，并能够将其展开为多个路径； 123456&gt; /tmp/&#123;a,b&#125; # 相当于&gt; /tmp/a /tmp/b&gt; mkdir -pv /tmp/x/&#123;y1/&#123;a,b&#125;,y2&#125;&gt; mkdir -v &#123;a,b&#125;_&#123;c,d&#125;&gt; mkdir -pv /tmp/mysysroot/&#123;bin,sbin,etc/sysconfig/network-scripts,usr/&#123;bin,sbin,local/&#123;bin,sbin,etc,lib&#125;,lib,lib64&#125;,var/&#123;cache,log,run&#125;&#125; 4. 获取命令的执行状态和执行结果命令的执行状态: 表示命令执行成功还是失败 命令执行完成之后，其状态返回值保存于bash的 $? 特殊变量中； 命令返回值: 表示命令的返回结果，或者是命令的输出内容 bash 中可以通过如下方式引用命令的执行结果，这在 bash 编程中非常有用 $(COMMAND) COMMAND 5. 引用与快捷键5.1 Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name 5.2 快捷键 Ctrl+a：跳转至命令行行首 Ctrl+e：跳转至命令行行尾 Ctrl+u：删除行首至光标所在处之间的所有字符； Ctrl+k：删除光标所在处至行尾的所有字符； Ctrl+l：清屏，相当于clear 6. globbing - 文件名通配通配符指的是 bash 中的特殊字符，称为元字符，元字符不表示字符本身而是表示一定范围内的或符合匹配条件的一类字符。通过元字符达到模糊匹配的作用。需要注意的是通配符跟正则表达式是完全不同的东西，不同软件，程序中的通配符也不会完全相同。需要特别注意的是bash 中的通配机制 匹配的是整体文件名，而非部分 bash 中的元字符如下 *：匹配任意长度的任意字符 ?：匹配任意单个字符 []：匹配指定范围内的任意单个字符，有如下几种特殊格式： `[a-z], [A-Z]: 不会区分文件名大小写，二者表示范围相同 [0-9], [a-z0-9]`: [[:upper:]]：所有大写字母 [[:lower:]]：所有小写字母 [[:alpha:]]：所有字母 [[:digit:]]：所有数字 [[:alnum:]]：所有的字母和数字 [[:space:]]：所有空白字符 [[:punct:]]：所有标点符号 [^]：匹配指定范围外的任意单个字符 [^[:upper:]] [^0-9] [^[:alnum:]] 123456789101112131415161718# 练习# 显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现一位任意字符的文件或目录；&gt; ls -d /var/l?[[:lower:]]# 显示/etc目录下，以任意一位数字开头，且以非数字结尾的文件或目录；&gt; ls -d /etc/[0-9]*[^0-9]# 显示/etc目录下，以非字母开头，后面跟一个字母及其它任意长度任意字符的文件或目录；&gt; ls -d /etc/[^a-z][a-z]*# 复制/etc目录下，所有以m开头，以非数字结尾的文件或目录至/tmp/magedu.com目录；&gt; cp -r /etc/m*[^0-9] /tmp/magedu.com/# 复制/usr/share/man目录下，所有以man开头，后跟一个数字结尾的文件或目录至/tmp/man/目录下；&gt; cp -r /usr/share/man/man[0-9] /tmp/man/# 复制/etc目录下，所有以.conf结尾，且以m,n,r,p开头的文件或目录至/tmp/conf.d/目录下；&gt; cp -r /etc/[mnrp]*.conf /tmp/conf.d/ 7. IO重定向及管道7.1 IO重定向：IO 我的理解就是文本流，所谓 IO 重定向就是将原本输入输出一个地方的文件流重新导向另一个地方。与输入输出相关的概念如下 可用于输入的设备包括：文件、键盘设备、文件系统上的常规文件、网卡等； 可用于输出的设备包括：文件、显示器、文件系统上的常规文件、网卡等； 默认情况下，bash 为程序提供了三种标准数据流： 输入的数据流；&lt;– 标准输入(stdin)，键盘； 输出的数据流：–&gt; 标准输出(stdout)，显示器； 错误输出流： –&gt; 标准错误输出(stderr)，显示器； IO 重定可分为覆盖重定向和追加重定向，所谓覆盖就是如果重定向的目标是文件，会先清空文件中的内容，而追加只是在文件的结尾继续写入。IO重定向的实现如下: 输入重定向： &lt; &lt;&lt;: 表示创建文档，使用方式见下 cat命令 输出重定向 &gt;: 覆盖重定向 == 1&gt; &gt;&gt;: 追加重定向 == 1&gt;&gt; 错误输出重定向： 2&gt;: 覆盖重定向 2&gt;&gt;: 追加重定向 合并正常输出流和错误输出流： &amp;&gt; &amp;&gt;&gt; 123456# 合并正常输出流和错误输出流COMMAND &gt; /path/to/somefile 2&gt;&amp;1 # 方法一COMMAND &amp;&gt; /path/to/somefile # 方法二COMMAND &gt;&gt; /path/to/somefile 2&gt;&amp;1 # 方法一COMMAND &amp;&gt;&gt; /path/to/somefile # 方法二 需要注意的是上述中 1,2 指代的是标准输入输出对应的文件描述符(fd, file descriptor)。文件描述符是操作系统的一个抽象概念，表示打开的文件。大家可以理解为 Linux中一切皆文件，如果要操作文件必须将文件关联到某个文件描述符。bash 在开启时，会自动做如下关联 标准输入：0 标准输出：1 错误输出：2 Linux 中有一个特殊设备/dev/null，它会丢弃接收到的所有输入，又称数据黑洞。通常在 shell 编程中，我们只需要知道命令的执行状态，而无需命令的执行结果时，可以将输出重定向至此设备 1&gt; head -1 /etc/passwd &amp;&gt; /dev/null # 判断 /etc/passwd 是否有内容 7.2 管道管道是 Linux 提供的一种进程间交互(IPC)的一种方法。大家不必过于纠结它是个什么东西，只要知道的是，它可以把一个程序的输入变成另一个程序的输入，就像一根管道一样连接着程序与程序。管道的使用方式类似 COMMAND | COMMAND | COMMAND....,使用 | 链接多个命令即可。1234# 管道与 IO重定向定义&gt; cat /etc/issue | tr &apos;a-z&apos; &apos;A-Z&apos; &gt; /tmp/issue&gt; who | head -2 | tr &apos;a-z&apos; &apos;A-Z&apos; | tr -d &apos;0-9&apos; &gt; /tmp/who.txt 7.3 bash 中对IO重定向的控制set 作用: 设置或撤销，shell 选项或位置参数的值 set -C 作用: 禁止覆盖输出重定向至已存在的文件； 附注: 此时可使用强制覆盖输出：&gt;| set +C 作用: 关闭上述特性 7.4 重定向相关命令catcat &gt; /PATH/TO/SOMEFILE &lt;&lt; EOF12345678910# EOF 表示文档创建的结束符# 通过屏幕的输入将保存至 /PATH/TO/SOMEFILE&gt; cat &gt; /PATH/TO/SOMEFILE &lt;&lt; EOFhow are youyes it is meEOF&gt; cat /PATH/TO/SOMEFILEhow are youyes it is me tee命令：tee [OPTION]... [FILE] 作用: 把标准输入的数据复制到每一个文件FILE,同时送往标准输出, 参数: FILE: 可以有多个 选项: -a: 追加到给出的文件, 而不是覆盖 eg：COMMAND | tee /PATH/TO/SOMEFILE 8.命令 hash所谓命令 hash 是指 bash 会缓存此前命令的查找结果。哈希是一种数据结构，通常也称为字典存储着键值对，能通过键快速的查找到对应的值。bash 内置的 hash 命令能显示和管理 bash 命令的缓存结果。 hash [options] [COMMAND] 用法:- `hash`：列出所有的缓存结果 - `hash -d COMMAND`：删除 COMMAND 命令的缓存 - `hash -r`：清空所有缓存 9. 多命令执行bash 中可以同时执行多条命令，命令之间可以没有关系顺序执行，也可以逻辑关系。可以理解为写在命令行的单行脚本。 COMMAND1; COMMAND2;....: 多条命令互不影响，顺序执行 COMMAND1 &amp;&amp; COMMAND2: &amp;&amp; 表示逻辑与，只有在第一条命令执行成功时，才会执行第二条命令 COMMAND1 || COMMAND2: || 表示逻辑或，只有在第一条命令执行失败时，才会执行第二条命令 1id $username || useradd $username 这里可以将 COMMAND1，COMMAND2 想象成一个逻辑判断表达式，&amp;&amp; 表示逻辑与，如果 COMMAND1 为False，整个表达式一定为 False，因此也就没有必要执行 COMMAND2，从样如果COMMAND1 为真，在逻辑或下，整个表达式肯定为真，也没有必要执行第二个表达式。这就是逻辑运算中短路逻辑。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.1 Linux目录结构]]></title>
    <url>%2F2018%2F06%2F14%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2FLinux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux 目录结构 接下来，我们将学习 Linux 下的目录结构和Linux Bash 的基础特性。通过三节内容，我们将学习以下内容: Linux 文件系统及文件的组织结构 Linux 常见的文件类型 Bash 常见特性和快捷键使用 常用基础命令与命令历史 基础的文件管理命令与系统变量 文件系统同样是很复杂的东西，具体原理后面会介绍。当前，只要知道文件系统是操作系统对磁盘的抽象，为用户提供了管理磁盘文件的接口。开机启动时，内核加载完毕之后，内核就会挂载用户在开机启动配置文件中设置的根文件系统。Linux 上的文件系统必需挂载到根文件系统上才能被使用。开机启动流程，文件系统会在之后详细介绍。当前我们需要重点了解的是，Linux 上目录和文件的组织结构。 如同在 Windows 上创建目录和文件上一样，我们可以在Linux 上随意的创建和删除文件。但是就像我们很难在别人的Windows 系统上查找文件一样，如果各Linux 发行厂商随意的组织 Linux 的文件，当我们更换一个 Linux 发行版时，我们可能就很难找到配置文件，应用程序；程序开发者也很难统一配置程序的安装目录。所以 Linux 标准委员会为避免这种情况发生，指定了一个标准，叫 FHS(filesystem hierarchy standard)。 FHS 主要对 /, /usr, /var 的使用进行了规范，我们将按照这三个层次进行介绍。在本文的结尾，我们将对Linxu 上的文件系统类型作详细介绍。 1. FHS 简介1.1 官方文档简介This standard enables: Software to predict the location of installed files and directories, and Users to predict the location of installed files and directories. We do this by: Specifying guiding principles for each area of the filesystem, Specifying the minimum files and directories required, Enumerating exceptions to the principles, and Enumerating specific cases where there has been historical conflict. The FHS document is used by: Independent software suppliers to create applications which are FHS compliant, and work with distributionswhich are FHS complaint, OS creators to provide systems which are FHS compliant, and Users to understand and maintain the FHS compliance of a system.The FHS document has a limited scope: Local placement of local files is a local issue, so FHS does not attempt to usurp system administrators. FHS addresses issues where file placements need to be coordinated between multiple parties such as localsites, distributions, applications, documentation, etc. 1.2 FHS 标准内容概述/, /usr, /var 必需包含的目录，及目录作用如下: / bin/: 所有用户可用的基本命令程序文件 sbin/: 供系统管理使用的工具程序 boot/: 引导加载器必须用到的各静态文件，包括 kernal, initramfs(initrd), grub 等 dev/: 存储特殊文件或设备文件，设备包括如下两种类型 字符设备，又称线性设备 块设备，又称随机设备 etc/: 系统程序的配置文件，只能为静态 home/: 普通用户家目录的集中位置 root/: 管理员家目录 lib: 为系统启动或根文件系统上的应用程序(/bin, /sbin等)提供共享库，以及为内核提供内核模块 libc.so.*： 动态链接的 C库 ld*: 运行时链接器或加载器 modules/: 用于存储内核模块的目录 lib64: 同lib，64 位系统特有的存放 64 位共享库的目录 media/: 便携式设备挂载点 mnt/: 其他文件系统的临时挂载点 opt/: 附加应用程序的安装位置，可选路径 srv/: 当前主机为服务提供的数据 tmp: 为哪些会产生临时文件的程序提供的用于存储临时文件的目录 usr/: shareable, read-only data，独立的层级目录，存放全局共享的只读数据路径 bin/: sbin/: 非管理或维护系统运行所必须的，额外添加的管理命令 lib: lib64: includ/: C 程序头文件 share/: 命令手册页和自带文档等框架特有的文件的存储位置 X11R6: X-Window 程序的安装位置 src: 程序源码文件的存储位置 local/: Local hierarchy 独立的层级目录，让系统管理员安装本地应用程序，也通常用于安装第三方程序- 应用程序多版本共存时，新版程序通常安装于此目录 - 层级结构与 /usr 类似 var/: var Hierarchy, 独立的层级目录，用于存储常发生变化的数据的目录 cache/: Application cache data lib/: Variable state information local/: Variable data for /usr/local lock/: Lock files log: Log files and directories opt/: Variable data for /opt run/: Data relevant to running processes spool/: Application spool data tmp/: Temporary files preserved between system reboots proc/: 基于内存的虚拟文件系统，用于为内核及进程存储其相关信息； 它们多为内核参数，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径； 其主要作用在于为管理Linux设备提供一种统一模型的的接口； 参考: https://www.ibm.com/developerworks/cn/linux/l-cn-sysfs/ 2. / 根目录3. /usr 目录4. /var 目录5. Linux 系统上的文件类型5.1 常见文件类型：1234&gt; lldrwxrwxr-x. 2 tao tao 158 2月 25 18:32 ankidrwxrwxr-x. 3 tao tao 43 2月 24 18:36 codingdrwxrwxr-x. 4 tao tao 53 1月 30 14:11 linux ls -l 命令显示结果第一列的首子母即表示文件类型，Linux 中的文件类型如下 -：常规文件；即f； d: directory，目录文件(路径映射) b: block device，块设备文件，支持以“block”为单位进行随机访问 c：character device，字符设备文件，支持以“character”为单位进行线性访问 l：symbolic link，符号链接文件 p: pipe，命名管道 s: socket，套接字文件 5.2 设备文件的设备号1234&gt; ll /dev# 10, 58 表示设备的设备号crw-------. 1 root root 10, 58 6月 19 21:35 network_latencycrw-------. 1 root root 10, 57 6月 19 21:35 network_throughput 设备文件还有设备号，其作用如下: major number：主设备号，用于标识设备类型，进而确定要加载的驱动程序; 8位二进制：0-255 minor number：次设备号，用于标识同一类型中的不同的设备; 8位二进制：0-255]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.2 Linux 命令帮助]]></title>
    <url>%2F2018%2F06%2F13%2Flinux_mt%2F03-Linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F</url>
    <content type="text"><![CDATA[Linux 中获取命令帮助 通过之前的学习我们了解到 Linux 命令分为两类，一类是 shell 内置的内嵌命令，另一类是外部命令。这两种命令获取帮助的并不相同，对于内部命令使用 help command 即可。而对于外部命令有很多方式，其中最重要也是最便捷的就是使用 man 帮助手册。本节我们将学习如何获取外部命令的使用帮助，以及了解 man 手册的使用方式。 1. 获取命令的使用帮助内部命令：help COMMAND外部命令： COMMAND --help: 命令自带简要格式的使用帮助 man COMMAND: 使用手册：manual info COMMAND: 获取命令的在线文档； 很多应用程序会自带帮助文档：/usr/share/doc/APP-VERSION，包括不限于 README：程序的相关的信息； INSTALL: 安装帮助； CHANGES：版本迭代时的改动信息； 主流发行版官方文档: eg：http://www.redhat.com/doc 程序官方的文档：官方站点上的”Document” 搜索引擎 123# google 搜索引擎的使用技巧keyword filetype:pdfkeyword site:domain.tld 2. man 帮助手册的使用简述2.1 man 手册页组成关于man的简介如下列表所示: man手册的原始文档位于 /usr/share/man中， 使用手册为压缩格式的文件，有章节之分,包括 ls /usr/share/man man1：用户命令； man2：系统调用； man3：C库调用； man4：设备文件及特殊文件； man5：文件格式；（配置文件格式） man6：游戏使用帮助； man7：杂项； man8：管理工具及守护进行； 当我们 man COMMAND 进入man手册后，其由如下几个部分组成。界面示例如下 SECTION：组成部分 NAME：功能性说明 SYNOPSIS：语法格式 DESCRIPTION：描述 OPTIONS：选项 EXAMPLES：使用示例 AUTHOR: 作者 BUGS: 报告程序bug的方式 SEE ALSO: 参考 SYNOPSIS: 命令使用 []：可选内容； &lt;&gt;：必须提供的内容； a|b|c：多选一； ...：同类内容可出现多个； 123456789101112131415161718&gt; man ifconfigIFCONFIG(8) Linux System Administrator&apos;s Manual IFCONFIG(8)NAME ifconfig - configure a network interfaceSYNOPSIS ifconfig [-v] [-a] [-s] [interface] ifconfig [-v] interface [aftype] options | address ...NOTE This program is obsolete! For replacement check ip addr and ip link. For statistics use ip -s link.DESCRIPTION Ifconfig is used to configure the kernel-resident network interfaces. It is used at boot time to set up interfaces as necessary. After that, it is usually only needed when debugging or when system tuning is needed.............. 1.2 man 命令使用man [CHAPTER] COMMAND 作用: 在特定章节中搜索命令的帮助手册, CHAPTER 参数可选 注意： 并非每个COMMAND在所有章节下都有手册； 可通过 whatis COMMAND 查看哪些章节中存在COMMAND 的帮助手册 whatis的执行过程是查询数据库进行的，必要时可通过 makewhatis 手动更新数据库 1.2 man 手册查看操作进入man手册页之后，其界面环境就是调用 less 命令的执行结果，可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit)]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.1 Linux 命令基础]]></title>
    <url>%2F2018%2F06%2F12%2Flinux_mt%2F03-Linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 基础命令 在安装完 Centos 之后，我们开始正式学习 Linux。在深入学习 Linux 之前，我们需要学习一些最基本命令的使用。我们将分成两节来学习下面内容: Linux 中的命令类型 Linux 命令的标准使用格式 Linux 常见基础命令的使用 如何使用 Linux 帮助文档 Linux 各个部分大多都有标准进行规范，以降低在不同发行版之间的迁移难度，命令也不例外。本节我们首先将学习命令的语法通用格式，然后了解 Linu 中命令的分类；最后介绍 Linux 常用的基础命令。 1. 命令的语法通用格式：COMMAND OPTIONS ARGUMENTS COMMAND: 命令名，发起一命令，请求内核将某个二进制程序运行为一个进程； 命令本身是一个可执行的程序文件：二进制格式的文件，有可能会调用共享库文件； 多数系统程序文件都存放在：/bin, /sbin, /usr/bin, /usr/sbin，/usr/local/bin, /usr/local/sbin 普通命令：/bin, /usr/bin, /usr/local/bin 管理命令：/sbin, /usr/sbin, /usr/local/sbin 共享库：/lib, /lib64, /usr/lib, /usr/lib64, /usr/local/lib, /usr/local/lib64 32bits的库：/lib, /usr/lib, /usr/local/lib 64bits的库：/lib64, /usr/lib64, /usr/local/lib64 注意：并非所有的命令都有一个在某目录与之对应的可执行程序文件 命令必须遵循特定格式规范：exe, msi, ELF(Linux) 查看命令类型: file /bin/ls OPTIONS： 作用: 命令选项，指定命令的运行特性； 类型: 选项有两种表现形式： 短选项：-C, 例如-l, -d 注意：有些命令的选项没有-； 如果同一命令同时使用多个短选项，多数可合并：-l -d = -ld 长选项：–word, 例如–help, –human-readable 注意：长选项不能合并； 注意：有些选项可以带参数，此称为选项参数； ARGUMENTS： 命令的作用对象；命令对什么生效； 注意：不同的命令的参数；有些命令可同时带多个参数，多个之间以空白字符分隔； 例如：ls -ld /var /etc 2. Linxu 的命令类型 命令分为两类： 内置命令(builtin): 由shell程序的自带的命令： 外部命令: 独立的可执行程序文件，文件名即命令名： 查看命令类型：type COMMAND 内部命令显示为 builtin 外部命令显示为命令文件路径； 注意：命令可以有别名；别名可以与原名相同，此时原名被隐藏；此时如果要运行原命令，则使用\COMMAND； 3. Linxu 的常用命令3.1 文件与目录查看命令pwd: 作用: 显示工作目录 cd：cd [/PATH/TO/SOMEDIR] 作用: change directory 改变当前工作目录 选项: cd: 切换回家目录；注意： cd ~：切换回自己的家目录，bash中, ~表示家目录； cd ~USERNAME：切换至指定用户的家目录； cd -：在上一次所在目录与当前目录之间来回切换； 附注: 相关的环境变量 $PWD：当前工作目录 $OLDPWD：上一次的工作目录 lsls [OPTION] [FILE] 作用: list, 列出指定目录下的内容 选项: -a: 显示所有文件，包括隐藏文件； -A: 显示除.和..之外的所有文件； -l: –long, 长格式列表，即显示文件的详细属性信息； -h: –human-readable：对文件大小单位换算；换算后结果可能会非精确值； -d: 查看目录自身而非其内部的文件列表； -r: reverse, 逆序显示； -R: recursive，递归显示； cat：cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac：tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； filefile [FILE] 作用: 查看文件内容类型； echoecho [SHORT-OPTION] [STRING] 作用: 回显 选项: -n: 不进行换行； -e：让转义符生效； Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name 3.2 关机与重启命令shutdownshutdown [OPTIONS] [TIME] [WALL] 作用: 关机或重启命令 OPTIONS: -h: halt -r: reboot -c: cancel TIME： now: 立刻马上 hh:mm: 指定几时几秒 +m: m 分钟后 +0 3.3 日期相关的命令：Linux 系统启动时从硬件读取日期和时间信息；读取完成以后，就不再与硬件相关联；此时系统时钟与硬件时钟是相互独立的 datedate [OPTION] [+FORMAT] 作用: 显示系统时钟日期时间： 选项: -d String|-d @timestamp: 显示指定的时间字符串或时间戳表示的时间 -s, --set=STRING: 设置系统时间 FORMAT：格式符 %F:= %Y-%m-%d %T:直接显示时间 (24 小时制) %Y:完整年份 (0000-9999) %m:月份 (01-12) %d:日 (01-31) %H:小时(00-23) %M:分钟(00-59) %S:秒(00-60) %s:从1970年1月1号(unix元年)0点0分0秒到命令执行那一刻经过的秒数； 123456789101112131415# 按特定格式显示时间&gt; date +%s1531134611&gt; date -d @1531134611 +%F2018-07-09&gt; date -d &quot;2017-10-13 23:00:00&quot; +%F2017-10-13&gt; date# 设置系统时间&gt; date -s &quot;2018-10-13 23:10:12&quot;&gt; date -s &quot;2018/10/13 23:10:12&quot; hwclock / clockhwclock [function] [option] 作用:显示或设定硬件时钟 选项: -s: –hctosys,以硬件为准，把系统调整为与硬件时间相同； -w: –systohc：以系统为准，把硬件时间调整为与系统时钟相同； cal：cal [[month] year] 作用: 显示日历 3.4 命令别名与查找alias [alias-name[=string] 作用: 查看或定义命令别名： 常用: alias: 获取所有可用别名的定义： alias NAME=&#39;COMMAND&#39;： 定义别名： 注意：仅对当前shell进程有效 unalias NAME: 撤销别名： whichwhich [options] programname 作用: shows the full path of (shell) commands 选项: --skip-alias：忽略别名 whereis命令：whereis [options] name 作用: locate the binary, source, and manual page files for a command 选项: -b: 仅搜索二进制程序路径； -m：仅搜索使用手册文件路径； 3.5 登录用户查看whowho [OPTION] 作用: show who is logged on 选项: -b: 系统此次启动的时间； -r: 显示系统运行级别； ww [user] 作用: Show who is logged on and what they are doing. 增强版的 who ttytty 作用: 显示当前终端]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 Centos 安装]]></title>
    <url>%2F2018%2F06%2F11%2Flinux_mt%2F02-Linxu%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E4%BB%8B%E7%BB%8D%2FVmware%E4%B8%8BCentos%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[Vmware 下 Centos 的安装 1. Centos 安装]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 Linux 入门开篇]]></title>
    <url>%2F2018%2F06%2F10%2Flinux_mt%2F01-Linux%E4%BA%91%E8%AE%A1%E7%AE%97%E5%85%A5%E9%97%A8%E6%80%BB%E7%BA%B2%2F</url>
    <content type="text"><![CDATA[为什么要学习 Linux 1. Linux 云计算入门总纲开篇，应该是 Linux 学习和职业发展的指引。然后作为 Linux 的半吊子，说实话还没有建立起这样的知识框架，也就很难对这个行业的发展有独到深刻的见解。只想结合自己的实际经历，谈谈为什么自己想学好 Linux。下面这些理由，不知道是不是能命中你 Linux 实在太通用，无处不在，看到别人用到溜到飞，自己当然很想尝试 后端开发距最终的上线部署还有一段距离，很困惑自己写的程序最终是怎么服务用户的 云，docker 新技术层出不穷，自己却完全不知道是什么 很困惑怎么才能构建一个供1000万人以上的服务 说白了，就是对整个程序架构没有一个完整的认识，而个人觉得学习 Linux 运维建立认知最快，最直接的途径。 最近报名了马哥 Linux 培训班，希望能在 2018 年学好 Linux。学习 Linux 已经有很长一段时间，但始终感觉不得法，自我总结原因有两个。一是学习能力不够，难以形成完整的知识体系，二是工作中能使用 Linux 的场景还太少，缺少练习。 此博客用于记录和整理 Linux 运维知识和使用经验。一来督促自己养成写博客的习惯，二来提高学习效率，三来便于以后查询。 2. Linux 基础入门要了解操作系统或应用程序是怎么在计算机上运行起来的，其实是一件非常复杂的事。需要了解组成计算机的基本硬件，学习操作系统原理。想深入学习这块，推荐阅读《深入理解计算机系统》，《操作系统原理》。但作为初学者，很不建议在基本原理上花费很长时间，很容易让人奔溃。首先是要学会使用 Linux，在学习使用的过程逐步了解底层原理，循序渐进。 个人经验，除非智商超群，或是已经在相关领域有所积累，否则都应该从简单和基础入手，越简单越好，循序渐进才是最高效的学习途径。 接下来的内容，我们来学习如何在 Vmware 安装一个 Centos 系统，搭建起我们的学习环境。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 wrapt 模块实战]]></title>
    <url>%2F2018%2F06%2F07%2Fwrapt%2Fpython_decorator_16%2F</url>
    <content type="text"><![CDATA[装饰器和 wrapt 模块的介绍已经结束，作为整个系列的最后一篇的实战篇，我们来实现在一开始我提出的一个需求 1. 应用场景在我日常的开发过程中，经常要查询各种数据库，比如 mysql, mongo，es 。基本上所有的数据库对查询语句能添加的查询条件都有限制。对于大批量的查询条件，只能分批多次查询，然后将查询结果合并。我们能不能将这种查询分批在合并的操作抽象出来实现为一个装饰器，在需要时对查询函数包装即可？下面是我的一个实现示例。 2. 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/usr/bin/python# -*- coding: utf-8 -*-"""作用：用于优化的装饰器功能： 1. 实现分组迭代，分批查询的装饰器"""import osimport sysimport wraptimport inspectimport pandasdef get_slice(total_num, slice_num): """ :return: 等大小切片 """ r = [] n = total_num / slice_num m = total_num % slice_num end = 0 for i in range(1, n + 1): start = slice_num * (i - 1) end = slice_num * i r.append(slice(start, end)) else: if m &gt; 0: r.append(slice(end, end + m)) return rdef slice_call(iter_param, slice_num=500): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 函数自省 param = inspect.getcallargs(wrapped, *args, **kwargs) if instance: param.pop('self') if 'kwargs' in param: kwargs = param.pop('kwargs',&#123;&#125;) param.update(kwargs) iter_value = param.get(iter_param) if iter_value is None: return wrapped(**param) if isinstance(iter_value, pandas.DataFrame): iter_value.reset_index(drop=True, inplace=True) # 分批 total_num = len(iter_value) slice_iter = get_slice(total_num, slice_num) result = [] # 合并 for s in slice_iter: param[iter_param] = iter_value[s] result.append(wrapped(**param)) if result: return pandas.concat(result) else: return pandas.DataFrame() return wrapper# slice_call 使用示例@slice_call(iter_param='names')def get_video_by_name(self, names, c_type): where_name = "'" + "','".join(names) + "'" sql = ('select * from table' 'where a="%s" and b in (%s) and c&gt;=0;' % (c_type, where_name)) print sql df = self.mysql_obj.query('', sql) df['updateTime'] = df['updateTime'].apply(lambda x: x.strftime("%Y-%m-%d")) return df slice_call 函数在使用有一个限制条件，被包装函数的返回值必需是 pandas.DataFrame。因为在我日常的工作中，经常使用到 pandas 进行数据分析，对我来说，DataFrame 是一个非常通用的数据结构，因此就在此基础上构建了 slice_call 装饰器。整个实现中使用的额外知识就是函数的自省，由 inspect 模块提供，其他有关装饰器的部分都是前面博客介绍的内容，相信大家应该很容易就能看懂。 结语至此 Python 装饰器的内容就先到此为止，接下来想结合 wrapt, unittest, mock 来说一说如何在 Python 中作单元测试。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 wrapt 模块使用]]></title>
    <url>%2F2018%2F06%2F06%2Fwrapt%2Fpython_decorator_15%2F</url>
    <content type="text"><![CDATA[GrahamDumpleton wrapt blog 的翻译部分到此就结束。很可惜的是作者并没有把猴子补丁部分写完，查阅了 wrapt 的官方文档，上面只介绍了 wrapt 的装饰器，代理对象以及 synchronized 同步装饰器，也没有介绍猴子补丁相关内容。不过已经介绍的内容足够用了，接下来我想结合 wrapt 的文档介绍一下 wrapt 模块的使用，算是整个博客的总结。 1. 前文回顾在阐述 wrapt 的使用之前，有必要对之前的内容做一个简单总结，因为 wrapt 模块的接口正是与之前的内容一一对应的。GrahamDumpleton 编码 wrapt 的本意是想实现为 Python 代码中添加猴子补丁，然而 Python 中装饰器，辅助测试的模拟库与猴子补丁的实现方式极其相似，因此 GrahamDumpleton 就按照如下的方式为将我们讲解了 wrapt 模块的功用。 如何在 Python 实现一个通用的装饰器 如何使用 wrapt 实现模拟库来辅助单元测试 如何为 Python 添加猴子补丁 装饰器，模拟库，猴子补丁的实现是递进的。装饰器通常是在导入时，在被装饰的函数定义之后立即运行，且永久全局有效；模拟库作用的范围变窄，需要实现只作用于特定范围，比如特定的测试函数中；猴子补丁更随意，通常在类创建一段时间之后再执行，这种延迟性导致猴子补丁存在相对导入的次序问题。对于我们而言搞清楚装饰器与模拟库的使用即可，能使用到猴子补丁的情景少之又少。 装饰器那如何实现一个装饰器？传统的通过闭包实现的装饰器存在以下问题: 无法保留函数的自省属性和签名信息，无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 为解决这些问题和解决代码复用问题，wrapt 创建了以下对象或函数: 代理对象: ObjectProxy，解决了自省问题 包装对象: FunctionWrapper, BoundFunctionWrapper 继承自 ObjectProxy，并为装饰行为实现了描述符协议 工厂函数: decorator 解决了创建装饰器的代码复用问题。 wrapt 为辅助单元测试提供了另外一个工厂函数 transient_function_wrapper，其能创建一个仅仅限于特定范围的临时补丁。 装饰器实现的核心就是包装器对象，它同时接收包装函数，和被包装函数，并作为装饰结果的返回值替换被包装函数。在被包装函数被调用时，实际调用包装函数。所以包装对象同时实现了对象代理和描述符协议。 2. wrapt 接口123456789101112# wrapt.__init__from .wrappers import (ObjectProxy, CallableObjectProxy, FunctionWrapper, BoundFunctionWrapper, WeakFunctionProxy, resolve_path, apply_patch, wrap_object, wrap_object_attribute, function_wrapper, wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper)from .decorators import (adapter_factory, AdapterFactory, decorator, synchronized)from .importer import (register_post_import_hook, when_imported, notify_module_loaded, discover_post_import_hooks) wrapt 模块提供的接口大体上分成了以下几类: 代理对象: ObjectProxy, CallableObjectProxy, WeakFunctionProxy 包装对象: FunctionWrapper, BoundFunctionWrapper 装饰器工厂函数: function_wrapper, decorator 辅助测试的工厂函数: wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper 猴子补丁相关: .importer synchronized: java synchronized 的 Python 实现 接下来我们会详细介绍上述典型接口的使用方式。 2. 代理对象 ObjectProxy所谓代理包含两个层面的意思: 将上层的请求传递给后端的对象 将后端对象的返回值返回给上层的调用方 wrapt 模块的底层实现就是基于透明对象代理的包装器类。这种代理对象不仅代理了普通方法和属性的访问，也代理了众多内置方法和自省属性。这使得代理对象和被代理对象在 Python 的数据模型层面是完全一致。使用代理对象去代替被代理对象不会打破 Python 的内省机制。并且我们可以在代理对象上自定义属性和方法，以此来重载被代理对象的默认功能。 2.1 对象联动123456class ObjectProxy(with_metaclass(_ObjectProxyMetaType)): __slots__ = '__wrapped__' def __init__(self, wrapped): object.__setattr__(self, '__wrapped__', wrapped) ObjectProxy 是 wrapt 代理功能实现的基类，通常不直接使用，而是作为自定义代理对象的基类使用。代理对象实现了如下功能: 所有对代理对象的访问都会传递给被代理对象，包括比较操作，哈希这些 Python 的内置方法 在代理对象上自定义的方法会覆盖被代理对象同名方法，因此我们可以通过代理对象实现对被代理对象的方法重载 所有对代理对象属性的修改都会传递并修改后端的被代理对象 对后端被代理对象属性的直接修改也会直接反映在代理对象之上 也就是说默认情况下，对 ObjectProxy 的操作，方法是重载的，而对属性的修改，是直接作用在被代理对象上的。 123456789101112&gt;&gt;&gt; table = &#123;&#125;&gt;&gt;&gt; proxy = wrapt.ObjectProxy(table)&gt;&gt;&gt; proxy['key-1'] = 'value-1'&gt;&gt;&gt; proxy['key-2'] = 'value-2'&gt;&gt;&gt; proxy.keys()['key-2', 'key-1']&gt;&gt;&gt; table.keys()['key-2', 'key-1']&gt;&gt;&gt; isinstance(proxy, dict)True 2.2 不可变对象上述操作对于不可变对象的自操作是特例。 1234567891011121314&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; proxy += 1&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; print(proxy)2&gt;&gt;&gt; print(value)1 对于不可变对象，被代理对象保存的被代理对象的副本，因此对其自身的修改不会影响到后端的被代理对象。 2.3 类型比较由于 Python 复杂的对象模型和底层设计，以及 instance 函数内在比较逻辑，想把 ObjectProxy 类型比较的原理说清楚实在不容易。这里就不深入见解了，简而言之 ObjectProxy 类实例的__class__ 属性返回的是被代理对象的__class__ 属性值，instance()在进行类型检查时，首先比较的是 __class__，所以对代理对象进行类型比较的结果与以被代理对象本身进行比较的结果完全一致。同时由于抽象基类机制，ObjectProxy 实例与 ObjectProxy 类的类型比较也能正常进行。 12345678910111213141516171819202122232425&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; class CustomProxy(wrapt.ObjectProxy):... pass&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; type(proxy)&lt;class '__main__.CustomProxy'&gt;# 与被代理对象的类型比较&gt;&gt;&gt; proxy.__class__&lt;type 'int'&gt;&gt;&gt;&gt; isinstance(proxy, int)True# 与代理对象的类型比较&gt;&gt;&gt; isinstance(proxy, wrapt.ObjectProxy)True&gt;&gt;&gt; isinstance(proxy, CustomProxy)True 2.4 方法重载方法重载只要在自定义代理对象上自定义同名的方法即可，在代理对象内，通过 __wrapped__ 属性可以访问到原始的被代理的对象。 123456789101112131415161718def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __call__(self, *args, **kwargs): print('entering', self.__wrapped__.__name__) try: return self.__wrapped__(*args, **kwargs) finally: print('exiting', self.__wrapped__.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function)&gt;&gt;&gt; proxy()('entering', 'function')('executing', 'function')('exiting', 'function') 2.5 属性重载因为对 ObjectProxy 属性的访问都会直接代理至后端被代理对象，那如何自定义 ObjectProxy 自身的属性呢？ 方法一，任何以 _self_ 开头的属性只会保存在 ObjectProxy 上，不会传递给后端的被代理对象 12345678910111213141516171819202122232425262728def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs)def wrapper(wrapped, args, kwargs): print('entering', wrapped.__name__) try: return wrapped(*args, **kwargs) finally: print('exiting', wrapped.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function, wrapper)&gt;&gt;&gt; proxy._self_wrapper&lt;function wrapper at 0x1005961b8&gt;&gt;&gt;&gt; function._self_wrapperTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function' object has no attribute '_self_wrapper' 方法二，借助于 @property，定义属性描述符1234567891011121314151617181920212223242526272829class CustomProxy(wrapt.ObjectProxy): def __init__(self, wrapped): super(CustomProxy, self).__init__(wrapped) self._self_attribute = 1 @property def attribute(self): return self._self_attribute @attribute.setter def attribute(self, value): self._self_attribute = value @attribute.deleter def attribute(self): del self._self_attribute&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; print proxy.attribute1&gt;&gt;&gt; proxy.attribute = 2&gt;&gt;&gt; print proxy.attribute2&gt;&gt;&gt; del proxy.attribute&gt;&gt;&gt; print proxy.attributeTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'int' object has no attribute 'attribute' 方法三，将属性定义为类属性123456789101112131415&gt;&gt;&gt; class CustomProxy(ObjectProxy):... attribute = None...&gt;&gt;&gt; def function():... print('executing', function.__name__)...&gt;&gt;&gt; j = CustomProxy(function)&gt;&gt;&gt; j.attribute = 2&gt;&gt;&gt;&gt;&gt;&gt; function.attribute = 5&gt;&gt;&gt; print(j.attribute)2&gt;&gt;&gt; print(function.attribute)5 3. 扩展的代理对象除了默认 ObjectProxy 代理基类，wrapt 还提供了另外两个通用的代理对象。 3.1 CallableObjectProxy1234class CallableObjectProxy(ObjectProxy): def __call__(self, *args, **kwargs): return self.__wrapped__(*args, **kwargs) CallableObjectProxy 代理对象专用于代理函数，只是额外的附加了__call__方法，让代理对象成为可调用对象。 3.2 WeakFunctionProxy123456# 代理有点长，不粘了，有兴趣查看 wrapt 的源码class WeakFunctionProxy(ObjectProxy): __slots__ = ('_self_expired', '_self_instance') def __init__(self, wrapped, callback=None): 默认情况下，代理对象通过 __wrapped__ 属性保存了对被代理对像的引用，这样会导致被代理对象始终被引用而无法被垃圾处理器收回，WeakFunctionProxy 的作用就是实现在代理对象中实现对被代理对象的弱引用。在代理对象中实现弱引用并不容易，特别是对绑定方法对象的处理，以及要避免在回调函数中出现循环引用。有兴趣的同学可以看看 wrapt 的源代码。 3.3 自定义代理对象如上述两个内置扩展的代理对象，通过继承 ObjectProxy，我们也可以自定代理对象。代理对象中的方法会覆盖被代理对象的同名方法，利用这个特性我们可以重载被代理对象的行为，这在单元测试中经常使用，待会会有使用的详细示例。 4. 包装对象下面是在代理对象基础上实现包装器的简单示例，包装器继承自 wrapt.ObjectProxy，并将被代理对象作为参数传递给 ObjectProxy，从而具备了代理功能，并在此基础上附加了描述协议的处理逻辑。我们需要使用或者自定义包装对象的情景很少，此处不再对其作过多描述。 123456789101112class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __get__(self, instance, owner): function = self.__wrapped__.__get__(instance, owner) return BoundCallableWrapper(function, self._self_wrapper) def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs) 5. 辅助测试5.1 工厂函数wrapt 中有三个辅助测试的包装对象 wrapt.wrap_function_wrapper: 创建猴子补丁的工厂函数，会创建永久有效的补丁 wrapt.patch_function_wrapper: 简化 wrapt.wrap_function_wrapper 的装饰器函数 wrapt.transient_function_wrapper: 创建一个仅仅限于特定范围的临时补丁 下面是它们的使用实例 1234567891011121314151617181920212223242526def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)class Example(object): def name(self): return 'name'import wrapt# 版本一wrapt.wrap_function_wrapper(Example, 'name', wrapper) # 等同于wrapt.wrap_function_wrapper('example', 'Example.name', wrapper)# 版本二@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)# 版本三，wrapper 只对 test_method() 函数有效@transient_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@wrapper def test_method(): pass 5.2 高阶用法除了上述简单的使用示例外，12 使用 wrapt 辅助测试 还有更高级的使用示例，下面是示例代码。 包装一个返回函数的被包装对象12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 包装一个类示例的被包装对象123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 6. synchronizedsynchronized 装饰器实现了 java 中的同步原语 synchronized 功能。synchronized 功能和实现请参阅 07 实现 java 的 @synchronized 装饰器，下面是其使用方式 6.1 作为装饰器123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 6.2 作为上下文管里器1234567891011121314151617181920class Class(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): passclass Class(object): @synchronized @classmethod def function_cm(cls): pass def function_im(self): with synchronized(Class): pass 6.3 基于任意对象作同步除了使用默认的内置锁，synchronized 支持接收任意对象实现同步。但是作为同步而传入的对象必需能添加属性，因为 synchronized 会在传入的对象上保存创建的锁对象。因此为解除这个限制，synchronized 也支持传入支持 .require 和 .release 的类锁对象实现同步。 123456789101112131415161718192021class Data(object): passdata = Data()def function_1(): with synchronized(data): passdef function_2(): with synchronized(data): pass# synchronized 使用到了 vars(data)，任何没有 `__dict__` 属性的对象，都会调用失败&gt;&gt;&gt; vars(&#123;&#125;)Traceback (most recent call last): File "/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2882, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-3-880c6250c41c&gt;", line 1, in &lt;module&gt; vars(&#123;&#125;)TypeError: vars() argument must have __dict__ attribute 6.4 基于传入的类锁对象作同步12345semaphore = threading.Semaphore(2)@synchronized(semaphore)def function(): pass 任何支持 acquire() 和 release() 对象均可作为 synchronized的参数，因此用户可传入包含这两个方法的自定义对象来实现额外的功能。 7. decorator12def decorator(wrapper=None, enabled=None, adapter=None): pass decorator 工厂函数是 function_wrapper 工厂函数的升级版本，在装饰器基础上添加了另外两个控制功能，enabled 和 adapter参数必需作为关键词参数被使用。 7.1 装饰启动开关静态控制enabled 参数用于控制装饰器是否被启用，接收布尔值作为参数，enabled=True 时，装饰器正常启用，enabled=False 时不会应用任何包装器。因此，这提供了一种方便的方法，可以全局禁用特定的decorator，而不必删除decorator的所有用法，或者使用decorator函数的特殊变体。 123456789101112ENABLED = False@wrapt.decorator(enabled=ENABLED)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@pass_throughdef function(): pass&gt;&gt;&gt; type(function)&lt;type 'function'&gt; 动态控制在定义修饰符时为启用的选项提供一个布尔值，从而控制修饰符是否应该应用。因此，这是一个全局开关，一旦禁用，就无法在运行时在进程执行时动态地重新启用它。类似地，一旦启用，就不能禁用它。 提供布尔值的另一种方法是为enabled提供一个可调用对象 callable，该值返回一个布尔值。每次调用修饰函数时都将调用callable。如果callable返回True，表示decorator是活动的，则将调用包装器函数。如果callable返回False，包装器函数将被绕过，原始包装函数将被直接调用。 如果enabled不是None、布尔值或可调用值，则将对提供的对象执行布尔检查。这允许使用支持逻辑操作的定制对象。如果定制对象计算为False，包装器函数将再次被绕过。 123456def _enabled(): return True@wrapt.decorator(enabled=_enabled)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 7.2 更改签名信息默认的包装函数的签名来自被包装对象，adapter 参数的作用用于修改包装函数的签名信息。其接收一个函数作为参数，此函数的签名信息将作为包装函数的签名信息被返回。这个用的很少，就不再累述了。 实战有关 wrapt 的模块的实现和接口到此就介绍完了，在本系列博客的开篇我提到了我使用装饰器的一个典型应用场景: 对数据库查询实现分批操作。在接下来的的博客中，作为实战篇，我们来看看如何通过 wrapt 实现这个比较通用的需求。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 为 Python 应用自动打补丁]]></title>
    <url>%2F2018%2F06%2F05%2Fwrapt%2Fpython_decorator_14%2F</url>
    <content type="text"><![CDATA[前面我们已经决绝了猴子补丁的导入次序问题，但是这个解决方案有个前提，就是我们必需能修改应用程序代码，以在程序的最开始执行我们的注册函数。本节我们的目的是找到另一种解决方案取消这个限制。 1. 猴子补丁的问题所在在之前关于猴子的文章中，我们讨论了导入次序问题。也就是说，正确使用猴子补丁取决于，我们能在任何其他代码导入我们想要修补的模块之前为其打上打补丁。换句话说就是在我们打补丁之前，其他代码是否已经按名称导入了对模块内函数的引用，并将其存储在它自己的名称空间中。即在打补丁之前，其他模块是否已经使用了 from module import function 如果我们不能尽早进入，那么就需要对目标函数的所有使用打补丁，这在一般情况下是不可能的，因为我们不知道函数在哪里被导入。我所描述的一种解决方案是使用导入后钩子机制，使我们能够在模块被任何代码导入之前访问模块并打补丁。这种技术仍然依赖于在有效运行其他代码之前安装导入后钩子机制本身。这意味着必须手动修改应用程序的主Python脚本文件，这并不总是实用的。本文的目的是研究如何避免修改主Python脚本文件来解决导入次序问题。 2. 在 .pth 文件中执行代码作为Python导入系统的一部分，以及在哪些目录中搜索Python模块，有一种扩展机制，即可以将一个.pth扩展名文件安装到Python的site-packages目录中。用于指明Python包代码并不在默认的Python模块搜索路径上，而是存在于其他位置，通常是在site-packages的子目录中。.pth文件的目的是充当指向Python包的实际代码的指针。 在简单的情况下，.pth文件将包含与包含Python包代码的实际目录的名称相关的或绝对的路径名。如果它是一个相对路径名，那么它将相对于.pth文件所在的目录。 如果使用 .pth，当Python 解释器初始化时，它会创建Python模块的搜索路经，在添加所有默认搜索目录后，它将查找 site-packages内的所有目录，并解析每一个 .pth 文件，并将 .pth 内的目录添加到最后的搜索目录列表中。 现在，在Python的历史中，这个.pth机制被增强了，以支持一个特殊的情况。这种特殊情况是，如果.pth文件中的一行从导入开始，那么该行将作为Python代码执行，而不是简单地将其作为目录添加到要搜索模块的目录列表中。 这最初是为了允许为模块执行特殊的启动代码，以允许为Unicode注册一个非标准的编解码器。不过，它后来也被用于easy_install的实现中，如果您曾经运行过easy-install并查看了site-packages目录中的easy-install.pth文件，您会发现以下代码: 123import sys; sys.__plen = len(sys.path)./antigravity-0.1-py2.7.eggimport sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new) 因此，只要能够将代码放在一行上，就可以在每次运行Python解释器时，在.pth文件中做一些非常古怪的事情。我(作者)认为可执行代码在.pth文件中的概念是非常危险的，到目前为止，我(作者)一直避免依赖.pth文件的这个特性。 我(作者)对.pth文件中的可执行代码的担心是它总是在运行。这意味着，即使您已经将预构建的RPM/DEB包或Python wheel 安装到系统中的Python安装环境中，并且认为这样做更安全，因为避免了作为根用户运行 setup.py。但是.pth文件意味着包仍然可以在您不知情的情况下运行代码，甚至不需要将模块导入任何应用程序。考虑到安全性，Python真应该有一个白名单机制，用于确定信任哪些.pth文件，以允许其在每次运行Python解释器(特别是作为根用户)时执行代码。 如果有人关心的话，我将把这个讨论留给其他人来讨论，至少现在我将展示如何使用.pth文件的这个特性(滥用)来实现对正在运行的任何Python应用程序进行自动的猴子补丁的机制。 3. 添加导入勾子在前一篇文章中，我们讨论的导入后钩子机制，在任何Python应用程序脚本文件的开头，我都需要手动添加如下代码: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 它所做的是使用环境变量作为任何使用setuptools入口点注册的包的名称来源，这些入口点包含我们想要应用的猴子补丁。 了解了可以在.pth文件执行代码的能力,现在可以使用它，让这段代码在Python解释器启动时自动执行,从而避免了每次都需要手动修改每个Python应用程序，来应用我们的猴子补丁。 但是在实践中，我们需要的代码实际上要比这个稍微复杂一些，并且不能很容易地直接添加到.pth文件中，这是由于需要将所有代码写在一行上。因此，我们要做的是将所有代码放在一个单独的模块中，然后执行该模块。我们不希望每次都导入那个模块，也许用户看到它被导入时会感到害怕，即使它没有被使用，所以我们将通过环境变量的判断使用它。因此，我们可以在我们的.pth中使用的是: 1import os, sys; os.environ.get('AUTOWRAPT_BOOTSTRAP') and __import__('autowrapt.bootstrap') and sys.modules['autowrapt.bootstrap'].bootstrap() 也就是说，如果环境变量被设置为非空值，那么我们需要导入包含引导代码的模块并执行它。至于引导代码，这就有点麻烦了。我们不能只使用以前手动修改Python应用程序脚本文件时使用的代码。这是因为.pth文件的解析发生在Python解释器初始化。 问题有两个。第一个问题发生在执行导入钩子的发现，当.pth文件被执行时，它被处理的顺序是未知的，所以在我们的代码运行的时候，最终的Python模块搜索路径可能没有设置。第二个问题是.pth文件的处理发生在任何sitecustomize.py或usercustomize.py被处理完之前。因此，Python解释器可能不在其最终配置状态。因此，我们必须对我们所做的事情小心一点。 我们真正需要的是将任何操作延迟到Python解释器的初始化完成之后。问题是我们如何做到这一点。 4. site 模块Python解释器初始化的最后部分是由site 模块的main()函数完成的 1234567891011121314151617181920212223def main(): global ENABLE_USER_SITE abs__file__() known_paths = removeduppaths() if ENABLE_USER_SITE is None: ENABLE_USER_SITE = check_enableusersite() known_paths = addusersitepackages(known_paths) known_paths = addsitepackages(known_paths) if sys.platform == 'os2emx': setBEGINLIBPATH() setquit() setcopyright() sethelper() aliasmbcs() setencoding() execsitecustomize() if ENABLE_USER_SITE: execusercustomize() # .pth 在此之后执行 # Remove sys.setdefaultencoding() so that users cannot change the # encoding after initialization. The test for presence is needed when # this module is run as a script, because this code is executed twice. if hasattr(sys, "setdefaultencoding"): del sys.setdefaultencoding 我们希望依赖的.pth解析和代码执行是在addsitepackages()函数中完成的。因此，我们真正需要的是将代码的任何执行推迟到execsitecustomize()中或execusercustomize()函数运行之后。实现这一点的方法是对这两个函数进行修改，并在它们完成时触发我们的代码。 我们需要都打上补丁，因为usercustomize.py的执行是可选的，取决于ENABLE_USER_SITE环境变量是否为真。因此，我们的bootstrap()函数应该如下 1234567891011121314151617181920def _execsitecustomize_wrapper(wrapped): def _execsitecustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: if not site.ENABLE_USER_SITE: # 判断 _register_bootstrap_functions() return _execsitecustomizedef _execusercustomize_wrapper(wrapped): def _execusercustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: _register_bootstrap_functions() return _execusercustomizedef bootstrap(): site.execsitecustomize = _execsitecustomize_wrapper(site.execsitecustomize) site.execusercustomize = _execusercustomize_wrapper(site.execusercustomize) 尽管我曾经说过手工构建的猴子补丁有多糟糕，并且wrapt模块应该用于创建猴子补丁，但是在这种情况下，我们实际上不能使用wrapt模块。这是因为从技术上讲，作为用户安装的包，wrapt包此时可能不能使用。如果wrapt的安装方式是这样的，那么导入它的能力本身就依赖于.pth文件的处理。因此，我们使用一个函数闭包来使用简单的包装器。 在实际的包装器中，您可以看到两个包装器中哪个最终调用 _register_bootstrap_functions() 取决于ENABLE_USER_SITE是否为真，如果启用了对usersitecustomize()的支持，那么只能在execsitecustomize()中调用它。 最后，我们现在将_register_bootstrap_functions() 定义为: 1234567891011_registered = Falsedef _register_bootstrap_functions(): global _registered if _registered: return _registered = True from wrapt import discover_post_import_hooks for name in os.environ.get('AUTOWRAPT_BOOTSTRAP', '').split(','): discover_post_import_hooks(name) 5. 初始化包我们已经解决了所有问题，但是如何安装它，特别是如何安装自定义的.pth文件。为此我们使用一个设置.py文件: 12345678910111213141516import sysimport osfrom setuptools import setupfrom distutils.sysconfig import get_python_libsetup_kwargs = dict( name = 'autowrapt', packages = ['autowrapt'], package_dir = &#123;'autowrapt': 'src'&#125;, data_files = [(get_python_lib(prefix=''), ['autowrapt-init.pth'])], entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, install_requires = ['wrapt&gt;=1.10.4'],)setup(**setup_kwargs) 为了安装.pth，我们使用了setup()调用的data_files参数。使用distutils.sysconfig模块中的get_python_lib()函数确定安装文件的实际位置。前缀“空字符串”的参数确保了Python包安装的路经为 site-packages 的相对路径，而不是绝对路径。** 安装这个包时非常重要的一点是，您不能使用easy_install或python setup.py安装。只能使用pip安装这个包。 这样做的原因是，如果不使用pip，那么包安装工具可以将包安装为egg。在这种情况下，自定义.pth文件实际上将安装在egg目录中，而不是实际安装在site-packages目录中。 .pth文件只有被添加到 site-packages 目录中，才能用于映射autowrapt包存在的子目录。从site模块调用的addsitepackages()函数并不会处理包含在.pth文件添加的目录中的.pth文件，因此我们的自定义.pth文件将被跳过。** 在使用“pip”时，默认情况下不使用eggs，所以可行。 还要注意的是，这个包不能与buildout一起工作，因为它总是将包作为eggs安装，并且在Python 安装环境中安装任何脚本时，都会显式地设置Python模块搜索路径本身。 6. 使用示例此软件包的实际完整源代码可在: https://github.com/GrahamDumpleton/autowrapt 这个包也在PyPi上作为autowrapt发布，因此您可以尝试它，如果您真的想使用它的话。为了方便快速地测试它是否有效，autowrapt包打包了一个示例monkey patch。在上面的setyp.py被设置如下:** 1entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, 这个entry point 定义了一个名为autowrapt.examples的猴子补丁。定义了当导入 this 模块时，模块autowrapt.examples中的猴子补丁函数autowrapt_this()将被执行。** 所以要运行这个测试需要: pip install autowrapt 如果没有所需的最小版本，也应该安装wrapt模块。现在正常运行命令行解释器，并在提示符处执行: import this 这应该会显示Python的Zen。退出Python解释器，现在运行: AUTOWRAPT_BOOTSTRAP=autowrapt.examples python 这将再次运行Python解释器，并将环境变量AUTOWRAPT_BOOTSTRAP设置为autowrapt.examples,以匹配在setup.py中为autowrapt定义的entry point。autowrapt_this()”函数的实际代码是: 1234from __future__ import print_functiondef autowrapt_this(module): print('The wrapt package is absolutely amazing and you should use it.') 所以如果我们再一次运行: import this 我们现在应该看到Python Zen的扩展版本。在本例中，我们实际上并没有对目标模块中的任何代码打补丁，但它显示了补丁函数实际上是按预期被触发。 7. 其他机制虽然这种机制相当干净，并且只需要设置环境变量，但是不能像前面提到的那样与buildout一起使用。对于buildout，我们需要研究其他可以实现同样效果的方法。我将在下一篇关于这一主题的博文中讨论这些其他选择。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 猴子补丁在 Python 中的加载次序问题]]></title>
    <url>%2F2018%2F06%2F04%2Fwrapt%2Fpython_decorator_13%2F</url>
    <content type="text"><![CDATA[本节我们就来解决如何在 Python 中打补丁的问题。 1. 猴子补丁的加载次序问题在第 11 篇博客中，我们提到了应用猴子补丁时可能存在的问题。具体地说，如果需要被打补丁的模块已经被导入并被其他代码使用，那么它可能已经在自己的名称空间中创建了一个被打补丁的目标函数的本地引用。因此，尽管猴子补丁可以正常工作，但是仍然无法覆盖这种原始函数已经导入，并过通过本地引用直接访问原始函数的情况。 导入次序问题的解决方案之一是所谓的导入钩子。这是在PEP 369中描述的一种机制，虽然它从未进入Python核心，但是仍然可以使用现有的api将这种能力移植到Python中。然后，在模块导入目标函数并在自己的名称空间中创建对函数的引用之前，我们可以添加其他功能来发现猴子补丁代码，并在导入模块时自动应用它。 Post import hook mechanism暂时将 “Post import hook” 称为导入后勾子。导入后勾子机制在 PEP 369 中有一个使用示例: 12345import imp@imp.when_imported('decimal')def register(decimal): Inexact.register(decimal.Decimal) 其基本思想是，当看到这段代码时，它将导致在Python导入系统中注册一个回调，以便在导入decimal模块时，调用装饰器应用的register()函数。register()函数的参数是对被注册的模块的引用。然后，该函数可以对模块执行一些操作，最后再将模块返回到最初请求导入的代码中。除了使用作为装饰器的@imp.where_imported函数 ，还可以显式地使用imp.register_post_import_hook() 函数来注册导入后钩子。 123456import impdef register(decimal): Inexact.register(decimal.Decimal)imp.register_post_import_hook(register, 'decimal') 尽管PEP 369从未被合并到Python中，但是wrapt 提供了类似功能的装饰器和函数。尽管装饰器和函数被用来解决导入次序问题。但如果目标模块在导入后钩子函数执行之前就已经被导入，我们仍会面临导入次序问题。 这个问题最简单的解决方案是修改应用程序的主Python脚本，并将您需要的所有的”导入后勾子”的注册设置为绝对的第一件事。也就是说，在从应用程序导入任何其他模块包括任何解析命令行参数的标准库之前注册”导入后勾子”。 尽管你确实可以做到这一点，但是由于注册函数会发生事实上的调用，这意味注册函数的执行可能转而导入那些将要被打补丁的模块，所以依然可能发生导入错误。 有一种间接的方式可以解决所有的问题，下面是应用这个原则的例子。方法是相对于导入猴子补丁代码，我们创建一个注册函数，只有当被补丁的模块被导入，猴子补丁才会被惰性加载，之后才会被执行。 123456789101112import sysfrom wrapt import register_post_import_hookdef load_and_execute(name): def _load_and_execute(target_module): __import__(name) patch_module = sys.modules[name] getattr(patch_module, 'apply_patch')(target_module) return _load_and_executeregister_post_import_hook(load_and_execute('patch_tempfile'), 'tempfile') patch_tempfile.py代码如下: 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def apply_patch(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 使用交互式解释器运行第一个脚本，以便将我们留在解释器中，然后，我们可以显示导入tempfile模块并执行mkdtemp()函数，看看会发生什么。 123456$ python -i lazyloader.py&gt;&gt;&gt; import tempfilepatching tempfile&gt;&gt;&gt; tempfile.mkdtemp()calling mkdtemp'/var/folders/0p/4vcv19pj5d72m_bx0h40sw340000gp/T/tmpfB8r20' 上述整个导入过程是这样的: register_post_import_hook 为 tempfile 模块注册了 _load_and_execute 函数 import tempfile 时，会先执行 _load_and_execute 函数，此时会加载patch_tempfile 模块，并执行 apply_patch 函数 apply_patch 接收 tempfile 模块对象作为参数后执行，并使用 wrap_function_wrapper 函数为 mkdtemp 打上补丁。 mkdtemp 执行的就是打补丁之后的函数 整个过程，tempfile 模块被导入时，猴子补丁才被惰性加载。 换句话说，与大多数猴子补丁不同，我们并不是强行导入一个模块，以便在可能使用的基础上应用猴子补丁。相反，猴子补丁代码保持休眠和未使用，直到目标模块稍后被导入。如果没有导入目标模块，则该模块的猴子补丁代码本身甚至没有导入。 3. 发现导入后勾子如上所述，导入后钩子提供了一种稍微更好的方法来设置猴子补丁，以便应用它们。这是因为只有当包含要修补的函数的目标模块被导入时，它们才会被激活。这避免了不必要地导入可能不使用的模块，否则会增加应用程序的内存使用。 导入次序仍然很重要，因此，要确保在导入任何其他模块之前设置所有导入后钩子。并且在每次更改应用的猴子补丁后，需要修改应用程序代码。如果只是为了调试问题而频繁地添加猴子补丁，则可能不太方便。 后一个问题的解决方案是将猴子补丁分离到单独的模块中，并使用一个注册机制来宣布它们的可用性。然后，Python应用程序可以在一开始就执行通用的模板代码，该代码根据提供的配置发现应该应用哪些猴子补丁。注册机制将允许在运行时发现猴子补丁模块。 这里可以使用的一种特殊的注册机制是setuptools入口点。使用这个我们可以打包猴子补丁，这样它们就可以被单独安装以备使用。这样一套方案的结构是: 123setup.pysrc/__init__.pysrc/tempfile_debugging.py 这个包的 setup.py 代码将会是: 123456789101112131415161718192021from setuptools import setupNAME = 'wrapt_patches.tempfile_debugging'def patch_module(module, function=None): function = function or 'patch_%s' % module.replace('.', '_') return '%s = %s:%s' % (module, NAME, function)ENTRY_POINTS = [ patch_module('tempfile'),]setup_kwargs = dict( name = NAME, version = '0.1', packages = ['wrapt_patches'], package_dir = &#123;'wrapt_patches': 'src'&#125;, entry_points = &#123; NAME: ENTRY_POINTS &#125;,)setup(**setup_kwargs) 作为一种约定，我们使用命名空间包，以便我们的猴子补丁模块易于识别。在本例中，父包将是wrapt_patch，因为我们专门使用wrapt。这个特定包的名称将是wrapt_patch.tempfile_debug,表示我们将创建一些猴子补丁，以帮助我们调试使用tempfile模块。 setup.py的关键部分是定义entry_points。它将被设置成程序包名到猴子补丁映射的列表，这个列表包含了这个补丁模块要作用的所有目标Python模块。此处 ENTRY_POINTS 的值为 123ENTRY_POINTS = [ 'tempfile = wrapt_patches.tempfile_debugging:patch_tempfile',] src/init.py 将包含: 12import pkgutil__path__ = pkgutil.extend_path(__path__, __name__) 这是创建命名空间包的要求。最后，猴子补丁实际上包含在src/tempfile_debug中。代码跟以前很像。 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def patch_tempfile(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 定义了包后，我们将它安装到正在使用的Python安装或虚拟环境中。现在，我们可以在Python应用程序主脚本文件的开头添加显式的注册，我们将添加: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 如果我们在没有为猴子补丁特定配置的情况下运行应用程序，那么什么也不会发生。如果它们是启用的，那么它们将被自动发现并根据需要应用。 1234$ WRAPT_PATCHES=wrapt_patches.tempfile_debugging python -i entrypoints.pydiscover wrapt_patches.tempfile_debugging&gt;&gt;&gt; import tempfilepatching tempfile 理想的情况是，如果PEP 369真的进入了Python的核心，那么将类似的引导机制合并到Python本身中，以便在解释器初始化过程中尽早强制对猴子补丁进行注册。有了这一点，我们就有了一种有保证的方法来解决在做猴子补丁时的导入次序问题。 由于现在PEP 369还未进入Python的核心，所以我们在本例中所做的是修改Python应用程序自己添加引导代码，以便在应用程序执行的最开始执行注册。当应用程序归自己管理时这是可以的，但是如果想要对第三方应用程序进行打补丁，并且不希望修改其代码，那该怎么办呢?在这种情况下有什么选择? 在这种情况下可以使用一些技巧。下一篇关于猴子补丁主题的博文中我们将讨论为应用程序打补丁的可用选项。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 使用 wrapt 辅助测试]]></title>
    <url>%2F2018%2F06%2F03%2Fwrapt%2Fpython_decorator_12%2F</url>
    <content type="text"><![CDATA[前面我们说道过 Python 中使用猴子补丁典型情景之一就是使用模拟库来帮助执行单元测试，本节我们先把补丁和模块导入的相对次序问题放一放，先来看看如何使用 wrapt 模块辅助单元测试。 1. 使用 wrapt 进行测试在Python中讨论单元测试时，用于辅助该任务的比较流行的包之一是 mock 包。但是我(wrapt 的作者)觉得 mock 包不符合我的思维方式。 也可能只是我试图应用它的东西不太适合。在我想要测试的内容中，通常我不仅想要模拟更低的层，而且我想要验证传递到下一层的数据，或者修改结果。换句话说，我通常仍然需要系统作为一个整体来结束，并可能在很长一段时间内。 因此，对于我需要做的更复杂的测试，我实际上一直在依靠wrapt的猴子补丁功能。很有可能，因为我写了wrapt，我更熟悉它的范例，或者我更倾向于更明确的方式。不管怎样，至少对我来说，wrapt 能帮助我更快地完成工作。 为了进一步解释 wrapt 的猴子补丁功能，我在这篇博客文章中向大家展示了用wrapt模块实现部分 Mock 包的功能。只要记住，对于Mock模块我是一个绝对的新手，也可能也我太笨了，不能理解如何正确简单地使用它来做我想做的事情。 Return values and side effects如果你正在使用Mock，并且希望在调用时临时覆盖类的方法返回的值，一种方法是: 123456789101112from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch(__name__+'.ProductionClass.method', return_value=3)def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') mock_method.assert_called_with(3, 4, 5, key='value') assert result == 3 就我迄今为止提出的wrapt包而言，一种类似的做法是: 123456789101112131415from wrapt import patch_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch_function_wrapper(__name__, 'ProductionClass.method')def wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 不过，这里的一个问题是，wrapt.patch_function_wrapper()函数应用了一个永久补丁。在这个过程的生命周期中，这是可以的，但是在测试的情况下，我们通常希望一个补丁只应用于当时正在运行的单个单元测试函数。因此，补丁应该在测试结束时和调用下一个函数之前应该被删除。 对于该场景，wrapt包提供了另一个装饰器@wrapt.transient_function_wrapper。用来创建一个包装函数，该函数只应用于修饰函数所应用的特定调用的范围。因此，我们可以把上面写为: 12345678910111213141516from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 尽管这个示例展示了如何临时覆盖类的方法返回的值，但更典型的情况是，我们仍然希望能够调用原始的被覆盖的函数。可能验证传入的参数或从底层返回的返回值。当我尝试用Mock解决这个问题时，我想到的一般方法如下。 1234567891011121314151617from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, keydef wrapper(wrapped): def _wrapper(self, *args, **kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(self, *args, **kwargs) return _wrapper@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper(ProductionClass.method))def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') 这里有两个技巧 第一个是@Mock.path 的 autospec=True参数，用于执行方法绑定 第二个是需要在对它应用任何mock之前从’ProductionClass’捕获原始方法，这样当调用mock的副作用函数时，我就可以反过来调用它。 毫无疑问，有人会告诉我，我做错了，有一种更简单的方法，但这是我在阅读模拟文档10分钟后所能想到的最好的方法。 当使用wrapt执行相同的操作时，使用的方式与模拟返回值没有什么不同。这是因为wrapt函数包装器能同时适用普通函数或方法，所以在包装方法时不需要额外处理。此外，当调用wrapt包装函数时，它总是传递被包装的原始函数，因此不需要使用任何魔法来隐藏它。 123456789101112131415from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(*args, **kwargs)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') 使用此功能可以轻松地拦截调用，来执行传递的数据的验证，但仍然可调用原始函数，我可以相对轻松地创建一大堆装饰器，以便对数据执行验证，因为数据可能是通过系统的不同部分传递的。然后，我可以将这些装饰器堆叠在任何需要添加它们的测试函数上。 2. 包装不同类型的返回值返回函数上面的示例包括能够返回一个假的返回值，返回原始值，或者在部分原始数据类型或集合上进行一些轻微的修改。但在某些情况下，我实际上希望在返回值周围放置一个包装器，以修改后续代码与返回值的交互方式。 第一个例子是包装函数返回另一个函数，这个函数将被调用链中更高的函数调用。在这里，我可能想在返回的函数周围放置一个包装器，以便在调用它时拦截它。 Mock 包的使用方式如下1234567891011121314151617181920212223242526from mock import Mock, patchdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return functiondef wrapper2(wrapped): def _wrapper2(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper2def wrapper1(wrapped): def _wrapper1(self, *args, **kwargs): func = wrapped(self, *args, **kwargs) return Mock(side_effect=wrapper2(func)) return _wrapper1@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper1(ProductionClass.method))def test_method(mock_method): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: ProductionClass.method 函数返回值是另一个函数 side_effect 指定了第一层的包装函数 wrapper1，截获了ProductionClass.method 返回的 function 函数 wrapper1 将 function 包装再 wrapper2 内返回给了调用链中更高层的函数 更高层的函数调用 function 时，调用的则是 wrapper2 wrapt 包的使用方式: 12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: apply_ProductionClass_method_wrapper 装饰了原始的 ProductionClass.method 方法 apply_ProductionClass_method_wrapper 内 wrapped(*args, **kwargs) 返回结果就是 function，其又被 result_function_wrapper 装饰 调用链中更高层的函数调用 ProductionClass.method，实际调用的是 result_function_wrapper 本例使用了一个名为@wrapt.function_wrapper的新装饰器。还可以使用@wrapt.decorator。@wrapt.function_wrapper 实际上只是@wrapt.decorator的一个简化版本，它缺少一些在做显式的猴子补丁时通常不需要的铃铛和口子，但除此之外，它也可以用同样的方式使用。因此，我可以对结果返回的函数应用一个包装器。我甚至可以应用相同的原理应用在当函数作为参数传递给另一个函数的情况。 返回类的实例返回函数的另一个场景是返回类的实例。在这种情况下，我可能想要对类的实例的特定方法应用一个包装器。在mock 包中，需要再次使用“Mock”类，并且必须以不同的方式应用它来实现您想要的结果。现在我将不再关注mock，只关注wrapt的实现方式。 所以，根据需求，有几种方法可以用wrapt来实现。第一个方法是用封装原始方法的包装器直接替换实例上的方法 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 包装过程是: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method run_method_wrapper 包装 ProductionClass.method 的返回值 storage.run 这样可以得到想要的结果，但在本例中，实际上是一种糟糕的方法。问题是返回的对象是一个在测试之外有生命时间的对象。也就是说，我们正在修改一个存储在全局范围内的对象，该对象可能用于其他测试。通过简单地替换实例上的方法，我们进行了永久性的更改。 如果它是一个仅为一次调用而按需创建的类的临时实例，那么这是可以的，但是在其他情况下不行，因为它的影响是持久的。因此，我们不能修改实例本身，需要以其他方式封装实例来拦截方法调用。 为此，我们使用了所谓的对象代理。这是一个特殊的对象类型，我们可以创建一个实例来包装另一个对象。当访问代理对象时，任何访问属性的尝试都会从包装对象返回属性。类似地，调用代理上的方法将调用包装对象上的方法。 但是，拥有一个不同的代理对象允许我们更改代理对象上的行为，从而更改代码与包装对象的交互方式。因此，我们可以避免更改原始对象本身。因此，对于这个例子，我们可以做的是: 1234567891011121314151617181920212223242526from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): def run(self): return self.__wrapped__.run()@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 整个包装过程如下: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method 使用代理对象 StorageClassProxy 代理了对 storage 实例属性和方法的访问 StorageClassProxy 覆盖了 storage 的 run 方法 也就是说，我们在代理对象上定义run()方法，以拦截原始对象上相同方法的调用。然后我们可以继续返回假值，验证参数或结果，或者根据需要修改它们。通过代理，我们甚至可以通过向代理对象添加属性来拦截对原始对象属性的访问。 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def __init__(self): self.name = 'name'storage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): @property def name(self): return self.__wrapped__.name@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') assert data.name == 'name' 3. 更好的使用 Mock 模块这时你可能会说Mock做的远不止这些。你甚至可能想指出 mock 如何保存了调用的细节，这样就可以回溯，而不需要进行打点测试，这样甚至可以避免打点测试触发的异常被意外捕获的情况。 这是正确的，我们的意思是不要局限于使用基本的构建块本身，可以将多个模块结合使用，wrapt 是构建更好的模拟库进行测试的一个很好的基础。因此，我留给你们最后一个例子来让你们思考，如何使用 mock 来实现。 12345678910111213141516171819202122232425262728from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): passdef patch(module, name): def _decorator(wrapped): class Wrapper(object): @transient_function_wrapper(module, name) def __call__(self, wrapped, instance, args, kwargs): self.args = args self.kwargs = kwargs return wrapped(*args, **kwargs) wrapper = Wrapper() @wrapper def _wrapper(): return wrapped(wrapper) return _wrapper return _decorator@patch(__name__, 'ProductionClass.method')def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert real.method.__name__ == 'method' assert mock_method.args == (3, 4, 5) assert mock_method.kwargs.get('key') == 'value' 这是 wrapt 包实现猴子补丁的概览。还有一些其他的东西，但这是核心部分。我使用猴子补丁将工具添加到现有代码中以支持性能监视，但是我在这里展示了如何将相同的技术用于编写代码测试，以替代Mock等包。 正如我在上一篇文章中提到的，猴子补丁的一个主要问题是模块的导入结果与打补丁完成的时间相关。我将在下一篇文章中进一步讨论这个问题。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 在 Python 中安全的使用猴子补丁]]></title>
    <url>%2F2018%2F06%2F02%2Fwrapt%2Fpython_decorator_11%2F</url>
    <content type="text"><![CDATA[在之前 10 篇博客中，我们几乎完整的讨论了装饰器的实现。现在我们将焦点从装饰器转移到猴子补丁上来。 1. 猴子补丁通常在Python中永远不应该做的事情之一就是编写猴子补丁。但有些人认为这是一种有用的必需品，你可能无法避免修补第三方代码中的错误。其他人则可能会争辩说，现在有这么多的软件是开源的，所以您应该简单地向上游包维护人员提交一个补丁。 猴子补丁除了补丁还有其他用途。在Python中最常用的两种形式的猴子补丁是装饰器和使用模拟库来帮助执行单元测试，甚至你可能不把它与猴子补丁等同起来。另一个不常见的猴子补丁的例子是对现有的Python代码添加性能监视功能。 前面我们介绍了装饰器可能会导致什么问题。主要的问题就是，装饰器的实现方式可能没有保留适当的自省能力，当应用于类的方法时，它们可能也没有保留Python描述符协议的正确语义。当人们开始讨论如何修改任意代码，而不是简单地对自己的代码应用装饰器时，这两个问题就变得更加重要了，因为可能很容易地干扰现有代码的行为，或者以意想不到的方式打补丁。 典型的案例是，对一个类方法打补丁。与装饰器在类被创建时即运行不同，补丁代码运行时，类已经被创建，因此需要额外处理一些潜在问题。 我打算用这篇博文来解释wrapt包的猴补丁功能。尽管 wrapt 模块提供了创建装饰器的良好方式，但这并不是创建该包的主要目标。创建wrapt包的真正原因实际上是为猴子补丁代码实现健壮的机制。碰巧，安全执行猴子补丁所需的基本原则和机制也适用于实现装饰器。 2. 创建一个装饰器在开始修改任意代码之前，我们首先需要重新复述一下wrapt包如何用于创建装饰器。主要模式是: 12345678910111213141516171819import wraptimport inspect@wrapt.decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) wrapt包创建装饰器的一个特性是，在装饰器中，可以确定装饰器所使用的上下文。即可以确定修饰符是被应用于类、函数或静态方法、类方法或实例方法中的哪一个。对于将装饰器应用于实例方法的情况，为类的实例提供了一个单独的参数。对于类方法，单独的参数是对类本身的引用。在这两种情况下，它们都与“args”和“kwargs”参数相分离，因此不需要自己动手提取它们。因此，我将使用wrapt创建的装饰器称为通用装饰器。换句话说，可以创建一个单独的装饰器，它可以跨函数、方法和类使用，可以在不同的调用场景中相应地调整装饰器的行为。而不再需要创建一个装饰器的多个实现，并确保在每个场景中都使用了正确的实现。 这种装饰器的使用与其他方式创建的装饰器无异。 12345class Example(object): @universal def name(self): return 'name' 需要注意的是 @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖 12345class Example(object): def name(self): return 'name' name = universal(name) 这么写仍然可行，当以这种方式编写时，它使装饰者在某种程度上成为一种猴子补丁。这是因为猴子补丁通常所做的就是在一些现有函数周围引入一个包装器，这样就可以对原始函数进行拦截。然后，包装器函数允许在调用原始函数之前或之后执行操作，或者允许修改传递给包装函数的参数，或者以某种方式修改结果，或者甚至完全替换结果。 与装饰器的一个重要区别是，装饰器在类被创建时即运行。相比之下，猴子补丁更随意，通常在类创建一段时间之后再执行。 事实上你所作的是: 12345class Example(object): def name(self): return 'name'Example.name = universal(Example.name) 尽管使用wrapt包创建的装饰器函数可以以这种方式使用，并且仍将按预期工作，但总体而言，我不建议以这种模式给类的现有方法添加补丁。这是因为这种方式实际上并不等同于当类被定义时在类的主体内做同样的事情。特别是Example.name的访问实际上调用了描述符协议，因此返回了实例方法。我们可以通过运行代码看到这一点: 12345678910class Example(object): def name(self): return 'name' print type(name)print type(Example.name)which produces:&lt;type 'function'&gt;&lt;type 'instancemethod'&gt; 一般来说，这可能并不重要，但我看到过一些非常奇怪的情况，它们的区别很重要。因此，为了解决这个问题，wrapt包提供了执行猴子补丁的另一种实现机制。在上面为类的方法添加包装器的情况下，使用这种机制可以避免由这种细微差别所引起的任何问题。 3. 猴子补丁创建猴子补丁的创建与装饰器创建类似，首先需要创建一个包装函数，猴子补丁的包装函数与装饰器是一样的，如下图所示 12def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 不同的是不是使用装饰器工厂函数 @wrapt.decorator 创建装饰器并将其应用到被包装对象上，而是使用 wrapt.wrap_function_wrapper() 函数。 1234567class Example(object): def name(self): return 'name'import wraptwrapt.wrap_function_wrapper(Example, 'name', wrapper) 在这种情况下，我们将类放在同一个代码文件中，但是我们也可以这样做:** 1234import exampleimport wraptwrapt.wrap_function_wrapper(example, 'Example.name', wrapper) 也就是说，我们将目标所在的模块作为第一参数，第二个参数则是我们希望应用包装器的目标方法对象的路径。我们也可以完全跳过导入模块，只使用模块的名称。 123import wraptwrapt.wrap_function_wrapper('example', 'Example.name', wrapper) 为了证明任何东西都可以被装饰器简化，我们最终可以把整个东西写成: 12345import wrapt@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 在这个最后的示例中，将会发生的事情是，一旦导入了包含上述代码的模块，在“示例”模块中定义的指定目标函数将自动地使用包装器函数进行修补。 4. 延迟补丁问题现在需要着重提醒的是。在上述的操作之后应用补丁并不总是有效的。 问题的核心在于，是否正在对一个已导入的模块应用补丁。如果模块没有导入，wrap .wrap_function_wrapper() 调用将确保模块被导入，但是如果模块已经被代码的其他部分或第三方包导入，那么可能就会有问题。 特别的是，您尝试打补丁的目标函数是模块的一个正常的全局函数，其他一些代码可以通过以下步骤直接获取对它的引用: from example import function 如果你后来来了 12345import wrapt@wrapt.patch_function_wrapper('example', 'function')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 最后，目标模块中包含的函数的副本将应用包装器，但是其他代码创建的对它的引用将没有包装器。即在打补丁之后导入的目标函数都是被包装的，之前的都是未被包装的。 为了确保在此场景中始终使用包装器，您不仅需要在原始模块中，而且还需要在存储引用的任何模块中对其进行补丁。这只在非常有限的情况下是可行的因为在现实中，如果函数是一个普通的函数，你将不知道函数在哪里被使用。 这个问题的一个确切体现就是对gevent或eventlet等包打补丁时存在的问题。这两个包都延迟了功能的修补，因此对导入模块的顺序非常敏感。要解决这个问题，至少对于Python标准库中的模块来说，要打补丁的time.sleep()函数不仅需要在time模块中进行修补，还需要在threading模块中进行修补。 有一些技术可以用来尝试和避免这些问题，但我将把这些解释推迟到以后的一段时间。在我的下一篇博客文章中，我想介绍一些使用使用猴子补丁示例，看看如何在进行测试时使用wrapt替代 mock 模块。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 装饰类的性能]]></title>
    <url>%2F2018%2F06%2F01%2Fwrapt%2Fpython_decorator_10%2F</url>
    <content type="text"><![CDATA[在上一篇文章中，我们对作为函数闭包实现的装饰器与前文描述的通用装饰器进行了性能比较。本节我们继续我们的性能测试，看看装饰一个类方法时，不同实现方式的性能表现。 1. 装饰函数的性能比较在上一篇文章中，函数闭包实现的装饰器与前文描述的通用装饰器性能测试结果如下 对于2012年的MacBook Pro，直接调用函数的测试结果是: 10000000 loops, best of 3: 0.132 usec per loop 使用函数闭包实现的装饰器的测试结果是: 1000000 loops, best of 3: 0.326 usec per loop 最受，使用装饰器工厂函数的测试结果是: 1000000 loops, best of 3: 0.771 usec per loop 上述是代理对象，和 function wrapper 对象的Python实现测试结果，如果将它们以Python C扩展实现，可以降低至: 1000000 loops, best of 3: 0.382 usec per loop 这与使用函数闭包实现的装饰器，性能相差无几。 将装饰器应用在类方法会怎样？ 2. 必须绑定函数的开销将装饰器应用于类的方法的问题是，如果要遵守Python执行模型，则需要将装饰器实现为描述符，并在访问时正确地将方法绑定到类或类实例。在本系列文章中描述的装饰器中，我们正是实现了此机制，以便能够确定装饰器整被应用于与普通的函数、实例方法或类方法中的哪一个。 相比于使用函数闭包实现的装饰器不会遵守任何的Python 执行模型，这个绑定过程确保了正确的操作，但是也带来了额外的开销。为了查看发生了哪些额外的步骤，我们可以再次使用Python profile挂钩机制来跟踪修饰函数调用的执行。当前即跟踪实例方法的调用 首先，让我们来跟踪函数闭包实现的装饰器调用了哪些函数: 1234567891011121314151617181920def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapperclass Class(object): @my_function_wrapper def method(self): passinstance = Class()import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)instance.method() 结果跟装饰器一个普通函数类似: 1234_my_function_wrapper call method call method return_my_function_wrapper return 因此，我们应该预期，当我们执行实际的时间测试时，开销不会有很大的不同。现在使用我们的装饰器工厂函数。为了提供上下文，我展示了完整的代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 我们的装饰器实现如下: 123@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 装饰实例方法的测试输出结果如下: 12345678910111213('__get__', 'call') # function_wrapper ('__init__', 'call') # bound_function_wrapper ('__init__', 'call') # object_proxy ('__init__', 'return') ('__init__', 'return')('__get__', 'return')('__call__', 'call') # bound_function_wrapper ('my_function_wrapper', 'call') ('method', 'call') ('method', 'return') ('my_function_wrapper', 'return')('__call__', 'return') 可以看到，由于方法与发生在 __get__() 中的类实例的绑定，现在发生了很多事情。因此，开销也会显著增加。 3. 执行类方法的开销与前面一样，不再使用上面的实现，而是再次使用wrapt库中的实际实现。这次我们的测试代码是: $ python -m timeit -s &#39;import benchmarks; c=benchmarks.Class()&#39; &#39;c.method()&#39; 没有被装饰的实例方法，直接运行的结果是: 10000000 loops, best of 3: 0.143 usec per loop 这比普通函数调用的情况要多一点，因为发生的了实例方法的绑定。 使用函数闭包实现的装饰器。测试结果如下: 1000000 loops, best of 3: 0.382 usec per loop 再一次，比未修饰的情况稍微多一点，与被应用到函数的装饰器相差无几。因此，当应用于普通函数与实例方法时，装饰器的开销并没有太大的差异。现在轮到我们的装饰器工厂函数和 function wrapper对象。首先测试Python 实现: 100000 loops, best of 3: 6.67 usec per loop 与使用函数闭包实现装饰器相比，这在运行时开销上增加了不少负担。虽然每次执行只需要额外的6个usec，但是您需要在上下文中考虑这个问题。特别是，如果在处理web请求的过程中对一个调用了1000次的函数应用了这样的装饰器，那么在该web请求的响应时间之上增加了6 ms。 在这一点上，许多人无疑会辩称，如果运行成本太高，那么正确是不值得的。但是，装饰函数和装饰器本身也不可能什么都不做，因此所产生的额外开销可能只是运行时成本的一小部分，因此在实践中并不明显。同样的，如果使用Python C扩展模块实现呢？对于作为C扩展实现的对象代理和函数包装器，结果是: 1000000 loops, best of 3: 0.836 usec per loop 所以不是6ms，而是小于1ms的额外开销如果修饰函数被调用1000次。它仍然比使用作为函数闭包实现的装饰器要多，但再次重申，在修饰类的方法时使用函数闭包不符合Python执行模型。 4. 需要大费周折么我是在吹毛求疵、过于迂腐地想把事情做好吗？当然，对于你现在所使用的装饰器，闭包实现可能工作的很好。但是当您开始使用函数包装器执行任意代码的猴子补丁时，情况就不一样了。如果你在做猴子补丁时不遵守Python的执行模型，那么你很容易以非常微妙和晦涩的方式打破第三方代码。客户可不会喜欢你破坏了他们的web应用程序。所以至少我现在所作的是很重要的。 在本文中，我只考虑了修饰类实例方法时的开销。我没有涵盖在修饰静态方法和类方法时的开销。如果您对它们的不同之处感到好奇，您可以在wrapt文档中查看完整的案例的基准。 在下一篇文章中，我将再次讨论性能开销问题，但也将讨论实现装饰器的一些替代方法，以便尝试并解决我在第一篇文章中提出的问题。这些内容将作为，对博客中描述的实现和 PyPi 模块中的实现的对比的一部分。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 装饰器性能比较]]></title>
    <url>%2F2018%2F05%2F30%2Fwrapt%2Fpython_decorator_09%2F</url>
    <content type="text"><![CDATA[前面我们探讨了装饰器的实现方式，并实现了一个所谓的通用装饰器模式，并用它创建了一个类似 Java 的 @synchronized 装饰器作为使用示例。本节我们来看看不同的装饰器实现方式的性能问题。在这篇关于装饰器的实现性能这篇文章之后，我们将开始深入探讨如何实现代理，它是通用装饰器机制中的基础组件。 1. 装饰一个普通函数在这篇文章中，我将只讨论用装饰器修饰一个普通函数的开销。相关的装饰器代码如下: 123456789101112131415161718192021222324class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper ... def __get__(self, instance, owner): ... def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 如果你想回忆完整的代码，你可以去查看之前的文章，那里有完整描述。使用装饰器工厂函数，创建装饰器，并装饰器一个普通函数可以像下面这样: 1234567@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @my_function_wrapperdef function(): pass 这与使用函数闭包以更传统的方式创建的decorator不同。使用闭包创建一个函数装饰器如下所示: 12345678def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapper@my_function_wrapperdef function(): pass 在我们调用函数时function()，这两种情况各自会发生什么? 2. 追踪函数执行为了跟踪代码的执行，我们可以使用Python的profile hook机制。 1234567import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)function() profile hook的目的是允许注册一个回调函数，该函数在所有函数的入口和出口调用。这样就可以追踪正在进行的函数调用的序列。对于函数闭包，输出如下: 1234_my_function_wrapper call function call function return_my_function_wrapper return 我们在这里看到的是函数闭包的嵌套函数被调用。这是因为在使用函数闭包的情况下，装饰器将函数替换为对嵌套函数的引用。当这个嵌套函数被调用时，它将依次调用原来的包装函数。对于我们的工厂函数，输出如下: 123456__call__ call my_function_wrapper call function call function return my_function_wrapper return__call__ return 这里的区别是，decorator 用 function wrapper 类的实例替换了函数。作为一个类，当它作为一个函数被调用时，__call__() 方法在类的实例上被调用。__call__() 方法随后调用用户提供的包装器函数，该函数反过来调用原始包装函数。 因此，结果是我们引入了额外的间接级别，或者换句话说，在执行路径中引入了额外的函数调用。记住，__call__()实际上是一个方法，而不仅仅是一个普通的函数。作为一种方法，实际上在幕后进行的工作要比普通的函数调用多得多。特别是，在调用未绑定方法之前，需要将其绑定到函数包装器类的实例。这不会出现在调用的跟踪中，但是它正在发生，并且会产生额外的开销。 3. 函数执行时间通过执行上面的跟踪，我们知道我们的解决方案会带来额外的方法调用开销。但是这会产生多少额外的开销呢？为了尝试度量每个解决方案中开销的增加，我们可以使用timeit模块来执行我们的函数调用。作为基线，我们首先需要知道在不应用任何修饰符的情况下对函数进行调用的时间开销。 123# benchmarks.pydef function(): pass 为记录时间，我们需要使用以下命令: $ python -m timeit -s &#39;import benchmarks&#39; &#39;benchmarks.function()&#39; 以这种方式使用的timeit模块时，它将执行适当的大量函数调用，将所有调用的总时间除以调用次数，最后得到单个调用的时间值。对于2012年款的MacBook Pro来说，输出如下: 10000000 loops, best of 3: 0.132 usec per loop 接下来测试函数闭包，输出如下: 1000000 loops, best of 3: 0.326 usec per loop 最后测试我们的装饰器工厂函数: 1000000 loops, best of 3: 0.771 usec per loop 在这个最后的例子中，我使用的是wrapt模块实现，而不是本系列博文中迄今为止给出的代码。这个实现的工作方式略有不同，因为它在描述的内容上有一些额外的功能，设计也有一些不同。即便是最轻量级的实现，性能开销也差不多。 4. 加速包装器的执行在这一点上毫无疑问会有人们想要指出,即使对于方法调用而言，它更加正确的实现了描述符协议，但是这所谓的的更好的方法实在是太慢，难以在实际生产环境中使用。因此，是否可以做些什么来加速实现呢? 此时可以采用的方法是将函数包装器和对象代理实现为Python C扩展模块。为了简单起见，我们可以将装饰器工厂函数本身作为纯Python代码来实现，因为工厂函数只在修饰符应用到函数时才调用，而不是修饰函数的每次调用时都会调用，因此它的时间开销并不重要。** 我绝对不会做的一件事是写博客，讨论如何将函数包装器和对象代理作为Python C扩展模块实现。不过请放心，它的工作方式与纯Python实现相同。显然，它的运行速度要快得多，因为它是使用Python C api实现的C代码，而不是纯粹的Python代码。 将函数包装器和对象代理作为Python C扩展模块实现的开销如何呢?测试如下: 1000000 loops, best of 3: 0.382 usec per loop 因此，尽管将函数包装器和对象代理作为Python C扩展模块实现需要付出更多的努力，但这些努力是值得的，结果时现在非常接近使用函数闭包的装饰器实现。 4. 装饰类方法性能到目前为止，我们只考虑了装饰一个普通函数的情况。正如预期的那样，与function wrapper作为一个类实现类似，由于引入了额外的间接层，因此开销明显更多。尽管如此，它仍然只有半微秒。 尽管如此，通过实现我们的函数包装器和对象代理作为C代码，我们还是能够将性能达到同一量级，在这里，作为函数闭包实现的装饰器工厂函数的开销可以忽略不计。 那么装饰类方法的性能如何呢。将在下一篇博客揭晓。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 将 @synchronized 实现为上下文管理器]]></title>
    <url>%2F2018%2F05%2F29%2Fwrapt%2Fpython_decorator_08%2F</url>
    <content type="text"><![CDATA[在前一篇文章中，我们描述了如何使用新的通用装饰器模式来实现Python的 @synchronized 同步原语装饰器。在Java提供的两个同步机制中，同步方法和同步原语，目前为止我们只实现了同步方法。本文将描述如何将其扩展为上下文管理器，从而等效的实现Java的同步原语。 1. @synchronized 当前实现到目前为止，我们的@synchronized 装饰器的实现是。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 通过确定装饰器被用于包装普通函数、实例方法或类的方法中的哪一个，我们可以在许多场景中使用同一一个装饰器。 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 我们现在想要实现的是让同步装饰器也能完成如下操作: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，除了可以用作装饰器之外，它还能与with语句一起用作上下文管理器。通过这样做，它就能够对函数中的部分语句加锁，而不是整个函数。用作上下文管理器时，如果需要与实例方法同步，我们需要将把self参数或类实例传递给synchronized。如果需要与类方法同步，则传递类对象本身。 2. 将 function_wrapper 实现为上下文管里器在现有的synchronized实现上，当使用synchronized作为函数调用时，它将返回函数包装器类的一个实例。 12&gt;&gt;&gt; synchronized(None)&lt;__main__.function_wrapper object at 0x107b7ea10&gt; 这个函数包装器没有实现作为上下文管理器的对象所需的__enter__()和__exit__()函数。函数包装器是我们自己的类，所以我们只需要创建子类并为其添加这两个方法即可。同时这个函数包装器的创建是在@decorator的定义中绑定的，所以我们需要绕过@decorator并直接使用函数包装器。因此，第一步是重写我们的 @synchronized decorator，不使用@decorator。 123456789101112131415161718192021def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) return function_wrapper(wrapped, _synchronized_wrapper) 这与我们最初的实现相同，但是我们现在可以访问到创建函数包装器对象 function_wrapper。因此我们可以创建一个满足上下文管里器协议的 function_wrapper 的子类来替换 function_wrapper。 12345678910111213141516171819202122232425262728293031def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) class _synchronized_function_wrapper(function_wrapper): def __enter__(self): self._lock = _synchronized_lock(self.wrapped) self._lock.acquire() return self._lock def __exit__(self, *args): self._lock.release() return _synchronized_function_wrapper(wrapped, _synchronized_wrapper) 3. 两种调用方式当 synchronized 作为装饰器使用时，新的function wrapper子类被用于包装被包装函数和方法。当函数或类方法被调用时，function wrapper 基类中的 __call__ 方法被调用。装饰器将在尝试获取锁之后执行被包装函数。 当synchronized作为上下文管里器使用时。子类将用于包装类实例或类本身。没有方法会被调用，取而代之的是在进入上下文时，__enter__() 会获取锁，离开上下文时，__exit__() 会释放锁。 与在之前的文章中形容的复杂度相比，现在的实现简单明了。 4. 不只是个装饰器希望这能说明的一点是，尽管@decorator被用来创建自定义装饰器，但这并不总是最合适的方式。function wrapper 对象的单独存在为修改被包装对象的行为提供了很大的灵活性。在某些情况下，还可以直接删除和使用对象代理。所有这些都提供了一个通用的工具集，用于进行任何类型的包装或修补，而不仅仅是用于装饰。现在，我将开始将这一系列博客文章的焦点转移到更一般的包装和猴子补丁上。 在此之前，在下一篇文章中，我将首先讨论与使用函数闭包实现装饰器的更传统方式相比，使用 function wrapper 隐含的性能影响。以及使用Python C扩展实现完整的对象代理和 function wrapper 后，性能改善的大小。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 实现 java 的 @synchronized 装饰器]]></title>
    <url>%2F2018%2F05%2F26%2Fwrapt%2Fpython_decorator_07%2F</url>
    <content type="text"><![CDATA[在之前的博客中，我们讨论了装饰器的实现，并实现了一个通用装饰器模式。作为这种模式的使用示例，本节我们来实现 java 中的 @synchronized 装饰器。 1. Java @synchronized 装饰器java 的同步原语有两种形式，分别是同步方法和同步代码块。在Java 中创建同步方法，只需要在其定义时添加synchronized关键字即可。 123456789101112public class SynchronizedCounter &#123; private int c = 0; public synchronized void increment() &#123; c++; &#125; public synchronized void decrement() &#123; c--; &#125; public synchronized int value() &#123; return c; &#125;&#125; 使一个方法同步意味着不可能在同一个对象上同时调用多个同步方法。当一个线程正在执行一个对象的同步方法时，所有其他调用相同对象的同步方法的线程将阻塞直至当前同步方法调用完成。 换句话说，类的每个实例都有一个内在的锁对象，并且在进入一个方法时，锁会被获取，当方法返回时它会被释放。锁是所谓的重入锁，这意味着线程可以在它持有锁的同时，再次获得它，而不会阻塞。正因为如此，一个同步的方法可以调用同一个对象上的另一个同步方法。 在Java中创建同步代码的第二种方法是同步代码块。与同步方法不同，同步代码块必须指定提供内在锁的对象。 1234567public void addName(String name) &#123; synchronized(this) &#123; lastName = name; nameCount++; &#125; nameList.add(name);&#125; 值得注意的是，在Java中，可以使用任何对象作为锁的源，不需要创建特定锁类型的实例来同步。如果在类中需要更细粒度的锁，那么可以简单地创建或使用现有的任意对象进行同步。 12345678910111213141516public class MsLunch &#123; private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() &#123; synchronized(lock1) &#123; c1++; &#125; &#125; public void inc2() &#123; synchronized(lock2) &#123; c2++; &#125; &#125;&#125; 这些同步原语使用起来相对简单，因此，如何才能通过装饰器在Python中让类似操作以同样简单的方式实现呢。 2.同步线程的互斥锁在Python中，不可能使用任意对象做同步。相反必要创建一个特定的锁对象，该对象内部持有一个线程互斥锁。锁对象提供了一个 acquire()和release() 方法来操作锁。同时由于上下文管理器被引入到 Python 中，所以锁也支持与with语句一起使用。使用这个特定的特性，用于实现Python的@synchronized 装饰器的典型实现是: 1234567891011121314def synchronized(lock=None): def _decorator(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper return _decoratorlock = threading.RLock()@synchronized(lock)def function(): pass 使用此方法在一段时间后变得很烦人，因为对于需要同步的每个不同的函数，必须首先创建一个线程锁。替代方法是，为每个装饰器自动创建一个线程锁。 1234567891011def synchronized(wrapped): lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function(): pass 我们甚至可以使用前面描述的模式，为每次调用提供一个可选的参数 1234567891011121314151617181920def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function1(): passlock = threading.Lock()@synchronized(lock=lock)def function2(): pass 无论方法如何，基于函数闭包的装饰器都会遇到我们已经列出的所有问题。因此，我们可以采取的第一步是使用我们新的装饰器工厂函数替代它。 12345678910111213def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @decorator def _wrapper(wrapped, instance, args, kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper(wrapped) 因为使用了我们的装饰器工厂函数，这意味着相同的代码可以安全的应在实例、类或静态方法上。需要强调的是在类方法上使用此装饰器看似简单，但并不是很有用。因为锁仅仅对被装饰的方法有用，并且会对类的所有实例在同一方法上施加同步锁。这并不是我们想要的，也不能同java的同步方法相对应。 在次重申我们要实现的目标是，被装饰器标识为同步的所有实例方法，我们希望每个类实例都有一个独立的同步锁来实现实例内的方法同步。不同类实例之间不要同步。 过去已经有一些文章描述了如何改进这一点，包括这个很复杂的尝试。个人觉得它的实现方式是相当笨拙的，甚至怀疑它实际上不是线程安全的，因为在创建一些锁的过程中有一个竞争条件。因为它使用了函数闭包，并且没有我们的通用装饰器的概念，所以还需要创建大量不同的装饰器，然后在一个装饰器入口点上尝试将它们整合在一起。显然，我们现在应该能够做得更好。 3. 将互斥锁存储在被包装对象上解决这个问题的关键在于我们可以在哪里存储线程锁。在被包装对象调用之间存储任何数据的惟一选项将是被包装对象本身，包括被包装的函数，类实例方法和类方法。因此相对于需要传入锁，或者在函数闭包中创建锁，让我们尝试在包装器本身中的创建和管理锁。** 首先考虑一个正常函数的情况。在这种情况下，我们所能做的就是将所需的线程锁存储在包装的函数对象本身上。 123456789101112131415@decoratordef synchronized(wrapped, instance, args, kwargs): lock = vars(wrapped).get('_synchronized_lock', None) if lock is None: lock = vars(wrapped).setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)@synchronizeddef function(): pass&gt;&gt;&gt; function()&gt;&gt;&gt; function._synchronized_lock&lt;_RLock owner=None count=0&gt; 我们要处理的一个关键问题是如何第一次创建线程锁。为此我们需要做的是查看线程锁是否已被创建。** lock = vars(wrapped).get(&#39;_synchronized_lock&#39;, None) 如果返回一个有效的线程锁对象，那么我们就可以继续尝试获取锁。如果锁不存在我们需要创建锁,但是我们必需小心避免竞态条件，因为当两个线程同时进入这部分代码时，它们都会判断需要第一次创建锁。我们用来解决这个问题的窍门是: lock = vars(wrapped).setdefault(&#39;_synchronized_lock&#39;, threading.RLock()) 当两个线程同时尝试创建锁时，它们都可能创建一个锁实例，但是由于使用了dict.setdefault()，只会有一个进程会成功。因为 dict.setdefault() 总是返回它第一次存储的值。所以所有的线程都会继续运行并且尝试获取相同的锁对象。其中一个线程对象会被丢弃也不存在任何问题，因为这只会在初始化并出现竞争条件时才会发生。 因此，我们已经成功地复制了最初的内容，不同之处在于线程锁存储在被包装的函数上，而不是存储在一个封闭函数的堆栈上。我们仍然有一个问题，即每个实例方法都有一个不同的锁。(而不是一个实例内的所有同步方法共用一个锁)。简单的解决方案是利用我们的通用装饰器，它提供了判断装饰器被使用的上下文的能力。 具体点说，我们需要判断当前是否在装饰一个类方法或实例方法，如果是，则将锁对象存储在 instance 参数上。 12345678910111213141516171819202122232425262728293031323334353637383940@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: context = vars(wrapped) else: context = vars(instance) lock = context.get('_synchronized_lock', None) if lock is None: lock = context.setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)class Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo1 = Object()o2 = Object()&gt;&gt;&gt; o1.method_im()&gt;&gt;&gt; o1._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o1._synchronized_lock)4386605392&gt;&gt;&gt; o2.method_im()&gt;&gt;&gt; o2._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o2._synchronized_lock)4386605456 这个简单的改变实际上已经达到了我们想要的结果。如果同步的装饰器被用于一个正常的函数，那么线程锁将被存储在函数本身上，并且它将单独存在，并且只在调用相同的函数之间进行同步。 对于实例方法，线程锁将被存储在类的实例上，实例方法会绑定到类，因此在该类上标记为同步的任何实例方法都将在该线程锁上同步，从而模拟Java的行为 那类方法呢。在这种情况下，instance 参数实际上是类。如果线程锁被存储在类上，那么结果将是，如果有多个类方法，并且它们都被标记为synchronized，那么它们将相互排斥。这种情况下线程锁的使用方式将不同于实例方法，但这实际上也是我们想要的。 代码是否对类方法有效? 12345678&gt;&gt;&gt; Object.method_cm()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 38, in __call__ return self.wrapper(self.wrapped, instance, args, kwargs) File "synctest.py", line 176, in synchronized lock = context.setdefault('_synchronized_lock'),AttributeError: 'dictproxy' object has no attribute 'setdefault' 很不幸，有错。这种情况的原因是，类 __dict__ 不是一个普通的字典，而是一个 dictproxy 。一个 dictproxy 不与普通的dict共享相同的方法，特别是它不提供setdefault()方法。因此，我们需要一种不同的方法来为类创建同步线程锁。dictproxy 还导致了另一个问题，即它不支持属性设置。但是类本身支持属性设置 1234&gt;&gt;&gt; vars(Object)['_synchronized_lock'] = threading.RLock()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'dictproxy' object does not support item assignment 123&gt;&gt;&gt; setattr(Object, '_synchronized_lock', threading.RLock())&gt;&gt;&gt; Object._synchronized_lock&lt;_RLock owner=None count=0&gt; 由于函数对象和类实例都可以，所以我们需要切换更新属性的方法。 4. 存储在装饰器上的元线程锁作为dict.setdefault()第一次设置锁的原子方式的替代方法，我们可以做的是使用存储在@synchronized 装饰器本身上的元线程锁。由于元线程锁的创建仍存在竞争条件，因此需要使用dict.setdefault()实现元线程锁的原子性创建。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 请注意，由于对封装函数的锁存在的检查与创建元锁之间的间隙，在我们获得了元锁之后，我们需要再次检查锁是否存在。这是为了避免两个线程同时在尝试创建锁而发生竞争条件。 这里有一点很重要，我们仅仅在更新被包装对象上的锁时使用了属性访问方法。而在查找被包装对象上是否存在锁时，没有使用getattr()方法，而是继续在vars()返回的__dict__中查找它。这是必要的，因为当在类的实例上使用getattr()时，如果该属性在类的实例中不存在，那么查找规则意味着如果该属性在类本身上存在，那么将返回该属性。 如果一个同步的类方法是第一个被调用的，这会导致问题，因为它会在类本身上留下一个锁。当随后调用实例方法时，如果使用了getattr()，它会找到类类型的锁并返回它，并且会被错误地使用。因此，我们继续通过 __dict__ 寻找锁，因为它只包含实例中实际存在的内容。 有了这些修改，所有锁的创建都可以自动完成，并在不同的上下文中创建一个适当的锁。 12345678910111213141516171819202122232425262728@synchronizeddef function(): passclass Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo = Object()&gt;&gt;&gt; function()&gt;&gt;&gt; id(function._synchronized_lock)4338158480&gt;&gt;&gt; Object.method_cm()&gt;&gt;&gt; id(Object._synchronized_lock)4338904656&gt;&gt;&gt; o.method_im()&gt;&gt;&gt; id(o._synchronized_lock)4338904592 代码也适用于在静态方法或类中使用@synchronized。综上所述，@synchronized 可以被应用的场景如下: 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 5. 实现同步代码块所以，我们已经完成了对同步方法的支持，如何实现同步代码块呢。要实现的目标是能按照下面的方式编写代码: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，我们需要 synchronized 装饰器不仅可以用作装饰器，而且还可以作为上下文管理器使用。在synchronized作为上下文管理器时，类似于Java，需要提供给它执行同步操作的对象，对于实例方法而言，这个对象是 self 参数或者类的实例。为了解释我们如何做到这一点，需要等待下一篇文章。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 装饰器的类实现]]></title>
    <url>%2F2018%2F05%2F25%2Fwrapt%2Fpython_decorator_06%2F</url>
    <content type="text"><![CDATA[上一篇文章中，我们讨论了如何实现一个带参数的装饰器，以及如何让装饰器可选的接收参数而不是必需输入参数。也讨论了如何让装饰器能在被包装函数的不同调用之间保持状态。保持状态的一种可用方法是使用类实现装饰器。然而我们实现的通用装饰器模式在使用类实现装饰器还存在一些问题，本文我们将来探讨问题出现的根源以及如何解决。 1. 装饰器工厂函数正如前文所述，我们通过类实现装饰器的模式如下 12345678910class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 当我们这么做时，装饰器在被应用时发生了如下错误: 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) _decorator() 是我们装饰器工厂函数的内部函数。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 错误的原因是我们使用函数闭包实现装饰器工厂函数，却希望它能同时工作在普通函数和类方法上。当类方法被访问时，将触发描述符协议，绑定将会发生；类实例的引用将自动作为第一个参数传递给类方法。而 _decorator() 却没有被定义成同时接收 self和wrapped 作为参数，所以调用失败。我们可以创建一个仅用于类实例的装饰器工厂函数。但是这与我们之前要为类方法和函数创建统一的装饰器的初衷相违背。 解决问题的方法是，使用我们的 function_wrapper 作为装饰器工厂的返回对象，而不是函数闭包。 12345678910111213141516171819def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): return function_wrapper(wrapped, wrapper) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper)class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 这种方式特别巧妙，但是很不容易理解，我们再来看看整个调用的发生过程 with_arguments(arg=1) 带参数的装饰器被使用时，将创建一个类实例 ins 在 @decorator 装饰下, ins 的 __call__ 方法此时是 function_wrapper(__call__, _wrapper) 对象 @ 将 function 对象作为参数传递给创建的类实例，将调用 ins.__call__(function) 方法，此时将触发function_wrapper的描述符协议，并进一步调用 _wrapper(__call__, ins) 函数，functions 对象则通过 arg 传递给 _execute 函数，_execute 执行返回新的 function_wrapper(functions, __call__) 对象 装饰的最终结果是，我们现在不必担心 @decorator 被应用在普通函数，实例方法还是一个类方法上。因为在所有的情况下，被绑定的实例对象不会通过 args 被传递 细心的读者很快就会发现另一个问题，在 __call__ 在被调用时，需要传入装饰器类的实例即 self 参数，而在上述的实现中并没有此步骤。(不过我没懂为什么作者在 _wrapper 内多嵌套一层_execute函数，应该是想说名这是要被执行的部分。) 2. 类的绑定要求更改之后，重新进行测试，我们遇到了一个新的问题。这次发生在被被包装函数被调用的时候。 123456&gt;&gt;&gt; function()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 243, in __call__ return self.wrapper(self.wrapped, None, args, kwargs)TypeError: __call__() takes exactly 5 arguments (4 given) 现在这个问题是__call__()方法传递给@decorator发生在 类初始化，此时它是未绑定方法，任何类实例远还没被创建。通常情况下，类实例的引用在方法被绑定时被提供，但是因为我们的装饰器实际是一个工厂函数，因此这里涉及到了两层绑定。外部包装函数的类实例被传递给工厂函数内部的 _wrapper 函数的instance参数。但是它在 function wrapper 对象被创建的时候，完全没有被使用。为了解决这个问题，我们需要根据是否绑定了一个实例方法，显示使用类实例绑定我们的包装函数 1234567891011def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 在这个示例中，有三种情况需要我们处理。 第一种情况是 instance 为 None。这对应于decorator函数被应用在普通函数，类静态方法或一个类上 第二种情况是 instance 不为 None，但是是一个类对象。这对应用于一个类方法。这种情况下，我们需要通过包装函数的get()将包装函数显示绑定到一个类对象。 第三种即最后一种情况下，instance 不是None，也不是一个类对象。这对应于实例方法。在这种情况我们仍然需要绑定包装函数，只不过这次绑定的是类实例。 3. 总结改进之后，我们解决了所有问题，而且很大程度上完善了我们的装饰器模式。所以，目前我们的通用装饰器解决方案如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 尽管在之前的文章中提到过。这里给出的对象代理实现并不是一个完美实现。因此，不要使用这段代码。如果你使用了，就会发现。在被包装函数上的部分内省操作不会按照我们所预期的执行。特别的，访问函数的doc属性总是返回 None。类似Python3中的新增变量 __qualname__ 和 __module__ 也不能正确显示。 正确处理像__doc__这样的内置属性是比较费劲的，因为内置属性的获取逻辑与普通属性有时候并不相同。上述实现中我们期望的是，无论从代理对象还是代理对象的子类，我们都是从被包装函数获取并返回属性值，但是对于__doc__属性，即便是代理对象的子类没有__doc__属性，它也同样会覆盖父类的__doc__，结果是代理对象的子类拦截了对 __doc__ 属性的获取。所以这里展示的代理对象仅仅是一个参照实现。 大体上说，这里所有的代码都仅仅是参照实现。目的不是使用而是展示如何实现一个更加通用的装饰器。它只是提供给你一个学习的途径。不要期望通过简单的几行代码就能实现，事情不会那么简单。 4. wrapt 模块如果我告诉你不要使用这里的代码，那你应该怎么做呢？答案是在PyPi上已经有现成的 wrapt 模块。wrapt 模块已经上线几个月了，但是目前为止并没有广为人知。它实现了这里描述的所有细节，甚至更多。这个模块实现了一个完整的代理对象，能使所有代码正确执行。并且提供了很多和装饰器工厂函数相关的特性，也提供了很多和猴子补丁相关的特性。 虽然我指出了wrapt 模块的存在，但是博客内容不会就此停止，因为我还有其他一些主题想要阐述。这些内容包括通用装饰器的应用，启用和关闭装饰器，装饰器执行性能问题，以及代理对象，猴子补丁的实现问题等等。 接下来的博客，我将举一个通用装饰器应用的特殊示例，来说明Python 装饰器如此强大，为什么Pyhton不提供一个@synchronized装饰器。在装饰器第一次被引入编程语言时，这个装饰器被当作是如何使用装饰器的经典示例。然而我能找到的所有实现都是半成品，很少在现实世界中被使用。我相信这里的通用装饰器能帮助我们实现一个可用的@synchronized装饰器。我将在下一篇博客中详述它。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 带参数的装饰器]]></title>
    <url>%2F2018%2F05%2F24%2Fwrapt%2Fpython_decorator_05%2F</url>
    <content type="text"><![CDATA[在之前的博客，通过使用代理对象，装饰器工厂函数等技术，我们已经实现了一个通用装饰器。在这篇文章中，我们将使用前面文章中描述的装饰器工厂函数，介绍如何使用它来实现接受参数的装饰器，包括强制参数和可选的接收参数。 1. 装饰器创建模式前面文章中描述的关键组件是一个函数包装器对象。我不打算复制代码，所以请参阅前面的帖子。简而言之，它是一个类类型，它接受要被包装的函数和一个用户提供的包装器函数。所得到的函数包装器对象的实例被用来代替被包装函数，当调用时，会将被包装函数的调用委托给用户提供的包装器函数。这允许用户修改调用的方式，在调用被包装函数之前或之后执行操作，或者修改输入参数或结果。function_wrapper 和装饰器工厂一起使用创建装饰器的方式如下:** 12345678910111213141516171819# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator# 使用工厂函数创建的装饰器@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) print('KWARGS', kwargs) return wrapped(*args, **kwargs)# 应用装饰器包装函数@my_function_wrapperdef function(a, b): pass 在本例中，创建的最终装饰器不接受任何参数，但如果我们希望装饰器能够接受参数，在调用用户提供的包装器函数时可访问传入的参数，那么我们该如何做呢？ 2. 使用函数闭包收集参数最简单的实现一个能接收参数的装饰器的方式是使用函数闭包 123456789def with_arguments(arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments(arg=1)def function(): pass 实际上，外部函数本身是一个工厂函数，可根据传入的参数，返回不同的装饰器实例。因此，当外部工厂函数被应用到一个具有特定参数的函数时，它返回内部装饰器函数，实际上它是应用于被包装的函数。当包装器函数最终被调用时，它会调用被包装函数，并通过作为函数闭包的一部分来访问传递给外部工厂函数的原始参数。** 位置或关键字参数可以与外部装饰器工厂函数一起使用，但是我认为关键字参数可能是一个更好的惯例，我稍后会展示。现在，如果带有参数的装饰器具有默认值，使用这种方法来实现装饰器，即使不传递参数，也必需将其作为一个不同的调用来使用。也就是说，仍然需要提供空括号。 123456789def with_arguments(arg='default'): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments()def function(): pass 尽管这只是一个特例，但看起来不优雅。大多数更喜欢当所有参数都是可选，并没有被显示传递参数时，括号时可选的。换句话说，当没有参数被传递时，可以被写成 123@with_argumentsdef function(): pass 当我们从另一个角度看问题时，这个想法实际上是有价值的。如果一个装饰器最初不接收参数，但是之后又需要可选的接收参数。如果括号是可选的，那么原来不带参数调用装饰器的代码也无需改变。 3. 带可选参数的装饰器允许装饰器添加可选参数，可以将上面的方法更改为: 12345678910111213141516def optional_arguments(wrapped=None, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped)@optional_arguments(arg=2)def function1(): pass@optional_argumentsdef function2(): pass 当具有默认的可选参数时，外部工厂函数将被包装函数作为第一个参数并默认为 None。第一次调用时，被包装函数是 None，通过 partical 函数再一次返回装饰器工厂函数。第二次调用，被包装函数将被传入并被装饰器包装。 将装饰器被直接装饰函数时，因为默认参数的存在，我们不需要显示传递参数。因为 wrapped 惨数值不是None，装饰器直接返回工厂函数，直接装饰函数。 此时工厂函数的参数必需是关键词参数，Python 3允许您使用新的关键字参数语法来强制使用关键词参数。 123456789def optional_arguments(wrapped=None, *, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped) 这样，就可以避免有人不小心将装饰器参数作为位置参数传递给 wrapped。对于一致性，关键字参数也可以被强制执行，即使它不是必需的。 12345def required_arguments(*, arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper 4. 在调用之间保持状态某些时候，装饰器可能需要在函数调用之间保持状态。一个典型的例子是缓存装饰器。此时，由于包装器函数本身没有任何状态收集器，所以只能借助于装饰器能够访问到的外部数据结构作为状态收集器进行状态保持。 有几种方法可以做到这一点。 第一个是将保持状态的对象作为显式参数传递给装饰器 12345678910111213141516def cache(d): @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = wrapped(*args, **kwargs) return result return _wrapper_d = &#123;&#125;@cache(_d)def function(): return time.time() 除非有特定的需要能够传入状态对象，否则第二个更好的方法是在外部函数的调用中创建状态对象。 1234567891011121314151617def cache(wrapped): d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function(): return time.time() 这种情况下，外部包装函数在函数内部自定状态对象，而不是通过参数显示传递。如果这是一个合理的默认值，但是在某些情况下，仍然需要将状态对象作为参数传递进来，那么可以使用可选的装饰数参数。 12345678910111213141516171819202122232425262728293031def cache(wrapped=None, d=None): if wrapped is None: return functools.partial(cache, d=d) if d is None: d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function1(): return time.time()_d = &#123;&#125;@cache(d=_d)def function2(): return time.time()@cache(d=_d)def function3(): return time.time() 5. 使用类创建装饰器在第一篇文章中，我们说过可以使用类实现装饰器。 1234567class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 就像之前已经阐述的，这种通过类实现的装饰器存在缺陷，但是作为一种替代模式，这种原始的方法也能保持状态。具体地说，类的构造函数可以将状态对象连同被包装函数保存为类实例的属性。 1234567891011121314151617class cache(object): def __init__(self, wrapped): self.wrapped = wrapped self.d = &#123;&#125; def __call__(self, *args, **kwargs): try: key = (args, frozenset(kwargs.items())) return self.d[key] except KeyError: result = self.d[key] = self.wrapped(*args, **kwargs) return result@cachedef function(): return time.time() 在装饰器逻辑特别复杂时，这种通过类实现的装饰器也存在一些好处。可以拆分封装在不同的类方法中。那么使用我们的新函数包装器和装饰器工厂，能否将装饰器实现为类呢？一种可能的方式是这样: 123456789101112class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 装饰器执行逻辑是这样的，当带参数的装饰器被使用时，将创建一个类实例。在被包装函数被调用时，将调用 @decorator 装饰的实例方法 __call__()，__call__()进而调用被包装函数。因为__call__()是实例的绑定方法，所以能够访问到类实例拥有的状态对象。 那么事实上是否能正常运行呢？ 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) 理想很丰满，显示很骨干。失败的原因就在于装饰器工厂函数的实现方式，我们将在下一篇文章种解释并解决这个特别的问题。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 作为另一种一种替代方式是，仍然使用类封装所需的逻辑，并在函数闭包类创建实例供包装函数使用。装饰器将功能委托给类实例，但是本身不作为类实现。这种方式需要额外创建一个类，使用起来并不优雅。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 实现一个通用装饰器]]></title>
    <url>%2F2018%2F05%2F22%2Fwrapt%2Fpython_decorator_04%2F</url>
    <content type="text"><![CDATA[本节我们将实现一个”通用装饰器”，它能够让用户提供的包装函数通过传入的参数判断其被使用的上下文，即确定，它是被应用在函数，实例方法，类方法，类对象中的哪一个。因为装饰器不是在各个环境种被单独实现，而是以一种更加统一的方式创建，所以将这种能确定上下文的装饰器称为通用装饰器。 1. 内容回顾到目前为止，我们创建装饰器的方式已经经过了几次迭代: 第一篇博客中我们介绍使用函数创建装饰器的传统方式，这种方式存在几个重大问题 为解决函数创建装饰器的问题，我们在第二篇博客中使用了代理对象，并将装饰器实现成了描述符，这种方式有效的解决了之前的问题，但是存在大量的样板代码 为了提高创建装饰器的效率，第三篇博客中我们使用了装饰器工厂函数，抽象了装饰器的创建过程，用户只需提供一个执行所需的包装函数即可。我们的目的是实现一个通用装饰器，能够让用户的包装函数通过传入参数确定其被使用的上下文。 12345678910111213# 包装函数通过传入参数确定其被使用的上下文@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 目前为止我们已经能够区分装饰器是被用于普通函数和还是实例方法，但是当通过类调用类方法和静态方法时将出现问题。本文我们将继续探索如何调整我们的装饰器工厂函数，以区分类方法和静态方法，以便找到实现通用装饰器的模式 2. 区分普通函数和实例方法目前为止，我们的通用装饰器模式实现如下: 123456789101112131415161718192021222324252627282930313233class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 为了测试当前的模式能在任何情况下都能工作，我们需要使用装饰器工厂创建一个装饰器，它能在执行时打印绑定的 instance 对象，以及传递进来的参数。 12345@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) 当装饰器被应用到一个正常的函数和实例方法时，包括通过显式传入实例调用实例方法时，我们能够得到符合预期的结果 12345678910111213141516171819202122@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 但是当装饰起被应用到类方法以及静态方法时，参数传递发生了错误。instance 按预期要么为空，要么接收的是类实例或类对象，现在却是传递给函数的第一个实参。并不符合我们通用装饰器的要求 。 12345678910111213141516171819class Class(object): @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE 1ARGS (2,) 3. 区分类方法和静态方法因此，我们要指出的是，在实例被传递为None的情况下，我们需要能够区分这三种情况: 通过类直接调用实例方法 类方法被调用 静态方法被调用 一种判断方法是查看绑定函数的__self__属性。该属性保存了函数在特定时间点绑定到的对象类型信息。我们先来看看通过类调用不同方法时，此属性的值。 123456789101112&gt;&gt;&gt; print(Class.function_im.__self__)None&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' 通过类调用实例方法的情况，__self__ 值为 None，对于类方法，它将是类对象，在静态方法的情况下，不存在 __self__ 属性。似乎检查 __self__ 是一个有效的判断方法 在我们编写一个基于此的解决方案之前，我们先检查一下Python 3，以确保我们在那里没问题，并且没有任何变化。 12345678910111213141516&gt;&gt;&gt; print(Class.function_im.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "dectest.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__'&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' Python 3 与 Python 2 表现并不相同，此方法无效。但是为什么会出现这种情况？发生这种情况的原因是，Pyhton3 已经没有未绑定对象这个对象，通过类直接调用实例方法时返回的也是函数。而Python2中通过类调用实例的返回值类型依赖于 __self__ 是否为None，所以Python3中删除了此属性。因此，我们现在不能区分通过类调用实例方法和调用静态方法这两种情况。 另一个方法是在 function_wrapper 构造函数内，检查被包装对象的类型，并确定它是类方法还是静态方法。然后，将判定信息传递到 bound function wrapper 并进行进一步检查。 12345678910111213141516171819202122232425262728293031323334class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function' and self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 如果有人实际上在他们的decorator中实现了描述符协议，那么希望他们也可以在这里使用对象代理。因为对象代理拥有class属性，它将返回被包装对象的类，这意味着isinstance()检查仍然会成功，因为isinstance()会优先考虑class的返回结果，而不是对象的实际类型。 无论如何，更改后，我们重新测试如下 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 成功，我们已经修复了调用类方法和静态方法时参数列表问题。现在的问题是，虽然对通过实例调用方法时， instance 参数没有问题。但是无论是通过实例还是类，传递给类方法和静态方法的 instance 参数都没有什么用。并且我们不能将它同其他情形区别开。理想情况下，我们希望调用类方法时 instance 参数始终为类对象，而调用静态方法时，则使用为 None。因此 对于静态方法，我们只需要在检查被包装类型时，判断 ‘staticmethod’ 即可 对于类方法的情况，如果我们回头看一下我们的测试，看看是否可以使用__self__属性，我们发现，对于类方法，__self__是类实例，对于静态方法，属性不存在。因此，我们可以做的是，如果包装对象的类型不是一个函数，那么我们可以查找__self__的值，如果它不存在的话，就会默认为None。这将满足这两种情况。进一步改进后如下 1234567891011121314151617181920212223class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function': # 通过类调用的实例方法 if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: # 通过实例调用的实例方法 return self.wrapper(self.wrapped, self.instance, args, kwargs) else: # 调用静态方法，__self__ 属性不存在，instance 为 None # 调用类方法时，__self__ 为类对象， instance 为类对象 instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) 如果我们重新测试一次，我们将得到我们想要得结果 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 现在万事大吉了？可惜并不是。 4. 多层绑定还有一个我们还没有考虑到的特殊情况，即为方法创建别名，并通过别名调用时。 1234567891011121314151617181920212223&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE 1ARGS (2,)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 132, in __call__ return self.wrapper(wrapped, instance, args, kwargs) File "test.py", line 58, in my_function_wrapper return wrapped(*args, **kwargs)TypeError: unbound method function_im() must be called with Class instance as first argument (got int instance instead)&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 对于类方法或静态方法来说，一切都很好，但是对于实例方法来说却失败了。这里的问题是由于在第一次访问实例方法时，它将返回绑定的bound_function wrapper对象。然后把它作为类的属性分配回来。当通过新名称进行后续查找时，在正常情况下，绑定将再次发生，以将其绑定到实际实例。在我们的绑定函数包装器的实现中，我们不提供__get__()方法，因此不会发生这种重新绑定。结果是，在随后的调用中，它全部崩溃。 Class.function_rm = Class.function_im 设置别名时，发生第一次描述符协议，function_rm 绑定得是 bound_function_wrapper 对象，第二次通过别名调用实例方法时会发生第二次描述符协议，进行第二次绑定。 因此，解决方案是我们需要向 bound_function_wrapper 添加__get__()方法，为其提供了执行进一步绑定的能力。我们只希望在实例为None的地方执行这个操作，这表明我们处理的是实例方法，而不是类方法或静态方法。 (注: Class.function_rm = Class.function_im 第一次绑定时，self.binding 为 function，并且由于时通过类直接调用实例方法，因此 instance 参数是 None。包装普通函数时也符合此类情况，但是不会触发描述符协议，只有通过实例调用发生第二次绑定时，才会调用bound_function_wrapper 的__get__方法) 另一个问题是，我们需要绑定的是原始的被包装函数，而不是绑定后的包装函数。最简单的处理方法是将对原始函数包装器 function_wrapper 的引用传递给绑定的函数包装器bound_function_wrapper，并通过它获得原始的被包装函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent # 目的是获取原始的被包装函数 def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): # 仅在通过类调用实例方法时才会发生第二次绑定 if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) # instance 是第二次绑定传入的实例对象 return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 再次运行测试得到如下所示 1234567891011121314151617&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;__main__.Class object at 0x105609790&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 5. 装饰器应用顺序目前为止，我们的装饰器一直被放置在将方法标记为类方法或静态方法的装饰器之外。如果我们颠倒顺序会怎样？ 1234567891011121314151617181920212223242526272829class Class(object): @classmethod @my_function_wrapper def function_cm(self, a, b): pass @staticmethod @my_function_wrapper def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_cm(1,2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 静态方法按预期运行，但是类方法不行。在这个特殊的例子中，它实际上可以被看作是Python本身的一个bug。具体地说，classmethod 装饰器本身并不能对它包装的所有对象都遵守描述符协议。这也是为什么当使用闭包实现装饰器会发生错误的原因。如果classmethod 装饰器能正常工作，一起都是OK 的。对于那些对细节感兴趣的人，您可以在Python bug跟踪器中查看19072。 6. 装饰器一个类除了与类方法的装饰器顺序之外，我们实现的通用装饰器的模式看起来很好。我在上一篇文章中提到过，我们的目标是，我们也可以区分什么时候装饰器被应用到一个类中。所以让我们试试 1234567@my_function_wrapperclass Class(object): pass&gt;&gt;&gt; c = Class()INSTANCE NoneARGS () 基于此，我们无法将其与普通函数或类方法区分开来。如果我们再考虑一下，在这个例子中传递给包装器函数的包装对象将是类本身。让我们输出传递给用户包装函数的 wrapped参数，看看是否能区分出这种情景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('WRAPPED', wrapped) print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)WRAPPED &lt;function function at 0x10e13bb18&gt;INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): pass @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_im(1,2)WRAPPED &lt;bound method Class.function_im of &lt;__main__.Class object at 0x107e90950&gt;&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)WRAPPED &lt;functools.partial object at 0x107df3208&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)@my_function_wrapperclass Class(object): passc = Class()&gt;&gt;&gt; c = Class()WRAPPED &lt;class '__main__.Class'&gt;INSTANCE NoneARGS () 答案是肯定的，因为它是唯一一个被包装对象是类型对象的情况。 7. 通用装饰器结构我们的目标是，一个装饰器能同时被应用在普通函数，示例方法，类方法以及类上。比较特殊的是静态方法，但是实践中，静态方法与函数并没有本质上的不同，只是它被放在不同的地方。在装饰器的执行过程中区分出静态方法是必要的，但是静态方法不会包含任何连接到它所在的类的参数。如果需要，在开始更应该创建一个类方法。最后我们的通用装饰器可以被展示如下: 12345678910111213141516@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) 这样的通用装饰器有实际用途吗?我相信有一些很好的例子，我将在随后的博客文章中特别提到其中一个。其他一些框架，比如Django，也使用了一些技巧来创建同时适用于函数和实例方法的装饰器。事实证明，他们使用的方法是不正确的，因为它不遵守描述符协议。如果您对此感兴趣，请参见Django bug跟踪器中的第21247号问题。下一篇博客中将介绍一些具有可选参数的装饰器的问题，通用装饰器的使用实例留在以后展示。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 使用工厂函数创建装饰器]]></title>
    <url>%2F2018%2F05%2F12%2Fwrapt%2Fpython_decorator_03%2F</url>
    <content type="text"><![CDATA[上一篇文章描述了一种基于代理对象创建装饰器的模式，并且通过将装饰器实现为一个描述符，解决了当装饰器应用于类方法时，对象绑定问题。代理对象和描述符的组合自动确保了内省机制能正常进行。现在的问题是如何消除样本代码来解决代码复用的问题。本文我们将进一步改进创建装饰器的方式，通过使用装饰器工厂函数，来抽象装饰器的创建，用户只需提供一个执行所需功能的的包装函数即可。 1. 装饰器的实现模式如前所述，我们需要一个代理对象，其实现如下 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 正如最后一次指出的那样，这是对它所做事情的最小表示。一个通用的对象代理需要做更多的工作。 描述符本身将按照如下模式实现 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 当将装饰器应用于一个正常的函数时，将使用包装器的 __call__()方法。如果将包装器应用于类的方法，则在属性访问时调用 __get__() 方法，返回一个新的绑定对象之后的装饰器，并在被调用时调用新的装饰器的__call__()方法。这使得我们的包装器能作为描述符来传递描述符协议，以根据需要对包装的对象进行绑定。 2. 创建装饰器的装饰器正常工作的装饰器有一个固定的实现模式，因此，我们可以使用工场函数抽象装饰器创建的过程，工厂函数可以作为一个装饰器使用，创建一个装饰器的过程如下: 1234567@decoratordef my_function_wrapper(wrapped, args, kwargs): return wrapped(*args, **kwargs)@my_function_wrapperdef function(): pass 这个装饰器工厂函数 decorator 应该怎么实现呢？就像表现的一样，我们的装饰器工厂函数是非常简单的，与partial()函数并没有很大不同，在装饰器定义时接收用户提供的包装函数，在装饰器应用时接收被包装函数，并将他们传递到function wrapper对象中。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 我们现在只需要修改我们的装饰器 function wrapper 对象的实现，将包装对象的实际执行委托给用户提供的包装函数。 123456789101112131415161718192021class bound_function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs) function_wrapper 和 bound_function_wrapper 同时接收包装函数，和被包装函数，并将 __call__() 实际执行委托给用户提供的包装函数，由用户调用被包装函数并返回值。 因此，我们可以使用工厂来简化创建装饰器的过程。现在让我们来检查一下，在所有的情况下，这将在实际工作中发挥作用，并且看看我们还能找到什么其他的问题，以及我们是否能在这些情况下改进。 3. 装饰类方法第一个可能导致问题的领域是创建一个单独的decorator，它可以同时处理类的正常函数和实例方法。为了测试我们的新decorator是如何工作的，我们可以在调用包装函数时打印传递给包装器的args，并可以比较结果。 1234@decoratordef my_function_wrapper(wrapped, args, kwargs): print('ARGS', args) return wrapped(*args, **kwargs) 首先让我们尝试包装一个普通函数: 123456@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)ARGS (1, 2) 正如所期望的那样，在函数被调用时，只有两个参数被输出。包装一个实例方法会如何？ 123456789class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im()ARGS (1, 2) 同样，当调用实例方法时传入的两个参数被输出。因此，装饰器对正常函数和实例方法的工作方式是相同的。 这里的问题是，用户如何在他们的包装函数中获取类的实例。当函数被绑定到类的实例时，我们丢失了这个信息，因为类实例现在与传入的绑定函数关联，而不是参数列表。要解决这个问题，我们可以记住在调用绑定函数时传递给 __get__() 方法的实例是什么。在 bound wrapper被创建，作为参数传递给bound wrapper。 12345678910111213141516171819202122class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 在bound wrapper中，类实例作为额外的参数传给用户创建的包装函数。对于普通函数，在顶级包装器中，对于这个新的实例参数，我们没有传递任何内容。现在，我们可以修用户的包装函数，以输出实例和传递的参数。 12345678910111213@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 因此，这种变化能让我们在包装器函数中区分出一个普通函数调用和一个的实例方法调用。对实例的引用甚至是单独传递的，在调用原始被包装函数时，我们不必为一个实例方法去判断并移除额外的类实例参数。对于类，原始的被包装函数已经是绑定对象，所以不能在传入类实例对象。 需要注意的是实例方法可以通过类，显示传递类实例来调用，我们需要验证这种情况是否仍然符合我们的要求。 123&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE NoneARGS (&lt;__main__.Class object at 0x1085ca9d0&gt;, 1, 2) 不幸的是，将实例显式地传递给类中的函数作为参数时，类实例没有通过 instance 传递给包装函数，而是作为 arg 的第一个参数被传递。这并不是一个理想的结果 为了处理这种变化，我们可以在调用bound_function_wrapper.__call__()之前检查实例，并从参数列表的开头弹出实例。然后使用 partcial 函数将实例绑定到被包装函数上，并调用用户的包装函数。 1234567891011121314class bound_function_wrapper(object_proxy): def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)# We then get the same result no matter whether the instance method is called via the class or not.&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 对于实例方法，一切都可以正常执行，被包装函数无论是实例方法和还是普通函数接收参数完全相同。得益与 instance 参数，在将装饰器应用于实例方法时，我们可以按需调用类方法。 对于类可以拥有的其他方法类型，特别是类方法和静态方法会怎样？ 12345678910class Class(object): @my_function_wrapper @classmethod def function_cm(cls, a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,) 正如所看见得，装饰器对类方法和静态方法有非常严重得问题。这两种情况下，在函数被绑定时，instance 参数将为空。此时传递给函数的第一实参将被传递给 instance，这显然是不正确的，应该怎么做？ 4. 通用装饰器所以我们并没有完成一个通用的装饰器，但我们到底想要达到什么目的呢?我们最初的装饰模式有什么问题?这里的终极目标是我所说的“通用装饰器”。一个可以应用于普通函数、实例方法、类方法、静态方法甚至是类的修饰符，修饰符能够在使用的时候自动适用它被使用的上下文。 目前为止，实现装饰器的所有方法想达到上述目标是不可能了。只能通过复制代码，或者通过某种技巧转换装饰器，以便装饰器能在不同的上下文中使用。我的目标是能实现如下功能: 123456789101112@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 本文中，我们已经实现了让装饰器在普通函数和实例方法上正确执行，我们现在需要了解如何处理类方法、静态方法以及将装饰器应用于类的场景。本系列的下一篇文章将继续追求这个目标，并描述如何进一步调整我们的装饰器。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 装饰器与描述符协议]]></title>
    <url>%2F2018%2F05%2F08%2Fwrapt%2Fpython_decorator_02%2F</url>
    <content type="text"><![CDATA[上一篇文章说明了普通函数实现的装饰器存在的问题。本文我们将着眼于之前阐述的最后一个问题，如何将装饰器应用到一个描述符上。 1. 描述符协议有关 Python 的对象模型和底层设计原理推荐大家读一读《流畅的Python》，这里不会详细解释描述符是什么以及他们的工作原理。简而言之，描述符就是存在绑定行文的对象，即属性访问会被描述符协议实现的方法所覆盖。实现描述符协议的特殊方法包括 __get__(), __set__(), 和 __delete__()。如果任意一中方法在一个对象中被定义，就可以说该对象是一个描述符** 123obj.attribute attribute.__get_(obj.type(obj))obj.attribute = value attribute.__set_(obj, value)del obj.attribute attribute.__delete_(obj, value) 上述描述的是，如果一个类的属性包含上述任意一中特殊方法，当相应操作在类属性被执行时，这些特殊方法将取代默认方法被调用。这就允许一个属性去覆盖将发生默认操作。 也许你以为你从未使用过描述符，事实上，函数对象就是描述符。当在类中定义函数时，函数就是普通的函数。当你通过’.’属性访问函数时，你将调用函数的 __get__()方法，将函数与一个类实例绑定，进而返回一个绑定方法对象** 123456789101112def f(obj): pass&gt;&gt;&gt; hasattr(f, '__get__')True&gt;&gt;&gt; f&lt;function f at 0x10e963cf8&gt;&gt;&gt;&gt; obj = object()&gt;&gt;&gt; f.__get__(obj, type(obj))&lt;bound method object.f of &lt;object object at 0x10e8ac0b0&gt;&gt; 所以当你调用类方法时，调用的不是原始函数的 __call__()，而是访问函数时临时创建的绑定方法对象的 __call__() 方法，当然，你通常不会看到所有这些中间步骤，只看到结果。 1234567&gt;&gt;&gt; class Object(object):... def f(self): pass&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; obj.f&lt;bound method Object.f of &lt;__main__.Object object at 0x10abf29d0&gt;&gt; 现在回想一下在第一个博客文章中给出的例子，当我们对一个类方法应用了装饰器时，我们遇到了如下错误: 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 示例中的问题在于 @classmethod 装饰器返回的 classmethod 对象本身并没有 __call__() 方法，__call__() 方法仅存在于 classmethod 对象__get__()被调用时返回的结果中。 更具体的说， 人们使用的简单装饰器，并没有对被包装的描述符对象执行描述符协议以产生的一个可调用对象。想反，只是简单的直接调用被包装对象。因为其没有 __call__() 方法，结果当然会失败。 那为什么将装饰器应用在普通的实例方法上仍然可以运行呢？原因是一个普通函数本身具有 __call__() 方法，包装函数直接调用的是此方法。而且尽管绑定步骤被跳过，但是包装函数将 self 包含的实例对象通过第一参数显示传递给了原始的未绑定函数对象。因此对于一个普通的实例方法包装前后调用实际上是相同的，只有当被包装的对象(如@classmethod)依赖于正确应用的描述符协议时，才会崩溃。 2. 包装描述符对象解决包装器不能在类方法执行描述符协议获取绑定对象的方法是，让包装器也成为一个描述符对象。 1234567891011121314class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 如果将包装器应用于一个正常的函数，则使用包装器的 __call__()方法。如果将包装器应用于类的方法，则调用__get__()方法，该方法返回一个新的绑定包装器，并调用该方法的 __call__() 方法。这样我们的包装器就可以在描述符的传播过程中使用。 因为将装饰器实现为一个描述符对象时，使用闭包总是会失败，因此这种情况下为了让所有的事都能正常工作，我们必需总是使用类实现装饰器。装饰器类将实现描述符协议，如上所式。 现在的问题是，我们如何解决我们列出的其他问题。我们使用functools.wrap() 和 functools.update_wrapper() 解决命名问题，现在我们应该怎么做以便继续使用他们。因为 functools.wrap() 内部使用 update_wrapper(),所以我们只需要看看它如何实现。 12345678910111213141516171819WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__')WRAPPER_UPDATES = ('__dict__',)def update_wrapper(wrapper, wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES): wrapper.__wrapped__ = wrapped for attr in assigned: try: value = getattr(wrapped, attr) except AttributeError: pass else: setattr(wrapper, attr, value) for attr in updated: getattr(wrapper, attr).update( getattr(wrapped, attr, &#123;&#125;)) 如上展示的是Python3.3中的代码，事实上它还存在一个bug，在Python3.4中已经修复。 在函数体中，3件事需要被做。 第一件是将被包装函数保存为包装函数的__wrapped__属性。这就是那个bug，因为它应该在最后实现 第二步，复制诸如 __name__ 和 __doc__ 属性； 最后一步，复制被包装函数dict属性值到包装函数，结果是很多对象需要被复制 如果我们使用的是一个函数闭包或直接的类包装器，那么这个复制就可以在decorator应用的时候完成。当装饰器被实现为描述符时，也需要在 bound wrapper 中完成上述工作。 123456789class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) 因为bound wrapper 在包装器每次被作为类的绑定方法调用时都会被创建，所有将非常慢。我们需要更高效的方式处理它。 2. 代理对象性能问题的解决方法是，使用代理对象。这是一个特殊的包装类，因为它的行为跟它包装的东西看起来很像。 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 一个完全透明的对象代理本身就是一个复杂的怪物，所以我打算暂时把细节掩盖起来，并在一个单独的博客文章中讨论它。上面的例子是它所做事情的最小表示。实际上，它实际上需要做更多的工作。简而言之，它将有限的属性从包装的对象复制到自身，并使用特殊的方法、属性和 __getattr__() 来从包装对象中获取属性，从而避免需要复制许多可能永远不会被访问的属性。 我们现在要做的是从对象代理中派生出包装器类，并取消调用update_wrapper()。 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 现在从包装器中查询像 __name__ 和 __doc__ 这样的属性时，将从被包装函数直接返回。使用透明的对象代理也意味着像 inspect.getargspec() 和 inspection.getsource() 这样的调用也将按照预期正常工作。 3. 代码复用尽管这种模式解决了最初确定的问题，但它包含了大量的重复样板代码。此外，在现在的代码中有两个位置，调用被包装函数。因而需要在两个地方重复实现包装逻辑。因此，每次需要实现一个装饰器时都要复制这一点，因此会有点痛苦。 我们可以做的是将整个过程打包到一个装饰器工厂函数中，从而避免每次都需要手工完成这一切。如何做到这一点将成为本系列下一篇博客文章的主题。从这一点开始，我们可以开始研究如何进一步改进功能，并引入新的功能，这些都是使用常规的装饰器实现方法难以实现的。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 如何实现一个 Python 装饰器]]></title>
    <url>%2F2018%2F05%2F04%2Fwrapt%2Fpython_decorator_01%2F</url>
    <content type="text"><![CDATA[稍微对 Python 有所了解的程序员一定知道 Python 装饰器和函数闭包。我曾经也以为很了解，直到在《流畅的Python》中看到了 Wrapt 模块。 Wrapt 模块的作者 Graham Dumpleton 先生写了 14 篇博客详细讲解了如何在 Python 中实现一个能同时包装函数，类方法，实例方法的通用装饰器。本文以及接下来几篇文章是我对那 14 篇博客的整理和笔记。 Graham Dumpleton 先生的博文 和 Wrapt 模块请参阅: GrahamDumpleton wrapt blog wrapt 1.10.11 documentation 1. 通过函数闭包实现装饰器装饰器的典型目的是为被包装函数附加的额外的处理逻辑。我遇到的使用装饰器的最典型场景是，大多数数据库对一次查询可设置的查询的条件有数量限制，大量查询时需要将多个查询条件分组进行多次查询在合并查询结果。比如我有100000 用户需要根据ID 查询其性别，查询条件太多，只能分批多次查询，然后将查询结果合并。这种分批查询不仅对 mysql，对其他任何数据库都适用，所以非常适用用装饰器将分批查询再合并的功能抽象出来。 1.1 实现原理大多数人(我)都是通过闭包来创建一个装饰器，就像下面这样。1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper# @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖@function_wrapperdef function(): passfunction = function_wrapper(function) 整个包装的执行过程如下: 包装函数(function_wrapper)接收被包装函数(wrapped)作为参数，并将内部的另一个内部函数(_wrapper) 作为返回值 通过@装饰器或函数的调用赋值，使用 _wrapper 替换 wrapped，这样对 wrapped 的调用实际是调用的 _wrapped _wrapped 通过函数闭包保留了对 wrapped 函数的引用，这样它就可以在内部调用 wrapped 函数并返回调用结果。 _wrapped 在调用 wrapped 之前或之后可以添加其他处理逻辑，以达到为 wrapped 附加功能的目的。 虽然通常都是适用函数闭包实现装饰器，但是能展示它工作原理的更好的示例是使用一个类实现它: function_wrapper 类通过属性保留对被包装函数的引用 当被包装函数被调用时，包装类的 __call__ 方法被调用，并进而调用原始的被包装函数 __call__ 包含了附加的通用处理逻辑。 12345678class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass 1.2 局限尽管通过闭包实现装饰器很简单，但是这种方式存在很多局限，其中最重要的是打断了 Python 内部的自省，也没有遵循 Python 对象模型的执行方式。 猴子补丁与装饰器十分相似的一个技术是 monkey patching(猴子打补丁)，猴子打补丁会进入并修改其他人的代码。二者不同的是装饰器作用的时间是函数定义完成之后，而猴子补订在函数导入模块时被应用。为了能同时使用函数包装器和猴子补丁，函数包装器必需是透明的，并且内部维护了一个堆，以便多个装饰器，猴子补订能按照预期的顺序执行。 2. 自省丢失当我们讨论函数闭包时，我们会预期函数的自省属性和函数的外在表现相一致。这些包括__name__，__doc__ 属性。但是当使用函数闭包时，原函数的自省属性会被内嵌函数所替代，因为函数闭包返回的是内嵌函数。 1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)_wrapper 当使用类实现闭包时，类实例没有 __name__ 属性，访问此属性时，会导致 AttributeError 异常 1234567891011121314class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function_wrapper' object has no attribute '__name__' 此处的解决方式是，在函数闭包内，将被包装函数的内省属性复制到内嵌函数上。这样函数名称和文档字符串属性就能表现正常 12345678910111213def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) _wrapper.__name__ = wrapped.__name__ _wrapper.__doc__ = wrapped.__doc__ return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 手动复制属性是费劲的，如果未来扩展了其他自省属性，代码需要被更新。例如需要复制 __module__ 属性，在Python3 中需要复制 __qualname__ 和 __annotations__ 属性。为了避免这么做，Python 标准库为我们提供了 functools.wraps() 装饰器，完成自省属性的复制 1234567891011121314import functoolsdef function_wrapper(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 使用类实现装饰器时，我们需要使用 functools.update_wrapper() 函数 12345678import functoolsclass function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 或许你已经认为通过 functolls.wraps 函数我们能确保函数的自省属性是正确的，但事实上它并不能一直有效。假如我们去访问函数的参数信息，返回的将是包装函数的参数信息而不是被包装函数的。即，在使用闭包的方式中，内嵌函数的参数信息被返回。因此包装器没能保留函数签名信息 123456789import inspectdef function_wrapper(wrapped): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))ArgSpec(args=[], varargs='args', keywords='kwargs', defaults=None) 类包装器更加严重，因为会触发异常，并解释称被包装函数不是一个函数。我们完全不能获取函数签名信息，即使被包装函数是可调用的 123456789101112class function_wrapper(object): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))Traceback (most recent call last): File "...", line XXX, in &lt;module&gt; print(inspect.getargspec(function)) File ".../inspect.py", line 813, in getargspec raise TypeError('&#123;!r&#125; is not a Python function'.format(func))TypeError: &lt;__main__.function_wrapper object at 0x107e0ac90&gt; is not a Python function 另外一个自省的示例是使用 inspect.getsource() 获取函数源代码。闭包装饰器返回的是内嵌函数的源代码，而类装饰器则会触发异常 3.描述符协议同函数类似，装饰器也可以应用于类方法。Python 包含了两个特殊的装饰器@classmethod 和 @staticmethod 将实例方法转换为特殊的类方法。装饰器应用于类方法同样隐含着几个问题 12345678910111213class Class(object): @function_wrapper def method(self): pass @classmethod def cmethod(cls): pass @staticmethod def smethod(): pass 第一即使使用了 functools.wraps 或者 functools.update_wrapper，当装饰器被用在 @classmethod，@staticmethod 上时，仍然会导致异常。这是因为这两个特殊的装饰器没能将一些必要的属性复制过来。这是一个Python2 的bug，并在Python3中通过忽略丢失的属性修复了 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): passTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in Class File "&lt;stdin&gt;", line 2, in wrapper File ".../functools.py", line 33, in update_wrapper setattr(wrapper, attr, getattr(wrapped, attr))AttributeError: 'classmethod' object has no attribute '__module__' 即使我们运行在 Python3 上，我们依然会遇到问题。这是因为所有类型的装饰器都假设被包装函数是直接可调用的。事实上并非如此。Python classmethod 装饰器返回一个描述符，这个描述符不是直接可调用的，但是装饰器假设被包装函数直接可调用，因此会出错。 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 4. 总结函数闭包实现的装饰器存在以下问题: 无法保留函数的自省属性 无法获取函数签名信息 无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 使用 functools.wraps() 和 functools.update_wrapper() 能保留常规的自省属性，但依旧无法保留函数签名信息和源代码，而且由于 Python2 的bug，无法将装饰器直接应用于类方法和静态方法(导入时即报错) 确实存在第三方包，尝试解决这些问题，例如PyPi上的decorator模块。这个模块虽然对前两类问题有所帮助，但仍然存在一些潜在的问题，当尝试通过猴子补丁动态应用函数包装时，可能会导致问题 这并不意味着这些问题是不可解决的，而且可以以一种不牺牲性能的方式解决。现在已经说明了要解决的问题，在随后的文章将会解释如何解决这些问题，以及提供哪些额外的功能。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor tornado 部署]]></title>
    <url>%2F2017%2F09%2F21%2Fdeploy%2Fsupervisor_tornado%2F</url>
    <content type="text"><![CDATA[通过 supervisor 创建监听套接字的文件描述符，为多个 tornado 进程共享 1. tornado 启动12345678910111213from tornado.netutil import set_close_execdef main(): app = AnalyticApiApplication() http_serve = httpserver.HTTPServer(app) # http_serve.listen(options.port) # supervisor 创建的监听套接字文件描述符，通过 0 号传递给 tornado的所有进程 sock = socket.fromfd(0, family=socket.AF_INET, type=socket.SOCK_STREAM) set_close_exec(sock.fileno()) sock.setblocking(0) # 设置套接字为非阻塞调用 http_serve.add_socket(sock) ioloop.IOLoop.instance().start() 2. supervisor 配置12345678command=/home/tao/.local/bin/pipenv run python app.py --connect=local-dev --debug=1socket=tcp://localhost:8888directory=/home/tao/projects/analytics_apiuser=taonumprocs=4process_name=%(program_name)s_%(process_num)02dstdout_logfile =/var/log/tornado_pyapi_stdout_%(process_num)02d.log stderr_logfile =/var/log/tornado_pyapi_stderr_%(process_num)02d.log 3. tornado.bind_socket12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False): """Creates listening sockets bound to the given port and address. Returns a list of socket objects (multiple sockets are returned if the given address maps to multiple IP addresses, which is most common for mixed IPv4 and IPv6 use). Address may be either an IP address or hostname. If it's a hostname, the server will listen on all IP addresses associated with the name. Address may be an empty string or None to listen on all available interfaces. Family may be set to either `socket.AF_INET` or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise both will be used if available. The ``backlog`` argument has the same meaning as for `socket.listen() &lt;socket.socket.listen&gt;`. ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``. ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket in the list. If your platform doesn't support this option ValueError will be raised. """ if reuse_port and not hasattr(socket, "SO_REUSEPORT"): raise ValueError("the platform doesn't support SO_REUSEPORT") sockets = [] if address == "": address = None if not socket.has_ipv6 and family == socket.AF_UNSPEC: # Python can be compiled with --disable-ipv6, which causes # operations on AF_INET6 sockets to fail, but does not # automatically exclude those results from getaddrinfo # results. # http://bugs.python.org/issue16208 family = socket.AF_INET if flags is None: flags = socket.AI_PASSIVE bound_port = None for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags)): af, socktype, proto, canonname, sockaddr = res if (sys.platform == 'darwin' and address == 'localhost' and af == socket.AF_INET6 and sockaddr[3] != 0): # Mac OS X includes a link-local address fe80::1%lo0 in the # getaddrinfo results for 'localhost'. However, the firewall # doesn't understand that this is a local address and will # prompt for access (often repeatedly, due to an apparent # bug in its ability to remember granting access to an # application). Skip these addresses. continue try: sock = socket.socket(af, socktype, proto) except socket.error as e: if errno_from_exception(e) == errno.EAFNOSUPPORT: continue raise set_close_exec(sock.fileno()) if os.name != 'nt': sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if reuse_port: sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) if af == socket.AF_INET6: # On linux, ipv6 sockets accept ipv4 too by default, # but this makes it impossible to bind to both # 0.0.0.0 in ipv4 and :: in ipv6. On other systems, # separate sockets *must* be used to listen for both ipv4 # and ipv6. For consistency, always disable ipv4 on our # ipv6 sockets and use a separate ipv4 socket when needed. # # Python 2.x on windows doesn't have IPPROTO_IPV6. if hasattr(socket, "IPPROTO_IPV6"): sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1) # automatic port allocation with port=None # should bind on the same port on IPv4 and IPv6 host, requested_port = sockaddr[:2] if requested_port == 0 and bound_port is not None: sockaddr = tuple([host, bound_port] + list(sockaddr[2:])) sock.setblocking(0) sock.bind(sockaddr) bound_port = sock.getsockname()[1] sock.listen(backlog) sockets.append(sock) return sockets]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>部署工具</tag>
        <tag>supervisor</tag>
        <tag>tornado</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualenv]]></title>
    <url>%2F2017%2F09%2F04%2Fdeploy%2Fvirtualenv%2F</url>
    <content type="text"><![CDATA[virtualenv 基本使用 1. 环境创建virtualenv dirname – 创建虚拟环境source dirname/bin/activate – 启用虚拟环境 virtualenv 可用选项 作用 –distribute dirname 创建新的虚拟环境，并安装 pip –no-site-packages 使系统环境的包对虚拟环境不可见 2.virtualenvwrapper作用：virtualenv 管理工具，方便的创建/激活/管理/销毁虚拟环境 命令 作用 mkvirtualenv virname 新建虚拟环境 workon virname 激活 deactivate 关闭 rmvirtualenv virname 删除]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>部署工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo github blog]]></title>
    <url>%2F2017%2F09%2F03%2Fhexo%2Fhexo-github%2F</url>
    <content type="text"><![CDATA[使用 githup pages 和 hexo搭建 blog，本文不是完整教程，只是整个流程概览和常用命令备忘 1. github blog 搭建 安装node.js node -v 安装 hexo npm install hexo-cli -g 注册 github 帐号 新建xxx.github.io仓库，xxx 为帐号名称 初始化 hexo blog 123hexo init blogcd blognpm install 配置 hexo github 安装 hexo-deployer-gitnpm install hexo-deployer-git --save 在网站的_config.yml中配置deploy 123deploy:type: git repo: &lt;repository url&gt; branch: [branch] 提交git 12hexo d -ghexo d 2. hexo 常用命令 命令 作用 hexo init dir_name 创建博客目录 hexo clean …. hexo g(generate) 生成静态文件 hexo s(server) 启动本地web服务，用于博客的预览 hexo d(deploy) 部署播客到远端 hexo d -g 生成部署 hexo s -g 生成预览 hexo new “name” 新建文章 hexo new page “name” 新建页面 Quick StartHexo HomedocumentationtroubleshootingHexo GitHub. Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
