<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[33 深度和广度优先搜索]]></title>
    <url>%2F2018%2F11%2F16%2Falog%2Fgraph_search%2F</url>
    <content type="text"><![CDATA[图的深度和广度优先搜索 1. 特性上一节我们讲解了图的存储和表示，这一节我们来介绍图上的搜索算法。图的搜索方法有很多，最常见的就是深度和广度优先搜索，除此之外还有 A、IDA 等启发式搜索算法。因为邻接表更加常用，我们就以邻接表作为图的存储方式来讲解最基础的深度和广度优先算法。 1.1 广度优先搜索广度优先搜索（Breadth-First-Search），简称为 BFS，就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。所有的顶点按照从左往右，从上往下的顺序依次迭代。为了保证迭代的次序需要用到队列，整个过程就是从顶点入队开始，将队首元素出队，并将出队顶点的下一层顶点依次入队，迭代直至队列为空的过程。为了防止顶点被重复遍历，需要对已经遍历的顶点进行表识。 1.2 深度优先搜索深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”，每次迭代时任意选择一个分岔的”顶点”进行搜索，直至没有顶点时退回到上一个顶点重新选择新的顶点继续遍历，直到所有顶点都被遍历结束。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[32 图的表示]]></title>
    <url>%2F2018%2F11%2F15%2Falog%2Fgraph%2F</url>
    <content type="text"><![CDATA[如何表示一个图 1. 特性从本节开始，我们将进入图的学习。图是一种比树更复杂的非线性结构，图中有以下一些专用术语: 顶点: 图中的节点被称为顶点 边: 顶点之间存在链接关系，可以有方向，也可以有权重 有向图: 边有方向的图 带权图: 边存在权重的图 度: 顶点包含的边数，在有向图中，度分为出度和入度 很显然在表示和存储一个图时，我们需要保存图的顶点，边，以及边的方向和权重。而图的存储有两个常见方法: 邻接矩阵和邻接表 1.1 邻接矩阵邻接矩阵的底层是一个二维数组，A[i][j] 表示从节点 i 指向节点 j 的一条边，A[i][j]元素的值表示是否存在这条边或者在带权图中表示边的权重。 邻接矩阵的存储方式简单、直接，基于数组，在获取两个顶点的关系时，非常高效；可以将很多图的运算转换成矩阵之间的运算，计算方便。但是最大的缺点是浪费空间，在无向图中，有一半的空间是浪费的。如果我们存储的是稀疏图,也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵就更加浪费空间。通常我们遇到的都是稀疏图，所以邻接矩阵的存储方法并不常用。 1.2 邻接表 如上图，在邻接表中每个顶点对应一条链表，链表中存储的是与此顶点直接先连的其他顶点。与邻接矩阵相比，邻接表更加节省空间，但是使用起来就比较耗时，如果我们想确定是否存在从 i 指向 j 的边，我们必需遍历顶点 i 上的整个链表。 为了提高查找效率，我们可以将邻接表中的链表改成红黑树、跳表、散列表，甚至将链表改成有序动态数组，通过二分查找的方法来快速定位两个顶点之间否是存在边。至于如何选择，还需要看具体的业务场景。 1.3 应用示例我们以微博的用户关系为例，假设我们需要支持下面这样几个操作： 判断用户 A 是否关注了用户 B； 判断用户 A 是否是用户 B 的粉丝； 根据用户名称的首字母排序，分页获取用户的粉丝列表； 根据用户名称的首字母排序，分页获取用户的关注列表。 社交网络是一张稀疏图，更适合使用邻接表来存储。不过，此处我们需要两个图: 邻接表和逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系，分别用于关注和粉丝两种关系的判断。因为我们有排序需求，而跳表存储的数据本身就是有序的，所以我们选择用跳表来替代链表。 但是对于拥有亿级别用户的微博，显然我们没法将图存在一台机器的内存上。我们可以通过哈希算法等数据分片方式，通过对顶点的哈希然后分片，将邻接表存储在不同的机器上。当要查询顶点与顶点关系的时候，我们就利用同样的哈希算法，先定位顶点所在的机器，然后再在相应的机器上查找。 此外借助于 mysql 这样的外部存储，我们可以将 (user_id, follower_id) 这样的关注关系存储在 mysql 中。相比于图这可能是更好的解决方案。 2. 实现]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[31 动态规划]]></title>
    <url>%2F2018%2F11%2F10%2Falog%2Fdp%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29 分治算法]]></title>
    <url>%2F2018%2F11%2F05%2Falog%2Fdivide%2F</url>
    <content type="text"><![CDATA[编程思想之分治算法]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30 回溯算法]]></title>
    <url>%2F2018%2F11%2F05%2Falog%2Fbacktracking%2F</url>
    <content type="text"><![CDATA[编程思想之回溯算法]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28 贪心算法]]></title>
    <url>%2F2018%2F11%2F04%2Falog%2Fgreedy%2F</url>
    <content type="text"><![CDATA[编程思想之贪心算法]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27 AC 自动机]]></title>
    <url>%2F2018%2F11%2F03%2Falog%2Fac%2F</url>
    <content type="text"><![CDATA[敏感词过滤]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26 Trie 树]]></title>
    <url>%2F2018%2F11%2F02%2Falog%2Ftrie%2F</url>
    <content type="text"><![CDATA[一组字符串的快速匹配]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25 字符串匹配之 BM 算法]]></title>
    <url>%2F2018%2F11%2F01%2Falog%2Fstr_match2%2F</url>
    <content type="text"><![CDATA[最优匹配的 BM 算法 1. BM 算法本节我们继续介绍另一个高效的字符串匹配算法 BM(Boyer-Moore)。BM 与 KMP 优化思路类似，都是希望尽可能增加发生不匹配时，模式串后移的位数来提高字符串的匹配效率。BM 要想达到更高的匹配效率，必需利用更多的已知信息。 这里依旧推荐阮一峰老师有关 BM算法的博客。因为阮一峰老师讲的已经不能在通俗易懂，这里我就简单总结一下 BM 算法所使用的匹配规则。示例采用博客中的示例，即在”HERE IS A SIMPLE EXAMPLE”，中搜索 “EXAMPLE”。 1.1 坏字符规则 开始匹配时，主串与模式串头部对齐，从尾部开始比较。此时”S”与”E”不匹配。我们称”S”为”坏字符”（bad character），即不匹配的字符。 利用坏字符以及坏字符是否出现在模式串中，BR 算法使用的第一个移位规则被称为坏字符规则: 后移位数 = 坏字符的位置 - 搜索词中的上一次出现位置。如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。道理很显而易见，如果出现坏字符，我们就直接把模式串移动到能跟坏字符匹配的位置上来。 示例中”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位 1.2 好后缀规则借鉴 KMP 算法，利用已经匹配的字符串和已匹配部分是否出现在模式串中，BR 算法使用的第二个移位规则被称为 好后缀规则:后移位数 = 好后缀的位置 - 搜索词中的上一次出现位置 “好后缀”的位置以最后一个字符为准。假定”ABCDEF”的”EF”是好后缀，则它的位置以”F”为准，即5（从0开始计算）。 如果”好后缀”在搜索词中只出现一次，则它的上一次出现位置为 -1。比如，”EF”在”ABCDEF”之中只出现一次，则它的上一次出现位置为-1（即未出现）。 如果”好后缀”有多个，则除了最长的那个”好后缀”，其他”好后缀”的上一次出现位置必须在头部。比如，假定”BABCDAB”的”好后缀”是”DAB”、”AB”、”B”，请问这时”好后缀”的上一次出现位置是什么？回答是，此时采用的好后缀是”B”，它的上一次出现位置是头部，即第0位 道理也很显而易见，如果已经匹配的部分多次出现在模式串，当发生不匹配时，就直接把模式串移动到上一次匹配的位置上。显然 BM 与KMP 不同，BM 不要求后缀匹配的部分必需是模式串的前缀。 “MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。此时，所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”还出现在头部，所以后移 6 - 0 = 6位。 1.3 移位选择Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。更巧妙的是，这两个规则的移动位数，只与模式串有关，与主串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。 2. 实现显然 BR 算法的核心是要先生成《坏字符规则表》和《好后缀规则表》，然后利用这两个规则表进行字符串匹配。 2.1 坏字符规则表2.2 好后缀规则表2.3 字符串匹配参考: 王争老师专栏-数据结构与算法之美 阮一峰-Boyer-Moore算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24 字符串匹配之 KMP 算法]]></title>
    <url>%2F2018%2F10%2F31%2Falog%2Fstr_match3%2F</url>
    <content type="text"><![CDATA[优雅的的 KMP 算法 1. KMP 算法BM（Boyer-Moore）和 KMP(Knuth-Morris-Pratt) 都是非常高效的字符串匹配算法。BM 比 KMP 更高效，有实验统计 BM 的性能 是 KMP 3-4 倍。但是他们都非常复杂难懂。除了专栏，我也非常推荐你看一看阮一峰老师有关 BM 和 KMP 算法的介绍。因为 BM 算法利用到了KMP的算法思想，本节我们就先来介绍 KMP 的实现。 1.1 优化思路KMP 算法基于这样一个实现思路: 如下图所示，对于字符串匹配过程中已经匹配的部分，我们是已知的；利用这个已知的信息，我们可以把模式串往后移动更多位，而不是 BR 算法中的一位。而最终移动的位数取决于已匹配部分的&quot;前缀&quot;和&quot;后缀&quot;的最长的共有元素的长度，我们将这个最长的公共子串称为最长可匹配(前缀/后缀)子串 在上面的图例中，已匹配部分是 ABCDAB，前后缀最长匹配的元素是 AB，因此前缀 AB就可以直接来到后缀AB的位置，直接向后移动 4 位继续匹配，如下图所示。 字符串已匹配部分永远是模式串的前缀子串，因此最长可匹配(前缀/后缀)子串我们可以提前计算出来，这个就是 KMP 中的 部分匹配表。因此，整个 KMP 的计算过程就分成了两步: 计算部分匹配表 根据部分匹配表计算每次不匹配时，模式串的移动位数，进行字符串匹配 1.2 部分匹配表部分匹配表，被称为失效函数，又称为 next 数组。在计算 next 数组之前，首先我们需要明确两个概念: “前缀”和”后缀”: “前缀”指除了最后一个字符以外，一个字符串的全部头部组合 “后缀”指除了第一个字符以外，一个字符串的全部尾部组合 12345678以&quot;ABCDAB&quot;为例0. &quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0；1. &quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0；2. &quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0；3. &quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0；4. &quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1；5. &quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2；6. &quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。 即”ABCDAB” 的 next 数组为 [0, 0, 0, 0, 1, 2, 0]。其中 next 数组的下标对应每个前缀子串结尾字符的下标 next 数组的值则是最长可匹配子串的长度 1.3 KMP 复杂度分析KMP 的空间复杂度是 O(m)，时间复杂度为 O(m+n)。分析过程在我们讲解完 KMP 的实现之后再来讲解。 2. KMP 算法实现2.1 计算部分匹配表部分匹配表的计算非常巧妙，下面是代码： 123456789101112131415def kmp_next(P): m = len(P) fail = [0] * m j = 1 # 按照下标从小到大的子串 k = 0 # 上一个子串最长可匹配子串的长度 while j &lt; m: if P[j] == P[k]: fail[j] = k + 1 j += 1 k += 1 elif k &gt; 0: k = fail[k - 1] else: j += 1 return fail 我们以”ABCDAB”为例来讲解计算过程，大家需要牢记的是P[j] 表示当前子串的最后一个字符，P[k] 表示上一个子串的最长可匹配子串的下一个字符，此时分为三种情况: P[j] == P[k]: 对应ABCDAB，前一个子串是ABCDA，最长可匹配子串是 A，此时P[5]==P[1]==B，即AB=AB,所以 ABCDAB的最长可匹配子串长度就是 2 P[j] != P[k] and k &gt; 0: 对应ABCDABD，P[6]!=P[2]，即D!=C，此时可以确定的是ABCDABD的最长可匹配子串，只能从ABD进行匹配，进而问题转换为已知AB的最长可匹配子串，求ABD的最长可匹配子串问题。 P[j] != P[k] and k == 0: 显然此时就没有任何可匹配到的子串。 这个计算过程很巧妙，不多看几次很难明白。 在next 的计算过程中，使用了一个额外的数组，因此这一部份的空间复杂度是 O(m)。在 while 循环中 j 执行的次数一定不会超过 m，而 k 变量无论是增加累计的量，还是减少累计的量都不会超过 m，因此这一部分的时间复杂度为 O(m)。 2.2 KMP 字符串匹配过程字符串匹配的过程中，最重要的一步是确定不匹配时，后移的位数，代码如下: 12345678910111213141516def kmp_match(T, P): fail = kmp_next(P) n, m = len(T), len(P) k = 0 j = 0 while j &lt; n: if T[j] == P[k]: if k == m - 1: return j - (m - 1) k += 1 j += 1 elif k &gt; 0: k = fail[k - 1] # 后移表示为 k 索引的变化 else: j += 1 return -1 整个匹配过程中，j 变量的执行次数不会超过 n，而变量 k，无论是增加的累计量还是减少的累计量都不会超过 n，因此这一部分的时间复杂度不会超过 O(n)。因此总的时间复杂度不会超过O(m+n)。 参考: 王争老师专栏-数据结构与算法之美 阮一峰-KMP算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23 字符串匹配之 BF & RK 算法]]></title>
    <url>%2F2018%2F10%2F30%2Falog%2Fstr_match1%2F</url>
    <content type="text"><![CDATA[粗暴匹配的 BF 与 RK 算法 1. 特性从本节开始我们将学习字符串匹配算法。字符串匹配算法有很多，大体可以分成两类: 单模式串匹配算法: 一个串跟一个串进行匹配，包括BF，RK，KMP，BM 算法 多字符串匹配算法: 一个串中同时查找多个串，包括 Trie 树和 AC 自动机 本节我们先来学习“最简单粗暴的” BF 和 RK 算法。为了便于描述，对于在字符串A中查找 B，我们将 A 称为主串，B 称为模式串，n=len(A), m=len(B)。 1.1 BF 算法BF(Brute Force) 暴力匹配算法，采用的就是我们最容易理解的穷举法。从主串的第一位开始检查主串中所有长度为 m 的子串看是否与模式串相等。主串中有(n-m+1)个长度为 m 的子串，因此总共需要比较(n-m+1)*m次 BF 算法的时间复杂度很高，为 O(m*n)，但却是一个比较常用的字符串匹配算法，而原因有两个: 大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。 算法简单，实现起来不容易出错 1.2 RK 算法RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。RK 算法可以理解为引入了哈希算法的 BF。 RK 算法希望通过计算字符串的哈希值，并通过比较哈希值，而不是比较字符串，来缩小BF算法中主串的子串与模式串的比较时间。要想达到优化的目的，我们必需使得(字符串哈希+哈希值比较的时间) &lt; (m 次字符比较的时间)。因为哈希值是整数，单次整数的比较时间可以忽略不计。但是字符串哈希值的计算也需要遍历每个字符，因此想要优化，必需精心设计此处的哈希函数。 为了减少字串哈希值的计算量，在计算第 i 个字串的哈希值时，需要能用到已经计算的第 i-1 个字串的哈希值，并且平衡好计算过程中空间占用和哈希冲突的概率。因为 RK 算法并不常用，所以这里我不再过多讲述，有兴趣的同学可以自己查看专栏的介绍。 RK 算法的时间复杂度取决于哈希函数，理想情况下，RK 算法的时间复杂度是 O(n)，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，时间复杂度就退化为 O(n*m)。 2. 实现2.1 BF 算法123456789101112131415def find_brute(T, P): """ :param T: 主串 :param P: 模式串 :return: """ n, m = len(T), len(P) for i in range(n - m + 1): j = 0 while j &lt; m and T[i + j] == P[j]: j += 1 if j == m: return i return -1 3. 应用今天讲的一维字符串匹配可以应用到二维空间中。即如下图所示，在一个二维主串中搜索另一个二维模式串。 下面是代码实现:1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22 堆的应用]]></title>
    <url>%2F2018%2F10%2F29%2Falog%2Fheap_use%2F</url>
    <content type="text"><![CDATA[动态 topK 1. 堆的应用2. 实现2.1 合并小文件2.2 高性能定时器2.3 动态 topK2.4 动态求中位数参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 堆]]></title>
    <url>%2F2018%2F10%2F28%2Falog%2Fheap%2F</url>
    <content type="text"><![CDATA[能找到”最好学生”的堆 1. 特性堆是一种特殊的二叉树，它满足如下两个属性: 堆是一完全二叉树 堆中每个节点的值都必需大于等于(或小于等于)其子树中每个节点的值，下称为 Heap-Order 完全二叉树被定义为除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。所以完全二叉树具有如下一些特性: 非常适合使用数组进行存储，不会出现空间浪费 如果下标从 1 开始，下标为 i 的节点的左右子节点的下标是 2*i，2*i+1； 对于一个有 n 个元素的完全二叉树，树的高度为 logn 为了维护堆的Heap-Order，当我们更改堆中的元素时，我们需要在堆中上下交换堆的元素，额外交换的次数不会超过树的高度即 logn，所以堆的更新操作的时间复杂度为 O(logn)。 1.1 支持的操作堆支持以下一些常用操作: 添加一个元素: 将元素添加到数组的末尾，并对其从下往上的堆化，时间复杂度为 logn 删除堆顶元素: 删除堆顶元素，并用数组末尾元素填充堆顶，对新的堆顶元素从上往下的堆化，时间复杂度为 logn 构建堆: 自底向上的构建堆，时间复杂度为O(n) 堆排序: 包括建堆和排序，排序的时间复杂度为O(nlogn) 1.2 堆排序与快速排序堆排序与快速排序都是原地排序算法，排序的平均时间复杂度都是O(nlogn)，甚至堆排序比快排更加稳定。但是快排的性能还是比堆排序要好，原因有两个: 堆排序数据访问的方式没有快排友好。快排中数据是顺序访问的，但是堆排序是按照指数跳越访问的，对 CPU 缓存不友好 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。 2. 实现2.1 小堆的实现我们选择小堆作为堆实现的示例，大堆的实现类似。对于堆而言最核心的就是从下往上和从上往下的堆化操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132class PriorityQueueBase(object): class _Item(object): __slots__ = '_key', '_value' def __init__(self, key, value): self._key = key self._value = value def __gt__(self, other): return self._key &gt; other._key def __lt__(self, other): return self._key &lt; other._key def __eq__(self, other): return self._key == other._keyclass HeapPriorityQueue(PriorityQueueBase): def __init__(self, content=()): """ :return: 构建堆 """ self._data = [self._Item(k,v) for k, v in content] if self._data: self._heap() def _heap(self): """ """ i = self._parent(len(self._data) - 1) while i &gt;= 0: self._downheap(i) i -= 1 def _parent(self, i): """ :param i: :return: 父节点索引 """ return (i - 1) // 2 def _left(self, i): """ :param i: :return: 左子节点索引 """ return i * 2 + 1 def _right(self, i): """ :param i: :return: 右子节点索引 """ return i * 2 + 2 def has_left(self, i): return self._left(i) &lt; len(self._data) def has_right(self, i): return self._right(i) &lt; len(self._data) def _swap(self, i, j): """ :return: 数据交换 """ self._data[i], self._data[i] = self._data[j], self._data[i] def _upheap(self, i): """ :param i: :return: 从下往上堆化 """ parent = self._parent(i) while self._data[parent] &gt; self._data[i] and i &gt; 0: self._swap(parent, i) i = parent parent = self._parent(parent) def _downheap(self, i): """ :param i: :return: 从上往下堆化 """ while self.has_left(i): small_child = self._left(i) if self.has_right(i): right = self._right(i) if self._data[small_child] &gt; self._data[right]: small_child = right if self._data[i] &gt; self._data[small_child]: self._swap(i, small_child) i = small_child else: break def __len__(self): return len(self._data) def is_empty(self): return len(self) == 0 def add(self, key, value): """ :param key: :param value: :return: 向堆中添加元素 """ self._data.append(self._Item(key, value)) self._upheap(len(self._data) - 1) def min(self): """ :return: 获取堆顶元素，但不删除 """ if not self.is_empty(): item = self._data[0] return item._key, item._value raise ValueError('Priority Queue is empty') def remove_min(self): """ :return: 获取并删除堆顶元素 """ if self.is_empty(): ValueError('Priority Queue is empty') item = self._data[0] self._data[0] = self._data.pop() self._downheap(0) return item._key, item._value 2.2 堆的原排序堆的原排序排序包括两个过程: 建堆+排序。建堆就是上面 _heap 方法展示的过程，通过由底向上构建堆，我们可以在 O(n) 的时间复杂度内实现堆构建。 排序时，我们将堆顶元素与数组最后的元素交换，然后对前 n-1 个元素组成的堆堆化，然后再将堆顶元素与数组倒数第二个元素交换，以此类推，当堆中只剩下一个元素时排序即完成。 很可惜的是，我们上面的小堆实现无法实现堆的原地排序，因为我们无法控制堆中的元素个数，以达到缩减堆范围的目的。但是实现起来也很简单，通过添加额外的可控的计数器作为堆元素个数的记录，而不是直接使用 len(self._data) 我们就可以很容易实现。 2.2 可删除和修改任意位置的堆最后我们介绍一种可更新和删除任意位置的堆。我们使用一个叫作定位器 Locator 对象作为堆中的元素，Locator记录了元素在堆中数组的索引，在执行更新和删除操作时，将Locator作为参数传递给函数，就可以直接定位元素位置，并对其执行更新操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class AdaptHeapPriorityQueue(HeapPriorityQueue): class Locator(HeapPriorityQueue._Item): __slots__ = '_index' def __init__(self, key, value, index): super(AdaptHeapPriorityQueue.Locator, self).__init__(key, value) self._index = index def __init__(self): super(AdaptHeapPriorityQueue, self).__init__() def add(self, key, value): token = self.Locator(key, value, len(self._data)) self._data.append(token) self._upheap(len(self._data) - 1) return token def _swap(self, i, j): super(AdaptHeapPriorityQueue, self)._swap(i, j) self._data[i]._index = i self._data[j]._index = j def _bubble(self, j): if j &gt; 0 and self._data[j] &lt; self._data[self._parent(j)]: self._upheap(j) else: self._downheap(j) def update(self, loc, key, value): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') loc._key = key loc._value = value self._bubble(j) def remove(self, loc): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') if j == len(self) - 1: self._data.pop() else: self._data[j] = self._data.pop() self._bubble(j) return loc._key, loc._value 3 算法堆有众多应用，限于篇幅，我们在接下来的一节来专门讲解。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20 递归树]]></title>
    <url>%2F2018%2F10%2F27%2Falog%2Frecursion_tree%2F</url>
    <content type="text"><![CDATA[利用树计算递归函数的时间复杂度 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19 红黑二叉树]]></title>
    <url>%2F2018%2F10%2F26%2Falog%2Fred_black_tree%2F</url>
    <content type="text"><![CDATA[搞不懂的”红黑数”…. 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18 二叉查找树与完全二叉树]]></title>
    <url>%2F2018%2F10%2F25%2Falog%2Fbinary_tree%2F</url>
    <content type="text"><![CDATA[有散列表了，为什么还要”一颗树” 1. 特性2. 实现2.1 二叉搜索树我们实现的二叉搜索树将支持: 标准映射操作: __setitem__ __getitem__ __delitem__ 有序映射操作: find_lt find_range 基于位置操作 after(p) before(p) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244from collections import MutableMappingfrom linked_tree import LinkedBinaryTreeclass MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._keyclass TreeMap(LinkedBinaryTree, MapBase): class Position(LinkedBinaryTree.Position): def key(self): return self.element()._key def value(self): return self.element()._value def _subtree_search(self, p, k): """ :param p: :param k: :return: 在子树中搜索值为 k 的节点，未搜索到返回最后搜索路经的最终位置 """ p_value = p.key() if p_value == k: return p elif p_value &gt; k: if self.left(p): return self._subtree_search(self.left(p), k) else: if self.right(p): return self._subtree_search(self.right(p), k) return p def _subtree_first_position(self, p): """ :return: 返回子树迭代时，第一个位置节点 """ walk = p while self.left(walk): walk = self.left(walk) return walk def _subtree_last_position(self, p): """ :param p: :return: 返回子树迭代时，最后一个位置节点 """ walk = p while self.right(walk): walk = self.right(walk) return walk ################# 引导方法 ####################### def first(self): """ :return: 返回树迭代序列的第一个节点 """ return self._subtree_first_position(self.root()) if len(self) &gt; 0 else None def last(self): """ :return: 返回树迭代序列的最后一个节点 """ return self._subtree_last_position(self.root()) if len(self) &gt; 0 else None def before(self, p): """ :param p: :return: 返回迭代序列中位于 p 之前的，最大节点 """ self._validate(p) if self.left(p): return self._subtree_last_position(self.left(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.left(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def after(self, p): """ :param p: :return: 返回迭代序列中位于 p 之后的，最小节点 """ self._validate(p) if self.right(p): self._subtree_first_position(self.right(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.right(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def find_position(self, k): """ :param k: :return: 查找值等于 k 的位置节点 """ if self.is_empty(): return None else: p = self._subtree_search(self.root(), k) # avl 平衡树的钩子函数 self._rebalance_access(p) return p ####################### 有序映射 ###################### def find_min(self): """ :return: 查找树中的最小值 """ if self.is_empty(): return None else: p = self.first() return p.key(), p.value() def find_ge(self, k): """ :param k: :return: 查找大于等于 k 的最小节点 """ p = self.find_position(k) if p and p.key() &lt; k: p = self.after(p) return p.key(), p.value() if p else None, None def find_range(self, start, stop): """ :param start: :param stop: :return: 查找值位于 start &lt;= k &lt; stop 的节点 """ if not self.is_empty(): if start is None: p = self.first() else: p = self.find_position(start) if p and p.key() &lt; start: p = self.after(p) while p and (stop is None or p.key() &lt; stop): yield p.key(), p.value() p = self.after(p) ########################### 增删改查节点操作 ################ def __getitem__(self, item): """ :param item: :return: 查找 item 映射的值 """ if not self.is_empty(): p = self.find_position(item) self._rebalance_access(p) if p.key() == item: return p.value() raise KeyError('Key Error:' + repr(item)) def __setitem__(self, key, value): """ :param key: :param value: :return: 设置键 key 的值为 value """ if self.is_empty(): leaf = self._add_root(self._Item(key, value)) else: p = self.find_position(key) if p.key() == key: p.element()._value = value self._rebalance_access(p) return else: item = self._Item(key, value) if p.key() &lt; key: leaf = self._add_right(p, item) else: leaf = self._add_left(p, item) self._rebalance_insert(leaf) def __iter__(self): """ :return: 产生键的一个迭代 """ p = self.first() while p: yield p.key() p = self.after(p) def delete(self, p): """ :param p: :return: 删除位置节点 p """ self._validate(p) if self.left(p) and self.right(p): r = self._subtree_last_position(self.left(p)) self._replace(p, r.element()) p = r parent = self.parent(p) self._delete(p) self._rebalance_delete(parent) def __delitem__(self, key): """ :param key: :return: 删除键 key """ if not self.is_empty(): p = self._subtree_search(self.root(), key) if p.key() == key: self.delete(p) return self._rebalance_access(p) raise KeyError('Key Error: ' + repr(key)) ################### 平衡二叉树的钩子函数 ############### def _rebalance_delete(self, p): pass def _rebalance_insert(self, p): pass def _rebalance_access(self, p): pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17 树的存储与遍历]]></title>
    <url>%2F2018%2F10%2F24%2Falog%2Ftree_base%2F</url>
    <content type="text"><![CDATA[如何表示和存储一颗树？ 1. 特性树是我们接触的第一种非线性结构，在树中一个”父”元素可以有一个或多个”子”元素，这种组织关系要比一个序列中两个元素之间简单的”前”,”后”关系更加复杂。 最常用的树是二叉树，即一个父节点最多只有两个子节点，在二叉树的基础上如果我们按照特定的数据分布在树的各个节点组织数据，我们就可以得到诸如二叉搜索树，堆，红黑二叉树等多种具有特定用途的数据结构。 下面就是从树到二叉树的抽象层次结构，本节我们就来介绍如何存储和实现一个树。 123 Tree(树) BinaryTree(二叉树) LinkedTreeArrayBinaryTree LinkedBinaryTree 我们将 Tree，BinaryTree 实现为抽象基类，来定义和抽象普通树和二叉树可执行操作，并以二叉树的链式存储为例来实现一颗二叉树。我们会在堆章节中实现一个基于数组的二叉树。一颗普通的链式存储与基于数组的存储与二叉树类似，我们会简单阐述它们的实现方式。 2. 实现2.1 TreeTree 被实现为 Python 抽象基类，我们使用一种叫作 Position 的位置对象作为对树节点访问的代理。通过 Position 对象提供的辅助功能，我们可以验证待操作节点是否属于被操作的树，并抽象树的节点所表达的”父子”，以及迭代过程中的前后关系。 一个普通树能执行的操作有限，通过包括以下几种: 获取和判断树的根节点 获取节点的子节点树，并借此判断节点是否为叶子节点 获取节点的父节点和所有子节点 获取树的所有节点 获取树中节点个数，判断树是否未空 获取树或节点的高度和深度 树的前序遍历和后序遍历 需要注意的是中序是二叉树特有的遍历方式，一颗普通的树没有中序遍历。下面是一个普通树的抽象实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import abcclass Tree(object): __metaclass__ = abc.ABCMeta class Position(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def element(self): """ :return: 返回存储在 p 中的元素值 """ @abc.abstractmethod def __eq__(self, other): pass @abc.abstractmethod def __ne__(self, other): return not self == other @abc.abstractmethod def root(self): """ :return: 返回树的根节点 """ pass @abc.abstractmethod def parent(self, p): """ :param p: :return: 返回 p 节点的父节点 """ pass @abc.abstractmethod def children(self, p): """ :param p: :return: 返回 p 节点孩子的迭代 """ @abc.abstractmethod def num_children(self, p): """ :param p: :return: 返回节点 p 孩子的个数 """ pass @abc.abstractmethod def __len__(self): pass def is_root(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是根节点 """ return self.root() == p def is_leaf(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是叶子节点 """ return self.num_children(p) == 0 def is_empty(self): """ :return: 判断树是否为空 """ return len(self) == 0 def depth(self, p): """ :param p: :return: 返回 p 节点的深度 """ if self.is_root(p): return 0 else: return 1 + self.depth(self.parent(p)) def height(self, p=None): """ :return: 返回树的高度 """ p = p or self.root() return self._height(p) def _height(self, p): if self.is_leaf(p): return 0 else: return 1 + max(self._height(c) for c in self.children(p)) 2.2 BinaryTree相对于普通树，二叉树是具有如下属性的树: 每个节点至多两个节点 每个节点被命名为左右子节点 在顺序上，同一个节点左孩子优于右孩子 因此二叉树与普通的树相比多了如下3个操作: 获取节点的左右孩子 获取节点的兄弟节点 需要注意的是虽然封装原则表名类的外部行为不需要依赖类的内部实现，而操作的效率却极大的依赖实现方式，所以我们更倾向于在 Tree 类的每个更具体的子类中提供合适的更新操作。因此我们不会在基类中限制树的更新操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class BinaryTree(Tree): __metaclass__ = abc.ABCMeta @abc.abstractmethod def left(self, p): """ :param p: :return: 返回节点的左孩子 """ pass @abc.abstractmethod def right(self, p): """ :param p: :return: 返回节点的右孩子 """ pass def slide(self, p): """ :param p: :return: 返回节点的兄弟节点 """ parent = self.parent(p) if parent is not None: left = self.left(parent) right = self.right(parent) if left == p: return right else: return left def children(self, p): """ :param p: :return: 返回节点的所有子节点 """ left = self.left(p) if p is not None: yield left right = self.right(p) if right is not None: yield right 2.3 LinkedBinaryTreeLinkedBinaryTree 是我们第一个具体实现的链式二叉树。除了必需实现的抽象方法，更新操作外，我们还提供了树的四中遍历方式，用来迭代树中的元素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235from collections import dequefrom tree import BinaryTreeclass LinkedBinaryTree(BinaryTree): class _Node(object): __slots__ = "element", "parent", "left", "right" def __init__(self, element, parent=None, left=None, right=None): self.element = element self.parent = parent self.left = left self.right = right class Position(BinaryTree.Position): def __init__(self, container, node): self._node = node self._container = container def element(self): return self._node.element def __eq__(self, other): return type(other) is type(self) and self._node is other._node def _make_position(self, node): if node is not None: return self.Position(self, node) def _validate(self, p): if not isinstance(p, self.Position): raise TypeError('p must be proer Position type') if p._container is not self: raise ValueError('p not belong to this container') if p._node.parent is p._node: raise ValueError('p will no longer valid') return p._node def __init__(self): self._root = None self._size = 0 def __len__(self): return self._size def root(self): return self._make_position(self._root) def parent(self, p): node = self._validate(p) return self._make_position(node.parent) def left(self, p): node = self._validate(p) return self._make_position(node.left) def right(self, p): node = self._validate(p) return self._make_position(node.right) def num_children(self, p): node = self._validate(p) count = 0 if node.left is not None: count += 1 if node.left is not None: count += 1 return count def _add_root(self, e): """ :param e: :return: 向树添加根节点 """ if self._root is not None: raise ValueError('Root exists') self._root = self._Node(e) self._size += 1 return self._make_position(self._root) def _add_left(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.left is not None: raise ValueError('Left child exists') self._size += 1 left_node = self._Node(e, node) node.left = left_node return self._make_position(left_node) def _add_right(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.right is not None: raise ValueError('right child exists') self._size += 1 right_node = self._Node(e, node) node.right = right_node return self._make_position(right_node) def _replace(self, p, e): """ :param p: :param e: :return: 替换节点的元素值 """ node = self._validate(p) old = node.element node.element = e return old def _delete(self, p): """ :param p: :return: 删除节点， 不能通过移动元素值来删除元素，因为 Position 内部是通过 Node 判断是否相等的 """ node = self._validate(p) if node.left and node.right: raise ValueError('p must leaf') child = node.left if node.left else node.right if child is not None: child.parent = node.parent if node is self._root: self._root = child else: if node is node.parent.left: node.parent.left = child else: node.parent.right = child node.parent = node self._size -= 1 return node.element def attach(self, p, t1, t2): """ :param p: :param t1: :param t2: :return: 在叶子节点附加左右子树 """ node = self._validate(p) if not type(self) is type(t1) is type(t2): raise TypeError() if not self.is_leaf(p): raise ValueError('p must leaf') self._size += len(t1) + len(t2) if not t1.is_empty(): node.left = t1._root t1._root.parent = node t1._size = 0 t1._root = None if not t2.is_empty(): node.right = t2._root t2._root.parent = node t2._size = 0 t2._root = None def positions(self): """ :return: 返回树所有位置的一个迭代 """ return self.preorder() def __iter__(self): for p in self.positions(): yield p.element() def preorder(self): """ :return: 树的前序遍历 """ if not self.is_empty(): for p in self._subtree_preorder(self.root()): yield p def _subtree_preorder(self, p): yield p for i in self.children(p): for other in self._subtree_preorder(i): yield other def postorder(self): """ :return: 后序遍历 """ if not self.is_empty(): for p in self._subtree_postorder(self.root()): yield p def _subtree_postorder(self, p): for i in self.children(p): for other in self._subtree_preorder(i): yield other yield p def breadthfirst(self): """ :return: 广度优先遍历 """ if not self.is_empty(): queue = deque() queue.append(self.root()) while len(queue) &gt; 0: p = queue.popleft() for c in self.children(p): queue.append(c) yield p def inorder(self): """ :return: 中序遍历 """ if not self.is_empty(): return self._subtree_inorder(self.root()) def _subtree_inorder(self, p): left = self.left(p) if left is not None: for other in self._subtree_inorder(left): yield other yield p right = self.right(p) if right is not None: for other in self._subtree_inorder(right): yield other 3.相关算法不考虑特殊的树，仅仅是普通的二叉树就有很多应用，比如计算目录的容量，表达式树。与树相关的递归也是经常考的算法题。但是考虑篇幅的原因，我会在讲解完所有的树之后，用几篇单独的文章来说明与树相关的算法。 3.1 表达式树作为二叉树的第一个例子，我们将使用二叉树来表示算数表达式的结构。我们将定义一个 BinaryTree 的子类 ExpressionTree，在其内部的每个节点必需存储一个操作符，每个叶子节点则必需存储一个数字。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677from expression import infix_to_postfixfrom linked_tree import LinkedBinaryTreeclass ExpressionTree(LinkedBinaryTree): def __init__(self, token, left=None, right=None): super(ExpressionTree, self).__init__() if not isinstance(token, (str, unicode)): raise TypeError('Token must be a string') self._add_root(token) if left or right: if token not in '+-*/': raise ValueError('token must be in +-*/') self.attach(self.root(), left, right) def __str__(self): result = [] if not self.is_empty(): self._parenthesize_recur(self.root(), result) return ''.join(result) def _parenthesize_recur(self, p, result): if self.is_leaf(p): result.append(p.element()) else: result.append('(') self._parenthesize_recur(self.left(p), result) result.append(p.element()) self._parenthesize_recur(self.right(p), result) result.append(')') def evaluate(self): """ :return: 计算表达式树的值 """ return self._evaluate_cur(self.root()) def _evaluate_cur(self, p): if self.is_leaf(p): return float(p.element()) else: left = self._evaluate_cur(self.left(p)) op = p.element() right = self._evaluate_cur(self.right(p)) if op == '+': return left + right elif op == '-': return left - right elif op == '/': return left / right else: return left * right @staticmethod def build_expression_tree(expression): """ :param expression: 表达式默认以空格分隔 :return: 构建表达式树 """ stack = [] postfix = infix_to_postfix(expression) for i in postfix: if i not in '+-*/': stack.append(ExpressionTree(i)) else: right = stack.pop() left = stack.pop() stack.append(ExpressionTree(i, left, right)) t = stack.pop() return tif __name__ == '__main__': expression = '10 / 5 + 1 + ( 100 / 10 )' t = ExpressionTree.build_expression_tree(expression) print t print t.evaluate() 在原书 《数据结构与算法：python语言实现》 中，通过 build_expression_tree 方法构建表达式树时，要求传入的表达式必需是完全括号，即形如 2 * 6 + 2 的表达式必需写成(2 * 6) + 2 才能正确执行。对于一般的算数表达式必需先借助栈，将中缀表达式转换为后缀表达式才能正确构建表达式树，整个过程类似于栈中表达式的求值过程。 3.2 树遍历的应用树的遍历有很多应用，但是这些应用都有一个共通的特点，即他们都是在树的遍历过程的前后附加一些特殊操作。利用面向对象编程中的模板方法模式，我们可以将树的遍历过程定义为一个通用的计算机制，并在迭代的过程中定义好钩子函数。所有类似的应用都可以通过继承并自定义钩子函数的方式快速实现。 对于树的遍历而言，通常有四个变量是我们会利用的信息，我们需要在遍历的前后将它们传递给钩子函数: p: 当前节点的位置对象 d: p 的深度 path: 从根到 p 的路经 result: p 所有子节点的遍历结果 下面是树遍历过程的模板方法的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class EulerTour(object): def __init__(self, tree): self._tree = tree def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): """ :param p: :param d: :param path: :param result: :return: """ self._hook_previsit(p, d, path) path.append(0) result = [] for c in self._tree.children(p): result.append(self._tour(c, d + 1, path)) path[-1] += 1 value = self._hook_postvisit(p, d, path, result) path.pop() return value def _hook_previsit(self, p, d, path): pass def _hook_postvisit(self, p, d, path, result): passclass BinaryEulerTour(BinaryEulerTour): def __init__(self, tree): super(BinaryEulerTour, self).__init__(tree) def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): self._hook_previsit(p, d, path) result = [None, None] if self._tree.left(p): path.append(0) result[0] = self._tour(self._tree.left(p), d + 1, path) path.pop() self._hook_invisit(p, d, path) if self._tree.right(p): path.append(1) result[1] = self._tour(self._tree.right(p), d + 1, path) path.pop() value = self._hook_postvisit(p, d, path, result) return value def _hook_invisit(self, p, d, path): pass 此时如果我们想构建一个表示目录结构的目录树，并计算目录的大小，借助于 EulerTour 可以很容易的实现 123456class DiskSpace(EulerTour): def __init__(self, tree): super(DiskSpace, self).__init__(tree) def _hook_postvisit(self, p, d, path, result): return p.element() + sum(result) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 哈希算法]]></title>
    <url>%2F2018%2F10%2F23%2Falog%2Fhash%2F</url>
    <content type="text"><![CDATA[如何使用使用哈希算法？ 1 特性将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。优秀的哈希算法必需满足如下几点要求: 不能反向推导: 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）； 输入数据敏感: 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同； 散列冲突小: 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小； 执行效率高: 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。 1.1 应用哈希算法的应用非常多，最常见的有如下七种: 安全加密: 不能反向推导 + 散列冲突小，无法通过哈希值逆推出原文 唯一标识: 输入数据敏感 + 散列冲突小，可以通过哈希值的比较间接判断，原文是否相等 数据校验: 输入数据敏感 + 散列冲突小，数据损坏，哈希值就会发生变化 散列函数: 散列函数对哈希算法更加看重的是散列的平均性和哈希算法的执行效率 负载均衡: 利用哈希算法的唯一标识功能，可以将同一客户端 IP 或 session 路由到同一服务器 路由的服务器编号=hash(client_ip or session_id) % len(server_list) 数据分片: 利用哈希算法的唯一标识功能，无需比较就可以将相同的数据归类在一起 分配到的机器编号=hash(keyword) / len(server_list) 分布式存储: 数据分片 + 一致性哈希算法 2. 实现2.1 一致性哈希算法 利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题。下面是 Python 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657'''consistent_hashing.py is a simple demonstration of consistenthashing.'''import bisectimport hashlibclass ConsistentHash: '''ConsistentHash(n,r) creates a consistent hash object for a cluster of size n, using r replicas. It has three attributes. num_machines and num_replics are self-explanatory. hash_tuples is a list of tuples (j,k,hash), where j ranges over machine numbers (0...n-1), k ranges over replicas (0...r-1), and hash is the corresponding hash value, in the range [0,1). The tuples are sorted by increasing hash value. The class has a single instance method, get_machine(key), which returns the number of the machine to which key should be mapped.''' def __init__(self, num_machines=1, num_replicas=1): self.num_machines = num_machines self.num_replicas = num_replicas hash_tuples = [(j, k, my_hash(str(j) + "_" + str(k))) \ for j in range(self.num_machines) \ for k in range(self.num_replicas)] # Sort the hash tuples based on just the hash values hash_tuples.sort(lambda x, y: cmp(x[2], y[2])) self.hash_tuples = hash_tuples def get_machine(self, key): '''Returns the number of the machine which key gets sent to.''' h = my_hash(key) # edge case where we cycle past hash value of 1 and back to 0. if h &gt; self.hash_tuples[-1][2]: return self.hash_tuples[0][0] hash_values = map(lambda x: x[2], self.hash_tuples) index = bisect.bisect_left(hash_values, h) return self.hash_tuples[index][0]def my_hash(key): '''my_hash(key) returns a hash in the range [0,1).''' return (int(hashlib.md5(key).hexdigest(), 16) % 1000000) / 1000000.0def main(): ch = ConsistentHash(7, 3) print "Format:" print "(machine,replica,hash value):" for (j, k, h) in ch.hash_tuples: print "(%s,%s,%s)" % (j, k, h) while True: print "\nPlease enter a key:" key = raw_input() print "\nKey %s maps to hash %s, and so to machine %s" \ % (key, my_hash(key), ch.get_machine(key)) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import bisectimport md5class ConsistentHashRing(object): """Implement a consistent hashing ring.""" def __init__(self, replicas=100): """Create a new ConsistentHashRing. :param replicas: number of replicas. """ self.replicas = replicas self._keys = [] self._nodes = &#123;&#125; def _hash(self, key): """Given a string key, return a hash value.""" return long(md5.md5(key).hexdigest(), 16) def _repl_iterator(self, nodename): """Given a node name, return an iterable of replica hashes.""" return (self._hash("%s:%s" % (nodename, i)) for i in xrange(self.replicas)) def __setitem__(self, nodename, node): """Add a node, given its name. The given nodename is hashed among the number of replicas. """ for hash_ in self._repl_iterator(nodename): if hash_ in self._nodes: raise ValueError("Node name %r is " "already present" % nodename) self._nodes[hash_] = node bisect.insort(self._keys, hash_) def __delitem__(self, nodename): """Remove a node, given its name.""" for hash_ in self._repl_iterator(nodename): # will raise KeyError for nonexistent node name del self._nodes[hash_] index = bisect.bisect_left(self._keys, hash_) del self._keys[index] def __getitem__(self, key): """Return a node, given a key. The node replica with a hash value nearest but not less than that of the given name is returned. If the hash of the given name is greater than the greatest hash, returns the lowest hashed node. """ hash_ = self._hash(key) start = bisect.bisect(self._keys, hash_) if start == len(self._keys): start = 0 return self._nodes[self._keys[start]] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 散列表与链表]]></title>
    <url>%2F2018%2F10%2F22%2Falog%2Fhash_list%2F</url>
    <content type="text"><![CDATA[“形影不离”的散列表与链表 1. 特性散列表和链表，经常会被放在一起使用。原因是散列表虽然支持高效的数据插入、删除、查找操作，但是散列后的数据都是无序存储的，无法支持按照某种顺序快速地遍历数据。散列表是动态的数据结构，如果每次按序访问都要拷贝到数组，排序然后在遍历，效率太低了。而支持动态创建的链表刚好能解决散列表的有序遍历问题。 3. 应用3.1 LRU 缓存淘汰算法借助于散列表和链表可以实现时间复杂度降为 O(1)的 LRU 缓存淘汰算法。 12 3.2 Redis 的有序集合Redis 的有序集合就是跳表和散列表的结合，支持按照 key（键值）和score（分值）查找，添加和删除成员对象。12 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 散列表]]></title>
    <url>%2F2018%2F10%2F21%2Falog%2Fhash_map%2F</url>
    <content type="text"><![CDATA[散列表原理 1. 特性散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，其由三个核心部分组成: key: 元素的键 hash func: 散列函数，将键隐射为底层数组的下标 table: 底层的数组 散列表通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，下面是我们要关注的核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 1.1 散列函数散列函数在设计上有三点基本要求: 因为数组下标是从 0 开始的的，所以散列函数计算得到的散列值必需是一个非负整数； 如果 key1 = key2，那 hash(key1) == hash(key2)； 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2) 第三点看起来合情合理，但是要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。因此散列过程中会产生散列冲突。而且数组的存储空间有限，也会加大散列冲突的概率。 1.2 散列冲突常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。 开放寻址法开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。重新探测新的位置有很多方法，常见有线性探测，二次探测和双重散列，我们将其统称为探测函数。散列函数和探测函数一起，确定了元素的一系列可存储位置。 插入过程就是按序探测第一个非空位置并存储 查找过程就是按照相同的探测顺序，逐一比较数组中的元素和要查找的元素直至找到相等元素(找到)或一个空位置(不存在)。 因为数组空闲位置是判断是查找的判定条件，所以不能通过直接将数组元素置空来删除散列表中的元素。我们可以将删除的元素，特殊标记为 deleted。当探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。 散列表的装载因子 = 填入表中的元素个数 / 散列表的长度 装载因子越大，说明空闲位置越少，冲突越小，散列表的性能越好。 链表法 链表法是一种更加常用的散列冲突解决办法，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。 插入时，通过散列函数计算出对应的散列槽位，将其插入到对应链表中，时间复杂度是 O(1)。 查找、删除时，通过散列函数计算出对应的槽，然后遍历链表查找或者删除。时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。 2. 实现散列表的性能与散列函数，散列冲突和装载因子有关，要想实现一个工业级的散列表就要从这三个因素入手。 2.1 散列函数设计散列函数的设计遵循以下几个要点: 散列函数不能太复杂 散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突 实际工作中，还需要综合考虑包括关键字的长度、特点、分布、还有散列表的大小等在内的各个因素 2.2 装载因子控制对于没有频繁插入和删除的静态数据集合来说，因为数据是已知的，我们可以根据数据的特点、分布等，设计出完美的、极少冲突的散列函数。 对于动态数据集，我们可以动态扩缩容: 装载因子过大时，重新申请一个更大的散列表，动态扩容。 装载因子过小时，可以启动动态缩容。如果我们更加在意执行效率，能够容忍多消耗一点内存空间，也可以不缩容 需要注意的是动态扩缩容时，因为散列表的大小发生了变化，数据存储的位置就变了，所以需要通过散列函数重新计算每个数据的存储位置。在散列表的动态扩容中，装载因子阈值的设置非常重要，太小会导致内存浪费严重，太大会导致冲突过多，要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。 2.3 避免低效扩容动态扩容一个 1G 的散列表依旧很慢，为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个到多个数据放入到新散列表。将扩容过程分散到每次的插入操作中。 2.4 冲突解决方法选择开放寻址法开放寻址法中，散列表的数据都存储在数组中，所以开放寻址法的优点与使用数组类似 可以有效地利用 CPU 缓存加快查询速度 序列化起来比较简单。 但是缺点也很明显: 删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据 所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。 使用开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。所以比起链表法更浪费内存空间。当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的 ThreadLocalMap使用开放寻址法解决散列冲突的原因. 链表法链表法利用的是链表这种离散的内存空间，因此 对内存的利用率更高。因为链表结点可以在需要的时候再创建，无需像开放寻址法那样事先申请好 对大装载因子的容忍度更高。对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。 但是缺点也很明显，链表对于存储小的数据会浪费很多空间(指针的存在)，离散的内存分布也无法利用 CPU 的缓存加速。 链表法中的链表可以改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。 所以基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。 2.5 java 的 HashMap我们以 java 中的 HashMap 来说一说如何实现一个工业及的散列表: 初始大小: HashMap 默认的初始大小是 16，这个默认值是可以设置的 装载因子和动态扩容: HashMap 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。 散列冲突解决: HashMap 底层采用链表法，在 JDK1.8 版本中引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表 3. Python 的 dict上面我们介绍了散列表的实现原理，但是实现一个工业及的散列表是在大量数学和实验的基础上实现的。因为我主要用的还是 Python ，因此我就以 Python 中的dict 实现来介绍当前工业级的散列表的最佳实践，并着手实现一个简单的散列表。 3.1 散列函数Python 中的散列函数通常有两个部分组成: 哈希码: 将一个键映射到一个整数 压缩函数: 将哈希码映射到散列表内部数组的索引 这么做的目的是将哈希码的计算与具体的散列表大小相独立，这样就可以为每个对象开发一个通用的哈希码，并且可以用于任意大小的散列表，只有压缩函数与散列表的大小有关。 3.2 哈希码不同对象的哈希码有如下几种实现方式: 对于数值类型的对象，我们可以简单的把用于表示数值 X 的各个位所表示的值作为它的哈希码。如果数值的位数超过哈希码的长度，比如将 64 位浮点数哈希为 32 位的整数，可以对前后 32 求和或做异或处理 对于字符串或元组形式表示的可变长度对象，通常使用多项式哈希和循环移位哈希，这两种方式都会考虑字符串中字符的位置 多项式哈希码的计算方式如下，其中 i 表示字符串中第 i 个字符，a 是非 0 常数。在处理英文字符串时 33，37，39，41 是合适选择值。12 循环移位的 Python 算法如下，在处理英文字符串时 5 位移动能产生最少的散列冲突。 1234567def hash_code(s): mask = (1 &lt;&lt; 32) - 1 h = 0 for c in s: h = (h &lt;&lt; 5 &amp; mask) | (h &gt;&gt; 27) h += ord(c) return h Python 中的哈希码Python 中只有不可变的数据类型可以哈希，以确保一个对象的生命周期中其哈希码不变。对于字符串 Python 使用类似于多项式哈希码的技术，精心设计了字符串的哈希码，没有使用异或和相加。使用相似的基于元组每个元素的哈希码的组合技术计算元组的哈希码。对于 frozenset 对象，元素的顺序是无关的，因此一个自然的选择是用异或值计算单个哈希码而不用任何移位。 用户自定义对象默认是不可哈希的，除非自定义 __hash__ 内置函数，hash() 函数会调用此方法获取对象的哈希码。通过计算组合属性的哈希码作为自定义对象的哈希码是常见方法。 123def __hash__(): return hash(self._red, self._green, self._blue) 一个重要的规则是，__eq__ 与 __hash__ 的实现必需一致，即如果x==y，则 hash(x)==hash(y)。比如 hash(1)==hash(1.0) 3.3 压缩函数一个好的压缩函数应该确保两个不同的哈希码映射到相同索引的可能性为 1/N，工业级别最常用的压缩函数是 MAD(Multiply-Add-Divide)。选择这个压缩函数是为了消除在哈希码集合中的重复模式，并且得到更好的哈希函数。 1234[(ai + b) mod p] mod N- N: 散列表内部数组的大小- p: 比 N 大的素数- a，b 是从区间 [0, p-1] 任意选择的整数，并且 a &gt; 0 3.4 散列冲突处理散列冲突解决方案中的开放寻址法，有多个变种。常见的包括线性探测，二次探测，双哈希策略。Python 中采用的是迭代地探测桶。这种方法下散列表的负载因子可以达到 2/3。12345# 迭代地探测桶A[(h(k) + f(i)) mod N]- h(k): 哈希码- f(i): 基于伪随机数产生器的函数，它提供一个基于原始哈希码位的可重复的但是随机 的，连续的地址探测序列 4. 散列表的简单实现最后，我们介绍散列表的两种实现，一种使用链表法，另一种使用包含线性探测的开放寻址。 4.1 公用基类参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 跳表]]></title>
    <url>%2F2018%2F10%2F20%2Falog%2Fskip_list%2F</url>
    <content type="text"><![CDATA[跳表: 链表上的“二分查找” 1. 特性跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。实现上跳表使用空间换时间的思想，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。 1.1 跳表的结构跳表就是在有序链表的基础上添加了多层”索引”。通过每隔几个节点提取一个节点形成上层索引，每层索引的节点个数成等比数列分布，从顶向下的每次查询都会将查询区间“折半”，从而达到 O(logN) 的时间复杂度。每次查询对查询区间的缩减取决于索引构建策略，通过改变索引构建策略，有效平衡执行效率和内存消耗。待会我们会看到更加具体的分析过程。 跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树。Redis 中的有序集合（Sorted Set）就是在跳表的基础上实现的。 1.2 跳表的查找假设我们每隔两个节点构建一层索引，最上层有两个节点，总共有 N 个节点。则第 h 层的节点个数为 N/2^h，包含最底层的链表在内总共有 logN 层。如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。对于每隔两个节点构建的索引 m=3。 原因是，假设我们要查找的数据是 x，在第 k 级索引中，我们遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以我们通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以，我们在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。 所以在跳表中查询任意数据的时间复杂度就是 O(logn)。而整个跳表需要额外添加的节点数为n/2+n/4+n/8…+8+4+2=n-2，所以空间复杂度为 O(n)。 如果我们每三个结点或五个结点，抽一个结点到上级索引。总的索引结点大约就是 n/3+n/9+n/27+…+9+3+1=n/2，而查询时间复杂度的系数就会从 3 变成 4。因此通过改变索引构建策略，有效平衡执行效率和内存消耗。 1.3 跳表的插入跳表的插入有两个要点: 要保证原始链表中数据的有序性 要维护索引与原始链表大小之间的平衡，避免复杂度退化 因此在插入前需要先找到插入位置，然后通过一个随机函数，来决定将这个结点插入到哪几级索引中。整个过程的时间复杂度= O(logn)(查找) + O(1)(链表的插入) 1.4 跳表的删除删除的过程只是在查找的基础上多了链表的删除操作，对于双向链表而言删除的时间复杂度也是 O(logn)。需要注意的是删除的节点也可能出现在索引中，需要一并删除。 1.5 跳表与红黑树跳表和红黑树都是非常高效的动态数据结构，在插入、删除、查找以及迭代输出有序序列上，时间复杂度都是 O(logn)。但是存在以下不同: 按照区间来查找数据，跳表比红黑树更加高效，跳表可以在 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历即可 相对于红黑树跳表更加简单灵活，通过改变索引构建策略，可以有效平衡执行效率和内存消耗 红黑树出现的更早，很多编程语言中的 Map 类型都是通过红黑树实现的。可以直接拿来用，但是跳表并没有一个现成的实现，想要使用必须自己实现。 2. 实现下面是 Python 的跳表实现。 12 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 映射]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fmap%2F</url>
    <content type="text"><![CDATA[无处不在的映射 1. 映射前面我们讲解了基于数组和链表最基础的数据结构。在继续下面的内容之前，我们先来说一说映射。因为映射与我们接下来的很多数据结构与算法相关。映射可以看作是搜索或查找的扩展，后面介绍的很多数据结构都是为实现快速的增删改查。因此在继续其他数据结构的介绍之前，我想先介绍一下映射的抽象数据类型以及它的常见几种实现方式。 1.1 映射的抽象数据类型抽象基类Python 中使用抽象基类来表达抽象数据类型。如下所示，抽象基类包含两类方法 一是由 abc.abstractmethod 装饰的抽象方法，这些方法必需由继承自抽象基类的子类来提供具体实现 二是在抽象方法基础上定义的具体方法，基类上的具体方法通过继承可以实现最大化代码复用 123456789101112import abcclass ADT(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def abstract_method(self): pass def specific_method(self): return self.abstract_method() Python 中 映射 map 的 ADT 与 MutableMapping 抽象基类相对应。 映射的抽象方法映射 M 有如下五个抽象方法，这些方法必需由子类提供具体实现: M[k]: 返回键 k 对应的值，键不存在则触发异常，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 映射的具体方法为了方便其他功能实现，映射包含了如下具体方法，子类通过继承 MutableMapping 可以自动获取: K in M M.get(k, d=None) M.setdefault(k, d) M.pop(k, d=None) M.popitem() M.clear() M.keys() M.values() M.items() M.update(M2) M == M2 M ！= M2 因为这些方法很容易做到见名知意，我就不再一一解释了。 1.2 map 的实现层次map ADT 有众多的实现方式，为了方便代码重用，我们使用如下层次结构 MutableMapping 是 Python 提供的映射的抽象，提供了现成的映射具体方法 MapBase: 继承自 MutableMapping，为自定义的映射类型提供扩展支持 UnsortedMap: 基于未排序数组的映射实现 HashMapBase: 映射的散列表实现 SortedTableMap: 基于二分查找的映射实现 SkipList: 映射的跳表实现 TreeMap: 二叉搜索树木及其变种的映射实现 2. 实现本节我们就以最简单的 UnsortedMap 为例，实现一个最简单的映射。更加高级的实现我们会在后面一一讲解。 2.1 MapBaseMapBase 是我们在 MutableMapping 基础上自定义的抽象基类，它提供了一个 _Item 类用于保存键与值的映射关系。12345678910111213141516171819class MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __ne__(self, other): return not (self == other) def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._key 2.2 UnsortedMap1pass]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 二分查找]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fbinary_search%2F</url>
    <content type="text"><![CDATA[不简单的简单二分查找 1. 特性二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。 二分查找看似简单，但是二分查找的变体一点都不简单，“你”经常看到的二分查找其实是最简单的二分查找即: 有序数组中不存在重复元素，通过二分查找值等于给定值的数据。注意不重复和等于，这里存在很多的变体。 其次二分查找存在很大的局限性: 二分查找依赖的是顺序表结构，简单点说就是数组。 主要原因是二分查找算法需要按照下标随机访问元素。数组按照下标随机访问数据的时间复杂度是 O(1) 如果是链表，随机访问的时间复杂度是 O(n)。如果数据使用链表存储，二分查找的时间复杂就会变得很高。 其他数据结构存储的数据，则无法应用二分查找。 二分查找针对的是有序数据。如果数据没有序，就要先排序。 所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中 针对频繁插入删除的动态数据集合二分查找将不再适，快速查找需要使用二叉树 数据量太大不适合二分查找: 二分查找依赖数组，而数组为了支持随机访问，需要连续的内存空间，对内存的要求苛刻。 要注意数组要求的连续内存意味着即便系统上有零散的 2G 内存也无法申请到连续的 1G 内存。虽然数组对内存要求苛刻，但是同等条件下数组却是最省内存空间的存储方式，因为除了数据本身之外，不需要额外存储其他信息。 1.1 二分查找的变形如果放开不重复和等于的限制，二分查找有很多变形，典型的包括: 查找第一个值等于给定值的元素 查找最后一个值等于给定值的元素 查找第一个大于等于给定值的元素 查找最后一个小于等于给定值的元素 凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。实际上，“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。比如今天讲的这几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。 2. 实现2.1 最简单的二分查找123456789101112def binary_search(A, value): start = 0 end = len(A) - 1 while start &lt;= end: mid = start + ((end -start) &gt;&gt; 1) if A[mid] == value: return mid elif A[mid] &lt; value: start = mid + 1 else: end = mid -1 最简单的二分查找实现中有以下几个需要注意的点: 循环退出条件是 start &lt;= end 不是 start &lt; end 使用 mid=(low+high)/2 对mid取值是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 low+((high-low)&gt;&gt;1)。因为相比除法运算来说，计算机处理位运算要快得多。 start 和 end 的更新，如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致死循环。 2.2 查找第一个值等于给定值的元素12345678910111213def bs_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为第一个出现的值 if mid == 0 or (A[mid-1] != value): return mid end = mid - 1 2.3 查找最后一个值等于给定值的元素12345678910111213def bs_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为最后一个出现的值 if mid == n or (A[mid + 1] != value): return mid end = mid + 1 2.4 查找第一个大于等于给定值的元素1234567891011def bs_gte_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt;= value: # 判断是否为第一个 if mid == 0 or (A[mid - 1] &lt; value): return mid end = mid - 1 else: start = mid + 1 2.5 查找最后一个小于等于给定值的元素1234567891011def bs_lte_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt; value: end = mid -1 else: # 判断是否为最后一个 if mid == n or (A[mid + 1] &gt; value): return mid start = mid + 1 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 工业级的排序算法]]></title>
    <url>%2F2018%2F10%2F18%2Falog%2Fsort_4%2F</url>
    <content type="text"><![CDATA[实现一个通用的，高效的工业级排序函数 1. 排序算法对比前面我们我们介绍了最常见最经典的几个排序算法，它们有不同的时间复杂度，空间复杂度与使用情景。那么如何用它们实现一个通用的、高效率的排序函数呢？ 线性排序算法的时间复杂度比较低，但适用场景太过比较特殊，所以几乎不会使用。 为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。 归并排序由于不是原地排序算法，空间复杂度为 O(n)，数剧集大时过于占用内存，所以很少使用。 1.2 快排优化快速排序在最坏情况下的时间复杂度是 O(n2)，原因主要是我们的分区点选择不够合理。有两种比较常用合理的分区算法: 三数取中法: 每间隔某个固定的长度，取数据出来比较，将中间值作为分区点 随机法: 从要排序的区间中，随机选择一个元素作为分区点 此外快速排序是用递归来实现的，递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。 2. 实现2.1 Glibc 的 qsort我们以 Glibc 中的 qsort() 函数为例来说明如何实现一个排序函数: qsort() 会优先使用归并排序来排序输入数据，因为小数据集下，归并排序不会占用多少内存，且排序快 要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序 qsort() 使用“三数取中法”选择分区点 qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决操作系统的堆栈溢出问题 在快速排序的过程中，当排序区间的元素个数小于等于 4 时，qsort() 就退化为插入排序；因为我们前面也讲过，在小规模数据面前，插入排序比递归调用的快排更快 在 qsort() 插入排序的算法实现中，还利用了哨兵技术，来减少判断的次数 2.2 Tim-Sort1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 线性排序]]></title>
    <url>%2F2018%2F10%2F17%2Falog%2Fsort_3%2F</url>
    <content type="text"><![CDATA[非基于比较的三个排序算法: 桶排序，计数排序，基数排序 1. 线性排序桶排序、计数排序、基数排序的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以我们今天学习重点的是掌握这些排序算法的适用场景。 桶排序和计数排序的排序思想是可以对数剧集进行有限分类，都是针对范围不大的数据，将数据划分成不同的桶来实现排序，只不过二者桶的粒度不同。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。 2. 实现2.1 桶排序桶排序的核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 只要桶的数量接近数据的个数，并且数据在所有桶内分配均匀，桶排序的时间复杂度接近 O(n)。显然桶排序对要排序数据有苛刻的限制: 首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。 其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。 1234567891011121314151617181920from collections import dequedef sort_bucket(S): """ :param S: [(v, item)] :return: """ m = max((i[0] for i in S)) bucket_map = [deque() for i in range(m + 1)] for i in S: bucket = bucket_map[i[0]] bucket.append(i) c = 0 for i in range(m + 1): b = bucket_map[i] while len(b) &gt; 0: S[c] = b.popleft() c += 1 桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 2.2 计数排序计数排序可视为桶排序的特殊情况，当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。计数排序之所以叫作计数排序，是因为其特殊的通过“计数”进行排序的算法得名的。 1234567891011121314151617def sort_count(S): if len(S) &lt;= 1: return S m = max(S) bucket = [0] * (m + 1) for i in S: bucket[i] += 1 for i in range(1, m + 1): bucket[i] += bucket[i - 1] tmp = [0] * len(S) for i in S: bucket[i] -= 1 tmp[bucket[i]] = i for i in range(len(S)): S[i] = tmp[i] 计数排序只能用在数据范围不大的场景，如果数据范围 k 比要排序的数据 n 大很多，就不适合用排序了。而且，而且计数排序只能用在给非负整数得排序中，如果要排序的数据是其他类型的，要其在不改变相对大小的情况下，转化为非负整数。 2.3 基数排序基数排序的核心是可以将数据分割出独立的“位”来比较，然后按照从低位到高位依次排序，只要每次按位排序的算法是稳定的就可以得到正确的排序。 根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候基数排序的时间复杂度就近似于 O(n)。 显然基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了 123456789101112131415def sort_base(S, num): if len(S) &lt;= 1: return S T = [(0, i) for i in S] for n in range(num): T = [(i[1] // 10 ** n % 10, i[1]) for i in T] sort_bucket(T) print T for i in range(len(S)): S[i] = T[i][1]aa = [43, 41, 31, 57]sort_base(aa, 2)print aa 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 基于比较的排序(下)]]></title>
    <url>%2F2018%2F10%2F16%2Falog%2Fsort_2%2F</url>
    <content type="text"><![CDATA[基于分治编程思想的归并排序和快速排序 1. 分治前面讲到的三种排序算法，平均时间复杂度都是 O(n2)，只是适合规模较小的数剧集，接下来要讲的归并排序和快速排序，平均时间复杂度都是 O(nlogn)，它们都用到了分治思想。 分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。分治与我们前面提到的递归很像，分治算法一般都是通过递归实现的。 虽然快排和归并排序都采用了分治的思想，但是它们完全不一样。归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，快排的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的但是它是非原地排序算法。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。正因为此，归并排序没有快排应用广泛。 2. 实现2.1 归并排序归并排序的核心是将数组从中间分成前后两个部分，然后对前后两个部分分别排序，再将它们合并起来。 1234567891011121314151617181920def merge(a, b, c): i = j = 0 while i + j &lt; len(c): if i == len(a) or (j &lt; len(b) and a[i] &gt; b[j]): c[i + j] = b[j] j += 1 else: c[i + j] = a[i] i += 1def sort_merge(alist): if len(alist) &lt;= 1: return alist mid = len(alist) // 2 left = alist[:mid] right = alist[mid:] sort_merge(left) sort_merge(right) merge(left, right, alist) 归并排序并不是原地排序算法，原因很简单 merge 函数在合并两个已排序数组时使用了额外的存储空间，其空间复杂度为 O(n)。最好最坏和平均时间复杂度都是 O(nlogn)，在整个比较过程并没有发生数据交换，只要 merge 函数保持元素的相对顺序，归并排序是稳定的排序算法。 2.2 快速排序快排的算法描述快排排序由以下 3 个步骤组成: 分解: 如果待排序列 S 有至少两个元素，从 S 中选择一个特定的元素 x 作为基准，将 S 中的元素分别放置在 3 个序列中: L 存储 S 中小于 x 的元素 E 存储 S 中等于 x 的元素 G 存储 S 中大于 x 的元素 递归: 递归的排序序列 L 和 G 合并: 按照 L,E,G 的顺序将元素放回 S 中 123456789101112131415161718192021222324252627def sort_quick(S): n = len(S) if len(S) &lt;= 1: return x = S.first() # 基准 x L = LinkedQueue() E = LinkedQueue() G = LinkedQueue() # 分解 while not S.empty(): if S.first() &lt; x: L.enqueue(S.dequeue()) elif S.first() &gt; x: G.enqueue(S.dequeue()) else: E.enqueue(S.dequeue()) # 递归 sort_quick(L) sort_quick(G) # 合并 while not L.is_empty(): S.enqueue(L.dequeue()) while not E.is_empty(): S.enqueue(E.dequeue()) while not G.is_empty(): S.enqueue(G.dequeue()) 快排的原地排序快排的原地排序的核心是选择数组中的一个数据项作为分区点 x，然后遍历数组通过数据交换，使得 x 左边的数据都小于 x，x 右边的数据都大于 x。x 将数组分成了两个区间，然后对这两个区间递归执行此过程直至区间长度为 1 ，完成排序。 1234567891011121314151617def sort_quick(alist, left, right): if left &gt;= right: return alist l = left + 1 r = right x = alist[left] while l &lt;= r: while l &lt;= r and alist[l] &lt; x: l += 1 while l &lt;= r and alist[r] &gt; x: r -= 1 if l &lt;= r: alist[l], alist[r] = alist[r], alist[l] alist[left], alist[r] = alist[r], alist[left] sort_quick(alist, left, r - 1) sort_quick(alist, r + 1, right) 显然这个过程发生了数据交换，但是并没有使用额外的存储空间，所以快排并不是稳定的排序算法，但是原地排序算法。 快排的最好和平均时间复杂度都是O(nlogn)，但是极端情况下，如果数组本身是有序的，并且我们选择最大或者最小(两端)的数据作为分区点，我们需要大约 n 次分区才能完成排序过程。快排的时间复杂度就会退化为 O(n2)。但是退化到 O(n2) 的概率非常小，我们可以通过合理的选择分区点来避免这种情况。 3. 算法3.1 求无序数组中的第 K 大元素利用快排的分区思想，我们可以在O(n) 时间复杂度内求无序数组中的第 K 大元素。 我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。如果 p+1=K，那 A[p] 就是要求解的元素；如果 K&gt;p+1, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找。同理，如果 K&lt;p+1，那我们就在 A[0…p-1] 区间查找。 12345678910111213141516171819def quick_select(S, left, right, k): r = right l = left + 1 pivot = S[left] while l &lt;= r: while l &lt;= r and S[l] &lt;= pivot: l += 1 while l &lt;= r and S[r] &gt;= pivot: r -= 1 if l &lt;= r: S[l], S[r] = S[r], S[l] S[left], S[r] = S[r], S[left] if r + 1 == k: return S[r] elif r + 1 &gt; k: return quick_select(S, left, r - 1, k) else: return quick_select(S, r + 1, right, k) 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 基于比较的排序(上)]]></title>
    <url>%2F2018%2F10%2F14%2Falog%2Fsort_1%2F</url>
    <content type="text"><![CDATA[基于比较的排序算法: 冒泡排序、插入排序和选择排序 1. 排序算法要点排序算法太多了，因此除了要学习各种算法的原理，代码实现之外；我们还要搞明白如何比较和分析一个排序算法。评价一个算法可以从如下几个方面入手: 算法的执行效率: 算法的执行效率包括最好情况、最坏情况、平均情况的时间复杂度；之所以要区分这三种情况，是因为大多数排序算法在不同有序度的数据集上的时间复杂度不相同 时间复杂度的系数、常数 、低阶；通常我们要排序的数剧集并不大，因此需要将系数、常数 、低阶考虑进来 比较次数和交换（或移动）次数，基于比较的排序算法需要进行数据的比较和移动两个操作，因此需要把这两个操作考虑进来 排序算法的内存消耗，排序算法中，我们将空间复杂度为O(1) 的算法称为原地排序算法 排序算法的稳定性，稳定性指如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 这些方面可以帮助我们分析和更好的理解每种算法的特点。 1.1 排序算法分类排序算法太多了，最经典的、最常用的包括：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。如上图所示按照时间复杂度它们分成了三类。 本节我们先来介绍基于比较的排序算法:冒泡排序、插入排序和选择排序。 这三种时间复杂度为 O(n2) 的排序算法中，冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，我会讲到，有些编程语言中的排序函数的实现原理会用到插入排序算法。 1.2 有序度有序度是数组中具有有序关系的元素对的个数，逆序度恰恰相反，完全有序的数组的有序度叫作满有序度。逆序度的定义正好跟有序度相反显然 逆序度 = 满有序度 - 有序度。排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，排序完成。 在下面的冒泡和插入排序的实现中，我们会发现无论是插入排序还是选择排序，每次数据交换只会增加 1 个有序度(因为它们只会对相邻的元素进行交换)。因此这两种排序的数据交换次数是相同的都是数剧集的逆序度。但是冒泡排序的实现更复杂需要更多次的赋值操作。所以如果将时间复杂度的系数、常数 、低阶考虑进来，冒泡排序并没有插入排序快。 2. 实现2.1 冒泡排序冒泡排序的核心是每次只会操作相临的两个数据，比较它们的大小，并在不满足大小关系时交换；在 n 次操作之后将最大或者最小值移动到最前端。 总共经过 n 次冒泡之后，排序即可完成。冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。 冒泡是原地排序算法，只要我们在代码中不交换相等的元素，冒泡排序就是稳定的排序算法 12345def sort_bubble(alist): for end in range(len(alist), 1, -1): for i in range(1, end): if alist[i] &lt; alist[i-1]: alist[i], alist[i-1] = alist[i-1], alist[i] 2.2 插入排序插入排序将数据分为已排序和未排序两个区间，然后不断取未排序区间中的元素插入到已排序区间中，并保持已排序区间的有序；重复直至未排序区间为空即可。 插入排序是原地排序算法，在插入排序中，对于值相等的元素，我们只要将后出现的元素插入到后出现元素的后面，插入排序就是稳定的排序算法。 12345678def sort_insert(alist): for end in range(1, len(alist)): tmp = alist[end] p = end - 1 while p &gt;= 0 and alist[p] &gt; tmp: alist[p + 1] = alist[p] p -= 1 alist[p + 1] = tmp 2.3 选择排序选择排序将数据分为已排序和未排序两个区间，不同的是选择排序每次会从未排序区间找出最小的元素放到已排序区间的末尾，而不是插入。 选择排序是原地排序算法，最好最坏和平均时间复杂度都是O(n2)，但是选择排序并不是稳定的排序算法。原因是选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。 1234567def sort_select(alist): for start in range(0, len(alist)): m = start for i in range(start + 1, len(alist)): if alist[i] &lt; alist[m]: m = i alist[start], alist[m] = alist[m], alist[start] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 递归]]></title>
    <url>%2F2018%2F10%2F13%2Falog%2Frecursion%2F</url>
    <content type="text"><![CDATA[递归是一种应用非常广泛的算法（或者编程技巧）。很多数据结构和算法的编码实现都要用到递归，比如 DFS 深度优先搜索、前中后序二叉树遍历等等。所以，搞懂递归非常重要。 1 特性基本上，所有的递归问题都可以用递推公式来表示。要想使用递归解决问题，必需满足三个前提条件: 一个问题的解可以分解为几个子问题的解，子问题就是规模更小的问题 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 存在递归终止条件 1.1 如何写递归代码写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再找出终止条件，最后将递推公式和终止条件翻译成代码。 编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。 1.2 递归存在的问题使用递归时会存在很多问题，最常见的两个是: 递归代码要警惕堆栈溢出 递归代码要警惕重复计算 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销。 1.3 应用递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现。 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 队列]]></title>
    <url>%2F2018%2F10%2F12%2Falog%2Fqueue%2F</url>
    <content type="text"><![CDATA[先进者先出，这就是典型的”队列”。 1. 特性我们知道，栈只支持两个基本操作：入栈 push()，出栈 pop()，队列与栈类似基本操作只有两个: 入队 enqueue() 向对尾添加一个数据，出队 dequeue() 从队列头部取出一个数据。 1.1 应用队列的应用非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。 队列可以应用在任何有限资源池中，用于排队请求。对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。 1.2 阻塞队列阻塞队列其实就是在队列基础上增加了阻塞操作。它有两个显著特征: 队列空时，从队头取数据会被阻塞，直到队列中有了数据才能返回 队列满时，向队尾插入数据会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回我们可以使用阻塞队列轻松实现一个“生产者，消费者模型”。 1.3 并发队列线程安全的队列我们叫作并发队列，最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。 实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 1.4 双端对列双端对列是一种类对列数据结构，支持在对列的头部和尾部都能进行插入和删除操作。Python 中的 collections.deque 就是一个双端对列的实现。 2. 实现跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。 2.1 顺序队列顺序队列的实现需要两个指针，head 指针指向队列头部，tail 指针指向队列尾部，即下一个入队元素将被保存的位置索引。显然随着不断的入队，出队 tail 指针出超过数组的索引范围，此时即便数组还有空闲位置也无法继续添加数据。此时借鉴在数组删除中介绍的方法，如果没有空间，我们只需要在下一次入队时集中触发以此数据移动操作，队列中的数据集中移动数组最前方即可。另一种解决方案则是使用循环队列。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class ArrayQueue(object): __CAPACITY__ = 10 def __init__(self): self.head = self.tail = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self.tail - self.head def is_empty(self): return len(self) == 0 def is_end(self): return self.tail == self._capacity def is_full(self): return len(self) == self._capacity def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) elif self.is_end(): self._move() self._buf[self.tail] = value self.tail += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') h = self._buf[self.head] self._buf[self.head] = 0 self.head += 1 if len(self) &lt; self._capacity / 4: self._resize(self._capacity / 2) return h def _resize(self, size): buf = [0] * size base = len(self) for i in range(base): vi = self.head + i buf[i] = self._buf[vi] self._capacity = size self._buf = buf self.head = 0 self.tail = base def _move(self): i = 0 base = len(self) while i &lt; base: self._buf[i] = self._buf[self.head + i] i ++ self.head = 0 self.tail = base 2.2 链式队列基于单链表的队列，我们在链表那一章已经包含在单链表的实现中。这里我们就基于双链表来实现一个队列，也把之前遗留的循环链表的实现补上。 12345678910111213141516171819202122232425262728293031323334353637383940class LinkedCircularQueue(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, nxt=None): self._element = element self._next = nxt def __init__(self): self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') self._size -= 1 node = self._tail._next if self.is_empty(): self._tail = None else: self._tail._next = node._next node._next = None value = node.element return value def enqueue(self, value): node = self._Node(value) if self.is_empty(): node._next = node else: node._next = self._tail._next self._tail._next = node self._tail = node self._size += 1 2.3 循环对列循环对列与顺序队列类似，但是通过循环利用底层的数组有效的避免了数据移动。循环队列实现相比顺序队列更复杂，有以下几点需要注意: 追加到队尾的元素的位置不在是 tail 而是要判断 tail 是否大于 n，如果大于插入位置则为 tail % n，同时更新 tail 应该更新为 tail % n + 1 队空的条件仍然是 tail == head 但是队列满的条件则为 (tail + 1) % n == head 1234567891011121314151617181920212223242526272829303132333435363738394041424344class ArrayCircularQueue(object): __CAPACITY__ = 10 def __init__(self): self._head = 0 self._size = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self._size def is_empty(self): return self._size == 0 def is_full(self): return self._size == len(self._buf) def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) vi = (self._head + self._size) % self._capacity self._buf[vi] = value self._size += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') value = self._buf[self._head] self._buf[self._head] = 0 self._head = (self._head + 1) % self._capacity if self._size &lt; self._capacity / 4: self._resize(self._capacity / 2) self._size -= 1 return value def _resize(self, size): buf = [0] * size for i in range(self._size): vi = (i + self._head) % self._capacity buf[i] = self._buf[vi] self._capacity = size self._buf = buf self._head = 0 2.4 双端对列链表那一章，我们实现了一个双向队列，在此基础上我们来实现一个双端队列。前面对双向链表的抽象实现是非常重要的，因为我们后面很多数据结构都是建立在双向链表的基础上。 12345678910111213141516171819202122from double_link import DoubleLinkclass LinkedDeque(DoubleLink): def __init__(self): super(LinkedDeque, self).__init__() def insert_first(self, value): self.insert_between(value, self._head, self._head._next) def insert_last(self, value): self.insert_between(value, self._tail._pre, self._tail) def delete_first(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._head._next) def delete_last(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._tail._pre) 2.5 并发对列一个基于 CAS 的无锁并发队列实现起来是很复杂的，我们暂时先把这个放一放，在这个系列的结尾会用专门的一篇文章来讲解实现。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 栈]]></title>
    <url>%2F2018%2F10%2F11%2Falog%2Fstack%2F</url>
    <content type="text"><![CDATA[后进者先出，先进者后出，这就是典型的“栈”结构。 1. 特性栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。 2. 实现栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。 2.1 顺序栈顺序栈依赖一个能自动扩缩容的数组容器，我们可以像数组章节一样，自己实现一个数组容器，也可以直接使用 Python 内置的 list。list 的接口已经包含并大大超过了栈的可操作范围，这里我们采用一种称为”适配器模式”的通用方法，将栈操作委托给一个内部的 list 实例，来实现一个顺序栈。 这个实现起来很简单，就不写的过于复杂了。 1234567891011121314class ArrayStack(object): def __init__(self): self._buf = [] def __len__(self): return len(self._buf) def pop(self): if len(self._buf) &lt; 1: raise ValueError('stack is empty') return self._buf.pop() def push(self, value): self._buf.append(value) 2.2 链式栈在链表的头部插入和删除一个节点的时间复杂度都是 O(1)，因此我们很容易的就可以将链表的头部作为栈顶实现一个链式栈，并且我们的都不管链表的尾，链表只要维护一个指向头节点指针和自身大小的计数即可。 注意不要将链表的尾作为栈顶，虽然可以实现 O(1) 向链尾插入节点，但是删除尾节点需要遍历整个链表。在链表章节，我们已经实现了一个”超纲的”链式栈，这里就不再累述了。 3. 相关算法操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。这种栈被称为函数调用栈。除此之外诸如表达式求值，括号匹配以及实现浏览器的前进后退功能都与栈有关。 3.1 表达式求值对一个类似于 3-(1/4+7)*3 中缀表达式进行求值分成两步: 将中缀表达式转换为后缀表达式 对后缀表达式进行求值 这两步都用到了栈。为了简单起见，我们只处理+ - * / () 四种运算 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from stack import ArrayStackfrom operator import add, div, mul, subop_priority = &#123; '(': 1, '+': 2, '-': 2, '*': 3, '/': 3, ')': 4&#125;op_func = &#123; '+': add, '-': sub, '*': mul, '/': div&#125;def infix_to_postfix(expression): s = ArrayStack() r = [] expression = expression.split(' ') for e in expression: if e not in op_priority: r.append(e) elif e == '(': s.push(e) elif e == ')': if s.top() != '(': r.append(s.pop()) s.pop() else: while len(s) &gt; 0: t = s.top() if op_priority[t] &gt;= op_priority[e]: r.append(s.pop()) else: break s.push(e) while len(s) &gt; 0: r.append(s.pop()) return ''.join(r)def calculate_postfix(expression): s = ArrayStack() expression = expression.split(' ') for e in expression: if e not in op_priority: s.push(e) else: right = float(s.pop()) left = float(s.pop()) # print left, right value = op_func[e](left, right) s.push(value) return s.pop()def main(): print infix_to_postfix('( A + B ) * ( C + D )') print infix_to_postfix('A + B * C') print calculate_postfix('7 8 + 3 2 + /') print infix_to_postfix('6 / 3') print calculate_postfix('15 3 /') 3.2 括号匹配括号匹配有两个类似的问题，一个是类似于对形如 (1 + 2) + (10) 表达式检测括号是否成对出现；另一个更加常用的是检测 HTML 标签是否完整匹配。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from stack import ArrayStack# 括号匹配def per_check(expression): left = '(&#123;[' right = ')&#125;]' s = ArrayStack() expression = expression.replace(' ', '') for e in expression: if e in left: s.push(left.index(e)) elif e in right: i = right.index(e) if len(s) &lt;=0: return False elif i != s.pop(): return False if len(s) &gt; 0: return False return True# html 标签匹配def html_match(html_string): start = 0 s = ArrayStack() while start != -1: start = html_string.find('&lt;', start) if start == -1: break end = html_string.find('&gt;', start + 1) tag = html_string[start + 1: end] print tag if tag.startswith('/'): if len(s) &lt;= 0: return False else: top = s.pop() # print top, tag[1:] if top != tag[1:]: return False else: s.push(tag) start = end if len(s) &gt; 0: return False return Truedef main(): # print per_check('&#123;&#123;([][])&#125;()&#125;') # print per_check('()]') print html_match('&lt;a&gt;&lt;/a&gt;')if __name__ == "__main__": main() 3.3 浏览器的前进后退功能12345678910111213141516171819202122232425262728from stack import ArrayStackclass Browser(object): def __init__(self): self._back = ArrayStack() self._forward = ArrayStack() def back(self): """ :return: 后退 """ if len(self._back) &gt; 0: self._forward.push(self._back.pop()) def forward(self): """ :return: 前进 """ if len(self._forward) &gt; 0: self._back.push(self._forward.pop()) def new_click(self): """ :return: 打开新连接 """ while len(self._forward) &gt; 0: self._forward.pop() 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 链表]]></title>
    <url>%2F2018%2F10%2F10%2Falog%2Flinkedlist%2F</url>
    <content type="text"><![CDATA[相比于数组必需使用连续的内存空间，链表通过“指针”将一组零散的内存块串联起来使用，因此更加灵活。 1. 特性我们知道数组受限于保持数据的连续，插入和删除都需要移动大量的数据，而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 1.1 性能比较由于数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 虽然常见的数组容器都支持动态扩容，但是当需要申请更大的内容容纳更多的数据，数据的拷贝操作是非常耗时的。 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 2. 实现链表有多种结构，常见的有单链表，双链表，循环链表。接下来我们就来介绍并实现这三种常见的链表。 2.1 单链表 单链表之所以叫”单”链表，是因为它的每个节点只保存了指向下一个节点的指针，而没有保存指向它自己的前一个节点的指针。因此在插入节点时，我们必需先获取插入位置之前的节点。 为了方便后续用链表去实现栈和队列，我们在单链表中显示的维护一个 _head 和_tail 的指针用于指向链表的首尾节点，并实现下面三个方法: 在链表的头部插入一个节点 删除链表的头节点 在链表尾部添加一个节点 因为我们必需遍历整个链表才能获取尾节点的前一个节点，所以很难高效的从单链表的尾部删除元素，所以我们不会实现一个删除尾节点的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class Link(object): class _Node(object): __slots__ = "_next", "_element" def __init__(self, element, nxt=None): self._next = nxt self._element = element def __str__(self): a = self._next b = [str(self._element)] while a: b.append(str(a._element)) a = a._next return '-&gt;'.join(b) def __init__(self): self._head = None self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def _insert_tail(self, element): """ :param element: :return: 链表尾部追加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: self._tail._next = node self._tail = node self._size += 1 def _remove_head(self): """ :return: 链表首部删除元素 """ if self.is_empty(): raise ValueError('link is empt') answer = self._head._element self._head = self._head._next self._size -= 1 if self.is_empty(): self._tail = None return answer def _insert_head(self): """ :return: 链表首部添加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: node._next = self._head self._head = node self._size += 1 # 栈方法 pop = _remove_head push = _insert_head # 堆方法 enqueue = _insert_tail dequeue = _remove_head 2.4 循环链表 循环链表跟单链表唯一的区别就在尾结点。单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题 双向链表的实现与单向链表大体上相同，除了尾节点的特殊处理。因此，我们暂时忽略循环链表的实现，等到下一章我们使用一个循环链表来实现一个队列，再来展示循环链表的实现。 2.3 双链表 双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。可以支持双向遍历，这样也带来了双向链表操作的灵活性。链表在插入和删除时必需先找到被操作节点的前驱节点，而单链表并不支持直接获取其前驱节点，必需从头开始重新遍历链表。而双向链表支持双向便利可直接获取，所以操作起来更加灵活。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 在双链表的实现中，我们将引入头哨兵和尾哨兵；使用哨兵可以帮助我们避免处理链表中没有节点时的特殊情况帮助我们简化双向链表的实现。这里可以与上面不使用哨兵的单向链表作对比。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class DoubleLink(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, pre=None, nxt=None): self._element = element self._next = nxt self._pre = pre def __init__(self): self._head = self._Node(None) self._tail = self._Node(None) self._head._next = self._tail self._tail._pre = self._head self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def insert_between(self, element, pre_node, next_node): """ :param element: :param pre_node: :param next_node: :return: 在两个节点之间插入一个节点 """ node = self._Node(element, pre=pre_node, nxt=next_node) pre_node._next = node next_node._pre = node self._size += 1 return node def delete_node(self, node): """ :param node: :return: 删除节点 """ element = node._element node._pre._next = node._next node._next._pre = node._pre self._size -= 1 node._pre = node._next = node._element = None return element 3. 相关算法相比与数组，链表写起来就很复杂，有如下一些算法，可以帮助我们练习链表。为了简化代码实现，下面所有函数的参数 link 都是 下面 Node 类的实例 123456789101112class Node(object): def __init__(self, data=None, nxt=None): self.data = data self.nxt = nxt def __str__(self): a = self.nxt b = [str(self.data)] while a: b.append(str(a.data)) a = a.nxt return '-&gt;'.join(b) 3.1 单链表反转123456789def reverse(link): pre = None pwd = link while pwd: # print pre.data, pwd.data # pwd.nxt, pwd, pre = pre, pwd.nxt, pwd pwd.nxt, pre, pwd = pre, pwd, pwd.nxt # pre, pwd.nxt, pwd = pwd, pre, pwd.nxt return pre 3.2 链表中环的检测12345678def has_cycle(link): one = double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if one is double: return True return False 3.3 两个有序链表的合并123456789101112131415161718def merge(link_one, link_two): link = Node() a = link_one b = link_two c = link while a and b: if a.data &lt; b.data: c.nxt = a a = a.nxt else: c.nxt = b b = b.nxt c = c.nxt if a is not None: c.nxt = a if b is not None: c.nxt = b return link.nxt 3.4 删除链表倒数第 n 个节点12345678910111213141516171819def delete_last(link, n): if link is None: return link pre = None first = link second = link for i in range(1, n): second = second.nxt if second is None: return None while second.nxt: second = second.nxt pre = first first = first.nxt if pre is None: return first.nxt else: pre.nxt = first.nxt return link 3.5 求链表的中间节点123456789101112def get_middle(link): if link is None or link.nxt is None: return link, None one = link double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if double.nxt is None: return one, None else: return one, one.nxt 3.6 基于链表实现 LRU 缓存算法实现思路如下: 我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 下面是相关的代码实现: 1234567891011121314151617181920# 基于双向链表 LinkedListclass LRU(object): def __init__(self, capacity=3): self.capacity = capacity self.num = 0 self.link = LinkedList() def cache(self, value): if self.num &lt; self.capacity: self.link.insert(0, value) self.num += 1 else: if self.link.remove(value): self.link.insert(0, value) else: del self.link[-1] self.link.insert(0, value) def __str__(self): return str(self.link) 实际上，我们可以继续优化这个实现思路，比如引入（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 如何在 Python 中进行单元测试]]></title>
    <url>%2F2018%2F10%2F09%2Funittest%2Funittest_01%2F</url>
    <content type="text"><![CDATA[https://blog.csdn.net/zcabcd123/article/details/54892467]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>unittest</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 数组]]></title>
    <url>%2F2018%2F10%2F08%2Falog%2Farray%2F</url>
    <content type="text"><![CDATA[数组和链表应该是数据结构与算法中最基础的数据结构。与链表相比，数组更加简单，所以相比于数组的实现和与之相关的算法，充分认识数组的内在特性反而更加重要。 1. 特性数组（Array）是一种线性表数据结构，用一组连续的内存空间，来存储一组具有相同类型的数据。正是由于连续的内存空间和存储相同类型数据的特性，使得数组支持基于下标的“随机访问”。但是也正是为了维持这种连续的特性，使得数组的插入和删除操作必需作大量的数据移动，因为数组内不能”弯曲”也不能出现”空洞”。 1.1 插入如果数组是有序的，插入一个新的元素到第 k 位置则必需移动 k 之后的所有数据；但是如果数组中的数据本身是无序的，我们可以直接将第 k 位的数据移动到数组元素的最后，再把新的元素插入到原来的第 k 位以避免大量的数据移动。 1.2 删除数组的删除与插入类似，如果要删除第 k 位的元素，为了保证数组内的连续行，也需要移动大量的数据，不然数组就会出现空洞，内存就不连续了。如果数据内的数据是有序，则这种移动不可避免，如果是数组是无序的，可以直接用数组最后的元素覆盖第 k 位的元素。 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。我们可以将多次删除操作集中在一起执行，来提高删除的效率。我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。 1.3 动态扩容因为需要为数组分配连续的内存空间，因此数组在使用前就需要预先确定好大小。当需要向满的数组中插入数据时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。数组的插入，删除以及由此待来的动态扩容是非常基础的操作，因此大多数编程语言除了基本的底层数组之外，都提供了包含丰富接口的数组容器，方便程序员编程适用，比如 Python 中的列表(list)。 1.4 数组与数组容器的使用选择何时使用数组何时使用编程语言提供的数组容器，专栏-数据结构与算法之美给了下面的一些建议: 容器都有额外的性能损耗，如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 2. 实现列表和元组是 Python 提供的数组容器，它们都是引用结构，即 list 内部的底层数组存储的不是元素本身，而是列表元素的内存地址，这些内存地址指向每个列表元素。 除了数组容器之外，array 和 ctypes 提供了创建原始底层数组(即保存的不是内存地址而是元素本身的原始数组)的方法。array 模块提供的 array 类只支持基于 C 语言的原始数据类型，不支持用户自定义的数据类型，自定义类型的底层数组由 ctypes 这个底层模块提供。 下面我们就以 ctypes 提供的底层数组为基础创建了一个类似 list 的数组容器。这里的实现并不完备，目的是为了展示 Python list 的底层实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import ctypesclass DynamicArray(object): def __init__(self): self._n = 0 # 列表当中实际存储的元素个数 self._capacity = 1 # 当前分配的底层数组，能存储的元素个数 self._buf = self._make_array(self._capacity) # 底层数组的引用 def __len__(self): return self._n def __getitem__(self, item): """ :param item: :return: 简单起见，只支持简单的正向索引 """ if 0 &lt;= item &lt; self._n: return self._buf[item] raise IndexError('%s out of range' % self.__class__.__name__) def append(self, value): if self._n == self._capacity: self._resize(size= 2 * self._capacity) self._buf[self._n] = value self._n += 1 def _resize(self, size): """ :param c: :return: 底层数组的动态扩容 """ buf = self._make_array(size) for i in xrange(self._n): buf[i] = self._buf[i] self._buf = buf self._capacity = size @staticmethod def _make_array(size): """创建一个指定大小的底层数组""" return (size * ctypes.py_object)() def insert(self, k, value): if self._n == self._capacity: self._resize(2 * self._capacity) for i in xrange(self._n, k, -1): self._buf[i] = self._buf[i - 1] self._buf[k] = value self._n += 1 def remove(self, value): """ :param value: :return: 删除第一值等于 value 的元素 """ for i in xrange(self._n): if self._buf[i] == value: for j in xrange(i, self._n - 1): self._buf[j] = self._buf[j + 1] self._buf[self._n - 1] = None # 删除最后一个元素的引用，以便被回收 self._n -= 1 return raise ValueError('value not found') 3. 相关算法与数组专门相关的算法并不多，因为太底层了。这里我们介绍两个: 用数组实现的位图以及凯撒密码 3.1 位图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import arrayimport numbersclass BitMap(object): def __init__(self): self._buf = array.array('L') # 'L' 表示 32 位无符号的整数 @staticmethod def __check(num): if not (isinstance(num, numbers.Integral) and num &gt;= 0): raise ValueError("num is not unsigned int") return num / 32, num % 32 def __len__(self): return len(self._buf) def __getitem__(self, item): return self._buf[item] def __iter__(self): return iter(self._buf) def __contains__(self, item): i, b = self.__check(item) return i &lt; len(self._buf) and (self._buf[i] &amp; (1 &lt;&lt; b)) def __str__(self): r = [] # print self._buf for i in xrange(len(self._buf)): if self._buf[i]: for j in xrange(32): if self._buf[i] &amp; (1 &lt;&lt; j): r.append(32 * i + j) return str(r) def add(self, num): i, b = self.__check(num) while i &gt;= len(self._buf): self._buf.append(0) self._buf[i] |= (1 &lt;&lt; b) def union(self, bit_map): for i, v in enumerate(bit_map): if i &lt; len(self._buf): self._buf[i] |= v else: self._buf.append(v)def main(): bm = BitMap() bm.add(1) bm.add(144) bm.add(9) bm.add(9) print bm print 9 in bm print 8 in bm y = BitMap() y.add(9) y.add(42) print y bm.union(y) print bm 3.2 凯撒密码有关凯撒密码的说明，大家可以看看百科的说明:凯撒密码 12345678910111213141516171819202122class CaesarCipher(object): def __init__(self, shift): self.encode = [(chr(ord('A') + (i + shift) % 26)) for i in range(26)] self.decode = [(chr(ord('A') + (i - shift) % 26)) for i in range(26)] print self.encode print self.decode def encrypt(self, message): return self._transform(message, self.encode) def decrypt(self, message): return self._transform(message, self.decode) @staticmethod def _transform(message, code): m = list(message) r = [] for i in m: if i.isupper(): t = code[ord(i) - ord('A')] r.append(t) return ''.join(r) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 数据结构与算法学习开篇]]></title>
    <url>%2F2018%2F10%2F07%2Falog%2Falgo_start%2F</url>
    <content type="text"><![CDATA[数据结构与算法前前后后已经学习了很长时间，从一开始看《数据结构与算法分析:C语言描述》，到后来看 Python 相关实现《Problem Solving with Algorithms and Data Structures using Python》，但是一直感觉不得其法。 究其原因，一方面是自己对 C 语言一知半解，所以一开始练习太少；另一方面是工作中使用太少，知识这种东西只有到达一定的熟练程度才能真正发现其作用。现在有幸在极客时间订阅了王争老师的专栏数据结构与算法之美，看过之后感觉很好，相比与之前看的书籍有很好的发散和扩展，恰逢《数据结构与算法：python语言实现》也刚刚面市。所以决定下定决心在 2018 最后三个月好好重新学习数据结构与算法。因此就有了这个系列的博客，希望监督自己多加练习。 本系列博客会按照专栏数据结构与算法之美的结构组织，也会从中摘录部分内容，在此特地申明，也非常推荐大家订阅此专栏。然后会以《数据结构与算法：python语言实现》作为辅助来扩展内容，并且在每篇文章的最后，我会尽可能给出与当篇文章相关的 linkcode 习题。 当然作为自己的博客，目的不是复制别人的内容，是想对常用的数据结构作一个总结，然后督促自己动手实现这些数据结构和算法。最后想说一句，数据结构和算法看起来没用，我们平时大多数使用的都是语言内置好的容器和现成的函数，我们只需要知道它们的功能，无需关注它们的实现细节，我们也能写出我们的程序。但是程序的效率很大程度上依赖锁使用组件的效率，我们不关注这些细节，可能别人已经写好了，但是我们却没正确的使用。Python 就有以本书叫《Python: Faster Way》，如果我们对 Python 常见数据结构有所了解，其时很自然的就会明白它们上面所说明的用法。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor tornado 部署]]></title>
    <url>%2F2018%2F09%2F21%2Fdeploy%2Fsupervisor_tornado%2F</url>
    <content type="text"><![CDATA[通过 supervisor 创建监听套接字的文件描述符，为多个 tornado 进程共享 1. tornado 启动12345678910111213from tornado.netutil import set_close_execdef main(): app = AnalyticApiApplication() http_serve = httpserver.HTTPServer(app) # http_serve.listen(options.port) # supervisor 创建的监听套接字文件描述符，通过 0 号传递给 tornado的所有进程 sock = socket.fromfd(0, family=socket.AF_INET, type=socket.SOCK_STREAM) set_close_exec(sock.fileno()) sock.setblocking(0) # 设置套接字为非阻塞调用 http_serve.add_socket(sock) ioloop.IOLoop.instance().start() 2. supervisor 配置12345678command=/home/tao/.local/bin/pipenv run python app.py --connect=local-dev --debug=1socket=tcp://localhost:8888directory=/home/tao/projects/analytics_apiuser=taonumprocs=4process_name=%(program_name)s_%(process_num)02dstdout_logfile =/var/log/tornado_pyapi_stdout_%(process_num)02d.log stderr_logfile =/var/log/tornado_pyapi_stderr_%(process_num)02d.log 3. tornado.bind_socket12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False): """Creates listening sockets bound to the given port and address. Returns a list of socket objects (multiple sockets are returned if the given address maps to multiple IP addresses, which is most common for mixed IPv4 and IPv6 use). Address may be either an IP address or hostname. If it's a hostname, the server will listen on all IP addresses associated with the name. Address may be an empty string or None to listen on all available interfaces. Family may be set to either `socket.AF_INET` or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise both will be used if available. The ``backlog`` argument has the same meaning as for `socket.listen() &lt;socket.socket.listen&gt;`. ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``. ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket in the list. If your platform doesn't support this option ValueError will be raised. """ if reuse_port and not hasattr(socket, "SO_REUSEPORT"): raise ValueError("the platform doesn't support SO_REUSEPORT") sockets = [] if address == "": address = None if not socket.has_ipv6 and family == socket.AF_UNSPEC: # Python can be compiled with --disable-ipv6, which causes # operations on AF_INET6 sockets to fail, but does not # automatically exclude those results from getaddrinfo # results. # http://bugs.python.org/issue16208 family = socket.AF_INET if flags is None: flags = socket.AI_PASSIVE bound_port = None for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags)): af, socktype, proto, canonname, sockaddr = res if (sys.platform == 'darwin' and address == 'localhost' and af == socket.AF_INET6 and sockaddr[3] != 0): # Mac OS X includes a link-local address fe80::1%lo0 in the # getaddrinfo results for 'localhost'. However, the firewall # doesn't understand that this is a local address and will # prompt for access (often repeatedly, due to an apparent # bug in its ability to remember granting access to an # application). Skip these addresses. continue try: sock = socket.socket(af, socktype, proto) except socket.error as e: if errno_from_exception(e) == errno.EAFNOSUPPORT: continue raise set_close_exec(sock.fileno()) if os.name != 'nt': sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if reuse_port: sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) if af == socket.AF_INET6: # On linux, ipv6 sockets accept ipv4 too by default, # but this makes it impossible to bind to both # 0.0.0.0 in ipv4 and :: in ipv6. On other systems, # separate sockets *must* be used to listen for both ipv4 # and ipv6. For consistency, always disable ipv4 on our # ipv6 sockets and use a separate ipv4 socket when needed. # # Python 2.x on windows doesn't have IPPROTO_IPV6. if hasattr(socket, "IPPROTO_IPV6"): sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1) # automatic port allocation with port=None # should bind on the same port on IPv4 and IPv6 host, requested_port = sockaddr[:2] if requested_port == 0 and bound_port is not None: sockaddr = tuple([host, bound_port] + list(sockaddr[2:])) sock.setblocking(0) sock.bind(sockaddr) bound_port = sock.getsockname()[1] sock.listen(backlog) sockets.append(sock) return sockets]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>supervisor</tag>
        <tag>tornado</tag>
        <tag>部署工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 wrapt 模块使用]]></title>
    <url>%2F2018%2F09%2F20%2Fwrapt%2Fpython_decorator_15%2F</url>
    <content type="text"><![CDATA[GrahamDumpleton wrapt blog 的翻译部分到此就结束。很可惜的是作者并没有把猴子补丁部分写完，查阅了 wrapt 的官方文档，上面只介绍了 wrapt 的装饰器，代理对象以及 synchronized 同步装饰器，也没有介绍猴子补丁相关内容。不过已经介绍的内容足够用了，接下来我想结合 wrapt 的文档介绍一下 wrapt 模块的使用，算是整个博客的总结。 1. 前文回顾在阐述 wrapt 的使用之前，有必要对之前的内容做一个简单总结，因为 wrapt 模块的接口正是与之前的内容一一对应的。GrahamDumpleton 编码 wrapt 的本意是想实现为 Python 代码中添加猴子补丁，然而 Python 中装饰器，辅助测试的模拟库与猴子补丁的实现方式极其相似，因此 GrahamDumpleton 就按照如下的方式为将我们讲解了 wrapt 模块的功用。 如何在 Python 实现一个通用的装饰器 如何使用 wrapt 实现模拟库来辅助单元测试 如何为 Python 添加猴子补丁 装饰器，模拟库，猴子补丁的实现是递进的。装饰器通常是在导入时，在被装饰的函数定义之后立即运行，且永久全局有效；模拟库作用的范围变窄，需要实现只作用于特定范围，比如特定的测试函数中；猴子补丁更随意，通常在类创建一段时间之后再执行，这种延迟性导致猴子补丁存在相对导入的次序问题。对于我们而言搞清楚装饰器与模拟库的使用即可，能使用到猴子补丁的情景少之又少。 装饰器那如何实现一个装饰器？传统的通过闭包实现的装饰器存在以下问题: 无法保留函数的自省属性和签名信息，无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 为解决这些问题和解决代码复用问题，wrapt 创建了以下对象或函数: 代理对象: ObjectProxy，解决了自省问题 包装对象: FunctionWrapper, BoundFunctionWrapper 继承自 ObjectProxy，并为装饰行为实现了描述符协议 工厂函数: decorator 解决了创建装饰器的代码复用问题。 wrapt 为辅助单元测试提供了另外一个工厂函数 transient_function_wrapper，其能创建一个仅仅限于特定范围的临时补丁。 装饰器实现的核心就是包装器对象，它同时接收包装函数，和被包装函数，并作为装饰结果的返回值替换被包装函数。在被包装函数被调用时，实际调用包装函数。所以包装对象同时实现了对象代理和描述符协议。 2. wrapt 接口123456789101112# wrapt.__init__from .wrappers import (ObjectProxy, CallableObjectProxy, FunctionWrapper, BoundFunctionWrapper, WeakFunctionProxy, resolve_path, apply_patch, wrap_object, wrap_object_attribute, function_wrapper, wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper)from .decorators import (adapter_factory, AdapterFactory, decorator, synchronized)from .importer import (register_post_import_hook, when_imported, notify_module_loaded, discover_post_import_hooks) wrapt 模块提供的接口大体上分成了以下几类: 代理对象: ObjectProxy, CallableObjectProxy, WeakFunctionProxy 包装对象: FunctionWrapper, BoundFunctionWrapper 装饰器工厂函数: function_wrapper, decorator 辅助测试的工厂函数: wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper 猴子补丁相关: .importer synchronized: java synchronized 的 Python 实现 接下来我们会详细介绍上述典型接口的使用方式。 2. 代理对象 ObjectProxy所谓代理包含两个层面的意思: 将上层的请求传递给后端的对象 将后端对象的返回值返回给上层的调用方 wrapt 模块的底层实现就是基于透明对象代理的包装器类。这种代理对象不仅代理了普通方法和属性的访问，也代理了众多内置方法和自省属性。这使得代理对象和被代理对象在 Python 的数据模型层面是完全一致。使用代理对象去代替被代理对象不会打破 Python 的内省机制。并且我们可以在代理对象上自定义属性和方法，以此来重载被代理对象的默认功能。 2.1 对象联动123456class ObjectProxy(with_metaclass(_ObjectProxyMetaType)): __slots__ = '__wrapped__' def __init__(self, wrapped): object.__setattr__(self, '__wrapped__', wrapped) ObjectProxy 是 wrapt 代理功能实现的基类，通常不直接使用，而是作为自定义代理对象的基类使用。代理对象实现了如下功能: 所有对代理对象的访问都会传递给被代理对象，包括比较操作，哈希这些 Python 的内置方法 在代理对象上自定义的方法会覆盖被代理对象同名方法，因此我们可以通过代理对象实现对被代理对象的方法重载 所有对代理对象属性的修改都会传递并修改后端的被代理对象 对后端被代理对象属性的直接修改也会直接反映在代理对象之上 也就是说默认情况下，对 ObjectProxy 的操作，方法是重载的，而对属性的修改，是直接作用在被代理对象上的。 123456789101112&gt;&gt;&gt; table = &#123;&#125;&gt;&gt;&gt; proxy = wrapt.ObjectProxy(table)&gt;&gt;&gt; proxy['key-1'] = 'value-1'&gt;&gt;&gt; proxy['key-2'] = 'value-2'&gt;&gt;&gt; proxy.keys()['key-2', 'key-1']&gt;&gt;&gt; table.keys()['key-2', 'key-1']&gt;&gt;&gt; isinstance(proxy, dict)True 2.2 不可变对象上述操作对于不可变对象的自操作是特例。 1234567891011121314&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; proxy += 1&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; print(proxy)2&gt;&gt;&gt; print(value)1 对于不可变对象，被代理对象保存的被代理对象的副本，因此对其自身的修改不会影响到后端的被代理对象。 2.3 类型比较由于 Python 复杂的对象模型和底层设计，以及 instance 函数内在比较逻辑，想把 ObjectProxy 类型比较的原理说清楚实在不容易。这里就不深入见解了，简而言之 ObjectProxy 类实例的__class__ 属性返回的是被代理对象的__class__ 属性值，instance()在进行类型检查时，首先比较的是 __class__，所以对代理对象进行类型比较的结果与以被代理对象本身进行比较的结果完全一致。同时由于抽象基类机制，ObjectProxy 实例与 ObjectProxy 类的类型比较也能正常进行。 12345678910111213141516171819202122232425&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; class CustomProxy(wrapt.ObjectProxy):... pass&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; type(proxy)&lt;class '__main__.CustomProxy'&gt;# 与被代理对象的类型比较&gt;&gt;&gt; proxy.__class__&lt;type 'int'&gt;&gt;&gt;&gt; isinstance(proxy, int)True# 与代理对象的类型比较&gt;&gt;&gt; isinstance(proxy, wrapt.ObjectProxy)True&gt;&gt;&gt; isinstance(proxy, CustomProxy)True 2.4 方法重载方法重载只要在自定义代理对象上自定义同名的方法即可，在代理对象内，通过 __wrapped__ 属性可以访问到原始的被代理的对象。 123456789101112131415161718def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __call__(self, *args, **kwargs): print('entering', self.__wrapped__.__name__) try: return self.__wrapped__(*args, **kwargs) finally: print('exiting', self.__wrapped__.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function)&gt;&gt;&gt; proxy()('entering', 'function')('executing', 'function')('exiting', 'function') 2.5 属性重载因为对 ObjectProxy 属性的访问都会直接代理至后端被代理对象，那如何自定义 ObjectProxy 自身的属性呢？ 方法一，任何以 _self_ 开头的属性只会保存在 ObjectProxy 上，不会传递给后端的被代理对象 12345678910111213141516171819202122232425262728def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs)def wrapper(wrapped, args, kwargs): print('entering', wrapped.__name__) try: return wrapped(*args, **kwargs) finally: print('exiting', wrapped.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function, wrapper)&gt;&gt;&gt; proxy._self_wrapper&lt;function wrapper at 0x1005961b8&gt;&gt;&gt;&gt; function._self_wrapperTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function' object has no attribute '_self_wrapper' 方法二，借助于 @property，定义属性描述符1234567891011121314151617181920212223242526272829class CustomProxy(wrapt.ObjectProxy): def __init__(self, wrapped): super(CustomProxy, self).__init__(wrapped) self._self_attribute = 1 @property def attribute(self): return self._self_attribute @attribute.setter def attribute(self, value): self._self_attribute = value @attribute.deleter def attribute(self): del self._self_attribute&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; print proxy.attribute1&gt;&gt;&gt; proxy.attribute = 2&gt;&gt;&gt; print proxy.attribute2&gt;&gt;&gt; del proxy.attribute&gt;&gt;&gt; print proxy.attributeTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'int' object has no attribute 'attribute' 方法三，将属性定义为类属性123456789101112131415&gt;&gt;&gt; class CustomProxy(ObjectProxy):... attribute = None...&gt;&gt;&gt; def function():... print('executing', function.__name__)...&gt;&gt;&gt; j = CustomProxy(function)&gt;&gt;&gt; j.attribute = 2&gt;&gt;&gt;&gt;&gt;&gt; function.attribute = 5&gt;&gt;&gt; print(j.attribute)2&gt;&gt;&gt; print(function.attribute)5 3. 扩展的代理对象除了默认 ObjectProxy 代理基类，wrapt 还提供了另外两个通用的代理对象。 3.1 CallableObjectProxy1234class CallableObjectProxy(ObjectProxy): def __call__(self, *args, **kwargs): return self.__wrapped__(*args, **kwargs) CallableObjectProxy 代理对象专用于代理函数，只是额外的附加了__call__方法，让代理对象成为可调用对象。 3.2 WeakFunctionProxy123456# 代理有点长，不粘了，有兴趣查看 wrapt 的源码class WeakFunctionProxy(ObjectProxy): __slots__ = ('_self_expired', '_self_instance') def __init__(self, wrapped, callback=None): 默认情况下，代理对象通过 __wrapped__ 属性保存了对被代理对像的引用，这样会导致被代理对象始终被引用而无法被垃圾处理器收回，WeakFunctionProxy 的作用就是实现在代理对象中实现对被代理对象的弱引用。在代理对象中实现弱引用并不容易，特别是对绑定方法对象的处理，以及要避免在回调函数中出现循环引用。有兴趣的同学可以看看 wrapt 的源代码。 3.3 自定义代理对象如上述两个内置扩展的代理对象，通过继承 ObjectProxy，我们也可以自定代理对象。代理对象中的方法会覆盖被代理对象的同名方法，利用这个特性我们可以重载被代理对象的行为，这在单元测试中经常使用，待会会有使用的详细示例。 4. 包装对象下面是在代理对象基础上实现包装器的简单示例，包装器继承自 wrapt.ObjectProxy，并将被代理对象作为参数传递给 ObjectProxy，从而具备了代理功能，并在此基础上附加了描述协议的处理逻辑。我们需要使用或者自定义包装对象的情景很少，此处不再对其作过多描述。 123456789101112class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __get__(self, instance, owner): function = self.__wrapped__.__get__(instance, owner) return BoundCallableWrapper(function, self._self_wrapper) def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs) 5. 辅助测试5.1 工厂函数wrapt 中有三个辅助测试的包装对象 wrapt.wrap_function_wrapper: 创建猴子补丁的工厂函数，会创建永久有效的补丁 wrapt.patch_function_wrapper: 简化 wrapt.wrap_function_wrapper 的装饰器函数 wrapt.transient_function_wrapper: 创建一个仅仅限于特定范围的临时补丁 下面是它们的使用实例 1234567891011121314151617181920212223242526def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)class Example(object): def name(self): return 'name'import wrapt# 版本一wrapt.wrap_function_wrapper(Example, 'name', wrapper) # 等同于wrapt.wrap_function_wrapper('example', 'Example.name', wrapper)# 版本二@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)# 版本三，wrapper 只对 test_method() 函数有效@transient_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@wrapper def test_method(): pass 5.2 高阶用法除了上述简单的使用示例外，12 使用 wrapt 辅助测试 还有更高级的使用示例，下面是示例代码。 包装一个返回函数的被包装对象12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 包装一个类示例的被包装对象123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 6. synchronizedsynchronized 装饰器实现了 java 中的同步原语 synchronized 功能。synchronized 功能和实现请参阅 07 实现 java 的 @synchronized 装饰器，下面是其使用方式 6.1 作为装饰器123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 6.2 作为上下文管里器1234567891011121314151617181920class Class(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): passclass Class(object): @synchronized @classmethod def function_cm(cls): pass def function_im(self): with synchronized(Class): pass 6.3 基于任意对象作同步除了使用默认的内置锁，synchronized 支持接收任意对象实现同步。但是作为同步而传入的对象必需能添加属性，因为 synchronized 会在传入的对象上保存创建的锁对象。因此为解除这个限制，synchronized 也支持传入支持 .require 和 .release 的类锁对象实现同步。 123456789101112131415161718192021class Data(object): passdata = Data()def function_1(): with synchronized(data): passdef function_2(): with synchronized(data): pass# synchronized 使用到了 vars(data)，任何没有 `__dict__` 属性的对象，都会调用失败&gt;&gt;&gt; vars(&#123;&#125;)Traceback (most recent call last): File "/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2882, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-3-880c6250c41c&gt;", line 1, in &lt;module&gt; vars(&#123;&#125;)TypeError: vars() argument must have __dict__ attribute 6.4 基于传入的类锁对象作同步12345semaphore = threading.Semaphore(2)@synchronized(semaphore)def function(): pass 任何支持 acquire() 和 release() 对象均可作为 synchronized的参数，因此用户可传入包含这两个方法的自定义对象来实现额外的功能。 7. decorator12def decorator(wrapper=None, enabled=None, adapter=None): pass decorator 工厂函数是 function_wrapper 工厂函数的升级版本，在装饰器基础上添加了另外两个控制功能，enabled 和 adapter参数必需作为关键词参数被使用。 7.1 装饰启动开关静态控制enabled 参数用于控制装饰器是否被启用，接收布尔值作为参数，enabled=True 时，装饰器正常启用，enabled=False 时不会应用任何包装器。因此，这提供了一种方便的方法，可以全局禁用特定的decorator，而不必删除decorator的所有用法，或者使用decorator函数的特殊变体。 123456789101112ENABLED = False@wrapt.decorator(enabled=ENABLED)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@pass_throughdef function(): pass&gt;&gt;&gt; type(function)&lt;type 'function'&gt; 动态控制在定义修饰符时为启用的选项提供一个布尔值，从而控制修饰符是否应该应用。因此，这是一个全局开关，一旦禁用，就无法在运行时在进程执行时动态地重新启用它。类似地，一旦启用，就不能禁用它。 提供布尔值的另一种方法是为enabled提供一个可调用对象 callable，该值返回一个布尔值。每次调用修饰函数时都将调用callable。如果callable返回True，表示decorator是活动的，则将调用包装器函数。如果callable返回False，包装器函数将被绕过，原始包装函数将被直接调用。 如果enabled不是None、布尔值或可调用值，则将对提供的对象执行布尔检查。这允许使用支持逻辑操作的定制对象。如果定制对象计算为False，包装器函数将再次被绕过。 123456def _enabled(): return True@wrapt.decorator(enabled=_enabled)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 7.2 更改签名信息默认的包装函数的签名来自被包装对象，adapter 参数的作用用于修改包装函数的签名信息。其接收一个函数作为参数，此函数的签名信息将作为包装函数的签名信息被返回。这个用的很少，就不再累述了。 实战有关 wrapt 的模块的实现和接口到此就介绍完了，在本系列博客的开篇我提到了我使用装饰器的一个典型应用场景: 对数据库查询实现分批操作。在接下来的的博客中，作为实战篇，我们来看看如何通过 wrapt 实现这个比较通用的需求。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 wrapt 模块实战]]></title>
    <url>%2F2018%2F09%2F20%2Fwrapt%2Fpython_decorator_16%2F</url>
    <content type="text"><![CDATA[装饰器和 wrapt 模块的介绍已经结束，作为整个系列的最后一篇的实战篇，我们来实现在一开始我提出的一个需求 1. 应用场景在我日常的开发过程中，经常要查询各种数据库，比如 mysql, mongo，es 。基本上所有的数据库对查询语句能添加的查询条件都有限制。对于大批量的查询条件，只能分批多次查询，然后将查询结果合并。我们能不能将这种查询分批在合并的操作抽象出来实现为一个装饰器，在需要时对查询函数包装即可？下面是我的一个实现示例。 2. 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/usr/bin/python# -*- coding: utf-8 -*-"""作用：用于优化的装饰器功能： 1. 实现分组迭代，分批查询的装饰器"""import osimport sysimport wraptimport inspectimport pandasdef get_slice(total_num, slice_num): """ :return: 等大小切片 """ r = [] n = total_num / slice_num m = total_num % slice_num end = 0 for i in range(1, n + 1): start = slice_num * (i - 1) end = slice_num * i r.append(slice(start, end)) else: if m &gt; 0: r.append(slice(end, end + m)) return rdef slice_call(iter_param, slice_num=500): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 函数自省 param = inspect.getcallargs(wrapped, *args, **kwargs) if instance: param.pop('self') if 'kwargs' in param: kwargs = param.pop('kwargs',&#123;&#125;) param.update(kwargs) iter_value = param.get(iter_param) if iter_value is None: return wrapped(**param) if isinstance(iter_value, pandas.DataFrame): iter_value.reset_index(drop=True, inplace=True) # 分批 total_num = len(iter_value) slice_iter = get_slice(total_num, slice_num) result = [] # 合并 for s in slice_iter: param[iter_param] = iter_value[s] result.append(wrapped(**param)) if result: return pandas.concat(result) else: return pandas.DataFrame() return wrapper# slice_call 使用示例@slice_call(iter_param='names')def get_video_by_name(self, names, c_type): where_name = "'" + "','".join(names) + "'" sql = ('select * from table' 'where a="%s" and b in (%s) and c&gt;=0;' % (c_type, where_name)) print sql df = self.mysql_obj.query('', sql) df['updateTime'] = df['updateTime'].apply(lambda x: x.strftime("%Y-%m-%d")) return df slice_call 函数在使用有一个限制条件，被包装函数的返回值必需是 pandas.DataFrame。因为在我日常的工作中，经常使用到 pandas 进行数据分析，对我来说，DataFrame 是一个非常通用的数据结构，因此就在此基础上构建了 slice_call 装饰器。整个实现中使用的额外知识就是函数的自省，由 inspect 模块提供，其他有关装饰器的部分都是前面博客介绍的内容，相信大家应该很容易就能看懂。 结语至此 Python 装饰器的内容就先到此为止，接下来想结合 wrapt, unittest, mock 来说一说如何在 Python 中作单元测试。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 为 Python 应用自动打补丁]]></title>
    <url>%2F2018%2F06%2F05%2Fwrapt%2Fpython_decorator_14%2F</url>
    <content type="text"><![CDATA[前面我们已经决绝了猴子补丁的导入次序问题，但是这个解决方案有个前提，就是我们必需能修改应用程序代码，以在程序的最开始执行我们的注册函数。本节我们的目的是找到另一种解决方案取消这个限制。 1. 猴子补丁的问题所在在之前关于猴子的文章中，我们讨论了导入次序问题。也就是说，正确使用猴子补丁取决于，我们能在任何其他代码导入我们想要修补的模块之前为其打上打补丁。换句话说就是在我们打补丁之前，其他代码是否已经按名称导入了对模块内函数的引用，并将其存储在它自己的名称空间中。即在打补丁之前，其他模块是否已经使用了 from module import function 如果我们不能尽早进入，那么就需要对目标函数的所有使用打补丁，这在一般情况下是不可能的，因为我们不知道函数在哪里被导入。我所描述的一种解决方案是使用导入后钩子机制，使我们能够在模块被任何代码导入之前访问模块并打补丁。这种技术仍然依赖于在有效运行其他代码之前安装导入后钩子机制本身。这意味着必须手动修改应用程序的主Python脚本文件，这并不总是实用的。本文的目的是研究如何避免修改主Python脚本文件来解决导入次序问题。 2. 在 .pth 文件中执行代码作为Python导入系统的一部分，以及在哪些目录中搜索Python模块，有一种扩展机制，即可以将一个.pth扩展名文件安装到Python的site-packages目录中。用于指明Python包代码并不在默认的Python模块搜索路径上，而是存在于其他位置，通常是在site-packages的子目录中。.pth文件的目的是充当指向Python包的实际代码的指针。 在简单的情况下，.pth文件将包含与包含Python包代码的实际目录的名称相关的或绝对的路径名。如果它是一个相对路径名，那么它将相对于.pth文件所在的目录。 如果使用 .pth，当Python 解释器初始化时，它会创建Python模块的搜索路经，在添加所有默认搜索目录后，它将查找 site-packages内的所有目录，并解析每一个 .pth 文件，并将 .pth 内的目录添加到最后的搜索目录列表中。 现在，在Python的历史中，这个.pth机制被增强了，以支持一个特殊的情况。这种特殊情况是，如果.pth文件中的一行从导入开始，那么该行将作为Python代码执行，而不是简单地将其作为目录添加到要搜索模块的目录列表中。 这最初是为了允许为模块执行特殊的启动代码，以允许为Unicode注册一个非标准的编解码器。不过，它后来也被用于easy_install的实现中，如果您曾经运行过easy-install并查看了site-packages目录中的easy-install.pth文件，您会发现以下代码: 123import sys; sys.__plen = len(sys.path)./antigravity-0.1-py2.7.eggimport sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new) 因此，只要能够将代码放在一行上，就可以在每次运行Python解释器时，在.pth文件中做一些非常古怪的事情。我(作者)认为可执行代码在.pth文件中的概念是非常危险的，到目前为止，我(作者)一直避免依赖.pth文件的这个特性。 我(作者)对.pth文件中的可执行代码的担心是它总是在运行。这意味着，即使您已经将预构建的RPM/DEB包或Python wheel 安装到系统中的Python安装环境中，并且认为这样做更安全，因为避免了作为根用户运行 setup.py。但是.pth文件意味着包仍然可以在您不知情的情况下运行代码，甚至不需要将模块导入任何应用程序。考虑到安全性，Python真应该有一个白名单机制，用于确定信任哪些.pth文件，以允许其在每次运行Python解释器(特别是作为根用户)时执行代码。 如果有人关心的话，我将把这个讨论留给其他人来讨论，至少现在我将展示如何使用.pth文件的这个特性(滥用)来实现对正在运行的任何Python应用程序进行自动的猴子补丁的机制。 3. 添加导入勾子在前一篇文章中，我们讨论的导入后钩子机制，在任何Python应用程序脚本文件的开头，我都需要手动添加如下代码: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 它所做的是使用环境变量作为任何使用setuptools入口点注册的包的名称来源，这些入口点包含我们想要应用的猴子补丁。 了解了可以在.pth文件执行代码的能力,现在可以使用它，让这段代码在Python解释器启动时自动执行,从而避免了每次都需要手动修改每个Python应用程序，来应用我们的猴子补丁。 但是在实践中，我们需要的代码实际上要比这个稍微复杂一些，并且不能很容易地直接添加到.pth文件中，这是由于需要将所有代码写在一行上。因此，我们要做的是将所有代码放在一个单独的模块中，然后执行该模块。我们不希望每次都导入那个模块，也许用户看到它被导入时会感到害怕，即使它没有被使用，所以我们将通过环境变量的判断使用它。因此，我们可以在我们的.pth中使用的是: 1import os, sys; os.environ.get('AUTOWRAPT_BOOTSTRAP') and __import__('autowrapt.bootstrap') and sys.modules['autowrapt.bootstrap'].bootstrap() 也就是说，如果环境变量被设置为非空值，那么我们需要导入包含引导代码的模块并执行它。至于引导代码，这就有点麻烦了。我们不能只使用以前手动修改Python应用程序脚本文件时使用的代码。这是因为.pth文件的解析发生在Python解释器初始化。 问题有两个。第一个问题发生在执行导入钩子的发现，当.pth文件被执行时，它被处理的顺序是未知的，所以在我们的代码运行的时候，最终的Python模块搜索路径可能没有设置。第二个问题是.pth文件的处理发生在任何sitecustomize.py或usercustomize.py被处理完之前。因此，Python解释器可能不在其最终配置状态。因此，我们必须对我们所做的事情小心一点。 我们真正需要的是将任何操作延迟到Python解释器的初始化完成之后。问题是我们如何做到这一点。 4. site 模块Python解释器初始化的最后部分是由site 模块的main()函数完成的 1234567891011121314151617181920212223def main(): global ENABLE_USER_SITE abs__file__() known_paths = removeduppaths() if ENABLE_USER_SITE is None: ENABLE_USER_SITE = check_enableusersite() known_paths = addusersitepackages(known_paths) known_paths = addsitepackages(known_paths) if sys.platform == 'os2emx': setBEGINLIBPATH() setquit() setcopyright() sethelper() aliasmbcs() setencoding() execsitecustomize() if ENABLE_USER_SITE: execusercustomize() # .pth 在此之后执行 # Remove sys.setdefaultencoding() so that users cannot change the # encoding after initialization. The test for presence is needed when # this module is run as a script, because this code is executed twice. if hasattr(sys, "setdefaultencoding"): del sys.setdefaultencoding 我们希望依赖的.pth解析和代码执行是在addsitepackages()函数中完成的。因此，我们真正需要的是将代码的任何执行推迟到execsitecustomize()中或execusercustomize()函数运行之后。实现这一点的方法是对这两个函数进行修改，并在它们完成时触发我们的代码。 我们需要都打上补丁，因为usercustomize.py的执行是可选的，取决于ENABLE_USER_SITE环境变量是否为真。因此，我们的bootstrap()函数应该如下 1234567891011121314151617181920def _execsitecustomize_wrapper(wrapped): def _execsitecustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: if not site.ENABLE_USER_SITE: # 判断 _register_bootstrap_functions() return _execsitecustomizedef _execusercustomize_wrapper(wrapped): def _execusercustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: _register_bootstrap_functions() return _execusercustomizedef bootstrap(): site.execsitecustomize = _execsitecustomize_wrapper(site.execsitecustomize) site.execusercustomize = _execusercustomize_wrapper(site.execusercustomize) 尽管我曾经说过手工构建的猴子补丁有多糟糕，并且wrapt模块应该用于创建猴子补丁，但是在这种情况下，我们实际上不能使用wrapt模块。这是因为从技术上讲，作为用户安装的包，wrapt包此时可能不能使用。如果wrapt的安装方式是这样的，那么导入它的能力本身就依赖于.pth文件的处理。因此，我们使用一个函数闭包来使用简单的包装器。 在实际的包装器中，您可以看到两个包装器中哪个最终调用 _register_bootstrap_functions() 取决于ENABLE_USER_SITE是否为真，如果启用了对usersitecustomize()的支持，那么只能在execsitecustomize()中调用它。 最后，我们现在将_register_bootstrap_functions() 定义为: 1234567891011_registered = Falsedef _register_bootstrap_functions(): global _registered if _registered: return _registered = True from wrapt import discover_post_import_hooks for name in os.environ.get('AUTOWRAPT_BOOTSTRAP', '').split(','): discover_post_import_hooks(name) 5. 初始化包我们已经解决了所有问题，但是如何安装它，特别是如何安装自定义的.pth文件。为此我们使用一个设置.py文件: 12345678910111213141516import sysimport osfrom setuptools import setupfrom distutils.sysconfig import get_python_libsetup_kwargs = dict( name = 'autowrapt', packages = ['autowrapt'], package_dir = &#123;'autowrapt': 'src'&#125;, data_files = [(get_python_lib(prefix=''), ['autowrapt-init.pth'])], entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, install_requires = ['wrapt&gt;=1.10.4'],)setup(**setup_kwargs) 为了安装.pth，我们使用了setup()调用的data_files参数。使用distutils.sysconfig模块中的get_python_lib()函数确定安装文件的实际位置。前缀“空字符串”的参数确保了Python包安装的路经为 site-packages 的相对路径，而不是绝对路径。** 安装这个包时非常重要的一点是，您不能使用easy_install或python setup.py安装。只能使用pip安装这个包。 这样做的原因是，如果不使用pip，那么包安装工具可以将包安装为egg。在这种情况下，自定义.pth文件实际上将安装在egg目录中，而不是实际安装在site-packages目录中。 .pth文件只有被添加到 site-packages 目录中，才能用于映射autowrapt包存在的子目录。从site模块调用的addsitepackages()函数并不会处理包含在.pth文件添加的目录中的.pth文件，因此我们的自定义.pth文件将被跳过。** 在使用“pip”时，默认情况下不使用eggs，所以可行。 还要注意的是，这个包不能与buildout一起工作，因为它总是将包作为eggs安装，并且在Python 安装环境中安装任何脚本时，都会显式地设置Python模块搜索路径本身。 6. 使用示例此软件包的实际完整源代码可在: https://github.com/GrahamDumpleton/autowrapt 这个包也在PyPi上作为autowrapt发布，因此您可以尝试它，如果您真的想使用它的话。为了方便快速地测试它是否有效，autowrapt包打包了一个示例monkey patch。在上面的setyp.py被设置如下:** 1entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, 这个entry point 定义了一个名为autowrapt.examples的猴子补丁。定义了当导入 this 模块时，模块autowrapt.examples中的猴子补丁函数autowrapt_this()将被执行。** 所以要运行这个测试需要: pip install autowrapt 如果没有所需的最小版本，也应该安装wrapt模块。现在正常运行命令行解释器，并在提示符处执行: import this 这应该会显示Python的Zen。退出Python解释器，现在运行: AUTOWRAPT_BOOTSTRAP=autowrapt.examples python 这将再次运行Python解释器，并将环境变量AUTOWRAPT_BOOTSTRAP设置为autowrapt.examples,以匹配在setup.py中为autowrapt定义的entry point。autowrapt_this()”函数的实际代码是: 1234from __future__ import print_functiondef autowrapt_this(module): print('The wrapt package is absolutely amazing and you should use it.') 所以如果我们再一次运行: import this 我们现在应该看到Python Zen的扩展版本。在本例中，我们实际上并没有对目标模块中的任何代码打补丁，但它显示了补丁函数实际上是按预期被触发。 7. 其他机制虽然这种机制相当干净，并且只需要设置环境变量，但是不能像前面提到的那样与buildout一起使用。对于buildout，我们需要研究其他可以实现同样效果的方法。我将在下一篇关于这一主题的博文中讨论这些其他选择。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 猴子补丁在 Python 中的加载次序问题]]></title>
    <url>%2F2018%2F06%2F04%2Fwrapt%2Fpython_decorator_13%2F</url>
    <content type="text"><![CDATA[本节我们就来解决如何在 Python 中打补丁的问题。 1. 猴子补丁的加载次序问题在第 11 篇博客中，我们提到了应用猴子补丁时可能存在的问题。具体地说，如果需要被打补丁的模块已经被导入并被其他代码使用，那么它可能已经在自己的名称空间中创建了一个被打补丁的目标函数的本地引用。因此，尽管猴子补丁可以正常工作，但是仍然无法覆盖这种原始函数已经导入，并过通过本地引用直接访问原始函数的情况。 导入次序问题的解决方案之一是所谓的导入钩子。这是在PEP 369中描述的一种机制，虽然它从未进入Python核心，但是仍然可以使用现有的api将这种能力移植到Python中。然后，在模块导入目标函数并在自己的名称空间中创建对函数的引用之前，我们可以添加其他功能来发现猴子补丁代码，并在导入模块时自动应用它。 Post import hook mechanism暂时将 “Post import hook” 称为导入后勾子。导入后勾子机制在 PEP 369 中有一个使用示例: 12345import imp@imp.when_imported('decimal')def register(decimal): Inexact.register(decimal.Decimal) 其基本思想是，当看到这段代码时，它将导致在Python导入系统中注册一个回调，以便在导入decimal模块时，调用装饰器应用的register()函数。register()函数的参数是对被注册的模块的引用。然后，该函数可以对模块执行一些操作，最后再将模块返回到最初请求导入的代码中。除了使用作为装饰器的@imp.where_imported函数 ，还可以显式地使用imp.register_post_import_hook() 函数来注册导入后钩子。 123456import impdef register(decimal): Inexact.register(decimal.Decimal)imp.register_post_import_hook(register, 'decimal') 尽管PEP 369从未被合并到Python中，但是wrapt 提供了类似功能的装饰器和函数。尽管装饰器和函数被用来解决导入次序问题。但如果目标模块在导入后钩子函数执行之前就已经被导入，我们仍会面临导入次序问题。 这个问题最简单的解决方案是修改应用程序的主Python脚本，并将您需要的所有的”导入后勾子”的注册设置为绝对的第一件事。也就是说，在从应用程序导入任何其他模块包括任何解析命令行参数的标准库之前注册”导入后勾子”。 尽管你确实可以做到这一点，但是由于注册函数会发生事实上的调用，这意味注册函数的执行可能转而导入那些将要被打补丁的模块，所以依然可能发生导入错误。 有一种间接的方式可以解决所有的问题，下面是应用这个原则的例子。方法是相对于导入猴子补丁代码，我们创建一个注册函数，只有当被补丁的模块被导入，猴子补丁才会被惰性加载，之后才会被执行。 123456789101112import sysfrom wrapt import register_post_import_hookdef load_and_execute(name): def _load_and_execute(target_module): __import__(name) patch_module = sys.modules[name] getattr(patch_module, 'apply_patch')(target_module) return _load_and_executeregister_post_import_hook(load_and_execute('patch_tempfile'), 'tempfile') patch_tempfile.py代码如下: 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def apply_patch(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 使用交互式解释器运行第一个脚本，以便将我们留在解释器中，然后，我们可以显示导入tempfile模块并执行mkdtemp()函数，看看会发生什么。 123456$ python -i lazyloader.py&gt;&gt;&gt; import tempfilepatching tempfile&gt;&gt;&gt; tempfile.mkdtemp()calling mkdtemp'/var/folders/0p/4vcv19pj5d72m_bx0h40sw340000gp/T/tmpfB8r20' 上述整个导入过程是这样的: register_post_import_hook 为 tempfile 模块注册了 _load_and_execute 函数 import tempfile 时，会先执行 _load_and_execute 函数，此时会加载patch_tempfile 模块，并执行 apply_patch 函数 apply_patch 接收 tempfile 模块对象作为参数后执行，并使用 wrap_function_wrapper 函数为 mkdtemp 打上补丁。 mkdtemp 执行的就是打补丁之后的函数 整个过程，tempfile 模块被导入时，猴子补丁才被惰性加载。 换句话说，与大多数猴子补丁不同，我们并不是强行导入一个模块，以便在可能使用的基础上应用猴子补丁。相反，猴子补丁代码保持休眠和未使用，直到目标模块稍后被导入。如果没有导入目标模块，则该模块的猴子补丁代码本身甚至没有导入。 3. 发现导入后勾子如上所述，导入后钩子提供了一种稍微更好的方法来设置猴子补丁，以便应用它们。这是因为只有当包含要修补的函数的目标模块被导入时，它们才会被激活。这避免了不必要地导入可能不使用的模块，否则会增加应用程序的内存使用。 导入次序仍然很重要，因此，要确保在导入任何其他模块之前设置所有导入后钩子。并且在每次更改应用的猴子补丁后，需要修改应用程序代码。如果只是为了调试问题而频繁地添加猴子补丁，则可能不太方便。 后一个问题的解决方案是将猴子补丁分离到单独的模块中，并使用一个注册机制来宣布它们的可用性。然后，Python应用程序可以在一开始就执行通用的模板代码，该代码根据提供的配置发现应该应用哪些猴子补丁。注册机制将允许在运行时发现猴子补丁模块。 这里可以使用的一种特殊的注册机制是setuptools入口点。使用这个我们可以打包猴子补丁，这样它们就可以被单独安装以备使用。这样一套方案的结构是: 123setup.pysrc/__init__.pysrc/tempfile_debugging.py 这个包的 setup.py 代码将会是: 123456789101112131415161718192021from setuptools import setupNAME = 'wrapt_patches.tempfile_debugging'def patch_module(module, function=None): function = function or 'patch_%s' % module.replace('.', '_') return '%s = %s:%s' % (module, NAME, function)ENTRY_POINTS = [ patch_module('tempfile'),]setup_kwargs = dict( name = NAME, version = '0.1', packages = ['wrapt_patches'], package_dir = &#123;'wrapt_patches': 'src'&#125;, entry_points = &#123; NAME: ENTRY_POINTS &#125;,)setup(**setup_kwargs) 作为一种约定，我们使用命名空间包，以便我们的猴子补丁模块易于识别。在本例中，父包将是wrapt_patch，因为我们专门使用wrapt。这个特定包的名称将是wrapt_patch.tempfile_debug,表示我们将创建一些猴子补丁，以帮助我们调试使用tempfile模块。 setup.py的关键部分是定义entry_points。它将被设置成程序包名到猴子补丁映射的列表，这个列表包含了这个补丁模块要作用的所有目标Python模块。此处 ENTRY_POINTS 的值为 123ENTRY_POINTS = [ 'tempfile = wrapt_patches.tempfile_debugging:patch_tempfile',] src/init.py 将包含: 12import pkgutil__path__ = pkgutil.extend_path(__path__, __name__) 这是创建命名空间包的要求。最后，猴子补丁实际上包含在src/tempfile_debug中。代码跟以前很像。 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def patch_tempfile(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 定义了包后，我们将它安装到正在使用的Python安装或虚拟环境中。现在，我们可以在Python应用程序主脚本文件的开头添加显式的注册，我们将添加: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 如果我们在没有为猴子补丁特定配置的情况下运行应用程序，那么什么也不会发生。如果它们是启用的，那么它们将被自动发现并根据需要应用。 1234$ WRAPT_PATCHES=wrapt_patches.tempfile_debugging python -i entrypoints.pydiscover wrapt_patches.tempfile_debugging&gt;&gt;&gt; import tempfilepatching tempfile 理想的情况是，如果PEP 369真的进入了Python的核心，那么将类似的引导机制合并到Python本身中，以便在解释器初始化过程中尽早强制对猴子补丁进行注册。有了这一点，我们就有了一种有保证的方法来解决在做猴子补丁时的导入次序问题。 由于现在PEP 369还未进入Python的核心，所以我们在本例中所做的是修改Python应用程序自己添加引导代码，以便在应用程序执行的最开始执行注册。当应用程序归自己管理时这是可以的，但是如果想要对第三方应用程序进行打补丁，并且不希望修改其代码，那该怎么办呢?在这种情况下有什么选择? 在这种情况下可以使用一些技巧。下一篇关于猴子补丁主题的博文中我们将讨论为应用程序打补丁的可用选项。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 使用 wrapt 辅助测试]]></title>
    <url>%2F2018%2F06%2F03%2Fwrapt%2Fpython_decorator_12%2F</url>
    <content type="text"><![CDATA[前面我们说道过 Python 中使用猴子补丁典型情景之一就是使用模拟库来帮助执行单元测试，本节我们先把补丁和模块导入的相对次序问题放一放，先来看看如何使用 wrapt 模块辅助单元测试。 1. 使用 wrapt 进行测试在Python中讨论单元测试时，用于辅助该任务的比较流行的包之一是 mock 包。但是我(wrapt 的作者)觉得 mock 包不符合我的思维方式。 也可能只是我试图应用它的东西不太适合。在我想要测试的内容中，通常我不仅想要模拟更低的层，而且我想要验证传递到下一层的数据，或者修改结果。换句话说，我通常仍然需要系统作为一个整体来结束，并可能在很长一段时间内。 因此，对于我需要做的更复杂的测试，我实际上一直在依靠wrapt的猴子补丁功能。很有可能，因为我写了wrapt，我更熟悉它的范例，或者我更倾向于更明确的方式。不管怎样，至少对我来说，wrapt 能帮助我更快地完成工作。 为了进一步解释 wrapt 的猴子补丁功能，我在这篇博客文章中向大家展示了用wrapt模块实现部分 Mock 包的功能。只要记住，对于Mock模块我是一个绝对的新手，也可能也我太笨了，不能理解如何正确简单地使用它来做我想做的事情。 Return values and side effects如果你正在使用Mock，并且希望在调用时临时覆盖类的方法返回的值，一种方法是: 123456789101112from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch(__name__+'.ProductionClass.method', return_value=3)def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') mock_method.assert_called_with(3, 4, 5, key='value') assert result == 3 就我迄今为止提出的wrapt包而言，一种类似的做法是: 123456789101112131415from wrapt import patch_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch_function_wrapper(__name__, 'ProductionClass.method')def wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 不过，这里的一个问题是，wrapt.patch_function_wrapper()函数应用了一个永久补丁。在这个过程的生命周期中，这是可以的，但是在测试的情况下，我们通常希望一个补丁只应用于当时正在运行的单个单元测试函数。因此，补丁应该在测试结束时和调用下一个函数之前应该被删除。 对于该场景，wrapt包提供了另一个装饰器@wrapt.transient_function_wrapper。用来创建一个包装函数，该函数只应用于修饰函数所应用的特定调用的范围。因此，我们可以把上面写为: 12345678910111213141516from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 尽管这个示例展示了如何临时覆盖类的方法返回的值，但更典型的情况是，我们仍然希望能够调用原始的被覆盖的函数。可能验证传入的参数或从底层返回的返回值。当我尝试用Mock解决这个问题时，我想到的一般方法如下。 1234567891011121314151617from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, keydef wrapper(wrapped): def _wrapper(self, *args, **kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(self, *args, **kwargs) return _wrapper@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper(ProductionClass.method))def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') 这里有两个技巧 第一个是@Mock.path 的 autospec=True参数，用于执行方法绑定 第二个是需要在对它应用任何mock之前从’ProductionClass’捕获原始方法，这样当调用mock的副作用函数时，我就可以反过来调用它。 毫无疑问，有人会告诉我，我做错了，有一种更简单的方法，但这是我在阅读模拟文档10分钟后所能想到的最好的方法。 当使用wrapt执行相同的操作时，使用的方式与模拟返回值没有什么不同。这是因为wrapt函数包装器能同时适用普通函数或方法，所以在包装方法时不需要额外处理。此外，当调用wrapt包装函数时，它总是传递被包装的原始函数，因此不需要使用任何魔法来隐藏它。 123456789101112131415from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(*args, **kwargs)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') 使用此功能可以轻松地拦截调用，来执行传递的数据的验证，但仍然可调用原始函数，我可以相对轻松地创建一大堆装饰器，以便对数据执行验证，因为数据可能是通过系统的不同部分传递的。然后，我可以将这些装饰器堆叠在任何需要添加它们的测试函数上。 2. 包装不同类型的返回值返回函数上面的示例包括能够返回一个假的返回值，返回原始值，或者在部分原始数据类型或集合上进行一些轻微的修改。但在某些情况下，我实际上希望在返回值周围放置一个包装器，以修改后续代码与返回值的交互方式。 第一个例子是包装函数返回另一个函数，这个函数将被调用链中更高的函数调用。在这里，我可能想在返回的函数周围放置一个包装器，以便在调用它时拦截它。 Mock 包的使用方式如下1234567891011121314151617181920212223242526from mock import Mock, patchdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return functiondef wrapper2(wrapped): def _wrapper2(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper2def wrapper1(wrapped): def _wrapper1(self, *args, **kwargs): func = wrapped(self, *args, **kwargs) return Mock(side_effect=wrapper2(func)) return _wrapper1@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper1(ProductionClass.method))def test_method(mock_method): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: ProductionClass.method 函数返回值是另一个函数 side_effect 指定了第一层的包装函数 wrapper1，截获了ProductionClass.method 返回的 function 函数 wrapper1 将 function 包装再 wrapper2 内返回给了调用链中更高层的函数 更高层的函数调用 function 时，调用的则是 wrapper2 wrapt 包的使用方式: 12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: apply_ProductionClass_method_wrapper 装饰了原始的 ProductionClass.method 方法 apply_ProductionClass_method_wrapper 内 wrapped(*args, **kwargs) 返回结果就是 function，其又被 result_function_wrapper 装饰 调用链中更高层的函数调用 ProductionClass.method，实际调用的是 result_function_wrapper 本例使用了一个名为@wrapt.function_wrapper的新装饰器。还可以使用@wrapt.decorator。@wrapt.function_wrapper 实际上只是@wrapt.decorator的一个简化版本，它缺少一些在做显式的猴子补丁时通常不需要的铃铛和口子，但除此之外，它也可以用同样的方式使用。因此，我可以对结果返回的函数应用一个包装器。我甚至可以应用相同的原理应用在当函数作为参数传递给另一个函数的情况。 返回类的实例返回函数的另一个场景是返回类的实例。在这种情况下，我可能想要对类的实例的特定方法应用一个包装器。在mock 包中，需要再次使用“Mock”类，并且必须以不同的方式应用它来实现您想要的结果。现在我将不再关注mock，只关注wrapt的实现方式。 所以，根据需求，有几种方法可以用wrapt来实现。第一个方法是用封装原始方法的包装器直接替换实例上的方法 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 包装过程是: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method run_method_wrapper 包装 ProductionClass.method 的返回值 storage.run 这样可以得到想要的结果，但在本例中，实际上是一种糟糕的方法。问题是返回的对象是一个在测试之外有生命时间的对象。也就是说，我们正在修改一个存储在全局范围内的对象，该对象可能用于其他测试。通过简单地替换实例上的方法，我们进行了永久性的更改。 如果它是一个仅为一次调用而按需创建的类的临时实例，那么这是可以的，但是在其他情况下不行，因为它的影响是持久的。因此，我们不能修改实例本身，需要以其他方式封装实例来拦截方法调用。 为此，我们使用了所谓的对象代理。这是一个特殊的对象类型，我们可以创建一个实例来包装另一个对象。当访问代理对象时，任何访问属性的尝试都会从包装对象返回属性。类似地，调用代理上的方法将调用包装对象上的方法。 但是，拥有一个不同的代理对象允许我们更改代理对象上的行为，从而更改代码与包装对象的交互方式。因此，我们可以避免更改原始对象本身。因此，对于这个例子，我们可以做的是: 1234567891011121314151617181920212223242526from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): def run(self): return self.__wrapped__.run()@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 整个包装过程如下: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method 使用代理对象 StorageClassProxy 代理了对 storage 实例属性和方法的访问 StorageClassProxy 覆盖了 storage 的 run 方法 也就是说，我们在代理对象上定义run()方法，以拦截原始对象上相同方法的调用。然后我们可以继续返回假值，验证参数或结果，或者根据需要修改它们。通过代理，我们甚至可以通过向代理对象添加属性来拦截对原始对象属性的访问。 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def __init__(self): self.name = 'name'storage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): @property def name(self): return self.__wrapped__.name@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') assert data.name == 'name' 3. 更好的使用 Mock 模块这时你可能会说Mock做的远不止这些。你甚至可能想指出 mock 如何保存了调用的细节，这样就可以回溯，而不需要进行打点测试，这样甚至可以避免打点测试触发的异常被意外捕获的情况。 这是正确的，我们的意思是不要局限于使用基本的构建块本身，可以将多个模块结合使用，wrapt 是构建更好的模拟库进行测试的一个很好的基础。因此，我留给你们最后一个例子来让你们思考，如何使用 mock 来实现。 12345678910111213141516171819202122232425262728from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): passdef patch(module, name): def _decorator(wrapped): class Wrapper(object): @transient_function_wrapper(module, name) def __call__(self, wrapped, instance, args, kwargs): self.args = args self.kwargs = kwargs return wrapped(*args, **kwargs) wrapper = Wrapper() @wrapper def _wrapper(): return wrapped(wrapper) return _wrapper return _decorator@patch(__name__, 'ProductionClass.method')def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert real.method.__name__ == 'method' assert mock_method.args == (3, 4, 5) assert mock_method.kwargs.get('key') == 'value' 这是 wrapt 包实现猴子补丁的概览。还有一些其他的东西，但这是核心部分。我使用猴子补丁将工具添加到现有代码中以支持性能监视，但是我在这里展示了如何将相同的技术用于编写代码测试，以替代Mock等包。 正如我在上一篇文章中提到的，猴子补丁的一个主要问题是模块的导入结果与打补丁完成的时间相关。我将在下一篇文章中进一步讨论这个问题。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 在 Python 中安全的使用猴子补丁]]></title>
    <url>%2F2018%2F06%2F02%2Fwrapt%2Fpython_decorator_11%2F</url>
    <content type="text"><![CDATA[在之前 10 篇博客中，我们几乎完整的讨论了装饰器的实现。现在我们将焦点从装饰器转移到猴子补丁上来。 1. 猴子补丁通常在Python中永远不应该做的事情之一就是编写猴子补丁。但有些人认为这是一种有用的必需品，你可能无法避免修补第三方代码中的错误。其他人则可能会争辩说，现在有这么多的软件是开源的，所以您应该简单地向上游包维护人员提交一个补丁。 猴子补丁除了补丁还有其他用途。在Python中最常用的两种形式的猴子补丁是装饰器和使用模拟库来帮助执行单元测试，甚至你可能不把它与猴子补丁等同起来。另一个不常见的猴子补丁的例子是对现有的Python代码添加性能监视功能。 前面我们介绍了装饰器可能会导致什么问题。主要的问题就是，装饰器的实现方式可能没有保留适当的自省能力，当应用于类的方法时，它们可能也没有保留Python描述符协议的正确语义。当人们开始讨论如何修改任意代码，而不是简单地对自己的代码应用装饰器时，这两个问题就变得更加重要了，因为可能很容易地干扰现有代码的行为，或者以意想不到的方式打补丁。 典型的案例是，对一个类方法打补丁。与装饰器在类被创建时即运行不同，补丁代码运行时，类已经被创建，因此需要额外处理一些潜在问题。 我打算用这篇博文来解释wrapt包的猴补丁功能。尽管 wrapt 模块提供了创建装饰器的良好方式，但这并不是创建该包的主要目标。创建wrapt包的真正原因实际上是为猴子补丁代码实现健壮的机制。碰巧，安全执行猴子补丁所需的基本原则和机制也适用于实现装饰器。 2. 创建一个装饰器在开始修改任意代码之前，我们首先需要重新复述一下wrapt包如何用于创建装饰器。主要模式是: 12345678910111213141516171819import wraptimport inspect@wrapt.decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) wrapt包创建装饰器的一个特性是，在装饰器中，可以确定装饰器所使用的上下文。即可以确定修饰符是被应用于类、函数或静态方法、类方法或实例方法中的哪一个。对于将装饰器应用于实例方法的情况，为类的实例提供了一个单独的参数。对于类方法，单独的参数是对类本身的引用。在这两种情况下，它们都与“args”和“kwargs”参数相分离，因此不需要自己动手提取它们。因此，我将使用wrapt创建的装饰器称为通用装饰器。换句话说，可以创建一个单独的装饰器，它可以跨函数、方法和类使用，可以在不同的调用场景中相应地调整装饰器的行为。而不再需要创建一个装饰器的多个实现，并确保在每个场景中都使用了正确的实现。 这种装饰器的使用与其他方式创建的装饰器无异。 12345class Example(object): @universal def name(self): return 'name' 需要注意的是 @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖 12345class Example(object): def name(self): return 'name' name = universal(name) 这么写仍然可行，当以这种方式编写时，它使装饰者在某种程度上成为一种猴子补丁。这是因为猴子补丁通常所做的就是在一些现有函数周围引入一个包装器，这样就可以对原始函数进行拦截。然后，包装器函数允许在调用原始函数之前或之后执行操作，或者允许修改传递给包装函数的参数，或者以某种方式修改结果，或者甚至完全替换结果。 与装饰器的一个重要区别是，装饰器在类被创建时即运行。相比之下，猴子补丁更随意，通常在类创建一段时间之后再执行。 事实上你所作的是: 12345class Example(object): def name(self): return 'name'Example.name = universal(Example.name) 尽管使用wrapt包创建的装饰器函数可以以这种方式使用，并且仍将按预期工作，但总体而言，我不建议以这种模式给类的现有方法添加补丁。这是因为这种方式实际上并不等同于当类被定义时在类的主体内做同样的事情。特别是Example.name的访问实际上调用了描述符协议，因此返回了实例方法。我们可以通过运行代码看到这一点: 12345678910class Example(object): def name(self): return 'name' print type(name)print type(Example.name)which produces:&lt;type 'function'&gt;&lt;type 'instancemethod'&gt; 一般来说，这可能并不重要，但我看到过一些非常奇怪的情况，它们的区别很重要。因此，为了解决这个问题，wrapt包提供了执行猴子补丁的另一种实现机制。在上面为类的方法添加包装器的情况下，使用这种机制可以避免由这种细微差别所引起的任何问题。 3. 猴子补丁创建猴子补丁的创建与装饰器创建类似，首先需要创建一个包装函数，猴子补丁的包装函数与装饰器是一样的，如下图所示 12def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 不同的是不是使用装饰器工厂函数 @wrapt.decorator 创建装饰器并将其应用到被包装对象上，而是使用 wrapt.wrap_function_wrapper() 函数。 1234567class Example(object): def name(self): return 'name'import wraptwrapt.wrap_function_wrapper(Example, 'name', wrapper) 在这种情况下，我们将类放在同一个代码文件中，但是我们也可以这样做:** 1234import exampleimport wraptwrapt.wrap_function_wrapper(example, 'Example.name', wrapper) 也就是说，我们将目标所在的模块作为第一参数，第二个参数则是我们希望应用包装器的目标方法对象的路径。我们也可以完全跳过导入模块，只使用模块的名称。 123import wraptwrapt.wrap_function_wrapper('example', 'Example.name', wrapper) 为了证明任何东西都可以被装饰器简化，我们最终可以把整个东西写成: 12345import wrapt@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 在这个最后的示例中，将会发生的事情是，一旦导入了包含上述代码的模块，在“示例”模块中定义的指定目标函数将自动地使用包装器函数进行修补。 4. 延迟补丁问题现在需要着重提醒的是。在上述的操作之后应用补丁并不总是有效的。 问题的核心在于，是否正在对一个已导入的模块应用补丁。如果模块没有导入，wrap .wrap_function_wrapper() 调用将确保模块被导入，但是如果模块已经被代码的其他部分或第三方包导入，那么可能就会有问题。 特别的是，您尝试打补丁的目标函数是模块的一个正常的全局函数，其他一些代码可以通过以下步骤直接获取对它的引用: from example import function 如果你后来来了 12345import wrapt@wrapt.patch_function_wrapper('example', 'function')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 最后，目标模块中包含的函数的副本将应用包装器，但是其他代码创建的对它的引用将没有包装器。即在打补丁之后导入的目标函数都是被包装的，之前的都是未被包装的。 为了确保在此场景中始终使用包装器，您不仅需要在原始模块中，而且还需要在存储引用的任何模块中对其进行补丁。这只在非常有限的情况下是可行的因为在现实中，如果函数是一个普通的函数，你将不知道函数在哪里被使用。 这个问题的一个确切体现就是对gevent或eventlet等包打补丁时存在的问题。这两个包都延迟了功能的修补，因此对导入模块的顺序非常敏感。要解决这个问题，至少对于Python标准库中的模块来说，要打补丁的time.sleep()函数不仅需要在time模块中进行修补，还需要在threading模块中进行修补。 有一些技术可以用来尝试和避免这些问题，但我将把这些解释推迟到以后的一段时间。在我的下一篇博客文章中，我想介绍一些使用使用猴子补丁示例，看看如何在进行测试时使用wrapt替代 mock 模块。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 装饰类的性能]]></title>
    <url>%2F2018%2F06%2F01%2Fwrapt%2Fpython_decorator_10%2F</url>
    <content type="text"><![CDATA[在上一篇文章中，我们对作为函数闭包实现的装饰器与前文描述的通用装饰器进行了性能比较。本节我们继续我们的性能测试，看看装饰一个类方法时，不同实现方式的性能表现。 1. 装饰函数的性能比较在上一篇文章中，函数闭包实现的装饰器与前文描述的通用装饰器性能测试结果如下 对于2012年的MacBook Pro，直接调用函数的测试结果是: 10000000 loops, best of 3: 0.132 usec per loop 使用函数闭包实现的装饰器的测试结果是: 1000000 loops, best of 3: 0.326 usec per loop 最受，使用装饰器工厂函数的测试结果是: 1000000 loops, best of 3: 0.771 usec per loop 上述是代理对象，和 function wrapper 对象的Python实现测试结果，如果将它们以Python C扩展实现，可以降低至: 1000000 loops, best of 3: 0.382 usec per loop 这与使用函数闭包实现的装饰器，性能相差无几。 将装饰器应用在类方法会怎样？ 2. 必须绑定函数的开销将装饰器应用于类的方法的问题是，如果要遵守Python执行模型，则需要将装饰器实现为描述符，并在访问时正确地将方法绑定到类或类实例。在本系列文章中描述的装饰器中，我们正是实现了此机制，以便能够确定装饰器整被应用于与普通的函数、实例方法或类方法中的哪一个。 相比于使用函数闭包实现的装饰器不会遵守任何的Python 执行模型，这个绑定过程确保了正确的操作，但是也带来了额外的开销。为了查看发生了哪些额外的步骤，我们可以再次使用Python profile挂钩机制来跟踪修饰函数调用的执行。当前即跟踪实例方法的调用 首先，让我们来跟踪函数闭包实现的装饰器调用了哪些函数: 1234567891011121314151617181920def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapperclass Class(object): @my_function_wrapper def method(self): passinstance = Class()import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)instance.method() 结果跟装饰器一个普通函数类似: 1234_my_function_wrapper call method call method return_my_function_wrapper return 因此，我们应该预期，当我们执行实际的时间测试时，开销不会有很大的不同。现在使用我们的装饰器工厂函数。为了提供上下文，我展示了完整的代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 我们的装饰器实现如下: 123@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 装饰实例方法的测试输出结果如下: 12345678910111213('__get__', 'call') # function_wrapper ('__init__', 'call') # bound_function_wrapper ('__init__', 'call') # object_proxy ('__init__', 'return') ('__init__', 'return')('__get__', 'return')('__call__', 'call') # bound_function_wrapper ('my_function_wrapper', 'call') ('method', 'call') ('method', 'return') ('my_function_wrapper', 'return')('__call__', 'return') 可以看到，由于方法与发生在 __get__() 中的类实例的绑定，现在发生了很多事情。因此，开销也会显著增加。 3. 执行类方法的开销与前面一样，不再使用上面的实现，而是再次使用wrapt库中的实际实现。这次我们的测试代码是: $ python -m timeit -s &#39;import benchmarks; c=benchmarks.Class()&#39; &#39;c.method()&#39; 没有被装饰的实例方法，直接运行的结果是: 10000000 loops, best of 3: 0.143 usec per loop 这比普通函数调用的情况要多一点，因为发生的了实例方法的绑定。 使用函数闭包实现的装饰器。测试结果如下: 1000000 loops, best of 3: 0.382 usec per loop 再一次，比未修饰的情况稍微多一点，与被应用到函数的装饰器相差无几。因此，当应用于普通函数与实例方法时，装饰器的开销并没有太大的差异。现在轮到我们的装饰器工厂函数和 function wrapper对象。首先测试Python 实现: 100000 loops, best of 3: 6.67 usec per loop 与使用函数闭包实现装饰器相比，这在运行时开销上增加了不少负担。虽然每次执行只需要额外的6个usec，但是您需要在上下文中考虑这个问题。特别是，如果在处理web请求的过程中对一个调用了1000次的函数应用了这样的装饰器，那么在该web请求的响应时间之上增加了6 ms。 在这一点上，许多人无疑会辩称，如果运行成本太高，那么正确是不值得的。但是，装饰函数和装饰器本身也不可能什么都不做，因此所产生的额外开销可能只是运行时成本的一小部分，因此在实践中并不明显。同样的，如果使用Python C扩展模块实现呢？对于作为C扩展实现的对象代理和函数包装器，结果是: 1000000 loops, best of 3: 0.836 usec per loop 所以不是6ms，而是小于1ms的额外开销如果修饰函数被调用1000次。它仍然比使用作为函数闭包实现的装饰器要多，但再次重申，在修饰类的方法时使用函数闭包不符合Python执行模型。 4. 需要大费周折么我是在吹毛求疵、过于迂腐地想把事情做好吗？当然，对于你现在所使用的装饰器，闭包实现可能工作的很好。但是当您开始使用函数包装器执行任意代码的猴子补丁时，情况就不一样了。如果你在做猴子补丁时不遵守Python的执行模型，那么你很容易以非常微妙和晦涩的方式打破第三方代码。客户可不会喜欢你破坏了他们的web应用程序。所以至少我现在所作的是很重要的。 在本文中，我只考虑了修饰类实例方法时的开销。我没有涵盖在修饰静态方法和类方法时的开销。如果您对它们的不同之处感到好奇，您可以在wrapt文档中查看完整的案例的基准。 在下一篇文章中，我将再次讨论性能开销问题，但也将讨论实现装饰器的一些替代方法，以便尝试并解决我在第一篇文章中提出的问题。这些内容将作为，对博客中描述的实现和 PyPi 模块中的实现的对比的一部分。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 装饰器性能比较]]></title>
    <url>%2F2018%2F05%2F30%2Fwrapt%2Fpython_decorator_09%2F</url>
    <content type="text"><![CDATA[前面我们探讨了装饰器的实现方式，并实现了一个所谓的通用装饰器模式，并用它创建了一个类似 Java 的 @synchronized 装饰器作为使用示例。本节我们来看看不同的装饰器实现方式的性能问题。在这篇关于装饰器的实现性能这篇文章之后，我们将开始深入探讨如何实现代理，它是通用装饰器机制中的基础组件。 1. 装饰一个普通函数在这篇文章中，我将只讨论用装饰器修饰一个普通函数的开销。相关的装饰器代码如下: 123456789101112131415161718192021222324class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper ... def __get__(self, instance, owner): ... def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 如果你想回忆完整的代码，你可以去查看之前的文章，那里有完整描述。使用装饰器工厂函数，创建装饰器，并装饰器一个普通函数可以像下面这样: 1234567@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @my_function_wrapperdef function(): pass 这与使用函数闭包以更传统的方式创建的decorator不同。使用闭包创建一个函数装饰器如下所示: 12345678def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapper@my_function_wrapperdef function(): pass 在我们调用函数时function()，这两种情况各自会发生什么? 2. 追踪函数执行为了跟踪代码的执行，我们可以使用Python的profile hook机制。 1234567import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)function() profile hook的目的是允许注册一个回调函数，该函数在所有函数的入口和出口调用。这样就可以追踪正在进行的函数调用的序列。对于函数闭包，输出如下: 1234_my_function_wrapper call function call function return_my_function_wrapper return 我们在这里看到的是函数闭包的嵌套函数被调用。这是因为在使用函数闭包的情况下，装饰器将函数替换为对嵌套函数的引用。当这个嵌套函数被调用时，它将依次调用原来的包装函数。对于我们的工厂函数，输出如下: 123456__call__ call my_function_wrapper call function call function return my_function_wrapper return__call__ return 这里的区别是，decorator 用 function wrapper 类的实例替换了函数。作为一个类，当它作为一个函数被调用时，__call__() 方法在类的实例上被调用。__call__() 方法随后调用用户提供的包装器函数，该函数反过来调用原始包装函数。 因此，结果是我们引入了额外的间接级别，或者换句话说，在执行路径中引入了额外的函数调用。记住，__call__()实际上是一个方法，而不仅仅是一个普通的函数。作为一种方法，实际上在幕后进行的工作要比普通的函数调用多得多。特别是，在调用未绑定方法之前，需要将其绑定到函数包装器类的实例。这不会出现在调用的跟踪中，但是它正在发生，并且会产生额外的开销。 3. 函数执行时间通过执行上面的跟踪，我们知道我们的解决方案会带来额外的方法调用开销。但是这会产生多少额外的开销呢？为了尝试度量每个解决方案中开销的增加，我们可以使用timeit模块来执行我们的函数调用。作为基线，我们首先需要知道在不应用任何修饰符的情况下对函数进行调用的时间开销。 123# benchmarks.pydef function(): pass 为记录时间，我们需要使用以下命令: $ python -m timeit -s &#39;import benchmarks&#39; &#39;benchmarks.function()&#39; 以这种方式使用的timeit模块时，它将执行适当的大量函数调用，将所有调用的总时间除以调用次数，最后得到单个调用的时间值。对于2012年款的MacBook Pro来说，输出如下: 10000000 loops, best of 3: 0.132 usec per loop 接下来测试函数闭包，输出如下: 1000000 loops, best of 3: 0.326 usec per loop 最后测试我们的装饰器工厂函数: 1000000 loops, best of 3: 0.771 usec per loop 在这个最后的例子中，我使用的是wrapt模块实现，而不是本系列博文中迄今为止给出的代码。这个实现的工作方式略有不同，因为它在描述的内容上有一些额外的功能，设计也有一些不同。即便是最轻量级的实现，性能开销也差不多。 4. 加速包装器的执行在这一点上毫无疑问会有人们想要指出,即使对于方法调用而言，它更加正确的实现了描述符协议，但是这所谓的的更好的方法实在是太慢，难以在实际生产环境中使用。因此，是否可以做些什么来加速实现呢? 此时可以采用的方法是将函数包装器和对象代理实现为Python C扩展模块。为了简单起见，我们可以将装饰器工厂函数本身作为纯Python代码来实现，因为工厂函数只在修饰符应用到函数时才调用，而不是修饰函数的每次调用时都会调用，因此它的时间开销并不重要。** 我绝对不会做的一件事是写博客，讨论如何将函数包装器和对象代理作为Python C扩展模块实现。不过请放心，它的工作方式与纯Python实现相同。显然，它的运行速度要快得多，因为它是使用Python C api实现的C代码，而不是纯粹的Python代码。 将函数包装器和对象代理作为Python C扩展模块实现的开销如何呢?测试如下: 1000000 loops, best of 3: 0.382 usec per loop 因此，尽管将函数包装器和对象代理作为Python C扩展模块实现需要付出更多的努力，但这些努力是值得的，结果时现在非常接近使用函数闭包的装饰器实现。 4. 装饰类方法性能到目前为止，我们只考虑了装饰一个普通函数的情况。正如预期的那样，与function wrapper作为一个类实现类似，由于引入了额外的间接层，因此开销明显更多。尽管如此，它仍然只有半微秒。 尽管如此，通过实现我们的函数包装器和对象代理作为C代码，我们还是能够将性能达到同一量级，在这里，作为函数闭包实现的装饰器工厂函数的开销可以忽略不计。 那么装饰类方法的性能如何呢。将在下一篇博客揭晓。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 将 @synchronized 实现为上下文管理器]]></title>
    <url>%2F2018%2F05%2F29%2Fwrapt%2Fpython_decorator_08%2F</url>
    <content type="text"><![CDATA[在前一篇文章中，我们描述了如何使用新的通用装饰器模式来实现Python的 @synchronized 同步原语装饰器。在Java提供的两个同步机制中，同步方法和同步原语，目前为止我们只实现了同步方法。本文将描述如何将其扩展为上下文管理器，从而等效的实现Java的同步原语。 1. @synchronized 当前实现到目前为止，我们的@synchronized 装饰器的实现是。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 通过确定装饰器被用于包装普通函数、实例方法或类的方法中的哪一个，我们可以在许多场景中使用同一一个装饰器。 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 我们现在想要实现的是让同步装饰器也能完成如下操作: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，除了可以用作装饰器之外，它还能与with语句一起用作上下文管理器。通过这样做，它就能够对函数中的部分语句加锁，而不是整个函数。用作上下文管理器时，如果需要与实例方法同步，我们需要将把self参数或类实例传递给synchronized。如果需要与类方法同步，则传递类对象本身。 2. 将 function_wrapper 实现为上下文管里器在现有的synchronized实现上，当使用synchronized作为函数调用时，它将返回函数包装器类的一个实例。 12&gt;&gt;&gt; synchronized(None)&lt;__main__.function_wrapper object at 0x107b7ea10&gt; 这个函数包装器没有实现作为上下文管理器的对象所需的__enter__()和__exit__()函数。函数包装器是我们自己的类，所以我们只需要创建子类并为其添加这两个方法即可。同时这个函数包装器的创建是在@decorator的定义中绑定的，所以我们需要绕过@decorator并直接使用函数包装器。因此，第一步是重写我们的 @synchronized decorator，不使用@decorator。 123456789101112131415161718192021def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) return function_wrapper(wrapped, _synchronized_wrapper) 这与我们最初的实现相同，但是我们现在可以访问到创建函数包装器对象 function_wrapper。因此我们可以创建一个满足上下文管里器协议的 function_wrapper 的子类来替换 function_wrapper。 12345678910111213141516171819202122232425262728293031def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) class _synchronized_function_wrapper(function_wrapper): def __enter__(self): self._lock = _synchronized_lock(self.wrapped) self._lock.acquire() return self._lock def __exit__(self, *args): self._lock.release() return _synchronized_function_wrapper(wrapped, _synchronized_wrapper) 3. 两种调用方式当 synchronized 作为装饰器使用时，新的function wrapper子类被用于包装被包装函数和方法。当函数或类方法被调用时，function wrapper 基类中的 __call__ 方法被调用。装饰器将在尝试获取锁之后执行被包装函数。 当synchronized作为上下文管里器使用时。子类将用于包装类实例或类本身。没有方法会被调用，取而代之的是在进入上下文时，__enter__() 会获取锁，离开上下文时，__exit__() 会释放锁。 与在之前的文章中形容的复杂度相比，现在的实现简单明了。 4. 不只是个装饰器希望这能说明的一点是，尽管@decorator被用来创建自定义装饰器，但这并不总是最合适的方式。function wrapper 对象的单独存在为修改被包装对象的行为提供了很大的灵活性。在某些情况下，还可以直接删除和使用对象代理。所有这些都提供了一个通用的工具集，用于进行任何类型的包装或修补，而不仅仅是用于装饰。现在，我将开始将这一系列博客文章的焦点转移到更一般的包装和猴子补丁上。 在此之前，在下一篇文章中，我将首先讨论与使用函数闭包实现装饰器的更传统方式相比，使用 function wrapper 隐含的性能影响。以及使用Python C扩展实现完整的对象代理和 function wrapper 后，性能改善的大小。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 实现 java 的 @synchronized 装饰器]]></title>
    <url>%2F2018%2F05%2F26%2Fwrapt%2Fpython_decorator_07%2F</url>
    <content type="text"><![CDATA[在之前的博客中，我们讨论了装饰器的实现，并实现了一个通用装饰器模式。作为这种模式的使用示例，本节我们来实现 java 中的 @synchronized 装饰器。 1. Java @synchronized 装饰器java 的同步原语有两种形式，分别是同步方法和同步代码块。在Java 中创建同步方法，只需要在其定义时添加synchronized关键字即可。 123456789101112public class SynchronizedCounter &#123; private int c = 0; public synchronized void increment() &#123; c++; &#125; public synchronized void decrement() &#123; c--; &#125; public synchronized int value() &#123; return c; &#125;&#125; 使一个方法同步意味着不可能在同一个对象上同时调用多个同步方法。当一个线程正在执行一个对象的同步方法时，所有其他调用相同对象的同步方法的线程将阻塞直至当前同步方法调用完成。 换句话说，类的每个实例都有一个内在的锁对象，并且在进入一个方法时，锁会被获取，当方法返回时它会被释放。锁是所谓的重入锁，这意味着线程可以在它持有锁的同时，再次获得它，而不会阻塞。正因为如此，一个同步的方法可以调用同一个对象上的另一个同步方法。 在Java中创建同步代码的第二种方法是同步代码块。与同步方法不同，同步代码块必须指定提供内在锁的对象。 1234567public void addName(String name) &#123; synchronized(this) &#123; lastName = name; nameCount++; &#125; nameList.add(name);&#125; 值得注意的是，在Java中，可以使用任何对象作为锁的源，不需要创建特定锁类型的实例来同步。如果在类中需要更细粒度的锁，那么可以简单地创建或使用现有的任意对象进行同步。 12345678910111213141516public class MsLunch &#123; private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() &#123; synchronized(lock1) &#123; c1++; &#125; &#125; public void inc2() &#123; synchronized(lock2) &#123; c2++; &#125; &#125;&#125; 这些同步原语使用起来相对简单，因此，如何才能通过装饰器在Python中让类似操作以同样简单的方式实现呢。 2.同步线程的互斥锁在Python中，不可能使用任意对象做同步。相反必要创建一个特定的锁对象，该对象内部持有一个线程互斥锁。锁对象提供了一个 acquire()和release() 方法来操作锁。同时由于上下文管理器被引入到 Python 中，所以锁也支持与with语句一起使用。使用这个特定的特性，用于实现Python的@synchronized 装饰器的典型实现是: 1234567891011121314def synchronized(lock=None): def _decorator(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper return _decoratorlock = threading.RLock()@synchronized(lock)def function(): pass 使用此方法在一段时间后变得很烦人，因为对于需要同步的每个不同的函数，必须首先创建一个线程锁。替代方法是，为每个装饰器自动创建一个线程锁。 1234567891011def synchronized(wrapped): lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function(): pass 我们甚至可以使用前面描述的模式，为每次调用提供一个可选的参数 1234567891011121314151617181920def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function1(): passlock = threading.Lock()@synchronized(lock=lock)def function2(): pass 无论方法如何，基于函数闭包的装饰器都会遇到我们已经列出的所有问题。因此，我们可以采取的第一步是使用我们新的装饰器工厂函数替代它。 12345678910111213def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @decorator def _wrapper(wrapped, instance, args, kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper(wrapped) 因为使用了我们的装饰器工厂函数，这意味着相同的代码可以安全的应在实例、类或静态方法上。需要强调的是在类方法上使用此装饰器看似简单，但并不是很有用。因为锁仅仅对被装饰的方法有用，并且会对类的所有实例在同一方法上施加同步锁。这并不是我们想要的，也不能同java的同步方法相对应。 在次重申我们要实现的目标是，被装饰器标识为同步的所有实例方法，我们希望每个类实例都有一个独立的同步锁来实现实例内的方法同步。不同类实例之间不要同步。 过去已经有一些文章描述了如何改进这一点，包括这个很复杂的尝试。个人觉得它的实现方式是相当笨拙的，甚至怀疑它实际上不是线程安全的，因为在创建一些锁的过程中有一个竞争条件。因为它使用了函数闭包，并且没有我们的通用装饰器的概念，所以还需要创建大量不同的装饰器，然后在一个装饰器入口点上尝试将它们整合在一起。显然，我们现在应该能够做得更好。 3. 将互斥锁存储在被包装对象上解决这个问题的关键在于我们可以在哪里存储线程锁。在被包装对象调用之间存储任何数据的惟一选项将是被包装对象本身，包括被包装的函数，类实例方法和类方法。因此相对于需要传入锁，或者在函数闭包中创建锁，让我们尝试在包装器本身中的创建和管理锁。** 首先考虑一个正常函数的情况。在这种情况下，我们所能做的就是将所需的线程锁存储在包装的函数对象本身上。 123456789101112131415@decoratordef synchronized(wrapped, instance, args, kwargs): lock = vars(wrapped).get('_synchronized_lock', None) if lock is None: lock = vars(wrapped).setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)@synchronizeddef function(): pass&gt;&gt;&gt; function()&gt;&gt;&gt; function._synchronized_lock&lt;_RLock owner=None count=0&gt; 我们要处理的一个关键问题是如何第一次创建线程锁。为此我们需要做的是查看线程锁是否已被创建。** lock = vars(wrapped).get(&#39;_synchronized_lock&#39;, None) 如果返回一个有效的线程锁对象，那么我们就可以继续尝试获取锁。如果锁不存在我们需要创建锁,但是我们必需小心避免竞态条件，因为当两个线程同时进入这部分代码时，它们都会判断需要第一次创建锁。我们用来解决这个问题的窍门是: lock = vars(wrapped).setdefault(&#39;_synchronized_lock&#39;, threading.RLock()) 当两个线程同时尝试创建锁时，它们都可能创建一个锁实例，但是由于使用了dict.setdefault()，只会有一个进程会成功。因为 dict.setdefault() 总是返回它第一次存储的值。所以所有的线程都会继续运行并且尝试获取相同的锁对象。其中一个线程对象会被丢弃也不存在任何问题，因为这只会在初始化并出现竞争条件时才会发生。 因此，我们已经成功地复制了最初的内容，不同之处在于线程锁存储在被包装的函数上，而不是存储在一个封闭函数的堆栈上。我们仍然有一个问题，即每个实例方法都有一个不同的锁。(而不是一个实例内的所有同步方法共用一个锁)。简单的解决方案是利用我们的通用装饰器，它提供了判断装饰器被使用的上下文的能力。 具体点说，我们需要判断当前是否在装饰一个类方法或实例方法，如果是，则将锁对象存储在 instance 参数上。 12345678910111213141516171819202122232425262728293031323334353637383940@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: context = vars(wrapped) else: context = vars(instance) lock = context.get('_synchronized_lock', None) if lock is None: lock = context.setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)class Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo1 = Object()o2 = Object()&gt;&gt;&gt; o1.method_im()&gt;&gt;&gt; o1._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o1._synchronized_lock)4386605392&gt;&gt;&gt; o2.method_im()&gt;&gt;&gt; o2._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o2._synchronized_lock)4386605456 这个简单的改变实际上已经达到了我们想要的结果。如果同步的装饰器被用于一个正常的函数，那么线程锁将被存储在函数本身上，并且它将单独存在，并且只在调用相同的函数之间进行同步。 对于实例方法，线程锁将被存储在类的实例上，实例方法会绑定到类，因此在该类上标记为同步的任何实例方法都将在该线程锁上同步，从而模拟Java的行为 那类方法呢。在这种情况下，instance 参数实际上是类。如果线程锁被存储在类上，那么结果将是，如果有多个类方法，并且它们都被标记为synchronized，那么它们将相互排斥。这种情况下线程锁的使用方式将不同于实例方法，但这实际上也是我们想要的。 代码是否对类方法有效? 12345678&gt;&gt;&gt; Object.method_cm()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 38, in __call__ return self.wrapper(self.wrapped, instance, args, kwargs) File "synctest.py", line 176, in synchronized lock = context.setdefault('_synchronized_lock'),AttributeError: 'dictproxy' object has no attribute 'setdefault' 很不幸，有错。这种情况的原因是，类 __dict__ 不是一个普通的字典，而是一个 dictproxy 。一个 dictproxy 不与普通的dict共享相同的方法，特别是它不提供setdefault()方法。因此，我们需要一种不同的方法来为类创建同步线程锁。dictproxy 还导致了另一个问题，即它不支持属性设置。但是类本身支持属性设置 1234&gt;&gt;&gt; vars(Object)['_synchronized_lock'] = threading.RLock()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'dictproxy' object does not support item assignment 123&gt;&gt;&gt; setattr(Object, '_synchronized_lock', threading.RLock())&gt;&gt;&gt; Object._synchronized_lock&lt;_RLock owner=None count=0&gt; 由于函数对象和类实例都可以，所以我们需要切换更新属性的方法。 4. 存储在装饰器上的元线程锁作为dict.setdefault()第一次设置锁的原子方式的替代方法，我们可以做的是使用存储在@synchronized 装饰器本身上的元线程锁。由于元线程锁的创建仍存在竞争条件，因此需要使用dict.setdefault()实现元线程锁的原子性创建。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 请注意，由于对封装函数的锁存在的检查与创建元锁之间的间隙，在我们获得了元锁之后，我们需要再次检查锁是否存在。这是为了避免两个线程同时在尝试创建锁而发生竞争条件。 这里有一点很重要，我们仅仅在更新被包装对象上的锁时使用了属性访问方法。而在查找被包装对象上是否存在锁时，没有使用getattr()方法，而是继续在vars()返回的__dict__中查找它。这是必要的，因为当在类的实例上使用getattr()时，如果该属性在类的实例中不存在，那么查找规则意味着如果该属性在类本身上存在，那么将返回该属性。 如果一个同步的类方法是第一个被调用的，这会导致问题，因为它会在类本身上留下一个锁。当随后调用实例方法时，如果使用了getattr()，它会找到类类型的锁并返回它，并且会被错误地使用。因此，我们继续通过 __dict__ 寻找锁，因为它只包含实例中实际存在的内容。 有了这些修改，所有锁的创建都可以自动完成，并在不同的上下文中创建一个适当的锁。 12345678910111213141516171819202122232425262728@synchronizeddef function(): passclass Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo = Object()&gt;&gt;&gt; function()&gt;&gt;&gt; id(function._synchronized_lock)4338158480&gt;&gt;&gt; Object.method_cm()&gt;&gt;&gt; id(Object._synchronized_lock)4338904656&gt;&gt;&gt; o.method_im()&gt;&gt;&gt; id(o._synchronized_lock)4338904592 代码也适用于在静态方法或类中使用@synchronized。综上所述，@synchronized 可以被应用的场景如下: 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 5. 实现同步代码块所以，我们已经完成了对同步方法的支持，如何实现同步代码块呢。要实现的目标是能按照下面的方式编写代码: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，我们需要 synchronized 装饰器不仅可以用作装饰器，而且还可以作为上下文管理器使用。在synchronized作为上下文管理器时，类似于Java，需要提供给它执行同步操作的对象，对于实例方法而言，这个对象是 self 参数或者类的实例。为了解释我们如何做到这一点，需要等待下一篇文章。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 装饰器的类实现]]></title>
    <url>%2F2018%2F05%2F25%2Fwrapt%2Fpython_decorator_06%2F</url>
    <content type="text"><![CDATA[上一篇文章中，我们讨论了如何实现一个带参数的装饰器，以及如何让装饰器可选的接收参数而不是必需输入参数。也讨论了如何让装饰器能在被包装函数的不同调用之间保持状态。保持状态的一种可用方法是使用类实现装饰器。然而我们实现的通用装饰器模式在使用类实现装饰器还存在一些问题，本文我们将来探讨问题出现的根源以及如何解决。 1. 装饰器工厂函数正如前文所述，我们通过类实现装饰器的模式如下 12345678910class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 当我们这么做时，装饰器在被应用时发生了如下错误: 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) _decorator() 是我们装饰器工厂函数的内部函数。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 错误的原因是我们使用函数闭包实现装饰器工厂函数，却希望它能同时工作在普通函数和类方法上。当类方法被访问时，将触发描述符协议，绑定将会发生；类实例的引用将自动作为第一个参数传递给类方法。而 _decorator() 却没有被定义成同时接收 self和wrapped 作为参数，所以调用失败。我们可以创建一个仅用于类实例的装饰器工厂函数。但是这与我们之前要为类方法和函数创建统一的装饰器的初衷相违背。 解决问题的方法是，使用我们的 function_wrapper 作为装饰器工厂的返回对象，而不是函数闭包。 12345678910111213141516171819def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): return function_wrapper(wrapped, wrapper) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper)class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 这种方式特别巧妙，但是很不容易理解，我们再来看看整个调用的发生过程 with_arguments(arg=1) 带参数的装饰器被使用时，将创建一个类实例 ins 在 @decorator 装饰下, ins 的 __call__ 方法此时是 function_wrapper(__call__, _wrapper) 对象 @ 将 function 对象作为参数传递给创建的类实例，将调用 ins.__call__(function) 方法，此时将触发function_wrapper的描述符协议，并进一步调用 _wrapper(__call__, ins) 函数，functions 对象则通过 arg 传递给 _execute 函数，_execute 执行返回新的 function_wrapper(functions, __call__) 对象 装饰的最终结果是，我们现在不必担心 @decorator 被应用在普通函数，实例方法还是一个类方法上。因为在所有的情况下，被绑定的实例对象不会通过 args 被传递 细心的读者很快就会发现另一个问题，在 __call__ 在被调用时，需要传入装饰器类的实例即 self 参数，而在上述的实现中并没有此步骤。(不过我没懂为什么作者在 _wrapper 内多嵌套一层_execute函数，应该是想说名这是要被执行的部分。) 2. 类的绑定要求更改之后，重新进行测试，我们遇到了一个新的问题。这次发生在被被包装函数被调用的时候。 123456&gt;&gt;&gt; function()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 243, in __call__ return self.wrapper(self.wrapped, None, args, kwargs)TypeError: __call__() takes exactly 5 arguments (4 given) 现在这个问题是__call__()方法传递给@decorator发生在 类初始化，此时它是未绑定方法，任何类实例远还没被创建。通常情况下，类实例的引用在方法被绑定时被提供，但是因为我们的装饰器实际是一个工厂函数，因此这里涉及到了两层绑定。外部包装函数的类实例被传递给工厂函数内部的 _wrapper 函数的instance参数。但是它在 function wrapper 对象被创建的时候，完全没有被使用。为了解决这个问题，我们需要根据是否绑定了一个实例方法，显示使用类实例绑定我们的包装函数 1234567891011def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 在这个示例中，有三种情况需要我们处理。 第一种情况是 instance 为 None。这对应于decorator函数被应用在普通函数，类静态方法或一个类上 第二种情况是 instance 不为 None，但是是一个类对象。这对应用于一个类方法。这种情况下，我们需要通过包装函数的get()将包装函数显示绑定到一个类对象。 第三种即最后一种情况下，instance 不是None，也不是一个类对象。这对应于实例方法。在这种情况我们仍然需要绑定包装函数，只不过这次绑定的是类实例。 3. 总结改进之后，我们解决了所有问题，而且很大程度上完善了我们的装饰器模式。所以，目前我们的通用装饰器解决方案如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 尽管在之前的文章中提到过。这里给出的对象代理实现并不是一个完美实现。因此，不要使用这段代码。如果你使用了，就会发现。在被包装函数上的部分内省操作不会按照我们所预期的执行。特别的，访问函数的doc属性总是返回 None。类似Python3中的新增变量 __qualname__ 和 __module__ 也不能正确显示。 正确处理像__doc__这样的内置属性是比较费劲的，因为内置属性的获取逻辑与普通属性有时候并不相同。上述实现中我们期望的是，无论从代理对象还是代理对象的子类，我们都是从被包装函数获取并返回属性值，但是对于__doc__属性，即便是代理对象的子类没有__doc__属性，它也同样会覆盖父类的__doc__，结果是代理对象的子类拦截了对 __doc__ 属性的获取。所以这里展示的代理对象仅仅是一个参照实现。 大体上说，这里所有的代码都仅仅是参照实现。目的不是使用而是展示如何实现一个更加通用的装饰器。它只是提供给你一个学习的途径。不要期望通过简单的几行代码就能实现，事情不会那么简单。 4. wrapt 模块如果我告诉你不要使用这里的代码，那你应该怎么做呢？答案是在PyPi上已经有现成的 wrapt 模块。wrapt 模块已经上线几个月了，但是目前为止并没有广为人知。它实现了这里描述的所有细节，甚至更多。这个模块实现了一个完整的代理对象，能使所有代码正确执行。并且提供了很多和装饰器工厂函数相关的特性，也提供了很多和猴子补丁相关的特性。 虽然我指出了wrapt 模块的存在，但是博客内容不会就此停止，因为我还有其他一些主题想要阐述。这些内容包括通用装饰器的应用，启用和关闭装饰器，装饰器执行性能问题，以及代理对象，猴子补丁的实现问题等等。 接下来的博客，我将举一个通用装饰器应用的特殊示例，来说明Python 装饰器如此强大，为什么Pyhton不提供一个@synchronized装饰器。在装饰器第一次被引入编程语言时，这个装饰器被当作是如何使用装饰器的经典示例。然而我能找到的所有实现都是半成品，很少在现实世界中被使用。我相信这里的通用装饰器能帮助我们实现一个可用的@synchronized装饰器。我将在下一篇博客中详述它。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 带参数的装饰器]]></title>
    <url>%2F2018%2F05%2F24%2Fwrapt%2Fpython_decorator_05%2F</url>
    <content type="text"><![CDATA[在之前的博客，通过使用代理对象，装饰器工厂函数等技术，我们已经实现了一个通用装饰器。在这篇文章中，我们将使用前面文章中描述的装饰器工厂函数，介绍如何使用它来实现接受参数的装饰器，包括强制参数和可选的接收参数。 1. 装饰器创建模式前面文章中描述的关键组件是一个函数包装器对象。我不打算复制代码，所以请参阅前面的帖子。简而言之，它是一个类类型，它接受要被包装的函数和一个用户提供的包装器函数。所得到的函数包装器对象的实例被用来代替被包装函数，当调用时，会将被包装函数的调用委托给用户提供的包装器函数。这允许用户修改调用的方式，在调用被包装函数之前或之后执行操作，或者修改输入参数或结果。function_wrapper 和装饰器工厂一起使用创建装饰器的方式如下:** 12345678910111213141516171819# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator# 使用工厂函数创建的装饰器@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) print('KWARGS', kwargs) return wrapped(*args, **kwargs)# 应用装饰器包装函数@my_function_wrapperdef function(a, b): pass 在本例中，创建的最终装饰器不接受任何参数，但如果我们希望装饰器能够接受参数，在调用用户提供的包装器函数时可访问传入的参数，那么我们该如何做呢？ 2. 使用函数闭包收集参数最简单的实现一个能接收参数的装饰器的方式是使用函数闭包 123456789def with_arguments(arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments(arg=1)def function(): pass 实际上，外部函数本身是一个工厂函数，可根据传入的参数，返回不同的装饰器实例。因此，当外部工厂函数被应用到一个具有特定参数的函数时，它返回内部装饰器函数，实际上它是应用于被包装的函数。当包装器函数最终被调用时，它会调用被包装函数，并通过作为函数闭包的一部分来访问传递给外部工厂函数的原始参数。** 位置或关键字参数可以与外部装饰器工厂函数一起使用，但是我认为关键字参数可能是一个更好的惯例，我稍后会展示。现在，如果带有参数的装饰器具有默认值，使用这种方法来实现装饰器，即使不传递参数，也必需将其作为一个不同的调用来使用。也就是说，仍然需要提供空括号。 123456789def with_arguments(arg='default'): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments()def function(): pass 尽管这只是一个特例，但看起来不优雅。大多数更喜欢当所有参数都是可选，并没有被显示传递参数时，括号时可选的。换句话说，当没有参数被传递时，可以被写成 123@with_argumentsdef function(): pass 当我们从另一个角度看问题时，这个想法实际上是有价值的。如果一个装饰器最初不接收参数，但是之后又需要可选的接收参数。如果括号是可选的，那么原来不带参数调用装饰器的代码也无需改变。 3. 带可选参数的装饰器允许装饰器添加可选参数，可以将上面的方法更改为: 12345678910111213141516def optional_arguments(wrapped=None, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped)@optional_arguments(arg=2)def function1(): pass@optional_argumentsdef function2(): pass 当具有默认的可选参数时，外部工厂函数将被包装函数作为第一个参数并默认为 None。第一次调用时，被包装函数是 None，通过 partical 函数再一次返回装饰器工厂函数。第二次调用，被包装函数将被传入并被装饰器包装。 将装饰器被直接装饰函数时，因为默认参数的存在，我们不需要显示传递参数。因为 wrapped 惨数值不是None，装饰器直接返回工厂函数，直接装饰函数。 此时工厂函数的参数必需是关键词参数，Python 3允许您使用新的关键字参数语法来强制使用关键词参数。 123456789def optional_arguments(wrapped=None, *, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped) 这样，就可以避免有人不小心将装饰器参数作为位置参数传递给 wrapped。对于一致性，关键字参数也可以被强制执行，即使它不是必需的。 12345def required_arguments(*, arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper 4. 在调用之间保持状态某些时候，装饰器可能需要在函数调用之间保持状态。一个典型的例子是缓存装饰器。此时，由于包装器函数本身没有任何状态收集器，所以只能借助于装饰器能够访问到的外部数据结构作为状态收集器进行状态保持。 有几种方法可以做到这一点。 第一个是将保持状态的对象作为显式参数传递给装饰器 12345678910111213141516def cache(d): @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = wrapped(*args, **kwargs) return result return _wrapper_d = &#123;&#125;@cache(_d)def function(): return time.time() 除非有特定的需要能够传入状态对象，否则第二个更好的方法是在外部函数的调用中创建状态对象。 1234567891011121314151617def cache(wrapped): d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function(): return time.time() 这种情况下，外部包装函数在函数内部自定状态对象，而不是通过参数显示传递。如果这是一个合理的默认值，但是在某些情况下，仍然需要将状态对象作为参数传递进来，那么可以使用可选的装饰数参数。 12345678910111213141516171819202122232425262728293031def cache(wrapped=None, d=None): if wrapped is None: return functools.partial(cache, d=d) if d is None: d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function1(): return time.time()_d = &#123;&#125;@cache(d=_d)def function2(): return time.time()@cache(d=_d)def function3(): return time.time() 5. 使用类创建装饰器在第一篇文章中，我们说过可以使用类实现装饰器。 1234567class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 就像之前已经阐述的，这种通过类实现的装饰器存在缺陷，但是作为一种替代模式，这种原始的方法也能保持状态。具体地说，类的构造函数可以将状态对象连同被包装函数保存为类实例的属性。 1234567891011121314151617class cache(object): def __init__(self, wrapped): self.wrapped = wrapped self.d = &#123;&#125; def __call__(self, *args, **kwargs): try: key = (args, frozenset(kwargs.items())) return self.d[key] except KeyError: result = self.d[key] = self.wrapped(*args, **kwargs) return result@cachedef function(): return time.time() 在装饰器逻辑特别复杂时，这种通过类实现的装饰器也存在一些好处。可以拆分封装在不同的类方法中。那么使用我们的新函数包装器和装饰器工厂，能否将装饰器实现为类呢？一种可能的方式是这样: 123456789101112class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 装饰器执行逻辑是这样的，当带参数的装饰器被使用时，将创建一个类实例。在被包装函数被调用时，将调用 @decorator 装饰的实例方法 __call__()，__call__()进而调用被包装函数。因为__call__()是实例的绑定方法，所以能够访问到类实例拥有的状态对象。 那么事实上是否能正常运行呢？ 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) 理想很丰满，显示很骨干。失败的原因就在于装饰器工厂函数的实现方式，我们将在下一篇文章种解释并解决这个特别的问题。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 作为另一种一种替代方式是，仍然使用类封装所需的逻辑，并在函数闭包类创建实例供包装函数使用。装饰器将功能委托给类实例，但是本身不作为类实现。这种方式需要额外创建一个类，使用起来并不优雅。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 实现一个通用装饰器]]></title>
    <url>%2F2018%2F05%2F22%2Fwrapt%2Fpython_decorator_04%2F</url>
    <content type="text"><![CDATA[本节我们将实现一个”通用装饰器”，它能够让用户提供的包装函数通过传入的参数判断其被使用的上下文，即确定，它是被应用在函数，实例方法，类方法，类对象中的哪一个。因为装饰器不是在各个环境种被单独实现，而是以一种更加统一的方式创建，所以将这种能确定上下文的装饰器称为通用装饰器。 1. 内容回顾到目前为止，我们创建装饰器的方式已经经过了几次迭代: 第一篇博客中我们介绍使用函数创建装饰器的传统方式，这种方式存在几个重大问题 为解决函数创建装饰器的问题，我们在第二篇博客中使用了代理对象，并将装饰器实现成了描述符，这种方式有效的解决了之前的问题，但是存在大量的样板代码 为了提高创建装饰器的效率，第三篇博客中我们使用了装饰器工厂函数，抽象了装饰器的创建过程，用户只需提供一个执行所需的包装函数即可。我们的目的是实现一个通用装饰器，能够让用户的包装函数通过传入参数确定其被使用的上下文。 12345678910111213# 包装函数通过传入参数确定其被使用的上下文@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 目前为止我们已经能够区分装饰器是被用于普通函数和还是实例方法，但是当通过类调用类方法和静态方法时将出现问题。本文我们将继续探索如何调整我们的装饰器工厂函数，以区分类方法和静态方法，以便找到实现通用装饰器的模式 2. 区分普通函数和实例方法目前为止，我们的通用装饰器模式实现如下: 123456789101112131415161718192021222324252627282930313233class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 为了测试当前的模式能在任何情况下都能工作，我们需要使用装饰器工厂创建一个装饰器，它能在执行时打印绑定的 instance 对象，以及传递进来的参数。 12345@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) 当装饰器被应用到一个正常的函数和实例方法时，包括通过显式传入实例调用实例方法时，我们能够得到符合预期的结果 12345678910111213141516171819202122@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 但是当装饰起被应用到类方法以及静态方法时，参数传递发生了错误。instance 按预期要么为空，要么接收的是类实例或类对象，现在却是传递给函数的第一个实参。并不符合我们通用装饰器的要求 。 12345678910111213141516171819class Class(object): @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE 1ARGS (2,) 3. 区分类方法和静态方法因此，我们要指出的是，在实例被传递为None的情况下，我们需要能够区分这三种情况: 通过类直接调用实例方法 类方法被调用 静态方法被调用 一种判断方法是查看绑定函数的__self__属性。该属性保存了函数在特定时间点绑定到的对象类型信息。我们先来看看通过类调用不同方法时，此属性的值。 123456789101112&gt;&gt;&gt; print(Class.function_im.__self__)None&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' 通过类调用实例方法的情况，__self__ 值为 None，对于类方法，它将是类对象，在静态方法的情况下，不存在 __self__ 属性。似乎检查 __self__ 是一个有效的判断方法 在我们编写一个基于此的解决方案之前，我们先检查一下Python 3，以确保我们在那里没问题，并且没有任何变化。 12345678910111213141516&gt;&gt;&gt; print(Class.function_im.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "dectest.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__'&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' Python 3 与 Python 2 表现并不相同，此方法无效。但是为什么会出现这种情况？发生这种情况的原因是，Pyhton3 已经没有未绑定对象这个对象，通过类直接调用实例方法时返回的也是函数。而Python2中通过类调用实例的返回值类型依赖于 __self__ 是否为None，所以Python3中删除了此属性。因此，我们现在不能区分通过类调用实例方法和调用静态方法这两种情况。 另一个方法是在 function_wrapper 构造函数内，检查被包装对象的类型，并确定它是类方法还是静态方法。然后，将判定信息传递到 bound function wrapper 并进行进一步检查。 12345678910111213141516171819202122232425262728293031323334class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function' and self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 如果有人实际上在他们的decorator中实现了描述符协议，那么希望他们也可以在这里使用对象代理。因为对象代理拥有class属性，它将返回被包装对象的类，这意味着isinstance()检查仍然会成功，因为isinstance()会优先考虑class的返回结果，而不是对象的实际类型。 无论如何，更改后，我们重新测试如下 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 成功，我们已经修复了调用类方法和静态方法时参数列表问题。现在的问题是，虽然对通过实例调用方法时， instance 参数没有问题。但是无论是通过实例还是类，传递给类方法和静态方法的 instance 参数都没有什么用。并且我们不能将它同其他情形区别开。理想情况下，我们希望调用类方法时 instance 参数始终为类对象，而调用静态方法时，则使用为 None。因此 对于静态方法，我们只需要在检查被包装类型时，判断 ‘staticmethod’ 即可 对于类方法的情况，如果我们回头看一下我们的测试，看看是否可以使用__self__属性，我们发现，对于类方法，__self__是类实例，对于静态方法，属性不存在。因此，我们可以做的是，如果包装对象的类型不是一个函数，那么我们可以查找__self__的值，如果它不存在的话，就会默认为None。这将满足这两种情况。进一步改进后如下 1234567891011121314151617181920212223class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function': # 通过类调用的实例方法 if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: # 通过实例调用的实例方法 return self.wrapper(self.wrapped, self.instance, args, kwargs) else: # 调用静态方法，__self__ 属性不存在，instance 为 None # 调用类方法时，__self__ 为类对象， instance 为类对象 instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) 如果我们重新测试一次，我们将得到我们想要得结果 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 现在万事大吉了？可惜并不是。 4. 多层绑定还有一个我们还没有考虑到的特殊情况，即为方法创建别名，并通过别名调用时。 1234567891011121314151617181920212223&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE 1ARGS (2,)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 132, in __call__ return self.wrapper(wrapped, instance, args, kwargs) File "test.py", line 58, in my_function_wrapper return wrapped(*args, **kwargs)TypeError: unbound method function_im() must be called with Class instance as first argument (got int instance instead)&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 对于类方法或静态方法来说，一切都很好，但是对于实例方法来说却失败了。这里的问题是由于在第一次访问实例方法时，它将返回绑定的bound_function wrapper对象。然后把它作为类的属性分配回来。当通过新名称进行后续查找时，在正常情况下，绑定将再次发生，以将其绑定到实际实例。在我们的绑定函数包装器的实现中，我们不提供__get__()方法，因此不会发生这种重新绑定。结果是，在随后的调用中，它全部崩溃。 Class.function_rm = Class.function_im 设置别名时，发生第一次描述符协议，function_rm 绑定得是 bound_function_wrapper 对象，第二次通过别名调用实例方法时会发生第二次描述符协议，进行第二次绑定。 因此，解决方案是我们需要向 bound_function_wrapper 添加__get__()方法，为其提供了执行进一步绑定的能力。我们只希望在实例为None的地方执行这个操作，这表明我们处理的是实例方法，而不是类方法或静态方法。 (注: Class.function_rm = Class.function_im 第一次绑定时，self.binding 为 function，并且由于时通过类直接调用实例方法，因此 instance 参数是 None。包装普通函数时也符合此类情况，但是不会触发描述符协议，只有通过实例调用发生第二次绑定时，才会调用bound_function_wrapper 的__get__方法) 另一个问题是，我们需要绑定的是原始的被包装函数，而不是绑定后的包装函数。最简单的处理方法是将对原始函数包装器 function_wrapper 的引用传递给绑定的函数包装器bound_function_wrapper，并通过它获得原始的被包装函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent # 目的是获取原始的被包装函数 def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): # 仅在通过类调用实例方法时才会发生第二次绑定 if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) # instance 是第二次绑定传入的实例对象 return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 再次运行测试得到如下所示 1234567891011121314151617&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;__main__.Class object at 0x105609790&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 5. 装饰器应用顺序目前为止，我们的装饰器一直被放置在将方法标记为类方法或静态方法的装饰器之外。如果我们颠倒顺序会怎样？ 1234567891011121314151617181920212223242526272829class Class(object): @classmethod @my_function_wrapper def function_cm(self, a, b): pass @staticmethod @my_function_wrapper def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_cm(1,2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 静态方法按预期运行，但是类方法不行。在这个特殊的例子中，它实际上可以被看作是Python本身的一个bug。具体地说，classmethod 装饰器本身并不能对它包装的所有对象都遵守描述符协议。这也是为什么当使用闭包实现装饰器会发生错误的原因。如果classmethod 装饰器能正常工作，一起都是OK 的。对于那些对细节感兴趣的人，您可以在Python bug跟踪器中查看19072。 6. 装饰器一个类除了与类方法的装饰器顺序之外，我们实现的通用装饰器的模式看起来很好。我在上一篇文章中提到过，我们的目标是，我们也可以区分什么时候装饰器被应用到一个类中。所以让我们试试 1234567@my_function_wrapperclass Class(object): pass&gt;&gt;&gt; c = Class()INSTANCE NoneARGS () 基于此，我们无法将其与普通函数或类方法区分开来。如果我们再考虑一下，在这个例子中传递给包装器函数的包装对象将是类本身。让我们输出传递给用户包装函数的 wrapped参数，看看是否能区分出这种情景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('WRAPPED', wrapped) print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)WRAPPED &lt;function function at 0x10e13bb18&gt;INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): pass @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_im(1,2)WRAPPED &lt;bound method Class.function_im of &lt;__main__.Class object at 0x107e90950&gt;&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)WRAPPED &lt;functools.partial object at 0x107df3208&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)@my_function_wrapperclass Class(object): passc = Class()&gt;&gt;&gt; c = Class()WRAPPED &lt;class '__main__.Class'&gt;INSTANCE NoneARGS () 答案是肯定的，因为它是唯一一个被包装对象是类型对象的情况。 7. 通用装饰器结构我们的目标是，一个装饰器能同时被应用在普通函数，示例方法，类方法以及类上。比较特殊的是静态方法，但是实践中，静态方法与函数并没有本质上的不同，只是它被放在不同的地方。在装饰器的执行过程中区分出静态方法是必要的，但是静态方法不会包含任何连接到它所在的类的参数。如果需要，在开始更应该创建一个类方法。最后我们的通用装饰器可以被展示如下: 12345678910111213141516@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) 这样的通用装饰器有实际用途吗?我相信有一些很好的例子，我将在随后的博客文章中特别提到其中一个。其他一些框架，比如Django，也使用了一些技巧来创建同时适用于函数和实例方法的装饰器。事实证明，他们使用的方法是不正确的，因为它不遵守描述符协议。如果您对此感兴趣，请参见Django bug跟踪器中的第21247号问题。下一篇博客中将介绍一些具有可选参数的装饰器的问题，通用装饰器的使用实例留在以后展示。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 使用工厂函数创建装饰器]]></title>
    <url>%2F2018%2F05%2F12%2Fwrapt%2Fpython_decorator_03%2F</url>
    <content type="text"><![CDATA[上一篇文章描述了一种基于代理对象创建装饰器的模式，并且通过将装饰器实现为一个描述符，解决了当装饰器应用于类方法时，对象绑定问题。代理对象和描述符的组合自动确保了内省机制能正常进行。现在的问题是如何消除样本代码来解决代码复用的问题。本文我们将进一步改进创建装饰器的方式，通过使用装饰器工厂函数，来抽象装饰器的创建，用户只需提供一个执行所需功能的的包装函数即可。 1. 装饰器的实现模式如前所述，我们需要一个代理对象，其实现如下 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 正如最后一次指出的那样，这是对它所做事情的最小表示。一个通用的对象代理需要做更多的工作。 描述符本身将按照如下模式实现 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 当将装饰器应用于一个正常的函数时，将使用包装器的 __call__()方法。如果将包装器应用于类的方法，则在属性访问时调用 __get__() 方法，返回一个新的绑定对象之后的装饰器，并在被调用时调用新的装饰器的__call__()方法。这使得我们的包装器能作为描述符来传递描述符协议，以根据需要对包装的对象进行绑定。 2. 创建装饰器的装饰器正常工作的装饰器有一个固定的实现模式，因此，我们可以使用工场函数抽象装饰器创建的过程，工厂函数可以作为一个装饰器使用，创建一个装饰器的过程如下: 1234567@decoratordef my_function_wrapper(wrapped, args, kwargs): return wrapped(*args, **kwargs)@my_function_wrapperdef function(): pass 这个装饰器工厂函数 decorator 应该怎么实现呢？就像表现的一样，我们的装饰器工厂函数是非常简单的，与partial()函数并没有很大不同，在装饰器定义时接收用户提供的包装函数，在装饰器应用时接收被包装函数，并将他们传递到function wrapper对象中。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 我们现在只需要修改我们的装饰器 function wrapper 对象的实现，将包装对象的实际执行委托给用户提供的包装函数。 123456789101112131415161718192021class bound_function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs) function_wrapper 和 bound_function_wrapper 同时接收包装函数，和被包装函数，并将 __call__() 实际执行委托给用户提供的包装函数，由用户调用被包装函数并返回值。 因此，我们可以使用工厂来简化创建装饰器的过程。现在让我们来检查一下，在所有的情况下，这将在实际工作中发挥作用，并且看看我们还能找到什么其他的问题，以及我们是否能在这些情况下改进。 3. 装饰类方法第一个可能导致问题的领域是创建一个单独的decorator，它可以同时处理类的正常函数和实例方法。为了测试我们的新decorator是如何工作的，我们可以在调用包装函数时打印传递给包装器的args，并可以比较结果。 1234@decoratordef my_function_wrapper(wrapped, args, kwargs): print('ARGS', args) return wrapped(*args, **kwargs) 首先让我们尝试包装一个普通函数: 123456@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)ARGS (1, 2) 正如所期望的那样，在函数被调用时，只有两个参数被输出。包装一个实例方法会如何？ 123456789class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im()ARGS (1, 2) 同样，当调用实例方法时传入的两个参数被输出。因此，装饰器对正常函数和实例方法的工作方式是相同的。 这里的问题是，用户如何在他们的包装函数中获取类的实例。当函数被绑定到类的实例时，我们丢失了这个信息，因为类实例现在与传入的绑定函数关联，而不是参数列表。要解决这个问题，我们可以记住在调用绑定函数时传递给 __get__() 方法的实例是什么。在 bound wrapper被创建，作为参数传递给bound wrapper。 12345678910111213141516171819202122class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 在bound wrapper中，类实例作为额外的参数传给用户创建的包装函数。对于普通函数，在顶级包装器中，对于这个新的实例参数，我们没有传递任何内容。现在，我们可以修用户的包装函数，以输出实例和传递的参数。 12345678910111213@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 因此，这种变化能让我们在包装器函数中区分出一个普通函数调用和一个的实例方法调用。对实例的引用甚至是单独传递的，在调用原始被包装函数时，我们不必为一个实例方法去判断并移除额外的类实例参数。对于类，原始的被包装函数已经是绑定对象，所以不能在传入类实例对象。 需要注意的是实例方法可以通过类，显示传递类实例来调用，我们需要验证这种情况是否仍然符合我们的要求。 123&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE NoneARGS (&lt;__main__.Class object at 0x1085ca9d0&gt;, 1, 2) 不幸的是，将实例显式地传递给类中的函数作为参数时，类实例没有通过 instance 传递给包装函数，而是作为 arg 的第一个参数被传递。这并不是一个理想的结果 为了处理这种变化，我们可以在调用bound_function_wrapper.__call__()之前检查实例，并从参数列表的开头弹出实例。然后使用 partcial 函数将实例绑定到被包装函数上，并调用用户的包装函数。 1234567891011121314class bound_function_wrapper(object_proxy): def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)# We then get the same result no matter whether the instance method is called via the class or not.&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 对于实例方法，一切都可以正常执行，被包装函数无论是实例方法和还是普通函数接收参数完全相同。得益与 instance 参数，在将装饰器应用于实例方法时，我们可以按需调用类方法。 对于类可以拥有的其他方法类型，特别是类方法和静态方法会怎样？ 12345678910class Class(object): @my_function_wrapper @classmethod def function_cm(cls, a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,) 正如所看见得，装饰器对类方法和静态方法有非常严重得问题。这两种情况下，在函数被绑定时，instance 参数将为空。此时传递给函数的第一实参将被传递给 instance，这显然是不正确的，应该怎么做？ 4. 通用装饰器所以我们并没有完成一个通用的装饰器，但我们到底想要达到什么目的呢?我们最初的装饰模式有什么问题?这里的终极目标是我所说的“通用装饰器”。一个可以应用于普通函数、实例方法、类方法、静态方法甚至是类的修饰符，修饰符能够在使用的时候自动适用它被使用的上下文。 目前为止，实现装饰器的所有方法想达到上述目标是不可能了。只能通过复制代码，或者通过某种技巧转换装饰器，以便装饰器能在不同的上下文中使用。我的目标是能实现如下功能: 123456789101112@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 本文中，我们已经实现了让装饰器在普通函数和实例方法上正确执行，我们现在需要了解如何处理类方法、静态方法以及将装饰器应用于类的场景。本系列的下一篇文章将继续追求这个目标，并描述如何进一步调整我们的装饰器。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 装饰器与描述符协议]]></title>
    <url>%2F2018%2F05%2F08%2Fwrapt%2Fpython_decorator_02%2F</url>
    <content type="text"><![CDATA[上一篇文章说明了普通函数实现的装饰器存在的问题。本文我们将着眼于之前阐述的最后一个问题，如何将装饰器应用到一个描述符上。 1. 描述符协议有关 Python 的对象模型和底层设计原理推荐大家读一读《流畅的Python》，这里不会详细解释描述符是什么以及他们的工作原理。简而言之，描述符就是存在绑定行文的对象，即属性访问会被描述符协议实现的方法所覆盖。实现描述符协议的特殊方法包括 __get__(), __set__(), 和 __delete__()。如果任意一中方法在一个对象中被定义，就可以说该对象是一个描述符** 123obj.attribute attribute.__get_(obj.type(obj))obj.attribute = value attribute.__set_(obj, value)del obj.attribute attribute.__delete_(obj, value) 上述描述的是，如果一个类的属性包含上述任意一中特殊方法，当相应操作在类属性被执行时，这些特殊方法将取代默认方法被调用。这就允许一个属性去覆盖将发生默认操作。 也许你以为你从未使用过描述符，事实上，函数对象就是描述符。当在类中定义函数时，函数就是普通的函数。当你通过’.’属性访问函数时，你将调用函数的 __get__()方法，将函数与一个类实例绑定，进而返回一个绑定方法对象** 123456789101112def f(obj): pass&gt;&gt;&gt; hasattr(f, '__get__')True&gt;&gt;&gt; f&lt;function f at 0x10e963cf8&gt;&gt;&gt;&gt; obj = object()&gt;&gt;&gt; f.__get__(obj, type(obj))&lt;bound method object.f of &lt;object object at 0x10e8ac0b0&gt;&gt; 所以当你调用类方法时，调用的不是原始函数的 __call__()，而是访问函数时临时创建的绑定方法对象的 __call__() 方法，当然，你通常不会看到所有这些中间步骤，只看到结果。 1234567&gt;&gt;&gt; class Object(object):... def f(self): pass&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; obj.f&lt;bound method Object.f of &lt;__main__.Object object at 0x10abf29d0&gt;&gt; 现在回想一下在第一个博客文章中给出的例子，当我们对一个类方法应用了装饰器时，我们遇到了如下错误: 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 示例中的问题在于 @classmethod 装饰器返回的 classmethod 对象本身并没有 __call__() 方法，__call__() 方法仅存在于 classmethod 对象__get__()被调用时返回的结果中。 更具体的说， 人们使用的简单装饰器，并没有对被包装的描述符对象执行描述符协议以产生的一个可调用对象。想反，只是简单的直接调用被包装对象。因为其没有 __call__() 方法，结果当然会失败。 那为什么将装饰器应用在普通的实例方法上仍然可以运行呢？原因是一个普通函数本身具有 __call__() 方法，包装函数直接调用的是此方法。而且尽管绑定步骤被跳过，但是包装函数将 self 包含的实例对象通过第一参数显示传递给了原始的未绑定函数对象。因此对于一个普通的实例方法包装前后调用实际上是相同的，只有当被包装的对象(如@classmethod)依赖于正确应用的描述符协议时，才会崩溃。 2. 包装描述符对象解决包装器不能在类方法执行描述符协议获取绑定对象的方法是，让包装器也成为一个描述符对象。 1234567891011121314class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 如果将包装器应用于一个正常的函数，则使用包装器的 __call__()方法。如果将包装器应用于类的方法，则调用__get__()方法，该方法返回一个新的绑定包装器，并调用该方法的 __call__() 方法。这样我们的包装器就可以在描述符的传播过程中使用。 因为将装饰器实现为一个描述符对象时，使用闭包总是会失败，因此这种情况下为了让所有的事都能正常工作，我们必需总是使用类实现装饰器。装饰器类将实现描述符协议，如上所式。 现在的问题是，我们如何解决我们列出的其他问题。我们使用functools.wrap() 和 functools.update_wrapper() 解决命名问题，现在我们应该怎么做以便继续使用他们。因为 functools.wrap() 内部使用 update_wrapper(),所以我们只需要看看它如何实现。 12345678910111213141516171819WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__')WRAPPER_UPDATES = ('__dict__',)def update_wrapper(wrapper, wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES): wrapper.__wrapped__ = wrapped for attr in assigned: try: value = getattr(wrapped, attr) except AttributeError: pass else: setattr(wrapper, attr, value) for attr in updated: getattr(wrapper, attr).update( getattr(wrapped, attr, &#123;&#125;)) 如上展示的是Python3.3中的代码，事实上它还存在一个bug，在Python3.4中已经修复。 在函数体中，3件事需要被做。 第一件是将被包装函数保存为包装函数的__wrapped__属性。这就是那个bug，因为它应该在最后实现 第二步，复制诸如 __name__ 和 __doc__ 属性； 最后一步，复制被包装函数dict属性值到包装函数，结果是很多对象需要被复制 如果我们使用的是一个函数闭包或直接的类包装器，那么这个复制就可以在decorator应用的时候完成。当装饰器被实现为描述符时，也需要在 bound wrapper 中完成上述工作。 123456789class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) 因为bound wrapper 在包装器每次被作为类的绑定方法调用时都会被创建，所有将非常慢。我们需要更高效的方式处理它。 2. 代理对象性能问题的解决方法是，使用代理对象。这是一个特殊的包装类，因为它的行为跟它包装的东西看起来很像。 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 一个完全透明的对象代理本身就是一个复杂的怪物，所以我打算暂时把细节掩盖起来，并在一个单独的博客文章中讨论它。上面的例子是它所做事情的最小表示。实际上，它实际上需要做更多的工作。简而言之，它将有限的属性从包装的对象复制到自身，并使用特殊的方法、属性和 __getattr__() 来从包装对象中获取属性，从而避免需要复制许多可能永远不会被访问的属性。 我们现在要做的是从对象代理中派生出包装器类，并取消调用update_wrapper()。 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 现在从包装器中查询像 __name__ 和 __doc__ 这样的属性时，将从被包装函数直接返回。使用透明的对象代理也意味着像 inspect.getargspec() 和 inspection.getsource() 这样的调用也将按照预期正常工作。 3. 代码复用尽管这种模式解决了最初确定的问题，但它包含了大量的重复样板代码。此外，在现在的代码中有两个位置，调用被包装函数。因而需要在两个地方重复实现包装逻辑。因此，每次需要实现一个装饰器时都要复制这一点，因此会有点痛苦。 我们可以做的是将整个过程打包到一个装饰器工厂函数中，从而避免每次都需要手工完成这一切。如何做到这一点将成为本系列下一篇博客文章的主题。从这一点开始，我们可以开始研究如何进一步改进功能，并引入新的功能，这些都是使用常规的装饰器实现方法难以实现的。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 如何实现一个 Python 装饰器]]></title>
    <url>%2F2018%2F05%2F04%2Fwrapt%2Fpython_decorator_01%2F</url>
    <content type="text"><![CDATA[稍微对 Python 有所了解的程序员一定知道 Python 装饰器和函数闭包。我曾经也以为很了解，直到在《流畅的Python》中看到了 Wrapt 模块。 Wrapt 模块的作者 Graham Dumpleton 先生写了 14 篇博客详细讲解了如何在 Python 中实现一个能同时包装函数，类方法，实例方法的通用装饰器。本文以及接下来几篇文章是我对那 14 篇博客的整理和笔记。 Graham Dumpleton 先生的博文 和 Wrapt 模块请参阅: GrahamDumpleton wrapt blog wrapt 1.10.11 documentation 1. 通过函数闭包实现装饰器装饰器的典型目的是为被包装函数附加的额外的处理逻辑。我遇到的使用装饰器的最典型场景是，大多数数据库对一次查询可设置的查询的条件有数量限制，大量查询时需要将多个查询条件分组进行多次查询在合并查询结果。比如我有100000 用户需要根据ID 查询其性别，查询条件太多，只能分批多次查询，然后将查询结果合并。这种分批查询不仅对 mysql，对其他任何数据库都适用，所以非常适用用装饰器将分批查询再合并的功能抽象出来。 1.1 实现原理大多数人(我)都是通过闭包来创建一个装饰器，就像下面这样。1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper# @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖@function_wrapperdef function(): passfunction = function_wrapper(function) 整个包装的执行过程如下: 包装函数(function_wrapper)接收被包装函数(wrapped)作为参数，并将内部的另一个内部函数(_wrapper) 作为返回值 通过@装饰器或函数的调用赋值，使用 _wrapper 替换 wrapped，这样对 wrapped 的调用实际是调用的 _wrapped _wrapped 通过函数闭包保留了对 wrapped 函数的引用，这样它就可以在内部调用 wrapped 函数并返回调用结果。 _wrapped 在调用 wrapped 之前或之后可以添加其他处理逻辑，以达到为 wrapped 附加功能的目的。 虽然通常都是适用函数闭包实现装饰器，但是能展示它工作原理的更好的示例是使用一个类实现它: function_wrapper 类通过属性保留对被包装函数的引用 当被包装函数被调用时，包装类的 __call__ 方法被调用，并进而调用原始的被包装函数 __call__ 包含了附加的通用处理逻辑。 12345678class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass 1.2 局限尽管通过闭包实现装饰器很简单，但是这种方式存在很多局限，其中最重要的是打断了 Python 内部的自省，也没有遵循 Python 对象模型的执行方式。 猴子补丁与装饰器十分相似的一个技术是 monkey patching(猴子打补丁)，猴子打补丁会进入并修改其他人的代码。二者不同的是装饰器作用的时间是函数定义完成之后，而猴子补订在函数导入模块时被应用。为了能同时使用函数包装器和猴子补丁，函数包装器必需是透明的，并且内部维护了一个堆，以便多个装饰器，猴子补订能按照预期的顺序执行。 2. 自省丢失当我们讨论函数闭包时，我们会预期函数的自省属性和函数的外在表现相一致。这些包括__name__，__doc__ 属性。但是当使用函数闭包时，原函数的自省属性会被内嵌函数所替代，因为函数闭包返回的是内嵌函数。 1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)_wrapper 当使用类实现闭包时，类实例没有 __name__ 属性，访问此属性时，会导致 AttributeError 异常 1234567891011121314class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function_wrapper' object has no attribute '__name__' 此处的解决方式是，在函数闭包内，将被包装函数的内省属性复制到内嵌函数上。这样函数名称和文档字符串属性就能表现正常 12345678910111213def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) _wrapper.__name__ = wrapped.__name__ _wrapper.__doc__ = wrapped.__doc__ return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 手动复制属性是费劲的，如果未来扩展了其他自省属性，代码需要被更新。例如需要复制 __module__ 属性，在Python3 中需要复制 __qualname__ 和 __annotations__ 属性。为了避免这么做，Python 标准库为我们提供了 functools.wraps() 装饰器，完成自省属性的复制 1234567891011121314import functoolsdef function_wrapper(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 使用类实现装饰器时，我们需要使用 functools.update_wrapper() 函数 12345678import functoolsclass function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 或许你已经认为通过 functolls.wraps 函数我们能确保函数的自省属性是正确的，但事实上它并不能一直有效。假如我们去访问函数的参数信息，返回的将是包装函数的参数信息而不是被包装函数的。即，在使用闭包的方式中，内嵌函数的参数信息被返回。因此包装器没能保留函数签名信息 123456789import inspectdef function_wrapper(wrapped): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))ArgSpec(args=[], varargs='args', keywords='kwargs', defaults=None) 类包装器更加严重，因为会触发异常，并解释称被包装函数不是一个函数。我们完全不能获取函数签名信息，即使被包装函数是可调用的 123456789101112class function_wrapper(object): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))Traceback (most recent call last): File "...", line XXX, in &lt;module&gt; print(inspect.getargspec(function)) File ".../inspect.py", line 813, in getargspec raise TypeError('&#123;!r&#125; is not a Python function'.format(func))TypeError: &lt;__main__.function_wrapper object at 0x107e0ac90&gt; is not a Python function 另外一个自省的示例是使用 inspect.getsource() 获取函数源代码。闭包装饰器返回的是内嵌函数的源代码，而类装饰器则会触发异常 3.描述符协议同函数类似，装饰器也可以应用于类方法。Python 包含了两个特殊的装饰器@classmethod 和 @staticmethod 将实例方法转换为特殊的类方法。装饰器应用于类方法同样隐含着几个问题 12345678910111213class Class(object): @function_wrapper def method(self): pass @classmethod def cmethod(cls): pass @staticmethod def smethod(): pass 第一即使使用了 functools.wraps 或者 functools.update_wrapper，当装饰器被用在 @classmethod，@staticmethod 上时，仍然会导致异常。这是因为这两个特殊的装饰器没能将一些必要的属性复制过来。这是一个Python2 的bug，并在Python3中通过忽略丢失的属性修复了 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): passTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in Class File "&lt;stdin&gt;", line 2, in wrapper File ".../functools.py", line 33, in update_wrapper setattr(wrapper, attr, getattr(wrapped, attr))AttributeError: 'classmethod' object has no attribute '__module__' 即使我们运行在 Python3 上，我们依然会遇到问题。这是因为所有类型的装饰器都假设被包装函数是直接可调用的。事实上并非如此。Python classmethod 装饰器返回一个描述符，这个描述符不是直接可调用的，但是装饰器假设被包装函数直接可调用，因此会出错。 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 4. 总结函数闭包实现的装饰器存在以下问题: 无法保留函数的自省属性 无法获取函数签名信息 无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 使用 functools.wraps() 和 functools.update_wrapper() 能保留常规的自省属性，但依旧无法保留函数签名信息和源代码，而且由于 Python2 的bug，无法将装饰器直接应用于类方法和静态方法(导入时即报错) 确实存在第三方包，尝试解决这些问题，例如PyPi上的decorator模块。这个模块虽然对前两类问题有所帮助，但仍然存在一些潜在的问题，当尝试通过猴子补丁动态应用函数包装时，可能会导致问题 这并不意味着这些问题是不可解决的，而且可以以一种不牺牲性能的方式解决。现在已经说明了要解决的问题，在随后的文章将会解释如何解决这些问题，以及提供哪些额外的功能。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
        <tag>函数装饰器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualenv]]></title>
    <url>%2F2017%2F09%2F04%2Fdeploy%2Fvirtualenv%2F</url>
    <content type="text"><![CDATA[virtualenv 基本使用 1. 环境创建virtualenv dirname – 创建虚拟环境source dirname/bin/activate – 启用虚拟环境 virtualenv 可用选项 作用 –distribute dirname 创建新的虚拟环境，并安装 pip –no-site-packages 使系统环境的包对虚拟环境不可见 2.virtualenvwrapper作用：virtualenv 管理工具，方便的创建/激活/管理/销毁虚拟环境 命令 作用 mkvirtualenv virname 新建虚拟环境 workon virname 激活 deactivate 关闭 rmvirtualenv virname 删除]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>部署工具</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo github blog]]></title>
    <url>%2F2017%2F09%2F03%2Fhexo%2Fhexo-github%2F</url>
    <content type="text"><![CDATA[使用 githup pages 和 hexo搭建 blog，本文不是完整教程，只是整个流程概览和常用命令备忘 1. github blog 搭建 安装node.js node -v 安装 hexo npm install hexo-cli -g 注册 github 帐号 新建xxx.github.io仓库，xxx 为帐号名称 初始化 hexo blog 123hexo init blogcd blognpm install 配置 hexo github 安装 hexo-deployer-gitnpm install hexo-deployer-git --save 在网站的_config.yml中配置deploy 123deploy:type: git repo: &lt;repository url&gt; branch: [branch] 提交git 12hexo d -ghexo d 2. hexo 常用命令 命令 作用 hexo init dir_name 创建博客目录 hexo clean …. hexo g(generate) 生成静态文件 hexo s(server) 启动本地web服务，用于博客的预览 hexo d(deploy) 部署播客到远端 hexo d -g 生成部署 hexo s -g 生成预览 hexo new “name” 新建文章 hexo new page “name” 新建页面 Quick StartHexo HomedocumentationtroubleshootingHexo GitHub. Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
