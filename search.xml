<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[1 Go 设计模式]]></title>
    <url>%2F2021%2F01%2F01%2Fgo%2Fgo_design%2Fgo_design_1%2F</url>
    <content type="text"><![CDATA[这个系列是 Go 语言设计模式的系列，掌握如何使用编程语言实现 23 种常见设计模式是精通一门语言的”捷径”。这个系列我们就来学习 Go 设计模式的最佳实践。 1. 学习资料到目前为止为了学习设计模式，我已经看过不少的书和视频，其中我觉得很好的有下面这些: 王铮老师在极客时间的专栏-设计模式之美: 以 Java 为基础，非常详细的讲解了设计模式和编程设计思想的方方面面 JavaScript设计模式与开发实践: JavaScript 如何实现常见的设计模式 耗子哥博客系列 目前还没找到一本专门讲解 Go 设计模式的书，网上包括 github 虽然有不少人已经将 23 中设计模式使用 Go 总结实现了一遍，但基本上都是照”葫芦画瓢”，看不出实现方式与其他语言有什么不同。 这个系列的目的就是为了收集 Go 语言设计模式中的最佳实践，写出更优雅的 Go 代码。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 go 标准库和第三方库入门]]></title>
    <url>%2F2020%2F12%2F01%2Fgo%2Fgo_module%2Fgo_module_1%2F</url>
    <content type="text"><![CDATA[那些难缠的标准库么 1. Go 的那些库随着 Go 语言的深入学习，慢慢接触到更多的 Go 库包括标准库和第三方库，希望通过这个系列慢慢积累对 Go 的使用经验。这个系列会从标准库讲起，然后不定时的记录使用到的优秀的第三方库。如果有可能会其中部分作一些源码解析。 2. 学习资料想搜索 Go 有那些库，可以访问下面这些链接: go标准库的中文网 pkg.go Go Doc]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>go标准库及第三方库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 文件 IO 和字符操作]]></title>
    <url>%2F2020%2F12%2F01%2Fgo%2Fgo_module%2Fgo_module_2%2F</url>
    <content type="text"><![CDATA[文件IO 1. 文件 IO 概述Go 的标准库我们就从文件 IO 和字符操作(包括字符串和字节数组)。Go 标准库中为文件 IO 提供了如下这些包: 文件操作的方法在 os 包中 为了扩展”文本操作”的范围(类似 Linux 中一切接文件，可以把文本操作扩展到其他类型的资源上) io 包提供了对I/O原语的基本接口，io 包基本任务是包装这些原语已有的实现（如os包里的原语），使之成为共享的公共接口。 os 包内的文件IO 是不带语言层的缓存的， bufio 提供了语言层带缓存 IO，通过带缓存 IO，使得我们可以以特定的方式读取类文件中的内容，比如按特定分隔符读取等等 string，bytes 提供了对 string，bytes 操作的方法，为了扩展 string 和bytes 的操作，string 和 bytes 包为 string 和 bytes 实现部分文件 io 的公共接口。 所以接下来我们先从文件 IO 入手，学习 os，io，bufio 和 string/bytes 中的文件 io 操作，然后再顺带介绍一下 string 和 bytes 提供的字符操作函数。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>go标准库及第三方库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 react 项目实战]]></title>
    <url>%2F2020%2F11%2F15%2Fweb%2Freact%2Freact_15%2F</url>
    <content type="text"><![CDATA[react 项目实战 1. 项目初始化123456789101112131415161718192021222324252627282930313233343536373839404142# 1. 安装 create-react-appcnpm i -g create-react-app# 2. 创建项目create-react-app react_admin# 3. 安装所需的包cnpm i -S antd axios babel-plugin-import customize-cra draft-js draftjs-to-html echarts echarts-for-react html-to-draftjs jsonp less less-loader react-draft-wysiwyg react-redux redux store wangeditorcnpm install --save react-draft-wysiwyg draft-js draftjs-to-html html-to-draftjs cnpm i -S @craco/craco craco-less @babel/plugin-proposal-decorators# 3. 修改 package.json 项目启动方式"scripts": &#123; "start": "craco start", "build": "craco build", "test": "craco test", "eject": "react-scripts eject" &#125;,# 4. 根目录创建 craco.config.js 文件const CracoLessPlugin = require('craco-less');module.exports = &#123; babel: &#123; //用来支持装饰器 plugins: [["@babel/plugin-proposal-decorators", &#123; legacy: true &#125;]] &#125;, plugins: [ &#123; plugin: CracoLessPlugin, options: &#123; lessLoaderOptions: &#123; lessOptions: &#123; modifyVars: &#123; '@primary-color': '#1DA57A' &#125;, javascriptEnabled: true, &#125;, &#125;, &#125;, &#125;, ],&#125;; 2. 数据准备以及后端服务启动项目后台使用 nodejs，并使用 mongodb 数据库。因此需要安装 mongodb。 1234567# 1. 启动mongomongod# 2. 启动后台服务node serve.js# 也可以使用 nodemon 来启动服务实时监听后台代码的变化nodemon server.js]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 Dva]]></title>
    <url>%2F2020%2F11%2F14%2Fweb%2Freact%2Freact_14%2F</url>
    <content type="text"><![CDATA[react 项目实战 1. Dva 简介Dva 是一个基于 redux 和 redux-saga 的数据流方案，然后为了简化开发体验，dva 还额外内置了 react-router 和 fetch，所以也可以理解为一个轻量级的应用框架。Dva 仅有 6 个 api，对 redux 用户尤其友好，配合 umi 使用后更是降低为 0 API。 1.1 Dva 中的数据流 数据的改变发生通常是通过用户交互行为或者浏览器行为（如路由跳转等）触发的，当此类行为会改变数据的时候可以通过 dispatch 发起一个 action，如果是同步行为会直接通过 Reducers 改变 State ，如果是异步行为（副作用）会先触发 Effects 然后流向 Reducers 最终改变 State，所以在 dva 中，数据流向非常清晰简明。 如上述的数据流所示，使用 Dva 我们需要如下步骤: 创建 store 即 state 数据共享的中心 创建 model 一个 model 就是一个独立的共享数据模块，其中 Reducer 用于处理同步更新操作，Effect 用于处理异步操作 connect 向组件注入 model 1.2 Dva 安装12345# 安装 dva 客户端工具cnpm install dva-cli -g# 安装 dvacnpm install dva —save 2. react 中使用 dva在 react 引入 dva 需要以 dva 的方式来构建项目，总的来说需要以下几步: 创建 model 以 dva 方式注册 model，然后启动项目 通过 connect 将 model 共享的数据和方法注册到组件中 2.1 model 创建src/model/user.js 12345678910111213141516171819202122232425262728293031323334353637383940// 异步请求的接口，将被 call 方法调用function login(name) &#123; return () =&gt; &#123; return new Promise((resolve) =&gt; &#123; return setTimeout(() =&gt; &#123; resolve(&#123; id: 1, name &#125;) &#125;, 1000) &#125;) &#125;&#125;export default &#123; namespace: 'user', // 1. dva model 的命名空间，用于区分其他 model state: &#123; // 2. 共享的数据 isLogin: false, userInfo: &#123; &#125; &#125;, reducers: &#123; // 3. reducer 同步方法 // 直接修改 state 中的数据 initLogin(state, action) &#123; // state 是当前的状态，action 是组件触发的动作，包括传入的载荷 return &#123;'userInfo': action.userInfo&#125; &#125; &#125;, effects: &#123; // 4. effects 异步方法 *login(action, &#123; call, put &#125;) &#123; console.log(action) const ret = yield call(login(action.name)) // 5. put 将操作提交至 reducer 进行同步修改 yield put(&#123; type: 'initLogin', userInfo: ret &#125;) &#125; &#125;&#125; 2.2 dva 注册model 并启动项目/src/index.js 1234567891011121314import React from 'react';import './index.css';import App from './App';import user from './models/user'import dva from 'dva'const app = dva();// 1. 注册 model，多个 model 需要使用多次 app.model(user);// 2. 注册路由app.router(() =&gt; &lt;App /&gt;);app.start('#root'); 2.3 connect 使用共享数据src/compoents/LoginDva.js 1234567891011121314151617181920212223242526272829303132import React, &#123; Component &#125; from 'react'import &#123; connect &#125; from 'dva'@connect( // 2. state 用于共享数据 state =&gt; (&#123; // 1. user 就是 dva model 的命名空间名称，返回的就是 model state 的数据 user: state.user &#125;), // 3. 映射数据修改的方法 &#123; login: (name) =&gt; (&#123; type: 'user/login', // 2. action 需要带命名空间 name &#125;) &#125;)class LoginDva extends Component &#123; render() &#123; console.log('---------------') console.log(this.props) console.log(this.props.user.userInfo) return ( &lt;div&gt; &lt;h3&gt;用户是否登录: &#123;this.props.user.userInfo.name&#125;&lt;/h3&gt; &lt;button onClick=&#123;() =&gt; &#123; this.props.login("tsong") &#125;&#125;&gt;登录&lt;/button&gt; &lt;/div&gt; ) &#125;&#125;export default LoginDva 3. UmiJS 中使用 dvaUmiJS 已经自动集成了 dva 使用起来非常方便，只需要定义 model 直接 connect 注入即可使用。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 UmiJS]]></title>
    <url>%2F2020%2F11%2F13%2Fweb%2Freact%2Freact_13%2F</url>
    <content type="text"><![CDATA[react 项目实战 1. umi简介umi 是阿里开源的一款 react 开发框架，集成了众多的 react 组件，与dva 一起用于开发大型项目。下面是 umi 的架构图: 1.1 UmiJS 安装1234567891011121314151617181920212223242526272829303132333435# 1. 使用 yarn 并更改为阿里源npm install -g yarnyarn config set registry https://registry.npm.taobao.org -gyarn config set sass_binary_site http://cdn.npm.taobao.org/dist/node-sass -g# 查询源yarn config get registry# 2. 安装 UmiJS# 创建项目mkdir myapp &amp;&amp; cd myapp# 通过官方工具创建项目yarn create @umijs/umi-app# 安装依赖yarn# 启动项目yarn start# 3. 部署发布# 构建产物默认生成到 ./dist 下，然后通过 tree 命令查看，yarn buildtree ./dist# 本地验证# 发布之前，可以通过 serve 做本地验证，yarn global add serveserve ./dist# 4. 页面生成umi generate &lt;type&gt; &lt;name&gt; [options]# 生成一个最简洁的页面 homeumi g page home 1.2 umi 命令行工具 umi build: 编译构建 web 产物 umi dev: 启动本地开发服务器进行项目的开发调试 umi generate: 内置的生成器功能，内置的类型有 page ，用于生成最简页面。支持别名调用 umi g umi generate &lt;type&gt; &lt;name&gt; [options] umi g page home umi plugin: 快速查看当前项目使用到的所有的 umi 插件 umi plugin &lt;type&gt; [options]，当前支持的 type 是 list，可选参数 key umi plugin list umi -v: 查看 umi 版本 1.2 项目结构一个基础的 Umi 项目大致是这样的: 12345678910111213├── package.json├── .umirc.ts├── .env├── dist├── mock├── public└── src ├── .umi ├── layouts/index.tsx ├── pages ├── index.less └── index.tsx └── app.ts]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 react 导航守卫]]></title>
    <url>%2F2020%2F11%2F12%2Fweb%2Freact%2Freact_12%2F</url>
    <content type="text"><![CDATA[react 导航守卫 1. react 导航守卫react 中没有提供特定的导航守卫的钩子函数，导航守卫通过高阶组件，包装 Route 组件来实现。要实现一个拦截验证登录的功能，需要以下几个步骤: 使用 react-redux 来共享登录状态 定义高阶组件，来包装 Route 验证登录状态 1.1 共享登录状态共享登录装填123456789101112131415161718192021222324252627282930313233343536// store/auth.jsconst authInfo = &#123; isLogin: false, userInfo: &#123; &#125;&#125;export function auth(state=authInfo, action)&#123; switch (action.type) &#123; case 'login': return &#123;isLogin: true&#125; default: return state; &#125;&#125;export const mapAuthState = state =&gt; &#123; return &#123; auth: state.auth &#125;&#125;const Login = (dispatch)=&gt;&#123; setTimeout(()=&gt;&#123; dispatch(&#123;type: 'login'&#125;) &#125;, 1000)&#125;export const mapAuthDisPatch = dispatch =&gt; &#123; return &#123; login: ()=&gt;&#123; dispatch(Login) &#125; &#125;&#125; 创建 store 对象123456789101112131415// store/index.jsimport logger from 'redux-logger'import thunk from 'redux-thunk'import &#123;createStore, combineReducers, applyMiddleware&#125; from "redux"import &#123;auth&#125; from './auth'import &#123;counter&#125; from './counter'const store = createStore(combineReducers(&#123; auth, counter&#125;), applyMiddleware(logger, thunk))export default store 2. 挂载 store1234567891011// index.jsimport ReactDOM from "react-dom"import App from "./App"import store from './store'import &#123;Provider&#125; from 'react-redux'ReactDOM.render(( &lt;Provider store=&#123;store&#125;&gt; &lt;App name="你好"/&gt; &lt;/Provider&gt;), document.querySelector("#root")) 3. 定义验证登录的高阶组件1234567891011121314151617181920212223242526272829303132333435363738// hoc/RequireLogin.jsimport React, &#123; Component &#125; from 'react'import &#123;Redirect, Route&#125; from 'react-router-dom'import &#123;mapAuthState&#125; from '../store/auth'import &#123;connect&#125; from 'react-redux'import AuthUtil from "../utils/auth"// 函数式的高阶组件，因为装饰器无法装饰函数，所以此处无法使用export function PrivateRoute(&#123;component: Comp, ...reset&#125;)&#123; return ( &lt;Route &#123;...reset&#125; component=&#123;props=&gt;&#123; // return &lt;UsedComp &#123;...props&#125;&gt;&lt;/UsedComp&gt; if (AuthUtil.isAuth)&#123; return &lt;Comp &#123;...props&#125;&gt;&lt;/Comp&gt; &#125;else&#123; return &lt;Redirect to=&#123;&#123;pathname: '/login', state: props.location&#125;&#125;&gt;&lt;/Redirect&gt; &#125; &#125;&#125;&gt;&lt;/Route&gt; )&#125;class RequireLogin extends Component &#123; render() &#123; const Comp = this.props.component return ( &lt;Route &#123;...this.props&#125; component=&#123;props=&gt;&#123; // return &lt;UsedComp &#123;...props&#125;&gt;&lt;/UsedComp&gt; if (this.props.auth.isLogin)&#123; return &lt;Comp &#123;...props&#125;&gt;&lt;/Comp&gt; &#125;else&#123; return &lt;Redirect to=&#123;&#123;pathname: '/login', state: &#123;from: props.location&#125;&#125;&#125;&gt;&lt;/Redirect&gt; &#125; &#125;&#125;&gt;&lt;/Route&gt; ) &#125;&#125;export default connect(mapAuthState)(RequireLogin) 4. 使用验证登录的高阶组件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// App.jsimport React, &#123; Component &#125; from 'react'import &#123;BrowserRouter, HashRouter, Link, Route, Switch, Redirect&#125; from 'react-router-dom'import &#123;Button&#125; from "antd"import './App.css'import Home from './pages/Home'import Course from './pages/Course'import User from './pages/User'import NotFound from './pages/NotFound'import About from './pages/About'import Login from './pages/Login'import RequireLogin, &#123;PrivateRoute&#125; from './hoc/RequireLogin'export default class App extends Component &#123; render() &#123; return ( // 1. 要想使用路由，html 必须位于 HashRouter 或者 BrowserRouter 组件内 // HashRouter 显示的 url 带有 /#/ // BrowserRouter 显示的时干净的 url &lt;HashRouter&gt; &lt;ul&gt; &#123;/* 2. Link 用于设置路由 */&#125; &lt;li&gt;&lt;Link to="/"&gt;首页&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/course"&gt;课程&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/user"&gt;用户&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/about"&gt;关于&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; &#123;/* 5. 默认情况下，Route 匹配后会继续往下执行，进行匹配 */&#125; &#123;/* Switch 表示匹配成功一个路由后，就不再继续匹配 */&#125; &lt;Switch&gt; &#123;/* 3. Router 用于路由配置 */&#125; &#123;/* exact 加上之后表示精准匹配，就不会总是显示第一个路由 */&#125; &lt;Route exact path="/home" component=&#123;Home&#125;&gt;&lt;/Route&gt; &lt;Route path="/course" component=&#123;Course&#125;&gt;&lt;/Route&gt; &lt;Route path="/user" component=&#123;User&#125;&gt;&lt;/Route&gt; &#123;/* 6. 验证登录 */&#125; &lt;RequireLogin path="/about" component=&#123;About&#125;&gt;&lt;/RequireLogin&gt; &lt;Route path="/login" component=&#123;Login&#125;&gt;&lt;/Route&gt; &#123;/* 5. 重定向 */&#125; &lt;Redirect to="/home"&gt;&lt;/Redirect&gt; &#123;/* 4. 不设置 path 用于配置 404 路由 */&#125; &lt;Route component=&#123;NotFound&#125;&gt;&lt;/Route&gt; &lt;/Switch&gt; &#123;/* &lt;Button type='primary'&gt;登录&lt;/Button&gt; */&#125; &lt;/HashRouter&gt; ) &#125;&#125; 5. 登录页面123456789101112131415161718192021222324252627282930import React, &#123; Component &#125; from 'react'import &#123;connect&#125; from 'react-redux'import &#123;Button&#125; from 'antd'import &#123; Redirect &#125; from 'react-router-dom'import &#123;mapAuthState, mapAuthDisPatch&#125; from '../store/auth'class Login extends Component &#123; handleLogin = ()=&gt;&#123; this.props.login() &#125; render() &#123; let &#123;isLogin&#125; = this.props.auth console.log(this.props) console.log(this.props.location) let path = this.props.location.state.from.pathname if (isLogin)&#123; return &lt;Redirect to=&#123;path&#125;&gt;&lt;/Redirect&gt; &#125; else &#123; return ( &lt;div&gt; &lt;p&gt;请先登录&lt;/p&gt; &lt;Button onClick=&#123;this.handleLogin&#125;&gt;登录&lt;/Button&gt; &lt;/div&gt; ) &#125; &#125;&#125;export default connect(mapAuthState, mapAuthDisPatch)(Login)]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 react-router]]></title>
    <url>%2F2020%2F11%2F11%2Fweb%2Freact%2Freact_11%2F</url>
    <content type="text"><![CDATA[react-router 1. react-routerreact-router 是 react 中实现路由创建单页面的路由组件。 1cnpm i react-router-dom -S react-router-dom 提供了如下几个对象: 要想使用路由，html 必须位于 HashRouter 或者 BrowserRouter 组件内 HashRouter 显示的 url 带有 /#/ BrowserRouter 显示的时干净的 url Link: 相当于 a 标签表示一个页面 Route: 路由配置 Switch: 表示匹配成功一个路由后，就不再继续匹配，默认情况下，Route 匹配后会继续往下执行，进行匹配 1.1 react-router 基本使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import React, &#123; Component &#125; from 'react'import &#123;BrowserRouter, HashRouter, Link, Route, Switch, Redirect&#125; from 'react-router-dom'import Home from './pages/Home'import Course from './pages/Course'import User from './pages/User'import NotFound from './pages/NotFound'export default class App extends Component &#123; render() &#123; return ( // 1. 要想使用路由，html 必须位于 HashRouter 或者 BrowserRouter 组件内 // HashRouter 显示的 url 带有 /#/ // BrowserRouter 显示的时干净的 url &lt;HashRouter&gt; &lt;ul&gt; &#123;/* 2. Link 用于设置路由 */&#125; &lt;li&gt;&lt;Link to="/"&gt;首页&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/course"&gt;课程&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/user"&gt;用户&lt;/Link&gt;&lt;/li&gt; &#123;/* state 用于 react 内传递参数，可以通过 this.props.location.state 访问 state 中的参数 */&#125; &#123;/* seach 用于设置 url 的查询参数， 解析时使用 const params= new URLSearchParams(this.props.location.search) params.get("id") 就可以获取对应的值*/&#125; &lt;li&gt;&lt;Link to=&#123;pathname: "/user", state:&#123;&#125;, search: "?id=1"&#125;&gt;用户&lt;/Link&gt;&lt;/li&gt; &#123;/* &lt;Prompt when=&#123;true&#125; message=&#123;location=&gt;&#123;`确定跳转至 $&#123;location.pathname&#125;`&#125;&#125;&gt;&lt;/Prompt&gt; */&#125; &lt;/ul&gt; &#123;/* 5. 默认情况下，Route 匹配后会继续往下执行，进行匹配 */&#125; &#123;/* Switch 表示匹配成功一个路由后，就不再继续匹配 */&#125; &lt;Switch&gt; &#123;/* 3. Router 用于路由配置 */&#125; &#123;/* exact 加上之后表示精准匹配，就不会总是显示第一个路由 */&#125; &lt;Route exact path="/" component=&#123;Home&#125;&gt;&lt;/Route&gt; &lt;Route path="/course" component=&#123;Course&#125;&gt;&lt;/Route&gt; &lt;Route path="/user" component=&#123;User&#125;&gt;&lt;/Route&gt; &#123;/* 5. 重定向 */&#125; &lt;Redirect to="/home"&gt;&lt;/Redirect&gt; &#123;/* to 也可以是一个对象，其中 state 将传递给组件的 this.props.location.state */&#125; &lt;Redirect to=&#123;pathname: "/home", state: &#123;from: "/about"&#125;&#125;&gt;&lt;/Redirect&gt; &#123;/* 4. 不设置 path 用于配置 404 路由 */&#125; &lt;Route component=&#123;NotFound&#125;&gt;&lt;/Route&gt; &lt;/Switch&gt; &#123;/* &lt;Button type='primary'&gt;登录&lt;/Button&gt; */&#125; &lt;/HashRouter&gt; ) &#125;&#125; Route 会为 component 指定的路由组件添加三个属性 location, match, history location: 本地信息对象 pathname: 当前页面的 url search: url 中的查询参数，通过new UrlSearchParams 解析 hash: state: 通过 history.push({state: “”}) 传递的参数 match: 匹配的路由信息对象，含了当前的路由信息，和 url 参数 params: url 参数 path: 匹配的路由 url: 当前页面的 url history: 页面跳转 goBack(): 返回上一页 push(): 跳转到特定页面 1.2 实现二级路由react-router 实现二级路由与一级路由类似，直接在需要配置二级路由的组件中编写路由代码即可: 123456789101112131415161718192021222324252627import React, &#123; Component &#125; from 'react'import &#123;Link, Route&#125; from 'react-router-dom'import CourseDetail from './CourseDetail'import CourseIndex from './CourseIndex'export default class Course extends Component &#123; render() &#123; console.log(this.props) return ( &lt;div&gt; &#123;/* 1. 实现二级路由 */&#125; &lt;ul&gt; &#123;/* 2. Route 会为 component 指定的路由组件添加三个属性 location, match, history */&#125; &#123;/* match 中包含了当前的路由信息，和 url 参数 */&#125; &lt;li&gt;&lt;Link to=&#123;`$&#123;this.props.match.url&#125;/python`&#125;&gt;Python&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/course/goland"&gt;GoLang&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/course/javascript"&gt;Javascript&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; &#123;/* 4. 配置路由 */&#125; &#123;/* 与 vue 类似，同样可以设置路由参数，复用组件 */&#125; &lt;Route path="/course/:courseName" component=&#123;CourseDetail&#125;&gt;&lt;/Route&gt; &#123;/* 5. 表示进入到 /course 二级根页面显示的信息 */&#125; &lt;Route exact path=&#123;this.props.match.path&#125; component=&#123;CourseIndex&#125;&gt;&lt;/Route&gt; &lt;/div&gt; ) &#125;&#125; 通过组件内 this.props.match 我们可以获取路由中的参数信息 123456789101112import React, &#123; Component &#125; from 'react'export default class CourseDetail extends Component &#123; render() &#123; const &#123;match&#125; = this.props return ( &lt;div&gt; 当前课程为: &#123;match.params.courseName&#125; &lt;/div&gt; ) &#125;&#125; 1.3 页面跳转React 组件的 this.props.history 为我们提供了页面跳转的功能: 123456789101112131415161718192021222324252627282930import React, &#123; Component &#125; from 'react'import &#123;Button&#125; from 'antd'export default class CourseDetail extends Component &#123; goHome = () =&gt; &#123; // 3. 带参数进行页面跳转 // 目标页面的组件通过 this.props.location.state 可以访问到传入的参数 this.props.history.push(&#123; pathname: '/', state: &#123; for: 'bar' &#125; &#125;) &#125; render() &#123; const &#123;match&#125; = this.props // console.log(this.props) return ( &lt;div&gt; 当前课程为: &#123;match.params.courseName&#125; &#123;/* 1. 返回上一页 */&#125; &lt;Button onClick=&#123;()=&gt;this.props.history.goBack()&#125;&gt;返回上一页&lt;/Button&gt; &#123;/* 2. 命名导航，跳转到特定页面 */&#125; &lt;Button onClick=&#123;()=&gt;this.props.history.push('/')&#125;&gt;跳转首页&lt;/Button&gt; &lt;Button onClick=&#123;this.goHome&#125;&gt;跳转首页带参数&lt;/Button&gt; &lt;/div&gt; ) &#125;&#125; 1.3 编辑页面的未保存跳转提醒在编辑页面，用户可能意外的点击其他链接，导致当前编辑的内容丢失，正常情况下，如果页面有未保存的内容，用户在离开时我们需要给予提示。这个提示也是通过路由实现的。使用的是 react-route-dom 的 Prompt 组件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import React, &#123; Component &#125; from 'react'import &#123; Switch, Link, BrowserRouter, Route, Prompt&#125; from 'react-router-dom'class Editor extends Component &#123; constructor(props) &#123; super(props) this.state = &#123; "isEditor": 0 &#125; this.editorMap = &#123; 0: "未修改", 1: "修改进行中", 2: "已经保存" &#125; &#125; handleChange = (e) =&gt; &#123; this.setState(&#123; isEditor: 1 &#125;) &#125; handleSubmit = e =&gt; &#123; e.preventDefault(); e.target.reset() this.setState(&#123; isEditor: 0 &#125;) &#125; render() &#123; return ( &lt;div&gt; &lt;form onSubmit=&#123;this.handleSubmit&#125;&gt; &#123;/* 1. Prompt 组件在 when 属性为 true 时，在跳转前就会用弹窗提示用户是否需要跳转 */&#125; &#123;/* message 就是提示信息，其是一个接受 location 对象的函数 */&#125; &lt;Prompt when=&#123;this.state.isEditor &gt; 0&#125; message=&#123; location=&gt;`当前页面编辑未保存，确定要跳转至$&#123;location.pathname&#125;么？`&#125; &gt; &lt;/Prompt&gt; &lt;h3&gt;编辑状态: &#123;this.editorMap[this.state.isEditor]&#125;&lt;/h3&gt; &lt;input type="text" onChange=&#123;this.handleChange&#125; /&gt; &lt;button&gt;提交&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; ) &#125;&#125;class EditorA extends Component &#123; render() &#123; return ( &lt;div&gt; A页 &lt;/div&gt; ) &#125;&#125;class EditorB extends Component &#123; render() &#123; return ( &lt;div&gt; B页 &lt;/div&gt; ) &#125;&#125;export default class BlockBack extends Component &#123; render() &#123; return ( &lt;BrowserRouter&gt; &lt;div&gt; &lt;ul&gt; &lt;li&gt;&lt;Link to="/editor"&gt;编辑&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/editor/a"&gt;编辑A&lt;/Link&gt;&lt;/li&gt; &lt;li&gt;&lt;Link to="/editor/b"&gt;编辑B&lt;/Link&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;Switch&gt; &lt;Route exact path="/editor" component=&#123; Editor&#125;&gt;&lt;/Route&gt; &lt;Route path="/editor/a" component=&#123; EditorA&#125;&gt;&lt;/Route&gt; &lt;Route path="/editor/b" component=&#123; EditorB&#125;&gt;&lt;/Route&gt; &lt;/Switch&gt; &lt;/BrowserRouter&gt; ) &#125;&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 redux、mobx 与 redux-saga]]></title>
    <url>%2F2020%2F11%2F10%2Fweb%2Freact%2Freact_10%2F</url>
    <content type="text"><![CDATA[使用 redux 与 react-redux 共享数据 1. reduxredux 是 react 中做状态共享的库，作用于前面我们讲的 vuex 类似，用于在大型项目中的数据共享和管理。redux 遵循严格的单向数据流: Store 中保存着用户共享的数据 要想修改数据，用户需要发出 Action Store 自动调用 Reducer，并且传入两个参数：当前 State 和收到的 Action Reducer 会返回新的 State State 一旦有变化，Store 就会调用监听函数: store.subscribe(listener); listener 可以通过store.getState()得到当前状态。如果使用的是 React，这时可以触发重新渲染 View 每次state更新，都会重新render整个项目，⼤型应⽤中会造成不必要的重复渲染。如何更优雅的使⽤redux呢，我们需要 react-redux。 12cnpm i redux -Scnpm i react-redux -S 1.1 redux 使用使用 redux 需要如下几个步骤: 创建 store，store 在初始化的时候，接收修改数据的 Action store 注册和监听 react 组件 使用 store，通过 store.dispatch/store.getState 修改和获取 store 中的值 1234567891011121314151617181920212223// src/store.js 创建 storeimport &#123;createStore&#125; from "redux"// 1. 创建 Reducersfunction counter(state = 0, action)&#123; // action.type 是 Action dispatch 触发的动作类型 switch (action.type) &#123; case "+": return state + 1 break; case "-": return state - 1 default: return state &#125;&#125;// 2. 创建 storeconst store = createStore(counter)export default store 1234567891011// src/index.js 注册监听 React 组件function render()&#123; ReactDOM.render(&lt;ReduxTest /&gt;, document.querySelector("#root"))&#125;render()// 1. 注册和订阅 react 组件，reder 就是注册到 redux 的回调函数// 每次 redux state 更新时，都会重新调用 reduxstore.subscribe(render) 12345678910111213141516171819202122232425262728293031// react 中使用 storeimport React, &#123; Component &#125; from 'react'import store from "../store"import &#123;Button&#125; from "antd"export default class ReduxTest extends Component &#123; add = ()=&gt;&#123; // 2. 触发 store 的 Action store.dispatch(&#123; type: '+' &#125;) &#125; down = ()=&gt;&#123; store.dispatch(&#123; type: '-' &#125;) &#125; render() &#123; console.log(store) return ( &lt;div&gt; &lt;h2&gt;Redux 使用&lt;/h2&gt; &#123;/* 1. 从 store 中获取值 */&#125; &lt;h3&gt;state: &#123;store.getState()&#125;&lt;/h3&gt; &lt;Button onClick=&#123;this.add&#125;&gt;+1&lt;/Button&gt; &lt;Button onClick=&#123;this.down&#125;&gt;-1&lt;/Button&gt; &lt;/div&gt; ) &#125;&#125; 2. react-redux使用 react-redux 分为如下几个步骤: 创建 store，代码同上 通过 Provider 将 store 导入到特定组件，避免了重复渲染整个组件 通过 connect 高阶组件，将读取和修改 store 操作，装饰到组件中 12345678910111213141516import &#123; Provider &#125; from "react-redux"// src/index.js 通过 Provider 将 store 导入到特定组件function render()&#123; ReactDOM.render(( // 1. 通过 Provider 将 store 导入到特定组件 &lt;Provider store=&#123;store&#125;&gt; &lt;ReduxTest&gt;&lt;/ReduxTest&gt; &lt;/Provider&gt; ), document.querySelector("#root"))&#125;render()// 2. 不需要再注册和订阅 react 组件// store.subscribe(render) 1234567891011121314151617181920212223242526272829303132333435363738394041// 组件中通过 connect 高阶组件，将读取和修改 store 操作，装饰到组件中import React, &#123; Component &#125; from 'react'import store from "../store"import &#123;Button&#125; from "antd"import &#123;connect&#125; from 'react-redux'// 1. 读取 store const mapState = state =&gt; &#123; return &#123; num: state &#125;&#125;// 2. 修改 storeconst mapDispatch = dispatch =&gt; &#123; return &#123; add()&#123; dispatch(&#123;type: '+'&#125;) &#125;, down()&#123; dispatch(&#123;type: '-'&#125;) &#125; &#125;&#125;class ReduxTest extends Component &#123; render() &#123; console.log(store) return ( &lt;div&gt; &lt;h2&gt;Redux 使用&lt;/h2&gt; &#123;/* 3. 子组件通过 props 读取注入的 mapState 和 mapDispatch 方法 */&#125; &lt;h3&gt;state: &#123;this.props.num&#125;&lt;/h3&gt; &lt;Button onClick=&#123;this.props.add&#125;&gt;+1&lt;/Button&gt; &lt;Button onClick=&#123;this.props.down&#125;&gt;-1&lt;/Button&gt; &lt;/div&gt; ) &#125;&#125;export default connect(mapState, mapDispatch)(ReduxTest) 3. redux 中间件 利⽤redux中间件机制可以在实际action响应前执⾏其它额外的业务逻辑。 通常我们没有必要⾃⼰写中间件，介绍两款⽐较成熟的中间件 redux-logger:处理⽇志记录的中间件 Redux-thunk:处理异步action 1cnpm i redux-thunk redux-logger -S 3.1 装载 redux 中间件redux 中间使用前需要装载: 1234567891011121314151617181920212223// src/store.js 中装载插件import &#123;createStore, applyMiddleware&#125; from "redux"import logger from "redux-logger"import thunk from 'redux-thunk'function counter(state = 0, action)&#123; // action.type 是 Action dispatch 触发的动作类型 switch (action.type) &#123; case "+": return state + 1 break; case "-": return state - 1 default: return state &#125;&#125;// 1. 使用 applyMiddleware 装载中间件const store = createStore(counter, applyMiddleware(logger, thunk))export default store 3.2 使用 redux-thunk 进行异步操作redux 中 Action 默认接收一个对象，表示执行的下一个任务，这个执行的过程必须是同步的。如果在执行之前需要一些异步操作，需要借助 redux-thunk 中间，此时 Action 接收一个函数。 1234567891011121314151617181920const asyncAdd = (dispatch)=&gt;&#123; setTimeout(() =&gt; &#123; dispatch(&#123;type: '+'&#125;) &#125;, 1000); &#125;// 2. 修改 storeconst mapDispatch = dispatch =&gt; &#123; return &#123; add()&#123; dispatch(&#123;type: '+'&#125;) &#125;, down()&#123; dispatch(&#123;type: '-'&#125;) &#125;, asyncAdd:()=&gt;&#123; dispatch(asyncAdd) &#125; &#125;&#125; 4. redux 状态模块化当 redux 中管理的共享状态越来越多时，我们需要对其模块化。redux 提供了 combineReducers 函数用于对模块进行整合。 123456789101112// src/store.js Reducer 整合const store = createStore(combineReducers(&#123; counter &#125;), applyMiddleware(logger, thunk))// 状态访问const mapState = state =&gt; &#123; return &#123; // 相应的对状态进行访问时，也要带上响应的键。 num: state.counter &#125;&#125; 5. mobx 简介mobx 是react 中另一款实现状态共享的组件。推荐在中小项目中使用。在 mobx 和 react 的组合中: React是⼀个消费者，将应⽤状态 state 渲染到组件树 Mobx是⼀个提供者，⽤于存储和更新状态state 1cnpm i mobx mobx-react -S 5.1 mobx 使用mobx 的使用分为如下几个步骤: 创建 mobx 状态对象，并为状态对象创建操作状态的方法 将mobx 状态对象通过组件属性注入组件 在组件中通过 props 属性引用状态对象，并使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 1. src/Store/mobx.js 创建 mobx 状态对象import &#123;observable, action&#125; from "mobx"// 创建观察者export const appState = observable(&#123; num: 0&#125;)// actionappState.add = action(()=&gt;&#123; appState.num++&#125;)appState.down = action(()=&gt;&#123; appState.num--&#125;)// 2. 通过组件属性注入 appStateimport React, &#123; Component &#125; from 'react'export default class App extends Component &#123; render() &#123; return ( &lt;div&gt; &#123;/* 直接通过属性注入的方式使用 state */&#125; &lt;MobxTest appState=&#123;appState&#125;&gt;&lt;/MobxTest&gt; &lt;/div&gt; ) &#125;&#125;// 3. 在组件中使用状态对象import React, &#123; Component &#125; from 'react'// import &#123;appState&#125; from '../Store/mobx'import &#123;observer&#125; from "mobx-react"import &#123;Button&#125; from "antd"class MobxTest extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;h2&gt;MuboxTest&lt;/h2&gt; &#123;/* 直接通过 props 操作 state */&#125; &lt;p&gt;&#123;this.props.appState.num&#125;&lt;/p&gt; &#123;/* 注意此处必须使用箭头函数 */&#125; &lt;Button onClick=&#123;()=&gt;&#123;this.props.appState.add()&#125;&#125;&gt;+1&lt;/Button&gt; &lt;/div&gt; ) &#125;&#125;// 4. 组件监听状态的变化export default observer(MobxTest) 5.2 appState 的装饰器写法appState 还有另一种装饰器写法，如下: 1234567891011121314class NumState&#123; @observable num = 0; @action add()&#123; this.num ++ &#125; @action down()&#123; this.num -- &#125;&#125;export default new NumState() 5.3 对⽐ redux 和Mobx 学习难度 redux &gt; mobx ⼯作量 redux &gt; mobx 内存开销 redux &gt; mobx 状态管理的集中性 redux &gt; mobx 样板代码的必要性 redux &gt; mobx 结论：使⽤Mobx⼊⻔简单，构建应⽤迅速，但是当项⽬⾜够⼤的时候，还是redux,爱不释⼿，那还是开启严格模式，再加上⼀套状态管理的规范，代码的复用性非常的高 6. redux-sagaredux-chunk 中管理异步操作的方式是使用回调函数，在复杂场景中很容易陷入到回调地狱中，而 redux-saga 使用 ES6 协程解决了这个问题。redux-sage 与 redux-thunk 使用的方式类似，都是作为 redux 插件的方式被使用，唯一的区别就是处理异步操作的方式。 redux-saga 使用的是 ES6 原始的 Promis 和 yield 语法，并且与 redux-chunk 一样，状态的初始化，同步异步操作没有封装在一起，感觉使用起来并不是非常方便。推荐使用 Dva 进行数据管理，接口更加简洁。 1npm i redux-saga -S 完整使用 redux 和 redux-saga 的步骤如下: 使用 redux-saga 封装异步操作，定义 redux-saga 的 action 创建 操作共享数据的 reducer，reducer 中的异步操作将使用 redux-saga 定义的action 创建 redux store 和 redux-saga 中间件，关联 store、中间件和 reducer 不要忘记通过 Provider 将 store 导入 react 组件中使用 connect 将 redux 共享的数据和操作映射至待使用的组件中 定义 redux-saga 的 actionredux-saga/effects 暴露了三个接口: call: 执行异步操作 put: 相当于 dispatch 触发 reducer 中的同步操作 takeEvery: 注册 redux-saga 的 action 123456789101112131415161718192021222324252627282930313233// src/store/userSaga.jsimport &#123; call, put, takeEvery &#125; from 'redux-saga/effects'const api = &#123; login: async () =&gt; &#123; return new Promise((resolve, reject) =&gt; &#123; setTimeout(() =&gt; &#123; resolve(&#123;id:1, name: "小马哥"&#125;) &#125;, 1000) &#125;) &#125;&#125;// 1. 创建的 Work Sagefunction* login(action) &#123; try &#123; const result = yield call(api.login) console.log(result) // 1. dispatch 触发 reducer 里面的同步操作 yield put(&#123;'type': 'login', result&#125;) &#125; catch (error) &#123; yield put(&#123;'tyoe': 'loginErr', message: error.message&#125;) &#125; &#125;// 2. 将 login 与 Saga 关联起来，类似监听function* loginSaga() &#123; // login_saga 相当于 saga 的 action yield takeEvery("login_request", login)&#125;export default loginSaga 创建 reducer1234567891011121314151617181920212223242526272829303132333435// src/store/userReducer.jsconst initState = &#123; isLogin: false, userInfo: &#123; &#125; &#125;export const mapUserState = (state) =&gt; &#123; return &#123; user: state.user &#125;&#125;export const mapUserOp = (dispatch) =&gt; (&#123; login: () =&gt; &#123; // login_request 就是 redux-saga 定义的 action dispatch(&#123;type: "login_request"&#125;) &#125;&#125;)function user(state = initState, action) &#123; switch (action.type) &#123; case 'login': return &#123;userInfo: action.result, isLogin: true&#125; break; default: return state &#125;&#125;export default user 创建 store 关联中间件和 reducer1234567891011121314151617181920// src/store/index.jsimport &#123; createStore, applyMiddleware, combineReducers &#125; from 'redux'import user from "./userReducer"import logger from 'redux-logger'import createSagaMiddleware from 'redux-saga'import userSaga from './userSaga'// 1. 创建 saga 中间件const sageMid = createSagaMiddleware()// 2. 创建 storeconst store = createStore(combineReducers(&#123; user&#125;), applyMiddleware(logger, sageMid))// 3. 运行 saga 中间件sageMid.run(userSaga)export default store 导入 store12345678910111213141516171819202122// project/index.jsimport React from 'react';import ReactDOM from 'react-dom';import './index.css';import App from './App';import reportWebVitals from './reportWebVitals';import store from './store'import &#123; Provider &#125; from 'react-redux'ReactDOM.render( &lt;React.StrictMode&gt; &lt;Provider store=&#123; store &#125;&gt; &lt;App /&gt; &lt;/Provider&gt; &lt;/React.StrictMode&gt;, document.getElementById('root'));// If you want to start measuring performance in your app, pass a function// to log results (for example: reportWebVitals(console.log))// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitalsreportWebVitals(); 使用 connect 导入共享数据1234567891011121314151617181920212223// src/components/Login.jsimport React, &#123; Component &#125; from 'react'import &#123; connect &#125; from 'react-redux'import &#123; mapUserOp, mapUserState &#125; from "../store/userReducer"@connect(mapUserState, mapUserOp)class Login extends Component &#123; login = () =&gt; &#123; this.props.login() &#125; render() &#123; console.log(this.props) console.log(this.props.user.userInfo) return ( &lt;div&gt; &lt;h3&gt;用户是否登录: &#123;this.props.user.isLogin&#125;&lt;/h3&gt; &lt;button onClick=&#123; this.login&#125;&gt;登录&lt;/button&gt; &lt;/div&gt; ) &#125;&#125;export default Login]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 Antd 组件设计]]></title>
    <url>%2F2020%2F11%2F09%2Fweb%2Freact%2Freact_9%2F</url>
    <content type="text"><![CDATA[本节我们仿照 Antd 自己实现一个登陆表单 1. Antd 的表单示例下面是一个从 Antd 摘录的横向登陆表单的创建示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import React, &#123; useState, useEffect &#125; from 'react';import &#123; Form, Input, Button &#125; from 'antd';import &#123; UserOutlined, LockOutlined &#125; from '@ant-design/icons';const HorizontalLoginForm = () =&gt; &#123; const [form] = Form.useForm(); const [, forceUpdate] = useState(&#123;&#125;); // To disable submit button at the beginning. useEffect(() =&gt; &#123; forceUpdate(&#123;&#125;); &#125;, []); const onFinish = (values) =&gt; &#123; console.log('Finish:', values); &#125;; return ( &lt;Form form=&#123;form&#125; name="horizontal_login" layout="inline" onFinish=&#123;onFinish&#125;&gt; &lt;Form.Item name="username" rules=&#123;[ &#123; required: true, message: 'Please input your username!', &#125;, ]&#125; &gt; &lt;Input prefix=&#123;&lt;UserOutlined className="site-form-item-icon" /&gt;&#125; placeholder="Username" /&gt; &lt;/Form.Item&gt; &lt;Form.Item name="password" rules=&#123;[ &#123; required: true, message: 'Please input your password!', &#125;, ]&#125; &gt; &lt;Input prefix=&#123;&lt;LockOutlined className="site-form-item-icon" /&gt;&#125; type="password" placeholder="Password" /&gt; &lt;/Form.Item&gt; &lt;Form.Item shouldUpdate=&#123;true&#125;&gt; &#123;() =&gt; ( &lt;Button type="primary" htmlType="submit" disabled=&#123; !form.isFieldsTouched(true) || !!form.getFieldsError().filter((&#123; errors &#125;) =&gt; errors.length).length &#125; &gt; Log in &lt;/Button&gt; )&#125; &lt;/Form.Item&gt; &lt;/Form&gt; );&#125;;export &#123; HorizontalLoginForm &#125; 从这个示例中我们可以看到: Form 组件接收了一个 form Button 提交表单通过 form.getFieldsError() 获取校验状态来决定是否可以提交 由此可见 form 对象中收集了所有表单的验证的和校验结果，form 对象需要做如下几个事情: 获取 Form.Item 组件的表单名称和验证规则 为 Button 组件绑定 onChange 事件获取表单输入值，并进行校验收集验证状态 提供 getFieldsError 方法返回最终的校验状态 isFieldsTouched 表示表单是否被触碰，通过表单的 onFocus 事件进行处理 综上所述，想要实现 Antd 的表单关键在于 form 对象以及如何在 Form 组件内获取其子组件 Form.Item 以及子子组件 Button 等表单组件的信息。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 组件通信 Context]]></title>
    <url>%2F2020%2F11%2F08%2Fweb%2Freact%2Freact_8%2F</url>
    <content type="text"><![CDATA[组件通信 Context 1. ContextContext 提供了⼀个⽆需为每层组件⼿动添加 props，就能在组件树间进⾏数据传递的⽅法。⽬的是为了共享那些 全局 的数据，例如当前认证的⽤户、主题等。Context 提供了 provider/comsumer 有点类似与 Vue 中的 provide/inject。 Context 有两种使用方式，接下来我们一一来看 1.1 静态注入12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import React, &#123; Component &#125; from 'react'import &#123;Button&#125; from "antd"// 1. 创建 Contextconst ThemeContext = React.createContext()// 三层组件class ThemeBtn extends Component &#123; // 2. 将子组件使用的 Context 设置为当前组件的静态属性，即声明使用到的上下文对象 // 必须是静态属性，且属性名为 contextType static contextType = ThemeContext constructor(props)&#123; super(props) // 3. 创建和声明 Context 后，子组件实例就会有一个 context 属性表示接收到的 Context console.log(this.context) &#125; render() &#123; return ( &lt;div&gt; &#123;/*4. 使用 context ，context 就是父组件通过 Context.Provider 传递过来的值 */&#125; &lt;Button type=&#123;this.context.type&#125;&gt;&#123;this.context.name&#125;&lt;/Button&gt; &lt;/div&gt; ) &#125;&#125;// 二层组件function ToolBar(props)&#123; return ( &lt;ThemeBtn&gt;&lt;/ThemeBtn&gt; )&#125;// 顶层父组件export default class ContextUse extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; store : &#123; type: "primary", name: "确认" &#125; &#125; &#125; render() &#123; return ( &lt;div&gt; &#123;/* 4. 在父组件中使用 Context.Provider 提供值，必须使用 value 属性来传值*/&#125; &lt;ThemeContext.Provider value=&#123;this.state.store&#125;&gt; &lt;ToolBar&gt;&lt;/ToolBar&gt; &lt;/ThemeContext.Provider&gt; &lt;/div&gt; ) &#125;&#125; 1.2 基于函数渲染基于函数渲染使用: ThemeContext.Provider: 在父组件中来提供数据 ThemeContext.Comsumer: 在子组件中使用数据 推荐使用这种方式，更容易理解。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import React, &#123; Component &#125; from 'react'import &#123;Button&#125; from "antd"// 1. 创建 Contextconst ThemeContext = React.createContext()class ThemeBtn extends Component &#123; render() &#123; return ( &lt;ThemeContext.Consumer&gt; &#123;/* 2. 在子组件中使用 ThemeContext.Consumer 来消费 Context 提供的值，必须使用函数*/&#125; &#123; value =&gt; &lt;Button type=&#123;value.type&#125;&gt;&#123;value.name&#125;&lt;/Button&gt; &#125; &lt;/ThemeContext.Consumer&gt; ) &#125;&#125;function ToolBar(props)&#123; return ( &lt;ThemeBtn&gt;&lt;/ThemeBtn&gt; )&#125;export default class ContextUse extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; store : &#123; type: "primary", name: "确认" &#125; &#125; &#125; render() &#123; return ( &lt;div&gt; &#123;/* 2. 在父组件中使用 Context.Provider 提供值，必须使用 value 属性来传值*/&#125; &lt;ThemeContext.Provider value=&#123;this.state.store&#125;&gt; &lt;ToolBar&gt;&lt;/ToolBar&gt; &lt;/ThemeContext.Provider&gt; &lt;/div&gt; ) &#125;&#125; 2. 组件通信的高阶装饰器写法我们可以将上面的 Context 组件通信写成高阶组件的方式，以达到更高和更便利的复用。将 Context 定义成高阶组件如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445import React, &#123; Component &#125; from 'react'const ThemeContext = React.createContext()// 1. 装饰父组件，用于提供数据export const withProvider = (Comp)=&gt;&#123; return class extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; store : &#123; type: "primary", name: "确认" &#125; &#125; &#125; render() &#123; return ( &lt;ThemeContext.Provider value=&#123;this.state.store&#125;&gt; &lt;Comp &#123;...this.props&#125;&gt;&lt;/Comp&gt; &lt;/ThemeContext.Provider&gt; ) &#125; &#125;&#125;// 2. 装饰 Button 接收数据export const withComsumer = (Comp)=&gt;&#123; console.log("Button 装饰完成") return class extends Component &#123; render() &#123; console.log("使用新组件") return ( &lt;ThemeContext.Consumer&gt; &#123; value=&gt;&lt;Comp &#123;...this.props&#125; value=&#123;value&#125;&gt;&lt;/Comp&gt; &#125; &lt;/ThemeContext.Consumer&gt; ) &#125; &#125;&#125; 使用定义的高阶组件: 1234567891011121314151617181920212223242526272829303132import React, &#123; Component &#125; from 'react'import &#123;Button&#125; from "antd"import &#123;withComsumer, withProvider&#125; from "../Hoc/WithContext"@withComsumerclass ThemeBtn extends Component &#123; render() &#123; console.log("原始 Button组件进入") return ( &lt;Button type=&#123;this.props.value.type&#125;&gt;&#123;this.props.value.name&#125;&lt;/Button&gt; ) &#125;&#125;function ToolBar(props)&#123; return ( &lt;ThemeBtn&gt;&lt;/ThemeBtn&gt; )&#125;@withProviderclass ContextUseDec extends Component &#123; render() &#123; return ( &lt;ToolBar&gt;&lt;/ToolBar&gt; ) &#125;&#125;export default ContextUseDec]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 高阶组件]]></title>
    <url>%2F2020%2F11%2F07%2Fweb%2Freact%2Freact_7%2F</url>
    <content type="text"><![CDATA[高阶组件应用 1. 高阶组件(HOC)所谓高阶组件是一个函数，其接收一个或多个组件，返回一个新的组件。感觉上就是一个函数装饰器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import React, &#123; Component &#125; from 'react'// 一：返回函数式的高阶组件function funcHighOrderComp(Comp)&#123; console.log("新的组件") return (props)=&gt;&#123; console.log("调用新组件") const attach = &#123;'title': "react", "price": 1688&#125; return ( &lt;div&gt; &#123;/* 注意 React 中组件名必须大写 */&#125; &lt;Comp &#123;...props&#125; &#123;...attach&#125;&gt;&lt;/Comp&gt; &lt;/div&gt; ) &#125;&#125;// 二：返回类的高阶组件，组件内部就可以定义类组件的声明周期函数const funcHigh = (Comp)=&gt;&#123; return class extends Component&#123; componentDidMount()&#123; console.log("发起 Ajax 请求") &#125; render()&#123; const attach = &#123;'title': "react", "price": 1688&#125; return ( &lt;div&gt; &#123;/* 注意 React 中组件名必须大写 */&#125; &lt;Comp &#123;...this.props&#125; &#123;...attach&#125;&gt;&lt;/Comp&gt; &lt;/div&gt; ) &#125; &#125;&#125;class BaseCom extends Component &#123; render() &#123; console.log("-----------") return ( &lt;div&gt; &lt;p&gt;当前价格: &#123;this.props.price&#125;&lt;/p&gt; &lt;/div&gt; ) &#125;&#125;export default funcHigh(BaseCom) 1.1 使用装饰器实现高阶组件ES7 提供了装饰器语法，是的我们的高阶组件实现更加容易，在使用装饰器前，我们需要先安装两个包来做兼容: 123456789101112131415161718192021222324252627# 1. 安装兼容插件# cnpm install --save-dev babel-plugin-transformdecorators-legacy @babel/plugin-proposal-decoratorscnpm i craco-less -Scnpm i @babel/plugin-proposal-decorators -S# 2. 修改 craco.config.jsconst CracoLessPlugin = require('craco-less');module.exports = &#123; babel: &#123; //用来支持装饰器 plugins: [["@babel/plugin-proposal-decorators", &#123; legacy: true &#125;]] &#125;, plugins: [ &#123; plugin: CracoLessPlugin, options: &#123; lessLoaderOptions: &#123; lessOptions: &#123; modifyVars: &#123; '@primary-color': '#1DA57A' &#125;, javascriptEnabled: true, &#125;, &#125;, &#125;, &#125;, ]&#125;; 1.2 装饰器语法ES7 的装饰器语法与 Python 装饰器完全一样，上面示例中的高阶组件可以写成: 1234567891011121314151617181920212223242526272829303132const funcHigh = (Comp)=&gt;&#123; return class extends Component&#123; componentDidMount()&#123; console.log("发起 Ajax 请求") &#125; render()&#123; const attach = &#123;'title': "react", "price": 1688&#125; return ( &lt;div&gt; &#123;/* 注意 React 中组件名必须大写 */&#125; &lt;Comp &#123;...this.props&#125; &#123;...attach&#125;&gt;&lt;/Comp&gt; &lt;/div&gt; ) &#125; &#125;&#125;// 可以使用装饰器@funcHighclass BaseCom extends Component &#123; render() &#123; console.log("-----------") return ( &lt;div&gt; &lt;p&gt;当前价格: &#123;this.props.price&#125;&lt;/p&gt; &lt;/div&gt; ) &#125;&#125;export default BaseCom 2. 高阶组件的应用2.1 页面复用页面复用经常需要使用带参数的装饰器 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import React, &#123; Component &#125; from 'react'// 1. 闯将带参数的装饰器export const fetchMovie = (fetch) =&gt; (Comp) =&gt;&#123; return class extends Component&#123; constructor(props)&#123; super(props) this.state = &#123; movies: [] &#125; &#125; componentDidMount()&#123; if (fetch === "A") &#123; this.setState(&#123; movies: [ &#123; 'id': 1, 'movie': "夏洛特烦恼", 'category': "A" &#125; ] &#125;) &#125; else if (fetch === "B") &#123; this.setState(&#123; movies: [ &#123; 'id': 1, 'movie': "黄飞红", 'category': "B" &#125; ] &#125;) &#125; &#125; render()&#123; return ( &lt;div&gt; &lt;Comp &#123;...this.props&#125; data=&#123;this.state.movies&#125;&gt;&lt;/Comp&gt; &lt;/div&gt; ) &#125; &#125;&#125;// 2. 使用参数的装饰器@fetchMovie("A")export class MovieA extends Component &#123; render() &#123; return ( &lt;MovieList movieList=&#123;this.props.data&#125;&gt;&lt;/MovieList&gt; ) &#125;&#125; 2.2 权限控制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import React, &#123; Component &#125; from 'react'// 1. 带参数的高阶组件const withAuth = role =&gt; Comp =&gt; &#123; return class extends Component &#123; constructor(props) &#123; super(props) this.state = &#123; 'isAuth': false &#125; &#125; // 2. 访问后台数据，并验证用户是否具有相应的权限 componentDidMount() &#123; const user = "VIP" this.setState(&#123; 'isAuth': user === role &#125;) &#125; render() &#123; // 3. 根据是否有权限决定是否显示页面 if (this.state.isAuth) &#123; return ( &lt;Comp &#123;...this.props&#125;&gt;&lt;/Comp&gt; ) &#125; else &#123; return ( &lt;div&gt; 没有权限访问 &lt;/div&gt; ) &#125; &#125; &#125; &#125;// 4. 给组件附加权限验证@withAuth("VIP")class PageA extends Component &#123; render() &#123; return ( &lt;div&gt; Page A 页面 &lt;/div&gt; ) &#125;&#125;@withAuth("Admin")class PageB extends Component &#123; render() &#123; return ( &lt;div&gt; Page B 页面 &lt;/div&gt; ) &#125;&#125;export &#123; PageB, PageA&#125;;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 React 中的组件使用]]></title>
    <url>%2F2020%2F11%2F06%2Fweb%2Freact%2Freact_6%2F</url>
    <content type="text"><![CDATA[React 组件使用 1. 聪明组件VS傻⽠组件基本原则: 聪明组件(容器组件)负责数据获取 傻⽠组件(展示组件) 负责根据props显示信息内容 傻瓜式组件通常是函数式组件，函数通过参数进行传值，只要约定好数据接口就可以进行复用 在下面的示例中，Comment 就是我们的傻瓜式组件，接收评论内容，负责评论部分的展示。但是这个示例存在一个问题: 没请求一次评论数据，Comment 组件都会渲染一次，无论数据是否变化。此时我们需要生命周期中的 shouldComponentUpdate 方法，进行组件渲染优化。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import React, &#123; Component &#125; from 'react'function Comment(props)&#123; const &#123;id, author, content&#125; = props.comment console.log("render") return ( &lt;div&gt; &lt;p&gt;&#123;id&#125;&lt;/p&gt; &lt;p&gt;&#123;author&#125;&lt;/p&gt; &lt;p&gt;&#123;content&#125;&lt;/p&gt; &lt;/div&gt; )&#125;export default class CommentList extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; comments: [] &#125; &#125; componentDidMount()&#123; console.log("组件数据获取") setInterval(()=&gt;&#123; this.setState(&#123; comments: [ &#123; id: 1, author: "facebook", content: "react is good" &#125;, &#123; id: 2, author: "由于西", content: "vue is more good" &#125; ] &#125;) &#125;, 2000) &#125; render() &#123; // console.log(this.state.comments) return ( &lt;div&gt; &#123; this.state.comments.map(item=&gt;&#123; return &lt;Comment key=&#123;item.id&#125; comment=&#123;item&#125;&gt;&lt;/Comment&gt; &#125;) &#125; &lt;/div&gt; ) &#125;&#125; 2. 组件渲染优化前面的示例我们提到了，组件渲染的优化问题，我们有下面几种解决方案: 使用 shouldComponentUpdate 生命周期方法 让组件继承自 PureComponent: PureComponent 已实现了 shouldComponentUpdate 会自动执行 props 更新前后的比较 PureComponent 实现的的是浅层比较，因此需要改变组件传值的方式，只能传递基础类型，引用类型，如果两个对象值相同但是不同的对象，PureComponent 同样会判断为不同的对象 使用 React 高阶组件 React.memo，其功能与 PureComponent 类似 2.1 shouldComponentUpdate1234567891011121314151617181920212223class Comment extends Component&#123; shouldComponentUpdate(nextProps, nextState)&#123; // 性能优化的方法 // console.log(nextProps) // console.log(nextState) if (nextProps.comment.content === this.props.comment.content)&#123; return false &#125; else &#123; return true &#125; &#125; render()&#123; const &#123;id, author, content&#125; = this.props.comment console.log("render") return ( &lt;div&gt; &lt;p&gt;&#123;id&#125;&lt;/p&gt; &lt;p&gt;&#123;author&#125;&lt;/p&gt; &lt;p&gt;&#123;content&#125;&lt;/p&gt; &lt;/div&gt; ) &#125;&#125; 2.2 PureComponent123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import React, &#123; Component,PureComponent &#125; from 'react'// 1. 更改组件继承的类class Comment extends PureComponent&#123; render()&#123; const &#123;id, author, content&#125; = this.props console.log("render") return ( &lt;div&gt; &lt;p&gt;&#123;id&#125;&lt;/p&gt; &lt;p&gt;&#123;author&#125;&lt;/p&gt; &lt;p&gt;&#123;content&#125;&lt;/p&gt; &lt;/div&gt; ) &#125;&#125;export default class CommentList extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; comments: [] &#125; &#125; componentDidMount()&#123; console.log("组件数据获取") setInterval(()=&gt;&#123; this.setState(&#123; comments: [ &#123; id: 1, author: "facebook", content: "react is good" &#125;, &#123; id: 2, author: "由于西", content: "vue is more good" &#125; ] &#125;) &#125;, 2000) &#125; render() &#123; // console.log(this.state.comments) return ( &lt;div&gt; &#123; this.state.comments.map(item=&gt;&#123; // 更2. 改数据的传递方式 return &lt;Comment key=&#123;item.id&#125; &#123;...item&#125;&gt;&lt;/Comment&gt; &#125;) &#125; &lt;/div&gt; ) &#125;&#125; 2.3 高级组件 React.memoReact.memo 接收一个函数，返回一个函数式组件，所以称为高级组件，功能与 PureComponent 类似，可以进行自动的值比较。 12345678910const Comment = React.memo((&#123;id, author, content&#125;)=&gt;&#123; console.log("render") return ( &lt;div&gt; &lt;p&gt;&#123;id&#125;&lt;/p&gt; &lt;p&gt;&#123;author&#125;&lt;/p&gt; &lt;p&gt;&#123;content&#125;&lt;/p&gt; &lt;/div&gt; )&#125;) 3. 组件组合而非继承(重要)React 有非常强大的组合模式，推荐使用组件组合而非继承的方式实现组件的重用。下面示例的重点就是展示如何将 Button 和 Dialog 组件组合使用。 1234567891011121314151617181920212223242526272829303132333435363738394041import React, &#123; Component &#125; from 'react'import &#123;Button&#125; from "antd"function Dialog(props)&#123; return ( // 3. 设置边框样式，注意这里的 ES6 语法 &lt;div style=&#123;&#123;border: `1px solid $&#123;props.color&#125;`&#125;&#125;&gt; &#123;/* 1. 好比 vue 中的匿名插槽 */&#125; &#123;props.children&#125; &lt;div&gt; &#123;/* 4. 接收并显示组件 */&#125; &#123;props.btn&#125; &lt;/div&gt; &lt;/div&gt; )&#125;function Welcome(props)&#123; // 重点: 优先使用组件组合，将 Button 和 Dialog 组件组合使用，而不是继承 const confirmBtn = &lt;Button type='info'&gt;确认&lt;/Button&gt; return ( // 3. 也可以将组件作为属性传入其他组件中 &lt;Dialog color="red" btn=&#123;confirmBtn&#125;&gt; &#123;/* 2. Dialog 内的内容将作为 props.children 传给 Dialog 的 props */&#125; &lt;h3&gt;Welcom&lt;/h3&gt; &lt;p&gt;你好，欢迎光临&lt;/p&gt; &lt;/Dialog&gt; ) &#125;export default class Compod extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;Welcome&gt;&lt;/Welcome&gt; &lt;/div&gt; ) &#125;&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 组件使用]]></title>
    <url>%2F2020%2F11%2F05%2Fweb%2Freact%2Freact_5%2F</url>
    <content type="text"><![CDATA[React 表单: 受控组件和非受控组件 1. antd 概述antd 类似于 Vue 中的 vue-element-ui，是一个样式和表单组件的库 1. 安装1cnpm i antd -S 2. 导入与 vue-element-ui 类似，全局导入 antd 会对服务器造成较大的压力，推荐使用局部导入的方式文档: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 1. 安装 cracoyarn add @craco/cracocnpm i @craco/craco -S# 装饰器的插件yarn add @babel/plugin-proposal-decoratorsyarn add craco-less# 2. 修改 package.json 里的 scripts 属性"scripts": &#123;- "start": "react-scripts start",- "build": "react-scripts build",- "test": "react-scripts test",+ "start": "craco start",+ "build": "craco build",+ "test": "craco test",&#125;# 3. 在项目根目录创建一个 craco.config.js 用于修改默认配置module.exports = &#123; // ...&#125;;# 如果要支持装饰器语法，需要将 craco.config.js 配置为const CracoLessPlugin = require('craco-less');module.exports = &#123; babel: &#123; //用来支持装饰器 plugins: [["@babel/plugin-proposal-decorators", &#123; legacy: true &#125;]] &#125;, plugins: [ &#123; plugin: CracoLessPlugin, options: &#123; lessLoaderOptions: &#123; lessOptions: &#123; modifyVars: &#123; '@primary-color': '#1DA57A' &#125;, javascriptEnabled: true, &#125;, &#125;, &#125;, &#125;, ]&#125;;# 4. App.js 中部分导入import &#123;Button&#125; from "antd"import './App.css'# 5. App.css 中导入样式@import '~antd/dist/antd.css';]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 React 生命周期和受控组件]]></title>
    <url>%2F2020%2F11%2F04%2Fweb%2Freact%2Freact_4%2F</url>
    <content type="text"><![CDATA[React 生命周期 1. React 生命周期的钩子函数 1.1 react 生命周期钩子函数示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879import React, &#123; Component &#125; from 'react'class SubCount extends Component &#123; // 此方法在 父组件 render() 调用后，render() 完成前调用，因为子组件肯定在父组件 render() 函数内被使用 componentWillReceiveProps(newProps)&#123; console.log('子组件将要接收新属性',newProps); &#125; render() &#123; return ( &lt;div&gt; &lt;/div&gt; ); &#125;&#125;export default class LifyCycle extends Component &#123; static defaultProps = &#123; //1.加载默认的属性 name: '小马哥', age: 18 &#125; constructor(props) &#123; super(props); console.log('1.初始化 加载默认的状态'); this.state = &#123; count: 0 &#125; &#125; componentWillMount() &#123; console.log('2.父组件将要被挂载'); &#125; componentDidMount() &#123; // 当前的这个方法中，发起ajax请求，获取数据 数据驱动视图 console.log('4.父组件挂载完成'); &#125; shouldComponentUpdate(nextProps, nextState) &#123; // 性能的优化点 重要 console.log('5.组件是否要更新'); if (nextState.count % 2 === 0) &#123; return true; &#125; else &#123; return false; &#125; &#125; componentWillUpdate()&#123; console.log('7.组件将要更新'); &#125; componentDidUpdate() &#123; console.log('8.组件已经更新完成'); &#125; componentWillUnmount() &#123; console.log('组件卸载完成'); &#125; handleClick = () =&gt; &#123; this.setState((preveState, preveProps) =&gt; (&#123; count: preveState.count + 1 &#125;), () =&gt; &#123; console.log(this.state.count); &#125;) &#125; render() &#123; console.log('3.父组件(render)了'); return ( &lt;div&gt; &lt;h2&gt;当前的值:&#123;this.state.count&#125;&lt;/h2&gt; &lt;button onClick=&#123;this.handleClick&#125;&gt;+1&lt;/button&gt; &lt;SubCount count=&#123;this.state.count&#125;&gt;&lt;/SubCount&gt; &lt;/div&gt; ) &#125;&#125; 2. 受控组件受控组件，就是受状态控制的组件，需要与状态进⾏相应的绑定 受控组件必须要有⼀个 onChange 事件，否则不能使⽤ 受控组件可以赋予默认值（实际上就是设置初始状态） 官⽅推荐使⽤受控组件的写法，可以使⽤受控组件实现双向绑定。 无论受控和非受控组件，目的都是获取表单的值。受控组件通过绑定表单的 value 到 state 属性，然后通过 state 属性获取表单的值；非受控组件则是通过 ref 获取表单的引用，通过直接操作 DOM 来获取表单的值。 一个受控组件的实现如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445import React, &#123; Component &#125; from 'react'export default class Control extends Component &#123; constructor(props)&#123; super(props) this.state = &#123; val: "", // 1. 为表单设置默认值 data: [] &#125; &#125; handleInput(e)&#123; // 4. 通过 onChange 事件捕获表单输入值，实现双向数据绑定 let val = e.target.value; this.setState(&#123; val &#125;) &#125; handleClick()&#123; let data = [...this.state.data] data.push(this.state.val) console.log(data) this.setState(&#123; val: "", data: data &#125;) &#125; render() &#123; return ( &lt;div&gt; &lt;p&gt;当前输入值: &#123;this.state.val&#125;&lt;/p&gt; &#123;/* 2. value 属性绑定默认值 */&#125; &#123;/* 3. onChange 事件用来捕获表单输入并更新组件状态 */&#125; &lt;input type="text" value=&#123;this.state.val&#125; onChange=&#123;(e)=&gt;this.handleInput(e)&#125;/&gt; &lt;button onClick=&#123;()=&gt;this.handleClick()&#125;&gt;添加&lt;/button&gt; &lt;ul&gt; &#123; this.state.data &amp;&amp; this.state.data.map((item, index)=&gt;&#123; return &lt;li key=&#123;index&#125;&gt;&#123;item&#125;&lt;/li&gt; &#125;) &#125; &lt;/ul&gt; &lt;/div&gt; ) &#125;&#125; 3. 非受控组件一个非受控组件实现如下: 12345678910111213141516171819202122232425262728export class UnCotrol extends Component&#123; constructor(props)&#123; super(props) this.state = &#123; val: "" &#125; &#125; handleInput(e)&#123; let v1 = e.target.value // 2. 我们可以通过事件获取表单输入的值 // 3. 通过 this.refs.a 我们可以获取 ref="a" 标识的组件，这种方式我们也可以获取表单输入的值 let v2 = this.refs.a.value console.log(v1, v2) this.setState(&#123; val: v1 &#125;) &#125; render()&#123; return ( &lt;div&gt; &lt;p&gt;输入: &#123;this.state.val&#125;&lt;/p&gt; &#123;/* 1. input 输入框并没有绑定组件状态 */&#125; &lt;input type="text" onChange=&#123;(e)=&gt;&#123;this.handleInput(e)&#125;&#125; ref="a"/&gt; &lt;/div&gt; ) &#125;&#125; 4. React 中表单的使用React 中的表单都是通过受控组件来实现即通过 value=组件状态和 onChange 事件来实时获取表单中的值。不同表单的使用示例可以看官方文档。下面是摘录的 select 表单使用示例: 123456789101112131415161718192021222324252627282930313233343536class FlavorForm extends React.Component &#123; constructor(props) &#123; super(props); this.state = &#123;value: 'coconut'&#125;; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); &#125; handleChange(event) &#123; this.setState(&#123;value: event.target.value&#125;); &#125; handleSubmit(event) &#123; alert('你喜欢的风味是: ' + this.state.value); // 阻止默认事件，才会执行接下来定义的操作 event.preventDefault(); &#125; render() &#123; return ( &lt;form onSubmit=&#123;this.handleSubmit&#125;&gt; &lt;label&gt; 选择你喜欢的风味: &lt;select value=&#123;this.state.value&#125; onChange=&#123;this.handleChange&#125;&gt; &lt;option value="grapefruit"&gt;葡萄柚&lt;/option&gt; &lt;option value="lime"&gt;酸橙&lt;/option&gt; &lt;option value="coconut"&gt;椰子&lt;/option&gt; &lt;option value="mango"&gt;芒果&lt;/option&gt; &lt;/select&gt; &lt;/label&gt; &lt;input type="submit" value="提交" /&gt; &lt;/form&gt; ); &#125;&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 React 组件]]></title>
    <url>%2F2020%2F11%2F03%2Fweb%2Freact%2Freact_3%2F</url>
    <content type="text"><![CDATA[React 组件化开发 1. React 组件化开发React 核心就是组件化开发，其核心就是使用 JavaScript，React创建组件有来两种⽅式 函数声明 类声明 1.1 函数式组件12345function Welcome(props)&#123; return &lt;h2&gt;hello,&#123;props.name&#125;&lt;/h2&gt;&#125;ReactDOM.render(&lt;Welcome name="tsong"/&gt;, document.queryBySelect("#root)) 函数式组件有三个使用要点: 函数声明的组件,必须返回⼀个JSX元素 可以通过属性给组件传递值,函数通过 props 参数属接收 函数名必须要大写 1.2 类声明组件1234567891011// 通过 vscode 插件和 rcc 指令可以自动生成如下的模板代码class App extends React.Component&#123; constructor(props)&#123; super(props) &#125; render()&#123; return &lt;h2&gt;Hello, &#123;this.props.name&#125;&lt;/h2&gt; &#125;&#125;ReactDOM.render(&lt;App name="你好"/&gt;, document.querySelector("#root")) 使用类声明的组件有如下几个使用要点: 在React中有⼀个属性Component,是⼀个基类,使⽤类声明组件时,必须继承这个基类 在类中,必须有render函数, render 函数中,需要return⼀个JSX元素 constructor 不是必须的，如果需要 constructor，必须接受 props 作为参数，并调用父类初始化方法传入 props 组件名称必须以⼤写字⺟开头，React会将⼩写字⺟开头的组件称之为标签 同函数组件一样可以通过属性给组件传递值，JSX 所接收的属性（attributes）转换为单个对象作为 props 参数传递给类的构造函数，并保存为类的 props 属性 1.3 两种方式对比真实项⽬中,都只使⽤class定义组件。class定义的组件中有this,状态、⽣命周期；function声明都没有。 2. 组件间通信前面我们已经演示了如何由父组件向子组件传值: 通过组件属性，并通过 props 接收的方式。接下来我们来看看在 react 如何实现子向父传值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import React, &#123; Component &#125; from 'react'class Comment extends Component&#123; // 4. 子组件同样存在 this 指向问题，需要使用箭头函数定义 handleClick = ()=&gt;&#123; console.log("子组件button") // 5. 调用传入的父组件的方法，向父组件传值 this.props.add("子组件传递过来的值") &#125; render()&#123; return ( // 3. 子组件中定义 onClick 事件 &lt;div&gt; &lt;p&gt;计数: &#123;this.props.state.count&#125;&lt;/p&gt; &lt;button onClick=&#123;this.handleClick&#125;&gt;+1&lt;/button&gt; &lt;/div&gt; ) &#125;&#125;export default class App extends Component &#123; constructor(props)&#123; super(props) // 必须在初始化时声明 state 对象和相应属性，才能在后续的 setState 方法使用和更改 this.state = &#123; count: 0 &#125; &#125; add(val)&#123; console.log(this) this.state.count += 1 console.log(this.state.count) // 直接修改值是无法生效的 // this.setState(&#123; // count: this.state.count + 1 // &#125;) &#125; add1 = (val) =&gt;&#123; console.log(this) this.state.count += 1 console.log(this.state.count) // 直接修改值是无法生效的 // this.setState(&#123; // count: this.state.count + 1 // &#125;) &#125; render() &#123; return ( // 1. 父组件通过组件属性向子组件传递 add 函数 // 2. 为了保证 add 函数内部的 this 指向，有两种处理方式: // - 在绑定 add 属性时，使用箭头函数 // - 将 Parent 的 add 方法直接定义为箭头函数，eg: add1 &lt;div&gt; &lt;Comment state=&#123;this.state&#125; add=&#123;()=&gt;this.add()&#125;&gt;&lt;/Comment&gt; &lt;Comment state=&#123;this.state&#125; add=&#123;this.add1&#125;&gt;&lt;/Comment&gt; &lt;/div&gt; ) &#125;&#125; react 子向父组件传值的要点是: 父组件首先需要向子组件传入接收值的方法 子组件中通过表单或其他方式更改值后，通过调用父组件传入的方法，向父组件传值 3. 组件状态react 中每个组件都会维护自身的状态 state ，即组件中维护的数据，要想修改组件中的数据，并让 react 重新渲染，我们必须使用 react 提供的特殊方法 this.setState。下面是使用示例: 123456789101112131415161718192021222324252627282930313233export default class App extends React.Component&#123; constructor(props)&#123; super(props) // 3. state 是 react 组件类的一个特殊属性 this.state = &#123; count: 0 &#125; &#125; add(e)&#123; console.log(e) // 1. 修改属性值必须通过 this.setState 方法 this.setState(&#123; // 4. count 键对应的属性为 this.state.count，react 会合并并更新 this.state 的值 // 5. this.state.count 的更新是一个异步操作 count: this.state.count + 1 &#125;) console.log(this.state.count); // 6. 因为异步更新，此时是拿不到新值的 &#125; addE=(e)=&gt; &#123; console.log(this) console.log(e) &#125; render()&#123; return ( // 2. 修改 add 函数的 this 指向 &lt;div&gt; &lt;p&gt;计数: &#123;this.state.count&#125;&lt;/p&gt; &lt;button onClick=&#123;(e)=&gt;this.add(e)&#125;&gt;+1&lt;/button&gt; &lt;button onClick=&#123;this.addE&#125;&gt;+1&lt;/button&gt; &lt;/div&gt; ) &#125;&#125; 在上面的示例中有如下几点需要注意: React 中组件的状态(数据)，分为传入的数据 props 和自身定义的是数据 state，props 的数据是不能修改的，而修改 state 数据必须使用 this.setState button onClick 事件触发的函数 this 指向的是标签元素，为了在 add 中访问到 react 的属性值，我们必须修改 add 函数的 this 指向。推荐使用示例中添加额外箭头函数的方式，这样可以保留事件触发时的 event 对象，或者直接将 add 方法定义为箭头函数并接收事件对象效果是完全一样的 在 this.setState 中更新属性值的操作是一个异步操作 3.1 setStatereact 组件 this.setState 方法中组件状态的更新是一个异步操作，如果我们想使用组件状态中最新的值，必须使用另一种 this.setState 的使用方式(函数式使用方式): 第一个参数，接收当前 this.state 和 this.props 作为参数，执行修改组件状态的方法 第二个参数，是一个回调函数，在函数内部就可以获取组件状态的最新值 1234567891011121314151617export default class App extends React.Component&#123; constructor(props)&#123; super(props) this.state = &#123; count: 0 &#125; &#125; add(e)&#123; console.log(e) this.setState((state, props)=&gt;(&#123; count: state.count + 1 &#125;),()=&gt;&#123; console.log(this.state.count) &#125;) // 注意: 此处只能拿到更新前的值 console.log(this.state.count) &#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 React 基础]]></title>
    <url>%2F2020%2F11%2F02%2Fweb%2Freact%2Freact_2%2F</url>
    <content type="text"><![CDATA[React 使用入门 1. React 项目创建1.1 create-react-app 安装12345678910111213# 安装脚手架cnpm i -g create-react-app# 创建项目create-react-app react_hello# 启动项目cd react_helloyarn start# 安装 ant-designcnpm i antd -Syarn add antd create-react-app react_hello 创建项目后，默认会安装如下三个包: react: react 核心 api 库 react-dom: 将虚拟 DOM 渲染成真实 DOM react-scripts: react 运行、打包、编译的脚本库 1.2 项目创建123456789101112131415161718192021222324252627282930313233// src/index.jsimport React from "react"import ReactDOM from "react-dom"const user = &#123; firstName: "小", lastName: "马哥"&#125;function formatName(user)&#123; return user.firstName + user.lastName&#125;function greatUser(user)&#123; if (user)&#123; // JSX 可以在任何地方使用 return &lt;h2&gt;&#123;formatName(user)&#125;&lt;/h2&gt; &#125; return &lt;h2&gt;hello, react&lt;/h2&gt;&#125;// 这种在 JS 中包含标签的用法称为 JSX，ele 是一个对象// JSX = JavaScript + XML 表示一个虚拟 DOM -- 一种语法糖// JSX 可以在任意地方使用// 类似 Vue 里面 &#123;&#123; &#125;&#125; 的插值语法，在 JSX中可以使用 &#123;&#125; 进行插值 // 注意不能直接使用 &#123;greatuser(user)&#125;，因为 &#123;&#125; 插值语法只能在 JSX 中使用，&#123;&#125; 插值需要一个标签承接const ele = &lt;div&gt;&#123;greatUser(user)&#125;&lt;/div&gt;console.log(ele)// ReactDOM.render 渲染页面ReactDOM.render(ele, document.querySelector("#root")) 2. JSX类似 &lt;div&gt;{&quot;react&quot;}&lt;/div&gt; 的 JSX 对象在编译时，会被 babel-react 插件编译成 JS 的对象 React.DOM。所以无论 JS 是否使用了 react 模块，只要使用了 JSX 都要导入 React import React from &#39;react&#39; 记住 JSX 就是一个对象，并且这个对象中可以使用 {} 插值语法。所以编写 React 就跟编写 JS 一样，不像 Vue 有其他额外的语法。 2.1 元素渲染元素是构成React应⽤的最⼩砖块,⽐如: const ele = &lt;h1&gt;hello,world&lt;/h1&gt;。与浏览器的 DOM 元素不同， React 元素是创建开销极⼩的普通对象。 React DOM 会负责更新 DOM 来与 React 元素保持⼀致。 React只需要更新它需要更新的部分，React DOM会将元素和它的⼦元素与它们之前的状态进⾏⽐较(diff 算法),并只会进⾏必要的更新来使DOM达到预期的状态。有关 diff 算法，我们在后面源码学习部分在详细介绍。 2.2 循环绑定元素123456789let ul = (&lt;ul&gt; &#123; arr.map((item, index)=&gt;&#123; return ( item.price &lt; 1000 ? null : &lt;li key=&#123;index&#125;&gt;&#123;item&#125;&lt;/li&gt;; ) &#125;) &#125;&lt;/ul&gt;) 在React中,循环绑定元素都是使⽤ map ⽅法,不能使⽤ forEach 是因为 forEach没有返回值。过滤元素只要把不符合条件的元素,返回为 null 即可。 2.3 其他资源使用在 react 中使用组件时，一切皆模块，诸如 css，图片都可以导入到 react 的 js 文件中并在直接使用，像下面这样: 12345678910111213141516171819202122232425262728293031323334import React, &#123; Component &#125; from 'react'import './App.css' // 1. 导入 css 文件，应用样式import Logo from './logo.svg' // 2. 导入图片，并使用变量接收class MyButton extends Component &#123; render() &#123; return ( &lt;div&gt; &lt;button&gt;&#123;this.props.name&#125;&lt;/button&gt; &lt;img src=&#123;Logo&#125; alt=""/&gt; &lt;/div&gt; ) &#125;&#125;export default class App extends React.Component&#123; constructor(props)&#123; super(props) this.user = &#123; name: '设置', &#125; &#125; render()&#123; return ( &lt;div&gt; // 解构传值，与直接设置属性值类似 &lt;MyButton &#123;...this.user&#125;&gt;&lt;/MyButton&gt; &lt;MyButton name="删除"&gt;&lt;/MyButton&gt; &lt;/div&gt; ) &#125;&#125; 3. 项目结构每个框架的使用都有其最佳实践，目的是将将项目划分为特定的多个模块，使我们的开发更加高效。React 项目典型的组织方式如下: 123456789my-react # 项目陆慕 public # 静态文件 src # 源码目录 store # redux 数据共享的目录 index.js # 创建 redux store cart.js # 购物车共享的 redux Reducer 和映射的方法 login.js # 登录共享的 redux Reducer 和映射的方法 ..... pages # react-router 的路由组件]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 React 入门开篇]]></title>
    <url>%2F2020%2F11%2F01%2Fweb%2Freact%2Freact_1%2F</url>
    <content type="text"><![CDATA[这个系列是 React.js 框架的使用，目的是能使用 React 开发开发常见的 Web 应用。 1. React 内容概述我们将分为如下几个部分来详细讲解 React 的使用: React 基础，包括 使用 create-react-app 创建项目 JSX与模板语法 diff 算法更新过程 setState 数据更新 React 组件化开发，包括 props 传值和组件间通信 React 生命周期 组件开发之如何设计一个类似 Ant Design 的 form 表单 React Router 2. 学习资料React 的参考资料主要是 React 的官方文档。与 React 相比 React 提供的 api 更接近原生 JS，没有额外的过多语法，所以看上一边文档，就差不多了。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>React</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 Vue Xmall 商城实战]]></title>
    <url>%2F2020%2F10%2F11%2Fweb%2Fvue%2Fvue_11%2F</url>
    <content type="text"><![CDATA[Vue 项目实战，实现一个 Xmall 的购物商城 1. 项目构建123456789101112131415161718# 1. 项目创建# 选择 bable，vuex vue routervue create xmall # 2. 安装 element-uivue add element # 选择局部安装# 3. 安装 sass# https://cli.vuejs.org/zh/guide/css.htmlcnpm install -D sass-loader sass# 4. 安装 axioscnpm i axios -S# 5. 安装图片懒加载库cnpm i vue-lazyload -S# 6. 删除默认内置的路由和组件]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 Vuex]]></title>
    <url>%2F2020%2F10%2F10%2Fweb%2Fvue%2Fvue_10%2F</url>
    <content type="text"><![CDATA[Vuex 状态管理和数据共享 1. Vuex 概述Vuex 是⼀个专为 Vue.js 应⽤程序开发的状态管理模式。它采⽤集中式存储管理应⽤的所有组件的状态，并以相应的规则保证状态以⼀种可预测的⽅式发⽣变化。 为了修改 Vuex 中保存的数据，需要调用在 Actions 和 Mutations 中定义的方法: Actions 中定义的是异步方法，所有异步操作必须经由 Actions 去调用 Mutations Mutations 中定义的是同步的方法，如果 Mutations 中定义异步方法会造成数据的不一致 修改状态的唯一方法就是提交 Mutations Vuex 通常用于大型项目中不相关的组件之间的通信。 1.1 vuex 安装12cnpm i vuex -Svue add vuex 2. Vuex 使用2.1 Vuex 创建vue add vuex 后，在项目的根目录中我们将看到以下几个文件: scr/store/index.js: 初始化 Vuex src/main.js: 导入并挂载 Vuex 的实例 12345678910111213141516171819202122232425262728293031323334import Vue from 'vue'import Vuex from 'vuex'Vue.use(Vuex)export default new Vuex.Store(&#123; state: &#123; // 保存着共享的数据 count: 0 &#125;, getters: &#123; // 定义取值器，用于封装一些复杂的计算逻辑 isOver(state)&#123; return state.count &gt; 10 &#125; &#125;, mutations: &#123; // 声明的同步方法 add(state, amount=1)&#123; // 修改状态 state.count++ &#125;, sub(state)&#123; state.count-- &#125; &#125;, actions: &#123; // 声明的异步方法 add(context, amount=1)&#123; // context 是 Vuex自动传入的，其他参数是组件调用 dispatch 传入的其他参数 // commit mutations 中声明的方法 let &#123;commit&#125; = context; commit("add", amount); &#125; &#125;, modules: &#123; &#125;&#125;) 123456789101112131415// main.jsimport Vue from 'vue'import App from './App.vue'import router from './router'// 导入import store from './store'Vue.config.productionTip = falsenew Vue(&#123; router, // 挂载 store, render: h =&gt; h(App)&#125;).$mount('#app') 2.2 Vuex 使用Vuex 实例已经挂载到 Vue的原型上，通过 Vue 实例的 $store 属性，我们就可以访问到共享数据。 12345678910111213141516171819202122232425262728293031323334353637383940&lt;template&gt; &lt;div class="home"&gt; &#123;&#123;count&#125;&#125; &lt;button @click="add"&gt;+1&lt;/button&gt; &lt;button @click="sub"&gt;-1&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;// @ is an alias to /srcexport default &#123; name: 'Home', components: &#123; &#125;, computed: &#123; count() &#123; // 获取 Vuex getters 中定义的值 console.log(this.$store.getters.isOver); return this.$store.state.count; &#125; &#125;, methods: &#123; add() &#123; // dispatch 去触发 Actions 中对应的方法 // 传递给 dispatch/commit 的额外参数会传递给 Vuex 中对应的方法 this.$store.dispatch('add', 100) // dispatch 的另一种书写方式 this.$store.dispatch(&#123; type: "add", amount: 100 &#125;) &#125;, sub()&#123; // 如果不涉及异步操作，也只可以调用 Mutation 中定义的方法 this.$store.commit("sub") &#125; &#125;,&#125;&lt;/script&gt; 2.1 添加插件Vuex 自带一个日志插件用于一般的调试: 12345import createLogger from 'vuex/dist/logger'const store = new Vuex.Store(&#123; plugins: [createLogger()]&#125;) 3. Vuex 的辅助函数从上面的示例中我们可以看到，为了去修改 Vuex 中的函数，我们可能会需要编写多个重复调用的函数。为了方便 Vuex 共享数据的操作， Vuex 提供了一些辅助函数: mapState mapGetters mapMutations, mapActions 上面我们定义的方法也可用辅助函数，重写如下: 123456789101112131415161718192021222324252627&lt;script&gt;// @ is an alias to /srcimport &#123;mapState, mapGetters, mapMutations, mapActions&#125; from 'vuex';export default &#123; name: 'Home', components: &#123; &#125;, computed: &#123; count() &#123; console.log(this.$store.getters.isOver); return this.$store.state.count; &#125;, ...mapState(['username']), // 自定义 state 在本组件的变量名，其他辅助函数使用类似 ...mapState(&#123; myCount: 'count' &#125;), ...mapGetters(['isOver']) &#125;, methods: &#123; ...mapActions(['add']), ...mapMutations(['sub']) &#125;,&#125;&lt;/script&gt; 使用辅助函数的不方便之处在于，没法想 Vuex 中定义的方法传递参数，如果需要传递参数则必须使用之前定义的方式。 4. Vuex 的模块化Vuex 通过 models 可以进行模块化，并定义命名空间，便于大型项目中的数据共享管理。这也是 Vuex 相比于共享事件总线优越的地方。我们可以像下面这样定义 Vuex 模块: 在 src/store 下创建目录 modules，并新建 cart.js, product.js 分别表示购物车和产品列表的数据 在 Vuex 实例的 modules 属性中注册 cart.js product.js 共享模块 使用辅助函数或者直接操作 vuex 实例时要加上命名空间 如果希望你的模块具有更高的封装度和复用性，你可以通过添加 namespaced: true 的方式使其成为带命名空间的模块。当模块被注册后，它的所有 getter、action 及 mutation 都会自动根据模块注册的路径调整命名。比如: 12345678910111213141516171819202122232425262728293031323334353637383940const store = new Vuex.Store(&#123; modules: &#123; account: &#123; namespaced: true, // 模块内容（module assets） state: () =&gt; (&#123; ... &#125;), // 模块内的状态已经是嵌套的了，使用 `namespaced` 属性不会对其产生影响 getters: &#123; isAdmin () &#123; ... &#125; // -&gt; getters['account/isAdmin'] &#125;, actions: &#123; login () &#123; ... &#125; // -&gt; dispatch('account/login') &#125;, mutations: &#123; login () &#123; ... &#125; // -&gt; commit('account/login') &#125;, // 嵌套模块 modules: &#123; // 继承父模块的命名空间 myPage: &#123; state: () =&gt; (&#123; ... &#125;), getters: &#123; profile () &#123; ... &#125; // -&gt; getters['account/profile'] &#125; &#125;, // 进一步嵌套命名空间 posts: &#123; namespaced: true, state: () =&gt; (&#123; ... &#125;), getters: &#123; popular () &#123; ... &#125; // -&gt; getters['account/posts/popular'] &#125; &#125; &#125; &#125; &#125;&#125;) 4.1 在带命名空间的模块内访问全局内容如果你希望使用全局 state 和 getter，rootState 和 rootGetters 会作为第三和第四参数传入 getter，也会通过 context 对象的属性传入 action。 若需要在全局命名空间内分发 action 或提交 mutation，将 { root: true } 作为第三参数传给 dispatch 或 commit 即可。 12345678910111213141516171819202122232425262728293031modules: &#123; foo: &#123; namespaced: true, getters: &#123; // 在这个模块的 getter 中，`getters` 被局部化了 // 你可以使用 getter 的第四个参数来调用 `rootGetters` someGetter (state, getters, rootState, rootGetters) &#123; getters.someOtherGetter // -&gt; 'foo/someOtherGetter' rootGetters.someOtherGetter // -&gt; 'someOtherGetter' &#125;, someOtherGetter: state =&gt; &#123; ... &#125; &#125;, actions: &#123; // 在这个模块中， dispatch 和 commit 也被局部化了 // 他们可以接受 `root` 属性以访问根 dispatch 或 commit someAction (&#123; dispatch, commit, getters, rootGetters &#125;) &#123; getters.someGetter // -&gt; 'foo/someGetter' rootGetters.someGetter // -&gt; 'someGetter' dispatch('someOtherAction') // -&gt; 'foo/someOtherAction' dispatch('someOtherAction', null, &#123; root: true &#125;) // -&gt; 'someOtherAction' commit('someMutation') // -&gt; 'foo/someMutation' commit('someMutation', null, &#123; root: true &#125;) // -&gt; 'someMutation' &#125;, someOtherAction (ctx, payload) &#123; ... &#125; &#125; &#125;&#125; 4.2 使用示例下面是使用 vuex 模块构建购物车的一个完整案例: 1234567891011121314151617181920212223242526272829303132333435363738394041// cart.jsexport default &#123; namespaced: true, // 将模块注册为单独的命名空间，命名空间的名称同 Vuex modules 挂载的名称 state: &#123; cartList: [] &#125;, getters:&#123; cartCount(state)&#123; return state.cartList.length; &#125; &#125;, actions: &#123; &#125;, mutations: &#123; &#125;&#125;// store/index.jsimport Vue from 'vue'import Vuex from 'vuex'Vue.use(Vuex)import cart from './modules/cart'import product from './modules/product'export default new Vuex.Store(&#123; state: &#123; // 保存着共享的数据 &#125;, getters: &#123; &#125;, mutations: &#123; // 声明的同步方法 &#125;, actions: &#123; // 声明的异步方法 &#125;, modules: &#123; // 挂载 Vuex 模块 cart, // cart 名称也将作为命名空间使用 product &#125;&#125;) 使用带命名空间的 Vuex12345678910111213141516171819202122232425&lt;template&gt; &lt;div&gt; &#123;&#123;cartCount&#125;&#125; &#123;&#123;myCount&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import &#123;mapGetters&#125; from 'vuex' export default &#123; computed: &#123; // 第一参数为命名空间 ...mapGetters('cart', ['cartCount']), myCount()&#123; console.log(this.$store) return this.$store.getters['cart/cartCount']; &#125; &#125;, &#125;&lt;/script&gt;&lt;style lang="scss" scoped&gt;&lt;/style&gt; 5. Vuex 实战实战项目是做一个从购物页面，添加商品到购物车中，我们按照如下方式组织模块: 定义两个 vuex 模块 cart.js, product.js 分别管理商品列表页和购物车里的商品 定义两个组件，购物车和商品列表组件，用于展示所有商品和购物车 两个组件通过 vuex 共享和互操作数据。 vuex 的存在，将数据和数据的操作集中到了一起，组件只是简单的使用了 vuex 中定义的数据和方法。 5.1 product.js123456789101112131415161718192021222324252627282930313233import axios from 'axios'export default &#123; namespaced: true, state: &#123; products: [] &#125;, actions: &#123; // 获取所有商品 async getProducts(&#123;commit&#125;) &#123; try &#123; let res = await axios.get("api/products") let result = res.data.result // console.log(result) commit('getProducts', result) &#125; catch (error) &#123; console.log(error) &#125; &#125; &#125;, mutations: &#123; getProducts(state, products)&#123; state.products = products &#125;, // 减少商品库存 subProduct(state, &#123;id&#125;)&#123; let product = state.products.find(item=&gt;item.id===id); console.log(product) product.inventory-- &#125; &#125;&#125; 5.2 cart.js123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657export default &#123; namespaced: true, // 将模块注册为单独的命名空间，命名空间的名称同 Vuex modules 挂载的名称 state: &#123; cartList: [] &#125;, getters:&#123; cartCount(state)&#123; return state.cartList.length; &#125;, // rootState 表示根 vuex 实例 cartList(state, getters, rootState)&#123; // console.log(rootState.product.products); return state.cartList.map((&#123;id, num&#125;)=&gt;&#123; let product = rootState.product.products.find(item=&gt;item.id === id) return &#123; price: product.price, title: product.title, num: num &#125; &#125;) &#125;, /// getters 表示当前 getters cartMoney(state, getters)&#123; return getters.cartList.reduce((sum, item)=&gt;&#123; return sum + item.price * item.num &#125;, 0) &#125; &#125;, actions: &#123; // 1. 添加购物车 addCart(&#123;commit, state&#125;, product)&#123; let i = state.cartList.find(item=&gt;item.id === product.id) if (!i)&#123; // 商品不存在 commit('addCart', &#123;id: product.id, num: 1&#125;) &#125; else&#123; commit('increCart', &#123;id: product.id&#125;) &#125; // 如果想提交另一个 vuex 模块的 Mutations 方法，需要第三个参数 &#123;root: true&#125; commit('product/subProduct', &#123;id: product.id&#125;, &#123;root: true&#125;) &#125; &#125;, mutations: &#123; // 1. 添加购物车 addCart(state, &#123;id, num&#125;)&#123; state.cartList.push(&#123; id, num &#125;) &#125;, // 2. 增加购车的计数 increCart(state, &#123;id&#125;)&#123; let product = state.cartList.find(item=&gt;item.id === id); product.num++ &#125; &#125;&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 Vue Router]]></title>
    <url>%2F2020%2F10%2F09%2Fweb%2Fvue%2Fvue_9%2F</url>
    <content type="text"><![CDATA[Vue Router 路由管理 1. Vue-Router 概述Vue-Router 是 vue 中构建单页面应用的组件，提供了路由功能: 多页面应用: 每一页都是一个 .html 页面，便于做 SEO 优化 单页面应用: 单个 html 页面，通过 a 标签切换不同的视图 典型的单页面应用包括使用 vue-element-admin 制作的后台管理系统。 1.1 安装12npm i vue-router -Svue add router 2. Vue-Router 使用当我们在项目添加 vue-router 后，vue-cli 会在项目中为我们添加如下几个文件: src/router/index.js: 实例化路由的地方 src/views: 路由组件，又称为视图 要想使用路由组件需要如下几个步骤: 在 router/index.js 中实例化路由组件实例 在 main.js 中将路由组件实例挂载到根 Vue 实例中，此时我们在每一个 vue 组件中获取如下两个对象: $router: 路由对象，提供了编程式导航的功能 $route: 路由信息对象，提供了获取路由参数的功能 在 App.vue 中使用 &lt;router-link&gt; 和 &lt;router-view&gt; 显示视图 router/index.js 中路由匹配的优先级按照定义从上往下，优先级越来越低 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// 1. router/index.jsimport Vue from "vue"import VueRouter from "vue-router"import About from '@/views/About.vue';import Home from '@/views/Home.vue'// 挂载 VueRouter 的组件，这样才能使用后面的 &lt;router-link&gt; 和 &lt;router-view&gt;Vue.use(VueRouter)const router = new VueRouter(&#123; mode: "history", // 历史模式，url 中不会出现 # // 路由匹配的优先级按照定义从上往下，优先级越来越低 routes:[ &#123; path: '/', component: Home &#125;, // 3. 路由别名 &#123; path: '/about', component: About alias: "/aaaa" &#125;, // 1. 路由重定向 &#123; path: '/redirect', redirect: '/about' &#125;, // 1. 路由重定向 &#123; path: '/aaa', redirect: &#123;name: "about"&#125; &#125;, // 2. 404 页面 // 通过 * 模糊匹配，我们可以定义 404 页面 &#123; path: '*', // ES6 中动态加载模块 component: () =&gt; import('@/views/404.vue') &#125; ]&#125;)export default router// 2. main.jsimport Vue from 'vue'import App from './App.vue'import router from '@/router';Vue.config.productionTip = falsenew Vue(&#123; // 挂载到实例中 router, render: h =&gt; h(App)&#125;).$mount('#app')// 3. app.vue 中定义路由出口&lt;template&gt; &lt;div id="app"&gt; &lt;div id="nav"&gt; &lt;!-- router-link 相当于 a 标签，to 属性相当于 href 属性 --&gt; &lt;router-link to="/"&gt;Home&lt;/router-link&gt; | &lt;router-link to="/about"&gt;About&lt;/router-link&gt; &lt;/div&gt; &lt;!-- 相当于路由组件的出口, router-link 匹配的路由组件就会被渲染到此处 --&gt; &lt;router-view/&gt; &lt;/div&gt;&lt;/template&gt; 上面是 vue-router 的基本使用，在这些基础使用上 vue-router 提供了其他”扩展”，包括: 命名路由 动态路由 路由查询参数 接下来我们一一介绍 2.1 命令路由所谓命名路由，就是对路由命名，并基于命名使用路由组件。 定义命名路由:1234567891011121314const router = new VueRouter(&#123; routes:[ &#123; path: '/', name: "home", component: Home &#125;, &#123; path: '/about', name: "about", component: About &#125; ]&#125;) 使用命名路由: 1234567891011&lt;template&gt; &lt;div id="app"&gt; &lt;div id="nav"&gt; &lt;!-- router-link 相当于 a 标签，to 属性相当于 href 属性 --&gt; &lt;router-link :to="&#123;name: 'home'&#125;"&gt;Home&lt;/router-link&gt; | &lt;router-link :to="&#123;name: 'about'&#125;"&gt;About&lt;/router-link&gt; &lt;/div&gt; &lt;!-- 相当于路由组件的出口 --&gt; &lt;router-view/&gt; &lt;/div&gt;&lt;/template&gt; 2.2 动态路由和查询参数动态路由用于动态匹配 url 中的参数，类似 /user/1, /usr/2,接下来我们将介绍: 如何定义动态路由 如何在 route-linke 传递动态路由的参数，以复用路由 如何在组件中获取动态路由的参数 路由查询参数就是 url 中的查询参数，它无须在路由定义时特殊定义，配置和获取的方式与动态路由类似。 定义动态路由12345678910111213141516const router = new VueRouter(&#123; routes:[ &#123; // :id 表示匹配并接收的 url 参数 path: '/user/:id', name: "user", component: User &#125;, // * 表示 url 的模糊匹配 &#123; path: '/user-*', name: "user", component: User &#125; ]&#125;) 传递动态路由的参数可以像下面这样向路由组件传递参数，来复用路由组件 1234567891011121314&lt;template&gt; &lt;div id="app"&gt; &lt;div id="nav"&gt; &lt;!-- params 就是插入到 url 中的动态路由参数 --&gt; &lt;router-link :to="&#123;name: 'user', params:&#123;id: 1&#125;&#125;"&gt;User1&lt;/router-link&gt; &lt;router-link :to="&#123;name: 'user', params:&#123;id: 2&#125;&#125;"&gt;User2&lt;/router-link&gt; &lt;!-- query 就是向 url 传入的查询参数 --&gt; &lt;router-link :to="&#123;name: 'user', params:&#123;id: 2&#125;, query:&#123;title:'产品', price: 10&#125;&#125;"&gt;User3&lt;/router-link&gt; &lt;/div&gt; &lt;router-view/&gt; &lt;/div&gt;&lt;/template&gt; 获取动态路由的参数 通过 vue 实例的 $route.params 属性我们可以获取 url 中定义的路由参数 通过 vue 实例的 $route.pathMatch 属性我们可以获取 url 中模糊匹配的部分 通过 vue 实例的 $route.query 属性我们可以获取 url 的查询参数 123456789101112131415161718192021222324252627282930313233&lt;script&gt; export default &#123; // 当路由的参数变化时，此路由组件会被复用，因为两个路由复用了同样的组件 // created 函数在被复用时就不会重新调用 created () &#123; // params 接收路由中定义的参数 console.log(this.$route.params.id); // pathMatch 接收 url 中模糊匹配的部分 console.log(this.$route.params.pathMatch); // query 接收路由查询参数 console.log(this.$route.query); &#125;, // 方法一: 监听 $route 的变化 watch: &#123; $route: (to, from)=&gt;&#123; console.log("watch 监听机制") console.log(to.params.id); console.log(from.params.id); // 请求数据接口 &#125; &#125;, // 方法二: 路由导航守卫 beforeRouteUpdate(to, from, next)&#123; console.log("路由导航守卫") console.log(to.params.id); console.log(from.params.id); // 一定要调用 next，不然会阻塞整个路由，后续页面展示的逻辑无法继续进行 next(); &#125; &#125; &#125;&lt;/script&gt; 通过动态路由我们就可以达到复用组件的目的，但是需要注意的是复用组件时，此时组件就不会重新加载了，比如 /user/1 切换到 /user/2 时，vue 声明周期中的一些构造函数就不会重新调用。为了在组件切换时执行一些必须执行到的逻辑，比如请求后台接口，我们可以使用如下两个方法: watch 监听 $route 的变化 使用路由当行守卫 beforeRouteUpdate 方法，所谓导航守卫就是路由声明周期提供的钩子函数，后面我们详细介绍。 路由组件传值上面我们介绍了通过 $route 来接受路由上的各种参数，但是这种直接通过 $route 的方式会让我们的路由和组件之间形成高度的偶尔。我们通过 props 父组件传值的方式，来更好的向路由组件进行传值。 路由定义时传入值: 123456789101112131415161718192021const router = new VueRouter(&#123; routes:[ // props 为 true 只会传递动态路由参数 &#123; path: '/user/:id', name: "user", component: User, props:true &#125;, // props 可以为自定义函数，接受 route(即 $route)，可以自定义返回上述所有参数 &#123; path: '/user/:id', name: "user", component: User, props:(route) =&gt; (&#123; id: route.params.id, title: route.query.title, &#125;) &#125;, ]&#125;) 视图组件去接受值: 12345&lt;script&gt; export default &#123; props:['id', 'title'] &#125;&lt;/script&gt; 2.3 编程式导航&lt;route-link&gt; 定义的是声明式路由，有时候我们想在页面中实现页面的跳转，比如前进或者后退。这时候我们就可以通过 vue.$router 实现动态跳转，vue 中称为编程式导航。 12345678910111213141516171819202122232425262728293031&lt;script&gt; export default &#123; methods: &#123; goBack()&#123; // go 方法中 // 0 刷新 // 1 前进 // -1 表示后退 // -n 表示后退 n 如果没有 n 条历史记录则会失败不跳转 this.$router.go(-1); &#125;, goHome() &#123; // 以下任意一种方法都可以 this.$router.push('/'); this.$router.push('home'); this.$router.push(&#123; path: "/" &#125;); this.$router.push(&#123; name: "user", params: &#123; id: 1 &#125;, query: &#123; title: "苹果" &#125; &#125;); &#125; &#125; &#125;&lt;/script&gt; 2.4 嵌套路由嵌套路由在子 URL 中在实现的一层路由，比如在 /user/1/post, /user/1/profile 我们可以在 ‘/user/:id’ 下在创建一层子路由。这样post和profile 就可以公用 /user 页面的逻辑，最终实现的效果就是 user页面下动态的包含了子路由组件的页面。 步骤包括: 定义嵌套路由 在 User.vue 中定义路由出口 1234567891011121314151617181920212223242526272829const router = new VueRouter(&#123; mode: 'history', routes:[ &#123; path: '/user/:id', name: "user", component: ()=&gt;import('@/views/User.vue'), props:(route) =&gt; (&#123; id: route.params.id, title: route.query.title, &#125;), // children 用于定义子路由 children: [&#123; path: 'posts', component: ()=&gt;import('@/views/Post.vue') &#125;,&#123; path: 'profile', component: ()=&gt;import('@/views/Profile.vue') &#125; ] &#125;, &#123; path: '*', component: () =&gt; import('@/views/404.vue') &#125; ]&#125;) User.vue中定义子路由出口 123456789&lt;template&gt; &lt;div&gt; &lt;h3&gt;User组件传入的 id： &#123;&#123; $route.params.id &#125;&#125;&lt;/h3&gt; &lt;h3&gt;User组件的url匹配： &#123;&#123; $route.params.pathMatch &#125;&#125;&lt;/h3&gt; &lt;h3&gt;传入的值： &#123;&#123; id &#125;&#125;&lt;/h3&gt; &lt;button @click="goHome"&gt;跳转到首页&lt;/button&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt; 嵌套路由和动态路由的区别在于: 动态路由用于复用组件，其展示的页面都是一样 嵌套路由展示的是不同样式和结构的页面 3. 命名视图在前面的内容中，我们通过: VueRouter 中定义路由，一个 url 对应一个组件 通过 &lt;router-view/&gt; 定义路由的出口，当我们点击一个 URL 展示时，这个 &lt;router-view/&gt; 就回展示路由定义中 url 对应的 component 定义的组件 但是我们进入一个页面时，这个页面可能包含不止一个组件，典型的首页，包括: 内容组件 main 侧边栏组件 sider 这时候我们就需要使用命名视图。使用命名视图需要以下步骤: 定义命名视图 通过 &lt;router-view/&gt; 使用命名视图 1234567891011121314const router = new VueRouter(&#123; mode: 'history', routes:[ &#123; path: '/', name: "home", components: &#123; default: Home, main: ()=&gt;import('@/views/Main.vue'), side: ()=&gt;import('@/views/Side.vue') &#125; &#125; ]&#125;) 12345678910&lt;template&gt; &lt;div id="app"&gt; &lt;div id="nav"&gt; &lt;!-- 显示上面 default 定义的默认组件 --&gt; &lt;router-view/&gt; &lt;!-- name= 表示用对应的命名视图 --&gt; &lt;router-view name="main" class="main"&gt;&lt;/router-view&gt; &lt;router-view name="side" class="side"&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt; 每一个 router-view 标签类似一个 div 标签，可以为为其设置 class 样式，定义布局。 对于命名路由的匹配逻辑是这样的: &lt;router-view/&gt; 作为路由出口，会显示匹配到的路由组件，匹配到 /user 就展示 User 组件，匹配到 /home 就展示 Home 组件 &lt;router-view name=&quot;main&quot;&gt;&lt;/router-view&gt; 的命名路由会在匹配到的路由上，找对应名称的组件，比如匹配到 /user 时，就去 /user 下的 components 中找对应名称的组件，如果有就展示，没有就跳过 3. 导航守卫所谓导航表示路由正在发生变化，守卫就是路由变化声明周期的别称。 完整的导航解析流程包括: 导航被触发。 在失活的组件⾥调⽤离开守卫。 调⽤全局的 beforeEach 守卫。 在重⽤的组件⾥调⽤ beforeRouteUpdate 守卫 (2.2+)。 在路由配置⾥调⽤ beforeEnter 。 解析异步路由组件。 在被激活的组件⾥调⽤ beforeRouteEnter 。 调⽤全局的 beforeResolve 守卫 (2.5+)。 导航被确认。 调⽤全局的 afterEach 钩⼦ 触发 DOM 更新。 ⽤创建好的实例调⽤ beforeRouteEnter 守卫中传给 next 的回调函数 导航守卫的钩子函数中，必须调用通过参数传递进来的 next 回调函数。 3.1 导航守卫中的钩子函数导航守卫提供了如下钩子函数: beforeEach: 全局守卫，定义在 VueRouter 实例中，导航切换时都会调用 组件内守卫: beforeRouteEnter(to,from,next4): 守卫执行前调用，此时组件实例还未被创建，此时不能获取组件实例 this，用处不大 beforeRouteUpdate(to,from,next4): 路由发生变化，组件被复用后调用，可以访问组件实例 this berforRouteLeave(to,from,next4): 导航离开组件时调用，可以访问组件实例 this 12345678910111213141516171819202122232425const Foo = &#123; template: `...`, beforeRouteEnter (to, from, next) &#123; // 在渲染该组件的对应路由被 confirm 前调用 // 不！能！获取组件实例 `this` // 因为当守卫执行前，组件实例还没被创建 &#125;, beforeRouteEnter (to, from, next) &#123; next(vm =&gt; &#123; // beforeRouteEnter 守卫 不能 访问 this，因为守卫在导航确认前被调用，因此即将登场的新组件还没被创建。 // 不过，你可以通过传一个回调给 next来访问组件实例。在导航被确认的时候执行回调，并且把组件实例作为回调方法的参数。 // 通过 `vm` 访问组件实例 &#125;) &#125;, beforeRouteUpdate (to, from, next) &#123; // 在当前路由改变，但是该组件被复用时调用 // 举例来说，对于一个带有动态参数的路径 /foo/:id，在 /foo/1 和 /foo/2 之间跳转的时候， // 由于会渲染同样的 Foo 组件，因此组件实例会被复用。而这个钩子就会在这个情况下被调用。 // 可以访问组件实例 `this` &#125;, beforeRouteLeave (to, from, next) &#123; // 导航离开该组件的对应路由时调用 // 可以访问组件实例 `this` &#125;&#125; 3.2 berforRouteLeaveberforROuteLeave 主要用在用户离开页面的提示，提示用户是否保存当前页面的编辑。 123456789101112131415161718192021222324252627282930&lt;!-- 组件内 --&gt;&lt;script&gt; export default &#123; data() &#123; return &#123; content: '' &#125; &#125;, beforeRouteLeave (to, from, next) &#123; if (this.content)&#123; if (confirm("当前页面未保存是否离开"))&#123; console.log(to) // false 表示停留在当前页面，不跳转 next(false) &#125; &#125;else&#123; next(); &#125; &#125;, beforeRouteEnter (to, from, next) &#123; console.log(this); // undefined next(vm=&gt;&#123; // 通过 next 的回调用，可以接收到组件实例 this &#125;) &#125;, beforeRouteUpdate(to, from, next)&#123; // 组件重用时会调用这个方法 &#125; &#125;&lt;/script&gt; 3.3 路由 meta 元信息路由 meta 元信息指的是，我们可以通过路由配置中的 meta 属性，为路由添加元信息，元信息和 beforeEach 全局守卫，我们就可以实现类似登录这些功能。实现面向切面编程。我们首先来看如何定义路由元信息: 1234567891011121314const router = new VueRouter(&#123; mode: 'history', routes:[ &#123; path: '/edit', name: 'edit', component: ()=&gt;import('@/views/edit.vue'), // meta 属性用于定义元数据信息 meta: &#123; requireAuth: true &#125; &#125; ]&#125;) 组件的元信息，最后都会保存在组件实例的 meta 和 matched 属性上。接下来我们看看如何结合 beforeEach 实现对特定 url 的登录要求: 定义元信息第一步，我们需要定义路由元信息和全局守卫，设置登录要求 123456789101112131415161718192021222324252627282930313233343536373839const router = new VueRouter(&#123; mode: 'history', routes:[ &#123; path: '/edit', name: 'edit', component: ()=&gt;import('@/views/edit.vue'), meta: &#123; requireAuth: true &#125; &#125;, &#123; path: '/login', name: 'login', component: ()=&gt;import('@/views/Login.vue'), // 登录后的跳转页面 props: (route)=&gt;(&#123; redirect: route.query.redirect &#125;) &#125; ]&#125;)router.beforeEach((to, from, next)=&gt;&#123; //1. 获取组件元信息 if (to.matched.some(item=&gt;item.meta.requireAuth))&#123; // 2. 需要的登录 if (!localStorage.getItem("user"))&#123; console.log(to.fullPath); next(&#123; path: '/login', query: &#123; redirect: to.fullPath &#125; // 登录后返回到当前页面 &#125;) &#125; &#125; next();&#125;) 定义登录逻辑123456789101112131415161718192021222324252627282930313233343536373839&lt;template&gt; &lt;div&gt; &lt;h3&gt;登录页面&lt;/h3&gt; &lt;label for="name"&gt;姓名: &lt;input type="text" id="name" name="name" v-model="name"&gt; &lt;/label&gt; &lt;label for="pwd"&gt; 密码: &lt;input type="password" name="password" id="pwd" v-model="password"&gt; &lt;/label&gt; &lt;button @click="hLogin"&gt;登录&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; props: ['redirect'], data() &#123; return &#123; name: '', password: '' &#125; &#125;, methods: &#123; hLogin() &#123; setTimeout(()=&gt;&#123; localStorage.setItem("user", this.name); console.log(this.redirect); this.$router.push(this.redirect); &#125;,1000) &#125; &#125;, &#125;&lt;/script&gt;&lt;style lang="scss" scoped&gt;&lt;/style&gt; 3.4 何时与后端进行数据交互有时候，进入某个路由后，需要从服务器获取数据。我们可以通过两种方式来实现： 导航完成之后获取：先完成导航，然后在接下来的组件生命周期钩子中(created,mounted等方法)获取数据。在数据获取期间显示“加载中”之类的指示。 导航完成之前获取：导航完成前，在路由进入的守卫中获取数据，在数据获取成功后执行导航。 导航完成后获取数据导航完成后获取数据，我们会马上导航和渲染组件，然后在组件的 created 钩子中获取数据。这让我们有机会在数据获取期间展示一个 loading 状态，还可以在不同视图间展示不同的 loading 状态。假设我们有一个 Post 组件，需要基于 $route.params.id 获取文章数据： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;template&gt; &lt;div class="post"&gt; // 加载中 &lt;div v-if="loading" class="loading"&gt; Loading... &lt;/div&gt; &lt;div v-if="error" class="error"&gt; &#123;&#123; error &#125;&#125; &lt;/div&gt; &lt;div v-if="post" class="content"&gt; &lt;h2&gt;&#123;&#123; post.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;&#123;&#123; post.body &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;export default &#123; data () &#123; return &#123; loading: false, post: null, error: null &#125; &#125;, created () &#123; // 组件创建完后获取数据， // 此时 data 已经被 observed 了 this.fetchData() &#125;, // 监听路由的变化，重要 watch: &#123; // 如果路由有变化，会再次执行该方法 '$route': 'fetchData' &#125;, methods: &#123; fetchData () &#123; this.error = this.post = null this.loading = true // replace getPost with your data fetching util / API wrapper getPost(this.$route.params.id, (err, post) =&gt; &#123; this.loading = false if (err) &#123; this.error = err.toString() &#125; else &#123; this.post = post &#125; &#125;) &#125; &#125;&#125; 需要特别注意的是，使用 VueRouter 下，路由组件总是会被重用，我们需要同时在 created 方法以及 watch $route 中获取数据。 就像上面示例中的一样。 在导航完成前获取数据我们在导航转入新的路由前获取数据。我们可以在接下来的组件的 beforeRouteEnter 守卫中获取数据，当数据获取成功后只调用 next 方法。 12345678910111213141516171819202122232425262728293031export default &#123; data () &#123; return &#123; post: null, error: null &#125; &#125;, beforeRouteEnter (to, from, next) &#123; getPost(to.params.id, (err, post) =&gt; &#123; next(vm =&gt; vm.setData(err, post)) &#125;) &#125;, // 路由改变前，组件就已经渲染完了 // 逻辑稍稍不同 beforeRouteUpdate (to, from, next) &#123; this.post = null getPost(to.params.id, (err, post) =&gt; &#123; this.setData(err, post) next() &#125;) &#125;, methods: &#123; setData (err, post) &#123; if (err) &#123; this.error = err.toString() &#125; else &#123; this.post = post &#125; &#125; &#125;&#125; 在为后面的视图获取数据时，用户会停留在当前的界面，因此建议在数据获取期间，显示一些进度条或者别的指示。如果数据获取失败，同样有必要展示一些全局的错误提醒。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 深入 Vue 响应式更新原理]]></title>
    <url>%2F2020%2F10%2F08%2Fweb%2Fvue%2Fvue_8%2F</url>
    <content type="text"><![CDATA[响应式更新原理 1. 异步更新队列1.1 异步更新队列概述Vue 在更新 DOM 时是异步执行的。只要侦听到数据变化，Vue 将开启一个队列，并缓冲在同一事件循环中发生的所有数据变更。如果同一个 watcher 被多次触发，只会被推入到队列中一次。这种在缓冲时去除重复数据对于避免不必要的计算和 DOM 操作是非常重要的。然后，在下一个的事件循环“tick”中，Vue 刷新队列并执行实际 (已去重的) 工作。 例如，当你设置 vm.someData = ‘new value’，该组件不会立即重新渲染。当刷新队列时，组件会在下一个事件循环“tick”中更新。多数情况我们不需要关心这个过程，但是如果你想基于更新后的 DOM 状态来做点什么，这就可能会有些棘手。虽然 Vue.js 通常鼓励开发人员使用“数据驱动”的方式思考，避免直接接触 DOM，但是有时我们必须要这么做。为了在数据变化之后等待 Vue 完成更新 DOM，可以在数据变化之后立即使用 Vue.nextTick(callback)。这样回调函数将在 DOM 更新完成后被调用。例如： 1234567891011var vm = new Vue(&#123; el: '#example', data: &#123; message: '123' &#125;&#125;)vm.message = 'new message' // 更改数据vm.$el.textContent === 'new message' // falseVue.nextTick(function () &#123; vm.$el.textContent === 'new message' // true&#125;) 在组件内使用 vm.$nextTick() 实例方法特别方便，因为它不需要全局 Vue，并且回调函数中的 this 将自动绑定到当前的 Vue 实例上： 1234567891011121314151617Vue.component('example', &#123; template: '&lt;span&gt;&#123;&#123; message &#125;&#125;&lt;/span&gt;', data: function () &#123; return &#123; message: '未更新' &#125; &#125;, methods: &#123; updateMessage: function () &#123; this.message = '已更新' console.log(this.$el.textContent) // =&gt; '未更新' this.$nextTick(function () &#123; console.log(this.$el.textContent) // =&gt; '已更新' &#125;) &#125; &#125;&#125;) 因为 $nextTick() 返回一个 Promise 对象，所以你可以使用新的 ES2017 async/await 语法完成相同的事情： 12345678910methods: &#123; // 1. 定义 async 函数 updateMessage: async function () &#123; this.message = '已更新' console.log(this.$el.textContent) // =&gt; '未更新' // 2. 在 await 后获取更新的值 await this.$nextTick() console.log(this.$el.textContent) // =&gt; '已更新' &#125;&#125; 1.2 nextTick 的应用当我们更新 Vue 实例属性之后，由于更新队列的存在，我们是无法立刻获取更新的 DOM，通常我们也无须像上面一样直接从 DOM 中获取数据。但是如果跨组件的使用数据时，仍然会存在类似的现象，我们看下面这个示例: 同前面一样，我们通过父子传值的方式，像子组件传入 msg 属性值 子组件在 show 方法中通过 this.msg 正常获取父组件传入的值 我们模拟后台异步获取数据，并在父组件中更新 msg，更新的同时通过 ref 调用子组件中的方法 此时由于更新队列的存在，msg 的值还没更新至子组件，子组件是无法获取 msg 更新后的值的 注意跟是否是异步加载无关，只要是更新 vue 属性并立刻调用子组件的方法，子组件都无法立刻获取最新的值 这个例子告诉我们，Vue 中尽量使用数据驱动的方式去更新 DOM 获取数据，而要避免直接通过操作 DOM 的方式，通过 ref 引用的方式就是直接操作 DOM。这里解决的方法就是使用 nextTick，在下一个事件循环中执行子组件的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125; &lt;button ref="btn" @click="updateMsg"&gt;按钮&lt;/button&gt; &lt;!-- 1. 父组件向子组件传入了 msg 属性 --&gt; &lt;my-header ref="header" :msg="msg"&gt;&lt;/my-header&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; const MyHeader = &#123; template: ` &lt;div&gt; &lt;/div&gt; `, props: ['msg'], methods: &#123; // 2. 子组件中我们想获取，父组件传入的 msg 属性 show()&#123; console.log(this.msg) &#125; &#125;, &#125; new Vue(&#123; el: "#app", data() &#123; return &#123; msg: "v1", &#125; &#125;, components:&#123; MyHeader: MyHeader &#125;, methods: &#123; // 5. 只要是更新 vue 属性并立刻调用子组件的方法，子组件都无法立刻获取最新的值 updateMsg()&#123; this.msg = "V3" this.$refs.header.show() &#125; &#125;, created() &#123; // 3. 模拟异步加载，我们从后端获取 msg 值后立马通过 ref 调用子组件中的方法 // 4. 此时我们是无法立刻在子组件中获取更新后的 msg 值的 setTimeout(() =&gt; &#123; this.msg = "v2" this.$refs.header.show() &#125;, 1000); // 5. 解决方法是，使用 nextTick 在下一个事件循环中取调用子组件方法 setTimeout(() =&gt; &#123; this.msg = "v2" this.$nextTick(function()&#123; this.$refs.header.show() &#125;) &#125;, 1000); &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 设计与实现 Element UI 的 form 表单]]></title>
    <url>%2F2020%2F10%2F07%2Fweb%2Fvue%2Fvue_7%2F</url>
    <content type="text"><![CDATA[Element UI 表单设计组件 1. Element UI 组件安装12345678910111213141516171819202122# https://element.eleme.cn/#/zh-CN/component/quickstart# 1. 安装cnpm i element-ui# 借助 babel-plugin-component 可以实现按需导入 element-ui 组件 cnpm i babel-plugin-component -D# 2. 修改 .babelrc&#123; "presets": [["es2015", &#123; "modules": false &#125;]], "plugins": [ [ "component", &#123; "libraryName": "element-ui", "styleLibraryName": "theme-chalk" &#125; ] ]&#125;# 3. 方式二: 使用 vue add element 在交互页面选择按需导入vue add element 2. Element 表单组件分析下面是从 ElementUI 官网摘取的一个 Form 表单示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;template&gt; &lt;div&gt; &lt;el-form :model=&quot;ruleForm&quot; // 表单绑定的数据 status-icon :rules=&quot;rules&quot; // 验证的规则 ref=&quot;ruleForm&quot; label-width=&quot;100px&quot; class=&quot;demo-ruleForm&quot; &gt; &lt;el-form-item label=&quot;密码&quot; prop=&quot;pass&quot;&gt; &lt;el-input type=&quot;password&quot; v-model=&quot;ruleForm.pass&quot; autocomplete=&quot;off&quot; &gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;确认密码&quot; prop=&quot;checkPass&quot;&gt; &lt;el-input type=&quot;password&quot; v-model=&quot;ruleForm.checkPass&quot; autocomplete=&quot;off&quot; &gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item label=&quot;年龄&quot; prop=&quot;age&quot;&gt; &lt;el-input v-model.number=&quot;ruleForm.age&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;submitForm(&apos;ruleForm&apos;)&quot; &gt;提交&lt;/el-button &gt; &lt;el-button @click=&quot;resetForm(&apos;ruleForm&apos;)&quot;&gt;重置&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data() &#123; return &#123; ruleForm: &#123; pass: &quot;&quot;, checkPass: &quot;&quot;, age: &quot;&quot;, &#125;, rules: &#123; pass: [&#123; validator: validatePass, trigger: &quot;blur&quot; &#125;], checkPass: [&#123; validator: validatePass2, trigger: &quot;blur&quot; &#125;], age: [&#123; validator: checkAge, trigger: &quot;blur&quot; &#125;], &#125;, &#125;; &#125;&#125;;&lt;/script&gt;&lt;style lang=&quot;scss&quot; scoped&gt;&lt;/style&gt; 可以看到 ElementUI 的 Form 表单分成了如下三个部分: el-form: 作用: 定义数据和校验规则 el-form-item: 作用: 有 prop 属性的 el-input: 通过 prop 关联 el-form 中的数据和校验规则，并进行校验和显示错误信息 无 prop 属性的 el-input: 显示信息 el-input: 作用: 负责双向数据绑定，将数据同步到 el-form 上 通知 el-form-item 做数据校验 接下来我们就仿照 ElementUI 来实现一个我们自己的 Form 表单 3. 自定义 Form 表单3.1 实现双向数据绑定的 Input双向数据绑定 v-mode == v-bind:value + v-on:input，下面是我们自定义 MyInput 的实现: 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;template&gt; &lt;div&gt; &lt;input :type=&quot;type&quot; :value=&quot;inputVal&quot; @input=&quot;handleInput&quot; /&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data() &#123; return &#123; inputVal: this.value, &#125;; &#125;, props: &#123; type: &#123; type: String, default: &quot;text&quot;, &#125;, // A. MyInput 的 value 属性值 value: &#123; type: String, default: &quot;&quot;, &#125;, &#125;, methods: &#123; handleInput(e) &#123; // 1. 通过 input 事件更新输入框的值 this.inputVal = e.target.value; // 2. 触发绑定在当前的 MyInput 组件上的 input 事件实现双向数据绑定 // 要实现双向数据绑定的是 MyInput 组件，v-model 绑定的 MyInput value 属性和 input 事件 // B. MyInput 的 input 事件 this.$emit(&quot;input&quot;, this.inputVal); // 3. 触发 form-item 中的数据校验 this.$parent.$emit(&quot;validate&quot;, this.inputVal); &#125;, &#125;,&#125;;&lt;/script&gt;&lt;style lang=&quot;scss&quot; scoped&gt;&lt;/style&gt; 3.2 Form 组件结构表单数据和校验规则Form 组件需要做如下几个事情: 作为最外层的父组件，需要接收数据和校验规则，并通过 provide 将其传给子组件 FormItem 保存所有 FormItem，用以在 submit 时调用所有 FormItem 进行提交前的验证 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;template&gt; &lt;div&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; // 1. props 接收表单数据和校验规则 data() &#123; return &#123; formItems: [], &#125;; &#125;, props: &#123; model: &#123; type: Object, require: true, &#125;, rules: &#123; type: Object, &#125;, &#125;, methods: &#123; // 2. 表单提交时的校验规则 validate(callback) &#123; // 获取所有的验证结果，并同一处理 console.log(this.formItems); const tasks = this.formItems.map((item) =&gt; // 记住需要传入对应表单的值 item.validate(this.model[item.prop]) ); let ret = true; Promise.all(tasks).then((results) =&gt; &#123; results.forEach((valid) =&gt; &#123; if (!valid) &#123; ret = false; &#125; &#125;); // callback 必须放在 Promise 内，因为 Promise 是在下一个事件循环才执行的 callback(ret); &#125;); &#125;, &#125;, created() &#123; // 3. 注册事件，FormItem 通过触发相应事件注册自身到 Form 组件中 this.$on(&quot;addItem&quot;, (item) =&gt; &#123; this.formItems.push(item); &#125;); &#125;, provide() &#123; return &#123; model: this.model, rules: this.rules, &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style lang=&quot;scss&quot; scoped&gt;&lt;/style&gt; 3.3 FormItemFormItem 中需要做如下几个事情: 通过 prop 属性获取绑定的表单字段以及值 通过 inject 接收 Form 组件注入的验证规则 使用 async-validator 进行规则校验，并显示错误信息 将自身注册到父组件 Form 中 在编写 FormItem 的代码前，我们需要先安装 cnpm i async-validator -S 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;template&gt; &lt;div&gt; &lt;label v-if=&quot;label&quot;&gt;&#123;&#123; label &#125;&#125;&lt;/label&gt; &lt;slot&gt;&lt;/slot&gt; &lt;!-- 显示校验的错误信息 --&gt; &lt;p v-if=&quot;status === &apos;error&apos;&quot; class=&quot;error&quot;&gt;&#123;&#123; errorMsg &#125;&#125;&lt;/p&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Schema from &quot;async-validator&quot;;export default &#123; data() &#123; return &#123; status: &quot;&quot;, // 校验的状态 errorMsg: &quot;&quot;, // 错误信息 &#125;; &#125;, props: &#123; label: &#123; type: String, default: &quot;&quot;, &#125;, prop: &#123; type: String, default: &quot;&quot;, &#125;, &#125;, mounted() &#123; // 4. 将自身注册到 Form 组件中，所以更好的方式 if (this.prop) &#123; // 5. 因为 FormItem 可能是不带 prop 的 FormItem，所以必须判断 this.$parent.$emit(&quot;addItem&quot;, this); &#125; &#125;, // 1. inject 接收父组件传过来的表单数据和校验规则 inject: [&quot;model&quot;, &quot;rules&quot;], methods: &#123; validate(value) &#123; // 因为 aysnc-validator 是通过回调函数获取校验结果的，所以要想拿到校验结果，必须通过 Promise return new Promise((resolve) =&gt; &#123; console.log(value); // 1. 输入框输入的值 // 2. 获取父辈 Form 组件中的校验规则 const descriptor = &#123; [this.prop]: this.rules[this.prop] &#125;; console.log(descriptor); const validator = new Schema(descriptor); // 3. 执行校验 validator.validate(&#123; [this.prop]: value &#125;, (errors) =&gt; &#123; if (errors) &#123; console.log(errors); this.status = &quot;error&quot;; this.errorMsg = errors[0].message; resolve(false); &#125; else &#123; this.status = &quot;&quot;; this.errorMsg = &quot;&quot;; resolve(true); &#125; &#125;); &#125;); &#125;, &#125;, created() &#123; this.$on(&quot;validate&quot;, this.validate); &#125;,&#125;;&lt;/script&gt;&lt;style scoped&gt;.error &#123; color: red;&#125;&lt;/style&gt; 3.4 自定义表单组件的使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;ElForm&gt;&lt;/ElForm&gt; &#123;&#123; ruleForm &#125;&#125; &lt;!-- MyForm 绑定表单数据和校验规则 --&gt; &lt;MyForm :model=&quot;ruleForm&quot; :rules=&quot;rules&quot; ref=&quot;my-form&quot;&gt; &lt;!-- FormItem 执行具体校验规则并显示错误信息 --&gt; &lt;MyFormItem label=&quot;用户&quot; prop=&quot;name&quot;&gt; &lt;!-- Input 实现双向数据绑定 --&gt; &lt;MyInput v-model=&quot;ruleForm.name&quot;&gt;&lt;/MyInput&gt; &lt;/MyFormItem&gt; &lt;MyFormItem label=&quot;密码&quot; prop=&quot;passwd&quot;&gt; &lt;MyInput type=&quot;password&quot; v-model=&quot;ruleForm.passwd&quot;&gt;&lt;/MyInput&gt; &lt;/MyFormItem&gt; &lt;!-- 表单提交的校验事件，通过 ref 引用 Form 表单 --&gt; &lt;button @click=&quot;submit(&apos;my-form&apos;)&quot;&gt;提交&lt;/button&gt; &lt;/MyForm&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import ElForm from &quot;./components/ElForm&quot;;import MyInput from &quot;./components/MyInput&quot;;import MyFormItem from &quot;./components/MyFormItem&quot;;import MyForm from &quot;./components/MyForm&quot;;export default &#123; name: &quot;app&quot;, components: &#123; ElForm, MyInput, MyFormItem, MyForm, &#125;, methods: &#123; // 表单提交的校验事件，通过 ref 引用表单 submit(name) &#123; console.log(this.$refs[name]); this.$refs[name].validate((valid) =&gt; &#123; if (valid) &#123; console.log(&quot;校验成功&quot;); &#125; else &#123; console.log(&quot;校验失败&quot;); &#125; &#125;); &#125;, &#125;, data() &#123; return &#123; ruleForm: &#123; name: &quot;&quot;, passwd: &quot;&quot;, &#125;, rules: &#123; name: [&#123; type: &quot;string&quot;, required: true, message: &quot;Name is required&quot; &#125;], passwd: [ &#123; type: &quot;string&quot;, required: true, message: &quot;Password is required&quot; &#125;, ], &#125;, &#125;; &#125;,&#125;;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 Vue 工程化与 vue-cli3]]></title>
    <url>%2F2020%2F10%2F06%2Fweb%2Fvue%2Fvue_6%2F</url>
    <content type="text"><![CDATA[Vue 工程化 1. 单文件组件概述所谓单文件组件就是将组件放置在一个单独的文件中，可以为这个组件单独定义模板，js 和 CSS。最后通过脚手架和编译工具(比如webpack、babel)将所有单文件组件合并成一个前端应用。 2. 脚手架 vue-client3 安装 安装Nodejs 保证Node.js8.9或更高版本 终端中输入node -v,保证已安装成功 安装淘宝镜像源 npm install -g cnpm --registry=https://registry.npm.taobao.org 以后的npm可以用cnpm代替 安装Vue Cli3脚手架 cnpm install -g @vue/cli 检查其版本是否正确 vue --version 官方文档: vue-cl3 3. 快速原型开发使用 vue serve 和 vue build 命令对单个 *.vue 文件进行快速原型开发，不过这需要先额外安装一个全局的扩展： 1cnpm install -g @vue/cli-service-global vue serve 的缺点就是它需要安装全局依赖，这使得它在不同机器上的一致性不能得到保证。因此这只适用于快速原型开发。 快速原型开发，我们需要的仅仅是一个 App.vue 文件： 3.1 快速原型开发的步骤12345678# 1. 初始化项目，生成 package.json 项目配置文件npm init# 2. 创建单文件组件，文件必须是 App.vue 或者 index.vuetouch App.vue# 3. 运行 vue serve 3.2 App.vue12345678910111213141516&lt;template&gt; &lt;div&gt; &lt;h2&gt;hello world 单页面组件&lt;/h2&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; &#125;&lt;/script&gt;// scoped 表示当前的样式只对当前的组件有效&lt;style scoped&gt; &lt;/style&gt; 4. vue-cli 生成项目使用 vue create mysite 可以帮助我们创建一个完整的 vue 项目。这是一个交互命令，会出现如下的预置选项: 选择 Manually select features 选择项目所需的预置选项: 其中，如下四个通常是我们需要的: Babel Router Vuex Linter/Formatter 5. 购物车案例实战5.1 项目初始化12345678# 1. 创建项目，提前安装好 vuex routervue create # 2. 安装 element-ui 并配置按需导入vue add element# 3. 验证项目是否安装成功npm run serve 5.2 购物车实现]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 Vue 组件异步加载和混入]]></title>
    <url>%2F2020%2F10%2F05%2Fweb%2Fvue%2Fvue_5%2F</url>
    <content type="text"><![CDATA[响应式更新原理 1. 组件的异步加载大型项目中，为了提高网页的加载速度，通常我们只会在使用相应组件时才会下载组件所在的 js 文件并加载组件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 3.使用子组件 --&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;!-- 4. 因为使用了 ES6 import script 标签的 type 需要改为 module --&gt; &lt;script type='module'&gt; import xxx from './modules.js'; const App = &#123; data() &#123; return &#123; isShow: false &#125; &#125;, methods: &#123; asyncLoad() &#123; this.isShow = !this.isShow; &#125; &#125;, // 2. 将组件挂载设置成一个工厂函数，实现异步按需挂载 components: &#123; Test:()=&gt;import('./Test.js') &#125;, // 1. 当点击按钮时 Test 组件才会被加载，下载 modules.js template: ` &lt;div&gt; &lt;button @click='asyncLoad'&gt;异步加载&lt;/button&gt; &lt;Test v-if='isShow'&gt;&lt;/Test&gt; &lt;/div&gt; `, &#125; new Vue(&#123; el: '#app', data: &#123; &#125;, components: &#123; App &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2. 组件混入类似于面向对象的混入技术，Vue 组件也通过 mixin 混入其他组件，以此来分发组件中的可复用功能。混入组件中的属性和方法，都将被添加到被混入的组件中。 2.1 局部混入组件实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- &lt;button @click="handlerMoTai"&gt;显示模态组件&lt;/button&gt; &lt;button @click="handlerTishi"&gt;显示提示组件&lt;/button&gt; &lt;Modal ref='mo'&gt;&lt;/Modal&gt; &lt;ToolTip ref='ti'&gt;&lt;/ToolTip&gt; --&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 1. 定义局部混入组件 const toggleShow = &#123; data() &#123; return &#123; isShow: false &#125; &#125;, methods: &#123; toggleShow() &#123; this.isShow = !this.isShow &#125; &#125; &#125; // 1. 混入组件后，Modal 中会包含 isShow 属性和 toggleShow 方法 const Modal = &#123; template: ` &lt;div v-if='isShow'&gt;&lt;h3&gt;模态框组件&lt;/h3&gt;&lt;/div&gt; `, // 2. 混入局部的mixin mixins: [toggleShow] &#125; const ToolTip = &#123; template: ` &lt;div v-if='isShow'&gt; &lt;h2&gt;提示框组件&lt;/h2&gt; &lt;/div&gt; `, // 3. 混入局部的 Mixin mixins: [toggleShow] &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; Modal, ToolTip &#125;, template: ` &lt;div&gt; &lt;button @click='handleModel'&gt;模态框&lt;/button&gt; &lt;button @click='handleToolTip'&gt;提示框&lt;/button&gt; &lt;Modal ref='modal'&gt;&lt;/Modal&gt; &lt;ToolTip ref='toolTip'&gt;&lt;/ToolTip&gt; &lt;/div&gt; `, methods: &#123; handleModel() &#123; this.$refs.modal.toggleShow(); &#125;, handleToolTip() &#123; this.$refs.toolTip.toggleShow(); &#125; &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3. 全局混入组件实现使用全局混入组件，要格外小心，因为每个组件实例创建时，它都会被调用，并混入到组件实例中。 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &#123;&#123;msg&#125;&#125; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 1. 全局混入组件 VUe.mixins(&#123; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 Vue 声明周期]]></title>
    <url>%2F2020%2F10%2F04%2Fweb%2Fvue%2Fvue_4%2F</url>
    <content type="text"><![CDATA[Vue 声明周期 1. Vue 生命周期概述所谓生命周期就是 Vue 实例从创建到销毁的整个过程，通过在这个过程中安插一些钩子函数，我们就可以实现面向切面编程。下面是 Vue 声明周期的示意图: 2. 生命周期中的各个钩子函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .active&#123; color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 3.使用子组件 --&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; /* beforeCreate created beforeMount mounted beforeUpdate updated activated 激活 deactivated 停用 配合keep-alive beforeDestroy destroyed */ Vue.component('Test', &#123; data() &#123; return &#123; msg: "小马哥", isRed:false &#125; &#125;, methods: &#123; handlerClick() &#123; this.msg = 'alex'; this.isRed = true; &#125; &#125;, template: ` &lt;div&gt; &lt;button @click='handlerClick'&gt;改变&lt;/button&gt; &lt;h3 :class='&#123;active:isRed&#125;'&gt;&#123;&#123;msg&#125;&#125;&lt;/h3&gt; &lt;/div&gt; `, beforeCreate() &#123; console.log('组件创建之前', this.$data); &#125;, created() &#123; // 非常重要的事情,在此时发送ajax 请求后端的数据 console.log('组件创建完成', this.$data); &#125;, beforeMount() &#123; // 即将挂载 console.log('DOM挂载之前', document.getElementById('app')); &#125;, mounted() &#123; // 发送ajax console.log('DOM挂载完成', document.getElementById('app')); &#125;, beforeUpdate() &#123; // 获取更新之前的DOM console.log('更新之前的DOM', document.getElementById('app').innerHTML); &#125;, updated() &#123; // 获取最新的DOM console.log('更新之后的DOM', document.getElementById('app').innerHTML); &#125;, beforeDestroy() &#123; console.log('销毁之前'); &#125;, destroyed() &#123; console.log('销毁完成'); &#125;, activated()&#123; console.log('组件被激活了'); &#125;, deactivated()&#123; console.log('组件被停用了'); &#125; &#125;) const App = &#123; data() &#123; return &#123; isShow: true &#125; &#125;, components: &#123;&#125;, methods: &#123; clickHandler() &#123; this.isShow = !this.isShow; &#125; &#125;, template: ` &lt;div&gt; &lt;keep-alive&gt; &lt;Test v-if='isShow'&gt;&lt;/Test&gt; &lt;/keep-alive&gt; &lt;button @click='clickHandler'&gt;改变生死&lt;/button&gt; &lt;/div&gt; `, &#125; new Vue(&#123; el: '#app', data: &#123; &#125;, components: &#123; App &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2.1 activated/deactivated&lt;keep-alive&gt;&lt;/keep-alive&gt; 用于当组件逻辑上被销毁时，不销毁而是放入到一个缓存中，当需要组件时不是重新创建而是直接从缓存中取出: deactivated: 组件被停用，即当组件被放入缓存时调用 activated: 组件被激活，即组件被重新使用时调用 组件被缓存时会保留所有当前状态，所以 &lt;keep-alive&gt;&lt;/keep-alive&gt; 可以避免用户意外操作导致当前的状态，比如编辑的文本意外丢失。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 Vue 组件与组件通信]]></title>
    <url>%2F2020%2F10%2F03%2Fweb%2Fvue%2Fvue_3%2F</url>
    <content type="text"><![CDATA[1. 组件概述上一节我们介绍了 Vue 的基本用法，Vue 的核心逻辑就是数据驱动视图，个人觉得所谓数据驱动视图就是将声明式的语法在前端更进一步。我们都知道 HTML 和 CSS 都是声明式的语言，Vue 则通过将 DOM 操作抽象成”可以在 HTML 中使用的插值表达式和指令”以及执行业务逻辑的各种方法，将Web 页面中的声明式语法更进一步，而连接这两个部分的正是数据。 接下来我们就来学习前端发展中了另一个重要概念: “组件化”。所谓组件就是 html + css + js。本节我们将介绍: Vue 中组件的定义和使用 Vue 组件间的通信 插槽 2. 组件定义和使用Vue 中组件可以认为组合 html+css+js 的单元，有点类似于 CSS 网格布局中的一个 Container 容器。通过组件，Vue 可以在更高的层次上复用代码。 通常一个应用会以一棵嵌套的组件树的形式来组织： Vue 中组件分为: 全局组件: 无论组件是否被使用都会被加载 局部组件: 只有被使用时，才会被加载 2.1 局部组件的创建和使用使用局部组件包含: 创建，挂载和使用三个步骤 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 3. 使用组件 --&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 1. 创建子组件 const App = &#123; // 组件的 data 属性必须是一个函数，避免复用组件带来的共享引用问题 data() &#123; return &#123; msg: "学习组件使用" &#125; &#125;, // 组件必须包含 template 模板，定义组件包含的具体内容 // template 必须要包含一个闭合标签，这里 div 标签不可省略 template: ` &lt;div&gt; &lt;h3&gt;&#123;&#123;msg&#125;&#125;&lt;/h3&gt; &lt;button @click="handleApp"&gt; 点击&lt;/button&gt; &lt;/div&gt; `, methods: &#123; handleApp() &#123; this.msg = "我是APP组件" &#125; &#125; &#125; new Vue(&#123; el: "#app", data: &#123; &#125;, // 2. 挂载子组件 components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2.2 全局组件的创建和使用全局组件的创建是通过 Vue.component 函数，并且全局组件无须挂载可直接使用: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 1. 创建全局组件 // 第一个参数是组件名，第二是组件的配置，与局部组件的配置完全相同 Vue.component("Vheader", &#123; template: ` &lt;div&gt; &lt;h3&gt;我是一个全局的导航组件&lt;/h3&gt; &lt;/div&gt; ` &#125;) // 这是一个局部组件 const App = &#123; // 2. 直接使用全局组件，无须挂载可直接使用 template: ` &lt;div&gt; &lt;Vheader&gt;&lt;/Vheader&gt; &lt;/div&gt; ` &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, // 2. 挂载子组件 components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3. 组件间通信Vue 将页面实现为组件树，不同组件之间如果想共享数据就需要进行通信，Vue 中的组件通信都是单向的，分为如下四种通信方式: 父传子: 通过 props 以及绑定子组件自定义属性 子传父: 通过子组件事件 平行组件: 通过中央事件总线 其他方式: provide 和 inject 以及组件之间的引用关系 refs: 通过引用直接访问 3.1 父组件向子组件传值父组件向子组件传值是通过”子组件标签的自定义属性”完成的: 子组件通过 props 声明接收值的变量 父组件中为子组件绑定同名的自定义属性来传值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; Vue.component("Vheader", &#123; template: ` &lt;div&gt; &lt;h3&gt;&#123;&#123;pMsg&#125;&#125;&lt;/h3&gt; &lt;/div&gt; `, // 1. 在子组件中声明 props 接收在父组件中挂载的属性 // 2. props 中声明的变量可以在 template 中任意使用 props: ['pMsg'] &#125;) const App = &#123; // 3. 在父组件中绑定自定义属性 // pMsg 是绑定的自定义属性，同时也是子组件接收值的变量名 template: ` &lt;div&gt; &lt;Vheader :pMsg='msg'&gt;&lt;/Vheader&gt; &lt;/div&gt; `, data() &#123; return &#123; 'msg': "我是父组件传过来的值" &#125; &#125; &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, // 2. 挂载子组件 components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3.2 子组件向父组件传值子组件向父组件传值的方式是: 子组件触发事件，父组件监听子组件事件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; Vue.component("Vheader", &#123; template: ` &lt;div&gt; &lt;h3&gt;我是一个全局的导航组件&lt;/h3&gt; &lt;input type="text" @input=getName&gt; &lt;/div&gt; `, methods: &#123; getName(e) &#123; const value = e.target.value; // 2. 子组件通过 this.$emit 触发父组件绑定的自定义事件，并传值 this.$emit('sendValue', value) &#125; &#125;, &#125;) const App = &#123; // 1. 在父组件中的子组件标签上绑定自定义事件 template: ` &lt;div&gt; &lt;p&gt;&#123;&#123;childValue&#125;&#125;&lt;/p&gt; &lt;Vheader @sendValue='reciveName'&gt;&lt;/Vheader&gt; &lt;/div&gt; `, data() &#123; return &#123; 'childValue': "" &#125; &#125;, methods: &#123; reciveName(value) &#123; console.log(value) this.childValue = value &#125; &#125;, &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3.3 平行组件通信平行组件的通信是通过全局的中央事件总线实现的: 接收数据的组件事先在中央事件总线上注册事件和回调函数 传值组件触发对应事件来传值 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 1. 创建中央事件总线 const bus = new Vue(); Vue.component("A", &#123; data() &#123; return &#123; count: 0 &#125; &#125;, template: ` &lt;div&gt; &lt;p&gt;购物车数量: &#123;&#123;count&#125;&#125;&lt;/p&gt; &lt;/div&gt; `, // 2. 在组件被创建后绑定事件和回调函数，以接收值 // 注意组件内的 this 指向了当前的组件实例，因此不同组件内 this 指向是不同的 created() &#123; bus.$on("eventAddShop", (value) =&gt; &#123; this.count += 1; &#125;); &#125;, &#125;) Vue.component("B", &#123; template: ` &lt;div&gt; &lt;button @click="addShop"&gt;添加购物车&lt;/button&gt; &lt;/div&gt; `, methods: &#123; // 3. 触发中央总线上的相应事件，以传值 addShop() &#123; bus.$emit("eventAddShop", 1); &#125; &#125;, &#125;) const App = &#123; template: ` &lt;div&gt; &lt;A&gt;&lt;/A&gt; &lt;B&gt;&lt;/B&gt; &lt;/div&gt; ` &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3.4 父孙组件通信所谓父孙组件通信是为了在父组件中实现，父组件与其嵌套的多层的子组件之间相互通信。其实现方式是: 父组件通过 provide 提供变量 子组件通过 inject 来注入变量，不论子组件嵌套的深度 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; const bus = new Vue(); Vue.component("A", &#123; template: ` &lt;div&gt; &lt;p&gt;&#123;&#123;msg&#125;&#125;&lt;/p&gt; &lt;/div&gt; `, // 2. 子组件通过 inject 注入变量，变量名必须与父组件提供的变量名相同 inject: ['msg'] &#125;) Vue.component("B", &#123; template: ` &lt;div&gt; &lt;A&gt;&lt;/A&gt; &lt;/div&gt; ` &#125;) const App = &#123; template: ` &lt;div&gt; &lt;B&gt;&lt;/B&gt; &lt;/div&gt; `, // 1. 父组件通过 provide 提供变量 provide() &#123; return &#123; msg: "父组件 provide 的变量" &#125; &#125; &#125; new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3.5 通过组件之间的引用关系通信每一个组件实例都有如下属性，可以获取其在组件树中的父组件和子组件: this.$parent: 获取组件的父组件 this.$children: 获取组件的直接子组件 3.6 refsrefs 通过为组件或者标签定义一个唯一 id 引用，以达到可以直接访问的目的。通过 refs 访问一个标签的步骤分为: 为标签定义 ref 属性，并赋予唯一 id 通过组件实例 vue.$refs.id 直接获取对应元素(id 为对应的 ref 属性值) 给标签添加 ref 获取的就是真实的 dom 给组件添加 ref 获取的就是组件的实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; Vue.component("Vheader", &#123; template: ` &lt;div&gt; &lt;h3&gt;子组件&lt;/h3&gt; &lt;/div&gt; ` &#125;) const App = &#123; // 1. 为标签添加 ref 属性，赋予其一个唯一 id // 给标签添加 ref 获取的就是真实的 dom // 给组件添加 ref 获取的就是组件的实例 template: ` &lt;div&gt; &lt;Vheader ref="header"&gt;&lt;/Vheader&gt; &lt;button ref="btn"&gt;按钮&lt;/button&gt; &lt;/div&gt; `, data() &#123; return &#123; 'msg': "我是父组件传过来的值" &#125; &#125;, // 2. 通过 vue 实例的 $refs 属性可以直接访问添加了 ref 属性的标签 mounted() &#123; console.log(this.$refs.btn) &#125;, &#125; // Vue 实例 new Vue(&#123; el: "#app", data: &#123; &#125;, // 2. 挂载子组件 components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 4. 插槽所谓插槽就是定义了如何向组件中插入内容，从而提高组件的复用性。Vue 的插槽分为: 匿名插槽 具名插槽 作用域插槽 接下来我们一一介绍 4.1 匿名插槽1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; Vue.component("MBtn", &#123; // 2. slot 定义的匿名占位符，会被组件名标签中的内容替换 // 匿名插槽又称默认插槽，只能出现一次 template: ` &lt;button&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/button&gt; ` &#125;) const App = &#123; // 1. 组件名 MBtn == m-btn // 3. &lt;MBtn&gt;内容&lt;/MBtn&gt; 标签中的内容会自动填充占位符 template: ` &lt;div&gt; &lt;MBtn&gt;登录&lt;/MBtn&gt; &lt;m-btn&gt;注册&lt;/m-btn&gt; &lt;/div&gt; ` &#125; new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 4.2 具名插槽123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;App&gt;&lt;/App&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; Vue.component("MBtn", &#123; // 1. 具有name 属性的 slot 称为具名插槽 template: ` &lt;button&gt; &lt;slot name="login"&gt;&lt;/slot&gt; &lt;slot name="submit"&gt;&lt;/slot&gt; &lt;/button&gt; ` &#125;) const App = &#123; // 2. 通过 template 的 slot 属性去匹配插入的插槽的位置 // 3. template 内容顺序决定了展示的顺序 template: ` &lt;div&gt; &lt;m-btn&gt; &lt;template slot="submit"&gt;提交&lt;/template&gt; &lt;/m-btn&gt; &lt;m-btn&gt; &lt;template slot="login"&gt;登录&lt;/template&gt; &lt;/m-btn&gt; &lt;/div&gt; ` &#125; new Vue(&#123; el: "#app", data: &#123; &#125;, components: &#123; App &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 4.3 作用域插槽作用域插槽的提供了在不影响原有组间设计的情况下，扩展组件的能力，其能访问到插入组件内的数据。如其名扩展了组件的作用域。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125;，&#123;&#123;todo.title&#125;&#125; &lt;my-header :todo="todo"&gt; &lt;!-- 3. 通过 v-slot:name 使用具名插槽 --&gt; &lt;template v-slot:header&gt; &lt;h1&gt;Here might be a page title&lt;/h1&gt; &lt;/template&gt; &lt;!-- 4. 通过 v-slot:name="data" 使用具名作用域插槽 --&gt;4. &lt;template v-slot:todo-name="data"&gt; &lt;h3&gt;aaaa&lt;/h3&gt; &#123;&#123;data.todoTitle&#125;&#125; &lt;/template&gt; &lt;!-- 5. 使用匿名插槽 --&gt; &lt;template v-slot:default&gt; &lt;p&gt;A paragraph for the main content.&lt;/p&gt; &lt;p&gt;And another one.&lt;/p&gt; &lt;/template&gt; &lt;/my-header&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; const MyHeader = &#123; // 1. 通过 slot name 属性定义具名插槽，name 好像不能是驼峰格式命名 // 2. 通过 slot 绑定属性定义作用域插槽 template: ` &lt;div&gt; &lt;h2&gt;插槽示例&lt;/h2&gt; &#123;&#123;todo&#125;&#125; &lt;slot name="todo-name" :todoTitle="todo.title"&gt;&lt;/slot&gt; &lt;slot name="header"&gt;&lt;/slot&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt; `, props: ['todo'] &#125; new Vue(&#123; el: "#app", data() &#123; return &#123; msg: "Hello Vue", todo: &#123; "title": "Vue 插槽" &#125; &#125; &#125;, components:&#123; MyHeader: MyHeader &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 Vue 入门]]></title>
    <url>%2F2020%2F10%2F02%2Fweb%2Fvue%2Fvue_2%2F</url>
    <content type="text"><![CDATA[1. Vue 中的基本概念为简化 DOM 操作，Vue 为我们提供了插值表达式和一些指令，这些是 Vue 的使用基础。插值表达式和指令可以访问 Vue 实例中定义的特定方法，包括 data，watch，filter，method，这些特定方法定义了数据，以及各种监听和操作数据的方法。最终的目的是为了达到数据驱动视图。 1.1 插值表达式和指令插值表达式和指令: 提供了类似模板引擎的功能，包括: 插值表达式使用双大括号: v-if/v-else/v-else-if: 只有条件为 true 是元素才会渲染，有更高的切换开销 v-show: 条件渲染，不管初始变量如何，元素总是被渲染，有更高的初始化开销 v-text: v-html: v-bind: 属性绑定 v-on: 事件绑定，vue 还提供了事件修饰符，用于阻止默认事件，阻止冒泡等常用的事件处理功能 v-model: 双向数据绑定 下面这些基础指令的使用示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .active &#123; color: red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 1. 插值表达式，可以插入任何的 js 表达式 --&gt; &lt;!-- 可访问 vue 实例中定义的所有属性和方法 --&gt; &lt;div id=1&gt; &lt;h1&gt;1. 插值表达式&lt;/h1&gt; &lt;p&gt;&#123;&#123; msg &#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; &#123;id: msg&#125; &#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; 1 &gt; 2 ? "真的" : "假的"&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123; getContents() &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;!-- 2. 插入可被渲染的标签: v-text 与 v-html 指令 --&gt; &lt;!-- v-text 相当于原生的 innerText --&gt; &lt;!-- v-html 相当于原生的 innerHT --&gt; &lt;div id="2"&gt; &lt;h1&gt;2. 插入可渲染文本&lt;/h1&gt; &lt;h3 v-text='msg'&gt;&lt;/h3&gt; &lt;div v-html='htmlMsg'&gt; &lt;/div&gt; &lt;/div&gt; &lt;div id="3"&gt; &lt;h1&gt;3. 循环和判断&lt;/h1&gt; &lt;!-- 3. v-if v-else v-else-if 条件显示--&gt; &lt;!-- 会将元素从 DOM 中插入或删除 --&gt; &lt;div v-if="Math.random() &gt; 0.5"&gt; 显示 &lt;/div&gt; &lt;div v-else&gt; 隐藏 &lt;/div&gt; &lt;!-- 4. v-show 条件显示--&gt; &lt;!-- 控制的元素的 display 属性，false 时，display: none --&gt; &lt;h3 v-show="!isShow"&gt; isShow 显示&lt;/h3&gt; &lt;!-- 5. v-for 循环 --&gt; &lt;ul&gt; &lt;!-- v-for 建议绑定 :key，key 会成为单个元素的标识，便于 vue 进行局部更新， --&gt; &lt;!-- 如果 vue 无法定位数据变更会更改哪些元素，他将更新所有元素 --&gt; &lt;li v-for="(item,index) in menus" :key='item.id'&gt; 菜名&#123;&#123;index&#125;&#125;: &#123;&#123;item.name&#125;&#125; &lt;/li&gt; &lt;li v-for="item in menus" :key='item.id'&gt; 菜名&#123;&#123;item.id&#125;&#125;: &#123;&#123;item.name&#125;&#125; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;div class="4"&gt; &lt;h1&gt;4. 属性绑定&lt;/h1&gt; &lt;!-- 6. v-bind 将属性值绑定到 vue 实例的属性 --&gt; &lt;a v-bind:href="ref.url" v-bind:title="ref.title"&gt;&#123;&#123;ref.name&#125;&#125;&lt;/a&gt; &lt;!-- v-bind 的简写 --&gt; &lt;a :href="ref.url" :title="ref.title"&gt;&#123;&#123;ref.name&#125;&#125;&lt;/a&gt; &lt;!-- 根据 isActive 决定是否 class=active，多个 class 会自动合并 --&gt; &lt;h3 class="size" v-bind:class="&#123;active: isActive&#125;"&gt;控制 class 属性值&lt;/h3&gt; &lt;p :style="&#123;color:pColor,size: fontSize + 'px'&#125;"&gt; 控制 style 属性&lt;/p&gt; &lt;/div&gt; &lt;div id="5"&gt; &lt;h1&gt;5. 事件绑定&lt;/h1&gt; &lt;!-- 7. v-on 事件绑定 --&gt; &lt;p :class='&#123;active: isActive&#125;'&gt;&#123;&#123;num&#125;&#125;&lt;/p&gt; &lt;button v-on:click="num+=1"&gt;+1&lt;/button&gt; &lt;!-- v-on 简写 @ --&gt; &lt;button @click="handleClick"&gt;+2&lt;/button&gt; &lt;!-- 8. 事件修饰符 --&gt; &lt;!-- 阻止单击事件继续传播 --&gt; &lt;a v-on:click.stop="doThis"&gt;&lt;/a&gt; &lt;!-- 提交事件不再重载页面 --&gt; &lt;form v-on:submit.prevent="onSubmit"&gt;&lt;/form&gt; &lt;!-- 修饰符可以串联 --&gt; &lt;a v-on:click.stop.prevent="doThat"&gt;&lt;/a&gt; &lt;!-- 只有修饰符 --&gt; &lt;form v-on:submit.prevent&gt;&lt;/form&gt; &lt;!-- 添加事件监听器时使用事件捕获模式 --&gt; &lt;!-- 即内部元素触发的事件先在此处理，然后才交由内部元素进行处理 --&gt; &lt;div v-on:click.capture="doThis"&gt;...&lt;/div&gt; &lt;!-- 只当在 event.target 是当前元素自身时触发处理函数 --&gt; &lt;!-- 即事件不是从内部元素触发的 --&gt; &lt;div v-on:click.self="doThat"&gt;...&lt;/div&gt; &lt;!-- 点击事件将只会触发一次 --&gt; &lt;a v-on:click.once="doThis"&gt;&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- 1. 引包 --&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 2. 实例化 Vue new Vue(&#123; el: "#app", // 绑定的元素 // 数据属性 data: &#123; msg: "hello world", // data 中属性将被保存为 vue 实例的属性 htmlMsg: "&lt;p&gt;v-html插入可渲染的标签&lt;/p&gt;", isShow: true, ref: &#123; name: "百度", url: "https://www.baidu.com", title: "百度一下" &#125;, isActive: false, pColor: "red", fontSize: "30", num: 1, menus: [&#123; "id": 1, name: "鸡翅" &#125;, &#123; "id": 2, name: "土豆" &#125;] &#125;, // 方法 methods: &#123; getContents() &#123; return this.msg; // this 指向 vue 实例，可以直接访问 data 中保存在 vue 的属性 &#125;, handleClick() &#123; this.num += 2 this.isActive = !this.isActive &#125; &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 1.2 双向数据绑定所谓双向数据绑定，是针对像 input，textarea 等表单元素，用于实现: 将变量绑定到视图(标签元素) 修改表单元素可以修改变量值 这样的 变量-&gt;视图，视图-&gt;变量的双向数据绑定。我们来看下面这个示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 1. 输入框 --&gt; &lt;p&gt;&#123;&#123; msg &#125;&#125;&lt;/p&gt; &lt;input type="text" v-model="msg"&gt; &lt;!-- 2. 单选框，变量将保存为 true 或 false--&gt; &lt;label for="checkbox"&gt;&#123;&#123;checked&#125;&#125;&lt;/label&gt; &lt;input type="checkbox" id="checkbox" v-model="checked"&gt; &lt;!-- 3. 复选框将保存到值为列表的变量中 --&gt; &lt;div class="box"&gt; &lt;label for="a"&gt;黄瓜&lt;/label&gt; &lt;input type="checkbox" name="" id="a" value="黄瓜" v-model="boxCollect"&gt; &lt;label for="b"&gt;西红柿&lt;/label&gt; &lt;input type="checkbox" name="" id="b" value="西红柿" v-model="boxCollect"&gt; &lt;p&gt;&#123;&#123;boxCollect&#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: "#app", data: &#123; msg: "hello", checked: true, boxCollect: [] &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; v-model 存在三个修饰符: .lazy: 在默认情况下，v-model 在每次 input 事件触发后将输入框的值与数据进行同步 (除了上述输入法组合文字时)。你可以添加 lazy 修饰符，从而转为在 change 事件之后进行同步 .number: 将用户的输入值转为数值类型 .trim: 自动过滤用户输入的首尾空白字符 12&lt;!-- 在“change”时而非“input”时更新 --&gt;&lt;input v-model.lazy="msg"&gt; 2. Vue 实例中的方法Vue 实例可以定义如下属性和方法: data: Vue 示例包含的数据 watch: 监听器用于监听值的变化 computed: 计算属性有三个核心作用: 用于封装复杂的计算逻辑 缓存计算结果 监听变量，并自动更新计算 filters: 过滤器，用于格式化数据，分为全局过滤和局部过滤器，局部过滤器只能在当前的 vue 实例中使用 2.1 watch 监听器JavaScript 中值分为基础类型和引用类型，对于引用类型要想监听其值的变化，我们需要深度监听 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 2. v-model 双向数据绑定，通过输入框改变变量的值 --&gt; &lt;label for="person"&gt;&#123;&#123;who&#125;&#125;&lt;/label&gt; &lt;input type="text" name="" id="person" v-model="who"&gt; &lt;label for="study"&gt;&#123;&#123;student[0].name&#125;&#125;&lt;/label&gt; &lt;button @click="student[0].name='好棒'"&gt;改变学生&lt;/button&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: "#app", data: &#123; who: "tsong", // 1. 被监听的变量 student: [&#123; "name": "高手" &#125;] &#125;, watch: &#123; // 3. 函数名是监听的变量名，函数接收变量的(新值, 旧值) who(newV, oldV) &#123; console.log(newV) &#125;, // 4. 深度监听 student: &#123; deep: true, // 表示深度监听 // handler 表示深度监听处理器 handler: function(newV, oldV) &#123; console.log(newV) &#125; &#125; &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2.2 computed 计算属性12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;p&gt;&#123;&#123;reverse&#125;&#125;&lt;/p&gt; &lt;p&gt;&#123;&#123;computedSetter&#125;&#125;&lt;/p&gt; &lt;button @click='change'&gt;更新值&lt;/button&gt; &lt;button @click='setCom'&gt;计算属性设置 setter&lt;/button&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: "#app", data: &#123; msg: "hello", // 1. computed 监听的变量 &#125;, methods: &#123; change() &#123; this.msg = "你好" // 3. 变量更新后，计算属性会监听到变化，并自动更新 &#125;, setCom(event) &#123; const &#123; value &#125; = event.target; this.computedSetter = "更新了"; // 5. 为计算属性直接赋值 &#125; &#125;, computed: &#123; // 2. 计算属性，会自动计算并缓存，如果数据没有变化，计算属性直接从缓存中取值 reverse() &#123; return this.msg.split('').reverse().join('') &#125;, // 4. 可以像下面这样，把计算属性定义成一个访问器属性 computedSetter: &#123; get: function() &#123; return this.msg + " getter" &#125;, set: function(newV) &#123; // 6. 计算属性接收值并更新变量 this.msg = newV &#125; &#125; &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 2.3 过滤器12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &lt;!-- 2. 通过管道符使用过滤器，price 和 $ 将传给过滤器函数--&gt; &lt;h3&gt;&#123;&#123;price | formatPrice("$")&#125;&#125;&lt;/h3&gt; &lt;h3&gt;&#123;&#123;msg | reverse("$")&#125;&#125;&lt;/h3&gt; &lt;/div&gt; &lt;script src="./vue.js"&gt;&lt;/script&gt; &lt;script&gt; // 3. 创建全局过滤器，可以在所有 Vue 组件中使用 Vue.filter("reverse", value =&gt; &#123; return value.split('').reverse().join(""); &#125;); new Vue(&#123; el: "#app", data: &#123; msg: "hello", price: 10 &#125;, // 1. 定义局部过滤器 filters: &#123; formatPrice: function(price, f) &#123; return f + price; &#125; &#125; &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 3. 对象变更检测注意事项由于 JS 的机制，Vue 是不能检测对象属性的添加和删除。因此像下面这个示例，点击按钮给 this.user 添加 age 属性后，页面也无法显示。如果想动态的添加响应式的属性需要通过 vue.$set 方法 vue.$set(object, key, value)。如多想一次添加多个属性，可通过this.user = Object.assign({}, this.user, {&#39;attr&#39;: &#39;&#39;}) 创建一个新的对象赋值给 this.user 实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt; &#123;&#123;user.name&#125;&#125;,&#123;&#123;user.age&#125;&#125;, &#123;&#123;user.ageSet&#125;&#125; &lt;button @click="addAge"&gt;添加年龄&lt;/button&gt; &lt;button @click="addAgeSet"&gt;通过 vue.$set 添加属性&lt;/button&gt; &lt;/div&gt; &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt; &lt;script&gt; new Vue(&#123; el: "#app", data() &#123; return &#123; user: &#123; "name": "tsong" &#125;, &#125; &#125;, methods: &#123; // 1. 按钮点击后，user.age 是无法显示的 addAge()&#123; this.user.age=10 &#125;, // 2. 添加响应式属性，需要通过 $set 方法 addAgeSet()&#123; this.$set(this.user, 'ageSet', 10) &#125;, // 3. 添加多个响应式属性，因为是创建了新的对象，Vue 响应式可以检测到对象的创建 addMulti()&#123; this.user = Object.assign(&#123;&#125;, this.user, &#123; name: "AAA", phone: "XXXXX" &#125;) &#125; &#125;, &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 Vue 入门开篇]]></title>
    <url>%2F2020%2F10%2F01%2Fweb%2Fvue%2Fvue_1%2F</url>
    <content type="text"><![CDATA[这个系列是 Vue.js 框架的使用，目的是能使用 Vue 开发开发常见的 Web 应用。 1. Vue 内容概述我们将分为如下几个部分来详细讲解 Vue 的使用: Vue 基础，包括插值表达式和 Vue 指令 Vue 组件化开发与组件通信，以及插槽的用法 Vue 生命周期及其方法 Vue 组件异步加载和混入 Vue 工程化，vue-cli3 以及单文件组件的使用 组件开发之如何设计一个类似 ElementUI 的 form 表单 深入 Vue 响应式更新原理 Vue Router Vuex 2. 学习资料Vue 已经进入 3.0 时代，但是市面上 Vue 的优秀书籍确实寥寥无几，最好的参考资料就是 Vue的官方文档]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 CSS 精讲]]></title>
    <url>%2F2020%2F09%2F06%2Fweb%2Fhtml_css%2Fhtml_css_7%2F</url>
    <content type="text"><![CDATA[经过一段时间的磨练，基本的 CSS 规则都会了，但还是有一些比较细节的知识未掌握。这一节是 CSS 的知识精讲，主要是记录一些自己未记住的知识点。 1. CSS 权重CSS 权重决定了 CSS 有样式的应用优先级(注意CSS样式的应用不取决于书写顺序)。 CSS 权重 = “元素选择器” 1 + “类选择器” 10 + “ID选择器” 100 + “行类样式” 1000 2. CSS 字体和文本属性2.1 字体属性包括 字体: font-family: &#39;Franklin Gothic Medium&#39;, &#39;Arial Narrow&#39;, Arial, sans-serif; 可以设置多个备选字体 字体大小 font-size: 30px 像素单位有三个 px: 像素单位，绝对单位 em: 相对单位，相对于当前所在区域的字体大小 rem: 移动端的相对单位 字体颜色 color: red 颜色表示法有三种: 单词表示法: red rgb 和 rgba 表示法 十六进制表示法 字体样式 font-style: italic 字体粗细: font-weight: 400 取值范围为 100-900,400 表示 normal 2.2 文本属性包括: 文本修饰 text-decoration: line-through 修饰词: underline: 下划线 none: 无线 line-through: 删除线 文本缩进 text-indent: 2em 单位建议使用 em 行高: line-height: 40px 设置行高可以使文本在垂直居中 中文字间距:letter-spacing 单词字间距: word-spacing 文本水平对齐方式: text-align: center center 表示文本水平居中 2.3 综合属性综合属性可以在同一个属性中设置多个属性，比如: 123/* 设置: 字体大小 20px，行高为 3 倍字体大小，备选字体 */font: 20px / 3 'Franklin Gothic Medium', 'Arial Narrow', Arial, sans-serif;;&#125; 3. 盒子模型3.1 display在界面我们介绍盒子模型时说道，元素分为两类: 块级元素 行内元素 漏掉了行内块元素，img 和 input 都属于行内块元素。所有元素所属的元素类型都由其 display 属性决定: display: block 表示块元素 display: inline 表示行内元素 display: inline-block 表示行内块元素 3.2 marginmargin 在垂直方向上会出现外边距合并，水平方向则不存在。即如果上下两个盒子A和B，A 的下边距为 30px，B 的上边距为100px，最终 AB盒子的上下边距是 100px 而不是 130px。 因此我们在设置一个盒子的外边距时，尽量统一设置一个方向的外边距。 4. 清楚默认样式浏览器会为不同元素设置默认样式，我们在进行 CSS 样式设置时最好先清楚这些默认样式，下面是清楚默认样式的代码示例: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* http://meyerweb.com/eric/tools/css/reset/ v2.0 | 20110126 License: none (public domain)*/html, body, div, span, applet, object, iframe,h1, h2, h3, h4, h5, h6, p, blockquote, pre,a, abbr, acronym, address, big, cite, code,del, dfn, em, img, ins, kbd, q, s, samp,small, strike, strong, sub, sup, tt, var,b, u, i, center,dl, dt, dd, ol, ul, li,fieldset, form, label, legend,table, caption, tbody, tfoot, thead, tr, th, td,article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary,time, mark, audio, video &#123; margin: 0; padding: 0; border: 0; font-size: 100%; font: inherit; vertical-align: baseline;&#125;/* HTML5 display-role reset for older browsers */article, aside, details, figcaption, figure, footer, header, hgroup, menu, nav, section &#123; display: block;&#125;body &#123; line-height: 1;&#125;ol, ul &#123; list-style: none;&#125;blockquote, q &#123; quotes: none;&#125;blockquote:before, blockquote:after,q:before, q:after &#123; content: ''; content: none;&#125;table &#123; border-collapse: collapse; border-spacing: 0;&#125; 5. 浮动元素的破坏性浮动元素存在以下几个现象: 文字环绕现象 脱离标准文档流 多个浮动元素会相互贴边 浮动元素有收缩现象，默认元素与其父元素同款，但是浮动元素的宽度取决于其内容的宽度 浮动元素因脱离了正常的页面布局刘，因而撑不起父元素的高度，导致父元素高度塌陷问题。 5.1 清除浮动所谓清除浮动就是解决浮动带来的破坏性。清除浮动有多种方法: 固定宽度: 方法: 为父元素设置固定宽度，宽度应该是其浮动子元素的最大高度 缺点: 这种方法在其子元素高度变化时需要重新设置，不够灵活 内墙法: 方法: 在最后一个浮动元素的后面，添加一个块级元素，并设置 clear: both 清除浮动 缺点: 结构冗余 伪元素清除法: 方法: 类似内墙法，只不过额外添加的块元素是通过伪元素实现的 overflow: hidden 方法: 为父元素设置overflow: hidden 会形成一个 BFC(Block Formatting Context)区域 原理: BFC 区域的一条显示规则就是计算 BFC 的高度时，浮动元素也参与计算 除了 overflow: visible 其他 overflow 属性值都能形成 BFC 123456789101112131415161718192021222324252627282930&lt;!-- 内墙法 --&gt;&lt;style&gt; /* 2. 内墙法 */ .top_bar .clear&#123; clear: both; &#125; /* 3. 伪元素清除法 */ .clearfix::after&#123; content: ""; display: block; clear: both; &#125; .top_bar&#123; /* 4. 形成 BFC 区域 */ overflow: hidden; border: 1px solid red; &#125;&lt;/style&gt;&lt;body&gt; &lt;div class="top_bar clearfix"&gt; &lt;div class="a"&gt;浮动1&lt;/div&gt; &lt;div class="b"&gt;浮动2&lt;/div&gt; &lt;div class="clear"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="second"&gt;&lt;/div&gt;&lt;/body&gt; 6. BFC7. 浮动和定位对行内元素的影响 将一个行内元素设置成 float 相当于把这个元素设置成了一个块元素 绝对定位和固定定位，与 float 一样也可以将这个元素设置成了一个块元素 总结: 脱离标准文档流的 float、绝对定位、固定定位都会将行内元素设置成一个块元素 对 div 等块级元素设置 float 会收缩效果。 8. 定位与 z-index给元素设置定位会出现压盖现象，z-index 可以设置相互压盖元素显示的优先级。 z-index 有如下几个特性: 只能用于设置了定位的元素上 是一个整数，越大显示优先级越高 如果父辈元素也设置了 z-index，则元素显示的优先级由其父辈的 z-index 决定 9 背景与边框属性9.1 背景属性背景包括如下属性 背景色: background-color: red 背景图片: background-img: url(&quot;/images/image.jpg&quot;) 背景图片的平铺方式: background-repeat: no-repeat 表示背景图片是否重复以填充整个元素 no-repeat 表示不复制，repeat-x 横向平铺 repeaet-y 纵向平铺 背景图片定位: background-position: 0 0 定位有三种方式: 50px 100px: x 轴方向(水平方向)右移 50px，垂直方向下移 100px top/center/bottom left/center/right: 关键字定位，分别表示上下、左右额位置 0% 50%: 水平方向右移 0%, 垂直方向下移 50% 缩放背景图片的尺寸: background-size: 24px 596px 对应为宽度和高度 background-size: cover: 根据容器的百分比进行伸缩 综合属性: backgroud: url(&quot;&quot;) no-repeat center top 9.2 CSS Sprite 雪碧图CSS Sprite 是一个将多个小图标合并到一张图上，并利用 CSS 背景定位来显示需要显示的部分的技术。 CSS Sprite 适用于: 静态图片，不随用户信息变化而变化 小图片，2-3kb 加载量比较大 一些大图片不建议使用雪碧图 目的是减少 HTTP 请求的数量，加快网页响应速度，跟合并 JS 文件和 CSS 文件是一个道理。 123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; * &#123; padding: 0; margin: 0; &#125; div &#123; width: 24px; height: 24px; display: inline-block; border: 1px solid palegreen; /* 图片大小: 48px * 1184px */ background: url("/_posts/html_css/taobao_sprite.png") no-repeat 0 0 ; background-size: 24px 597px; &#125; .sprit2 &#123; background-position: 0 -44px; &#125; .sprit3 &#123; background-position: 0 -88px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="sprit"&gt;&lt;/div&gt; &lt;div class="sprit2"&gt;&lt;/div&gt; &lt;div class="sprit3"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 9.3 边框属性边框包括如下属性: 边框的圆角: border-radius: 3px 10px 30px 2px border-radius: 50%: 将正方形设置为圆 border-top-left: 15px 15px 边框阴影: box-shadow: 0px 0px 5px red inset 水平偏移方向 垂直偏移方向 模糊程度 颜色 外设还是内设，默认为外设，inset 表示内设 10. CSS 类命名规范10.1 相对网页外层重要部分CSS样式命名 外套 wrap ——————用于最外层 头部 header —————-用于头部 主要内容 main ————用于主体内容（中部） 左侧 main-left ————-左侧布局 右侧 main-right ———–右侧布局 导航条 nav —————–网页菜单导航条 内容 content —————用于网页中部主体 底部 footer —————–用于底部 10.2 DIV+CSS命名参考表 CSS样式命名 说明 #wrapper 页面外围控制整体布局宽度 #container或#content 容器,用于最外层 #layout 布局 #head, #header 页头部分 #foot, #footer 页脚部分 #nav 主导航 #subnav 二级导航 #menu 菜单 #submenu 子菜单 #sideBar 侧栏 #sidebar_a, #sidebar_b 左边栏或右边栏 #main 页面主体 #tag 标签 #msg #message 提示信息 #tips 小技巧 #vote 投票 #friendlink 友情连接 #title 标题 #summary 摘要 #loginbar 登录条 #searchInput 搜索输入框 #hot 热门热点 #search 搜索 #search_output 搜索输出和搜索结果相似 #searchBar 搜索条 #search_results 搜索结果 #copyright 版权信息 #branding 商标 #logo 网站LOGO标志 #siteinfo 网站信息 #siteinfoLegal 法律声明 #siteinfoCredits 信誉 #joinus 加入我们 #partner 合作伙伴 #service 服务 #regsiter 注册 arr/arrow 箭头 #guild 指南 #sitemap 网站地图 #list 列表 #homepage 首页 #subpage 二级页面子页面 #tool, #toolbar 工具条 #drop 下拉 #dorpmenu 下拉菜单 #status 状态 #scroll 滚动 .tab 标签页 .left .right .center 居左、中、右 .news 新闻 .download 下载 .banner 广告条(顶部广告条) 11. 居中11.1 行内元素居中行内元素居中分为: 水平居中: text-align 垂直居中: 方法一: 设置 line-height 与 height 同高 方法二: 将容器设置为 table-cell 并设置 vertical-align 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; /* 方法一: text-align, line-height */ .box &#123; width: 200px; height: 200px; background-color: aquamarine; text-align: center; line-height: 200px; &#125; /* 方法二: text-align, table-cell */ .box2 &#123; width: 200px; height: 200px; background-color: aquamarine; display: table-cell; vertical-align: middle; text-align: center; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;span&gt;JMM&lt;/span&gt; &lt;/div&gt; &lt;div class="box2"&gt; &lt;span&gt;JMM&lt;/span&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 11.2 块元素居中块元素居中有三种方法： position + margin table-cell position: 纯定位的方式 position + margin123456789101112131415161718192021222324252627282930&lt;style&gt; /* 方法一: position + margin */ /* 父元素: position: relative */ .box &#123; width: 200px; height: 200px; background-color: orange; position: relative; &#125; .child &#123; width: 100px; height: 100px; background-color: aquamarine; /* 子元素: 设置 position + margin + top/left/right/buttom */ position: absolute; margin: auto; left: 0; right: 0; top: 0; bottom: 0; &#125;&lt;/style&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="child"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt; table-cell123456789101112131415161718192021222324252627282930313233&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .box &#123; width: 200px; height: 200px; background-color: orange; /* 方法二: 父元素设置 table-cell */ display: table-cell; vertical-align: middle; text-align: center; &#125; .child &#123; width: 100px; height: 100px; background-color: aquamarine; /* 方法二: 子元素设置 inline-block */ display: inline-block; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="child"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 纯位移计算1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; .box &#123; width: 200px; height: 200px; background-color: orange; /* 方法三: 父元素 */ position: relative;; &#125; .child &#123; width: 88px; height: 88px; background-color: aquamarine; /* 方法三: 纯定位方式，位移父子宽高差值的一半*/ position: absolute; top: 50%; left: 50%; margin-left: -44px; margin-top: -44px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div class="box"&gt; &lt;div class="child"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class="box2"&gt; &lt;span&gt;JMM&lt;/span&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 CSS 布局-响应式布局]]></title>
    <url>%2F2020%2F09%2F06%2Fweb%2Fhtml_css%2Fhtml_css_6%2F</url>
    <content type="text"><![CDATA[1. 什么是响应式布局响应式网页设计(responsive web design，RWD）指的是允许Web页面适应不同屏幕宽度因素等，进行布局和外观的调整的一系列实践。现代的CSS布局方式基本上就是响应式的，其依赖于 CSS 的如下技术: 媒体查询 灵活网格 下面我们来一一介绍这些内容。 1.1 媒体查询媒介查询允许我们运行一系列测试，例如用户的屏幕是否大于某个宽度或者某个分辨率，并将CSS选择性地适应用户的需要应用在样式化页面上。例如，下面的媒体查询用于测试当 Web 页面为屏幕媒体（也就是说不是印刷文档），且视口至少有800像素宽应用此 CSS 样式 1234567&lt;style&gt; @media screen and (min-width: 800px) &#123; .container &#123; margin: 1em 2em; &#125; &#125; &lt;/style&gt; 媒体查询，以及样式改变时的点，被叫做断点（breakpoints）。使用媒体查询时的一种通用方式是，为窄屏设备（例如移动设备）创建一个简单的单栏布局，然后检查当前屏幕是否是大屏，如果是大屏采用一种多栏的布局 。这经常被描述为移动优先设计。 1.3 灵活网格响应式站点是建立在灵活网格上的。一个灵活网格意味着你不需要适配每个可能使用的设备尺寸，然后为其建立一个精确到像素级的适配布局。使用灵活网格，你只需要加进去一个断点，在内容看起来不齐整的时候改变设计。现代布局方式，例如多栏布局、伸缩盒和网格默认是响应式的。这些现代 CSS 布局技术，我们在之前的章节都已经一一介绍过了。 1.4 响应式图像最简单的处理响应式图像的方式是像下面这样缩放图片: 123img &#123; max-width: 100%:&#125; 这种方式有显然的弊端，图像有可能会显示得比它的原始尺寸小很多，以至于浪费带宽，对于移动端而言下载了过大的图片。响应式图像，使用了元素和 srcset和sizes 特性解决了这些问题。 你可以提供附带着“提示”（描述图像最适合的屏幕尺寸和分辨率的元数据）的多种尺寸，浏览器将会选择对设备最合适的图像，以确保用户下载尺寸适合他们使用的设备的图像。待会我们会详细介绍这些标签和特性的使用方式。 1.5 响应式排版借助媒体查询，我们不仅可以实现响应式布局，还能实现响应式排版，即依据屏幕大小设置字体的大小。另一种实现响应式排版的方法是使用视口单位vw。这也是我们接下来要讲解的内容之一。 2. 媒体查询CSS媒体查询提供了一种应用 CSS 的方法，即仅在浏览器和设备的环境与你指定的规则相匹配的时候CSS才会真的被应用。允许你按照视口的尺寸创建不同的布局。 2.1 媒体查询的语法最简单的媒体查询语法看起来是像这样的： 123@media media-type and (media-feature-rule) &#123; /* CSS rules go here */&#125; 它由以下部分组成： 一个媒体类型，告诉浏览器这段代码是用在什么类型的媒体上的（例如印刷品或者屏幕）； 一个媒体表达式，是一个被包含的CSS生效所需的规则或者测试； 一组CSS规则，会在测试通过且媒体类型正确的时候应用。 2.2 媒体类型媒体类型有： all print: 打印体 screen: 屏幕 speech 2.3 媒体特征规则有多种设置媒体特性规则的方式: 宽和高: 最常探测的特征是视口宽度，可以使用min-width、max-width和width媒体特征，在视口宽度大于或者小于某个大小——或者是恰好处于某个大小——的时候，应用CSS。 朝向: 探测媒体是竖放（portrait mode）还是横放（landscape mode）模式 123456789101112/* max 表示小于 400px 适用 */@media screen and (max-width: 400px) &#123; body &#123; color: blue; &#125;&#125;@media (orientation: landscape) &#123; body &#123; color: rebeccapurple; &#125;&#125; 2.4 媒体特征规则运算符媒体特征规则支持使用 and，”,”，not 来组合多个探测条件。 1234567891011121314151617181920/* and 表示逻辑与 */@media screen and (min-width: 400px) and (orientation: landscape) &#123; body &#123; color: blue; &#125;&#125;/* 逗号表示或 */@media screen and (min-width: 400px), screen and (orientation: landscape) &#123; body &#123; color: blue; &#125;&#125;/* not操作符让整个媒体查询失效。这就直接反转了整个媒体查询的含义 */@media not all and (orientation: landscape) &#123; body &#123; color: blue; &#125;&#125; 3. 响应式图像4. 视口单位另一种实现响应式排版的方法是使用视口单位vw。1vw等同于视口宽度的百分之一，即如果你用vw来设定字体大小的话，字体的大小将总是随视口的大小进行改变。 123h1 &#123; font-size: 6vw;&#125; 问题在于，当做上面的事情的时候，因为文本总是随着视口的大小改变大小，用户失去了放缩任何使用vw单位的文本的能力。所以你永远都不要只用viewport单位设定文本。 4.1 calc()这里有一个解决方法，它使用了calc()，如果你将vw单位加到了使用固定大小（例如em或者rem）的值组，那么文本仍然是可放缩的。基本来说，是vw加在了放缩后的值上。 123h1 &#123; font-size: calc(1.5rem + 3vw);&#125; 也就是说，我们只需要指定标题的字体大小一次，而不是为移动端设定它，然后再在媒介查询中重新定义它。字体会在你增加视口大小的时候逐渐增大。 4.2 视口元标签一张响应式页面的HTML源代码，你通常将会在文档的看到下面的标签。 1&lt;meta name="viewport" content="width=device-width,initial-scale=1"&gt; 这个元标签告诉移动端浏览器，它们应该将视口宽度设定为设备的宽度，将文档放大到其预期大小的100%。必须这么设置的原因是移动端浏览器倾向于在它们的视口宽度上说谎。 移动端浏览器经常会把视口宽度设为960像素，并以这个宽度渲染页面。结果就会导致你的带断点和媒介查询的响应式设计不会在移动端浏览器上像预期那样工作。如果你有个窄屏布局，在480像素及以下的视口宽度下生效，但是视口是按960像素设定的，你将不会在移动端看到你的窄屏布局。通过设定width=device-width 将浏览器视口宽度设置为设备宽度，你的媒介查询才会像预期那样生效。 所以你应该在你的文档头部总是包含上面那行HTML。 和视口元标签一起，你可以使用另外几个设定，但大体说来，上面那行就是你想要使用的。 initial-scale：设定了页面的初始缩放，我们设定为1。 height：特别为视口设定一个高度。 minimum-scale：设定最小缩放级别。 maximum-scale：设定最大缩放级别。 user-scalable：如果设为no的话阻止缩放。 你应该避免使用minimum-scale、maximum-scale，尤其是将user-scalable设为no。用户应该有权力尽可能大或小地进行缩放，阻止这种做法会引起访问性问题。 学习资源 MDN-响应式布局 MDN-媒体查询 MDN-响应式图像 B站油管最火CSS布局视频: 看完 MDN 在看 B站小甲鱼: 没有一点 HTML 和 CSS 基础的可以先看这个视频]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 CSS 布局-网格]]></title>
    <url>%2F2020%2F09%2F05%2Fweb%2Fhtml_css%2Fhtml_css_5%2F</url>
    <content type="text"><![CDATA[本篇是 CSS 布局的第三篇，今天我们来介绍 CSS3 提供的最新布局技术-网格。我们将按照网格的创建，和网格的使用两个部分来介绍 CSS 网格的使用。 1. 网格的创建CSS网格是一个用于web的二维布局系统。利用网格，你可以把内容按照行与列的格式进行排版。一个网格通常具有许多的列（column）与行（row），以及行与行、列与列之间的间隙，这个间隙一般被称为沟槽（gutter）。 因此一个基本的网格设置需要如下 CSS 属性: 配置项 CSS 属性 作用 网格样式 display:grid 将父容器设置为一个网格 列 grid-template-columns 显示设置列数和列宽 行 grid-template-rows 显示设置行数和行宽 间隙 grid-column-gap 设置列间隙 间隙 grid-row-gap 设置行间隙 间隙 grid-gap 同时设置行列间隙 隐式网格 grid-auto-rows 设置隐式网格的行宽 隐式网格 grid-auto-columns 设置隐式网格的列宽 我们将以下面这个例子为基础演示如何使用 CSS 创建网格进行排版: 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;CSS Grid starting point&lt;/title&gt; &lt;style&gt; body &#123; width: 90%; max-width: 900px; margin: 2em auto; font: .9em/1.2 Arial, Helvetica, sans-serif; &#125; .container &gt; div &#123; border-radius: 5px; padding: 10px; background-color: rgb(207,232,220); border: 2px solid rgb(79,185,227); &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Simple grid example&lt;/h1&gt; &lt;div class="container"&gt; &lt;div&gt;One&lt;/div&gt; &lt;div&gt;Two&lt;/div&gt; &lt;div&gt;Three&lt;/div&gt; &lt;div&gt;Four&lt;/div&gt; &lt;div&gt;Five&lt;/div&gt; &lt;div&gt;Six&lt;/div&gt; &lt;div&gt;Seven&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 1.1 创建网格容器首先，将容器的display属性设置为grid来定义一个网络，前面我们介绍 display 属性的时候说过，dsiplay: grid 属于元素的内部显示类型，用来控制其子元素的布局。因此要创建网格，我们首先要为排版的内容创建一个容器，将父容器改为网格布局后，他的直接子项会变为网格项。 12345&lt;style&gt; .container &#123; display: grid; &#125;&lt;/style&gt; 1.2 定义列数和列宽display: grid的声明默认只创建了一个只有一列的网格，我们需要继续为网格定义列数和列宽。 12345678910&lt;style&gt; .container &#123; display: grid; /* grid-template-columns: 200px 200px 200px */ /* grid-template-columns: 20% 30% 50% */ grid-template-columns: 1fr 2fr 1fr; /* grid-template-columns: repeat(3, 1fr); */ /* grid-template-columns: repeat(3, 1fr, 2fr); */ &#125;&lt;/style&gt; 列宽的定义有三种: 长度 百分比 fr 单位 fr 是一个比例单位，用于划分可用空间(除去固定宽度后的可用空间，fr 和 长度可混用)。可以使用repeat 函数可以重复构建具有某些宽度配置的某些列。 1.3 定义网格间隙使用 grid-column-gap 属性来定义列间隙；使用 grid-row-gap 来定义行间隙；使用 grid-gap 可以同时设定两者。 1234567&lt;style&gt; .container &#123; display: grid; grid-template-columns: 1fr 2fr 1fr; grid-gap: 20px; &#125;&lt;/style&gt; 1.4 隐式网格 显式网格: 是使用 grid-template-columns 或 grid-template-rows 属性显示设置行列数的网格 隐式网格: 行列数根据内容自动调整的网格。简单来说，隐式网格就是为了放显式网格放不下的元素，浏览器根据已经定义的显式网格自动生成的网格部分。 通过 grid-auto-rows 和 grid-auto-columns 属性可以设置隐式网格的宽度，它们的默认参数是 auto，即行列宽自动根据内容调整。 2. 网格属性值设置的函数CSS3 为网格的属性值设置提供了很多有用的函数，方便我们灵活的设置自适应的网页。下面我们来详细看看这些函数的用法，包括: minmax repeat 2.1 minmaxminmax(min, max): 作用: 为一个行/列的尺寸设置了取值范围 参数: min: 最小尺寸 max: 最大尺寸，可以为关键词 auto 标识根据内容自动调整 示例: 比如设定为 minmax(100px, auto)，那么尺寸就至少为100像素，并且如果内容尺寸大于100像素则会根据内容自动调整。 12345678&lt;style&gt; .container &#123; display: grid; grid-template-columns: repeat(1, 1 60% 3); grid-auto-rows: minmax(100px, auto); grid-gap: 20px; &#125;&lt;/style&gt; 2.2 repeatrepeat 函数可以重复构建具有某些宽度配置的某些列。某些情况下，我们需要让网格自动创建很多列来填满整个容器。实现方式如下所示: 12345678&lt;style&gt; .container &#123; display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); repeat(4, [col-start] 250px [col-end]) grid-gap: 20px; &#125;&lt;/style&gt; 在这个示例中: repeat 函数中的一个关键字 auto-fill 来替代确定的重复次数。 第二个参数，我们使用 minmax 函数来设定一个行/列的最小值，以及最大值1fr。 3. 网格的使用3.1 使用网格索引在定义完了网格之后，我们要把元素放入网格中，网格的分割线构成我们索引网格位置的索引。从左往右，开始索引为 1。一个定义了 12 个列的网格分割线编号如下: 通过以下属性来指定使用的网格从那条线开始到哪条线结束。 grid-column-start grid-column-end grid-column: 缩写，grid-column-start / grid-column-end grid-row-start grid-row-end grid-row: 缩写 grid-row-start / grid-row-end 12345678910111213&lt;style&gt; header &#123; /* 分割线 1-3 框定的第 1,2两列 */ grid-column: 1 / 3; grid-row: 1; &#125; article &#123; /* 单个值直接标识第几列 */ grid-column: 2; grid-row: 2; &#125;&lt;/style&gt; 3.2 使用命名网格另一种往网格放元素的方式是用grid-template-areas属性，并对网格区域进行命名并使用。 1234567891011121314151617181920&lt;style&gt; .container &#123; display: grid; grid-template-areas: "header header" "sidebar content" "footer footer"; grid-template-columns: 1fr 3fr; grid-gap: 20px; &#125; header &#123; grid-area: header; &#125; article &#123; grid-area: content; &#125;&lt;/style&gt; grid-template-areas属性的使用规则如下： 你需要填满网格的每个格子 对于某个横跨多个格子的元素，重复写上那个元素grid-area属性定义的区域名字 所有名字只能出现在一个连续的区域，不能在不同的位置出现 一个连续的区域必须是一个矩形 使用.符号，让一个格子留空 学习资源 MDN-网格 B站油管最火CSS布局视频: 看完 MDN 在看 B站小甲鱼: 没有一点 HTML 和 CSS 基础的可以先看这个视频]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 CSS 布局-弹性盒子和多列布局]]></title>
    <url>%2F2020%2F09%2F04%2Fweb%2Fhtml_css%2Fhtml_css_4%2F</url>
    <content type="text"><![CDATA[本篇是 CSS 布局的第二篇，今天我们来介绍 CSS3 另外两种布局技术弹性盒子和多列布局。 1. 弹性盒子弹性盒子是一种用于按行或按列布局元素的一维布局方法。长久以来，CSS 布局中唯一可靠且跨浏览器兼容的创建工具只有 floats 和 positioning，但是下面简单的需求却难以实现: 在父内容里面垂直居中一个块内容。 使容器的所有子项占用等量的可用宽度/高度，而不管有多少宽度/高度可用。 使多列布局中的所有列采用相同的高度，即使它们包含的内容量不同。 弹性盒子使得很多布局任务变得更加容易。 1.1 flex 模型说明当元素表现为 弹性盒子(flex) 时，它们沿着两个轴来布局： flex container: 设置了 display: flex 的父元素被称之为 flex 容器。 flex 项（flex item）:在 flex 容器中表现为弹性盒子的元素 主轴（main axis）是沿着 flex 元素放置的方向延伸的轴。该轴的开始和结束被称为 main start 和 main end。 交叉轴（cross axis）是垂直于 flex 元素放置方向的轴。该轴的开始和结束被称为 cross start 和 cross end。 前面我们介绍 display 属性的时候说过，dsiplay: flex 属于元素的内部显示类型，用来控制其子元素的布局。因此要创建弹性盒子，我们首先要为排版的内容创建一个容器，将父容器设置为 flex，他的直接子项将作为弹性盒子显示。 1.2 弹性盒子的相关属性CSS 中有如下属性可以对弹性盒子进行设置: CSS 属性 作用 默认值 flex-direction 指定主轴的方向，flex item放置方向 row，按行排列 flex-wrap flex item 宽度之和超出容器时，自动换行 flex 设置 flex item 的宽度，有多种设置方式 flex-flow flex-direction 和 flex-wrap align-item 控制 flex item 在交叉轴上的位置 stretch justify-content 控制 flex 项在主轴上的位置 flex-start order flex item 的属性值，控制其排序 123456789&lt;style&gt; .container &#123; flex-direction: row; flex-wrap: wrap; /* 合并写法 */ flex-flow: row wrap; &#125;&lt;/style&gt; 下面我们一一来介绍这些属性的用法和效果。下面是我们使用的基础示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;Flexbox 0 — starting code&lt;/title&gt; &lt;style&gt; html &#123; font-family: sans-serif; &#125; body &#123; margin: 0; &#125; header &#123; background: purple; height: 100px; &#125; h1 &#123; text-align: center; color: white; line-height: 100px; margin: 0; &#125; article &#123; padding: 10px; margin: 10px; background: aqua; &#125; /* Add your flexbox CSS below here */ &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;header&gt; &lt;h1&gt;Sample flexbox example&lt;/h1&gt; &lt;/header&gt; &lt;section&gt; &lt;article&gt; &lt;h2&gt;First article&lt;/h2&gt; &lt;p&gt;Tacos actually microdosing&lt;/p&gt; &lt;/article&gt; &lt;article&gt; &lt;h2&gt;Second article&lt;/h2&gt; &lt;p&gt;Tacos actually microdosing2&lt;/p&gt; &lt;/article&gt; &lt;article&gt; &lt;h2&gt;Third article&lt;/h2&gt; &lt;p&gt;Tacos actually microdosing3&lt;/p&gt; &lt;/article&gt; &lt;/section&gt; &lt;/body&gt;&lt;/html&gt; 1.3 display: flex要想设置 元素为横向的三列布局，我们需要为 flexible 元素的父元素 section 设置 display： 123section &#123; display:flex&#125; 1.4 flex-directionflex-direction 可以指定主轴的方向（弹性盒子子类放置的地方），其有如下可选值: row: 默认值，使得它们在按你浏览器的默认语言方向排成一排(前面说过不同语言的语言方向不一样，我们就是按行排列) row-reverse: row 的逆序 column: 将主轴的方向设置为列(默认语言的垂直方向) 将其设置为 column，将使得页面回到最初的单列布局。 1234section &#123; display:flex; flex-direction: column;&#125; 1.5 flex-wrap当在布局中使用定宽或者定高时，flex item 不会自动换行，从而超过父容器的宽度。解决的方式使用 flex-wrap 让 flex item 自动换行。 12345section &#123; display:flex; flex-wrap: wrap; flex-direction: column;&#125; 1.5 flexflex 属性用于指定 flex item 行高或列宽。它是一个缩写属性，有如下几种设置方式: 200px: 固定值，意味着每个元素的宽度至少是200px； 可以单独指定全写 flex-basis 属性的值 1: 无单位的比例值，表示每个元素占用空间都是相等的，占用的空间是在设置 padding 和 margin 之后剩余的空间 可以单独指定全写 flex-grow 属性的值 1 200px: 每个flex 项将首先给出200px的可用空间，然后，剩余的可用空间将根据分配的比例共享 1.6 align-itemalign-items 控制 flex 项在交叉轴上的位置: stretch: 默认的值，其会使所有 flex 项沿着交叉轴的方向拉伸以填充父容器 如果父容器在交叉轴方向上没有固定宽度（即高度），则所有 flex 项将变得与最长的 flex 项一样长（即高度保持一致）。 center: 会使这些项保持其原有的高度，但是会在交叉轴居中。这就是那些按钮垂直居中的原因。 flex-start 或 flex-end: 使 flex 项在交叉轴的开始或结束处对齐所有的值 start 或 end self-start 或 self-end 123456789container &#123; display: flex; align-items: center; justify-content: space-around;&#125;item &#123; align-self: flex-start&#125; 对 flex item 设置 align-self 属性可以覆盖 align-items 的行为。 1.7 justify-contentjustify-content 控制 flex 项在主轴上的位置。 flex-start: 默认值，这会使所有 flex 项都位于主轴的开始处。 flex-end: 来让 flex 项位于主轴的结尾处。 center 在 justify-content 里也是可用的，可以让 flex 项在主轴居中。 space-around 是很有用的——它会使所有 flex 项沿着主轴均匀地分布，在任意一端都会留有一点空间。 space-between，它和 space-around 非常相似，只是它不会在两端留下任何空间。 1.8 order通过 order 属性，可以改变 flex 项的布局位置的功能，而不会影响到源顺序。 123button:first-child &#123; order: 1;&#125; 注意: 所有 flex 项默认的 order 值是 0。 order 值大的 flex 项比 order 值小的在显示顺序中更靠后。 相同 order 值的 flex 项按源顺序显示 也可以给 order 设置负值使它们比值为 0 的元素排得更前面 2. 多列布局多列布局是现代布局方式中最古老的一个。多列布局声明提供了一种多列组织内容的方式。同弹性盒子一样需要为待排版的内容创建一个父元素容器，然后使用下面属性设置多列布局: CSS 属性 作用 默认值 column-count 设置列数 column-width 设置列宽度 column-gap 更改列的间隙 column-rule 在列间加入一条分割线 设施方式同 border break-inside 控制多列布局内容的拆分、折断 2.1 列数设置column-count，column-width 从两个方面设置多列布局的列数，二者不能同时使用: column-count: 直接指定列数 column-width: 指定列的宽度，浏览器将按照你指定的宽度尽可能多的创建列；任何剩余的空间之后会被现有的列平分。 2.2 更改列样式多列布局创建的列无法单独的设定样式。 不存在让单独某一列比其他列更大的方法，同样无法为某一特定的列设置独特的背景色、文本颜色。只有两个属性更改统一设置所有列的样式： 12345.container &#123; column-count: 3; column-gap: 20px; column-rule: 4px dotted rgb(79, 185, 227);&#125; 分割线本身并不占用宽度。它置于用 column-gap 创建的间隙内。 2.3 列与内容折断多列布局的内容被拆成碎块，即内容不再同一列内。为每一个列项添加 break-inside: avoid 可以保证内容不会被折断。 学习资源 MDN-弹性盒子 MDN-多列布局 B站油管最火CSS布局视频: 看完 MDN 在看 B站小甲鱼: 没有一点 HTML 和 CSS 基础的可以先看这个视频]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 CSS 选择器]]></title>
    <url>%2F2020%2F09%2F03%2Fweb%2Fhtml_css%2Fhtml_css_2%2F</url>
    <content type="text"><![CDATA[本节我们来学习 CSS 选择器，内容不复杂，就是要记住几种选择器语法。 1. 选择器的分类通常我们将 CSS 选择器分为如下五类: 基本选择器: 通用选择器: * 元素选择器：以某个 HTML 元素作为选择器 类选择器: 使用 HTML 元素的 class 属性进行定位，语法为 .class id选择器: 使用 HTML 元素的 id 属性进行定位，语法为 #id 复合选择器: 由两个或者多个基础选择器组成 交集选择器: 选择器.类选择器，元素选择器#id选择器 并级选择器: 选择器1，选择器2,…. 后代选择器: 选择器1 选择器2 …..，选择所有后代元素 子元素选择器: 选择器1 &gt; 选择器2，只选择直接子元素 相邻兄弟选择器: 选择器1 + 选择器2，选择器2选择的元素必须紧跟在选择器1后面，并且它们有相同父元素 通用兄弟选择器: 选择器1 ~ 选择器2，与相邻兄弟选择器相比不需要紧挨着 伪类选择器: 用于当已有元素处于某个状态时，为其添加样式 伪元素选择器: 用于创建一些不存在文档树的元素，为其添加样式 属性选择器: 通过元素的属性选择元素 接下来我们来详细讲解伪类与伪元素选择器。 2. 伪元素选择器所谓伪元素选择器指的是”假装”有一个元素，然后选择它，包括: ::first-line: 选择文本的第一行，仅对块级元素内的第一行内容有效 ::first-letter: 选择文本块的第一个字符 ::before/::after: ::selection: 选择用户选中的文本 3. 伪类选择器所谓伪类选择器指的是选择处于特定状态的元素，包括: 动态伪类选择器 UI 伪类选择器 结构伪类选择器 其他伪类选择器 3.1 动态伪类选择器动态伪类选择器会根据条件的改变而匹配元素，包括: 伪类选择器: :link: 链接未被访问时 :visited: 链接被访问过后 :hover: 当鼠标悬停在链接上时， :active: 鼠标按下链接的那一刻 :focus: 当元素获取焦点时，所谓获取焦点指的是能获取键盘输入的字符时 说明: :hover 必须位于:link 和 :visited 后面，:active 必须位于 :hover 后面，记忆方法 LOVE &amp; HATE :hover 伪类选择器可以用于所有标签上 其他伪类选择器只能用于 a 标签上 123456div:hover&#123; background-color: green;&#125;div:hover span&#123; color: white;&#125; 3.2 UI 伪类选择器UI 伪类选择器用于选择具有特定状态的表单元素: 通用 UI 伪类选择器: :enable/:disable: 分别用于选中可用和不可用状态下的表单 :checked: 用于选中单选框，复选框和下拉列表被选中的选项 :required/:optional: 用于选中可选和必选的表单元素 :default: 选中默认的表单元素，比如提交表单就是一个默认元素 :read-only/:read-write: 分别用于选中只读和可读可写的表单元素，input 默认是可读可写的 适用于 input 的 UI 伪类选择器: :vaild/:invalid: 用于选中值合法和不合法的 input 元素 :in-range/:out-of-range: 适用: 设置了min，max 属性且 type=”number” 的 input 元素 :in-range 表示值在范围内时选中，:out-of-range 表示不在范围内时选中 3.3 结构伪类选择器结构伪类选择器用于选择 DOM 中特定位置的元素，包括: 没什么用的结构伪类选择器: :root: 总是匹配到 HTML 元素 :empty: 总是匹配没有定义任何内容的元素 匹配子元素的结构伪类选择器: 选择的方式是元素相对于其父元素的位置 :first-child/:last-child: 作用: 选择第一个和最后一个子元素 示例: p:first-child 选择p元素，且p是其父元素的第一个子元素 :only-child: 如果该元素是其父元素的唯一子元素，选中 :only-of-type: 作用: 如果子元素是其父元素下唯一类型的子元素，选中 示例: strong:only-of-type 如果 strong 是其父元素内的唯一一个 strong，选中 :first-of-type/:last-of-type: 作用: 选择第一个和最后一个特定类型的子元素 示例: p:first-of-type 如果 p 是其父元素内第一 p 元素，不一定是第一个位置，选中 :nth-child(n)/:nth-last-child(n): 作用: n 指定元素所在的索引，:nth-child(n) 表示匹配顺序第 n 个子元素 示例: p:nth-child(3) 如果 p 是其父元素的第三个子元素，选中 :nth-of-type(n)/:nth-last-of-type(n): 作用: n 指定元素所在的索引，但是索引仅限于指定的特定类型 示例: p:nth-of-type(3) 如果 p 是其父元素的第三个 p 元素，选中 3.4 其他伪类选择器其他伪类选择器是不能归属于上面分类的伪类选择器，包括: :target: 选中页面内锚点 :lang(): 作用: 匹配了设置了 lang 全局属性的元素 示例: lang(en) 选中类似 &lt;p lang=&quot;en&quot;&gt;&lt;/p&gt; 设置了 lang=”en” 的元素 :not(selector): 作用: 否定选择器，选择 selector 选择器选中之外的元素 4. 属性选择器 选择器 描述 [attribute] 用于选取带有指定属性的元素 [attribute=value] 用于选取带有指定属性和值的元素 [attribute~=value] 用于选取属性值中包含指定词汇的元素，该值必须是整个单词 [attribute =value] 用于选取带有以指定值开头的属性值的元素，该值必须是整个单词 [attribute^=value] 匹配属性值以指定值开头的每个元素 [attribute$=value] 匹配属性值以指定值结尾的每个元素 [attribute*=value] 匹配属性值中包含指定值的每个元素 1234[class|=top]&#123; background-color:yellow;&#125; 上面的 css 将选中一下标签: 123&lt;p class="top aaa"&gt;&lt;/p&gt; &lt;!-- 横杠作为分隔符的也可以匹配 --&gt;&lt;p class="top-aaa"&gt;&lt;/p&gt;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 CSS 布局-基础]]></title>
    <url>%2F2020%2F09%2F03%2Fweb%2Fhtml_css%2Fhtml_css_3%2F</url>
    <content type="text"><![CDATA[CSS 布局是学习 HTML&amp;CSS 的第一个难点，我们分三节来搞定他。 1. CSS 布局概述CSS 布局技术的作用是控制HTML 元素显示的相对位置。在我们学些 CSS 的不同布局技术之前，我们首先要搞明白下面这些内容: CSS 的盒子模型: 元素在页面显示的基本控制单位 块级元素和行内元素: 按照 HTML 默认显示方式，对 HTML 元素的分类，块级元素和行内元素都与一种特定的盒子模型相关联 正常布局流: 浏览器的默认布局行为，即如何对每个 HTML 元素对应的盒子进行排版 1.1 块元素与行内元素HTML 的元素分为两类: 块元素: 占据其父元素整块空间，默认情况下，块级元素会新起一行(与语言默认的阅读顺序有关)。 行内元素: 只能位于块元素内，只会占据内容实际使用空间。 块元素内容的布局方向被描述为块方向。块方向在英语等具有水平书写模式(writing mode)的语言中垂直运行。它可以在任何垂直书写模式的语言中水平运行。对应的内联方向是内联内容（如句子）的运行方向。 HTML 元素是块元素还是行内元素并不是绝对的。每一个 HTML 元素都有一个默认的 display 属性值，它决定了这个元素应该以怎样的形态还在那时在我们面前。 1.3 盒子模型盒子模型是浏览样式和布局的基本单位，浏览器通过控制每个盒子的样式，盒子与盒子之间的位置关系达到设置样式和布局的目的。标准的盒子模型如下: 块级元素与内联元素的盒子模型表现不同: 块级元素对应的是块级盒子(Block box) 盒子会在内联的方向上扩展并占据父容器在该方向上的所有可用空间，在绝大数情况下意味着盒子会和父容器一样宽每个盒子都会换行 width 和 height 属性可以发挥作用 内边距（padding）, 外边距（margin） 和 边框（border） 会将其他元素从当前盒子周围“推开” 行内元素对应的是内联盒子(Inline box)，与块级盒子相比: 盒子不会产生换行 width 和 height 属性将不起作用 垂直方向的内边距、外边距以及边框会被应用但是不会把其他处于 inline 状态的盒子推开 水平方向的内边距、外边距以及边框会被应用而且也会把其他处于 inline 状态的盒子推开 1.4 正常布局流正常布局流(normal flow)是指在不对页面进行任何布局控制时，浏览器默认的HTML布局方式。正常布局流中: HTML元素完全按照源码中出现的先后次序显示 块级元素和行内元素将按照前面介绍的盒子模型进行展示 接下来我们介绍的布局技术就是用来覆盖默认的布局行为: display 属性: 可以更改标签默认的显示方式 position 属性: 定位，允许你精准设置盒子的位置 float: 浮动 弹性盒子 多列布局 网格 本节我们主要来介绍前两种传统的布局方式 position 和 float。我们将在接下来的两节中分别介绍弹性盒子和多列布局，网格。 2. display 属性值display 属性值决定了元素的展现形态，可以设置元素的内部和外部显示类型: 元素的外部显示类型 outer display types 决定了该元素在流式布局中的表现（块级 block 或内联元素 inline） 元素的内部显示类型 inner display types 可以控制其子元素的布局，这些属性需要和其他布局技术结合使用(注意作用的对象是元素的子元素) display 有下面这些可选值: 值 描述 none 此元素不会被显示。 block 此元素将显示为块级元素，此元素前后会带有换行符。 inline 默认。此元素会被显示为内联元素，元素前后没有换行符。 inline-block 行内块元素。（CSS2.1 新增的值） list-item 此元素会作为列表显示。 run-in 此元素会根据上下文作为块级元素或内联元素显示。 table 此元素会作为块级表格来显示（类似 &lt;table&gt;），表格前后带有换行符。 inline-table 此元素会作为内联表格来显示（类似 &lt;table&gt;），表格前后没有换行符。 table-row-group 此元素会作为一个或多个行的分组来显示（类似 &lt;tbody&gt;）。 table-header-group 此元素会作为一个或多个行的分组来显示（类似 &lt;thead&gt;）。 table-footer-group 此元素会作为一个或多个行的分组来显示（类似 &lt;tfoot&gt;）。 table-row 此元素会作为一个表格行显示（类似 &lt;tr&gt;）。 table-column-group 此元素会作为一个或多个列的分组来显示（类似 &lt;colgroup&gt;）。 table-column 此元素会作为一个单元格列显示（类似 &lt;col&gt;） table-cell 此元素会作为一个表格单元格显示（类似 &lt;td&gt; 和 &lt;th&gt;） table-caption 此元素会作为一个表格标题显示（类似 &lt;caption&gt;） inherit 规定应该从父元素继承 display 属性的值。 3. 定位position 有不同值，对应不同的定位方式: position值 定位方式 显示规则 static 静态定位 元素定位的默认值，意味将元素放入布局流的正常位置 relative 相对定位 相对于元素正常布局流的位置，向上向下向左向右移动，不会影响周围元素的位置 absolute 绝对定位 相对于绝对定位元素的包含元素( 元素或其最近的定位祖先)，位于独立的层，不再存在于正常文档布局流中 fixed 固定定位 与绝对定位类似，但是只相对于浏览器视口本身，位于独立的层，不再存在于正常文档布局流中 sticky “粘性”定位 相对位置和固定位置的混合体 3.1 relative相对定位有一下特点: 不脱离标准文档流 参考点: 以原来的位置为参考点 修改相对定位，需要使用top，bottom，left和right属性。需要注意的是这些属性值的设置方式是相反的，你需要考虑一个看不见的力，推动定位的盒子的一侧，移动它的相反方向。 所以例如，如果你指定 top: 30px;一个力推动框的顶部，使它向下移动30px。top，bottom，left和right 属性对下面几个 position 值同样适用。 3.2 absolute绝对定位有以下特点: 脱离标准文档流，不在页面占据位置 层级提高，存在压盖现象 绝对定位元素的参考点取决于绝对定位元素的父元素的position属性: 如果所有的父元素都没有显式地定义position属性，绝对定位元素会被放在元素的外面，并且根据浏览器视口来定位，即相对于元素 如果存在任意父元素 position 属性为非 static，绝对定位元素就会相对于最近的 position != static 的父元素进行定位，即相对于最近的定位祖先。 “子绝父相”，即子元素使用绝对定位，父元素使用相对定位是我们 CSS 布局中常用的定位方式，这样可以帮助我们将子元素的定位限定在父元素内。 3.3 fixed固定定位有以下特点: 脱离标准文档流 一旦设置固定定位，在页面中滚动网页，固定不变 参考点是浏览器的左上角 fixed 与绝对定位的工作方式完全相同，只有一个主要区别：绝对定位固定元素是相对于 元素或其最近的定位祖先，而固定定位固定元素则是相对于浏览器视口本身。 3.4 sticky允许被定位的元素表现得像相对定位一样，直到它滚动到某个阈值点（例如，从视口顶部起1​​0像素）为止，此后它就变得固定了。 3.5 z-indexz-index 属性值用于设置重叠元素的显示顺序，你可以想想网页也有一个z轴：一条从屏幕表面到你的脸。z-index 值影响定位元素位于该轴上的位置；正值将它们移动到堆栈上方，负值将它们向下移动到堆栈中。默认情况下，定位的元素都具有z-index为auto，实际上为0。 4. float4.1 float 的使用float 属性最初只用于在成块的文本内浮动图像。但是能浮动不止图像，float 可以生成多列布局。我们来看一个 float 的简单示例 12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;style&gt; body&#123; width: 600px; margin: 0 auto; &#125; img &#123; float: left; margin-right: 30px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;Simple float example&lt;/h1&gt; &lt;img src="https://mdn.mozillademos.org/files/13340/butterfly.jpg" alt="A pretty butterfly with red, white, and brown coloring, sitting on a large leaf"&gt; &lt;p&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla luctus aliquam dolor, eu lacinia lorem placerat vulputate. Duis felis orci, pulvinar id metus ut, rutrum luctus orci. Cras porttitor imperdiet nunc, at ultricies tellus laoreet sit amet. Sed auctor cursus massa at porta. Integer ligula ipsum, tristique sit amet orci vel, viverra egestas ligula. Curabitur vehicula tellus neque, ac ornare ex malesuada et. In vitae convallis lacus. Aliquam erat volutpat. Suspendisse ac imperdiet turpis. Aenean finibus sollicitudin eros pharetra congue. Duis ornare egestas augue ut luctus. Proin blandit quam nec lacus varius commodo et a urna. Ut id ornare felis, eget fermentum sapien.&lt;/p&gt; &lt;p&gt;Nam vulputate diam nec tempor bibendum. Donec luctus augue eget malesuada ultrices. Phasellus turpis est, posuere sit amet dapibus ut, facilisis sed est. Nam id risus quis ante semper consectetur eget aliquam lorem. Vivamus tristique elit dolor, sed pretium metus suscipit vel. Mauris ultricies lectus sed lobortis finibus. Vivamus eu urna eget velit cursus viverra quis vestibulum sem. Aliquam tincidunt eget purus in interdum. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 对于 float: 浮动元素 (这个例子中的 元素)会脱离正常的文档布局流，并吸附到其父容器的左边 (这个例子中的元素)。 在正常布局中位于该浮动元素之下的内容，此时会围绕着浮动元素，填满其右侧的空间。 浮动内容仍然遵循盒子模型诸如外边距和边界。 可以漂浮任何的东西，只要有两个项目的空间，以配合在一起。 4.2 多列浮动布局1234567891011&lt;h1&gt;2 column layout example&lt;/h1&gt;&lt;div&gt; &lt;h2&gt;First column&lt;/h2&gt; &lt;p&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla luctus aliquam dolor, eu lacinia lorem placerat vulputate. Duis felis orci, pulvinar id metus ut, rutrum luctus orci. Cras porttitor imperdiet nunc, at ultricies tellus laoreet sit amet. Sed auctor cursus massa at porta. Integer ligula ipsum, tristique sit amet orci vel, viverra egestas ligula. Curabitur vehicula tellus neque, ac ornare ex malesuada et. In vitae convallis lacus. Aliquam erat volutpat. Suspendisse ac imperdiet turpis. Aenean finibus sollicitudin eros pharetra congue. Duis ornare egestas augue ut luctus. Proin blandit quam nec lacus varius commodo et a urna. Ut id ornare felis, eget fermentum sapien.&lt;/p&gt;&lt;/div&gt;&lt;div&gt; &lt;h2&gt;Second column&lt;/h2&gt; &lt;p&gt;Nam vulputate diam nec tempor bibendum. Donec luctus augue eget malesuada ultrices. Phasellus turpis est, posuere sit amet dapibus ut, facilisis sed est. Nam id risus quis ante semper consectetur eget aliquam lorem. Vivamus tristique elit dolor, sed pretium metus suscipit vel. Mauris ultricies lectus sed lobortis finibus. Vivamus eu urna eget velit cursus viverra quis vestibulum sem. Aliquam tincidunt eget purus in interdum. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.&lt;/p&gt;&lt;/div&gt; 像上面这样，要实现一个两列布局，我们需要: 每个列都需要一个外部元素来包含其内容，并让我们一次操作它的所有内容，这个外部元素通常是类似， 等语义化标签，这里使用的是 div 标签 要想将两个 div 放在一起，我们需要将它们的宽度之和设置为父元素宽度的 100% 或者更小，这样它们才能彼此相邻 最后让两个 div 标签左右浮动 下面是设置的 CSS 样式 1234567891011&lt;style&gt; div:nth-of-type(1) &#123; width: 48%; float: left; &#125; div:nth-of-type(2) &#123; width: 48%; float: right; &#125;&lt;/style&gt; 4.3 清除浮动浮动存在的一个问题是所有在浮动下面的自身不浮动的内容都将围绕浮动元素进行包装。通过 clear 属性可以清除浮动。当你把这个应用到一个元素上时，它主要意味着”此处停止浮动”——这个元素和源码中后面的元素将不浮动。 clear 可以取三个值： left：停止任何活动的左浮动 right：停止任何活动的右浮动 both：停止任何活动的左右浮动 4.4 浮动问题浮动元素宽度问题通过浮动来进行布局的一个问题是，通过合理配置浮动元素的宽度，包括边框和内外距。因为如果浮动元素的宽的和超过父元素，布局就会错乱。一种避免边框内边距对宽度造成的方式是使用 box-sizing 属性。 box-sizing 通过更改盒模型来拯救我们，盒子的宽度取值为 content + padding + border，而不仅是之前的content——所以当增加内边距或边界的宽度时，不会使盒子更宽——而是会使内容调整得更窄。 box-sizing 取值包括: content-box: width = content border-box: width = border + padding + content 清除浮动的元素无法设置外边距问题浮动的元素存在于正常的文档布局流之外，在某些方面的行为相当奇怪： 首先，他们在父元素中所占的面积的有效高度为0 其次，非浮动元素的外边距不能用于它们和浮动元素之间来创建空间 我们可以通过在浮动和非浮动元素之间创建一个不显示的空标签来解决。像下面这样: 通过 div.clearfix 来清除浮动 将外边距加在 div.clearfix 和 footer 之间 123456789101112131415&lt;style&gt; .clearfix &#123; clear: both; &#125;&lt;/style&gt;&lt;div&gt; &lt;h2&gt;Second column&lt;/h2&gt; &lt;p&gt;Nam vulputate diam nec tempor bibendum. Donec luctus augue eget malesuada ultrices. Phasellus turpis est, posuere sit amet dapibus ut, facilisis sed est. Nam id risus quis ante semper consectetur eget aliquam lorem. Vivamus tristique elit dolor, sed pretium metus suscipit vel. Mauris ultricies lectus sed lobortis finibus. Vivamus eu urna eget velit cursus viverra quis vestibulum sem. Aliquam tincidunt eget purus in interdum. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.&lt;/p&gt;&lt;/div&gt;&lt;div class="clearfix"&gt;&lt;/div&gt;&lt;footer&gt;&lt;/footer&gt; 不同列的行高不一样最后一个问题是我们布局的多列高度不同，我们可以通过给所有的列固定height 来解决这个问题，但是它使设计呆板，因此我们需要更加高级的布局技术。 学习资源 MDN-CSS定位: 非常的详细清晰 MDN-浮动: 非常的详细清晰 B站油管最火CSS布局视频: 看完 MDN 在看 B站小甲鱼: 没有一点 HTML 和 CSS 基础的可以先看这个视频]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 HTML&CSS 入门开篇]]></title>
    <url>%2F2020%2F09%2F01%2Fweb%2Fhtml_css%2Fhtml_css_1%2F</url>
    <content type="text"><![CDATA[这个系列是 javaScript 系列的后续，想做前端开发只会 JS 还是不够的，还要会 HTML&amp;CSS，还要回 Vue，还要回 React…..。人生何其艰难啊啊。 1. HTML&amp;CSSHTML 和 CSS 的内容很多，但是大多数都是标准，没有太多的理解上或者上可以通过逻辑串联的地方。W3CSchool 和 MDN 已经罗列的非常好了，所以也不想一个个标签在码一遍。所以这个系列没什么连贯性，基本上有什么觉得值的写的难的就会写上。目前能想到的内容如下: CSS 选择器 CSS 布局 2. 学习资料下面是找到的前端学习资料: w3school MDN: 非常的详细 B站小甲鱼-零基础入门学习Web开发: 没有一点 HTML 和 CSS 基础的可以先看这个视频 找学习资料的时候，发现了一个培训班路飞学城，感觉还可以，报了。师傅领进门，学习在个人，加油吧骚年。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>HTML&amp;CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 模块化]]></title>
    <url>%2F2020%2F08%2F27%2Fweb%2FES6%2Fes6_12%2F</url>
    <content type="text"><![CDATA[JavaScript 模块化 1. JavaScript 模块化概述ECMAScript 6以前，在应用程序的每一个JavaScript中定义的一切都共享一个全局作用域。随着应用复杂度的提升，这一做法会引起诸如命名冲突、安全等问题。ES6 为 JavaScript 引入了模块。JavaScript 模块化经历了好几个阶段，我也不是很了解，这里我们就直接来看看 ES6 定义的最新语法。 那什么是模块呢: ES6 中模块是自动运行在严格模式下并且没有办法退出运行的JavaScript代码 在模块顶部创建的变量不会自动被添加到全局共享作用域，这个变量仅在模块的顶级作用域中存在 模块内定义的元素必须导出才能被其他模块访问 在模块的顶部，this的值是undefined 模块不支持HTML风格的代码注释 模块和 JavaScript 脚本代表了JavaScript代码加载和求值的一个重要变化。 2. 模块的基本语法与模块的相关的语法包括: 模块的导出 模块的导入 导出绑定: 在一个模块中导出另一个模块的变量 默认导出 JavaScript 模块的导入和导出有各种方式，下面是一个使用的示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 1. 模块导出// 导出声明: 可以将export放在任何变量、函数或类声明的前面export let name = "hii";function sum()&#123;&#125;// 导出引用:export sum;// 导出重命名export &#123;sum as add&#125;;// 导出默认值// 由于函数被模块所代表，因而它不需要一个名称export default function(num1, num2)&#123; return num1 + num2;&#125;export default sum;export &#123; sum as default &#125;;// 2. 模块导入// import语句的两个部分分别是：要导入的标识符和标识符应当从哪个模块导入// var1, var2 称为绑定，../example.js 称为模块说明符import &#123; var1, var2 &#125; from "../example.js";// 导入整个模块，所有导出将作为 example 的属性存在，又称为 命名空间导入import * as example from "../example.js";// 导入重命名import &#123;add as sum&#125; from "../example.js";// 导入默认值，这里不需要大括号import sum from "../example.js";// 导入默认以及非默认值，在import语句中，默认值必须排在非默认值之前。import sum, &#123;var1, var2&#125; from "../example.js";// 导入默认值时使用重命名语法：import &#123; default as sum, var2 &#125; from "../example.js";// 无绑定导入import "../example.js";// 3. 导出绑定export &#123; sum as add &#125; from "../example.js";// 如果想导出另一个模块中的所有值，则可以使用*模式：export * from "../example.js"; 对于导出: 除非用 default 关键字，否则不能用这个语法导出匿名函数或类 用default来重命名模块是为了尽可能与非默认导出的定义一致 对于导入: 当从模块中导入一个绑定时，它就好像使用const定义的一样。你无法定义另一个同名变量（包括导入另一个同名绑定），也无法在import语句前使用标识符或改变绑定的值 为了最好地兼容多个浏览器和Node.js环境，导入的模块路劲一定要包含/、./或../ 可以导入整个模块作为一个单一的对象，所有的导出都可以作为对象的属性使用，又称命名空间导入 不管在import语句中把一个模块写了多少次，该模块将只执行一次。导入模块的代码执行后，实例化过的模块被保存在内存中 export和import必须在其他语句和函数之外使用，不支持动态导入导出，目的是让 JavaScript 引擎静态地确定哪些可以导出 无绑定导入: 某些模块可能不导出任何东西，相反，它们可能只修改全局作用域中的对象。内建对象（如Array和Object）的共享定义可以在模块中访问，对这些对象所做的更改将反映在其他模块中 导出绑定: 导出一切是指导出默认值及所有命名导出值，而默认值只能有一个，将无法定义一个新的默认导出 模块标识符浏览器要求模块说明符具有以下几种格式之一： 以/开头的解析为从根目录开始。 以./开头的解析为从当前目录开始 以../开头的解析为从父目录开始 URL格式 一些看起来正常的模块说明符在浏览器中实际上是无效的，并且会导致错误，例如：1234// 即使在&lt;script&gt;标签中用作src的值时二者都可以正常工作// 但是作为模块时，因为缺少正确的起始字符，实际上是无效的import &#123; var &#125; from "example.js";import &#123; var &#125; from "example/script.js"; 2.1 导入绑定的副作用ECMAScript 6的import语句为变量、函数和类创建的是只读绑定，而不是像正常变量一样简单地引用原始绑定。标识符只有在被导出的模块中可以修改，即便是导入绑定的模块也无法更改绑定的值。 123456789101112// 1. 模块export var name = "tsong";export function setName(name)&#123; name = name;&#125; // 2. 导入模块import &#123;name, setName&#125; from "./test.js";setName("PPP");// 只读绑定，不能修改name = "XXXX"; // 报错 在上面的示例中，name是导出的name标识符的本地名称，此 name 在导入模块中是只读绑定不能修改，但是能立即反映出 setName 对 name标识符的修改 2.2 模块加载ES6 没有定义如何加载模块，只定义了语法，并将加载机制抽象到一个未定义的内部方法HostResolveImportedModule中。浏览器和 Node.js 有不同的实现机制。 在浏览器中有如下使用模块的方式: &lt;script src=&quot;&quot;&gt;&lt;/script&gt; &lt;script&gt;js code&lt;/script&gt; Web Worker或Service Worker(不懂) 通过使用 &lt;script src=&quot;&quot; type=&quot;mode&quot;&gt;&lt;/script&gt;, 定义 type=”mode” 表示加载一个模块。虽然模块与正常的JavaScript脚本并没有什么不同，但是，模块实际的加载过程却有一些不同: 首先为了支持模块内的相互导入，&lt;script type =&quot;module&quot;&gt;执行时自动应用defer属性，默认保证了模块执行的顺序性 每个模块都可以从一个或多个其他的模块导入，这会使问题复杂化: 首先解析模块以识别所有导入语句； 然后，每个导入语句都触发一次获取过程(网络或者缓存) 所有导入资源都被加载和执行后才会执行当前模块 12345678910&lt;script src="module1.js" type="module"&gt;&lt;/script&gt;// 要使用 ES6 模块功能，script 引入的 JS 本身也必须是 模块&lt;script type="module"&gt; import &#123; sum &#125; from "./module1.js"&lt;/script&gt;&lt;script src="module2.js" type="module"&gt;&lt;/script&gt; 在上面的示例中，模块的加载和解析顺序是这样的: 下载并解析module1.js 递归下载并解析module1.js中导入的资源 解析内联模块 递归下载并解析内联模块中导入的资源 下载并解析module2.js 递归下载并解析module2.js中导入的资源 加载完成后，只有当文档完全被解析之后才会执行其他操作。文档解析完成后，会发生以下操作： 递归执行module1.js中导入的资源 执行module1.js 递归执行内联模块中导入的资源 执行内联模块 递归执行module2.js中导入的资源 执行module2.js async属性也可以应用在模块上，效果与应用在脚本上类似，与脚本唯一的区别是在模块执行前，模块中所有的导入资源都必须下载下来。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 类]]></title>
    <url>%2F2020%2F08%2F27%2Fweb%2FES6%2Fes6_13%2F</url>
    <content type="text"><![CDATA[JavaScript 的类 1. JavaScript class 类声明语法ES6 为 JavaScript 添加了类似其他面向对象语言的 class 类声明语法，在内部实现上 class 只是基于原型的面向对象开发的语法糖。而使用 class 定义类属性和方法的方式与对象字面量基本上完全相同，包括简明式的方法声明，可计算属性，访问器属性等等，但不需要在类的各元素之间使用逗号分隔。 123456789function Person(name)&#123; this.name = name;&#125;;Person.prototype.sayName = function()&#123; console.log(this.name);&#125;var person = new Person("Ward"); 上面是 ES5 中创建类的示例，而与此对应的 class 类声明如下: 1234567891011121314151617class Person &#123; // 等价的构造函数 constructor(name)&#123; this.name = name; // 构造函数内 new.target 等于类的构造函数 console.log(new.target === Person) &#125; // 没有逗号分隔 // 等价于 Person.prototype.sayName sayName()&#123; console.log(this.name); &#125;&#125;var person = new Person("Ward");console.log(typeof Person); // function class 类声明仅仅是基于原型的类型声明的语法糖: class 内部使用特殊的 constructor 方法名来定义构造函数 typeof PersonClass 返回的结果是”function”，所以 Person 声明实际上创建了一个具有构造函数方法行为的函数 定义在 class 内的方法，最终同样被定义在 Person 的原型上 1.1 class 类声明与基于原型的类定义的区别尽管类与自定义类型之间有诸多相似之处，但它们存在下面差异: 函数声明可以被提升，而类声明与let声明类似，不能被提升；真正执行声明语句之前，它们会一直存在于临时死区中。 类声明中的所有代码将自动运行在严格模式下，而且无法强行让代码脱离严格模式执行。 在自定义类型中，需要通过Object.defineProperty()方法手工指定某个方法为不可枚举；而在类中，所有方法都是不可枚举的。 每个类都有一个名为[[Construct]]的内部方法，通过关键字new调用那些不含[[Construct]]的方法会导致程序抛出错误。 使用除关键字new以外的方式调用类的构造函数会导致程序抛出错误 类方法没有 [[Construct]] 内部方法，作为构造函数调用时也会报错 在类中修改类名会导致程序报错。 Person.prototype 将是一个只可读的类属性，任何的重新赋值都不会生效，也不会报错 因此与 class 类声明严格相等的原型类定义如下: 1234567891011121314151617181920212223242526272829// 1. 类声明不会提升let Person = (function()&#123; // 2. 严格模式 "use strict"; // 3. 类中类名不可修改 const Person2 = function(name)&#123; // 5. 构造函数不能作为函数直接调用 if (new.target === "undefined")&#123; throw new Error("必须通过构造函数进行调用") &#125; this.name = name; &#125; // 4. 方法不可枚举 Object.defineProperty(Person2.prototype, sayName, &#123; value: function()&#123; // 6. 方法不能作为构造函数调用 if (new.target !== "undefined")&#123; throw new Error("不可使用 new 关键词进行调用") &#125; console.log(this.name); &#125;, writable: true, enumerable: false, configurable: true &#125;); return Person2&#125;()); 2. class 类语法ES6 中 class 定义的类同函数一样(本质上也是函数)，是一等公民，都有两种存在方式: 声明形式和表达式形式。在类中定义属性和方法与对象字面量基本类似，下面定义一个 class 类可能会用到的语法示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 1. 类表达式let Person = class &#123; constructor(name)&#123; this.name = name; &#125;&#125;// 2. 命名类表达式let Person = class Person2&#123; constructor(name)&#123; this.name = name; &#125;&#125;methodName = "query"class Custom &#123; constructor(element)&#123; this.element = element; this.item = []; &#125; // 3. 访问器属性 get html()&#123; return this.element.html; &#125; set html(value)&#123; this.element.innerHTML = value; &#125; // 4. 可计算成员名称 get [methodName]() &#123; return "query" &#125; // 5. 定义默认迭代器 *[Symbol.iterator]()&#123; yield *this.items.values() &#125; // 另一种定义迭代器的方式 [Symbol.iterator]()&#123; return this.items.values() &#125;&#125; 注: 类声明与类表达式的主要区别在于类的 name 属性，匿名类表达式的name属性值是一个空字符串，而类声明的name属性值为类名 命名类表达式定义的类名 Person2 只存在类定义中，只能在类的内部使用，外部无法使用(看上面的 ES5 类定义的等价示例就明白了) 2.1 静态方法在ECMAScript 5中，直接将方法添加到构造函数中来模拟静态成员是一种常见的模式，class 类通过 static 关键字简化了静态的方法创建: 12345678910111213let Person = class &#123; constructor(name)&#123; this.name = name; &#125; // 1. 静态方法 static create()&#123; return new Person("aa"); &#125; // 2. 静态属性 static age: 10&#125; 类中的所有方法和访问器属性都可以用static关键字来定义，唯一的限制是不能将static用于定义构造函数方法。因为构造函数不在原型链上，所以 JavaScript 中实例无法访问静态成员。 3. 类继承ES5 中实现继承需要编写不少的代码，需要分别继承属性和方法，并重写构造函数的原型。ES6 简化了类继承的实现，使用熟悉的extends关键字可以指定类继承的函数。原型会自动调整，通过调用super()方法即可访问基类的构造函数。 12345678910111213141516171819202122232425262728293031class Rectangle&#123; constructor(length, width)&#123; this.length = length; this.width = width; &#125; getArea()&#123; return this.length * this.width; &#125; static create(length, width)&#123; return new Rectangle(length, width); &#125;&#125;// 1. extend 继承class Square extends Rectangle &#123; constructor(length)&#123; // 等价于 Rectangle.call(this, length, length) super(length, length); &#125; getArea()&#123; // 通过 super 调用父类方法 return super.getArea(); &#125;&#125;// 如果基类有静态成员，那么这些静态成员在派生类中也可用var rect = Square.create(3, 4);console.log(rect isinstanceof Rectangle); // trueconsole.log(rect isinstanceof Square); // false 注意: 如果在派生类中指定了构造函数则必须要调用super()，如果不这样做程序就会报错 如果选择不使用构造函数，则当创建新的类实例时会自动调用super()并传入所有参数 在构造函数中访问this之前一定要调用super()，它负责初始化this，如果在调用super()之前尝试访问this会导致程序出错 如果不想调用super()，则唯一的方法是让类的构造函数返回一个对象 如果基类有静态成员，那么这些静态成员在派生类中也可用 3.1 派生子表达式类ES6 扩展了从表达式导出类的功能，只要表达式可以被解析为一个函数并且具有[[Construct]]属性和原型，那么就可以用extends进行继承。因为extend 可以继承自任意类型的表达式，所以我们可以动态地确定类的继承目标。 1234567891011121314151617181920212223242526272829303132function Person(name)&#123; this.name = name;&#125;;Person.prototype.sayName = function()&#123; console.log(this.name);&#125;function getBase()&#123; return Person&#125;// 1. 动态确定继承目标class China extends getBase()&#123;&#125;// mixin()函数会用所有mixin对象的自有属性动态填充新函数的原型function mixin(...mixins)&#123; var base = function()&#123;&#125;; object.assign(base.prototype, ...mixins); return base;&#125;class ShowMixin&#123;&#125;// 2. 混入类class Anhui extends mixin(Person, ShowMixin)&#123;&#125; 在上面的示例中: Person 是一个ECMAScript 5风格的构造函数，China 是一个类，由于 Person 具有[[Construct]]属性和原型，因此 China 类可以直接继承它 China 的父类可以通过函数动态确定 因为继承目标可以动态确定，我们可以通过 mixin 函数实现多类混入 在extends后可以使用任意表达式，但不是所有表达式最终都能生成合法的类。如果使用null或生成器函数会导致错误发生，类在这些情况下没有[[Consturct]]属性，尝试为其创建新的实例会导致程序无法调用[[Construct]]而报错。 3.2 内建对象的继承ES5 中想通过继承的方式创建属于自己的特殊数组几乎是不可能的，例如: 123456789101112131415161718function MyArray()&#123; Array.apply(this, arguments);&#125;MyArray.prototype = Object.create(Array.prototype,&#123; constructor:&#123; value: MyArray, writable: true, configurable: true, enumerable: true &#125;&#125;)var colors = new MyArray()colors[0] = "red";console.log(colors.length); // 应该为 1colors.length = 0; console.log(colors[0]); // 元素应该被删除 MyArray实例的length和数值型属性的行为与内建数组中的不一致，这是因为通过传统JavaScript继承形式实现的数组继承没有从Array.apply()或原型赋值中继承相关功能。ECMAScript 6类语法的一个目标是支持内建对象继承，因而ES6中的类继承模型与ECMAScript 5及早期版本中的稍有不同： 在ECMAScript 5的传统继承方式中，先由派生类型（例如，MyArray）创建this的值，然后调用基类型的构造函数（例如Array.apply()方法）。这也意味着，this的值开始指向的是MyArray的实例，但是随后会被来自Array的其他属性所修饰。 ECMAScript 6中的类继承则与之相反，先由基类（Array）创建this的值，然后派生类的构造函数（MyArray）再修改这个值。所以一开始可以通过this访问基类的所有内建功能，然后再正确地接收所有与之相关的功能。这也是在构造函数必须先调用 super() 才能使用 this 的原因。 1234567891011121314class MyArray extends Array&#123;&#125;var colors = new MyArray()colors[0] = "red";console.log(colors.length); // 1colors.length = 0; console.log(colors[0]); // undefinedlet items = new MyArray(1,2,3,4),subitems = items.slice(1, 3);console.log(items instanceof MyArray); // trueconsole.log(subitems instanceof MyArray); // true 3.3 Symbol.species属性在上面的示例中，我们自定义了一个继承自Array的派生类MyArray，正常情况下，继承自Array的slice()方法应该返回Array的实例，但是在这段代码中，slice()方法返回的是MyArray的实例。在浏览器引擎背后是通过Symbol.species属性实现这一行为。 Symbol.species 被用于定义返回函数的静态访问器属性。被返回的函数是一个构造函数，每当要在实例的方法中（不是在构造函数中）创建类的实例时必须使用这个构造函数。。以下这些内建类型均已定义Symbol.species属性：Array，ArrayBuffer，Map，Promise，RegExp，Set，Typed arrays。 前面列示的每个类型都有一个默认的Symbol.species属性，该属性的返回值为this，这也意味着该属性总会返回构造函数。如果在自定义的类中实现这个功能，则代码看起来可能是这样的： 123456789101112131415class MyClass &#123; // Symbol.species被用来给MyClass赋值静态访问器属性 static get [Symbol.species]()&#123; return this; &#125; constructor(value)&#123; this.value &#125; clone()&#123; // this.constructor 返回实例对应的类对象 return new this.constructor[Symbol.species](this.value); &#125;&#125; 在这个示例中，Symbol.species被用来给MyClass赋值静态访问器属性，请注意，这里只有一个getter方法却没有setter方法，这是因为在这里不可以改变类的种类。调用this.constructor[Symbol.species]会返回MyClass，clone()方法通过这个定义可以返回新的实例，从而允许派生类覆盖这个值。 12345678910111213141516171819class M1 extends MyClass&#123;&#125;class M2 extends MyClass&#123; static get [Symbol.species]()&#123; return MyClass; &#125;&#125;let m1 = new M1("foo"),clone1 = m1.clone(),m2 = new M2("bar"),clone2 = m2.clone();console.log(clone1 instanceof MyClass); // trueconsole.log(clone1 instanceof M1); // trueconsole.log(clone2 instanceof MyClass); // trueconsole.log(clone2 instanceof M2); // false 上面的示例中: MyDerivedClass1继承MyClass时未改变Symbol.species属性，由于this.constructor[Symbol.species]的返回值是MyDerivedClass1，因此调用clone()返回的是MyDerivedClass1的实例。 MyDerivedClass2继承MyClass时重写了Symbol.species让其返回MyClass，调用MyDerivedClass2实例的clone()方法时，返回值是一个MyClass的实例 通过Symbol.species可以定义当派生类的方法返回实例时，应该返回的值的类型。 4. 定义抽象基类前面我们介绍了如何通过 new.target 的判断函数被调用的方式，在类的构造函数中也可以通过new.target来确定类是如何被调用的。因为类构造函数必须通过new关键字调用，所以 new.target 不会为 undefined，但是其值可能因为谁调用而不同。当子类通过 super() 调用父类的构造函数时，父类内的 new.target 将等于子类的构函数，因此我们可以用new.target创建一个抽象基类。 12345678910111213141516class Shape&#123; constructor() &#123; if (new.target === Shape)&#123; throw new Error("不能直接实例化") &#125; &#125;&#125;class Rectangle extends Shape &#123; constructor(length, width)&#123; // super()调用执行了Shape的构造函数，new.target与Rectangle等价 super(); this.legth = length; this.width = width; &#125;&#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 代理和反射]]></title>
    <url>%2F2020%2F08%2F26%2Fweb%2FES6%2Fes6_11%2F</url>
    <content type="text"><![CDATA[JavaScript 提供的内置方法重载 1. 代理与反射概述ECMAScript 6添加了一些内建对象，赋予开发者更多访问JavaScript引擎的能力。代理（Proxy）是一种可以拦截并改变底层JavaScript引擎操作的包装器，其实就是一种重载 JavaScript 内置方法的工具。反射就是调用 JavaScript 引擎内置方法的 API。这里面有个逻辑问题，比如我想重载 Object.get 方法，如果我又想在重载的方法中获取对象属性，此时我就不能使用 Object.get ，否则就会死循环。所以需要提供另一套与重载方法相对应的 api 去获取对象属性。所以每个重载的方法都有一个与之对应的反射API: 注: 代理陷阱指的就是重载的方法 默认特性就是与之相关的反射 API 2. 代理使用 new Proxy(target, handler)可创建代替其他目标（target）对象的代理，其接受两个参数： target: 要代理的目标 handler：处理程序，定义一个或多个要重载方法的对象 2.1 代理与反射使用示例我们以重载 set 方法为例，来看看如何使用代理和反射。需求是，创建一个属性值只能是数字的对象。 123456789101112131415161718192021222324252627let target = &#123; name: "target"&#125;// 1. 创建代理对象let proxy = new Proxy(target, &#123; // 2. set 陷阱 set(trapTarget, key, value, receiver)&#123; if (!trapTarget.hasOwnProperty(key))&#123; if (isNaN(value))&#123; throw new TypeError("属性必须是数值") &#125; &#125; // 3. 与 set 陷阱对应的反射 API return Reflect.set(trapTarget, key, value, receiver); &#125;， // 4. get 陷阱 get(trapTarget, key, receiver)&#123; // in操作符检查receiver而不检查trapTarget，是为了防止receiver代理含有has陷阱 if (!key in receiver)&#123; throw new TypeError("属性不存在"); &#125; return Reflect.get(trapTarget, key, receiver); &#125;&#125;)proxy.count = 1proxy.name = "name" 在处理程序中，重载 set 方法的函数我们成为 set 陷阱，每一个”陷阱”都有一个与之对应的，接受相同参数的反射 API，与 set陷阱对应的就是 Reflect.set。set 陷阱接受如下参数: set(trapTarget, key, value, receiver): trapTarget: 用于接收属性（代理的目标）的对象 key: 要写入的属性键（字符串或Symbol类型） value: 被写入属性的值 receiver: 操作发生的对象（通常是代理） 在代理中，除了专门为操作定义的陷阱外，其余操作均使用默认特性，不使用任何陷阱的处理程序等价于简单的转发代理。 接下来我不想把所有的方法重载都讲一遍，挑一些我觉得对有助于加深对 JavaScript 的理解的介绍一下，包括: ownKeys 函数的 apply 和 constructor 可撤销代理 2.2 ownKeysownKeys 代理陷阱可以拦截内部方法[[OwnPropertyKeys]]，[[OwnPropertyKeys]] 返回一个数组，这个数组被用于如下四个方法: Object.keys()、Object.getOwnPropertyNames(): 返回的结果将Symbol类型的属性名排除在外 Object.getOwnPropertySymbols(): 将字符串类型的属性名排除在外 Object.assign(): 用数组来确定需要复制的属性 与 ownKeys 相对应的反射APi是 Reflect.ownKeys() 返回的数组中包含所有自有属性的键名，字符串类型和Symbol类型的都包含在内。ownKeys 使用方式如下: ownKeys(trapTarget): 作用: 过滤不想使用的属性键 返回值: 必须是一个数组或类数组对象，否则就抛出错误 参数: trapTarget: 操作的目标 注: ownKeys代理陷阱，不影响更常用的操作,例如for-of循环和Object.keys()方法，这些不能使用代理来更改 ownKeys 陷阱会影响for-in循环，当确定循环内部使用的键时会调用陷阱 123456// 过滤任何以下划线开头的属性let proxy = new Proxy(&#123;&#125;, &#123; ownKeys(trapTarget)&#123; return Reflect.ownKeys(trapTarget).filter(key =&gt; typeof key !=== "string" || key[0] !=== "_"); &#125;&#125;) 2.3 函数的 apply 和 constructor所有代理陷阱中，只有apply和construct的代理目标是一个函数。函数有两个内部方法: [[Construct]]: 若使用new操作符调用函数，则执行[[Construct]]方法，此时执行 construct 陷阱 [[Call]]: 若不用 new，则执行[[Call]]方法，此时会执行apply陷阱 apply(trapTarget, thisArg, argumentsList): 作用: 重载函数的普通调用 参数: trapTarget: 被执行的函数（代理的目标） thisArg: 函数被调用时内部this的值 argumentsList: 传递给函数的参数数组 construct(trapTarget, argumentsList, newTarget): 作用: 重载构造函数调用 参数: trapTarget: 被执行的函数（代理的目标） argumentsList: 传递给函数的参数数组 newTarget: 可选，用于指定函数内部new.target的值 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 验证函数参数function sum(...values)&#123; return values.reduce((previous, current) =&gt; previous + current, 0);&#125;let sumProxy = new Proxy(sum, &#123; // 箭头函数没有 this 指向，这里必须是 function 声明的函数？ apply: function(trapTarget, thisArg, argumentsList)&#123; argumentsList.forEach(arg =&gt; &#123; if (typeof arg !== "number")&#123; throw new TypeErro("所有参数必须是数值"); &#125; &#125;); return Reflect.apply(trapTarget, thisArg, argumentsList); &#125;, construct: function(trapTarget, argumentsList)&#123; // 当然，也可以不借助代理而用new.target来完成相同的事情 throw new TypeError("改函数不可通过 new 调用"); &#125;&#125;);// 不用new调用构造函数// 可调用的类构造函数function Number(...values)&#123; if (typeof new.target === "undefiend")&#123; throw new TypeError("改函数必须通过 new 调用"); &#125; this.values = values;&#125;let NumberProxy = new Proxy(Number, &#123; apply: function(trapTarget, thisArg, argumentsList)&#123; // apply陷阱用传入的参数调用Reflect.construct()，就可以让 // NumbersProxy()函数无须使用new就能实现用new调用Numbers()的行为 // Numbers()内部的new.target等于Numbers()，所以不会有错误抛出。 return Reflect.construct(trapTarget, argumentsLists); &#125;, // 或者 apply: function(trapTarget, thisArg, argumentsList)&#123; return new Number(...argumentsList); &#125;&#125;) 注意: 用new调用时创建一个instance对象，它同时是代理和目标的实例，因为instanceof通过原型链来确定此信息，而原型链查找不受代理影响 因为类构造函数的内部方法[[Call]]被指定来抛出一个错误，要想创建可调用类构造函数只能通过代理来进行 2.4 可撤销代理通常，在创建代理后，代理不能脱离其目标，可以使用Proxy.revocable()方法创建可撤销的代理，该方法采用与Proxy构造函数相同的参数：目标对象和代理处理程序。返回值是具有以下属性的对象： proxy: 可被撤销的代理对象 revoke: 撤销代理要调用的函数，当调用revoke()函数时，不能通过proxy执行进一步的操作，任何与代理对象交互的尝试都会触发代理陷阱抛出错误 1234567let target = &#123;"name": "target"&#125;;let &#123;proxy, revoke&#125; = Proxy.revocable(target, &#123;&#125;);console.log(proxy.name);revoke();console.log(proxy.name); // 报错]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 异步编程]]></title>
    <url>%2F2020%2F08%2F25%2Fweb%2FES6%2Fes6_10%2F</url>
    <content type="text"><![CDATA[async 与 await 1. ES6 异步编程概述JavaScript引擎是基于单线程（Single-threaded）事件循环的概念构建的，同一时刻只允许一个代码块在执行。JavaScript引擎同一时刻只能执行一个代码块，所以需要跟踪即将运行的代码，那些代码被放在一个任务队列（job queue）中，每当一段代码准备执行时，都会被添加到任务队列。每当JavaScript引擎中的一段代码结束执行，事件循环（eventloop）会执行队列中的下一个任务，它是JavaScript引擎中的一段程序，负责监控代码执行并管理任务队列。请记住，队列中的任务会从第一个一直执行到最后一个。为了在实现循环中实现异步编程，JavaScript 提供了如下异步编程模型: 响应用户操作的时间 回调函数 Promise async/awit 定义的协程 1.1 事件用户点击按钮或按下键盘上的按键会触发类似onclick这样的事件，它会向任务队列添加一个新任务来响应用户的操作。直到事件触发时才执行事件处理程序。 事件模型适用于处理简单的交互，但不适合组合复杂的异步逻辑。 1.2 回调函数回调模式与事件模型类似，异步代码都会在未来的某个时间点执行，二者的区别是回调模式中被调用的函数是作为参数传入的。与事件相比回调模式比事件模型更灵活，通过回调模式链接多个调用更容易，但是很容易就陷入所谓的”回调地狱”中。 同事件一样，回调函数无法组合复杂的组合逻辑，例如，并行执行两个异步操作，当两个操作都结束时通知你；或者同时进行两个异步操作，只取优先完成的操作结果。 1.3 PromisePromise相当于异步操作结果的占位符，类似于其他语言中类似Future和Deferred，用于表示操作的未来结果。Promise 具有生命周期: 先是处于进行中（pending）的状态，此时操作尚未完成 操作结束后，Promise可能会进入到以下两个状态中的其中一个： Fulfilled Promise异步操作成功完成 Rejected 由于程序错误或一些其他原因，Promise异步操作未能成功完成 内部属性 [[PromiseState]] 被用来表示Promise的3种状态：”pending”、”fulfilled”及”rejected。基于成功或失败的状态，Promise 可以像事件和回调函数一样指定稍后执行的代码，可以链式地编写 Promise。接下来我们会详细介绍 Promise 提供的异步编程接口。需要说明的是 Promise 不暴露 [[PromiseState]] 属性，我们无法获取此属性值，但是 JavaScript 提供了其他方法让我们捕获 Promise 状态的变化，接下来我们会详细介绍。 1.4 协程async/awit 定义的协程组合了生成器和 Promise，实现了以同步方式编写异步代码，要想明白其实现机制，我们需要按次序理解一下问题: 如何使用生成器实现一个异步任务执行器 如何让异步任务函数返回一个 Promise(表示未来操作的结果) 如何让 Promise 与第一步定义的异步任务执行器结合，更好的将异步代码同步化。 在同步代码中，代码按照执行次序一行行执行，因为是同步，我们总是可以得到上一步执行的结果。在协程中，我们通过一个表示未来操作执行结果的 Promise 对象来得到上一行代码的执行结果(假设是异步操作)，让异步代码同步化。 2. Promise前面我们已经说过了，Promise 表示一个异步操作的结果，通过捕获 Promise 状态的变化我们可以获取异步操作的结果，基于结果我们可以定义接下来的操作。为此 Promise 提供了如下方法: then() catch() 2.1 Promise 定义的方法promise.then(fulfilled_function, reject_function): 作用: 定义 Promise 状态改变时(异步操作完成后)，执行的操作 参数: 两个参数都是可选的 fulfilled_function: 当Promise的状态变为fulfilled时要调用的函数 异步操作的返回值会传递给此函数 reject_function: Promise的状态变为rejected时要调用的函数 所有与失败状态相关的附加数据都会传递给这个拒绝函数 说明: 如果一个对象实现了上述的then()方法，那这个对象我们称之为thenable对象 分离的 fulfilled_function，reject_function 可以确切提供异步操作成功还是失败的处理语义，如果使用事件，在遇到错误时不会主动触发；如果使用回调函数，则必须要记得每次都检查错误参数 如果不给Promise添加拒绝处理程序，那所有失败就自动被忽略了，所以一定要添加拒绝处理程序 每次调用then()方法或catch()方法都会创建一个新任务，当Promise 表示的异步任务执行完成时。这些任务最终都会被加入到一个为Promise量身定制的独立队列中，即便一个Promise处于已处理状态，在这之后添加到任务队列中的处理程序仍将执行 如果执行器内部抛出一个错误，则Promise的拒绝处理程序就会被调用，每个执行器中都隐含一个try-catch块，所以错误会被捕获并传入拒绝处理程序 promise.catch(reject_function): 作用: 相当于只传入拒绝处理程序的then()方法 说明: catch 提供了用于捕获异步操作错误的确切语义 123456789101112// readFile 的实现参见 创建未完成的Promise 中示例let promise = readFile("test.txt");promise.then(function(contents)&#123; console.log(contents);&#125;, function(err)&#123; onsole.log(err.message);&#125;)promise.catch(function(err)&#123; onsole.log(err.message);&#125;) 2.2 捕获已拒绝 Promise 的钩子关Promise的其中一个最具争议的问题是，如果在没有拒绝处理程序的情况下拒绝一个Promise，那么不会提示失败信息，这是JavaScript语言中唯一一处没有强制报错的地方。Promise的特性决定了很难检测一个Promise是否被处理过，为此 Node.js 和 浏览器提供了捕获已拒绝 Promise 的钩子，虽然它们还不是 ES6 的标准。 当Promise 被拒绝时，浏览器会在 window 对象上触发两个事件: unhandledrejection 在一个事件循环中，当Promise被拒绝，并且没有提供拒绝处理程序时被调用 rejectionhandled 在一个事件循环后，当Promise被拒绝，并且没有提供拒绝处理程序时被调用 这两个事件的事件处理程序会接受一个有以下属性的事件对象作为参数: type: 事件名称（”unhandledrejection”或”rejectionhandled”） promise: 被拒绝的Promise对象 reason: 来自Promise的拒绝值 2.3 创建未完成的Promise所谓创建未完成的Promise，就是如何用 Promise 包装一个异步任务。这里的等价含义是如何将回调函数转换为Promise。 用Promise构造函数可以创建新的 Promise，其只接受一个参数：包含初始化Promise代码的执行器（executor）函数。执行器接受两个参数，分别是 resolve()函数，执行器成功完成时调用resolve()函数，resolve 函数接收的参数将被 Promise 传递给 fulfilled_function reject()函数，执行器失败时则调用reject()函数，reject 函数接收的参数将被 Promise 传递给 reject_function 下面这个示例是在 Node.js 中用 Promise 实现的Promise 版 readFile()函数： 12345678910111213141516171819202122232425// NodeJs 示例let fs = require("fs");function readFile(filename)&#123; return new Promise(function(resolve, reject)&#123; fs.readFile(filename, &#123;"encoding": "utf8"&#125;, function(err, contents)&#123; // 检查错误 if (err)&#123; reject(err); return; &#125; // 执行成功 resolve(contents); &#125;); &#125;)&#125;let promise = readFile("test.txt");promise.then(function(contents)&#123; console.log(contents);&#125;, function(err)&#123; onsole.log(err.message);&#125;) 当上面的 readFile()方法被调用时: 执行器会立刻执行，fs.readFile 异步读取文件的函数会立即执行 然后执行后续的 promise.then 在执行器中，无论是调用resolve()还是reject()，都会向任务队列中添加一个任务来解决这个Promise(更新 Promise 状态)。类似于 setTimeout()或setInterval()函数向任务队列中添加一个新任务，并明确指定将任务延后执行 当异步文件读取完成时，会调用resolve()/reject()触发一个异步操作，传入then()和catch()方法的函数会被添加到任务队列中并异步执行 因此整个代码的执行过程为 当前事件循环: 执行执行器 执行promise.then 读文件完成所在的事件循环: 调用 resolve()，想任务队列添加解决 Promise 的任务 下一个事件循环: 执行解决 Promise 的任务，真正调用 resolve() 将定义在 then()方法中的函数到任务队列 下一事件循环: 执行then()方法的函数 之所以调用resolve()还是reject()，都会向任务队列中添加一个任务来解决这个Promise，是为了保证 resolve()/reject() 的执行总是在 promise.then 方法之后执行，即使执行器执行的不是异步代码也是如此。这样才能保证完成处理程序和拒绝处理程序总是在执行器完成后被添加到任务队列的末尾。 2.4 创建已完成的 Promise创建已处理的Promise表示你想用Promise来表示一个已知值，相对于编排一个只是简单地给resolve()函数传值的任务，更好的办法是使用如下方法: Promise.resolve Promise.reject Promise.resolve(value) 作用: 接受一个参数并返回一个完成态的Promise 说明: 不会有任务编排的过程，而且需要向Promise添加一至多个完成处理程序来获取值 Promise.reject() 作用: 创建已拒绝的 Promise Promise.resolve()和Promise.reject()都有如下特点: 传入一个Promise，那么这个Promise会被直接返回 都可以接受非Promise的Thenable对象作为参数，此时这些方法会创建一个新的Promise，并在then()函数中被调用 在下面这个示例中: Promise.resolve()调用的是thenable.then() 由于 then()方法内部调用了resolve(42)，因此thenable 被转换为一个已完成的 Promise p1，如果调用 reject(43) 则返回一个已拒绝的 Promise，当然也可以执行异步函数，根据异步函数结果调用 resolve 或者 reject p1从Thenable对象接受传入的值（也就是42），p1的完成处理程序的形参value将被赋值 42 12345678910let thenable = &#123; then: function(resolve, reject) &#123; resolve(42); &#125;&#125;let p1 = Promise.resolve(thenable);p1.then(function(value) &#123; console.log(value);&#125;) 有了Promise.resolve()方法和Promise.reject()方法，我们可以更轻松地处理非Promise的Thenable对象。 至此，看起来好像Promise只是将回调函数和setTimeout()函数结合起来，并在此基础上做了一些改进。但 Promise 实现的功能不仅如此。 2.5 Promise 提供的链式调用每次调用 then() 或 catch() 方法时实际上创建并返回了另一个Promise，这样我们可以以链式调用的方式，串联起一连串异步操作，在这个链式调用中: 只有前一个 Promise 完成或者失败后，才会触发下一个 Promise 处于链式调用后端的拒绝处理程序，可以处理它前面所有 Promise 发生的异常，包括完成处理程序和拒绝处理程序。所以务必在Promise链的末尾留有一个拒绝处理程序以确保能够正确处理所有可能发生的错误 如果在完成处理程序和拒绝处理程序中的返回值，可以沿着链式调用链继续传递 完成和拒绝处理程序中返回了一个新的 Promise，相当于在调用链中插入了一个新的 Promise，这个新的 Promise 的完成状态决定了后面调用链的执行 1234567891011121314151617181920212223242526272829303132let p1 = new Promise(function(resole, reject) &#123; throw new Error("Expose P1");&#125;)p1.catch(function(err) &#123; console.log(err.message); throw new Error("Boom");// 1. Promise 的链式调用// 2. 链式 Promise 后面的调用可以感知到链中其他Promise的错误。&#125;).catch(function(err) &#123; console.log(err.message);&#125;)let p2 = Promise.resolve(42);p2.then(function(value) &#123; // 3.完成处理程序的返回值可以在调用链上传递 return value + 1;&#125;).then(function(value) &#123; console.log(value); // 43&#125;)let pp1 = Promise.resolve(42);let pp2 = Promise.resolve(43);let pp3 = pp1.then(function(value) &#123; console.log(value); // 4. 完成程序中返回的 Promise 相当于在调用链中插入这个 Promise // 5. pp1 then 返回的 pp3 是一个新的 Promise return pp2&#125;);console.log(pp3 === pp2); 2.6 Promise 提供的任务组合前面我们看到的都是单个Promise响应，而如果想通过监听多个Promise来决定下一步的操作，则可以使用 ES6 提供的Promise.all() 和 Promise.race()两个方法 Promise.all(promise_iter): 参数: 含有多个受监视Promise的可迭代对象 作用: 返回一个 promise 只有 promise_iter 中所有 Promise都被完成后返回的Promise才会被完成 promise_iter 中只要有一个 Promise 被拒绝，那么返回的Promise不会等所有Promise完成而立即被拒绝 123456789101112131415161718let p1 = new Promise(function(resole, reject) &#123; setTimeout(function() &#123; console.log("p1"); resole(41); &#125;, 200) // return resole(41);&#125;)console.log("p2")let p2 = Promise.resolve(42);let p3 = Promise.resolve(43);let p4 = Promise.all([p1, p2, p3])p4.then(function(value) &#123; console.log(value); // [41, 42, 43]&#125;).catch(function(value)&#123; // 拒绝处理程序只接受一个值 console.log(Array.isArray(value)); // false&#125;) 在上面的示例中: Promise.all()方法创建Promise p4 传入p4完成处理程序的结果是一个包含每个Promise 完成处理程序返回值的（42、43和44）的数组，这些值与它们在 all 中传入的顺序一致 如果 p1,p2,p3 任何一个失败，比如 p2 失败，p4 会立即失败，不会等 p1,p3 执行完成。p4 的拒绝处理程序总是接收一个值，来自被拒绝的 Promise Promise.race(promise_iter): 参数: 含有多个受监视Promise的可迭代对象 作用: 返回一个 promise，传给Promise.race()方法的Promise会进行竞选，以决出哪一个先被解决， 如果先解决的是已完成Promise，则返回已完成Promise 如果先解决的是已拒绝Promise，则返回已拒绝Promise 应用: 给某个异步请求设置超时时间 12345678910111213141516let p1 = new Promise(function(resole, reject) &#123; setTimeout(function() &#123; console.log("p1输出"); resole(41); &#125;, 200) // return resole(41); &#125;)let p2 = Promise.reject(42);let p3 = Promise.resolve(43);let p4 = Promise.race([p1, p2, p3])p4.then(function(value) &#123; console.log(value);&#125;).catch(function(value) &#123; console.log("失败: $&#123;value&#125;")&#125;) 在上面这段程序中: 由于p2已处于被拒绝状态，因而当Promise.race()方法被调用时p4也被拒绝了 p4 不会等待 p1,p3 完成，所以打印的顺序是”失败:43 =&gt; p1 输出” 3. JavaScript 异步编程前面我们说了，要搞清楚 awit/async 提供的异步编程机制，需要明白以下三个问题: 如何使用生成器实现一个异步任务执行器 如何让异步任务函数返回一个 Promise(表示未来操作的结果) 如何让 Promise 与第一步定义的异步任务执行器结合，更好的将异步代码同步化 接下来我们就来一一解决这三个问题。 3.1 异步任务执行器首先，生成器可以返回值也可以接收值，这就是在用户程序可独立调度的执行单元，又被称为”协程”，我们可以自己编写一个调度器来调度生成器的执行，示例代码像下面这样: 123456789101112131415161718192021222324252627282930313233343536373839404142// 异步任务执行器function run(taskDef) &#123; // 1. 调用生成器函数返回一个迭代器，并初始化 let task = taskDef(); let result = task.next(); // 2. 不断迭代迭代器的调度程序 function step() &#123; if (!result.done) &#123; value = result.value; // 3. 如果迭代返回的是一个函数，表示是一个异步任务 if (typeof value === "function") &#123; value(function(content, err) &#123; if (err) &#123; result = task.throw(err); step(); &#125; else &#123; result = task.next(content); step(); &#125; &#125;) &#125; result = task.next(value); step(); &#125; &#125; step();&#125;let fs = require("fs");// 定义一个可用于任务执行的函数function reedFile(filename) &#123; return function(callback) &#123; fs.readFile(filename, callback); &#125;&#125;// 执行一个任务run(function*() &#123; let contents = yield readFile("example.txt"); console.log(contentss)&#125;) 在上面这个异步任务调度器中: 原本以回调函数执行的异步任务，被包装成了一个接受参数和回调函数的嵌套函数 异步任务的回调函数，被调度器设置成，根据异步任务结果，驱动调度器执行的函数 但是这个实现有一些明显的问题: 首先，定义用于执行的函数，其返回值是一个接受回调函数的函数，很难理解，这句话本身也是如此 无法区分用作任务执行器回调函数的返回值和一个不是回调函数的返回值 但是如果用 Promise 来表示每个异步操作的返回值，我们就可以大大简化调度器。这就引出来我们第二个问题，如何让异步任务函数返回一个 Promise。 3.2 让异步任务返回 Promise这个问题的解决方案我们在讲解创建未完成的 Promise 就解决了:12345678910111213141516let fs = require("fs");function readFile(filename)&#123; return new Promise(resolve, reject)&#123; fs.readFile(filename, &#123;"encoding": "utf8"&#125;, function(err, contents)&#123; // 检查错误 if (err)&#123; reject(err); return; &#125; // 执行成功 resolve(contents); &#125;); &#125;&#125; 最后我们来看如何把 Promise 和异步调度器结合起来。 3.3 结合 Promise 和异步调度器1234567891011121314151617181920212223function run(taskDef) &#123; // 1. 调用生成器函数返回一个迭代器，并初始化 let task = taskDef(); let result = task.next(); // 2. 不断迭代迭代器的调度程序 function step() &#123; if (!result.done) &#123; // 3. 总是将迭代器的返回值包装成一个 Promise 对象 promise = Promise.resolve(result.value); // 4. 添加处理程序，提取Promise的值并将其传回迭代器 promise.then(function(content)&#123; result = task.next(content); step(); &#125;).catch(function(err)&#123; result = task.throw(err); step(); &#125;) &#125; &#125; step();&#125; 在这个版本的代码中: Promise 完全表示出了它的语义，一个异步操作的未来的结果，代码非常清晰 调用Promise.resolve()是为了防止函数不返回Promise，也就是说，用yield调用同步或异步方法都可以正常运行，永远不需要检查返回值是否为Promise。 添加完成处理程序提取Promise的值并将其传回迭代器 拒绝处理程序将所有拒绝结果存储到一个错误对象中，然后通过task.throw()方法将错误对象传回迭代器 唯一需要关注的是像readFile()这样的异步函数，需要被转换成一个返回 Promise 对象的函数 4. asyncES2017 引入了 async/await 关键字，其内部原理就是我们刚刚所说的 Promise + 生成器函数。awit/async 其基本思想是用async标记的函数代替生成器，用await代替yield来调用函数，就像这样:1234567891011// 1. async 修饰的函数总是返回一个 Promise 对象async function f()&#123;&#125;console.log(f()); // Promise// 2. 使用示例(async function() &#123; let contents = awit readFile("example.txt"); console.log(contentss)&#125;) 在上面的示例中: async表示该函数以异步模式运行，函数的返回值总是被包装成一个 Promise 对象 await关键字表示调用readFile(“config.json”)的函数应该返回一个 Promise 如果 await 后面不是一个 Promise 对象，JavaScript 会自动将其包装成一个 Promise 对象 类似 run 的异步任务调度器，由 JavaScript 引擎提供 如同 run 实现，如果Promise被拒绝则await应该抛出错误，否则通过Promise来返回值 最后的结果是，你可以按照同步方式编写异步代码。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 迭代器与生成器]]></title>
    <url>%2F2020%2F08%2F24%2Fweb%2FES6%2Fes6_9%2F</url>
    <content type="text"><![CDATA[迭代器和生成器 1. 迭代器和生成器在设计模式中迭代器代表一种有序遍历数据的方式，在编程语言的实现中，迭代器是一种特殊对象，其包含了遍历集合数据的协议(方法)。通过迭代器我们可以屏蔽不同数据集合之间的差异，统一遍历各种集合数据类型。而生成器是返回迭代器的函数。 2. 迭代器ES6 中迭代器是一种特殊对象: 都有一个next()方法，每次调用都返回一个结果对象 结果对象有两个属性： 一个是value，表示下一个将要返回的值 另一个是done，它是一个布尔类型的值，当没有更多可返回数据时返回true 迭代器会保存一个内部指针，用来指向当前集合中值的位置，以便实现有序遍历集合数据 迭代器结束标识是返回类似 {value: “return_value”, “done”: true} 的结果对象，return_value 是迭代器最终返回的值，但它不是数据集的一部分，它与函数的返回值类似，表示最后一次给调用者传递信息的方法，如果没有相关数据则返回undefined 下面是使用 ES5 实现的一个迭代器示例: 123456789101112131415161718function createIter(items)&#123; var i = 0; // 内部指针 return &#123; // next 方法，每次调用返回一个结果对象 next: function()&#123; // 在迭代结束时 done 为 true var done = (i &gt;= items.length); var value = !done ? items[i++] : undefined; return &#123; done: done, value: value &#125; &#125; &#125;&#125; 3. 生成器生成器是一种返回迭代器的函数: 通过function关键字后的星号（*）来表示，星号可以紧挨着function关键字，也可以在中间添加一个空格 函数中使用新的关键字 yield，通过 yield 指定调用迭代器的next()方法时的返回值及返回顺序 生成器有如下使用限制: yield关键字只可在生成器内部使用，在其他地方使用会导致程序抛出语法错误 不能用箭头函数来创建生成器 1234567891011121314151617// 1. 生成器函数function *createIter()&#123; yield 1; yield 2;&#125;// 2. 生成器表达式let createIter = function *(items)&#123;&#125;// 3. 生成器对象方法let o = &#123; *createIter(items)&#123; &#125;&#125; 3. 可迭代对象可迭代对象是指具有 Symbol.iterator 属性的对象，Symbol.iterator 通过指定的函数可以返回一个作用于附属对象的迭代器 ES6 使用新加入的 for-of 循环来遍历可迭代对象，在下面的示例中 for-of循环的代码通过调用values数组的Symbol.iterator方法来获取迭代器 然后在每次循环中调用一次迭代器的 next()，并将返回对象的 value 属性保存在变量 num 中 循环调用直至结果对象的done属性值为true时 12345678910111213141516171819202122// 1. for-of 循环let arr = [1, 3, 10]for (let num of arr)&#123; console.log(num);&#125;// 2. 访问数组默认迭代器let arrIter = arr[Symbol.iterator]()// 3. 检查对象是否是可迭代对象function isIterator(obj)&#123; return typeof obj[Symbol.iterator] === "function";&#125;// 4. 创建可迭代对象let collection = &#123; items: [] *[Symbol.iterator]()&#123; return items[Symbol.iterator](); &#125;&#125; 如果将for-of语句用于不可迭代对象、null或undefined将会导致程序抛出错误。前面我们所说的展开运算符可以作用于所有可迭代对象。 3.1 集合数据迭代器ES6 为三种集合类型:数组、Map集合与Set集合内建了以下三种迭代器： entries(): 返回一个迭代器，其值为多个键值对 values(): 返回一个迭代器，其值为集合的值 keys(): 返回一个迭代器，其值为集合中的所有键名 注意: 对于数组对象来说，无论是否为数组添加命名属性，打印出来的都是数字类型的索引；而for-in循环迭代的是数组属性(字符串)而不是数字类型的索引。 每个集合类型都有一个默认的迭代器，在for-of循环中，如果没有显式指定则使用默认的迭代器。数组和Set集合的默认迭代器是values()方法，Map集合的默认迭代器是entries()方法 WeakSet集合与WeakMap集合就没有内建的迭代器，由于要管理弱引用，因而无法确切地知道集合中存在的值，也就无法迭代这些集合了 3.2 字符串迭代器字符串通过方括号语法可以访问字符串中的字符，但方括号操作的是编码单元而非字符，因此无法正确访问双字节字符。ES6 改变了字符串的默认迭代器，使其操作字符而不是编码单元，因此可以正确处理双字节字符。 1234var message = "A 𠮷 B"for (let c of message)&#123; console.log(c);&#125; 3.3 NodeList迭代器ES6 为 DOM 中定义的 NodeList 类型添加了默认迭代器，以方便迭代其中的 DOM 元素，其行为与数组的默认迭代器完全一致。 12345var divs = document.getElementByTagName("div");for (let div of divs)&#123; console.log(div.id);&#125; 4. 生成器函数的执行流程4.1 正常执行流程了解生成器函数的执行流程，对我们后面学习 JavaScript 的异步编程至关重要。我们来看下面这个示例: 123456789101112function* createIterator() &#123; let first = yield 1; let second = yield first + 2; yield second + 3;&#125;let iterator = createIterator();// 第一次调用next()方法时无论传入什么参数都会被丢弃console.log(iterator.next()); // &#123;1, false&#125;console.log(iterator.next(4)); // &#123;6, false&#125;console.log(iterator.next(5)); // &#123;8, false&#125;console.log(iterator.next()); // &#123;true&#125; 上图详细描述了示例中生成器函数详细的执行过程。 4.2 向生成器抛出错误123456789101112function* createIterator() &#123; let first = yield 1; let second = yield first + 2; yield second + 3;&#125;let iterator = createIterator();console.log(iterator.next()); // &#123;1, false&#125;console.log(iterator.next(4)); // &#123;6, false&#125;// 通过 throw 方法可以向生成器函数抛出错误console.log(iterator.throw(new Error("Boom"))); 通过迭代器对象的 throw 方法，可以向生成器函数抛出异常，上面深灰色星星指明了调用 throw() 方法后生成器内部抛出错误的位置，此后的代码都中止执行。 我们可以在生成器函数捕获迭代器抛出的异常，像下面这样: 1234567891011121314151617function* createIterator() &#123; let first = yield 1; try&#123; let second = yield first + 2; &#125; catch (error)&#123; second = 6; &#125; yield second + 3;&#125;let iterator = createIterator();console.log(iterator.next()); // &#123;1, false&#125;console.log(iterator.next(4)); // &#123;6, false&#125;// 通过 throw 方法可以向生成器函数抛出错误console.log(iterator.throw(new Error("Boom"))); // &#123;9, false&#125;console.log(iterator.next()); // &#123;true&#125; 注意: ：调用throw()方法后也会像调用next()方法一样返回一个结果对象。 如上所述，next()和throw()就像是迭代器的两条指令，控制着生成器函数何时执行何时终止。让生成器变成了一个用户可以调度的”线程”即协程。 4.3 生成器的返回值而在生成器中，return表示所有操作已经完成，属性done被设置为true；属性value会被设置成return的返回值。生成器的返回值不是数据集的一部分，展开运算符与for-of循环语句会直接忽略通过return语句指定的任何返回值，只要done一变为true就立即停止读取其他的值。 4.4 委托生成器委托生成器可以将生成数据的过程委托给其他生成器，语法为 yield *Iterator: 12345678910111213141516171819202122function* a() &#123; yield 1; yield 2; return 3;&#125;function* b(count) &#123; for (let i = 0; i &lt; count; i++) &#123; yield i + count; &#125;&#125;function* c() &#123; // 1. yield* 将执行过程委托给另一个生成器 // 并用 count 接收了生成器函数的返回值 let count = yield* a(); yield* b(count);&#125;for (let n of c()) &#123; console.log(n);&#125; 5. 异步任务执行]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 新类型 Set 与 Map 与增强的数组]]></title>
    <url>%2F2020%2F08%2F23%2Fweb%2FES6%2Fes6_8%2F</url>
    <content type="text"><![CDATA[ES6 的新类型 1. 为什么需要新的 Set 和 Map在ECMAScript 5中，开发者们用对象属性来模拟这 Set 和 Map: 1234567891011// 1. 模拟 setvar set = Object.create(null);set.foo = true;if set.foo()&#123;&#125;// 2. 模拟 mapvar map = Object.create(null);map.foo = "bar" 变量set 和 map 是一个原型为null的对象，不继承任何属性。不过这种解决方案存在下面严重的问题: 因为对象属性只能是字符串，所以 map[&quot;5&quot;]和map[5]引用的其实是同一个属性，无法区分数字键和字符串的键 具有相同字符串表示的对象，用作键时也会导致冲突 对象支持 in 运算来判断属性是否存在，但是，in运算符也会检索对象的原型，只有当对象原型为null时使用这个方法才比较稳妥 基于这些 ES6 引入了 Set 和 Map。 2. SetSet类型是一种有序列表，其中含有一些相互独立的非重复值(引擎内部使用 Object.is() 方法检测两个值是否一致)，下面是其基本用法: 123456789101112131415161718// 1. 初始化let setFromArray = new Set([1, 2, 2]);let set = new Set();// 2. 添加删除元素set.add(5);set.add("5");set.delete("5");set.clear(); // 清空 set//3. 检查元素是否存在set.has(5);// 4. 获取 set 长度set.size;// 5. set 转数组array = [...setFromArray] Set构造函数可以接受所有可迭代对象作为参数，数组、Set集合、Map集合都是可迭代的 2.1 set.forEach 方法ES6 为集合添加了跟数组一样的 forEach 方法: set_obj.forEach(function(value, value, set_obj), scope_obj): 作用: 对 set 中每个元素调用 forEach 中的回调函数 参数: 接受一个函数和可选的作用域对象，作用域对象将绑定到回调函数中 回调函数: 接受三个参数，(元素值，元素值，被遍历的Set集合本身) 说明: Set集合中的每个元素也按照键名和值的形式储存，从而才能保证在所有 forEach() 方法的回调函数中前两个参数值具有相同含义 12345678910111213141516171819// 5. forEach let setFromArray = new Set([1, 2, 2]);let processor = &#123; output(value)&#123; console.log(value); &#125;, process(dataSet)&#123; // 1. 可以进行 this 绑定 dataSet.forEach(function(value)&#123; this.output(value) &#125;, this) // 2. 也可以使用箭头函数 dataSet.forEach(value =&gt; this.output(value)); &#125;&#125;processor.process(setFromArray) 3. Weak Set 集合Weak Set集合只存储对象的弱引用，并且不可以存储原始值；集合中的弱引用如果是对象唯一的引用，则会被回收并释放相应内存。其支持一下操作: 123456789101112let set = new WeakSet();let key = &#123;&#125;, k2 = &#123;&#125;;let set = new WeakSet([key, k2]);set.add(key);set.has(key);key = null;set.has(key);set.delete(k2); 与 Set 相比，WeakSet: WeakSet构造函数不接受任何原始值，向初始化、add()、has()和delete() 传入非对象参数都会导致程序报错 Weak Set集合不暴露任何迭代器（例如keys()和values()方法） Weak Set集合不支持forEach()方法。 Weak Set集合不支持size属性 4. MapES6 Map类型是一种储存着许多键值对的有序列表，其中的键名和对应的值支持所有的数据类型。键名的等价性判断通过调用Object.is()方法进行判断。下面是其基本用法: 12345678910111213141516// 1. 初始化let map = new Map();let key = &#123;&#125;;// 2. 添加删除元素map.set(5, "number5");map.get(5);map.set(key, "key");map.delete(key);map.clear(); // 清空 map//3. 检查元素是否存在map.has(5);// 4. 获取 map 长度set.size; 可以向Map构造函数传入[[key, value]...] 的数组来初始化一个Map集合。Map 同样支持 forEach() 方法 map_obj.forEach(function(value, key, map_obj), scope_obj),与 set 不同的是，其回调函数都接受3个参数：(值，值对应的键名，Map集合本身)。遍历过程中，会按照键值对插入Map集合的顺序将相应信息传入forEach()方法的回调函数。 5. Weak Map 集合ECMAScript 6中的Weak Map类型是一种存储着许多键值对的无序列表，列表的键名必须是非null类型的对象，键名对应的值则可以是任意类型，其键保存的对象的弱引用。Weak Map集合最大的用途是保存Web页面中的DOM元素。 12345678let map = new WeakMap();let key = &#123;&#125;, k2 = &#123;&#125;;let map = new WeakSet([[key, 1],[k2, 2]]);map.set(key, 10);map.has(key);map.get(key);map.delete(key); 5.1 Weak Map 的应用Weak Map 的另一个典型用途是构建对象的私有属性: 123456789101112let Person = (function()&#123; let pri = new WeakMap(); function Person(name)&#123; pri.set(this, &#123;"name": name&#125;) &#125; Person.prototype.getName = function()&#123; return pri.get(this).name; &#125; return Person;&#125;)(); 条目会被添加到Weak Map集合中，条目的键是this，值是对象包含的私有信息。当对象实例被销毁，相关信息也会被销毁，从而保证了信息的私有性。 5.2 WeakMap 与 Map 的区别相对Map集合而言，Weak Map集合 对用户的可见度更低 不支持通过forEach()方法、size属性及clear()方法来管理集合中的元素 如果你只想使用非对象作为键名，那么普通的Map集合是你唯一的选择。 6. Array 增强ES6 增强了数组了数组的功能，包括: 创建数组的两个方法: Array.of(), Array.from() 元素查找: array_obj.find(), array.findIndex(), array_obj.includes() 数组填充: array_obj.fill(), array.copyWith() 定型数组: 位操作的特定数组 6.1 数组创建Array.of在ECMAScript 6以前，创建数组的方式主要有两种，一种是调用Array构造函数，另一种是用数组字面量语法。但是 Array 构造函数有个一个怪异的行为: 如果传入一个数值型的值，那么数组的length属性会被设为该值(怪异行为) 如果传入多个值，此时无论这些值是不是数值型的，都会变为数组的元素。 Array.of()方法来解决这个怪异行为，无论有多少参数，无论参数是什么类型的，Array.of()方法总会创建一个包含所有参数的数组。 12345let a = Array(10);console.log(a.length); // 10let b = Array.of(10); console.log(b.length); // 1 Array.fromArray.from()方法可以接受可迭代对象或类数组对象作为第一个参数，最终返回一个数组。因此想要将 arguments 对象转换为数组有下面三种方法: 123Array.prototype.slice.call(arugments);[...arguments];Array.from(arguments); 因为 arguments 是可迭代对象，所以我们可以使用展开运算符，但是 Array.from()方法不仅适用于可迭代对象也适用于类数组对象。如果一个对象既是类数组又是可迭代的，那么Array.from()方法会优先使用迭代器。 Array.from(trans_obj, trans_function, scope_obj) 接收三个参数: trans_obj: 前面所说的待转换对象 trans_function: 一个映射函数，用来将类数组对象中的每一个值转换成其他形式，最后将这些结果储存在结果数组的相应索引中 scope_obj: 绑定到 trans_function this 的绑定对象 最后这两个方法都通过派生数组类继承，使用当前构造函数（也就是of()方法中的this值）来确定正确的返回数据的类型。 6.2 元素查找find()方法和findIndex()方法都接受两个参数： 一个是回调函数: 与数组的map()和forEach()方法的参数相同:(元素值，元素索引，数组本身) 回调函数返回 true 表示查找成功 查找成功，find()方法返回查找到的值，findIndex()方法返回查找到的值的索引 另一个是可选参数，用于指定回调函数中this的值 注意如果只想查找与某个值匹配的元素，则indexOf()方法和lastIndexOf()方法更好的选择。 1234let num = [25, 30, 35, 40];console.log(num.find(value=&gt; value &gt; 33)); // 35console.log(num.findIndex(value=&gt; value &gt; 35)); // 2 6.3 元素填充array_obj.fill(value, start_index, end_index): 作用: 指定的值填充一至多个数组元素 参数: value: 填充数组的值 start_index: 填充的开始索引 end_index: 填充的结束索引，不包含，默认等于 array_obj.length 注意: 如果开始索引或结束索引为负值，那么这些值会与数组的length属性相加来作为最终位置 array_obj.copyWith(copy_start, paste_end, copy_num) 作用: 从数组中复制元素的值，拷贝到指定位置 参数: copy_start: 开始填充值的索引位置 paste_end: 开始复制值的索引位置 copy_num: 限制被重写元素的数量 1234567891011// 复制数组前两个元素的值到后两个元素let num = [1, 2, 3, 4];num.copyWithin(2, 0);console.log(num); // [1, 2, 1, 2]// 从 0 开始复制// 从 2 开始粘贴// 限制重写元素个数为 1let num = [1, 2, 3, 4];num.copyWithin(2, 0, 1);console.log(num); // [1, 2, 1, 4] array_obj.includes(value, start): 作用: 如果在数组中找到要搜索的值，则返回true，否则返回false 参数: value: 待查找值 start: 开始查找的索引 说明: 内部使用 用includes()方法进行值比较时，===操作符的使用有一个例外：NaN也被认为是等于NaN +0和-0被认为是相等的，与 indexOf 方法相同 1234567let value = [1, NaN， +0]value.indexOf(NaN); // -1value.includes(NaN); // truevalue.indexOf(-0); // 2value.includes(-0); // true 7. 定型数组定型数组是一种用于处理数值类型（正如其名，不是所有类型）数据的专用数组。在JavaScript中，数字是以64位浮点格式存储的，并按需转换为32位整数，所以算术运算非常慢，因此在ECMAScript 6中引入定型数组来解决这个问题。所谓定型数组，就是将任何数字转换为一个包含数字比特的数组，随后就可以通过我们熟悉的JavaScript数组方法来进一步处理。 定型数组支持存储和操作以下8种不同的数值类型： 有符号的8位整数（int8） 无符号的8位整数（uint8） 有符号的16位整数（int16） 无符号的16位整数（uint16） 有符号的32位整数（int32） 无符号的32位整数（uint32） 32位浮点数（float32） 64位浮点数（float64） 所有与定型数组有关的操作和对象都集中在这8个数据类型上，但是要是定型数组，需要创建一个数组缓冲区存储这些数据。数组缓冲区是为定型数组分配的内存，而定型数组的类型决定如何解析内存中的值。 7.1 数组缓冲区数组缓冲区包含特定数量字节的内存地址，可以通过ArrayBuffer构造函数来创建数组缓冲区: 1234let buffer = new ArrayBuffer(10); // 分配 10 个字节console.log(buffer.byteLength); // 10 let buffer2 = buffer.slice(4, 6); // 通过 slice 创建数组缓冲区 7.2 视图要想修改数组缓冲区，需要使用视图对象。数组缓冲区是内存中的一段地址，视图是用来操作内存的接口，可以按照定一种数值类型向数组缓冲区读取和写入数据。DataView类型是一种通用的数组缓冲区视图，其支持所有8种数值型数据类型。 DataView(buffer, offset, num) 接收三个参数: buffer: 数组缓冲区 offset: 偏移量，视图选取从偏移量开始往后的字节 num: 执行选取的字节数量 注意: 可以基于同一个数组缓冲区创建多个view DataView 有如下属性和方法: buffer 视图绑定的数组缓冲区 byteOffset DataView构造函数的第二个参数，默认是0，只有传入参数时才有值 byteLength DataView构造函数的第三个参数，默认是缓冲区的长度byteLength getInt8(byteOffset, littleEndian): 读取位于byteOffset后的int8类型数据， littleEndian 布尔值，表示是否按照小端序进行读取 setInt8(byteOffset, value, littleEndian): 在byteOffset处写入int8类型数据 littleEndian 布尔值，表示是否按照小端序格式存储 getUint8，setUint8，getFloat32，setFloat32，getFloat64，setFloat64，包括其他宽度的整数修改对应的数值即可 12345let buffer = new ArrayBuffer(10); // 分配 10 个字节let view = new DataView(buffer); // 默认读写 10 个字节let part = newDataView(buffer, 5, 2); // 读写第 5,6 个字节view.setInt8(0. 5); 当混合使用不同数据类型时，DataView对象是一个完美的选择，然而，如果你只使用某个特定的数据类型，那么特定类型的视图则是更好的选择。特定类型的视图就是定型数组。 7.3 定型数组ECMAScript 6定型数组实际上是用于数组缓冲区的特定类型的视图。可以像正常数组一样通过数值型索引来访问元素。 Uint8ClampedArray与Uint8Array大致相同，唯一的区别在于数组缓冲区中的值如果小于0或大于255，Uint8ClampedArray会分别将其转换为0或255，例如，-1会变为0，300会变为255。 创建定型数组定型数组的构造函数有多种使用方式: 传入与 DataView 相同的参数 传入一个数字，表示分配给数组的元素数量（不是比特数量），构造函数将创建一个新的缓冲区，并按照数组元素的数量和构造函数对应的数值宽度来分配合理的比特数量 将以下任一对象作为唯一的参数传入： 一个定型数组: 数组中的每个元素会作为新的元素被复制到新的定型数组中 一个可迭代对象 一个数组 一个类数组对象 注意: 无效数据都会被过滤 123456789// 使用方式二let ints = new Int16Array(2);console.log(ints.byteLength); // 4console.log(ints.length); // 2// 使用方式三，来自对象let int1 = new Int16Array([2, 3]);let int2 = new Int32Array(int1);console.log(int1.buffer === int2.buffer); // false 每种定型数组由多个元素组成，元素大小指的是每个元素表示的字节数。该值存储在每个构造函数和每个实例的BYTES_PER_ELEMENT属性中。 定型数组与普通数组的相似之处在许多情况下可以按照普通数组的使用方式去使用定型数组: 以下方法均可用于定型数组：copyWith，fill，find，findIndex，slice，map，filter，some，reduce，join，sort，indexOf,reverse… 都有3个相同的迭代器，分别是entries()方法、keys()方法和values()方法 都含有静态of()方法和from()方法 定型数组与普通数组的差异 定型数组不是普通数组。它不继承自Array 不同通过修改 length 来修改定型数组的大小 定型数组中的方法在赋值时会额外检查数值类型是否安全，0被用于代替所有非法值 定型数组中不存在的数值索引赋值会被忽略 定型数组不包括如下数组方法: concat,pop,push,shift,splice,unshift 除concat()方法外，这个列表中的方法都可以改变数组的尺寸 定型数组中还有两个没出现在普通数组中的方法： set(array, offset): 作用：将其他数组复制到已有的定型数组 array: 数组（定型数组或普通数组都支持） offset: 表示开始插入数据的位置，默认为 0 subarray(start, end): 作用: 提取已有定型数组的一部分作为一个新的定型数组 start: 可选的开始位置 end: 可选的结束位置，不包含 可以省略这两个参数来克隆一个新的定型数组]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 Symbol 与方法重载]]></title>
    <url>%2F2020%2F08%2F22%2Fweb%2FES6%2Fes6_7%2F</url>
    <content type="text"><![CDATA[Symbol 类型以及引入的”方法重载” 1. Symbol1.1 Symbol 概述ES6 引入 Symbol 类型的由来是为了给对象添加私有属性。与其他语言比如 Python 类似，这些私有属性都与语言内部实现有关。接下来我们就来介绍介绍 Symbol 类型的用法以及与 Symbol 相关语言内部实现。需要强调一下的是，在 Symbol 类型出来之前，对象的属性名都是字符串，现有有 Symbol 和字符串两种。 2. Symbol 的使用2.1 Symbol 创建Symbol 与数值一样是 ES6 定义的原始值。它没有字面量形式，没有与之对应的包装类型，不能使用 new Symbol() 创建，只能通过全局的 Symbol 函数创建。Symbol 被创建出来就是唯一的，你无法通过实例化来得到两个相等但却不全等的 Symbol 实例，这也正是 Symbol 被用于实现私有属性的原因。 Symbol函数接受一个可选参数，其可以让你添加一段文本描述即将创建的Symbol，这段描述不可用于属性访问。Symbol的描述被存储在内部的[[Description]]属性中，不能直接在代码里访问[[Description]]，只有当调用Symbol的toString()方法时才可以读取这个属性。 12345let firstName = Symbol("firstName");let person = &#123;&#125;;person[firstName] = "tsong";console.log(typeof firstName); // Symbol 2.2 Symbol 的类型转换没有与 Symbol 逻辑等价的其他类型值，尤其是不能将Symbol强制转换为字符串和数字类型，等价的布尔值永远为 true。 123let firstName = Symbol("firstName");let desc = firstName + ""; // 报错let n = firstName / 10; // 报错 2.3 Symbol 使用Symbol也可以用于可计算对象字面量属性名、Object.defineProperty()方法和Object.defineProperties()方法的调用过程中: 123456789let firstName = Symbol("firstName");let person = &#123;&#125;;Object.defineProperty(person， &#123; [firstName]:&#123; value: "zhang", writable: false &#125;&#125;) 为了保证向前兼容，Object.keys()方法和Object.getOwnPropertyNames()方法都不支持Symbol属性。ECMAScript 6中添加一个Object.getOwnPropertySymbols()方法来检索对象中的Symbol属性。 2.4 Symbol 的共享为了让跨模块共享 Symbol，ECMAScript 6提供了一个可以随时访问的全局Symbol注册表。如果想创建一个可共享的Symbol，要使用Symbol.for()方法。它只接受一个参数，也就是即将创建的Symbol的字符串标识符，这个参数同样也被用作Symbol的描述。类似于一全局字典，保存了标识符到 Symbol 实例的映射。 Symbol.for()方法首先在全局Symbol注册表中搜索键为”uid”的Symbol是否存在，如果存在，直接返回已有的Symbol；否则，创建一个新的Symbol，并使用这个键在Symbol全局注册表中注册，随即返回新创建的Symbol。 而Symbol.keyFor()方法则在 Symbol 全局注册表中检索与 Symbol 有关的键。即通过 symbol 实例查找对应的标识符，用于判断特定 symbol 实例是否存在。 12345let uid = Symbol.for("124");let uid2 = Symbol.for("124");uid === uid2; // trueconsole.log(Symbol.keyFor(uid2)); // "uid" symbol 全局注册表没有提供命名空间，使用时需要注意冲突。 3. well-know Symbol所谓 well-know 就是语言内部使用的特殊 symbol，它们都是 Symbol 对象的一个属性。ES6 通过在原型链上定义与 Symbol 相关的属性来暴露更多的语言内部逻辑。语言描述很复杂，我们以 Symbol.hasInstance 为例来说说。当我们调用 obj instanceof Array; 时，JavaScript 实际会调用 Array[Symbol.instanceof](obj)，因此我们可以通过自定义Array 的 Symbol.instanceof来重载默认的 instanceof 行为。跟 Python 的运算符重载一个道理。 这些well-known Symbol包括： Symbol.hasInstance: 一个在执行instanceof时调用的内部方法，用于检测对象的继承信息 Symbol.isConcatSpreadable: 一个布尔值，用于表示当传递一个集合作为Array.prototype.concat()方法的参数时，是否应该将集合内的元素规整到同一层级 Symbol.iterator: 一个返回迭代器的方法 字符串处理相关的: Symbol.match: 一个在调用String.prototype.match()方法时调用的方法，用于比较字符串 Symbol.replace: 一个在调用String.prototype.replace()方法时调用的方法，用于替换字符串的子串 Symbol.search: 一个在调用String.prototype.search()方法时调用的方法，用于在字符串中定位子串 Symbol.split: 一个在调用String.prototype.split()方法时调用的方法，用于分割字符串 Symbol.species: 用于创建派生类的构造函数 Symbol.toPrimitive: 一个返回对象原始值的方法 Symbol.toStringTag: 一个在调用Object.prototype.toString()方法时使用的字符串，用于创建对象描述 Symbol.unscopables: 一个定义了一些不可被with语句引用的对象属性名称的对象集合 3.1 Symbol.hasInstanceSymbol.hasInstance 的作用前面我们已经介绍过了，这里我们就来看一个自定义 Symbol.hasInstance 的示例:123456789101112function Special&#123;&#125;Object.defineProperty(Special, Symbol.hasInstance, &#123; value: function(v)&#123; return (v instanceof Number) &amp;&amp; (v&gt;=1 &amp;&amp; v &lt;100); &#125;&#125;)let one = new Number(200), two = new Number(2);one instanceof Special; // falsetwo instanceof Special; // true 注意，如果要触发Symbol.hasInstance调用，instanceof的左操作数必须是一个对象，如果左操作数为非对象会导致instanceof总是返回false。 3.2 Symbol.isConcatSpreadableSymbol.isConcatSpreadable 用于控制数组的 concat 方法。JavaScript数组的concat()方法被设计用于拼接两个数组，如果传给 concat 是一个数组，就会自动将它们分解为独立元素。 Symbol.isConcatSpreadable属性是一个布尔值，如果该属性值为true，则表示对象有length属性和数字键，故它的数值型属性值应该被独立添加到concat()调用的结果中。可以在派生数组子类中将Symbol.isConcatSpreadable设置为false，从而防止元素在调用concat()方法时被分解。 1234567let collection = &#123; 0: "a", length: 1, [Symbol.isConcatSpreadable]: true&#125;let mess = [].concat(collection);console.log(mess); // ["a"] 3.3 Symbol stringSymbol.match、Symbol.replace、Symbol.search和Symbol.split这4个Symbol属性表示match()、replace()、search()和split()方法的第一个参数应该调用的正则表达式参数的方法，它们被定义在RegExp.prototype中，是字符串方法应该使用的默认实现。 3.4 Symbol.toPrimitiveSymbol.toPrimitive方法与强制类型转换有关,被定义在每一个标准类型的原型上，并且规定了当对象被转换为原始值时应当执行的操作。每当执行原始值转换时，总会调用Symbol.toPrimitive方法并传入一个值作为参数，这个值在规范中被称作类型提示（hint）。类型提示参数的值只有三种选择：”number”、”string”或”default”，传递这些参数时，Symbol.toPrimitive返回的分别是：数字、字符串或无类型偏好的值。 对于大多数标准对象，数字模式有以下特性，根据优先级的顺序排列如下： 调用valueOf()方法，如果结果为原始值，则返回 否则，调用toString()方法，如果结果为原始值，则返回 如果再无可选值，则抛出错误。 对于大多数标准对象，字符串模式有以下优先级排序： 调用toString()方法，如果结果为原始值，则返回 否则，调用valueOf()方法，如果结果为原始值，则返回 如果再无可选值，则抛出错误 1234567891011121314151617181920function Temperature(degree)&#123; this.degree = degree;&#125;Temperature.prototype[Symbol.toPrimitive] = funciton(hit)&#123; switch(hit)&#123; case "string": return this.degree + "度"; case "number": return this.degree; case "default": return this.degree + "-default"; &#125;&#125;let f = Temperature(312)console.log(f + "!"); // +运算符触发默认模式，hint被设置为"default"；console.log(f / 10); // /运算符触发数字模式console.log(String(f)); // String()函数触发字符串模式 3.5 Symbol.toStringTagSymbol.toStringTag 表示的属性在每一个对象都存在，Object.prototype.toString() 方法被调用时，会使用 Symbol.toStringTag 属性值来构建起返回值。 Object.prototype.toString() 的返回值在 JavaScript 中被用作对象标识符，在跨执行环境中会被用于类型判断。(注: iframe 标签就会在页面引入新的执行环境)。 我们可以像下面这样自定义对象的 toString 方法的使用，同时不影响使用 Object.prototype.toString.call() 返回对象标识符进行跨执行环境的类型判断。 12345678910111213function Person(name)&#123; this.name = name;&#125;Person.prototype[Symbol.toStringTag] = "Person";Person.prototype.toString()&#123; return self.name;&#125;var me = Person("tsong");console.log(me); // tsongconsole.log(Object.prototype.toString.call(me)) //[Object Person] 3.6 Symbol.unscopablesSymbol.unscopables 与 with 语句有关，因为非常不建议使用 with 语句，所以这个属性我们就不在详述了。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 对象扩展与类]]></title>
    <url>%2F2020%2F08%2F21%2Fweb%2FES6%2Fes6_6%2F</url>
    <content type="text"><![CDATA[ES6 关于对象使用和交互的扩展。 1. ES6 对象扩展概述ES6 对对象做了如下扩展: 对象字面量语法扩展 Object 新增方法 自由属性枚举顺序 增强对象原型 正式的方法定义 ECMAScript 6 规范清晰划分了对象的类别，理解这些术语对理解这门语言非常重要: 普通（Ordinary）对象: 具有JavaScript对象所有的默认内部行为 特异（Exotic）对象: 具有某些与默认行为不符的内部行为 标准（Standard）对象: ECMAScript 6规范中定义的对象，标准对象既可以是普通对象，也可以是特异对象 内建对象: 脚本开始执行时存在于JavaScript执行环境中的对象，所有标准对象都是内建对象 2. 对象字面量语法扩展ES6 为对象字面量提供了多种简写方式: 属性初始化简写： 当一个对象的属性与本地变量同名时，不必再写冒号和值，简单地只写属性名即可 JavaScript引擎会在可访问作用域中查找其同名变量 对象方法简写: 消除了冒号和function关键字 这是定义对象方法的标准形式 可计算的属性名: 用于动态定义属性名，类似于动态获取对象属性的方括号语法 语法: [expression] 12345678910111213141516171819202122let name = "tsong", age = 19// 1. 属性初始化的简写语法let obj = &#123; name, age&#125;// 2. 对象方法的简写语法let obj = &#123; name: "tsong", getName() &#123; return this.name; &#125;&#125;// 3. 可计算单额属性名let suffix = "name";let obj = &#123; ["first " + suffix]: "tsong",&#125; 3. Object 新增方法在ECMAScript6中，为了使某些任务更易完成，在全局Object对象上引入了一些新方法。 3.1 Object.isObject.is 用来弥补全等运算符的不准确运算，它与 === 存在下面区别: 12345+0 === -0; // true;Object.is(+0, -0); // falseNaN === NaN ; // falseObject.is(NaN, NaN); // true 3.2 Object.assignObject.assgin(base_obj, …source_obj): 作用: 这个方法接受一个接收对象和任意数量的源对象，并将源对象自身的属性和方法复制到接受对象上 返回: 返回接收对象 注意: 如果多个源对象具有同名属性，则排位靠后的源对象会覆盖排位靠前的 Object.assign()方法执行了赋值操作，因此提供者的访问器属性最终会转变为接收对象中的一个数据属性 3.3 自由属性枚举顺序ECMAScript 6严格规定了对象的自有属性被枚举时的返回顺序，这会影响到Object.getOwnPropertyNames()方法及Reflect.ownKeys 返回属性的形式，，Object.assign()方法处理属性的顺序也将随之改变。 自有属性枚举顺序的基本规则是： 所有数字键按升序排序 所有字符串键按照它们被加入对象的顺序排序 所有symbol键（在第6章详细讲解）按照它们被加入对象的顺序排序 注意: 对于for-in循环，由于并非所有厂商都遵循相同的实现方式，因此仍未指定一个明确的枚举顺序；而Object.keys()方法和JSON.stringify()方法都指明与for-in使用相同的枚举顺序，因此它们的枚举顺序目前也不明晰。 3. 增强对象原型ES6 为了更方便的操作对象原型，提供了 Object.setPrototypeOf() 方法和 super 引用。 3.1 Object.setPrototypeOfObject.setPrototypeOf(obj, prototype_obj) 方法我们在 ES5 中介绍面向对象时就已经详细介绍过了。对象原型的真实值被储存在内部专用属性[[Prototype]]中，调用Object.getPrototypeOf()方法返回储存在其中的值，调用Object.setPrototypeOf()方法改变其中的值。 12345678910let animal = &#123; "name": "animal"&#125;let dog = &#123; "name": "dog"&#125;let friend = Object.create(animal);Object.setPrototypeOf(friend, dog); 3.2 super 引用super 引用用于快速访问对象原型。 123456789101112131415let dog = &#123; greed() &#123; return "dog" &#125;&#125;let f = &#123; greed() &#123; // return Object.getPrototypeOf(this).greed.call(this) + " .hi" return super.greed() + " .hi" &#125;&#125;Object.setPrototypeOf(f, dog)console.log(f.greed()) super引用相当于指向对象原型的指针，也就是Object.getPrototypeOf(this)。这里调用super.getGreeting()方法相当于在当前上下文中调用Object.getPrototypeOf(this).getGreeting.call(this) super 引用只能在简写方法中使用，这与 ES6 正式的方法定义有关。 3. 正式的方法定义ECMAScript 6中正式将方法定义为一个函数，它会有一个内部的 [[HomeObject]] 属性来容纳这个方法从属的对象。Super引用 只能在使用简写方法的方法中使用，在其他方法声明中使用会导致语法错误。 1234567891011let dog = &#123; // 方法 greed() &#123; return "dog" &#125;, // 匿名函数定义的方法，内部没有 HomeObject 属性 say: function()&#123; &#125;&#125; 3.1 super 有引用的原理Super的所有引用都通过[[HomeObject]]属性来确定后续的运行过程: 第一步是在[[HomeObject]]属性上调用Object.getPrototypeOf()方法来检索原型的引用 然后搜寻原型，找到同名函数(会按照原型链往上查找，直至找到同名函数) 最后，设置this绑定并且调用相应的方法 3.2 多重继承Super引用在多重继承的情况下非常有用，我们看下面这个示例: 12345678910111213141516171819202122let animal = &#123; greed() &#123; return "animal" &#125;&#125;let dog = &#123;&#125;let f = &#123; greed() &#123; return Object.getPrototypeOf(this).greed.call(this) + " .hi" // super 会按照原型链查找直至找到 animal 中的 greed 方法并调用 // return super.greed() + " .hi" &#125;&#125;Object.setPrototypeOf(dog, animal)Object.setPrototypeOf(f, dog)g = Object.create(f)console.log(g.greed()) 这里原型链关系为 g-&gt;f-&gt;dog-&gt;animal，调用 g.greed() 时，将调用 f.greed()，在其内部因为 this 指向 g，所以 Object.getPrototypeOf(this) 会返回 f，这样 f.greed() 内部又会调用 f.greed() 造成死循环。 而使用 super 引用正式解决多重继承问题的关键，因为 Super 引用不是动态变化的，它总是指向正确的对象，它会直至找到 animal.greed 方法，然后调用。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 箭头函数]]></title>
    <url>%2F2020%2F08%2F20%2Fweb%2FES6%2Fes6_5%2F</url>
    <content type="text"><![CDATA[ES6 的函数增强 1.ES6 函数概述ES6 对 JavaScript 的函数增加体现在如下几个方面: 参数默认值 不定参数与展开运算符 函数 name 属性 区分构造函数调用与普通函数调用 在代码块中声明函数 箭头函数 1.1 参数默认值ES6 中 JavaScript 终于可以像其他语言一样提供默认值了，像下面这样: 1234567891011121314// 示例一function request(url, timeout=100, callback=function()&#123;&#125;)&#123;&#125;// 示例二：function add(first, second=getValue())&#123;&#125;function add(first, second=first)&#123;&#125;// 示例三: function add(first=second, second) // 形成临界死区，报错// add(undefined, 1)执行时相当于let first = second; // second 临界死区let second = 1; 从上面的示例可以看到 JavaScript 的默认参数由下面这些特点: 示例一: 默认参数语法格式与默认值如何生效: 声明函数时，可以为任意参数指定默认值，在已指定默认值的参数后可以继续声明无默认值参数。这在其他语言中是不允许的。 默认值只有当不为参数传入值或主动传入undefined时才会使用参数的默认值 null 是一个合法值，如果传入的是 null，不会使用默认参数 示例二: 默认值求值时点: 初次解析函数声明时不会调用getValue()方法，只有当调用add()函数且不传入第二个参数时才会调用 正因为默认参数是在函数调用时求值，所以可以使用先定义的参数作为后定义参数的默认值 示例三: 默认参数的临界死区: 在引用参数默认值的时候，只允许引用前面参数的值，即先定义的参数不能访问后定义的参数，因为会形成临界死区 函数参数有自己的作用域和临时死区，其与函数体的作用域是各自独立的，也就是说参数的默认值不可访问函数体内声明的变量 默认参数与 arguments 对象因为出现了默认参数，arguments 对象的行为也发生了变化: 命名参数与 arguments 的联动: 在ECMAScript 5非严格模式下，函数命名参数的变化会体现在arguments对象中 在ECMAScript 5的严格模式下，取消了这种联动行为，无论参数如何变化，arguments对象不再随之改变 在ECMAScript 6中，如果一个函数使用了默认参数值，则无论是否显式定义了严格模式，arguments对象的行为都将与ECMAScript 5严格模式下保持一致，即 arguments对象保持与命名参数分离 1.2 不定参数JavaScript 的函数一直以来可以无视函数声明，接受任意多个参数。函数内部使用 arguments 来接受所有参数。而 ES 6 引入了像 Go 一样接受不定参数的语法 ...args。 123function pick(obj, ...keys)&#123;&#125; 如上例: keys 是一个数组，包含自它传入的所有参数，不包括 obj arguments对象包含的则是所有传入的参数，包括object 函数的length属性统计的是函数命名参数的数量，不定参数不会影响length属性的值，即上面的 pick.length === 1 使用限制JavaScript 的不定参数有如下使用限制: 每个函数最多只能声明一个不定参数，而且一定要放在所有参数的末尾 不定参数不能用于对象字面量setter之中 123456let obj = &#123; // 语法错误，对象字面量setter的参数有且只能有一个 set name(...value)&#123; &#125;&#125; 1.3 展开运算符与不定参数相对应的就是展开运算符，用于将类数组对象展开为独立的多个参数: 123Math.max(...[10, 40, 24, 100])// 可以将展开运算符与其他正常传入的参数混合使用。Math.max(...[10, 40, 24, 100], 0) 1.4 函数 name 属性为了便于调试，ES6 为每个函数都添加了合适的 name 属性。ES6 内部做了很多事情来保证这个 name 合理，这里我们就不详细讲解了。 2. 构造函数与普通函数分离2.1 函数的多重功能ECMAScript 5 中的函数具有多重功能，可以结合new使用，函数内的this值将指向一个新对象，函数最终会返回这个新对象。JavaScript函数有两个不同的内部方法： [[Call]]: 如果不通过new关键字调用函数，则执行[[Call]]函数，从而直接执行代码中的函数体。 [[Construct]]: 当通过new关键字调用函数时，执行的是[[Construct]]函数 它负责创建一个通常被称作实例的新对象，然后再执行函数体，将this绑定到实例上 具有[[Construct]]方法的函数被统称为构造函数。 不是所有函数都有[[Construct]]方法，因此不是所有函数都可以通过new来调用，例如箭头函数就没有这个[[Construct]]方法。 2.2 ES5 如何区分函数的不同调用由于函数的多重作用，就导致函数内部很难判断函数是如何被调用的。在ECMAScript 5中，如果想确定一个函数是否通过new关键字被调用（或者说，判断该函数是否作为构造函数被调用），最流行的方式是使用instanceof: 123456789function Person(name)&#123; if (this instanceof Person)&#123; this.name = name; &#125; else &#123; throw new Error("必须通过 new 关键字调用"); &#125;&#125;Person.call(p1, "tsong"); 但这个方法也不完全可靠，通过 call，apply，bind 等函数绑定调用同样可以将函数内部的 this 绑定到一个 Person 实例。为此ECMAScript 6引入了new.target这个元属性。 2.3 元属性（Metaproperty）new.target为了解决判断函数是否通过new关键字调用的问题，ECMAScript 6引入了new.target这个元属性。元属性是指非对象的属性，其可以提供非对象目标的补充信息（例如new）。 当调用函数的[[Construct]]方法时，new.target被赋值为new操作符的目标，通常是新创建对象实例，也就是函数体内this的构造函数；如果调用[[Call]]方法，则new.target的值为undefined。 有了这个元属性，可以通过检查new.target是否被定义过来安全地检测一个函数是否是通过new关键字调用的: 1234567891011function Person(name)&#123; if (typeof new.target != undefined)&#123; this.name = name; &#125;&#125;function Person(name)&#123; if (new.target === Person)&#123; this.name = name; &#125;&#125; 3. 在代码块中声明函数ES5 中最好不在代码块中声明函数，这在不同浏览器会导致不同的行为。为此 ECMAScript 5的严格模式中引入了一个错误提示，当在代码块内部声明函数时程序会抛出错误。 在ECMAScript 6 严格模式下，会将代码块内声明的函数视作一个块级声明，从而可以在定义该函数的代码块内访问和调用它。在定义函数的代码块内，块级函数会被提升至顶部。注意用let定义的函数表达式不会被提升，因此会存在临界死区。 1234567if (true)&#123; console.log(typeof doSomething); // 抛出错误 let doSomething = function()&#123; &#125; doSomething();&#125; 非严格模式下声明的块级函数，不再提升至代码块的顶部，而是提升至外围函数或全局作用域的顶部。 4. 箭头函数顾名思义，箭头函数是一种使用箭头（=&gt;）定义函数的新语法，它与传统的JavaScript函数有些许不同，主要集中在以下方面： 没有this、super、arguments和new.target绑定，箭头函数中的this、super、arguments及new.target这些值由外围最近一层非箭头函数决定。 不能通过new关键字调用: 箭头函数没有[[Construct]]方法，所以不能被用作构造函数 没有原型: 不存在prototype这个属性 不可以改变this的绑定: 函数内部的this值不可被改变，在函数的生命周期内始终保持一致。 不支持arguments对象: 箭头函数没有arguments绑定 不支持重复的命名参数 箭头函数出现的原因有下面几个: 首先，也是最重要的，this绑定是JavaScript程序中一个常见的错误来源，箭头函数消除了这方面的烦恼 限制了箭头函数的this值，相当于限定的作用范围，更加明晰 4.1 箭头函数语法可以像下面这样定义箭头函数: 123456789101112131415161718192021222324// 一行表达式的函数体，会自动作为返回值let reflect = value =&gt; value;let sum = (num1, num2) =&gt; num1 + num2;let get = () =&gt; "tsong";// 空函数let nothing = () =&gt; &#123;&#125;;// 多行函数体，需要大括号和显示的返回值let sum = (num1, num2) =&gt; &#123; return num1 + num2;&#125;// 返回对象字面量，需要括号括起let getObj = id =&gt; (&#123;id: id, name: "One"&#125;);// 立即执行的箭头函数，需要() 包裹箭头函数体let person = (name =&gt; &#123; return &#123; getName: function()&#123; return name; &#125; &#125;&#125;)("tsong"); 4.2 箭头函数的 this 对象箭头函数中没有this绑定，必须通过查找作用域链来决定其值。如果箭头函数被非箭头函数包含，则this绑定的是最近一层非箭头函数的this；否则，this的值会被设置为undefined。箭头函数中的this值取决于该函数外部非箭头函数的this值，且不能通过call()、apply()或bind()方法来改变this的值。 4.3 箭头函数的 arguments箭头函数没有自己的arguments对象，且未来无论函数在哪个上下文中执行，箭头函数始终可以访问外围函数的arguments对象。即使函数箭头此时已不再处于创建它的函数的作用域中，却依然可以访问当时的arguments对象，这是arguments标识符的作用域链解决方案所规定的。 4.4 类方法中的箭头函数ES6 为 JavaScript 添加了类似其他面向对象语言的 class 类声明语法，具体的语法我们后面会详细介绍。ES6 中定义一个类的示例如下: 1234567891011121314151617class Person &#123; // 等价的构造函数 constructor(name)&#123; this.name = name; // 构造函数内 new.target 等于类的构造函数 console.log(new.target === Person) &#125; // 没有逗号分隔 // 等价于 Person.prototype.sayName sayName()&#123; console.log(this.name); &#125;&#125;var person = new Person("Ward");console.log(typeof Person); // function 我们能看到 sayName() 定义的方法等价于 等价于 Person.prototype.sayName = function(){}。 但是有了箭头函数之后，类的方法的方法就有两种定义方式，如下: 123456789101112131415161718// 普通函数方式class A&#123; aa()&#123; console.log(this) &#125;&#125;// 箭头函数方式class B&#123; bb = ()=&gt;&#123; console.log(this) &#125;&#125;a = new A()a.aa()b = new B()b.bb() 执行 a.aa(), b.bb() 时内部打印的 this 指向如下: 从上面的输出可以看到: aa() == A.prototype.aa = function(){} 普通函数定义的方法，是定义在对象的原型上 bb() 箭头函数定义的方法， this 始终绑定在实例上。 箭头函数中没有this绑定，必须通过查找作用域链来决定其值。如果箭头函数被非箭头函数包含，则this绑定的是最近一层非箭头函数的this；否则，this的值会被设置为undefined。箭头函数中的this值取决于该函数外部非箭头函数的this值。 对于 b.bb() 箭头函数内部 this 绑定到 b 实例如何理解呢？在我们执行 b = new B() bb() 箭头函数被创建，此时 B 函数就是箭头函数 bb 的外部非箭头函数，bb 箭头函数内部的 this 就是 B 函数内部的 this，即 new B() 创建的新实例对象。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 解构]]></title>
    <url>%2F2020%2F08%2F19%2Fweb%2FES6%2Fes6_4%2F</url>
    <content type="text"><![CDATA[类似”Python” 的解包赋值，解构是一种打破数据解构，将其拆分为更小部分的过程。 1. 解构概述解构作用对象是对象和数组，我觉得可以理解成对象字面量和数组字面量的”逆过程”。 2. 对象解构下面是一个对象解构的完整示例: 12345678910111213141516171819let obj = &#123; name: "tsong", age: 10&#125;let &#123;name, age: varAge=28, value=10&#125; = obj;// 1. &#123;&#125; 不能作为表达式，必须使用小括号(&#123;name, age&#125;) = obj; // 2. 解构是赋值表达式不能单独使用，下面将报错let &#123;name, age&#125;; // 解构赋值表达式的值为 = 右侧的值function output(value)&#123; console.log(value === obj); // true&#125;output(&#123;name, age&#125; = obj) 对于 age: varAge = 28: age: 表示在 obj 中搜索的属性名 varAge: 表示最终赋值的局部变量名 = 28: 表示当 obj 中不存在 age 属性或者其值为 undefined 时设置的默认值，与函数默认值完全相同 当属性名与变量名相同时，可简写，比如这里的 name 和 value=10，与对象字面量的属性简写类似 注意: 解构是赋值表达式，不能单独使用 let {name, age} 将报错 对已声明变量的解构，必须使用小括号包裹，JavaScript引擎将一对开放的花括号视为一个代码块，而语法规定，代码块语句不允许出现在赋值语句左侧，添加小括号后可以将块语句转化为一个表达式，从而实现整个解构赋值的过程。 解构赋值表达式的值与表达式右侧（也就是=右侧）的值相等，如此一来，在任何可以使用值的地方你都可以使用解构赋值表达式 解构可以嵌套解构 2. 数组解构下面是一个数组解构的完整示例: 1234567let color = ["red", "green", "black"]let [first, second] = color; // 按位置查找let [,,third] = color; // , 占位符表示跳过let [one, ...collect] = color; // 不定元素let [...copy] = color; // 数组复制，等同有 color.concat()let [,,,four="default"] = color; // 默认值let [a, b] = [b, a]; // 交换变量值 3. 解构函数参数解构也可以用于函数参数，比如: 123function setCookie(name, value, &#123;path, domain, expire&#125;)&#123; // let &#123;path, domain, expire&#125; = null // 将报错&#125; 因为不能对 null 和 undefined 进行解构，函数调用必须给解构参数提供默认值。因此一个提供默认值的解构参数要像下面这样: 123456789function setCookie(name, value, &#123; path = "/", domain = "www.test.com", expire = 10 &#125; = &#123;&#125; )&#123; console.log(path);&#125; 4. 严格模式限制由于实现的难点，ECMAScript 2016只有参数为不包含解构或默认值的简单参数列表时才可以在函数体中使用”usestrict”。以下是一些合法与非法使用指令的示例： 1234567891011121314151617// 简单参数列表可以运行function okey1(first, second) &#123; "use strict"; return first;&#125;// 非法: 抛出错误function okey2(first, second=first) &#123; "use strict"; return first;&#125;// 非法: 抛出错误function okey3(&#123;first, second&#125;) &#123; "use strict"; return first; &#125;]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 字符串与正则表达式]]></title>
    <url>%2F2020%2F08%2F18%2Fweb%2FES6%2Fes6_3%2F</url>
    <content type="text"><![CDATA[ES6 对字符串扩展主要集中在 Unicode，正则表达式以及模板字符串。我们先说最重要的模板字符串。 1. 模板字符串模板字符串有点类似 Python 中的 Jinja2，通过模板字符串 ES6 解决了 JavaScript 中的如下问题: 创建多行字符串 字符串格式化 HTML 转义 1. 基本语法模板字符串的基本用法如下: 模板字符串使用反引号包裹 在反撇号中的所有空白符都属于字符串的一部分，因此可以直接创建多行字符串 通过占位符${}可以嵌入任何合法的JavaScript表达式 占位符可以访问作用域中所有可访问的变量 模板字面量本身也是JavaScript表达式，所以你可以在一个模板字符串里嵌入另外一个模板字符串 123456789101112name = "tsong"let message = ` my name is $&#123;name&#125;, // 占位符 new line // 模板字符串内可直接换行 $$&#123;(count * price).toFixed(2)&#125; // 第一个 $ 是美元符，因为没有紧跟着 &#123; 所以无需转义`let html = `&lt;div&gt; &lt;h1&gt;Title&lt;/h1&gt;&lt;/div&gt;`.trim() 1.2 标签模板模板字面量真正的强大之处在于标签模板。一个标签模板是由标签和模板字符串组成的，像下面这样: 1let message = tag`Hello world`; 其中 tag 就是标签，是位于模板字面量第一个反撇号（`）前方标注的字符串。标签是一个形如下面的函数: 123function tag(literals, ...substitutions)&#123; // 必须返回一个字符串&#125; 其中: literals: 一个数组，包含JavaScript解释过后的字面量字符串 相当于模板字符串按照占位符 split 后得到的字符串数组 literals里的第一个元素是一个空字符串，这确保了literals[0]总是字符串的始端 每一个占位符的解释值都会作为参数传给标签函数，通常使用不定参数来接受 我们以下面这个例子具体讲讲每个参数的含义: 123456let count = 10, price = 0.25let message = passthru`$&#123;count&#125; items cost $$&#123;(count * price).toFixed(2)&#125;.`;function passthru(literals, ...substitutions)&#123; // 必须返回一个字符串&#125; passthru 将接受如下参数 : literals: [&quot;&quot;, &quot; items cost $&quot;, &quot;.&quot;] count 的解释值 10 (count * price).toFixed(2)的解释值 2.50 因此整个过程相当于调用了函数 message = passthru([&quot;&quot;, &quot; items cost $&quot;, &quot;.&quot;], 10, 2.50) 而 passthru 函数必须返回一个字符串作为结果。最终的结果就是标签决定了模板字符串的输出结果。 1.3 在模板字面量中使用原始值模板标签同样可以访问原生字符串信息，也就是说通过模板标签可以访问到字符转义被转换成等价字符前的原生字符串。最简单的例子是使用内建的String.raw()标签： 1234567&gt; let m1 = `m1 \n newline`let m2 = String.raw`m1 \n newline`&gt; m1 // 变量m1中的\n被解释为一个新行"m1 newline"&gt; m2 // 变量 m2 获取的是\n的原生形式"\\n""m1 \n newline" 标签函数的第一个参数 literals 是一个数组，它有一个额外的属性raw，是一个包含每一个字面值的原生等价信息的数组。即 literals[i]总有一个等价的literals.raw[i]，包含着它的原生字符串信息。 2. Unicode 支持ES6 以前，JavaScript字符串一直基于16位字符编码（UTF-16）进行构建。但是 UTF-16 无法表示所有字符，为此，UTF-16引入了代理对。也就是说，字符串里的字符有两种， 一种是由一个编码单元16位表示的BMP字符 另一种是由两个编码单元32位表示的辅助平面字符 而之前所有的字符处理方法和正则表达式都把32位的辅助平面字符当做两个 utf16 编码进行处理。 12345678910111213&gt; let test = '𠮷'&gt; test.length2&gt; /^.$/.test(test)false&gt; test.charAt(0)"�"&gt; test.charAt(1)"�"&gt; test.charCodeAt(1)57271&gt; test.charCodeAt(0)55362 为此 ES6 增加了如下方法: codePointAt(): 接受编码单元的位置而非字符位置作为参数，返回与字符串中给定位置对应的码位 String.fromCodePoint(): 根据指定的码位生成一个字符 normalize(): 提供Unicode的标准化形式，接受一个参数表示应用的哪种Unicode标准化形式 以标准等价方式分解，然后以标准等价方式重组（”NFC”），默认选项 以标准等价方式分解（”NFD”） 以兼容等价方式分解（”NFKC”） 以兼容等价方式分解，然后以标准等价方式重组（”NFKD”） 给正则表达式定义了一个支持Unicode的u修饰符，u 表示从编码单元操作模式切换为字符模式 123456789101112131415161718192021&gt; String.fromCodePoint(134071)"𠮷"// 正则表达式 u 修饰符&gt; let test = '𠮷'&gt; test.length2&gt; /^.$/.test(test)false&gt; /^.$/u.test(test)true// 兼容 u 修饰符function hasRegExpU()&#123; try&#123; let pattern = new RegExp("", "u"); return true; &#125; catch(ex)&#123; return false &#125;&#125; 3. 正则表达式JavaScript 正则表达式是一个不完整实现，因为完整的 perl 实现的正则表达式代码量过多，JavaScript 也不需要这么多功能。ES6 为正则表达式对象增加了 y 修饰符和 flag 属性。 3.1 y 修饰符y 修饰符会影响正则表达式搜索过程中的sticky属性，当在字符串中开始字符匹配时，它会通知搜索从正则表达式的lastIndex属性开始进行，如果在指定位置没能成功匹配，则停止继续匹配。 123456789101112131415161718192021222324let text = "hello1 hello2 hello3"pattern = /hello\d\s?/globalPattern = /hello\d\s?/gstickyPattern = /hello\d\s?/ypattern.lastIndex = 1globalPattern.lastIndex = 1stickyPattern.lastIndex = 1p = pattern.exec(text)g = globalPattern.exec(text)y = stickyPattern.exec(text)&gt; p[0]"hello1 "&gt; g[0]"hello2 "&gt; ynull&gt; globalPattern.stickyfalse&gt; stickyPattern.stickytrue 关于y修饰符需要注意: 只有调用exec()和test()这些正则表达式对象的方法时才会涉及lastIndex属性 调用字符串的方法，例如match()，则不会触发粘滞行为 如果此时lastIndex的值不为0，正则表达式包括 ^，则该表达式永远不会匹配到正确结果 同 u 修饰符一样，y 修饰符也需要做兼容性检测 3.2 flags 属性在ECMAScript 5中，你可能通过source属性获取正则表达式的文本，修饰符只能 reg.toString() 返回的文本解析获取，无法直接获取。ECMAScript 6新增了一个flags只读属性，可直接获取正则表达式的修饰符。 123&gt; stickyPattern = /hello\d\s?/y&gt; stickyPattern.flags"y" 3.3 正则表达式复制ES6 还扩展了 RegExp 的构造函数，ES5 中:123&gt; pattern = /hello\d\s?/&gt; RegExp(pattern) // 获得 pattern 对象的一个复制&gt; RegExp(pattern, "g") // 不允许修改复制的正则表达式对象 ES6 RegExp(pattern, &quot;g&quot;) 报错的行为，并允许修改正则表达式的修饰符。 4. 其他字符串变更4.1 子串识别在没有这三个方法之前，字符串中是否包含子串都是使用的 indexOf 和 lastIndexOf 两个方法，ES6 为我们新增了如下三个方法: includes(substring, startIndex)方法，如果在字符串中检测到指定文本则返回true，否则返回false startsWith(substring, startIndex)方法，如果在字符串的起始部分检测到指定文本则返回true，否则返回false endsWith(substring, startIndex)方法，如果在字符串的结束部分检测到指定文本则返回true，否则返回false 4.2 字符串重复ECMAScript 6还为字符串增添了一个repeat()方法，用于重复字符串: 12&gt; "x".repeat(3)"xxx"]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 块级作用域绑定的let和const]]></title>
    <url>%2F2020%2F08%2F17%2Fweb%2FES6%2Fes6_2%2F</url>
    <content type="text"><![CDATA[要理解 ES6 为什么要引入 let 和 const 声明，我们首先要搞清楚 ES5 中变量声明和变量作用域存在问题。 1. var 声明与作用域JavaScript的变量声明机制一直令我们感到困惑。大多数类C语言在声明变量的同时也会创建变量（绑定）。而在以前的JavaScript中，何时创建变量要看怎么声明变量。 变量提升: ES5 中 JavaScript 不存在块级作用域，在函数作用域或全局作用域中通过关键字var声明的变量，无论实际上是在哪里声明的，都会被当成在当前作用域顶部声明的变量，也就是变量提升机制 重复声明: var 可重复声明同名变量 循环中的函数: 循环内的每次迭代会共享相同的变量，这是大多数语言都存在的问题，但是 es6 额外解决了。 全局块作用域绑定: 当var被用于全局作用域时，它会创建一个新的全局变量作为全局对象（浏览器环境中的window对象）的属性 这意味着用var很可能会无意中覆盖一个已经存在的全局变量 1.1 变量提升在 ES5 中下面两种 value 变量声明的效果是完全一样的。 123456789function getValue(condition)&#123; if (condition)&#123; var value = "blue"; // value 变量会提升至函数作用域顶部 &#125; else &#123; // 此处可以访问变量 value，值为 undefined return null; &#125; // 此处可以访问变量 value，值为 undefined&#125; 在预编译阶段，JavaScript引擎会将上面的getValue函数修改成下面这样： 123456789function getValue(condition)&#123; // 变量value的声明被提升至函数顶部，而初始化操作依旧留在原处执行 var value; if (condition)&#123; value = "blue"; &#125; else &#123; return null; &#125;&#125; 2.2 循环中的函数1234567891011var funcs = [];for (var i = 0; i &lt; 10; i++) &#123; funcs.push(function()&#123; console.log(i); &#125;) &#125;// 输出 10 个 10funcs.forEach(function(func)&#123; func();&#125;) 上面代码执行的最终结果会输出 10 个 10，这是因为循环里的每次迭代同时共享着变量i，循环内部创建的函数全都保留了对相同变量的引用。循环结束时变量i的值为10。这个问题在大多数其他语言都会存在，解决方案是使用闭包保存住每次迭代时 i 的值。但是 ES6 的 let 声明为我们额外解决了这个问题。 2. let 和 const 声明于上面对应的，ES6 通过 let/const 引入了块级作用域: 变量提升: let 声明的变量将其作用域限定在当前代码块中，并且不会出现变量提升，变量只会在代码块执行时声明、创建、销毁 重复声明: let 禁止重复声明，无论是 var、let 还是 const 声明的变量都不能在使用 let 重复声明 循环中的函数: 循环中的let声明每次迭代都会创建新的变量，而不是共享变量 全局块作用域绑定: let 会在全局作用域下创建一个新的绑定，但该绑定不会添加为全局对象的属性 2.1 临界死区(TDZ)let和const声明的变量不会被提升到作用域顶部，如果在声明之前访问这些变量，即使是相对安全的typeof操作符也会触发引用错误。JavaScript引擎在扫描代码发现变量声明时，要么将它们提升至作用域顶部（遇到var声明），要么将声明放到TDZ中（遇到let和const声明）。访问TDZ中的变量会触发运行时错误。只有执行过变量声明语句后，变量才会从TDZ中移出，然后方可正常访问。 123456console.log(typeof value); // 1 undefined, 不会报错if (condition)&#123; console.log(typeof value); // 2 引用错误，临界死区 let value = "blue"&#125; 从上面的示例可以看到: 条件判断内 typeof 使用的 value(2 处) 处于 let 的临界死区内，无法使用 外部作用域的 value(1 处) 并不在块级作用域的 TDZ 中，意味着不存在value这个绑定，typeof操作最终返回”undefined” 2.2 重复声明1234567891011121314151617// 注意: 命令行中下面的示例可以执行，但是在 js 中，let 会形成临界死区，a = 1 就会报错// 疑问: 直接赋值的变量竟然可以使用 let 再次声明，但是下面的 var 不行// 猜测原因: 与变量的查找顺序有关，声明的变量位于单独的"查找区域"，直接赋值的变量不会加入到这个区域// 所以不会进行重复声明检测，而能访问到 a 是因为 window 对象会作为最后的查找作用域&gt; a = 1&gt; window.a 1&gt; let a// 同一作用域中已经存在某个标识符，不能使用 let 重复声明&gt; var b=1&gt; window.b1&gt; let bVM299:1 Uncaught SyntaxError: Identifier 'b' has already been declared at &lt;anonymous&gt;:1:1(anonymous) @ VM299:1 2.3 循环中的let声明123456789101112var funcs = [];// let和const都会每次迭代时都会创建新的变量，进行新的绑定for (let i = 0; i &lt; 10; i++) &#123; funcs.push(function()&#123; console.log(i); &#125;) &#125;funcs.forEach(function(func)&#123; func();&#125;) 在上面 for 循环中，每次循环的时候let声明都会创建一个新变量i，并将其初始化为i的当前值，所以循环内部创建的每个函数都能得到属于它们自己的i的副本。对于for-in循环和for-of循环来说也是一样的。 2.4 全局块作用域绑定1234567let RegExp = "hello";console.log(RegExp); // helloconsole.log(window.RegExp === RegExp); // falseconst ncz = "hi";console.log(ncz); // helloconsole.log("ncz" in window); // false 这里let声明的RegExp创建了一个绑定并遮蔽了全局的RegExp变量。结果是window.RegExp和RegExp不相同，但不会破坏全局作用域。如果不想为全局对象创建属性，则使用let和const要安全得多。如果希望在全局对象下定义变量，仍然可以使用var。这种情况常见于在浏览器中跨frame或跨window访问代码。 2.5 const 与 let 不同const 与 let 有如下不同: 使用const声明的是常量，其值一旦被设定后不可更改。因此，每个通过const声明的常量必须进行初始化。 用const声明的对象，不允许修改绑定，但允许修改对象的属性值。这个也很好理解，const 限定的是变量的值，对于对象而言保存在变量中的是对象的引用，这个引用不能更改，但是引用指向的对象可以更改。 对于普通的for循环来说，可以在初始化变量时使用const，但是更改这个变量的值就会抛出错误，也就是说循环中的 const 不会在每次迭代时创建新的变量。在for-in或for-of循环中使用const时的行为与使用let一致，当然循环内不能改变 const 声明的变量的值。 12345678910111213141516171819202122232425262728// 1. 普通 for 循环var funcs = [];// i++ 修改了常量所以会报错，如果后续循环不会修改该变量，那可以使用const声明for (const i = 0; i &lt; 10; i++) &#123; funcs.push(function()&#123; console.log(i); &#125;) &#125;// 2. for-invar funcs = [];ob = &#123; a: 1, b: 2, c: 3&#125;// 每次迭代不会（像前面for循环的例子一样）修改已有绑定，而是会创建一个新绑定for (const key in ob) &#123; funcs.push(function()&#123; console.log(typeof key); console.log(key); &#125;)&#125;funcs.forEach(function(func)&#123; func();&#125;) 除此上面这些外，const 与 let 没有任何不同。 2.6 块级绑定最佳实践默认使用const，只有确实需要改变变量的值时使用let。因为大部分变量的值在初始化后不应再改变，而预料外的变量值的改变是很多bug的源头。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 ES6 入门开篇]]></title>
    <url>%2F2020%2F08%2F16%2Fweb%2FES6%2Fes6_1%2F</url>
    <content type="text"><![CDATA[好用的 ES6 1. 当下最近这段时间终于沉下心来开始学习前端的知识，经历了三个月找工作的不断打击后，慢慢恢复了平静。今年其实已经看过不少东西了，本来想找找工作给自己点鼓励。不过没关系，我之所以转行到软件不仅仅是因为它能帮助我生活的更好，通过软件真正能做出来一些有意思的东西。 2. 聊聊 JavaScript前面的 JavaScript 系列我们差不多把 JavaScript ES5 的老语法讲完了，个人感觉跟 Python，Go 相比 JavaScript 真算不上一门优雅的语言。大体原因我觉的有一下几个: 标准比内容多，兼容性差: 商业竞争真的是语言设计的绊脚石，各大厂商都想标新立异 在属性的读取和赋值上，JavaScript 可以直接对属性读取和赋值，也提供了众多的属性读取和赋值方法，很混乱 基于原型的面向对象相比类真的是有点绕 当然好的事情已经发生了，如果你看过 ES6 也学过 Python，就会发现 ES6 引入的新语法，都能在 Python 找到类似的踪迹。这些新的语言真的是让我们编写程序越来越简单。 那么这个系列我们就来学习 ES6 的新语法。市面上的书基本上都是通过比较 ES6 与 ES5 的差异来介绍 ES6，这对前端开发的”老鸟们”很友好，但是对于菜鸟新手们么就有点难受。你还得先学 ES5，然后在学 ES6，虽然很多 ES5 的语法已经不用了，但是你还是需要知道，因为历史的遗留你无法撼动。 3. 怎么学 ES6目前为止我已经扫了一遍阮一峰老师的 《ES6 标准入门（第3版）》 书很好推荐大家阅读，唯一的缺点可能就是有点厚。因为最近要赶路飞学城上的课程，所以这个系列我决定选用另一本稍微薄一点书《深入理解ES6》。书的目录就是我们接下来要介绍的内容的大纲。 话不多说，我们就开始这个系列吧。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>ES6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 JavaScript Ajax]]></title>
    <url>%2F2020%2F08%2F15%2Fweb%2FJavaScript%2Fjs_12%2F</url>
    <content type="text"><![CDATA[JavaScript 与 服务器通信 1. AjaxAjax，全称 Asynchronous JavaScript+XML，能够向服务器请求额外的数据而无须卸载页面。Ajax通信与数据格式无关；这种技术就是无须刷新页面即可从服务器取得数据，但不一定是XML数据。 本节我们将介绍 Ajax 的如下实现: XMLHttpRequest: ES5 中 JavaScript 的 http 客户端，能够以异步方式发送请求 CORS Ajax: 跨域资源请求 图片 Ping JSONP Comet: 一种服务器向页面推送数据的技术 SSE: （Server-SentEvents，服务器发送事件）是围绕只读Comet交互推出的API或者模式 这些技术实现的思路大体上都是相似的，通过内置一个新的对象来封装通信的细节，并通过事件触发的方式来实现异步。JavaScript http 请求与异步编程在 ES6 中得到了很大改进，ES5 中的很多计数目前已经很少使用，因此对上面这些技术我们只介绍基本原理不会详解介绍 API 接口。后面 ES6 部分会详细介绍最新的技术。 不过在此之前我们要学习一下 JavaScript 如何处理 JSON 数据，毕竟这是现在主流的数据交换格式。 2.JSON 解析ECMAScript 5对解析JSON的行为进行规范，定义了全局对象JSON。JSON对象有两个方法: stringify(): 把JavaScript对象序列化为JSON字符串和 parse(): 把JSON字符串解析为原生JavaScript值 2.1 JSON.stringifyJSON.stringify(js_obj, filter, indentation) 参数: js_obj: 被序列化的 JavaScript 值 filter: 过滤器，数组或者一个函数 indentation: 是否保留缩进 如果这个参数是一个数值，那它表示的是每个级别缩进的空格数 如果缩进参数是一个字符串而非数值，则这个字符串将在JSON字符串中被用作缩进字符 缩进空格数或字符数最大长度为 10，超过 10 会自动截断为 10 注意: 在序列化JavaScript对象时，所有函数及原型成员都会被有意忽略，不体现在结果中 值为undefined的任何属性也都会被跳过 如果过滤器参数是数组，序列化的结果将只包含数组中列出的属性。如果第二个参数是函数，传入的函数接收两个参数，属性（键）名和属性值。属性名只能是字符串，而在值并非键值对儿结构的值时，键名可以是空字符串。函数返回的值就是相应键的值，如果函数返回了undefined，那么相应的属性会被忽略。 2.2 JSON.parseJSON.parse(json_string, replacer) 参数: json_string: JSON 字符串 replacer: 替换函数，接收两个参数属性名和值 如果还原函数返回undefined，则表示要从结果中删除相应的键 如果返回其他值，则将该值插入到结果中。 注意: 字符串不是有效的JSON，该方法会抛出错误 1var book = JSON.parse('&#123;"name": "中国"&#125;') 2.3 对象 toJSON 方法可以给对象定义toJSON()方法，返回其自身的JSON数据格式。假设把一个对象传入JSON.stringify()，序列化该对象的顺序如下: 如果存在toJSON()方法而且能通过它取得有效的值，则调用该方法。否则，返回对象本身 如果提供了第二个参数，应用这个函数过滤器。传入函数过滤器的值是第(1)步返回的值 对第(2)步返回的每个值进行相应的序列化 如果提供了第三个参数，执行相应的格式化 2. XMLHTTPRequest一个使用 XMLHTTPRequest 发送请求到接受响应的完整示例如下所示: 12345678910var xhr = new XMLHTTPRequest();xhr.open("get", "example.php", false); // 启动请求xhr.overrideMimeType("text/xml"); // 重写XHR响应的MIME类型xhr.setRequestHeader("myHeader", "value"); // 自定义请求头xhr.send(null); // 发送请求xhr.abort(); // abort() 方法用于取消异步请求xhr.getResponseHeader("myHeader"); // 获取响应头信息xhr.getAllResponseHeader(); // 取得一个包含所有头部信息的长字符串 默认情况下，在发送XHR请求的同时，还会发送下列头部信息: Accept：浏览器能够处理的内容类型 Accept-Charset：浏览器能够显示的字符集 Accept-Encoding：浏览器能够处理的压缩编码 Accept-Language：浏览器当前设置的语言 Connection：浏览器与服务器之间连接的类型 Cookie：当前页面设置的任何Cookie Host：发出请求的页面所在的域 Referer：发出请求的页面的URI User-Agent：浏览器的用户代理字符串 在发送请求时: 查询字符串中每个参数的名称和值都必须使用encodeURIComponent()进行编码 使用XHR来模仿表单提交：首先将 Content-Type 头部信息设置为 application/x-www-form-urlencoded 1234xhr.open("post", "postexample.php", false); // 启动请求xhr.setRequestHeader("Content-Type", "application/x-www-form-urlencoded"); // 自定义请求头var form = document.getElementById("form");xhr.send(serialize(form)); // 将页面中表单的数据进行序列化 2.1 请求发送XMLHTTPRequest.open(method, url, async) 作用: 不会真正发送请求，而只是启动一个请求以备发送 参数: method: get/post url: URL相对于执行代码的当前页面 async: 是否以同步方式发送请求，false 以同步方式发送请求 XMLHTTPRequest.send(body) 作用: 发送请求 参数: body: 作为请求主体发送的数据，如果不需要通过请求主体发送数据，则必须传入null(为了浏览器兼容) XMLHTTPRequest.abort(): 作用: 取消异步请求 注意: 调用这个方法后，XHR对象会停止触发事件 也不再允许访问任何与响应有关的对象属性 在终止请求之后，还应该对XHR对象进行解引用操作 由于内存原因，不建议重用XHR对象。 XMLHTTPRequest.setRequestHeader(header, value): 作用: 自定义请求头部 注意: 必须在调用open()方法之后且调用send()方法之前调用setRequestHeader() 2.2 接受响应在收到响应后，响应的数据会自动填充XHR对象的如下属性: responseText：作为响应主体被返回的文本 responseXML：如果响应的内容类型是”text/xml”或”application/xml”，这个属性中将保存包含着响应数据的XML DOM文档 status：响应的HTTP状态 statusText: HTTP状态的说明 在接收到响应后，第一步是检查status属性，以确定响应已经成功返回。 12345if (xhr.status &gt;= 200 &amp;&amp; xhr.status &lt; 300 || xhr.status == 304 )&#123; alter(xhr.responseText);&#125; else &#123; alter("Request unsucess" + xhr.status);&#125; 2.3 表单处理XMLHttpRequest 2级定义了FormData类型为序列化表单以及创建与表单格式相同的数据（用于通过XHR传输）提供了便利。创建了FormData的实例后，可以将它直接传给XHR的send()方法。使用FormData的方便之处体现在不必明确地在XHR对象上设置请求头部。 12345var data = new FormData();data.append("name", "tsong");var data = new FormData(document.forms[0]);xhr.send(data); 2.4 XMLHTTPRequest 异步事件XMLHTTPRequest 包含了如下事件: readystatechange timeout readystatechange异步发送请求时，通过检测 XHR 对象的 readyState 属性，可以判断请求/响应当前活动阶段: 0：未初始化，尚未调用open()方法 1：启动，已经调用open()方法，但尚未调用send()方法 2：发送，已经调用send()方法，但尚未接收到响应 3：接收，已经接收到部分响应数据 4：完成，已经接收到全部响应数据，而且已经可以在客户端使用了 只要readyState属性的值由一个值变成另一个值，都会触发一次readystatechange事件。通常，我们只对readyState值为4的阶段感兴趣，因为这时所有数据都已经就绪。不过，必须在调用open()之前指定onreadystatechange事件处理程序才能确保跨浏览器兼容性。 1234567891011121314var xhr = XMLHTTPRequest();xhr.onreadystatechange = function()&#123; if (xhr.readstatechange == 4)&#123; if (xhr.status &gt;= 200 &amp;&amp; xhr.status &lt; 300 || xhr.status == 304 )&#123; alter(xhr.responseText); &#125; else &#123; alter("Request unsucess" + xhr.status); &#125; &#125;&#125;;xhr.open("get", "example.php", true);xhr.send(null); 这里有两点需要注意的地方: 与其他事件处理程序不同，这里没有向onreadystatechange事件处理程序中传递event对象；必须通过XHR对象本身来确定下一步该怎么做 没有使用this对象，原因是onreadystatechange事件处理程序的作用域问题。如果使用this对象，在有的浏览器中会导致函数执行失败，或者导致错误发生 timeout为XHR对象添加了一个timeout属性，表示请求在等待响应多少毫秒之后就终止。在给timeout设置一个数值后，如果在规定的时间内浏览器还没有接收到响应，那么就会触发timeout事件，进而会调用ontimeout事件处理程序。 123456789101112131415161718192021var xhr = XMLHTTPRequest();xhr.onreadystatechange = function()&#123; if (xhr.readstatechange == 4)&#123; try &#123; if (xhr.status &gt;= 200 &amp;&amp; xhr.status &lt; 300 || xhr.status == 304 )&#123; alter(xhr.responseText); &#125; else &#123; alter("Request unsucess" + xhr.status); &#125; &#125; catch (error) &#123; // &#125; &#125;&#125;;xhr.open("get", "example.php", true);xhr.timeout = 1000;xhr.ontimeout = function()&#123; alter("Request timeout")&#125;;xhr.send(null); 在上面的示例中，如果请求在 1s 内没有返回，就会自动终止。请求终止时，会调用ontimeout事件处理程序。但此时readyState可能已经改变为4了，这意味着会调用onreadystatechange事件处理程序。可是，如果在超时终止请求之后再访问status属性，就会导致错误。为避免浏览器报告错误，可以将检查status属性的语句封装在一个try-catch语句当中。 2.5 进度事件Progress Events 定义了与客户端服务器通信有关的事件。这些事件最早其实只针对XHR操作，但目前也被其他API借鉴。有以下6个进度事件: loadstart：在接收到响应数据的第一个字节时触发 progress： 在接收响应期间持续不断地触发 onprogress事件处理程序会接收到一个event对象，其target属性是XHR对象 target 包含着三个额外的属性：lengthComputable、position和totalSize 为确保正常执行，必须在调用open()方法之前添加onprogress事件处理程序 error：在请求发生错误时触发 abort：在因为调用abort()方法而终止连接时触发 load： 在接收到完整的响应数据时触发 load事件，用以替代 readystatechange 事件 而onload事件处理程序会接收到一个event对象，其target属性就指向XHR对象实例 只要浏览器接收到服务器的响应，不管其状态如何，都会触发load事件。而这意味着你必须要检查status属性 结果是不如直接使用 readystatechange 事件 loadend：在通信完成或者触发error、abort或load事件后触发 3. CORS默认情况下，XHR对象只能访问与包含它的页面位于同一个域中的资源。CORS（Cross-Origin Resource Sharing，跨源资源共享）是W3C的一个工作草案，定义了在必须访问跨源资源时，浏览器与服务器应该如何沟通。CORS背后的基本思想，就是使用自定义的HTTP头部让浏览器与服务器进行沟通，从而决定请求或响应是应该成功，还是应该失败。 大多数浏览器都通过XMLHttpRequest对象实现了对CORS的原生支持。跨域 XHR 有一些安全限制: 不能使用setRequestHeader()设置自定义头部。 不能发送和接收cookie。 调用getAllResponseHeaders()方法总会返回空字符串 在CORS出现以前，要实现跨域Ajax通信颇费一些周折。开发人员想出了一些办法，利用DOM中能够执行跨域请求的功能。 3.1 图片Ping第一种跨域请求技术是使用&lt;img&gt;标签，因为加载图片无须担心跨域问题。通过动态地创建图像，使用它们的onload和onerror事件处理程序来确定是否接收到了响应。 图像Ping是与服务器进行简单、单向的跨域通信的一种方式。请求的数据是通过查询字符串形式发送的，而响应可以是任意内容，但通常是像素图或204响应。通过图像Ping，浏览器得不到任何具体的数据，但通过侦听load和error事件，它能知道响应是什么时候接收到的。图像Ping最常用于跟踪用户点击页面或动态广告曝光次数。 3.2 JSONPJSONP由两部分组成：回调函数和数据。回调函数是当响应到来时应该在页面中调用的函数。回调函数的名字一般是在请求中指定的。而数据就是传入回调函数中的JSON数据。下面是一个典型的JSONP请求。 1http://tst.com/json/?callback=handlRes JSONP是通过动态&lt;script&gt;元素来使用的，使用时可以为src属性指定一个跨域URL。这里的&lt;script&gt;元素与&lt;img&gt;元素类似，都有能力不受限制地从其他域加载资源。因为JSONP是有效的JavaScript代码，所以在请求完成后，即在JSONP响应加载到页面中以后，就会立即执行。 123456function handleRes(response)&#123; return respose.ip;&#125;var script = document.createElement("script");script.scr = "http://tst.com/json/?callback=handlRes";document.body.insertBefore(script, document.body.firstChild); 4. CometAjax是一种从页面向服务器请求数据的技术，而Comet则是一种服务器向页面推送数据的技术。有两种实现Comet的方式：长轮询和流： 短轮询: 浏览器定时向服务器发送请求，看有没有更新的数据 长轮询: 页面发起一个到服务器的请求，然后服务器一直保持连接打开，直到有数据可发送。发送完数据之后，浏览器关闭连接，随即又发起一个到服务器的新请求 短轮询是服务器立即发送响应，无论数据是否有效，而长轮询是等待发送响应。 轮询的优势是所有浏览器都支持，因为使用XHR对象和setTimeout()就能实现 HTTP流: 流不同于上述两种轮询，因为它在页面的整个生命周期内只使用一个HTTP连接 具体来说，就是浏览器向服务器发送一个请求，而服务器保持连接打开，然后周期性地向浏览器发送数据 通过侦听readystatechange事件及检测readyState的值是否为3，就可以利用XHR对象实现HTTP流 当readyState值变为3时，responseText属性中就会保存接收到的所有数据 5. SSESSE API用于创建到服务器的单向连接: 服务器通过这个连接可以发送任意数量的数据 服务器响应的MIME类型必须是text/event-stream，而且是浏览器中的JavaScript API能解析格式输出 SSE支持短轮询、长轮询和HTTP流，而且能在断开连接时自动确定何时重新连接 有了这么简单实用的API，再实现Comet就容易多了。 5.1 SSE API要预订新的事件流，首先要创建一个新的EventSource对象，并传进一个入口点: 12345// 传入的URL必须与创建对象的页面同var source = New EventSource("example.php");source.onmessage = function(event)&#123; // 接收数据 var data = event.data;&#125;; EventSource对象会保持与服务器的活动连接。如果连接断开，还会重新连接。EventSource的实例有一个readyState属性，值为0表示正连接到服务器，值为1表示打开了连接，值为2表示关闭了连接。另外，还有以下三个事件: open：在建立连接时触发 message：在从服务器接收到新事件时触发 error：在无法建立连接时触发 6. WebSocketWeb Sockets的目标是在一个单独的持久连接上提供全双工、双向通信。在JavaScript中创建了Web Socket之后，会有一个HTTP请求发送到浏览器以发起连接。在取得服务器响应后，建立的连接会使用HTTP升级从HTTP协议交换为WebSocket协议。也就是说，使用标准的HTTP服务器无法实现WebSockets，只有支持这种协议的专门服务器才能正常工作。 Web Sockets 使用的协议是 ws:// 和 wss://(加密)。使用自定义协议而非HTTP协议的好处是，能够在客户端和服务器之间发送非常少量的数据，而不必担心HTTP那样字节级的开销。 6.1 WebSocket API要创建Web Socket，先实例一个WebSocket对象并传入要连接的URL： 12345678var socket = new WebSocket("ws://www.example.com/server.php");socket.close();socket.send("hello"); // 发送数据// 必须使用DOM 0级语法分别定义每个事件处理程序socket.onmessage = function(event)&#123; // 通过 message 事件接收数据 var data = event.data&#125;; 必须给WebSocket构造函数传入绝对URL。同源策略对Web Sockets不适用，因此可以通过它打开到任何站点的连接。WebSocket也有一个表示当前状态的readyState属性: WebSocket.OPENING (0)：正在建立连接 WebSocket.OPEN (1)：已经建立连接 WebSocket.CLOSING (2)：正在关闭连接 WebSocket.CLOSE (3)：已经关闭连接 WebSocket没有readystatechange事件；不过，它有其他事件，对应着不同的状态: 当服务器向客户端发来消息时，WebSocket对象就会触发message事件，数据保存在 event.data 中 open：在成功建立连接时触发 error：在发生错误时触发，连接不能持续 close：在连接关闭时触发 close事件的event对象有额外的信息 open,error,close 的事件对象有三个额外的属性：wasClean、code和reason: wasClean是一个布尔值，表示连接是否已经明确地关闭； code是服务器返回的数值状态码 reason是一个字符串，包含服务器发回的消息 在考虑是使用SSE还是使用Web Sockets时，可以考虑如下几个因素: 是否有自由度建立和维护Web Sockets服务器，SSE通过常规HTTP通信，因此现有服务器就可以满足需求 到底需不需要双向通信，只需读取服务器数据（如比赛成绩），那么SSE比较容易实现]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 JavaScript 表单处理]]></title>
    <url>%2F2020%2F08%2F14%2Fweb%2FJavaScript%2Fjs_11%2F</url>
    <content type="text"><![CDATA[使用 JavaScript 操作表单 1. 表单的 JavaScript 对象1.1 HTMLFormElement在HTML中，表单是由 &lt;form&gt; 元素来表示的，而在JavaScript中，表单对应的则是HTMLForm-Element类型。 HTMLFormElement 继承了HTMLElement，除了默认属性外 HTMLFormElement 还有下面独有的属性和方法: acceptCharset：服务器能够处理的字符集；等价于HTML中的accept-charset特性 action：接受请求的URL；等价于HTML中的action特性 elements：表单中所有控件的集合（HTMLCollection） enctype：请求的编码类型；等价于HTML中的enctype特性 length：表单中控件的数量 method：要发送的HTTP请求类型，通常是”get”或”post”；等价于HTML的method特性 name：表单的名称；等价于HTML的name特性 reset()：将所有表单域重置为默认值 submit()：提交表单 target：用于发送请求和接收响应的窗口名称；等价于HTML的target特性 1.2 表单对象获取取得 &lt;form&gt; 元素引用的方式有好几种: 为其添加id特性，并使用 document.getElementById()方法 document.forms可以取得页面中所有的表单，并使用数值或者 name 值进行索引 1.3 表单提交通过提交按钮提交像下面这样使用&lt;input&gt;或&lt;button&gt;可以定义提交按钮，用户点击提交按钮就会提交表单。 12345678910&lt; !-- 只要表单中存在上面列出的任何一种按钮，那么在相应表单控件拥有焦点的情况下，按回车键就可以提交该表单 --&gt;&lt; !-- 如果表单里没有提交按钮，按回车键不会提交表单 -- &gt;&lt;! -- 通用提交按钮-- &gt;&lt;input type="submit" value="Submit Button"&gt;&lt;! -- 自定义按钮 -- &gt;&lt;button type="submit"&gt;Submit&lt;/button&gt;&lt;! -- 图像按钮-- &gt;&lt;input type="image" src="a.gif"&gt; 以这种方式提交表单时，浏览器会在将请求发送给服务器之前触发submit事件。这样，我们就有机会验证表单数据，并据以决定是否允许表单提交。阻止这个事件的默认行为就可以取消表单提交。 1234567var form = document.getElementById("myForm");var handler = function(event)&#123; // 验证表单逻辑 // 验证失败阻止表单提交 event.preventDefault()&#125;;form.addEventListener("submit", handler, false); 通过 JavaScript 直接提交在JavaScript中，以编程方式调用submit()方法也可以提交表单。这种方式无需表单包含提交按钮，任何时候都可以正常提交表单。此时不会触发submit事件，在调用此方法之前先验证表单数据。 1.4 表单重置表单重置的逻辑与表单提交类似，可以创建重置按钮，也可以在 JavaScript 调用表单对象的 reset() 方法重置。用户单击重置按钮重置表单时，会触发reset事件。但是与调用submit()方法不同，调用reset()方法会像单击重置按钮一样触发reset事件。重置表单通常很少使用。 12&lt;input type="reset" value="reset button"&gt;&lt;button type="reset"&gt;reset button&lt;/button&gt; 2. 表单字段可以像访问页面中的其他元素一样，使用原生DOM方法访问表单元素。此外每个表单都有elements属性: elements 属性是表单中所有表单元素（字段）的集合 elements 集合是一个有序列表，其中包含着表单中的所有字段，表单字段在elements集合中的顺序，与它们出现在标记中的顺序相同 可以按照位置和name特性对表单字段进行索引 也可以通过访问表单的属性来访问元素(位置索引或name特性)。这些属性与通过elements集合访问到的元素是相同的。但是应该尽可能使用elements，通过表单属性访问元素只是为了与旧浏览器向后兼容而保留的一种过渡方式 1234var form = document.getElementById("myForm");var field1 = form.elements[0];var field2 = form.elements["color"];var c = form.elements.length; 如果有多个表单控件都在使用一个name（如单选按钮），那么就会返回以该name命名的一个NodeList，不过位置索引永远是只返回一个表单字段。 1234567891011121314&lt;form method="post" id="myForm"&gt; &lt;ul&gt; &lt;li&gt;&lt;input type="radio" name="color" value="red"&gt;Red&lt;/li&gt; &lt;li&gt;&lt;input type="radio" name="color" value="blue"&gt;Blue&lt;/li&gt; &lt;li&gt;&lt;input type="radio" name="color" value="black"&gt;Black&lt;/li&gt; &lt;ul&gt;&lt;/form&gt;&lt;script&gt; var form = document.getElementById("myForm"); var colorF = form.elements['color']; alter(colorF.length); // 3 alter(form.elements[0] === colorF[0]); // true&lt;/script&gt; 2.1 共有的表单字段属性除了元素之外，所有表单字段都拥有相同的一组属性: disabled：布尔值，表示当前字段是否被禁用 form：指向当前字段所属表单的指针；只读 name：当前字段的名称 readOnly：布尔值，表示当前字段是否只读 tabIndex：表示当前字段的切换（tab）序号 type：当前字段的类型，如”checkbox”、”radio”，等等 value：当前字段将被提交给服务器的值。对文件字段来说，这个属性是只读的，包含着文件在计算机中的路径 除了form属性之外，可以通过JavaScript动态修改任何属性。常用的场景是在提交后禁用表单避免重复提交。注意最好是通过submit事件来禁用提交按钮，不能通过onclick事件处理程序来实现这个功能，原因是不同浏览器之间存在“时差”：有的浏览器会在触发表单的submit事件之前触发click事件，此时永远都不会提交表单。 2.2 共有的表单字段方法每个表单字段都有两个方法： focus(): 用于将浏览器的焦点设置到表单字段 如果表单的 type值为”hidden”或者使用CSS的display和visibility属性隐藏了该字段，调用此方法都会报错 HTML5为表单字段新增了一个autofocus属性。在支持这个属性的浏览器中，只要设置这个属性，不用JavaScript就能自动把焦点移动到相应字段 blur()： 从元素中移走焦点 1&lt;input type="text" autofocus&gt; 2.3 共有的表单字段事件除了支持鼠标、键盘、更改和HTML事件之外，所有表单字段都支持下列3个事件 blur：当前字段失去焦点时触发 change： 对于&lt;input&gt;和&lt;textarea&gt;元素，在它们失去焦点且value值改变时触发 对于&lt;select&gt;元素，在其选项改变时触发(不失去焦点也会触发change事件) focus：当前字段获得焦点时触发 当用户改变了当前字段的焦点，或者我们调用了blur()或focus()方法时，都可以触发blur和focus事件。这两个事件在所有表单字段中都是相同的。但是，change事件在不同表单控件中触发的次数会有所不同。 change事件则经常用于验证用户在字段中输入的数据。关于blur和change事件的关系，并没有严格的规定。为此，不能假定这两个事件总会以某种顺序依次触发。下面是一段验证用户在文本框中是否输入的是数值的逻辑，如果不是数值进行提示: 1234567891011121314151617181920212223242526var textbox = document.forms[0].elements[0];textbox.addEventListener("focus", function(event)&#123; var target = event.target; if (target.style.backgroundColor != "red")&#123; target.style.backgroundColor = "yellow"; &#125; &#125;, false);textbox.addEventListener("blur", function(event)&#123; var target = event.target; if (/[^\d]/.test(target.value))&#123; target.style.backgroundColor = "red"; &#125; else &#123; target.style.backgroundColor = ""; &#125;&#125;, false);textbox.addEventListener("change", function(event)&#123; var target = event.target; if (/[^\d]/.test(target.value))&#123; target.style.backgroundColor = "red"; &#125; else &#123; target.style.backgroundColor = ""; &#125;&#125;, false);]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 JavaScript 事件]]></title>
    <url>%2F2020%2F08%2F13%2Fweb%2FJavaScript%2Fjs_10%2F</url>
    <content type="text"><![CDATA[JavaScript与HTML之间的交互是通过事件实现的。事件，就是文档或浏览器窗口中发生的一些特定的交互瞬间。 1. 事件以及事件处理流程事件就是用户或浏览器自身执行的某种动作。而响应某个事件的函数就叫做事件处理程序（或事件侦听器）。类似设计模式里的观察者模式，支持页面的行为（JavaScript代码）与页面的外观（HTML和CSS代码）之间的松散耦合。 1.1 事件流事件流描述的是从页面中接收事件的顺序。 事件流有两种完全相反的实现: 事件冒泡: 即事件开始时由最具体的元素（文档中嵌套层次最深的那个节点）接收，然后逐级向上传播到较为不具体的节点 事件捕获: 事件捕获的思想是不太具体的节点应该更早接收到事件，而最具体的节点应该最后接收到事件 事件捕获的用意在于在事件到达预定目标之前捕获它 由于老版本的浏览器不支持，因此很少有人使用事件捕获。可以放心地使用事件冒泡，在有特殊需要时再使用事件捕获。尽管“DOM2级事件”规范要求事件应该从document对象开始传播，但大多数浏览器都是从window对象开始捕获事件的。 事件流的阶段划分“DOM2级事件”规定的事件流包括三个阶段：事件捕获阶段、处于目标阶段和事件冒泡阶段 2. 事件处理程序为事件指定处理程序的方式有好几种。 2.1 HTML事件处理程序某个元素支持的每种事件，都可以使用一个与相应事件处理程序同名的HTML特性来指定。 1&lt;input type="button" value="Click" onclick="alter('click')"&gt; 事件处理程序中的代码在执行时，有权访问全局作用域中的任何代码。这样指定事件处理程序具有一些独到之处。首先，这样会动态创建一个封装着元素属性值的函数。这个函数使用with像下面这样扩展作用域： 123456789function ()&#123; with(documnet)&#123; with(this.form)&#123; // 如果当前元素是一个表单输入元素 with(this)&#123; // 元素属性值 &#125; &#125; &#125;&#125; 因此，在函数内部: 存在一个局部变量event，也就是事件对象，通过event变量，可以直接访问事件对象 this值等于事件的目标元素 可以像访问局部变量一样访问document及该元素本身的成员 如果当前元素是一个表单输入元素，则作用域中还会包含访问表单元素（父元素）的入口 1234&lt;form method="post"&gt; &lt;input type="text" name="username" value=""&gt; &lt;input type="button" value="Echo Username" onclick="alter(username.value)"&gt;&lt;/form&gt; HTML事件处理程序的缺点HTML事件处理程序有如下的缺点，导致开发人员更倾向于使用JavaScript指定事件处理程序: 这样扩展事件处理程序的作用域链在不同浏览器中会导致不同结果。不同JavaScript引擎遵循的标识符解析规则略有差异，很可能会在访问非限定对象成员时出错。 存在一个时差问题。因为用户可能会在HTML元素一出现在页面上就触发相应的事件，但当时的事件处理程序有可能尚不具备执行条件。为此，很多HTML事件处理程序都会被封装在一个try-catch块中，以便错误不会浮出水面 HTML指定事件处理程序的最后一个缺点是HTML与JavaScript代码紧密耦合 2.2 DOM0 级事件处理程序通过JavaScript指定事件处理程序的传统方式，就是将一个函数赋值给一个事件处理程序属性。每个元素（包括window和document）都有自己的事件处理程序属性，这些属性通常全部小写，例如onclick。将这种属性的值设置为一个函数，就可以指定事件处理程序，如下所示： 123456var btn = document.getElementById("myBtn");btn.onclick = function()&#123; alter("click");&#125;;btn.onclick = null // 删除事件处理程序 以这种方式指定的事件处理程序是在元素的作用域中运行；换句话说，程序中的this引用当前元素。this访问元素的任何属性和方法。以这种方式添加的事件处理程序会在事件流的冒泡阶段被处理。但要注意，在这些代码运行以前不会指定事件处理程序，因此如果这些代码在页面中位于按钮后面，就有可能在一段时间内怎么单击都没有反应。 如果你使用HTML指定事件处理程序，那么onclick属性的值就是一个包含着在同名HTML特性中指定的代码的函数。而将相应的属性设置为null，也可以删除以这种方式指定的事件处理程序。 DOM0 级事件处理程序的缺点是不能给同一个元素绑定多个相同的事件处理程序。 2.3 DOM2 级事件处理程序“DOM2级事件”定义了两个方法，用于处理指定和删除事件处理程序的操作：addEventListener()和removeEventListener()。所有DOM节点中都包含这两个方法，并且它们都接受3个参数：要处理的事件名、作为事件处理程序的函数和一个布尔值。最后这个布尔值参数如果是true，表示在捕获阶段调用事件处理程序；如果是false，表示在冒泡阶段调用事件处理程序。 123456789var btn = document.getElementById("myBtn");var btnClick = function()&#123; alter("click");&#125;;btn.addEventListener("click", btnClick, false);btn.removeEventListener("click", btnClick, false) // 删除事件处理程序 与DOM0级方法一样，这里添加的事件处理程序也是在其依附的元素的作用域中运行。使用DOM2级方法添加事件处理程序的主要好处是可以添加多个事件处理程序。 使用removeEventListener()来移除事件处理程序，移除时传入的参数与添加处理程序时使用的参数相同。这也意味着通过addEventListener()添加的匿名函数将无法移除。 2.4 事件处理程序移除内存中过时不用的“空事件处理程序”（dangling event handler），是造成Web应用程序内存与性能问题的主要原因。有两种情况会出现过时不用的”空事件处理程序”: 第一种情况就是从文档中移除带有事件处理程序的元素时，包括: 使用removeChild()和replaceChild()方法 使用innerHTML替换页面中某一部分 卸载页面，如果在页面被卸载之前没有清理干净事件处理程序，那它们就会滞留在内存中 移除元素12345678910&lt;div id="myDiv"&gt; &lt;input type="button" value="Click" id="myBtn"&gt;&lt;/div&gt;&lt;script&gt; var btn = document.getElementById("myBtn"); btn.onclick = function()&#123; // btn.onclick = null; document.getElementById("myDiv").innerHtml = "Process"； &#125;;&lt;/script&gt; 在上面的示例中，btn.onclick 的时间处理函数与 btn 对应的 myBtn 标签仍处于相互引用状态，有些浏览器很有可能会将对元素和对事件处理程序的引用都保存在内存中。最好手工移除事件处理程序 btn.onclick = null; 卸载页面对于一般来说，最好的做法是在页面卸载之前，先通过onunload事件处理程序移除所有事件处理程序。只要是通过onload事件处理程序添加的东西，最后都要通过onunload事件处理程序将它们移除。 2.5 事件绑定的兼容写法由于 ie8 浏览器不支持 addEventListener/removeEventListener 方法,对应的方法为 attachEvent/detachEvent，并且其事件处理函数中 this 的绑定的是 window 而不是事件源对象，因此我们需要为事件绑定进行兼容。兼容的代码如下: 12345678910111213function addEvent(target, eventType, handler)&#123; // target 表示绑定事件的 HTMLElement // eventType 表示事件类型 // handler 表示检出处理函数 if (target.addEventListener)&#123; target.addEventListener(eventType, handler, false); &#125; else &#123; // handler.call 用于解决 this 指向问题 target.attachEvent('on' + eventType, function()&#123; handler.call(target); &#125;) &#125;&#125; 3. 事件对象3.1 定义在触发DOM上的某个事件时，会产生一个事件对象event，这个对象中包含着所有与事件有关的信息。包括导致事件的元素、事件的类型以及其他与特定事件相关的信息。兼容DOM的浏览器会将一个event对象传入到事件处理程序中。在通过HTML特性指定事件处理程序时，变量event中保存着event对象(注: 对于大多数浏览器也同样是这样，window.event 保存着事件对象，可直接使用 event 变量。) 123456789101112var btn = document.getElementById("myBtn");var btnClick = function(event)&#123; alter(event.type);&#125;;btn.addEventListener("click", btnClick, false);// 兼容获取 event 对象的写法function handler(e)&#123; e = e || window.event;&#125; 3.2 事件对象属性和方法event对象包含与创建它的特定事件有关的属性和方法。事件类型不一样，可用的属性和方法也不一样。不过，所有事件都会有下表列出的成员。 在事件处理程序内部，对象this始终等于currentTarget的值，而target则只包含事件的实际目标。如果直接将事件处理程序指定给了目标元素，则this、currentTarget和target包含相同的值。如果事件处理程序存在于按钮的父节点中（例如document.body），那么这些值是不相同的。 currentTarget: 返回事件绑定的节点 target/srcElement: 返回事件的实际目标对象 this: 始终等于currentTarget 12345document.body.onclick = function(event)&#123; alter(event.currentTarget === document.body); //true alter(this === document.body); // true alter(event.target === document.getElementById("myBtn")); // true&#125; 下面是一些特殊属性的用途: 在需要通过一个函数处理多个事件时，可以使用type属性 只有cancelable属性设置为true的事件，才可以使用preventDefault()来取消其默认行为 stopPropagation()方法用于立即停止事件在DOM层次中的传播，即取消进一步的事件捕获或冒泡 事件对象的eventPhase属性，可以用来确定事件当前正位于事件流的哪个阶段 1: 捕获阶段调用的事件处理程序 2: 事件处理程序处于目标对象上 3: 在冒泡阶段调用的事件处理程序 注意，在事件处理程序中删除按钮也能阻止事件冒泡。目标元素在文档中是事件冒泡的前提。最后只有在事件处理程序执行期间，event对象才会存在；一旦事件处理程序执行完成，event对象就会被销毁。 下面我们来一一介绍这些属性的作用: 阻止事件冒泡与事件冒泡相关的有四个属性: bubbles: 表示当前事件是否会冒泡，只读 大部分事件都会冒泡，但是 focus，blur，scroll 事件不会冒泡 cancelBubble: 可读写，默认为 false，设置 true 用于阻止事件冒泡 stopPropagation(): 取消事件的进一步冒泡，无返回值 但是无法阻止同一事件的其他监听函数调用 stopImmediatePropagation(): 既可以阻止进一步冒泡，也可以阻止同一事件的其他监听函数调用 123456789// 阻止事件冒泡的兼容写法var handle = function()&#123; e = e || window.event; if (e.stopPropagation)&#123; e.stopPropagation(); &#125; else&#123; e.cancelBubble = true; &#125;&#125; 取消默认事件对于 a 标签，form 标签我们可以像下面这样阻止其默认事件:12&lt;a href="javascript:void(0)"&gt;&lt;/a&gt;&lt;a href="javascript:"&gt;&lt;/a&gt; 除此之外 event 上的如下属性也可以用于取消标签的默认事件: preventDefault(): 用于阻止默认事件 returnValue: 默认为 true，改为 false 可阻止默认事件 在事件监听函数中直接 return false 123456789101112131415var handle = function()&#123; e = e || window.event; e.preventDefault(); // 方法一 e.returnValue = false; // 方法二 return false // 方法三&#125;// 兼容写法var handle = function()&#123; e = e || window.event; if (e.preventDefault)&#123; e.preventDefault(); &#125; else &#123; e.returnValue = false; &#125; 4. 事件类型“DOM3级事件”规定了以下几类事件: UI（User Interface，用户界面）事件，当用户与页面上的元素交互时触发； 焦点事件，当元素获得或失去焦点时触发； 鼠标事件，当用户通过鼠标在页面上执行操作时触发； 滚轮事件，当使用鼠标滚轮（或类似设备）时触发； 文本事件，当在文档中输入文本时触发； 键盘事件，当用户通过键盘在页面上执行操作时触发； 合成事件，当为IME（Input Method Editor，输入法编辑器）输入字符时触发； 变动（mutation）事件，当底层DOM结构发生变化时触发 HTML5详尽列出了浏览器应该支持的所有事件 常用的事件有如下这些: 事件 说明 load 当页面完全卸载后在window上面触发，当所有框架都卸载后在框架集上面触发当图像加载完毕时在元素上面触发 unload 当页面完全卸载后在window上面触发，当所有框架都卸载后在框架集上面触发只要用户从一个页面切换到另一个页面，就会发生unload事件利用这个事件最多的情况是清除引用，以避免内存泄漏。 error 当发生JavaScript错误时在window上面触发，当无法加载图像时在元素上面触发，当无法加载嵌入内容时在元素上面触发，或者当有一或多个框架无法加载时在框架集上面触发 resize 当窗口或框架的大小变化时在window或框架上面触发 select 当用户选择文本框（&lt;input&gt;或&lt;texterea&gt;）中的一或多个字符时触发 focus 元素获取焦点时触发，这个事件不会冒泡 blur 元素失去焦点时触发，这个事件不会冒泡 click 在用户单击主鼠标按钮（一般是左边的按钮）或者按下回车键时触发 dblclick 在用户双击主鼠标按钮（一般是左边的按钮）时触发 mousedown 在用户按下了任意鼠标按钮时触发 mouseup 在用户释放鼠标按钮时触发 mouseover 鼠标指针首次移入另一个元素边界之内时触发 mouseout 鼠标移出元素时触发 4.1 鼠标事件鼠标事件都是在浏览器视口中的特定位置上发生的。因此通过鼠标事件上的各种属性我们可以获取鼠标的位置，这些位置包括: 客户区鼠标位置 页面鼠标位置 屏幕鼠标位置 相对目标元素的鼠标位置 客户区坐标位置客户区位置保存在 clientX/clientY 或者 x/y 属性中，表示鼠标指针在视口中的水平和垂直坐标 页面鼠标位置页面鼠标位置保存在 pageX/pageY 中，表示鼠标光标在页面中的位置，因此坐标是从页面本身而非视口的左边和顶边计算的(因为页面可能滚动)。 屏幕鼠标位置屏幕鼠标位置保存在 screenX/screenY 中，表示相对于整个电脑屏幕的位置。 相对目标元素的鼠标位置offsetX/offsetY 属性表示鼠标相对于事件源标签的位置 5. 事件委托过多的添加事件处理函数会导致性能问题: 每个函数都是对象，都会占用内存；内存中的对象越多，性能就越差 必须事先指定所有事件处理程序而导致的DOM访问次数，会延迟整个页面的交互就绪时间 事件委托就是为了解决事件处理程序过多的问题。事件委托利用了事件冒泡，只指定一个事件处理程序，就可以管理某一类型的所有事件。用事件委托，只需在DOM树中尽量最高的层次上添加一个事件处理程序。 1234567891011121314151617181920212223var list = document.getElementById("myLinks");var handler = function(event)&#123; target = envent.target; switch (target.id)&#123; case "doSomething": // 某一个按钮的处理逻辑 break; case "sayHi": alter("say hi"); break; &#125;&#125;;list.addEventListener("click", handler, false);// 事件委托的兼容处理btn.onclick = function(e) &#123; // event 事件对象兼容 e = e || window.event // target 与 srcElement 作用相同，不同浏览器支持不一样 var target = e.target || e.srcElement;&#125; 最适合采用事件委托技术的事件包括click、mousedown、mouseup、keydown、keyup和keypress。 6. 错误事件捕获任何没有通过try-catch处理的错误都会触发window对象的error事件(只要发生错误，无论是不是浏览器生成的)。在任何Web浏览器中，onerror事件处理程序都不会创建event对象，但它可以接收三个参数：错误消息、错误所在的URL和行号。要指定onerror事件处理程序，必须使用如下所示的DOM0级技术，它没有遵循“DOM2级事件”的标准格式。 123window.error = function(message, url, line)&#123; return false; // &#125; 通过在 error 事件处理函数内返回 false，可以阻止浏览器报告错误的默认行为。返回false，这个函数实际上就充当了整个文档中的try-catch语句。理想情况下，只要可能就不应该使用它。只要能够适当地使用try-catch语句。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 JavaScript DOM]]></title>
    <url>%2F2020%2F08%2F12%2Fweb%2FJavaScript%2Fjs_9%2F</url>
    <content type="text"><![CDATA[JavaScript 的文档对象模型 DOM。 1. DOM 对象模型简介HTML 文档在浏览器加载后会成为一颗 DOM 树供 JavaScript 使用(通过 document 对象访问)。树中节点按照在 HTML 中不同部分分成: 文档节点: 文档的根节点，即 document 元素节点: HTML 元素标签 特性节点: HTML 标签的特性 attribute 文本节点: HTML 标签内的文本 注释节点: HTML 注释信息 总共 12 个节点类型，这些都类型都继承自一个基类型 Node。DOM 提供了众多的属性和方法来设置标签，并通过树特有的家谱定位方式(父节点，子节点…)提供了查找节点的方法。DOM 标准就是定义了不同DOM节点包含的属性和方法，接下来我们会就常用的部分一一介绍。 123 NodeHTMLDocument HTMLElement Text Comment 2.NodeNode 在继承关系中相当于所有节点的基类，它在 DOM1级定义 2.1 Node 提供的属性Node 基类提供了如下的属性用于获取节点信息和节点的关联节点: 属性 返回值 nodeType 节点类型 nodeName 节点名称 nodeValue 节点包含值 childNodes 返回一个类数组的 NodeList 对象包含了节点包含的所有直接子节点 parentNode 节点的父节点 previousSibling 上一个同胞节点 nextSibling 下一个同胞节点 firstChild childNodes列表中的第一个 lastChild childNodes列表中的最后一个节点 ownerDocument 指向表示整个文档的文档节点 hasChildNodes() 在节点包含一或多个子节点的情况下返回true 需要注意的是虽然所有节点类型都继承自Node，但并不是每种节点都有子节点。 nodeName，nodeValuenodeName，nodeValue 属性依节点类型返回不同值，对应关系如下: nodeType nodeName nodeValue Node.ELEMENT_NODE(1) 元素标签名 null Node.ATTRIBUTE_NODE(2) NodeTEXT_NODE(3) #text 文本值 Node.CDATA_SECTION_NODE(4) Node.ENTITY_REFERENCE_NODE(5) Node.ENTITY_NODE(6) Node.PROCESSING_INSTRUCTION_NODE(7) Node.COMMENT_NODE(8) #comment 注释内容 Node.DOCUMENT_NODE(9) #document null Node.DOCUMENT_TYPE_NODE(10) doctype名称 null Node.DOCUMENT_FRAGMENT_NODE(11) Node.NOTATION_NODE(12 NodeListnode.childNodes 返回的 NodeList 是一个类数组对象，支持方括号语法索引节点。NodeList对象的独特之处在于，它实际上是基于DOM结构动态执行查询的结果，因此DOM结构的变化能够自动反映在NodeList对象中，而不是一次访问时的快照。 1234var firstChild = someNode.childNodes[0]var secondChild = someNode.childNodes.item(1)var count = someNode.childNodes.lengthvar arrayOfNode = Array.prototype.slice.call(someNode.childNodes, 0) 2.2 Node 提供的方法Node 基类提供了如下的方法用于操作节点包含的子节点。 方法 作用 返回值 appendChild(node) 在节点尾部添加子节点 返回追加的节点 insertBefore(node, baseNode) 将节点插入到baseNode(参照节点)前 插入的节点 replaceChild(node, replaceNode) 替换节点 removeChild(node) 移除节点 返回移除的节点 cloneNode(bool) 创建节点的副本，参数表示是否深复制true 表示深复制，即复制节点及其整个子节点树false，执行浅复制，即只复制节点本身 appendChild最常用的方法是appendChild()，用于向childNodes列表的末尾添加一个节点。添加节点后，childNodes的新增节点、父节点及以前的最后一个子节点的关系指针都会相应地得到更新。如果传入到appendChild()中的节点已经是文档的一部分了，那结果就是将该节点从原来的位置转移到新位置 insertBeforeinsertBefore 接受两个参数：要插入的节点和作为参照的节点。如果参照节点是null，则insertBefore()与appendChild()执行相同的操作。 replaceChild,removeChildreplaceChild()，removeChild()移除的节点仍然为文档所有，只不过在文档中已经没有了自己的位置。 前面介绍的四个方法操作的都是某个节点的子节点，也就是说，要使用这几个方法必须先取得父节点（使用parentNode属性）。另外，并不是所有类型的节点都有子节点，如果在不支持子节点的节点上调用了这些方法，将会导致错误发生。 cloneChildcloneChild 复制后返回的节点副本属于文档所有，但并没有为它指定父节点。因此，这个节点副本就成为了一个“孤儿”，除非通过appendChild()、insertBefore()或replaceChild()将它添加到文档中. 接下来我们来一一介绍常见的具体 DOM 节点类型。 3. Document 节点JavaScript通过Document类型表示文档。在浏览器中，document对象是 HTMLDocument （继承自Document类型）的一个实例，表示整个HTML页面。而且，document对象是window对象的一个属性，因此可以将其作为全局对象来访问。 Document节点的子节点可以是DocumentType、Element、ProcessingIn-struction或Comment。DocumentType 用于特殊表示 &lt;! DOCTYPE&gt;标签。 3.1 document 的属性 属性 返回值 documentElement 指向&lt;html&gt;元素 body 指向&lt;body&gt;元素 doctype 指向&lt;! DOCTYPE&gt;标签元素 title 包含着&lt;title&gt;元素中的文本，修改title属性的值会改变&lt;title&gt;元素 URL 页面完整的URL domain 页面的域名 referrer 页面跳转前的URL anchors 包含文档中所有带name特性的&lt;a&gt;元素 forms 包含文档中所有的&lt;form&gt;元素 images 包含文档中所有的&lt;img&gt;元素 links 包含文档中所有带href特性的&lt;a&gt;元素 3.2 document 节点查找document 下列方法提供了索引 DOM 树节点的方法: 方法 作用 返回值 getElementById(id) 通过标签 id 查找元素节点 元素节点 getElementsByTagName(tag) 通过标签名查找元素节点 NodeList getElementByName(name) 返回带有给定name特性的所有元素 HTMLCollection getElementsByTagNamegetElementsByTagName 返回的是包含零或多个元素的NodeList。在HTML文档中，这个方法会返回一个HTMLCollection对象，作为一个“动态”集合，该对象与NodeList非常类似。 HTMLCollection 对象还有一个方法，叫做namedItem()，使用这个方法可以通过元素的name特性取得集合中的项。对命名的项也可以使用方括号语法来访问 123var images = document.getElementByTagName("img");var myImage = images.namedItem("myImage");var myImage = images["myImage"]; 对HTMLCollection而言，我们可以向方括号中传入数值或字符串形式的索引值。在后台，对数值索引就会调用item()，而对字符串索引就会调用namedItem()。 3.3 document 文档写入document 下列方法提供了将输出流写入到网页中的能力: write()、writeln(): 接受一个字符串参数，即要写入到输出流中的文本 write()会原样写入，而writeln()则会在字符串的末尾添加一个换行符（\n） 还可以使用write()和writeln()方法动态地包含外部资源 在页面被呈现的过程中 document.write() 将直接向其中输出了内容 如果在文档加载结束后再调用document.write()，那么输出的内容将会重写整个页面 open()和close(): 分别用于打开和关闭网页的输出流 1234567// 字符串"&lt;/script&gt;"将被解释为与外部的&lt;script&gt;标签匹配，结果文本"，需要转义document.write("&lt;script type=\"\text/javascript" scr=\"file.js\"&gt;" + "&lt;\/script&gt;");// 到页面完全加载之后延迟执行的 document.write 将重写整个页面window.onload = function()&#123; document.write("hello world")&#125; 3.4 document 节点创建document.createElement()方法可以创建新元素节点。这个方法只接受一个参数，即要创建元素的标签名。这个标签名在HTML文档中不区分大小写。要把新元素添加到文档树，可以使用appendChild()、inser-tBefore()或replaceChild()方法。 1div = document.createElement("div"); document.createTextNode()可以创建新文本节点，这个方法接受一个参数——要插入节点中的文本 4. Element 节点Element类型用于表现XML或HTML元素，提供了对元素标签名、子节点及特性的访问。HTML元素所有HTML元素都由HTMLElement类型表示，HTMLElement 类型直接继承自Element并添加了一些属性。 所有HTML元素都是由 HTMLElement 或者其更具体的子类型来表示的。下表列出了所有HTML元素以及与之关联的类型。每种 HTMLElement 子类型都有与之相关的特性和方法，这里我们只介绍 HTMLElement 的通用属性和方法。 4.1 HTMLElement 的属性 属性 返回值 tagName 通 nodeName 返回节点标签名 id 元素在文档中的唯一标识符 title 有关元素的附加说明信息，一般通过工具提示条显示出来 className 与元素的class特性对应，即为元素指定的CSS类更改 css 属性于此关联的样式会立即更新 attributes NamedNodeMap 特性节点 Attr 的集合(不推荐使用) style 设置 CSS 样式的对象 onclick 等等时间处理程序 remove() 直接删除节点自身 attributesattributes属性返回的 NamedNodeMap 是如下 {“attr”: Attr 节点} 的集合12345678910&gt; div = document.getElementById("s_top_wrap")&gt; div.attributes0: id1: class2: stylelength: 3class: classid: idstyle: style__proto__: NamedNodeMap 与NodeList类似，NamedNodeMap 也是一个“动态”的集合。元素的每一个特性都由一个Attr节点表示。通常我们使用 attributes 属性去遍历元素的所有特性。 1234for (let i=0;i&lt;div.attributes.lenght;i++)&#123; attr = div.attrbutes[i].nodeName; value = div.attrbutes[i].nodeValue;&#125; 4.2 HTMLElement 特性获取html 元素特性操作主要有如下三个方法: getAttribute(attr) setAttribute(attr, value) removeAttribute(attr) getAttributegetAttribute 用于通过特性名获取特性值。attr 为特性名，不区分大小写。HTMLElement 有5个属性可以通过 HTMLElement 节点本身的属性来访问(上面我们已经列出)。有两类特殊的特性，它们虽然有对应的属性名，但属性的值与通过getAttribute()返回的值并不相同: 第一类特性就是style: 通过getAttribute()访问时，返回的style特性值中包含的是CSS文本 通过属性来访问它则会返回一个对象 第二类特性是onclick这样的事件处理程序 通过getAttribute()访问，则会返回相应代码的字符串 在访问onclick属性时，则会返回一个JavaScript函数 由于存在这些差别，在通过JavaScript以编程方式操作DOM时，开发人员经常不使用getAttri-bute()，而是只使用对象的属性。只有在取得自定义特性值的情况下，才会使用getAttribute()方法。 123div = document.getElementById("myDiv");div.getAttribute("id");div.getAttribute("class"); setAttributesetAttribute(attr, value) 用于设置特性值。setAttribute()会以指定的值替换现有的值；如果特性不存在，setAttribute()则创建该属性并设置相应的值。因为所有特性都是属性，所以直接给属性赋值可以设置特性的值。不过，像下面这样为DOM元素添加一个自定义的属性，该属性不会自动成为元素的特性。 12div.mycolor = "red";div.getAttribute("mycolor"); // null removeAttribute调用这个方法不仅会清除特性的值，而且也会从元素中完全删除特性。 5. Text 节点Text 节点存在如下属性和方法: normalize()： 如果在一个包含两个或多个文本节点的父元素上调用normalize()方法，则会将所有文本节点合并成一个节点，结果节点的nodeValue等于将合并前每个文本节点的nodeValue值拼接起来的值 splitText(index): 与normalize()相反的方法,将一个文本节点分成两个文本节点，即按照指定的位置分割nodeValue值。 6. DOM2 以及 HTML 标准前面我们已经介绍了 DOM 节点的基本内容。DOM 标准是一个不断完善的过程，这个过程因为某些特殊目的为多种节点添加了各种方法。接下来我们按照操作目的一一来介绍这些方法。 6.1 选择符API选择符 API 提供了索引节点的新方法，这些方法适用于 HTMLDocument 和 HTMLElement 节点。 方法 作用 querySelector(css) querySelector()方法接收一个CSS选择符，返回与该模式匹配的第一个元素 querySelectorAll(css) 返回匹配css选择符的一个NodeList的实例 matchesSelector(css) 如果调用元素与该选择符匹配，返回true getElementsByClassName() 接收一个包含一或多个类名的字符串，返回带有指定类的所有元素的NodeList 处于效率考虑 querySelectorAll 返回的值实际上是带有所有属性和方法的NodeList，而其底层实现则类似于一组元素的快照，而非不断对文档进行搜索的动态查询。 6.2 元素遍历对于HTML 中元素间的空格，不同浏览器处理方式不同，IE9及之前版本不会返回文本节点，而其他所有浏览器都会返回文本节点。这样，就导致了在使用childNodes和firstChild等属性时的行为不一致。Element Traversal规范新定义了一组属性。 属性 作用 childElementCount 返回子元素（不包括文本节点和注释）的个数 firstElementChild 指向第一个子元素；firstChild的元素版 lastElementChild 指向最后一个子元素；lastChild的元素版 previousElementSibling 指向前一个同辈元素；previousSibling的元素版 nextElementSibling 指向后一个同辈元素；nextSibling的元素版 6.3 class 增删改查为了避免直接操作 class 类名字符串的复杂性，HTML5 新增了一个 classList 属性，classList属性是新集合类型DOMTokenList的实例。 DOMTokenList有一个表示自己包含多少元素的length属性，而要取得每个元素可以使用item()方法，也可以使用方括号语法。此外，这个新类型还定义如下方法。 add(value)：将给定的字符串值添加到列表中。如果值已经存在，就不添加了 contains(value)：表示列表中是否存在给定的值，如果存在则返回true，否则返回false。 remove(value)：从列表中删除给定的字符串。 toggle(value)：如果列表中已经存在给定的值，删除它；如果列表中没有给定的值，添加它。 6.4 焦点管理HTML5也添加了辅助管理DOM焦点的功能。首先就是document.activeElement属性，这个属性始终会引用DOM中当前获得了焦点的元素。默认情况下，文档刚刚加载完成时，document.activeElement中保存的是document.body元素的引用。文档加载期间，document.activeElement的值为null。 另外就是新增了document.hasFocus()方法，这个方法用于确定文档是否获得了焦点。 6.5 插入标记插入标记的技术，可以让我们快速插入多个HTML文本，而不必为带插入的每个HTML元素创建相应的节点。 innerHTML属性在读模式下，innerHTML属性返回与调用元素的所有子节点（包括元素、注释和文本节点）对应的HTML标记。在写模式下，innerHTML会根据指定的值创建新的DOM树，然后用这个DOM树完全替换调用元素原先的所有子节点。 1div.innerHTML = "&lt;div&gt;test&lt;/div&gt;" 使用innerHTML属性也有一些限制。比如，在大多数浏览器中，通过innerHTML插入&lt;script&gt;元素并不会执行其中的脚本。 outerHTML属性在读模式下，outerHTML返回调用它的元素及所有子节点的HTML标签。在写模式下，outerHTML会根据指定的HTML字符串创建新的DOM子树，然后用这个DOM子树完全替换调用元素。 innerText属性在通过innerText读取值时，它会按照由浅入深的顺序，将子文档树中的所有文本拼接起来。在通过innerText写入值时，结果会删除元素的所有子节点，插入包含相应文本值的文本节点。 outerText属性除了作用范围扩大到了包含调用它的节点之外，outerText与innerText基本上没有多大区别。在读取文本值时，outerText与innerText的结果完全一样。但在写模式下，outerText就完全不同了：outerText不只是替换调用它的元素的子节点，而是会替换整个元素（包括子节点）。 6.6 滚动页面HTML5选择了scrollIntoView()作为标准方法来实现滚动页面。scrollIntoView()可以在所有HTML元素上调用。如果给这个方法传入true作为参数，或者不传入任何参数，那么窗口滚动之后会让调用元素的顶部与视口顶部尽可能平齐。如果传入false作为参数，调用元素会尽可能全部出现在视口中，实际上，为某个元素设置焦点也会导致浏览器滚动并显示出获得焦点的元素。 7. 样式任何支持style特性的HTML元素在JavaScript中都有一个对应的style属性。这个style对象是CSSStyleDeclaration的实例，包含着通过HTML的style特性指定的所有样式信息，但不包含与外部样式表或嵌入样式表经层叠而来的样式。在style特性中指定的任何CSS属性都将表现为这个style对象的相应属性。对于使用短划线（分隔不同的词汇，例如background-image）的CSS属性名，必须将其转换成驼峰大小写形式，才能通过JavaScript来访问。 由于float是JavaScript中的保留字，因此不能用作属性名。“DOM2级样式”规范规定样式对象上相应的属性名应该是cssFloat; 12div = document.getElementById("myDiv");div.style.backgroundColor="red"; 7.1 style 对象属性和方法style 对象提供了如下属性和方法: cssText：返回style特性中的CSS代码 读取模式下，cssText返回浏览器对style特性中CSS代码的内部表示 在写入模式下，赋给cssText的值会重写整个style特性的值 设置cssText是为元素应用多项变化最快捷的方式，因为可以一次性地应用所有变化。 length：应用给元素的CSS属性的数量 parentRule：表示CSS信息的CSSRule对象 getPropertyCSSValue(propertyName)：返回包含给定属性值的CSSValue对象 CSSValue对象 包含两个属性 cssText和cssValueType cssText属性的值与getPropertyValue()返回的值相同 cssValueType属性则是一个数值常量，表示值的类型：0表示继承的值，1表示基本的值，2表示值列表，3表示自定义的值。 getPropertyValue(propertyName)：返回给定属性的字符串值 getPropertyPriority(propertyName)：如果给定的属性使用了！important设置，则返回”important”；否则，返回空字符串 item(index)：返回给定位置的CSS属性的名称，也可以使用方括号语法 removeProperty(propertyName)：从样式中删除给定属性 setProperty(propertyName, value, priority)：将给定属性设置为相应的值，并加上优先权标志（”important”或者一个空字符串） 1234567div.style.cssText = "width: 23px;"for (let i=0; i&lt;div.style.length;i++)&#123; console.log(div.style[i])&#125;div.style.removeProperty("border"); 7.2 计算样式虽然style对象能够提供支持style特性的任何元素的样式信息，但它不包含那些从其他样式表层叠而来并影响到当前元素的样式信息。 “DOM2级样式”增强了document.defaultView，提供了getComputedStyle()方法。这个方法接受两个参数： 要取得计算样式的元素和一个伪元素字符串（例如”:after”） 如果不需要伪元素信息，第二个参数可以是null getComputedStyle()方法返回一个CSSStyleDeclaration对象（与style属性的类型相同），其中包含当前元素的所有计算的样式。所有计算的样式都是只读的；不能修改计算后样式对象中的CSS属性。 12345678// ie 部分浏览器不支持 getComputedStyle() 可以使用下面的代码进行兼容function getStyle(element, attr)&#123; if (element.currentStyle)&#123; return element.currentStyle[attr] &#125;else &#123; return getComputedStyle(element, null)[attr] &#125;&#125; 8. 元素大小元素大小相关的 DOM 操作用于解决以下问题: 获取元素的偏移量和大小 获取元素的客户区大小 获取元素的滚动大小 8.1 offsetParentHTMLElement.offsetParent 指向与当前元素最近的经过定位的父级元素，分为如下四种情况: 元素本身有 fixed 定位，offsetParent 为 null 元素本身无 fixed 定位，父元素存在定位，offsetParent 是以最近的经过定位的父元素 元素无定位，父元素也无定位，offsetParent 为 body body 元素的 offsetParent 为 null 8.2 偏移量和大小通过下列4个属性可以取得元素的偏移量: offsetHeight：元素在垂直方向上占用的空间大小，以像素计。包括元素的高度、（可见的）水平滚动条的高度、上边框高度和下边框高度 offsetWidth：元素在水平方向上占用的空间大小，以像素计。包括元素的宽度、（可见的）垂直滚动条的宽度、左边框宽度和右边框宽度 offsetLeft：元素的左外边框至包含元素(offsetParent)的左内边框之间的像素距离 offsetTop：元素的上外边框至包含元素(offsetParent)的上内边框之间的像素距离 与 HTMLElement.style.width HTMLElement.style.heigth 相比: 通过 style 获取的 width，height 只能获取 html 的行内属性，不能获取样式表内属性 通过 style 获取的 width，height 都是带 px 单位的字符串值，而 offsetHeight, offsetWidth 是表示长宽的数值 offsetHeight, offsetWidth 都是只读的不能用于修改样式 8.3 客户区大小元素的客户区大小（client dimension），指的是元素内容及其内边距所占据的空间大小，其包括如下四个属性: clientWidth属性是元素内容区宽度加上左右内边距宽度 clientHeight属性是元素内容区高度加上上下内边距高度 clientLeft属性是元素左边框的宽度 clientTop属性是元素上边框的高度 与 offset 相关的属性类型 client 的四个属性同样也是只读的。如果给元素设置 “display:none” client 四个属性值将都为 0; 8.4 滚动大小滚动大小（scroll dimension），指的是包含滚动内容的元素的大小，其包含如下四个属性 scrollHeight：在没有滚动条的情况下，元素内容的总高度 scrollWidth：在没有滚动条的情况下，元素内容的总宽度 scrollLeft：被隐藏在内容区域左侧的像素数(左方被卷起的宽度)。通过设置这个属性可以改变元素的滚动位置 scrollTop：被隐藏在内容区域上方的像素数(卷起的高度)。通过设置这个属性可以改变元素的滚动位置。 scrollTop，scrollLeft 是可读写的，scrollHeight，scrollWidth 只是只读的。 此外 window 对象有一个 scrollTo(left, top) 方法，可以直接设置页面滚动到什么位置，参数left，top 分表表示距离视口左上角顶点，往右，往下多少。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 JavaScript BOM]]></title>
    <url>%2F2020%2F08%2F11%2Fweb%2FJavaScript%2Fjs_8%2F</url>
    <content type="text"><![CDATA[JavaScript 浏览器对象模型 BOM。 1. BOM 概述BOM提供了很多对象，用于访问浏览器的功能，这些功能与任何网页内容无关。其主要包含如下几个对象: window: 表示浏览器的一个实例 既是通过JavaScript访问浏览器窗口的一个接口，又是ECMAScript规定的Global对象 所有全局变量和函数都作为 window 对象的属性和方法存在 location: 提供了与当前加载的文档相关的信息 navigator: 提供了客户端浏览器的相关信息 history: 保存着用户上网的历史记录 1. windows 对象1.1 window 对象的常用属性和方法 属性/方法 作用 示例 encodeURI(uri) url 编码，只能编译空格等简单字符 decodeURI(uri) encodeURI 对应的解码方法 encodeURIComponent(uri) url 编码，可编译所有特殊字符 decodeURIComponent(uri) encodeURIComponent 对应的解码方法 alter(message) 警告对话框，通常使用alert()生成的“警告” comfirm(message) 确认对话框，向用户确认消息，返回 true/false prompt(message, default) 提示对话框，返回用户输入的文本或者 null setTimeout(func, time) 定时器，超时调用 setInterval(func, span) 定时器，间歇调用 123456789101112131415161718192021222324252627282930// 1. 设置超时调用var timeID = setTimeout(function()&#123; console.log("hello, world")&#125;, 5000);// 取消超时调用clearTimeout(timeID)// 2. 间歇调用及取消var num = 0;var max = 10;var intervalId = null;function increaNum()&#123; num ++; if (num == max)&#123; clearInterval(intervalId); &#125;&#125;intervalId = setInterval(increaNum, 1000);// 3. 使用超时调用模拟间歇调用function increaNum2()&#123; num ++; if (num &lt; max)&#123; setTimeout(increaNum2, 1000) &#125;&#125;setTimeout(increaNum2, 1000) 注意对于可能会被重复启动的定时器(比如通过页面按钮启动的定时器，应该先清除定时器，再重新开启定时器) 2. location 对象location 提供了与当前加载的文档相关的信息。location 是一个特殊对象，window.location和document.location引用的是 同一个 location 对象。 2.1 location 对象的属性和方法 属性/方法 作用 示例 hash 锚部分 #contents host 域名:端口号 www.baidu.com:80 hostname 域名 www.baidu.com href 完整 URL https://www.baidu.com pathname URI 路径 /news/ port 端口号 80 protocol 协议 https: search 查询字符串 ?q=javascript assign(rul) 可回退跳转，相当于 location.href=url replace(url) 不可回退跳转 reload() 重载网页 123456789101112131415161718192021// 1. 获取查询字符串function getQueryArgs()&#123; var qs = location.search.length &gt; 0 ? location.search.substring(1): "" var args = &#123;&#125;; var items = qs.length ? qs.split("&amp;") : []; var item=null, name = null, value = null; for (i=0; i&lt;items.length;i++)&#123; item = items[i].split("="); name = decodeURIComponent(item[0]); value = decodeURIComponent(item[1]); if (name.length)&#123; args[name] = value; &#125; &#125; return args&#125;// 2. 重载页面location.reload() // 可能从缓存中重载页面location.reload(true) // 从服务器重载页面 3. navigatornavigator 提供了客户端浏览器的相关信息。 3.1 navigator 对象的属性和方法 属性/方法 作用 示例 plugins 当前浏览器安装的插件 4. historyhistory 浏览器历史浏览记录对象，保存着用户上网的历史记录 4.1 history 对象的属性和方法 属性/方法 作用 示例 go(num) 在历史记录中跳转，num 表示前进(正数)和后退(负数)次数]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 JavaScript 面向对象]]></title>
    <url>%2F2020%2F08%2F10%2Fweb%2FJavaScript%2Fjs_7%2F</url>
    <content type="text"><![CDATA[JavaScript 中的面向对象编程。 本节我们我们要介绍的是 JavaScript 中如何实现面向对象编程。JavaScript 中对象的创建有多种方式，这是这门语言的灵活性导致。我们的最终目的是找到一种创建方式使得: 使得同一类对象可以共享特定的属性和方法，通过共享可以减少对象占用的空间 同一类的不同实例，可以定义私有属性和方法 这就是面向对象的核心，继承可以实现共享，也可以为实例定义私有属性和方法，JavaScript 使用原型来实现面向对象。不过在讲解如何实现面向对象前，我们需要先弄清楚 JavaScript 对象的属性。 1. 对象属性ECMAScript 为属性定义了多个特征，这些特征表征了属性可以如何被操作，ECMAScript 规定有两种属性：数据属性和访问器属性。 1.1 数据属性数据属性有4个描述其行为的特性。 [[Configurable]]： 表示能否通过delete删除属性从而重新定义属性 能否修改属性的特性 或者能否把属性修改为访问器属性 这个特性默认值为true 当设置为 false 时，只允许将 Writable 从 true 改成 false，除此之外对其他四个属性的任意修改都会失败 [[Enumerable]]： 表示能否通过for-in循环返回属性 这个特性默认值为true [[Writable]]： 表示能否修改属性的值 这个特性默认值为true [[Value]]： 包含这个属性的数据值 读取属性值的时候，从这个位置读 写入属性值的时候，把新值保存在这个位置 这个特性的默认值为undefined 注意当 Writable=false Configurable=true 时，Value 值可以再次通过 defineProperty 进行修改，但是直接的属性赋值是不行的 像下面这样，直接在对象上定义的属性，他们的[[Configurable]]、[[Enumerable]]和[[Writable]]特性都被设置为true，而[[Value]]特性被设置为指定的值 123var person = &#123; name: "abc" // [[Value]]特性将被设置为"abc"&#125; 特性修改要修改属性默认的特性，必须使用ECMAScript 5的Object.defineProperty()方法: Object.defineProperty(obj, property, descriptor): obj: 属性所在对象 property: 属性名 descriptor: 描述符对象，对象的属性必须是：configurable、enumerable、writable和value 在调用Object.defineProperty()方法时，如果不指定，configurable、enumerable和writable特性的默认值都是false 12345var person = &#123;&#125;object.defineProperty(person, "name", &#123; writable: false, value: "abc"&#125;) 特性的判断Object 的原型对象还提供了如下实例方法用来对属性特性进行判断: obj.propertyIsEnumerable(property): 用于判断，对象的属性是否可枚举。这个方法只能判断实例对象本身的属性，对于继承而来的属性都会返回 false 1.2 访问器属性访问器属性不包含数据值；它们包含一对儿getter和setter函数(都不是必须的): 在读取访问器属性时，会调用getter函数，这个函数负责返回有效的值 在写入访问器属性时，会调用setter函数并传入新值，这个函数负责决定如何处理数据 访问器属性有如下4个特性: [[Configurable]]： 表示能否通过delete删除属性从而重新定义属性 能否修改属性的特性 或者能否把属性修改为数据属性 这个特性默认值为true [[Enumerable]]： 表示能否通过for-in循环返回属性 这个特性默认值为true [[Get]]： 在读取属性时调用的函数。默认值为undefined 只指定getter意味着属性是不能写 [[Set]]： 在写入属性时调用的函数。默认值为undefined 只指定setter函数的属性也不能读 访问器属性不能直接定义，必须使用Object.defineProperty()来定义: 123456789101112131415var book = &#123; _year: 2014, edition: 1&#125;;Object.defineProperty(book, "year",&#123; get: function()&#123; return this._year; &#125;, set: function(year)&#123; if (year &gt; 2014)&#123; this._year = year; this.edition = year - this._year; &#125; &#125;&#125;); 1.3 属性特性修改除了 Object.defineProperty 外，还有以下方法支持属性特性的修改和读取: Object.definedProperties: 一次增加多个属性 Object.getOwnerPropertyDescriptor: 获取给定属性的描述符 不能用于继承而来的属性 可以针对任何对象——包括DOM和BOM对象，使用Object.getOwnPropertyDescriptor()方法 1234567891011121314151617181920212223242526272829303132var book = &#123;&#125;;Object.defineProperties(book, &#123; _year: &#123; value: 24 &#125;, year: &#123; get: function()&#123; return this._year; &#125;, set: function(year)&#123; if (year &gt; 2014)&#123; this._year = year; this.edition = year - this._year; &#125; &#125; &#125;&#125;);var desc = Object.getOwnerPropertyDescriptor(book, "_year");alter(desc.value)// 简便写法var book = &#123; // 访问器的简便写法 get year()&#123; &#125; set year(value)&#123; &#125;&#125; 1.4 属性特性注意事项使用 defineProperty 总是为实例添加自身的私有属性，其将覆盖继承而来的同名属性。 12345678910111213141516var obj = Object.defineProperty(&#123;&#125;, "p", &#123; value: 10, writable: false &#125;)obj2 = Object.create(obj);console.log(obj2.p); // 10obj2.p = 20;console.log(obj2.p); // 10, 原型上的不可修改属性，实例也不可修改// 使用 defineProperty 为实例添加属性，这样就可以覆盖继承的属性，从而可修改Object.defineProperty(obj2, "p", &#123; value: 20, writable: true&#125;)console.log(obj2.p); // 20 2. 对象创建2.1 工厂模式前面在介绍 Object 时，我们说到创建对象可以使用 Object 构造函数和对象字面量。但这有个明显的缺点：使用同一个接口创建很多对象，会产生大量的重复代码。为解决这个问题，人们开始使用工厂模式的一种变体。即使用函数封装对象的创建过程。 12345function createPerson()&#123; var o = new Object(); o.name = "abc"; return o;&#125; 工厂模式虽然解决了创建多个相似对象的问题，但却没有解决对象识别的问题（即怎样知道一个对象的类型）。 2.2 构造函数ECMAScript中的构造函数可用来创建特定类型的对象。像Object和Array这样的原生构造函数，在运行时会自动出现在执行环境中，是语言内置的。我们也可以自定义构造函数: 123456789function Person(name)&#123; this.name = name; this.sayName = function()&#123; alter(this.name) &#125;;&#125;var p1 = new Person("1");var p2 = new Person("2");var p3 = new Person(); // 等价于 p3 = new Person 在构造函数 Person 内: 没有显式地创建对象； 直接将属性和方法赋给了this对象； 没有return语句 要创建Person的新实例，必须使用new操作符。以这种方式调用构造函数实际上会经历以下4个步骤： 创建一个新对象； 将构造函数的作用域赋给新对象（因此this就指向了这个新对象）； 执行构造函数中的代码（为这个新对象添加属性）； 返回新对象 返回的对象都有如下属性用来连接实例化的新对象和构造函数: proto属性(原型对象)，指向构造函数的 prototype 属性对象 constructor（构造函数）属性，指向构造函数(注: 这个对象是通过原型对象继承而来，是原型对象唯一的私有属性) 创建自定义的构造函数意味着将来可以将它的实例标识为一种特定的类型，这正是构造函数模式胜过工厂模式的地方。为什么我们接下来将原型的时候会详细说明。 函数的返回值函数的返回值依其调用方式，有不同返回值 如果函数只作为普通函数执行(不加 new)，return 即是其返回值，没有 return 语句时默认返回 undefined 如果函数作为构造函数执行: 没有返回值或者返回值不是一个对象，则返回函数内部创建的 this 对象 如果返回值是一个对象，则返回该对象 构造函数与函数需要强调的是构造函数本身也是函数，类似于 Python 中的初始化函数 __init__，而对象的创建是通过 new 关键字。任何函数，只要通过new操作符来调用，那它就可以作为构造函数；而任何函数，如果不通过new操作符来调用，那它跟普通函数也不会有什么两样。 构造函数的问题使用构造函数的主要问题，就是每个方法都要在每个实例上重新创建一遍。即无法实现共享，同一构造函数返回的不同对象上的同名函数是不相等的。 2.3 原型模式我们创建的每个函数都有一个prototype（原型）属性，这个属性是一个指针，指向一个对象，而这个对象的用途是包含可以由特定类型的所有实例共享的属性和方法。如果按照字面意思来理解，那么prototype就是通过调用构造函数而创建的那个对象实例的原型对象。原型模式创建对象的方式如下: 12345678function Person()&#123;&#125;Person.prototype.name = "abc";Person.prototype.sayName = function()&#123; alter(this.name) &#125;;var p1 = new Person(); 构造函数，原型与对象构造函数，原型与对象之间的关系是这样的: 只要创建了一个新函数，就会根据一组特定的规则为该函数创建一个prototype属性，这个属性指向函数的原型对象 所有原型对象都会自动获得一个constructor（构造函数）属性，这个属性是一个指向 prototype 属性所在函数的指针 构造函数创建的实例的内部将包含一个指针（内部属性[[Prototype]]），指向构造函数的原型对象 每当代码读取某个对象的某个属性时，都会执行一次搜索，搜索的顺序按照: 对象实例本身-&gt;实例的原型-&gt;实例原型的原型直至 Object对象，以此构成了一条原型链。而这正是多个对象实例共享原型所保存的属性和方法的基本原理。 以前面使用Person构造函数和Person.prototype创建实例的代码为例，各个对象之间的关系如下图所示。 1234567Person.prototype.isPrototype(p1) // 判断实例的[[Prototype]] 是否指向该原型Object.getPrototypeOf(p1) == Person.prototype // 获取实例的原型p1.hasOwnPrototype("name") // 如果给定属性存在于对象实例中时返回 trueObject.keys(p1.prototype)Object.keys(p1) // 取得对象上所有可枚举的实例属性，注意实例是相对而言的Object.getOwnPropertyNames(p1) // 获取所有实例属性，无论是否可枚举 注: ECMAScript 5的Object.getOwnPropertyDescriptor()方法只能用于实例属性，要取得原型属性的描述符，必须直接在原型对象上调用Object.getOwnPropertyDescriptor()方法。 完整的原型链如果将上面的原型链继续扩展至 Object.prototype，一个完整的原型链如下图所示: 个人觉得，要理解原型链一个重要的地方是，这里的 Foo.prototype 跟 Foo 函数是独立，是两个完全不同的对象，只不过彼此通过 prototype 属性相关联，prototype 属性就像其他属性一样是一个可随意可复制的属性。它们唯一需要保证的关系是 prototype 属性值需要有一个 constructor 属性指向构造函数 Foo。 原型模式的简化更常见的做法是用一个包含所有属性和方法的对象字面量来重写整个原型对象， 123456function Person();Person.prototype = &#123; // constructor: Person, name: "12"&#125; 这么写法有个例外，constructor属性不再指向Person了。每创建一个函数，就会同时创建它的prototype对象，这个对象也会自动获得constructor属性。而这里重写了默认的 prototype 对象，因此 constructor 属性也就变成了新对象的constructor属性（指向Object构造函数），不再指向Person函数。 可以像注释一样，重设 constructor 属性，那么此时 constructor 的[[Enumerable]] 特性被设置为true。所以完备的写法应该像下面这样: 1234567891011function Person()&#123;&#125;;Person.prototype = &#123; // constructor: Person, name: "12"&#125;Object.definePrototype(Person.prototype, "constructor", &#123; enumerable: false, value: Person&#125;) 原型模式的缺点在原型模式下我们无法为实例自定义属性，因为构造函数是空的。 2.4 组合构造函数和原型构造函数模式用于定义实例属性，而原型模式用于定义方法和共享的属性。这应该是目前的标准实现方式。 12345678910111213function Person(age)&#123; this.age = age;&#125;;Person.prototype = &#123; // constructor: Person, name: "12"&#125;Object.definePrototype(Person.prototype, "constructor", &#123; enumerable: false, value: Person&#125;) 当然我们可以把原型的赋值也放到构造函数中: 123456789101112131415function Person(age)&#123; this.age = age; if (typeof this.name != "string")&#123; Person.prototype = &#123; // constructor: Person, name: "12" &#125; Object.definePrototype(Person.prototype, "constructor", &#123; enumerable: false, value: Person &#125;); &#125;;&#125;; 2.5 寄生函数模式没看懂这种创建模式存在的必要。下面是这种模式的一个示例: 1234567891011function SpecialArray()&#123; var arr = new Array(); arr.push(arguments); arr.toShow = function()&#123; alter(this.join("|")) &#125;; return arr;&#125;var colors = new SpecialArray("red");colors.toShow(); 除了使用new操作符并把使用的包装函数叫做构造函数之外，这个模式跟工厂模式其实是一模一样的。。构造函数在不返回值的情况下，默认会返回新对象实例。而通过在构造函数的末尾添加一个return语句，可以重写调用构造函数时返回的值。 返回的对象与构造函数或者与构造函数的原型属性之间没有关系；也就是说，构造函数返回的对象与在构造函数外部创建的对象没有什么不同。所以为什么不直接用工厂模式？ 2.6 稳妥构造函数模式所谓稳妥对象，指的是没有公共属性，而且其方法也不引用this的对象。这种构造函数，实际上是一种函数闭包的应用。 12345678910function Person(age)&#123; var o = Object(); o.sayAge = function()&#123; // 方法通过闭包而不是 this 引用 age 的值 alter(age); &#125;; return o&#125;;var p1 = Person(15); // 不适用 newp1.sayAge(); 3. 原型链与继承所谓原型链就是，对象实例本身-&gt;实例的原型-&gt;实例原型的原型直至 Object对象构成的链条。而继承就是原型链上的搜索顺序。 123456789101112131415161718192021function Super()&#123; this.A = true;&#125;Super.prototype.getA = function()&#123; return this.A;&#125;;function Sub()&#123; this.B = false;&#125;Sub.prototype = new Super();// 新方法必须在原型替换之后定义Sub.prototype.getB = function()&#123; return this.B;&#125;var t = new Sub();alter(t.getA()); 可以看到实现继承的本质是重写了原型对象。最终结果就是这样的：t 指向Sub的原型(即 Super的实例)，Sub的原型又指向Super的原型。 我们知道，所有引用类型默认都继承了 Object，而这个继承也是通过原型链实现的。所有函数的默认原型都是Object的实例，因此默认原型都会包含一个内部指针，指向Object.prototype。这也正是所有自定义类型都会继承toString()、valueOf()等默认方法的根本原因。 3.1 原型与类型判断可以通过两种方式来确定原型和实例之间的关系 第一种方式是使用instanceof操作符，只要用这个操作符来测试实例与原型链中出现过的构造函数，结果就会返回true 第二种方式是使用isPrototypeOf()方法。同样，只要是原型链中出现过的原型，都可以说是该原型链所派生的实例的原型 12alter(t instanceof Super);alter(Super.prototype.isPrototype(t)) 3.2 原型链的问题上面使用原型链的主要问题是在创建子类型的实例时，不能向超类型的构造函数中传递参数。实际上，应该说是没有办法在不影响所有对象实例的情况下，给超类型的构造函数传递参数。 所以我们需要更好的方式去利用原型实现继承。 4. 继承的实现4.1 组合继承组合继承组合了构造函数和原型链: 构造函数的技巧是在子类型构造函数的内部调用超类型构造函数，这样可以实现为子类对象定义独立的属性和方法 通过在原型上定义方法实现了函数复用，又能够保证每个实例都有它自己的属性 最终使用原型链实现了对原型属性和方法的继承，而通过借用构造函数来实现对实例属性的继承 这是目前最常用的继承模式。说的比较抽象，我们来看下面这个示例 123456789101112131415161718192021function Super(name)&#123; this.A = true; this.name = name;&#125;Super.prototype.getA = function()&#123; return this.A;&#125;;function Sub(name, age)&#123; // Super.call(this, name) // 二次调用 this.age = age&#125;Sub.prototype = new Super(); // 一次调用Sub.prototype.constructor = Sub;// 新方法必须在原型替换之后定义Sub.prototype.getB = function()&#123; return this.B;&#125; 组合继承最大的问题就是无论什么情况下，都会调用两次超类型构造函数。一次是在创建子类型原型的时候，另一次是在子类型构造函数内部。像上面这样， name 属性也会创建两次，一次在 Sub 的原型上，一次是Sub 对象上。整个原型链与继承关系就变成下图这个样子: 4.3 原型式继承原型式继承的核心思想是借助原型可以基于已有的对象创建新对象，同时还不必因此创建自定义类型。能这么做的前提是必须有一个对象可以作为另一个对象的基础。下面是这种实现的示例: 123456// object()对传入其中的对象执行了一次浅复制function object(o)&#123; function F()&#123;&#125; F.prototype = o; return new F(); &#125; ECMAScript 5通过新增Object.create()方法规范化了原型式继承。这个方法接收两个参数： 一个用作新对象原型的对象 （可选的）一个为新对象定义额外属性的对象，与Object.defineProperties()方法的第二个参数格式相同：每个属性都是通过自己的描述符定义的 12345678910var person = &#123; name: "abc", friends: ["a", "b"] // 浅复制，引用类型值的属性始终都会共享相应的值&#125;;var pp = Object.create(person, &#123; name: &#123; value: "tt" &#125;&#125;); 4.4 寄生组合式继承所谓寄生组合式继承，即通过借用构造函数来继承属性，通过原型链的混成形式来继承方法。其背后的基本思路是：不必为了指定子类型的原型而调用超类型的构造函数，我们所需要的无非就是超类型原型的一个副本而已。 12345678910111213141516171819202122232425262728// 方法一使用超类原型的副本function inheritPrototype(sub, super)&#123; // 第一步是创建超类型原型的一个副本。 var prototype = Object(super.prototype); prototype.constructor = sub; sub.prototype = prototype;&#125;// 方法二使用 Object.create() 代理父类实例化，这样化，原型链中就多了一个对象，这种方式使用更多function inheritCreate(sub, super)&#123; var prototype = Object.create(super.prototype); prototype.constructor = sub; sub.prototype = prototype;&#125;function Super(name)&#123; this.color = []; this.name = name;&#125;function Sub(name, age)&#123; // Super.call(this, name) // 一次调用 this.age = age&#125;inheritPrototype(Sub, Super);// inheritCreate(Sub, Super); 开发人员普遍认为寄生组合式继承是引用类型最理想的继承范式。 4.5 多重继承JavaScript 中默认不支持多重继承，多重继承可以借用 Object.assign 方法，将其他父类的方法拷贝到原型上来实现。但是这种方法在拷贝之后，修改父类是无法影响子类的。 1234567891011121314151617181920212223242526function Animal(name) &#123; this.name = name; &#125; Animal.prototype.getName = function() &#123; return this.name; &#125; function Other(age) &#123; this.age = age; &#125; Other.prototype.sayAge = function() &#123; return this.age &#125; function Dog(name, age) &#123; Animal.call(this, name); Other.call(this, age); // 1. 继承属性 &#125; // 2. 继承方法 Object.assign(Dog.prototype, Animal.prototype) Object.assign(Dog.prototype, Other.prototype) var d = new Dog("阿黄", 10) 5. Object 对象上的重要方法Object 对象本身有很多方法，常见的包括: Object 本身的方法: Object.keys() Object.getOwnPropertyNames() Object.getPrototypeOf() Object.setPrototypeOf() Object.create() 定义在 Object.prototype 上的实例方法(obj 表示任意实例对象): Object.prototype.valueOf() Object.prototype.toString() Object.prototype.toLocalString() Object.prototype.isPrototypeOf() Object.prototype.hasOwnProperty() Object.prototype.propertyIsEnumerable() 下面我们来一一介绍这些方法的使用。 5.1 本身的方法属性枚举keys 和 getOwnPropertyNames 都用于获取对象自身上所有的属性名(不包括继承而来的属性)，区别在于: Object.keys(obj): 只能获取可枚举属性 Object.getOwnPropertyNames(obj): 可同时获取可枚举和不可枚举属性 for-in 循环能遍历对象的所有可枚举属性，包括自身以及继承而来的 123Object.keys(p1.prototype)Object.keys(p1) // 取得对象上所有可枚举的实例属性，注意实例是相对而言的Object.getOwnPropertyNames(p1) // 获取所有实例属性，无论是否可枚举 原型对象操作 Object.getPrototypeOf(obj): 用于获取对象的原型对象 Object.setPrototypeOf(obj, proto_obj): 将 proto_obj 设置为 obj 的原型对象 123Person.prototype.isPrototype(p1) // 判断实例的[[Prototype]] 是否指向该原型Object.getPrototypeOf(p1) == Person.prototype // 获取实例的原型p1.hasOwnPrototype("name") // 如果给定属性存在于对象实例中时返回 true 属性描述符Object 提供了下列方法用于操作属性描述符: Object.getOwnPropertyDescription(obj, property): 获取对象 obj 属性 property 的描述符 只能用于获取自身的属性，无法获取继承而来的属性 Object.defineProperty(obj, property, descriptor): 为属性定义属性描述符 Object.definedProperties(obj, pro_descriptor): 一次为多个属性定义属性描述符 对象创建Object.create(proto_obj): 作用: 创建一个新的对象，并将 proto_obj 设置为其原型对象 5.2 实例方法对象类型转换下面这些方法与对象类型自动转换有关，前面我们在介绍 JavaScript 自动类型转换时介绍过这些方法的使用: obj.valueOf(): 返回对象的值形式 obj.toString(): 返回对象的字符串形式 obj.toLocalString(): 返回对象与地区相关的字符串 为特定对象自定义上面这些方法，可以实现类似算术运算的方法重载。 原型存在与属性判断下面这些方法的返回都是布尔值，用于对属性的特性或者原型的归属进行判断: obj.isPrototypeOf(base_obj): 判断 obj 是不是 base_obj 对象的原型对象 obj.hasOwnProperty(property): 判断 obj 本身是否包含属性 property，继承而来的属性不算 obj.propertyIsEnumerable(property): 判断 obj 的属性 property 是否可枚举，这个方法只能判断实例对象本身的属性，对于继承而来的属性都会返回 false]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 JavaScript 函数]]></title>
    <url>%2F2020%2F08%2F09%2Fweb%2FJavaScript%2Fjs_6%2F</url>
    <content type="text"><![CDATA[JS 中的函数是一个引用类型的值，所有函数都是 Function 类型的实例。 1. 函数创建JavaScript 中函数有三种创建方式: 函数声明语法 函数表达式 Function 构造函数: 接收多个参数，最后一个参数为函数体(很少使用) 123456789function sum(n1, n2)&#123; return n1 + n2; // 注意分号不要省略&#125;var sum = function(n1, n2)&#123; return n1 + n2; &#125;; // 还要注意函数末尾有一个分号，就像声明其他变量时一样。var sum = new Function("n1", "n2", "return n1+n2"); 函数声明和函数表达式并不完全一致: 解析器会率先读取函数声明，并使其在执行任何代码之前可用 – 函数声明提升 函数表达式，则必须等到解析器执行到它所在的代码行，才会真正被解释执行 除了什么时候可以通过变量访问函数这一点区别之外，函数声明与函数表达式的语法其实是等价的。 注: 不带标识符的 function 声明的是匿名函数，而带标识符 function 也可以作为表达式，叫命名函数表达式，但是必须使用括号包裹函数声明像下面这样(ES6中已经不是必须):12345678910var factorial = (function f(num)&#123; if (num &lt;=1)&#123; return 1; &#125; else &#123; return num * factorial(num - 1); return num * arguments.callee(num - 1) &#125;&#125;); // function 外的括号必不可少，ES6中已经不是必须f(3); // 命名函数表达式中的函数名 f，有点类似函数的形参,只能在函数的内部使用，不能在函数外部使用 变量与函数的声明提升声明提升指的是浏览器在预编译阶段会将变量和函数的声明移到所在作用域的最上面。因此下面的两端代码是等价的:1234567console.log(a);var a = 1;// 等同于var a;console.log(a);a = 1; 变量和函数的声明都会提升，当二者存在命名冲突时，函数声明提升优先级高于变量的声明提升，所以会存在下面这些现象:1234567891011121314151617181920212223// 1. 函数声明覆盖变量声明var afunction a()&#123;&#125;console.log(a); // function// 2. 函数声明不能覆盖赋值语句var a = 1;function a() &#123;&#125;console.log(a); // 1// 相当于var a;function a()&#123;&#125;;a = 1;// 3. 声明提升仅限于所在的作用域内function a() &#123; function b() &#123;&#125;;&#125;console.log(b); // undefined error 1.1 函数调用函数在声明后，有四种调用方式: 函数调用模式: 直接调用 方法调用模式: 作为对象的方法调用 构造函数调用模式: 使用 new 关键字调用 间接调用模式: 使用函数的 call 和 aplly 方法进行调用 要注意的是，不同的调用方式会影响函数内部 this 的指向，以及函数的返回值。这个非常重要，我们会在后面详细介绍它们的区别。 2. 函数参数JavaScript 的函数参数非常诡异: 函数内部有一个特殊的对象 arguments 它是一个类数组对象，收集了传入函数中的所有参数 命名的参数只提供便利，但不是必需的，解析器不会验证命名参数。意味着 JavaScript 的函数直接就可以接收任意数量的参数。 没有传递值的命名参数将自动被赋予undefined值 arguments对象可以与命名参数一起使用，arguments的值永远与对应命名参数的值保持同步 arguments 与命名参数值同步，并不是说读取这两个值会访问相同的内存空间；它们的内存空间是独立的，但它们的值会同步。 如果只传入了一个参数，那么为arguments[1]设置的值不会反映到命名参数中。这是因为arguments对象的长度是由传入的参数个数决定的，不是由定义函数时的命名参数的个数决定的 在下面这个示例中: num1的值与arguments[0]的值相同，因此它们可以互换使用 修改 arguments[0] num1 的值会自动同步 如果只传入一个参数，对arguments[1] 的赋值不会反映到 num2 中，num2 仍然为 undefined 1234567funciton doAdd(num1, num2)&#123; if (arguments.length == 1)&#123; return num1 + 10; &#125; else if (arguments.length == 2)&#123; return arguments[0] + num2; &#125;&#125; 2.1 arguments 的其他属性arguments 还有如下一些特殊的属性: callee: 是一个指针，指向拥有这个arguments对象的函数，可用于将函数与函数名解耦 12345678910111213function factorial(num)&#123; if (num &lt;=1&gt;)&#123; return 1; &#125; else &#123; return num * factorial(num - 1); // 如果 factorial 函数名被重新赋值就会发生错误 return num * arguments.callee(num - 1) // 正确写法 &#125;&#125;var trueF = factorial;factorial = function(num)&#123; return 0;&#125;; 使用命名函数表达式可以达到同样的效果: 12345678var factorial = (function f(num)&#123; if (num &lt;=1&gt;)&#123; return 1; &#125; else &#123; return num * factorial(num - 1); return num * arguments.callee(num - 1) &#125;&#125;); // function 外的括号必不可少 3. 函数内部属性在函数内部，有多个特殊的对象： arguments this caller length: 表示函数希望接收的形参个数 prototype: 函数对象的原型，不仅函数有，所有引用类型都存在 name: 当前函数的名称，对于匿名函数就是函数赋值的变量名称，对于命名好函数就是命名函数的名称 3.1 thisarguments 我们已经说过了，而 this 引用的是函数执行的环境对象。this 的是在函数被调用时决定的。原因也很简单，环境对象也是函数调用时创建的。 当在全局作用域中调用sayColor()时，this引用的是全局对象window(严格模式下 this 为 undefined)；当把函数赋值给某个对象时，this 指向的就是该对象。 123456789window.color = "red";var o = &#123;"color": "blue"&#125;;function sayColor()&#123; alter(this.color);&#125;sayColor(); // redo.sayColor = sayColor();o.sayColor(); // blue 3.2 callercaller 属性中保存着调用当前函数的函数的引用，如果是在全局作用域中调用当前函数，它的值为null。为了实现更松散的耦合，也可以通过arguments.callee.caller来访问相同的信息。 3.3 prototypeprototype 原型，与JavaScript 原型链和面向对象编程相关，我们在后面介绍 JavaScript 面向对象编程时在详细介绍。在ECMAScript 5中，prototype属性是不可枚举的，因此使用for-in无法发现。 4. 函数方法4.1 apply 和 call每个函数都包含两个非继承而来的方法：apply()和call()。这两个方法的用途都是在特定的作用域中调用函数，实际上等于设置函数体内this对象的值。 apply()方法接收两个参数： 一个是在其中运行函数的作用域 在非严格模式下，如果这个值是 null 或者 undefined 将会被转换成全局的 window 对象 在严格模式下，null 或者 undefined 不会转换成 window 对象，函数内的 this 此时就是 null 或 undefined 另一个是参数数组，可以是Array的实例，也可以是arguments对象 call()方法与apply()方法的作用相同，它们的区别仅在于接收参数的方式不同。对于call()方法而言 第一个参数是this值没有变化，变化的是其余参数都直接传递给函数 在使用call()方法时，传递给函数的参数必须逐个列举出来 apply()和call() 真正强大的地方是能够扩充函数赖以运行的作用域。 12345678910111213141516171819202122232425262728293031window.color = "red"var o = &#123;"color": "blue"&#125;;function sayColor()&#123; alter(this.color);&#125;sayColor(); // redsayColor.apply(window); // redsayColor.apply(o); // blue // sayColor 函数不需要与任何对象发生耦合// apply 与 call 方法的应用// 1.求数组最大值var arr = [1, 2, 4]Math.max.apply(null, marr)// 2. 将类数组转换为真正的数组function add()&#123; // 这里的 arguments 是作为作用域对象传入的，不是参数，所以前面不用传 null // slice 方法修改就是作用域对象，作用域对象必须是类数组，即包含数值索引和 length 方法 var arr = Array.prototype.slice.apply(arguments);&#125;// 3. 数组追加Array.prototype.push.apply(arr, [1,4,10])// 4. 使用 log 替代 console.logfunction log()&#123; console.log.apply(console, arguments);&#125;log(arr); 4.2 bindECMAScript 5还定义了一个方法：bind()。这个方法会创建一个函数的实例，其this值会被绑定到传给bind()函数的值。bind 通常用来实现函数式编程中的函数柯里化技术 1234567891011121314151617window.color = "red"var o = &#123;"color": "blue"&#125;;function sayColor()&#123; alter(this.color);&#125;var oSay = sayColor.bind(o); // oSay()函数的this值等于ooSay(); // blue// 函数柯里化function getConfig(color, size, other)&#123; console.log(color, size, other);&#125;var defaultConfig = getConfig.bind(null, "red", 100);defaultConfig("tt");defaultConfig("dd"); 4.3 其他场景下的 this 绑定除了函数的 call，apply，bind 的方法外，下面这些函数也提供了绑定 this 的方法: 数组的 forEach，filter，some，every 方法，都接收两个参数：要在每一项上运行的函数和（可选的）运行该函数的作用域对象。 12345678var a = 1;var obj = &#123; "a": 2&#125;var arr = [1, 2, 3]arr.forEach(function(el,index)&#123; console.log(el,index,this); &#125;,obj); 5. 作用域链与闭包5.1 执行环境和变量对象要搞清楚 JavaScript 变量的作用域，我们首先要明白两个概念: 执行环境和变量对象: 当某个函数被调用时，会创建一个执行环境（execution context） 后台的每个执行环境都有一个表示变量的对象——变量对象，所有变量和函数都保存在变量对象中 全局环境的变量对象始终存在，而像compare()函数这样的局部环境的变量对象，则只在函数执行的过程中存在 在 Web 浏览器中，全局执行环境被认为是 window 对象，因此所有的全局变量和函数都是作为 window 对象的属性和方法创建的 当执行流进入一个函数时，函数的环境就被推入一个环境栈中，函数执行完毕栈被弹出，环境对象被销毁，保存在其中的变量和函数也随之销毁 5.2 作用域链的创建作用域链的创建要从函数的创建和调用说起: 在创建函数时会创建一个预先包含全局变量对象的作用域链，这个作用域链被保存在内部的[[Scope]]属性中 当调用函数时，会为函数创建一个执行环境，然后通过复制函数的[[Scope]]属性中的对象构建起执行环境的作用域链 12345678910function compare(v1, v2)&#123; if (v1 &gt; v2)&#123; return -1; &#125; else if (v1 &lt; v2)&#123; return 1; &#125; return 0;&#125;var result = compare(2, 3) 对于像上面这样在全局环境中调用的 compare 函数，其执行环境与作用域如下图所示: compare 函数的本地变量对象被创建，并被推入执行环境作用域链的前端。显然，作用域链本质上是一个指向变量对象的指针列表，它只引用但不实际包含变量对象。 显然每个执行的函数都有自己的执行环境，每个执行环境都关联着自己的作用于连，标识符解析沿着作用域链进行，作用域链的前端始终是当前执行的代码所在环境的变量对象。 使用 var 声明的变量会自动被添加到最接近的环境中，函数内这个最接近的环境就是函数的局部环境，如果没有使用 var 声明，则自动被添加到全局环境。 5.3 作用域粒度JavaScript 执行环境只有全局和局部(函数)两种，因此 JS 中没有块级作用域。有些语句可以延长作用域链，因为这些语句可以在作用域链的前端临时增加一个变量对象，该变量对象会在代码执行后移除，这些语句包括: with: 将指定的对象添加到作用域链的前端，with 对象中的属性会覆盖作用域链中的同名对象 try-catch 语句的 catch 块: 创建一个新的变量对象添加到作用域的前端，其中包含的是被抛出的错误对象的声明 1234567function buildUrl()&#123; var qs= "?debug=true"; with(location)&#123; var url = href + qs; // href 引用的是 location.href &#125; return url;&#125; ES6 通过 let 关键词引入了块级作用域，我们在后面在详述。 5.4 闭包一般来讲，当函数执行完毕后，函数执行环境中的变量对象会随着执行环境的销毁而销毁。但是闭包(函数内定义的函数): 内部函数会将外部函数的变量对象添加到自己的作用域链中，这样内部函数就能访问外部函数中定义的变量 由于外部函数的变量对象存在引用，也不会随着外部函数执行环境销毁而销毁，直至内部函数执行环境被销毁 12345678910111213141516function createCompareFunc(propertyName)&#123; return function(obj1, obj2)&#123; var v1 = obj1[propertyName]; var v1 = obj1[propertyName]; if (v1 &gt; v2)&#123; return -1; &#125; else if (v1 &lt; v2)&#123; return 1; &#125; return 0; &#125;&#125;;var compare = createCompareFunc("age");var result = compare(&#123;"age": 10&#125;, &#123;"age": 20&#125;); 对于上面的闭包函数，在匿名函数从 createCompareFunc()中被返回后，它的作用域链被初始化为包含 createCompareFunc() 函数的活动对象和全局变量对象。这样，匿名函数就可以访问在createComparisonFunction()中定义的所有变量。compare 函数的作用域链如下图所示: 5.5 闭包的 this 对象前面我们提到过，函数内部的 this 对象是在运行时基于函数的执行环境绑定的：在全局函数中，this等于window，而当函数被作为某个对象的方法调用时，this等于那个对象。不过，匿名函数的执行环境具有全局性，因此其this对象通常指向window。怎么理解这句话呢，我们来看下面这个例子: 1234567891011121314151617181920212223242526272829var name = "window";var obj = &#123; name: "object", getName: function()&#123; return this.name; &#125;, getFunc: function()&#123; return function()&#123; return this.name; &#125;; &#125;, getFuncObj: function()&#123; var that = this; return function()&#123; return that.name; &#125;; &#125; &#125;object.getName(); // object(object.getName)() // object(object.getName = object.getName)(); // windowobject.getFunc()(); // windowobject.getFuncObj()(); // Object 第三行代码先执行了一条赋值语句，然后再调用赋值后的结果。因为这个赋值表达式的值是函数本身，所以this的值不能得到维持，结果就返回了”The Window”。 类比 Python 就是 JavaScript 对于对象方法不会执行对象绑定，所以才会出现 this 值丢失的情况。因此我们说匿名函数的执行环境具有全局性。 6. 模拟块级作用域由于 ES5 没有块级作用域，所以经常能看到那种立即定义执行的函数(IIFE)，ES6 通过 let 关键字引入了块级作用域，因此这里我们就不再介绍这部分知识了(过期了)。一个立即定义执行的函数就像下面这样: 1234567891011// 1. 立即执行函数的第一种写法(function()&#123; // 块级作用域&#125;)();// 2. 立即执行函数的第二种写法(function()&#123;&#125;())// 3. 立即执行函数的第三种写法// ! 可以改成 + 等等符号，目的是告诉解释器后面是一个表达式!(function()&#123;&#125;()) 注意最外层的括号不可省略，因为函数声明后不能跟()，因此需要将函数声明转换成函数表达式。这种技术经常在全局作用域中被用在函数外部，从而限制向全局作用域中添加过多的变量和函数。 7. 闭包的应用关于闭包在 JS 中的应用，我们举两个例子: 使用闭包实现缓存 img 图片对象上报 7.1 缓存7.2 img 图片对象上报使用闭包保存 img 对象的原因是，函数已经执行完会销毁 Image 对象，此时 src 的数据上报可能还未完成，导致上传失败。不过这个问题只存在低版本浏览器中。 123456789var report = function()&#123; var imgs = []; return function(src)&#123; var img = new Image(); imgs.push(img); img.src = src; return img &#125;&#125;(); 8. this 的指向问题JavaScript 中 this 的指向是一个比较容易迷惑的行为，在此我么罗列一下有哪些值得我们注意的场景。函数内部的 this 对象是在运行时基于函数的执行环境绑定的，其绑定方式基本上与函数调用的 4 种方式相关: 函数调用:this默认指向了window，所以嵌套函数，立即执行的函数，闭包内部 this 都指向 window 隐式绑定: 谁调用，绑定谁，通常是作为对象方法调用 对象方法不会执行对象绑定，所以任何的赋值操作都会导致 this 绑定丢失，包括函数别名，参数传递 显示绑定: 显示使用 apply 等方法绑定函数内部 this 对象 构造函数: 当函数作为构造函数使用时，内部的 this 是构造函数实例化的对象 123456789101112131415// 1. this默认指向了window// 2. 谁调用，绑定谁// 定时器，函数的最终调用方是 window，所以 this 指向 window 对象setTimeout(obj.foo,1000); // 3. 对象方法不会执行对象绑定，下面的对象绑定都会丢失// 函数别名var bar = obj.foo(); // 作为参数传递，也发生了赋值操作bar(obj.foo);// 间接调用(p.foo = obj.foo)(); // 相当于对函数立即执行，内部的this默认指向了window(false || obj.foo)();(1,obj.foo)();]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 JavaScript 基础类型的包装类型]]></title>
    <url>%2F2020%2F08%2F08%2Fweb%2FJavaScript%2Fjs_5%2F</url>
    <content type="text"><![CDATA[为了便于操作 JavaScript 中的基础类型，JavaScript 提供了基础类型的包装类型，包括 Number，Boolean，String，它们属于引用类型。 1. 基本类型类型的包装类型每当读取一个基本类型值的时候，后台就会创建一个对应的基本包装类型的对象，从而让我们能够调用一些方法来操作这些数据。 12var s1 = "some text"var s2 = s1.substring(2) s1 是基本类型字符串，基本类型值不是对象，因而从逻辑上讲它们不应该有方法。为了方便操作基本类型，后台已经自动完成了一系列的处理。当第二行代码访问s1时，访问过程处于一种读取模式，也就是要从内存中读取这个字符串的值。 而在读取模式中访问字符串时，后台都会自动完成下列处理: 创建String类型的一个实例 在实例上调用指定的方法 销毁这个实例 可以将以上三个步骤想象成是执行了下列ECMAScript代码。123var s1 = new String("some text");var s2 = s1.substring(2);s1 = null; 1.1 基本包装类型的生命周期引用类型与基本包装类型的主要区别就是对象的生存期: 使用new操作符创建的引用类型的实例，在执行流离开当前作用域之前都一直保存在内存中 自动创建的基本包装类型的对象，则只存在于一行代码的执行瞬间，然后立即被销毁，这意味着我们不能在运行时为基本类型值添加属性和方法 123var s1 = "some text"s1.color = "red" // console.log(s1.color) // null 第二行创建的String对象在执行第三行代码时已经被销毁了。第三行代码又创建自己的String对象，该对象是没有 color 属性的。 1.2 基本包装类型的使用注意可以显式地调用Boolean、Number和String来创建基本包装类型的对象。不过，应该在绝对必要的情况下再这样做，因为这种做法很容易让人分不清自己是在处理基本类型还是引用类型的值。 对基本包装类型的实例调用typeof会返回”object”，而且所有基本包装类型的对象在转换为布尔类型时值都是true。 Object构造函数也会像工厂方法一样，根据传入值的类型返回相应基本包装类型的实例。 12var v = new Object("text");v instanceof String; // true 要注意的是，使用new调用基本包装类型的构造函数，与直接调用同名的转型函数是不一样的。因为一个是创建了新的对象，一个是类型转换。 2. Boolean 类型Boolean类型是与布尔值对应的引用类型。因为 Boolean 包装对象没有什么可用方法，而且因为它是对象，对象的布尔值总为 true，在使用上返回会造成无解，因此永远不要使用 Boolean 包装对象。 12var b = new Boolean(false)console.log(b &amp;&amp; true) // true 3. Number 类型Number是与数字值对应的引用类型。Number 包装类型有如下属性和方法 属性/方法 作用 valueOf() 返回对象的基本类型的值 toString(base) 返回字符串形式的数值，base 表示数值的进制 toLocaleString(base) 同 toString() toFixed(n) 按照指定的小数位返回数值的字符串表示，n 表示小数位个数 toExponential(n) 返回以指数表示法（也称e表示法）表示的数值的字符串形式，n 表示小数位个数 toPrecision(n) 返回数值的最合适表示方式，n 表示所有数字的位数 4. String 类型String类型是字符串的对象包装类型。String 包装类型有如下属性和方法 属性/方法 作用 length 返回字符串的长度 charAt(n) 以单字符字符串的形式返回给定位置的那个字符 charCodeAt(n) 获取指定位置字符的编码 [n] 可以使用方括号加数字索引来访问字符串中的特定字符 concat(s1, s2,..) 拼接字符串，不如 + 好用 indexOf(substr, start) 从start 位置开始，从前往后，查找子串的位置 lastIndexOf(substr, start) 从start 位置开始，从后往前，查找子串的位置 trim() 去除首尾空格 toLowerCase() 转小写 toLocaleLowerCase() 转小写 toUpperCase() 转大写 toLocaleUpperCase() 转大写 localeCompare(string) 字符串比较，-1 表示字符串在参数字符串前，0 表示相等，1 表示在之后，返回值取决于实现 String.fromCharCode(num1, num2) 将字符编码转换为字符串 4.1 获取子串slice, substring, substr 用于获取字符串的子串: slice(start, [end]: 返回: 开始到结束位置的子串 start: 负值会与字符串长度相加 end: 负值会与字符串长度相加，省略表示到字符串结尾 substring(start, [end]): 返回: 开始到结束位置的子串，会自动把 start 和 end 中的较小值作为 start start: 负值转换成 0 end: 负值转换成 0，省略表示到字符串结尾 substr(start, [len]) 返回: 开始位置，长度为 len 的子串 start: 负值会与字符串长度相加 len: 负值转换成 0，省略表示到字符串结尾 4.2 字符串模糊匹配match(RegExp): 作用: 与调用RegExp的exec()方法相同 search(RegExp) 作用: 返回字符串中第一个匹配项的索引；如果没有找到匹配项，则返回-1 注意: search()方法始终是从字符串开头向后查找模式 4.3 字符串替换replace(string|RegExp, string|function): 作用: 字符串替换 参数一: 可以是一个RegExp对象或者一个字符串（这个字符串不会被转换成正则表达式） 是字符串，那么只会替换第一个子字符串 要想替换所有子字符串，唯一的办法就是提供一个正则表达式，而且要指定全局（g）标志 参数二: 第二个参数可以是一个字符串或者一个函数 可以使用特殊字符序列，引用最近一次匹配结果，这些特殊字符就是RegExp 中的短属性名 $$: $ 本身 $n: 第 n 个匹配组 $nn: 第 1-99 个匹配组 如果是函数，在只有一个匹配项，会接收 3个参数： 模式的匹配项 模式匹配项在字符串中的位置 原始字符串 如果是函数，在正则表达式中定义了多个捕获组的情况下，传递给函数的参数依次是 模式的匹配项、第一个捕获组的匹配项、第二个捕获组的匹配项……， 最后两个参数仍然分别是模式的匹配项在字符串中的位置和原始字符串 123456var text = "cat, bat, sat"text.replace("at", "ood")text.replace(/at/g, "ood")text.replcae(/(.at)/g, "word ($1)") 4.4 字符串分割split(string|RegExp, n): 作用: 分割字符串为数组 参数1: 字符串或者正则表达式，字符串不会自动转为 正则表达式 参数2: 指定数组的大小 1234var color = "red,black,blue"color.split(",")color.split(",", 2) // [red, black]color.split(/[^\,]+/) // ["", ",", ","]]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 JavaScript 内置的引用类型]]></title>
    <url>%2F2020%2F08%2F07%2Fweb%2FJavaScript%2Fjs_4%2F</url>
    <content type="text"><![CDATA[如同其他语言一样，为了提高编程的效率，JavaScript 内置了常用的”数据结构”，包括 Array、Date、RegExp，在 JavaScript 它们都是引用类型。这些内置类型一般的有构造函数和字面量两种创建方式。 1. ArrayJavaScript 的数组的每一项可以保存任何类型的数据，并且大小是可以动态调整的。数组的创建有两种方式: Array 构造函数 数组字面量: 不会调用Array构造函数 123456789101112131415var colors= new Array() // new 关键字可以省略var colors= Array(20) // 指定数组的长度var colors= new Array("red", "blue") // 直接传入数组的项var values = [1, 2, 3] // 数组字面量// 数组类型检测// 1. 对于一个网页，或者一个全局作用域，可以使用 instanceofif (value instanceof Array)&#123;&#125;// 2. 确定某个值到底是不是数组，而不管它是在哪个全局执行环境中创建的if (Array.isArray(value))&#123;&#125; 使用 instanceof 进行类型检测的问题在于，它假定只有一个全局执行环境。如果网页中包含多个框架，那实际上就存在两个以上不同的全局执行环境，从而存在两个以上不同版本的Array构造函数。如果你从一个框架向另一个框架传入一个数组，那么传入的数组与在第二个框架中原生创建的数组分别具有各自不同的构造函数。从而导致检测失败。 1.1 Array 数组长度数组长度保存在 length 属性中，与其他语言相比，JavaScript 数组在扩展上有下面一些特性: 如果设置某个值的索引超过了数组现有项数，数组就会自动增加到该索引值加1的长度，新增的每一项都会取得undefined值 Arrary.length 属性不是只读的，通过设置这个属性，可以从数组的末尾移除项或向数组中添加新项 数组最多可以包含4294967295个项 1.2 Array 的属性和方法通用方法 属性/方法 作用 示例 valueOf() 返回数组本身 toString() 对每一项调用 toString()，并返回逗号分隔的字符串 toLocalString() 对每一项调用 toLocalString()，并返回逗号分隔的字符串 join(seq) 返回以特定字符分隔的字符串，seq默认为逗号 push(arg1,arg2) 将任意项添加到数组末尾，返回修改后数组长度 pop() 弹出数组末尾项 shift() 移除数组中的第一个项并返回该项，同时将数组长度减1 unshift(arg1, arg2) 在数组前端添加任意个项并返回新数组的长度 reverse() 反转数组 sort(func) 默认调用每个数组项的toString()并排序，func 是用于决定如何排序的函数 concat(item, array) 默认返回当前数组的副本，有参数返回合并后的数组 slice(start, end) 切片，支持负索引 indexOf(item, [start]) 从前往后查找，严格相等 lastIndexOf(item, [start]) 从后往前查找，严格相等，start 是正向索引 注意: 如果数组中的某一项的值是null或者undefined，那么该值在join()、toLocaleString()、toString()和valueOf()方法返回的结果中以空字符串表示。 123456var a = [1, 3, 2]a.sort(function (v1, v2)&#123; return v2 - v1&#125;)b = a.concat(4, [20, 13]) 数组项删除和替换splice(start, del_num, item1, item2…): 作用: 向数组中插入项，返回一个数组，包含删除的项 参数: start: 开始位置，从 0 开始 del_num: 删除的项数 其他: 插入项 123456var color = ['red', 'green', 'black]&gt; color.splice(0, 1) // 删除第一项["red"]&gt; color.splice(1, 0, 'yellow', 'test') // 从第二项开始插入 数组迭代迭代方法: every()：对数组中的每一项运行给定函数，如果该函数对每一项都返回true，则返回true。 filter()：对数组中的每一项运行给定函数，返回该函数会返回true的项组成的数组。 forEach()：对数组中的每一项运行给定函数。这个方法没有返回值。 map()：对数组中的每一项运行给定函数，返回每次函数调用的结果组成的数组。 some()：对数组中的每一项运行给定函数，如果该函数对任一项返回true，则返回true。 每个方法都接收两个参数：要在每一项上运行的函数和（可选的）运行该函数的作用域对象。传入这些方法中的函数会接收三个参数：数组项的值、该项在数组中的位置和数组对象本身。 1234var num = [1, 2, 5, 10]everyResult = num.every(function (item, index, array)&#123; return item &gt; 2&#125;) 归并 reduce(): 从左往右合并 reduceRight(): 从右往左合并 这两个方法都接收两个参数：一个在每一项上调用的函数和（可选的）作为归并基础的初始值。传给reduce()和reduceRight()的函数接收4个参数：前一个值、当前值、项的索引和数组对象。 1234var num = [1, 2, 3, 4]var sum = num.reduce(function(pre, cur, index, array)&#123; return pre + cur&#125;, 1) // 11 2. DateDate 对象的创建有四种方式: new + Date() 构造函数: 通过时间戳创建 Date 对象 Date.parse(): 解析字符串时间为 Date 对象 Date.UTC(): 返回参数表示时间的时间戳，Date.UTC()的参数分别是: 年份 基于0的月份（一月是0，二月是1，以此类推） 月中的哪一天（1到31） 小时数（0到23）、分钟、秒以及毫秒数 Date.now(): 返回调用此方法时的时间戳12345678910111213141516171819// 1. 构造函数var now = new Date() // 不带参数返回当前时间的 Date 对象var now = new Date(1602380330000) // 可接受一个毫秒的时间戳，返回对应时间的 Date对象// 2. parse 方法// 直接将表示日期的字符串传递给Date构造函数，会在后台调用 Date.parse()var now = new Date("2019-10-11: 10:10:10")var now = new Date.parse("2019-10-11: 10:10:10")// 3. UTC 方法var stamp = Date.UTC(2020, 10) // 11 月var d = new Date(stamp)// 如同模仿Date.parse()一样，Date构造函数也会模仿Date.UTC()var y2k = new Date(2020, 10)var t = new Date(2005, 4, 5, 10, 10, 23)// 4. 当前时间戳var stamp = Date.now() // 等同于 +new Date()var start =+new Date() // + 用于将 Date 对象转成 number 2.2 Date 的属性和方法 属性/方法 作用 示例 valueOf() 返回日期的毫秒表示 toString() 通常返回带有时区信息的日期和时间 toLocalString() 按照与浏览器设置的地区相适应的格式返回日期和时间 toDateString() 以特定于实现的格式显示星期几、月、日和年 toTimeString() 以特定于实现的格式显示时、分、秒和时区； toLocaleDateString() 以特定于地区的格式显示星期几、月、日和年； toLocaleTimeString() 以特定于实现的格式显示时、分、秒； toUTCString() 以特定于实现的格式完整的UTC日期 2.3 Date 时间格式化js 没有内置 Date 的时间格式化方法，下面是一个自定义的实现方式。方法里面用到了我们接下里要将的正则表达式 RegExp1234567891011121314151617181920Date.prototype.format = function(fmt) &#123; //author: meizz var o = &#123; "M+" : this.getMonth()+1, //月份 "d+" : this.getDate(), //日 "h+" : this.getHours(), //小时 "m+" : this.getMinutes(), //分 "s+" : this.getSeconds(), //秒 "q+" : Math.floor((this.getMonth()+3)/3), //季度 "S" : this.getMilliseconds() //毫秒 &#125;; if(/(y+)/.test(fmt)) fmt=fmt.replace(RegExp.$1, (this.getFullYear()+"").substr(4 - RegExp.$1.length)); for(var k in o) if(new RegExp("("+ k +")").test(fmt)) fmt = fmt.replace(RegExp.$1, (RegExp.$1.length==1) ? (o[k]) : (("00"+ o[k]).substr((""+ o[k]).length))); return fmt; &#125;var time1 = new Date().format("yyyy-MM-dd HH:mm:ss"); 3. RegExp 正则表达式对象3.1 RegExp 对象的创建JS 的正则表达式与其他语言没有太大差别，其有两种创建方式: 字面量: /pattern/flag 构造函数: new RegExp(pattern, flag) 12var p1 = /[bc]at/givar p2= new RegExp("[bcat]", "gi") 由于RegExp构造函数的模式参数是字符串，所以在某些情况下要对字符进行双重转义。所有元字符都必须双重转义，那些已经转义过的字符也是如此，例如\n（字符\在字符串中通常被转义为\，而在正则表达式字符串中就会变成\\）。下表给出了一些模式，左边是这些模式的字面量形式，右边是使用RegExp构造函数定义相同模式时使用的字符串。 字面量 构造函数 /[bc]at/ “/\[bc\]at/“ /\w\hello/ “\w\\hello” 3.2 RegExp 实例属性和方法 属性/方法 作用 global 布尔值，表示是否设置了g标志 ignoreCase 布尔值，表示是否设置了i标志 lastIndex 整数，表示开始搜索下一个匹配项的字符位置，从0算起 multiline 布尔值，表示是否设置了m标志 source 正则表达式的字符串表示，按照字面量形式而非传入构造函数中的字符串模式 toLocaleString() 返回正则表达式的字面量 toString() 返回正则表达式的字面量 exec 方法exec(string) 作用: 返回包含第一个匹配项信息的数组，没有匹配时返回 null 返回的数组虽然是Array的实例，但包含两个额外的属性：index和input。 index表示匹配项在字符串中的位置，而input表示应用正则表达式的字符串 匹配项: 在数组中，第一项是与整个模式匹配的字符串 其他项是与模式中的捕获组匹配的字符串（如果模式中没有捕获组，则该数组只包含一项） 注意: 对于exec()方法而言，即使在模式中设置了全局标志（g），它每次也只会返回一个匹配项。 设置全局标志时: lastIndex的值在每次调用exec()后都会增加 每次调用exec()则都会在字符串中继续查找新匹配项 不设置全局标志 lastIndex 始终不变 每次返回第一个匹配项目 12345678910111213var text = "cat, dat, vat, tat"var p = /(.at)/m = p.exec(text) // m 将包含匹配项[cat, cat]m[0] // 与整个模式匹配的字符串m[1] // 匹配的分组// 1. 不设置全局标志 g，对同一字符串， exec 总是返回第一个匹配项m = p.exec(text) // m 仍将将包含匹配项[cat, cat]// 在全局匹配模式下，var p1 = /(.at)/g p1.exec(text) // [cat, cat]p2.exec(text) // [dat, dat] test 方法text(string): 返回: 模式与字符串匹配成功时返回 true, 否则返回 false 3.3 RegExp 构造函数属性和方法RegExp构造函数包含一些属性，适用于作用域中的所有正则表达式，并且基于所执行的最近一次正则表达式操作而变化。使用这些属性可以从exec()或test()执行的操作中提取出更具体的信息。这些属性分别有一个长属性名和一个短属性名: 长属性名 短属性名 说明 input $_ 最近一次要匹配的字符串 lastMatch $&amp; 最近一次的匹配项 lastParen $+ 最近一次匹配的捕获组 leftContext $` input 字符串中，lastMatch 之前的文本 rightContext $’ input 字符串中，lastMatch 之后的文本 multiline $* 布尔值，表示所有表达式是否都使用多行文本 $1-$9 存储第一、第二……第九个匹配的捕获组 12345678var text = "aa short bb thort"var p = /(.)hort/gif (p.test(text))&#123; console.log(RegExp.input) // aa short bb thort console.log(RegExp.lastMatch) // short console.log(RegExp.lastParen) // s console.log(RegExp.leftContext) // aa&#125; 4. Math 数学对象Math 数学对象提供了常用的数学常量以及一些辅助科学计算的函数。 4.1 Math 对象常用属性和方法 属性/方法 作用 PI E LN2 LN0 LOG2E SQRT2 平方根 min(n1,n2….) max(n1,n2….) ceil(num) 向上取整 floor(num) 向下取整 round(num) 四舍五入 random() 0-1的随机数 1234// 1. 求数组最大最小值var num = [1,3,4,10,3]Math.min.apply(null, num)Math.max.apply(null, num)]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 JavaScript 基本语法]]></title>
    <url>%2F2020%2F08%2F06%2Fweb%2FJavaScript%2Fjs_3%2F</url>
    <content type="text"><![CDATA[本节我们来介绍 J avaScript 中的基本概念，包括语法、变量，数据类型，操作符，流控以及函数，这些基础概念构成了一门编程语言的骨架。 1. 语法12 JavaScript 是一门类 C 语言，语法具有如下特性: 区分大小写 标识符: 标识符，是指变量、函数、属性的名字，或者函数的参数 与其 Python/Go 不同的是，JavaScript 的标识符可以包含或者以 $ 开头 官方推荐使用驼峰命名方式 注释: 单行注释: // 多行注释: /* */ 语句: 以分号结尾，可省略，但不建议省略 代码结尾处没有分号会导致压缩错误 代码块: {} 函数: 是一种引用类型的值，使用 function 关键词来申明 默认没有返回值 1.1 严格模式ES5 引入了严格模式（strict mode）的概念，在严格模式下可以避免 ES3 中一些不明确行为，对于不安全行为也会抛出异常。要在整个脚本中启用严格模式，可以在顶部添加 &quot;use strict&quot;;。这是一个编译指示，用于告诉支持的JavaScript引擎切换到严格模式。在函数内部的上方包含这条编译指示，也可以指定函数在严格模式下执行： 1234function doS()&#123; "use strict"; // TODO:&#125; 2. 流控JavaScript 支持一下流控语句: 判断: if/switch 循环: do-while/while/for lable/break/continue 枚举: for-in with 2.1 条件判断1234567891011121314151617181920212223242526272829if (i &gt; 25) &#123; alert("Greater than 25.");&#125; else if (i &lt; 0) &#123; alert("Less than 0.");&#125; else &#123; alert("Between 0 and 25, inclusive."); // 不要忘记结尾的分号&#125;switch (i) &#123; case 25: /* 合并两种情形 */ case 35: alert("25 or 35"); break; // 必须显示使用 break 退出 case 语句 default: alert("Other");&#125;var num = 25;switch (true) &#123; case num &lt; 0: alert("Less than 0."); break; case num &gt;= 0 &amp;&amp; num &lt;= 10: alert("Between 0 and 10."); break; default: alert("More than 10.");&#125; JS 的 switch 有以下特色: 要退出 switch 必须在每个 case 语句显示使用 break，类似 shell switch 可以使用任何类型，包括变量或者表达式 switch语句在比较值时使用的是全等操作符，因此不会发生类型转换 2.2 循环12345678910111213141516171819202122232425262728293031do &#123; statement&#125; while(expression); // 不要忘记结尾的分号while(expression)&#123; statement&#125;var count = 10;for (var i = 0; i &lt; count; i++)&#123; alert(i);&#125;for (;;) &#123; // 无限循环 doSomething();&#125;// label 用于执行类似 goto d的语句var num = 0;outermost:for (var i=0; i &lt; 10; i++) &#123; for (var j=0; j &lt; 10; j++) &#123; if (i == 5 &amp;&amp; j == 5) &#123; break outermost; &#125; num++; &#125;&#125;alert(num); //5 2.3 枚举对象属性123for (var propName in window) &#123; document.write(propName);&#125; 在使用for-in循环时，返回的是所有能够通过对象访问的、可枚举的（enumerated）属性，其中既包括存在于实例中的属性，也包括存在于原型中的属性。屏蔽了原型中不可枚举属性（即将[[Enumerable]]标记为false的属性）的实例属性也会在for-in循环中返回。属性特性我们会在后面面向对象中详细介绍。 2.4 withwith语句的作用是将代码的作用域设置到一个特定的对象中 12345with(location)&#123; var qs = search.substring(1); var hostName = hostname; var url = href;&#125; 在with语句的代码块内部，每个变量首先被认为是一个局部变量，而如果在局部环境中找不到该变量的定义，就会查询location对象中是否有同名的属性。如果发现了同名属性，则以location对象属性的值作为变量的值。 由于大量使用with语句会导致性能下降，同时也会给调试代码造成困难，不建议使用with语句。 3. 操作符与其他语言不同的是 JavaScript 的操作符包含了复杂的类型转换，总体上: 数值运算法需要将其他类型转换为数值类型在进行运算，比如一元运算，位运算，乘除取模运算，但是不包括加法运算 布尔运算支持短路逻辑，在用于条件判断时，总是将其他类型转换为布尔值在进行运算 NaN，Infinity, Null, Undefined 需要特殊对待 3.1 一元运算符一元运算符包括: +/-/后置++/后置–/前置++/前置–: 会执行同 Number() 函数一样的转换逻辑 delete: 删除对象 typeof: 检测变量类型 void: in deletedelete: 删除一个对象或一个对象的属性或者一个数组中某一个键值 能使用 delete 删除各种各样的隐式声明， 但是被var声明的除外 如果 delete可行会返回true，如果不成功返回false 1234delete objectName;delete objectName.property;delete objectName[index];delete property; // legal only within a with statement voidinin操作符会在通过对象能够访问给定属性时返回true，无论该属性存在于实例中还是原型中。 instanceof3.2 位运算符位运算符包括: a &amp; b: 按位与 AND a | b: 按位或 OR a ^ b: 按位异或 XOR ~a: 按位非 NOT a &lt;&lt; b: 左移 shift a &gt;&gt; b: 算术右移 a &gt;&gt;&gt; b: 无符号右移 3.3 布尔运算JS 的布尔运算支持短路逻辑，跟 Python 一样，如果操作数不是布尔值，逻辑运算符不一定返回布尔值。 布尔运算符包括: 逻辑与 (&amp;&amp;): expr1 &amp;&amp; expr2 如果第一个操作数是对象，则返回第二个操作数； 如果有一个操作数是null，则返回null；如果有一个操作数是NaN，则返回NaN；如果有一个操作数是undefined，则返回undefined。 逻辑或 (||): expr1 || expr2 如果第一个操作数是对象，则返回第一个操作数； 如果两个操作数都是null，则返回null；如果两个操作数都是NaN，则返回NaN；如果两个操作数都是undefined，则返回undefined。 逻辑非 (!): !expr 如果操作数是任意非0数值（包括Infinity），返回false； 如果操作数是null，返回true；如果操作数是NaN，返回true；如果操作数是undefined，返回true。 3.5 算术运算乘法(*)遵循如下转换规则: 如果有一个操作数是NaN，则结果是NaN； 如果是Infinity与0相乘，则结果是NaN； 如果是Infinity与非0数值相乘，则结果是Infinity或-Infinity，取决于有符号操作数的符号； 如果是Infinity与Infinity相乘，则结果是Infinity； 如果有一个操作数不是数值，则在后台调用Number()将其转换为数值，然后再应用上面的规则。 除法(*)遵循如下转换规则: 如果有一个操作数是NaN，则结果是NaN； 如果是Infinity被Infinity除，则结果是NaN； 如果是零被零除，则结果是NaN； 如果是非零的有限数被零除，则结果是Infinity或-Infinity，取决于有符号操作数的符号； 如果是Infinity被任何非零数值除，则结果是Infinity或-Infinity，取决于有符号操作数的符号； 求模(%)遵循如下转换规则: 如果被除数是无穷大值而除数是有限大的数值，则结果是NaN； 如果被除数是有限大的数值而除数是零，则结果是NaN； 如果是Infinity被Infinity除，则结果是NaN； 果被除数是有限大的数值而除数是无穷大的数值，则结果是被除数； 减法(-)遵循如下转换规则: 如果是Infinity减Infinity，则结果是NaN； 如果是+0减+0，则结果是+0；如果是+0减-0，则结果是-0；如果是-0减-0，则结果是+0； JS 加法运算符的转换逻辑更加复杂，针对不同类型有不同的计算逻辑: 数值类型: 如果有一个操作数是NaN，则结果是NaN； 如果是Infinity加-Infinity，则结果是NaN； 如果是+0加+0，则结果是+0；如果是-0加-0，则结果是-0；如果是+0加-0，则结果是+0。 字符串类型: 如果两个操作数都是字符串，则将第二个操作数与第一个操作数拼接起来； 如果只有一个操作数是字符串，则将另一个操作数转换为字符串，然后再将两个字符串拼接 其他运算: 如果有一个操作数是对象、数值或布尔值，则调用它们的toString()方法取得相应的字符串值，然后再应用前面关于字符串的规则。 对于undefined和null，则分别调用String()函数并取得字符串”undefined”和”null”。 1234var num1 = 5;var num2 = 10;var message = "The sum of 5 and 10 is " + num1 + num2;alert(message); // "The sum of 5 and 10 is 510" 3.6 关系运算符关系运算符运算符包括: &gt;&lt;: 如果两个操作数都是字符串，则比较两个字符串对应的字符编码值。 如果一个操作数是布尔值，则先将其转换为数值，然后再执行比较。 在比较数值和字符串时，字符串都会被转换成数值，然后再以数值方式与另一个数值比较 ==/!=: 相等/不相等 – 先转换在比较 布尔值-&gt;数值 如果一个操作数是字符串，另一个操作数是数值，将字符串转换成数值 如果一个操作数是对象，另一个操作数不是，则调用对象的valueOf()方法，用得到的基本类型值按照前面的规则进行比较； null和undefined是相等的，要比较相等性之前，不能将null和undefined转换成其他任何值。 NaN 与任何值不等 如果两个操作数都是对象，则比较它们是不是同一个对象 ===/!===: 全等和不全等 – 仅比较不转换 不转换类型条件下相等 null == undefined会返回true，因为它们是类似的值；但null === undefined会返回false，因为它们是不同类型的值。 3.7 条件操作符1variable = boolean_expression ? true_value : false_value; 3.8 逗号操作符逗号在 JS 中有以下几个作用: 使用逗号操作符可以在一条语句中执行多个操作，多用于声明多个变量； 除此之外，逗号操作符还可以用于赋值。在用于赋值时，逗号操作符总会返回表达式中的最后一项 12var num1=1,num2=2var num = (5, 1, 4, 8, 0); // num的值为0 4. 错误处理JavaScript 中使用 try-catch-finally 和 throw 来处理和触发异常，他们的语法如下: 123456789try &#123; // code&#125; catch(error)&#123; // 错误处理&#125; finally &#123; // 无论如何都会执行的代码 return value; // finally 的返回值将覆盖 try 与 catch 中的返回值&#125; 4.1 try-catch-finally catch块会接收到一个包含错误信息的对象，错误对象包含如下属性: message: 保存着错误消息的message属性 name: 保存着错误类型 其他属性因浏览器而异 只要代码中包含finally子句，则无论try或catch语句块中包含什么代码——甚至return语句，都不会阻止finally子句的执行 catch或finally有一个即可 所以下面的函数执行返回的是 0 而不是 2，因为 finally 语句无论如何都会执行 123456789function finallyTest()&#123; try&#123; return 0 &#125; catch &#123; return 1 &#125; finally &#123; return 2 &#125;&#125; 4.2 错误类型ECMA-262定义了下列7种错误类型： Error: 基类型，其他错误类型都继承自该类型 很少直接使用，主要用于自定义异常类型 EvalError RangeError: 索引或数值超过范围 ReferenceError: 找不到对象 SyntaxError: 语法错误 TypeError: 类型不支持要求的属性或方法 URIError: 使用encodeURI()或decodeURI()，URI格式不正确 可以像下面这样在try-catch语句的catch语句中使用instanceof操作符来判断具体的错误类型 1234567try &#123; // code&#125; catch(error)&#123; if (error instanceof ReferenceError)&#123; &#125;&#125; 4.3 自定义和抛出异常利用原型链还可以通过继承Error来创建自定义错误类型。需要为新创建的错误类型指定name和message属性。 1234567function CustomError(message)&#123; this.name = "CustomError"; this.message = message;&#125;CustomError.prototype = new Error();thro new CustomError("custom error"); throw操作符，用于抛出异常: 抛出错误时，必须要给throw操作符指定一个值，这个值是什么类型，没有要求 在遇到throw操作符时，代码会立即停止执行。仅当有try-catch语句捕获到被抛出的值时，代码才会继续执行 123// throw 必须指定一个值throw 123445throw True 抛出自定义异常的另一种方式是使用 assert() 函数，其接受两个参数: 一个是求值结果应该为true的条件 另一个是条件为false时要抛出的错误 1assert(condition, err_msg); 4.4 错误事件事件的具体内容我们会在后面详细介绍，此处只需要知道: 任何没有通过try-catch处理的错误都会触发window对象的error事件。 4.5 如何避免错误避免发生错误有如下建议: 类型判断: 在使用变量前进行变量类型检测，基本类型的值应该使用typeof来检测，而对象的值则应该使用instanceof来检测 对于查询字符串，必须要使用encodeURIComponent()函数进行编码 4.6 如何把错误记录到服务器可以使用下面的函数把页面错误记录到后台服务器: 1234function logError(sev, msg)&#123; var img = new Image(); img.src = "log.php?sev=" + encodeURIComponent(sev) + "&amp;msg=" + encodeURIComponent(msg);&#125; 使用了Image对象来发送请求，这样做非常灵活，主要表现如下几方面 所有浏览器都支持Image对象，包括那些不支持 XMLHttpRequest 对象的浏览器 可以避免跨域限制，通常都是一台服务器要负责处理多台服务器的错误，而这种情况下使用XMLHttpRequest是不行的]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 JavaScript 变量和类型系统]]></title>
    <url>%2F2020%2F08%2F05%2Fweb%2FJavaScript%2Fjs_2%2F</url>
    <content type="text"><![CDATA[本节我们来介绍 JavaScript 中的数据类型 1. JavaScript 的变量和类型JavaScript 有 6 种基本类型: Undefined: 未定义，变量已经声明但未赋值 Null: Boolean Number String Object: 对象，本质上是一组无序的键值对 JavaScript 中的变量是松散类型，可以用来保存任意类型的数据，即变量没有类型，值具有类型。每个变量仅仅是一个用于保存值的占位符而已。变量的定义有如下几种方式: 123message = 10; // 无论在何处都会声明一个全局变量，不建议使用var message; var a = "hi"; 1.1 值与引用按照值在变量中的保存方式，类型又分为: 基础类型值: 除 Object 外其他类型都是基础类型值，变量中保存的是实际的值 占据固定大小的空间，因此被保存在栈内存中 引用类型值: Object 是引用类型值，变量中保存的是对象的引用，Object 实际保存在堆内存中 在 JavaScript 中变量的赋值和参数的传递是按值传递的，这意味着: 对于基础类型的值，在赋值和传参时会创建一个新值 对于引用类型的值，赋值和传参时创建的是对象的引用，它们指向的是相同的对象，类似 Python 中的共享引用 12345678// 基础类型值无法动态添加属性var a=10a.age=10console.log(a.age) // undefinedvar a = new object()a.age=10console.log(a.age) // 10 1.2 基本类型与基本类型的包装类型除了特殊的 Undefined 和 Null，Number，String，Boolean 都有与之对应的包装类型。包装类型属于引用类型，用于为这三种类型添加属性和方法，便于对他们的操作。 除此之外我们只能给引用类型的值可以动态的添加属性，不能给基础类型的值动态的添加属性。 接下来我们会一一讲解这六种类型的使用以及用于变量类型检测的 typeof 操作符。Object 对象与 JavaScript 的原型链密切相关我们之后在作更详细介绍。之所以要先介绍 JavaScript 里面的数据类型，是因为 JavaScript 里面数据类型有一套非常复杂的转换关系，在后面介绍的操作符等语法知识时需要它们的转换规则。 2. 变量类型检测确定一个值是哪种基本类型可以使用typeof操作符，而确定一个值是哪种引用类型可以使用instanceof操作符。 2.1 检测变量类型使用 typeof 关键字可以检测给定变量的数据类型(准确来说是变量中存储值的数据类型)。 对一个值使用typeof操作符可能返回下列某个字符串： “undefined”: Undefined “boolean”: Boolean “string”: String “number”: Number “object”: 对象或null “function”: 函数 注意调用typeof null会返回”object”，因为特殊值null被认为是一个空的对象引用。从技术角度讲，函数在ECMAScript中是对象，不是一种数据类型。然而，函数也确实有一些特殊的属性，因此通过typeof操作符来区分函数和其他对象是有必要的。 2.2 检测对象所属的原型使用 instanceof 操作符可以检测对象所属的原型，通过原型链来识别。后面我们会详细介绍原型以及原型的实例。按照规定所有引用类型的值都是 Object 的实例，Object 是原型链的起点。instanceof 语法如下: 1var result variable instanceof constructor 2. Undefined在使用var声明变量但未对其加以初始化时，这个变量的值就是undefined。不过值为 undefined 的变量与未声明的变量还是不一样的，对于尚未声明过的变量，只能执行一项操作，即使用typeof操作符检测其数据类型。对未初始化和未声明的变量执行 typeof 操作符都会返回 undefined。所以除非显示初始化，否则无法通过 typeof 判断对象是未声明，还是未初始化。 12345678var message alter(message == undefined) // true// var agealter(age) // 产生错误alter(typeof message) // undefinedalter(typeof age) // undefined 3. Null从逻辑角度来看，null值表示一个空对象指针，而这也正是使用typeof操作符检测null值时会返回”object”的原因。如果定义的变量准备在将来用于保存对象，那么最好将该变量初始化为null而不是其他值。实际上，undefined值是派生自null值，undefined == null 相等性测试总是返回 true。 1234var car=null;alter(typeof car) // "object"alter(undefined == null) // true 4. BooleanJavaScript 中的布尔值是小写的 true 和 false。 使用 Boolean() 函数可以将任意其他类型转换为布尔类型。下面是转换的规则: string: 空字符串-&gt;false number: 0/NaN-&gt;false 对象: -&gt;true null/undefined: -&gt;false 除了显示类型转换，在所有的条件判断中都会发生上述的类型转换。 5. NumberJavaScript 种以下几个特殊的数值: Number.MIN_VALUE: 表示浮点数的下限，最小值 Number:MAX_VALUE: 表示浮点数的上限，最大值 -+Infinity: 表示超出数值范围的值 Number.POSITIVE_INFINITY 表示 +Infinity Number.NEGATIVE_INFINITY 表示 -Infinity 使用 isFinite()函数可判断值是否在数值范围内 NaN: 非数值，用于表示本来要返回数值的操作为返回数值的情况，例如除 0 操作 NaN 与任何值的操作都返回 NaN NaN 与任何值不相等，包括自身 isNaN() 函数用于判断值是否为 NaN JavaScript 中有三个函数可以把非数值转换为数值: Number(num): 任意类型转换为数值 parseInt(num, base): 将字符串转换为整型 parseFloat(num): 将字符串转换成整数或浮点数 Number() 函数有一套复杂的转换规则，简单总结起来: true/false -&gt; 1/0 null -&gt; 0 undefined -&gt; NaN string -&gt; 忽略空格和前缀 0，并按数值进行解析 而 paseInt 和 parseFloat 在解析字符串时，会忽略字符串前面的空格，直至找到第一个非空字符，如果第一个非空字符不是数字或负号就返回 NaN(parseInt(&quot;&quot;) 会返回 NaN)。paseInt/parseFloat 会解析到最后或遇到一个非数字字符。例如 parseInt(123blue)-&gt;123 6. String在 JavaScript 中 String 可以使用单引号或双引号表示，并且是不可变类型，其包含如下属性或方法: length(): 返回字符串的长度 有两种方法可以将其他类型转换为 String: 值的 toString() 方法: 除了 null/undefined 其他所有的值都有 toString() 方法，该方法返回值的字符串表示 对于数值，toString()，还可以指定返回值的进制 String() 函数: 值有 toString() 方法: 返回 toString() 的返回值 null: 返回 “null” undefined: 返回 “undefined” 6. 对象Object 是引用类型，类似传统面向对象中的类。对象是 Object 的实例，是一组数据和功能的集合。JavaScript 使用原型的方式来实现面向对象编程。Object 有点类似 Python 中的 Object，它是所有对象的原型的启点，提供了一些基础公共方法。 JavaScript 中内置了很多有引用类型，比如 Array(数组)，RegExp(正则表达式)，Date(日期时间)，我们也可以自定义引用类型。如何使用这些引用类型以及自定义引用类型我们会一一介绍，我们先来看看如何使用 Object。 6.1 对象创建对于 Object 和内置引用类型的实例一般都有两种创建方式: new + 构造函数() 对象字面量: 不会调用 Object 构造函数 1234567891011// 创建 Object类型的实例并为其添加属性或方法，就可以创建自定义对象var person=Object()person.name="tsong"person.age=30// 对象字面量var person = &#123; name: "tsong", // 属性名可以加引号，也可以不加，默认都会转为字符串 age: 30, // 最后一个属性不能有逗号 5: "test" // 数值属性名会自动转换为字符串&#125; 6.2 属性访问对象属性可以通过 .，也可以通过[] 进行访问，使用方括号的主要优点是可以通过变量来访问属性，对于存在语法错误的属性只能通过方括号进行访问。 12pernon["name"]person.name 6.3 Object 提供的默认方法和属性Object 具有如下属性和方法: Constructor: 保存用于创建当前对象的函数 hasOwnProperty(propertyName): 用于检查给定的属性在当前对象实例中是否存在 注意不是在对象的原型中是否存在 isPrototypeOf(object): 检查传入的对象是否是另一个对象的原型 propertyIsEnumerable(propertyName): 用于检查给定的属性是否能够使用 for-in 语句来枚举 toLocaleString(): 返回对象的字符串表示，该字符串与执行环境的地区对应 toString(): 返回对象的字符串表示 valueOf(): 返回对象的字符串、数值或者布尔值表示，通常与 toString() 返回值相同 由于在ECMAScript中Object是所有对象的基础，因此所有对象都具有这些基本的属性和方法，通常会重载这些方法。但是从技术角度讲，ECMA-262中对象的行为不一定适用于JavaScript中的其他对象。浏览器环境中的对象，比如BOM和DOM中的对象，都属于宿主对象，因为它们是由宿主实现提供和定义的。ECMA-262不负责定义宿主对象，因此宿主对象可能会也可能不会继承Object 6.3 对象的类型转换JavaScript 中的对象存在类似 Python 中运算符重载的功能，对对象作的值类型转换或判断基本都会首先调用对象的valueOf()方法，然后确定该方法返回的值是否可以转换。如果不能，则基于这个返回值再调用toString()方法，再测试返回值。 由于 Object 对象与 JavaScript 原型链密切相关，更详细的内容我们后面介绍 JavaScript 面向对象时再来详述。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 JavaScript 入门开篇]]></title>
    <url>%2F2020%2F08%2F04%2Fweb%2FJavaScript%2Fjs_1%2F</url>
    <content type="text"><![CDATA[要学的东西很多，其中有个叫 JavaScript 1. 为什么要学 JavaScriptWeb 开发一直是自己的“魔怔”，从转行做开发开始就一直想做 Web 开发，直到现在也不算入门。正好最近想做一个炒股软件，把自己的一些验证想法实现出来，正好借此机会学习一下前端开发。 2. 前端开发的技术栈JavaScript 与我之前学习的 Go 和 Python 还不一样，HTML、CSS 和 JavaScript 是密切相关的。在我们学习JavaScript 之前有必要去了解它们之间的关系。下面是一段 HTML 代码: 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Data Structures and Algorithms with JavaScript&lt;/title&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons"&gt; &lt;link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.indigo-pink.min.css"&gt; &lt;script defer src="https://code.getmdl.io/1.3.0/material.min.js"&gt;&lt;/script&gt; &lt;base target="myFrame" /&gt; &lt;style&gt; .mdl-layout__content &#123; padding: 10px; &#125; .mdl-layout__drawer &#123; width: 290px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;!-- Simple header with scrollable tabs. --&gt; &lt;div class="mdl-layout mdl-js-layout mdl-layout--fixed-header"&gt; &lt;header class="mdl-layout__header"&gt; &lt;div class="mdl-layout__header-row"&gt; &lt;!-- Title --&gt; &lt;span class="mdl-layout-title"&gt;Learning JavaScript Data Structures and Algorithms&lt;/span&gt; &lt;/div&gt; &lt;!-- Chapters --&gt; &lt;div class="mdl-layout__tab-bar mdl-js-ripple-effect"&gt; &lt;a href="#scroll-tab-1" class="mdl-layout__tab is-active"&gt;01_02&lt;/a&gt; &lt;a href="#scroll-tab-3" class="mdl-layout__tab"&gt;03&lt;/a&gt; &lt;/div&gt; &lt;/header&gt; &lt;/div&gt;&lt;/body&gt; HTML、CSS 和 JavaScritp 通过如下的方式结合在一起: HTML: 静态网页，Web 展示的具体的内容 浏览器在读取完 HTML 代码之后，会将其加载成 DOM 树 DOM: 文档对象模型，提供了访问和操作网页的方法和接口 CSS: 通过 CSS 选择器选择 HTML 中的特定标签为其添加样式(布局，颜色和格式) CSS 选择器是浏览器提供了声明式查询语言，用于选择页面的特定节点 CSS 通过 &lt;link&gt; 和 &lt;style&gt; 标签插入到 HTML 中 JavaScript: 动态网页通过 JavaScript 实现动态交互部分 包括语言、文档对象模型(DOM)和浏览器对象模型(BOM)三个部分 语言: JavaScript 作为编程语言的部分 DOM: 提供访问和操作网页内容的方法和接口 BOM: 提供与浏览器交互的方法和接口 JavaScript 通过 &lt;script&gt; 标签插入到HTML页面中 2.1 script 标签向HTML页面中插入JavaScript的主要方法，就是使用&lt;script&gt; 标签，HTML 4.01为定义了下列几个属性: async： 可选。表示应该立即下载脚本，但不应妨碍页面中的其他操作，比如下载其他资源或等待加载其他脚本 对 async，HTML 的解析同脚本的获取是同时进行的，脚本获取完整就会立即执行，脚本执行期间 HTML 会停止解析 只对外部脚本文件有效。 charset： 可选。表示通过src属性指定的代码的字符集。由于大多数浏览器会忽略它的值，因此这个属性很少有人用 defer： 可选。表示脚本可以延迟到文档完全被解析和显示之后再执行。 只对外部脚本文件有效 src： 可选。表示包含要执行代码的外部文件 type：可选。默认值为text/javascript 有两种使用&lt;script&gt;标签的方式：直接在页面中嵌入JavaScript代码和包含外部JavaScript文件。 1234567&lt;script&gt; funciton sayHi()&#123; alter("hi") &#125;&lt;/script&gt;&lt;script src="js/test.js"&gt;&lt;/script&gt; 2.2 script 解析顺序无论如何包含代码，只要不存在defer和async属性，浏览器都会按照&lt;script&gt; 元素在页面中出现的先后顺序对它们依次进行解析。换句话说，在第一个&lt;script&gt;元素包含的代码解析完成后，第二个&lt;script&gt;包含的代码才会被解析，然后才是第三个、第四个……。为了避免页面加载过慢，现代Web应用程序一般都把全部JavaScript引用放在元素中页面内容的后面。 对于同一个域名，浏览器最多允许并发 4 个线程对页面中的文件进行下载，因此 JS 文件的下载通常不会阻塞 HTML 的解析。但是 JS 的执行可能会影响 HTML 的解析，JS 可能会往 DOM 树中插入元素。因此 JS 的执行与 HTML 的解析是互斥的。也就是说如果页面上有多个 JS 文件，他们的下载是可能是同时进行的，并且下载期间 HTML 正在解析 script 标签之前的元素，但是 HTML 必须要等到 JS 下载执行完之后才能继续解析后面 script 标签之后的部分。 defer 和 ansync 可以影响 JS 的执行时点: defer: 表示 JS 必须等到 HTML 解析完成后在执行 ansync: 表示对 JS 进行异步执行，也就是说，HTML 不必等到 JS 执行完毕才能解析 script标签后面的内容。JS 在下载完成后异步执行，此时才会暂停 HTML 的解析，此时 HTML解析所处的位置是完全不定的。 3. 怎么学 JavaScriptJavaScript 在标准化的过程经历过很多次变化，目前主要以 ES6 为主。我们主要学习 JavaScript 的语言部分，BOM 和 DOM 在现在的诸如 Vue 等高级框架中都有更高级的抽象来解决不同浏览器的差异问题。 有了前面学习 Python 和 Go 的经历，通过学习下面的知识我们可以快速的学习一门语言的语法: 变量、数值类型和流控，包括 变量及常量的命名，声明和创建 基础数据类型 自定义类型 类型转换 条件判断和循环 变量的生命周期与作用域 基础数据类型的使用 模块和包 异常处理 函数 基于原型的面向对象开发 4. 学习资料ES6 标准出来之后 JS 的语法变动很大，市面上的大多数书籍集中于介绍这些差异，看了不少本书的前序和目录，最后决定选择以下基本详细阅读: 《JavaScript高级程序设计（第3版）》: 学习 JS 的基本语法(ES5) 《学习JavaScript数据结构与算法（第3版）》: 学习 JS 如何实现常见的数据结构与算法 《JavaScript设计模式与开发实践》: 学习 JS 如何实现常见的设计模式 5. 环境搭建5.1 Chrom Web Serve为了便于执行 JS，我们需要一台Web服务器。如果不需要请求后台接口，我们可以在Chrome 安装一个简单的Web服务器，叫做Web Server for Chrome的扩展,安装好之后，可以在浏览器地址栏中输入chrome://apps来找到它。 打开Web Server扩展后，可以点击CHOOSE FOLDER来选择需要在哪个文件夹中开启服务器，默认的IP和端口是 http://127.0.0.1:8887。 5.2 Vscode 调试工具配置要直接在VSCode中调试JavaScript或ECMAScript代码，首先需要安装Debugger for Chrome扩展。然后，启动Web Server for Chrome扩展，并在浏览器中打开待调试的代码。下图展示了如何直接在 VScode 中进行调试。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5. 不相交集合]]></title>
    <url>%2F2020%2F07%2F05%2Falgo_bit%2F5_union%2F</url>
    <content type="text"><![CDATA[不相交集合 1. 不相交集合的抽象在图的最小生成树算法(Kruskal 算法)中我们看到了一个有趣的数据结构，不相交集合(Group ADT)。不相交集合用来对数据进行分组和合并，但不同于Python Set: 我们不期望遍历分组的内容 也不能有效的测试给定集合是否包含给定的元素 甚至每一个分组都是不相同的，不明确的结构 为了区分不同的组，每个组都有指定的条目，我们称之为组的领导 Group ADT 包含以下操作: make_group: 创建一个包含新元素 x 的组，并返回存储 x 的位置 union(p, q): 合并包含位置 p, q 的组 find(p): 返回包含位置 p 的组的领导的位置 2. 不相交集合实现下面是基于树的 Group ADT 具体实现: 123456789101112131415161718192021222324252627282930313233class Partition(object): __slots__ = '_container', '_element', '_size', '_parent' class Position(object): def __init__(self, container, e): self._container = container self._element = e self._size = 1 self._parent = self def element(self): return self._element def make_group(self, e): return self.Position(self, e) def find(self, p): if p._parent != p: # 路径压缩 p._parenet = self.find(p._parent) return p._parent def union(self, p, q): a = self.find(p) b = self.find(q) if a is not b: if a._size &gt; b._size: b._parent = a a._size += b._size else: a._parent = b._parent b._size += a._size 在上面的实现过程中，我们使用了一个非常惊奇的启发式方法，路径压缩: 在 find 操作中，对每个 find 函数访问过的位置 q，对根重置 q 的父节点 使得对 n 个元素，执行 k 次 make，union，find 操作的时间复杂度是 O(klog*n) 注: log*n=3 –&gt; n=2^2^2]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>好玩的数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4. 图]]></title>
    <url>%2F2020%2F07%2F04%2Falgo_bit%2F4_graph%2F</url>
    <content type="text"><![CDATA[图 1. 图的抽象1.1 图的基本概念在基础的数据结构中，图应该算的上最复杂的非线性数据结构了，包含了很多专业术语，比如: 顶点，边，权 顶点的度，入度，出度概念比较好理解，就不在此叙述了，我们的重点是如何实现一个图以及图相关的众多算法。 1.2 图的存储图有两种存储方式: 邻接矩阵 邻接表 邻接矩阵直观，将图的运算转换成了矩阵运算，快速但是对于稀疏图而言非常浪费空间。因为大多数情况下我们遇到的都是稀疏图，所以下面我们重点讲解邻接表的实现方式。 1.3 图的抽象表示图是顶点和边的集合，我们将图的抽象模型定义为三种数据类型的组合: Vertex,Edge 和 Graph。VertexVertex ADT 用来表示顶点对象，有一个用来检索所存储元素的方法 element() EdgeEdge ADT 用来表示边，并具有如下方法: element(): 返回保存的边的值 endpoint(): 返回边对应的(u, v)，u为边起点，v为边的终点 opposite(u): 传入边的一个端点，返回边的另一个端点 GraphGraph ADT 表示图，包含如下方法: 图的实现: insert_vertex(v=None): 创建并返回一个顶点的 Vertex 对象 insert_edge(u, v, x=None): 创建一个从顶点u 到顶点 v，存储元素 x 的 Edge 边对象 remove_vertex(v): 删除顶点及与顶点关联的边 remove_edge(e): 删除边 e 图的使用: vertex_count(): 返回图的顶点数量 vertices(): 迭代返回图中的所有顶点 edge_count(): 返回图的边的数量 edges(): 迭代返回图中的所有边 get_edge(u, v): 返回从顶点 u 到顶点 v 的边，不存在返回 None 对于无向图 get_edge(u, v)，get_edge(v, u) 没有区别 degree(v, out=True): 返回顶点的出度，out=False 返回顶点的出度 incident_edges(v, out=True): 迭代返回顶点 v 的输出边，out=False 迭代返回顶点的输入边 2. 图的邻接表实现为了方便的索引，顶点的出度(输出边)与入度(输入边)，我们使用两个字典来记录边的指向关系: outgoing={}: 来记录顶点的出度 incoming={}: 来记录顶点的入度 当我们插入有向边 (v, u, x) 和 (u, v, y) 时，需要执行:1234567# 插入边(v, u)outgoing[v][u]=x # 记录顶点 v 的输出边incoming[u][v]=x # 记录顶点 u 的输入边# 插入边(u, v)outgoing[u][v]=y incoming[v][u]=y 所以当删除顶点 v 时，我们需要执行上述插入的逆过程:123456789# 删除边 (v, u)，即删除 v 的输出边for u in outgoing[v].keys(): del incoming[u][v]del outgoing[v]# 删除边 (u, v)，即删除 v 的输入边for u in incoming[v].keys(): del outgoing[u][v]del incomming[v] 为了统一有向图和无向图的处理，在无向的情况下，outgoing is incoming，并通过参数 is_directed 来决定图是否为有向图。所以对于无向图而言，上述删除操作执行一组即可(outgoing is incoming 时，上面的两组删除是重复操作)。下面是图邻接表的具体实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100class Vertex(object): __slots__ = '_element' def __init__(self, x): self._element = x def element(self): return self._element def __hash__(self): return hash(id(self))class Edge(object): __slots__ = '_origin', '_destination', '_element' def __init__(self, u, v, x): self._origin = u self._destination = v self._element = x def opposite(self, v): return self._destination if v is self._origin else self._origin def endpoints(self): return self._origin, self._destination def __hash__(self): return hash((self._origin, self._destination))class Graph(object): def __init__(self, directed=False): """ :param directed: 是否创建有向图，默认为 False 表示创建无向图 """ self._outgoing = &#123;&#125; # key 为起点，value 为终点的 # 设计要点: key 为终点，value 为起点的，无向图_incoming 只是 _outgoing 的别名 self._incoming = &#123;&#125; if directed else self._outgoing def is_directed(self): return self._incoming is not self._outgoing def vertex_count(self): return len(self._outgoing) def vertices(self): return self._outgoing.keys() def edge_count(self): total = sum(len(self._outgoing[u]) for u in self._outgoing) if not self.is_directed(): total /= 2 return total def edges(self): result = set() # 对于无向图，需要去重 for u in self._outgoing: result.update(u.values()) return result def degree(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming return len(adj[v]) def incident_edge(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming for edge in adj[v].values: yield edge ################ 图实现的重点 ######################## def insert_vertex(self, x=None): v = Vertex(x=x) self._outgoing[v] = &#123;&#125; if self.is_directed(): self._incoming[v] = &#123;&#125; return v def insert_edge(self, u, v, x): e = Edge(u, v, x) self._outgoing[u][v] = e self._incoming[v][u] = e def remove_vertex(self, v): # 删除 v 的输出边 for u in self._outgoing[v].keys(): del self._incoming[u][v] del self._outgoing[v] # 删除以 v 输入边 if self.is_directed(): for u in self._incoming[v].keys(): del self._outgoing[u][v] del self._incoming[v] def remove_edge(self, e): u, v = e.endpoints() del self._outgoing[u][v] del self._incoming[v][u] 3. 图的遍历算法图的遍历算法是回答许多有关图可达性问题的关键。 无向图可达性的问题包括:|无向图可达性问题|DFS 是否能解决|BFS 是否能解决||:—|:—|:—||计算 u-&gt;v 的路径|能|能||计算 G 中每一个顶点 s 与其他顶点之间的最小路径|不能|能||判断图 G 是否为连通图|能|能||如果 G 是连通的，计算的 G 的生成树|能|能||计算 G 的连通的分支|能|能||判断 G 是否存在循环|能|能| 有向图的可达性问题包括:|有向图可达性问题|DFS 是否能解决|BFS 是否能解决||:—|:—|:—||计算 u-&gt;v 的路径|能|能||计算顶点间的最短路径|不能|能|找出 G 从已知顶点 s 可达的顶点|能|能||判断 G 是否强连通|能|能||判断 G 是否存在循环|能|能||计算 G 的传递闭包|能|| DFS 深度优先遍历算法特性深度优先遍历算法可以用来分析图的结构: DFS 很自然的识别出以开始顶点 s 作为根的深度优先搜索树；如果边 e=(u, v) 发现了新顶点 v，那么边 e 叫作发现边或者树的边；除此之外的边叫作非树边 无向图中: 非树边连通了当前顶点和DFS树中的它的祖先，我们称这样的边叫 back 边 有向图中: DFS 过程中有三种非树边，假设边为非树边连接了 (u, v) back 边 : u 为当前节点，v 是DFS 树中 u 的祖先节点 forward 边: u 为当前节点，v 是DFS 树中 u 的孩子 cross 边: v 既不是 u 的祖先，也不是 u 的孩子 许多图的研究都是通过将图 G 的边按照上面的规则分组获得的: 发现边可以帮助我们解决树的可达性问题 当且仅当存在 back 边时，图存在循环 BFS 广度优先遍历算法特性广度优先遍历算法同样可以用来分析图的结构: 无向图的 BFS 所有的非树边都是 cross 边 有向图的 BFS，所有非树边都是 back 边或者 cross 边 显而易见，广度优先遍历可以计算从顶点 s 到任意顶点的最短路径 3.1 DFS下面是 DFS 相关算法的具体实现 DFS 实现下面是按照输出边的 DFS 实现。在 DFS 的遍历过程中我们需要记录以下信息: {“v”: edge(u, v)}: 记录顶点 v 的发现边 记录顶点的 back 边，以判断图是否存在循环(下面的实现未实现此功能) 123456789101112131415def DFS(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered)# u 为开始顶点，值为 None，用于标识其为开始顶点result = &#123;u: None&#125;DFS(g, u, result) discovered 字典这里为两个目的服务: 一是提供了用于判断顶点是否已被访问的机制 二是字典内保存的边就是DFS树的边。 如果假设顶点可以用 0 到 n-1 进行编号，discovered可以用基于这些数子的数组替代。或者可以直接将所有顶点的发现状态以及顶点的发现边作为顶点的属性，成为顶点的一部分。 u 到 v 的路径重建无向图和有向图的路径重建是相同的。 1234567891011def construct_path(u, v, discovered): path = [] if v in discovered: path.append(v) walk = v while walk is not u: parent = discovered[walk].opposite[walk] path.append(parent) walk = parent path.reverse() return path 连通性测试 无向图: 在任意顶点开始 DFS，然后测试 len(discovered) 和图的顶点数是否相同。如果相等无向图就是连通 有向图: 选择任意顶点 s 对 s 按照输出边执行 DFS 对 s 按照输入边执行 DFS 如果两次 DFS，len(discovered) 和图的顶点数都相同则有向图是强连通的 上面的 DFS 函数已经按照输出边实现了深度优先遍历，下面是按照输入边的DFS函数 12345678910111213def DFS_IN(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ # 以输入边执行反向的深度优先搜索 for e in g.incident_edge(u, outgoing=False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered) 计算所有的连通分支1234567def DFS_complete(g): forest = &#123;&#125; for u in g.vertices(): if u not in forest: forest[u] = None DFS(g, u, forest) return forest 无向图的连通分支数可以通过发现字典值为 None 的键的个数来判定。 找到有向图的强连通分支的情况更复杂，存在在 O(n+m)时间内计算这些连通分支的方法，使用两次单独的深度优先搜索遍历，本文未实现。 发现循环循环的存在当且仅当和 DFS 遍历相关的 back 边存在。 无向图搜索 back 边是容易的，因为所有的边不是树的边就是 back 边 无向图比较困难，DFS 代码内需要正确区分出 back 边，若被探索的有向边指向先前访问过的顶点，我们必须识别出改顶点是否是当前节点的祖先节点，这需要额外的记录。 3.2 BFS如下两个版本的广度有限搜索代码都是正确的，都是我们常用的形式。BFS 同样会输出 discovered ，因此对于上面使用 discovered 的 DFS 相关算法，对 BFS 同样适用。1234567891011121314151617181920212223def BFS(g, s, discovered): queue = deque() queue.append(s) discovered[s] = None while queue: u = queue.popleft() for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e queue.append(v)def BFS_1(g, s, discovered): level = [] while level: next_level = [] for u in level: for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e next_level.append(v) level = next_level 4. 树的其他算法讲完了图的遍历，接下来我们就可以来看看与图应用相关的算法了: 传递闭包 有向非循环图的拓扑排序 最短路径 最小生成树 4.1 传递闭包有向图 G 的传递闭包是有向图 G1 使得 G1 顶点与 G 的顶点一样，并且对于所有顶点对 (u, v) 能直接表示是否有从 u 到 v 的一条路径。传递闭包通过合并图 G 中的路径来快速回答图中顶点的可达性。 4.2 拓扑排序拓扑排序是一种排序，使得图 G 的任何有向路径以增加的顺序遍历顶点。图 G 有拓扑排序当且仅当它是非循环的。 拓扑排序是有向无环图的经典应用，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。其有两种实现方法，分别是Kahn 算法 和 DFS 深度优先搜索算法。 Kahn 算法Kahn 算法实际上用的是贪心算法思想。 定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。 我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中，并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。 Kahn 算法还能检测图是否存在环，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环 123456789101112131415161718192021def topologic_sort(g): topo = [] # 拓扑排序的结果 ready = [] # 入度为 0 待加入 topo 的顶点 incount = &#123;&#125; # 记录每个顶点的入度 for u in g.vertices(): c = g.degree(u, False) if c == 0: ready.append(u) else: incount[u] = c while ready: u = ready.pop() topo.append(u) # 获取 u 的输出边，减少对应顶点的入度 for e in g.incident_edge(u): # 迭代所有顶点的传出边 v = e.opposite(u) incount[v] -= 1 if incount[v] == 0: incount.pop(v) ready.append(v) return topo 和图的遍历一样如果顶点可以用 0 到 n-1 进行编号，我们可以用数组代替 incount，或者将入度的计数作为顶点属性来记录。显然整个算法的时间复杂度为 O(n + m) DFS 深度优先搜索算法使用 DF 实现拓扑排序的方法不好理解。假设图上的一个路径是A--&gt;B--&gt;C--&gt;D，如果我们按照输入边进行 DFS，那么顶点 A 一定在其他顶点之前输出。即所有入度为 0 的顶点一定在其他顶点之前输出，而递归调用的返回相当于对于顶点的入度减 1。最终的结果就是按照输入边对图的 DFS 和Kahn 算法一致。文字描述并不是很清楚，请结合代码查看。123456789101112131415161718def DFS_income(g, u, discovered, topo): for e in g.incident_edge(u, False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS_income(g, v, discovered, topo) # 类似于后序遍历, 顶点 A 会优先加入 topo topo.append(u)def topologic_dfs(g): discovered = &#123;&#125; topo = [] for u in g.vertices: if u not in discovered: discovered[u] = None DFS_income(g, u, discovered, topo) return topo 4.3 最短路径广度优先算法可以计算连通图中，从一个顶点到另一顶点的最短路径，但前提是图上的每条边的权重相同。那如何计算全重不同的图的最短路径呢？最出名的莫过于 Dijkstra 算法。 Dijkstra 算法是贪心算法。贪心算法的递归过程差不多是这样:假设我们计算图 G 上顶点 u 到顶点 v 的最短距离；对于到顶点 v 的所有输入边的顶点集合 S，如果我们知道 u 到 S 中每个顶点的最短距离，那我们就能计算出 u 到 v 的最短距离。 Dijkstra123456789101112131415161718192021222324252627282930313233def shortest_search(g, src): d = &#123;&#125; # 从 src 到 顶点的最短距离 cloud = &#123;&#125; # 收集已经计算得到最短距离的所有顶点 pre = &#123;&#125; # 还原最短路径的路径 pdlocator = &#123;&#125; # 定位顶点在优先队列中位置 pq = MinHeap() # 小对 # 初始化 for u in g.vertices(): d[u] = float('inf') d[src] = 0 pre[src] = None pdlocator[src] = pq.add(0, src) # 迭代优先队列，不断从中取出距离最小的顶点 while not pq.is_empty(): k, u = pq.remove_min() # 删除堆顶元素 cloud[u] = k del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) n = k + e.element() # 到顶点 v 新的距离 if v not in cloud: if v not in pdlocator: d[v] = n # 插入堆 pdlocator[v] = pq.add(d[v], v) pre[v] = u else: if n &lt; d[v]: d[v] = n # 更新堆 pq.update(pdlocator[v], n, v) pre[v] = u return cloud, pre 整个代码的时间负载度分成两个部分: 一是 while + for 内对顶点和边的迭代，因为每个顶点和每条边最多被迭代一次，所以时间负载度是O(n+m); 二是对优先队列的操作，包括: add, remove_min, update 这些操作的时间复杂度都是 logn，因此总的时间复杂度是 O((n+m)logn)。 MinHeap 还有其他实现方式，比如一个未排序的数组，此时 remove_min 为 O(n)，其他两个操作的时间复杂度都是O(1)，此时总体的时间复杂度就是 O(n*n + m)。因此使用哪种实现方式更优取决于图的稀疏程度。 需要注意的是与前面类似，对于 d，pre， pdlocator，cloud 如果顶点可以用 0 到 n-1 进行编号， 它们都可以用数组代替，或者将作为顶点属性来记录。 重建最短路径树上面我们计算出从 src 到各个顶点的最短距离，但是并没有明确计算出获取最短剧路的路径。最短路径的重建有两种方式: 向上面代码中那样，使用 pre 记录到达每个顶点的前一个顶点。 是直接从 cloud 的返回值进行重建。 1234567891011121314151617181920212223242526272829# 重建最短路径树def shortest_path_tree(g, s, d): """ :param g: :param s: src 顶点 :param d: cloud 的返回值 :return: """ tree = &#123;&#125; for v in d: if v is not s: for e in g.incident_edge(v, False): u = e.opposite(v) wgt = e.element() if d[v] == d[u] + wgt: tree[v] = e return tree # 计算到顶点 v 的最短路径def shortest_path(pre, v): """ :param pre: pre :return: """ p = [v] while v in pre and pre[v] is not None: v = pre[v] p.append(v) return p.reverse() 4.4 最小生成树所谓最小生成树(简称MST)就是在一个无向，有权图G中，找到一颗连接所有顶点的树，并且树包含的边的权重总和最低。最小生成树有两种常见解法: Prim-Jarnik 算法: 从单个根节点生成 MST，它和 Dijkstra有很多相似之处 Kruskal 算法: 通过按照边的权重的非递减去考虑边来成群的生成 MST 无论是哪种算法，它们都基于最小生成树这样一个事实。即 G 是一个有权重的连通图，另 V1 和 V2 是两个不相交的非空集合G的顶点的一部份。此外另 e 是那些一个顶点在 V1 一个顶点在V2的有最小权重的G的边，则 e 是最小生成树的一条边。 Prim-JarnikPrim-Jarnik 算法，我们以一某一顶点 s 开始，定义初始集合 C，然后每次迭代中，我们选择一个最小权重的边 e，将 C 中的顶点连接到 C 之外的顶点 v，之后在将 v 加入 C 中。此时 e 就是最小生成树的一条边。 12345678910111213141516171819202122232425262728def MST_Prim_Jarnik(g): d = &#123;&#125; tree = [] pq = MinHeap() # 小堆 pdlocator = &#123;&#125; # pdlocator 此处还起到判断顶点是否已经迭代过的作用 # 初始化 for v in g.vertices(): if len(d) == 0: d[v] = 0 else: d[v] = float('inf') pdlocator[v] = pq.add(d[v], (v, None)) while not pq.is_empty(): key, value = pq.remove_min() u, edge = value if edge is not None: tree.append(edge) del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) if v in pdlocator: wgt = e.element() if wgt &lt; d[v]: d[v] = wgt pq.update(pdlocator[v], (v, e)) return tree KruskalKruskal 算法，首先每个顶点本身是单元素集合。算法按照权重增加的顺序轮流考察每条边。如果一条边连接了两个不同的集群，那么 e 就是最小生成树的一条边。Kruskal 的具体实现如下，其中 Partition 是一个不相交集合和联合查找结构的实现。 12345678910111213141516171819202122def MST_Kruskal(g): tree = [] pq = MinHeap() # 优先队列 forest = Partition() position = &#123;&#125; for v in g.vertices(): position[v] = forest.make_group(v) for e in g.edges(): pq.add(e.element, e) size = g.vertice_count() while len(tree) != size - 1 and pq.is_empty(): wgt, edge = pq.remove_min() u, v = edge.endpoints() a = forest.find(position[u]) b = forest.find(position[v]) if a != b: tree.append(edge) forest.union(a, b) return tree 4.5 不相交集合和联合查找结构不相交集合和联合查找结构的实现参见: 不相交集合]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>好玩的数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3. 树]]></title>
    <url>%2F2020%2F07%2F03%2Falgo_bit%2F3_tree%2F</url>
    <content type="text"><![CDATA[树 1. 树的抽象我们都知道树是一种数组组织形式，通过限定树中数据的组织方式，我们可以得到很多树的变种。因此要想学好树，我们就要从最基本的树开始，逐一去了解每种特殊的树的数据组织方式以及他们能提供的操作。 1.1 数的组织方式我们所说的数据组织方式本质上应该包括两个方面: 底层数据的存储方式: 包括链表和数组，因此就有了链表实现的树，与数组实现的树 父子节点的排列方式: 排列方式包括如下几个层次: 每个节点的子节点个数 父子节点之间的大小顺序 每一个节点的子节点之间的大小顺序 树为否为完全二叉树 通常链表是实现树的通用方式，而数组实现的树通常仅限于完全二叉树。父子节点的排列方式决定了树的搜索属性，决定了每种树的特定用途。 1.2 树的抽象层次下面是树的一个类层次结构，接下来我们会一一介绍下面的各种树。12345678910Tree|------- BinaryTree| | | |--------ArraryBinaryTree| | | |--------LinkedBinaryTree| | |-------TreeMap| | | |------------ AVLTree| | | |------------ SplayTree| | | |------------ RedBlackTree 2. 树2.1 TreeTree 最普通的树，可以有任意的分叉和孩子数，支持如下操作: root(): 返回树的根节点 parent(p): 返回节点 p 的父节点 children(p): 返回节点 p 的子节点 is_root(p): 判断节点 p 是否为根节点 is_leaf(p): 判断节点 p 是否是叶节点 is_empty(): 判断树是否为空 depth(p): 计算节点 p 的深度 height(p): 计算节点 p 的高度 preorder(p): 先序遍历 postorder(p): 后序遍历 breadthfirst(): 层序遍历，又称广度优先遍历 说明: 树的遍历按照父节点被访问的次序分为: 先序遍历: 先访问树的父节点，在访问子节点 后序遍历: 先访问树的子节点，在访问父节点 层序遍历: 按树的层遍历所有节点 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class Tree(object): def depth(self, p): """ :param p: :return: 返回 p 节点的深度 """ if self.is_root(p): return 0 else: return 1 + self.depth(self.parent(p)) def height(self, p=None): """ :return: 返回树的高度 """ p = p or self.root() return self._height(p) def _height(self, p): if self.is_leaf(p): return 0 else: return 1 + max(self._height(c) for c in self.children(p)) def preorder(self): """ :return: 树的前序遍历 """ if not self.is_empty(): for p in self._subtree_preorder(self.root()): yield p def _subtree_preorder(self, p): yield p for i in self.children(p): for other in self._subtree_preorder(i): yield other def postorder(self): """ :return: 后序遍历 """ if not self.is_empty(): for p in self._subtree_postorder(self.root()): yield p def _subtree_postorder(self, p): for i in self.children(p): for other in self._subtree_preorder(i): yield other yield p def breadthfirst(self): """ :return: 中序遍历 """ if not self.is_empty(): queue = deque() queue.append(self.root()) while len(queue) &gt; 0: p = queue.popleft() yield p for c in self.children(p): queue.append(c) 2.2 BinaryTreeBinaryTree 二叉树是每个节点最多只有两个分叉的树，他在 Tree 的基础上增加了如下几个操作: left(p): 返回节点 p 的左子节点 right(p): 返回节点 p 的右子节点 sibling(p): 返回节点 p 的兄弟节点 inorder(p): 中序遍历 中序遍历是二叉树特有的遍历方式 节点的访问次序是左子节点-&gt;父节点-&gt;右子节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344class BinaryTree(Tree): def slide(self, p): """ :param p: :return: 返回节点的兄弟节点 """ parent = self.parent(p) if parent is not None: left = self.left(parent) right = self.right(parent) if left == p: return right else: return left def children(self, p): """ :param p: :return: 返回节点的所有子节点 """ left = self.left(p) if p is not None: yield left right = self.right(p) if right is not None: yield right def inorder(self): """ :return: 中序遍历 """ if not self.is_empty(): return self._subtree_inorder(self.root()) def _subtree_inorder(self, p): left = self.left(p) if left is not None: for other in self._subtree_inorder(left): yield other yield p right = self.right(p) if right is not None: for other in self._subtree_inorder(right): yield other 3. 树遍历的抽象-欧拉图和模板方法前面我们实现了树的四种遍历方式，以按照不同的顺序获取树中的元素。但是这提供的抽象能力还不够，更多时候，我们需要获取树遍历过程中的更多信息，比如当前位置的深度，或者从根节点到当前位置的完整路径，或者返回下一层信息到上一层。因此我们需要一个更通用的框架，即基于概念实现树的遍历–欧拉遍历。 什么是欧拉遍历，我们来看下面的伪代码:12345Algorithm eulertour(T, p) pre visit for p # 第一访问节点 p，前序遍历可执行的操作位于此处 for each child c in T.children(p) do eulertour(T, c) post visit for p # 第二次访问节点 p，后续遍历可执行的操作位于此处 显然我们可以把 eulertour 定义为模板方法，让继承自 eulertour 的子类去实现需要的前序后续遍历需要执行的操作。下面是 eulertour 的具体实现: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class EulerTour(object): # 一般欧拉遍历的实现 def __init__(self, tree): self._tree = tree def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): """ :param p: 当前遍历的节点 :param d: 节点所处的树的深度 :param path: 从根到达当前节点的路径 :return: 后续遍历的返回值 """ self._hook_previsit(p, d, path) # 先序遍历需实现的抽象方法 path.append(0) # path 最后一个索引记录了，当前节点所有子节点的排序 result = [] for c in self._tree.children(p): result.append(self._tour(c, d + 1, path)) path[-1] += 1 path.pop() value = self._hook_postvisit(p, d, path, result) return value def _hook_previsit(self, p, d, path): pass def _hook_postvisit(self, p, d, path, result): """ :param p: 当前遍历的节点 :param d: 节点所处的树的深度 :param path: 从根到达当前节点的路径 :param result: 子节点后续遍历返回值的列表 :return: 后续遍历的返回值 """class BinaryEulerTour(BinaryEulerTour): # 二叉树的欧拉遍历 def __init__(self, tree): super(BinaryEulerTour, self).__init__(tree) def _tour(self, p, d, path): self._hook_previsit(p, d, path) result = [None, None] if self._tree.left(p): path.append(0) result[0] = self._tour(self._tree.left(p), d + 1, path) path.pop() self._hook_invisit(p, d, path) if self._tree.right(p): path.append(1) result[1] = self._tour(self._tree.right(p), d + 1, path) path.pop() value = self._hook_postvisit(p, d, path, result) return value def _hook_invisit(self, p, d, path): pass 利用 BinaryEulerTour 我们可以开发一个用于计算二叉树的图形布局的子类，该算法用以下两条规则为二叉树的每个节点指定 x，坐标： x(p): 在节点 p 之前，中序遍历访问的节点数量 y(p): 是 T 中 p 的深度 123456789class BinaryLayout(BinaryEulerTour) def __init__(self, tree): super().__init__(tree) self._count = 0 def _hook_invisit(self, p, d, path): p.element().setX(self._count) p.element().setY(d) self._count+=1 除了 BinaryEulerTour 提供的钩子函数外，我们以 _count 实例变量的形式引入了额外的状态，从而调整了 BinaryEulerTour 框架，扩展了框架提供的功能。 4. 二叉搜索树与 AVL 平衡树4.1TreeMap 二叉搜索树是一种特殊的二叉树，其满足以下条件: 存储在 p 的左子树的键都小于 p 的键 存储在 p 的右子树的键都大于 p 的键 这个特性使得树的中序遍历可以按升序的方式输出键。这个特性使得二叉搜索树增加了如下方法: first(): 返回一个包含最小键的节点，即最左子节点 last(): 返回一个包含最大键的节点，即最右子节点 before(p): 返回比节点 p 的键小的所有节点中的键最大的节点 即中序遍历中在 p 之前最后一个被访问的节点 如果 p 是第一个节点，则返回 None after(p): 返回比节点 p 的键大的所有节点中最小的节点 即中序遍历中在 p 之后第一个被访问的节点 如果 p 是最后一个节点，返回 None search(k): 在树中搜索键 k，返回搜索路径的最终位置，这样get，set，del 方法可以复用 search 方法 find_le(k): 小于等于 k 的节点，可以基于 search(k) 和 before(p) 实现 find_ge(k): 大于等于 k 的节点，可以基于 search(k) 和 after(p) 实现 find_range(start, end): 位于 start, end 之间的节点 T[k]: 查找键 k 对应的 value T[k]=v: 设置键 k 的值 del T[k]: 删除键 k _rebalance_delete(p): AVL 和 红黑树实现树平衡的钩子函数 _rebalance_insert(p): AVL 和 红黑树实现树平衡的钩子函数 _rebalance_access(p): AVL 和 红黑树实现树平衡的钩子函数 下面是 TreeMap 的具体实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201class TreeMap(LinkedBinaryTree, MapBase): def _subtree_search(self, p, k): """ :param p: :param k: :return: 在子树中搜索值为 k 的节点，未搜索到返回最后搜索路经的最终位置 """ p_value = p.key() if p_value == k: return p elif p_value &gt; k: if self.left(p): return self._subtree_search(self.left(p), k) else: if self.right(p): return self._subtree_search(self.right(p), k) return p def _subtree_first_position(self, p): """ :return: 返回子树迭代时，第一个位置节点 """ walk = p while self.left(walk): walk = self.left(walk) return walk def _subtree_last_position(self, p): """ :param p: :return: 返回子树迭代时，最后一个位置节点 """ walk = p while self.right(walk): walk = self.right(walk) return walk ################# 引导方法 ####################### def first(self): """ :return: 返回树迭代序列的第一个节点 """ return self._subtree_first_position(self.root()) if len(self) &gt; 0 else None def last(self): """ :return: 返回树迭代序列的最后一个节点 """ return self._subtree_last_position(self.root()) if len(self) &gt; 0 else None def before(self, p): """ :param p: :return: 返回迭代序列中位于 p 之前的，最大节点 """ if self.left(p): return self._subtree_last_position(self.left(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.left(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def after(self, p): """ :param p: :return: 返回迭代序列中位于 p 之后的，最小节点 """ if self.right(p): self._subtree_first_position(self.right(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.right(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def find_position(self, k): """ :param k: :return: 查找值等于 k 的位置节点 """ if self.is_empty(): return None else: p = self._subtree_search(self.root(), k) # avl 平衡树的钩子函数 self._rebalance_access(p) return p ####################### 有序映射 ###################### def find_ge(self, k): """ :param k: :return: 查找大于等于 k 的最小节点 """ p = self.find_position(k) if p and p.key() &lt; k: p = self.after(p) return p.key(), p.value() if p else None, None def find_range(self, start, stop): """ :param start: :param stop: :return: 查找值位于 start &lt;= k &lt; stop 的节点 """ if not self.is_empty(): if start is None: p = self.first() else: p = self.find_position(start) if p and p.key() &lt; start: p = self.after(p) while p and (stop is None or p.key() &lt; stop): yield p.key(), p.value() p = self.after(p) ########################### 增删改查节点操作 ################ def __getitem__(self, item): """ :param item: :return: 查找 item 映射的值 """ if not self.is_empty(): p = self.find_position(item) self._rebalance_access(p) if p.key() == item: return p.value() raise KeyError('Key Error:' + repr(item)) def __setitem__(self, key, value): """ :param key: :param value: :return: 设置键 key 的值为 value """ if self.is_empty(): leaf = self._add_root(self._Item(key, value)) else: p = self.find_position(key) if p.key() == key: p.element()._value = value self._rebalance_access(p) return else: item = self._Item(key, value) if p.key() &lt; key: leaf = self._add_right(p, item) else: leaf = self._add_left(p, item) self._rebalance_insert(leaf) def __iter__(self): """ :return: 产生键的一个迭代 """ p = self.first() while p: yield p.key() p = self.after(p) def delete(self, p): """ :param p: :return: 删除位置节点 p """ if self.left(p) and self.right(p): r = self._subtree_last_position(self.left(p)) self._replace(p, r.element()) p = r parent = self.parent(p) self._delete(p) self._rebalance_delete(parent) def __delitem__(self, key): """ :param key: :return: 删除键 key """ if not self.is_empty(): p = self._subtree_search(self.root(), key) if p.key() == key: self.delete(p) return self._rebalance_access(p) raise KeyError('Key Error: ' + repr(key)) ################### 平衡二叉树的钩子函数 ############### def _rebalance_delete(self, p): pass def _rebalance_insert(self, p): pass def _rebalance_access(self, p): pass 4.2 AVL 树二叉搜索树的问题在于在不断的插入和删除之后树就会变得不平衡，从而导致增删改查的时间复杂度不断变高。而 AVL 树就是能保持树平衡的二叉树。AVL 树要求，对于树中每一个节点 p，p 的孩子的高度最多相差 1。伸展树和红黑树都能维持树的平衡，虽然它们与 AVL 树维持平衡的方法有所差别，但是核心操作都是树的旋转。因此要想写好这些树，首先我们要实现如下几个树的旋转操作: _relink(parent, child, make_left_child): 关联父子节点 _rotate(p): 旋转过程中，重新定义父子关系 _restructure(x): 执行旋转操作 12 TreeMap 中我们已经预留了维持树平衡的接口，AVL 实现中我们需要做的是 记录每个节点的高度 实现钩子函数 _rebalance_insert 和 _rebalance_delete(两个方法的实现相同)以保证在插入和删除节点后，AVL 树的高度满足树中每一个节点 p，p 的孩子的高度最多相差 1。 下面是 AVL 树的具体实现:12345678910111213141516171819202122232425262728293031323334353637383940414243444546```### 4.3 红黑树红黑树相较于 AVL 树，增删改查操作更加稳定，因此比 AVL 树更常用，但是其实现起来更为复杂。红黑树有现成的实现，手写他们不是我们的目的，我们的目的是明白树的整个抽象层次，并在需要的时候知道使用什么树。## 5. 树的序列化与反序列化序列化和反序列化是所有数据结构通用的操作，对于树也是如此，树的序列化与反序列化主要使用的是树的前序，层序遍历。### 5.1 二叉树序列化我们先来看如何使用先序遍历实现二叉树的序列化和反序列化。#### 先序遍历实现的序列化```pythonfrom collections import dequeclass Codec: def serialize(self, root): """Encodes a tree to a single string. :type root: TreeNode :rtype: str """ if root is None: return "null" return str(root.val) + "," + self.serialize(root.left) + "," + self.serialize(root.right) def deserialize(self, data): """Decodes your encoded data to tree. :type data: str :rtype: TreeNode """ collect = deque(data.split(",")) def dfs(): if len(collect) == 0: return None node = collect.popleft() if node == "null": return None root = TreeNode(int(node)) root.left = dfs() root.right = dfs() return root return dfs() 中序遍历实现的序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from collections import dequeclass Codec: def serialize(self, root): """Encodes a tree to a single string. :type root: TreeNode :rtype: str """ if not root: return "" collect = [] queue = deque([root]) while len(queue) &gt; 0: node = queue.popleft() if node: queue.append(node.left) queue.append(node.right) collect.append(str(node.val)) else: collect.append("null") return ",".join(collect) def deserialize(self, data): """Decodes your encoded data to tree. :type data: str :rtype: TreeNode """ if data == "": return None print(data) collect = deque(data.split(",")) root = TreeNode(int(collect.popleft())) queue = deque([root]) while len(queue) &gt; 0: parent = queue.popleft() left, right = collect.popleft(), collect.popleft() if left != "null": left_node = TreeNode(int(left)) queue.append(left_node) parent.left = left_node if right != "null": right_node = TreeNode(int(right)) queue.append(right_node) parent.right = right_node return root 5.1 普通树的序列化]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>好玩的数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2. 递归]]></title>
    <url>%2F2020%2F07%2F02%2Falgo_bit%2F2_recursion%2F</url>
    <content type="text"><![CDATA[递归 1. 如何写递归递归是一种应用非常广泛的算法（或者编程技巧），搞懂递归非常重要。基本上，所有的递归问题都可以用递推公式来表示。要想使用递归解决问题，必需满足三个前提条件: 一个问题的解可以分解为几个子问题的解，子问题就是规模更小的问题 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 存在递归终止条件 关键是如何编写递归代码呢？写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再找出终止条件，最后将递推公式和终止条件翻译成代码。 千万要注意递归代码的核心是发现问题分解的规律，并将其抽象为递推公式，千万不要想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。在编写递归代码的时候，我们可以按照如下的思路，按骥索图: 思考问题的分解规律，写出递推公式 有的问题分解很简单，比如二叉树的遍历，直接可以分解成左子树和右子树两个遍历 有的问题分解很难，比如动态规划 假设子问题已解决，并在此基础上，将递推公式翻译成代码，对问题进行求解 根据需要的值，思考递归函数的参数和返回值 思考边界，找出终止条件 我们以二叉树的序列化反序列化为例来看看，如何写递归代码。下面是使用先序遍历实现的二叉树的序列化反序列化: 123456789101112131415161718192021222324252627282930313233from collections import dequeclass Codec: def serialize(self, root): """Encodes a tree to a single string. :type root: TreeNode :rtype: str """ if root is None: return "null" return str(root.val) + "," + self.serialize(root.left) + "," + self.serialize(root.right) def deserialize(self, data): """Decodes your encoded data to tree. :type data: str :rtype: TreeNode """ collect = deque(data.split(",")) def dfs(): if len(collect) == 0: # 片段 2 return None node = collect.popleft() if node == "null": # 片段 2 return None root = TreeNode(int(node)) # 片段 1 root.left = dfs() root.right = dfs() return root return dfs() 二叉树反序列化的思考过程: 先序遍历是先输出父节点，在输出左子节点，最后右子节点 所以 collect.popleft() 第一输出的是父节点，第二次输出的左子树，第三次输出的是右子树 因为我们要知道父节点的子节点，因此我们可以先假设 dfs() 返回的是树的一个节点，即return root 按照左右子节点的输出顺序，就有上述代码”片段1” 最后我们来思考终止条件 如果已经遍历完输入，则退出，即代码”片段2” 如果当前输入为 null，说明为空，其不会有左右子节点，退出，即代码”片段3” 当然如果你不清楚树的先序遍历，自然不可能写出上面的代码。递归代码真正的难点其实就在于如何找出递归公式，特别是对于动态规划而言。 2. 递归存在的问题使用递归时会存在很多问题，最常见的两个是: 递归代码要警惕堆栈溢出 递归代码要警惕重复计算 为了避免重复计算，我们可以通过一个数据结构比如散列表来保存已经求解的函数调用 f(k)。当递归调用 f(k) 时先看下是否已经求解过了，如果是则直接返回，无须重复计算。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>好玩的数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. 编程思想]]></title>
    <url>%2F2020%2F07%2F01%2Falgo_bit%2F1_thought%2F</url>
    <content type="text"><![CDATA[编程思想 1. 原理基础的数据结构与算法中，有几块非常难懂，贪心，分治，回溯和动态规划这四个编程思想应该算是”名列前茅”了。本文希望通过详细解答几个经典示例来帮助大家搞懂他们。在进入实战之前，我们先来看看他们的区别。 1.1 动态规划动态规划适合解决的问题可以概括为“一个模型三个特征”。 一个模型: 多阶段决策最优解模型。动态规划通常被用来解决最优问题，而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。 三个特征: 最优子结构: 我们可以通过子问题的最优解，推导出问题的最优解 无后效性: 某阶段状态一旦确定，就不受之后阶段的决策影响 重复子问题: 不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态 了解了动态，接下我们就以动态为标杆，看看其他编程思想有什么不同 1.2 分治贪心、回溯、动态规划可以归为一类，都可以抽象成我们今天讲的那个多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但是，大部分都不能抽象成多阶段决策模型。 在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。 1.3 贪心它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性。贪心选择性的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。贪心算法实际上是动态规划算法的一种特殊情况。 1.4 回溯回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，我们都可以用回溯算法解决。回溯算法相当于穷举搜索。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。 它们之间的区别讲完了，接下来我们就来看看如何用它们来解决我们的编程问题。 2. 实战2.1 最少加油次数leecode 871 回溯12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution(object): def minRefuelStops(self, target, startFuel, stations): """ :type target: int :type startFuel: int :type stations: List[List[int]] :rtype: int """ self.min_station = len(stations) + 1 if startFuel &gt;= target: return 0 self.refuel_stop(target, stations, 0, startFuel, 0) self.min_station = self.min_station \ if self.min_station &lt;= len(stations) else -1 return self.min_station def refuel_stop(self, target, station, i, fuel, c): """ :param target: 距离目标地点还有多远 :param station: :param i: 表示到达第 i 个加油站，i 从 0 开始计数 :param fuel: 能走多远 :param c: 加油次数 :return: """ # 已经到最有一个加油站了 if i == len(station): if fuel &gt;= target: self.min_station = min(c, self.min_station) return # 剩下的油走不到下一站了，也无法到达 target if fuel &lt; min(station[i][0], target): return # 已经足够达到终点 if fuel &gt;= target: self.min_station = min(c, self.min_station) return # 没到达终点，油够到下一站 # 不加油 self.refuel_stop(target, station, i + 1, fuel, c) # 加油 if fuel &gt;= station[i][0]: self.refuel_stop(target, station, i + 1, fuel + station[i][1], c + 1) 动态规划如果我们仔细思考上面的回溯代码，我们会发现递归调用过程中如下几个变化的量: self.min_station: 加油次数，这是我们要求的结果变量 i: 第 i 个加油站 fuel: 能够达到的最远距离 看起来我们可以创建一个二维状态转移表，y 轴方向表示第 i 个加油站，x 轴方向表示加了几次油，二维表中的值表示能达到的最远距离。这里动态规划的解法需要我们稍微专变一下思路，求到达指定距离的最少加油次数，跟求指定加油次数能达到的最远距离是同一问题。 整个决策过程设计多个阶段，我们要决定在每个加油站是否加油，并求出能达到的最远距离。第二次加油能走的最远距离显然由上次能走的最远距离决定。符合多阶段最优解模型。 最后根据回溯算法的代码实现，我们可以画出递归树，看是否存在重复子问题。假设输入参数分别是: target = 100, startFuel = 20, stations = [[10,60],[20,30],[30,30],[60,40]] 123 f(0, 20) f(1, 20) f(1, 80)f(2, 0) f(2, 50) f(2, 80) f(2, 110) 递归树中的每个节点表示一种状态，我们用（i, fuel）来表示。其中，i 表示是否在第 i 个加油站加油，fuel 表示能达到的最远距离。看起来没有重复子问题，但是我们要计算的是加油一次能够达到的最远距离，所以上面的 f(1, 80) 和 f(2, 50) 表示我在第 1 个加油站加油最远可以走 80 ，在第 2 个加油站加油最远可以走 50 公里。显示我们会在第 1 个加油站。当然不容易想到。 接下来我们就可以画出状态转移表，并写出代码。在写代码的过程中，你就会发现二维表在这里并没有用，如果我们计算出了第 i 次油能走的最远距离dp[i]，那么 dp[i+1] 加油能达到的最远距离，就取决于 dp[i] 能达到的加油站以及每个加油站能加的油即: if dp[t] &gt;= station[i+1][0]; dp[t+1]=dp[t]+station[i+1][1]。下面就是代码实现: 1234567891011class Solution(object): def minRefuelStops(self, target, startFuel, stations): dp = [startFuel] + [0] * len(stations) for i, (location, capacity) in enumerate(stations): for t in xrange(i, -1, -1): if dp[t] &gt;= location: dp[t+1] = max(dp[t+1], dp[t] + capacity) for i, d in enumerate(dp): if d &gt;= target: return i return -1 注意 xrange(i, -1, -1) 不能改成 xrange(0, x + 1)。 2.2 最长递增子序列长度leecode 300 回溯下面是最长递增子序列长度回溯的非完整实现。123456789101112131415161718192021222324class Solution(object): def lengthOfLIS(self, nums): """ :type nums: List[int] :rtype: int """ self.nums = nums self.len = 1 self.get_lis(0, 1, self.nums[0]) def get_lis(self, i, l, m): """ :param i: 表示这是第几个数 :param l: l 当前的最长子序列长度 :param m: m 子序列中最大的书 :return: """ self.len = max(l, self.len) p = self.nums[i] if p &gt;= m: self.get_lis(i + 1, l + 1, p) else: self.get_lis(i + 1, 1, p) self.get_lis(i + 1, l, m) 动态规划实现回溯过程显示了以下几个递归变化量: i：第 i 个数 l: 最长子序列的长度 m：最长子序列中的最大值 同样的，我们可以通过一个二维数组，画出上面三个变量的状态转移表: y轴方向：数组中的第 i 个数 x轴方向: 标识最长子序列的长度 二维数组的值记录了对应位置最长子序列中的最大值 当我们找不到解题思路时，一定要画出上面上面的状态转移表，这样能帮我我们找到解题思路，写出状态转移方程。 12345678910111213141516171819202122232425262728293031323334class Solution(object): def lengthOfLIS(self, nums): """ :type nums: List[int] :rtype: int """ if not nums: return 0 n = len(nums) status = [None] * (n) status[0] = nums[0] end = 0 for i in range(1, n): end = max(end, self.binary_search(nums[i], status, end)) return end + 1 def binary_search(self, v, status, end, start=0): m = start if status[end] &lt; v: end += 1 status[end] = v return end while start &lt;= end: mid = start + ((end - start) &gt; 1) if status[mid] == v: return end elif status[mid] &lt; v: start = mid + 1 else: if mid == m or status[mid-1] &lt; v: status[mid] = v return end else: end = mid - 1]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>好玩的数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2. perf Examples]]></title>
    <url>%2F2020%2F06%2F18%2Fbrendangregg%2F02_perf_example%2F</url>
    <content type="text"><![CDATA[这是大神 Brendangregg perf Examples 一文的翻译。ftrace，perf，dtrace，systemtap等等追踪工具依赖的底层技术是类似的，深入了解一个工具，有助于我们学习其他的技术。本人英文能力一般，大家将就着看。 These are some examples of using the perf Linux profiler, which has also been called Performance Counters for Linux (PCL), Linux perf events (LPE), or perf_events. Like Vince Weaver, I’ll call it perf_events so that you can search on that term later. Searching for just “perf” finds sites on the police, petroleum, weed control, and a T-shirt. This is not an official perf page, for either perf_events or the T-shirt. 这些是使用perf Linux分析器的一些示例，它也被称为Linux性能计数器(PCL)、Linux perf事件(LPE)或perf_events。和Vince Weaver一样，我将它命名为perf_events，这样以后就可以搜索这个词了。搜索“perf”可以找到关于警察、石油、除草和t恤的网站。这不是一个官方的表演页面，无论是表演事件还是t恤。 perf_events is an event-oriented observability tool, which can help you solve advanced performance and troubleshooting functions. Questions that can be answered include: Why is the kernel on-CPU so much? What code-paths? Which code-paths are causing CPU level 2 cache misses? Are the CPUs stalled on memory I/O? Which code-paths are allocating memory, and how much? What is triggering TCP retransmits? Is a certain kernel function being called, and how often? What reasons are threads leaving the CPU? perf_events是一个面向事件的可观察性工具，它可以帮助您解决高级性能和故障诊断功能。可以回答的问题包括: 为什么内核占用cpu这么多?代码路径是什么? 哪些代码路径会导致CPU二级缓存丢失? cpu在内存I/O上停止了吗? 哪些代码路径正在分配内存，分配多少? 是什么触发TCP重传? 是否调用某个内核函数，调用频率是多少? 线程离开CPU的原因是什么? perf_events is part of the Linux kernel, under tools/perf. While it uses many Linux tracing features, some are not yet exposed via the perf command, and need to be used via the ftrace interface instead. My perf-tools collection (github) uses both perf_events and ftrace as needed. perf_events是Linux内核的一部分，位于tools/perf之下。虽然它使用了许多Linux跟踪特性，但是有些特性还没有通过perf命令公开，需要通过ftrace接口来使用。我的perf-tools集合(perf-tool)根据需要同时使用perf_events和ftrace。 This page includes my examples of perf_events. A table of contents: Screenshot One-Liners Presentations Background 4.1. Prerequisites 4.2. Symbols 4.3. JIT Symbols (Java, Node.js) 4.4. Stack Traces 4.5. Audience 4.6. Usage 4.7. Usage Examples 4.8. Special Usage Events 5.1. Software Events 5.2. Hardware Events (PMCs) 5.3. Kernel Tracepoints 5.4. USDT 5.5. Dynamic Tracing Examples 6.1. CPU Statistics 6.2. Timed Profiling 6.3. Event Profiling 6.4. Static Kernel Tracing 6.5. Static User Tracing 6.6. Dynamic Tracing 6.7. Scheduler Analysis 6.8. eBPF Visualizations 7.1. Flame Graphs 7.2. Heat Maps Targets More Building Troubleshooting Other Tools Resources Key sections to start with are: Events, One-Liners, Presentations, Prerequisites, CPU statistics, Timed Profiling, and Flame Graphs. Also see my Posts about perf_events, and Links for the main (official) perf_events page, awesome tutorial, and other links. The next sections introduce perf_events further, starting with a screenshot, one-liners, and then background. 上面是博客的大纲和写作顺序的一个简介。 This page is under construction, and there’s a lot more to perf_events that I’d like to add. Hopefully this is useful so far. 这个页面还在构建中，我还想添加更多的perf_events，希望到目前为止这是有用的。 1. Screenshot(总览)Starting with a screenshot, here’s perf version 3.9.3 tracing disk I/O: 下面是perf 3.9.3 版本跟踪磁盘I/O的一个示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&gt; perf record -e block:block_rq_issue -ag&gt; ls -l perf.data-rw------- 1 root root 3458162 Jan 26 03:03 perf.dataperf report[...]# Samples: 2K of event 'block:block_rq_issue'# Event count (approx.): 2216## Overhead Command Shared Object Symbol# ........ ............ ................. ....................# 32.13% dd [kernel.kallsyms] [k] blk_peek_request | --- blk_peek_request virtblk_request __blk_run_queue | |--98.31%-- queue_unplugged | blk_flush_plug_list | | | |--91.00%-- blk_queue_bio | | generic_make_request | | submit_bio | | ext4_io_submit | | | | | |--58.71%-- ext4_bio_write_page | | | mpage_da_submit_io | | | mpage_da_map_and_submit | | | write_cache_pages_da | | | ext4_da_writepages | | | do_writepages | | | __filemap_fdatawrite_range | | | filemap_flush | | | ext4_alloc_da_blocks | | | ext4_release_file | | | __fput | | | ____fput | | | task_work_run | | | do_notify_resume | | | int_signal | | | close | | | 0x0 | | | | | --41.29%-- mpage_da_submit_io[...] A perf record command was used to trace the block:block_rq_issue probe, which fires when a block device I/O request is issued (disk I/O). Options included -a to trace all CPUs, and -g to capture call graphs (stack traces). Trace data is written to a perf.data file, and tracing ended when Ctrl-C was hit. A summary of the perf.data file was printed using perf report, which builds a tree from the stack traces, coalescing common paths, and showing percentages for each path. 上面的 perf record 命令用于跟踪 block:block_rq_issue 探针，它在块设备I/O请求发出时触发(磁盘I/O)。选项 -a 用于跟踪所有cpu， -g用于捕获调用图(堆栈跟踪)。跟踪数据被写入perf.data 文件。当按Ctrl-C时，数据文件和跟踪结束。使用 perf report 命令可以打印 perf.data 内的追踪信息，perf record 从堆栈跟踪构建一个树，合并公共路径，并显示每个路径的百分比。 The perf report output shows that 2,216 events were traced (disk I/O), 32% of which from a dd command. These were issued by the kernel function blk_peek_request(), and walking down the stacks, about half of these 32% were from the close() system call. perf report 输出显示跟踪了2,216个事件(磁盘I/O)，其中32%来自dd命令。这些是由内核函数blk_peek_request()发出的，在堆栈中查找，其中大约一半来自 close() 系统调用。 Note that I use the “#” prompt to signify that these commands were run as root, and I’ll use “$” for user commands. Use sudo as needed. 注意，我使用“#”提示符来表示这些命令是以根用户身份运行的，对于用户命令，我将使用“$”。根据需要使用sudo。说明: 我改成了 “&gt;” 不然命令会跟 perf 的输出混淆。 2. One-Liners(常用命令)Some useful one-liners I’ve gathered or written. Terminology I’m using, from lowest to highest overhead: statistics/count: increment an integer counter on events sample: collect details (eg, instruction pointer or stack) from a subset of events (once every …) trace: collect details from every event 我收集并编写了一些有用的一行程序。并使用了如下的术语进行说明 statistics/count: 对事件增加一个整数计数器 sample: 从事件子集收集细节(例如，指令指针或堆栈)(每…一次) trace: 收集每个事件的细节 Listing Events(列出所有事件)1234567# Listing all currently known events:# 列出所有事件perf list# Listing sched tracepoints:# 列出 sched 静态探针perf list 'sched:*' Counting Events(事件计数)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# CPU counter statistics for the specified command:# 为特定命令进行 CPU 计数perf stat command# Detailed CPU counter statistics (includes extras) for the specified command:# 为特定命令进行详细的 CPU 计数perf stat -d command# CPU counter statistics for the specified PID, until Ctrl-C:# 为指定的 PID 进程进行 CPU 计数perf stat -p PID# CPU counter statistics for the entire system, for 5 seconds:# 整个系统的CPU计数器统计信息，持续5秒perf stat -a sleep 5# Various basic CPU statistics, system wide, for 10 seconds:# 指定范围，进行整个系统的 CPU 计数perf stat -e cycles,instructions,cache-references,cache-misses,bus-cycles -a sleep 10# Various CPU level 1 data cache statistics for the specified command:# 一级缓存统计perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores command# Various CPU data TLB statistics for the specified command:# TLB 统计perf stat -e dTLB-loads,dTLB-load-misses,dTLB-prefetch-misses command# Various CPU last level cache statistics for the specified command:# 最后一级缓存统计perf stat -e LLC-loads,LLC-load-misses,LLC-stores,LLC-prefetches command# Using raw PMC counters, eg, counting unhalted core cycles:# PMC 计数器perf stat -e r003c -a sleep 5# PMCs: counting cycles and frontend stalls via raw specification:perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5# Count syscalls per-second system-wide:# 系统级每秒系统调用计数:perf stat -e raw_syscalls:sys_enter -I 1000 -a# Count system calls by type for the specified PID, until Ctrl-C:# 指定 PID 统计每秒系统调用计数:perf stat -e 'syscalls:sys_enter_*' -p PID# Count system calls by type for the entire system, for 5 seconds:# 按整个系统的类型计数系统调用，持续5秒:perf stat -e 'syscalls:sys_enter_*' -a sleep 5# Count scheduler events for the specified PID, until Ctrl-C:# 计算指定PID的调度程序事件perf stat -e 'sched:*' -p PID# Count scheduler events for the specified PID, for 10 seconds:# 计算指定PID的调度程序事件，持续 10sperf stat -e 'sched:*' -p PID sleep 10# Count ext4 events for the entire system, for 10 seconds:# 计算整个系统的ext4事件perf stat -e 'ext4:*' -a sleep 10# Count block device I/O events for the entire system, for 10 seconds:# 计算整个系统的块设备I/O事件perf stat -e 'block:*' -a sleep 10# Count all vmscan events, printing a report every second:# 计算所有vmscan事件，每秒打印一个报告perf stat -e 'vmscan:*' -a -I 1000 Profiling(剖析)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# Sample on-CPU functions for the specified command, at 99 Hertz:perf record -F 99 command# Sample on-CPU functions for the specified PID, at 99 Hertz, until Ctrl-C:perf record -F 99 -p PID# Sample on-CPU functions for the specified PID, at 99 Hertz, for 10 seconds:perf record -F 99 -p PID sleep 10# Sample CPU stack traces (via frame pointers) for the specified PID, at 99 Hertz, for 10 seconds:perf record -F 99 -p PID -g -- sleep 10# Sample CPU stack traces for the PID, using dwarf (dbg info) to unwind stacks, at 99 Hertz, for 10 seconds:perf record -F 99 -p PID --call-graph dwarf sleep 10# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (&lt; Linux 4.11):perf record -F 99 -ag -- sleep 10# Sample CPU stack traces for the entire system, at 99 Hertz, for 10 seconds (&gt;= Linux 4.11):perf record -F 99 -g -- sleep 10# If the previous command didn't work, try forcing perf to use the cpu-clock event:perf record -F 99 -e cpu-clock -ag -- sleep 10# Sample CPU stack traces for a container identified by its /sys/fs/cgroup/perf_event cgroup:# 一个由其/sys/fs/cgroup/perf_event cgroup标识的容器的示例CPU堆栈跟踪:perf record -F 99 -e cpu-clock --cgroup=docker/1d567f4393190204...etc... -a -- sleep 10# Sample CPU stack traces for the entire system, with dwarf stacks, at 99 Hertz, for 10 seconds:# 整个系统的CPU堆栈跟踪示例，使用dwarf堆栈，频率为99赫兹，持续10秒:perf record -F 99 -a --call-graph dwarf sleep 10# Sample CPU stack traces for the entire system, using last branch record for stacks, ... (&gt;= Linux 4.?):# 整个系统的CPU堆栈跟踪示例，使用堆栈的最后一个分支记录perf record -F 99 -a --call-graph lbr sleep 10# Sample CPU stack traces, once every 10,000 Level 1 data cache misses, for 5 seconds:# 示例CPU堆栈跟踪，每10,000 次 1 级缓存丢失记录一次，持续5秒:perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5# Sample CPU stack traces, once every 100 last level cache misses, for 5 seconds:# 示例CPU堆栈跟踪，每100 次最后 1 级缓存丢失记录一次，持续5秒:perf record -e LLC-load-misses -c 100 -ag -- sleep 5 # Sample on-CPU kernel instructions, for 5 seconds:# 内核指令抽样perf record -e cycles:k -a -- sleep 5 # Sample on-CPU user instructions, for 5 seconds:# 用户指令抽样perf record -e cycles:u -a -- sleep 5 # Sample on-CPU user instructions precisely (using PEBS), for 5 seconds:# 使用 PEBS 进行用户指令抽样perf record -e cycles:up -a -- sleep 5 # Perform branch tracing (needs HW support), for 1 second:# 执行分支跟踪(需要HW支持)perf record -b -a sleep 1# Sample CPUs at 49 Hertz, and show top addresses and symbols, live (no perf.data file):perf top -F 49# Sample CPUs at 49 Hertz, and show top process names and segments, live:perf top -F 49 -ns comm,dso Static Tracing(静态追踪)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# Trace new processes, until Ctrl-C:# 跟踪进程创建perf record -e sched:sched_process_exec -a# Sample (take a subset of) context-switches, until Ctrl-C:# 抽样跟踪上下文切换perf record -e context-switches -a# Trace all context-switches, until Ctrl-C:# 跟踪所有上下文切换perf record -e context-switches -c 1 -a# Include raw settings used (see: man perf_event_open):perf record -vv -e context-switches -a# Trace all context-switches via sched tracepoint, until Ctrl-C:# 通过 sched 跟踪点跟踪所有上下文切换perf record -e sched:sched_switch -a# Sample context-switches with stack traces, until Ctrl-C:# 跟踪上下文切换的调用栈perf record -e context-switches -ag# Sample context-switches with stack traces, for 10 seconds:perf record -e context-switches -ag -- sleep 10# Sample CS, stack traces, and with timestamps (&lt; Linux 3.17, -T now default):perf record -e context-switches -ag -T# Sample CPU migrations, for 10 seconds:# 抽样统计 CPU 迁移perf record -e migrations -a -- sleep 10# Trace all connect()s with stack traces (outbound connections), until Ctrl-C:# 跟踪所有出站连接的调用栈perf record -e syscalls:sys_enter_connect -ag# Trace all accepts()s with stack traces (inbound connections), until Ctrl-C:# # 跟踪所有入站连接的调用栈perf record -e syscalls:sys_enter_accept* -ag# Trace all block device (disk I/O) requests with stack traces, until Ctrl-C:# 使用堆栈跟踪跟踪所有块设备(磁盘I/O)请求perf record -e block:block_rq_insert -ag# Sample at most 100 block device requests per second, until Ctrl-C:# 按照每秒最多 100 次的频率踪跟踪所有块设备(磁盘I/O)请求perf record -F 100 -e block:block_rq_insert -a# Trace all block device issues and completions (has timestamps), until Ctrl-C:# 跟踪所有块设备问题和完成情况perf record -e block:block_rq_issue -e block:block_rq_complete -a# Trace all block completions, of size at least 100 Kbytes, until Ctrl-C:# 跟踪所有大小至少为100 kb的块完成情况perf record -e block:block_rq_complete --filter 'nr_sector &gt; 200'# Trace all block completions, synchronous writes only, until Ctrl-C:# 跟踪所有同步完成的块请求perf record -e block:block_rq_complete --filter 'rwbs == "WS"'# Trace all block completions, all types of writes, until Ctrl-C:# 跟踪所有完成的写块请求perf record -e block:block_rq_complete --filter 'rwbs ~ "*W*"'# Sample minor faults (RSS growth) with stack traces, until Ctrl-C:# 跟踪主缺页异常perf record -e minor-faults -ag# Trace all minor faults with stack traces, until Ctrl-C:# 跟踪次缺页异常perf record -e minor-faults -c 1 -ag# Sample page faults with stack traces, until Ctrl-C:# 跟踪所有的缺页异常perf record -e page-faults -ag# Trace all ext4 calls, and write to a non-ext4 location, until Ctrl-C:# 跟踪所有ext4调用，并写入到非ext4位置perf record -e 'ext4:*' -o /tmp/perf.data -a # Trace kswapd wakeup events, until Ctrl-C:# 跟踪kswapd唤醒事件perf record -e vmscan:mm_vmscan_wakeup_kswapd -ag# Add Node.js USDT probes (Linux 4.10+):# 添加Node.js USDT探针perf buildid-cache --add `which node`# Trace the node http__server__request USDT event (Linux 4.10+):# 跟踪节点http_ server_ request USDT事件perf record -e sdt_node:http__server__request -a Dynamic Tracing(动态追踪)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# Add a tracepoint for the kernel tcp_sendmsg() function entry ("--add" is optional):# 为内核tcp_sendmsg()函数条目添加一个跟踪点perf probe --add tcp_sendmsg# Remove the tcp_sendmsg() tracepoint (or use "--del"):# 删除内核tcp_sendmsg()函数跟踪点perf probe -d tcp_sendmsg# Add a tracepoint for the kernel tcp_sendmsg() function return:# 为内核tcp_sendmsg()函数返回添加一个跟踪点perf probe 'tcp_sendmsg%return'# Show available variables for the kernel tcp_sendmsg() function (needs debuginfo):# 显示内核tcp_sendmsg()函数的可用变量perf probe -V tcp_sendmsg# Show available variables for the kernel tcp_sendmsg() function, plus external vars (needs debuginfo):# 显示内核tcp_sendmsg()函数的可用变量，以及外部变量(需要debuginfo)perf probe -V tcp_sendmsg --externs# Show available line probes for tcp_sendmsg() (needs debuginfo):# 显示tcp_sendmsg()的可用行探测perf probe -L tcp_sendmsg# Show available variables for tcp_sendmsg() at line number 81 (needs debuginfo):# 在第81行显示tcp_sendmsg()的可用变量perf probe -V tcp_sendmsg:81# Add a tracepoint for tcp_sendmsg(), with three entry argument registers (platform specific):# 为tcp_sendmsg()添加一个跟踪点，带有三个条目参数寄存器(平台特定的)perf probe 'tcp_sendmsg %ax %dx %cx'# Add a tracepoint for tcp_sendmsg(), with an alias ("bytes") for the %cx register (platform specific):# 为tcp_sendmsg()添加跟踪点，并为%cx寄存器(平台特定)添加别名(“字节”)perf probe 'tcp_sendmsg bytes=%cx'# Trace previously created probe when the bytes (alias) variable is greater than 100:# 当 bytes (别名)变量大于100 时，跟踪以前创建的探针时:perf record -e probe:tcp_sendmsg --filter 'bytes &gt; 100'# Add a tracepoint for tcp_sendmsg() return, and capture the return value:# 为tcp_sendmsg()返回添加一个跟踪点，并捕获返回值:perf probe 'tcp_sendmsg%return $retval'# Add a tracepoint for tcp_sendmsg(), and "size" entry argument (reliable, but needs debuginfo):# 为tcp_sendmsg()和“size”条目参数添加一个跟踪点perf probe 'tcp_sendmsg size'# Add a tracepoint for tcp_sendmsg(), with size and socket state (needs debuginfo):# 为tcp_sendmsg()添加一个跟踪点，该跟踪点具有大小和套接字状态perf probe 'tcp_sendmsg size sk-&gt;__sk_common.skc_state'# Tell me how on Earth you would do this, but don't actually do it (needs debuginfo):# 告诉我你到底会怎么做，但不要真的去做perf probe -nv 'tcp_sendmsg size sk-&gt;__sk_common.skc_state'# Trace previous probe when size is non-zero, and state is not TCP_ESTABLISHED(1) (needs debuginfo):# 跟踪上面创建的探测点，条件是 size 非零且状态不为TCP_ESTABLISHEDperf record -e probe:tcp_sendmsg --filter 'size &gt; 0 &amp;&amp; skc_state != 1' -a# Add a tracepoint for tcp_sendmsg() line 81 with local variable seglen (needs debuginfo):# 使用本地变量seglen为tcp_sendmsg()添加一个跟踪点perf probe 'tcp_sendmsg:81 seglen'# Add a tracepoint for do_sys_open() with the filename as a string (needs debuginfo):# 为do_sys_open()添加一个跟踪点，文件名为字符串perf probe 'do_sys_open filename:string'# Add a tracepoint for myfunc() return, and include the retval as a string:# 为myfunc()返回添加一个跟踪点，并将retval包含为一个字符串perf probe 'myfunc%return +0($retval):string'# Add a tracepoint for the user-level malloc() function from libc:# 为libc中的用户级malloc()函数添加一个跟踪点perf probe -x /lib64/libc.so.6 malloc# Add a tracepoint for this user-level static probe (USDT, aka SDT event):# 为这个用户级静态探测添加一个跟踪点(USDT，即SDT事件)perf probe -x /usr/lib64/libpthread-2.24.so %sdt_libpthread:mutex_entry# List currently available dynamic probes:# 列出当前可用的动态探测perf probe -l Mixed123456789101112131415# Trace system calls by process, showing a summary refreshing every 2 seconds:# 按进程跟踪系统调用，显示每2秒刷新一次的摘要perf top -e raw_syscalls:sys_enter -ns comm# Trace sent network packets by on-CPU process, rolling output (no clear):# 通过 on-CPU进程跟踪发送的网络数据包，滚动输出stdbuf -oL perf top -e net:net_dev_xmit -ns comm | strings# Sample stacks at 99 Hertz, and, context switches:# 按照 99 hz 的频率统计 CPU 时钟和上下文切换的调用栈perf record -F99 -e cpu-clock -e cs -a -g # Sample stacks to 2 levels deep, and, context switch stacks to 5 levels (needs 4.8):# 指定调用栈的统计深度perf record -F99 -e cpu-clock/max-stack=2/ -e cs/max-stack=5/ -a -g Special1234567# Record cacheline events (Linux 4.10+):# 记录cacheline事件perf c2c record -a -- sleep 10# Report cacheline events from previous recording (Linux 4.10+):# 报告之前记录的cacheline事件perf c2c report Reporting12345678910111213141516171819202122232425262728293031323334353637383940414243444546# Show perf.data in an ncurses browser (TUI) if possible:perf report# Show perf.data with a column for sample count:# 显示计数次数perf report -n# Show perf.data as a text report, with data coalesced and percentages:# 使用文本格式，报告 perf.dataperf report --stdio# Report, with stacks in folded format: one line per stack (needs 4.4):# 折叠格式的堆栈报告:每个堆栈一行perf report --stdio -n -g folded# List all events from perf.data:# 列出perf.data中的所有事件perf script# List all perf.data events, with data header (newer kernels; was previously default):# 在 perf script 开头添加统计信息perf script --header# List all perf.data events, with customized fields (&lt; Linux 4.1):# 指定字段显示 perf.data 中的事件信息perf script -f time,event,trace# List all perf.data events, with customized fields (&gt;= Linux 4.1):# 指定字段显示 perf.data 中的事件信息perf script -F time,event,trace# List all perf.data events, with my recommended fields (needs record -a; newer kernels):# 指定字段显示 perf.data 中的事件信息，并在头部显示统计信息perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso # List all perf.data events, with my recommended fields (needs record -a; older kernels):# 指定字段显示 perf.data 中的事件信息，并在头部显示统计信息perf script -f comm,pid,tid,cpu,time,event,ip,sym,dso# Dump raw contents from perf.data as hex (for debugging):# 按照十六进制从perf.data 转储原始内容perf script -D# Disassemble and annotate instructions with percentages (needs some debuginfo):# 显示反汇编并注释的代码perf annotate --stdio These one-liners serve to illustrate the capabilities of perf_events, and can also be used a bite-sized tutorial: learn perf_events one line at a time. You can also print these out as a perf_events cheatsheet. 这些一行程序演示了perf_events的功能，也可以作为小型教程使用:一次只学习一行perf_events。您还可以将其打印为perf_events备忘单。 3. PresentationsKernel Recipes (2017)At Kernel Recipes 2017 I gave an updated talk on Linux perf at Netflix, focusing on getting CPU profiling and flame graphs to work. This talk includes a crash course on perf_events, plus gotchas such as fixing stack traces and symbols when profiling Java, Node.js, VMs, and containers. A video of the talk is on youtube and the slides are on slideshare: There’s also an older version of this talk from 2015, which I’ve posted about. brendangregg 就 Linux perf 发表过两次演讲，下面是视频的链接: 2017 2015 4. BackgroundThe following sections provide some background for understanding perf_events and how to use it. I’ll describe the prerequisites, audience, usage, events, and tracepoints.下面几节提供了一些背景知识，帮助您理解perf_events以及如何使用它。内容包括: prerequisites 先决条件 audience 受众 usage 用法 events 事件 tracepoints 跟踪点 4.1. Prerequisites 先决条件The perf tool is in the linux-tools-common package. Start by adding that, then running “perf” to see if you get the USAGE message. It may tell you to install another related package (linux-tools-kernelversion).perf工具位于linux-tools-common包中。安装 linux-tools-common ，然后运行“perf”，提示信息可能会告诉您需要安装另一个相关的包(linux-tools-kernelversion)。 You can also build and add perf from the Linux kernel source. See the Building section.您还可以从Linux内核源代码构建和添加perf。 To get the most out perf, you’ll want symbols and stack traces. These may work by default in your Linux distribution, or they may require the addition of packages, or recompilation of the kernel with additional config options.为了获得最大的性能，您需要符号和堆栈跟踪。这些可能在Linux发行版中默认工作，或者可能需要额外的包，或者使用其他配置选项重新编译内核。 4.2. Symbols 符号表perf_events, like other debug tools, needs symbol information (symbols). These are used to translate memory addresses into function and variable names, so that they can be read by us humans. Without symbols, you’ll see hexadecimal numbers representing the memory addresses profiled.与其他调试工具一样，perf_events需要符号信息(符号)。它们被用来将内存地址转换成函数和变量名，以便我们人类能够读取它们。如果没有符号，您将看到十六进制数字表示所分析的内存地址。 The following perf report output shows stack traces, however, only hexadecimal numbers can be seen:下面的perf报告输出显示了堆栈跟踪，但是，只能看到十六进制数: 123456789101157.14% sshd libc-2.15.so [.] connect | --- connect | |--25.00%-- 0x7ff3c1cddf29 | |--25.00%-- 0x7ff3bfe82761 | 0x7ff3bfe82b7c | |--25.00%-- 0x7ff3bfe82dfc --25.00%-- [...] If the software was added by packages, you may find debug packages (often “-dbgsym”) which provide the symbols. Sometimes perf report will tell you to install these, eg: “no symbols found in /bin/dd, maybe install a debug package?”.如果软件是通过包添加的，您可能会发现提供这些符号的调试包(通常是“-dbgsym”)。有时perf 会提示去安装这些调试包。 Here’s the same perf report output seen earlier, after adding openssh-server-dbgsym and libc6-dbgsym (this is on ubuntu 12.04):下面是添加了 openssh-server-dbgsym和libc6-dbgsym(这是在ubuntu 12.04上)之后，看到的 perf 报告输出: 123456789101157.14% sshd libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--25.00%-- add_one_listen_addr.isra.0 | |--25.00%-- __nscd_get_mapping | __nscd_get_map_ref | |--25.00%-- __nscd_open_socket --25.00%-- [...] I find it useful to add both libc6-dbgsym and coreutils-dbgsym, to provide some symbol coverage of user-level OS codepaths.我发现同时添加libc6-dbgsym和coreutils-dbgsym很有用，可以提供用户级 OS 代码页的一些符号表。 Another way to get symbols is to compile the software yourself. For example, I just compiled node (Node.js):另一种获取符号的方法是自己编译软件。例如，编译 node (node.js): 12# file node-v0.10.28/out/Release/node node-v0.10.28/out/Release/node: ELF 64-bit LSB executable, ... not stripped This has not been stripped, so I can profile node and see more than just hex. If the result is stripped, configure your build system not to run strip(1) on the output binaries. Kernel-level symbols are in the kernel debuginfo package, or when the kernel is compiled with CONFIG_KALLSYMS.内核级符号位于内核debuginfo包中，或者在内核编译时启用 CONFIG_KALLSYMS 选项 4.3. JIT Symbols (Java, Node.js) JIT 符号表Programs that have virtual machines (VMs), like Java’s JVM and node’s v8, execute their own virtual processor, which has its own way of executing functions and managing stacks. If you profile these using perf_events, you’ll see symbols for the VM engine, which have some use (eg, to identify if time is spent in GC), but you won’t see the language-level context you might be expecting. Eg, you won’t see Java classes and methods.拥有虚拟机(VMs)的程序(如Java的JVM和node的v8)执行它们自己的虚拟处理器，它有自己执行函数和管理堆栈的方式。如果使用perf_events对它们进行分析，只能看到 VM 引擎的符号，这些符号有一些用途(例如，用于确定是否在GC中花费了时间)，但通常不是期望的语言级上下文。不可能不会看到Java类和方法。 perf_events has JIT support to solve this, which requires the VM to maintain a /tmp/perf-PID.map file for symbol translation. Java can do this with perf-map-agent, and Node.js 0.11.13+ with –perf_basic_prof. See my blog post Node.js flame graphs on Linux for the steps.perf_events支持JIT来解决这个问题，这需要VM维护一个 /tmp/perf-PID.map 的符号表转义文件。Java可以使用perf-map-agent实现这一点，而Node.js 0.11.13+可以使用–perf_basic_prof 。请参阅我的博客文章Node.js火焰图在Linux上的步骤。 Note that Java may not show full stacks to begin with, due to hotspot on x86 omitting the frame pointer (just like gcc). On newer versions (JDK 8u60+), you can use the -XX:+PreserveFramePointer option to fix this behavior, and profile fully using perf. See my Netflix Tech Blog post, Java in Flames, for a full writeup, and my Java flame graphs section, which links to an older patch and includes an example resulting flame graph. I also summarized the latest in my JavaOne 2016 talk Java Performance Analysis on Linux with Flame Graphs. 注意，由于hotspot在x86上省略了帧指针(就像gcc一样)，Java可能一开始就没有显示完整的堆栈。在较新的版本(JDK 8u60+)上，您可以使用-XX:+PreserveFramePointer选项来修复此行为，并使用perf完全配置文件。请参阅我的Netflix技术博客文章，Java in flame，以获得完整的描述，以及我的Java火焰图部分，其中链接到一个较老的补丁，并包括一个生成火焰图的示例。我还在我的演讲中总结了最新的用法 Java Performance Analysis on Linux with Flame Graphs. 4.4 Stack Traces 堆栈追踪Always compile with frame pointers. Omitting frame pointers is an evil compiler optimization that breaks debuggers, and sadly, is often the default. Without them, you may see incomplete stacks from perf_events, like seen in the earlier sshd symbols example. There are three ways to fix this: either using dwarf data to unwind the stack, using last branch record (LBR) if available (a processor feature), or returning the frame pointers.总是使用框架指针进行编译。省略帧指针是一种糟糕的编译器优化，它会破坏调试器，不幸的是，它通常是默认的。如果没有它们，您可能会从perf_events中看到不完整的堆栈，就像前面的sshd符号示例中看到的那样。有三种方法可以解决这个问题:要么使用dwarf数据展开堆栈，要么使用可用的最后一个分支记录(LBR)(如果处理器特性支持)，要么返回帧指针。 There are other stack walking techniques, like BTS (Branch Trace Store), and the new ORC unwinder. I’ll add docs for them at some point (and as perf support arrives).还有其他堆栈遍历技术，比如BTS(分支跟踪存储)和新的ORC解卷器。我将在某个时候为它们添加文档。 Frame Pointers 帧指针The earlier sshd example was a default build of OpenSSH, which uses compiler optimizations (-O2), which in this case has omitted the frame pointer. Here’s how it looks after recompiling OpenSSH with -fno-omit-frame-pointer:早期的sshd示例是OpenSSH的默认构建，它使用编译器优化(-O2)，省略了帧指针。下面是用-fno-omit-frame-pointer(省略帧指针)重新编译OpenSSH后，进行剖析的结果: 123456789101112131415100.00% sshd libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--30.00%-- add_one_listen_addr.isra.0 | add_listen_addr | fill_default_server_options | main | __libc_start_main | |--20.00%-- __nscd_get_mapping | __nscd_get_map_ref | |--20.00%-- __nscd_open_socket --30.00%-- [...] Now the ancestry from add_one_listen_addr() can be seen, down to main() and __libc_start_main().现在可以看到来自 add_one_listen_addr() 的祖先，一直到main()和libc_start_main()。意思是省略帧指针后，堆栈信息显示不完整 The kernel can suffer the same problem. Here’s an example CPU profile collected on an idle server, with stack traces (-g):内核也有类似省略帧指针的问题。下面是一个在空闲服务器上收集的带有堆栈跟踪(-g)的 CPU 剖析信息: 12345678999.97% swapper [kernel.kallsyms] [k] default_idle | --- default_idle 0.03% sshd [kernel.kallsyms] [k] iowrite16 | --- iowrite16 __write_nocancel (nil) The kernel stack traces are incomplete. Now a similar profile with CONFIG_FRAME_POINTER=y:内核堆栈跟踪是不完整的。下面是启用 CONFIG_FRAME_POINTER=y 编译选项后类似的剖析结果: 12345678910111213141516171819202122232425262728293031323334353699.97% swapper [kernel.kallsyms] [k] default_idle | --- default_idle cpu_idle | |--87.50%-- start_secondary | --12.50%-- rest_init start_kernel x86_64_start_reservations x86_64_start_kernel 0.03% sshd [kernel.kallsyms] [k] iowrite16 | --- iowrite16 vp_notify virtqueue_kick start_xmit dev_hard_start_xmit sch_direct_xmit dev_queue_xmit ip_finish_output ip_output ip_local_out ip_queue_xmit tcp_transmit_skb tcp_write_xmit __tcp_push_pending_frames tcp_sendmsg inet_sendmsg sock_aio_write do_sync_write vfs_write sys_write system_call_fastpath __write_nocancel Much better – the entire path from the write() syscall (__write_nocancel) to iowrite16() can be seen.效果好很多，可以看到 write() 系统调用的完整信息。 DwarfSince about the 3.9 kernel, perf_events has supported a workaround for missing frame pointers in user-level stacks: libunwind, which uses dwarf. This can be enabled using “–call-graph dwarf” (or “-g dwarf”).从3.9内核开始，perf_events就支持用户级栈中缺少帧指针的解决方案:libunwind，叫做 dwarf。可以使用”–call-graph dwarf”(或“-g dwarf”)启用此功能。 Also see the Building section for other notes about building perf_events, as without the right library, it may build itself without dwarf support.perf 可以在没有 dwarf 支持的情况下构建。因此是否支持 dwarf 要查阅安装信息。 LBRYou must have Last Branch Record access to be able to use this. It is disabled in most cloud environments, where you’ll get this error:您必须拥有最后一个分支记录访问权才能使用它。它在大多数云环境中是禁用的，你会得到这个错误: 123&gt; perf record -F 99 -a --call-graph lbrError:PMU Hardware doesn't support sampling/overflow-interrupts. Here’s an example of it working:下面是它能工作的一个例子: 123456789101112131415161718192021222324252627&gt; perf record -F 99 -a --call-graph lbr^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.903 MB perf.data (163 samples) ]&gt; perf script[...]stackcollapse-p 23867 [007] 4762187.971824: 29003297 cycles:ppp: 1430c0 Perl_re_intuit_start (/usr/bin/perl) 144118 Perl_regexec_flags (/usr/bin/perl) cfcc9 Perl_pp_match (/usr/bin/perl) cbee3 Perl_runops_standard (/usr/bin/perl) 51fb3 perl_run (/usr/bin/perl) 2b168 main (/usr/bin/perl)stackcollapse-p 23867 [007] 4762187.980184: 31532281 cycles:ppp: e3660 Perl_sv_force_normal_flags (/usr/bin/perl) 109b86 Perl_leave_scope (/usr/bin/perl) 1139db Perl_pp_leave (/usr/bin/perl) cbee3 Perl_runops_standard (/usr/bin/perl) 51fb3 perl_run (/usr/bin/perl) 2b168 main (/usr/bin/perl)stackcollapse-p 23867 [007] 4762187.989283: 32341031 cycles:ppp: cfae0 Perl_pp_match (/usr/bin/perl) cbee3 Perl_runops_standard (/usr/bin/perl) 51fb3 perl_run (/usr/bin/perl) 2b168 main (/usr/bin/perl) Nice! Note that LBR is usually limited in stack depth (either 8, 16, or 32 frames), so it may not be suitable for deep stacks or flame graph generation, as flame graphs need to walk to the common root for merging. 很好!但是注意，LBR通常限制了堆栈深度(8、16或32帧)，所以它可能不适合深度堆栈或火焰图生成，因为火焰图需要走到用于合并的公共根。 Here’s that same program sampled using the by-default frame pointer walk:下面是使用默认栈指针输出的剖析信息 1234567891011121314&gt; perf record -F 99 -a -g^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.882 MB perf.data (81 samples) ]&gt; perf script[...]stackcollapse-p 23883 [005] 4762405.747834: 35044916 cycles:ppp: 135b83 [unknown] (/usr/bin/perl)stackcollapse-p 23883 [005] 4762405.757935: 35036297 cycles:ppp: ee67d Perl_sv_gets (/usr/bin/perl)stackcollapse-p 23883 [005] 4762405.768038: 35045174 cycles:ppp: 137334 [unknown] (/usr/bin/perl) You can recompile Perl with frame pointer support (in its ./Configure, it asks what compiler options: add -fno-omit-frame-pointer). Or you can use LBR if it’s available, and you don’t need very long stacks.对于上面的输出，你可以选择使用 -fno-omit-frame-pointer 选项重新编译 Perl，如果你需要深度的堆栈追踪也可以使用 LBR。 4.5. AudienceTo use perf_events, you’ll either: Develop your own commands Run example commands Developing new invocations of perf_events requires the study of kernel and application code, which isn’t for everyone. Many more people will use perf_events by running commands developed by other people, like the examples on this page. This can work out fine: your organization may only need one or two people who can develop perf_events commands or source them, and then share them for use by the entire operation and support groups. 开发新的perf_events调用需要研究内核和应用程序代码，这并不适合所有人。更多的人将通过运行其他人开发的命令来使用perf_events，就像本文中的示例一样。这可以很好地解决问题:您的组织可能只需要一到两个人，他们可以开发perf_events命令或获取它们的源代码，然后共享它们供整个操作和支持组使用。 Either way, you need to know the capabilities of perf_events so you know when to reach for it, whether that means searching for an example command or writing your own. One goal of the examples that follow is just to show you what can be done, to help you learn these capabilities. You should also browse examples on other sites (Links).无论使用哪种方法，您都需要了解perf_events的功能，这样才能有效的搜索。下面的示例的一个目标就是向您展示可以做什么，以帮助您学习这些功能。您还应该在其他站点(链接)上浏览示例。 If you’ve never used perf_events before, you may want to test before production use (it has had kernel panic bugs in the past). My experience has been a good one (no panics).如果您以前从未使用过perf_events，那么您可能希望在生产环境使用之前进行测试(它以前出现过内核故障)。我的经历很好(不用恐慌)。 4.6. Usageperf_events provides a command line tool, perf, and subcommands for various profiling activities. This is a single interface for the different instrumentation frameworks that provide the various events.perf_events为各种分析活动提供了 perf 密令。这是用于提供各种事件的不同工具框架的单个接口。 The perf command alone will list the subcommands; here is perf version 4.10 (for the Linux 4.10 kernel):不带参数的 perf 命令将会列出所有子命令;下面是perf 4.10版本的输出(适用于Linux 4.10内核): 1234567891011121314151617181920212223242526272829303132# perf usage: perf [--version] [--help] [OPTIONS] COMMAND [ARGS] The most commonly used perf commands are: annotate Read perf.data (created by perf record) and display annotated code archive Create archive with object files with build-ids found in perf.data file bench General framework for benchmark suites buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file config Get and set variables in a configuration file. data Data file related processing diff Read perf.data files and display the differential profile evlist List the event names in a perf.data file inject Filter to augment the events stream with additional information kmem Tool to trace/measure kernel memory properties kvm Tool to trace/measure kvm guest os list List all symbolic event types lock Analyze lock events mem Profile memory accesses record Run a command and record its profile into perf.data report Read perf.data (created by perf record) and display the profile sched Tool to trace/measure scheduler properties (latencies) script Read perf.data (created by perf record) and display trace output stat Run a command and gather performance counter statistics test Runs sanity tests. timechart Tool to visualize total system behavior during a workload top System profiling tool. probe Define new dynamic tracepoints trace strace inspired tool See 'perf help COMMAND' for more information on a specific command. Apart from separate help for each subcommand, there is also documentation in the kernel source under tools/perf/Documentation. perf has evolved, with different functionality added over time, so on an older kernel you may be missing some subcommands or functionality. Also, its usage may not feel consistent as you switch between activities. It’s best to think of it as a multi-tool.除了每个子命令的单独帮助之外，在工具/perf/Documentation下的内核源代码中也有文档。perf不断发展，随着时间的推移添加了不同的功能，因此在较老的内核中，您可能会丢失一些子命令或功能。而且，当您在活动之间切换时，它的用法可能感觉不一致。最好将其视为一个多工具。 perf_events can instrument in three ways (now using the perf_events terminology): counting events in-kernel context, where a summary of counts is printed by perf. This mode does not generate a perf.data file. sampling events, which writes event data to a kernel buffer, which is read at a gentle asynchronous rate by the perf command to write to the perf.data file. This file is then read by the perf report or perf script commands. bpf programs on events, a new feature in Linux 4.4+ kernels that can execute custom user-defined programs in kernel space, which can perform efficient filters and summaries of the data. Eg, efficiently-measured latency histograms. perf_events有三种使用方式(现在使用perf_events术语): 计数模式: 对应 perf stat 命令，其在内核上下文中计数事件，其中计数的摘要由perf打印。此模式不生成perf.data文件 采样事件：将事件数据写入内核缓冲区，由perf 以缓慢的异步速率读取内核缓冲区，以便写入到perf.data 文件。然后，perf report 或perf script 命令读取此文件。 事件上的bpf程序，这是Linux 4.4+内核中的一个新特性，它可以在内核空间中执行自定义用户定义的程序，可以执行高效的数据筛选和总结。 Try starting by counting events using the perf stat command, to see if this is sufficient. This subcommand costs the least overhead.尝试从使用perf stat命令计算事件开始，看看这是否足够。这个子命令开销最小。 When using the sampling mode with perf record, you’ll need to be a little careful about the overheads, as the capture files can quickly become hundreds of Mbytes. It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size.在使用perf记录的采样模式时，您需要注意开销，因为捕获文件可能很快就会变成数百兆字节。这取决于您正在跟踪的事件的频率:频率越高，开销越大，性能越大，数据越多 To really cut down overhead and generate more advanced summaries, write BPF programs executed by perf. See the eBPF section.要真正减少开销并生成更高级的摘要，可以编写由perf执行的BPF程序。请参阅eBPF部分。 4.7. Usage ExamplesThese example sequences have been chosen to illustrate some different ways that perf is used, from gathering to reporting.选择这些示例序列是为了说明使用perf的一些不同方式，从收集到报告。 Performance counter summaries, including IPC, for the gzip command:gzip命令的性能计数器总结，包括IPC: 1# perf stat gzip largefile Count all scheduler process events for 5 seconds, and count by tracepoint:按照静态探针对进程调度事件进行计数，持续 5s 1# perf stat -e 'sched:sched_process_*' -a sleep 5 Trace all scheduler process events for 5 seconds, and count by both tracepoint and process name:按照静态探针跟踪进程调度事件，持续 5s12# perf record -e 'sched:sched_process_*' -a sleep 5# perf report Trace all scheduler process events for 5 seconds, and dump per-event details:按照静态探针跟踪进程调度事件，持续 5s，并转储事件信息信息12# perf record -e 'sched:sched_process_*' -a sleep 5# perf script Trace read() syscalls, when requested bytes is less than 10:跟踪请求的字节小于10 的 read() 系统调用1# perf record -e 'syscalls:sys_enter_read' --filter 'count &lt; 10' -a Sample CPU stacks at 99 Hertz, for 5 seconds:以 99hz 的频率抽样CPU堆栈12# perf record -F 99 -ag -- sleep 5# perf report Dynamically instrument the kernel tcp_sendmsg() function, and trace it for 5 seconds, with stack traces:添加 tcp_sendmsg 动态探针，追踪 5s，并记录堆栈1234# perf probe --add tcp_sendmsg# perf record -e probe:tcp_sendmsg -ag -- sleep 5# perf probe --del tcp_sendmsg# perf report Deleting the tracepoint (–del) wasn’t necessary; I included it to show how to return the system to its original state.没有必要删除跟踪点(–del);我包含它是为了说明如何将系统返回到其原始状态。 Caveats The use of -p PID as a filter doesn’t work properly on some older kernel versions (Linux 3.x): perf hits 100% CPU and needs to be killed. It’s annoying. The workaround is to profile all CPUs (-a), and filter PIDs later.警告使用-p PID作为过滤器在一些较老的内核版本(Linux 3.x)上不能正常工作。解决方法是配置所有cpu (-a)，然后 filter 选项过滤出所需的 PID 信息。 4.8. Special UsageThere’s a number of subcommands that provide special purpose functionality. These include: perf c2c (Linux 4.10+): cache-2-cache and cacheline false sharing analysis. perf kmem: kernel memory allocation analysis. perf kvm: KVM virtual guest analysis. perf lock: lock analysis. perf mem: memory access analysis. perf sched: kernel scheduler statistics. Examples. These make use of perf’s existing instrumentation capabilities, recording selected events and reporting them in custom ways. 有许多子命令提供特殊用途的功能。这些包括: perf c2c (Linux 4.10+): cache-2-cache and cacheline false 共享分析 perf kmem: 内核内存分配分析。 perf kvm：KVM虚拟客户端分析。 perf lock: 锁分析 perf mem: 内存访问分析。 perf sched: 内核调度器的统计数据。示例 它们利用perf现有的检测功能，记录选定的事件并以定制的方式报告它们。 5. Eventsperf_events instruments “events”, which are a unified interface for different kernel instrumentation frameworks. The following map (from my SCaLE13x talk) illustrates the event sources:perf_events工具“事件”，它是不同内核工具框架的统一接口。下面的地图(来自我的SCaLE13x演讲)说明了事件来源: The types of events are: Hardware Events: CPU performance monitoring counters. Software Events: These are low level events based on kernel counters. For example, CPU migrations, minor faults, major faults, etc. Kernel Tracepoint Events: This are static kernel-level instrumentation points that are hardcoded in interesting and logical places in the kernel. User Statically-Defined Tracing (USDT): These are static tracepoints for user-level programs and applications. Dynamic Tracing: Software can be dynamically instrumented, creating events in any location. For kernel software, this uses the kprobes framework. For user-level software, uprobes. Timed Profiling: Snapshots can be collected at an arbitrary frequency, using perf record -FHz. This is commonly used for CPU usage profiling, and works by creating custom timed interrupt events. event 有如下类型: Hardware Events: CPU性能监视计数器 Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点， User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 使用perf -FHz 选项以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 Details about the events can be collected, including timestamps, the code path that led to it, and other specific details. The capabilities of perf_events are enormous, and you’re likely to only ever use a fraction.可以收集事件的详细信息，包括时间戳、导致事件的代码路径和其他特定细节。perf_events的功能非常强大，您可能只会使用一小部分。 Currently available events can be listed using the list subcommand:可以使用list子命令列出当前可用的事件: 123456789101112131415161718192021222324252627282930313233343536373839# perf listList of pre-defined events (to be used in -e): cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] cpu-clock [Software event] task-clock [Software event] page-faults OR faults [Software event] context-switches OR cs [Software event] cpu-migrations OR migrations [Software event] minor-faults [Software event] major-faults [Software event] alignment-faults [Software event] emulation-faults [Software event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event][...] rNNN [Raw hardware event descriptor] cpu/t1=v1[,t2=v2,t3 ...]/modifier [Raw hardware event descriptor] (see 'man perf-list' on how to encode it) mem:&lt;addr&gt;[:access] [Hardware breakpoint] probe:tcp_sendmsg [Tracepoint event][...] sched:sched_process_exec [Tracepoint event] sched:sched_process_fork [Tracepoint event] sched:sched_process_wait [Tracepoint event] sched:sched_wait_task [Tracepoint event] sched:sched_process_exit [Tracepoint event][...]# perf list | wc -l 657 When you use dynamic tracing, you are extending this list. The probe:tcp_sendmsg tracepoint in this list is an example, which I added by instrumenting tcp_sendmsg(). Profiling (sampling) events are not listed.当您使用动态跟踪时，您是在扩展这个列表。这个列表中的 probe:tcp_sendmsg 探针就是我动态插入 tcp_sendmsg() 的例子。 5.1. Software EventsThere is a small number of fixed software events provided by perf:perf提供了少量固定的软件事件: 12345678910111213141516# perf listList of pre-defined events (to be used in -e): alignment-faults [Software event] bpf-output [Software event] context-switches OR cs [Software event] cpu-clock [Software event] cpu-migrations OR migrations [Software event] dummy [Software event] emulation-faults [Software event] major-faults [Software event] minor-faults [Software event] page-faults OR faults [Software event] task-clock [Software event][...] These are also documented in the man page perf_event_open(2):这些也记录在手册页perf_event_open(2): 12345678910111213141516171819202122232425[...] PERF_COUNT_SW_CPU_CLOCK This reports the CPU clock, a high-resolution per- CPU timer. PERF_COUNT_SW_TASK_CLOCK This reports a clock count specific to the task that is running. PERF_COUNT_SW_PAGE_FAULTS This reports the number of page faults. PERF_COUNT_SW_CONTEXT_SWITCHES This counts context switches. Until Linux 2.6.34, these were all reported as user-space events, after that they are reported as happening in the kernel. PERF_COUNT_SW_CPU_MIGRATIONS This reports the number of times the process has migrated to a new CPU. PERF_COUNT_SW_PAGE_FAULTS_MIN This counts the number of minor page faults. These did not require disk I/O to handle.[...] The kernel also supports traecpoints, which are very similar to software events, but have a different more extensible API.内核也支持traecpoints，它与软件事件非常相似，但具有不同的更具可扩展性的API。 Software events may have a default period. This means that when you use them for sampling, you’re sampling a subset of events, not tracing every event. You can check with perf record -vv:软件事件可能有一个默认的周期。这意味着当您使用它们进行抽样时，您是在对事件的子集进行抽样，而不是跟踪每个事件。你可以通过 perf record -vv 查看: 12345678910111213141516# perf record -vv -e context-switches /bin/trueUsing CPUID GenuineIntel-6-55------------------------------------------------------------perf_event_attr: type 1 size 112 config 0x3 &#123; sample_period, sample_freq &#125; 4000 sample_type IP|TID|TIME|PERIOD disabled 1 inherit 1 mmap 1 comm 1 freq 1 enable_on_exec 1[...] See the perf_event_open(2) man page for a description of these fields. This default means is that the kernel adjusts the rate of sampling so that it’s capturing about 4,000 context switch events per second. If you really meant to record them all, use -c 1:有关这些字段的描述，请参见perf_event_open(2)手册页。这个默认的意思是内核调整采样率，以便它每秒捕获大约4000个上下文切换事件。如果你真的想把它们全部记录下来，请使用-c1: 1234567891011121314# perf record -vv -e context-switches -c 1 /bin/trueUsing CPUID GenuineIntel-6-55------------------------------------------------------------perf_event_attr: type 1 size 112 config 0x3 &#123; sample_period, sample_freq &#125; 1 sample_type IP|TID|TIME disabled 1 inherit 1 mmap 1 comm 1 enable_on_exec 1 Check the rate of events using perf stat first, so that you can estimate the volume of data you’ll be capturing. Sampling a subset by default may be a good thing, especially for high frequency events like context switches.首先使用perf stat检查事件的速率，这样您就可以估计将要捕获的数据量。在默认情况下对子集进行采样可能是一件好事，特别是对于上下文切换这样的高频率事件。 Many other events (like tracepoints) have a default of 1 anyway. You’ll encounter a non-1 default for many software and hardware events.许多其他事件(比如跟踪点)的默认值都是1。对于许多软件和硬件事件，您将遇到非1的缺省值。 5.2. Hardware Events (PMCs)perf_events began life as a tool for instrumenting the processor’s performance monitoring unit (PMU) hardware counters, also called performance monitoring counters (PMCs), or performance instrumentation counters (PICs). These instrument low-level processor activity, for example, CPU cycles, instructions retired, memory stall cycles, level 2 cache misses, etc. Some will be listed as Hardware Cache Events.perf_events最初作为一种工具用于检测处理器的性能监视单元 PMU，PMU 被称为硬件计数器，也叫做性能监视计数器(pmmc)或性能仪表计数器(PICs)。它监测低层次的处理器活动，例如，CPU周期，指令退役，内存失速周期，二级缓存丢失，等等。其中一些将作为硬件缓存事件列出。 PMCs are documented in the Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 3B: System Programming Guide, Part 2 and the BIOS and Kernel Developer’s Guide (BKDG) For AMD Family 10h Processors. There are thousands of different PMCs available.pmc在Intel 64和IA-32架构软件开发人员手册卷3B:系统编程指南，第2部分和AMD家族10h处理器的BIOS和内核开发人员指南(BKDG)中有文档记录。有数千种不同的pmc可用。 A typical processor will implement PMCs in the following way: only a few or several can be recorded at the same time, from the many thousands that are available. This is because they are a fixed hardware resource on the processor (a limited number of registers), and are programmed to begin counting the selected events.典型的处理器将以以下方式实现pmc:在可用的数千个pmc中，只能同时记录几个pmc。这是因为它们是处理器上的固定硬件资源(寄存器的有限数量)，并且被编程为开始计算所选事件。 For examples of using PMCs, see CPU Statistics.有关使用pmc的示例，请参见CPU统计信息。 5.3. Kernel TracepointsThese tracepoints are hard coded in interesting and logical locations of the kernel, so that higher-level behavior can be easily traced. For example, system calls, TCP events, file system I/O, disk I/O, etc. These are grouped into libraries of tracepoints; eg, “sock:” for socket events, “sched:” for CPU scheduler events. A key value of tracepoints is that they should have a stable API, so if you write tools that use them on one kernel version, they should work on later versions as well.这些跟踪点被硬编码在内核的有用的位置上，以便更高层次的行为可以很容易地被跟踪。例如，系统调用、TCP事件、文件系统I/O、磁盘I/O等等。它们被分组到跟踪点库中;例如，“sock:”表示套接字事件，“sched:”表示CPU调度器事件。跟踪点的一个关键价值是它们应该有一个稳定的API，因此如果您编写的工具在一个内核版本上使用它们，那么它们也应该适用于以后的版本。 Tracepoints are usually added to kernel code by placing a macro from include/trace/events/. XXX cover implementation.跟踪点通常通过放置在 include/trace/events/.XXX 中的宏添加到内核代码中来实现。 Summarizing the tracepoint library names and numbers of tracepoints, on my Linux 4.10 system:下面是 Linux4.10 系统上对 tracepoint 库和数量的统计。 1234567891011121314151617181920&gt; perf list | awk -F: '/Tracepoint event/ &#123; lib[$1]++ &#125; END &#123; for (l in lib) &#123; printf " %-16.16s %d\n", l, lib[l] &#125; &#125;' | sort | column alarmtimer 4 i2c 8 page_isolation 1 swiotlb 1 block 19 iommu 7 pagemap 2 syscalls 614 btrfs 51 irq 5 power 22 task 2 cgroup 9 irq_vectors 22 printk 1 thermal 7 clk 14 jbd2 16 random 15 thermal_power_ 2 cma 2 kmem 12 ras 4 timer 13 compaction 14 libata 6 raw_syscalls 2 tlb 1 cpuhp 3 mce 1 rcu 1 udp 1 dma_fence 8 mdio 1 regmap 15 vmscan 15 exceptions 2 migrate 2 regulator 7 vsyscall 1 ext4 95 mmc 2 rpm 4 workqueue 4 fib 3 module 5 sched 24 writeback 30 fib6 1 mpx 5 scsi 5 x86_fpu 14 filelock 10 msr 3 sdt_node 1 xen 35 filemap 2 napi 1 signal 2 xfs 495 ftrace 1 net 10 skb 3 xhci-hcd 9 gpio 2 nmi 1 sock 2 huge_memory 4 oom 1 spi 7 These include: block: block device I/O ext4: file system operations kmem: kernel memory allocation events random: kernel random number generator events sched: CPU scheduler events syscalls: system call enter and exits task: task events 这些包括: block: 块设备I/O ext4: 文件系统操作 kmem: 内核内存分配事件 random: 内核随机数生成器事件 sched: CPU调度器事件 random: 系统调用的进入和返回 task: 任务事件 It’s worth checking the list of tracepoints after every kernel upgrade, to see if any are new. The value of adding them has been debated from time to time, with it wondered how many people will use them (I do). There is a balance to aim for: I’d include the smallest number of probes that sufficiently covers common needs, and anything unusual or uncommon can be left to dynamic tracing.在每次内核升级之后，都有必要检查跟踪点列表，看看是否有新的跟踪点。添加它们是经过充分考虑的，包括评估有多少人会使用它们。需要实现一个平衡:我将包括尽可能少的探测，以充分满足常见需求，任何不寻常或不常见的情况都可以留给动态跟踪。 For examples of using tracepoints, see Static Kernel Tracing.有关使用跟踪点的示例，请参见静态内核跟踪。 5.4. User-Level Statically Defined Tracing (USDT)Similar to kernel tracepoints, these are hardcoded (usually by placing macros) in the application source at logical and interesting locations, and presented (event name and arguments) as a stable API. Many applications already include tracepoints, added to support DTrace. However, many of these applications do not compile them in by default on Linux. Often you need to compile the application yourself using a –with-dtrace flag.与内核跟踪点类似，这些跟踪点是硬编码的(通常通过将宏放置在应用程序源代码中)，并作为稳定的API呈现(事件名称和参数)。许多应用程序已经包括跟踪点，这些跟踪点是为了支持DTrace而添加的。然而，许多这些应用程序在Linux上默认情况下并不编译它们。通常需要使用—with-dtrace标志自己编译应用程序。 For example, compiling USDT events with this version of Node.js:例如，用这个版本的Node.js编译USDT事件: 123456$ sudo apt-get install systemtap-sdt-dev # adds "dtrace", used by node build$ wget https://nodejs.org/dist/v4.4.1/node-v4.4.1.tar.gz$ tar xvf node-v4.4.1.tar.gz $ cd node-v4.4.1$ ./configure --with-dtrace$ make -j 8 To check that the resulting node binary has probes included:检查产生的二进制程序是否包含了 USDT 探测点: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354$ readelf -n nodeDisplaying notes found at file offset 0x00000254 with length 0x00000020: Owner Data size Description GNU 0x00000010 NT_GNU_ABI_TAG (ABI version tag) OS: Linux, ABI: 2.6.32Displaying notes found at file offset 0x00000274 with length 0x00000024: Owner Data size Description GNU 0x00000014 NT_GNU_BUILD_ID (unique build ID bitstring) Build ID: 1e01659b0aecedadf297b2c56c4a2b536ae2308aDisplaying notes found at file offset 0x00e70994 with length 0x000003c4: Owner Data size Description stapsdt 0x0000003c NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: gc__start Location: 0x0000000000dc14e4, Base: 0x000000000112e064, Semaphore: 0x000000000147095c Arguments: 4@%esi 4@%edx 8@%rdi stapsdt 0x0000003b NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: gc__done Location: 0x0000000000dc14f4, Base: 0x000000000112e064, Semaphore: 0x000000000147095e Arguments: 4@%esi 4@%edx 8@%rdi stapsdt 0x00000067 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__server__response Location: 0x0000000000dc1894, Base: 0x000000000112e064, Semaphore: 0x0000000001470956 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000061 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: net__stream__end Location: 0x0000000000dc1c44, Base: 0x000000000112e064, Semaphore: 0x0000000001470952 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000068 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: net__server__connection Location: 0x0000000000dc1ff4, Base: 0x000000000112e064, Semaphore: 0x0000000001470950 Arguments: 8@%rax 8@-1144(%rbp) -4@-1148(%rbp) -4@-1152(%rbp) stapsdt 0x00000060 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__client__response Location: 0x0000000000dc23c5, Base: 0x000000000112e064, Semaphore: 0x000000000147095a Arguments: 8@%rdx 8@-1144(%rbp) -4@%eax -4@-1152(%rbp) stapsdt 0x00000089 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__client__request Location: 0x0000000000dc285e, Base: 0x000000000112e064, Semaphore: 0x0000000001470958 Arguments: 8@%rax 8@%rdx 8@-2184(%rbp) -4@-2188(%rbp) 8@-2232(%rbp) 8@-2240(%rbp) -4@-2192(%rbp) stapsdt 0x00000089 NT_STAPSDT (SystemTap probe descriptors) Provider: node Name: http__server__request Location: 0x0000000000dc2e69, Base: 0x000000000112e064, Semaphore: 0x0000000001470954 Arguments: 8@%r14 8@%rax 8@-4344(%rbp) -4@-4348(%rbp) 8@-4304(%rbp) 8@-4312(%rbp) -4@-4352(%rbp) For examples of using USDT events, see Static User Tracing.有关使用USDT事件的示例，请参见静态用户跟踪。 5.5. Dynamic TracingThe difference between tracepoints and dynamic tracing is shown in the following figure, which illustrates the coverage of common tracepoint libraries:跟踪点和动态跟踪之间的区别如下图所示，它说明了通用跟踪点库的覆盖范围: While dynamic tracing can see everything, it’s also an unstable interface since it is instrumenting raw code. That means that any dynamic tracing tools you develop may break after a kernel patch or update. Try to use the static tracepoints first, since their interface should be much more stable. They can also be easier to use and understand, since they have been designed with a tracing end-user in mind.虽然动态跟踪可以看到所有东西，但它也是一个不稳定的接口，因为它检测的是原始代码。这意味着您开发的任何动态跟踪工具在内核补丁或更新之后可能会中断。首先尝试使用静态跟踪点，因为它们的接口应该更加稳定。它们也更容易使用和理解，因为它们是为跟踪最终用户而设计的。 One benefit of dynamic tracing is that it can be enabled on a live system without restarting anything. You can take an already-running kernel or application and then begin dynamic instrumentation, which (safely) patches instructions in memory to add instrumentation. That means there is zero overhead or tax for this feature until you begin using it. One moment your binary is running unmodified and at full speed, and the next, it’s running some extra instrumentation instructions that you dynamically added. Those instructions should eventually be removed once you’ve finished using your session of dynamic tracing.动态跟踪的一个好处是，它可以在活动的系统上启用，而不需要重新启动任何东西。您可以使用一个已经运行的内核或应用程序，然后开始动态检测，它(安全地)在内存中修补指令以添加检测。这意味着在您开始使用此功能之前，此功能的开销或税收为零。这一刻，您的二进制文件还在以全速运行，而下一刻，它又在运行一些您动态添加的额外的检测指令。当您使用完动态跟踪会话后，这些指令最终应该被删除。 The overhead while dynamic tracing is in use, and extra instructions are being executed, is relative to the frequency of instrumented events multiplied by the work done on each instrumentation.在使用动态跟踪和执行额外指令时的开销，与插装事件的频率乘以在每个插装上所做的工作有关。 For examples of using dynamic tracing, see 6.5. Dynamic Tracing.有关使用动态跟踪的示例，请参见 6.5. Dynamic Tracing 6. ExamplesThese are some examples of perf_events, collected from a variety of 3.x Linux systems.下面是 Linux3.x perf_events的一些示例。 6.1. CPU StatisticsThe perf stat command instruments and summarizes key CPU counters (PMCs). This is from perf version 3.5.7.2:下面是 3.5.7.2版本的 perf stat 子命令输出的 PMCs 计数器统计值。 1234567891011121314151617# perf stat gzip file1 Performance counter stats for 'gzip file1': 1920.159821 task-clock # 0.991 CPUs utilized 13 context-switches # 0.007 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.134 K/sec 5,649,595,479 cycles # 2.942 GHz [83.43%] 1,808,339,931 stalled-cycles-frontend # 32.01% frontend cycles idle [83.54%] 1,171,884,577 stalled-cycles-backend # 20.74% backend cycles idle [66.77%] 8,625,207,199 instructions # 1.53 insns per cycle # 每周期指令数 # 0.21 stalled cycles per insn [83.51%] 1,488,797,176 branches # 775.351 M/sec [82.58%] 53,395,139 branch-misses # 3.59% of all branches [83.78%] 1.936842598 seconds time elapsed This includes instructions per cycle (IPC), labled “insns per cycle”, or in earlier versions, “IPC”. This is a commonly examined metric, either IPC or its invert, CPI. Higher IPC values mean higher instruction throughput, and lower values indicate more stall cycles. I’d generally interpret high IPC values (eg, over 1.0) as good, indicating optimal processing of work. However, I’d want to double check what the instructions are, in case this is due to a spin loop: a high rate of instructions, but a low rate of actual work completed.这包括每个周期的指令(IPC)，标签为“每个周期的insns”，或者在早期版本中为“IPC”。这是一个经常被检验的指标，无论是IPC还是它的倒数CPI。更高的IPC值意味着更高的指令吞吐量，更低的值表示更多的停顿周期。一般来说，我认为IPC值越高(例如，超过1.0)就越好，表示工作的最佳处理。但是，需要检查执行指令是什么，以防这是一个旋转循环: 指令率高，但实际完成的工作率低。 There are some advanced metrics now included in perf stat: frontend cycles idle, backend cycles idle, and stalled cycles per insn. To really understand these, you’ll need some knowledge of CPU microarchitecture.现在perf stat中包含了一些高级指标:frontend cycles idle, backend cycles idle, 和 stalled cycles per insn.。要真正理解这些，您需要一些CPU微架构的知识。 CPU MicroarchitectureCPU 微内核架构 The frontend and backend metrics refer to the CPU pipeline, and are also based on stall counts. The frontend processes CPU instructions, in order. It involves instruction fetch, along with branch prediction, and decode. The decoded instructions become micro-operations (uops) which the backend processes, and it may do so out of order. For a longer summary of these components, see Shannon Cepeda’s great posts on frontend and backend.前端和后端指标指的是CPU管道，统计的是它们的停顿次数。前端按顺序处理CPU指令。它包括指令获取，以及分支预测和解码。解码后的指令成为后端处理的微操作(uops)，并且可能会乱序地执行。对于这些组件的更长的总结，请参阅Shannon Cepeda关于前端和后端的优秀文章。 The backend can also process multiple uops in parallel; for modern processors, three or four. Along with pipelining, this is how IPC can become greater than one, as more than one instruction can be completed (“retired”) per CPU cycle.后台也可以并行处理多个uops;对于现代处理器来说，有三到四个。与流水线操作一起，IPC可以变得大于1，因为每个CPU周期可以完成多条指令(“已退役”)。 Stalled cycles per instruction is similar to IPC (inverted), however, only counting stalled cycles, which will be for memory or resource bus access. This makes it easy to interpret: stalls are latency, reduce stalls. I really like it as a metric, and hope it becomes as commonplace as IPC/CPI. Lets call it SCPI.每条指令的停滞周期类似于IPC(反向)，但是，只计算停滞周期，这将用于内存或资源总线访问。这很容易解释:档位是延迟，减少档位。我真的很喜欢把它作为一个度量标准，并希望它能像IPC/CPI一样普及。我们叫它SCPI。 Detailed ModeThere is a “detailed” mode for perf stat:下面是 perf stat 的详细输出模式 123456789101112131415161718192021# perf stat -d gzip file1 Performance counter stats for 'gzip file1': 1610.719530 task-clock # 0.998 CPUs utilized 20 context-switches # 0.012 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.160 K/sec 5,491,605,997 cycles # 3.409 GHz [40.18%] 1,654,551,151 stalled-cycles-frontend # 30.13% frontend cycles idle [40.80%] 1,025,280,350 stalled-cycles-backend # 18.67% backend cycles idle [40.34%] 8,644,643,951 instructions # 1.57 insns per cycle # 0.19 stalled cycles per insn [50.89%] 1,492,911,665 branches # 926.860 M/sec [50.69%] 53,471,580 branch-misses # 3.58% of all branches [51.21%] 1,938,889,736 L1-dcache-loads # 1203.741 M/sec [49.68%] 154,380,395 L1-dcache-load-misses # 7.96% of all L1-dcache hits [49.66%] 0 LLC-loads # 0.000 K/sec [39.27%] 0 LLC-load-misses # 0.00% of all LL-cache hits [39.61%] 1.614165346 seconds time elapsed This includes additional counters for Level 1 data cache events, and last level cache (LLC) events.这包括用于一级数据缓存事件和最后一级缓存(LLC)事件的额外计数器。 Specific CountersHardware cache event counters, seen in perf list, can be instrumented. Eg:perf list 可以像下面这样查看硬件缓存事件 12345678910111213141516171819# perf list | grep L1-dcache L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event] L1-dcache-store-misses [Hardware cache event] L1-dcache-prefetches [Hardware cache event] L1-dcache-prefetch-misses [Hardware cache event]# perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores gzip file1 Performance counter stats for 'gzip file1': 1,947,551,657 L1-dcache-loads 153,829,652 L1-dcache-misses # 7.90% of all L1-dcache hits 1,171,475,286 L1-dcache-stores 1.538038091 seconds time elapsed The percentage printed is a convenient calculation that perf_events has included, based on the counters I specified. If you include the “cycles” and “instructions” counters, it will include an IPC calculation in the output.根据我指定的计数器，perf_events包含了打印的百分比，这是一个很方便的计算。如果包含“cycle”和“instructions”计数器，那么它将在输出中包含IPC计算。 These hardware events that can be measured are often specific to the processor model. Many may not be available from within a virtualized environment.这些可以测量的硬件事件通常是特定于处理器模型的。许多可能无法从虚拟化环境中获得。 Raw CountersThe Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 3B: System Programming Guide, Part 2 and the BIOS and Kernel Developer’s Guide (BKDG) For AMD Family 10h Processors are full of interesting counters, but most cannot be found in perf list. If you find one you want to instrument, you can specify it as a raw event with the format: rUUEE, where UU == umask, and EE == event number. Here’s an example where I’ve added a couple of raw counters:Intel 64和cia -32架构软件开发人员手册卷3B:系统编程指南，第2部分和AMD家族10h处理器的BIOS和内核开发人员指南(BKDG)充满了有趣的计数器，但大部分不能在perf列表中找到。如果您找到一个想要检测的事件，可以将其指定为原始事件，格式为:rUUEE，其中UU == umask, EE ==事件编号。这里有一个例子，我已经添加了一对原始计数器: 12345678910# perf stat -e cycles,instructions,r80a2,r2b1 gzip file1 Performance counter stats for 'gzip file1': 5,586,963,328 cycles # 0.000 GHz 8,608,237,932 instructions # 1.54 insns per cycle 9,448,159 raw 0x80a2 11,855,777,803 raw 0x2b1 1.588618969 seconds time elapsed If I did this right, then r80a2 has instrumented RESOURCE_STALLS.OTHER, and r2b1 has instrumented UOPS_DISPATCHED.CORE: the number of uops dispatched each cycle. It’s easy to mess this up, and you’ll want to double check that you are on the right page of the manual for your processor.如果我做对了，那么r80a2已经检测了resource_stall。r2b1已经检测了uops_dispatch。核心:每个周期分派的uops数量。这很容易搞砸，您需要再次检查是否在处理程序手册的正确页面。 If you do find an awesome raw counter, please suggest it be added as an alias in perf_events, so we all can find it in perf list.如果你发现一个非常棒的原始计数器，请建议将它作为别名添加到perf_events中，这样我们就可以在perf列表中找到它。 Other OptionsThe perf subcommands, especially perf stat, have an extensive option set which can be listed using “-h”. I’ve included the full output for perf stat here from version 3.9.3, not as a reference, but as an illustration of the interface:perf子命令，特别是perf stat，有一个广泛的选项集，可以使用“-h”列出。这里我包含了perf stat 3.9.3版本的完整输出，不是作为参考，而是作为界面的说明: 1234567891011121314151617181920212223242526272829303132# perf stat -h usage: perf stat [&lt;options&gt;] [&lt;command&gt;] -e, --event &lt;event&gt; event selector. use 'perf list' to list available events --filter &lt;filter&gt; event filter -i, --no-inherit child tasks do not inherit counters -p, --pid &lt;pid&gt; stat events on existing process id -t, --tid &lt;tid&gt; stat events on existing thread id -a, --all-cpus system-wide collection from all CPUs -g, --group put the counters into a counter group -c, --scale scale/normalize counters -v, --verbose be more verbose (show counter open errors, etc) -r, --repeat &lt;n&gt; repeat command and print average + stddev (max: 100) -n, --null null run - dont start any counters -d, --detailed detailed run - start a lot of events -S, --sync call sync() before starting a run -B, --big-num print large numbers with thousands' separators -C, --cpu &lt;cpu&gt; list of cpus to monitor in system-wide -A, --no-aggr disable CPU count aggregation -x, --field-separator &lt;separator&gt; print counts with custom separator -G, --cgroup &lt;name&gt; monitor event in cgroup name only -o, --output &lt;file&gt; output file name --append append to the output file --log-fd &lt;n&gt; log output to fd, instead of stderr --pre &lt;command&gt; command to run prior to the measured command --post &lt;command&gt; command to run after to the measured command -I, --interval-print &lt;n&gt; print counts at regular interval in ms (&gt;= 100) --aggr-socket aggregate counts per processor socket Options such as –repeat, –sync, –pre, and –post can be quite useful when doing automated testing or micro-benchmarking.在进行自动化测试或微基准测试时，–repeat, –sync, –pre, 和 –post等选项非常有用。 6.2. Timed Profilingperf_events can profile CPU usage based on sampling the instruction pointer or stack trace at a fixed interval (timed profiling).perf_events可以基于对指令指针或堆栈跟踪的固定间隔采样(定时分析)来分析CPU使用情况。 Sampling CPU stacks at 99 Hertz (-F 99), for the entire system (-a, for all CPUs), with stack traces (-g, for call graphs), for 10 seconds:以99赫兹(-F 99)，对整个系统(-a，对所有CPU)采样CPU堆栈，采样10秒，并记录堆栈(-g，调用图): 12345# perf record -F 99 -a -g -- sleep 30[ perf record: Woken up 9 times to write data ][ perf record: Captured and wrote 3.135 MB perf.data (~136971 samples) ]# ls -lh perf.data-rw------- 1 root root 3.2M Jan 26 07:26 perf.data The choice of 99 Hertz, instead of 100 Hertz, is to avoid accidentally sampling in lockstep with some periodic activity, which would produce skewed results. This is also coarse: you may want to increase that to higher rates (eg, up to 997 Hertz) for finer resolution, especially if you are sampling short bursts of activity and you’d still like enough resolution to be useful. Bear in mind that higher frequencies means higher overhead.选择99赫兹而不是100赫兹，是为了避免偶然地与某些周期性活动同步采样，以免产生扭曲的结果。这也是粗糙的:你可能想要增加到更高的速率(例如，高达997赫兹)以获得更好的分辨率，特别是当你采样活动的短脉冲时，你仍然希望有足够的分辨率。请记住，更高的频率意味着更高的开销。 The perf.data file can be processed in a variety of ways. On recent versions, the perf report command launches an ncurses navigator for call graph inspection. Older versions of perf (or if you use –stdio in the new version) print the call graph as a tree, annotated with percentages:perf.data 文件可以用多种方法处理。在最近的版本中，perf report命令启动ncurses导航器来检查调用图。旧版本的perf(或者如果你在新版本中使用–stdio)将调用图打印成树状，并标注百分比: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# perf report --stdio# ========# captured on: Mon Jan 26 07:26:40 2014# hostname : dev2# os release : 3.8.6-ubuntu-12-opt# perf version : 3.8.6# arch : x86_64# nrcpus online : 8# nrcpus avail : 8# cpudesc : Intel(R) Xeon(R) CPU X5675 @ 3.07GHz# cpuid : GenuineIntel,6,44,2# total memory : 8182008 kB# cmdline : /usr/bin/perf record -F 99 -a -g -- sleep 30 # event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = ...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, breakpoint = 5# ========## Samples: 22K of event 'cpu-clock'# Event count (approx.): 22751## Overhead Command Shared Object Symbol# ........ ....... ................. ...............................# 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--96.67%-- extract_buf | extract_entropy_user | urandom_read | vfs_read | sys_read | system_call_fastpath | read | |--1.69%-- account | | | |--99.72%-- extract_entropy_user | | urandom_read | | vfs_read | | sys_read | | system_call_fastpath | | read | --0.28%-- [...] | |--1.60%-- mix_pool_bytes.constprop.17[...] This tree starts with the on-CPU functions and works back through the ancestry. This approach is called a “callee based call graph”. This can be flipped by using -G for an “inverted call graph”, or by using the “caller” option to -g/–call-graph, instead of the “callee” default.这个树从on-CPU函数开始，并通过祖先开始工作。这种方法称为“基于调用者的调用图”。这可以通过使用-G来反转调用关系图，对于 -g/–call-graph 记录的调用图，也可以使用 caller 来代替 默认值callee，以反转调用关系图。默认是用 -g 选项记录的是“基于调用者的调用图”，使用 -g caller 或者 –children 将反转调用关系图。 The hottest (most frequent) stack trace in this perf call graph occurred in 90.99% of samples, which is the product of the overhead percentage and top stack leaf (94.12% x 96.67%, which are relative rates). perf report can also be run with “-g graph” to show absolute overhead rates, in which case “90.99%” is directly displayed on the stack leaf: 上面的perf调用图显示采样中最热(最频繁)的堆栈跟踪发生频率是 90.99%，它是Overhead列的百分比和顶部堆栈叶(94.12% x 96.67%，它们是相对比率)的乘积。perf报告也可以用“-g graph”运行，直接显示绝对的开销占比。此时将像下面这样，“90.99%”直接显示在堆栈叶上: 123456 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--90.99%-- extract_buf[...] If user-level stacks look incomplete, you can try perf record with “–call-graph dwarf” as a different technique to unwind them. See the Stacks section.如果用户级堆栈看起来不完整，您可以尝试使用“–call-graph dwarf”作为另一种技术来展开它们。请参阅书库部分。 The output from perf report can be many pages long, which can become cumbersome to read. Try generating Flame Graphs from the same data.perf报告的输出可能有很多页长，读起来可能很麻烦。可以尝试生成火焰图来查看。 6.3. Event ProfilingApart from sampling at a timed interval, taking samples triggered by CPU hardware counters is another form of CPU profiling, which can be used to shed more light on cache misses, memory stall cycles, and other low-level processor events. The available events can be found using perf list: 除了按时间间隔采样外，由CPU硬件计数器触发的采样是CPU分析的另一种形式，它可以用来更清楚地了解缓存丢失、内存停滞周期和其他低级处理器事件。可用事件可以找到使用perf列表: 12345678910111213141516# perf list | grep Hardware cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event] L1-dcache-store-misses [Hardware cache event][...] For many of these, gathering a stack on every occurrence would induce far too much overhead, and would slow down the system and change the performance characteristics of the target. It’s usually sufficient to only instrument a small fraction of their occurrences, rather than all of them. This can be done by specifying a threshold for triggering event collection, using “-c” and a count. 对于其中的许多情况，在每次出现时都收集堆栈会导致过多的开销，并会降低系统速度并改变目标的性能特征。通常，只测量它们出现的一小部分，而不是全部，就足够了。这可以通过使用“-c” 指定触发事件收集的阈值来实现。 For example, the following one-liner instruments Level 1 data cache load misses, collecting a stack trace for one in every 10,000 occurrences: 例如，下面的一行程序统计 1级数据缓存加载失败次数，每10000次失败收集一次堆栈跟踪: 1# perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5 The mechanics of “-c count” are implemented by the processor, which only interrupts the kernel when the threshold has been reached.“-c count”机制是由处理器实现的，它只在达到阈值时中断内核。 See the earlier Raw Counters section for an example of specifying a custom counter, and the next section about skew.有关指定自定义计数器的示例，请参阅前面的Raw计数器部分，和下一节。 Skew and PEBSThere’s a problem with event profiling that you don’t really encounter with CPU profiling (timed sampling). With timed sampling, it doesn’t matter if there was a small sub-microsecond delay between the interrupt and reading the instruction pointer (IP). Some CPU profilers introduce this jitter on purpose, as another way to avoid lockstep sampling. But for event profiling, it does matter: if you’re trying to capture the IP on some PMC event, and there’s a delay between the PMC overflow and capturing the IP, then the IP will point to the wrong address. This is skew. Another contributing problem is that micro-ops are processed in parallel and out-of-order, while the instruction pointer points to the resumption instruction, not the instruction that caused the event. I’ve talked about this before.事件分析存在一个CPU分析不会遇到的问题(定时采样)。对于定时采样，在中断和读取指令指针(IP)之间是否有一个亚微秒的延迟并不重要。一些CPU分析器故意引入这种抖动，作为避免同步采样的另一种方法。但是对于事件分析来说，这确实很重要:如果您试图捕获某个PMC事件上的IP，并且在PMC溢出和捕获IP之间存在延迟，那么IP将指向错误的地址。这是倾斜。另一个问题是微操作是并行和无序处理的，而指令指针指向的是恢复指令，而不是导致事件的指令。我之前讲过这个。· The solution is “precise sampling”, which on Intel is PEBS (Precise Event-Based Sampling), and on AMD it is IBS (Instruction-Based Sampling). These use CPU hardware support to capture the real state of the CPU at the time of the event. perf can use precise sampling by adding a :p modifier to the PMC event name, eg, “-e instructions:p”. The more p’s, the more accurate. Here are the docs from tools/perf/Documentation/perf-list.txt:解决方案是“精确采样”，在英特尔上是PEBS(基于事件的精确采样)，在AMD上是IBS(基于指令的采样)。它们使用CPU硬件支持来捕获事件发生时CPU的真实状态。perf可以通过在PMC事件名称中添加一个:p修饰符来使用精确的采样，例如，“-e instructions:p”。p越多，越准确。以下是tools/perf/Documentation/perf-list.txt提供的文档: 12345678The 'p' modifier can be used for specifying how precise the instructionaddress should be. The 'p' modifier can be specified multiple times:'p'修饰符可以用来指定指令地址的精确程度。“p”修饰符可以被指定多次: 0 - SAMPLE_IP can have arbitrary skid SAMPLE_IP可以任意滑动 1 - SAMPLE_IP must have constant skid SAMPLE_IP必须有持续的滑动 2 - SAMPLE_IP requested to have 0 skid SAMPLE_IP请求没有滑动 3 - SAMPLE_IP must have 0 skid SAMPLE_IP必须是0滑块 In some cases, perf will default to using precise sampling without you needing to specify it. Run “perf record -vv …” to see the value of “precise_ip”. Also note that only some PMCs support PEBS.在某些情况下，perf将默认使用精确采样，而不需要您指定它。运行”perf record -vv…”可以看到”precise_ip”的值。还要注意，只有一些pmc支持PEBS。 If PEBS isn’t working at all for you, check dmesg:如果PEBS根本不适合你，查看dmesg: 123# dmesg | grep -i pebs[ 0.387014] Performance Events: PEBS fmt1+, SandyBridge events, 16-deep LBR, full-width counters, Intel PMU driver.[ 0.387034] core: PEBS disabled due to CPU errata, please upgrade microcode The fix (on Intel): 12345678910111213# apt-get install -y intel-microcode[...]intel-microcode: microcode will be updated at next bootProcessing triggers for initramfs-tools (0.125ubuntu5) ...update-initramfs: Generating /boot/initrd.img-4.8.0-41-generic# reboot(system reboots)# dmesg | grep -i pebs[ 0.386596] Performance Events: PEBS fmt1+, SandyBridge events, 16-deep LBR, full-width counters, Intel PMU driver.# XXX: Need to cover more PEBS problems and other caveats.需要覆盖更多的PEBS问题和其他警告。 6.4. Static Kernel TracingThe following examples demonstrate static tracing: the instrumentation of tracepoints and other static events.下面的示例演示了如何进行静态跟踪: 跟踪点和其他静态事件。 Counting SyscallsThe following simple one-liner counts system calls for the executed command, and prints a summary (of non-zero counts):下面是一个统计系统调用并打印摘要(非零计数)的简单命令: 123456789101112131415161718192021222324252627# perf stat -e 'syscalls:sys_enter_*' gzip file1 2&gt;&amp;1 | awk '$1 != 0' Performance counter stats for 'gzip file1': 1 syscalls:sys_enter_utimensat 1 syscalls:sys_enter_unlink 5 syscalls:sys_enter_newfstat 1,603 syscalls:sys_enter_read 3,201 syscalls:sys_enter_write 5 syscalls:sys_enter_access 1 syscalls:sys_enter_fchmod 1 syscalls:sys_enter_fchown 6 syscalls:sys_enter_open 9 syscalls:sys_enter_close 8 syscalls:sys_enter_mprotect 1 syscalls:sys_enter_brk 1 syscalls:sys_enter_munmap 1 syscalls:sys_enter_set_robust_list 1 syscalls:sys_enter_futex 1 syscalls:sys_enter_getrlimit 5 syscalls:sys_enter_rt_sigprocmask 14 syscalls:sys_enter_rt_sigaction 1 syscalls:sys_enter_exit_group 1 syscalls:sys_enter_set_tid_address 14 syscalls:sys_enter_mmap 1.543990940 seconds time elapsed In this case, a gzip command was analyzed. The report shows that there were 3,201 write() syscalls, and half that number of read() syscalls. Many of the other syscalls will be due to process and library initialization.在本例中，分析了gzip命令。报告显示有3201个write()系统调用，而read()系统调用只有这个数量的一半。许多其他系统崩溃都是由于进程和库的初始化。 A similar report can be seen using strace -c, the system call tracer, however it may induce much higher overhead than perf, as perf buffers data in-kernel.使用系统调用跟踪程序strace -c可以看到类似的报告，但是它可能导致比perf高得多的开销，因为perf在内核中缓冲数据。 perf vs straceTo explain the difference a little further: the current implementation of strace uses ptrace(2) to attach to the target process and stop it during system calls, like a debugger. This is violent, and can cause serious overhead. To demonstrate this, the following syscall-heavy program was run by itself, with perf, and with strace. I’ve only included the line of output that shows its performance:为了进一步解释这种差异:strace的当前实现使用ptrace(2)附加到目标进程并在系统调用期间停止它，就像调试器一样。这是暴力的，并可能导致严重的开销。为了演示这一点，下面使用perf和strace单独运行具有大量系统调用的程序。我只包含了显示其性能的输出行: 12345678# dd if=/dev/zero of=/dev/null bs=512 count=10000k5242880000 bytes (5.2 GB) copied, 3.53031 s, 1.5 GB/s# perf stat -e 'syscalls:sys_enter_*' dd if=/dev/zero of=/dev/null bs=512 count=10000k5242880000 bytes (5.2 GB) copied, 9.14225 s, 573 MB/s# strace -c dd if=/dev/zero of=/dev/null bs=512 count=10000k5242880000 bytes (5.2 GB) copied, 218.915 s, 23.9 MB/s With perf, the program ran 2.5x slower. But with strace, it ran 62x slower. That’s likely to be a worst-case result: if syscalls are not so frequent, the difference between the tools will not be as great.使用perf，程序运行速度慢了2.5倍。但使用strace时，它的运行速度慢了62倍。这可能是最糟糕的结果:如果系统调用不那么频繁，那么工具之间的差异就不会那么大。 Recent version of perf have included a trace subcommand, to provide some similar functionality to strace, but with much lower overhead.perf的最新版本包含了一个跟踪子命令，以提供一些与strace类似的功能，但开销要低得多。 New ProcessesTracing new processes triggered by a “man ls”:下面跟踪man ls命令创建的新进程 1234567891011121314151617# perf record -e sched:sched_process_exec -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ]# perf report -n --sort comm --stdio[...]# Overhead Samples Command# ........ ............ .......# 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff Nine different commands were executed, each once. I used -n to print the “Samples” column, and “–sort comm” to customize the remaining columns.可以看到执行了9个不同的命令，每个命令执行一次。我使用-n来打印“Samples”列，使用—sort comm来定制其余的列。 This works by tracing sched:sched_process_exec, when a process runs exec() to execute a different binary. This is often how new processes are created, but not always. An application may fork() to create a pool of worker processes, but not exec() a different binary. An application may also reexec: call exec() again, on itself, usually to clean up its address space. In that case, it’s will be seen by this exec tracepoint, but it’s not a new process.通过跟踪sched:sched_process_exec，可以跟踪进程通过 exec() 执行的不同的二进制文件。新流程通常是这样创建的，但并不总是这样。应用程序可以使用fork()创建工作进程池，而不是通过 exec() 运行一个二进制文件。应用程序也可以重新执行:在自身上再次调用exec()，通常是为了清理其地址空间。在这种情况下，它将被这个exec跟踪点看到，但它不是一个新的进程。 The sched:sched_process_fork tracepoint can be traced to only catch new processes, created via fork(). The downside is that the process identified is the parent, not the new target, as the new process has yet to exec() it’s final program.sched:sched_process_fork跟踪点可以被跟踪到仅捕获通过fork()创建的新进程。缺点是所标识的进程是父进程，而不是新目标，因为新进程还没有执行exec()它的最终程序。 Outbound ConnectionsThere can be times when it’s useful to double check what network connections are initiated by a server, from which processes, and why. You might be surprised. These connections can be important to understand, as they can be a source of latency.有时候，仔细检查服务器启动了哪些网络连接、从哪些进程启动以及为什么启动是很有用的。你可能会感到惊讶。理解这些连接很重要，因为它们可能是延迟的来源。 For this example, I have a completely idle ubuntu server, and while tracing I’ll login to it using ssh. I’m going to trace outbound connections via the connect() syscall. Given that I’m performing an inbound connection over SSH, will there be any outbound connections at all?对于本例，我有一个完全空闲的ubuntu服务器，在跟踪时，我将使用ssh登录到它。我将通过connect()系统调用跟踪出站连接。假设我正在通过SSH执行入站连接，那么还会有出站连接吗? 1234567891011121314151617181920212223242526272829303132# perf record -e syscalls:sys_enter_connect -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.057 MB perf.data (~2489 samples) ]# perf report --stdio# ========# captured on: Tue Jan 28 10:53:38 2014# hostname : ubuntu# os release : 3.5.0-23-generic# perf version : 3.5.7.2# arch : x86_64# nrcpus online : 2# nrcpus avail : 2# cpudesc : Intel(R) Core(TM) i7-3820QM CPU @ 2.70GHz# cpuid : GenuineIntel,6,58,9# total memory : 1011932 kB# cmdline : /usr/bin/perf_3.5.0-23 record -e syscalls:sys_enter_connect -a # event : name = syscalls:sys_enter_connect, type = 2, config = 0x38b, ...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# ========## Samples: 21 of event 'syscalls:sys_enter_connect'# Event count (approx.): 21## Overhead Command Shared Object Symbol# ........ ....... .................. ...........................# 52.38% sshd libc-2.15.so [.] __GI___connect_internal 19.05% groups libc-2.15.so [.] __GI___connect_internal 9.52% sshd libpthread-2.15.so [.] __connect_internal 9.52% mesg libc-2.15.so [.] __GI___connect_internal 9.52% bash libc-2.15.so [.] __GI___connect_internal The report shows that sshd, groups, mesg, and bash are all performing connect() syscalls. Ring a bell?报告显示，sshd, groups, mesg, 和 bash都在执行connect()系统调用。? The stack traces that led to the connect() can explain why:导致connect()的堆栈跟踪可以解释为什么: 12345678910111213141516171819202122232425262728293031323334353637383940414243# perf record -e syscalls:sys_enter_connect -ag^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.057 MB perf.data (~2499 samples) ]# perf report --stdio[...] 55.00% sshd libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--27.27%-- add_one_listen_addr.isra.0 | |--27.27%-- __nscd_get_mapping | __nscd_get_map_ref | |--27.27%-- __nscd_open_socket --18.18%-- [...] 20.00% groups libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--50.00%-- __nscd_get_mapping | __nscd_get_map_ref | --50.00%-- __nscd_open_socket 10.00% mesg libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--50.00%-- __nscd_get_mapping | __nscd_get_map_ref | --50.00%-- __nscd_open_socket 10.00% bash libc-2.15.so [.] __GI___connect_internal | --- __GI___connect_internal | |--50.00%-- __nscd_get_mapping | __nscd_get_map_ref | --50.00%-- __nscd_open_socket 5.00% sshd libpthread-2.15.so [.] __connect_internal | --- __connect_internal Ah, these are nscd calls: the name service cache daemon. If you see hexadecimal numbers and not function names, you will need to install debug info: see the earlier section on Symbols. These nscd calls are likely triggered by calling getaddrinfo(), which server software may be using to resolve IP addresses for logging, or for matching hostnames in config files. Browsing the stack traces should identify why.啊，这些是nscd调用:名称服务缓存守护进程。如果您看到的是十六进制数字而不是函数名，则需要安装调试信息:请参阅前面关于符号的部分。这些nscd调用可能是通过调用getaddrinfo()触发的，服务器软件可能使用该函数来解析用于日志记录的IP地址，或者用于匹配配置文件中的主机名。浏览堆栈跟踪应该确定原因。 For sshd, this was called via add_one_listen_addr(): a name that was only visible after adding the openssh-server-dbgsym package. Unfortunately, the stack trace doesn’t continue after add_one_listen_add(). I can browse the OpenSSH code to figure out the reasons we’re calling into add_one_listen_add(), or, I can get the stack traces to work. See the earlier section on Stack Traces.对于sshd，这是通过add_one_listen_addr()调用的:这个名称只有在添加openssh-server-dbgsym包之后才可见。不幸的是，在add_one_listen_add()之后，堆栈跟踪不会继续。我可以浏览OpenSSH代码来找出调用add_one_listen_add()的原因，或者，我可以让堆栈跟踪工作。请参阅前面关于堆栈跟踪的部分。 I took a quick look at the OpenSSH code, and it looks like this code-path is due to parsing ListenAddress from the sshd_config file, which can contain either an IP address or a hostname.我快速查看了OpenSSH代码，该代码路径似乎是由于从sshd_config文件解析ListenAddress而产生的，该文件可以包含IP地址或主机名。 Socket BuffersTracing the consumption of socket buffers, and the stack traces, is one way to identify what is leading to socket or network I/O.跟踪套接字缓冲区的消耗和堆栈跟踪是识别导致套接字或网络I/O的原因的一种方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# perf record -e 'skb:consume_skb' -ag^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.065 MB perf.data (~2851 samples) ]# perf report[...] 74.42% swapper [kernel.kallsyms] [k] consume_skb | --- consume_skb arp_process arp_rcv __netif_receive_skb_core __netif_receive_skb netif_receive_skb virtnet_poll net_rx_action __do_softirq irq_exit do_IRQ ret_from_intr default_idle cpu_idle start_secondary 25.58% sshd [kernel.kallsyms] [k] consume_skb | --- consume_skb dev_kfree_skb_any free_old_xmit_skbs.isra.24 start_xmit dev_hard_start_xmit sch_direct_xmit dev_queue_xmit ip_finish_output ip_output ip_local_out ip_queue_xmit tcp_transmit_skb tcp_write_xmit __tcp_push_pending_frames tcp_sendmsg inet_sendmsg sock_aio_write do_sync_write vfs_write sys_write system_call_fastpath __write_nocancel The swapper stack shows the network receive path, triggered by an interrupt. The sshd path shows writes.交换器堆栈显示由中断触发的网络接收路径。sshd路径显示写操作。 6.5. Static User TracingSupport was added in later 4.x series kernels. The following demonstrates Linux 4.10 (with an additional patchset), and tracing the Node.js USDT probes:在4.x 的内核中，添加了用户态静态追踪机制。下面演示了Linux 4.10(附加了一个补丁集)，如何跟踪Node.js 的USDT探针: 1234567891011121314151617# perf buildid-cache --add `which node`# perf list | grep sdt_node sdt_node:gc__done [SDT event] sdt_node:gc__start [SDT event] sdt_node:http__client__request [SDT event] sdt_node:http__client__response [SDT event] sdt_node:http__server__request [SDT event] sdt_node:http__server__response [SDT event] sdt_node:net__server__connection [SDT event] sdt_node:net__stream__end [SDT event]# perf record -e sdt_node:http__server__request -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.446 MB perf.data (3 samples) ]# perf script node 7646 [002] 361.012364: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.204718: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.363043: sdt_node:http__server__request: (dc2e69) XXX fill me in, including how to use arguments.XXX告诉我，包括如何使用参数。 If you are on an older kernel, say, Linux 4.4-4.9, you can probably get these to work with adjustments (I’ve even hacked them up with ftrace for older kernels), but since they have been in development, I haven’t seen documentation outside of lkml, so you’ll need to figure it out. (On this kernel range, you might find more documentation for tracing these with bcc/eBPF, including using the trace.py tool.)如果您使用的是一个较老的内核，比如Linux 4.4-4.9，你可以做相应的调整来使用用户态追踪(我甚至用ftrace对较老的内核进行了分解)，但是由于它们已经在开发中，我还没有看到lkml之外的文档，所以您需要弄清楚它。(在这个内核范围内，您可能会找到更多使用bcc/eBPF跟踪这些文件的文档，包括使用trace.py工具。) 6.6. Dynamic TracingFor kernel analysis, I’m using CONFIG_KPROBES=y and CONFIG_KPROBE_EVENTS=y, to enable kernel dynamic tracing, and CONFIG_FRAME_POINTER=y, for frame pointer-based kernel stacks. For user-level analysis, CONFIG_UPROBES=y and CONFIG_UPROBE_EVENTS=y, for user-level dynamic tracing.对于内核分析，使用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y来启用内核动态跟踪，对于基于框架指针的内核堆栈，使用CONFIG_FRAME_POINTER=y。对于用户级分析，CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y用于启用用户级动态跟踪。 Kernel: tcp_sendmsg()This example shows instrumenting the kernel tcp_sendmsg() function on the Linux 3.9.3 kernel:下面的例子展示了在Linux 3.9.3内核上检测内核tcp_sendmsg()函数: 12345678# perf probe --add tcp_sendmsgFailed to find path of kernel module.Added new event: probe:tcp_sendmsg (on tcp_sendmsg)You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1 This adds a new tracepoint event. It suggests using the -R option, to collect raw sample records, which is already the default for tracepoints. Tracing this event for 5 seconds, recording stack traces:这将添加一个新的跟踪点事件。它建议使用-R选项来收集原始示例记录，这已经是跟踪点的默认值。-R 用于设置跟踪事件5秒，并记录堆栈跟踪: 123# perf record -e probe:tcp_sendmsg -a -g -- sleep 5[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.228 MB perf.data (~9974 samples) ] And the report:下面是输出报告 12345678910111213141516171819202122232425262728293031323334353637# perf report --stdio# ========# captured on: Fri Jan 31 20:10:14 2014# hostname : pgbackup# os release : 3.9.3-ubuntu-12-opt# perf version : 3.9.3# arch : x86_64# nrcpus online : 8# nrcpus avail : 8# cpudesc : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz# cpuid : GenuineIntel,6,45,7# total memory : 8179104 kB# cmdline : /lib/modules/3.9.3/build/tools/perf/perf record -e probe:tcp_sendmsg -a -g -- sleep 5 # event : name = probe:tcp_sendmsg, type = 2, config = 0x3b2, config1 = 0x0, config2 = 0x0, ...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, tracepoint = 2, breakpoint = 5# ========## Samples: 12 of event 'probe:tcp_sendmsg'# Event count (approx.): 12## Overhead Command Shared Object Symbol# ........ ....... ................. ...............# 100.00% sshd [kernel.kallsyms] [k] tcp_sendmsg | --- tcp_sendmsg sock_aio_write do_sync_write vfs_write sys_write system_call_fastpath __write_nocancel | |--8.33%-- 0x50f00000001b810 --91.67%-- [...] This shows the path from the write() system call to tcp_sendmsg().这显示了从write()系统调用到tcp_sendmsg()的路径。 You can delete these dynamic tracepoints if you want after use, using perf probe –del.如果需要，可以在使用后删除这些动态跟踪点，使用perf probe –del。 Kernel: tcp_sendmsg() with sizeIf your kernel has debuginfo (CONFIG_DEBUG_INFO=y), you can fish out kernel variables from functions. This is a simple example of examining a size_t (integer), on Linux 3.13.1.如果内核有debuginfo (CONFIG_DEBUG_INFO=y)，那么可以从函数中提取内核变量。这是在Linux 3.13.1上检查size_t(整数)的一个简单示例。 Listing variables available for tcp_sendmsg():列出tcp_sendmsg()可用的变量: 1234567# perf probe -V tcp_sendmsgAvailable variables at tcp_sendmsg @&lt;tcp_sendmsg+0&gt; size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk Creating a probe for tcp_sendmsg() with the “size” variable:使用变量“size”为tcp_sendmsg()创建一个探针: 1234567# perf probe --add 'tcp_sendmsg size'Added new event: probe:tcp_sendmsg (on tcp_sendmsg with size)You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1 Tracing this probe:跟踪此探针 1234567891011121314151617181920212223242526272829303132333435# perf record -e probe:tcp_sendmsg -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.052 MB perf.data (~2252 samples) ]# perf script# ========# captured on: Fri Jan 31 23:49:55 2014# hostname : dev1# os release : 3.13.1-ubuntu-12-opt# perf version : 3.13.1# arch : x86_64# nrcpus online : 2# nrcpus avail : 2# cpudesc : Intel(R) Xeon(R) CPU E5645 @ 2.40GHz# cpuid : GenuineIntel,6,44,2# total memory : 1796024 kB# cmdline : /usr/bin/perf record -e probe:tcp_sendmsg -a # event : name = probe:tcp_sendmsg, type = 2, config = 0x1dd, config1 = 0x0, config2 = ...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, tracepoint = 2, breakpoint = 5# ========# sshd 1301 [001] 502.424719: probe:tcp_sendmsg: (ffffffff81505d80) size=b0 sshd 1301 [001] 502.424814: probe:tcp_sendmsg: (ffffffff81505d80) size=40 sshd 2371 [000] 502.952590: probe:tcp_sendmsg: (ffffffff81505d80) size=27 sshd 2372 [000] 503.025023: probe:tcp_sendmsg: (ffffffff81505d80) size=3c0 sshd 2372 [001] 503.203776: probe:tcp_sendmsg: (ffffffff81505d80) size=98 sshd 2372 [001] 503.281312: probe:tcp_sendmsg: (ffffffff81505d80) size=2d0 sshd 2372 [001] 503.461358: probe:tcp_sendmsg: (ffffffff81505d80) size=30 sshd 2372 [001] 503.670239: probe:tcp_sendmsg: (ffffffff81505d80) size=40 sshd 2372 [001] 503.742565: probe:tcp_sendmsg: (ffffffff81505d80) size=140 sshd 2372 [001] 503.822005: probe:tcp_sendmsg: (ffffffff81505d80) size=20 sshd 2371 [000] 504.118728: probe:tcp_sendmsg: (ffffffff81505d80) size=30 sshd 2371 [000] 504.192575: probe:tcp_sendmsg: (ffffffff81505d80) size=70[...] The size is shown as hexadecimal.大小显示为十六进制。 Kernel: tcp_sendmsg() line number and local variable内核:将显示 tcp_sendmsg()行号和本地变量值 With debuginfo, perf_events can create tracepoints for lines within kernel functions. Listing available line probes for tcp_sendmsg():使用debuginfo, perf_events可以为内核函数中的行创建跟踪点。列出tcp_sendmsg()可用的行探测: 123456789101112131415161718192021222324252627# perf probe -L tcp_sendmsg&lt;tcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0&gt; 0 int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg, size_t size) 2 &#123; struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; 6 int iovlen, flags, err, copied = 0; 7 int mss_now = 0, size_goal, copied_syn = 0, offset = 0; bool sg; long timeo;[...] 79 while (seglen &gt; 0) &#123; int copy = 0; 81 int max = size_goal; skb = tcp_write_queue_tail(sk); 84 if (tcp_send_head(sk)) &#123; 85 if (skb-&gt;ip_summed == CHECKSUM_NONE) max = mss_now; 87 copy = max - skb-&gt;len; &#125; 90 if (copy &lt;= 0) &#123; new_segment:[...] This is Linux 3.14.5; your kernel version may look different. Lets check what variables are available on line 81:这是Linux 3.14.5;您的内核版本可能看起来不同。让我们检查在第81行有哪些变量可用: 123456789101112131415# perf probe -V tcp_sendmsg:81Available variables at tcp_sendmsg:81 @&lt;tcp_sendmsg+537&gt; bool sg int copied int copied_syn int flags int mss_now int offset int size_goal long int timeo size_t seglen struct iovec* iov struct sock* sk unsigned char* from Now lets trace line 81, with the seglen variable that is checked in the loop:现在让我们跟踪第81行，并使用循环中的seglen变量: 12345678910111213141516171819# perf probe --add 'tcp_sendmsg:81 seglen'Added new event: probe:tcp_sendmsg (on tcp_sendmsg:81 with seglen)You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1# perf record -e probe:tcp_sendmsg -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.188 MB perf.data (~8200 samples) ]# perf script sshd 4652 [001] 2082360.931086: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x80 app_plugin.pl 2400 [001] 2082360.970489: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x20 postgres 2422 [000] 2082360.970703: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x52 app_plugin.pl 2400 [000] 2082360.970890: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x7b postgres 2422 [001] 2082360.971099: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0xb app_plugin.pl 2400 [000] 2082360.971140: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x55[...] This is pretty amazing. Remember that you can also include in-kernel filtering using –filter, to match only the data you want.这是相当惊人的。请记住，还可以使用–filter包括内核内筛选，以便只匹配所需的数据。 User: malloc()While this is an interesting example, I want to say right off the bat that malloc() calls are very frequent, so you will need to consider the overheads of tracing calls like this.虽然这是一个有趣的示例，但我想马上说明malloc()调用非常频繁，因此需要考虑跟踪这样的调用的开销。 Adding a libc malloc() probe:添加一个 libc malloc 探针 1234567# perf probe -x /lib/x86_64-linux-gnu/libc-2.15.so --add mallocAdded new event: probe_libc:malloc (on 0x82f20)You can now use it in all perf tools, such as: perf record -e probe_libc:malloc -aR sleep 1 Tracing it system-wide: 123# perf record -e probe_libc:malloc -a^C[ perf record: Woken up 12 times to write data ][ perf record: Captured and wrote 3.522 MB perf.data (~153866 samples) ] The report:12345678910111213141516171819202122232425262728293031323334353637383940414243# perf report -n[...]# Samples: 45K of event 'probe_libc:malloc'# Event count (approx.): 45158## Overhead Samples Command Shared Object Symbol# ........ ............ ............... ............. ..........# 42.72% 19292 apt-config libc-2.15.so [.] malloc 19.71% 8902 grep libc-2.15.so [.] malloc 7.88% 3557 sshd libc-2.15.so [.] malloc 6.25% 2824 sed libc-2.15.so [.] malloc 6.06% 2738 which libc-2.15.so [.] malloc 4.12% 1862 update-motd-upd libc-2.15.so [.] malloc 3.72% 1680 stat libc-2.15.so [.] malloc 1.68% 758 login libc-2.15.so [.] malloc 1.21% 546 run-parts libc-2.15.so [.] malloc 1.21% 545 ls libc-2.15.so [.] malloc 0.80% 360 dircolors libc-2.15.so [.] malloc 0.56% 252 tr libc-2.15.so [.] malloc 0.54% 242 top libc-2.15.so [.] malloc 0.49% 222 irqbalance libc-2.15.so [.] malloc 0.44% 200 dpkg libc-2.15.so [.] malloc 0.38% 173 lesspipe libc-2.15.so [.] malloc 0.29% 130 update-motd-fsc libc-2.15.so [.] malloc 0.25% 112 uname libc-2.15.so [.] malloc 0.24% 108 cut libc-2.15.so [.] malloc 0.23% 104 groups libc-2.15.so [.] malloc 0.21% 94 release-upgrade libc-2.15.so [.] malloc 0.18% 82 00-header libc-2.15.so [.] malloc 0.14% 62 mesg libc-2.15.so [.] malloc 0.09% 42 update-motd-reb libc-2.15.so [.] malloc 0.09% 40 date libc-2.15.so [.] malloc 0.08% 35 bash libc-2.15.so [.] malloc 0.08% 35 basename libc-2.15.so [.] malloc 0.08% 34 dirname libc-2.15.so [.] malloc 0.06% 29 sh libc-2.15.so [.] malloc 0.06% 26 99-footer libc-2.15.so [.] malloc 0.05% 24 cat libc-2.15.so [.] malloc 0.04% 18 expr libc-2.15.so [.] malloc 0.04% 17 rsyslogd libc-2.15.so [.] malloc 0.03% 12 stty libc-2.15.so [.] malloc 0.00% 1 cron libc-2.15.so [.] malloc This shows the most malloc() calls were by apt-config, while I was tracing.这显示了大多数malloc()调用是通过apt-config进行的。 User: malloc() with sizeAs of the Linux 3.13.1 kernel, this is not supported yet:在Linux 3.13.1内核中，这还不被支持: 123# perf probe -x /lib/x86_64-linux-gnu/libc-2.15.so --add 'malloc size'Debuginfo-analysis is not yet supported with -x/--exec option. Error: Failed to add events. (-38) As a workaround, you can access the registers (on Linux 3.7+). For example, on x86_64: 12# perf probe -x /lib64/libc-2.17.so '--add=malloc size=%di' probe_libc:malloc (on 0x800c0 with size=%di) These registers (“%di” etc) are dependent on your processor architecture. To figure out which ones to use, see the X86 calling conventions on Wikipedia, or page 24 of the AMD64 ABI (PDF). (Thanks Jose E. Nunez for digging out these references.)这些寄存器(“%di”等)依赖于你的处理器架构。要确定使用哪些，请参阅Wikipedia上的X86调用约定，或AMD64 ABI (PDF)的第24页。(感谢何塞·e·努涅斯(Jose E. Nunez)挖掘出这些参考资料。) 6.7. Scheduler AnalysisThe perf sched subcommand provides a number of tools for analyzing kernel CPU scheduler behavior. You can use this to identify and quantify issues of scheduler latency.perf sched子命令提供了许多用于分析内核CPU调度器行为的工具。您可以使用它来识别和量化调度器延迟的问题。 The current overhead of this tool (as of up to Linux 4.10) may be noticeable, as it instruments and dumps scheduler events to the perf.data file for later analysis. For example:这个工具的当前开销(从Linux 4.10开始)可能是显而易见的，因为它将调度器事件转储到perf。供以后分析使用。例如: 123# perf sched record -- sleep 1[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 1.886 MB perf.data (13502 samples) ] That’s 1.9 Mbytes for one second, including 13,502 samples. The size and rate will be relative to your workload and number of CPUs (this example is an 8 CPU server running a software build). How this is written to the file system has been optimized: it only woke up one time to read the event buffers and write them to disk, which greatly reduces overhead. That said, there are still significant overheads with instrumenting all scheduler events and writing event data to the file system. These events:一秒是1.9兆字节，包括13502个样本。大小和速率将与您的工作负载和CPU数量相关(本例是运行软件构建的8 CPU服务器)。如何将其写入文件系统已经进行了优化:它只唤醒一次来读取事件缓冲区并将其写入磁盘，这大大减少了开销。也就是说，在检测所有调度器事件和向文件系统写入事件数据方面仍然存在很大的开销。 12345678910111213141516171819202122232425262728293031# perf script --header# ========# captured on: Sun Feb 26 19:40:00 2017# hostname : bgregg-xenial# os release : 4.10-virtual# perf version : 4.10# arch : x86_64# nrcpus online : 8# nrcpus avail : 8# cpudesc : Intel(R) Xeon(R) CPU E5-2680 v2 @ 2.80GHz# cpuid : GenuineIntel,6,62,4# total memory : 15401700 kB# cmdline : /usr/bin/perf sched record -- sleep 1 # event : name = sched:sched_switch, , id = &#123; 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759 &#125;, type = 2, size = 11...# event : name = sched:sched_stat_wait, , id = &#123; 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767 &#125;, type = 2, size =...# event : name = sched:sched_stat_sleep, , id = &#123; 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775 &#125;, type = 2, size ...# event : name = sched:sched_stat_iowait, , id = &#123; 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783 &#125;, type = 2, size...# event : name = sched:sched_stat_runtime, , id = &#123; 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791 &#125;, type = 2, siz...# event : name = sched:sched_process_fork, , id = &#123; 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799 &#125;, type = 2, siz...# event : name = sched:sched_wakeup, , id = &#123; 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807 &#125;, type = 2, size = 11...# event : name = sched:sched_wakeup_new, , id = &#123; 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815 &#125;, type = 2, size ...# event : name = sched:sched_migrate_task, , id = &#123; 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823 &#125;, type = 2, siz...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: breakpoint = 5, power = 7, software = 1, tracepoint = 2, msr = 6# HEADER_CACHE info available, use -I to display# missing features: HEADER_BRANCH_STACK HEADER_GROUP_DESC HEADER_AUXTRACE HEADER_STAT # ========# perf 16984 [005] 991962.879966: sched:sched_wakeup: comm=perf pid=16999 prio=120 target_cpu=005[...] If overhead is a problem, you can use my eBPF/bcc Tools including runqlat and runqlen which use in-kernel summaries of scheduler events, reducing overhead further. An advantage of perf sched dumping all events is that you aren’t limited to the summary. If you caught an intermittent event, you can analyze those recorded events in custom ways until you understood the issue, rather than needing to catch it a second time.如果开销是一个问题，您可以使用我的eBPF/bcc工具，包括runqlat和runqlen，它们使用内核内的调度器事件摘要，进一步减少开销。perf sched转储所有事件的一个优点是您不局限于摘要。如果捕捉到一个间歇事件，您可以用自定义的方式分析那些记录的事件，直到您理解问题为止，而不需要再次捕捉它。 The captured trace file can be reported in a number of ways, summarized by the help message:捕获的跟踪文件可以用多种方式报告，通过帮助可以查看这些处理方式:12345678# perf sched -h Usage: perf sched [] &#123;record|latency|map|replay|script|timehist&#125; -D, --dump-raw-trace dump raw trace in ASCII -f, --force don't complain, do it -i, --input input file name -v, --verbose be more verbose (show symbol address, etc) perf sched latency will summarize scheduler latencies by task, including average and maximum delay:perf sched latency 将按任务统计调度程序延迟，包括平均延迟和最大延迟: 1234567891011121314151617181920# perf sched latency ----------------------------------------------------------------------------------------------------------------- Task | Runtime ms | Switches | Average delay ms | Maximum delay ms | Maximum delay at | ----------------------------------------------------------------------------------------------------------------- cat:(6) | 12.002 ms | 6 | avg: 17.541 ms | max: 29.702 ms | max at: 991962.948070 s ar:17043 | 3.191 ms | 1 | avg: 13.638 ms | max: 13.638 ms | max at: 991963.048070 s rm:(10) | 20.955 ms | 10 | avg: 11.212 ms | max: 19.598 ms | max at: 991963.404069 s objdump:(6) | 35.870 ms | 8 | avg: 10.969 ms | max: 16.509 ms | max at: 991963.424443 s :17008:17008 | 462.213 ms | 50 | avg: 10.464 ms | max: 35.999 ms | max at: 991963.120069 s grep:(7) | 21.655 ms | 11 | avg: 9.465 ms | max: 24.502 ms | max at: 991963.464082 s fixdep:(6) | 81.066 ms | 8 | avg: 9.023 ms | max: 19.521 ms | max at: 991963.120068 s mv:(10) | 30.249 ms | 14 | avg: 8.380 ms | max: 21.688 ms | max at: 991963.200073 s ld:(3) | 14.353 ms | 6 | avg: 7.376 ms | max: 15.498 ms | max at: 991963.452070 s recordmcount:(7) | 14.629 ms | 9 | avg: 7.155 ms | max: 18.964 ms | max at: 991963.292100 s svstat:17067 | 1.862 ms | 1 | avg: 6.142 ms | max: 6.142 ms | max at: 991963.280069 s cc1:(21) | 6013.457 ms | 1138 | avg: 5.305 ms | max: 44.001 ms | max at: 991963.436070 s gcc:(18) | 43.596 ms | 40 | avg: 3.905 ms | max: 26.994 ms | max at: 991963.380069 s ps:17073 | 27.158 ms | 4 | avg: 3.751 ms | max: 8.000 ms | max at: 991963.332070 s[...] To shed some light as to how this is instrumented and calculated, I’ll show the events that led to the top event’s “Maximum delay at” of 29.702 ms. Here are the raw events from perf sched script:为了说明如何测量和计算它，我将展示导致最高事件的“最大延迟”为29.702 ms的事件。下面是来自perf sched脚本的原始事件: 12345 sh 17028 [001] 991962.918368: sched:sched_wakeup_new: comm=sh pid=17030 prio=120 target_cpu=002[...] cc1 16819 [002] 991962.948070: sched:sched_switch: prev_comm=cc1 prev_pid=16819 prev_prio=120 prev_state=R ==&gt; next_comm=sh next_pid=17030 next_prio=120[...] The time from the wakeup (991962.918368, which is in seconds) to the context switch (991962.948070) is 29.702 ms. This process is listed as “sh” (shell) in the raw events, but execs “cat” soon after, so is shown as “cat” in the perf sched latency output.从唤醒(991962.918368，单位是秒)到上下文切换(991962.948070)的时间是29.702 ms。这个过程在原始事件中以“sh”(shell)的形式列出，但是execs“cat”紧随其后，所以在perf sched延迟输出中显示为“cat”。 perf sched map shows all CPUs and context-switch events, with columns representing what each CPU was doing and when. It’s the kind of data you see visualized in scheduler analysis GUIs (including perf timechart, with the layout rotated 90 degrees). Example output: perf sched map 显示所有CPU和上下文切换事件，其中的列表示每个CPU正在做什么以及何时做。它是在调度器分析gui中可以看到的可视化数据(包括将布局旋转90度的perf timechart)。示例输出: 123456789101112131415161718192021222324# perf sched map *A0 991962.879971 secs A0 =&gt; perf:16999 A0 *B0 991962.880070 secs B0 =&gt; cc1:16863 *C0 A0 B0 991962.880070 secs C0 =&gt; :17023:17023 *D0 C0 A0 B0 991962.880078 secs D0 =&gt; ksoftirqd/0:6 D0 C0 *E0 A0 B0 991962.880081 secs E0 =&gt; ksoftirqd/3:28 D0 C0 *F0 A0 B0 991962.880093 secs F0 =&gt; :17022:17022 *G0 C0 F0 A0 B0 991962.880108 secs G0 =&gt; :17016:17016 G0 C0 F0 *H0 B0 991962.880256 secs H0 =&gt; migration/5:39 G0 C0 F0 *I0 B0 991962.880276 secs I0 =&gt; perf:16984 G0 C0 F0 *J0 B0 991962.880687 secs J0 =&gt; cc1:16996 G0 C0 *K0 J0 B0 991962.881839 secs K0 =&gt; cc1:16945 G0 C0 K0 J0 *L0 B0 991962.881841 secs L0 =&gt; :17020:17020 G0 C0 K0 J0 *M0 B0 991962.882289 secs M0 =&gt; make:16637 G0 C0 K0 J0 *N0 B0 991962.883102 secs N0 =&gt; make:16545 G0 *O0 K0 J0 N0 B0 991962.883880 secs O0 =&gt; cc1:16819 G0 *A0 O0 K0 J0 N0 B0 991962.884069 secs G0 A0 O0 K0 *P0 J0 N0 B0 991962.884076 secs P0 =&gt; rcu_sched:7 G0 A0 O0 K0 *Q0 J0 N0 B0 991962.884084 secs Q0 =&gt; cc1:16831 G0 A0 O0 K0 Q0 J0 *R0 B0 991962.884843 secs R0 =&gt; cc1:16825 G0 *S0 O0 K0 Q0 J0 R0 B0 991962.885636 secs S0 =&gt; cc1:16900 G0 S0 O0 *T0 Q0 J0 R0 B0 991962.886893 secs T0 =&gt; :17014:17014 G0 S0 O0 *K0 Q0 J0 R0 B0 991962.886917 secs [...] This is an 8 CPU system, and you can see the 8 columns for each CPU starting from the left. Some CPU columns begin blank, as we’ve yet to trace an event on that CPU at the start of the profile. They quickly become populated.这是一个8 CPU的系统，您可以看到每个CPU从左侧开始的8列。一些CPU列开始时是空白的，因为我们还没有跟踪配置文件开始时那个CPU上的事件。它们很快就有了人口。 The two character codes you see (“A0”, “C0”) are identifiers for tasks, which are mapped on the right (“=&gt;”). This is more compact than using process (task) IDs. The ““ shows which CPU had the context switch event, and the new event that was running. For example, the very last line shows that at 991962.886917 (seconds) CPU 4 context-switched to K0 (a “cc1” process, PID 16945).您看到的两个字符代码(“A0”、“C0”)是任务的标识符，它们被映射在右侧(“=&gt;”)。这比使用进程(任务)id更紧凑。“”显示哪个CPU拥有上下文切换事件，以及正在运行的新事件。例如，最后一行显示在991962.886917(秒)处，CPU 4上下文切换到K0(一个“cc1”进程，PID 16945)。 That example was from a busy system. Here’s an idle system:上面的例子来自一个繁忙的系统。下面是一个空闲系统:12345678910111213141516171819# perf sched map *A0 993552.887633 secs A0 =&gt; perf:26596 *. A0 993552.887781 secs . =&gt; swapper:0 . *B0 993552.887843 secs B0 =&gt; migration/5:39 . *. 993552.887858 secs . . *A0 993552.887861 secs . *C0 A0 993552.887903 secs C0 =&gt; bash:26622 . *. A0 993552.888020 secs . *D0 . A0 993552.888074 secs D0 =&gt; rcu_sched:7 . *. . A0 993552.888082 secs . . *C0 A0 993552.888143 secs . *. . C0 A0 993552.888173 secs . . . *B0 A0 993552.888439 secs . . . *. A0 993552.888454 secs . *C0 . . A0 993552.888457 secs . C0 . . *. 993552.889257 secs . *. . . . 993552.889764 secs . . *E0 . . 993552.889767 secs E0 =&gt; bash:7902[...] Idle CPUs are shown as “.”.空闲cpu显示为”.”。 Remember to examine the timestamp column to make sense of this visualization (GUIs use that as a dimension, which is easier to comprehend, but here the numbers are just listed). It’s also only showing context switch events, and not scheduler latency. The newer timehist command has a visualization (-V) that can include wakeup events.请记住检查timestamp列以理解这种可视化(gui使用它作为维度，这更容易理解，但这里只列出数字)。它还只显示上下文切换事件，而没有显示调度程序延迟。更新的timehist命令有一个可视化(-V)，可以包含唤醒事件。 perf sched timehist was added in Linux 4.10, and shows the scheduler latency by event, including the time the task was waiting to be woken up (wait time) and the scheduler latency after wakeup to running (sch delay). It’s the scheduler latency that we’re more interested in tuning. Example output:perf sched timehist是在Linux 4.10中添加的，它按事件显示调度程序延迟，包括任务等待被唤醒的时间(等待时间)和调度程序从唤醒到运行的延迟(sch delay)。我们更感兴趣的是调优调度程序延迟。示例输出: 123456789101112131415161718192021# perf sched timehistSamples do not have callchains. time cpu task name wait time sch delay run time [tid/pid] (msec) (msec) (msec)--------------- ------ ------------------------------ --------- --------- --------- 991962.879971 [0005] perf[16984] 0.000 0.000 0.000 991962.880070 [0007] :17008[17008] 0.000 0.000 0.000 991962.880070 [0002] cc1[16880] 0.000 0.000 0.000 991962.880078 [0000] cc1[16881] 0.000 0.000 0.000 991962.880081 [0003] cc1[16945] 0.000 0.000 0.000 991962.880093 [0003] ksoftirqd/3[28] 0.000 0.007 0.012 991962.880108 [0000] ksoftirqd/0[6] 0.000 0.007 0.030 991962.880256 [0005] perf[16999] 0.000 0.005 0.285 991962.880276 [0005] migration/5[39] 0.000 0.007 0.019 991962.880687 [0005] perf[16984] 0.304 0.000 0.411 991962.881839 [0003] cat[17022] 0.000 0.000 1.746 991962.881841 [0006] cc1[16825] 0.000 0.000 0.000 [...] 991963.885740 [0001] :17008[17008] 25.613 0.000 0.057 991963.886009 [0001] sleep[16999] 1000.104 0.006 0.269 991963.886018 [0005] cc1[17083] 19.998 0.000 9.948 This output includes the sleep command run to set the duration of perf itself to one second. Note that sleep’s wait time is 1000.104 milliseconds because I had run “sleep 1”: that’s the time it was asleep waiting its timer wakeup event. Its scheduler latency was only 0.006 milliseconds, and its time on-CPU was 0.269 milliseconds.该输出包括sleep命令run，用于将perf本身的持续时间设置为1秒。注意，sleep的等待时间是1000.104毫秒，因为我已经运行了“sleep 1”:这是它在休眠等待计时器唤醒事件的时间。它的调度器延迟只有0.006毫秒，它在cpu上的时间是0.269毫秒。 There are a number of options to timehist, including -V to add a CPU visualization column, -M to add migration events, and -w for wakeup events. For example:timehist有许多选项，包括添加CPU可视化列的-V，添加迁移事件的-M，以及用于唤醒事件的-w。例如: 12345678910111213141516171819202122232425262728# perf sched timehist -MVwSamples do not have callchains. time cpu 012345678 task name wait time sch delay run time [tid/pid] (msec) (msec) (msec)--------------- ------ --------- ------------------ --------- --------- --------- 991962.879966 [0005] perf[16984] awakened: perf[16999] 991962.879971 [0005] s perf[16984] 0.000 0.000 0.000 991962.880070 [0007] s :17008[17008] 0.000 0.000 0.000 991962.880070 [0002] s cc1[16880] 0.000 0.000 0.000 991962.880071 [0000] cc1[16881] awakened: ksoftirqd/0[6] 991962.880073 [0003] cc1[16945] awakened: ksoftirqd/3[28] 991962.880078 [0000] s cc1[16881] 0.000 0.000 0.000 991962.880081 [0003] s cc1[16945] 0.000 0.000 0.000 991962.880093 [0003] s ksoftirqd/3[28] 0.000 0.007 0.012 991962.880108 [0000] s ksoftirqd/0[6] 0.000 0.007 0.030 991962.880249 [0005] perf[16999] awakened: migration/5[39] 991962.880256 [0005] s perf[16999] 0.000 0.005 0.285 991962.880264 [0005] m migration/5[39] migrated: perf[16999] cpu 5 =&gt; 1 991962.880276 [0005] s migration/5[39] 0.000 0.007 0.019 991962.880682 [0005] m perf[16984] migrated: cc1[16996] cpu 0 =&gt; 5 991962.880687 [0005] s perf[16984] 0.304 0.000 0.411 991962.881834 [0003] cat[17022] awakened: :17020[...] 991963.885734 [0001] :17008[17008] awakened: sleep[16999] 991963.885740 [0001] s :17008[17008] 25.613 0.000 0.057 991963.886005 [0001] sleep[16999] awakened: perf[16984] 991963.886009 [0001] s sleep[16999] 1000.104 0.006 0.269 991963.886018 [0005] s cc1[17083] 19.998 0.000 9.948 The CPU visualization column (“012345678”) has “s” for context-switch events, and “m” for migration events, showing the CPU of the event. If you run perf sched record -g, then the stack traces are appended on the right in a single line (not shown here).CPU可视化列(“012345678”)使用“s”表示上下文切换事件，使用“m”表示迁移事件，来显示CPU上的事件。如果您运行perf sched record -g，那么堆栈跟踪将附加在右侧的一行中(这里没有显示)。 The last events in that output include those related to the “sleep 1” command used to time perf. The wakeup happened at 991963.885734, and at 991963.885740 (6 microseconds later) CPU 1 begins to context-switch to the sleep process. The column for that event still shows “:17008[17008]” for what was on-CPU, but the target of the context switch (sleep) is not shown. It is in the raw events: 该输出中的最后一个事件包括与用于为perf计时的“sleep 1”命令相关的事件。唤醒发生在 991963.885734 ，在991963.885740(6微秒后)CPU 1开始上下文切换到睡眠进程。对于cpu上的内容，该事件的列仍然显示“:17008[17008]”，但是没有显示上下文切换(sleep)的目标。它是在原始事件: 12:17008 17008 [001] 991963.885740: sched:sched_switch: prev_comm=cc1 prev_pid=17008 prev_prio=120 prev_state=R ==&gt; next_comm=sleep next_pid=16999 next_prio=120 The 991963.886005 event shows that the perf command received a wakeup while sleep was running (almost certainly sleep waking up its parent process because it terminated), and then we have the context switch on 991963.886009 where sleep stops running, and a summary is printed out: 1000.104 ms waiting (the “sleep 1”), with 0.006 ms scheduler latency, and 0.269 ms of CPU runtime. 991963.886005 事件表明,当 sleep 运行时 perf 命令被唤醒(几乎可以肯定是 sleep 唤醒了它的父进程,因为它终止了),然后我们有 991963.886009 的上下文切换,睡眠停止运行,并打印出总结:1000.104毫秒(“睡眠1”),等待0.006调度器延迟和0.269毫秒的CPU运行时。 Here I’ve decorated the timehist output with the details of the context switch destination in red:这里我用红色的上下文切换目的地的细节装饰了timehist输出:12345991963.885734 [0001] :17008[17008] awakened: sleep[16999]991963.885740 [0001] s :17008[17008] 25.613 0.000 0.057 next: sleep[16999]991963.886005 [0001] sleep[16999] awakened: perf[16984]991963.886009 [0001] s sleep[16999] 1000.104 0.006 0.269 next: cc1[17008]991963.886018 [0005] s cc1[17083] 19.998 0.000 9.948 next: perf[16984] When sleep finished, a waiting “cc1” process then executed. perf ran on the following context switch, and is the last event in the profile (perf terminated). I’ve added this as a -n/–next option to perf (should arrive in Linux 4.11 or 4.12). 当休眠结束时，等待的“cc1”进程被执行。perf 在以下上下文切换中运行，并且是 profile 文件中的最后一个事件。我使用 perf的-n/–next选项来显示这些信息(在Linux 4.11或4.12中可用)。 perf sched script dumps all events (similar to perf script):perf sched script 转储所有事件(类似于perf脚本): 12345678910# perf sched script perf 16984 [005] 991962.879960: sched:sched_stat_runtime: comm=perf pid=16984 runtime=3901506 [ns] vruntime=165... perf 16984 [005] 991962.879966: sched:sched_wakeup: comm=perf pid=16999 prio=120 target_cpu=005 perf 16984 [005] 991962.879971: sched:sched_switch: prev_comm=perf prev_pid=16984 prev_prio=120 prev_stat... perf 16999 [005] 991962.880058: sched:sched_stat_runtime: comm=perf pid=16999 runtime=98309 [ns] vruntime=16405... cc1 16881 [000] 991962.880058: sched:sched_stat_runtime: comm=cc1 pid=16881 runtime=3999231 [ns] vruntime=7897... :17024 17024 [004] 991962.880058: sched:sched_stat_runtime: comm=cc1 pid=17024 runtime=3866637 [ns] vruntime=7810... cc1 16900 [001] 991962.880058: sched:sched_stat_runtime: comm=cc1 pid=16900 runtime=3006028 [ns] vruntime=7772... cc1 16825 [006] 991962.880058: sched:sched_stat_runtime: comm=cc1 pid=16825 runtime=3999423 [ns] vruntime=7876... Each of these events (“sched:sched_stat_runtime” etc) are tracepoints you can instrument directly using perf record.这些事件(“sched:sched_stat_runtime”等)都是可以使用perf记录直接检测的跟踪点。 As I’ve shown earlier, this raw output can be useful for digging further than the summary commands.如前所述，这个原始输出对于深入研究summary命令以外的内容很有用。 perf sched replay will take the recorded scheduler events, and then simulate the workload by spawning threads with similar runtimes and context switches. Useful for testing and developing scheduler changes and configuration. Don’t put too much faith in this (and other) workload replayers: they can be a useful load generator, but it’s difficult to simulate the real workload completely. Here I’m running replay with -r -1, to repeat the workload: perf sched replay将获取已记录的调度程序事件，然后通过使用类似的运行时和上下文切换生成线程来模拟工作负载。用于测试和开发调度器更改和配置。不要太相信这个(和其他)工作负载重播器:它们可以是一个有用的负载生成器，但是很难完全模拟真实的工作负载。这里我使用了 -r -1 选项来运行重放，以重复工作负载: 1234567891011121314151617181920212223242526# perf sched replay -r -1run measurement overhead: 84 nsecssleep measurement overhead: 146710 nsecsthe run test took 1000005 nsecsthe sleep test took 1107773 nsecsnr_run_events: 4175nr_sleep_events: 4710nr_wakeup_events: 2138task 0 ( swapper: 0), nr_events: 13task 1 ( swapper: 1), nr_events: 1task 2 ( swapper: 2), nr_events: 1task 3 ( kthreadd: 4), nr_events: 1task 4 ( kthreadd: 6), nr_events: 29[...]task 530 ( sh: 17145), nr_events: 4task 531 ( sh: 17146), nr_events: 7task 532 ( sh: 17147), nr_events: 4task 533 ( make: 17148), nr_events: 10task 534 ( sh: 17149), nr_events: 1------------------------------------------------------------#1 : 965.996, ravg: 966.00, cpu: 798.24 / 798.24#2 : 902.647, ravg: 966.00, cpu: 1157.53 / 798.24#3 : 945.482, ravg: 966.00, cpu: 925.25 / 798.24#4 : 943.541, ravg: 966.00, cpu: 761.72 / 798.24#5 : 914.643, ravg: 966.00, cpu: 1604.32 / 798.24[...] 6.8. eBPFAs of Linux 4.4, perf has some enhanced BPF support (aka eBPF or just “BPF”), with more in later kernels. BPF makes perf tracing programmatic, and takes perf from being a counting &amp; sampling-with-post-processing tracer, to a fully in-kernel programmable tracer.从Linux 4.4开始，perf已经增强了对BPF的支持(又名eBPF或简称为“BPF”)，在以后的内核中会有更多的增强。BPF使perf跟踪成为可编程的，并使perf从一个计数和取样与后处理跟踪程序，成为一个完全在内核内可编程跟踪程序。 eBPF is currently a little restricted and difficult to use from perf. It’s getting better all the time. A different and currently easier way to access eBPF is via the bcc Python interface, which is described on my eBPF Tools page. On this page, I’ll discuss perf.eBPF目前在 perf 上有限制，并且难以使用。不过情况一直在好转。一种不同的、目前更容易的访问eBPF的方法是通过bcc Python接口，它在我的eBPF工具页面上被描述。当前只讨论perf。 PrerequisitesLinux 4.4 at least. Newer versions have more perf/BPF features, so the newer the better. Also clang (eg, apt-get install clang).至少是Linux 4.4。较新的版本有更多的perf/BPF特性，所以越新越好。还有 clang (eg，apt-get install clang)。 kmem_cache_alloc from ExampleThis program traces the kernel kmem_cache_alloc() function, only if its calling function matches a specified range, filtered in kernel context. You can imagine doing this for efficiency: instead of tracing all allocations, which can be very frequent and add significant overhead, you filter for just a range of kernel calling functions of interest, such as a kernel module. I’ll loosely match tcp functions as an example, which are in memory at these addresses:这个程序跟踪内核kmem_cache_alloc()函数，仅当它的调用函数匹配指定的范围(在内核上下文中过滤)。您可以想象这样做是为了提高效率:您不必跟踪所有的分配(这可能非常频繁并增加显著的开销)，而是只过滤感兴趣的一系列内核调用函数，比如内核模块。我将松散匹配tcp函数作为一个例子，这是在内存在这些地址: 12345678910111213141516# grep tcp /proc/kallsyms | more[...]ffffffff817c1bb0 t tcp_get_info_chrono_statsffffffff817c1c60 T tcp_init_sockffffffff817c1e30 t tcp_splice_data_recvffffffff817c1e70 t tcp_pushffffffff817c20a0 t tcp_send_mssffffffff817c2170 t tcp_recv_skbffffffff817c2250 t tcp_cleanup_rbuf[...]ffffffff818524f0 T tcp6_proc_exitffffffff81852510 T tcpv6_exitffffffff818648a0 t tcp6_gro_completeffffffff81864910 t tcp6_gro_receiveffffffff81864ae0 t tcp6_gso_segmentffffffff8187bd89 t tcp_v4_inbound_md5_hash I’ll assume these functions are contiguous, so that by tracing the range 0xffffffff817c1bb0 to 0xffffffff8187bd89, I’m matching much of tcp.我假设这些函数是连续的，因此通过跟踪范围0xffffffffffff817c1bb0到0xffffffff8187bd89，我匹配了大部分tcp。 Here is my BPF program, kca_from.c:这是我的BPF程序，kca_from.c: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;uapi/linux/bpf.h&gt;#include &lt;uapi/linux/ptrace.h&gt;#define SEC(NAME) __attribute__((section(NAME), used))/* * Edit the following to match the instruction address range you want to * sample. Eg, look in /proc/kallsyms. The addresses will change for each * kernel version and build. */#define RANGE_START 0xffffffff817c1bb0#define RANGE_END 0xffffffff8187bd89struct bpf_map_def &#123; unsigned int type; unsigned int key_size; unsigned int value_size; unsigned int max_entries;&#125;;static int (*probe_read)(void *dst, int size, void *src) = (void *)BPF_FUNC_probe_read;static int (*get_smp_processor_id)(void) = (void *)BPF_FUNC_get_smp_processor_id;static int (*perf_event_output)(void *, struct bpf_map_def *, int, void *, unsigned long) = (void *)BPF_FUNC_perf_event_output;struct bpf_map_def SEC("maps") channel = &#123; .type = BPF_MAP_TYPE_PERF_EVENT_ARRAY, .key_size = sizeof(int), .value_size = sizeof(u32), .max_entries = __NR_CPUS__,&#125;;SEC("func=kmem_cache_alloc")int func(struct pt_regs *ctx)&#123; u64 ret = 0; // x86_64 specific: probe_read(&amp;ret, sizeof(ret), (void *)(ctx-&gt;bp+8)); if (ret &gt;= RANGE_START &amp;&amp; ret &lt; RANGE_END) &#123; perf_event_output(ctx, &amp;channel, get_smp_processor_id(), &amp;ret, sizeof(ret)); &#125; return 0;&#125;char _license[] SEC("license") = "GPL";int _version SEC("version") = LINUX_VERSION_CODE; Now I’ll execute it, then dump the events:现在我将执行它，然后转储事件: 1234567891011121314151617# perf record -e bpf-output/no-inherit,name=evt/ -e ./kca_from.c/map:channel.event=evt/ -a -- sleep 1bpf: builtin compilation failed: -95, try external compiler[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.214 MB perf.data (3 samples) ]# perf script testserver00001 14337 [003] 481432.395181: 0 evt: ffffffff81210f51 kmem_cache_alloc (/lib/modules/...) BPF output: 0000: 0f b4 7c 81 ff ff ff ff ..|..... 0008: 00 00 00 00 .... redis-server 1871 [005] 481432.395258: 0 evt: ffffffff81210f51 kmem_cache_alloc (/lib/modules/...) BPF output: 0000: 14 55 7c 81 ff ff ff ff .U|..... 0008: 00 00 00 00 .... redis-server 1871 [005] 481432.395456: 0 evt: ffffffff81210f51 kmem_cache_alloc (/lib/modules/...) BPF output: 0000: fe dc 7d 81 ff ff ff ff ..&#125;..... 0008: 00 00 00 00 .... It worked: the “BPF output” records contain addresses in our range: 0xffffffff817cb40f, and so on. kmem_cache_alloc() is a frequently called function, so that it only matched a few entries in one second of tracing is an indication it is working (I can also relax that range to confirm it).eBPF 脚本已经开始工作:“BPF输出”记录包含我们的筛选范围内的地址:0xffffffffff817cb40f，等等。kmem_cache_alloc()是一个经常调用的函数，因此在跟踪过程中，它在一秒钟内只匹配了几个条目，这表明它在工作(我还可以放宽这个范围来确认它)。 Adding stack traces with -g:添加堆栈跟踪-g: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# perf record -e bpf-output/no-inherit,name=evt/ -e ./kca_from.c/map:channel.event=evt/ -a -g -- sleep 1bpf: builtin compilation failed: -95, try external compiler[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.215 MB perf.data (3 samples) ]# perf scripttestserver00001 16744 [002] 481518.262579: 0 evt: 410f51 kmem_cache_alloc (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9cb40f tcp_conn_request (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9da243 tcp_v4_conn_request (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d0936 tcp_rcv_state_process (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9db102 tcp_v4_do_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9dcabf tcp_v4_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b4af4 ip_local_deliver_finish (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b4dff ip_local_deliver (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b477b ip_rcv_finish (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b50fb ip_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 97119e __netif_receive_skb_core (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 971708 __netif_receive_skb (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9725df process_backlog (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 971c8e net_rx_action (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8e58d __do_softirq (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8c9ac do_softirq_own_stack (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 28a061 do_softirq.part.18 (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 28a0ed __local_bh_enable_ip (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b8ff3 ip_finish_output2 (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b9f43 ip_finish_output (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba9f6 ip_output (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba155 ip_local_out (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba48a ip_queue_xmit (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d3823 tcp_transmit_skb (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d5345 tcp_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9da764 tcp_v4_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9f1abc __inet_stream_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9f1d38 inet_stream_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 952fd9 SYSC_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 953c1e sys_connect (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8b9fb entry_SYSCALL_64_fastpath (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 10800 __GI___libc_connect (/lib/x86_64-linux-gnu/libpthread-2.23.so) BPF output: 0000: 0f b4 7c 81 ff ff ff ff ..|..... 0008: 00 00 00 00 .... redis-server 1871 [003] 481518.262670: 0 evt: 410f51 kmem_cache_alloc (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9c5514 tcp_poll (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9515ba sock_poll (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 485699 sys_epoll_ctl (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8b9fb entry_SYSCALL_64_fastpath (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 106dca epoll_ctl (/lib/x86_64-linux-gnu/libc-2.23.so) BPF output: 0000: 14 55 7c 81 ff ff ff ff .U|..... 0008: 00 00 00 00 .... redis-server 1871 [003] 481518.262870: 0 evt: 410f51 kmem_cache_alloc (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ddcfe tcp_time_wait (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9cefff tcp_fin (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9cf630 tcp_data_queue (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d0abd tcp_rcv_state_process (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9db102 tcp_v4_do_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9dca8b tcp_v4_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b4af4 ip_local_deliver_finish (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b4dff ip_local_deliver (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b477b ip_rcv_finish (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b50fb ip_rcv (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 97119e __netif_receive_skb_core (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 971708 __netif_receive_skb (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9725df process_backlog (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 971c8e net_rx_action (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8e58d __do_softirq (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8c9ac do_softirq_own_stack (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 28a061 do_softirq.part.18 (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 28a0ed __local_bh_enable_ip (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b8ff3 ip_finish_output2 (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9b9f43 ip_finish_output (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba9f6 ip_output (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba155 ip_local_out (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9ba48a ip_queue_xmit (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d3823 tcp_transmit_skb (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d3e24 tcp_write_xmit (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d4c31 __tcp_push_pending_frames (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9d6881 tcp_send_fin (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9c70b7 tcp_close (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 9f161c inet_release (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 95181f sock_release (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 951892 sock_close (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 43b2f7 __fput (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 43b46e ____fput (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 2a3cfe task_work_run (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 2032ba exit_to_usermode_loop (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 203b29 syscall_return_slowpath (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) a8ba88 entry_SYSCALL_64_fastpath (/lib/modules/4.10.0-rc8-virtual/build/vmlinux) 105cd __GI___libc_close (/lib/x86_64-linux-gnu/libpthread-2.23.so) BPF output: 0000: fe dc 7d 81 ff ff ff ff ..&#125;..... 0008: 00 00 00 00 .... This confirms the parent functions that were matched by the range.这确认了与范围匹配的父函数。 More ExamplesXXX fill me in. 7. Visualizations(可视化)perf_events has a builtin visualization: timecharts, as well as text-style visualization via its text user interface (TUI) and tree reports. The following two sections show visualizations of my own: flame graphs and heat maps. The software I’m using is open source and on github, and produces these from perf_events collected data.perf_events有一个内置的可视化:timecharts，以及通过文本用户界面(TUI)和树状报告的文本风格的可视化。下面两个部分展示了我自己的可视化:火焰图和热图。我使用的软件是开源的，并且在github上，并从perf_events收集的数据中生成这些数据。 7.1. Flame GraphsFlame Graphs can be produced from perf_events profiling data using the FlameGraph tools software. This visualizes the same data you see in perf report, and works with any perf.data file that was captured with stack traces (-g).火焰图可以使用FlameGraph工具软件从perf_events分析数据生成。这将可视化您在perf报告中看到的相同数据，并与任何perf一起工作。用堆栈跟踪捕获的数据文件(-g)。 ExampleThis example CPU flame graph shows a network workload for the 3.2.9-1 Linux kernel, running as a KVM instance (SVG, PNG):这个示例CPU火焰图显示了3.2.9-1 Linux内核的网络工作负载，它作为一个KVM实例运行(SVG， PNG): Flame Graphs show the sample population across the x-axis, and stack depth on the y-axis. Each function (stack frame) is drawn as a rectangle, with the width relative to the number of samples. See the CPU Flame Graphs page for the full description of how these work.火焰图在x轴上显示样本总体，在y轴上显示堆栈深度。每个函数(堆栈框架)被绘制成一个矩形，宽度与样本的数量相关。请查看CPU火焰图页面，以获得如何工作的完整描述。 You can use the mouse to explore where kernel CPU time is spent, quickly quantifying code-paths and determining where performance tuning efforts are best spent. This example shows that most time was spent in the vp_notify() code-path, spending 70.52% of all on-CPU samples performing iowrite16(), which is handled by the KVM hypervisor. This information has been extremely useful for directing KVM performance efforts.您可以使用鼠标探索内核CPU时间花在哪里，快速量化代码路径，并确定性能调优工作最好花在哪里。这个示例显示，大部分时间都花在vp_notify()代码路径上，所有cpu上的示例中有70.52%的时间执行iowrite16()，它由KVM管理程序处理。这些信息对于指导KVM性能工作非常有用。 A similar network workload on a bare metal Linux system looks quite different, as networking isn’t processed via the virtio-net driver, for a start.裸机Linux系统上类似的网络工作负载看起来非常不同，因为首先网络不是通过virtio-net驱动程序处理的。 GenerationThe example flame graph was generated using perf_events and the FlameGraph tools:示例火焰图是使用perf_events和FlameGraph工具生成的: 12345# git clone https://github.com/brendangregg/FlameGraph # or download it from github# cd FlameGraph# perf record -F 99 -ag -- sleep 60# perf script | ./stackcollapse-perf.pl &gt; out.perf-folded# cat out.perf-folded | ./flamegraph.pl &gt; perf-kernel.svg The first perf command profiles CPU stacks, as explained earlier. I adjusted the rate to 99 Hertz here; I actually generated the flame graph from a 1000 Hertz profile, but I’d only use that if you had a reason to go faster, which costs more in overhead. The samples are saved in a perf.data file, which can be viewed using perf report:第一个perf命令配置CPU堆栈，如前所述。我把频率调到99赫兹;实际上，我从1000赫兹的数据中生成了火焰图，但只应该在你有理由更快的时候使用更高的频率，这样会花费更多的开销。样本保存在一个perf.data 文件，可使用perf报告查看: 12345678910111213141516171819202122232425262728293031323334# perf report --stdio[...]# Overhead Command Shared Object Symbol# ........ ............... ..................... ...................................# 72.18% iperf [kernel.kallsyms] [k] iowrite16 | --- iowrite16 | |--99.53%-- vp_notify | virtqueue_kick | start_xmit | dev_hard_start_xmit | sch_direct_xmit | dev_queue_xmit | ip_finish_output | ip_output | ip_local_out | ip_queue_xmit | tcp_transmit_skb | tcp_write_xmit | | | |--98.16%-- tcp_push_one | | tcp_sendmsg | | inet_sendmsg | | sock_aio_write | | do_sync_write | | vfs_write | | sys_write | | system_call | | 0x369e40e5cd | | | --1.84%-- __tcp_push_pending_frames[...] This tree follows the flame graph when reading it top-down. When using -g/–call-graph (for “caller”, instead of the “callee” default), it generates a tree that follows the flame graph when read bottom-up. The hottest stack trace in the flame graph (@70.52%) can be seen in this perf call graph as the product of the top three nodes (72.18% x 99.53% x 98.16%).堆栈树与火焰图一样，遵循从上到下的查看逻辑，即子函数在上，复函数在下。如果使用 -g/--call-graph caller 替代默认的 callee 选项。调用栈和火焰图会倒置。在这个火焰图中个，火焰图(@70.52%)中最热的堆栈轨迹是前三个节点(72.18% x 99.53% x 98.16%)的乘积。 The perf report tree (and the ncurses navigator) do an excellent job at presenting this information as text. However, with text there are limitations. The output often does not fit in one screen (you could say it doesn’t need to, if the bulk of the samples are identified on the first page). Also, identifying the hottest code paths requires reading the percentages. With the flame graph, all the data is on screen at once, and the hottest code-paths are immediately obvious as the widest functions.perf 输出树(和ncurses导航器)在将这些信息显示为文本方面做得很好。但是，使用文本也有限制。输出常常无法装入一个屏幕(如果在第一页上标识了大部分示例，则可以说不需要)。此外，确定最热门的代码路径需要阅读百分比。通过使用flame图，所有数据都立即显示在屏幕上，最热门的代码路径作为最宽的函数会立即显示出来。 For generating the flame graph, the perf script command dumps the stack samples, which are then aggregated by stackcollapse-perf.pl and folded into single lines per-stack. That output is then converted by flamegraph.pl into the SVG. I included a gratuitous “cat” command to make it clear that flamegraph.pl can process the output of a pipe, which could include Unix commands to filter or preprocess (grep, sed, awk). 为了生成火焰图，perf script 命令转储堆栈示例，然后通过 stackcollapse-perf.pl 聚合这些示例，并将其折叠为每个堆栈的单行。然后，该输出由flamegraphic.pl转换为SVG。我附带了一个“cat”命令，以说明flamegraphics.pl可以处理管道的输出，其中可以包括用于过滤或预处理的Unix命令(grep、sed、awk)。 PipingA flame graph can be generated directly by piping all the steps:所有步骤通过管道直接生成火焰图:1# perf script | ./stackcollapse-perf.pl | ./flamegraph.pl &gt; perf-kernel.svg In practice I don’t do this, as I often re-run flamegraph.pl multiple times, and this one-liner would execute everything multiple times. The output of perf script can be dozens of Mbytes, taking many seconds to process. By writing stackcollapse-perf.pl to a file, you’ve cached the slowest step, and can also edit the file (vi) to delete unimportant stacks, such as CPU idle threads.在实际操作中，我不会这样做，因为我经常重复运行多次flamegraphic.pl，而这个一行程序会将所有内容执行多次。perf脚本的输出可能是几十兆字节，处理需要很多秒。通过将stackcollapse-perf.pl的输出写入文件，可以缓存最慢的步骤，还可以编辑文件(vi)来删除不重要的堆栈，比如CPU空闲线程。 FilteringThe one-line-per-stack output of stackcollapse-perf.pl is also convenient for grep(1). Eg:stackcollapse-perf.pl 输出的堆栈，每堆栈输出一行，对于grep很方便。例如: 1234567# perf script | ./stackcollapse-perf.pl &gt; out.perf-folded# grep -v cpu_idle out.perf-folded | ./flamegraph.pl &gt; nonidle.svg# grep ext4 out.perf-folded | ./flamegraph.pl &gt; ext4internals.svg# egrep 'system_call.*sys_(read|write)' out.perf-folded | ./flamegraph.pl &gt; rw.svg I frequently elide the cpu_idle threads in this way, to focus on the real threads that are consuming CPU resources. If I miss this step, the cpu_idle threads can often dominate the flame graph, squeezing the interesting code paths.我经常以这种方式省略cpu_idle线程，以便关注消耗CPU资源的实际线程。如果我错过了这一步，cpu_idle线程通常会占据火焰图，挤压感兴趣的代码路径。 Note that it would be a little more efficient to process the output of perf report instead of perf script; better still, perf report could have a report style (eg, “-g folded”) that output folded stacks directly, obviating the need for stackcollapse-perf.pl. There could even be a perf mode that output the SVG directly (which wouldn’t be the first one; see perf-timechart), although, that would miss the value of being able to grep the folded stacks (which I use frequently).注意，处理perf report 的输出比处理perf脚本的输出效率更高一些;更好的是，perf report 可以具有直接输出折叠的堆栈的报告样式(例如“-g folding”)，从而避免了 stackcollapse-perf.pl 的需要。甚至可以有一个直接输出SVG的perf模式(这不是第一个;但是，这将错过能够grep折叠的堆栈(我经常使用它)的价值。 There are more examples of perf_events CPU flame graphs on the CPU flame graph page, including a summary of these instructions. I have also shared an example of using perf for a Block Device I/O Flame Graph.在CPU火焰图页面上有更多关于perf_events CPU火焰图的例子，包括一个摘要。我还分享了一个在[块设备I/O火焰图]中使用perf的例子。 7.2. Heat MapsSince perf_events can record high resolution timestamps (microseconds) for events, some latency measurements can be derived from trace data.由于perf_events可以记录事件的高分辨率时间戳(微秒)，因此可以从跟踪数据中度量延迟。 ExampleThe following heat map visualizes disk I/O latency data collected from perf_events (SVG, PNG):以下热图显示了从perf_events (SVG、PNG收集的磁盘I/O延迟数据: Mouse-over blocks to explore the latency distribution over time. The x-axis is the passage of time, the y-axis latency, and the z-axis (color) is the number of I/O at that time and latency range. The distribution is bimodal, with the dark line at the bottom showing that many disk I/O completed with sub-millisecond latency: cache hits. There is a cloud of disk I/O from about 3 ms to 25 ms, which would be caused by random disk I/O (and queueing). Both these modes averaged to the 9 ms we saw earlier.将鼠标移到块上，以研究延时随时间的分布。x轴是时间的流逝，y轴是延迟，z轴(颜色)是此时的I/O数量和延迟范围。分布是双峰的，底部的暗线显示许多磁盘I/O在亚毫秒级的延迟下完成:缓存命中。磁盘I/O的云大约在3 ms到25 ms之间，这可能是由随机磁盘I/O(和排队)造成的。这两种模式的平均频率为9毫秒。 The following iostat output was collected at the same time as the heat map data was collected (shows a typical one second summary):下面的iostat输出是在收集热图数据的同时收集的(显示一个典型的一秒摘要):12345# iostat -x 1[...]Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00vdb 0.00 0.00 334.00 0.00 2672.00 0.00 16.00 2.97 9.01 9.01 0.00 2.99 100.00 This workload has an average I/O time (await) of 9 milliseconds, which sounds like a fairly random workload on 7200 RPM disks. The problem is that we don’t know the distribution from the iostat output, or any similar latency average. There could be latency outliers present, which is not visible in the average, and yet are causing problems. The heat map did show I/O up to 50 ms, which you might not have expected from that iostat output. There could also be multiple modes, as we saw in the heat map, which are also not visible in an average.这个工作负载的平均I/O时间(等待)为9毫秒，这听起来像是在7200 RPM磁盘上相当随机的工作负载。问题是我们不知道iostat输出的分布情况，也不知道任何类似的延迟平均值。可能存在延迟异常值，这在一般情况下是不可见的，但却会导致问题。热图显示I/O最高可达50毫秒，这可能是iostat输出所没有预料到的。也可以有多种模式，正如我们在热图中看到的那样，在平均模式中也不可见。 GatheringI used perf_events to record the block request (disk I/O) issue and completion static tracepoints:我使用perf_events 记录 block_rq_issue(磁盘I/O)和 block_rq_complete 跟踪点: 123456789101112131415# perf record -e block:block_rq_issue -e block:block_rq_complete -a sleep 120[ perf record: Woken up 36 times to write data ][ perf record: Captured and wrote 8.885 MB perf.data (~388174 samples) ]# perf script[...] randread.pl 2522 [000] 6011.824759: block:block_rq_issue: 254,16 R 0 () 7322849 + 16 [randread.pl] randread.pl 2520 [000] 6011.824866: block:block_rq_issue: 254,16 R 0 () 26144801 + 16 [randread.pl] swapper 0 [000] 6011.828913: block:block_rq_complete: 254,16 R () 31262577 + 16 [0] randread.pl 2521 [000] 6011.828970: block:block_rq_issue: 254,16 R 0 () 70295937 + 16 [randread.pl] swapper 0 [000] 6011.835862: block:block_rq_complete: 254,16 R () 26144801 + 16 [0] randread.pl 2520 [000] 6011.835932: block:block_rq_issue: 254,16 R 0 () 5495681 + 16 [randread.pl] swapper 0 [000] 6011.837988: block:block_rq_complete: 254,16 R () 7322849 + 16 [0] randread.pl 2522 [000] 6011.838051: block:block_rq_issue: 254,16 R 0 () 108589633 + 16 [randread.pl] swapper 0 [000] 6011.850615: block:block_rq_complete: 254,16 R () 108589633 + 16 [0][...] The full output from perf script is about 70,000 lines. I’ve included some here so that you can see the kind of data available.perf脚本的完整输出约为70,000行。我在这里添加了一些这样你就能看到可用的数据。 ProcessingTo calculate latency for each I/O, I’ll need to pair up the issue and completion events, so that I can calculate the timestamp delta. The columns look straightforward (and are in include/trace/events/block.h), with the 4th field the timestamp in seconds (with microsecond resolution), the 6th field the disk device ID (major, minor), and a later field (which varies based on the tracepoint) has the disk offset. I’ll use the disk device ID and offset as the unique identifier, assuming the kernel will not issue concurrent I/O to the exact same location.为了计算每个I/O的延迟，我需要将问题事件和完成事件配对，以便计算时间戳增量。这些列看起来很简单(位于include/trace/events/block.h中)，第4个字段是时间戳(以秒为单位)，第6个字段是磁盘设备ID(主、次)，后面的字段(根据跟踪点变化)是磁盘偏移量。我将使用磁盘设备ID和偏移量作为唯一标识符，假设内核不会向完全相同的位置发出并发I/O。 I’ll use awk to do these calculations and print the completion times and latency:我将使用awk来做这些计算，并打印完成时间和延迟:1234567891011# perf script | awk '&#123; gsub(/:/, "") &#125; $5 ~ /issue/ &#123; ts[$6, $10] = $4 &#125; $5 ~ /complete/ &#123; if (l = ts[$6, $9]) &#123; printf "%.f %.f\n", $4 * 1000000, ($4 - l) * 1000000; ts[$6, $10] = 0 &#125; &#125;' &gt; out.lat_us# more out.lat_us6011793689 84376011797306 34886011798851 12836011806422 112486011824680 182106011824693 21908[...] I converted both columns to be microseconds, to make the next step easier.我将两个列都转换为微秒，以使下一步更容易。 GenerationNow I can use my trace2heatmap.pl program (github), to generate the interactive SVG heatmap from the trace data (and uses microseconds by default):现在我可以使用我的trace2heatmap.pl程序(github)，从跟踪数据生成交互式SVG热图(默认使用微秒):1# ./trace2heatmap.pl --unitstime=us --unitslat=us --maxlat=50000 out.lat_us &gt; out.svg When I generated the heatmap, I truncated the y scale to 50 ms. You can adjust it to suit your investigation, increasing it to see more of the latency outliers, or decreasing it to reveal more resolution for the lower latencies: for example, with a 250 us limit.当我生成热图时，我将y刻度缩短到50毫秒。您可以调整它以适应您的调查，增加它以查看更多的延迟异常值，或者减少它以显示更低延迟的更高分辨率:例如，使用250 us的限制。 OverheadsWhile this can be useful to do, be mindful of overheads. In my case, I had a low rate of disk I/O (~300 IOPS), which generated an 8 Mbyte trace file after 2 minutes. If your disk IOPS were 100x that, your trace file will also be 100x, and the overheads for gathering and processing will add up.虽然这样做很有用，但要注意日常开销。在我的例子中，我的磁盘I/O率很低(~300 IOPS)，这在2分钟后生成了一个8兆字节的跟踪文件。如果您的磁盘IOPS是它的100倍，那么跟踪文件也将是100倍，收集和处理的开销将会增加。 For more about latency heatmaps, see my LISA 2010 presentation slides, and my CACM 2010 article, both about heat maps. Also see my Perf Heat Maps blog post.有关延迟热图的更多信息，请参阅我的LISA 2010演示幻灯片和我的CACM 2010文章，都是关于热图的。也可以查看我的Perf Heat Maps博客文章。 8. TargetsNotes on specific targets. Under construction. 8.1. Java8.2. Node.jsNode.js V8 JIT internals with annotation support https://twitter.com/brendangregg/status/755838455549001728js V8 JIT内部注释支持 https://twitter.com/brendangregg/status/755838455549001728 9. MoreThere’s more capabilities to perf_events than I’ve demonstrated here. I’ll add examples of the other subcommands when I get a chance.perf_events的功能比我在这里演示的更多。如果有机会，我将添加其他子命令的示例。 Here’s a preview of perf trace, which was added in 3.7, demonstrated on 3.13.1:下面是perf trace的预览，它是在3.7中添加的，在3.13.1中演示:1234567891011121314151617181920212223# perf trace ls 0.109 ( 0.000 ms): ... [continued]: read()) = 1 0.430 ( 0.000 ms): ... [continued]: execve()) = -2 0.565 ( 0.051 ms): execve(arg0: 140734989338352, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.697 ( 0.051 ms): execve(arg0: 140734989338353, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.797 ( 0.046 ms): execve(arg0: 140734989338358, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 0.915 ( 0.045 ms): execve(arg0: 140734989338359, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 1.030 ( 0.044 ms): execve(arg0: 140734989338362, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 1.414 ( 0.311 ms): execve(arg0: 140734989338363, arg1: 140734989358048, arg2: 40612288, arg3: 1407... 2.156 ( 1.053 ms): ... [continued]: brk()) = 0xac9000 2.319 ( 1.215 ms): ... [continued]: access()) = -1 ENOENT No such file or directory 2.479 ( 1.376 ms): ... [continued]: mmap()) = 0xb3a84000 2.634 ( 0.052 ms): access(arg0: 139967406289504, arg1: 4, arg2: 139967408408688, arg3: 13996740839... 2.787 ( 0.205 ms): ... [continued]: open()) = 3 2.919 ( 0.337 ms): ... [continued]: fstat()) = 0 3.049 ( 0.057 ms): mmap(arg0: 0, arg1: 22200, arg2: 1, arg3: 2, arg4: 3, arg5: 0 ) = 0xb3a... 3.177 ( 0.184 ms): ... [continued]: close()) = 0 3.298 ( 0.043 ms): access(arg0: 139967406278152, arg1: 0, arg2: 6, arg3: 7146772199173811245, arg4... 3.432 ( 0.049 ms): open(arg0: 139967408376811, arg1: 524288, arg2: 0, arg3: 139967408376810, arg4:... 3.560 ( 0.045 ms): read(arg0: 3, arg1: 140737350651528, arg2: 832, arg3: 139967408376810, arg4: 14... 3.684 ( 0.042 ms): fstat(arg0: 3, arg1: 140737350651216, arg2: 140737350651216, arg3: 354389249727... 3.814 ( 0.054 ms): mmap(arg0: 0, arg1: 2221680, arg2: 5, arg3: 2050, arg4: 3, arg5: 0 ) = 0xb36...[...] An advantage is that this is buffered tracing, which costs much less overhead than strace, as I described earlier. The perf trace output seen from this 3.13.1 kernel does, however, looks suspicious for a number of reasons. I think this is still an in-development feature. It reminds me of my dtruss tool, which has a similar role, before I added code to print each system call in a custom and appropriate way.一个优点是这是缓冲跟踪，它的开销比我前面描述的strace小得多。但是，这个3.13.1内核的perf跟踪输出看起来很可疑，原因有很多。我认为这仍然是一个正在开发的特性。这让我想起了dtruss工具，它具有类似的作用，在添加代码以自定义和适当的方式打印每个系统调用之前。 10. BuildingThe steps to build perf_events depends on your kernel version and Linux distribution. In summary:构建perf_events的步骤取决于您的内核版本和Linux发行版。总而言之: Get the Linux kernel source that matches your currently running kernel (eg, from the linux-source package, or kernel.org). Unpack the kernel source. cd tools/perf make Fix all errors, and most warnings, from (4). The first error may be that you are missing make, or a compiler (gcc). Once you have those, you may then see various warnings about missing libraries, which disable perf features. I’d install as many as possible, and take note of the ones you are missing.第一个错误可能是您缺少make或编译器(gcc)。一旦有了这些，您可能会看到各种关于丢失库的警告，这些库会禁用perf特性。我会安装尽可能多的，并注意那些你没有安装的。 These perf build warnings are really helpful, and are generated by its Makefile. Here’s the makefile from 3.9.3:这些perf构建警告非常有用，是由它的Makefile生成的。下面是来自3.9.3的makefile:12345678910111213# grep found Makefilemsg := $(warning No libelf found, disables 'probe' tool, please install elfutils-libelf-devel/libelf-dev);msg := $(error No gnu/libc-version.h found, please install glibc-dev[el]/glibc-static);msg := $(warning No libdw.h found or old libdw.h found or elfutils is older than 0.138, disables dwarf support. Please install new elfutils-devel/libdw-dev);msg := $(warning No libunwind found, disabling post unwind support. Please install libunwind-dev[el] &gt;= 0.99);msg := $(warning No libaudit.h found, disables 'trace' tool, please install audit-libs-devel or libaudit-dev);msg := $(warning newt not found, disables TUI support. Please install newt-devel or libnewt-dev);msg := $(warning GTK2 not found, disables GTK2 support. Please install gtk2-devel or libgtk2.0-dev);$(if $(1),$(warning No $(1) was found))msg := $(warning No bfd.h/libbfd found, install binutils-dev[el]/zlib-static to gain symbol demangling)msg := $(warning No numa.h found, disables 'perf bench numa mem' benchmark, please install numa-libs-devel or libnuma-dev); Take the time to read them. This list is likely to grow as new features are added to perf_events.花点时间来阅读它们。随着perf_events添加新特性，这个列表很可能会增长。 The following notes show what I’ve specifically done for kernel versions and distributions, in case it is helpful.下面的说明展示了我针对内核版本和发行版所做的具体操作，如果有帮助的话。 Packages: Ubuntu, 3.8.6Packages required for key functionality: gcc make bison flex elfutils libelf-dev libdw-dev libaudit-dev. You may also consider python-dev (for python scripting) and binutils-dev (for symbol demangling), which are larger packages.关键功能所需的包:gcc make bison flex elfutils libelf-dev libdwi -dev libaudit-dev。您还可以考虑python-dev(用于python脚本)和binutil-dev(用于符号拆分)，它们是更大的包。 Kernel Config: 3.8.6Here are some kernel CONFIG options for perf_events functionality:下面是perf_events功能的一些内核配置选项:123456789101112131415161718192021222324# for perf_events:CONFIG_PERF_EVENTS=y# for stack traces:CONFIG_FRAME_POINTER=y# kernel symbols:CONFIG_KALLSYMS=y# tracepoints:CONFIG_TRACEPOINTS=y# kernel function trace:CONFIG_FTRACE=y# kernel-level dynamic tracing:CONFIG_KPROBES=yCONFIG_KPROBE_EVENTS=y# user-level dynamic tracing:CONFIG_UPROBES=yCONFIG_UPROBE_EVENTS=y# full kernel debug info:CONFIG_DEBUG_INFO=y# kernel lock tracing:CONFIG_LOCKDEP=y# kernel lock tracing:CONFIG_LOCK_STAT=y# kernel dynamic tracepoint variables:CONFIG_DEBUG_INFO=y You may need to build your own kernel to enable these. The exact set you need depends on your needs and kernel version, and list is likely to grow as new features are added to perf_events.您可能需要构建自己的内核来启用这些功能。您需要的具体设置取决于您的需求和内核版本，随着perf_events添加新特性，列表可能会增长。 10.1. Static BuildsI’ve sometimes done this so that I have a single perf binary that can be copied into Docker containers for execution. Steps, given the Linux source:我有时这样做，以便我有一个单一的perf二进制文件，可以复制到Docker容器中执行。Steps, given the Linux source: 1234cd tools/perfvi Makefile.perf LDFLAGS=-staticmake clean; make 11. TroubleshootingIf you see hexadecimal numbers instead of symbols, or have truncated stack traces, see the Prerequisites section.如果您看到的是十六进制数字而不是符号，或已截断堆栈跟踪，请参阅先决条件部分。 Here are some rough notes from other issues I’ve encountered.以下是我遇到的其他问题的一些梗概。 This sometimes works (3.5.7.2) and sometimes throws the following error (3.9.3):这有时工作(3.5.7.2)，有时抛出以下错误(3.9.3): 1234ubuntu# perf stat -e 'syscalls:sys_enter_*' -a sleep 5Error:Too many events are opened.Try again after reducing the number of events. This can be fixed by increasing the file descriptor limit using ulimit -n.这可以通过使用ulimit -n增加文件描述符限制来解决。 Type 3 errors:1234567891011121314151617181920212223ubuntu# perf report0xab7e48 [0x30]: failed to process type: 3# ========# captured on: Tue Jan 28 21:08:31 2014# hostname : pgbackup# os release : 3.9.3-ubuntu-12-opt# perf version : 3.9.3# arch : x86_64# nrcpus online : 8# nrcpus avail : 8# cpudesc : Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz# cpuid : GenuineIntel,6,45,7# total memory : 8179104 kB# cmdline : /lib/modules/3.9.3-ubuntu-12-opt/build/tools/perf/perf record -e sched:sched_process_exec -a # event : name = sched:sched_process_exec, type = 2, config = 0x125, config1 = 0x0, config2 = 0x0, excl_usr = 0, excl_kern = 0, excl_host = 0, excl_guest = 1, precise_ip = 0# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, tracepoint = 2, breakpoint = 5# ========#Warning: Timestamp below last timeslice flush 12. Other Toolsperf_events has the capabilities from many other tools rolled into one: strace(1), for tracing system calls, tcpdump(8), for tracing network packets, and blktrace(1), for tracing block device I/O (disk I/O), and other targets including file system and scheduler events. Tracing all events from one tool is not only convenient, it also allows direct correlations, including timestamps, between different instrumentation sources. Unlike these other tools, some assembly is required, which may not be for everyone (as explained in Audience).perf_events可以将许多其他工具的功能集成在一起:strace(1)用于跟踪系统调用，tcpdump(8)用于跟踪网络包，blktrace(1)用于跟踪块设备I/O(磁盘I/O)，以及其他目标，包括文件系统和调度器事件。跟踪来自一个工具的所有事件不仅方便，而且还允许不同检测源之间的直接关联，包括时间戳。与这些其他工具不同，需要进行一些组装，这可能不适用于每个人(就像在Audience解释的那样)。 13. ResourcesResources for further study.用于进一步研究的资源。 13.1. PostsI’ve been writing blog posts on specific perf_events topics. My suggested reading order is from oldest to newest (top down):我一直在写关于特定perf_events主题的博客文章。我建议的阅读顺序是从老到新(自上而下): 22 Jun 2014: perf CPU Sampling 29 Jun 2014: perf Static Tracepoints 01 Jul 2014: perf Heat Maps 03 Jul 2014: perf Counting 10 Jul 2014: perf Hacktogram 11 Sep 2014: Linux perf Rides the Rocket: perf Kernel Line Tracing 17 Sep 2014: node.js Flame Graphs on Linux 26 Feb 2015: Linux perf_events Off-CPU Time Flame Graph 27 Feb 2015: Linux Profiling at Netflix 24 Jul 2015: Java Mixed-Mode Flame Graphs (PDF) 30 Apr 2016: Linux 4.5 perf folded format And posts on ftrace:和关于ftrace的文章 13 Jul 2014: Linux ftrace Function Counting 16 Jul 2014: iosnoop for Linux 23 Jul 2014: Linux iosnoop Latency Heat Maps 25 Jul 2014: opensnoop for Linux 28 Jul 2014: execsnoop for Linux: See Short-Lived Processes 30 Aug 2014: ftrace: The Hidden Light Switch 06 Sep 2014: tcpretrans: Tracing TCP retransmits 31 Dec 2014: Linux Page Cache Hit Ratio 28 Jun 2015: uprobe: User-Level Dynamic Tracing 03 Jul 2015: Hacking Linux USDT 13.2. Linksperf_events: perf-tools (github), a collection of my performance analysis tools based on Linux perf_events and ftrace. perf Main Page. The excellent perf Tutorial, which focuses more on CPU hardware counters. The Unofficial Linux Perf Events Web-Page by Vince Weaver. The perf user mailing list. Mischa Jonker’s presentation Fighting latency: How to optimize your system using perf (PDF) (2013). The OMG SO PERF T-shirt (site has coarse language). Shannon Cepeda’s great posts on pipeline speak: frontend and backend. Jiri Olsa’s dwarf mode callchain patch. Linux kernel source: tools/perf/Documentation/examples.txt. Linux kernel source: tools/perf/Documentation/perf-record.txt. … and other documentation under tools/perf/Documentation. A good case study for Transparent Hugepages: measuring the performance impact using perf and PMCs. Julia Evans created a perf cheatsheet based on my one-liners (2017). ftrace: perf-tools (github), a collection of my performance analysis tools based on Linux perf_events and ftrace. Ftrace: The hidden light switch, by myself for lwn.net, Aug 2014. Linux kernel source: Documentation/trace/ftrace.txt. lwn.net Secrets of the Ftrace function tracer, by Steven Rostedt, Jan 2010. lwn.net Debugging the kernel using Ftrace - part 1, by Steven Rostedt, Dec 2009. lwn.net Debugging the kernel using Ftrace - part 2, by Steven Rostedt, Dec 2009.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Brendan Gregg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6. redis 拓展篇]]></title>
    <url>%2F2020%2F05%2F06%2Fredis%2F06_%E6%BA%90%E7%A0%81%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis 源码 1. 集群篇概述拓展篇我们将介绍 Redis 各种数据结构的实现 字符串 dict 压缩列表: intset 快速列表: ziplist 跳表: skiplist 紧凑列表: 基数树 LFU 和 LRU 惰性删除 字段遍历 2. 字符串Redis 的字符串叫做 SDS(Simple Dynamic String)，它的结构是一个带长度信息的字节数组: 123456struct SDS&lt;T&gt; &#123; T capacity; // 数组容量 T len; // 数组长度 byte flags; // 特殊标志位 byte[] content; // 数组内容&#125; 上面的 SDS 结构使用了泛型 T，为什么不用 int，是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示。Redis 规定字符串的长度不得超过 512MB。 2.1 embstr 和 rawRedis 的字符串有两种存储形式: embstr: 长度特别短时(小于等于 44 字节) raw: 长度超过 44 字节时 12&gt; set codehole abcdg&gt; debug object codehole RedisObject为了解释这个现象，我们首先需要了解 Redis 对象头结构，所有的 Redis 对象都有下面的头结构: type: 4bit，不同的对象具有不同的类型 type encoding: 4bit，同一类型的 type 会有不同的存储形式 encoding lru: 24bit，记录了对象的 LRU 信息 refcount: 4bytes，对象的引用计数，为 0 时，对象就会被销毁 ptr: 32bit/64-bit，指向对象内容的具体存储位置 RedisObject 对象头结构需要占据 16 字节的存储空间。 1234567struct RedisObject &#123; int4 type; int4 encoding; int24 lru; int32 refcount; void *ptr; &#125; robj; 正因为有了 RedisObject 对象头结构，当存储的值是数值时，type 可以指向对应的数值类型，从而将值保存为数值。当把数值修改成字符串时，值将自动转换成字符串的保存形式。 12345678910&gt; set numberStr 1&gt; object encoding numberStr"int"&gt; append numberStr a&gt; get numberStr"1a"&gt; object encoding numberStr"raw" SDS我们再看 SDS 结构体大小，在字符串比较小时，SDS 对象头结构的大小是 capacity+3，至少是 3 字节。意味着分配一个字符串最小空间为 19(16 + 3)字节。 123456struct SDS &#123; int8 capacity; int8 len; int8 flags; byte[] content;&#125; embstr 存储形式它将 RedisObject对象头结构和 SDS 对象连续存在一起，使用 malloc 一次分配。raw 则需要使用两次 malloc，两个对象头在内存地址上一般是不连续的。 embstr 对于 embstr，由于其实现是只读的，因此在对 embstr 对象进行修改时，都会先转化为 raw 再进行修改。因此，只要是修改 embstr 对象，修改后的对象一定是 raw 的，无论是否达到了 44个字节。 rawjemalloc/tcmalloc 分配内存大小的单位都是 2/4/8/16/32/64。string 最小空间为 19字节，所以为了容纳一个完整的 embstr，jemalloc 至少会分配 32 字节的空间，至多分配 64 字节的空间。如果字符串超过 64 字节，Redis 就会认为这是一个大字符串，不适合使用 embstr 存储，而应该使用 raw。 又因为 SDS 结构中 content 存储的字符串是以字节 NULL 结尾的(目的是为了便于直接使用 glibc 的字符串处理函数，以及为了便于字符串的调试打印输出)。所以 content 的最大长度 = 64 - 19 - 1 = 44。 2.2 字符串扩容Redis中的字符串是可修改的，小于 1MB 前，扩容采用加倍策略，超过1MB后，每次扩容增加 1MB。 3. dictdict 在 Redis 中帮助实现了下面这些结构: hash/set zset 集合中 value 和 score 值的映射关系 整个 Redis 数据库的 key-value 存储在一个全局 dict 中 带过期时间的 key 集合也是一个字典 123456789struct RedisDb &#123; dict* dict; //all keys key=&gt;value dict* expires; // all expired keys key=&gt;long(timestamp) &#125;struct zset &#123; dict *dict; // all values value=&gt;score zskiplist *zsl;&#125; 3.1 dict 内部结构1234struct dict &#123; .... dictht ht[2]&#125; 如上图所示，为了渐进式 rehash，dict 结构的内部包含两个 hashtable(ht[2])。HashTable 与我们正常实现的 hashmap 几乎一样: 使用链表法解决哈希冲突 使用渐进rehash，避免大字典扩容造成了单线程的Redis 停止响应。有客户端访问，redis 后台的定时任务都会进行字典的 rehash 默认的哈希函数是 siphash，siphash 算法即使在输入 key 很小的情况下，也可以产生随机性特别好的输出，并且性能非常优秀 扩容条件: 正常情况下，负载因子为 1 即开始扩容 如果 Redis 正在做 bgsave，为了减少内存页的过多分离，Redis会尽量不做扩容，但是如果负载因子达到 5，会强制扩容 缩容条件是负载因子小于 0.1 3.2 setset 的底层实现也是字典，只不过所有的 value 都是 NULL。 4. 小对象存储如果 Redis 内部管理的集合数据结构很小，它会使用紧凑存储形式压缩存储，包括 ziplist 和 intset 4.1 ziplist ziplist 的数据结构如上图所示，它是一个紧凑的字节数组，是 hash、zset 小数据集存储数据结构 存储 hash 时: key 和value会被作为两个 entry 相邻存储 存储 zset 时: value 和 score 作为两个 entry 相邻存储 1234567&gt; hset hello a 1&gt; object encoding hello"ziplist"&gt; zadd world 2 b&gt; object encoding world"ziplist" ziplist 实现细节12345678910111213struct ziplist&lt;T&gt; &#123; int32 zlbytes; // 压缩列表占用字节数 int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量 int16 zllength; // 元素个数 T[] entries; // 元素内容列表 int8 zlend; // 标志压缩列表的结束，值恒为 0xFF&#125;struct entry &#123; int&lt;var&gt; prevlen; // 前一个entry的字节长度 int&lt;var&gt; encoding; // 元素类型编码 optional byte[]; // 元素内容&#125; ziplist 的内部结构如上: ziplist 为了支持双向遍历，才有了 ztail_offset，用于快速定位最后的元素 entry 随着容纳的元素类型不同而不同 prevlen 表示前一个entry 长度，向后遍历时需要，int&lt;var&gt; 表示是一种特殊类型的变长整数(要么为一个字节，还要么就是 5 个字节) encoding 存储接下来的元素内容的编码类型信息，ziplist 通过这个字段决定后面的 content 形式 entry encodingRedis 为了节约空间，对 entry 的 encoding 字段进行了相当复杂的设计。通过这个字段的前缀位来识别具体存储的数据形式: 字符串和数值 字符串的格式如下: 00xxxxxx: 后面 6 位存储字符串长度，字符串的最大长度为 63 01xxxxxx xxxxxxx:后面 14 位存储字符串长度 10000000 xxxxxxx xxxxxxx xxxxxxx xxxxxxx: 特大字符串，4 个字节表示长度 这样大的字符串是没有机会使用的，因为 ziplist 只用来存储小数据 数值的格式如下: 首字节标识 encoding 长度 数值长度 描述 11000000 3 bytes 2 bytes int16_t 11010000 5 bytes 4 bytes int32_t 11100000 9 bytes 8 bytes int64_t 11110000 4 bytes 3 bytes int24 11111110 2 bytes 1 byte int8 11111111 1 byte 0 bit 列表结束符，也就是 zlend 的值0xFF 1111xxxx 1 byte 4 bits4 极小整数, 可以存储 0 - 12， 因为 0000，1110，1111 不能使用，只能存储 1 - 13，所以保存进来的数字进行 + 1 操作，解析后需要 -1 content 字段的类型是 optional，表示字段是可选的，因为很小的整数已经保存在 encoding 中。 ziplist 弊端因为 ziplist 是紧凑存储，没有冗余空间，这意味修改字符串(扩大)、插入新元素就需要调用 relloc 扩展内存。如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大消耗，所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。 因为每个 entry 的 prevlen 都是边长类型，如果内从小于254，prevlen 就用 1 字节存储。否则就用 5 字节存储。这意味着如果前一个元素长度从 253 变成 254 后面的 entry 也需要扩展，极端情况下会导致级联更新。 4.2 intsetintset 是一个紧凑的整数数组结构，用于存储元素都是整数且个数较少的 set 集合。 12345struct intset&lt;T&gt;&#123; int32 encoding; // 决定整数位是 16位、32位、64位 int32 length; // 元素个数 int&lt;T&gt; contents; // 整数数组&#125; intset 的数据结构如上图图所示: 如果整数可以用 uint16 表示，intset 就是 16位的数组 如果超过 uint16 就使用 uint32，intset 就是 32 位的数组 Redis 支持 set 集合动态从 uint16 –&gt; uint32 –&gt; uint64 转换 如果 set 存储的是字符串，set 立即升级为 hashtable 1234567&gt; sadd hello 1 2 3&gt; object encoding hellointset&gt; sadd hello yes no&gt; object encoding hellohashtable 4.3 小对象存储的限制条件当集合对象的元素不断增加，或者某个 value 值过大，这种小对象存储就会被升级为标准结构。Redis 规定的小对象存储结构的限制条件如下: 1234567hash-max-ziplist-entries 512 # hash 的元素个数超过 512 就必须用标准结构存储hash-max-ziplist-value 64 # hash 的任意元素的 key/value 的长度超过 64 就必须用标准结构存储list-max-ziplist-entries 512 # list 的元素个数超过 512 就必须用标准结构存储list-max-ziplist-value 64 # list 的任意元素的 key/value 的长度超过 64 就必须用标准结构存储zset-max-ziplist-entries 128 # zset 的元素个数超过 128 就必须用标准结构存储zset=max-ziplist-value 64 # zset 的任意元素的长度超过 64 就必须用标准结构存储set-max-intset-entries 512 # set 的证书元素个数超过 512 就必须用标准结构存储 5. quicklist早期 Redis list 使用的是压缩列表和普通的双向链表(linkedlist)，考虑到双向链表的存储效率问题(指针占据大量空间)，Redis 使用 quicklist 代替了 ziplist 和 linkedlist quicklist 则是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 存储，多个 ziplist 使用双向指针连接。 quicklist 内部默认单个 ziplist 长度为 8KB，如果超过这个字节数，就会另起一个 ziplist。ziplist 的长度由配置参数 list-max-ziplist-size 决定。 为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 压缩算法，可以选择压缩深度。压缩的实际深度由配置参数 list-compress-depth 决定。所谓压缩深度值的是，从首位第 n 个ziplist 之后开始压缩。比如压缩深度为 1，表示从quicklist 首位第二个 ziplist 开始压缩。为了支持快速的 push/pop 操作，可以调大压缩深度。 6. skiplistRedis 的 zset 是一个复合结构: dict: 存储 value 与 score 的对应关系 skiplist: 跳表 按照 score 排序 指定 score 的范围获取 value 获取 value 的排名 1234567891011121314151617struct zset &#123; dict *dict; // all values value=&gt;score zskiplist *zsl;&#125;struct zslode &#123; string value; double score; zslnode* [] forwards; // 多层连接指针 zslnode* backword; // 回溯指针&#125;struct zsl &#123; zslnode* header; // 跳表投指针 int maxLevel; // 跳表当前的最高层 map &lt;string, zslnode*&gt; ht; // hash 结构的所有键值对&#125; Redis 实现的跳表中: 最大有 64 层 zset 排序时，不只看 score 值，score 值相同时，还会比较 value，以避免 score 都相同导致的性能退化 为了获取排名 rank，Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属性，表示从前一个节点沿着当前层的forward 指针调到当前这个节点中间跳过了多少个节点。在插入和删除的过程中都会更新 span 值的大小。这样当我们要计算一个元素的排名时，只需要将搜索过程中的所有节点的跨度 span 累计起来就可以得到 1234567891011struct zslforward &#123; zslnode* item; long span;&#125;struct zslode &#123; string value; double score; zslforward* [] forwards; // 多层连接指针 zslnode* backword; // 回溯指针&#125; 7. 紧凑列表Redis5.0 引入了新的数据结构 listpack，它是对 ziplist 结构的改进。 123456789101112struct listpack&lt;T&gt; &#123; int32 total_bytes; // 占用的总字节数 int16 size; // 元素个数 T[] entries; // 紧凑元素列表 int8 end; // 同 zlend 一样，恒为 0xFF&#125;struct lpentry&#123; int&lt;var&gt; encoding; optional byte[] content; int&lt;var&gt; length;&#125; 与 ziplist 的元素相比，listpack 的 entry 将长度字段放在元素的结尾，并且存储的是本元素的长度，而不是上一个元素。 正因为将长度放在了结尾，所以可以省去用于标记最后一个元素位置的 zltail_offset 字段。最后一个元素的位置可以通过 total_bytes 字段和最后一个元素的长度计算出来。 除此之外与 ziplist 相比 listpack 还有如下特点: 长度字段使用 varint 变长整数编码(这是通用的变长类型) listpack 的 encoding 也进行了复杂的设计，大体上与 ziplist 的 encoding 类似 listpack 的设计彻底消灭了 ziplist 存在的级联更新，元素之间完全独立，不会因为一个元素的长度变长导致后续的元素内容收到影响。 8. 基数树rax 是Redis 内部比较特殊的数据结构，它是一个有序字典树(又称基数树 Radix Tree，它与 Trie Tree很相似)，按照 key 的字典序排列，支持快速定位、插入、删除操作。 rax 的应用如下: Redis Stream 里: 被用于存储消息队列， 在 Stream 里面消息ID 的前缀是时间戳+序号，使用 rax 进行存储就可以快速根据消息ID 定位消息，然后继续遍历指定消息之后的所有消息 在 Redis Cluster 里: 被用于记录槽位和key的对应关系 raxNode 的key是槽位编号 hashslot 和 key 的组合 因为 rax 的key 是按照 key 前缀顺序挂载的，意味着同样的 hashslot 的对象key会挂在同一个 raxNode下面。这样就可以快速遍历具体槽位下面的所有对象key rax 在 Redis 中的实现比较复杂，我们暂时不在详述。 说明: Radix Tree 和 Trie Tree 都是二叉树，因此通过中序遍历就可以按序输出。 参考 wiki.shileizcc]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5. redis 拓展篇]]></title>
    <url>%2F2020%2F05%2F05%2Fredis%2F05_%E6%8B%93%E5%B1%95%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis 拓展应用 1. 拓展篇概述拓展篇我们将介绍基于 Redis 的扩展应用 Stream 消息流 Info 指令，Redis 的监测 分布式锁的实现 Redis 的惰性删除 Redis 的加密 2. 消息队列通过 List 实现的消息队列支持只有一组消费着，没有 ack 保证，不支持多播，消息无法持久化。为了解决这些问题，Redis 陆续引入了不同的消息队列实现。本节我们就来介绍 Redis 中队列实现的多种方式，包括: list 实现的消息队列 zset 实现的延时队列 pubsub 发布订阅 Stream 2.1 Redis List 消息队列最简单的消息队列，通过 list 和 list 操作指令(rpush，lpush，rpop，lpop) 实现。rpop，lpop 在 list 为空时会造成忙等待。Redis 提供了对应的阻塞读版本: blpop，brpop，这两个指令在list 为空时就会阻塞等待。这就是所谓的长轮询优化。 需要注意的是被 block 住的空闲连接可能会被服务器端断开，因此使用 brpop，blpop 时需要捕获连接异常并重试。 2.2 延时队列延时队列需要记录消息的到期处理时间，以便及时对消息进行处理。可以通过 zset 来实现延时队列，将消息序列化成一个字符串作为 zset 的 value，到期处理时间作为 score。然后用多个线程轮询 zset 获取到期的任务进行处理。因为使用了多线程，此时需要考虑并发争抢，确保任务不会被多次执行。下面是实现的一个 demon 1234567891011def loop(): while 1: values = redis.zrangebyscore("delay-queue", 0, time.time(), start=0, num=1) if not values: time.sleep(1) continue value = values[0] success = redis.zrem("delay-queue", value) if success: msg = json.load(value) handle_msg(msg) 这个示例通过判断 zrem 有没有成功删除消息的方式来判断是否成功抢占任务，来避免多次执行一个任务。那些没有抢到的进程都白取了一次任务，可以考虑使用 lua 脚本来优化这个逻辑，将zrangebyscore 和 zrem 放到服务器端进行原子化操作，这样多个进程抢占任务就不会出现浪费了。 2.2 pubsub(发布/订阅)list 实现的消息队列只支持一组消费者，不支持消息的多播(扇出)。Redis 使用了一个单独的模块来支持多个消费者组，叫做 PubSub。下面是 PubSub 使用的 Python 代码示例: 1234567891011121314151617# 发布client = redis.StrictRedis()client.publish("code", "python")# 订阅-非阻塞client = redis.StrictRedis()p = client.pubsub()p.subscribe("code")while True: msg = p.get_message() # 非阻塞的# 订阅-阻塞client = redis.StrictRedis()p = client.pubsub()p.subscribe("code")for msg in p.listen(): # 阻塞监听 print(msg) Redis 支持对主题名称使用模糊匹配来订阅多个主题。如果生产者新增了同模式的主题，消费者可以立即收到消息，无须额外的订阅指令。 1&gt; psubscribe code* pubsub 的缺点pubsub 的消息是不会持久化的: 如果消息没有对应的消费者，那么消息会被直接丢弃 如果有多个消费者，其中一个消费者中间迭机掉线，等到它从新上线之间的所有消息，对于这个消费者就彻底丢失了 所以 Redis 的 pubsub 没有太多合适的适用场景。 2.3 StreamStream 结构Stream支持多播的可持久化消息队列。其结构如下图所示: Stream: 是一个消息链表，具有唯一的名称(Redis key)，消息是持久化的 每个消息都有唯一的ID 每个 Stream 支持多个消费组 消费组: 每个消费组会有一个游标 last_delivered_id 表示当前已经消费到哪条消息 每个消费组都有一个 Stream 内唯一名称 通过 xgroup create 创建消费者组，需要指定从哪个消息ID开始消费，这个ID用来初始化 last_delivered_id 同一个消费组支持多个消费者 消费者: 消费者之间属于竞争关系 每个消费者在组内唯一 消费者内部会有一个状态变量 pending_ids，记录了被客户端读取，但还没有 ack 的消息。 pending_ids 用来确保客户端至少消费了一次消息 pending_id是变量被Redis 称为 PEL Stream 操作消息的增删改查指令如下: xadd: 向Stream 追加消息，提供了一个定长参数 maxlen，超过长度的老消息会被彻底删除 xdel: 标记删除 xrange: 按范围获取消息，自动过滤已经删除的消息 xlen: 获取Stream 消息的长度 del: 删除整个 Stream 消息列表中是所有消息 xinfo: 获取 stream 信息 12# * 表示自动生成消息ID&gt; xadd codehole maxlen 3 * name xiaoshuo 消费组指令: xgroup read: 创建消费组 xreadgroup: 消费者组的组内消费 组内消费的消息ID 一般设置为 0-0，表示读取所有 PEL 消息以及自 last_delivered_id 之后的新消息 xack: 确认消息 Stream 在每个消费者结构中保存了正在处理中的消息ID列表 PEL，如果消费者收到消息，处理完成但是没有回复 ack，PEL就会不断增大，从而占用越来越多的内存，因此消息必须 ack 123&gt; xgroup create codehole cg1 0-0 # 0-0 用于初始化 last_delivered_id&gt; xreadgroup GROUP cg2 c1 count 1 stream codehole 0-0 # 0-0 组内消费的起始 ID&gt; xack codehole cg1 ID1 ID2 独立消费者使用 xread 可以定义独立消费者，在没有消费组的情况下直接读取Stream 中的消息。独立消费者将Stream 当做消息队列 list 来使用，设置可以在没有消息时阻塞等待。 客户端使用 xread 顺序消费是一定要保存 xread 返回的消息ID，下次调用时需要将此 ID 当做 xread 参数传入以便继续消费后面的消息。 123456# 从头部读取消息&gt; xread count 1 stream code 0-0 # 从尾部读取消息，只接受新消息&gt; xread count 1 stream code $# 阻塞读取&gt; xread block 0 count 1 stream code $ 分区Redis 不支持消息分区，只能在客户端通过生产和消费多个 Stream 来手动分区。 Kafka 支持 Partition，与 Redis 类似，Kafka 也是通过客户端的 hash 算法来将不同的消息塞入到不同的分区。这个实现方式与 Redis 的生产消费多个 Stream 是类似的。但是显然 kafka 的机制更加完善，因为分区不仅仅是消息的分区分配问题，分区通常都会有多个副本，这就涉及到 leader 副本的选举等一系列问题。 2. Info 指令在诊断 Redis 性能问题之前，需要了解 Redis 的运行状态，通过强大的 info 指令，可以查看 Redis 内部一系列的运行参数。info 的输出分为 9 大块: Server: 服务器运行的环境参数 Clients: 客户端相关信息 Memory: 服务器运行内存统计数据 Persistence: 持久化信息 Stats: 通用统计数据 Replication: 主从复制相关信息 CPU: CPU 使用情况 Cluster: 集群信息 KeySpace: 键值对统计数量信息 info 可一次获取所有信息，也可分块获取。 3. 分布式锁3.1 Redis 分布式锁的实现用 redis 实现的分布式锁有如下几个要点: 本质上就是在 redis 占一个”坑”，一般使用 setnx(set if not exists)，抢占成功即加锁成功，用完了在调用 del 指令删除键即释放锁 为了避免因del 删除指令未被执行而导致的死锁，需要给锁加一个过期时间 由于 setnx + expire 也不是原子的，因此加锁需要 set 指令的扩展 如果加锁和释放锁之间的逻辑执行太长，以至于超过锁的超时限制，就很好有可能出现并发问题，因此 Redis 分布式锁不适合较长时间的任务 通过占位实现锁，可能会被未占用锁的进程误删除，稍微安全的做法是，将 set 指令的 value 设置为一个随机数，相当于版本号，释放锁时先验证，然后再删除 key。但是匹配 value 和 删除 key 不是一个原子操作，这里就需要 Lua 脚本处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行(我觉得这里不能说是原子执行，只能说严格串行执行) 123456789101112# 1. 可能死锁&gt; setnx lock:codehole true&gt; del lock:codehole# 2. 异常完全有可能在 setnx 和 expire 之间发生 &gt; setnx lock:codehole true&gt; expire lock:codehole 5&gt; del lock:codehole# 3. 正确的实现，创建和设置超时是一个原子操作&gt; set lock:codehole true ex 5 nx&gt; del lock:codehole Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。是否需要可重入依赖于业务逻辑，这里不再详述。 锁冲突的处理客户端加锁失败，一般有以下 3 中策略来处理: 直接抛出异常: 比较适合客户端直接发送的请求 sleep: 阻塞并重试 延时队列: 将当前冲突的请求放到消息队列中，稍后在重试，比较适合异步消息处理。 3.2 Redis 中的乐观锁分布式锁是一种悲观锁， Redis 通过另一种机制 watch 提供了乐观锁，使用方式如下: 1234&gt; watch books&gt; multi&gt; incr books&gt; exec watch 会在事务开始之前监测一个或多个关键变量 事务执行时，即开始顺序执行事务队列中的命令时，Redis 会先检查关键变量自 watch 以来是否被修改，包括当前事务所在的客户端 如果关键变量被修改，exec 指令返回 NULL，表示事务执行失败 否则执行事务 注意 watch 之后即便是当前事务所在的客户端对关键变量进行修改(指在 watch 和 multi 之间对关键变量的修改)，事务也会报错，同时Redis 禁止在 multi 和 exec 之间执行 watch 指令。 3.3 分布式锁在集群环境下，主从切换可能会导致锁信息的丢失从而出现问题。为了解决这个问题，Redis 使用了 Redlock 算法。 为了使用 Redlock，需要提供多个 Redis 实例，这些实例之间相互独立，没有主从关系。加锁时客户端向过半节点发送set(key, value, nx=True, err=XXX)，只要过半节点 set 成功，加锁成功。释放锁是向所有节点发送 del 指令，不过Redlock 还需要考虑出错重试，时钟漂移等很多细节问题。 4. 惰性删除5. Redis 加密Redis 中的安全措施 5.1 指令安全Redis 在配置文件中 rename-command 指令，用于将某些危险的指令修改成特别的名称，比如在配置文件的 security 块增加: 12rename-command keys abckeysabcrename-command flushall "" # 禁用指令 5.2 端口安全5.3 增加密码访问限制5.4 Lua 脚本安全必须禁止Lua脚本由用户输入(UGC)生成 5.5 使用 spiped SSL 代理Redis 不支持 SSL 连接，可以用 SSL 代理，官方推荐 spiped。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4. redis 集群篇]]></title>
    <url>%2F2020%2F05%2F04%2Fredis%2F04.%E9%9B%86%E7%BE%A4%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis 集群 1. 集群篇概述集群篇我们将介绍 Redis 的三种集群实现方式: Sentinel Codis Cluster Redis 集群需要解决如下的问题: 主从同步以及高可用 数据分片 就每个一个 key 所在的分片达成一致，此处需要引入分布式强一致性协议 负载均衡，以及负载均衡过程中读写的处理 1. Redis 主从同步1.1 增量同步Redis 支持主从同步，从从同步。Redis 同步的是指令流: 主节点: 将那些对自己的状态产生修改的指令记录在本地的内存buffer中 然后异步将 buffer 中的指令同步到从节点 从节点: 一边执行同步的指令流 一边向主节点反馈同步到了哪里(偏移量) buffer 是一个环形缓冲区，意味指令可能在同步到从节点之前就已经被覆盖了，特别是在主从节点之间发生网络问题时。此时就需要更加复杂的同步机制了–快照同步。 1.2 快照同步快照同步是一个非常耗费资源的操作，整个过程如下图所示: 主节点: 进行 bgsave，将当前内存数据快照到磁盘文件中 将快照文件的内容全部传送至从节点 从节点: 从节点接收快照文件后，将当前内存的数据清空 执行一次全量加载 加载完毕后通知主节点继续进行增量同步整个快照同步过程，主节点的 buffer 仍在不停的移动，如果同步的时间过长或复制 buffer 过小，都会导致同步期间，增量指令已经发生的覆盖，这样就会导致快照同步完成后无法进行增量复制，陷入快照同步的死循环。所以务必配置合适的复制 buffer 大小。 1.3 增加从节点新增的从节点，必须先进行一次快照同步后在继续进行增量同步。 1.4 无盘复制所谓无盘复制是指主服务直接通过套接字将快照内容发送给从节点，生成快照是一个遍历的过程，主节点一边遍历内存，一边将序列化后的内容发送到从节点，从节点先将接收到的内容保存至磁盘，在进行一次性加载。 无盘复制可以避免 bgsave 带来了大量磁盘IO，降低对主服务器性能的影响，特别是AOF 进行 fsync 时。 1.5 wait 指令wait 指令用于实现主从同步复制，确保系统强一致性(不严格的)。 wait N TIME_OUT: 作用: 等待 wait 指令之前的所有写操作同步到 N 个从节点，最多等 TIME_OUT 参数: N: 从节点个数 TIME_OUT: 同步的超时时长，0表示无限等待如果 TIME_OUT=0，网络发生分区，主从同步无法完成，wait 将永远阻塞，Redis 服务将不可用。 2. SentinelSentinel 是 Redis 高可用的解决方案，自动完成主从切换: Sentinel 负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换成主节点 客户端连接集群时，首先连接 Sentinel，通过 Sentinel 来查询主节点地址，然后在连接主节点进行数据交互 当主节点发生故障时，客户端会重新向 Sentinel 请求主节点地址，并重新连接 Sentinel 会持续监控挂掉的主节点，并在其恢复时将其调整为从节点，避免发生脑裂 2.1 消息丢失因为采用主从异步复制，Sentinel 是无法保证消息完全不丢失的，但可以尽量保证消息少丢失，它有两个限制选项: min-slaves-to-write 表示主节点必须至少有一个从节点在进行正常复制，否则停止对外写服务 默认值为 1 min-slaves-max-log 主从同步的最大延时，默认值为 10s 如果主节点超过 10s 没有收到从节点的同步反馈，意味着从节点同步不正常 2.2 Sentinel 使用示例下面是 Python 连接 Sentinel 操作 Redis 的代码示例: 123456789101112131415161718192021222324252627282930313233343536373839404142#!/usr/bin/env python# -*- coding:utf-8 -*-#!/usr/bin/env pythonimport redisfrom redis.sentinel import Sentinel# 连接哨兵服务器(主机名也可以用域名)sentinel = Sentinel([('172.31.0.2', 5001), ('172.31.0.3', 5001), ('172.31.0.4', 5001), ('172.31.0.5', 5001) ], socket_timeout=0.5)# 获取主服务器地址master = sentinel.discover_master('mymaster')print(master)# 输出：('172.31.0.2', 5001)# 获取从服务器地址slave = sentinel.discover_slaves('mymaster')print(slave)# 输出：[('172.31.3', 5001), ('172.31.0.4', 5001), ('172.31.0.5', 5001)]# 获取主服务器进行写入master = sentinel.master_for('mymaster', socket_timeout=0.5, password='redis_auth_pass', db=15)w_ret = master.set('foo', 'bar')# 输出：True# # 获取从服务器进行读取（默认是round-roubin）slave = sentinel.slave_for('mymaster', socket_timeout=0.5, password='redis_auth_pass', db=15)r_ret = slave.get('foo')print(r_ret)# # 输出：bar 如果发生了主从切换，redis-py 客户端的连接重置发生在如下两个时点: 连接池建立连接时，会去查询主节点地址，如果发现主节点变化，就会重新使用新地址建立连接 如果是 Sentinel 主动进行主从切换，并且主节点依旧在线，只不过变成了从节点。因为从节点是只读的，此时对从节点的所有修改指令都会抛出 ReadonlyError。redis-py 会捕获这个特殊的异常，并将所有的旧连接全部关闭，后续指令就会进行重连。但是要注意，如果没有修改指令，旧的连接是不会重置的，此时我们将从从节点读取数据，需要注意由此带来的数据一致性问题。 3. Codis单个 Redis 实例在海量并发下显得捉襟见肘: 单个 Redis 内存不宜过大，内存过大会导致 rdb 文件过大，进一步导致主从同步时全量同步事件过长，在实例重启恢复时也会消耗很长的时间加载时间 单个 Redis 实例只能利用单个核心，在进行大量操作时压力非常大 正因为如此 Redis 集群应运而生，将众多小内存的 Redis 实例整合起来，并充分利用多核 CPU 的计算能力。 Codis 是 Redis 集群方案之一，它是一个代理中间件，具有如下特性: 使用 Redis 协议对外提供服务，客户端操作 Codis 与操作 Redis 没有分别 Codis 将接收到的指令转发到后面的 Redis 实例执行，并将返回的结果转回给客户端 Codis 是无状态的，所以我们启动多个 Codis 实例，增加整体 QPS 并起到容灾作用 3.1 Codis 分片原理Codis 负责 key 的分区: 它默认将所有 key 划分到 1024 个槽位(slot)，然后使用 crc32(key) % 1024 确定 key 对应的槽位。 每个槽位都会唯一隐射到后面的多个 Redis 实例之一。 Codis 会在内存中维护槽位和 Redis 实例的映射关系 多个 Codis 实例需要就槽位与 Redis 实例的映射关系达成一致，并且需要持久化这个映射关系信息。Codis 开始使用 Zookeeper 后来也支持 etcd。如下图所示: Codis 将槽位信息存储在 Zookeeper 中，并且提供了一个 Dashboard 观察和修改槽位关系 当槽位关系变化时，Codis 会监听到变化并重新同步槽位关系，从而实现多个 Codis 之间的槽位关系一致 3.2 Codis 扩容过程无论是 Codis 还是后面要将的 Redis Cluster，都需要解决扩容问题，包括: 槽位如何迁移 迁移过程中的请求处理问题 与 kafka 创建新的分区副本，在执行分区再分配，并删除冗余副本的方式不同。Redis(包括 Codis 和 Cluster)都采用了边迁移，边删除的方式。所以在迁移的过程中，当前槽位的数据会同时存在于新旧槽位中，Codis 需要判断该将请求转发到两个实例。此时 Codis 与 Cluster 处理的方式不同: Codis 接收到位于正在迁移槽位中的 key 后，会立即强制对当前的单个 key 进行迁移，迁移完成后，再将请求转发到新的 Redis 实例 Cluster 则会在客户端请求错实例后，返回一个重定向指令，将客户端重定向到 key 所在的新 Redis 实例。具体的过程我们稍后在详述。 自动均衡Codis 提供了自动均衡功能，会在系统比较空闲的时候观察每个 Redis 实例对应的 slot 数量，如果不平衡，就会自动迁移. 3.3 Codis 的代价分区虽然能均衡负载，但也引入了其他问题: 不能在支持事务 rename 操作也很危险，因为它的参数是两个 key 为了扩容，单个 key 对应的 value 不宜过大，因为集群迁移的最小单元是 key 官方建议单个集合结构的总字节容量不要超过 1MB，如果要存放社交关系数据，就需要在业务层拆分了 mget 查询需要有一个分批查询然后汇总的过程，这是数据分区的必然结果 4. ClusterRedis Cluster 是 Redis 的亲儿子，由 Redis 作者提供的 Redis 集群化方案。Redis Cluster 是去中心化的，Redis Cluster 中的节点通过一种特殊二进制协议交互集群信息(混合使用了复杂的 Raft 和 Gossip 协议)。 4.1 Cluster 分区原理Redis Cluster 将所有数据划分为 16348 个槽位，使用公式 crc16(key) % 16348 确定 key 所在的槽位。每个节点负责存储一部分槽位，而槽位的信息存储于每个节点中。 Redis Cluster 的客户端在连接集群时，也会缓存一份集群的槽位配置信息，以便客户端查询 key 时可以直接定位目标节点。这就涉及到客户端、集群各个节点的槽位信息同步问题。客户端连接错目标Redis 实例时，Redis Cluster 通过特殊的跳转指令(MOVED)，携带正确目标实例告诉客户端，客户端收到 MOVED 指令后，重新连接获取数据，并同时更新槽位信息缓存。 由于分区，Cluster 也存在着同 Codis 一样的问题: 不支持事务，rename 不是原子的等等 4.2 扩容Redis Cluster 提供了工具 redis-trib 让运维人员手动调整槽位的分配。同 Codis 一样，Cluster 迁移的基本单位是槽。 Redis Cluster 槽位迁移以及迁移过程中的查询过程入上图所示: 迁移过程中，槽的源节点状态为 migrating，目标节点状态为 importing 迁移的大致流程是这样的: redis-trib 会在源节点和中间节点设置好中间过渡状态 …. 注意: 这里描述的迁移过程是同步的，在目标节点执行 restore 指令到删除 key 之间，源节点的主线程处于阻塞状态，直到 key 被成功删除 查询过程大致是这样的: 客户端首先尝试访问旧节点 …. 因为 key 是迁移过程的基本单位，如果 key 很大，因为 migrate 指令是阻塞指令，会同时导致源节点和目标节点卡顿，影响集群稳定性。所以业务逻辑要避免产生很大的 key。 4.3 容错Redis Cluster 可以为每个主节点设置多个从节点，主节点故障时，集群自动进行主从切换。如果集群没有从节点，并且主节点故障了，那么集群将处于完全不可用状态。节点的超时故障判断由如下两个参数控制: cluster-node-timeout: 超时故障时间 cluster-slave-validity-factor: timeout 的倍乘系数 Redis Cluster 使用 Gossip 协议对节点的上下线达成一致。 4.4 集群变更感知前面提到 MOVED 跳转指令可以让客户端跟新槽位映射信息。Redis Cluster 客户端对于集群节点变更的感知也是通过类似方式。 当目标节点down机时，客户端会抛出 ConnectionError 异常，此时客户端会随机重试，这时也会收到一个 MOVED 指令，确定目标槽位的新主节点。 如果运维主动切换主节点，这时旧主节点收到指令时会返回 ClusterDown 错误。这时客户端会关闭所有连接，清空槽位映射关系，然后向上层报错。待下一条指令过来时，重新尝试初始化节点信息。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3. redis 原理篇]]></title>
    <url>%2F2020%2F05%2F03%2Fredis%2F03_%E5%8E%9F%E7%90%86%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis 原理篇 1. 原理篇概述原理篇我们将介绍 Redis 的如下内容: IO模型 网络协议 持久化 管道 事务 小对象压缩 1. IO 模型首先Redis 是个单线程程序。 1.1 redis 高并发的原因为什么单线程还能支持如此高的并发量，原因有下面几个: 高效的事务和使用内存保存所有数据 使用 IO 多路复用处理并发的客户端连接 指令队列和响应队列 高效的事务和内存使用通常的事务处理机制希望囊括用户的所有操作: - **事务总是需要等待来自用户的输入**，同时还要支持潜在大量并发需求，那么系统大部分时间处于空闲状态。 - 于此同时事务总体沿用交互式客户端/服务器风格，一次一个请求有语句。请求与结果在应用代码和数据库服务器之间来回交互。**这种交互式的事务处理，大量时间耗费在应用程序与数据库之间的网络通信上**。数据库总是在等待应用程序提交下一个请求。 - 在这种类型的数据库中，为了获得足够的吞吐量，需要能够同时处理多个事务 而像 Redis 这种单线程串行的系统则将人为交互从事务中移除，并且不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程打包发送到数据库，同时事务所需的所有数据已经全部加载到内存中，使得存储过程高效执行，而无需等待网络和磁盘I/O。 与直觉相反，内存数据库的性能欧式并不是因为它们不需要从磁盘读取。如果有足够的内存，即便是基于磁盘的存储引擎，也可能不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存中。相反内存数据库可以更快是因为它们避免使用写磁盘的格式对内存数据结构编码的开销。 内存数据库另一个有意思地方是提供了基于磁盘索引难以实现的数据结构，典型的是 Redis。内存数据库使用所谓的反缓存方法，在内存不够用时将最近最少使用的数据写到磁盘，可以支持比内存更大的数据集。 正因为 Redis 是单线程，所以要小心使用 Redis 指令，特别是那些时间复杂度为 O(n) 级别的指令。因为单条指令执行太长时间就会导致 Redis 卡顿。 IO 多路复用使用 IO 多路复用可以解决 C10K 问题，IO 多路复用的原理读者可以自行查阅相关资料，这里不再赘述。 指令队列和响应队列Redis 会将每个客户端套接字都关联一个指令队列，客户端指令通过队列来排队顺序处理。 Redis 同样也会为每个客户端套接字关联一个响应队列。Redis 通过响应队列将指令的返回结果恢复给客户端。 2. 通信协议RESP 是 Redis 序列化协议(Redis Serialization Protocol)的简写。它是一种文件协议，优势在于简单，解析性能好。具体的协议细节，这里我们不在赘述，有兴趣大家可以直接阅读 《Redis深度历险：核心原理与应用实践》。 3. 持久化Redis 持久化机制有两种: 快照: 一次全量备份 是内存数据的二进制序列化形式，存储上非常紧凑 AOF 日志: 连续增量备份 是内存数据修改的指令记录文本 在运行的过程中会慢慢变大，数据库重启需要加载 AOF 日志进行指令重放，为了避免重放时间过长，需要定期进行 AOF 日志压缩 3.1 快照原理持久化是不能影响正常的客户端请求的。所以持久化的同时，内存数据还在改变。我们需要一种机制来获取所有数据的一致性视图。Redis 使用的是操作系统的多进程 COW(Copy On Write)。 Redis 在持久化时会调用 glibc 的函数 fork 一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。COW 保证了父进程对内存数据的修改不会影响子进程的内存。子进程可以拿到 Redis 所有数据的一致性视图。 3.2 AOFAOF 日志存储的是 Redis 服务器的顺序指令序列，只记录堆内存进行修改的指令。 Redis 会在收到客户端修改指令后，进行参数校验、逻辑处理，如果没有问题，就立即将指令文本存储到 AOF 日志中。也就是说，先执行指令，在将日志存盘。 AOF 重写Redis 提供了 bgrewriteaof 指令对 AOF 进行压缩，其原理是创建一个子进程对内存进行遍历，转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完成后，再将操作期间发生的增量AOF 日志追加到新的 AOF日志文件中。追加完成后新的 AOF 日志文件将替代旧的 AOF 日志文件。 fsync通常文件写操作是将数据写到了操作系统的页缓存，然后由操作系统定期将页缓存刷入磁盘(调用 fsync 函数)。fsync 是一个磁盘 IO 操作。 生产环境中，Redis 通常是每个 1s 左右进行一次 fsync 操作，这个时间是可配置的。这是在数据安全性和性能之间的权衡。 3.3 持久化策略无论是快照遍历内存，然后大块写磁盘；还是AOF 定期 fsync 都会增加系统负载。所以通常 Redis 的主节点不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，通常没有客户端请求的压力。 3.4 Redis 4.0 混合持久化Redis 4.0 增加了一个新的持久化选型-混合持久化。如下图所示: 将 rdb 文件(快照的结果文件)和增量的 AOF 日志文件存在一起 这里 AOF 日志不再是全量日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志(很小) 于是 Redis 重启时，先加载 rdb，在重放增量 AOF 日志，就可以避免之前的 AOF 全量重放的低效率 4. 管道Pipeline 管道是 Redis 客户端提供的一种技术，通过对管道内的指令改变读写顺序，并合并连续的写请求和读请求，从而减少网络 IO 的次数，从而提升性能。注意这跟服务器没有直接关系。 redis 自带的压力测试工具 redis-benchmark 可以进行管道的压力测试: 123&gt; redis-benchmark -t set -q# -P 表示管道内并行的请求数量&gt; redis-benchmark -t set -q -P 2 5. Redis 事务Redis 如下命令用于启动事务: multi: begin 开启事务 exec: commit 提交 discard: rollback 回滚 123456789&gt; multiOK&gt; incr booksQUEUED&gt; incr booksQUEUED&gt; exec(interger) 1(interger) 2 上面的指令演示了一个完整的事务过程。所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开始执行整个事务队列，执行完成之后一次性返回所有指令的运行结果。因为 Redis 单线程特性，可以保证他们能得到顺序执行，而不被打断。 但是 Redis的事务不具备原子性，当事务中的一连串命令，发生错误时，发生错误的指令不会影响接下来的其他指令的运行，更不会回滚。Redis 是单线程，准确来说它仅仅满足事务隔离性中的串行化。 discard 作用仅仅是丢弃事务队列里的命名。此处不存在回滚一说，因为命令压根没有执行。 为了避免事务中多次发送命令带来了多次网络开销，通常事务与管道一起使用。 12345pip = redis.pipeline(transaction=True)pipe.multi()pipe.incr("books")pipe.incr("books")values = pipe.execute()]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2. redis 基础篇]]></title>
    <url>%2F2020%2F05%2F02%2Fredis%2F02_%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Redis 基础篇: Redis 提供的那些数据结构 1. 基础篇概述基础篇我们将介绍 Redis 的如下内容: Redis 基础数据结构 分布式锁的实现 延时队列的实现 位图 HyperLogLog: 做不精确统计用的 布隆过滤器 限流 GeoHash: 找附近的人 scan: 字典扫描 1. Redis 基础数据结构Redis 有五种基础数据结构: string: 字符串 list: 列表 hash: 字典 set: 集合 zset: 有序集合 1.1 string在 redis 内部 string 就是一个字符数组。Reids 全称是 Remote Dictionary Service(远程字典服务)，所有的数据结构都以唯一的 key 字符串作为名称，然后通过这个唯一的 key 获取相应的 value 数据。不同的数据结构差异就在于 value 的不同。 Redis 字符串是可以修改的，内部结构类似 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。 当字符串大小小于 1MB 时，扩容都是加倍的 当字符串大小大于 1MB 事，扩容一次只会多增加 1MB 的空间 字符串最大长度为 512MB string 支持如下操作: 键值对操作 get key set key value del key 批量键值对操作 mget key key key mset key value key value 键过期设置 expire key time: 对 key 设置过期时间 time 单位为秒 ttl key: 获取 key 的过期时间 set 扩展命令 setex: == set + expire setnx: 不存在则执行 set 创建 计数: 前提是 value 是一个整数，范围在 signed long 内 incr key : 加 1 incrby key num: 加 num 1.2 list(列表)在 Redis 内部 list 被实现为 quicklist，这是一个特殊实现的快速链表而不是数组。因为普通的链表指针太多会浪费空间，还会加重内存的碎片化。所以 Redis 将多个元素合并成一个 ziplist(压缩列表)，ziplist 是一块连续内存，内部可以存放多个元素，多个 ziplist 使用双向指针连接成 quicklist。quicklist 的具体实现后面我们会详细介绍。 当列表弹出最后一个元素后，该数据结构被自动删除，内存被回收。常用来做异步队列使用。 list 支持如下操作: 队列和栈操作 rpush key v v v: 右进 lpush key v v v: 左进 rpop key: 右出 lpop key: 左出 llen key: 获取长度 查询 lindex key index: 索引 lrange key start end: 切片 ltrim key start end: 保留切片内的元素，删除所有其他元素 1.3 hash(字典)Redis 的字典使用 链表法解决哈希冲突，与其他的字典实现不同，Redis 字典还有如下特点: 字典的值也只能是字符串 使用渐进式 rehash 进行扩容 hash 支持如下操作: hset key k v hget key k hgetall key hlen key hmset key k v k v hincrby key k num: 对单个 key 进行计数 1.4 set(集合)set 的内部实现相当于一个特殊的字典，字典中所有 key 的 value 都是 NULL。 set 支持如下操作: sadd key v smembers key: 查看所有 sismember key v: 是否包含 scard key: 获取长度 spop key: 弹出一个 1.5 zset(有序集合)zset 有序结合被实现为跳表，zset 是另一种映射的实现，redis 将 zset 的 key 表示为 value，而 value 表示为 score，代表 value 的排序权重。 zset 支持如下操作: zadd key score v: 添加 v zrem key v: 删除 v zcard key: 获取长度 zscore key v: 获取 value 的score zrank key v: 获取 value 排名 zrange key r1 r2: 按 score 排序输出，r1，r2 是排名范围 zrevrange key r1 r2: 按 score 逆序输出 zrangebyscore key s1 s2 [withscores]: 按照 score 排序输出，s1,s2 是 score 范围 withscores 表示同时输出 score 分数 s1,s2 值可为 -inf/inf 表示负正无穷大 score 在 zset 中存储为 double 类型，注意存在精度问题 1.6 容器型类型结构的通用规则list、hash、set、zset 是容器型数据结构，它们共享下面通用规则: create if not exists: 不存在就创建，再进行操作 drop if no element: 如果容器里没有元素了，会立即删除，释放内存 1.7 过期时间Redis 所有数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。过期是以对象为单位的，一个 hash 结构的过期是整个 hash 对象的过期，不存在某个子 key 过期。 另外需要注意的是，如果一个字符串已经设置了过期时间，然后调用 set 方法修改了它，它的过期时间会消失。 2. 分布式锁用 redis 实现的分布式锁有如下几个要点: 本质上就是在 redis 占一个”坑”，一般使用 setnx(set if not exists)，抢占成功即加锁成功，用完了在调用 del 指令删除键即释放锁 为了避免因del 删除指令未被执行而导致的死锁，需要给锁加一个过期时间 由于 setnx + expire 也不是原子的，因此加锁需要 set 指令的扩展 如果加锁和释放锁之间的逻辑执行太长，以至于超过锁的超时限制，就很好有可能出现并发问题，因此 Redis 分布式锁不适合较长时间的任务 通过占位实现锁，可能会被未占用锁的进程误删除，稍微安全的做法是，将 set 指令的 value 设置为一个随机数，相当于版本号，释放锁时先验证，然后再删除 key。但是匹配 value 和 删除 key 不是一个原子操作，这里就需要 Lua 脚本处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行(我觉得这里不能说是原子执行，只能说严格串行执行) 123456789101112# 1. 可能死锁&gt; setnx lock:codehole true&gt; del lock:codehole# 2. 异常完全有可能在 setnx 和 expire 之间发生 &gt; setnx lock:codehole true&gt; expire lock:codehole 5&gt; del lock:codehole# 3. 正确的实现，创建和设置超时是一个原子操作&gt; set lock:codehole true ex 5 nx&gt; del lock:codehole Redis 分布式锁如果要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。是否需要可重入依赖于业务逻辑，这里不再详述。 至此我们讨论的 redis 分布式锁实现依旧是不完备的，后面我们会继续深入讨论。 3. 延时队列redis 队列有多种实现方式，为了内容的完整性，我们将延时队列的实现放入了后面拓展篇。 4. 位图4.1 位图实现Redis 中的字符串是动态的字节数组，是可以修改的，所以可以直接把字符串当做 byte 数组来使用。 4.2 位图操作Redis 提供一下指令进行位操作: getbit index 0|1 : 读取特定位的值 setbit key index 0|1 : 设置特定位的值 bitcount key [start, end]: 统计指定范围内 1 的个数 bitpos key 0|1 [start, end]: 查找指定范围内出现的第一个 0 或 1 bitfield: 一次进行多个位操作 注: byte 数组是自动扩展的，如果设置的偏移量超过了现在范围，redis 将自动对位数组进行 0 扩充。 bitcount/bitpos 的范围参数 [start, end] 是字符索引，[0, 0] 表示第一个字符，即前 8 个位 123456789101112131415# 1. 位设置和读取&gt; setbit s 1 1&gt; setbit s 2 1&gt; setbit s 4 1&gt; get s # get 返回的是 bytes 对应的字符"h"&gt; set w h # 整存零取&gt; getbit w 1(integer) 1# 2. 位统计&gt; set w hello&gt; bitcount 0 0 # 第一个字符中 1 的个数&gt; bitpos w 1 1 1 # 从第二字符起，第一 1 的位置 bitfieldbitfield 有三个子命令，get、set、incrby 可以对指定位片段进行读写，但是最多只能处理 64 个连续的位。如果超过 64 位就要使用多个子命令，bitfield 可以一次执行多个子命令。 12345678&gt; set w hello&gt; bitfield w get u4 0 # 从第 1 位开始取 4 位作为无符号整数(u) 返回&gt; bitfield w get i3 2&gt; bitfield w set u8 8 97 # 从第 9 位开始将接下来的 8 个位用无符号整数 97 替代# incrby 用于执行自增操作&gt; bitfield w incrby u4 2 1 # 从第 3 位开始，对接下来的 4 位无符号整数 + 1 incrby 自增指令可能会导致溢出，bitfield 提供了 overflow 子命令用于选择溢出行为: wrap: 折返，默认值 fail：报错不执行 sat：饱和截断，停留在最大或最小值。 overflow 只会影响下一个指令，下一个指令执行完成后溢出策略会变成默认的 wrap。 123&gt; set w hellp&gt; bitfield w overflow sat incrby u4 2 1&gt; bitfield w overflow fail incrby u4 2 1 5. HyperLogLogHyperLogLog 提供不精确的去重计数方案，虽然不精确，但是也不是非常离谱，标准误差 0.81%。 HyperLogLog 需要占据 12KB 的存储空间(无论对多少数据去重，最多占用 12K)，所以不适合统计单个用户的相关数据。Redis 对 HyperLogLog 的存储进行了优化，在计数较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用的空间渐渐超过阈值时，才会一次性转变成稠密矩阵。 5.1 使用HyperLogLog 提供了三个指令: pfadd: 增加计数 pfcount: 获取计数 pfmerge: 将多个 pf 计数值累加在一起 1234&gt; pfadd codehole user1&gt; pfadd codehole user2&gt; pfcount codehole2 5.2 原理HyperLogLog 的计数利用了这样一个统计规律: 一堆随机数的数量N与随机数中低位连续零位的最大长度K满足这样一个关系: N=2^K。而通过哈希，就可以将字符串映射为随机数，并且可以去重。 Redis 使用 2^14 个桶，对随机数进行独立计数，每个桶使用 6bit 记录连续零位的最大长度。使用这些桶计算N并求平均值。所以一个 HyperLogLog 需要占用: 2^14 * 6 / 8=12KB 6. 布隆过滤器布隆过滤器，类似于不精确的 set 用于元素去重和快速判断元素是否在集合中。使用布隆过滤器空间上能节省 90%，当然过滤就不是特别准确，存在误判。 布隆过滤器判断某个值存在时，值可能不存在，但是判断某个值不存在时，肯定不存在。 6.1 使用Redis 4.0 提供了插件功能之后，布隆过滤器通过插件的方式添加到 Redis 中。布隆过滤器有如下几个命令: bf.add: 添加元素，只能一次添加一个元素 bf.madd: 用于一次添加多个元素 bf.exists: 查询元素是否存在 bf.mexists: 一次判断多个元素是否存在 bf.reserve key error_rate initial_size: 作用: 自定义布隆过滤器，设置最大错误率，如果 key 已经存在会报错 参数: error_rate: 最大错误率，越小，需要的空间越大 initial_size: 预计放入的元素数量，实际数量超过这个数量时，误判率会上升，所以需要预估一个合理的数值 默认: error_rate=0.01 initial_size=100 12345678&gt; bf.add codehole user1&gt; bf.add codehole user2&gt; bf.exists codehole user11&gt; bf.madd codehole user10 user11 user12&gt; bf.mexists codehole user4 user500 6.2 原理布隆过滤器就是大型的位数组和几个不一样的无偏 hash 函数。 6.3 空间占用估计布隆过滤器的空间计算， 输入有两个参数: n: 预计元素数量 f: 错误率 输出也有两个元素: L: 位数组的长度 k: hash 函数的最佳数量 12k=0.7*(L/n)f=0.6185^(L/n) 在线的布隆计算器参见 https://krisives.github.io/bloom-calculator 6.4 实际数量超限事的错误率实际数量超出预计元素时，错误率的变化参见公式: f=(1-0.5^t)^k f: 错误率 k: hash 函数的最佳数量 t: 实际元素数量与预计元素(initial_size) 的倍数 当实际数量超出预计元素时，错误率会随着倍数 t 显著增大。 6.5 应用布隆过滤器在 NoSQL 中使用广泛，当用户查询某个 row 时，可先通过内存中的布隆过滤器过滤掉大量不存在 row 请求，然后再去磁盘进行查询，可以显著降低 IO 请求的数量。 布隆过滤器也长用在爬虫，对大量 URL 进行去重。 7 限流本片文章我们来介绍如何使用 Redis 实现限流算法，包括两种实现方式: 简单限流: 通过 zset 实现 漏斗限流: Redis4.0 提供的限流模块，Redis-Cell 7.1 简单限流使用 zset 结构记录用户的行为历史，每一个行为都会作为一个 zset ，使用 score 记录时间戳，用于计算滑动时间的窗口，value 为什么值不重要，只要唯一即可，也可使用时间戳。而且只要保留最近的一个时间窗口即可。下面是一个实现示例: 123456789101112131415client = redis.StrictRedis()def is_action_allow(user_id, action_key, period, max_count): key = 'hit:%s:%s' % (user_id, action_key) now_ts = int(time.time() * 1000) with client().pipeline() as pipe: pip.zadd(key, now_ts, now_ts) # 只保留窗口内的记录 pipe.zremrangebyscore(key, 0, now_ts - period * 1000) pipe.zcard(key) # 设置过期时间，避免冷用户持续占用内存 # 过期时间为时间窗口长度，再多宽限 1s pip.expire(key, period + 1) _, _, current_count, _ = pipe.execute() return current_count &lt; max_count 连续的 Redis 操作都是针对同一 key，使用 pipeline 可以显著提高 Redis 存储效率。 这种方案有个缺点，因为它要记录时间窗口内所有的行为记录，如果量很大，比如限定 60s 内不得超过 100万次，就会消耗大量的空间。 7.2 漏斗限流Redis-Cell 提供了 cl.throttle 指令用于执行限流算法，使用示例如下: 123456&gt; cl.throttle user_id:key 15 30 60 11) (interger) 0 # 0-允许，1-拒绝1) (interger) 15 # 漏斗容量1) (interger) 14 # 漏斗剩余空间1) (interger) -1 # 如果被拒绝，需要多长时间后再试1) (interger) 2 # 多长时间漏斗完全空 cl.throttle user_id:key 15 30 60 1 参数: 15: capacity 漏斗的容量 30 60: 每 60s 最多 30 次，漏水速率 1: quota 可选参数默认值为 1 8. GeoHashRedis3.2 增加了地理位置模块 Geo，我们可以实现类似附近的餐馆这样的功能。 8.1 附近的人计算方法如果要计算“附近的人”，也就是给定一个元素的坐标，然后计算这个坐标附近的其他元素，按照距离进行排序，该如何处理？ 如果现在元素的经纬度坐标使用关系数据库 （元素 id， 经度 x， 纬度 y） 存储，你该如何计算？ 首先，你不可能通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行全量距离计算再排序。这样可以明显减少计算量。如何划分矩形区域呢？可以指定一个半径 r，使用一条 SQL 就可以圈出来。 1select id from position where x0-r &lt; x &lt; x0+r and y0-r &lt; y &lt; y0+r 但是数据库查询不适合大并发的场景。 8.2 GeoHash业界比较通用的地理位置距离排序算法是 GeoHash 算法，GeoHash 算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算“附近的人”时，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行了。 在 Redis 中，经纬度使用 52 位整数值编码，放在 zset 中，value 是元素的 key，score 是 GeoHash 的 52 位整数值。zset 的score 虽然是浮点数，但是对于 52 位整数值可以无损存储。通过 zset 的score 排序就可以得到坐标附近的其他元素。通过 score 可以还原坐标值就可以得到元素的原始坐标。 GeoHash 对二维坐标进行的一维映射时有损的，通过映射还原的值也会出现小的偏差。 8.3 Geo指令Geo 有 6 个指令 geoadd: 添加经纬度，值为(经度，维度，元素)的三元组 zrem: 删除 Geo 元素(Geo 底层只是一个普通的 zset) geolist：计算两个元素之间的距离，参数是(集合名称，元素A，元素B，距离单位) geopos: 获取集合中任意元素的经纬度坐标，一次可获得多个 geohas: 获取元素经纬度编码字符串，base32编码 georadiusbymeember: 查询指定元素附近的其他元素 genradius: 根据经纬度查询附近的元素，参数与georadiusbymeember相同，只不过把元素换成经纬度 12345678910111213141516171819202122&gt; geoadd company 116.88888 39.92343 juejin&gt; geoadd company 126.88888 49.92343 jd&gt; geoadd company 78.88888 20.92343 abc&gt; zrem company abc&gt; geolist company juejin jd km &gt; geopos company juejin jd&gt; geohash company jd# 范围 20 公里以内最多 3 个元素按距离正排，不排除自身&gt; georadiusbymember company jd 20 km count 3 asc# # 范围 20 公里以内最多 3 个元素按距离倒排&gt; georadiusbymember company jd 20 km count 3 asc# withdist: 显示实际距离# withhash: 显示距离编码信息# withcoord: 显示经纬度&gt; georadiusbymember company jd 20 km withcoord withdist withhash count 3 asc&gt; genradius company 59.223, 46.134 20 km withdist count 3 asc 8.4 Geo 使用注意事项如果将所有的地理的位置放在同一个 Geo 结构中，就会导致 zset 集合过大。Redis 集群环境中，集合可能从一个节点迁移到另一节点，如果单个 key 的数据过大，会对集群的迁移工作造成较大的影响，所以集群环境中一个单个 key 对应的数据量不宜超过 1MB，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。 所以建议 Geo 的数据使用单独的Redis 实例部署，不使用集群环境。如果数据过大，可以按照省市区进行拆分。 9. key 查找9.1 keys 和 scan 命令Redis 提供了一个简答指令 keys 用于列出所有满足正则匹配的 key。但是 keys 指令有两个明显的缺点: 没有 offset，limit，一次输出满足所有的 key 复杂度 O(n)，如果实例中 key 太多，因为Redis 是单线程程序，就会导致Redis 服务卡顿，所有的读写操作就会被延迟。 Redis 为了解决这个问题，加入了 scan 指令，scan 相比 keys 有如下特点: 复杂度O(n)，但是通过游标分步进行，不会阻塞线程 提供 limit 参数，限制返回的最大条数，注意 limit 限制的是 Redis 遍历的条数不是返回条数 服务器不维护游标状态，当前的位置是通过 scan 返回给客户端的游标整数 返回结果可能有重复，需要客户端去重 遍历过程中如有数据被修改，改动后的数据能不能被遍历具有不确定性 单次返回结果为空不代表遍历结果，遍历结束只能通过 scan 返回的游标值判断。 scan cursor match pattern count limit cursor: 查询的游标 pattern: key 匹配的正则表达式 limit: 返回的最大条数 特别要注意，limit 不是限定返回结果的数量，而是限定服务器单次遍历的字典槽位数量(约等于) 所以返回结果的集合可能为空，但是游标值不为 0，遍历未结束 12345678910&gt; keys *&gt; keys code*&gt; scan 0 match key* count 10001) 88432) 1) key1 2) key2 .......&gt; scan 8843 match key* count 1000 9.2 scan 原理redis 中所有 Key 都存储在一个很大的字典中。字典由一位数组和二维链表组成。scan 指令返回的游标就是第一维数组的位置索引(又称槽)，不考虑扩缩容直接按照数组下标进行遍历即可，limit 参数控制的就是需要遍历的槽位数。之所以范湖结果有多又少，是因为槽位有可能为空，也有可能槽位上的链表有多个元素。 scan 的遍历顺序不是从数组 0 索引开始直至结尾，而是采用了高位进位加法来遍历。之所以采用这个方法是考虑到字典的扩缩容，避免槽位遍历的重复和遗漏(原因见下)。 高位进位加法如下: 加法从左边加，进位往右边移动。 9.3 Redis Key 扩缩容Redis 存储所有 Key 的字典，一维数组的大小总是 2^n，扩容一次，空间加倍。因为数组长度总是 2^n 次方，字典哈希过程中对数组长度的取模运算，等价于位与操作:123a mod 8 == a &amp; (8-1) = a &amp; 7a mod 16 == a &amp; (16-1) = a &amp; 15a mod 32 == a &amp; (32-1) = a &amp; 31 这里的 8/16/32 是数组的长度而 7、15、31 称为字典的 mask 值，mask 的作用就是保留 hash 值的低位。注意这里可以这么计算的前提是数组大小总是 2^n。 假设当前的字典的数组长度由 8 扩容到 16，那么 3号槽位内的值将被 rehash 到 3号和 11 号槽位。11 的二进制 1011 就是对 3 的二进制 011 增加了一个高位。 抽象一点说如果开始槽位的二进制数是 xxx，那么该槽位中的元素将被 rehash 到 0xxx 和 1xxx(xxx+8)。如果字典长度由 16 扩展成 32，那么对应 xxxx 中的元素将被 rehash 到 0xxxx 和 1xxxx(xxxx + 16)中。 如上图所示，假设我们采用高位进位加法即将要遍历 110 这个位置: 扩容情况下 扩容后，当前槽位上所有的元素对应的新槽位是0110和1110 此时可以直接从0110这个槽位开始往后继续遍历，0110槽位之前的所有槽位都已经遍历过了 这样可以避免扩容后对已经遍历过的槽位进行重复遍历 缩容情况下 当前槽位所有的元素对应的新槽位是10 此时可以直接从10这个槽位开始往后继续遍历，10槽位之前的所有槽位都已经遍历过了，这样能避免缩容的重复遍历 但是这会对 010这个槽位 上的元素进行重复遍历，因为 010 槽位缩容后也会进入到 10 槽位，而 010 之前已经遍历过了 注意图中的每一行就是高位进位加法的连续值，也是我们的遍历顺序。 9.4 渐进式 rehashRedis采用渐进式rehash，需要同时保留旧数组和新数组，然后在定时任务中以及后续对hash的指令操作中渐渐地将旧数组中挂接的元素迁移到新数组上。 这意味着如果要操作处于rehash中的字典，需要同时访问新旧两个数组结构。scan处于rehash中的字典，也需要同时扫描新旧槽位，然后将结果融合后返回给客户端 scan 是一些列指令，除了 scan 本身还包括 zscan: 遍历 zset 集合元素 hscan: 遍历 hash 字典中的元素 sscan: 遍历 set 集合的元素 这些命令的原理与 scan 类似，因为 hash 底层就是字典，set 是一个特殊的 hash (所有的 value 指向同一个元素)，zset 内部也使用了字典来存储所有的元素内容。 9.5 大 Key 问题有时候由于操作不当，会在Redis 生成很大的Key，很大的 Key 会导致: 集群环境中，数据迁移卡顿 key 扩容时，一次性申请更大的内存，导致卡顿(因为字典内部数组的大小总是 2^n) Key被删除，内存会一次性回收，导致卡顿 在平时的业务开发中，要尽量避免大Key的产生！redis-cli 提供了 –-bigkeys 选项用于定位 redis 中的大 key。 redis-cli –-bigkeys 内部就用到了 scan 指令过程大概是这样: 扫描每一个 key，并使用 type 指令获取 key 的类型 获取类型后，使用相应数据结构的 size 或 len 方法获取它的大小 对于每一种类型，将大小排名的前几个作为扫描结果展示出来 123456# 可能会提升 Redis 的 ops，因为会使用 scan 扫描所有 Key&gt; redis-cli -h 127.0.0.1 -p 7001 --bigkeys # 限制 bigkeys 的扫描频率# -i 0.1 表示每隔 100 条，scan 就会休眠 0.1s&gt; redis-cli -h 127.0.0.1 -p 7001 --bigkeys -i 0.1]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. redis 开篇入门]]></title>
    <url>%2F2020%2F05%2F01%2Fredis%2F01_redis%E5%BC%80%E7%AF%87%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[《Redis深度历险：核心原理与应用实践》 读书笔记 1. 写在开始Redis 不言而喻，必知必会系列，现在太多的应用都要依赖 Redis。市面上 Redis 书很多，图文并茂又不啰嗦的就是这本 《Redis深度历险：核心原理与应用实践》了。 2. 本书结构本书将 Redis 的内容分成了如下几个模块: 基础和应用篇: Redis 提供的数据结构和基于此实现的功能，包括: Redis 基础数据结构 分布式锁的实现 延时队列的实现 位图 HyperLogLog: 做不精确统计用的 布隆过滤器 限流 GeoHash: 找附近的人 scan: 字典扫描 原理篇: IO模型、网络协议、持久化和事务、消息的发布和订阅 集群篇: Redis 的三种集群模式 Sentinel Codis Cluster 拓展篇: 基于 Redis 的扩展应用，或者叫高级应用 Stream 消息流 Info 指令，Redis 的监测 分布式锁的实现 Redis 的惰性删除 Redis 的加密 源码篇: Redis 各种数据结构的实现 字符串 dict 压缩列表 快速列表 跳表 基数树 LFU 和 LRU 惰性删除 字段遍历 3. 资源收录除了本书，目前还没找到其他好的 Kafka 学习资源，跟自己没有深度使用过有关。不过建议在看本书之前看看 《数据密集型应用系统设计》。相信你会对本书所说的内容有更加深刻的理解。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 Kafka 可靠性]]></title>
    <url>%2F2020%2F04%2F09%2Fkafka%2F09_kafka%E5%8F%AF%E9%9D%A0%E6%80%A7%2F</url>
    <content type="text"><![CDATA[Kafka 如何保证数据一致性 1. Kafka 可靠性概述Kafka 采用主从复制的复制方案，这就引出一系列问题：Kafka 多副本之间如何进行数据同步，尤其是在发生异常时候的处理机制又是什么？多副本间的数据一致性如何解决，基于的一致性协议又是什么？如何确保 Kafka 的可靠性？Kafka 中的可靠性和可用性之间的关系又如何？ 接下来我们就从副本的角度切入来深挖Kafka中的数据一致性、数据可靠性等问题，主要包括: 副本剖析 日志同步机制 可靠性分析 2. 副本剖析2.1 失效副本在ISR集合之外，也就是处于 同步失效 或 功能失效 （比如副本处于非存活状态）的副本统称为失效副本，失效副本对应的分区也就称为同步失效分区，即under-replicated分区。 通过kafka-topics.sh脚本的under-replicated-partitions参数我们可以查看主题中的失效副本: 12345bin/kafka-topics.sh \ --zookeeper localhost:2181/kafka \ --describe \ --topic topic_partition \ --under-replicated-partitions 同步失效失效副本不仅是指处于功能失效状态的副本，处于同步失效状态的副本也可以看作失效副本。 怎么判定一个分区是否有副本处于同步失效的状态呢？: 唯一的broker端参数replica.lag.time.max.ms可以配置一个最大的同步超时时间 当ISR集合中的一个 follower 副本滞后leader副本的时间超过此参数指定的值时则判定为同步失败，需要将此follower副本剔除出ISR集合 replica.lag.time.max.ms参数的默认值为10000 具体的实现原理如下: 当follower副本将leader副本LEO（LogEndOffset）之前的日志全部同步时，则认为该 follower 副本已经追赶上 leader 副本，此时更新该副本的lastCaughtUpTimeMs 标识 Kafka 的副本管理器会启动一个副本过期检测的定时任务，而这个定时任务会定时检查当前时间与副本的 lastCaughtUpTimeMs 差值是否大于参数replica.lag.time.max.ms 指定的值。 千万不要错误地认为 follower 副本只要拉取 leader副本的数据就会更新 lastCaughtUpTimeMs。试想一下，当 leader 副本中消息的流入速度大于follower 副本中拉取的速度时，就算 follower 副本一直不断地拉取 leader 副本的消息也不能与leader副本同步。此时副本也会从 ISR 集合中剔除。 一般有一下情况会导致副本失效： follower副本进程卡住，在一段时间内根本没有向leader副本发起同步请求，比如频繁的Full GC。 follower副本进程同步过慢，在一段时间内都无法追赶上leader副本，比如I/O开销过大 如果通过工具增加了副本因子，那么新增加的副本在赶上leader副本之前也都是处于失效状态的。 如果一个follower副本由于某些原因（比如宕机）而下线，之后又上线，在追赶上leader副本之前也处于失效状态。 同步失效分区是kafka 健康监测的一个重要指标。 2.2 ISR 伸缩Kafka 在启动的时候会开启两个与 ISR 相关的定时任务： isr-expiration: 周期性地检测每个分区是否需要缩减其ISR集合 isr-change-propagation: 广播 ISR 的变更 isr-expiration 周期和replica.lag.time.max.ms参数有关，大小是这个参数值的一半 当检测到ISR集合中有失效副本时，就会收缩ISR集合 如果某个分区的ISR集合发生变更，则会将变更后的数据记录到 ZooKeeper 对应的/brokers/topics/＜topic＞/partition/＜parititon＞/state节点中，内容为 {&quot;controller_epoch&quot;: 26, &quot;leader&quot;: 0, &quot;version&quot;: 1, &quot;leader_epoch&quot;: 2,&quot;isr&quot;: [0,1]} controller_epoch表示当前Kafka控制器的epoch leader表示当前分区的leader副本所在的broker的id编号 version表示版本号（当前版本固定为1） leader_epoch表示当前分区的leader纪元 isr表示变更后的ISR列表 isr-change-propagation 当 ISR 集合发生变更时还会将变更后的记录缓存到 isrChangeSet 中 isr-change-propagation任务会周期性（固定值为 2500ms）地检查 isrChangeSet，如果发现isrChangeSet中有ISR集合的变更记录，那么它会在ZooKeeper的/isr_change_notification路径下创建一个以 isrchange开头的持久顺序节点（比如/isr_change_notification/isr_change_0000000000），并将isrChangeSet中的信息保存到这个节点中 Kafka控制器为/isr_change_notification添加了一个Watcher，当这个节点中有子节点发生变化时会触发Watcher的动作，以此通知控制器更新相关元数据信息并向它管理的broker节点发送更新元数据的请求，最后删除/isr_change_notification路径下已经处理过的节点 频繁地触发Watcher会影响Kafka控制器、ZooKeeper甚至其他broker节点的性能。为了避免这种情况，Kafka添加了限定条件，当检测到分区的ISR集合发生变化时，还需要检查以下两个条件： 上一次ISR集合发生变化距离现在已经超过5s 上一次写入ZooKeeper的时间距离现在已经超过60s 只有满足以上两个条件之一才可以将ISR集合的变化写入目标节点 isr 扩大follower 副本追赶上leader副本的判定准则是此副本的LEO是否不小于leader副本的HW，注意这里并不是和leader副本的LEO相比。 ISR扩充之后同样会更新ZooKeeper中的/brokers/topics/＜topic＞/partition/＜parititon＞/state节点和isrChangeSet，之后的步骤就和ISR收缩时的相同。 HW 更新当ISR集合发生增减时，或者ISR集合中任一副本的LEO发生变化时，都可能会影响整个分区的HW。 2.2 LEO 与 HW消息同步过程 如上图所示某个分区有3个副本分别位于broker0、broker1和broker2节点中，其中带阴影的方框表示本地副本(指代 broker 实际保存的副本)。假设broker0上的副本1为当前分区的leader副本，那么副本2和副本3就是follower副本，整个消息追加的过程可以概括如下： 生产者客户端发送消息至leader副本（副本1）中 消息被追加到leader副本的本地日志，并且会更新日志的偏移量 follower副本（副本2和副本3）向leader副本请求同步数据 leader副本所在的服务器读取本地日志，并更新对应拉取的follower副本的信息 leader副本所在的服务器将拉取结果返回给follower副本 follower副本收到leader副本返回的拉取结果，将消息追加到本地日志中，并更新日志的偏移量信息 follower 拉取消息follower副本向leader副本拉取消息，在拉取的请求中会带有自身的LEO信息，这个LEO信息对应的是FetchRequest请求中的fetch_offset。leader副本返回给follower副本相应的消息，并且还带有自身的HW信息。这个HW信息对应的是FetchResponse中的high_watermark。 follower副本拉取到了消息后，更新各自的LEO。与此同时，还会更新自己的HW，更新HW的算法是比较当前LEO和leader副本中传送过来的HW的值，取较小值作为自己的HW值。 leader 收到 follower 拉取消息请求leader副本收到来自follower副本的FetchRequest请求，其中带有LEO的相关信息，选取其中的最小值作为新的HW。 在一个分区中: leader副本所在的节点会记录所有副本的LEO， follower副本所在的节点只会记录自身的LEO 对HW而言，各个副本所在的节点都只记录它自身的HW leader 副本收到 follower副本的FetchRequest请求之后，它首先会从自己的日志文件中读取数据，然后在返回给follower副本数据前先更新follower副本的LEO。 2.3 LEO 和 HW 持久化Kafka 的根目录下有 cleaner-offset-checkpoint、log-start-offset-checkpoint、recovery-point-offset-checkpoint和replication-offset-checkpoint四个检查点文件。 日志存储部门我们介绍了，cleaner-offset-checkpoint 就是清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。 而其他几个检查点文件与 LEO 和 HW 有关: recovery-point-offset-checkpoint 对应 LEO Kafka 中会有一个定时任务负责将所有分区的 LEO 刷写到恢复点文件 recovery-point-offset-checkpoint 中 定时周期由 broker 端参数 log.flush.offset.checkpoint.interval.ms来配置，默认值为60000 replication-offset-checkpoint: 对应 HW 另一个定时任务负责将所有分区的HW刷写到复制点文件replication-offset-checkpoint中 定时周期由broker端参数replica.high.watermark.checkpoint.interval.ms来配置，默认值为5000 log-start-offset-checkpoint 对应logStartOffset，用来标识日志的起始偏移量 各个副本在变动 LEO 和 HW 的过程中，logStartOffset 也有可能随之而动 Kafka 也有一个定时任务来负责将所有分区的 logStartOffset书写到起始点文件log-start-offset-checkpoint中 定时周期由broker端参数log.flush.start.offset.checkpoint.interval.ms来配置，默认值为60000 2.4 Leader Epoch(非常重要)前面是正常情况下的leader副本与follower副本之间的同步过程，如果leader副本发生切换，那么同步过程又该如何处理呢？如果处理不当会出现数据丢失和数据不一致问题。 数据丢失首先我们来看数据丢失问题。 数据不一致问题Leader Epoch为了解决上述两种问题，Kafka引入了leader epoch的概念，在需要截断数据的时候使用leader epoch作为参考依据而不是原本的HW。 leader epoch代表leader的纪元信息（epoch），初始值为0。每当leader变更一次，leader epoch的值就会加1，相当于为leader增设了一个版本号。 与此同时，每个副本中还会增设一个矢量＜LeaderEpoch=＞StartOffset＞，其中StartOffset表示当前LeaderEpoch下写入的第一条消息的偏移量。每个副本的Log下都有一个leader-epoch-checkpoint文件，在发生leader epoch变更时，会将对应的矢量对追加到这个文件中。 我们再来看一下引入 leader epoch 之后如何应付前面所说的数据丢失和数据不一致的场景。 我的理解是，这里的 Leader Epoch 相当于 Lamport 时间戳，用于确保全序关系 2.5 Kafka 为什么不支持读写分离(非常重要)在Kafka中，生产者写入消息、消费者读取消息的操作都是与leader副本进行交互的，从而实现的是一种主写主读的生产消费模型。 Kafka并不支持主写从读，这是为什么呢？对于这个问题，我们可以从“收益点”这个角度来做具体分析。 主写从读可以让从节点去分担主节点的负载压力，预防主节点负载过重而从节点却空闲的情况发生。但是主写从读需要解决主从复制延迟带来的问题: 如何解决主从同步过程中，从节点读取到旧消息的问题。 并且在Kafka中，主从同步会比 Redis 更加耗时，它需要经历网络→主节点内存→主节点磁盘→网络→从节点内存→从节点磁盘这几个阶段 另一方面，读写分离要实现的负载均衡，通过分区和kafka 生产消费模型同样可以达到。所以没有必要去实现额外的读写分离。 当然前面的结论成立的前提是，不存在巨大的扇出(分区数据不均衡)。 有以下几种情况（包含但不仅限于）会造成一定程度上的负载不均衡： broker端的分区分配不均。当创建主题的时候可能会出现某些broker分配到的分区数多而其他broker分配到的分区数少，那么自然而然地分配到的leader副本也就不均 生产者写入消息不均。生产者可能只对某些broker中的leader副本进行大量的写入操作，而对其他broker中的leader副本不闻不问 消费者消费消息不均。消费者可能只对某些broker中的leader副本进行大量的拉取操作，而对其他broker中的leader副本不闻不问。 leader副本的切换不均。在实际应用中可能会由于broker宕机而造成主从副本的切换，或者分区副本的重分配等，这些动作都有可能造成各个broker中leader副本的分配不均 总的来说，Kafka 只支持主写主读有几个优点：可以简化代码的实现逻辑，减少出错的可能；将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控;没有延时的影响；在副本稳定的情况下，不会出现数据不一致的情况。 3. 日志同步机制在分布式系统中，日志同步机制既要保证数据的一致性，也要保证数据的顺序性。虽然有许多方式可以实现这些功能，但最简单高效的方式还是从集群中选出一个leader来负责处理数据写入的顺序性。于此同时需要解决的是 leader 选举问题，必须确保选择具有最新日志消息的follower作为新的leader。 日志同步机制的一个基本原则就是：如果告知客户端已经成功提交了某条消息，那么即使 leader宕机，也要保证新选举出来的leader中能够包含这条消息。这里就有一个需要权衡（tradeoff）的地方，如果leader在消息被提交前需要等待更多的follower确认，那么在它宕机之后就可以有更多的follower替代它，不过这也会造成性能的下降。 在Kafka中动态维护着一个ISR集合，处于ISR集合内的节点保持与leader相同的高水位（HW），只有位列其中的副本（unclean.leader.election.enable配置为false）才有资格被选为新的 leader。写入消息时只有等到所有 ISR 集合中的副本都确认收到之后才能被认为已经提交。位于 ISR 中的任何副本节点都有资格成为 leader，选举过程简单、开销低。Kafka中包含大量的分区，leader副本的均衡保障了整体负载的均衡，所以这一因素也极大地影响Kafka的性能指标。 另外，一般的同步策略依赖于稳定的存储系统来做数据恢复，也就是说，在数据恢复时日志文件不可丢失且不能有数据上的冲突。不过它们忽视了两个问题：首先，磁盘故障是会经常发生的，在持久化数据的过程中并不能完全保证数据的完整性；其次，即使不存在硬件级别的故障，我们也不希望在每次写入数据时执行同步刷盘（fsync）的动作来保证数据的完整性，这样会极大地影响性能。而 Kafka 不需要宕机节点必须从本地数据日志中进行恢复，Kafka 的同步方式允许宕机副本重新加入ISR集合，但在进入ISR之前必须保证自己能够重新同步完leader中的所有数据。 4. 可靠性分析(非常重要)前提: 只考虑Kafka本身使用方式的前提下如何最大程度地提高可靠性。 就Kafka而言，越多的副本数越能够保证数据的可靠性，一般而言，设置副本数为3即可满足绝大多数场景对可靠性的要求，更高的可靠性要求可以将副本数设置为 5。与此同时，如果能够在分配分区副本的时候引入基架信息（broker.rack 参数），那么还要应对机架整体宕机的风险。 仅依靠副本数来支撑可靠性是远远不够的，大多数人还会想到生产者客户端参数 acks。 4.1 ack参数配置ack=1对于acks=1的配置，生产者将消息发送到leader副本，leader副本在成功写入本地日志之后会告知生产者已经成功提交。如果此时ISR集合的follower副本还没来得及拉取到leader中新写入的消息，leader就宕机了，那么此次发送的消息就会丢失。 ack=-1对于ack=-1的配置，生产者将消息发送到leader副本，leader副本在成功写入本地日志之后还要等待 ISR 中的 follower 副本全部同步完成才能够告知生产者已经成功提交，即使此时leader副本宕机，消息也不会丢失 同样对于acks=-1的配置，如果在消息成功写入leader副本之后，并且在被ISR中的所有副本同步之前leader副本宕机了，那么生产者会收到异常以此告知此次发送失败。 4.2 可靠性min.insync.replicas但是 ack=-1 并不代表数据一定不会丢失。试想一下这样的情形，leader 副本的消息流入速度很快，而follower副本的同步速度很慢，在某个临界点时所有的follower副本都被剔除出了ISR集合，那么ISR中只有一个leader副本，最终acks=-1演变为acks=1的情形，如此也就加大了消息丢失的风险。 Kafka也考虑到了这种情况，并为此提供了min.insync.replicas参数（默认值为1）来作为辅助（配合acks=-1来使用），这个参数指定了ISR集合中最小的副本数，如果不满足条件就会抛出NotEnoughReplicasException或NotEnoughReplicasAfterAppendException。在正常的配置下，需要满足副本数 &gt; min.insync.replicas参数的值。一个典型的配置方案为：副本数配置为 3，min.insync.replicas 参数值配置为 2。 注意 min.insync.replicas参数在提升可靠性的时候会从侧面影响可用性。试想如果ISR中只有一个leader副本，那么最起码还可以使用，而此时如果配置 min.insync.replicas＞1，则会使消息无法写入。 unclean.leader.election.enable与可靠性和ISR集合有关的还有一个参数—unclean.leader.election.enable。这个参数的默认值为false，如果设置为true就意味着当leader下线时候可以从非ISR集合中选举出新的 leader，这样有可能造成数据的丢失。如果这个参数设置为 false，那么也会影响可用性，非ISR集合中的副本虽然没能及时同步所有的消息，但最起码还是存活的可用副本。 4.3 消息发送模式我们讨论了消息发送的3种模式，即发后即忘、同步和异步。发后即忘的模式，生产者对消息是否写入成功一无所知，不适合高可靠性要求的场景。采用同步或异步的模式，在出现异常情况时可以及时获得通知，以便可以做相应的补救措施，比如选择重试发送（可能会引起消息重复） 重试配置对于可重试异常，客户端内部本身提供了重试机制来应对这种类型的异常，通过 retries 参数即可配置。默认情况下，retries参数设置为0，即不进行重试，对于高可靠性要求的场景，需要将这个值设置为大于 0 的值。 与 retries 参数相关的还有一个retry.backoff.ms参数，它用来设定两次重试之间的时间间隔，以此避免无效的频繁重试。在配置retries和retry.backoff.ms之前，最好先估算一下可能的异常恢复时间，这样可以设定总的重试时间大于这个异常恢复时间，以此来避免生产者过早地放弃重试。如果不知道 retries 参数应该配置为多少，则可以参考 KafkaAdminClient，在 KafkaAdminClient 中retries参数的默认值为5。 retries参数值大于0，则可能引起一些负面的影响: 由于默认的max.in.flight.requests.per.connection参数值为5，这样可能会影响消息的顺序性，对此要么放弃客户端内部的重试功 能，要么将max.in.flight.requests.per.connection参数设置为1，这样也就放弃了吞吐 其次，有些应用对于时延的要求很高，很多时候都是需要快速失败的，设置retries&gt;0会增加客户端对于异常的反馈时延，如此可能会对应用造成不良的影响 4.4 磁盘同步在broker端还有两个参数log.flush.interval.messages和log.flush.interval.ms，用来调整同步刷盘的策略，默认是不做控制而交由操作系统本身来进行处理。 同步刷盘是增强一个组件可靠性的有效方式，但也极其损耗性能。更好的方式是多副本机制，所以这两个参数通常不用修改。 4.5 消息的可靠性对于消息的可靠性，很多人都会忽视消费端的重要性，如果一条消息成功地写入 Kafka，并且也被Kafka完好地保存，而在消费时由于某些疏忽造成没有消费到这条消息，那么对于应用来说，这条消息也是丢失的。 enable.auto.commit 参数的默认值为 true，即开启自动位移提交的功能，虽然这种方式非常简便，但它会带来重复消费和消息丢失的问题，对于高可靠性要求的应用来说显然不可取，所以需要将 enable.auto.commit 参数设置为 false 来执行手动位移提交。 在执行手动位移提交的时候也要遵循一个原则：如果消息没有被成功消费，那么就不能提交所对应的消费位移。对于高可靠要求的应用来说，宁愿重复消费也不应该因为消费异常而导致消息丢失。 有时候，由于应用解析消息的异常，可能导致部分消息一直不能够成功被消费，那么这个时候为了不影响整体消费的进度，可以将这类消息暂存到死信队列中，以便后续的故障排除。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 深入理解客户端]]></title>
    <url>%2F2020%2F04%2F08%2Fkafka%2F08_%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[从客户端入手，深入地挖掘Kafka的实现原理 1. 内容概述本章我们将从客户端的角度入手，同时涉及客户端和服务端的内容，以便深入地挖掘Kafka的实现原理，内容包括: 分区分配策略 消费者协调器和组协调器 _consumer_offset 2. 分区分配策略前面我们讲解了消费者和消费组的模型，客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略，它如下几个策略: RangeAssignor: 默认策略，值为 org.apache.kafka.clients.consumer.RangeAssignor RoundRobinAssignor 值为 org.apache.kafka.clients.consumer.RoundRobinAssignor StickyAssignor 消费者客户端参数 partition.assignment.strategy可以配置多个分配策略，彼此之间以逗号分隔。 2.1 RangeAssignorRangeAssignor 分配策略的原理是 按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，以保证分区尽可能均匀地分配给所有的消费者 对于每一个主题，RangeAssignor策略会将消费组内所有订阅这个主题的消费者按照名称的字典序排序，然后为每个消费者划分固定的分区范围 假设消费组内有2个消费者C0和C1，都订阅了主题t0和t1，并且每个主题都有3个分区，则RangeAssignor 分区分配结果是 12消费者C0: t0p0, t0p1, t1p0, t1p1消费者C1: t0p2, t1p2 2.2 RoundRobinAssignorRoundRobinAssignor分配策略的原理是将消费组内所有消费者及消费者订阅的所有主题的分区按照字典序排序，然后通过轮询方式逐个将分区依次分配给每个消费者。 如果同一个消费组内所有的消费者的订阅信息都是相同的，那么RoundRobinAssignor分配策略的分区分配会是均匀的。 如果同一个消费组内的消费者订阅的信息是不相同的，那么在执行分区分配的时候就不是完全的轮询分配，有可能导致分区分配得不均匀。如果某个消费者没有订阅消费组内的某个主题，那么在分配分区的时候此消费者将分配不到这个主题的任何分区。 2.3 StickyAssignor引入 StickyAssignor 策略，主要有两个目的: 分区的分配要尽可能均匀。 分区的分配尽可能与上次分配的保持相同。 当两者发生冲突时，第一个目标优先于第二个目标。使用StickyAssignor分配策略的一个优点就是可以使分区重分配具备“黏性”，减少不必要的分区移动（即一个分区剥离之前的消费者，转而分配给另一个新的消费者）。 3. 消费者协调器和组协调器多个消费者之间的分区分配是需要协同的，协调过程由消费者协调器（ConsumerCoordinator）和组协调器（GroupCoordinator）来完成，它们之间使用一套组协调协议进行交互。 新版客户端将全部消费组分成多个子集，每个消费组的子集在服务端对应一个 GroupCoordinator 对其进行管理: GroupCoordinator 是 Kafka 服务端中用于管理消费组的组件 而消费者客户端中的 ConsumerCoordinator 组件负责与 GroupCoordinator进行交互 ConsumerCoordinator与GroupCoordinator之间最重要的职责就是负责执行消费者再均衡的操作，包括前面提及的分区分配的工作也是在再均衡期间完成的。就目前而言，一共有如下几种情形会触发再均衡的操作： 有新的消费者加入消费组。 有消费者宕机下线，这个下线指的是因为各种原因，包括迭机、网络延迟、GC 等导致消费者长时间未向GroupCoordinator发送心跳 有消费者主动退出消费组（发送 LeaveGroupRequest 请求）。比如客户端调用了unsubscrible（）方法取消对某些主题的订阅。 消费组所对应的GroupCoorinator节点发生了变更 消费组内所订阅的任一主题或者主题的分区数量发生变化 4. 再均衡原理我们就以有消费者加入消费组为例来简单介绍一下再均衡的具体内容，消费者、消费组及组协调器之间会经历一下几个阶段: 第一阶段（FIND_COORDINATOR） 目的: 消费者需要确定它所属的消费组对应的GroupCoordinator所在的broker，并创建与该broker相互通信的网络连接 第二阶段（JOIN_GROUP）: 进入加入消费组 第三阶段（SYNC_GROUP）: leader 消费者将分区分配的方案同步给各个消费者 第四阶段（HEARTBEAT）：确定拉取消息的起始位置 4.1 FIND_COORDINATOR如果消费者已经保存了与消费组对应的 GroupCoordinator 节点的信息，并且与它之间的网络连接是正常的，那么就可以进入第二阶段。否则需要向集群中的某个节点发送 FindCoordinatorRequest 请求来查找对应的 GroupCoordinator，这里的“某个节点”并非是集群中的任意节点，而是负载最小的节点。 FindCoordinatorRequest 请求体的结构如下，它只有两个域（Field）： coordinator_key 在这里就是消费组的名称，即 groupId coordinator_type置为0 Kafka 在收到 FindCoordinatorRequest 请求之后，会根据 coordinator_key（也就是groupId）查找对应的GroupCoordinator节点，如果找到对应的GroupCoordinator则会返回其相对应的node_id、host和port信息。 GroupCoordinator的查找大体会经过如下这样一个过程: 先根据消费组groupId的哈希值计算__consumer_offsets中的分区编号 找到对应的__consumer_offsets中的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为这个groupId所对应的GroupCoordinator节点 消费者groupId最终的分区分配方案及组内消费者所提交的消费位移信息都会发送给此分区leader副本所在的broker节点，让此broker节点既扮演GroupCoordinator的角色，又扮演保存分区分配方案和组内消费者位移的角色，可以省去很多不必要的中间轮转所带来的开销。 4.2 JOIN_GROUPJoinGroupRequest消费者会向GroupCoordinator发送 JoinGroupRequest 请求，并处理响应。 JoinGroupRequest的结构包含多个域： group_id: 就是消费组的id，通常也表示为groupId。 session_timout: 对应消费端参数 session.timeout.ms，默认值为 10000，即10秒 GroupCoordinator超过session_timeout指定的时间内没有收到心跳报文则认为此消费者已经下线 rebalance_timeout 对应消费端参数 max.poll.interval.ms，默认值为300000，即 5 分钟 表示当消费组再平衡的时候，GroupCoordinator 等待各个消费者重新加入的最长等待时间 member_id 表示 GroupCoordinator 分配给消费者的 id 标识 消费者第一次发送JoinGroupRequest请求的时候此字段设置为null。 protocol_type: 表示消费组实现的协议，对于消费者而言此字段值为“consumer” group_protocols: 数组类型，其中可以囊括多个分区分配策略 主要取决于消费者客户端参数 partition.assignment.strategy 的配置 如果是原有的消费者重新加入消费组，那么在真正发送JoinGroupRequest 请求之前还要执行一些准备工作： 如果消费端参数enable.auto.commit设置为true（默认值也为true），即开启自动提交位移功能，那么在请求加入消费组之前需要向 GroupCoordinator 提交消费位移。这个过程是阻塞执行的，要么成功提交消费位移，要么超时。 如果消费者添加了自定义的再均衡监听器（ConsumerRebalanceListener），那么此时会调用onPartitionsRevoked（）方法在重新加入消费组之前实施自定义的规则逻辑 因为是重新加入消费组，之前与GroupCoordinator节点之间的心跳检测也就不需要了，所以在成功地重新加入消费组之前需要禁止心跳检测的运作。 消费者在发送JoinGroupRequest请求之后会阻塞等待Kafka服务端的响应。服务端在收到JoinGroupRequest 请求后会交由 GroupCoordinator 来进行处理。 选举消费组的leaderGroupCoordinator需要为消费组内的消费者选举出一个消费组的leader: 如果消费组内还没有 leader，那么第一个加入消费组的消费者即为消费组的 leader 如果 leader 消费者退出，选择消费者保存数组中的第一个消费者为 leader 选举分区分配策略每个消费者都可以设置自己的分区分配策略，对消费组而言需要从各个消费者呈报上来的各个分配策略中选举一个彼此都“信服”的策略来进行整体上的分区分配。 这个分区分配的选举并非由leader消费者决定，而是根据消费组内的各个消费者投票来决定的。所谓投票是根据各个消费者呈报的分配策略来实施。最终选举的分配策略基本上可以看作被各个消费者支持的最多的策略。 如果有消费者并不支持选出的分配策略，那么就会报出异常 IllegalArgumentException。消费者所支持的分配策略”是指 partition.assignment.strategy 参数配置的策略，如果这个参数值只配置了RangeAssignor，那么这个消费者客户端只支持 RangeAssignor 分配策略 JoinGroupResponse在此之后，Kafka服务端就要发送 JoinGroupResponse 响应给各个消费者，leader消费者和其他普通消费者收到的响应内容并不相同。 JoinGroupResponse 的结构如下: JoinGroupResponse 包含了多个域: generation_id 用来标识当前消费组的年代信息，避免受到过期请求的影响 leader_id 表示消费组leader消费者的member_id members 发送给普通消费者的JoinGroupResponse中的members内容为空 leader消费者的JoinGroupResponse中的members包含有效数据。members为数组类型，其中包含各个成员信息。 member_metadata 为消费者的订阅信息，与 JoinGroupRequest 中的protocol_metadata内容相同，是对应选举完成后的结果 Kafka把分区分配的具体分配交还给客户端，自身并不参与具体的分配细节，这样即使以后分区分配的策略发生了变更，也只需要重启消费端的应用即可，而不需要重启服务端。 4.3 SYNC_GROUPleader 消费者根据在第二阶段中选举出来的分区分配策略来实施具体的分区分配，在此之后需要将分配的方案同步给各个消费者，此时leader消费者并不是直接和其余的普通消费者同步分配方案，而是通过 GroupCoordinator 这个“中间人”来负责转发同步分配方案的。在第三阶段，也就是同步阶段，各个消费者会向GroupCoordinator发送 SyncGroupRequest 请求来同步分配方案，如下图。 只有leader消费者发送的 SyncGroupRequest 请求中才包含具体的分区分配方案，其余消费者发送的SyncGroupRequest请求中的group_assignment为空。 其余消费者发送的SyncGroupRequest请求中的group_assignment为空。它是一个数组类型，其中包含了各个消费者对应的具体分配方案：member_id表示消费者的唯一标识，而member_assignment是与消费者对应的分配方案。 服务端在收到消费者发送的SyncGroupRequest请求之后会交由GroupCoordinator来负责具体的逻辑处理。GroupCoordinator同样会先对SyncGroupRequest请求做合法性校验，在此之后会将从 leader 消费者发送过来的分配方案提取出来，连同整个消费组的元数据信息一起存入Kafka的__consumer_offsets主题中，最后发送响应给各个消费者以提供给各个消费者各自所属的分配方案。 SyncGroupResponseSyncGroupRequest请求对应的是 SyncGroupResponse，里面包含的就是消费者对应的所属分配方案 当消费者收到所属的分配方案之后会调用PartitionAssignor中的onAssignment（）方法。随后再调用ConsumerRebalanceListener中的OnPartitionAssigned（）方法。之后开启心跳任务，消费者定期向服务端的GroupCoordinator发送HeartbeatRequest来确定彼此在线。 消费组元数据信息消费组的元数据信息也保存在 __consumer_offsets主题中。每个消费组的元数据信息都是一条消息，不过这类消息并不依赖于具体版本的消息格式。具体的格式如下: key和 value 中的 version 表示版本，就目前版本而言，key的version为2，而value的version为1。 key中的 group 字段，就是消费组的名称，确定这条信息所要存储的分区还是根据单独的group字段来计算的，这样就可以保证消费组的元数据信息与消费组对应的GroupCoordinator处于同一个broker节点上，省去了中间轮转的开销。 value 中包含的内容有很多 protocol_type：消费组实现的协议，这里的值为“consumer”。 generation：标识当前消费组的年代信息，避免收到过期请求的影响。 protocol：消费组选取的分区分配策略。 leader：消费组的leader消费者的名称。 members：数组类型，其中包含了消费组的各个消费者成员信息，其中subscription和assignment这两个字段，分别代码消费者的订阅信息和分配信息。 4.4 HEARTBEAT进入这个阶段之后，消费组中的所有消费者就会处于正常工作状态。在正式消费之前，消费者还需要确定拉取消息的起始位置。消费者可以通过OffsetFetchRequest请求获取上次提交的消费位移并从此处继续消费。 消费者通过向 GroupCoordinator 发送心跳来维持它们与消费组的从属关系，以及它们对分区的所有权关系。 心跳线程是一个独立的线程，可以在轮询消息的空档发送心跳。如果消费者停止发送心跳的时间足够长，则整个会话就被判定为过期，GroupCoordinator 也会认为这个消费者已经死亡，就会触发一次再均衡行为。消费者的心跳间隔时间由参数heartbeat.interval.ms指定，默认值为3000，即3秒，这个参数必须比session.timeout.ms参数设定的值要小，一般情况下heartbeat.interval.ms的配置值不能超过session.timeout.ms配置值的1/3。这个参数可以调整得更低，以控制正常重新平衡的预期时间。 如果一个消费者发生崩溃，并停止读取消息，那么 GroupCoordinator 会等待一小段时间，确认这个消费者死亡之后才会触发再均衡。在这一小段时间内，死掉的消费者并不会读取分区里的消息。这个一小段时间由 session.timeout.ms 参数控制，该参数的配置值必须在broker端参数 group.min.session.timeout.ms（默认值为 6000，即 6 秒）和 group.max.session.timeout.ms（默认值为300000，即5分钟）允许的范围内。 还有一个参数 max.poll.interval.ms，它用来指定使用消费者组管理时 poll（）方法调用之间的最大延迟，也就是消费者在获取更多消息之前可以空闲的时间量的上限。如果此超时时间期满之前poll（）没有调用，则消费者被视为失败，并且分组将重新平衡，以便将分区重新分配给别的成员。 除了被动退出消费组，还可以使用 LeaveGroupRequest 请求主动退出消费组，比如客户端调用了unsubscrible（）方法取消对某些主题的订阅。 5. __consumer_offsets剖析对于主题consumer_offsets的深度掌握也可以让我们更好地理解和使用好位移提交。一般情况下，当集群中第一次有消费者消费消息时会自动创建主题 consumer_offsets。 __consumer_offsets 有如下几个控制参数: offsets.topic.replication.factor: 设置副本数，默认值为 3 offsets.topic.num.partitions: 设置分区数，默认值为 50 5.1 OffsetCommitRequest客户端提交消费位移是使用 OffsetCommitRequest 请求，其结构如下: OffsetCommitRequest 包含多个域: retention_time 表示当前提交的消费位移所能保留的时长，不过对于消费者而言这个值保持为-1 也就是说，按照 broker 端的配置 offsets.retention.minutes 来确定保留时长 offsets.retention.minutes的默认值为10080，即7天，超过这个时间后消费位移的信息就会被删除（使用墓碑消息和日志压缩策略） 其余字段大抵也是按照分区的粒度来划分消费位移的： topic表示主题名称 partition表示分区编号等 注意这里还有一个metadata字段 metadata是自定义的元数据信息，不设置默认为空字符串，其长度不能超过 offset.metadata.max.bytes 参数（broker 端配置，默认值为4096）所配置的大小 5.2 消费位移对应的消息格式同消费组的元数据信息一样，最终提交的消费位移也会以消息的形式发送至主题__consumer_offsets，与消费位移对应的消息也只定义了 key 和 value 字段的具体内容，它不依赖于具体版本的消息格式，以此做到与具体的消息格式无关。 key和value中都包含了version字段，这个用来标识具体的key和value的版本信息。目前key和value的version值都为1。 key 包含 group、topic、partition字段，分别表示消费组的groupId、主题名称和分区编号 虽然key中包含了4个字段，但最终确定这条消息所要存储的分区还是根据单独的 group 字段来计算的，这样就可以保证消费位移信息与消费组对应的GroupCoordinator 处于同一个 broker 节点上，省去了中间轮转的开销，这一点与消费组的元数据信息的存储是一样的。 value: 包含 offset、metadata、commit_timestamp、expire_timestamp字段分别表示消费位移、自定义的元数据信息、位移提交到 Kafka 的时间戳、消费位移被判定为超时的时间戳。 其中 offset 和 metadata 与OffsetCommitRequest 请求体中的 offset 和 metadata 对应 expire_timestamp 和OffsetCommitRequest 请求体中的 retention_time 也有关联， commit_timestamp 值与offsets.retention.minutes参数值之和即为expire_timestamp（默认情况下） 5.3 OffsetCommitResponse在处理完消费位移之后，Kafka返回OffsetCommitResponse给客户端，OffsetCommitResponse的结构如下图: 5.4 位移查看工具可以通过 kafka-console-consumer.sh 脚本来查看__consumer_offsets 中的内容。 12345bin/kafka-console-consumer.sh / --bootstrap-server localhost:9092 / --topic __consumer_offset / --partition 20 / --formatter "kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter" 5.5 消费位移清理在Kafka中有一个名为“delete-expired-group-metadata”的定时任务来负责清理过期的消费位移，这个定时任务的执行周期由参数 offsets.retention.check.interval.ms 控制，默认值为600000，即10分钟。 最后，如果有若干消费者消费了某个主题中的消息，并且也提交了相应的消费位移，那么在删除这个主题之后会一并将这些消费位移信息删除。 6. 事务一般而言，消息中间件的消息传输保障有3个层级，分别如下。 at most once：至多一次。消息可能会丢失，但绝对不会重复传输。 at least once：最少一次。消息绝不会丢失，但可能会重复传输。 exactly once：恰好一次。每条消息肯定会被传输一次且仅传输一次。 生产者可以进行多次重试来确保消息已经写入 Kafka，这个重试的过程中有可能会造成消息的重复写入，所以这里 Kafka 提供的消息传输保障为 at least once。 对消费者而言，消费者处理消息和提交消费位移的顺序在很大程度上决定了消费者提供哪一种消息传输保障。 Kafka从0.11.0.0版本开始引入了幂等和事务这两个特性，以此来实现EOS（exactly once semantics，精确一次处理语义）。 6.1 幂等所谓的幂等，简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会重复写入消息，而使用Kafka的幂等性功能之后就可以避免这种情况。 开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数 enable.idempotence 设置为true即可。 不过如果要确保幂等性功能正常，还需要确保生产者客户端的 retries、acks、max.in.flight.requests.per.connection 这几个参数不被配置错。实际上在使用幂等性功能的时候，用户完全可以不用配置（也不建议配置）这几个参数。 如果用户对这几个参数配置了: retries: 如果指定了 retries 参数，那么这个参数的值必须大于 0，否则会报出ConfigException 如果没有显式地指定 retries 参数，那么 KafkaProducer 会将它置为 Integer.MAX_VALUE 同时还需要保证 max.in.flight.requests.per.connection 参数的值不能大于5，这个参数的默认值是 5，否则也会报出ConfigException ack: 如果显式地指定了 acks 参数，那么需要保证这个参数的值为-1（all） 如果不为-1（这个参数的值默认为1），那么也会报出ConfigException 如果用户没有显式地指定这个参数，那么KafkaProducer会将它置为-1 幂等的实现为了实现生产者的幂等性，Kafka为此引入了producer id（以下简称PID）和序列号（sequence number）这两个概念，分别对应 v2 版的日志格式中RecordBatch的producer id和first seqence这两个字段。 每个新的生产者实例在初始化的时候都会被分配一个PID，这个PID对用户而言是完全透明的。对于每个PID，消息发送到的每一个分区都有对应的序列号，这些序列号从0开始单调递增。生产者每发送一条消息就会将＜PID，分区＞对应的序列号的值加1。 broker端会在内存中为每一对＜PID，分区＞维护一个序列号。对于收到的每一条消息，它的序列号的值（SN_new），broker端中维护的对应的序列号的值（SN_old） 如果 SN_new=SN_old+1，broker才会接收它 如果SN_new＜SN_old+1，那么说明消息被重复写入，broker可以直接将其丢弃 如果SN_new＞SN_old+1，那么说明中间有数据尚未写入，出现了乱序，暗示可能有消息丢失，对应的生产者会抛出OutOfOrderSequenceException，这个异常是一个严重的异常，后续的诸如 send（）、beginTransaction（）、commitTransaction（）等方法的调用都会抛出IllegalStateException的异常。 引入序列号来实现幂等也只是针对每一对＜PID，分区＞而言的，也就是说，Kafka的幂等只能保证单个生产者会话（session）中单分区的幂等。 6.2 事务幂等性并不能跨多个分区运作，而事务可以弥补这个缺陷。事务可以保证对多个分区写入操作的原子性。 对流式应用，一个典型的应用模式为“consume-transform-produce”：应用程序从某个主题中消费消息，然后经过一系列转换后写入另一个主题。Kafka 中的事务可以使应用程序将消费消息、生产消息、提交消费位移当作原子操作来处理，同时成功或失败，即使该生产或消费会跨多个分区。 生产者事务保证为了实现事务，应用程序必须提供唯一的 transactionalId，这个 transactionalId 通过客户端参数transactional.id来显式设置。 事务要求生产者开启幂等特性，因此通过将transactional.id参数设置为非空从而开启事务特性的同时需要将 enable.idempotence 设置为 true （如果未显式设置，则KafkaProducer默认会将它的值设置为true），如果用户显式地将enable.idempotence设置为false，则会报出ConfigException： transactionalId与PID一一对应，两者之间所不同的是transactionalId由用户显式设置，而PID是由Kafka内部分配的。另外，为了保证新的生产者启动后具有相同 transactionalId 的旧生产者能够立即失效，每个生产者通过transactionalId获取PID的同时，还会获取一个单调递增的producer epoch（对应下面要讲述的 KafkaProducer.initTransactions（）方法）。如果使用同一个transactionalId开启两个生产者，那么前一个开启的生产者会报出如下的错误： 从生产者的角度分析，通过事务，Kafka 可以保证跨生产者会话的消息幂等发送，以及跨生产者会话的事务恢复。 前者表示具有相同 transactionalId 的新生产者实例被创建且工作的时候，旧的且拥有相同transactionalId的生产者实例将不再工作。 后者指当某个生产者实例宕机后，新的生产者实例可以保证任何未完成的旧事务要么被提交（Commit），要么被中止（Abort），如此可以使新的生产者实例从一个正常的状态开始工作。 消费者事务保证从消费者的角度分析，事务能保证的语义相对偏弱。出于以下原因，Kafka 并不能保证已提交的事务中的所有消息都能够被消费： 对采用日志压缩策略的主题而言，事务中的某些消息有可能被清理（相同key的消息，后写入的消息会覆盖前面写入的消息） 事务中消息可能分布在同一个分区的多个日志分段（LogSegment）中，当老的日志分段被删除时，对应的消息可能会丢失 消费者可以通过seek（）方法访问任意offset的消息，从而可能遗漏事务中的部分消息。 消费者在消费时可能没有分配到事务内的所有分区，如此它也就不能读取事务中的所有消息。 事务接口KafkaProducer提供了5个与事务相关的方法: initTransactions方法: 用来初始化事务 这个方法能够执行的前提是配置了transactionalId，如果没有则会报出IllegalStateException beginTransaction（）方法用来开启事务 sendOffsetsToTransaction（）方法为消费者提供在事务内的位移提交的操作； commitTransaction（）方法用来提交事务； abortTransaction（）方法用来中止事务，类似于事务回滚 事务实现(未完成)日志文件中除了普通的消息，还有一种消息专门用来标志一个事务的结束，它就是控制消息（ControlBatch）。控制消息一共有两种类型：COMMIT和ABORT，分别用来表征事务已经成功提交或已经被成功中止。KafkaConsumer 可以通过这个控制消息来判断对应的事务是被提交了还是被中止了，然后结合参数isolation.level配置的隔离级别来决定是否将相应的消息返回给消费端应用，如图7-19所示。注意ControlBatch对消费端应用不可见。 为了实现事务的功能，Kafka还引入了事务协调器（TransactionCoordinator）来负责处理事务，这一点可以类比一下组协调器（GroupCoordinator）。每一个生产者都会被指派一个特定的TransactionCoordinator，所有的事务逻辑包括分派 PID 等都是由 TransactionCoordinator 来负责实施的。TransactionCoordinator 会将 事务状态持久化到内部主题__transaction_state 中。下面就以最复杂的consume-transform-produce的流程（参考图7-21）为例来分析Kafka事务的实现原理。 整个过程分为如下步骤: 1.查找TransactionCoordinator 与查找GroupCoordinator节点一样，也是通过FindCoordinatorRequest请求来实现的，不同是请求中的coordinator_type就由原来的0变成了1 Kafka 在收到 FindCoorinatorRequest 请求之后，会根据 coordinator_key （也就是transactionalId）查找对应的TransactionCoordinator节点。 具体查找TransactionCoordinator的方式是根据transactionalId的哈希值对__transaction_state中的分区个数取余，计算出对应分区号 找到对应的分区之后，再寻找此分区leader副本所在的broker节点，该broker节点即为这个transactionalId对应的TransactionCoordinator节点 _transaction_state中的分区个数，可以通过broker端参数transaction.state.log.num.partitions来配置，默认值为50 2.获取PID 生产者获取PID的操作是通过InitProducerIdRequest请求来实现的 请求体中包含两个字段: transactional_id 表示事务的 transactionalId transaction_timeout_ms表示TransactionCoordinaor等待事务状态更新的超时时间，通过生产者客户端参数transaction.timeout.ms配置，默认值为60000。 2.1保存PID 当TransactionCoordinator第一次收到包含该transactionalId的InitProducerIdRequest请求时，它会把transactionalId和对应的PID以消息（我们习惯性地把这类消息称为“事务日志消息”）的形式保存到主题__transaction_state中 开启事务: KafkaProducer的beginTransaction（）方法可以开启一个事务，调用该方法后，生产者本地会标记已经开启了一个新的事务 只有在生产者发送第一条消息之后 TransactionCoordinator才会认为该事务已经开启。 Consume-Transform-Produce AddPartitionsToTxnRequest: 当生产者给一个新的分区（TopicPartition）发送数据前，它需要先向TransactionCoordinator发送AddPartitionsToTxnRequest请求 这个请求会让 TransactionCoordinator 将＜transactionId，TopicPartition＞的对应关系存储在主题__transaction_state中 有了这个对照关系之后，我们就可以在后续的步骤中为每个分区设置COMMIT或ABORT标记 如果该分区是对应事务中的第一个分区，那么此时TransactionCoordinator还会启动对该事务的计时 ProduceRequest 发送生产消息 与普通消息的区别是ProducerBatch中会包含实质的PID、producer_epoch和sequence number AddOffsetsToTxnRequest TransactionCoordinator收到这个请求之后会通过groupId来推导出在consumer_offsets中的分区，之后TransactionCoordinator会将这个分区保存在transaction_state中 TxnOffsetCommitRequest 将本次事务中包含的消费位移信息offsets存储到主题__consumer_offsets中 EndTxnRequest: 提交或者中止事务 commitTransaction（）方法还是 abortTransaction（）方法，生产者都会向TransactionCoordinator发送EndTxnRequest请求 TransactionCoordinator在收到EndTxnRequest请求后会执行如下操作： 将PREPARE_COMMIT或PREPARE_ABORT消息写入主题__transaction_state 通过WriteTxnMarkersRequest请求将COMMIT或ABORT信息写入用户所使用的普通主题和__consumer_offsets 将COMPLETE_COMMIT或COMPLETE_ABORT信息写入内部主题__transaction_state __transaction_state＜transaction_Id，PID＞的对应关系被持久化存储到主题__transaction_state中的具体内容格式入下图所示: 其中: transaction_status 包含 Empty（0） Ongoing（1） PrepareCommit（2） PrepareAbort（3） CompleteCommit（4） CompleteAbort（5） Dead（6）这几种状态 InitProducerIdRequest/InitProducerIdResponse InitProducerIdRequest还会触发执行以下任务： 增加该 PID 对应的 producer_epoch。具有相同 PID 但 producer_epoch 小于该producer_epoch的其他生产者新开启的事务将被拒绝 恢复（Commit）或中止（Abort）之前的生产者未完成的事务 AddPartitionsToTxnRequest 事务提交Kafka 的事务实现是两阶段提交。 将PREPARE_COMMIT或PREPARE_ABORT消息写入主题__transaction_state，进行预提交 第一阶段: WriteTxnMarkersRequest 由TransactionCoordinator 发向事务中各个分区的leader 节点的 当节点收到这个请求之后，会在相应的分区中写入控制消息（ControlBatch） 控制消息用来标识事务的终结，它和普通的消息一样存储在日志文件中 第二阶段: TransactionCoordinator将最终的COMPLETE_COMMIT或COMPLETE_ABORT信息写入主题transaction_state以表明当前事务已经结束，此时可以删除主题transaction_state中所有关于该事务的消息。 由于主题__transaction_state 采用的日志清理策略为日志压缩，所以这里的删除只需将相应的消息设置为墓碑消息即可。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 服务端]]></title>
    <url>%2F2020%2F04%2F07%2Fkafka%2F07_%E6%9C%8D%E5%8A%A1%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[Kafka 服务端的核心设计和运行机制 1. Kafka 服务端概述前面我们已经介绍了，Kafka 生产者、消费者客户端、主题与分区管理、日志存储。但对于Kafka 服务端的一些核心设计与运行机理还未涉及。那么本节我们来介绍 kafka 服务端的相关设计，包括: 网络协议设计 时间轮 延迟操作 控制器及参数解密 尤其是协议设计和控制器的介绍，这些是深入了解Kafka的必备知识点。 1. 协议设计Kafka自定义了一组基于TCP的二进制协议，在 Kafka 2.0.0 中，一共包含了 43 种协议类型，每种协议类型都有对应的请求（Request）和响应（Response） Request每种类型的Request都包含相同结构的协议请求头（RequestHeader）和不同结构的协议请求体。 协议请求头中包含 4 个域（Field）: api_key: API 标识，标识请求的类型 api_version: API 版本号 correlation_id: 客户端生成的唯一请求 ID 标识，服务器端在处理完请求后也会将此 ID 写到 Response，这样客户端就能将请求和响应关联起来 client_id: 客户端 ID Response每种类型的 Response 也包含相同结构的协议响应头（ResponseHeader）和不同结构的响应体（ResponseBody） 协议响应头中只有一个 correlation_id，这是客户端请求中的请求 ID。 请求响应所使用的基础类型Kafka中所有协议类型的Request和Response的结构都是具备固定格式的，并且它们都构建于多种基本数据类型之上。这些基础类型如下图所示: 类型 描述 boolean int8、int16、int32、int64 uint32 varint 变长整型，值在 -2^31 - 2^31-1，ZigZag编码 varlong 变长长整型，值在 -2^63 - 2^63-1，ZigZag编码 string 字符串，开头是int16的长度字段，代表字符串长度 N，后面包含 N 个UTF8编码的字符串 nullable_string 可为空的字符串，空字符串用-1表示，其他同string bytes 字节序列，开头是int32的长度字段，代表字节序列长度 N，后面包含 N 个字节 nullable_bytes 可为空的字节序列，空为 -1 records 表示kafka 中的一个消息序列，可以看做 nullable_bytes array 给定类型T的数组，T可以是基础类型或基础类型组成的结构体，开头是int32的长度字段，表示有 N 个T示例，后面在跟 N 个 T 实例；空数组表示为 -1 下面就以最常见的消息发送和消息拉取的两种协议类型做细致的讲解: 消息发送的协议类型: ProduceRequest/ProduceResponse，对应的api_key=0，表示PRODUCE 经历了 7 个版本(V0-V6)，我们将讲解最新版本（V6，即api_version=6） 拉取消息的协议类型: FetchRequest/FetchResponse，对应的api_key=1，表示FETCH 经历了 9 个版本(V0-V8)，我们将讲解最新版本（V8，即api_version=8） 1.1 ProduceRequest/ProduceResponseProduceRequestProduceRequest 的组织结构如下图所示: 除了请求头中的4个域，其余ProduceRequest请求体中各个域的含义如下: 在讲解生产者客户端时我们了解到: 消息累加器 RecordAccumulator 中的消息是以＜分区，Deque＜ProducerBatch＞＞的形式进行缓存的 之后由Sender线程转变成＜Node，List＜ProducerBatch＞＞的形式 针对每个Node，Sender线程在发送消息前会将对应的List＜ProducerBatch＞形式的内容转变成 ProduceRequest 的具体结构 List＜ProducerBatch＞中的内容首先会按照主题名称进行分类（对应ProduceRequest中的域topic），然后按照分区编号进行分类（对应ProduceRequest中的域partition），分类之后的ProducerBatch集合就对应ProduceRequest中的域record_set 每个分区中的消息是顺序追加的，那么在客户端中按照分区归纳好之后就可以省去在服务端中转换的操作了，这样就将负载分摊到客户端，减轻了服务端的压力 ProducerResponseV6版本中ProduceResponse的组织结构如下图所示: 除了响应头中的correlation_id，其余ProduceResponse各个域的含义如下: 1.2 FetchRequest/FetchResponseFetchRequestFetchRequest的组织结构如下图所示: 除了请求头中的4个域，其余FetchRequest中各个域的含义如下 如果要拉取某个分区中的消息，就需要指定详细的拉取信息，也就是需要设定 partition、fetch_offset、log_start_offset和max_bytes这4个域的具体值，那么对每个分区而言，就需要占用4B+8B+8B+4B=24B的空间。 一般情况下，不管是 follower 副本还是普通的消费者，它们的订阅信息是长期固定的。也就是说，FetchRequest 中的 topics 域的内容是长期固定的，只有在拉取开始时或发生某些异常时会有所变动。 Kafka从1.1.0版本开始针对FetchRequest引入了session_id、epoch和forgotten_topics_data等域，session_id和epoch确定一条拉取链路的fetch session，当session建立或变更时会发送全量式的 FetchRequest，所谓的全量式就是指请求体中包含所有需要拉取的分区信息；当session稳定时则会发送增量式的FetchRequest请求，里面的topics域为空，因为topics域的内容已经被缓存在了session链路的两侧。如果需要从当前fetch session中取消对某些分区的拉取订阅，则可以使用forgotten_topics_data字段来实现。 这个改进在大规模（有大量的分区副本需要及时同步）的Kafka集群中非常有用，它可以提升集群间的网络带宽的有效使用率。不过对客户端而言效果不是那么明显，一般情况下单个客户端不会订阅太多的分区，不过总体上这也是一个很好的优化改进。 FetchResponseFetchResponse 的结构如下: FetchResponse结构中的域也很多，它主要分为4层: 第1层包含throttle_time_ms、error_code、session_id 和 responses 第二层 reponse 包括具体的响应内容 第3层中包含分区的元数据信息（partition、error_code 等）及具体的消息内容（record_set），aborted_transactions和事务相关 2. 时间轮Kafka中存在大量的延时操作，比如延时生产、延时拉取和延时删除等。Kafka并没有使用JDK自带的Timer或DelayQueue来实现延时的功能，而是基于时间轮的概念自定义实现了一个用于延时功能的定时器（SystemTimer）。JDK中Timer和DelayQueue的插入和删除操作的平均时间复杂度为O（nlogn），而基于时间轮可以将插入和删除操作的时间复杂度都降为O（1） 2.1 时间轮的数据结构时间轮的数据结构如下: 其由如下几个部分组成: TimingWheel: 时间轮 是一个存储定时任务的环形队列，底层采用数组实现 数组中的每个元素可以存放一个定时任务列表（TimerTaskList） 数组的每一项称为时间格，每个时间格代表当前时间轮的基本时间跨度（tickMs） 时间轮的时间格个数是固定的，即数组长度，可用wheelSize来表示 时间轮的总体时间跨度 = tickMs * wheelSize TimerTaskList: TimerTaskList是一个环形的双向链表 链表中的每一项表示的都是定时任务项（TimerTaskEntry），其中封装了真正的定时任务（TimerTask） currentTime: 表示事件轮的表盘指针，用来表示时间轮当前所处的时间，是tickMs的整数倍 currentTime可以将整个时间轮划分为到期部分和未到期部分 currentTime当前指向的时间格也属于到期部分，表示刚好到期，需要处理此时间格所对应的TimerTaskList中的所有任务。 2.2 定时任务的执行时间轮的tickMs为1ms且wheelSize等于20，初始情况下表盘指针currentTime指向时间格0: 定时为2ms的任务会存放到时间格为2的TimerTaskList中 2ms 后，currentTime 向后推移到时间格2，此时就需要执行时间格2中 TimerTaskList 中的任务 此时定时为 8ms 的任务到来，它将被插入到时间格10中 定时为 19ms 的任务会复用原来的TimerTaskList，被插入原本已经到期的时间格1中 整个时间轮的总体跨度是不变的，随着指针currentTime的不断推进，当前时间轮所能处理的时间段也在不断后移，总体时间范围在currentTime和currentTime+interval之间。 2.3 多层时间轮加入定时任务的到期事件为 100w ms，应该怎么办呢？很显然我们不能创建一个 100w 项的数组。 Kafka 为此引入了层级时间轮的概念，当任务的到期时间超过了当前时间轮所表示的时间范围时，就会尝试添加到上层时间轮中。 复用之前的案例: 每一层时间轮的wheelSize是固定的，都是20 第一层的时间轮tickMs=1ms、wheelSize=20、interval=20ms 第二层的时间轮的tickMs为第一层时间轮的interval，即20ms，interval=400ms 以此类推，第三层时间轮 tickMs=400ms，interval=8000ms 450ms的定时任务，的执行过程是这样的: 450ms 超过了第二层能表示的最大范围 400ms，所以最终被插入第三层时间轮中时间格1的TimerTaskList。 第三层的时间格1表示的时间范围[400ms，800ms），这个时间范围内可能有多个任务。当此TimerTaskList到期之时，原本定时为450ms的任务还剩下50ms的时间，还不能执行这个任务的到期操作。 这里就有一个 时间轮降级 的操作，会将这个剩余时间为 50ms 的定时任务重新提交到层级时间轮中，此时第一层时间轮的总体时间跨度20ms不够，而第二层足够，所以该任务被放到第二层时间轮到期时间为[40ms，60ms）的时间格中 再经历40ms之后，此任务还剩不到 10ms，将被再一次降级，被添加到第一层时间轮到期时间为[10ms，11ms）的时间格中 再经历 10ms 后，此任务真正到期，最终执行相应的到期操作 2.4 kafka 实现在 Kafka 中: TimingWheel 在创建的时候以当前系统时间为第一层时间轮的起始时间（startMs） 除了第一层时间轮，其余高层时间轮的起始时间（startMs）都设置为创建此层时间轮时前面第一轮的currentTime。 每一轮的 currentTime=timeMs-（timeMs%tickMs），timeMs 为当前事件与 startMs 的插值，时间每推进一次，每个层级的时间轮的currentTime都会依据此公式执行推进。 Kafka 中的定时器只需持有 TimingWheel 的第一层时间轮的引用，但每一层时间轮都会有一个引用（overflowWheel）指向更高一层的应用 2.5 Kafka如何推进时间在Kafka中到底是怎么推进时间的呢？Kafka中的定时器借了JDK中的DelayQueue来协助推进时间轮。 具体做法是 对于每个使用到的TimerTaskList都加入DelayQueue，“每个用到的TimerTaskList”特指非哨兵节点的定时任务项TimerTaskEntry对应的TimerTaskList。 DelayQueue会根据TimerTaskList对应的超时时间expiration来排序，最短expiration的TimerTaskList会被排在DelayQueue的队头。 Kafka中会有一个线程来获取 DelayQueue 中到期的任务列表，线程所对应的名称叫作“ExpiredOperationReaper”，可以直译为“过期操作收割机”。 当“收割机”线程获取 DelayQueue 中超时的任务列表 TimerTaskList之后，既可以根据 TimerTaskList 的 expiration 来推进时间轮的时间，也可以就获取的TimerTaskList执行相应的操作，对里面的TimerTaskEntry该执行过期操作的就执行过期操作，该降级时间轮的就降级时间轮 可以发现，Kafka 中的 TimingWheel 专门用来执行插入和删除 TimerTaskEntry的操作，而 DelayQueue 专门负责时间推进的任务。 3. 延时操作在Kafka中有多种延时操作，比如延时生产，还有延时拉取（DelayedFetch）、延时数据删除（DelayedDeleteRecords）等。 延时由如下几个部分组成: 首先他必须由一个超时时间，如果在这个超时时间内未完成任务，就要强制返回 ，延时操作不同于定时操作，定时操作是指在特定时间之后执行的操作，而延时操作要在所设定的超时时间之前完成，所以延时操作能够支持外部事件的触发 外部事件的触发，要配备一个监听池来负责监听每个分区的外部事件 而超时操作则需要一个定时器 前面我们提到，时间轮是由线程ExpiredOperationReaper来驱动的，所以: 定时器、ExpiredOperationReaper线程、延时管理器(DelayedOperationPurgatory)、监听池是一一对应的。 ExpiredOperationReaper不仅可以推进时间轮，还会定期清理监听池中已完成的延时操作。 3.1 延时生产下图描绘了客户端在请求写入消息到收到响应结果的过程中与延时生产操作相关的细节: 其中: 如果客户端设置的 acks 参数不为-1，或者没有成功的消息写入，那么就直接返回结果给客户端 否则就需要创建延时生产操作并存入延时操作管理器 最终要么由外部事件触发，要么由超时触发而执行。 3.2 延时拉取有延时生产就有延时拉取。两个follower副本都已经拉取到了leader副本的最新位置，此时又向leader副本发送拉取请求，而leader副本并没有新的消息写入，那么此时leader副本该如何处理呢？ 如果 leader 没有新消息，而副本的拉取操作周而复始，只会平白消耗资源。 Kafka选择了延时操作来处理这种情况: Kafka在处理拉取请求时，会先读取一次日志文件，如果收集不到足够多（fetchMinBytes，由参数fetch.min.bytes配置，默认值为1）的消息，那么就会创建一个延时拉取操作（DelayedFetch）以等待拉取到足够数量的消息 当延时拉取操作执行时，会再读取一次日志文件，然后将拉取结果返回给 follower 副本 如果拉取进度一直没有追赶上leader副本，那么在拉取leader副本的消息时一般拉取的消息大小都会不小于fetchMinBytes，这样Kafka也就不会创建相应的延时拉取操作，而是立即返回拉取结果 延时拉取操作也会有一个专门的延时操作管理器负责管理。延时拉取操作同样是由超时触发或外部事件触发而被执行的。外部事件触发就稍复杂了一些，因为拉取请求不单单由 follower 副本发起，也可以由消费者客户端发起，两种情况所对应的外部事件也是不同的。 follower副本的延时拉取，它的外部事件就是消息追加到了leader副本的本地日志文件中；如果是消费者客户端的延时拉取，它的外部事件可以简单地理解为HW的增长。 4. 控制器在 Kafka 集群中会有一个或多个 broker，其中有一个 broker 会被选举为控制器（Kafka Controller），它负责 管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。 4.1 控制器选举Kafka中的控制器选举工作依赖于ZooKeeper: 成功竞选为控制器的broker会在ZooKeeper中创建/controller这个临时（EPHEMERAL）节点。 每个 broker 启动的时候会去尝试读取/controller节点的brokerid的值: 如果读取到brokerid的值不为-1，则表示已经有其他 broker 节点成功竞选为控制器，所以当前 broker 就会放弃竞选； 如果 ZooKeeper 中不存在/controller节点，或者这个节点中的数据异常，那么就会尝试去创建/controller节点。 当前broker去创建节点的时候，也有可能其他broker同时去尝试创建这个节点，只有创建成功的那个broker才会成为控制器，而创建失败的broker竞选失败。 每个broker都会在内存中保存当前控制器的brokerid值，这个值可以标识为activeControllerId。 4.2 屏蔽令牌ZooKeeper 中还有一个与控制器有关的/controller_epoch 节点，这个节点是持久（PERSISTENT）节点，节点中存放的是一个整型的controller_epoch值。controller_epoch用于记录控制器发生变更的次数，即记录当前的控制器是第几代控制器，我们也可以称之为“控制器的纪元”。 controller_epoch 的更新过程是这样的: controller_epoch 的初始值为1，即集群中第一个控制器的纪元为1 当控制器发生变更时，每选出一个新的控制器就将该字段值加1 每个和控制器交互的请求都会携带controller_epoch这个字段 如果请求的controller_epoch值小于内存中的controller_epoch值，则认为这个请求是向已经过期的控制器所发送的请求，那么这个请求会被认定为无效的请求。 如果请求的controller_epoch值大于内存中的controller_epoch值，那么说明已经有新的控制器当选了。由此可见，Kafka 通过 controller_epoch 来保证控制器的唯一性，进而保证相关操作的一致性。 4.3 控制器职责具备控制器身份的broker具有如下的额外职责: 监听分区相关的变化: 为ZooKeeper中的/admin/reassign_partitions 节点注册 PartitionReassignmentHandler，用来处理分区重分配的动作 为 ZooKeeper 中的/isr_change_notification节点注册IsrChangeNotificetionHandler，用来处理ISR集合变更的动作 为ZooKeeper中的/admin/preferred-replica-election节点添加PreferredReplicaElectionHandler，用来处理优先副本的选举动作 监听主题相关的变化: 为 ZooKeeper 中的/brokers/topics 节点添加TopicChangeHandler，用来处理主题增减的变化 为 ZooKeeper 中的/admin/delete_topics节点添加TopicDeletionHandler，用来处理删除主题的动作 监听broker相关的变化: 为ZooKeeper中的/brokers/ids节点添加BrokerChangeHandler，用来处理broker增减的变化 对主题、分区及broker有关的信息进行管理。对所有主题对应的 ZooKeeper 中的/brokers/topics/＜topic＞节点添加PartitionModificationsHandler，用来监听主题中的分区分配变化 启动并管理分区状态机和副本状态机 更新集群的元数据信息 如果参数 auto.leader.rebalance.enable 设置为 true，则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的优先副本的均衡 控制器在选举成功之后会读取 ZooKeeper 中各个节点的数据来初始化上下文信息（ControllerContext），控制需要对这些上下文信息进行管理，并将上下文信息的变更同步到其他普通的broker 节点中。 不管是监听器触发的事件，还是定时任务触发的事件，或者是其他事件都会读取或更新控制器中的上下文信息，那么这样就会涉及多线程间的同步。如果单纯使用锁机制来实现，那么整体的性能会大打折扣。针对这一现象，Kafka 的控制器使用单线程基于事件队列的模型，将每个事件都做一层封装，然后按照事件发生的先后顺序暂存到 LinkedBlockingQueue 中，最后使用一个专用的线程（ControllerEventThread）按照FIFO（First Input First Output，先入先出）的原则顺序处理各个事件，这样不需要锁机制就可以在多线程间维护线程安全。 4.4 普通 broker在最新的 kafka 实现中，普通broker极少需要再监听ZooKeeper中的数据变化，只对/controller节点添加监听器，以此来监听此节点的数据变化（ControllerChangeHandler） 当/controller 节点的数据发生变化时，每个 broker 都会更新自身内存中保存的activeControllerId。 如果broker 在数据变更前是控制器，在数据变更后自身的 brokerid 值与新的 activeControllerId 值不一致，那么就需要“退位”，关闭相应的资源，比如关闭状态机、注销相应的监听器等。 有可能控制器由于异常而下线，造成/controller 这个临时节点被自动删除；当/controller节点被删除时，每个broker都会进行选举，如果broker在节点被删除前是控制器，那么在选举前还需要有一个“退位”的动作。 4.4 kafka 如何优雅关闭4.5 分区 leader 选举分区创建和上线的 leader 选举分区leader副本的选举由控制器负责具体实施。 如下情况下会进行 leader 选举: 创建分区（创建主题或增加分区都有创建分区的动作） 分区上线（比如分区中原先的leader副本下线，此时分区需要选举一个新的leader 上线来对外提供服务） 对应的选举策略为OfflinePartitionLeaderElectionStrategy。这种策略的基本思路是按照 AR 集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。注意这里是根据AR的顺序而不是ISR的顺序进行选举的。 如果ISR集合中没有可用的副本，那么此时还要再检查一下所配置的unclean.leader.election.enable参数（默认值为false）。如果这个参数配置为true，那么表示允许从非ISR列表中的选举leader，从AR列表中找到第一个存活的副本即为leader。 分区重分配的 leader 选举当分区进行重分配（可以先回顾一下4.3.2节的内容）的时候也需要执行leader的选举动作，对应的选举策略为 ReassignPartitionLeaderElectionStrategy。这个选举策略的思路比较简单：从重分配的AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中。 优先副本选举时的 leader 选举当发生优先副本（可以先回顾一下4.3.1节的内容）的选举时，直接将优先副本设置为leader即可 节点下线的 leader 选举当某节点被优雅地关闭（也就是执行ControlledShutdown）时，位于这个节点上的leader副本都会下线，所以与此对应的分区需要执行leader的选举。与此对应的选举策略（ControlledShutdownPartitionLeaderElectionStrategy）为：从AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中，与此同时还要确保这个副本不处于正在被关闭的节点上。 5. 重要参数解析5.1 broker.id服务器端参数 broker.id是broker在启动之前必须设定的参数之一，在Kafka集群中，每个broker都有唯一的 id值用来区分彼此。 broker 在启动时会在 ZooKeeper 中的 /brokers/ids路径下创建一个以当前brokerId为名称的虚节点，broker的健康状态检查就依赖于此虚节点。当 broker 下线时，该虚节点会自动删除，其他 broker 节点或客户端通过判断/brokers/ids路径下是否有此broker的brokerId节点来确定该broker的健康状态。 broker.id 有三种配置方式: 配置文件 config/server.properties 里的 broker.id，默认值为-1， 在Kafka中，brokerId值必须大于等于0才有可能正常启动 meta.properties文件 通过服务端如下参数自动生成新的brokerId: broker.id.generation.enable: True 表示启用自动生成功能 reserved.broker.max.id: 自动生成的 brokerId 有一个基准值，即自动生成的 brokerId 必须超过这个基准值 他们的优先级是从上往下，优先级越来越低。 自动生成 broker.id 的原理自动生成的brokerId的原理是先往ZooKeeper中的 /brokers/seqid 节点中写入一个空字符串。然 后 获 取 返回的Stat 信息中的 version 值，进而将 version 的值和reserved.broker.max.id参数配置的值相加。 brokers/seqid节点在被更新后，dataVersion就自增1，表示数据发生了变更，这样通过ZooKeeper 的这个功能来实现集群层面的序号递增，整体上相当于一个发号器。 5.2 bootstrap.servers客户端参数 bootstrap.servers 是Kafka Producer、Kafka Consumer客户端中的必备参数。 我们一般可以简单地认为 bootstrap.servers 这个参数所要指定的就是将要连接的Kafka集群的broker地址列表。不过从深层次的意义上来讲，这个参数配置的是用来发现Kafka集群元数据信息的服务地址。 客户端连接Kafka集群要经历以下3个过程: 与bootstrap.servers参数所指定的Server连接，并发送MetadataRequest请求来获取集群的元数据信息 Server 通过 MetadataResponse 返回元数据信息 客户端KafkaProducer2收到的MetadataResponse之后解析出其中包含的集群元数据信息，然后与集群中的各个节点建立连接，之后就可以发送消息了 在绝大多数情况下，Kafka 本身就扮演着第一步和第二步中的 Server 角色，我们完全可以将这个Server的角色从Kafka中剥离出来，从而添加一些路由的功能、负载均衡的功能。 5.3 服务器端的配置参数 主题端参数 描述 对应的broker端参数 cleanup.policy 日志压缩策略。默认值为delete，还可以配置为compact log.cleanup.policy compression.type 消息的压缩类型。默认值是producer，表示保留生产者中所使用的原始压缩类型。还可以配置为uncompressed、snappy、lz4、gzip compression.type delete.retention.ms 被标识为删除的数据能够保留多久。默认值是86400000，即1天 log.clear.delete.retention.ms file.delete.delay.ms 清理文件之前可以等待多长时间，默认值是60000，即1分钟 log.segment.delete.delay.ms flush.messges 需要收集多少消息才会将它们强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值 log.flush.interval.messges flush.ms 需要等待多久才会将消息强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值 log.flush.interval.ms follower.replication.throttled.replicas 用来配置被限制速率的主题所对应的follower副本列表 follower.replication.throttled.replicas index.interval.bytes 用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值是4096 log.index.interval.bytes leader.replication.throttled.replicas 用来配置被限制速率的主题所对应的leader副本列表 leader.replication.throttled.replicas max.message.byte 消息的最大字节数，默认值是1000012 max.message.byte message.format.version 消息格式的版本，默认值为2.0-IV1 log.message.format.version message.timestamp.difference.max.ms 消息中自带的时间戳与broker收到消息时的时间戳之间的最大差值，默认值为Long.MAX_VALUE。此参数只有在message.timestamp.type参数设置为CreteTime时才有效 log.message.timestamp.difference.max.ms message.timestamp.type 消息的时间戳类型。默认值是CreteTime，还可以设置为LogAppendTime log.message.timestamp.type min.cleanable.dirty.ratio 日志清理时的最小污浊率，默认值是0.5 log.cleaner.min.cleanable.ratio min.compaction.lag.ms 日志再被清理前的最小保留时间，默认值为0 log.cleaner.min.compaction.lag.ms min.insync.replicas 分区ISR集合中至少有多少个副本，默认值为1 min.insync.replicas preallocate 在创建日志分段的时候是否要预分配空间，默认值为false log.preallocate retention.bytes 分区中所能保留的消息总量，默认值为-1，即没有限制 log.retention.bytes retention.ms 使用delete的日志清理策略时消息能够保留多长时间，默认值为604800000，即7天。如果设置为-1，则表示没有限制 log.retention.ms segment.bytes 日志分段的最大值，默认值为1073741824，即1GB log.segment.bytes segment.index.bytes 日志分段索引的最大值，默认值为10485760，即10MB log.index.size.max.bytes segment.jitter.ms 滚动日志分段时，在segment.ms的基础之上增加的随机数，默认为0 log.roll.jitter.ms segment.ms 最多多久滚动一次日志分段，默认值为604800000，即7天 log.roll.ms unclean.leader.election.enable 是否可以从非ISR集合中选举leader副本，默认值为false，如果设置为true，则可能造成数据丢失 unclean.leader.election.enable]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 日志存储]]></title>
    <url>%2F2020%2F04%2F06%2Fkafka%2F06_%E6%97%A5%E5%BF%97%E5%AD%98%E5%82%A8%2F</url>
    <content type="text"><![CDATA[Kafka 的日志 1. 日志概述kafka 是基于日志的消息系统，今天我们就来介绍 kafka 日志存储相关的内容，包括: 日志中消息的存储格式 日志索引 日志清理: 日志的删除 日志的压缩 日志的磁盘存储 1. 文件目录布局1.1 日志目录结构Kafka 中的消息是以主题为基本单位进行归类的，各个主题在逻辑上相互独立，从主题开始以此依次向下分为: 一个或多个分区，分区是逻辑上的概念 每个分区对应多个副本 一个副本对应一个日志(Log) 为了防止 Log 过大，Kafka 将 Log 切分为多个 LogSegment 日志分段 Log 和LogSegment 也不是纯粹物理意义上的概念: Log 在物理上只以文件夹的形式存储 而每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件(比如以.txnindex为后缀的事务索引文件) 主题、分区、副本、Log、LogSegment 之间的关系如上图所示: Log 即每个分区的副本，对应是一个命名形式为&lt;topic&gt;-&lt;partition&gt;的文件夹 每个LogSegment 对应于磁盘上的一个日志文件和两个索引文件，以及可能的其他文件 日志文件(以.log为文件后缀) 偏移量索引文件(以.index为文件后缀) 时间戳索引文件(以.timeindex为文件后缀) 还可能包含 .deleted，.cleaned，.swap等临时文件 .snapshot，.txnindex(事务索引文件) leader-epoch-checkpoint 等文件 日志写入: 向Log 中追加消息时是顺序写入的，只有最后一个 LogSegment 才能执行写入操作 最后一个 LogSegment 称为activeSegment，即表示当前活跃的日志分段 在创建主题的时候，如果当前 broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务 日志索引命名: 每个 LogSegment 都有一个基准偏移量 baseOffset，用来表示当前 LogSegment中第一条消息的offset 偏移量是一个64位的长整型数，日志文件和两个索引文件都是根据基准偏移量(baseOffset)命名的，名称固定为20位数字 Kafka 的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。 1.2 kafka 文件目录布局从更加宏观的视角上看，kafka 的文件目录如下图所示: 其中 当 Kafka 服务第一次启动的时候，会在默认的根目录下创建以下5个文件： log-start-offset-checkpoint: cleaner-offset-checkpoint: recovery-point-offset-checkpoint: 表示已经刷写到磁盘的记录，recoveryPoint: 以下的数据都是已经刷到磁盘上的了 replication-offset-checkpoint: 用来存储每个replica的 HW 高水位 meta.properties: broker.id 信息 第一次有消费者消费消息时: 会创建内部主题 __consumer_offsets 用于保存消费者提交的位移 图中的 __consumer_offsets* 文件夹就是对应的 Log 目录 创建主题时: 如果当前 broker中不止配置了一个根目录，那么会挑选分区数最少的那个根目录来完成本次创建任务 2. 消息格式演进Kafka的消息格式经历了3个版本：v0版本、v1版本和v2版本(如无特殊说明，下面都是消息未压缩的情形)。与消息对应的还有消息集的概念，消息集中包含一条或多条消息，消息集不仅是存储于磁盘及在网络上传输(Produce＆Fetch)的基本形式，而且是Kafka中压缩的基本单元。接下来我们会依次介绍 v0，v1，v2 三种消息的具体格式以及相应的消息集格式。 2.1 消息格式 v0v0版本的消息及消息集格式如下: 其中: LOG_OVERHEAD: 固定为12B offset 用来标志它在分区中的偏移量，这个offset是逻辑值，而非实际物理偏移值 8B message size表示消息的大小 4B RECORD: 最小大小为 4B+1B+1B+4B+4B=14B，不包括 key 和 value crc32(4B)：crc32校验值。校验范围为magic至value之间 magic(1B)：消息格式版本号，此版本的magic值为0 attributes(1B)：消息的属性。总共占1个字节，低3位表示压缩类型，其余位保留： 0表示NONE 1表示GZIP 2表示SNAPPY 3表示LZ4(LZ4自Kafka 0.9.x引入) key length(4B)：表示消息的key的长度，如果为-1，则表示没有设置key，即key=null key：可选，如果没有key则无此字段 value length(4B)：实际消息体的长度，如果为-1，则表示消息为空。 value：消息体，可以为空，比如墓碑(tombstone)消息 2.2 消息格式 v1v1，比v0版本就多了一个timestamp字段，表示消息的时间戳。如下图所示: 其中: magic字段的值为1 attributes: 低3位和v0版本的一样，表示压缩类型 第4个位(bit)： 0表示timestamp类型为CreateTime， 1表示timestamp类型为LogAppendTime 其他位保留 timestamp类型由broker端参数 log.message.timestamp.type 来配置，默认值为CreateTime，即采用生产者创建消息时的时间戳。 如果在创建 ProducerRecord 时没有显式指定消息的时间戳，那么 KafkaProducer也会在发送这条消息前自动添加上。 v1 版本的RECORD 最小长度为 14 + 8 = 22B 2.3 v0/v1 格式的消息压缩常见的压缩算法是数据量越大压缩效果越好，一条消息通常不会太大，这就导致压缩效果并不是太好。而Kafka实现的压缩方式是将多条消息一起进行压缩，这样可以保证较好的压缩效果。。在一般情况下，生产者发送的压缩数据在broker中也是保持压缩状态进行存储的，消费者从服务端获取的也是压缩的消息，消费者在处理消息之前才会解压消息，这样保持了端到端的压缩。 参数 compression.type 用来配置压缩方式，可选值包括: 默认值为”producer”，表示保留生产者使用的压缩方式 gzip、snappy、lz4，分别对应 GZIP、SNAPPY、LZ4 这 3 种压缩算法 uncompressed，则表示不压缩 压缩消息格式当消息压缩时是将整个消息集进行压缩作为内层消息(inner message)，内层消息整体作为外层(wrapper message)的 value，消息压缩后的格式如下图所示: 其中: 压缩后的外层消息(wrapper message)中的key为null， value字段中保存的是多条压缩消息(inner message，内层消息) Record表示的是从 crc32 到 value 的消息格式 当生产者创建压缩消息的时候，压缩消息消息集中的消息offset都是从0开始的，对 offset 的转换是在服务端进行的，客户端不需要做这个工作 外层消息保存了内层消息中最后一条消息的绝对位移(absolute offset)，绝对位移是相对于整个分区而言的。当消费者消费这个消息集的时候，首先解压缩整个消息集，然后找到内层消息中最后一条消息的inner offset，然后依次计算出消息集中每条消息的 offset 数据压缩的 timestamp 字段v1版本比v0版的消息多了一个timestamp字段。对于压缩的情形，外层消息的timestamp设置为 如果timestamp类型是CreateTime，那么设置的是内层消息中最大的时间戳。 如果timestamp类型是LogAppendTime，那么设置的是Kafka服务器当前的时间戳 内层消息的timestamp设置： 如果外层消息的timestamp类型是CreateTime，那么设置的是生产者创建消息时的时间戳。 如果外层消息的timestamp类型是LogAppendTime，那么所有内层消息的时间戳都会被忽略。 对 attributes 字段而言，它的 timestamp 位只在外层消息中设置，内层消息中的timestamp类型一直都是CreateTime。 注意: compact message是针对日志清理策略而言的(cleanup.policy=compact)，是指日志压缩(Log Compaction)后的消息。本节中的压缩消息单指compress message，即采用GZIP、LZ4等压缩工具压缩的消息。 2.4 消息格式 v2v2 参考 Protocol Buffer 引入了变长整型(Varints)和ZigZag编码。目的是进入降低消息所占用的大小。具体的编码方式大家可以参考其他资料，这里不再详述。 v2 的消息格式如下图所示:其中: Record Batch: 消息集 Record Batch Header: 从first offset到records count，这些字段是不被压缩的 records: 表示被压缩的消息 Record: 表示单条消息 生产者客户端中的 ProducerBatch 对应这里的 RecordBatch ，而 ProducerRecord 对应这里的Record。下面我们分别来讲解各个部分的含义 RecordRecord 包含如下字段: key、key length、value、value length字段同v0和v1版本的一样 length：消息总长度 attributes：弃用，但还是在消息格式中占据1B的大小，以备未来的格式扩展 timestamp delta：时间戳增量。通常一个timestamp需要占用8个字节，如果像这里一样保存与RecordBatch的起始时间戳的差值，则可以进一步节省占用的字节数。 offset delta：位移增量。保存与 RecordBatch起始位移的差值，可以节省占用的字节数 headers： 用来支持应用级别的扩展，而不需要像v0和v1版本一样不得不将一些应用级别的属性值嵌入消息体 Header的格式如图最右部分所示，包含key和value 一个Record里面可以包含0至多个Header 在 v2 版本中将 crc 的字段从 Record 中转移到了RecordBatch中 对于 v1 版本的消息，如果用户指定的 timestamp 类型是 LogAppendTime 而不是CreateTime，那么消息从生产者进入 broker 后，timestamp 字段会被更新，此时消息的 crc值将被重新计算，而此值在生产者中已经被计算过一次。再者，broker 端在进行消息格式转换时（比mp 字段会被更新，此时消息的 crc值将被重新计算，而此值在生产者中已经被计算过一次。再者，broker 端在进行消息格式转换时（比如v1版转成v0版的消息格式）也会重新计算crc的值。在这些类似的情况下，消息从生产者到消费者之间流动时，crc的值是变动的，需要计算两次crc的值，所以这个字段的设计在 v0 和 v1 版本中显得比较“鸡肋”。在 v2 版本中将 crc 的字段从 Record 中转移到了RecordBatch中。 Record BatchRecord Batch 包含如下字段: first offset：表示当前RecordBatch的起始位移 length：计算从partition leader epoch字段开始到末尾的长度 partition leader epoch：分区leader纪元，可以看作分区leader的版本号或更新次数 magic：消息格式的版本号，对v2版本而言，magic等于2 attributes：消息属性，注意这里占用了两个字节。 低3位表示压缩格式，可以参考v0和v1； 第4位表示时间戳类型 第5位表示此RecordBatch是否处于事务中，0表示非事务，1表示事务 第6位表示是否是控制消息(ControlBatch)，0表示非控制消息，而1表示是控制消息，控制消息用来支持事务功能 last offset delta： RecordBatch中最后一个Record的offset与first offset的差值 主要被broker用来确保RecordBatch中Record组装的正确性 first timestamp：RecordBatch中第一条Record的时间戳 max timestamp：RecordBatch 中最大的时间戳，一般情况下是指最后一个 Record的时间戳，和last offset delta的作用一样，用来确保消息组装的正确性。 producer id：PID，用来支持幂等和事务 producer epoch：和producer id一样，用来支持幂等和事务 first sequence：和 producer id、producer epoch 一样，用来支持幂等和事务 records count：RecordBatch中Record的个数。 v2版本的消息不仅提供了更多的功能，比如事务、幂等性等，某些情况下还减少了消息的空间占用，总体性能提升很大。使用kafka-dump-log.sh 可以查看kafka日志的内容来验证所使用的消息格式。命令如下: 1&gt; bin/kafka-dump-log.sh --files /tmp/kafka/topic-0/0000000000000.log --print-data-log kafka-dump-log.sh脚本也可以用来解析.index文件(还包括.timeindex、.snapshot、.txnindex等文件) 2. 日志索引kafka 日志的内容我们在上一节 kafka 消息格式已经详细介绍过了。接下来我们来看看，kafka 的两个索引文件: 偏移量索引 时间戳索引 2.1 kafka 索引简介偏移量索引文件用来建立消息偏移量(offset)到物理地址之间的映射关系，方便快速定位消息所在的物理文件位置；时间戳索引文件则根据指定的时间戳(timestamp)来查找对应的偏移量信息。 Kafka 中的索引文件以稀疏索引(sparse index)的方式构造消息的索引，它并不保证每个消息在索引文件中都有对应的索引项。每当写入一定量(由 broker 端参数 log.index.interval.bytes指定，默认值为4096，即4KB)的消息时，偏移量索引文件和时间戳索引文件分别增加一个偏移量索引项和时间戳索引项，增大或减小log.index.interval.bytes的值，对应地可以增加或缩小索引项的密度。 稀疏索引通过MappedByteBuffer将索引文件映射到内存中，以加快索引的查询速度。偏移量索引文件中的偏移量是单调递增的，查询指定偏移量时，使用二分查找法来快速定位偏移量的位置，如果指定的偏移量不在索引文件中，则会返回小于指定偏移量的最大偏移量。时间戳索引文件中的时间戳也保持严格的单调递增，查询指定时间戳时，也根据二分查找法来查找不大于该时间戳的最大偏移量，至于要找到对应的物理文件位置还需要根据偏移量索引文件来进行再次定位。稀疏索引的方式是在磁盘空间、内存空间、查找时间等多方面之间的一个折中。 2.2 日志分段触发点日志分段文件达到一定的条件时需要进行切分，那么其对应的索引文件也需要进行切分。日志分段文件切分包含以下几个条件，满足其一即可。 当前日志分段文件的大小超过了 broker 端参数 log.segment.bytes 配置的值。log.segment.bytes参数的默认值为1073741824，即1GB。 当前日志分段中消息的最大时间戳与当前系统的时间戳的差值大于 log.roll.ms或log.roll.hours参数配置的值。如果同时配置了log.roll.ms和log.roll.hours参数，那么log.roll.ms的优先级高。默认情况下，只配置了log.roll.hours参数，其值为168，即7天。 偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值。log.index.size.max.bytes的默认值为10485760，即10MB 追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE，即要追加的消息的偏移量不能转变为相对偏移量(offset-baseOffset＞Integer.MAX_VALUE) 对非当前活跃的日志分段而言，其对应的索引文件内容已经固定而不需要再写入索引项，所以会被设定为只读。而对当前活跃的日志分段(activeSegment)而言，索引文件还会追加更多的索引项，所以被设定为可读写。 在索引文件切分的时候，Kafka 会关闭当前正在写入的索引文件并置为只读模式，同时以可读写的模式创建新的索引文件，索引文件的大小由broker端参数 log.index.size.max.bytes 配置。Kafka 在创建索引文件的时候会为其预分配log.index.size.max.bytes 大小的空间，注意这一点与日志分段文件不同，只有当索引文件进行切分的时候，Kafka 才会把该索引文件裁剪到实际的数据大小。也就是说，与当前活跃的日志分段对应的索引文件的大小固定为 log.index.size.max.bytes，而其余日志分段对应的索引文件的大小为实际的占用空间。 2.3 偏移量索引12relative Offset| position 32 | 32 偏移量索引项的格式如上所示。每个索引项占用8个字节，分为两个部分。 relativeOffset： 相对偏移量，表示消息相对于baseOffset 的偏移量，占用4 个字节，当前索引文件的文件名即为baseOffset的值 消息的偏移量(offset)占用8个字节，也可以称为绝对偏移量 position：物理地址，也就是消息在日志分段文件中对应的物理位置，占用4个字节 可以使用 kafka-dump-log.sh脚本来解析.index文件内容: 123bin/kafka-dump-log.sh --files /tmp/kafka-logs/topic-log-0/000000000000000.index Dumping /tmp/kafka-logs/topic-log-0/000000000000000.index offset: 6 position 156 消息索引过程000000000000000.index 偏移量索引与 000000000000000.log 日志分段文件的对应关系如下: 日志查找分成了两个过程: 查找偏移量所在的日志分段: Kafka 的每个日志对象中使用了ConcurrentSkipListMap来保存各个日志分段，每个日志分段的baseOffset作为key，这样可以根据指定偏移量来快速定位到消息所在的日志分段。 根据日志分段的偏移量索引查找消息: 首先通过二分法在偏移量索引文件中找到不大于偏移量的最大索引项的 position 根据索引项中的position定位到具体的日志分段文件位置开始查找目标消息 Kafka 强制要求索引文件大小必须是索引项大小的整数倍，对偏移量索引文件而言，必须为8的整数倍。如果broker端参数log.index.size.max.bytes配置为67，那么Kafka在内部会将其转换为64，即不大于67，并且满足为8的整数倍的条件。 2.4 时间戳索引12timestamp | relative Offset 32 | 32 每个索引项占用12个字节，分为两个部分。 timestamp：当前日志分段最大的时间戳 relativeOffset：时间戳所对应的消息的相对偏移量 每个追加的时间戳索引项中的 timestamp 必须大于之前追加的索引项的 timestamp，否则不予追加 如果 broker 端参数 log.message.timestamp.type设置为LogAppendTime，那么消息的时间戳必定能够保持单调递增； 相反如果是 CreateTime 类型则无法保证。生产者可以使用类似 ProducerRecord(String topic，Integer partition，Long timestamp，K key，V value)的方法来指定时间戳的值。 即使生产者客户端采用自动插入的时间戳也无法保证时间戳能够单调递增，如果两个不同时钟的生产者同时往一个分区中插入消息，那么也会造成当前分区的时间戳乱序。 与偏移量索引文件相似，时间戳索引文件大小必须是索引项大小(12B)的整数倍，如果不满足条件也会进行裁剪。同样假设broker端参数log.index.size.max.bytes配置为67，那么对应于时间戳索引文件，Kafka在内部会将其转换为60。 索引文件的追加方式我们已经知道每当写入一定量的消息时，就会在偏移量索引文件和时间戳索引文件中分别增加一个偏移量索引项和时间戳索引项。两个文件增加索引项的操作是同时进行的，但并不意味着偏移量索引中的relativeOffset和时间戳索引项中的relativeOffset是同一个值。 需要注意的是即便日志索引内的时间戳不是单调递增的，也不会影响日志查找的准确性，因为每个追加的时间戳索引项中的 timestamp 必须大于之前追加的索引项的 timestamp，这就保证每个时间索引内的时间戳，在日志文件内，位于它之前的日志时间都小于这个时间戳，之后的可能大于也可能小于这个时间戳。这样总是能找到大于该时间戳的所有数据。 查找步骤 如图所示查找 targetTimeStamp=1526384718288开始的消息，分为如下几个步骤: 首先找到不小于指定时间戳的日志分段 将targetTimeStamp和每个日志分段中的最大时间戳largestTimeStamp逐一对比，直到找到不小于 targetTimeStamp 的 largestTimeStamp 所对应的日志分段。 日志分段中的largestTimeStamp的计算是先查询该日志分段所对应的时间戳索引文件，找到最后一条索引项，若最后一条索引项的时间戳字段值大于0，则取其值，否则取该日志分段的最近修改时间。 根据时间戳索引偏移量查找消息: 找到相应的日志分段之后，在时间戳索引文件中使用二分查找算法查找到不大于targetTimeStamp的最大索引项，即[1526384718283，28]，如此便找到了一个相对偏移量28 在偏移量索引文件中使用二分算法查找到不大于28的最大索引项，即[26，838] 从步骤1中找到日志分段文件中的838的物理位置开始查找不小于targetTimeStamp的消息 3. 日志清理将日志分段就是便于日志清理，Kafka提供了两种日志清理策略: 日志删除(Log Retention)：按照一定的保留策略直接删除不符合条件的日志分段 日志压缩(Log Compaction)：针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本 与此相关的 broker 端参数包括: log.cleanup.policy: 作用: 设置日志清理策略 可选值包括: delete: 默认值，采用日志删除的清理策略 compact: 采用日志压缩的清理策略，此时还需要将log.cleaner.enable(默认值为true)设定为true delete，compact: 同时支持日志删除和日志压缩两种策略 主题相关参数: 日志清理的粒度可以控制到主题级别，比如与log.cleanup.policy 对应的主题级别的参数为 cleanup.policy log.cleaner.enable 作用: 启用日志压缩 3.1 日志删除在Kafka的日志管理器中会有一个专门的日志删除任务来周期性地检测和删除不符合保留条件的日志分段文件，这个周期可以通过broker端参数 log.retention.check.interval.ms 来配置，默认值为 300000 即 5 分钟。 当前日志分段的保留策略有3种： 基于时间的保留策略 基于日志大小的保留策略 基于日志起始偏移量的保留策略 基于时间的保留策略日志删除任务会检查当前日志文件中是否有保留时间超过设定的阈值(retentionMs)来寻找可删除的日志分段文件集合(deletableSegments)。 retentionMs可以通过broker端以下参数设置: log.retention.hours，优先级最高 log.retention.minutes log.retention.ms，优先级最低 默认情况下只配置了log.retention.hours参数，其值为168，默认情况下日志分段文件的保留时间为7天 删除任务会根据日志分段中最大的时间戳 largestTimeStamp 来查找过期的日志分段，largestTimeStamp 的确定分为如下几个步骤: 查询该日志分段所对应的时间戳索引文件，查找时间戳索引文件中最后一条索引项 若最后一条索引项的时间戳字段值大于 0，则取其值，否则设置为最近修改时间lastModifiedTime 使用文件的最后的修改时间是不准确的，因为这些文件的修改时间可能会被认为修改 日志分段删除步骤如下: 如果所有的日志分段都过期，那至少要保证有一个活跃的日志分段，在此种情况下，会先切分出一个新的日志分段作为activeSegment，然后执行删除操作 删除日志分段时，首先会从Log对象中所维护日志分段的跳跃表中移除待删除的日志分段，以保证没有线程对这些日志分段进行读取操作 然后将日志分段所对应的所有文件添加上.deleted的后缀(当然也包括对应的索引文件) 最后交由一个以delete-file命名的延迟任务来删除这些以.deleted为后缀的文件，这个任务的延迟执行时间可以通过file.delete.delay.ms参数来调配，此参数的默认值为60000，即1分钟 基于日志大小基于日志大小的删除策略通过检查当前日志的大小是否超过设定的阈值(retentionSize)来寻找可删除的日志分段的文件集合(deletableSegments)。retentionSize 由以下参数控制: log.retention.bytes 作用: 配置Log中所有日志文件的总大小，默认值为-1，表示无穷大 log.segment.bytes: 作用: 配置单个日志分段(确切地说应该为.log日志文件)的大小，默认值为1073741824，即1GB。 查找可删除日志分段集合: 首先计算日志文件的总大小size和retentionSize的差值diff，即计算需要删除的日志总大小 然后从日志文件中的第一个日志分段开始进行查找可删除的日志分段的文件集合 查找出 deletableSegments 之后就执行删除操作，删除操作同上 基于偏移量一般情况下，日志文件的起始偏移量 logStartOffset 等于第一个日志分段的 baseOffset，但这并不是绝对的，logStartOffset 的值可以通过 DeleteRecordsRequest 请求(比如使用KafkaAdminClient的deleteRecords()方法、使用kafka-delete-records.sh脚本，具体用法参考9.1.3节)、日志的清理和截断等操作进行修改。 基于日志起始偏移量的保留策略的判断依据是某日志分段的下一个日志分段的起始偏移量baseOffset 是否小于等于logStartOffset。 3.2 日志压缩Log Compaction对于有相同key的不同value值，只保留最后一个版本。如果应用只关心key对应的最新value值，则可以开启Kafka的日志清理功能，Kafka会定期将相同key的消息进行合并，只保留最新的value值。 Log Compaction会生成新的日志分段文件，日志分段中每条消息的物理位置会重新按照新文件来组织。Log Compaction执行过后的偏移量不再是连续的，不过这并不影响日志的查询。 Log Compaction是针对key的，所以在使用时应注意每个消息的key值不为null。Kafka中用于保存消费者消费位移的主题__consumer_offsets使用的就是Log Compaction策略。 压缩方法kafka 每一个日志目录下都有一个名为 cleaner-offset-checkpoint 的文件，这个文件就是清理检查点文件，用来记录每个主题的每个分区中已清理的偏移量。通过清理检查点文件中的检查点cleaner checkpoint 将日志划分为: 已经清理过的clean部分，消息偏移量是断续递增的 一个还未清理过的 dirty 部分，消息偏移量是逐一递增的 如果客户端总能赶上dirty部分，那么它就能读取日志的所有消息，反之就不可能读到全部的消息。 firstDirtyOffset(与cleaner checkpoint相等)表示dirty部分的起始偏移量 为了避免当前活跃的日志分段activeSegment成为热点文件，activeSegment 不会参与 Log Compaction 的执行 firstUncleanableOffset为dirty部分的截止偏移量，整个dirty部分的偏移量范围为[firstDirtyOffset，firstUncleanableOffset)，注意这里是左闭右开区间。 Kafka 支持通过参数log.cleaner.min.compaction.lag.ms(默认值为0)来配置消息在被清理前的最小保留时间，默认情况下firstUncleanableOffset等于activeSegment的baseOffset。 压缩策略每个broker会启动log.cleaner.thread(默认值为1)个日志清理线程负责执行清理任务，这些线程会选择污浊率最高的日志文件进行清理: cleanBytes 表示clean部分的日志占用大小 dirtyBytes 表示dirty部分的日志占用大小 日志的污浊率(dirtyRatio)为：dirtyBytes = dirtyBytes/ (dirtyBytes + cleanBytes) log.cleaner.min.cleanable.ratio(默认值为0.5)来限定可进行清理操作的最小污浊率。 压缩实现日志压缩是通过 SkimpyOffsetMap 实现的: Kafka中的每个日志清理线程会使用一个名为SkimpyOffsetMap的对象来构建 key与offset 的映射关系的哈希表 日志清理需要遍历两次日志文件，第一次遍历把每个key的哈希值和最后出现的offset都保存在SkimpyOffsetMap中 第二次遍历会检查每个消息是否符合保留条件，如果符合就保留下来，否则就会被清理 SkimpyOffsetMap使用MD5来计算key的哈希值，使用线性探测解决哈希冲突，通过 broker 端参数 log.cleaner.io.buffer.load.factor(默认值为0.9)来调整负载因子。每个日志清理线程的SkimpyOffsetMap的内存占用大小为log.cleaner.dedupe.buffer.size/log.cleaner.thread，默认值为=128MB/1=128MB。 需要注意的是 SkimpyOffsetMap 中保存的是 key md5 之后的值与 offset 的对应关系。如果遇到两个不同的 key但哈希值相同的情况，那么其中一个key所对应的消息就会丢失。(如果保存的 MD5 后的哈希值何来哈希冲突检测一说？) 压缩分组Kafka 在实际清理过程中并不对单个的日志分段进行单独清理，而是将日志文件中offset从0至firstUncleanableOffset的所有日志分段进行分组，每个日志分段只属于一组，分组策略为：按照日志分段的顺序遍历，每组中日志分段的占用空间大小之和不超过segmentSize(可以通过broker端参数log.segment.bytes设置，默认值为1GB)，且对应的索引文件占用大小之和不超过 maxIndexSize(可以通过broker 端参数 log.index.interval.bytes设置，默认值为10MB)。同一个组的多个日志分段清理过后，只会生成一个新的日志分段。 压缩过程Log Compaction过程: 首先将每个日志分组中需要保留的消息复制到一个以.clean为后缀的临时文件中，此临时文件以当前日志分组中第一个日志分段的文件名命名，例如 00000000000000000000.log.clean。 Log Compaction过后将 .clean 的文件修改为 .swap 后缀的文件，例如：00000000000000000000.log.swap 然后删除原本的日志文件，最后才把文件的.swap后缀去掉 整个过程中的索引文件的变换也是如此 4. 磁盘存储kafka 高吞吐量依赖以下几个技术: 顺序写: Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消息，并且也不允许修改已写入的消息 充分利用页缓存: 避免 java 应用层的缓存，减少内存开销和 Java GC 的影响 kafka 写日志只写到文件系统的页缓存中，数据落盘由操作系统刷脏页控制 kafka 提供了 log.flush.interval.messages、log.flush.interval.ms 参数用于控制同步刷盘的频率 刷盘任务应交由操作系统去调配，消息的可靠性应该由多副本机制来保障，而不是由同步刷盘这种严重影响性能的行为来保障 操作系统使用 vm.swappiness 参数用于控制内存的交换倾向，越大表示越倾向于使用 swap 分区来释放内存，swap 分区导致严重性能问题，应极力避免，建议将此参数设置为 ，这样保留了swap的机制而又最大限度地限制了它对Kafka性能的影响 因为大量使用页缓存，kafka 重启和迭机并不会导致数据丢失，但是主机的迭机有可能导致数据丢失 sendfile: 提高数据的网络发送效率 对一个进程而言，它会在进程内部缓存处理所需的数据，然而这些数据有可能还缓存在操作系统的页缓存中，因此同一份数据有可能被缓存了两次并且，除非使用Direct I/O的方式，否则页缓存很难被禁止。此外，用过Java的人一般都知道两点事实：对象的内存开销非常大，通常会是真实数据大小的几倍甚至更多，空间使用率低下；Java的垃圾回收会随着堆内数据的增多而变得越来越慢。基于这些因素，使用文件系统并依赖于页缓存的做法明显要优于维护一个进程内缓存或其他结构，至少我们可以省去了一份进程内部的缓存消耗，同时还可以通过结构紧凑的字节码来替代使用对象的方式以节省更多的空间。如此，我们可以在 32GB 的机器上使用28GB至30GB的内存而不用担心GC所带来的性能问题。此外，即使Kafka服务重启，页缓存还是会保持有效，然而进程内的缓存却需要重建。这样也极大地简化了代码逻辑，因为维护页缓存和文件之间的一致性交由操作系统来负责，这样会比进程内维护更加安全有效。 4.1 操作系统的脏页控制Linux 中有如下参数用于控制系统刷脏页 vm.dirty_background_ratio: 指定当脏页数量达到系统内存的百分之多少之后就会触发 pdflush/flush/kdmflush 等后台回写进程的运行来处理脏页，一般设置为小于10的值即可，但不建议设置为0 vm.dirty_ratio: 指定当脏页数量达到系统内存的百分之多少之后就不得不开始对脏页进行处理，在此过程中，新的 I/O 请求会被阻挡直至所有脏页被冲刷到磁盘中 vm.dirty_expire_centisecs vm.dirty_writeback.centisecs 4.2 kafka 磁盘 IO 过程 从编程角度而言，一般磁盘I/O的场景有以下四种。 用户调用标准C库进行I/O操作，数据流为：应用程序buffer→C库标准IObuffer→文件系统页缓存→通过具体文件系统到磁盘。 用户调用文件 I/O，数据流为：应用程序 buffer→文件系统页缓存→通过具体文件系统到磁盘。 用户打开文件时使用O_DIRECT，绕过页缓存直接读写磁盘 用户使用类似dd工具，并使用direct参数，绕过系统cache与文件系统直接写磁盘 发起I/O请求的步骤可以表述为如下的内容（以最长链路为例）: 写操作：用户调用fwrite把数据写入C库标准IObuffer后就返回，即写操作通常是异步操作；数据写入C库标准IObuffer后，不会立即刷新到磁盘，会将多次小数据量相邻写操作先缓存起来合并，最终调用write函数一次性写入（或者将大块数据分解多次write 调用）页缓存；数据到达页缓存后也不会立即刷新到磁盘，内核有 pdflush 线程在不停地检测脏页，判断是否要写回到磁盘，如果是则发起磁盘I/O请求。 读操作：用户调用fread到C库标准IObuffer中读取数据，如果成功则返回，否则继续；到页缓存中读取数据，如果成功则返回，否则继续；发起 I/O 请求，读取数据后缓存buffer和C库标准IObuffer并返回。可以看出，读操作是同步请求。 I/O请求处理：通用块层根据I/O请求构造一个或多个bio结构并提交给调度层；调度器将 bio 结构进行排序和合并组织成队列且确保读写操作尽可能理想：将一个或多个进程的读操作合并到一起读，将一个或多个进程的写操作合并到一起写，尽可能变随机为顺序（因为随机读写比顺序读写要慢），读必须优先满足，而写也不能等太久。 4.3 磁盘 IO 调度策略针对不同的应用场景，I/O调度策略也会影响I/O的读写性能，目前Linux系统中的I/O调度策略有4种，分别为NOOP、CFQ、DEADLINE和 ANTICIPATORY，默认为CFQ。 NOOP该算法实现了最简单的FIFO队列，所有I/O请求大致按照先来后到的顺序进行操作。之所以说“大致”，原因是NOOP在FIFO的基础上还做了相邻I/O请求的合并，并不是完全按照先进先出的规则满足I/O请求。 CFQ该算法的特点是按照I/O请求的地址进行排序，而不是按照先来后到的顺序进行响应: CFQ为每个进程单独创建一个队列来管理该进程所产生的请求 各队列之间的调度使用时间片进行调度， I/O调度器每次执行一个进程的4次请求。 CFQ的出发点是对I/O地址进行排序，以尽量少的磁盘旋转次数来满足尽可能多的I/O请求。在CFQ算法下，SAS盘的吞吐量大大提高了。相比于NOOP的缺点是，先来的I/O请求并不一定能被满足，可能会出现“饿死”的情况。 DEADLINEDEADLINE在CFQ的基础上，解决了I/O请求“饿死”的极端情况。除了CFQ本身具有的I/O排序队列，DEADLINE额外分别为读I/O和写I/O提供了FIFO队列。优先级可以表示如下 1FIFO(read) &gt; FIFO(write) &gt; CFQ 读FIFO队列的最大等待时间为500ms，写FIFO队列的最大等待时间为5s。 ANTICIPATORYANTICIPATORY在DEADLINE的基础上，为每个读I/O都设置了6ms的等待时间窗口。如果在6ms内OS收到了相邻位置的读I/O请求，就可以立即满足。ANTICIPATORY算法通过增加等待时间来获得更高的性能，通过将多个随机的小写入流合并成一个大写入流（相当于将随机读写变顺序读写），通过这个原理来使用读取/写入的延时换取最大的读取/写入吞吐量。适用于大多数环境，特别是读取/写入较多的环境。 Kafka 操作的都是普通文件，并没有依赖于特定的文件系统，但是依然推荐使用EXT4或XFS。尤其是对XFS而言，它通常有更好的性能 4.4 零拷贝零拷贝是指将数据直接从磁盘文件复制到网卡设备，而无需经过应用程序。零拷贝技术依赖于底层的 sendfile（）方法实现。 正常的发送文件过程 正常我们读取一个文件并通过网络发送出去要经过如下四个过程: 调用read（）时，文件A中的内容被复制到了内核模式下的Read Buffer中。 CPU控制将内核模式数据复制到用户模式下 调用write（）时，将用户模式下的内容复制到内核模式下的Socket Buffer中 将内核模式下的Socket Buffer的数据复制到 数据平白无故地从内核模式到用户模式“走了一圈”，浪费了 2次复制过程： 第一次是从内核模式复制到用户模式； 第二次是从用户模式再复制回内核模式，即上面4次过程中的第2步和第3步 而且在上面的过程中，内核和用户模式的上下文的切换也是4次 零拷贝过程 零拷贝技术，那么应用程序可以直接请求内核把磁盘中的数据传输给 Socket: 零拷贝技术通过DMA（Direct Memory Access）技术将文件内容复制到内核模式下的Read Buffer 中 不过没有数据被复制到 Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到Socket Buffer中 DMA引擎直接将数据从内核模式中传递到网卡设备（协议引擎） 这里数据只经历了2次复制就从磁盘中传送出去了，并且上下文切换也变成了2次。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 主题和分区]]></title>
    <url>%2F2020%2F04%2F05%2Fkafka%2F05_%E4%B8%BB%E9%A2%98%E5%92%8C%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[主题和分区 1. 主题与分区概述主题是消息的集合，分区算是消息的二次分类。分区的划分不仅为Kafka提供了可伸缩性、水平扩展的功能，还通过多副本机制来为Kafka提供数据冗余以提高数据可靠性。 从底层来说，主题和分区都是逻辑概念。分区可以有一至多个副本，每个副本对应一个日志文件，每个日志文件对应一至多个日志分段（LogSegment），每个日志分段还可以细分为索引文件、日志存储文件和快照文件等。有关 Kafka 日志存储的内容我们将在下一节详述。 本节我们将聚焦于 Kafka 主题和分区的管理上，内容包括: 主题的管理； 初识KafkaAdminClient； 分区的管理； 优先副本的选举 分区重分配 复制限流 修改副本因子 2. 主题的管理主题的管理包括主题的增删改查。通过 Kafka提供的 kafka-topics.sh 脚本来执行这些操作，这个脚本位于$KAFKA_HOME/bin/目录下。其实质上是调用了kafka.admin.TopicCommand类来执行主题管理的操作。 除了 kafka-topics.sh 脚本，我们还可以通过KafkaAdminClient，这种方式实质上是通过发送 CreateTopicsRequest、DeleteTopicsRequest 等请求来实现。甚至我们还可以通过直接操纵日志文件和ZooKeeper节点来实现。 kafka 提供了如下命令行工具: 序号 脚本 功能 3 kafka-topics.sh topic管理脚本 3 kafka-configs.sh 配置管理，包括主题，broker，客户端，用户 1 kafka-perferred-replica-election.sh 对分区leader副本进行重新平衡 1 kafka-reassign-partitions.sh 分区重分配/复制限流/修改副本因子 1 kafka-server-start.sh 启动kafka服务 2 kafka-server-stop.sh 停止kafka服务 4 kafka-console-producer.sh kafka生产者控制台 5 kafka-replay-log-producer.sh 消费topic数据并转发到另外一个topic 5 kafka-console-consumer.sh kafka消费者控制台 7 kafka-simple-consumer-shell.sh 获取指定consumer group的位移信息 8 kafka-consumer-groups.sh kafka消费者组相关信息 9 kafka-producer-perf-test.sh kafka生产者性能测试脚本 10 kafka-consumer-perf-test.sh kafka消费者性能测试脚本 11 kafka-verifiable-consumer.sh 检验的kafka消费者 12 kafka-verifiable-producer.sh 检验的kafka生产者 kafka-topic.sh 命令bin/kafka-topics.sh 通用参数: –zookeeper: Zookeeper 连接地址，eg: node01:2181/kafka –topic: 主题名称 –create: 主题创建指令 –partitions: 指定分区数 –replication-factor: 指定副本数 –replica-assignment: 手动指定分区副本的分配方案 –config: 设置主题的配置参数 –if-not-exists –broker.rack: 指定机架信息，可以让副本尽量分配到不同机架上的机器上 –disable-rack-aware: 忽略机架信息 –list –describe: 查看分区副本的分配细节 topics-with-overrides: 只会列出包含了与集群不一样配置的主题 under-replicated-partitions: 找出所有包含失效副本的分区 unavailable-partitions: 查看主题中没有 leader 副本的分区 –alter –delete 2.1 创建主题主题的默认创建当 auto.create.topics.enable=true，出现以下情况时会默认创建新的主题: 生产者向一个尚未创建的主题发送消息时 消费者开始从未知主题中读取消息时 任意一个客户端向未知主题发送元数据请求时 而下面参数用于设置主题的分区和副本数: num.partitions: 默认分区数，默认值为 1 default.replication.factor: 默认副本数，默认值为 1 自动创建主题的行为都是非预期的，通常 auto.create.topics.enable 都需要设置为 false。推荐的方式是使用 kafka-topics.sh kafka-topics.sh 创建主题kafka-topics.sh脚本在创建主题时还会检测是否包含.或_ 字符。为什么要检测这两个字符呢？因为在Kafka的内部做埋点时会根据主题的名称来命名metrics的名称，并且会将点号“.”改成下画线“_”。假设遇到一个名称为“topic.1_2”的主题，还有一个名称为“topic_1.2”的主题，那么最后的metrics的名称都会为“topic_1_2”，这样就发生了名称冲突。 主题的命名同样不推荐（虽然可以这样做）使用双下画线__开头，因为以双下画线开头的主题一般看作Kafka的内部主题。 主题的名称必须由大小写字母、数字、点号“.”、连接线“-”、下画线“_”组成，不能为空，不能只有点号“.”，也不能只有双点号“..”，且长度不能超过249。 创建主题的命令示例如下: 123456# 1. 使用默认参数创建bin/kafka-topics.sh --zookeeper node01:2181 --create --topic t_cdr --partitions 30 --replication-factor 2# 2. 指定分区副本分配方案# 3. 指定主题配置参数 主题、分区、部分、日志之间的关系在执行完 create 主题创建指令后，Kafka会在 log.dir 或 log.dirs 参数所配置的目录下创建相应的主题分区。 123456log.dir &lt;topic&gt;-&lt;partition&gt; # 文件夹 .log # 日志分段 .index .timeindex ... 主题、分区、副本和 Log（日志）的关系入下图所示 主题和分区都是提供给上层用户的抽象，而在副本层面或更加确切地说是Log层面才有实际物理上的存在。 2.2 分区副本分配在生产者和消费者中也都有分区分配的概念: 生产者的分区分配是指为每条消息指定其所要发往的分区 消费者中的分区分配是指为消费者指定其可以消费消息的分区 这里的分区分配是指为集群制定创建主题时的分区副本分配方案，即在哪个broker中创建哪些分区的副本。 kafka-topics.sh脚本创建主题时的内部分配逻辑按照机架信息划分成两种策略：未指定机架信息和指定机架信息。内部的分配逻辑还比较复杂，这里我们不在详述。 主题创建时的 Zookeeper 操作当创建一个主题时，无论通过kafka-topics.sh脚本，还是通过其他方式创建主题时，实质上是 在ZooKeeper中的/brokers/topics节点下创建与该主题对应的子节点并写入分区副本分配方案 并且在/config/topics/节点下创建与该主题对应的子节点并写入主题相关的配置信息（这个步骤可以省略不执行） Kafka创建主题的实质性动作是交由控制器异步去完成的 2.3 主题查看list和describe指令可以用来方便地查看主题信息。 12345# 查看所有主题bin/kafka-topics.sh --zookeeper node01:2181 --list# 查看指定主题信息bin/kafka-topics.sh --zookeeper node01:2181 --describe --topic t_cdr describe 指令的 under-replicated-partitions和unavailable-partitions参数都可以找出有问题的分区。 通过 under-replicated-partitions 参数可以找出所有包含失效副本的分区。包含失效副本的分区可能正在进行同步操作，也有可能同步发生异常，此时分区的ISR集合小于 AR 集合。对于通过该参数查询到的分区要重点监控，因为这很可能意味着集群中的某个broker已经失效或同步效率降低等。 通过 unavailable-partitions 参数可以查看主题中没有 leader 副本的分区，这些分区已经处于离线状态，对于外界的生产者和消费者来说处于不可用的状态。 2.4 修改主题alter指令可以修改主题的配置和分区数。 增加分区数1bin/kafka-topics.sh --zookeeper node01:2181 --alter --topic t_cdr --partitions 10 增加分区数，根据key计算分区的行为就会受到影响。如此还会影响既定消息的顺序，对于基于key计算的主题而言，建议在一开始就设置好分区数量，避免以后对其进行调整。 减少分区数目前Kafka只支持增加分区数而不支持减少分区数。为什么不支持与实现复杂度和语义保证有关。 比如删除的分区中的消息该如何处理？ 如果随着分区一起消失则消息的可靠性得不到保障；如果需要保留则又需要考虑如何保留 直接存储到现有分区的尾部，消息的时间戳就不会递增，如此对于Spark、Flink这类需要消息时间戳（事件时间）的组件将会受到影响 如果分散插入现有的分区，那么在消息量很大的时候，内部的数据复制会占用很大的资源，而且在复制期间，此主题的可用性又如何得到保障？与此同时，顺序性问题、事务性问题，以及分区和副本的状态机切换问题都是不得不面对 更改配置更改配置，使用的是与 create 相同的 –config 参数，还可以通过 –delete-config 参数来删除之前覆盖的配置，使其恢复原有的默认值。 使用kafka-topics.sh脚本的alter指令来变更主题配置的功能已经过时（deprecated），将在未来的版本中删除，推荐使用kafka-configs.sh脚本来实现相关功能。 2.5 删除主题delete 指令用来删除主题。必须将delete.topic.enable参数配置为true才能够删除主题，这个参数的默认值就是true，如果配置为false，那么删除主题的操作将会被忽略。在实际生产环境中，建议将这个参数的值设置为true。 内部主题 consumer_offsets和transaction_state 是无法被删除的。 主题删除时的 Zookeeper 操作使用kafka-topics.sh脚本删除主题的行为本质上只是在ZooKeeper中的 /admin/delete_topics 路径下创建一个与待删除主题同名的节点，以此标记该主题为待删除的状态。与创建主题相同的是，真正删除主题的动作也是由Kafka的控制器负责完成的。 2.6 配置管理kafka-configs.sh 脚本是专门用来对配置进行操作。其包含变更配置alter和查看配置describe这两种指令类型。 kafka-configs.sh脚本不仅可以支持操作主题相关的配置，还可以支持操作broker、用户和客户端这3个类型的配置。 kafka-configs.sh 操作对象指定: entity-type: 指定操作配置的类型，可选值包括 topics、brokers、clients和users entity-name: 指定操作配置的名称，不指定，会查看 entity-type 的所有配置 alter: 变更指令 add-config: 实现配置增、改 delete-config: 实现配置删除，即恢复默认配置 123bin/kafka-configs.sh --zookeeper localhost:2181/kafkacluster --alter --entity-type topics --entity-name topicName --add-config 'max.message.bytes=50000000' --add-config 'flush.messages=50000'bin/kafka-configs.sh --zookeeper localhost:2181/kafkacluster --entity-type topics --entity-name topicName --describe 配置更改时的 Zookeeper 操作使用kafka-configs.sh脚本来变更（alter）配置时，会在ZooKeeper中创建一个命名形式为/config/&lt;entity-type&gt;/&lt;entity-name&gt;的节点，，并将变更的配置写入这个节点。 变更配置时还会在ZooKeeper中的/config/changes/节点下创建一个以config_change_为前缀的持久顺序节点（PERSISTENT_SEQUENTIAL），节点命名形式可以归纳为/config/changes/config_change_&lt;seqNo&gt; seqNo是一个单调递增的10位数字的字符串，不足位则用0补齐。 查看（describe）配置时，就是从/config/&lt;entity-type&gt;/&lt;entity-name&gt; 节点中获取相应的数据内容。 2.7 主题端配置参数与主题相关的所有配置参数在 broker 层面都有对应参数。如果没有修改过主题的任何配置参数，那么就会使用broker端的对应参数作为其默认值。 主题端参数 描述 对应的broker端参数 cleanup.policy 日志压缩策略。默认值为delete，还可以配置为compact log.cleanup.policy compression.type 消息的压缩类型。默认值是producer，表示保留生产者中所使用的原始压缩类型。还可以配置为uncompressed、snappy、lz4、gzip compression.type delete.retention.ms 被标识为删除的数据能够保留多久。默认值是86400000，即1天 log.clear.delete.retention.ms file.delete.delay.ms 清理文件之前可以等待多长时间，默认值是60000，即1分钟 log.segment.delete.delay.ms flush.messges 需要收集多少消息才会将它们强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值 log.flush.interval.messges flush.ms 需要等待多久才会将消息强制刷新到磁盘，默认值是Long.MAX_VALUE,即让操作系统来决定。建议不要修改此参数的默认值 log.flush.interval.ms follower.replication.throttled.replicas 用来配置被限制速率的主题所对应的follower副本列表 follower.replication.throttled.replicas index.interval.bytes 用来控制添加索引项的频率。每超过这个参数所设置的消息字节数时就可以添加一个新的索引项，默认值是4096 log.index.interval.bytes leader.replication.throttled.replicas 用来配置被限制速率的主题所对应的leader副本列表 leader.replication.throttled.replicas max.message.byte 消息的最大字节数，默认值是1000012 max.message.byte message.format.version 消息格式的版本，默认值为2.0-IV1 log.message.format.version message.timestamp.difference.max.ms 消息中自带的时间戳与broker收到消息时的时间戳之间的最大差值，默认值为Long.MAX_VALUE。此参数只有在message.timestamp.type参数设置为CreteTime时才有效 log.message.timestamp.difference.max.ms message.timestamp.type 消息的时间戳类型。默认值是CreteTime，还可以设置为LogAppendTime log.message.timestamp.type min.cleanable.dirty.ratio 日志清理时的最小污浊率，默认值是0.5 log.cleaner.min.cleanable.ratio min.compaction.lag.ms 日志再被清理前的最小保留时间，默认值为0 log.cleaner.min.compaction.lag.ms min.insync.replicas 分区ISR集合中至少有多少个副本，默认值为1 min.insync.replicas preallocate 在创建日志分段的时候是否要预分配空间，默认值为false log.preallocate retention.bytes 分区中所能保留的消息总量，默认值为-1，即没有限制 log.retention.bytes retention.ms 使用delete的日志清理策略时消息能够保留多长时间，默认值为604800000，即7天。如果设置为-1，则表示没有限制 log.retention.ms segment.bytes 日志分段的最大值，默认值为1073741824，即1GB log.segment.bytes segment.index.bytes 日志分段索引的最大值，默认值为10485760，即10MB log.index.size.max.bytes segment.jitter.ms 滚动日志分段时，在segment.ms的基础之上增加的随机数，默认为0 log.roll.jitter.ms segment.ms 最多多久滚动一次日志分段，默认值为604800000，即7天 log.roll.ms unclean.leader.election.enable 是否可以从非ISR集合中选举leader副本，默认值为false，如果设置为true，则可能造成数据丢失 unclean.leader.election.enable 3. KafkaAdminClient4. 分区的管理分区相关的知识和操作，包括优先副本的选举、分区重分配、复制限流、修改副本因子等内容。 4.1 kafka 负载均衡与优先副本的选举分区使用多副本机制来提升可靠性，但只有leader副本对外提供读写服务，而follower副本只负责在内部进行消息的同步。如果一个分区的leader副本不可用，此时Kafka就从剩余的follower副本中挑选一个新的leader副本来继续对外提供服务。 按照主从副本所在节点，可以将节点分为: leader 节点: 将leader副本所在的broker节点叫作分区的leader节点 follower节点: follower副本所在的broker节点 虽然不够严谨，但是 leader 节点是否分布均匀决定了 kafka 负载是否均衡。 为了能够有效地治理负载失衡的情况，Kafka引入了优先副本（preferred replica）的概念: 所谓的优先副本是指在 AR 集合列表中的第一个副本。 理想情况下，优先副本就是该分区的leader副本 所以也可以称之为preferred leader Kafka要确保所有主题的优先副本在Kafka集群中均匀分布，这样就保证了所有分区的leader均衡分布 所谓的优先副本的选举是指通过一定的方式促使优先副本选举为leader副本，以此来促进集群的负载均衡，这 需要注意的是，优先副本选举只能保证 leader 分配均衡，但这并不意味着Kafka集群的负载均衡，kafka 集群的负载均衡与如下因素有关: 分区分配均衡 leader 分配均衡 每个 leader 分区的负载 自动平衡功能由于 Kafka 集群的 broker 节点不可避免地会遇到宕机或崩溃从而导致 kafka 失衡，因此需要自动平衡功能。与此对应的 broker 端参数是 auto.leader.rebalance.enable，用于控制是否启用kafka 自动平衡功能，默认为 True 启用。 如果开启分区自动平衡的功能，则 Kafka 的控制器会启动一个定时任务，这个定时任务会轮询所有的 broker节点，计算每个broker节点的分区不平衡率（broker中的不平衡率=非优先副本的leader个数/分区总数）是否超过leader.imbalance.per.broker.percentage参数配置的比值，默认值为 10%，如果超过设定的比值则会自动执行优先副本的选举动作以求分区平衡。执行周期由参数 leader.imbalance.check.interval.seconds 控制，默认值为300秒，即5分钟。 不过在生产环境中不建议将auto.leader.rebalance.enable设置为默认的true。因为自动均衡会引起客户端一定时间的阻塞，可能在业务关键时期造成重大影响，而且是非预期不可控的。对于 kafka 集群一定的负载不均衡是可以接受的，重要的不平衡的程序，需要针对此类相关的埋点指标设置相应的告警，并超过预警时手动执行分区平衡。 手动均衡kafka-perferred-replica-election.sh 脚本提供了对分区leader副本进行重新平衡的功能(即执行优先副本的选举，保证所有的优先副本就是该分区的 leader副本)。优先副本的选举过程是一个安全的过程，Kafka客户端可以自动感知分区leader副本的变更。 1bin/kafka-perferred-replica-election.sh --zookeeper localhost:2181/kafka 上面示例中的这种使用方式会将集群上所有的分区都执行一遍优先副本的选举操作，leader 副本的转移也是一项高成本的工作，如果执行的分区数很多，势必会造成影响，如果集群包含大量分区，则可能失效。 优先副本选举过程在优先副本的选举过程中，具体的元数据信息会被存入 ZooKeeper的 /admin/preferred_replica_election 节点，如果这些数据超过了ZooKeeper节点所允许的大小，那么选举就会失败。默认情况下ZooKeeper所允许的节点数据大小为1MB。生产环境中一般分批、手动地执行优先副本的选举操作。同时，优先副本的选举操作也要注意避开业务高峰期，以免带来性能方面的负面影响。 kafka-perferred-replica-election.sh脚本中还提供了path-to-json-file参数来小批量地对部分分区执行优先副本的选举操作。通过path-to-json-file参数来指定一个JSON文件，这个JSON文件里保存需要执行优先副本选举的分区清单。 1234567891011121314151617181920cat election.json&#123; "partitions":[ &#123; "partition": 0, "topic": "topicName" &#125;, &#123; "partition": 1, "topic": "topicName" &#125;, &#123; "partition": 2, "topic": "topicName" &#125; ]&#125;bin/kafka-perferred-replica-election.sh --zookeeper localhost:2181/kafka \ --path-to-json-file election.json 4.2 分区重分配当集群中的一个节点突然宕机下线时，kafka 会自动对此节点上的 leader 副本转交到集群的其他follower副本中。但 Kafka 并不会将这些失效的分区副本自动地迁移到集群中剩余的可用broker节点上，因此需要手动进行分区副本的迁移。 当集群中新增broker节点时，只有新创建的主题分区才有可能被分配到这个节点上，而之前的主题分区并不会自动分配到新加入的节点中。 为了解决上述问题，需要让分区副本再次进行合理的分配，也就是所谓的分区重分配。Kafka提供了 kafka-reassign-partitions.sh 脚本来执行分区重分配的工作，它可以在集群扩容、broker节点失效的场景下对分区进行迁移。优先副本选举就属于分区重分配。 分区重分配的执行kafka-reassign-partitions.sh 脚本的使用分为 3 个步骤： 首先创建需要一个包含主题清单的JSON 文件 其次根据主题清单和 broker 节点清单生成一份重分配方案 最后根据这份方案执行具体的重分配动作 1234567891011121314151617181920212223242526272829303132# 1. 创建一个JSON文件（resign.json），文件内容为要进行分区重分配的主题清单cat resign.json&#123; "topics": [ &#123; "topic": "topic-ressign" &#125; ], "version": 1&#125;# 2. 生成重分配方案bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --generate \ # 一种指令类型 --topics-to-move-json-file resign.json \ # 执行要执行分区重分配的主题 --broker-list 0,2 # 指定要分配的节点列表 # 输出 Current partition replica assignment... # &#123;&#125; # 当前的分区副本分配情况，需要备份，以便后续的回滚操作 Proposed partition reassignment configuration # &#123;&#125; # 所对应的JSON 内容为重分配的候选方案，将其保存为 project.json# 3. 执行分区重分配bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --execute # 指令类型，表示执行分区重分配 --reassignment-json-file project.json # 指定分区重分配方案的路径# 4. 查看分区重分配的的进度bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --verify # 指令类型，查看分区重分配的进度 --reassignment-json-file project.json # 指定分区重分配方案的路径 对于分区重分配而言，这里还有可选的第四步操作，即验证查看分区重分配的进度。只需将上面的execute替换为verify即可。 分区重分配的基本原理分区重分配的基本原理是先通过控制器为每个分区添加新副本（增加副本因子），新的副本将从分区的leader副本那里复制。在复制完成之后，控制器将旧副本从副本清单里移除（恢复为原先的副本因子数）。 分区重分配对集群的性能有很大的影响，需要占用额外的资源，比如网络和磁盘。在实际操作中，我们将降低重分配的粒度，分成多个小批次来执行，以此来将负面的影响降到最低，这一点和优先副本的选举有异曲同工之妙。 还需要注意的是，如果要将某个broker下线，那么在执行分区重分配动作之前最好先关闭或重启broker。这样这个broker就不再是任何分区的leader节点了，它的分区就可以被分配给集群中的其他broker。这样可以减少broker间的流量复制，以此提升重分配的性能，以及减少对集群的影响。 4.3 复制限流分区重分配本质在于数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本来达到最终的目的。数据复制会占用额外的资源，这时就需要有一个限流的机制，可以对副本间的复制流量加以限制来保证重分配期间整体服务不会受太大的影响。 副本间的复制限流有两种实现方式：kafka-config.sh脚本和kafka-reassign-partitions.sh脚本。 通过 kafka-configs.sh 配置复制限流kafka-config.sh脚本主要以动态配置的方式来达到限流的目的，在broker级别有两个与复制限流相关的配置参数：` follower.replication.throttled.rate`: 设置follower副本复制的速度，单位都是B/s leader.replication.throttled.rate: 设置leader副本传输的速度，单位都是B/s 在主题级别也有两个相关的参数来限制复制的速度：leader.replication.throttled.replicas 和 follower.replication.throttled.replicas，它们分别用来配置被限制速度的主题所对应的leader副本列表和follower副本列表。 1234567891011121314# 对 broker 设置复制限流bin/kafka-configs.sh --zookeeper localhost:2181/kafka \ --entity-type broker \ --entity-name 1 \ --alter \ --add-config follower.replication.throttled.rate=1024,leader.replication.throttled.rate=1024# 对主题设置复制限流bin/kafka-configs.sh --zookeeper localhost:2181/kafka \ --entity-type topics \ --entity-name topic-throttle \ --alter \ --add-config leader.replication.throttled.replicas=[0:0,1:1,2:2], \ follower.replication.throttled.replicas=[0:1, 2:2, 2:0] 接下来我们看一个带限流的分区重分配方案。因为分区重分配会引起某个分区AR集合的变更，那么这个分区中与leader有关的限制会应用于重分配前的所有副本，因为任何一个副本都可能是leader，而与follower有关的限制会应用于所有移动的目的地。我们举一个例子。 首先看一下重分配前和分配后的分区副本布局对比，这里我们假设有 3 个 broker，一个主题有 3 个分区，每个分区两个副本。现在要将 broker 下架。 1234partition 重分配前的AR 重分配之后的AR 0 0,1 0,2 1 1,2 0,2 2 2,0 0,2 对上面的布局对比而言，分区0重分配的AR为[0，1]，重分配后的AR为[0，2]，那么这里的目的地就是新增的2。也就是说，对分区0而言，leader.replication.throttled.replicas配置为[0：0，0：1]，follower.replication.throttled.replicas 配置为[0：2]。分区 leader和 follower 则相应为 [1:1,1:2], [1:0] 接下来我们就可以执行具体操作: 1234567891011121314151617181920212223# 1. 为主题设置复制限流bin/kafka-configs.sh --zookeeper localhost:2181/kafka \ --entity-type topics \ --entity-name topic-throttle \ --alter \ --add-config leader.replication.throttled.replicas=[1:1,1:2,0:0,0:1], \ follower.replication.throttled.replicas=[0:2, 1:0]# 2. 设置 broker2 的复制限流bin/kafka-configs.sh --zookeeper localhost:2181/kafka \ --entity-type broker \ --entity-name 2 \ --alter \ --add-config follower.replication.throttled.rate=10,leader.replication.throttled.rate=10# 3. 执行正常的分区重分配bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --execute # 指令类型，表示执行分区重分配 --reassignment-json-file project.json # 指定分区重分配方案的路径# 4. 查看分区重分配的进度bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --verify # 指令类型，查看分区重分配的进度 --reassignment-json-file project.json # 指定分区重分配方案的路径 为了不影响Kafka本身的性能，往往对临时设置的一些限制性的配置在使用完后要及时删除。 kafka-reassign-partitions.sh 配置复制限流kafka-reassign-partitions.sh脚本本身也提供了限流的功能，只需一个throttle参数即可。 12345# 3. 执行正常的分区重分配，同时限流bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --execute # 指令类型，表示执行分区重分配 --reassignment-json-file project.json # 指定分区重分配方案的路径 --throttle 10 需要特别注意的是，使用这种方式的限流同样需要显式地在重分配完成之后手动删除限流的设置。如果想在重分配期间修改限制来增加吞吐量，以便完成得更快，则可以重新运行 kafka-reassign-partitions.sh脚本的execute命令，只需更改 throttle 的值即可。 kafka-reassign-partitions.sh脚本提供的限流功能背后的实现原理就是配置与限流相关的那4个参数而已，没有什么太大的差别。不过使用 kafka-config.sh 脚本的方式来实现复制限流的功能比较烦琐，并且在手动配置限流副本列表时也比较容易出错，推荐大家使用kafka-reassign-partitions.sh脚本配合throttle参数的方式，方便快捷且不容易出错。 4.4 修改副本因子kafka-reassign-partition.sh 还可以实现修改副本因子的功能。修改副本因子与分区重分配有一样，首先需要准备一份带修改的主题清单: 1234567891011121314151617181920cat project,json&#123; "topics": [ &#123; "topic": "topic-ressign", "partition": 1, "replicas": [ # 指定副本数 0, # brokerid，表示副本所在的节点 1, # 增加的 2 ], "log_dirs": [ # 指定副本所在的日志目录 "any", # any 表示使用默认配置 "any", # 增加的 "any" ] &#125; ], "version": 1&#125; 然后执行增加副本的操作: 123bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka \ --execute # 指令类型，表示执行分区重分配 --reassignment-json-file project.json # 指定分区重分配方案的路径 在配置文件中我们需要决定，每个分区的副本所在的节点，如果在众多 broker 中进行合理的分配是一个关键的问题。我们可以将我们的分配策略写成程序自动完成。 4.4 分区数选择分区数的选择没有固定答案，要根据实际的业务场景、软件条件、硬件条件、负载情况等来做具体的考量，并结合测试来最终决定。 性能测试工具Kafka 提供了如下测试工具: kafka-producer-perf-test.sh: 用于生产者性能测试 kafka-consumer-perf-test.sh: 用于消费者性能测试 分区数越大越好么？消息中间件的性能一般是指吞吐量（广义来说还包括延迟）。 分区是Kafka 中最小的并行操作单元，对生产者而言，每一个分区的数据写入是完全可以并行化的；对消费者而言，Kafka 只允许单个分区中的消息被一个消费者线程消费，一个消费组的消费并行度完全依赖于所消费的分区数。看上去好像分区数越多，吞吐量越大。 分区数不是越多越好，大量分区会导致下面这些问题: 分区进行 leader 角色切换的过程会变得不可用，如果集群某个 broker 节点宕机，那么会有大量分区同时进行 leader 角色切换，就会耗费可观的时间，并且在这个时间窗口内这些分区也会变得不可用。 让 kafka 启动和关闭变得更慢 增加日志清理的耗时，而且在被删除时也会耗费更多的时间 从吞吐量方面考虑，增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。 抛开硬件资源的影响，消息写入的吞吐量还会受到消息大小、消息压缩方式、消息发送方式（同步/异步）、消息确认类型（acks）、副本因子等参数的影响，消息消费的吞吐量还会受到应用逻辑处理速度的影响。 在设定完分区数，或者更确切地说是创建主题之后，还要对其追踪、监控、调优以求更好地利用它。 文件描述限制一味增加分区数并不能使吞吐量一直得到提升，并且如果分区数超过默认的配置值，还会引起kafka 奔溃。原因是 kafka 打开的文件描述符超过了系统配置的上线。对于线上环境，将文件描述符调至最大 65536 足以应对大多数情况。 文件描述符等资源限制可在 /etc/security/limits.conf 配置。也可以在/etc/profile 中通过 ulimit 命令配置。在选择合适的分区数之前，最好再考量一下当前Kafka进程中已经使用的文件描述符的个数。 分区数量的修改在创建主题之后，虽然我们还能够增加分区的个数，但基于key计算的主题需要严谨对待。如果分区的数量发生变化，那么有序性就得不到保证。在创建主题时最好能确定好分区数，尤其对于 key 高关联的应用，在创建主题时可以适当地多创建一些分区，以满足未来的需求。 有些应用场景会要求主题中的消息都能保证顺序性，这种情况下在创建主题时可以设定分区数为1，通过分区有序性的这一特性来达到主题有序性的目的。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.3 生产者客户端]]></title>
    <url>%2F2020%2F04%2F03%2Fkafka%2F03_%E7%94%9F%E4%BA%A7%E8%80%85%2F</url>
    <content type="text"><![CDATA[Kafka 的生产者客户端 1. 生产者客户端概述Kafka 生产者客户端一共有两大版本: Scala 语言的旧版 Java 语言的新版 旧版几乎不再使用，我们接下来主要介绍新版 Java 客户端的使用，内容包括: 生产者的客户端开发: 编码步骤 配置参数 消息的发送 序列化 分区器 生产者拦截器 原理: 生产者客户端的整体架构 元数据更新 重要的生产者配置参数 说明: Kafka 支持多语言，书中使用的是 Java，本人不会 Java，这里使用 Python 语言。 1. 客户端开发一个正常的生产逻辑需要具备以下几个步骤： 配置生产者客户端参数及创建相应的生产者实例 构建待发送消息 发送消息 关闭生产者实例 1234567891011121314151617181920212223from confluent_kafka import Producerimport socketconf = &#123;'bootstrap.servers': "host1:9092,host2:9092", 'client.id': socket.gethostname()&#125;producer = Producer(conf)# 1. 同步提交producer.produce(topic, key="key", value="value")producer.flush()# 2.异步提交def acked(err, msg): if err is not None: print("Failed to deliver message: %s: %s" % (str(msg), str(err))) else print("Message produced: %s" % (str(msg)))producer.produce(topic, key="key", value="value", callback=acked)# Wait up to 1 second for events. Callbacks will be invoked during# this method call if the message is acknowledged.producer.poll(1) 1.1 消息设置这里有必要单独说明的是构建的消息对象 ProducerRecord(Java 的客户端里把消息抽象成了一个独立的类，但是在 confluent_kafka 里并没有，这些参数直接放在了 produce 方法中) produce(topic[, value][, key][, partition][, on_delivery][, timestamp][, headers]) topic: 消息要发送到的主题 parition: 消息要发送到的分区 headers: 消息的头部，用来设定一些与应用相关的信息，如无需要也可以不用设置 key: 指定消息的键，用来计算分区号进而可以让消息发往特定的分区 有key的消息还可以支持日志压缩的功能 value: 消息体，一般不为空，如果为空则表示特定的消息—墓碑消息， timestamp: int 消息的时间戳，默认为当前时间 消息的时间戳一般有CreateTime(消息创建的时间) LogAppendTime(消息追加到日志文件的时间) 两种类型，confluent_kafka 还未找到设置的方式 on_delivery/callback: 指定消息发送的回调函数 1.2 生产者配置参数实例化生产者时需要配置相应的参数，即上面的 conf 对象，Producer 的 conf 至少需要如下参数: bootstrap.servers： 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单 默认: 默认值为 “” 格式: 具体的内容格式为host1：port1，host2：port2 说明: 不需要执行所有的broker地址，因为生产者会从给定的broker里查找到其他broker的信息 client.id: 作用: 设定KafkaProducer对应的客户端id 默认: 默认值为””，如果客户端不设置，则KafkaProducer会自动生成一个非空字符串，内容形式如“producer-1”“producer-2” 1.3 消息发送发送消息主要有三种模式： 发后即忘（fire-and-forget） 只管往Kafka中发送消息而并不关心消息是否正确到达 可能会造成消息丢失，性能最好，可靠性最差 同步（sync） 异步（async） 消息在通过send（）方法发往broker的过程中，有可能需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）的一系列作用之后才能被真正地发往 broker。 1.4 序列化broker 端接收的消息必须以字节数组（byte[]）的形式存在。因此在发往broker之前需要将消息中对应的key和value做相应的序列化操作来转换成字节数组。序列化需要使用序列化器（Serializer）。 1.5 分区器拦截器一般不是必需的，而序列化器是必需的。消息经过序列化之后就需要确定它发往的分区，如果消息ProducerRecord中指定了partition字段，那么就不需要分区器的作用，因为partition代表的就是所要发往的分区号。如果消息ProducerRecord中没有指定partition字段，那么就需要依赖分区器，根据key这个字段来计算partition的值。分区器的作用就是为消息分配分区。 1.6 拦截器生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息的内容等，也可以用来在发送回调逻辑前做一些定制化的需求，比如统计类工作。 2. 生产者客户端原理接下来我们将通过了解生产者客户端的整体脉络，以便能更好的使用它。 2.1 整体架构 如上图所示，生产者客户端由两个线程协调运行: 主线程: 将消息缓存到消息累加器（RecordAccumulator，也称为消息收集器）中 Sender线程: 从RecordAccumulator中获取消息并将其发送到Kafka中 RecordAccumulatorRecordAccumulator 主要用来缓存消息以便 Sender 线程可以批量发送: RecordAccumulator 缓存的大小可以通过生产者客户端参数 buffer.memory 配置，默认值为 33554432B，即 32MB 如果生产者发送消息的速度超过发送到服务器的速度，则会导致生产者空间不足，这个时候KafkaProducer的send（）方法调用要么被阻塞，要么抛出异常，这个取决于参数max.block.ms的配置，此参数的默认值为60000，即60秒。 RecordAccumulator 由如下几个部分组成: 主线程中发送过来的消息都会被追加到RecordAccumulator的某个双端队列（Deque）中 在 RecordAccumulator 的内部为每个分区都维护了一个双端队列，队列中的内容就是ProducerBatch，即 Deque＜ProducerBatch＞ 消息写入缓存时，追加到双端队列的尾部；Sender读取消息时，从双端队列的头部读取 注意 ProducerBatch不是ProducerRecord ，ProducerBatch中可以包含一至多个 ProducerRecord。通俗地说，ProducerRecord 是生产者中创建的消息，而 ProducerBatch是指一个消息批次 ，ProducerRecord会被包含在ProducerBatch中，这样可以使字节的使用更加紧凑。与此同时，将较小的ProducerRecord拼凑成一个较大的ProducerBatch，也可以 减少网络请求的次数以提升整体的吞吐量 ProducerBatch: ProducerBatch和消息的具体格式有关，后面我们会详细介绍 kafka 各个消息的消息格式。如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory如果生产者客户端需要向很多分区发送消息，则可以将buffer.memory参数适当调大以增加整体的吞吐量 BufferPool 与 batch.size: 消息在网络上都是以字节（Byte）的形式传输的，在发送之前需要创建一块内存区域来保存对应的消息，这块区域通常由 io.Buffer 创建和释放，为了 io.Buffer 的利用效率可以 BufferPool 对 io.Buffer 进行复用。(Java客户端中)BufferPool只针对特定大小的ByteBuffer进行管理，而其他大小的ByteBuffer不会缓存进BufferPool中，这个特定的大小由 batch.size 参数来指定，默认值为16384B，即16KB。 消息的发送也与 batch.size 有关，当一条消息（ProducerRecord）流入RecordAccumulator时，会先寻找与消息分区所对应的双端队列（如果没有则新建），再从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建），查看 ProducerBatch 中是否还可以写入这个 ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的ProducerBatch。在新建ProducerBatch时评估这条消息的大小是否超过batch.size参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建ProducerBatch，这段内存区域不会被复用。 SenderSender 的发送过程分为如下步骤: Sender 从 RecordAccumulator 中获取缓存的消息之后，首先会将 ＜分区，Deque＜ProducerBatch＞＞的保存形式转变成 ＜Node，List＜ ProducerBatch＞ 的形式。因为对于网络连接来说，客户端连接的是具体的 broker，而不关心消息属于哪个分区。 ＜Node，List＜ ProducerBatch＞ 进一步被转换为 ＜Node，Request＞，这样就可以发送 Request。这里的Request是指Kafka的各种协议请求，对于消息发送而言就是指具体的 ProduceRequest。 请求在从Sender线程发往Kafka之前还会保存到 InFlightRequests 中，InFlightRequests保存对象的具体形式为 Map＜NodeId，Deque＜Request＞＞，的主要作用是缓存了已经发出去但还没有收到响应的请求 InFlightRequests还提供了许多管理类的方法。比如通过配置 max.in.flight.requests.per.connection 可以限制每个连接最多缓存的请求数，默认值为 5。超过这个值之后就不能继续发送请求，除非缓存的请求收到了响应。通过比较。通过比较Deque＜Request＞的size与这个参数的大小来判断对应的Node中是否已经堆积了很多未响应的消息，如果真是如此，那么说明这个 Node 节点负载较大或网络连接有问题。 InFlightRequests还可以获得leastLoadedNode，即所有Node中负载最小的那一个。这里的负载最小是通过每个Node在InFlightRequests中还未确认的请求决定的，未确认的请求越多则认为负载越大。选择leastLoadedNode发送请求可以使它能够尽快发出，避免因网络拥塞等异常而影响整体的进度。leastLoadedNode的概念可以用于多个应用场合，比如元数据请求、消费者组播协议的交互。 2.2 元数据更新为什么需要元数据当我们发送消息时，除了主题，通常对其他必要信息一无所知。kafka 将消息发送到指定主题的某个分区的leader 副本之前，需要知道: 主题的分区数量，然后经过计算得出（或者直接指定）目标分区 之后KafkaProducer需要知道目标分区的leader副本所在的broker 节点的地址、端口等信息才能建立连接，最终才能将消息发送到 Kafka bootstrap.servers 参数只需要配置部分broker节点的地址即可，不需要配置所有broker节点的地址，因为客户端可以自己发现其他broker节点的地址，这一过程也属于元数据相关的更新操作。与此同时，分区数量及leader副本的分布都会动态地变化，客户端也需要动态地捕捉这些变化。 元数据是什么元数据是指Kafka集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的leader副本分配在哪个节点上，follower副本分配在哪些节点上，哪些副本在AR、ISR等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。 元数据何时更新当客户端中没有需要使用的元数据信息时，比如没有指定的主题信息，或者超过 metadata.max.age.ms 时间没有更新元数据都会引起元数据的更新操作。客户端参数metadata.max.age.ms的默认值为300000，即5分钟。元数据更新过程对外部使用者不可见。 当需要更新元数据时，会先挑选出leastLoadedNode，然后向这个Node发送MetadataRequest请求来获取具体的元数据信息。更新操作是由Sender线程发起的，在创建完MetadataRequest 之后同样会存入InFlightRequests，之后的步骤就和发送消息时的类似。元数据虽然由Sender线程负责更新，但是主线程也需要读取这些信息，这里需要数据同步。 3. 重要的生产者客户端参数生产者客户有很的参数，涉及到消息的顺序性、性能和可靠性，重要的参数列示如下: bootstrap.servers：前面已介绍 client.id: 前面已介绍 acks: 非常重要 作用: 指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的 可选值: 字符串类型 acks=1 响应时点: 生产者发送消息之后，只要分区的leader副本成功写入消息，那么它就会收到来自服务端的成功响应 丢失可能: 如果消息成功写入 Leader副本，并响应给生产者，在被副本拉取之前，Leader 副本崩溃，则消息丢失。 acks=0 响应时点: 生产者发送消息之后不需要等待任何服务端的响应 丢失可能: 如果消息在发送过程中就出现异常，那么消息就会丢失 acks=-1或acks=all 响应时点: 生产者在消息发送之后，需要等待ISR中的所有副本都成功写入消息之后才能够收到来自服务端的成功响应 丢失可能: 这并不意味着消息就一定可靠，因为ISR中可能只有leader副本。要获得更高的消息可靠性需要配合 min.insync.replicas 等 默认: 默认值 acks=1 说明: 生产者客户端在请求超时或者发生异常时，是需要进行重试的，这样才能保证消息不丢失，但由此也可能就导致了消息重复发送 max.request.size: 重要 作用: 限制生产者客户端能发送的消息的最大值 默认: 默认值为 1048576B，即 1MB 说明: 不建议读者盲目地增大这个参数的配置值。因为这个参数还涉及一些其他参数的联动，比如broker端的message.max.bytes 参数。如果配置错误会引起不必要的有异常 retries 和 retry.backoff.ms: 作用: 生产者内部重试的次数和重试间隔 配置这两个参数时，最好先估算一下可能的异常恢复时间，总的重试时间大于这个异常恢复时间，这样才能避免生产者过早地放弃重试。 默认: retries 默认值为0，表示不重试 retry.backoff.ms，默认值为100 说明: 一些临时性的异常可以通过重试来解决，比如网络抖动、leader副本的选举等，其他异常是不行的，比如配置错误 compression.type: 作用: 指定消息的压缩方式 可选值: gzip、snappy、lz4 默认: 默认值为 none，不压缩 说明: 消息压缩是一种使用时间换空间的优化方式，如果对时延有一定的要求，则不推荐对消息进行压缩。 connections.max.idle.ms: 作用: 指定在多久之后关闭限制的连接 默认: 默认值是540000（ms），即9分钟 说明: linger.ms: 作用: 指定生产者发送 ProducerBatch 之前等待更多消息（ProducerRecord）加入ProducerBatch 的时间 默认: 默认值为 0 说明: 增大这个参数的值会增加消息的延迟，但是同时能提升一定的吞吐量 receive.buffer.bytes: 作用: 设置Socket接收消息缓冲区（SO_RECBUF）的大小 默认: 默认值为32768（B），即32KB 设置为-1，则使用操作系统的默认值 说明: 如果Producer与Kafka处于不同的机房，则可以适地调大这个参数值 send.buffer.bytes: 作用: 设置Socket发送消息缓冲区（SO_SNDBUF）的大小 默认: 默认值为131072（B），即128KB 设置为-1，则使用操作系统的默认值 request.timeout.ms 作用: 配置 Producer 等待请求的最长时间 默认: 默认值为30000（ms） 说明: 这个参数需要比broker端参数 replica.lag.time.max.ms 的值要大，这样可以减少因客户端重试而引起的消息重复的概率。 3.1 kafka 消息有序性Kafka 可以保证同一个分区中的消息是有序的。对于某些应用来说，顺序性非常重要，比如MySQL的binlog传输。消息的有序性需要: 生产者按照一定顺序发送消息，保证消息顺序地写入分区 消费者需要按照同样的顺序消费消息 如果将acks参数配置为非零值，并且max.in.flight.requests.per.connection参数配置为大于 1，那么就有可能出现乱序。因此在需要保证消息顺序时，需要把参数max.in.flight.requests.per.connection配置为1，而不是把acks配置为0。不过这样也会影响整体的吞吐。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.4 消费者客户端]]></title>
    <url>%2F2020%2F04%2F03%2Fkafka%2F04_%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[Kafka 的生产者客户端 1. 消费者客户端概述接下来我们将介绍 kafka 消费者客户端，内容包括: 消费者与消费者组 消费者客户端开发，包括 主题订阅 反序列化 消费者拦截器 消息消费和消息确认 再均衡 与生产者客户端一样，消费者客户端也分成两个版本，我们只介绍新版本，并依旧使用 Python 语言来编写示例代码。 2. 消费者与消费者组kafka 通过消费者组（Consumer Group）来同时实现消息传递的两种模式: 负载均衡和扇出。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。消费者组中的每个消费者只能消费所分配到的分区中的消息。换言之，每一个分区只能被一个消费组中的一个消费者所消费。通过消费者客户端参数partition.assignment.strategy可以来设置消费者与订阅主题之间的分区分配策略，分区分配策略的细节我们之后在深入学习 kafka 相关原理时会详细讲解。 消费者组是一个逻辑上的概念，每一个消费者只隶属于一个消费组。每一个消费组都会有一个固定的名称，消费者在进行消费前需要指定其所属消费组的名称，通过消费者客户端参数group.id来配置，默认值为空字符串。 2. 消费者客户端开发一个正常的消费逻辑需要具备以下几个步骤： 配置消费者客户端参数及创建相应的消费者实例。 订阅主题 拉取消息并消费 消息确认，即提交消费位移 关闭消费者实例 12345678910111213141516171819202122232425262728293031323334from confluent_kafka import Consumerconf = &#123;'bootstrap.servers': "host1:9092,host2:9092", 'group.id': "foo", 'auto.offset.reset': 'smallest'&#125;consumer = Consumer(conf)running = Truedef basic_consume_loop(consumer, topics): try: # 订阅主题，一个或多个 consumer.subscribe(topics) while running: msg = consumer.poll(timeout=1.0) if msg is None: continue if msg.error(): if msg.error().code() == KafkaError._PARTITION_EOF: # End of partition event sys.stderr.write('%% %s [%d] reached end at offset %d\n' % (msg.topic(), msg.partition(), msg.offset())) elif msg.error(): raise KafkaException(msg.error()) else: msg_process(msg) finally: # Close down consumer to commit final offsets. consumer.close()def shutdown(): running = False 2.1 必要的连接参数Kafka消费者客户端有四个参数是必填的 bootstrap.servers： 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单 默认: 默认值为 “” 格式: 具体的内容格式为host1：port1，host2：port2 说明: 不需要指定所有的broker地址，因为消费者会从给定的broker里查找到其他broker的信息 group.id: 作用: 消费者隶属的消费者组名称 默认: 默认值为 “”，设置为空，则会报出异常 说明: 需要设置成具有一定的业务意义的名称 key.deserializer: 指定键的反序列化器 value.deserializer: 指定值的反序列化器 client.id: 作用: 设定KafkaConsumer对应的客户端id 默认: 默认值为 “”，非必须参数 说明: 客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1” Python kafka 客户端实现与 Java 略有不同，自定义反序列化器是通过Producer子类实现的，还有一些使用特殊序列化协议的序列化/反序列化器。 2.2 订阅主题和分区consumer.subscribe(topics[, on_assign=None][, on_revoke=None]) 作用: 主题订阅 topics: 指定订阅的主题，一个或多个 如果前后两次订阅了不同的主题，以最后一次的为准 正则表达式的主题名称需要以 “^” 开头 如果在订阅主题之后，又有人创建了新的主题，并且与正则表达式的主题匹配，消费者可以消费到新添加的主题中的消息 在Kafka 和其他系统之间进行数据复制时，这种正则表达式的方式就显得很常见 on_assign: 可调用函数，用于在 partition re-assignment 成功后提供自定义偏移量 on_revoke: 可调用函数，用于在再均衡开始前，提供对偏移量的处理，并提交至服务端 12# 1. 正则表达式的主题名称consumer.subscribe(["^my_topic.*", "^another[0-9]-?[a-z]+$", "not_a_regex"]) consumer.assign(partitions) 作用: 直接订阅主题的分区 partitions: TopicPartition 的 List 指定需要订阅的分区集合 TopicPartition(topic [, partition][, offset]) 作用: 保存主题单个分区的类 topic: 所属主题 partition: 分区ID offset: 初始分区偏移量 consumer.assignment() 作用: 返回主题的分区元数据，类型为 TopicPartition 的 List consumer.unsubscribe() 作用: 删除当前订阅 subscribe(topics)、正则表达式订阅的方式subscribe(Pattern)和指定分区的订阅方式 assign(TopicPartition)分表代表了三种不同的订阅状态：AUTO_TOPICS、AUTO_PATTERN和USER_ASSIGNED。这三种状态是互斥的，在一个消费者中只能使用其中的一种，否则会报错。 通过 subscribe（）方法订阅主题具有消费者自动再均衡的功能，在多个消费者的情况下可以根据分区分配策略来自动分配各个消费者与分区的关系。当消费组内的消费者增加或减少时，分区分配关系会自动调整，以实现消费负载均衡及故障自动转移。而通过assign()方法订阅分区时，是不具备消费者自动均衡的功能的。 2.3 反序列化2.4 消费者拦截器消费者拦截器主要在消费到消息或在提交消费位移时进行一些定制化的操作。暂时还未在 confluent kafka 中找到消费者拦截器的设置方式。 3. 消息消费Kafka中的消费是基于拉模式的。如示例所示，消费的过程是不断调用 poll() 方法，poll 返回的是所订阅主题(分区)上的一组消息。 consumer.poll([timeout=None]) 作用: 一次消费一个消息 返回: Message 或者 None 对于poll（）方法而言，如果某些分区中没有可供消费的消息，那么此分区对应的消息拉取的结果就为空 如果订阅的所有分区中都没有可供消费的消息，那么poll（）方法返回为空的消息集合。 timeout: 控制poll 方法的阻塞时间，在消费者的缓冲区里没有可用数据时会发生阻塞 timeout的设置取决于应用程序对响应速度的要求，比如需要在多长时间内将控制权移交给执行轮询的应用线程 如果应用线程唯一的工作就是从Kafka中拉取并消费消息，则可以将这个参数设置为最大值Long.MAX_VALUE。 classconfluent_kafka.Message 作用: 返回的消息包装类 consumer.consume([num_messages=1][, timeout=-1]) 作用: 一次消费多条消息 返回: list(Message) 参数: num_messages: 一次获取的最大消息数量，默认为 1 timeout: 获取消息时的超时时间 到目前为止，可以简单地认为poll（）方法只是拉取一下消息而已，但就其内部逻辑而言并不简单，它涉及消费位移、消费者协调器、组协调器、消费者的选举、分区分配的分发、再均衡的逻辑、心跳等内容，在后面的章节中会循序渐进地介绍这些内容。 3.1 位移提交每个消息在 Kafka 分区中都有一个 offset，相当于唯一ID，表示消息在分区中对应的位置。对于消费者，也有一个offset，消费者使用offset来表示消费到分区中某个消息所在的位置。 在每次调用poll（）方法时，它返回的是还没有被消费过的消息集。要做到这一点，就需要记录上一次消费时的消费位移。保存消费者位移的目的是为了在消费者重启或者再均衡之后，消费者知道从何处开始消费。 在旧消费者客户端中，消费位移是存储在ZooKeeper中的。而在新消费者客户端中，消费位移存储在Kafka内部的主题 __consumer_offsets 中。把将消费位移存储起来（持久化）的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。 如下图所示，假设消费者已经消费了 x 位置的消息: 我们称消费者的消费位移为 x，用 lastConsumedOffset 标识 消费者需要提交的消费位移是 x+1，即 position，它表示下一条需要拉取的消息的位置 还有一个committed offset的概念，它表示已经提交过的消费位移 位移提交的具体时机很有讲究，这决定了是可能造成重复消费和还是可能造成消息丢失。 位移提交有两种，手动提交和自动提交。自动提交由以下两个参数控制: enable.auto.commit: 默认值为 True 表示自动提交 auto.commit.interval.ms: int 表示自动提交的周期间隔，默认值为 5s 在默认的方式下，消费者每隔5秒会将拉取到的每个分区中最大的消息位移进行提交。自动位移提交的动作是在poll（）方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交，如果可以，那么就会提交上一次轮询的位移。 自动提交消费位移的方式非常简便，但随之而来的是重复消费和消息丢失的问题(注意是都有可能发生，因为消息会缓存在客户端)。与此同时，自动位移提交也无法做到精确的位移管理。因此大多数情况下，我们需要手动位移提交。 手动提交可以细分为同步提交和异步提交。同步异步提交与 commit 方法有关 comsumer.commit([message=None][, offsets=None][, asynchronous=True]) 作用: 提交位移 参数: message: 提交位移等于 消息的偏移量 + 1 offsets: list(TopicPartition)，主题列表 + 分区 + 提交偏移量 asynchronous: 是否异步提交，默认是 True 异步提交 注意: message 与 offset 是互斥的，如果都没有设置，则提交当前批次对应的 position 值 大多数情况下我们是按照分区的粒度划分提交位移的界限，此时需要 offsets 参数 同步位移提交123456789101112131415161718192021222324def consume_loop(consumer, topics): try: consumer.subscribe(topics) msg_count = 0 while running: msg = consumer.poll(timeout=1.0) if msg is None: continue if msg.error(): if msg.error().code() == KafkaError._PARTITION_EOF: # End of partition event sys.stderr.write('%% %s [%d] reached end at offset %d\n' % (msg.topic(), msg.partition(), msg.offset())) elif msg.error(): raise KafkaException(msg.error()) else: msg_process(msg) msg_count += 1 if msg_count % MIN_COMMIT_COUNT == 0: consumer.commit(async=False) finally: # Close down consumer to commit final offsets. consumer.close() 异步位移提交commit_completed 为异步提交设置有一个回调函数，用于处理异步提交失败的情况。我们可以在这个回调函数中进行位移提交的重试。但这样有可能覆盖掉后面发起的位移提交。为此我们可以设置一个递增的序号来维护异步提交的顺序，每次位移提交之后就增加序号相对应的值。在遇到位移提交失败需要重试的时候，可以检查所提交的位移和序号的值的大小，如果前者小于后者，则说明有更大的位移已经提交了，不需要再进行本次重试；如果两者相同，则说明可以进行重试提交。 在一般情况下，位移提交失败的情况很少发生，不重试也没有关系，后面的提交也会有成功的。重试会增加代码逻辑的复杂度，不重试会增加重复消费的概率。如果消费者正常退出或发生再均衡的情况，那么可以在退出或再均衡执行之前使用同步提交的方式做最后的把关。 123456789101112131415161718192021222324252627282930313233343536373839from confluent_kafka import Consumerdef commit_completed(err, partitions): if err: print(str(err)) else: print("Committed partition offsets: " + str(partitions))conf = &#123;'bootstrap.servers': "host1:9092,host2:9092", 'group.id': "foo", 'default.topic.config': &#123;'auto.offset.reset': 'smallest'&#125;, 'on_commit': commit_completed&#125;consumer = Consumer(conf)def consume_loop(consumer, topics): try: consumer.subscribe(topics) msg_count = 0 while running: msg = consumer.poll(timeout=1.0) if msg is None: continue if msg.error(): if msg.error().code() == KafkaError._PARTITION_EOF: # End of partition event sys.stderr.write('%% %s [%d] reached end at offset %d\n' % (msg.topic(), msg.partition(), msg.offset())) elif msg.error(): raise KafkaException(msg.error()) else: msg_process(msg) msg_count += 1 if msg_count % MIN_COMMIT_COUNT == 0: consumer.commit(async=True) finally: # Close down consumer to commit final offsets. consumer.close() 3.2 控制或关闭消费consumer 还提供了了方法用来，暂停和恢复消息拉取，以及最终关闭消费以释放资源。 consumer.pause(partitions) 作用: 暂停对传入的分区进行消费 参数: partitions: list(TopicPartition)，要暂停的主题分区列表 consumer.esume(partitions) 作用: 恢复对传入的分区的消费 参数: partitions: list(TopicPartition)，要暂停的主题分区列表 consumer.close() 作用: 停止消费 离开消费者群体 提交最终的位移 3.3 指定位移消费在 Kafka 中每当消费者查找不到所记录的消费位移时，就会根据消费者客户端参数 auto.offset.reset 的配置来决定从何处开始进行消费： auto.offset.reset 作用: 找不到消费者位移时，配置消费的起点 可选值: latest: 表示从分区末尾开始消费消息 earliest: 从起始处，也就是0开始消费 None: 查到不到消费位移的时候报错除了查找不到消费位移，位移越界也会触发 auto.offset.reset 参数的执行 consumer.seek 方法可以让我们更精确的控制消费的位移起点。 consumer.seek(partition) 作用: 执行消费的分区位移起点 参数: partition: TopicPartition，主题+分区+位移 说明: seek（）方法只能重置消费者分配到的分区的消费位置，而分区的分配是在 poll（）方法的调用过程中实现的 也就是说执行seek（）方法之前需要先执行一次poll（）方法，等到分配到分区之后才可以重置消费位置 对未分配到的分区执行seek（）方法，会报错 1# 1. seek 设置从末尾消费消息 根据时间设置位移起点有时候我们并不知道特定的消费位置，却知道一个相关的时间点，consumer.offsets_for_times 方法，通过 timestamp 来查询与此对应的分区位置。 consumer.offsets_for_times(partitions[, timeout=None]) 作用: 根据时间戳来查询对应的分区位置 每个分区返回的偏移量是其时间戳大于或等于相应分区中给定时间戳的最早偏移量 如果提供的时间戳超过分区中最后一条消息的时间戳，则返回值-1 返回: list(TopicPartition) 参数: partitions: list(TopicPartition) timeout: 超时时间 最后 seek() 方法也为我们提供了将消费位移保存在外部存储介质中的能力，还可以配合再均衡监听器来提供更加精准的消费能力。 3.4 再均衡再均衡是指分区的所属权从一个消费者转移到另一消费者的行为，它为消费组具备高可用性和伸缩性提供保障，使我们可以既方便又安全地删除消费组内的消费者或往消费组内添加消费者。不过在再均衡发生期间，消费组内的消费者是无法读取消息的。 另外，当一个分区被重新分配给另一个消费者时，消费者当前的状态也会丢失。一般情况下，应尽量避免不必要的再均衡的发生。 consumer.subscribe(topics[, on_assign=None][, on_revoke=None]) 中的 on_assign 和 on_revoke 参数就是再均衡监听器，用来设定发生再均衡动作前后的一些准备或收尾的动作。on_revoke: 调用: 在再均衡开始之前和消费者停止读取消息之后被调用 作用: 可以通过这个回调方法来处理消费位移的提交，以此来避免一些不必要的重复消费现象的发生 参数: list(TopicPartition) ，表示再均衡之前分配到的分区 on_assign: 调用: 会在重新分配分区之后和消费者开始读取消费之前被调用 作用: 可以通过这个回调方法设置新的位移起点 参数: list(TopicPartition) ，表示再均衡之后分配到的分区 再均衡监听器还可以配合外部存储使用，在此不再赘述。 3.5 消费者的多线程(进程)实现前面我们说过，一个分区只能被一个消费者进行消费，因此消费者的并发上限是分区数量。要想更快的进行消息处理，只能是一个线程接收消息，多个线程处理消息，但这对位移提交有比较高的编码要求。可以参考 TCP 中的滑动窗口，以固定的窗口为单位进行消息处理和位移提交。参考实现如下: 1# 1. 消费者的多进程实现 4. 重要的消费者参数消费者也有很多配置参数，这些参数涉及到 程序的可用性和性能 重要的列示如下: bootstrap.servers： 作用: 该参数用来指定生产者客户端连接Kafka集群所需的broker地址清单 默认: 默认值为 “” 格式: 具体的内容格式为host1：port1，host2：port2 说明: 不需要指定所有的broker地址，因为消费者会从给定的broker里查找到其他broker的信息 group.id: 作用: 消费者隶属的消费者组名称 默认: 默认值为 “”，设置为空，则会报出异常 说明: 需要设置成具有一定的业务意义的名称 key.deserializer: 指定键的反序列化器 value.deserializer: 指定值的反序列化器 client.id: 作用: 设定KafkaConsumer对应的客户端id 默认: 默认值为 “”，非必须参数 说明: 客户端不设置，则KafkaConsumer会自动生成一个非空字符串，内容形式如“consumer-1” fetch.min.bytes: 作用: 配置Consumer在一次拉取请求（调用poll（）方法）中能从Kafka中拉取的最小数据量 如果返回给Consumer的数据量小于这个参数所配置的值，那么它就需要进行等待，直到数据量满足这个参数的配置大小 默认: 默认值为1（B） 说明: 可以适当调大这个参数的值以提高一定的吞吐量，不过也会造成额外的延迟（latency） fetch.max.bytes: 作用: 配置Consumer在一次拉取请求中从Kafka中拉取的最大数据量 默认: 默认值为 52428800（B），也就是 50MB 说明: 如果在第一个非空分区中拉取的第一条消息大于该值，那么该消息将仍然返回 也就是说如果这个参数设置的值比任何一条写入Kafka中的消息要小，仍然是可以正常消费的 相关: Kafka中所能接收的最大消息的大小通过服务端参数message.max.bytes（对应于主题端参数max.message.bytes）来设置 fetch.max.wait.ms: 作用: 和fetch.min.bytes参数的等待时间，指定Kafka最长的等待时间 默认: 默认值为500（ms） 说明: max.partition.fetch.bytes: 作用: 配置从每个分区里返回给Consumer的最大数据量 默认: 默认值为1048576（B），即1MB 说明: fetch.max.bytes 用来限制一次拉取中整体消息的大小，此参数用来限制一次拉取中每个分区的消息大小 同样，如果这个参数设定的值比消息的大小要小，那么也不会造成无法消费 max.poll.records: 作用: 配置Consumer在一次拉取请求中拉取的最大消息数 默认: 默认值为500（条） 说明: connections.max.idle.ms: 作用: 指定多久之后关闭闲置的连接 默认: 默认值是540000（ms），即9分钟 说明: exclude.internal.topics: 作用: 指定Kafka中的内部主题是否可以向消费者公开 设置为true，那么只能使用subscribe（Collection）的方式而不能使用subscribe（Pattern）的方式来订阅内部主题 设置为false则没有这个限制 默认: 默认值为true 说明: receive.buffer.bytes: 作用: 设置Socket接收消息缓冲区（SO_RECBUF）的大小 默认: 默认值为65536（B），即64KB，如果设置为-1，则使用操作系统的默认值 说明: gsend.buffer.bytes: 作用: 设置Socket发送消息缓冲区（SO_SNDBUF）的大小 默认: 默认值为131072（B），即128KB，如果设置为-1，则使用操作系统的默认值 说明: request.timeout.ms: 作用: 配置Consumer等待请求响应的最长时间 默认: 默认值为30000（ms） 说明: metadata.max.age.ms 作用: 这个参数用来配置元数据的过期时间 默认: 默认值为300000（ms），即5分钟 说明: 如果元数据在此参数所限定的时间范围内没有进行更新，则会被强制更新，即使没有任何分区变化或有新的broker加入 reconnect.backoff.ms: 作用: 配置尝试重新连接指定主机之前的等待时间（也称为退避时间），避免频繁地连接主机 默认: 默认值为50（ms） 说明: 这种机制适用于消费者向broker发送的所有请求 retry.backoff.ms: 作用: 来配置尝试重新发送失败的请求到指定的主题分区之前的等待（退避）时间，避免在某些故障情况下频繁地重复发送 默认: 默认值为100（ms） 说明: isolation.level: 作用: 用来配置消费者的事务隔离级别 可选值: read_uncommitted 和 read_committed 表示消费者所消费到的位置 read_committed: 消费者会忽略事务未提交的消息，即只能消费到 LSO（LastStableOffset）的位置 read_uncommitted: 消费者可以消费到HW（High Watermark）处的位置 默认: 默认情况下为 read_uncommitted 说明:]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 Kafka 入门]]></title>
    <url>%2F2020%2F04%2F02%2Fkafka%2F02_kafka%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[在深入学习 Kafka 之前，本节我们先对 Kafka 里面的基础概念、安装使用做一个基本介绍。 1. 基本概念1.1 Kafka 体系架构 Kafka 体系结构中有下面这些基础概念: Producer: 生产者，负责将消息发送到特定的主题 Consumer: 消费者，负责订阅主题并进行消费 Broker: 服务代理点 Topic: 主题，Kafka中的消息以主题为单位进行归类 Partition: 主题是一个逻辑上的概念，其可以划分成多个分区 区在存储层面可以看作一个可追加的日志（Log）文件 offset: 消息偏移量，消息在被追加到分区日志文件的时候都会分配一个特定的偏移量 offset是消息在分区中的唯一标识，Kafka通过它来保证消息在分区内的顺序性 offset并不跨越分区，也就是说，Kafka保证的是分区有序而不是主题有序 Kafka 是多分区的，并采用一主多从的复制方案，leader 副本负责处理读写请求，follower 副本主负责与 leader副本保持同步，并通过 Zookeeper 进行 leader 选举和元数据的保存。 消息消费使用 Pull 模式，服务器端会保存消费的具体位置，当消费者宕机后恢复上线时可以根据之前保存的消费位置重新拉取需要的消息进行消费。 1.2 分区、偏移量分区中的所有副本统称为 AR(Assigned Replicas)，所有与leader副本保持一定程度同步的副本（包括leader副本在内）组成ISR（In-Sync Replicas)。复制存在延迟，所以一定程度的同步是指可忍受的复制滞后范围，这个范围可以通过参数进行配置。与leader副本同步滞后过多的副本（不包括leader副本）组成OSR（Out-of-Sync Replicas）。leader 副本负责跟踪所有副本的滞后状态，从而根据它们状态更新它们的 ISR 和 OSR 归属。默认情况下，当leader副本发生故障时，只有在ISR集合中的副本才有资格被选举为新的leader。 ISR与HW和LEO也有紧密的关系: HW(High Watermark)，俗称高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个offset之前的消息。 LEO(Log End Offset)，它标识当前日志文件中下一条待写入消息的offset，等于最后一条消息的 offset 加一 分区ISR集合中的每个副本都会维护自身的LEO，而ISR集合中最小的LEO即为分区的HW。消费者而言只能消费HW之前的消息。 由此可见，Kafka 的复制机制既不是完全的同步复制，也不是单纯的异步复制。而是类似于半同步，即在 ISR 集合执行同步复制，OSR 集合执行异步复制。Kafka使用这种ISR的方式有效地权衡了数据可靠性和性能之间的关系。 冷门知识: LW是Low Watermark的缩写，俗称“低水位”，代表AR集合中最小的logStartOffset值。副本的拉取请求（FetchRequest，它有可能触发新建日志分段而旧的被清理，进而导致logStartOffset的增加）和删除消息请求（DeleteRecordRequest）都有可能促使LW的增长 2. Kafka 安装配置3. 生产与消费4. 服务器端参数配置我们挑选一些重要的服务端参数来做细致的说明，这些参数都配置在$KAFKA_HOME/config/server.properties文件中。 zookeeper.connect 作用: 指明broker要连接的ZooKeeper集群的服务地址（包含端口号） 默认: 没有默认值，必填 格式: localhost1:2181，localhost2:2181，localhost3:2181/kafka 进行多节点配置，/kafka 指定了 chroot 路径 说明:最佳的实践方式是增加chroot路径，可以明确指明该chroot路径下的节点是为Kafka所用的，也可以实现多个Kafka集群复用一套ZooKeeper集群 listeners: 作用: 指明broker监听客户端连接的地址列表 默认: 默认值为 null 格式: protocol1://hostname1:port1, protocol2://hostname2:port2 protocol代表协议类型，当前支持 PLAINTEXT、SSL、SASL_SSL等 未开启安全认证，则使用简单的PLAINTEXT即可 advertised.listeners 作用: listeners 的关联配置主要用于 IaaS（Infrastructure as a Service）环境 advertised.listeners参数绑定公网IP供外部客户端使用 listeners参数来绑定私网IP地址供broker间通信使用 broker.id 作用: 指定Kafka集群中broker的唯一标识 默认: 默认值为 -1，如果没有设置，那么Kafka会自动生成一个 log.dir和log.dirs 作用: 来配置 Kafka 日志文件存放的根目录 都可以用来配置单个或多个根目录 log.dirs 的优先级比 log.dir 高 默认: 只配置了 log.dir 参数，其默认值为/tmp/kafka-logs message.max.bytes 作用: 指定broker所能接收消息的最大值 默认: 默认值为1000012（B），约等于976.6KB 说明: 如果 Producer 发送的消息大于这个参数所设置的值，那么（Producer）就会报出RecordTooLargeException的异常 如果需要修改这个参数，那么还要考虑max.request.size （客户端参数）、max.message.bytes（topic端参数）等参数的影响 为了避免修改此参数而引起级联的影响，建议在修改此参数之前考虑分拆消息的可行性 其他配置参数需要结合 Kafka 的原理进行解释，后续会慢慢介绍。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. Kafka 开篇入门]]></title>
    <url>%2F2020%2F04%2F01%2Fkafka%2F01_kafka%E5%BC%80%E7%AF%87%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[《深入理解Kafka：核心设计与实践原理》 读书笔记 1. 写在开始kafka 作为现在应用很广的基于日志的消息系统，无论从设计的典型上还是应用的广泛性上应该都是必学必会的。kafka 的书市面上算不错的有三本，最新的，讲的最好的应该这本《深入理解Kafka：核心设计与实践原理》。那废话不多说我们就开干吧。 2. 本书结构kafka 相关内容，我觉得主要分成以下几块: 使用部分: 生产者客户端，包括消息的发送、序列化、分区器、拦截器等等 消费者客户端，包括主题与分区的订阅、发序列化，消息的消费、位移提交、再均衡、拦截器等等 主题与分区的管理，包括主题的增删改、优先副本、分区重分配、复制限流等等 原理部分: 日志存储，包括文件目录的布局、日志格式的演化、日志清理、底层存储 kafka 服务端，包括协议设计、控制器、leader 选举 kafka 客户端，包括消费端分区分配策略、消费者协调器、组协调器、_consumer_offsets、事务 可靠性、一致性，包括失效副本、ISR伸缩、LEO与HW、Leader Epoch、日志同步机制 周边工具: Kafka Connect、Kafka Mirror Maker、Kafka Stream Kafka 监控 Kafka 与 Spark 的集成 应用: Kafka功能性扩展，包括过期时间、延时队列，死信队列、重试队列、消息路由、消息轨迹、消息审计、消息代理等等 3. 资源收录除了本书，目前还没找到其他好的 Kafka 学习资源，跟自己没有深度使用过有关。不过建议在看本书之前看看 《数据密集型应用系统设计》。相信你会对本书所说的内容有更加深刻的理解。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29 MYSQL 分区表]]></title>
    <url>%2F2020%2F03%2F29%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F61_%E5%88%86%E5%8C%BA%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[要不要使用分区表 1. 分区表为了说明分区表的组织形式，先创建一个表 t： 1234567891011CREATE TABLE `t` ( `ftime` datetime NOT NULL, `c` int(11) DEFAULT NULL, KEY (`ftime`)) ENGINE=InnoDB DEFAULT CHARSET=latin1PARTITION BY RANGE (YEAR(ftime))(PARTITION p_2017 VALUES LESS THAN (2017) ENGINE = InnoDB, PARTITION p_2018 VALUES LESS THAN (2018) ENGINE = InnoDB, PARTITION p_2019 VALUES LESS THAN (2019) ENGINE = InnoDB,PARTITION p_others VALUES LESS THAN MAXVALUE ENGINE = InnoDB);insert into t values('2017-4-1',1),('2018-4-1',1); 表 t 将包含了一个.frm 文件和 4 个.ibd 文件，每个分区对应一个.ibd 文件。也就是说： 对于引擎层来说，这是 4 个表； 对于 Server 层来说，这是 1 个表。 1.1 分区表的引擎层行为innodb 分区表 从上面的实验效果可以看出，session B 的第一个 insert 语句是可以执行成功的。这是因为，对于引擎来说，p_2018 和 p_2019 是两个不同的表，也就是说 2017-4-1 的下一个记录并不是 2018-4-1，而是 p_2018 分区的 supremum。所以 T1 时刻，在表 t 的 ftime 索引上，间隙和加锁的状态其实是图 4 这样的： myisam 分区表首先用 alter table t engine=myisam，把表 t 改成 MyISAM 表，然后执行下面这个操作 由于 MyISAM 引擎只支持表锁，所以这条 update 语句会锁住整个表 t 上的读。正是因为 MyISAM 的表锁是在引擎层实现的，session A 加的表锁，其实是锁在分区 p_2018 上。因此，只会堵住在这个分区上执行的查询，落到其他分区的查询是不受影响的。 分区策略每当第一次访问一个分区表的时候，MySQL 需要把所有的分区都访问一遍。 一个典型的报错情况是这样的：如果一个分区表的分区很多，比如超过了 1000 个，而 MySQL 启动的时候，open_files_limit 参数使用的是默认值 1024，那么就会在访问这个表的时候，由于需要打开所有的文件，导致打开表文件的个数超过了上限而报错。 MyISAM 分区表使用的分区策略，我们称为通用分区策略（generic partitioning），每次访问分区都由 server 层控制。通用分区策略，是 MySQL 一开始支持分区表的时候就存在的代码，在文件管理、表管理的实现上很粗糙，因此有比较严重的性能问题。 从 MySQL 5.7.9 开始，InnoDB 引擎引入了本地分区策略（native partitioning）。这个策略是在 InnoDB 内部自己管理打开分区的行为。 从 MySQL 8.0 版本开始，就不允许创建 MyISAM 分区表了，只允许创建已经实现了本地分区策略的引擎。目前来看，只有 InnoDB 和 NDB 这两个引擎支持了本地分区策略。 1.2 分区表的 server 层行为如果从 server 层看的话，一个分区表就只是一个表。 分区表，在做 DDL 的时候，影响会更大。虽然 session B 只需要操作 p_2107 这个分区，但是由于 session A 持有整个表 t 的 MDL 锁，就导致了 session B 的 alter 语句被堵住。 到这里我们小结一下： MySQL 在第一次打开分区表的时候，需要访问所有的分区； 在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁； 在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。 而关于“必要的分区”的判断，就是根据 SQL 语句中的 where 条件，结合分区规则来实现的。 2. 分区表的适用场景2.1 分区表的优点分区表的一个显而易见的优势是对业务透明，相对于用户分表来说，使用分区表的业务代码更简洁。 还有，分区表可以很方便的清理历史数据。如果一项业务跑的时间足够长，往往就会有根据时间删除历史数据的需求。这时候，按照时间分区的分区表，就可以直接通过 alter table t drop partition …这个语法删掉分区，从而删掉过期的历史数据。 这个 alter table t drop partition …操作是直接删除分区文件，效果跟 drop 普通表类似。与使用 delete 语句删除数据相比，优势是速度快、对系统影响小。 2.2 分区表的劣势实际使用时，分区表跟用户分表比起来，有两个绕不开的问题： 一个是第一次访问的时候需要访问所有分区 另一个是共用 MDL 锁。 因此，如果要使用分区表，就不要创建太多的分区。这里有两个问题需要注意： 分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了 分区也不要提前预留太多，在使用之前预先创建即可。对于没有数据的历史分区，要及时的 drop 掉。 至于分区表的其他问题，比如查询需要跨多个分区取数据，查询性能就会比较慢，基本上就不是分区表本身的问题，而是数据量的问题或者说是使用方式的问题了。当然，如果你的团队已经维护了成熟的分库分表中间件，用业务分表，对业务开发同学没有额外的复杂性，对 DBA 也更直观，自然是更好的。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28 MySQL 连接管理]]></title>
    <url>%2F2020%2F03%2F28%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F52_%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL 的连接管理 2. mysql 连接管理在 MySQL 中有两个 kill 命令： kill query + 线程 id: 表示终止这个线程中正在执行的语句； kill connection + 线程 id: connection 可缺省，表示断开这个线程的连接，如果这个线程有语句正在执行，也是要先停止正在执行的语句。 2.1 收到 kill 以后，线程做什么当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事： 把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)； 给 session B 的执行线程发一个信号，让 session B 退出等待或终止执行，来处理这个 THD::KILL_QUERY 状态 上面的分析中，隐含了这么三层意思： 一个语句执行过程中有多处“埋点”，在这些“埋点”的地方判断线程状态，如果发现线程状态是 THD::KILL_QUERY，才开始进入语句终止逻辑； 如果处于等待状态，必须是一个可以被唤醒的等待，否则根本不会执行到“埋点”处； 语句从开始进入终止逻辑，到终止逻辑完全完成，是有一个过程的。 因此不是“说停就停的”。我们来看另种kill 无效的情况: 线程没有执行到判断线程状态的逻辑 终止逻辑耗时较长 2.2 线程没有执行到判断线程状态的逻辑执行 set global innodb_thread_concurrency=2，将 InnoDB 的并发线程上限数设置为 2；然后，执行下面的序列： session D 执行的 kill query C 命令却没什么效果，直到 session E 执行了 kill connection 命令，才断开了 session C 的连接，提示“Lost connection to MySQL server during query”，此时执行 show processlist id=12 这个线程的 Commnad 列显示的是 Killed。也就是说，客户端虽然断开了连接，但实际上服务端上这条语句还在执行过程中。 killed 原因分析在这个例子里，12 号线程的等待逻辑是这样的：每 10 毫秒判断一下是否可以进入 InnoDB 执行，如果不行，就调用 nanosleep 函数进入 sleep 状态。 虽然 12 号线程的状态已经被设置成了 KILL_QUERY，但是在这个等待进入 InnoDB 的循环过程中，并没有去判断线程的状态，因此根本不会进入终止逻辑阶段。 当 session E 执行 kill connection 命令时，是这么做的: 把 12 号线程状态设置为 KILL_CONNECTION； 关掉 12 号线程的网络连接。因为有这个操作，所以你会看到，这时候 session C 收到了断开连接的提示。 如果一个线程的状态是KILL_CONNECTION，show processlist 就把Command列显示成Killed。 所以其实，即使是客户端退出了，这个线程的状态仍然是在等待中。那这个线程什么时候会退出呢？答案是，只有等到满足进入 InnoDB 的条件后，session C 的查询语句继续执行，然后才有可能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION，再进入终止逻辑阶段。 2.3 终止逻辑耗时较长到这里，我们来小结一下。kill 无效有两种情况: 第一种就是上面所说的线程没有执行到判断线程状态的逻辑。跟这种情况相同的，还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态。 另一类情况是，终止逻辑耗时较长。这时候，从 show processlist 结果上看也是 Command=Killed，需要等到终止逻辑完成，语句才算真正完成。这类情况，比较常见的场景有以下几种： 超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。大查询回滚。 如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。 DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。 2.4 killed 线程的处理如果你发现一个线程处于 Killed 状态，你可以做的事情就是，通过影响系统环境，让这个 Killed 状态尽快结束。 InnoDB 并发度的问题，你就可以临时调大 innodb_thread_concurrency 的值，或者停掉别的线程 如果是回滚逻辑由于受到 IO 资源限制执行得比较慢，就通过减少系统压力让它加速 对于回滚大事务导致的 killed 线程，重启服务是没用的，为重启之后该做的回滚动作还是不能少的。最好还是等待它自己执行完成。如果这个语句可能会占用别的锁，或者由于占用 IO 资源过多，从而影响到了别的语句执行的话，就需要先做主备切换，切到新主库提供服务。切换之后别的线程都断开了连接，自动停止执行。接下来还是等它自己执行完成。这个操作属于我们在文章中说到的，减少系统压力，加速终止逻辑。 3. mysql 客户端行为关于 mysql 的客户端，有以下几个常见的误解: 3.1 客户端终止连接客户端通过 Ctrl+C 命令，是不是就可以直接终止线程 Ctrl+C 操作的是客户端进程，与服务器端没有直接关系 MySQL 是停等协议，所以这个线程执行的语句还没有返回的时候，再往这个连接里面继续发命令也是没有用的。实际上，执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接，然后发送一个 kill query 命令 3.2 如果库里面的表特别多，连接就会很慢 有些线上的库，会包含很多表（我见过最多的一个库里有 6 万个表）。这时候，你就会发现，每次用客户端连接都会卡在下面这个界面上。 当使用默认参数连接的时候，MySQL 客户端会提供一个本地库名和表名补全的功能。为了实现这个功能，客户端在连接成功后，需要多做一些操作： 执行 show databases； 切到 db1 库，执行 show tables； 把这两个命令的结果用于构建一个本地的哈希表 最花时间的就是第三步在本地构建哈希表的操作,我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。提示也说了，如果在连接命令中加上 -A，就可以关掉这个自动补全的功能。 除了加 -A 以外，加–quick(或者简写为 -q) 参数，也可以跳过这个阶段。但是，这个–quick 是一个更容易引起误会的参数，也是关于客户端常见的一个误解。 3.3 客户端的 -quick 参数设置了这个参数可能会降低服务端的性能，而不是加速连接。 MySQL 客户端发送请求后，接收服务端返回结果的方式有两种： 一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。 另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法。 MySQL 客户端默认采用第一种方式，而如果加上–quick 参数，就会使用第二种不缓存的方式。采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。 为什么要给这个参数取名叫作 quick 呢？这是因为使用这个参数可以达到以下三点效果： 第一点，就是前面提到的，跳过表名自动补全功能。 第二点，mysql_store_result 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存，可能会影响客户端本地机器的性能； 第三点，是不会把执行命令记录到本地的命令历史文件 –quick 参数的意思，是让客户端变得更快]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27 MYSQL flush privileges]]></title>
    <url>%2F2020%2F03%2F27%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F51_grant_privileges%2F</url>
    <content type="text"><![CDATA[grant 之后要不要跟 flush privileges 1. 用户权限MySQL 使用 create user 来创建用户。 create user &#39;ua&#39;@&#39;%&#39; identified by &#39;pa&#39;; 的执行过程如下: 磁盘上，往 mysql.user 表里插入一行，由于没有指定权限，所以这行数据上所有表示权限的字段的值都是 N； 内存里，往数组 acl_users 里插入一个 acl_user 对象，这个对象的 access 字段值为 0。 在 MySQL 中，用户权限是有不同的范围的。从大到小的顺序依次是: 全局权限 db 权限 表权限和列权限 1.1 全局权限全局权限，作用于整个 MySQL 实例，这些权限信息保存在 mysql 库的 user 表里。 12# 1. 赋予 ua 全局权限grant all privileges on *.* to 'ua'@'%' with grant option; 这个 grant 命令做了两个动作： 磁盘上，将 mysql.user 表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为‘Y’； 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1” 在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。 基于上面的分析我们可以知道： grant 命令对于全局权限，同时更新了磁盘和内存。命令完成后即时生效，接下来新创建的连接会使用新的权限。 对于一个已经存在的连接，它的全局权限不受 grant 命令的影响。 收回全局权限使用下面的 revoke 命令:1revoke all privileges on *.* from 'ua'@'%'; 这条 revoke 命令的用法与 grant 类似，做了如下两个动作： 磁盘上，将 mysql.user 表里，用户’ua’@’%’这一行的所有表示权限的字段的值都修改为“N”； 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 的值修改为 0。 另外 grant 语句赋权时，可能还会看到这样的写法：1grant super on *.* to 'ua'@'%' identified by 'pa'; 这条命令加了 identified by ‘密码’， 语句的逻辑里面除了赋权外，还包含了： 如果用户’ua’@’%’不存在，就创建这个用户，密码是 pa； 如果用户 ua 已经存在，就将密码修改成 pa。 这是一种不建议的写法，因为这种写法很容易就会不慎把密码给改了。 1.2 db 权限12# 赋予 ua 数据库 db1 的操作权限grant all privileges on db1.* to 'ua'@'%' with grant option; 基于库的权限记录保存在 mysql.db 表中，在内存里则保存在数组 acl_dbs 中。这条 grant 命令做了如下两个动作： 磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”； 内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。 每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组，根据 user、host 和 db 找到匹配的对象，然后根据对象的权限位来判断。 也就是说，grant 修改 db 权限的时候，是同时对磁盘和内存生效的。 已存在连接的权限grant 操作对于已经存在的连接的影响，在全局权限和基于 db 的权限效果是不同的。 从上面这个操作序列我们可以看到: super 是全局权限，这个权限信息在线程对象中，而 revoke 操作影响不到这个线程对象。 acl_dbs 是一个全局数组，所有线程判断 db 权限都用这个数组，这样 revoke 操作马上就会影响到 session B。 代码实现上有一个特别的逻辑，如果当前会话已经处于某一个 db 里面，之前 use 这个库的时候拿到的库权限会保存在会话变量中。session C 在 T2 时刻执行的 use db1，拿到了这个库的权限，在切换出 db1 库之前，session C 对这个库就一直有权限。 1.3 表权限和列权限表权限定义存放在表 mysql.tables_priv 中，列权限定义存放在表 mysql.columns_priv 中。这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。 1234create table db1.t1(id int, a int);grant all privileges on db1.t1 to 'ua'@'%' with grant option;GRANT SELECT(id), INSERT (id,a) ON mydb.mytbl TO 'ua'@'%' with grant option; 跟 db 权限类似，这两个权限每次 grant 的时候都会修改数据表，也会同步修改内存中的 hash 结构。因此，对这两类权限的操作，也会马上影响到已经存在的连接。 2. flush privileges从上面的分析来看，grant 语句都是即时生效的，不需要执行 flush privileges 语句。 flush privileges 命令会清空 acl_users 数组，然后从 mysql.user 表中读取数据重新加载，重新构造一个 acl_users 数组。对于 db 权限、表权限和列权限，MySQL 也做了这样的处理。 也就是说，如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。而如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。 因此，grant 语句会同时修改数据表和内存，判断权限的时候使用的是内存数据。因此，规范地使用 grant 和 revoke 语句，是不需要随后加上 flush privileges 语句的。 2.1 需要执行 flush privilege 的场景显然，当数据表中的权限数据跟内存中的权限数据不一致的时候，flush privileges 语句可以用来重建内存数据，达到一致状态。这种不一致往往是由不规范的操作导致的，比如直接用 DML 语句操作系统权限表。 T3 时刻虽然已经用 delete 语句删除了用户 ua，但是在 T4 时刻，仍然可以用 ua 连接成功。原因就是，这时候内存中 acl_users 数组中还有这个用户，因此系统判断时认为用户还正常存在。 直接操作系统表是不规范的操作，这个不一致状态也会导致一些更“诡异”的现象发生。比如，前面这个通过 delete 语句删除用户的例子，就会出现下面的情况： 可以看到，由于在 T3 时刻直接删除了数据表的记录，而内存的数据还存在。这就导致了： T4 时刻给用户 ua 赋权限失败，因为 mysql.user 表中找不到这行记录； 而 T5 时刻要重新创建这个用户也不行，因为在做内存判断的时候，会认为这个用户还存在。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26 MYSQL 自增主键]]></title>
    <url>%2F2020%2F03%2F26%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F45_%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%2F</url>
    <content type="text"><![CDATA[自增主键为什么不连续 1. 自增值1.1 自增值的保存表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。不同的引擎对于自增值的保存策略不同。 MyISAM 引擎的自增值保存在数据文件中。 InnoDB 引擎的自增值，其实是保存在了内存里，并且到了 MySQL 8.0 版本后，才有了“自增值持久化”的能力，也就是才实现了“如果发生重启，表的自增值可以恢复为 MySQL 重启前的值”，具体情况是： 在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。 1.2 自增值修改机制果字段被定义为 AUTO_INCREMENT，在插入一行数据的时候，自增值的行为如下： 如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段； 如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。 假设，某次要插入的值是 X，当前的自增值是 Y。 如果 X&lt;Y，那么这个表的自增值不变； 如果 X≥Y，就需要把当前自增值修改为新的自增值。 新的自增值生成算法是：从 auto_increment_offset 开始，以 auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。 1.3 自增值的修改时机自增值的修改，是在真正执行插入数据的操作之前，如果插入操作并没有真正完成，自增值也不会改回来。 唯一键冲突是导致自增主键 id 不连续的第一种原因。 回滚也会产生类似的现象，这就是第二种原因。 1.4 自增值为什么不能回退假设有两个并行执行的事务，在申请自增值的时候，为了避免两个事务申请到相同的自增 id，肯定要加锁，然后顺序申请。 假设事务 A 申请到了 id=2， 事务 B 申请到 id=3，那么这时候表 t 的自增值是 4，之后继续执行。 事务 B 正确提交了，但事务 A 出现了唯一键冲突。 如果允许事务 A 把自增 id 回退，也就是把表 t 的当前自增值改回 2，那么就会出现这样的情况：表里面已经有 id=3 的行，而当前的自增 id 值是 2。 接下来，继续执行的其他事务就会申请到 id=2，然后再申请到 id=3。这时，就会出现插入语句报错“主键冲突”。 而为了解决这个主键冲突，有两种方法： 每次申请 id 之前，先判断表里面是否已经存在这个 id。如果存在，就跳过这个 id。但是，这个方法的成本很高。因为，本来申请 id 是一个很快的操作，现在还要再去主键索引树上判断 id 是否存在。 把自增 id 的锁范围扩大，必须等到一个事务执行完成并提交，下一个事务才能再申请自增 id。这个方法的问题，就是锁的粒度太大，系统并发能力大大下降。 可见，这两个方法都会导致性能问题。造成这些麻烦的罪魁祸首，就是我们假设的这个“允许自增 id 回退”的前提导致的。因此，InnoDB 放弃了这个设计，语句执行失败也不回退自增 id。也正是因为这样，所以才只保证了自增 id 是递增的，但不保证是连续的。 1.5 自增锁的优化史自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。接下来，我们先看一下自增锁设计的历史: 在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。 MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。 =0 时，表示采用之前 MySQL 5.0 版本的策略 =1 时: 普通 insert 语句，自增锁在申请之后就马上释放； 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放； =2 时，所有的申请自增主键的动作都是申请后就释放锁。 那么，为什么默认设置下，insert … select 要使用语句级的锁？为什么这个参数的默认值不是 2？答案是，这么设计还是为了数据的一致性。 设想一下，如果 session B 是申请了自增值以后马上就释放自增锁，那么就可能出现这样的情况： session B 先插入了两个记录，(1,1,1)、(2,2,2)； 然后，session A 来申请自增 id 得到 id=3，插入了（3,5,5)； 之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4) 如果我们现在的 binlog_format=statement，由于两个 session 是同时执行插入数据命令的，所以 binlog 里面对表 t2 的更新日志只有两种情况：要么先记 session A 的，要么先记 session B 的。 但不论是哪一种，这个 binlog 拿去从库执行，或者用来恢复临时实例，备库和临时实例里面，session B 这个语句执行出来，生成的结果里面，id 都是连续的。这时，这个库就发生了数据不一致。 其实，这是因为原库 session B 的 insert 语句，生成的 id 不连续。这个不连续的 id，用 statement 格式的 binlog 来串行执行，是执行不出来的。 而要解决这个问题，有两种思路： 一种思路是，让原库的批量插入数据语句，固定生成连续的 id 值。所以，自增锁直到语句执行结束才释放，就是为了达到这个目的。 另一种思路是，在 binlog 里面把插入数据的操作都如实记录进来，到备库执行的时候，不再依赖于自增主键去生成。这种情况，其实就是 innodb_autoinc_lock_mode 设置为 2，同时 binlog_format 设置为 row。 因此，在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row. 这样做，既能提升并发性，又不会出现数据一致性问题。需要注意的是，我这里说的批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句。 在普通的 insert 语句里面包含多个 value 值的情况下，即使 innodb_autoinc_lock_mode 设置为 1，也不会等语句执行完成才释放锁。因为这类语句在申请自增 id 的时候，是可以精确计算出需要多少个 id 的，然后一次性申请，申请完成后锁就可以释放了。 也就是说，批量插入数据的语句，之所以需要这么设置，是因为“不知道要预先申请多少个 id”。 1.6 自增 id 的优化对于批量插入，为了避免自增值用一个申请一个带来的低效。对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略： 语句执行过程中，第一次申请自增 id，会分配 1 个； 同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。注意是同一语句 这是主键 id 出现自增 id 不连续的第三种原因。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25 MYSQL Memory 存储引擎]]></title>
    <url>%2F2020%2F03%2F25%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F44_Memory%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[什么时候使用 Memory 存储引擎 1. 索引组织对比假设有以下的两张表 t1 和 t2，其中表 t1 使用 Memory 引擎， 表 t2 使用 InnoDB 引擎。1234create table t1(id int primary key, c int) engine=Memory;create table t2(id int primary key, c int) engine=innodb;insert into t1 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0);insert into t2 values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6),(7,7),(8,8),(9,9),(0,0); 1.1 innodb 组织形式InnoDB 表的数据放在主键索引树上，主键索引是 B+ 树。所以表 t2 的数据组织方式如下图所示：主键索引上的值是有序存储的。 主键索引上的值是有序存储的。在执行 select * 的时候，就会按照叶子节点从左到右扫描，所以得到的结果里，0 就出现在第一行。 1.2 Memory 组织形式与 InnoDB 引擎不同，Memory 引擎的数据和索引是分开的。我们来看一下表 t1 中的数据内容。 内存表的数据部分以数组的方式单独存放，而主键 id 索引里，存的是每个数据的位置。主键 id 是 hash 索引，可以看到索引上的 key 并不是有序的。 在内存表 t1 中，当我执行 select * 的时候，走的是全表扫描，也就是顺序扫描这个数组。因此，0 就是最后一个被读到，并放入结果集的数据。 需要指出的是，表 t1 的这个主键索引是哈希索引，因此如果执行范围查询是用不上主键索引的，需要走全表扫描，但是等值查找的速度比 B-Tree 索引快。 1.3 对比InnoDB 和 Memory 引擎的数据组织方式是不同的： InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。 这两个引擎存在一些典型不同： InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的； 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值； 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引； InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。 InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。 由于内存表的这些特性，每个数据行被删除以后，空出的这个位置都可以被接下来要插入的数据复用。 2. Memory 存储引擎内存表也是支 B-Tree 索引的。在 id 列上创建一个 B-Tree 索引，SQL 语句可以这么写：1alter table t1 add index a_btree_index using btree (id); 这时，表 t1 的数据组织形式就变成了这样： 2.1 Memory 特性一般在我们的印象中，内存表的优势是速度快，其中的一个原因就是 Memory 引擎支持 hash 索引。当然，更重要的原因是，内存表的所有数据都保存在内存，而内存的读写速度总是比磁盘快。 但不建议在生产环境上使用内存表。这里的原因主要包括两个方面： 锁粒度问题； 数据持久化问题。 内存表不支持行锁，只支持表锁。因此，一张表只要有更新，就会堵住其他所有在这个表上的读写操作。 2.2 数据持久化数据放在内存中，数据库重启的时候，所有的内存表都会被清空。在高可用架构下，内存表的这个特点简直可以当做 bug 来看待了。 对于一个双 M 集群，我们来看一下下面这个时序： 业务正常访问主库； 备库硬件升级，备库重启，内存表 t1 内容被清空； 备库重启后，客户端发送一条 update 语句，修改表 t1 的数据行，这时备库应用线程就会报错“找不到要更新的行”。 这样就会导致主备同步停止。当然，如果这时候发生主备切换的话，客户端会看到，表 t1 的数据“丢失”了。 由于 MySQL 知道重启之后，内存表的数据会丢失。所以，担心主库重启之后，出现主备不一致，MySQL 在实现上做了这样一件事儿：在数据库重启之后，往 binlog 里面写入一行 DELETE FROM t1。 在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。这样你在使用的时候就会发现，主库的内存表数据突然被清空了。 2.3 适用场景因为: 如果你的表更新量大，那么并发度是一个很重要的参考指标，InnoDB 支持行锁，并发度比内存表好； 能放到内存表的数据量都不大。如果你考虑的是读的性能，一个读 QPS 很高并且数据量不大的表，即使是使用 InnoDB，数据也是都会缓存在 InnoDB Buffer Pool 里的。因此，使用 InnoDB 表的读性能也不会差。 由于重启会丢数据，如果一个备库重启，会导致主备同步线程停止；如果主库跟这个备库是双 M 架构，还可能导致主库的内存表数据被删掉。 因此建议把普通内存表都用 InnoDB 表来代替。但是，有一个场景却是例外的 – 内存临时表。 内存临时表刚好可以无视内存表的两个不足，主要是下面的三个原因： 临时表不会被其他线程访问，没有并发性的问题； 临时表重启后也是需要删除的，清空数据这个问题不存在； 备库的临时表也不会影响主库的用户线程。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24 临时表]]></title>
    <url>%2F2020%2F03%2F24%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F43_%E4%B8%B4%E6%97%B6%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[什么时候会使用临时表 1. 临时表1.1 临时表跟内存表 内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。 而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎 1.2 临时表的特征 从行面可以看到，临时表在使用上有以下几个特点： 一个临时表只能被创建它的 session 访问，对其他线程不可见所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。 临时表可以与普通表同名。 session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。 show tables 命令不显示临时表。 由于临时表只能被创建它的 session 访问，所以在这个 session 结束的时候，会自动删除临时表。 不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。 不需要担心数据删除问题。临时表由于会自动回收，所以不需要这个额外的回收操作。 1.3 临时表的应用场景由于不用担心线程之间的重名冲突，临时表经常会被用在复杂查询的优化过程中。其中，分库分表系统的跨库查询就是一个典型的使用场景。 一般分库分表的场景，就是要把一个逻辑上的大表分散到不同的数据库实例上。分区 key 的选择是以“减少跨库和跨表查询”为依据的。 但是如果查询条件里面没有用到分区字段，那么该如何实现查询呢，有以下两种思路: 第一种思路是，在 proxy 层的进程代码中实现: 优势是处理速度快，拿到分库的数据以后，直接在内存中参与计算 需要的开发工作量比较大，特别是是对于 group by，join 的操作 对 proxy 端的压力比较大，尤其是很容易出现内存不够用和 CPU 瓶颈的问题 把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。 我们看下面这个示例: 123456789# ht 是一个大的分库分表，分区 key 是 fselect v from ht where k &gt;= M order by t_modified desc limit 100;# 思路二: 使用临时表实现的分库查询，汇总到汇总库# 每个分库的查询select v,k,t_modified from ht_x where k &gt;= M order by t_modified desc limit 100;# 汇总库的查询select v from temp_ht order by t_modified desc limit 100; 按照第二种思路，我们可以这样执行查询: 在汇总库上创建一个临时表 temp_ht，表里包含三个字段 v、k、t_modified； 在各个分库上执行 select v,k,t_modified from ht_x where k &gt;= M order by t_modified desc limit 100; 把分库执行的结果插入到 temp_ht 表中； 执行select v from temp_ht order by t_modified desc limit 100; 我们往往会发现每个分库的计算量都不饱和，所以会直接把临时表 temp_ht 放到 32 个分库中的某一个上。 1.4 为什么临时表可以重命名不同线程可以创建同名的临时表，这是怎么做到的呢？我们来看看MySQL是如何保存临时表的表结构与数据的 执行 create temporary table temp_t(id int primary key)engine=innodb; 临时表的 frm 文件放在临时文件目录下，文件名的后缀是.frm，前缀是#sql{进程 id}_{线程 id}_ 序列号。可以使用 select @@tmpdir 命令，来显示实例的临时文件目录。 关于表中数据的存放方式，在不同的 MySQL 版本中有着不同的处理方式： 在 5.6 以及之前的版本里，MySQL 会在临时文件目录下创建一个相同前缀、以.ibd 为后缀的文件，用来存放数据文件； 从 5.7 版本开始，MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。因此，我们就不需要再创建 ibd 文件了。 MySQL 维护数据表，除了物理上要有文件外，内存里面也有一套机制区别不同的表，每个表都对应一个 table_def_key。 个普通表的 table_def_key 的值是由“库名 + 表名”得到的 而对于临时表，table_def_key 在“库名 + 表名”基础上，又加入了“server_id+thread_id”。 在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。binlog 中也记录了 DROP TEMPORARY TABLE 这条命令。 临时表的 rename 操作执行 rename table 语句的时候，要求按照“库名 / 表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的 frm 文件是放在 tmpdir 目录下的，并且文件名的规则是“#sql{进程 id}{线程 id} 序列号.frm”，因此会报“找不到文件名”的错误。 1.5 临时表与主从复制临时表只在线程内自己可以访问，为什么需要写到 binlog 里面？ 1234create table t_normal(id int primary key, c int)engine=innodb;/*Q1*/create temporary table temp_t like t_normal;/*Q2*/insert into temp_t values(1,1);/*Q3*/insert into t_normal select * from temp_t;/*Q4*/ 如果关于临时表的操作都不记录，备库在执行到 insert into t_normal 的时候，就会报错“表 temp_t 不存在”。 如果当前的 binlog_format=row，那么跟临时表有关的语句，就不会记录到 binlog 里。也就是说，只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。这种情况下，创建临时表的语句会传到备库执行，因此备库的同步线程就会创建这个临时表。主库在线程退出的时候，会自动删除临时表，但是备库同步线程是持续在运行的。所以，这时候我们就需要在主库上再写一个 DROP TEMPORARY TABLE 传给备库执行。 在 binlog_format=’row’的时候，临时表的操作不记录到 binlog 中，也省去了不少麻烦，这也可以成为你选择 binlog_format 时的一个考虑因素。 MySQL 为什么会重写 drop table 命令MySQL 在记录 binlog 的时候，不论是 create table 还是 alter table 语句，都是原样记录，甚至于连空格都不变。但是如果执行 drop table t_normal，系统记录 binlog 就会写成：DROP TABLE t_normal /* generated by server */ drop table 命令是可以一次删除多个表的。比如，在上面的例子中，设置 binlog_format=row，如果主库上执行 “drop table t_normal, temp_t”这个命令，那么 binlog 中就只能记录：DROP TABLE t_normal /* generated by server */ 因为备库上并没有表 temp_t，将这个命令重写后再传到备库执行，才不会导致备库同步线程停止。所以，drop table 命令记录 binlog 的时候，就必须对语句做改写。/* generated by server */说明了这是一个被服务端改写过的命令。 从服务如何保证临时表不冲突MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key： session A 的临时表 t1，在备库的 table_def_key 就是：库名 +t1+“M 的 serverid”+“session A 的 thread_id”; session B 的临时表 t1，在备库的 table_def_key 就是 ：库名 +t1+“M 的 serverid”+“session B 的 thread_id” 2.内存临时表MySQL 什么时候会使用内部临时表？ 如果语句执行过程可以一边读数据，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果； join_buffer 是无序数组，sort_buffer 是有序数组，临时表是二维表结构； 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表。比如我们的例子中，union 需要用到唯一索引约束， group by 还需要用到另外一个字段来存累积计数；前面讲的如何显示随机消息中使用的 order by random 则是另一个例子。 2.1 union union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。 1(select 1000 as f) union (select id from t1 order by id desc limit 2); 上面这个 union 语句的执行过程是这样的: 创建一个内存临时表，这个临时表只有一个整型字段 f，并且 f 是主键字段。 执行第一个子查询，得到 1000 这个值，并存入临时表中。 执行第二个子查询： 拿到第一行 id=1000，试图插入临时表中。但由于 1000 这个值已经存在于临时表了，违反了唯一性约束，所以插入失败，然后继续执行； 取到第二行 id=999，插入临时表成功。 从临时表中按行取出数据，返回结果，并删除临时表，结果中包含两行数据分别是 1000 和 999 这里的内存临时表起到了暂存数据的作用，而且计算过程还用上了临时表主键 id 的唯一性约束，实现了 union 的语义。如果把上面这个语句中的 union 改成 union all 的话，就没有了“去重”的语义。这样执行的时候，就依次执行子查询，得到的结果直接作为结果集的一部分，发给客户端。因此也就不需要临时表了。 2.2 group by12345# 会对返回结果排序select id%10 as m, count(*) as c from t1 group by m;# order by null 结果集不排序select id%10 as m, count(*) as c from t1 group by m order by null; 它的 explain 结果如下： Extra 字段： Using index，表示这个语句使用了覆盖索引，选择了索引 a，不需要回表； Using temporary，表示使用了临时表； Using filesort，表示需要排序。 个语句的执行流程是这样的： 创建内存临时表，表里有两个字段 m 和 c，主键是 m； 扫描表 t1 的索引 a，依次取出叶子节点上的 id 值，计算 id%10 的结果，记为 x； 如果临时表中没有主键为 x 的行，就插入一个记录 (x,1); 如果表中有主键为 x 的行，就将 x 这一行的 c 值加 1； 遍历完成后，再根据字段 m 做排序，得到结果集返回给客户端。 最后一步，对内存临时表的排序，在如何显示随机消息中已经有过介绍。 临时表大小参数 tmp_table_size 用于控制内存临时表大小的，默认是 16M。如果执行过程中会发现内存临时表大小到达了上限，这时候就会把内存临时表转成磁盘临时表，磁盘临时表默认使用的引擎是 InnoDB。 3. group by 优化3.1 索引优化可以看到，不论是使用内存临时表还是磁盘临时表，group by 逻辑都需要构造一个带唯一索引的表，执行代价很高。 group by 的语义逻辑，是统计不同的值出现的个数。那么，如果扫描过程中可以保证出现的数据是有序的就无须临时表了。在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新。 1alter table t1 add column z int generated always as(id % 100), add index(z); 3.2 直接排序碰上不适合创建索引的场景,如果我们明明知道，一个 group by 语句中需要放到临时表上的数据量特别大，却还是要按照“先放到内存临时表，插入一部分数据后，发现内存临时表不够用了再转成磁盘临时表”，看上去就有点儿傻。 在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。 MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。 1select SQL_BIG_RESULT id%100 as m, count(*) as c from t1 group by m; 执行流程就是这样的： 初始化 sort_buffer，确定放入一个整型字段，记为 m； 扫描表 t1 的索引 a，依次取出里面的 id 值, 将 id%100 的值存入 sort_buffer 中； 扫描完成后，对 sort_buffer 的字段 m 做排序（如果 sort_buffer 内存不够用，就会利用磁盘临时文件辅助排序）； 排序完成后，就得到了一个有序数组 据有序数组，得到数组里面的不同值，以及每个值的出现次数。 3.3 group by 使用技巧group by 的几种实现算法，从中可以总结一些使用的指导原则： 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null； 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort； 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表； 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果 3.4 distinct 和 group by 的性能如果只需要去重，不需要执行聚合函数，distinct 和 group by 哪种效率高一些呢？ 12select a from t group by a order by null;select distinct a from t; 不需要执行聚合函数时，distinct 和 group by 这两条语句的语义和执行流程是相同的，因此执行性能也相同。执行流程是下面这样的。 创建一个临时表，临时表有一个字段 a，并且在这个字段 a 上创建一个唯一索引； 遍历表 t，依次取数据插入临时表中： 如果发现唯一键冲突，就跳过； 否则插入成功； 遍历完成后，将临时表作为结果集返回给客户端。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23 join]]></title>
    <url>%2F2020%2F03%2F23%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F42_join%2F</url>
    <content type="text"><![CDATA[join 语句是怎么执行的 1. 实验环境12345CREATE TABLE `t2` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`)) ENGINE=InnoDB;drop procedure idata;delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=1000)do insert into t2 values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata();create table t1 like t2;insert into t1 (select * from t2 where id&lt;=100) 这两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引。存储过程 idata() 往表 t2 里插入了 1000 行数据，在表 t1 里插入的是 100 行数据。 如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，为了便于分析执行过程中的性能问题，我们改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。 2. join 的合并算法依据是否能使用被驱动表索引，join 合并算法分为: Index Nested-Loop Join(NLJ): 可以使用被驱动表的索引 Simple Nested-Loop Join: 不能使用被驱动表的索引，执行过程与 Index Nested-Loop Join 类似，MySQL 并没有使用 Block Nested-Loop Join(BNL): 不能使用被驱动表的索引，会将全表扫描转换为内存比较 2.1 Index Nested-Loop Join1select * from t1 straight_join t2 on (t1.a=t2.a); 驱动表走全表扫描，而被驱动表是走树搜索。 假设被驱动表的行数是 M。每次在被驱动表查一行数据，要先搜索索引 a，再搜索主键索引。每次搜索一棵树近似复杂度是以 2 为底的 M 的对数，记为 log2M，所以在被驱动表上查一行的时间复杂度是 2*log2M。假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。因此整个执行过程，近似复杂度是 N + N*2*log2M。 2.2 Simple Nested-Loop Join驱动表是走全表扫描，被驱动表也是全表扫描，因此近似时间复杂度是N + N*M 2.3 Block Nested-Loop Join1select * from t1 straight_join t2 on (t1.a=t2.b); 这个算法的执行过程是这样的: 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存； 扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。 假设小表的行数是 N，大表的行数是 M，那么在这个算法里：两个表都做一次全表扫描，所以总的扫描行数是 M+N；内存中的判断次数是 M*N。因此近似时间复杂度是N + N*M 因此，从时间复杂度上来说，Simple Nested-Loop Join 与 Block Nested-Loop Join 是一样的。但是，Block Nested-Loop Join 算法的M*N次判断是内存操作，速度上会快很多，性能也更好。 join_buffer_sizejoin_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，就会分段存在，并执行上面的过程。 假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M， k=size of N /join_buffer_size 所以，在这个算法的执行过程中： 扫描行数是 N+N*M/join_buffer_size； 内存判断 N*M 次。 显然: 使用小表作为驱动表时，扫描行数少 join_buffer_size 越大，对被驱动表的全表扫描次数越少 2.4 join 使用建议 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的； 如果使用 Block Nested-Loop Join 算法，扫描行数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用。判断标准就是Extra 字段里面有没有出现“Block Nested Loop”字样。Explain下，没有用index nested-loop 的全要优化。 总是应该使用小表做驱动表。 小表的定义在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。(NLJ 算法是先过滤，再join) 1234567# t2 过滤只有 50 行，所以 t2 为小表select * from t1 straight_join t2 on (t1.b=t2.b) where t2.id&lt;=50;select * from t2 straight_join t1 on (t1.b=t2.b) where t2.id&lt;=50;# t1，t2 都是100行，但是 t1 只需要b 字段，t2 需要所有字段，所以 t1 是小表select t1.b,t2.* from t1 straight_join t2 on (t1.b=t2.b) where t2.id&lt;=100;select t1.b,t2.* from t2 straight_join t1 on (t1.b=t2.b) where t2.id&lt;=100; 2.5 BNL算法 对缓存的影响如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。这种情况对应的，是冷表的数据量小于整个 Buffer Pool 的 3/8，能够完全放入 old 区域的情况。如果这个冷表很大，就会出现另外一种情况：业务正常访问的数据页，没有机会进入 young 区域。由于优化机制的存在，一个正常访问的数据页，要进入 young 区域，需要隔 1 秒后再次被访问到。但是，由于我们的 join 语句在循环读磁盘和淘汰内存页，进入 old 区域的数据页，很可能在 1 秒之内就被淘汰了。这样，就会导致这个 MySQL 实例的 Buffer Pool 在这段时间内，young 区域的数据页没有被合理地淘汰。 大表 join 操作虽然对 IO 有影响，但是在语句执行结束后，对 IO 的影响也就结束了。但是，对 Buffer Pool 的影响就是持续性的，需要依靠后续的查询请求慢慢恢复内存命中率。 为了减少这种影响，你可以考虑增大 join_buffer_size 的值，减少对被驱动表的扫描次数。也就是说，BNL 算法对系统的影响主要包括三个方面： 可能会多次扫描被驱动表，占用磁盘 IO 资源； 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源； 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。 我们执行语句之前，需要通过理论分析和查看 explain 结果的方式，确认是否要使用 BNL 算法。如果确认优化器会使用 BNL 算法，就需要做优化。优化的常见做法是，给被驱动表的 join 字段加上索引，把 BNL 算法转成 BKA 算法。 3. MRRMulti-Range Read 优化 (MRR)主要目的是尽量使用顺序读盘。原理是这样的，因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。 对于语句 select * from t1 where a&gt;=1 and a&lt;=100; a 上有索引，语句的执行过程是这样的: 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ; 将 read_rnd_buffer 中的 id 进行递增排序； 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。 这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。 如果你想要稳定地使用 MRR 优化的话，需要设置set optimizer_switch=&quot;mrr_cost_based=off&quot;。（官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。） MRR 能够提升性能的核心在于，这条查询语句在索引 a 上做的是一个范围查询（也就是说，这是一个多值查询），可以得到足够多的主键 id。这样通过排序以后，再去主键索引查数据，才能体现出“顺序性”的优势。 4. Batched Key Access(BKA)MySQL 在 5.6 版本后开始引入的 Batched Key Access(BKA) 算法了。这个 BKA 算法，其实就是对 NLJ 算法的优化。BKA 依赖的就是 MRR。 NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。 我们可以把表 t1 的数据取出来一部分放入 join_buffer 中，然后应用 MRR 要使用BKA，在SQL查询前需要设置:1set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on'; 使用 BKA 算法的时候，并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。 5. BNL 算法优化5.1 BNL 转 BKA一些情况下，我们可以直接在被驱动表上建索引，这时就可以直接转成 BKA 算法了。但是，有时候你确实会碰到一些不适合在被驱动表上建索引的情况。比如下面这个语句： 12# t1 有1000行，t2 过滤后有 2000 行因此小表是 t1select * from t1 join t2 on (t1.b=t2.b) where t2.b&gt;=1 and t2.b&lt;=2000; 表 t2 中插入了 100 万行数据，但是经过 where 条件过滤后，需要参与 join 的只有 2000 行数据。如果这条语句同时是一个低频的 SQL 语句，那么再为这个语句在表 t2 的字段 b 上创建一个索引就很浪费了。 如果使用 BNL 算法来 join 的话，这个语句的执行流程是这样的： 把表 t1 的所有字段取出来，存入 join_buffer 中。这个表只有 1000 行，join_buffer_size 默认值是 256k，可以完全存入。 扫描表 t2，取出每一行数据跟 join_buffer 中的数据进行对比 如果不满足 t1.b=t2.b，则跳过； 如果满足 t1.b=t2.b, 再判断其他条件，也就是是否满足 t2.b 处于[1,2000]的条件，如果是，就作为结果集的一部分返回，否则跳过。 对于表 t2 的每一行，判断 join 是否满足的时候，都需要遍历 join_buffer 中的所有行。因此判断等值条件的次数是 1000*100 万 =10 亿次，这个判断的工作量很大。 这时候，我们可以考虑使用临时表。使用临时表的大致思路是： 把表 t2 中满足条件的数据放在临时表 tmp_t 中； 为了让 join 使用 BKA 算法，给临时表 tmp_t 的字段 b 加上索引； 让表 t1 和 tmp_t 做 join 操作。 123create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;select * from t1 join temp_t on (t1.b=temp_t.b); 基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的。总体来看，不论是在原表上加索引，还是用有索引的临时表，我们的思路都是让 join 语句能够用上被驱动表上的索引，来触发 BKA 算法，提升查询性能。 使用内存临时表在这个示例中，更好的方式是使用内存临时表代替 Innodb 临时表，原因有三个： 相比于 InnoDB 表，使用内存表不需要写磁盘，往表 temp_t 的写数据的速度更快； 索引 b 使用 hash 索引，查找的速度比 B-Tree 索引快； 临时表数据只有 2000 行，占用的内存有限。 1234# 将临时表 temp_t 改成内存临时表，并且在字段 b 上创建一个 hash 索引。create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;select * from t1 join temp_t on (t1.b=temp_t.b); 5.2 扩展 -hash join如果 join_buffer 里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是 10 亿次判断，而是 100 万次 hash 查找。这，也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。 实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下： select * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。 select * from t2 where b&gt;=1 and b&lt;=2000; 获取表 t2 中满足条件的 2000 行数据。 把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行 6. 问题6.1 join 的执行顺序问题: 如果用 left join 的话，左边的表一定是驱动表吗？ 如果两个表的 join 包含多个条件的等值匹配，是都要写到 on 里面呢，还是只把一个条件写到 on 里面，其他条件写到 where 部分？ 1234create table a(f1 int, f2 int, index(f1))engine=innodb;create table b(f1 int, f2 int)engine=innodb;insert into a values(1,1),(2,2),(3,3),(4,4),(5,5),(6,6);insert into b values(3,3),(4,4),(5,5),(6,6),(7,7),(8,8); 第二个问题，其实就是下面这两种写法的区别：12select * from a left join b on(a.f1=b.f1) and (a.f2=b.f2); /*Q1*/select * from a left join b on(a.f1=b.f1) where (a.f2=b.f2);/*Q2*/ 在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL。 因此，语句 Q2 里面 where a.f2=b.f2 就表示“找到这两个表里面，f1、f2 对应同时存在且相同的行。”虽然用的是 left join，但是语义跟 join 是一致的。因此，优化器就把这条语句的 left join 改写成了 join，然后因为表 a 的 f1 上有索引，就把表 b 作为驱动表，这样就可以用上 NLJ 算法。 因此: 这个例子说明，即使我们在 SQL 语句中写成 left join，执行过程还是有可能不是从左到右连接的。也就是说，使用 left join 时，左边的表不一定是驱动表。 如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面。 join 本身表示的就是同时存在并相等，因此join 将判断条件是否全部放在 on 部分就没有区别了 6.2 Simple Nested Loop Join 为什么比 BNL 性能低上面我们说 BNL 算法和 Simple Nested Loop Join 算法都是要判断 M*N 次（M 和 N 分别是 join 的两个表的行数），但是 Simple Nested Loop Join 算法的每轮判断都要走全表扫描，因此性能上 BNL 算法执行起来会快很多。 疑问是，Simple Nested Loop Join 算法，其实也是把数据读到内存里，然后按照匹配条件进行判断，为什么性能差距会这么大呢？ 释这个问题，需要用到 MySQL 中索引结构和 Buffer Pool 的相关知识点： 在对被驱动表做全表扫描的时候，如果数据没有在 Buffer Pool 中，就需要等待这部分数据从磁盘读入；从磁盘读入数据到内存中，会影响正常业务的 Buffer Pool 命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到 Buffer Pool 的头部； 即使被驱动表数据都在内存中，每次查找“下一个记录的操作”，都是类似指针操作。而 join_buffer 中是数组，遍历的成本更低。所以说，BNL 算法的性能会更好。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22 常见语句的执行逻辑]]></title>
    <url>%2F2020%2F03%2F22%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F41_count%2F</url>
    <content type="text"><![CDATA[count，order by 都是怎么执行的 1. count在不同的 MySQL 引擎中，count(*) 有不同的实现方式: MyISAM: 把一个表的总行数存在了磁盘上，在没有筛选条件时，count(*) 可以直接返回 Innodb: 需要把数据一行一行地从引擎里面读出来，然后累积计数。 由于 Innodb 事务是基于 MVCC 的多版本控制机制实现的，每一行记录都要判断自己是否对这个会话可见，因此对于 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。对于 count(*) 遍历主键索引和二级索引得到的结果逻辑上是一致的。MySQL 优化器会找到最小的那棵树来遍历。在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。 show table status 返回的 TABLE_ROWS 用于显示这个表当前有多少行，但它是通过采样计算得来的，很不准。 那怎么才能快速得到记录总数呢？ 我们只能自己计数。基本思路：你需要自己找一个地方，把操作记录表的行数存起来。 1.1 如何计数我们把这个计数直接放到 MySQL 数据库里单独的一张计数表 C 中，利用事务，我们可以保证计数更新与数据更新之间的一致性。 把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。 1.2 不同的 count 用法要想弄明白 ount(*)、count(主键 id)、count(字段) 和 count(1) 的差别，首先你要弄清楚 count() 的语义。count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。 所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。 至于分析性能差别的时候，你可以记住这么几个原则： server 层要什么就给什么； InnoDB 只给必要的值； 现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做 性能差别: count(主键 id):InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加 count(1): InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。 count(字段): 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加； 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加 count(*): 并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。 按照效率由低到高排序的话，count(字段) -&gt; count(主键 id) -&gt; count(1)≈count(\*)，所以我建议你，尽量使用 count(*) 2. order byorder by 如何执行取决于如下几个因素: 是否使用外部排序: MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer。 排序可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。 sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小 如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。否则就需要磁盘临时文件辅助排序 单行长度是否太大 默认 MySQL 会使用”全字段排序”，即把所需的所有字段都放到 sort_buffer_size 中然后排序 如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。此时 MySQL 就会采用另一种排序算法 “rowid 排序” max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。单行的长度超过这个值，就会使用 rowid 算法 是否有筛选字段与排序字段的联合索引: 可以利用索引的有序性直接排序，下称”索引直接排序” 因此我们将详细下面这几个问题: 如何判断排序语句是否使用了临时文件 全字段排序过程 rowid 排序过程 索引直接排序过程 2.1 是否使用了临时文件假设有个市民表定义如下，我们希望查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。123456789101112CREATE TABLE `t` ( `id` int(11) NOT NULL, `city` varchar(16) NOT NULL, `name` varchar(16) NOT NULL, `age` int(11) NOT NULL, `addr` varchar(128) DEFAULT NULL, PRIMARY KEY (`id`), KEY `city` (`city`)) ENGINE=InnoDB;select city,name,age from t where city='杭州' order by name limit 1000 ; 为避免全表扫描，我们需要在 city 字段加上索引。在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。 Extra 这个字段中的“Using filesort”表示的就是需要排序，但是并没有告诉我们MySQL使用了哪种排序是算法，也没有告诉我们是否使用了临时文件排序。用下面介绍的方法，可以确定一个排序语句是否使用了临时文件。 123456789101112131415161718192021/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a保存Innodb_rows_read的初始值, mairadb 有所区别 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* mariadb */select VARIABLE_VALUE into @a from information_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算Innodb_rows_read差值 */select @b-@a; 下面 OPTIMIZER_TRACE 的显示结果(显示的是2.2全字段排序的分析结果) number_of_tmp_files: 表示排序过程中使用的临时文件数。大于 0 表示使用了临时文件排序，外部排序一般使用归并排序算法 examined_rows: 表示参与排序的行数 sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了“紧凑”处理。即使 name 字段的定义是 varchar(16)，在排序过程中还是要按照实际长度来分配空间的。 最后一个查询语句 select @b-@a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行。 需要注意的是，为了避免对结论造成干扰，我把 internal_tmp_disk_storage_engine 设置成 MyISAM。否则，select @b-@a 的结果会显示为 4001。这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 internal_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 Innodb_rows_read 的值加 1。 2.2 全字段排序 如上图，使用全字段排序的过程如下: 初始化 sort_buffer，确定放入 name、city、age 这三个字段； 从索引 city 找到第一个满足 city=’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到 city 的值不满足查询条件为止； 对 sort_buffer 中的数据按照字段 name 做快速排序； 按照排序结果取前 1000 行返回给客户端。 2.3 rowid 排序 rowid 算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。 初始化 sort_buffer，确定放入两个字段，即 name 和 id； 从索引 city 找到第一个满足 city=’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中； 从索引 city 取下一个记录的主键 id； 重复步骤 3、4 直到不满足 city=’杭州’条件为止； 对 sort_buffer 中的数据按照字段 name 进行排序； 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。 rowid 排序多访问了一次表 t 的主键索引，最后的“结果集”是一个逻辑概念，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。 city、name、age 这三个字段的定义总长度是 36，我们把 max_length_for_sort_data 设置为 16，就可以让 MySQL 使用 rowid 进行排序。 12345678910111213141516171819202122SET max_length_for_sort_data = 16;/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a保存Innodb_rows_read的初始值, mairadb 有所区别 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* mariadb */select VARIABLE_VALUE into @a from information_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算Innodb_rows_read差值 */select @b-@a; 重新进行上面的查询分析会看到: sort_mode 变成了 &lt;sort_key, rowid&gt;，表示参与排序的只有 name 和 id 这两个字段。 number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍然是 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。 2.4 索引直接排序我们可以在这个市民表上创建一个 city 和 name 的联合索引，这个索引的示意图如下: 1alter table t add index city_user(city, name); 因为索引是按照city,name 排序的，所以排序过程就变成了: 从索引 (city,name) 找到第一个满足 city=’杭州’条件的主键 id； 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回； 从索引 (city,name) 取下一个记录主键 id； 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city=’杭州’条件时循环结束。 如果表上有 (city, name, age)，就可以使用覆盖索引，无须进行上述步骤 2 的回表过程，性能上会快很多。当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。 3. union 和 groupbyunion 和 group by 的执行逻辑参见临时表]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 MySQL 表复制]]></title>
    <url>%2F2020%2F03%2F21%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F27_%E8%A1%A8%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[怎么最快的复制一张表 1. 在两张表中拷贝数据如果可以控制对源表的扫描行数和加锁范围很小的话，我们简单地使用 insert … select 语句即可实现。当然，为了避免对源表加读锁，更稳妥的方案是先将数据写到外部文本文件，然后再写回目标表。这时，有三种常用的方法。 mysqldump 导出 CSV 文件 物理拷贝方法 我们使用下面的试验环境: 假设，我们要把 db1.t 里面 a&gt;900 的数据行导出来，插入到 db2.t 中。1234567891011121314151617181920create database db1;use db1;create table t(id int primary key, a int, b int, index(a))engine=innodb;delimiter ;; create procedure idata() begin declare i int; set i=1; while(i&lt;=1000)do insert into t values(i,i,i); set i=i+1; end while; end;;delimiter ;call idata();create database db2;create table db2.t like db1.t 1.1 mysqldump12345# 数据导出mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction --set-gtid-purged=OFF db1 t --where="a&gt;900" --result-file=/client_tmp/t.sql# 数据导入mysql -h127.0.0.1 -P13000 -uroot db2 -e "source /client_tmp/t.sql" mysqldump 参数: –single-transaction: 在导出数据的时候不需要对表 db1.t 加表锁，而是使用 START TRANSACTION WITH CONSISTENT SNAPSHOT 的方法； –add-locks 设置为 0，表示在输出的文件结果里，不增加” LOCK TABLES t WRITE;” ； –no-create-info 的意思是，不需要导出表结构； –set-gtid-purged=off 表示的是，不输出跟 GTID 相关的信息； –result-file 指定了输出文件的路径，其中 client 表示生成的文件是在客户端机器上的 –skip-extended-insert: 生成的文件中一条 INSERT 语句只插入一行数据的话，默认一条 INSERT 语句里面会包含多个 value 对 –tab 参数，可以同时导出表结构定义文件和 csv 数据文件 source需要说明的是，source 并不是一条 SQL 语句，而是一个客户端命令。mysql 客户端执行这个命令的流程是这样的： 打开文件，默认以分号为结尾读取一条条的 SQL 语句； 将 SQL 语句发送到服务端执行。 也就是说，服务端执行的并不是这个“source t.sql”语句，而是 INSERT 语句。所以，不论是在慢查询日志（slow log），还是在 binlog，记录的都是这些要被真正执行的 INSERT 语句。 1.2 导出 CSV12345# 导出数据select * from db1.t where a&gt;900 into outfile '/server_tmp/t.csv';# 导入数据load data infile '/server_tmp/t.csv' into table db2.t; outfileselect … into outfile，需要注意如下几点。 这条语句会将结果保存在服务端。如果你执行命令的客户端和 MySQL 服务端不在同一个机器上，客户端机器的临时目录下是不会生成 t.csv 文件的。 into outfile 指定了文件的生成位置（/server_tmp/），这个位置必须受参数 secure_file_priv 的限制。参数 secure_file_priv 的可选值和作用分别是： 如果设置为 empty，表示不限制文件生成的位置，这是不安全的设置； 如果设置为一个表示路径的字符串，就要求生成的文件只能放在这个指定的目录，或者它的子目录； 如果设置为 NULL，就表示禁止在这个 MySQL 实例上执行 select … into outfile 操作。 这条命令不会帮你覆盖文件，因此你需要确保 /server_tmp/t.csv 这个文件不存在，否则执行语句时就会因为有同名文件的存在而报错。 这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行。但是，如果字段中包含换行符，在生成的文本中也会有换行符。不过类似换行符、制表符这类符号，前面都会跟上“\”这个转义符，这样就可以跟字段之间、数据行之间的分隔符区分开。 select …into outfile 方法不会生成表结构文件, 所以我们导数据时还需要单独的命令得到表结构定义。mysqldump 提供了一个–tab 参数，可以同时导出表结构定义文件和 csv 数据文件。 1mysqldump -h$host -P$port -u$user ---single-transaction --set-gtid-purged=OFF db1 t --where="a&gt;900" --tab=$secure_file_priv 这条命令会在 $secure_file_priv 定义的目录下，创建一个 t.sql 文件保存建表语句，同时创建一个 t.txt 文件保存 CSV 数据。 load dataload data infile 的执行流程如下所示。 打开文件 /server_tmp/t.csv，以制表符 (\t) 作为字段间的分隔符，以换行符（\n）作为记录之间的分隔符，进行数据读取； 启动事务 判断每一行的字段数与表 db2.t 是否相同： 若不相同，则直接报错，事务回滚； 若相同，则构造成一行，调用 InnoDB 引擎接口，写入到表中。 重复步骤 3，直到 /server_tmp/t.csv 整个文件读入完成，提交事务。 load data 命令有两种用法: 不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下； 加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。 主从同步如果 binlog_format=statement，这个 load 语句记录到 binlog 里以后，怎么在备库重放呢？主从同步的流程如下: 主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到 binlog 文件中。 往 binlog 文件中写入语句 load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE db2.t 把这个 binlog 日志传到备库。 备库的 apply 线程在执行这个事务日志时： a. 先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 /tmp/SQL_LOAD_MB-1-0 中； b. 再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据 为什么要用 load data local,有两点原因: 为了确保备库应用 binlog 正常。因为备库可能配置了 secure_file_priv=null，所以如果不用 local 的话，可能会导入失败，造成主备同步延迟。 另一种应用场景是使用 mysqlbinlog 工具解析 binlog 文件，并应用到目标库的情况 mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd 把日志直接解析出来发给目标库执行。增加 local，就能让这个方法支持非本地的 $host。 1.3 物理拷贝方法前面提到的方法，都是逻辑导数据的方法，也就是将数据从表 db1.t 中读出来，生成文本，然后再写入目标表 db2.t 中。 有物理导数据的方法吗？比如，直接把 db1.t 表的.frm 文件和.ibd 文件拷贝到 db2 目录下。但是这样不行，因为一个 InnoDB 表，除了包含这两个物理文件外，还需要在数据字典中注册。直接拷贝这两个文件的话，因为数据字典中没有 db2.t 这个表，系统是不会识别和接受它们的。 不过，在 MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。 假设我们现在的目标是在 db1 库下，复制一个跟表 t 相同的表 r，具体的执行步骤如下 执行 create table r like t，创建一个相同表结构的空表； 执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除； 执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件； 在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）； 执行 unlock tables，这时候 t.cfg 文件会被删除； 执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。 关于拷贝表的这个流程，有以下几个注意点： 在第 3 步执行完 flsuh table 命令之后，db1.t 整个表处于只读状态，直到执行 unlock tables 命令后才释放读锁； 在执行 import tablespace 的时候，为了让文件里的表空间 id 和数据字典中的一致，会修改 r.ibd 的表空间 id。而这个表空间 id 存在于每一个数据页中。因此，如果是一个很大的文件（比如 TB 级别），每个数据页都需要修改，所以你会看到这个 import 语句的执行是需要一些时间的。当然，如果是相比于逻辑导入的方法，import 语句的耗时是非常短的。 1.4 方法对比三种方法的优缺点: 物理拷贝的方式速度最快，尤其对于大表拷贝来说是最快的方法。如果出现误删表的情况，用备份恢复出误删之前的临时库，然后再把临时库中的表拷贝到生产库上，是恢复数据最快的方法。但是，这种方法的使用也有一定的局限性： 必须是全表拷贝，不能只拷贝部分数据； 需要到服务器上拷贝数据，在用户无法登录数据库主机的场景下无法使用； 由于是通过拷贝物理文件实现的，源表和目标表都是使用 InnoDB 引擎时才能使用。 用 mysqldump 生成包含 INSERT 语句文件的方法，可以在 where 参数增加过滤条件，来实现只导出部分数据。这个方式的不足之一是，不能使用 join 这种比较复杂的 where 条件写法。 用 select … into outfile 的方法是最灵活的，支持所有的 SQL 写法。但，这个方法的缺点之一就是，每次只能导出一张表的数据，而且表结构也需要另外的语句单独备份。 后两种方式都是逻辑备份方式，是可以跨引擎使用的。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20 MySQL 误删恢复]]></title>
    <url>%2F2020%2F03%2F20%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F26_%E8%AF%AF%E5%88%A0%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[误删数据恢复 1. 误删数据传统的高可用架构是不能预防误删数据的，因为主库的一个 drop table 命令，会通过 binlog 传给所有从库和级联从库，进而导致整个集群的实例都会执行这个命令。 为了找到解决误删数据的更高效的方法，我们需要先对和 MySQL 相关的误删数据，做下分类： 使用 delete 语句误删数据行； 使用 drop table 或者 truncate table 语句误删数据表； 使用 drop database 语句误删数据库； 使用 rm 命令误删整个 MySQL 实例 恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。 这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。 1.1 误删预防误删更重要的是事前预防: 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。 码上线前，必须经过 SQL 审计。 账号分离，避免写错命令。 第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名 在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。 改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。 脚本分别是：备份脚本、执行脚本、验证脚本和回滚脚本。如果能够坚持做到，即使出现问题，也是可以很快恢复的，一定能降低出现故障的概率。 2. 误删行使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。 Flashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。 对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可； 对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event； 而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。 但是，delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，你应该优先考虑使用 truncate table 或者 drop table 命令。 3. 误删库 / 表使用 truncate /drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。因为即使我们配置了 binlog_format=row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate/drop 语句，这些信息是恢复不出数据的。 这个时候就需要使用全量备份，加增量日志了，这个方案要求线上有定期的全量备份，并且实时备份 binlog。 恢复数据的流程如下: 取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点； 用备份恢复出一个临时库； 从日志备份里面，取出凌晨 0 点之后的日志； 把这些日志，除了误删除数据的语句外，全部应用到临时库 关于这个过程，需要说明的是: mysqlbinlog 有一个–database 参数，用来指定误删表所在的库，这样可以跳过其他库，加快恢复速度 需要跳过 1 2 点误操作的语句: 使用了 GTID 模式: 假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 就可以跳过误删的操作 未使用 GTID 模式: 手动使用 –start-position –stop-position 跳过误删的操作 这个恢复的操作还是不够快，原因有以下两点: 如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志； 用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。 3.1 使用备库同步方式恢复数据更快的方法是在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样： 在 start slave 之前，先通过执行 change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表； 这样做可以用上并行复制技术，来加速整个数据恢复过程。 关于这个过程需要说明的是: binlog 备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删除了临时实例需要的 binlog 的话，我们可以从 binlog 备份系统中找到需要的 binlog，再放回备库中。 同步过程，同样需要跳过误删的操作 删掉的 binlog 放回备库的操作步骤 从备份系统下载 master.000005 和 master.000006 这两个文件，放到备库的日志目录下； 打开日志目录下的 master.index 文件，在文件开头加入两行，内容分别是 “./master.000005”和“./master.000006”; 重启备库，目的是要让备库重新识别这两个日志文件； 3.2 延迟复制备库上面利用备库并行复制的方案仍然存在恢复时间不可控问题。如果一个库的备份特别大，或者误操作的时间距离上一个全量备份的时间较长，这个恢复时间可能是要按天来计算的。 我们可以考虑搭建延迟复制的备库。这个功能是 MySQL 5.6 版本引入的。 一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。只要在延迟的时间内发现误删，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。 4. rm 删除数据对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19 MySQL 主库监测]]></title>
    <url>%2F2020%2F03%2F19%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F25_%E4%B8%BB%E5%BA%93%E7%9B%91%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[怎么判断一个主库是否出了问题？ 1. 主库监测在一主一备的双 M 架构里，主备切换只需要把客户端流量切到备库；而在一主多从架构里，主备切换除了要把客户端流量切到备库外，还需要把从库接到新主库上。 主备切换有两种场景，一种是主动切换，一种是被动切换。而其中被动切换，往往是因为主库出问题了，由 HA 系统发起的。那怎么判断主库是否出了问题，有以下几种方案: select 1 判断 1.1 select 1 判断select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。 innodb_thread_concurrency 参数的目的是，控制 InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。此时select 1 是能执行成功的，但是查询表 t 的语句会被堵住，系统已经处于不可用状态。 innodb_thread_concurrencyinnodb_thread_concurrency 这个参数的默认值是 0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。 通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。 需要注意的是 线程处于空闲状态，不算在并发线程里面。 在线程进入锁等待以后，也就是说等行锁（也包括间隙锁）的线程也不算在并发线程内 对于真正执行的查询，比如 select sleep(100) from t，还是要算进并发线程内 并发连接与并发查询show processlist 的结果指的就是并发连接。而“当前正在执行”的语句，才是我们所说的并发查询。 并发连接数达到几千个影响并不大，就是多占一些内存而已 并发查询太高才是 CPU 杀手。这也是为什么我们需要设置 innodb_thread_concurrency 参数的原因 1.2 更新判断为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。 同时更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。因此我们应该使用更新语句，而不是查询语句作为监控语句。更新语句类似于: 1mysql&gt; update mysql.health_check set t_modified=now(); timestamp 字段，用来表示最后一次执行检测的时间。 对于双主模型，如果主库 A 和备库 B 都用相同的更新命令进行监测，就可能出现行冲突。我们可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键: 12345678mysql&gt; CREATE TABLE `health_check` ( `id` int(11) NOT NULL, `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`)) ENGINE=InnoDB;/* 检测命令 */insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now(); 更新判断是一个相对比较常用的方案了，不过依然存在一些问题。其中，“判定慢”一直是让 DBA 头疼的问题。这里涉及到的是服务器 IO 资源分配的问题。检测使用的 update 命令，需要的IO资源很少，大概率可以执行成功。但可能此时系统的 IO 利用率已经达到 100%，正常的 SQL 已经执行的很慢了。 根本原因是我们上面说的所有方法，都是基于外部检测的。外部检测天然有一个问题，就是随机性。因为，外部检测都需要定时轮询，所以系统可能已经出问题了，但是却需要等到下一个检测发起执行语句的时候，我们才有可能发现问题。 1.3 内部统计MySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。 1234567891011121314151617181920212223242526272829MariaDB [performance_schema]&gt; select * from file_summary_by_event_name where event_name like "%innodb_log%" \G*************************** 1. row *************************** EVENT_NAME: wait/io/file/innodb/innodb_log_file # 统计的是 redo log 的写入时间 COUNT_STAR: 94 # 所有 IO 的总次数 SUM_TIMER_WAIT: 247391627463 # 所有 IO 类型的统计，单位是皮秒 MIN_TIMER_WAIT: 0 AVG_TIMER_WAIT: 2631825709 MAX_TIMER_WAIT: 11638807401 COUNT_READ: 6 # 读操作的统计 SUM_TIMER_READ: 30000390 MIN_TIMER_READ: 0 AVG_TIMER_READ: 5000065 MAX_TIMER_READ: 13752883 SUM_NUMBER_OF_BYTES_READ: 68096 # 总共从 redo log 统计了多少字节 COUNT_WRITE: 43 # 写操作统计 SUM_TIMER_WRITE: 1621529472 MIN_TIMER_WRITE: 0 AVG_TIMER_WRITE: 37709927 MAX_TIMER_WRITE: 73538815SUM_NUMBER_OF_BYTES_WRITE: 24576 COUNT_MISC: 45 # 其他类型的统计，对于redolog 就是 fsync SUM_TIMER_MISC: 245740097601 MIN_TIMER_MISC: 0 AVG_TIMER_MISC: 5460890834 MAX_TIMER_MISC: 116388074011 row in set (0.001 sec) 启用 performance_schema打开所有的 performance_schema 项，性能大概会下降 10% 左右。所以，我建议你只打开自己需要的项进行统计。你可以通过下面的方法打开或者关闭某个具体项的统计。 12# 打开 redo log 的统计项mysql&gt; update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%'; 异常检测比如，你可以设定阈值，单次 IO 请求时间超过 200 毫秒属于异常，然后使用类似下面这条语句作为检测逻辑。1234mysql&gt; select event_name,MAX_TIMER_WAIT FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT&gt;200*1000000000;# 清空统计数据，以免对下次检测产生影响mysql&gt; truncate table performance_schema.file_summary_by_event_name; 1.4 方案总结建议是优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18 MySQL 读写分离]]></title>
    <url>%2F2020%2F03%2F18%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F24_%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[读写分离，以及怎么处理主备延迟导致的读写分离问题。 1. 读写分离读写分离的主要目标就是分摊主库的压力。一般有两种架构: 客户端（client）主动做负载均衡，即由客户端自己选择连接的 mysql 服务器 在 MySQL 和客户端之间有一个中间代理层 proxy，客户端只连接 proxy， 由 proxy 根据请求类型和上下文决定请求的分发路由。 两种架构的对比: 客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。 带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。 但是无论那种将架构，由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。 主从延迟是不能 100% 避免的。不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。接下来，我们就来讨论怎么处理过期读问题。通常有下面这些解决方案: 强制走主库方案； sleep 方案； 判断主备无延迟方案； 配合 semi-sync 方案； 等主库位点方案；等 GTID 方案。 1.1 强制走主库方案 对于必须要拿到最新结果的请求，强制将其发到主库上。 对于可以读到旧数据的请求，才将其发到从库上 这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求。 1.2 Sleep 方案这个方案的假设是，大多数情况下主备延迟在 1 秒之内，主库更新后，读从库之前先 sleep 一下。 典型的场景是商品发布后，用 Ajax（Asynchronous JavaScript + XML，异步 JavaScript 和 XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了 sleep 的目的，进而也就解决了过期读的问题。 如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒；如果延迟超过 1 秒，还是会出现过期读。 1.3 判断主备无延迟方案确保备库无延迟，通常有三种做法 查询前，判断 seconds_behind_master 是否为 0 采用对比位点和 GTID 的方法来确保主备无延迟 下图是 show slave status 结果的部分截图 对比位点 Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点； Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。 这两组值完全相同，就表示接收到的日志已经同步完成。 对比 GTID 集合 Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。 Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合； Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。 对比位点和对比 GTID 这两种方法，都要比判断 seconds_behind_master 是否为 0 更准确。但还是没有达到“精确”的程度。 一个事务的 binlog 在主备库之间的状态： 主库执行完成，写入 binlog，并反馈给客户端； binlog 被从主库发送给备库，备库收到； 在备库执行 binlog 完成。 们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，存在客户端已经收到提交确认，而备库还没收到日志的状态。要解决这个问题，需要引入“半同步复制”。semi-sync 配合前面关于位点的判断，就能够确定在从库上执行的查询请求，可以避免过期读。 1.4 配合 semi-syncsemi-sync 做了这样的设计： 事务提交的时候，主库把 binlog 发给从库； 从库收到 binlog 以后，发回给主库一个 ack，表示收到了； 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。 也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。 semi-sync+ 位点判断的方案，只对一主一备的场景是成立的。在一主多从场景中，主库只要等到一个从库的 ack，就开始给客户端返回确认。这时对从库的查询请求，落在这个响应了 ack 的从库上，是能够确保读到最新数据；如果不是还是有可能发生过期读。 判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。 小结一下，semi-sync 配合判断主备无延迟的方案，存在两个问题： 一主多从的时候，在某些从库执行查询请求会存在过期读的现象； 在持续延迟的情况下，可能出现过度等待的问题。 等主库位点方案，就可以解决这两个问题。 1.5 等主库位点要明白等主库位点，要先明白这条命令:select master_pos_wait(file, pos[, timeout]); 执行逻辑: 它是在从库执行的； 参数 file 和 pos 指的是主库上的文件名和位置； timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。 返回结果: 正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务 如果执行期间，备库同步线程发生异常，则返回 NULL； 如果等待超过 N 秒，就返回 -1； 如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0 使用等等主库位点，进行查询的逻辑是这样的: trx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position； 选定一个从库执行查询语句； 在从库上执行 select master_pos_wait(File, Position, 1)； 如果返回值是 &gt;=0 的正整数，则在这个从库执行查询语句； 否则，到主库执行查询语句 步骤 5 到主库执行查询语句，是这类方案常用的退化机制。因为从库的延迟时间不可控，不能无限等待，所以如果等待超时，就应该放弃，然后到主库去查。如果所有的从库都延迟超过 1 秒了，那查询压力不就都跑到主库上了吗？确实是这样。 按照我们设定不允许过期读的要求，就只有两种选择，一种是超时放弃，一种是转到主库查询。具体怎么选择，就需要业务开发同学做好限流策略了。 1.6 GTID 方案select wait_for_executed_gtid_set(gtid_set, 1); 执行逻辑: 等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0； 超时返回 1。在前面等位点的方案中 在前面等位点的方案中，我们执行完事务后，还要主动去主库执行 show master status。而 MySQL 5.7.6 版本开始，允许在执行完更新类事务后，把这个事务的 GTID 返回给客户端，这样等 GTID 的方案就可以减少一次查询。 等 GTID 的执行流程就变成了： trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1； 选定一个从库执行查询语句； 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)； 如果返回值是 0，则在这个从库执行查询语句； 否则，到主库执行查询语句 跟等主库位点的方案一样，等待超时后是否直接到主库查询，需要业务开发同学来做限流考虑。 怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？你只需要将参数 session_track_gtids=OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。 1.7 方案总结在实际应用中，这几个方案是可以混合使用的。 比如，先在客户端对请求做分类，区分哪些请求可以接受过期读，而哪些请求完全不能接受过期读；然后，对于不能接受过期读的语句，再使用等 GTID 或等位点的方案。 但话说回来，过期读在本质上是由一写多读导致的。在实际应用中，可能会有别的不需要等待就可以水平扩展的数据库方案，但这往往是用牺牲写性能换来的，也就是需要在读性能和写性能中取权衡。 1.8 大事务的影响对大表做 DDL 的时候会怎么样。假设，这条语句在主库上要执行 10 分钟，提交后传到备库就要 10 分钟（典型的大事务）。那么，在主库 DDL 之后再提交的事务的 GTID，去备库查的时候，就会等 10 分钟才出现。 这样，这个读写分离机制在这 10 分钟之内都会超时，然后走主库。 这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询，然后把读请求都切到主库，再在主库上做 DDL。等备库延迟追上以后，再把读请求切回备库。当然了，使用 gh-ost 方案来解决这个问题也是不错的选择。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17 MySQL 主备切换]]></title>
    <url>%2F2020%2F03%2F17%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F23_%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[MySQL 主备切换策略，一主多从 1. 双主模型的主备切换策略如图 1 所示就是基本的主备切换流程 正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。但是，MySQL 要提供高可用能力，只有最终一致性是不够的。由于主备延迟的存在，所以在主备切换的时候，就相应的有不同的策略。 1.1 可靠性优先策略 如上图，可靠性优先的主备切换流程: 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步； 把主库 A 改成只读状态，即把 readonly 设置为 true； 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止； 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；把业务请求切到备库 B 以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。 假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了。此时我们必须等待备库执行完中转日志，才能切换到备库 B。这段时间，系统处于完全不可用的状态。所以在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。 1.2 可用性优先如果强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，那么系统几乎就没有不可用时间了。代价就是可能出现数据不一致的情况。使用 row 格式的 binlog 时，数据不一致问题会导致 mysql 报错，更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地就不一致了。如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致。 大多数情况下，应该使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的。在这个基础上，通过减少主备延迟，提升系统的可用性。 在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。 2. 一主多从大多数的互联网应用场景都是读多写少，因此你负责的业务，在发展过程中很可能先会遇到读性能的问题。此时我们就需要 MySQL 一主多从架构。我们将分成两个方面来讲解一主多从: 一主多从的切换正确性 一主多从的查询逻辑正确性的方法: 见下一节”读写分离” 下面，就是一个基本的一主多从结构: 虚线箭头表示的是主备关系，也就是 A 和 A’互为主备 从库 B、C、D 指向的是主库 A。 一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。 3. 一主多从的主备切换如图 2 所示，就是主库发生故障，主备切换后的结果。 相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。 3.1 基于位点的主备切换当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令:1234567CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password MASTER_LOG_FILE=$master_log_name MASTER_LOG_POS=$master_log_pos 最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。 原来节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志，A 的位点和 A’的位点是不同的。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。这个位点很难精确取到。 一种取同步位点的方法是这样的： 等待新主库 A’把中转日志（relay log）全部同步完成； 在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position； 取原主库 A 故障的时刻 T； 用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。 1mysqlbinlog File --stop-datetime=T --start-datetime=T 网络延迟的不确定性，从节点 B 是否已经执行过T时刻的位点是不确定的，因此我们从时刻 T 的位点同步时就有可能出现主键冲突(insert 语句被重复执行)。 通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。123456# 方法一: 手动跳过一个事务# 从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令set global sql_slave_skip_counter=1;start slave;# 方法二: 通过设置 slave_skip_errors 参数，直接设置跳过指定的错误。 在执行主备切换时，有这么两类错误，是经常会遇到的： 1062 错误是插入数据时唯一键冲突； 1032 错误是删除数据时找不到行。 我们可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。 这个背景是，我们很清楚在主备切换过程中，直接跳过 1032 和 1062 这两类错误是无损的，所以才可以这么设置 slave_skip_errors 参数。等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。 3.2 GTID基于位点的主备切换，复杂也容易出错，所以，MySQL 5.6 版本引入了 GTID，彻底解决了这个困难。 GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：GTID=server_uuid:gno server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值； gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。 注意: 事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，而 gno 是在事务提交的时候才会分配。 GTID 的使用GTID 模式的启动也很简单，只需配置两个参数: gtid_mode=on enforce_gtid_consistency=on 在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值。 gtid_next=automatic gtid_next 是一个指定的 GTID 的值 gtid_next=automatic 代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’; 把这个 GTID 加入本实例的 GTID 集合 如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next=’current_gtid’指定为 current_gtid，那么就有两种可能： 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略； 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1 一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。这样，每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。 通过提交一个特定 GTID 的空事务，我们就可以实现跳过主服务器同步过来的特定时事务: 12345678# 把这个 GTID 加到从库 的 GTID 集合中set gtid_next='aaaaaaaa-cccc-dddd-eeee-ffffffffffff:10';begin;commit;# 恢复 GTID 的默认分配行为set gtid_next=automatic;start slave; 4. 基于 GTID 的主备切换在 GTID 模式下，备库 B 要设置为新主库 A’的从库的语法如下：123456CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password master_auto_position=1 master_auto_position=1 就表示这个主备关系使用的是 GTID 协议。我们把现在这个时刻，实例 A’的 GTID 集合记为 set_a，实例 B 的 GTID 集合记为 set_b。接下来，我们就看看现在的主备切换逻辑。 我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的： 实例 B 指定主库 A’，基于主备协议建立连接。 实例 B 把 set_b 发给主库 A’。 实例 A’算出所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误； 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B； 之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行 在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。跟基于位点的主备协议不同。基于位点的协议，是由备库决定的，备库指定哪个位点，主库就发哪个位点，不做日志的完整性判断。 之后这个系统就由新主库 A’写入，主库 A’的自己生成的 binlog 中的 GTID 集合格式是：server_uuid_of_A’:1-M。如果之前从库 B 的 GTID 集合格式是 server_uuid_of_A:1-N， 那么切换之后 GTID 集合的格式就变成了 server_uuid_of_A:1-N, server_uuid_of_A’:1-M。当然，主库 A’之前也是 A 的备库，因此主库 A’和从库 B 的 GTID 集合是一样的。这就达到了我们预期。 4.1 问题在 GTID 模式下，如果一个新的从库接上主库，但是需要的 binlog 已经没了，要怎么做？ 如果业务允许主从不一致的情况，那么可以在主库上先执行 show global variables like ‘gtid_purged’，得到主库已经删除的 GTID 集合，假设是 gtid_purged1；然后先在从库上执行 reset master，再执行 set global gtid_purged =‘gtid_purged1’；最后执行 start slave，就会从主库现存的 binlog 开始同步。binlog 缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。 如果需要主从数据一致的话，最好还是通过重新搭建从库来做。 如果有其他的从库保留有全量的 binlog 的话，可以把新的从库先接到这个保留了全量 binlog 的从库，追上日志以后，如果有需要，再接回主库。 如果 binlog 有备份的情况，可以先在从库上应用缺失的 binlog，然后再执行 start slave。 5. GTID 和在线 DDL假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样： 在实例 X 上执行 stop slave。在实例 Y 上执行 DDL 语句。 注意，这里并不需要关闭 binlog。 执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。 到实例 X 上执行以下语句序列：123456set GTID_NEXT="server_uuid_of_Y:gno";begin;commit;set gtid_next=automatic;start slave; 这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 MySQL 主备延迟]]></title>
    <url>%2F2020%2F03%2F16%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F22_mysql%E4%B8%BB%E5%A4%87%E5%BB%B6%E8%BF%9F%2F</url>
    <content type="text"><![CDATA[MySQL 主备延迟与并行复制 1. 主备延迟与数据同步有关的时间点主要包括以下三个： 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1; 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2; 备库 B 执行完成这个事务，我们把这个时刻记为 T3。 所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。在网络正常的时候，日志从主库传给备库所需的时间是很短的，即 T2-T1 的值是非常小的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。所以说，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。 1.1 主备延迟的原因慢的原因有以下几个: 有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。这种部署现在比较少了,因为主备可能发生切换，备库随时可能变成主库，所以主备库选用相同规格的机器，并且做对称部署，是现在比较常见的情况。 备库的压力大,一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。结果就是，备库上的查询耗费了大量的 CPU 资源，影响了同步速度，造成主备延迟。 备库的压力大的情况，我们一般可以这么处理： 一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。 其中，一主多从的方式大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力。而从库，就很适合用来做备份。 除了上面这些因素，mysql 的下面这些操作也是造成主备延迟的重要因素: 大事务: 因为主库上必须等事务执行完成才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟。 大表 DDL: 另一种典型的大事务，计划内的 DDL，建议使用 gh-ost 方案 备库的并行复制能力 待会我们会详细讲解备库的并行复制能力是怎么影响主备延迟的。除了上面主库导致的主从延迟外，备库也可能导致主备延迟，就是备库起了一个长事务，比如 12begin; select * from t limit 1; # 不动了 这时候主库对表 t 做了一个加字段操作，即使这个表很小，这个 DDL 在备库应用的时候也会被堵住，从而导致主备延迟线性增长。 2. 备库的并行复制 谈到主备的并行复制能力，我们要关注的是图中黑色的两个箭头。一个箭头代表了客户端写入主库，另一箭头代表的是备库上 sql_thread 执行中转日志（relay log）。 在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。 而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。接下来我们就来看看 mysql 是如何从单线程演化成多线程复制的。 2.1 并行复制的原理 多线程复制机制，就是把只有一个线程的 sql_thread，拆成多个线程: coordinator: 就是原来的 sql_thread, 现在只负责读取中转日志和分发事务 worker 线程: 更新日志的，个数由参数 slave_parallel_workers 配置，对于32 核物理机，建议设置在 8-16 之间，毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了 需要注意的是事务是不能按照轮询的方式分发给各个 worker 的。因为不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。同理为了满足事务要求，同一个事务的多个更新语句，也不能分给不同的 worker 来执行 coordinator 在分发的时候，需要满足以下这两个基本要求： 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。 同一个事务不能被拆开，必须放到同一个 worker 中。 2.2 并行复制策略按表分发:按表分发的基本操作是这样的: 每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。 随着每个 worker 的执行，会把已完成事务涉及的表从 hash 表中删除 如果两个事务更新不同的表，它们就可以并行。 如果有跨表的事务，还是要把两张表放在一起考虑的 如果事务 T 跟多于一个 worker 冲突(worker 的hash 表内有与事务 T 操作相同的表)，coordinator 线程就进入等待，直至只与 1 个worker 进程冲突，并发 T 分配给它 这个按表分发的方案，在多个表负载均匀的场景里应用效果很好。如果碰到热点表，就变成了单线程复制。 按行分发按行复制的核心思路是： 如果两个事务没有更新相同的行，它们在备库上可以并行执行。这要求 binlog 格式必须是 row 判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。 worker hash 表的 key，就必须是“库名 + 表名 + 唯一键的值” 基于行的策略，事务 hash 表中还需要考虑唯一键(假设唯一索引名为 a)，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。因为唯一索引会引发唯一键错误，必须考虑事务执行顺序 因此假设要在表 t1 上执行 update t1 set a=1 where id=2 语句，a 是唯一索引列，原来的值为 2。coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项: key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。 key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。 key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。 如果是要操作很多行的大事务的话，按行分发的策略有两个问题： 耗费内存 耗费 CPU 因此需要为单个事务设置行数阈值，比如，如果单个事务更新的行数超过 10 万行，就暂时退化为单线程模式，退化过程的逻辑大概是这样的： coordinator 暂时先 hold 住这个事务； 等待所有 worker 都执行完成，变成空队列； coordinator 直接执行这个事务； 恢复并行模式。 分发策略的约束相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件： 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row； 表必须有主键； 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。 2.3 MySQL 5.6 版本的并行复制策略只是支持的粒度是按库并行: hash 表里，key 就是数据库名，库的数量相对于表和行少的多，因此也不会耗费什么内存和 CPU 并行效果，取决于压力模型。如果在主库上有多个 DB，并且压力均衡，使用这个策略的效果会很好 不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。 2.4 MariaDB 的并行复制策略MariaDB 的并行复制 利用了 redo log 组提交 (group commit) 优化: 能够在同一组里提交的事务，一定不会修改同一行； 主库上可以并行执行的事务，备库上也一定是可以并行执行的。 在实现上，MariaDB 是这么做的： 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1； commit_id 直接写到 binlog 里面； 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行； 这一组全部执行完成后，coordinator 再去取下一批。 是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。另外，这个方案很容易被大事务拖后腿。 2.4 MySQL 5.7 的并行复制策略由参数 slave-parallel-type 来控制并行复制策略： 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略； 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。 这里面的思考逻辑是这样的: 同时处于“执行状态”的所有事务，不是可以并行的，因为这里面包括了由于锁冲突而处于锁等待状态的事务，他们必须严格按照顺序执行 MariaDB 优化策略的核心，是“所有处于 commit”状态的事务可以并行。事务处于 commit 状态，表示已经通过了锁冲突的检验了 根据两阶段提交，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了 MySQL 5.7 并行复制策略的思想是： 同时处于 prepare 状态的事务，在备库执行时是可以并行的； 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。 binlog 的组提交的时候，介绍过两个参数： binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync; binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。 这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。 2.5 MySQL 5.7.22 的并行复制策略MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。它有三个值: COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。 WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。 WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。 WRITESET 就是我们前面介绍的基于行的并行复制，不过，MySQL 官方的这个实现还是有很大的优势： writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量； 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存； 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。 当然，对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。 官方 MySQL5.7 版本新增的备库并行策略，修改了 binlog 的内容，也就是说 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要把这个因素也考虑进去。 2.6 大事务的影响大事务不仅会影响到主库，也是造成备库复制延迟的主要原因之一]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 MySQL 主从复制]]></title>
    <url>%2F2020%2F03%2F15%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F21_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[接下来内容与 MySQL 主从复制相关的内容，包括: MySQL 如何保证主从同步的最终一致性，设计 binlog 同步过程和binlog 的格式 主备延迟，以及并行复制 由于主备延迟不可避免，因此由两种主备切换策略 主从复制同步位点的判断以及GTID 模式 读写分离，以及怎么处理主备延迟导致的读写分离问题 主库的心跳信息监测，以便在主库故障时及时进行主备切换 1. 主备的基本原理如图 1 所示就是基本的主备切换流程 在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。当需要切换的时候，就切成状态 2。 在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑： 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作； 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致； 可以用 readonly 状态，来判断节点的角色 readonly 设置对超级 (super) 权限用户是无效的，而用于同步更新的线程，拥有超级权限，因此 readonly 不会影响主从同步的写。 2. binlog 同步过程 图中画出的就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。 一个事务日志同步的完整过程是这样的： 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log） sql_thread 读取中转日志，解析出日志里的命令，并执行。 后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程，这个我们后面在详述。 3. binlog 的格式binlog 有两种格式，一种是 statement，一种是 row。第三种格式 mixed 是前两种格式的混合。 3.1 binlog 查看方法通过如下的方法我们可以查看每种binlog 格式记录的详细内容: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 1. 查看当前系统的二进制文件MariaDB [(none)]&gt; SHOW &#123;BINARY | MASTER&#125; LOGS+-------------------+-----------+| Log_name | File_size |+-------------------+-----------+| master-log.000001 | 1254 || master-log.000002 | 435 || master-log.000003 | 435 || master-log.000004 | 2389 |# 2. 查看 binlog 日志MariaDB [(none)]&gt; SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]MariaDB [(none)]&gt; show binlog events in 'master-log.000004';MariaDB [(none)]&gt; show binlog events in 'master-log.000004' from 387 limit 3;+-------------------+-----+------------+-----------+-------------+--------------------------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+-------------------+-----+------------+-----------+-------------+--------------------------------------------------------------+| master-log.000004 | 387 | Gtid | 1 | 429 | BEGIN GTID 0-1-6 || master-log.000004 | 429 | Query | 1 | 544 | use `tsong`; insert into course values(2, "计算机网络") || master-log.000004 | 544 | Xid | 1 | 575 | COMMIT /* xid=205 */ |+-------------------+-----+------------+-----------+-------------+--------------------------------------------------------------+3 rows in set (0.000 sec)# 3. 通过 mysqlbinlog 解析 binlog 的具体内容 mysqlbinlog -vv master-log.000004 --start-position=387 --stop-position=390;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200311 12:25:09 server id 1 end_log_pos 256 CRC32 0xe5385d26 Start: binlog v 4, server v 10.4.12-MariaDB-log created 200311 12:25:09BINLOG 'JWhoXg8BAAAA/AAAAAABAAAAAAQAMTAuNC4xMi1NYXJpYURCLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAA5AAEGggAAAAICAgCAAAACgoKAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEEwQADQgICAoKCgEmXTjl'/*!*/;# at 387#200311 12:27:27 server id 1 end_log_pos 429 CRC32 0x75f470c3 GTID 0-1-6 trans/*!100101 SET @@session.skip_parallel_replication=0*//*!*/;/*!100001 SET @@session.gtid_domain_id=0*//*!*/;/*!100001 SET @@session.server_id=1*//*!*/;/*!100001 SET @@session.gtid_seq_no=6*//*!*/;BEGIN/*!*/;DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 3.2 试验环境为了便于描述 binlog 的这三种格式间的区别，我们使用如下的环境，并执行最后的 delete 语句123456789101112131415161718mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), KEY `a` (`a`), KEY `t_modified`(`t_modified`)) ENGINE=InnoDB;insert into t values(1,1,'2018-11-13');insert into t values(2,2,'2018-11-12');insert into t values(3,3,'2018-11-11');insert into t values(4,4,'2018-11-10');insert into t values(5,5,'2018-11-09');# 用 MySQL 客户端来做这个实验的话，要记得加 -c 参数，否则客户端会自动去掉注释。mysql&gt; delete from t /*comment*/ where a&gt;=4 and t_modified&lt;='2018-11-10' limit 1; 3.3 statementbinlog_statement当 binlog_format=statement 时，show binlog events in &#39;master.000001&#39;; binlog 内容如下: 第一行 SET @@SESSION.GTID_NEXT=’ANONYMOUS’与主备切换有关，后面我们在详述 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务； 第三行就是真实执行的语句了，statement 格式下，记录到 binlog 里的是语句原文 最后一行是一个 COMMIT，里面写着 xid=61。xid 是 binlog 和 redo log 的关联字段，同时也是 statement 格式binlog 的完整性标识。 因为 statement 记录的原始语句，而不是具体的行，当使用 delete limit 等情况时，就有可能因为主备执行逻辑(比如执行时选择的索引)不同出现主备不一致的情况。 3.4 row 格式当 binlog_format=row 时，show binlog events in &#39;master.000001&#39;;binlog 内容如下: row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows： Table_map event，用于说明接下来要操作的表是 test 库的表 t; Delete_rows event，用于定义删除的行为。 show binlog 是无法查看 row binlog 的详细内容的，需要借助 mysqlbinlog 工具。下面是使用 mysqlbinlog 查看的 row 格式的 binlog 内容: 1mysqlbinlog -vv data/master.000001 --start-position=8900; row 格式的 binlog 包括以下内容: server id 1，表示这个事务是在 server_id=1 的这个库上执行的。 每个 event 都有 CRC32 的值，这是参数 binlog_checksum 设置成了 CRC32，用于检查 binlog 是否完整 binlog 记录的每个 SQL 都会被翻译成多个 event: Table_map event 显示了接下来要打开的表，map 到数字 226。如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。 Delete_rows event，用于定义删除的行为 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、 @2=4 这些值） binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id=4 这个信息。 最后的 Xid event，用于表示事务被正确地提交了。 当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id=4 的行，不会有主备删除不同行的问题。 3.4 mixed 格式为什么会有 mixed 这种 binlog 格式的存在场景？ 因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。 但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。 所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。 也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。 3.5 数据恢复但是 MySQL 的 binlog 格式最好还是设置成 row。因为需要 binlog 做数据恢复。 delete 语句，row 格式的 binlog 也会把被删掉的行的整行信息保存起来 insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行 update 语句，binlog 里面会记录修改前整行的数据和修改后的整行数据。 MariaDB 的Flashback工具正是基于 row 格式的 binlog 做数据恢复的工具。 如果直接使用 binlog 做数据恢复，标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令： 1mysqlbinlog master.000001 --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd; 记住，不要直接去binlog 内复制语句去执行，因为 mysql 会自动根据 sql 执行的上下文添加类似库切换，设置时间戳等命令，这些语句是需要同时被执行的。 4. 循环复制问题实际生产上使用比较多的是双 M 结构，也就是下图所示的主备切换流程。 双主模型中存在循环复制的问题: 业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（建议把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog，这样任意主库上的 binlog 都可以用作数据恢复） 那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？ MySQL 是这样解决循环复制的问题的: 两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系； 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id； 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id； 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了 按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样： 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id； 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id； 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。 但是即便如此存在下面两种情况一样会导致循环复制问题。 4.1 场景一在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。 4.2 场景二有三个节点的时候，如图 7 所示，trx1 是在节点 B 执行的，因此 binlog 上的 server_id 就是 B，binlog 传给节点 A，然后 A 和 A’搭建了双 M 结构，就会出现循环复制。 这种三节点复制的场景，做数据库迁移的时候会出现。可以在 A 或者 A’上，执行如下命令： 123stop slave；CHANGE MASTER TO IGNORE_SERVER_IDS=(server_id_of_B);start slave; 这样这个节点收到日志后就不会再执行。过一段时间后，再执行下面的命令把这个值改回来。 123stop slave；CHANGE MASTER TO IGNORE_SERVER_IDS=();start slave;]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 MYSQL 全表扫描]]></title>
    <url>%2F2020%2F03%2F14%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F16_%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[全表扫描对 MySQL 有什么影响 1. 对 server 层的影响1.1 发送数据的流程取数据和发数据的流程是这样的： 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。 重复获取行，直到 net_buffer 写满，调用网络接口发出去。 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。 可以看到： 一个查询在发送过程中，占用的 MySQL 内部的内存最大就是 net_buffer_length 这么大，并不会达到 200G； socket send buffer 也不可能达到 200G（默认定义 /proc/sys/net/core/wmem_default），如果 socket send buffer 被写满，就会暂停读数据的流程。 MySQL 是“边读边发的”，这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。 1.2 查询语句的状态变化一个查询语句的状态变化是这样的: MySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”； 然后，发送执行结果的列相关的信息（meta data) 给客户端； 再继续执行语句的流程； 执行完成后，把状态设置成空字符串。 也就是说: “Sending data”并不一定是指“正在发送数据”，而可能是处于执行器过程中的任意阶段。比如，锁等待的场景 仅当一个线程处于“等待客户端接收结果”的状态，才会显示”Sending to client” 1.3 客户端接收数据慢对事务的影响如果客户端使用–quick 参数，会使用 mysql_use_result 方法。这个方法是读一行处理一行。假设有一个业务的逻辑比较复杂，每读一行数据以后要处理的逻辑如果很慢，就会导致客户端要过很久才会去取下一行数据，可能就会出现如图 2 所示的 “Sending to client” 这种情况。 对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，我都建议你使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。当然前提是查询返回结果不多。 另一方面，如果你在自己负责维护的 MySQL 里看到很多个线程都处于“Sending to client”这个状态，就意味着你要让业务开发同学优化查询结果，并评估这么多的返回结果是否合理。 而如果要快速减少处于这个状态的线程的话，将 net_buffer_length 参数设置为一个更大的值是一个可选方案。 2. 全表扫描对 InnoDB 的影响Innodb 内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了两个作用: 加速更新 加速查询 而 Buffer Pool 对查询的加速效果，依赖于一个重要的指标，即：内存命中率。一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。 show engine innodb status 的 Buffer pool hit rate显示的就是当前的命中率。 2.1 innodb_buffer_pool_sizeInnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。 InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。为了避免一次全表扫描导致所有的缓存失效，InnoDB 对 LRU 算法做了改进。 在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。LRU 算法执行流程如下: 图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，将其移到链表头部，变成状态 2 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断： 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部； 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。 1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒 因此进入yong区域的缓存需要满足两个条件: 已经存在 old 缓存内 被第二次访问 两次访问之间的间隔超过 1s 这个策略，就是为了处理类似全表扫描的操作量身定制的。扫描大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。 全表扫描还是比较耗费 IO 资源的，所以业务高峰期还是不能直接在线上主库执行全表扫描的。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 MYSQL 索引选择]]></title>
    <url>%2F2020%2F03%2F13%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F15_%E4%BC%98%E5%8C%96%E5%99%A8%2F</url>
    <content type="text"><![CDATA[MySQL 如何选择索引 1. 优化器逻辑选择索引是优化器的工作。而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。优化器会考虑扫描行数、是否使用临时表、是否排序等因素进行综合判断。对于普通索引来说，优化器需要把回表的代价算进去。 2. 扫描行数MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“区分度”。 一个索引上不同的值越多，这个索引的区分度就越好。 一个索引上不同的值的个数，我们称之为“基数”（cardinality）。这个基数越大，索引的区分度越好。 2.1 索引区分度show index from t 可以查看索引的基数。 123456789101112131415MariaDB [tsong]&gt; show index from course \G*************************** 1. row *************************** Table: course Non_unique: 0 Key_name: PRIMARY Seq_in_index: 1 Column_name: id Collation: A Cardinality: 3 # 基数 Sub_part: NULL Packed: NULL Null: Index_type: BTREE Comment:Index_comment: 那 mysql 是如何计算索引的基数呢？ mysql 用的采样统计的方法: InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数 当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计 MySQL 中，有两种存储索引统计的方式，通过设置参数 innodb_stats_persistent 的值来选择： =ON: 表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10 =OFF: 表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16 因为是采样统计，所以这个基数是很容易不准确的，如果索引统计不准确，可以使用 analyze table t 重新统计索引信息。在实践中，如果你发现 explain 的结果预估的 rows 值跟实际情况差距比较大，可以采用这个方法来处理。 索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。 2.2 索引选择异常和处理如果只是索引统计不准确，通过 analyze 命令可以解决很多问题，但优化器可不止是看扫描行数。即便索引统计准确，MySQL 照样有可能选错索引。索引选择异常有以下几种处理方法: 采用 force index 强行选择一个索引，使用 force index 最主要的问题是变更的及时性 修改语句，引导 MySQL 使用我们期望的索引 我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。 3. MySQL 选错索引的示例我们创建如下表，并往表内插入10万行数据。1234567891011121314151617181920212223CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`), KEY `b` (`b`)) ENGINE=InnoDB；delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=100000)do insert into t values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata(); 我们做如下操作: 这时候，session B 的查询语句 select * from t where a between 10000 and 20000 就不会再选择索引 a 了。作为对比我们使用 force index(a) 来让优化器强制使用索引 a。下面的三条 SQL 语句，就是这个实验过程。 123set long_query_time=0;select * from t where a between 10000 and 20000; /*Q1*/select * from t force index(a) where a between 10000 and 20000;/*Q2*/ 我们可以通过通过慢查询日志（slow log）查看这两个SQL的执行过程: 前面我们说过优化器在选择索引时会考虑扫描行数、是否使用临时表、是否排序等因素进行综合判断。而扫描行数与索引区分度有关。这个简单的查询语句并没有涉及到临时表和排序，所以是扫描行数出了问题。使用 explain 可以查看优化器预估的，这两个语句的扫描行数: 这里有两个问题: 使用 force index(a) 的扫描行数为什么不准，达到了 37000？ 优化器为什么放着扫描 37000 行的执行计划不用，却选择了扫描行数是 100000 的执行计划呢？ 选择100000 的执行计划是因为使用普通索引需要把回表的代价算进去。优化器认为直接扫描主键索引更快。 而扫描行数不准与我们的操作序列有关。session A 开启了事务并没有提交，所以之前插入的 10 万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。这样，索引 a 上的数据其实就有两份。这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。 你可能觉得主键上的数据也不能删，那没有使用 force index 的语句，使用 explain 命令看到的扫描行数为什么还是 100000 左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段 a 作为索引更合适）是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是 show table status 的值。 统计信息不对，我们可以使用 analyze table t 命令，重新统计索引信息。当然并不是所有的索引选择错误都是由统计信息不对导致的，这时候我们就要通过上面说到的其他方法来解决。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 MySQL 问题追踪与性能优化]]></title>
    <url>%2F2020%2F03%2F12%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F14_%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MySQL 中怎么做问题追踪与性能优化 1. 问题排查的工具mysql 中有以下几种问题排查的工具: show processlist show engine innodb status information_schema.innodb_trx show engine innodb status optimizer_trace 慢查询日志 performance_schema 和 sys 系统库 1.1 试验环境接下来我们以下面的实现环境看看，如何使用这些工具排查 MySQL 的性能问题 1234567891011121314151617181920mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=100000) do insert into t values(i,i); set i=i+1; end while;end;;delimiter ;call idata(); 1.2 Mariadb 的差异Mariadb 没有 sys schema 库，mysql sys schema 部分功能通过 information_schema 和 插件提供。下面是二者之间的简单对比: 功能 MySQL Mariadb 查看MDL锁 sys.schema_table_lock_waits INSTALL SONAME ‘metadata_lock_info’information_schema.metadata_lock_info 查看Innodb行锁 sys.innodb_lock_waits information_schema.innodb_lock_waitsINNODB_LOCKSINNODB_TRX 会话状态 performance_schema.session_status information_schema.session_status 2. 锁等待排查在表 t 执行 SQL 语句 select * from t where id=1; 如果查询长时间不返回，一般这种情况，大概率是表 t 被锁住了。接下来分析原因的时候，一般都是首先执行一下 show processlist 命令，看看当前语句处于什么状态。然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。 出现锁等待有以下几种情况: Waiting for table metadata lock，即 等待 MDL 锁 Waiting for table flush Innodb 行锁 2.1 等待 MDL 锁第一种情况如下图所示，查询正在等待 MDL 锁。 这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。但是，由于在 show processlist 的结果里面，持有 MDL 写锁线程的 Command 列可能是“Sleep”，导致查找起来很不方便。 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。 不过启用 performance_schema 和 sys(mariadb 中为 information_schema) 系统库需要 MySQL 在启动时设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失。 mariadbmariadb 没有 sys.schema_table_lock_waits 可以通过 METADATA_LOCK_INFO plugin 来查看MDL 锁的相关信息。123456789101112131415161718192021222324252627282930313233343536# 1. 启用 METADATA_LOCK_INFO plugin# 临时INSTALL SONAME 'metadata_lock_info';# 永久[mariadb]...plugin_load_add = metadata_lock_info# 2. 查看MDL锁MariaDB [performance_schema]&gt; SELECT * FROM information_schema.metadata_lock_info;+-----------+--------------------------+---------------+----------------------+--------------+------------+| THREAD_ID | LOCK_MODE | LOCK_DURATION | LOCK_TYPE | TABLE_SCHEMA | TABLE_NAME |+-----------+--------------------------+---------------+----------------------+--------------+------------+| 11 | MDL_BACKUP_DDL | NULL | Backup lock | | || 11 | MDL_SHARED_NO_READ_WRITE | NULL | Table metadata lock | tsong | words || 11 | MDL_INTENTION_EXCLUSIVE | NULL | Schema metadata lock | tsong | |+-----------+--------------------------+---------------+----------------------+--------------+------------+3 rows in set (0.000 sec)# 直接查看被锁住的线程MariaDB [performance_schema]&gt; SELECT -&gt; CONCAT('Thread ',P.ID,' executing "',P.INFO,'" IS LOCKED BY Thread ', -&gt; M.THREAD_ID) WhoLocksWho -&gt; FROM INFORMATION_SCHEMA.PROCESSLIST P, -&gt; INFORMATION_SCHEMA.METADATA_LOCK_INFO M -&gt; WHERE LOCATE(lcase(LOCK_TYPE), lcase(STATE))&gt;0;+----------------------------------------------------------------------------------------+| WhoLocksWho |+----------------------------------------------------------------------------------------+| Thread 10 executing "select * from words where id=1 for update" IS LOCKED BY Thread 11 |+----------------------------------------------------------------------------------------+1 row in set (0.002 sec)# kill 占用锁的线程MariaDB [performance_schema]&gt; kill 11 2.2 等 flush第二种情况如下图所示，查询在等 flush flush tables 有两种用法: flush tables t with read lock: 只关闭表 t flush tables with read lock: 关闭 MySQL 里所有打开的表。 正常这两个语句执行起来都很快，除非它们也被别的线程堵住了 出现上面 Waiting for table flush 状态情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。 2.3 innodb 行锁第三种情况，等待Innodb 行锁的情况如下: state 为 statistics 的线程被阻塞。这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。 可以看到，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。 不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。 实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。 mariadbmariadb innodb_lock_waits 表位于 information_schema 中。可以使用下面的方法查看等待 Innodb 行锁的线程。 123456789101112131415161718192021222324# 1. 查看事务持有的锁MariaDB [information_schema]&gt; SELECT l.*, t.* FROM information_schema.INNODB_LOCKS l JOIN information_schema.INNODB_TRX t ON l.lock_trx_id = t.trx_id WHERE trx_state = 'LOCK WAIT' \G# 2. 查看行锁等待，MariaDB [information_schema]&gt; SELECT requesting_trx_id AS run_trx_id, r.trx_mysql_thread_id AS run_pid, blocking_trx_id, z.trx_mysql_thread_id AS blocking_pid FROM innodb_lock_waits AS l JOIN innodb_trx AS r ON l.requesting_trx_id = r.trx_id JOIN innodb_trx AS z ON l.blocking_trx_id = z.trx_id;+-----------------+---------+-----------------+--------------+| run_trx_id | run_pid | blocking_trx_id | blocking_pid |+-----------------+---------+-----------------+--------------+| 422151806689784 | 13 | 21240 | 10 |+-----------------+---------+-----------------+--------------+1 row in set (0.001 sec) 2.4 死锁查看出现死锁后，执行 show engine innodb status，有一节 LATESTDETECTED DEADLOCK，就是记录的最后一次死锁信息。 并发执行下面两个语句，产生的死锁信息如下图所示:12select id from t where c in(5,20,10) lock in share mode;select id from t where c in(5,20,10) order by c desc for update; 这个结果分成三部分： (1) TRANSACTION，是第一个事务的信息； (2) TRANSACTION，是第二个事务的信息； WE ROLL BACK TRANSACTION (1)，是最终的处理结果，表示回滚了第一个事务。 第一个事务的信息中： WAITING FOR THIS LOCK TO BE GRANTED，表示的是这个事务在等待的锁信息； index c of table test.t，说明在等的是表 t 的索引 c 上面的锁； lock mode S waiting 表示这个语句要自己加一个读锁，当前的状态是等待中； Record lock 说明这是一个记录锁； n_fields 2 表示这个记录是两列，也就是字段 c 和主键字段 id； 0: len 4; hex 0000000a; asc ;; 是第一个字段，也就是 c。值是十六进制 a，也就是 10； 1: len 4; hex 0000000a; asc ;; 是第二个字段，也就是主键 id，值也是 10； 这两行里面的 asc 表示的是，接下来要打印出值里面的“可打印字符”，但 10 不是可打印字符，因此就显示空格。 第一个事务信息就只显示出了等锁的状态，在等待 (c=10,id=10) 这一行的锁。当然你是知道的，既然出现死锁了，就表示这个事务也占有别的锁，但是没有显示出来。别着急，我们从第二个事务的信息中推导出来。 第二个事务显示的信息要多一些： “ HOLDS THE LOCK(S)”用来显示这个事务持有哪些锁； index c of table test.t 表示锁是在表 t 的索引 c 上； hex 0000000a 和 hex 00000014 表示这个事务持有 c=10 和 c=20 这两个记录锁； WAITING FOR THIS LOCK TO BE GRANTED，表示在等 (c=5,id=5) 这个记录锁。 说明: lock_mode X/S waiting表示next-key lock； lock_mode X/S locks rec but not gap是只有行锁； locks gap before rec，就是只有间隙锁； 从上面这些信息中，我们就知道： “lock in share mode”的这条语句，持有 c=5 的记录锁，在等 c=10 的锁； “for update”这个语句，持有 c=20 和 c=10 的记录锁，在等 c=5 的记录锁。 因此导致了死锁。这里，我们可以得到两个结论： 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问； 在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。 2. SQL执行追踪可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件，以及使用的排序算法。 1234567891011121314151617181920/* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* mariadb */select VARIABLE_VALUE into @a from information_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算Innodb_rows_read差值 */select @b-@a; 3. 性能优化说完了 MySQL 一些常见的问题追踪，接下来，我们来看看一些在业务高峰期拿来”应急”的解决方案，并着重说一说它们可能存在的风险，内容包括: 短连接风暴 慢查询性能问题 QPS 突增问题 4. 短连接风暴正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。 前面我们说过，MySQL 建立连接的过程，成本是很高的。除了正常的网络连接三次握手外，还需要做登录权限判断和获得这个连接的数据读写权限。在数据库压力比较小的时候，这些额外的成本并不明显。但是，短连接模型存在一个风险，就是一旦数据库处理得慢一些，连接数就会暴涨。 max_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。在机器负载比较高的时候，处理现有请求的时间变长，每个连接保持的时间也更长。这时，再有新建连接的话，就可能会超过 max_connections 的限制。对于被拒绝连接的请求来说，从业务角度看就是数据库不可用。 显然我们不能直接增大 max_connections 的值，让更多的连接都可以进来。因为更多的连接会进一步增大系统负载。，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。 这里还有两种方法，但要注意，这些方法都是有损的: 第一种方法：先处理掉那些占着连接但是不工作的线程。 减少连接过程的消耗 4.1 先处理掉那些占着连接但是不工作的线程对于那些不需要保持的连接，我们可以通过 kill connection 主动踢掉。这个行为跟事先设置 wait_timeout 的效果是一样的。设置 wait_timeout 参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。 但是需要注意，在 show processlist 的结果里，踢掉显示为 sleep 的线程，可能是有损的。我们来看下面这个例子。 session A,B 在show processlist 中都是 Sleep，但按照优先级来说，应该优先断开像 session B 这样的事务外空闲的连接。但是，怎么判断哪些是事务外空闲的呢？可以通过 information_schema 库的 innodb_trx 表。因此，如果是连接数过多，你可以优先断开事务外空闲太久的连接；如果这样还不够，再考虑断开事务内空闲太久的连接。 从服务端断开连接使用的是 kill connection + id 的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。 从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。 4.2 减少连接过程的消耗有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。但是风险极高，非常不建议。 跳过权限验证的方法是：重启数据库，并使用–skip-grant-tables 参数启动。在 MySQL 8.0 版本里，如果你启用–skip-grant-tables 参数，MySQL 会默认把 –skip-networking 参数打开，表示这时候数据库只能被本地的客户端连接。 5. 慢查询性能问题在 MySQL 中，会引发性能问题的慢查询，大体有以下三种可能： 索引没有设计好； SQL 语句没写好； MySQL 选错了索引。 5.1 索引没设计好这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。 比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的： 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引； 执行主备切换； 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。 这是一个“古老”的 DDL 方案。平时在做变更的时候，你应该考虑类似 gh-ost 这样的方案，更加稳妥。但是在需要紧急处理时，上面这个方案的效率是最高的。 5.2 语句没写好我们可以通过改写 SQL 语句来处理。MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。 123mysql&gt; insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");call query_rewrite.flush_rewrite_rules(); call query_rewrite.flush_rewrite_rules() 这个存储过程，是让插入的新规则生效。 5.3 选错了索引应急方案就是给这个语句加上 force index。同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。 5.4 问题总结慢查询导致性能问题的三种可能情况，实际上出现最多的是前两种，即：索引没设计好和语句没写好。而这两种情况，恰恰是完全可以避免的。比如，通过下面这个过程，我们就可以预先发现问题。 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志； 在测试表里插入模拟线上的数据，做一遍回归测试； 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。 如果新增的 SQL 语句不多，手动跑一下就可以。而如果是新项目的话，或者是修改了原有项目的 表结构设计，全量回归测试都是必要的。这时候，你需要工具帮你检查所有的 SQL 语句的返回结果。比如，你可以使用开源工具 pt-query-digest。 6. QPS 突增问题有时候由于业务突然出现高峰，或者应用程序 bug，导致某个语句的 QPS 突然暴涨，也可能导致 MySQL 压力过大，影响服务。如果是bug 引起的，最理想的情况是让业务把这个功能下掉，服务自然就会恢复。 而下掉一个功能，如果从数据库端处理的话，对应于不同的背景，有不同的方法可用。我这里再和你展开说明一下: 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回。 当然，这个操作的风险很高，需要你特别细致。它可能存在两个副作用： 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤； 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。 所以，方案 3 是用于止血的，跟前面提到的去掉权限验证一样，应该是你所有选项里优先级最低的一个方案。 同时你会发现，其实方案 1 和 2 都要依赖于规范的运维体系：虚拟化、白名单机制、业务账号分离。由此可见，更多的准备，往往意味着更稳定的系统。 在实际开发中，我们也要尽量避免一些低效的方法，比如避免大量地使用短连接。同时，如果你做业务开发的话，要知道，连接异常断开是常有的事，你的代码里要有正确地重连并重试的机制。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 SQL 一些常见的错误用法]]></title>
    <url>%2F2020%2F03%2F11%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F13_SQL%E9%94%99%E8%AF%AF%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 试验环境我们用下面两张表作为我们测试 SQL 用法的试验环境: 1234567891011121314151617181920# 交易信息表mysql&gt; CREATE TABLE `tradelog` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `operator` int(11) DEFAULT NULL, `t_modified` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`), KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;# 交易详情表mysql&gt; CREATE TABLE `trade_detail` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `trade_step` int(11) DEFAULT NULL, /*操作步骤*/ `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/ PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; 1.条件字段函数操作类似下面的 SQL，对索引字段做了函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。 12# t_modified 上存在索引mysql&gt; select count(*) from tradelog where month(t_modified)=7; 要注意的是，优化器并不是要放弃使用这个索引。在这个例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后发现，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此最终还是会选择索引 t_modified。 我们就要把 SQL 语句改成基于字段本身的范围查询。按照下面这个写法，优化器就能按照我们预期的，用上 t_modified 索引的快速定位能力了。 1234mysql&gt; select count(*) from tradelog where -&gt; (t_modified &gt;= '2016-7-1' and t_modified&lt;'2016-8-1') or -&gt; (t_modified &gt;= '2017-7-1' and t_modified&lt;'2017-8-1') or -&gt; (t_modified &gt;= '2018-7-1' and t_modified&lt;'2018-8-1'); 不过优化器在个问题上确实有“偷懒”行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 -1 才可以。 2. 隐式类型转换现在这里就有两个问题： 数据类型转换的规则是什么？ 为什么有数据类型转换，就需要走全索引扫描？ 2.1 类型转换规则类型装换的规则有一个简单地额判断法方法，看 select “10” &gt; 9 的结果： 如果规则是“将字符串转成数字”，那么就是做数字比较，结果应该是 1； 如果规则是“将数字转成字符串”，那么就是做字符串比较，结果应该是 0。 2.2 有类型转换，需要走全表扫描试验一下便知道在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。 12345# 示例表同上mysql&gt; select * from tradelog where tradeid=110717;# 上面的 SQL 等同于mysql&gt; select * from tradelog where CAST(tradid AS signed int) = 110717; 也就是说，上面这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。 3. 隐式字符编码转换如果要查询 id=2 的交易的所有操作步骤信息，SQL 语句可以这么写：1mysql&gt; select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/ 使用 explain 观察这个 SQL 的执行你就会发现并没有使用 trade_detail tradeid 上的索引，而是作的全表扫描。而原因就是这两个表的字符集不同，一个是 utf8，一个是 utf8mb4。 单独看步骤二，相当于执行 SQL select * from trade_detail where tradeid=$L2.tradeid.value;其中，$L2.tradeid.value 的字符集是 utf8mb4。字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部的操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较。 因此， 在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。也就是说，实际上这个语句等同于下面这个写法： 1select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; 这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。到这里，你终于明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。 如果要对上面的额语句作优化，有两种常见的做法: 比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了。 如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大， 或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了。 12# 主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换mysql&gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; 4. 字符串截断12345678910mysql&gt; CREATE TABLE `table_a` ( `id` int(11) NOT NULL, `b` varchar(10) DEFAULT NULL, PRIMARY KEY (`id`), KEY `b` (`b`)) ENGINE=InnoDB;# 假设现在表里面，有 100 万行数据，其中有 10 万行数据的 b 的值是’1234567890’mysql&gt; select * from table_a where b='1234567890abcd'; mysql 既不会判断字段 b 定义的是 varchar(10)，小于 “1234567890abcd” 长度直接返回空，也不是直接把’1234567890abcd’拿到索引里面去做匹配。而是: 在传给引擎执行的时候，做了字符截断。因为引擎里面这个行只定义了长度是 10，所以只截了前 10 个字节，就是’1234567890’进去做匹配； 因为是 select *， 所以要做 10 万次回表； 但是每次回表以后查出整行，到 server 层一判断，b 的值都不是’1234567890abcd’; 返回结果是空。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 MySQL如何显示随机消息]]></title>
    <url>%2F2020%2F03%2F10%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F12_%E9%9A%8F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[random 存在哪些问题 背景从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：1234567891011121314151617181920mysql&gt; CREATE TABLE `words` ( `id` int(11) NOT NULL AUTO_INCREMENT, `word` varchar(64) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=0; while i&lt;10000 do insert into words(word) values(concat(char(97+(i div 1000)), char(97+(i % 1000 div 100)), char(97+(i % 100 div 10)), char(97+(i % 10)))); set i=i+1; end while;end;;delimiter ;call idata(); 1. 方法一: order by rand()1.1 内存临时表select word from words order by rand() limit 3; 这个语句的意思很直白，但执行流程却有点复杂的。 我们先用 explain 命令来看看这个语句的执行情况。 Extra 字段显示 Using temporary，表示的是需要使用临时表；Using filesort，表示的是需要执行排序操作。排序有全字段排序和 rowid 排序两种算法，对于内存表临时表，会选用哪种排序算法呢？ 排序算法的选择: 对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。 对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。 因此上面这个 SQL 的执行过程是这样的: 创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。 从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。 现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序 初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型 从内存临时表中一行一行地取出 R 值和位置信息 分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。 在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数 排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。 图中的 POS 位置信息表示的是：每个引擎用来唯一标识数据行的信息。 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID； 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的； MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。 order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法 1.2 磁盘临时表tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。 磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。 1234567891011set tmp_table_size=1024;set sort_buffer_size=32768;set max_length_for_sort_data=16;/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* 执行语句 */select word from words order by rand() limit 3;/* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G max_length_for_sort_data 设置成 16，小于 word 字段的长度定义，所以我们看到 sort_mode 里面显示的是 rowid 排序 SQL 语句，只需要取 R 值最小的 3 个 rowid,MySQL 使用了优先队列排序算法，而不是归并排序，所以filesort_priority_queue_optimization 这个部分的 chosen=true，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的 number_of_tmp_files 是 0。 什么时候选择优先队列排序算法？如果 limit n * 待排序行的大小(上面的大小就是字段R, rowid) 小于 sort_buffer_size 就会使用优先队列排序算法。 1.3 总结不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。 2. 随机排序方法2.1 简化方法我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的： 取得这个表的主键 id 的最大值 M 和最小值 N; 用随机函数生成一个最大值到最小值之间的数 X = (M-N)*rand() + N; 取不小于 X 的第一个 ID 的行。 123mysql&gt; select max(id),min(id) into @M,@N from t ;set @X= floor((@M-@N+1)*rand() + @N);select * from t where id &gt;= @X limit 1; 这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。比如你有 4 个 id，分别是 1、2、4、5，如果按照上面的方法，那么取到 id=4 的这一行的概率是取得其他行概率的两倍。 2.2 严格随机法为了得到严格随机的结果，你可以用下面这个流程: 取得整个表的行数，记为 C； 使用 Y = floor(C * rand())，得到 Y1、Y2、Y3；floor 函数在这里的作用，就是取整数部分。 再执行三个 limit Y, 1 语句得到三行数据。 1234567mysql&gt; select count(*) into @C from t;set @Y1 = floor(@C * rand());set @Y2 = floor(@C * rand());set @Y3 = floor(@C * rand());select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行select * from t limit @Y2，1；select * from t limit @Y3，1； MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此上面取一个Y值 需要扫描 Y+1 行。再加上，第一步扫描的 C 行，总共需要扫描 C+Y+1 行，执行代价比随机算法 1 的代价要高。总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1) 进一步优化的方法是取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：select * from t limit N, M-N+1; 如果返回的数据太多，也可以先取回 id 值，在应用中确定了三个 id 值以后，再执行三次 where id=X 的语句。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 MYSQL 自增值的上限]]></title>
    <url>%2F2020%2F03%2F09%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F09_%E8%87%AA%E5%A2%9E%E5%80%BC%E4%B8%8A%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[MySQL 里面的几种自增 id，它们的值达到上限以后，会出现什么情况。 1. 表定义自增值 id表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。因此就会出现主键冲突错误。 2^32-1（4294967295）不是一个特别大的数，因此在建表的时候你需要考察你的表是否有可能达到这个上限，如果有可能，就应该创建成 8 个字节的 bigint unsigned。 2. InnoDB 系统自增 row_id如果你创建的 InnoDB 表没有指定主键，那么 InnoDB 会给你创建一个不可见的，长度为 6 个字节的 row_id。 InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都将当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。 在代码实现时 row_id 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个字节的长度，这样写到数据表中时只放了最后 6 个字节，所以 row_id 能写到数据表中的值，就有两个特征： row_id 写入表中的值范围，是从 0 到 248-1； 当 dict_sys.row_id=248时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是 0。 也就是说，写入表的 row_id 是从 0 开始到 248-1。达到上限后，下一个值就是 0，然后继续循环。 在 InnoDB 逻辑里，申请到 row_id=N 后，就将这行数据写入表中；如果表中已经存在 row_id=N 的行，新写入的行就会覆盖原有的行。要验证这个结论的话，你可以通过 gdb 修改系统的自增 row_id 来实现。注意，用 gdb 改变量这个操作是为了便于我们复现问题，只能在测试环境使用。 从这个角度看，我们还是应该在 InnoDB 表中主动创建自增主键。因为，表自增 id 到达上限后，再插入数据时报主键冲突错误，是更能被接受的。 毕竟覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。 3. Xidredo log 和 binlog 相配合的时候，提到了它们有一个共同的字段叫作 Xid。 MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。 而 global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。 但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。 global_query_id 达到上限后，就会继续从 0 开始计数。从理论上讲，还是就会出现同一个 binlog 里面出现相同 Xid 的场景。因为 global_query_id 定义的长度是 8 个字节，这个自增值的上限是 2^64-1。要出现这种情况，必须是下面这样的过程： 执行一个事务，假设 Xid 是 A； 接下来执行 264次查询语句，让 global_query_id 回到 A； 再启动一个事务，这个事务的 Xid 也是 A。 不过，264这个值太大了，大到你可以认为这个可能性只会存在于理论上。 4. Innodb trx_idXid 和 InnoDB 的 trx_id 是两个容易混淆的概念。 Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。 InnoDB 自己的 trx_id，是另外维护的。这个 trx_id 就是事务id(transaction id) InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。 InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。 对于正在执行的事务，你可以从 information_schema.innodb_trx 表中看到事务的 trx_id。 4.1 trx_id 的分配策略 session B 里，我从 innodb_trx 表里查出的这两个字段，第二个字段 trx_mysql_thread_id 就是线程 id。显示线程 id，是为了说明这两次查询看到的事务对应的线程 id 都是 5，也就是 session A 所在的线程。 T2 时刻显示的 trx_id 是一个很大的数；T4 时刻显示的 trx_id 是 1289，看上去是一个比较正常的数字。 这是因为在 T1 时刻，session A 还没有涉及到更新，是一个只读事务。而对于只读事务，InnoDB 并不会分配 trx_id。也就是说： 在 T1 时刻，trx_id 的值其实就是 0。而这个很大的数，只是显示用的。 直到 session A 在 T3 时刻执行 insert 语句的时候，InnoDB 才真正分配了 trx_id。所以，T4 时刻，session B 查到的这个 trx_id 的值就是 1289 需要注意的是，除了显而易见的修改类语句外，如果在 select 语句后面加上 for update，这个事务也不是只读事务。 trx_id 的增加: update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2； InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。 4.3 T2 时刻查到的这个很大的数字是怎么来的呢？这个数字是每次查询的时候由系统临时计算出来的。它的算法是：把当前事务的 trx 变量的指针地址转成整数，再加上 248。使用这个算法，就可以保证以下两点： 因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。 如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。 为什么还要再加上 248呢？在显示值里面加上 248，目的是要保证只读事务显示的 trx_id 值比较大，正常情况下就会区别于读写事务的 id。但是，trx_id 跟 row_id 的逻辑类似，定义长度也是 8 个字节。因此，在理论上还是可能出现一个读写事务与一个只读事务显示的 trx_id 相同的情况。不过这个概率很低，并且也没有什么实质危害，可以不管它。 只读事务不分配 trx_id，有什么好处 一个好处是，这样做可以减小事务视图里面活跃事务数组的大小。因为当前正在运行的只读事务，是不影响数据的可见性判断的。所以，在创建事务的一致性视图时，InnoDB 就只需要拷贝读写事务的 trx_id。 另一个好处是，可以减少 trx_id 的申请次数。在 InnoDB 里，即使你只是执行一个普通的 select 语句，在执行过程中，也是要对应一个只读事务的。所以只读事务优化后，普通的查询语句不需要申请 trx_id，就大大减少了并发事务申请 trx_id 的锁冲突。 4.3 trx_id 到达上线会怎么样max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就可能出现 max_trx_id 达到 248-1 的上限，然后从 0 开始的情况。 当达到这个状态后，MySQL 就会持续出现一个脏读的 bug，我们来复现一下这个 bug。我们来复现这个场景 由于我们已经把系统的 max_trx_id 设置成了 2^48-1，所以在 session A 启动的事务 TA 的低水位就是 248-1 在 T2 时刻，session B 执行第一条 update 语句的事务 id 就是 2^48-1，而第二条 update 语句的事务 id 就是 0 了，这条 update 语句执行后生成的数据版本上的 trx_id 就是 0。 在 T3 时刻，session A 执行 select 语句的时候，判断可见性发现，c=3 这个数据版本的 trx_id，小于事务 TA 的低水位，因此认为这个数据可见。 由于低水位值会持续增加，而事务 id 从 0 开始计数，就导致了系统在这个时刻之后，所有的查询都会出现脏读的。 并且，MySQL 重启时 max_trx_id 也不会清 0，也就是说重启 MySQL，这个 bug 仍然存在。 5. thread_idthread_id 的逻辑很好理解：系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。 thread_id_counter 定义的大小是 4 个字节，因此达到 2^32-1 后，它就会重置为 0，然后继续增加。但是，你不会在 show processlist 里看到两个相同的 thread_id。 这，是因为 MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 的时候，逻辑代码是这样的：1234do &#123; new_id= thread_id_counter++;&#125; while (!thread_ids.insert_unique(new_id).second); 6. 总结每种自增 id 有各自的应用场景，在达到上限后的表现也不同： 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。 row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。 Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。 InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。 thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 insert 语句的锁]]></title>
    <url>%2F2020%2F03%2F08%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F08_insert%E9%94%81%2F</url>
    <content type="text"><![CDATA[insert select 为什么有这么多锁？ 本节我们会介绍一些特殊的 insert 语句产生的锁: insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁 如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。 insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。 1. insert … select 语句1234567891011121314CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(null, 1,1);insert into t values(null, 2,2);insert into t values(null, 3,3);insert into t values(null, 4,4);create table t2 like t 在可重复读隔离级别下，binlog_format=statement 时, insert into t2(c,d) select c,d from t; 需要对表 t 的所有行和间隙加锁。原因还是日志和数据的一致性。 如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 binlog_format=statement 的情况下就会出现日志与数据的不一致。 2. insert 循环写入执行 insert … select 的时候，对目标表也不是锁全表，而是只锁住需要访问的资源。假设要往表 t2 中插入一行数据，这一行的 c 值是表 t 中 c 值的最大值加 1。1insert into t2(c,d) (select c+1, d from t force index(c) order by c desc limit 1); 这个语句的加锁范围，就是表 t 索引 c 上的 (3,4]和 (4,supremum]这两个 next-key lock，以及主键索引上 id=4 这一行。 如果我们是要把这样的一行数据插入到表 t 中的话：1insert into t(c,d) (select c+1, d from t force index(c) 使用 explain，查看二进制日志，以及 Innodb_rows_read Extra 字段可以看到“Using temporary”字样，表示这个语句用到了临时表 二进制日志显示执行过程中读取了 5 行 Innodb_rows_read 的值增加了 4。因为默认临时表是使用 Memory 引擎的，所以这 4 行查的都是表 t 也就是说对上面这条语句对表 t 做了全表扫描。执行过程如下: 创建临时表，表里有两个字段 c 和 d。 按照索引 c 扫描表 t，依次取 c=4、3、2、1，然后回表，读到 c 和 d 的值写入临时表。这时，Rows_examined=4。 由于语义里面有 limit 1，所以只取了临时表的第一行，再插入到表 t 中。这时，Rows_examined 的值加 1，变成了 5 也就是说，这个语句会导致在表 t 上做全表扫描，并且会给索引 c 上的所有间隙都加上共享的 next-key lock。所以，这个语句执行期间，其他事务不能在这个表上插入数据。 为什么需要临时表，原因是这类一边遍历数据，一边更新数据的情况，如果读出来的数据直接写回原表，就可能在遍历过程中，读到刚刚插入的记录，新插入的记录如果参与计算逻辑，就跟语义不符。 由于实现上这个语句没有在子查询中就直接使用 limit 1，从而导致了这个语句的执行需要遍历整个表 t。因此我们可以使用下面的 sql 进行优化 1234create temporary table temp_t(c int,d int) engine=memory;insert into temp_t (select c+1, d from t force index(c) order by c desc limit 1);insert into t select * from temp_t;drop table temp_t; 3. insert 唯一键冲突 这个例子也是在可重复读（repeatable read）隔离级别下执行的。可以看到，session B 要执行的 insert 语句进入了锁等待状态。也就是说，session A 执行的 insert 语句，发生唯一键冲突的时候，并不只是简单地报错返回，还在冲突的索引上加了锁。 一个 next-key lock 就是由它右边界的值定义的。这时候，session A 持有索引 c 上的 (5,10]共享 next-key lock（读锁）。 至于为什么要加这个读锁，没有找到合理的解释。从作用上来看，这样做可以避免这一行被别的事务删掉。 3.1 唯一键冲突导致的死锁场景 在 session A 执行 rollback 语句回滚的时候，session C 几乎同时发现死锁并返回。这个死锁产生的逻辑是这样的： 在 T1 时刻，启动 session A，并执行 insert 语句，此时在索引 c 的 c=5 上加了记录锁。 在 T2 时刻，session B 要执行相同的 insert 语句，发现了唯一键冲突，加上读锁；同样地，session C 也在索引 c 上，c=5 这一个记录上，加了读锁。 T3 时刻，session A 回滚。这时候，session B 和 session C 都试图继续执行插入操作，都要加上写锁。两个 session 都要等待对方的行锁，所以就出现了死锁 4. insert into … on duplicate key update如果将上面的session A 冲突改写成 insert into t values(11,10,10) on duplicate key update d=100; 就会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）。 insert into … on duplicate key update 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。注意，如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。 5. 小结insert … select 是很常见的在两个表之间拷贝数据的方法。你需要注意，在可重复读隔离级别下 binlog=statement，这个语句会给 select 的表里扫描到的记录和间隙加读锁。 而如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。 insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 MYSQL 索引]]></title>
    <url>%2F2020%2F03%2F07%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F07_%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[B+树索引 1. InnoDB 的索引模型实现索引的方式有很多方式，N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。每一个索引在 InnoDB 里面对应一棵 B+ 树。 根据叶子节点的内容，索引类型分为主键索引和非主键索引。 主键索引: 又称聚簇索引 clustered index，叶子节点保存的是整行数据。 非主键索引: 又称为二级索引 secondary index，叶子节保存的是主键的值。InnoDB会把主键字段放到索引定义字段后面，当然同时也会去重。 下面是一个示例，可以帮助我们理解主键，非主键索引的关系:12345678910CREATE TABLE `geek` ( `a` int(11) NOT NULL, `b` int(11) NOT NULL, `c` int(11) NOT NULL, `d` int(11) NOT NULL, PRIMARY KEY (`a`,`b`), KEY `c` (`c`), KEY `ca` (`c`,`a`), KEY `cb` (`c`,`b`)) ENGINE=InnoDB; 索引: 主键: 是 a,b 字段的聚簇索引，相当于 order by a,b 索引 c: 按 c 排序，同时记录主键，因为主键有排序，所以相当于 order by c,a,b 索引 ca: 先按 c 排序，再按 a 排序，同时记录主键，主键部分是 b，不是 ab，而是只有 b,相当于 order by c,a 索引 cb: 先按 c 排序，在按 b 排序，同时记录主键，主键部分只有 a，相当于 order by c,b 所以索引 ca 这里是重复的，应该被删除。 1.1 主键的选择由于树的有序性，并且每个叶子节点对应的数据页所能容纳的行数是有限制的，因此在数据的插入和删除过程中就会发生页的分裂和合并，因而会影响数据更新的性能。所以大多数情况下我们都建议使用自增主键 自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。同时每个非主键索引的叶子节点上都是主键的值。显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。 1.2 索引优化B+树索引有四种常见的优化方式: 覆盖索引: 索引包含的字段能够覆盖查询的需求，不用回表进行二次查询 左前缀索引: 合理调整索引字段的顺序，可以提高索引复用率，减少索引个数 常用的查询字段或者查询组合应该应该靠前 其次，考虑空间因素，例如name 字段是比 age 字段大的 ，应该创建一个（name,age) 的联合索引和一个 (age) 的单字段索引，而不是 (age, name) (name) 两个索引 索引下推: MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数 索引可能因为删除，或者页分裂等原因，导致数据页有空洞，适时地重建索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。 对于主键索引，不论是删除主键还是创建主键，都会将整个表重建，因此主键索引的重建应该使用 alter table T engine=InnoDB，而不是 drop primary key, add primary key 2. 普通索引与唯一索引通过上面我们已经知道了Innodb B+ 树索引的基本机构，那对于普通索引和唯一索引我们应该怎么选择呢。我们就从这两种索引对查询语句和更新语句的性能影响来进行分析。 2.1 查询分析假设我们要执行 select id from T where k=5，字段 k 上有索引 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 我们知道 InnoDB 的数据是按数据页为单位来读写的，对于普通索引来说，要多做的那一次“查找和判断下一条记录”的操作，就只需要一次指针寻找和一次计算。所以二者的性能相差微乎其微 2.2 更新分析对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。而这必须要将数据页读入内存才能判断。因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 2.3 索引选择这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响，所以，我建议你尽量选择普通索引。即使是对于 changer buffer 不适用的场景，比如所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。 特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。 最后关于普通索引和唯一索引的选择，首先，业务正确性优先。如果需要数据库保证数据唯一性，肯定是优先选择唯一索引 在一些“归档库”的场景，你是可以考虑使用普通索引的。比如，线上数据只需要保留半年，然后历史数据保存在归档库。这时候，归档数据已经是确保没有唯一键冲突了。要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。 3. 如何给字符串添加索引MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。指定前缀创建索引的好处是占用的空间会更小，可能会增加额外的记录扫描次数。 选择多长的前缀作为索引取决于索引的区分度，区分度越高，重复值越少，检索效率越高。长度越长区分度肯定越好，但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀: 12345678910# 计算待索引列上有多少不同的值mysql&gt; select count(distinct email) as L from SUser;# 查看不同长度前缀有多少不同的值mysql&gt; select count(distinct left(email,4)）as L4, count(distinct left(email,5)）as L5, count(distinct left(email,6)）as L6, count(distinct left(email,7)）as L7,from SUser; 使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如 5%，在可接受的范围内选择最短的长度构建索引。 除了区分度的影响，因为系统并不确定前缀索引的定义是否截断了完整信息，所以总是要回表查询整行数据，因此也就无法使用覆盖索引。这也是是否使用前缀索引需要考虑的因素。 有时候，我们会遇到前缀的区分度不够好的情况，使用太长的前缀，又会占用太多的存储空间。此时我们可以采用倒序存储或者 hash 字段方式创建索引。因此使用字符串创建索引，有以下几种方式: 直接创建完整索引，这样可能比较占用空间； 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引； 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描； 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。 3.1 字符串索引使用示例1234567891011# 创建前缀索引mysql&gt; alter table SUser add index index1(email);mysql&gt; alter table SUser add index index2(email(6));# 倒序索引，每次写和读的时候，都需要额外调用一次 reverse 函数mysql&gt; select field_list from t where id_card = reverse('input_id_card_string');# hash 字段mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc);# hash 值可能存在冲突，必须在查询条件加上原始字段mysql&gt; select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string']]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 MySQL 幻读与间隙锁]]></title>
    <url>%2F2020%2F03%2F06%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F06_%E9%97%B4%E9%9A%99%E9%94%81%2F</url>
    <content type="text"><![CDATA[幻读 1. 幻读幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。对于幻读需要在注意: 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。而当前读的规则，就是要能读到所有已经提交的记录的最新值。因此，幻读只在“当前读”下才会出现。 修改结果，被之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行” 1.1 幻读有什么问题？没有行锁到底会导致什么问题，我们来看下面这个示例: 经过 T1 时刻，id=5 这一行变成 (5,5,100)，当然这个结果最终是在 T6 时刻正式提交的 ; 经过 T2 时刻，id=0 这一行变成 (0,5,5); 经过 T4 时刻，表里面多了一行 (1,5,5); 其他行跟这个执行序列无关，保持不变。 这样看，这些数据也没啥问题，但是我们再来看看这时候 binlog 里面的内容。 T2 时刻，session B 事务提交，写入了两条语句； T4 时刻，session C 事务提交，写入了两条语句； T6 时刻，session A 事务提交，写入了 update t set d=100 where d=5 这条语句。 用 binlog 来克隆一个库，这三行的结果，都变成了 (0,5,100)、(1,5,100) 和 (5,5,100)。也就是数据库发生了数据不一致。 1.2 间隙锁的作用锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。基于行锁的并发控制，只能保护已经存在的行，但是对于新插入的行就会出现未保护的临界状态。 行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。锁是加在索引上的，这是 InnoDB 的一个基础设定，在分析问题的时候一定要谨记 2. 间隙锁间隙锁，锁的就是两个值之间的空隙。数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。 比如行锁，分成读锁和写锁。写锁跟任何其他读锁和写锁都是冲突的，也就是说，跟行锁有冲突关系的是“另外一个行锁”。但是间隙锁不一样，跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。即间隙锁保护的是这个间隙，不允许插入值。但，它们之间是不冲突的。 最后锁就是加在索引上的，这是 InnoDB 的一个基础设定，在分析问题的时候一定要谨记。 2.1 加锁范围我们创建下表，这个表除了主键 id 外，还有一个索引 c，初始化语句在表中插入了 6 行数据。 12345678910CREATE TABLE `t` ( `id` int(11) NOT NULL, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25); 间隙锁，锁的就是两个值之间的空隙。表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。+∞是开区间，实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样就符合前面说的“都是前开后闭区间”。 2.2 间隙锁的问题间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。我们来看下面这个操作序列 123456789begin;select * from t where id=N for update;/*如果行不存在*/insert into t values(N,N,N);/*如果行存在*/update t set d=N set id=N;commit; 这里，我用两个 session 来模拟并发，并假设 N=9。 你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下： session A 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10); session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功； session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待； session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。 至此，两个 session 进入互相等待状态，形成死锁。 2.3 间隙锁的理解间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。 间隙锁是在可重复读隔离级别下才会生效的。所以，你如果把隔离级别设置为读提交的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要把 binlog 格式设置为 row。这，也是现在不少公司使用的配置组合。 读提交隔离级别加 binlog_format=row 的组合和可重复度隔离级别应该如何选择，跟业务场景有关。如果读提交隔离级别够用，也就是说，业务不需要可重复读的保证，这样考虑到读提交下操作数据的锁范围更小（没有间隙锁），这个选择是合理的。 3. 加锁规则因为间隙锁在可重复读隔离级别下才有效，下面的规则，若没有特殊说明，默认是可重复读隔离级别。丁老师总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”: 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。 原则 2：查找过程中访问到的对象才会加锁。 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。 理解这个规则需要注意两点: 无论是等值查询，还是范围查询，在执行过程中，首先都要通过树搜索的方式定位记录，定位记录用的就是“等值查询”的方法。没有 desc 以下限值进行定位，有 desc 时以上线值进行定位。 锁是“在执行过程中一个一个加的”，而不是一次性加上去的 间隙锁本身是不互斥的 所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。 使用 show engine innodb status 可以查看锁等待，死锁等信息。 下面的表 t 是上面 2.1节 创建并初始化的表。 3.1 等值查询间隙锁第一个例子是关于等值条件操作间隙： 由于表 t 中没有 id=7 的记录，因此加锁为范围: 根据原则 1，加锁单位是 next-key lock，session A 加锁范围就是 (5,10] 同时根据优化 2，这是一个等值查询 (id=7)，而 id=10 不满足查询条件，next-key lock 退化成间隙锁，因此最终加锁的范围是 (5,10) 3.2 非唯一索引等值锁第二个例子是关于覆盖索引上的锁： 这里 session A 要给索引 c 上 c=5 的这一行加上读锁: 根据原则 1，加锁单位是 next-key lock，因此会给 (0,5]加上 next-key lock。 要注意 c 是普通索引，因此仅访问 c=5 这一条记录是不能马上停下来的，需要向右遍历，查到 c=10 才放弃。根据原则 2，访问到的都要加锁，因此要给 (5,10]加 next-key lock 但是同时这个符合优化 2：等值判断，向右遍历，最后一个值不满足 c=5 这个等值条件，因此退化成间隙锁 (5,10)。 根据原则 2 ，只有访问到的对象才会加锁，这个查询使用覆盖索引，并不需要访问主键索引，所以主键索引上没有加任何锁，这就是为什么 session B 的 update 语句可以执行完成。 在这个例子中，lock in share mode 只锁覆盖索引，但是如果是 for update 就不一样了。 执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。满足条件的行指的是索引 c 上所有被加锁的节点对应的主键 id。 锁是加在索引上的；同时，它给我们的指导是，如果你要用 lock in share mode 来给行加读锁避免数据被更新的话，就必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段。比如，将 session A 的查询语句改成 select d from t where c=5 lock in share mode。 3.3 主键索引范围锁第三个例子是关于范围查询的。 session A 的加锁范围: 开始执行的时候，要找到第一个 id=10 的行，因此本该是 next-key lock(5,10]。 根据优化 1， 主键 id 上的等值条件，退化成行锁，只加了 id=10 这一行的行锁 范围查找就往后继续找，找到 id=15 这一行停下来，因此需要加 next-key lock(10,15]。 需要注意一点，首次 session A 定位查找 id=10 的行的时候，是当做等值查询来判断的，而向右扫描到 id=15 的时候，用的是范围查询判断。这就是上面所说的 bug，唯一索引上的范围查询会访问到不满足条件的第一个值为止。并且不是等值查询，也不会优化。 3.4 非唯一索引范围锁 这次 session A 用字段 c 来判断，加锁规则跟案例三唯一的不同是： 在第一次用 c=10 定位记录的时候，索引 c 上加了 (5,10]这个 next-key lock 后，由于索引 c 是非唯一索引，没有优化规则，也就是说不会蜕变为行锁， 向右遍历的过程就不是等值查询了，最终 sesion A 加的锁是，索引 c 上的 (5,10] 和 (10,15] 这两个 next-key lock。 3.5 唯一索引范围锁 bug ession A 是一个范围查询: 按照原则 1 的话，应该是索引 id 上只加 (10,15]这个 next-key lock，并且因为 id 是唯一键，所以循环判断到 id=15 这一行就应该停止了。 但是实现上，InnoDB 会往前扫描到第一个不满足条件的行为止，也就是 id=20。而且由于这是个范围扫描，因此索引 id 上的 (15,20]这个 next-key lock 也会被锁上。 从这个例子也可以看出，在加锁时等值查询加锁，范围查询加锁时独立，并且取的是最后的交集。 3.6 非唯一索引上存在”等值”的例子接下来的例子，是为了更好地说明“间隙”这个概念。这里，我给表 t 插入一条新记录。1mysql&gt; insert into t values(30,10,30); 新插入的这一行 c=10，也就是说现在表里有两个 c=10 的行。你要知道，由于非唯一索引上包含主键的值，所以是不可能存在“相同”的两行的。 虽然有两个 c=10，但是它们的主键值 id 是不同的（分别是 10 和 30），因此这两个 c=10 的记录之间，也是有间隙的。 现在，我们来看一下案例六。这次我们用 delete 语句来验证。注意，delete 语句加锁的逻辑，其实跟 select … for update 是类似的 此时的加锁范围: session A 在遍历的时候，先访问第一个 c=10 的记录。同样地，根据原则 1，这里加的是 (c=5,id=5) 到 (c=10,id=10) 这个 next-key lock。 然后，session A 向右查找，直到碰到 (c=15,id=15) 这一行，循环才结束。根据优化 2，这是一个等值查询，向右查找到了不满足条件的行，所以会退化成 (c=10,id=10) 到 (c=15,id=15) 的间隙锁。 这个蓝色区域左右两边都是虚线，表示开区间，即 (c=5,id=5) 和 (c=15,id=15) 这两行上都没有锁。 3.7 limit 语句加锁例子 6 也有一个对照案例，场景如下所示： 案例七里的 delete 语句明确加了 limit 2 的限制，因此在遍历到 (c=10, id=30) 这一行之后，满足条件的语句已经有两条，循环就结束了。 索引 c 上的加锁范围就变成了从（c=5,id=5) 到（c=10,id=30) 这个前开后闭区间，如下图所示： 这个例子对我们实践的指导意义就是，在删除数据的时候尽量加 limit。这样不仅可以控制删除数据的条数，让操作更安全，还可以减小加锁的范围。 3.8 一个死锁的例子前面的例子中，我们在分析的时候，是按照 next-key lock 的逻辑来分析的，因为这样分析比较方便。最后我们再看一个案例，目的是说明：next-key lock 实际上是间隙锁和行锁加起来的结果。 我们按时间顺序来分析一下为什么是这样的结果。 session A 启动事务后执行查询语句加 lock in share mode，在索引 c 上加了 next-key lock(5,10] 和间隙锁 (10,15)； session B 的 update 语句也要在索引 c 上加 next-key lock(5,10] ，进入锁等待； 然后 session A 要再插入 (8,8,8) 这一行，被 session B 的间隙锁锁住。由于出现了死锁，InnoDB 让 session B 回滚。 你可能会问，session B 的 next-key lock 不是还没申请成功吗？其实是这样的，session B 的“加 next-key lock(5,10] ”操作，实际上分成了两步，先是加 (5,10) 的间隙锁，加锁成功；然后加 c=10 的行锁，这时候才被锁住的。也就是说，我们在分析加锁规则的时候可以用 next-key lock 来分析。但是要知道，具体执行的时候，是要分成间隙锁和行锁两段来执行的。 3.9 读提交的加锁规则我们上面的所有案例都是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有加锁的资源，都是在事务提交或者回滚的时候才释放的。 在最后的案例中，你可以清楚地知道 next-key lock 实际上是由间隙锁加行锁实现的。如果切换到读提交隔离级别 (read-committed) 的话，就好理解了，过程中去掉间隙锁的部分，也就是只剩下行锁的部分。 其实读提交隔离级别在外键场景下还是有间隙锁，相对比较复杂。 另外，在读提交隔离级别下还有一个优化，即：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。 也就是说，读提交隔离级别下，锁的范围更小，锁的时间更短，这也是不少业务都默认使用读提交隔离级别的原因。 3.10 非索引列加锁对于非索引列而言，因为无法直接精确定位值的位置，因此只能进行全表扫描: 在可重复读隔离级别下，会对所有行和间隙加锁 在读提交隔离级别下，语句执行过程中会对所有行加上行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放了，不需要等到事务提交。 123begin;select * from t where d=5 for update;commit; 上面这个例子，在读提交隔离级别下，在 select * from t where d=5 for update; 的执行过程中，所有行都会被加锁；语句执行完成之后，只会对 d=5 这一行加锁直至事务提交释放。 3.11 desc 语句加锁 session A 的 select 语句加锁过程是这样的： 由于是 order by c desc，要拿到满足条件的所有行，优化器必须第一个要定位的是索引 c 上“最右边的”c=20 的行，所以会加上间隙锁 (20,25) 和 next-key lock (15,20]。为什么不对 c=25 加锁，是因为查找 20 的过程是一个非唯一索引的等值查询，25 不满足查询条件无须加锁。 在索引 c 上向左遍历，要扫描到 c=10 才停下来，所以 next-key lock 会加到 (5,10]，这正是阻塞 session B 的 insert 语句的原因。注意向左遍历，在遍历过程中，就不是等值查询了。 在扫描过程中，c=20、c=15、c=10 这三行都存在值，由于是 select *，所以会在主键 id=10、15、20 上加三个行锁。 因此，session A 的 select 语句锁的范围就是：索引 c 上 (5, 25)；主键索引上 id=10、15、20 三个行锁。 每次加锁都会说明是加在“哪个索引上”的。因为，锁是加在索引上的，这是 InnoDB 的一个基础设定，在分析问题的时候一定要谨记。 3.12 in 语句加锁 12begin;select id from t where c in(5,20,10) lock in share mode; 这条查询语句里用的是 in，我们先来看这条语句的 explain 结果。 in 语句使用了索引 c 并且 rows=3，说明这三个值都是通过 B+ 树搜索定位的。 在查找 c=5 的时候，先锁住了 (0,5]。但是因为 c 不是唯一索引，为了确认还有没有别的记录 c=5，就要向右遍历，找到 c=10 才确认没有了，这个过程满足优化 2，所以加了间隙锁 (5,10)。 同样的，执行 c=10 这个逻辑的时候，加锁的范围是 (5,10] 和 (10,15)；执行 c=20 这个逻辑的时候，加锁的范围是 (15,20] 和 (20,25)。(因为 in 语句会事先对其中的值排序在查找，所以才会先对 c=10 执行加锁么？) 这些锁是“在执行过程中一个一个加的”，而不是一次性加上去的。 如果同时有另外一个语句，是这么写的： 1select id from t where c in(5,20,10) order by c desc for update; 我们现在都知道间隙锁是不互锁的，但是这两条语句都会在索引 c 上的 c=5、10、20 这三行记录上加记录锁。语句里面是 order by c desc， 这三个记录锁的加锁顺序，是先锁 c=20，然后 c=10，最后是 c=5。也就是说，这两条语句要加锁相同的资源，但是加锁顺序相反。当这两条语句并发执行的时候，就可能出现死锁。 4. 如何看待锁等待 由于 session A 并没有锁住 c=10 这个记录，所以 session B 删除 id=10 这一行是可以的。但是之后，session B 再想 insert id=10 这一行回去就不行了。 现在我们一起看一下此时 show engine innodb status 的结果，看看能不能给我们一些提示。锁信息是在这个命令输出结果的 TRANSACTIONS 这一节。你可以在文稿中看到这张图片 我们来看几个关键信息。 index PRIMARY of table test.t ，表示这个语句被锁住是因为表 t 主键上的某个锁。 lock_mode X locks gap before rec insert intention waiting 这里有几个信息： insert intention 表示当前线程准备插入一个记录，这是一个插入意向锁。为了便于理解，你可以认为它就是这个插入动作本身。 gap before rec 表示这是一个间隙锁，而不是记录锁。 那么这个 gap 是在哪个记录之前的呢？接下来的 0~4 这 5 行的内容就是这个记录的信息。 n_fields 5 也表示了，这一个记录有 5 列： 0: len 4; hex 0000000f; asc ;; 第一列是主键 id 字段，十六进制 f 就是 id=15。所以，这时我们就知道了，这个间隙就是 id=15 之前的，因为 id=10 已经不存在了，它表示的就是 (5,15)。 1: len 6; hex 000000000513; asc ;; 第二列是长度为 6 字节的事务 id，表示最后修改这一行的是 trx id 为 1299 的事务。 2: len 7; hex b0000001250134; asc % 4;; 第三列长度为 7 字节的回滚段信息。可以看到，这里的 acs 后面有显示内容 (% 和 4)，这是因为刚好这个字节是可打印字符。 后面两列是 c 和 d 的值，都是 15。 因此，我们就知道了，由于 delete 操作把 id=10 这一行删掉了，原来的两个间隙 (5,10)、(10,15）变成了一个 (5,15)。也就是说，所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 MYSQL 事务]]></title>
    <url>%2F2020%2F03%2F05%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F05_%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[事务的隔离性和回滚日志 1.事务的隔离性事务的隔离级别包括: 读未提交: read uncommitted，一个事务还没提交时，它做的变更就能被别的事务看到 读提交: read committed，一个事务提交之后，它做的变更才会被其他事务看到 可重复读: repeatable read，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的 串行化: 对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行(锁是在事务提交之后才释放的)。 在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。 “可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。 “读未提交”隔离级别下直接返回记录上的最新值，没有视图概念 “串行化”隔离级别下直接用加锁的方式来避免并行访问 MySQL 中数据的隔离级别由参数 transaction-isolation 配置 1.1 MVCC 与回滚日志在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 不同时刻启动的事务会有不同的 read-view。不同的 read-view 之间是不会相互影响的。同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的 read-view 的时候。 为什么不要使用长事务 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。 在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。 除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。 1.2 事务提交与管理autocommit: 是否自动提交事务 =0: 关闭事务的自动提交，意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。如果是长连接，就可能导致意外的长事务。 =1: 开始事务自动提交，事务启动需要显示使用 begin 或 start transaction配套的提交语句是 commit，回滚语句是 rollback。对于频繁使用事务的业务，可以使用 commit work and chain 语法，在事务提交时，自动开启一个新的事务，以减少 begin 语句的交互次数 可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 事务启动的时机begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的； 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。 1.3 如何避免长事务对业务的影响从应用开发端来看： 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。 其次，从数据库端来看： 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill；Percona 的 pt-kill 这个工具不错，推荐使用； 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题； 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 2.事务的一致性读视图在 MySQL 里，有两个“视图”的概念： 一个是 view，它是一个用查询语句定义的虚拟表 另一个是 InnoDB 在实现 MVCC 时用到的一致性读视图，即 consistent read view，用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现 2.1 MVCC 和一致性视图MVCC InnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id 每行数据也都是有多个版本的，每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的row trx_id 旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它 也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。下面是一个记录被多个事务连续更新后的状态 图中虚线框里是同一行数据的 4 个版本，当前最新版本是 V4 三个虚线箭头，就是 undo log； V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的 一致性视图InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。这个视图数组把所有的 row trx_id 分成了几种不同的情况。 对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见 上面的规则翻译一下: 一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 视图的更新读数据时是按照上述规则的一致性读，但是更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。因为更新时如果根据数据的历史版本去更新，就会导致当前最新版本出现数据丢失。 除了 update 语句外，select 语句如果加锁，也是当前读。 select + lock in share mode: 加读锁(S 锁，共享锁） select + for update: 加写锁（X 锁，排他锁） 而 update 更新语句的当前读也会给当前最新版本的数据加上读锁。 更新与两阶段锁 假设有上面一组更新事务: 虽然事务 C’还没提交，但是 (1,2) 这个版本也已经生成了，并且是当前的最新版本。 事务 C’没提交，也就是说 (1,2) 这个版本上的写锁还没释放 而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C’释放这个锁，才能继续它的当前读。 到这里，我们把一致性读、当前读和行锁就串起来了。 RR 与 RC可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.3 Go 语言的性能优化工具]]></title>
    <url>%2F2020%2F03%2F04%2Flinux_perf%2F63.go%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 MYSQL 锁]]></title>
    <url>%2F2020%2F03%2F04%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F04_%E9%94%81%2F</url>
    <content type="text"><![CDATA[全局锁 - 表锁 - 行锁 1. 全局锁全局锁: 作用: 对整个数据库实例加锁 加锁: Flush tables with read lock 解锁: unlock tables，客户端断开时会自动释放锁 场景: 全库逻辑备份，即把整库每个表都 select 出来存成文本 加锁范围: 数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句都会被阻塞 做全库备份时，对于 Innodb，通过可重复度隔离级别我们就可以获取数据库的一致视图，但是对 于MyISAM 这些不支持事务的存储引擎，只能使用 Flush tables with read lock 让整个库处于只读状态。 既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因： 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 2.表级锁MySQL 表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁: 加锁: lock tables t read/write tables 后面 s 可省略 lock tables t read/writer 会持有表 t 的 MDL 读/写锁 解锁: unlock tables，客户端断开时会自动释放锁 加锁范围: 除了会限制别的线程的读写外，也限定了本线程接下来的操作对象，如果在某个线程 A 中执行 lock tables t1 read, t2 write;线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表，线程A只能访问他锁定的表 元数据锁: 加锁: MDL 不需要显式使用，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。MDL 的作用是，保证读写的正确性 解锁: 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放 在做表结构变更的时候，如果操作不慎，就会导致锁住线上查询和更新。 session A 先启动，这时候会对表 t 加一个 MDL 读锁 由于 session B 需要的也是 MDL 读锁，因此可以正常执行 因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞 session D 等后续所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时后会再起一个新 session 再请求的话，这个库的线程很快就会爆满。 因为MDL锁只有在事务提交之后才会释放，因此对于存在长事务，或者操作非常频繁的表做DDL时要非常小心。好的做法是: 在 MySQL 的 information_schema 库的 innodb_trx 表中，可以查到当前执行中的事务。要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务 在 alter table 语句里面设定等待时间: 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 需要说明的是 5.7 版本修改了 MDL 的加锁策略，在&gt;=5.7 的MySQL上是无法复现上面的场景的。MDL 写锁在修改完表结构后就会退化为 MDL 读锁。 3.行锁行锁就是针对数据表中行记录的锁。MySQL 的行锁是在引擎层由各个引擎自己实现的。MyISAM 引擎就不支持行锁。锁是加在索引上的，这是 InnoDB 的一个基础设定，在分析问题的时候一定要谨记。 3.1 两阶段锁在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。如果把最可能造成冲突的锁语句放在最后面，这个锁的占用的时间就最少。这就最大程度地减少了事务之间的锁等待，提升了并发度。 3.2 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 但是这两种策略都各有利弊:innodb_lock_wait_timeout: 默认值是 50s，对于在线服务来说，这个等待时间往往是无法接受的。我们又不可能直接把这个时间设置成一个很小的值，因为如果是简单的锁等待而不是死锁，过短的超时时间会造成很多误伤。正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。 主动死锁检测: 在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。假如所有事务都要更新同一行，每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。 热点行更新导致的性能问题热点行更新导致的性能问题的症结在于，死锁检测要耗费大量的 CPU 资源。解决办法有如下几种: 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。 另一个思路是控制访问相同资源的并发事务量 比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低。并发控制要做在数据库服务端。如果有中间件，可以考虑在中间件实现；如果能修改 MySQL 源码的人，也可以做在 MySQL 里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 考虑通过将一行改成逻辑上的多行来减少锁冲突，但是需要根据业务逻辑做详细设计 4.MDL与主从同步问题问题: 当备库用–single-transaction 做逻辑备份的时候，如果从主库的 binlog 传来一个 DDL 语句会怎么样？ 假设这个 DDL 是针对表 t1 的，备份过程的语句如下:123456789101112Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ; # 确保 RR（可重复读）隔离级别Q2:START TRANSACTION WITH CONSISTENT SNAPSHOT； # 得到一个一致性视图/* other tables */ Q3:SAVEPOINT sp; # 设置一个保存点/* 时刻 1 */Q4:show create table `t1`; # 拿到表结构/* 时刻 2 */Q5:SELECT * FROM `t1`; # 正式导数据 /* 时刻 3 */Q6:ROLLBACK TO SAVEPOINT sp; # 释放 t1 的 MDL 锁 /* 时刻 4 *//* other tables */ DDL 从主库传过来的时间按照效果不同: 如果在 Q4 语句执行之前到达，现象：没有影响，备份拿到的是 DDL 后的表结构。 如果在“时刻 2”到达，则表结构被改过，Q5 执行的时候，报 Table definition has changed, please retry transaction，现象：mysqldump 终止； 如果在“时刻 2”和“时刻 3”之间到达，mysqldump 占着 t1 的 MDL 读锁，binlog 被阻塞，现象：主从延迟，直到 Q6 执行完成。 从“时刻 4”开始，mysqldump 释放了 MDL 读锁，现象：没有影响，备份拿到的是 DDL 前的表结构 5. 如何查看锁等待如果一条语句长时间不返回，一般碰到这种情况的话，大概率是表 t 被锁住了。一般首先执行一下 show processlist 命令，看看当前语句处于什么状态。然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。下面我们将分成如下几种情况来分析如何查看和解决锁等待: MDL 锁等待 5.1 MDL 锁等待 show processlist 出现 Waiting for table metadata lock 时，表示的是，现在有一个线程正在表 t 上请求或者持有 MDL 写锁，导致 select 语句被堵住。 这类问题的处理方式，就是找到谁持有 MDL 写锁，然后把它 kill 掉。 但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失) 5.2 等待 flush 这个状态表示的是，现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。 123flush tables t with read lock;flush tables with read lock; 但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。这个例子很简单，通过 processlist 直接就可以看出导致阻塞的语句。 5.3 等行锁 通过 lock in share mode 可以判断，sql 语句正在等待行锁。但问题是怎么查出是谁占着这个写锁。如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到。 blocking_pid 显示 4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。 KILL QUERY 4: 表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁 KILL 4: 表示直接断开这个连接。连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.2 Java 语言的性能优化工具]]></title>
    <url>%2F2020%2F03%2F03%2Flinux_perf%2F62.java%E8%AF%AD%E8%A8%80%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 Innodb 表空间回收]]></title>
    <url>%2F2020%2F03%2F03%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F03_Innodb%E8%A1%A8%E7%A9%BA%E9%97%B4%E7%9A%84%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？ 1.innodb_file_per_table一个 InnoDB 表包含两部分，即：表结构定义和数据。在 MySQL 8.0 版本以前，表结构是存在以.frm 为后缀的文件里。而 MySQL 8.0 版本，则已经允许把表结构定义放在系统数据表中了。 表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的。 innodb_file_per_table=off 位置: 所有数据库的所有存储引擎为Innodb的表使用同一个表空间文件 datadir/ibdata[N]: 共用的表空间文件，用于保存所有Innodb表的数据和索引 数据库目录/db_name.frm: 表结构定义保存在各个数据库目录下 特性: 不支持单表导入等高级特性 innodb_file_per_table=on 位置: 每表使用单独的表空间文件，位于各个数据库目录下 db_name.ibd: 表单独的表空间文件，用于存储单独表的数据和索引 db_name.frm: 用于存储表结构定义 建议将 innodb_file_table 设置为 ON，因为一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。 2. 数据的删除流程InnoDB 里的数据都是用 B+ 树的结构组织的，数据存储在磁盘页中。数据的删除就分成了两种情况: 删除一个记录: InnoDB 引擎只会把记录标记为删除，有符合范围条件的数据插入时，这个记录会被复用 一个数据页内的所有记录都被删除，整个数据页就可以被复用了。 但是记录跟页的复用是有区别的: 记录的复用，只限于符合范围条件的数据。 页的复用可以复用到任何位置 如果相邻两个数据页利用率都很小，系统会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用 所以 delete 删除命令只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。可以复用，而没有被使用的空间，看起来就像是“空洞”。 不止是删除数据会造成空洞，插入数据也会。随机的数据插入会导致页分裂，另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。 经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。重建表就可以达到这样的目的。在重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。 3.重建表回收表空间可以使用 alter table A engine=InnoDB 命令来重建表。这个语句在不同的 MySQL 版本中行为是不同的。 3.1 MySQL&lt;5.5alter table A engine=InnoDB 的执行流程如下: 转存数据: 新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中 交换表名 删除旧表 注意: 临时数据存放在 tmp_table 中，这是一个临时表，是在 server 层创建的 新版本中等同于执行命令 alter table t engine=innodb,ALGORITHM=copy; 新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。 花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。 3.2 MySQL&gt;=5.5注意: 临时数据存放在 tmp_file 中，“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的 等同于命令 alter table t engine=innodb,ALGORITHM=inplace; MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。重建表的流程如下： 建立一个临时文件，扫描表 A 主键的所有数据页； 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中； 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态； 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态； 用临时文件替换表 A 的数据文件。 图 4 的流程中，alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。MDL 读锁不会阻塞增删改操作，同时保护自己，禁止其他线程对这个表同时做 DDL。 由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。 上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗 IO 和 CPU 资源的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，推荐使用 GitHub 开源的 gh-ost 3.3 inplace 和 onlineinplace 和 online 并不是一回事，DDL 过程如果是 Online 的，就一定是 inplace 的；反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。 4. 三种重建表的语法optimize table、analyze table 和 alter table: 从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是ALGORITHM=inplace 的过程 analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁； optimize table t 等于 recreate+analyze]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.1 Python 语言的性能优化工具]]></title>
    <url>%2F2020%2F03%2F02%2Flinux_perf%2F61_python%E8%AF%AD%E8%A8%80%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[参考 pyflame python 性能分析 manpage-perf-python]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 MySQL 如何保证数据不丢失]]></title>
    <url>%2F2020%2F03%2F02%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F02_mysql%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E5%A4%B1%2F</url>
    <content type="text"><![CDATA[redo log，bin log 的写入流程 前面我们介绍了 WAL 机制，得到的结论是：只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。今天，我们就再一起看看 MySQL 写入 binlog 和 redo log 的流程，看看 MySQL 是如何保证数据不丢失的。 1. binlog 写入机制binlog 的写入逻辑比较简单：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。 整个写入的过程如上图，可以看出: 每个线程有自己 binlog cache，但是共用同一份 binlog 文件。 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS write 和 fsync 的时机，是由参数 sync_binlog 控制的： write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。 但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。 2. redolog 写入机制事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的: redo log buffer 里面的内容，每次生成后不要要直接持久化到磁盘，如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。 事务还没提交的时候，redo log buffer 中的部分日志可能被持久化到磁盘 2.1 redolog 的三种状态 redolog 有三种状态: 存在 redo log buffer 中，物理上是在 MySQL 进程内存中，就是图中的红色部分； 写到磁盘 (write)，但是没有持久化（fsync)，物理上是在文件系统的 page cache 里面，也就是图中的黄色部分 持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分，持久化到磁盘相对于写入 buffer 和 page 要慢的多 innodb_flush_log_at_trx_commit 控制了 redo log 的写入策略: 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。 实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。 我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。 如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。 每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。 3. 组提交机制3.1 LSN日志逻辑序列号（log sequence number，LSN）是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log， LSN 的值就会加上 length。LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。 如图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。 从图中可以看到 trx1 是第一个到达的，会被选为这组的 leader； 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160； trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘； 这时候 trx2 和 trx3 就可以直接返回了。 以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。 我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的： 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件； 调用 fsync 持久化。 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这样： 这样，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。 不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。 如果你想提升 binlog 组提交的效果，可以通过设置一下两个参数实现: binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync; binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync 这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。 现在你就能理解了，WAL 机制主要得益于两个方面： redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快； 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。 4. MySQL 的 IO 性能优化如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？ 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。 不建议把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。 5. crash-safe 保证为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？MySQL 这么设计的主要原因是，binlog 是不能“被打断的”。一个事务的 binlog 必须连续写，因此要整个事务完成后，再一起写到文件里。 事务执行期间，还没到提交阶段，如果发生 crash 的话，redo log 肯定丢了，这会不会导致主备不一致呢？不会。因为这时候 binlog 也还在 binlog cache 里，没发给备库。crash 以后 redo log 和 binlog 都没有了，从业务角度看这个事务也没有提交，所以数据是一致的。binlog 在 binlog cache 不够时也只会写入临时文件中，而不会持久化 binlog file 中。 数据库的 crash-safe 保证的是： 如果客户端收到事务成功的消息，事务就一定持久化了； 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了； 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。 6. 双非 “1” 配置存在下列场景时，线上生产库会设置成“非双 1”: 业务高峰期。一般如果有预知的高峰期，DBA 会有预案，把主库设置成“非双 1” 备库延迟，为了让备库尽快赶上主库 用备份恢复主库的副本，应用 binlog 的过程，这个跟上一种场景类似 批量导入数据的时候 一般情况下，把生产库改成“非双 1”配置，是设置 innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 MYSQL 基础架构]]></title>
    <url>%2F2020%2F03%2F01%2Fmysql%2FMySQL%E5%AE%9E%E6%88%9845%E8%AE%B2%2F01_mysql%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[一条 SQL 查询语句是如何执行的，一条更新语句又是如何执行的 今天是本系列的第一篇文章，借由MySQL查询和更新语句的执行，我们来说一说 MySQL 的一些重要的概念。内容包括: 查询语句的执行，我们说聊聊 MySQL 的基础架构 更新语句的执行，我们会介绍MySQL 非常重要的两个日志: redo log 和 bin log以及两阶段提交 与更新效率有关的 change buffer 此数据持久化相关的，刷脏页 1.查询语句的执行流程1.1 MySQL 基础架构上面是 MySQL 基础架构示意图。MySQL 可以分为 Server 层和存储引擎层两部分: Server 包括: 连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能 包含了所有的内置函数（如日期、时间、数学和加密函数等） 所有跨存储引擎的功能，比如存储过程、触发器、视图等都在这一层实现 存储引擎层: 负责数据的存储和提取 1.2 连接器连接器: 负责跟客户端建立连接、获取权限、维持和管理连接 权限获取: 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。 连接管理: 连接分为短连接，长连接，长时间空闲的链接连接称为空闲连接 空闲连接的保持时长由 wait_timeout 参数配置，默认为 8 小时，超时后连接就会自动断开 全部使用长连接后，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了，解决办法有如下两个: 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 MySQL&gt;=5.7，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 1.3 查询缓存查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。大多数情况下，建议按需启用查询缓存。 QUERY_CACHE_TYPE 配置参数用于控制是否启用查询缓存,可选值包括: OFF: 不启用，显示指定 SQL_CACHE 也不会缓存 ON: 启用，可以使用 SQL_NO_CACHE 显示指定不缓存查询结果 DEMAND: 按需启用，即可以使用 SQL_CACHE 显示指定缓存查询结果 MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。 1.4 分析器分析器，包括词法分析和语法分析，语法错误，会在此阶段爆出。 1.5 优化器优化器主要是优化SQL语句的执行: 在表里面有多个索引的时候，决定使用哪个索引 在一个语句有多表关联（join）的时候，决定各个表的连接顺序 1.6 执行器执行器负责执行语句 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限) 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 慢查询日志中记录有一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。 2.更新语句的执行流程首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。清除缓存这一步就是在分析器中执行的。与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。 2.1 redo log为了提高磁盘的IO效率，避免大规模的随机IO，MySQL 采用一种叫做 WAL 技术(Write-Ahead Logging)它的关键点就是先写日志，再写磁盘: 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log 里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做 InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头 checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos 和 checkpoint 之间是可用部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，这时候不能再执行新的更新，得停下来将数据更新到数据文件，把 checkpoint 推进一下 有了 redo log，InnoDB 既保证了即使数据库发生异常重启，之前提交的记录都不会丢失(数据已记录到文件，这个能力称为 crash-safe)，也避免了大规模的随机IO带来的效率低下。 2.2 bin logredo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。binlog 的主要作用有两个: 备份和数据恢复 主从同步的数据复制 bin log 与 redo log redo log 是物理日志，记录的是“在某个数据页上做了什么修改” binlog 是逻辑日志，记录的是这个语句的原始逻辑，用于数据归档。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志 2.3 Innodb 更新语句的执行流程1mysql&gt; update T set c=c+1 where ID=2; 我们以上面更新语句为例，来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。 浅色框表示是在 InnoDB 内部执行的 深色框表示是在执行器中执行的。 两阶段提交redo log 的写入拆成了两个步骤：prepare 和 commit，这就是”两阶段提交”。要明白为什么 redo log 需要使用两阶段提交，我们需要明白下面几点: redo log 与 bin log 存在的目的不同: redo log: 为了兼顾crash-safe 和IO效率 bin log: 是为了备份和数据 mysql 要保证已经提交 commit 的事务数据不能丢失，这就包括事务提交后，mysql 服务奔溃数据不丢失，误操作进行数据恢复时或主从同步时数据不丢失，前者是 redo log 保证的，后者是 binlog 保证，因此需要保证redo log 与 bin log 之间数据一致 两阶段提交的目的是为了让两份日志之间的逻辑一致。 redo log/bin log 如何保证奔溃恢复在上面更新语句的执行流程图中，标明了两阶段提交的两个不同时刻，我们来看看在两阶段提交的不同时刻，MySQL 异常重启会出现什么现象。 时刻A: 也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。 时刻 B: 也就是 binlog 写完，redo log 还没 commit 前发生 crash。我们先来看一下崩溃恢复时的判断规则: 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交； 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整： 如果是，则提交事务； 否则，回滚事务。时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。为什么这么设计，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。 2.4 一些常见问题bin log 是如何保证完整性的一个事务的 binlog 是有完整格式的： statement 格式的 binlog，最后会有 COMMIT； row 格式的 binlog，最后会有一个 XID event。 在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。 binlog redolog 是如何关联的它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log： 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交； 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。 binlog 为什么不能做奔溃恢复其中一个点是binlog 没有能力恢复“数据页”。假如事务提交了，也写入 binlog 了，但是数据在数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。redolog 是可以的，他记录了数据页的更新细节。 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。 数据是从哪落盘正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？ redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。 redo log 设置多大几个 TB 的磁盘的话，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。 redo log bufferredo log buffer 是什么？是先修改内存，还是先写 redo log 文件？ 在一个事务的更新过程中，日志是要写多次的，比如多次 insert。插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。 所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。 事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。 更新相同的值当 MySQL 去更新一行，但是要修改的值跟原来的值是相同的，这时候 MySQL 会真的去执行一次修改吗？还是看到值相同就直接返回呢？ MySQL 是否会更新，取决于MySQL是否读了数据，“读了数据，就会判断”。 update t set a=1 where id=1: 在这个语句里面，MySQL 认为读出来的值，只有一个确定的 (id=1), 而要写的是 (a=3)，只从这两个信息是看不出来“不需要修改” 因此InnoDB 认真执行了“把这个值修改成 (1,2)”这个操作，该加锁的加锁，该更新的更新。 update t set a=1 where id=1 and a=1: 在这个语句里面，MySQL 读出了 a 的值也做了判断 因此，Innodb 不会执行修改而是直接返回 面我们的验证结果都是在 binlog_format=statement 格式下进行的。如果是 binlog_format=row 并且 binlog_row_image=FULL 的时候，由于 MySQL 需要在 binlog 里面记录所有的字段，所以在读数据的时候就会把所有数据都读出来了。因此 update t set a=1 where id=1 中也会判断出 a=1，而不修改直接返回。同理，如果是 binlog_row_image=NOBLOB, 会读出除 blob 外的所有字段，在我们这个例子里，结果还是“返回 (1,2)”。 如果表中有 timestamp 字段而且设置了自动更新的话，那么更新“别的字段”的时候，MySQL 会读入所有涉及的字段，这样通过判断，就会发现不需要修改。 3. change buffer除了 redo log，bin log 为了提高IO效率，mysql 还有一个重要的组件 change buffer。要想理解 change buffer 的作用我们要回到在前面 Innodb 的更新流程中来。 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，需要先从磁盘读入内存，在执行更新操作。但是将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。 在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。 3.1 有 change buffer 的更新过程假设我们要执行下面的插入语句:1mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2); 我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图 2 所示是带 change buffer 的更新状态图。 更新语句涉及四个部分，内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、Innodb 全局表空间（ibdata1）。 t.ibd: 数据表空间存放着原始数据页 ibdata1: change buffer 在内存中有拷贝，也会被写入Innodb 的全局表空间中 如上图所示更新语句做了如下操作: Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4），注意两个动作在 redo log 记录的不同，一个是 To Page，一个是 new change buffer item 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。图中的两个虚线箭头，是后台操作，不影响更新的响应时间。 3.2 更新后的读请求我们现在要执行 select * from t where k in (k1, k2) 如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。 读 Page 1 的时候，直接从内存返回 要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。 写 redo log 包含了数据的变更和 change buffer 的变更。 可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。数据读入内存是需要占用 buffer pool 的，所以 changer buffer还能够避免占用内存，提高内存利用率。 3.3 merge 的执行流程上面我们介绍了单条记录 merge 的过程，但是 change buffer merge 的基本单位是磁盘页，merge 的执行流程是这样的： 从磁盘读入数据页到内存（老版本的数据页） 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个），依次应用，得到新版数据页； 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。 到这里 merge 过程就结束了。这时候，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。 3.4 changer buffer 的丢失问题如果某次写入使用了 change buffer 机制，之后主机异常重启，是否会丢失 change buffer 和数据。这个问题的答案是不会丢失，虽然是只更新内存，但是在事务提交的时候，我们把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。 3.5 changer buffer 适用场景因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 因此对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。对于此类不适用 change buffer 的场景，应该关闭 changer buffer。 特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。 4. 刷脏页通过上面的介绍，我们知道 InnoDB 在处理更新语句的时候，在更新内存写完 redo log 后，就返回给客户端，本次更新成功，数据并没有真正写入磁盘数据页。 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。 mysql 终究是要把数据写入磁盘数据页，对应的就是把内存里的数据写入磁盘的过程，术语就是 flush。不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而 MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。 4.1 什么时候会触发 flush有四种情况会触发 flush 刷脏页: InnoDB 的 redo log 写满了，这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。checkpoint 往前推进，就需要将对应的所有脏页都 flush 到磁盘上 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。 MySQL 认为系统“空闲”的时候 MySQL 正常关闭的情况，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快 我们一一来看这四种情况是如何触发 flush 刷脏页的 为什么淘汰内存时要 flush淘汰内存时必须刷脏页了，是因为如果刷脏页一定会写盘，就保证了每个数据页有两种状态： 一种是内存里存在，内存里就肯定是正确的结果，直接返回； 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样效率最高 4.2 flush 的性能影响redo log 写满这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。 因此 如果 redo log 文件设置的过小，这时候系统不得不停止所有更新，去推进 checkpoint。就会出现磁盘压力很小，但是数据库出现间歇性的性能下跌。，在这种情况下，连 change buffer 的优化也失效了。因为 checkpoint 一直要往前推，这个操作就会触发 merge 操作，然后又进一步地触发刷脏页操作； 内存不够用这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：第一种是，还没有使用的；第二种是，使用了并且是干净页；第三种是，使用了并且是脏页。InnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。 而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。 刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的： 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长； 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。 所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。 4.3 InnoDB 刷脏页的控制策略首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。 这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令： 1fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 因为没能正确地设置 innodb_io_capacity 参数，很可能会出现MySQL 的写入速度很慢，TPS 很低，但是数据库主机的 IO 压力并不大。如果这个是值设置的很低，InnoDB 认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。 InnoDB 的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是 redo log 写盘速度。InnoDB 会根据这两个因素先单独算出两个数字。 脏页比例innodb_max_dirty_pages_pct: 脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算的伪代码如下: 1234567F1(M)&#123; if M&gt;=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct;&#125; redo logInnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N) N 越大，算出来的值越大就好了。 刷盘速率根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。 4.3 脏页比例监控InnoDB 会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用 IO 资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到 MySQL“抖”了一下的原因。要尽量避免这种情况，你就要合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。 脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码： 123456mysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';mysql&gt; select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';mysql&gt; select @a/@b; 4.4 连带刷页在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。 innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。 找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了 4.5 内存淘汰脏页，对应的 redo log 的操作日志相关参数redo log innodb_flush_log_at_trx_commit: 作用: 事务提交之后多久更新 redo log 建议: 设置为 1 表示每次事务的 redo log 都直接持久化到磁盘。建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失 bin log sync_binlog: 作用: 表示事务提交之后多久更新 bin log 建议: 设置为 1 表示每次事务的 binlog 都持久化到磁盘。建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失 change buffer innodb_change_buffer_max_size: 作用: change buffer 用的是 buffer pool 里的内存，此参数用于控制 changer buffer 能够占用 buffer pool 最大百分比 示例: =50 表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 刷脏页 innodb_io_capacity: 设置磁盘的 IO 能力 innodb_max_dirty_pages_pct: 脏页比例的上线 innodb_flush_neighbors: 刷脏页时是否刷新邻居脏页]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>极客时间</tag>
        <tag>MySQL实战45讲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.3 案例-redis性能优化]]></title>
    <url>%2F2020%2F02%2F25%2Flinux_perf%2F53_redis%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节我们来介绍一个Redis性能优化的案例。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.3 案例-MySQL性能优化]]></title>
    <url>%2F2020%2F02%2F24%2Flinux_perf%2F52_mysql%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节我们来介绍一个MySQL性能优化的案例。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.2 案例-容器问题]]></title>
    <url>%2F2020%2F02%2F23%2Flinux_perf%2F51_%E5%AE%B9%E5%99%A8%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[本节我们来学习Linux性能优化的第二个案例容器问题。来自极客时间专栏-Linux性能优化实战-46讲 1. 容器问题简介容器封装了环境了依赖，给运维部署带来了非常大的遍历。但是任何技术都不是银弹。这些新技术，在带来诸多便捷功能之外，也带来了更高的复杂性，比如性能降低、架构复杂、排错困难等等。 容器对应用程序的影响体现在以下几个方面: 容器本身通过 cgroups 进行资源隔离，所以，在分析时要考虑 cgroups 对应用程序的影响。 容器的文件系统、网络协议栈等跟主机隔离。虽然在容器外面，我们也可以分析容器的行为，不过有时候，进入容器的命名空间内部，可能更为方便。 资源隔离导致的另一个问题是，很多动态追踪工具因为获取不到应用程序的符号链接文件，而我们通常也不会在容器内安装过多的性能排查工具，这样就导致了排查问题受阻 容器的运行可能还会依赖于其他组件，比如各种网络插件（比如 CNI）、存储插件（比如 CSI）、设备插件（比如 GPU）等，让容器的性能分析更加复杂。如果你需要分析容器性能，别忘了考虑它们对性能的影响。 1.1 案例准备本节我们使用一个 tomcat 服务器作为实例，来看看容器对服务的影响。 12345678# 1. 镜像准备git clone https://github.com/feiskyer/linux-perf-examples.gitcd tomcatcd natsudo make build# 2. 容器启动$ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8 docker 命令参数: -m 512M: 限制容器内存为 512M –cpus 0.1: 限制容器的 CPU 使用率 1.2 问题发现容器启动后，我们去请求 tomcat 服务: 1234567891011121314151617181920212223242526272829303132# 1. 请求tomcat 服务$ curl localhost:8080curl: (56) Recv failure: Connection reset by peer# 2. 查看 tomcat 容器日志$ docker logs -f tomcatUsing CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /docker-java-home/jreUsing CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar# 3. 查看 tomcat 容器状态$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0f2b3fcdd257 feisky/tomcat:8 "catalina.sh run" 2 minutes ago Exited (137) About a minute ago tomcat# 显示容器状态，jq用来格式化json输出$ docker inspect tomcat -f '&#123;&#123;json .State&#125;&#125;' | jq&#123; "Status": "exited", "Running": false, "Paused": false, "Restarting": false, "OOMKilled": true, "Dead": false, "Pid": 0, "ExitCode": 137, "Error": "", ...&#125; 上面列示的命令是我们查看容器服务常用的命令。显然容器已经被 OOMKilled 了。问题是我们为 tomcat 分配了 512M 内存，大于 tomcat 应用所需的内存256M(容器内的 tomcat 程序只申请了一个 256M 的数组)，为什么容器会 OOMKilled 呢？ 1.3 dmesg 查看 OOM 异常系统会把相关的 OOM 信息，记录到日志中，通过 dmesg 命令我们可以定位 OOM 的异常信息: 12345678910111213141516171819202122232425262728293031323334353637$ dmesg[193038.106393] java invoked oom-killer: gfp_mask=0x14000c0(GFP_KERNEL), nodemask=(null), order=0, oom_score_adj=0[193038.106396] java cpuset=0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 mems_allowed=0[193038.106402] CPU: 0 PID: 27424 Comm: java Tainted: G OE 4.15.0-1037 #39-Ubuntu[193038.106404] Hardware name: Microsoft Corporation Virtual Machine/Virtual Machine, BIOS 090007 06/02/2017[193038.106405] Call Trace:[193038.106414] dump_stack+0x63/0x89[193038.106419] dump_header+0x71/0x285[193038.106422] oom_kill_process+0x220/0x440[193038.106424] out_of_memory+0x2d1/0x4f0[193038.106429] mem_cgroup_out_of_memory+0x4b/0x80 # 内存超 cgroups 限制[193038.106432] mem_cgroup_oom_synchronize+0x2e8/0x320[193038.106435] ? mem_cgroup_css_online+0x40/0x40[193038.106437] pagefault_out_of_memory+0x36/0x7b[193038.106443] mm_fault_error+0x90/0x180[193038.106445] __do_page_fault+0x4a5/0x4d0[193038.106448] do_page_fault+0x2e/0xe0[193038.106454] ? page_fault+0x2f/0x50[193038.106456] page_fault+0x45/0x50[193038.106459] RIP: 0033:0x7fa053e5a20d[193038.106460] RSP: 002b:00007fa0060159e8 EFLAGS: 00010206[193038.106462] RAX: 0000000000000000 RBX: 00007fa04c4b3000 RCX: 0000000009187440[193038.106463] RDX: 00000000943aa440 RSI: 0000000000000000 RDI: 000000009b223000[193038.106464] RBP: 00007fa006015a60 R08: 0000000002000002 R09: 00007fa053d0a8a1[193038.106465] R10: 00007fa04c018b80 R11: 0000000000000206 R12: 0000000100000768[193038.106466] R13: 00007fa04c4b3000 R14: 0000000100000768 R15: 0000000010000000[193038.106468] Task in /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53 killed as a result of limit of /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53[193038.106478] memory: usage 524288kB, limit 524288kB, failcnt 77[193038.106480] memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0[193038.106481] kmem: usage 3708kB, limit 9007199254740988kB, failcnt 0[193038.106481] Memory cgroup stats for /docker/0f2b3fcdd2578165ea77266cdc7b1ad43e75877b0ac1889ecda30a78cb78bd53: cache:0KB rss:520580KB rss_huge:450560KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:520580KB inactive_file:0KB active_file:0KB unevictable:0KB[193038.106494] [ pid ] uid tgid total_vm rss pgtables_bytes swapents oom_score_adj name[193038.106571] [27281] 0 27281 1153302 134371 1466368 0 0 java[193038.106574] Memory cgroup out of memory: Kill process 27281 (java) score 1027 or sacrifice child[193038.148334] Killed process 27281 (java) total-vm:4613208kB, anon-rss:517316kB, file-rss:20168kB, shmem-rss:0kB[193039.607503] oom_reaper: reaped process 27281 (java), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB total-vm:4613208kB, anon-rss:517316kB, file-rss:20168kB 表示总的虚拟内存，匿名页常驻内存和页缓存。为什么 Tomcat 会申请这么多的堆内存呢？ 1.4 JVM 配置问题 JVM 根据系统的内存总量，来自动管理堆内存，不明确配置的话，堆内存的默认限制是物理内存的四分之一。 1234567891011# 重新启动容器$ docker rm -f tomcat$ docker run --name tomcat --cpus 0.1 -m 512M -p 8080:8080 -itd feisky/tomcat:8# 查看堆内存，注意单位是字节$ docker exec tomcat java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 132120576 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 2092957696 &#123;product&#125; 可以看到，初始堆内存的大小（InitialHeapSize）是 126MB，而最大堆内存则是 1.95GB，这可比容器限制的 512 MB 大多了。 之所以会这么大，其实是因为，容器内部看不到 Docker 为它设置的内存限制。虽然我们限制了容器的最大内存 512M，但是，从容器内部看到的限制，却并不是 512M。 1234$ docker exec tomcat free -m total used free shared buff/cache availableMem: 7977 521 1941 0 5514 7148Swap: 0 0 0 问题找到了，现在只要给 JVM 正确配置内存限制为 512M 就可以了。 1234# 删除问题容器$ docker rm -f tomcat# 运行新的容器$ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8 在 Docker 容器中运行 Java 应用，一定要确保，在设置容器资源限制的同时，配置好 JVM 的资源选项（比如堆内存等）。当然，如果你可以升级 Java 版本，那么升级到 Java 10 ，就可以自动解决类似问题了。 1.5 CPU 限制问题现在我们重新测试，看看 tomcat 服务是否已经正常: 123456789101112131415161718# 请求 tomcat 服务$ for ((i=0;i&lt;30;i++)); do curl localhost:8080; sleep 1; donecurl: (56) Recv failure: Connection reset by peercurl: (56) Recv failure: Connection reset by peerHello, wolrd!Hello, wolrd!Hello, wolrd!# 查看容器日志$ docker logs -f tomcat...18-Feb-2019 12:52:00.823 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/usr/local/tomcat/webapps/manager]18-Feb-2019 12:52:01.422 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/usr/local/tomcat/webapps/manager] has finished in [598] ms18-Feb-2019 12:52:01.920 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["http-nio-8080"]18-Feb-2019 12:52:02.323 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["ajp-nio-8009"]18-Feb-2019 12:52:02.523 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 22798 ms 日志显示 tomcat 启动过程，居然需要 22 秒。那么 tomcat 启动过程到底慢在哪呢？top 应该是我们很自然想到的第一个命令，但是我们需要查看的仅仅是 tomcat 服务，所以我们可以使用 pidstat 命令。 12345678910111213141516# 删除旧容器$ docker rm -f tomcat# 运行新容器$ docker run --name tomcat --cpus 0.1 -m 512M -e JAVA_OPTS='-Xmx512m -Xms512m' -p 8080:8080 -itd feisky/tomcat:8# 查询新容器中进程的Pid$ PID=$(docker inspect tomcat -f '&#123;&#123;.State.Pid&#125;&#125;')# 执行 pidstat$ pidstat -t -p $PID 112:59:28 UID TGID TID %usr %system %guest %wait %CPU CPU Command12:59:29 0 29850 - 10.00 0.00 0.00 0.00 10.00 0 java12:59:29 0 - 29850 0.00 0.00 0.00 0.00 0.00 0 |__java12:59:29 0 - 29897 5.00 1.00 0.00 86.00 6.00 1 |__java...12:59:29 0 - 29905 3.00 0.00 0.00 97.00 3.00 0 |__java12:59:29 0 - 29906 2.00 0.00 0.00 49.00 2.00 1 |__java12:59:29 0 - 29908 0.00 0.00 0.00 45.00 0.00 0 |__java 输出显示等待运行的使用率（%wait）非常高，这说明，这些线程大部分时间都在等待调度，而不是真正的运行。原因很简单，因为我们设置了 --cpus 0.1 的限制。所以放开 CPU 限制即可解决 tomcat 启动慢的问题。 在容器云的环境，我们通常都要预先评估应用程序的性能，然后据此设置容器的资源限制。没有资源限制，意味着容器可以占用整个系统的资源。这样，一旦任何应用程序发生异常，就可能拖垮整个环境。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.1 案例-NAT 优化和丢包分析]]></title>
    <url>%2F2020%2F02%2F22%2Flinux_perf%2F50_NAT%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节我们来学习Linux性能优化的第一个案例 NAT 优化。来自极客时间专栏-Linux性能优化实战-42讲 1. NAT 基础Linux 内核提供的 Netfilter 框架，允许对网络数据包进行修改（比如 NAT）和过滤（比如防火墙）。所以所谓防火墙并不是一个服务，而一个内核功能。而iptables、ip6tables、ebtables 等工具是管理和配置 Netfilter 上规则的工具。Netfilter 同样也是 LVS 四层负载均衡的基础 要掌握 iptables 的原理和使用方法，最核心的就是高清楚 Netfilter 的工作流向，即所谓的四表五链。下面是 Netfilter 工作流向的示意图 说明: 绿色背景的方框，表示表（table） 跟 table 一起的白色背景方框，则表示链（chain） 灰色的 conntrack ，表示连接跟踪模块。 conntrack 通过内核中的连接跟踪表（也就是哈希表），记录网络连接的状态，是 iptables 状态过滤（-m state）和 NAT 的实现基础。通过 conntrack 命令可以查看系统当前的连接跟踪表。内核的连接跟踪模块在维护每个连接状态的同时，也会带来很高的性能成本。 在使用 iptables 配置 NAT 规则时，Linux 需要转发来自其他 IP 的网络包，所以你千万不要忘记开启 Linux 的 IP 转发功能。 12$ sysctl net.ipv4.ip_forwardnet.ipv4.ip_forward = 1 2. NAT 优化我们准备两个服务: 一个是通过 host NetWork 直接启动的Nginx 服务，作为测试的基准，即对照组 一个是通过 Docker NAT 启动的Nginx 服务作为实现组 2.1 对照组1234567891011121314151617181920212223242526272829# 1. 镜像准备git clone https://github.com/feiskyer/linux-perf-examples.gitcd linux-perf-examplescd natsudo make build# 2. 运行对照组的Nginx 服务docker run --name nginx-hostnet --privileged --network=host -itd feisky/nginx:80curl 192.168.1.18# 3. 更改 文件描述符限制，默认只有 1024# 临时修改ulimit -n 65536# 永久修改vi /etc/security/limits.conf# 3. 执行 ab 基准测试# -c表示并发请求数为5000，-n表示总的请求数为10万# -r表示套接字接收错误时仍然继续执行，-s表示设置每个请求的超时时间为2s yum install httpd-toolsab -c 2000 -n 10000 -r -s 2 http://192.168.1.18/....Total transferred: 8450000 bytesHTML transferred: 6120000 bytesRequests per second: 5291.69 [#/sec] (mean)Time per request: 377.951 [ms] (mean)....# 4. 停止服务docker rm -f nginx-hostnet 2.2 实验组服务1234567891011# 1. 启动实验组服务$ docker run --name nginx --privileged -p 8080:8080 -itd feisky/nginx:natcurl http://192.168.1.18:8080/# 2. 查看 NAT 规则iptables -nL -t nat# 3. ab 测试ab -c 2000 -n 10000 -r -s 2 http://192.168.1.18:8080/...Benchmarking 192.168.1.18 (be patient)apr_pollset_poll: The timeout specified has expired (70007) 2.3 追踪内核丢包实验组并发请求数大大降低，根据前面介绍的 NAT 原理，我们有理由相信内核发生了丢包。下面我们使用Systemtap来跟踪内核的kfree_skb。Systemtap 中 kernel.trace(“kfree_skb”)表示内核释放了一个网络缓冲区的事件。 创建一个 dropwatch.stp 的脚本文件1234567891011121314151617181920212223242526272829#! /usr/bin/env stap############################################################# Dropwatch.stp# Author: Neil Horman &lt;nhorman@redhat.com&gt;# An example script to mimic the behavior of the dropwatch utility# http://fedorahosted.org/dropwatch############################################################# Array to hold the list of drop points we findglobal locations# Note when we turn the monitor on and offprobe begin &#123; printf("Monitoring for dropped packets\n") &#125;probe end &#123; printf("Stopping dropped packet monitor\n") &#125;# increment a drop counter for every location we drop atprobe kernel.trace("kfree_skb") &#123; locations[$location] &lt;&lt;&lt; 1 &#125;# Every 5 seconds report our drop locationsprobe timer.sec(5)&#123; printf("\n") foreach (l in locations-) &#123; printf("%d packets dropped at %s\n", @count(locations[l]), symname(l)) &#125; delete locations&#125; 执行 kfree_skb 动态追踪 123456789101112# 1. 执行 stap 动态追踪脚本$ stap --all-modules dropwatch.stp# 2. 执行 ab 测试，过一会就能看到上面 stap 脚本的输出$ ab -c 5000 -n 10000 -r -s 30 http://192.168.1.18:8080/# 3. dropwatch.stp 的输出6120 packets dropped at nf_hook_slow436 packets dropped at tcp_rcv_state_process374 packets dropped at tcp_v4_rcv10 packets dropped at netlink_broadcast_filtered3 packets dropped at unix_stream_connect 大量丢包都发生在 nf_hook_slow 位置，我们还得再跟踪 nf_hook_slow 的执行过程。可以使用 stap，更简单的是通过 perf 来完成。 2.4 跟踪 nf_hook_slow 执行过程123456789$ ab -c 5000 -n 10000 -r -s 30 http://192.168.0.30:8080/# 使用 perf 记录函数调用堆栈$ perf record -a -g -- sleep 30# 进入 perf 交互界面，输入查找命令 / 然后，在弹出的对话框中，输入 nf_hook_slow$ perf report -g graph,0# 实际: 实际情况是进入 nf_hook_slow 后看到的都是十六进制符号，而不是函数名，说明符号链接出现了问题。 进入 nf_hook_slow 调用栈，我们可以看到下面的调用栈: 可以看到，nf_hook_slow 调用最多的有三个地方: ipv4_conntrack_in: 接收网络包时，在连接跟踪表中查找连接，并为新的连接分配跟踪对象（Bucket） br_nf_pre_routing: 在 Linux 网桥中转发包。这是因为案例 Nginx 是一个 Docker 容器，而容器的网络通过网桥来实现； iptable_nat_ipv4_in: 接收网络包时，执行 DNAT，即把 8080 端口收到的包转发给容器 这三个来源，都是 Linux 的内核机制，所以接下来的优化，自然也是要从内核入手。 2.5 conntrack 内核参数使用 sysctl 可以查看内核选项的各种参数，我们可以先看看，内核提供了哪些 conntrack 的配置选项。12345678$ sysctl -a | grep conntracknet.netfilter.nf_conntrack_count = 180net.netfilter.nf_conntrack_max = 1000net.netfilter.nf_conntrack_buckets = 65536net.netfilter.nf_conntrack_tcp_timeout_syn_recv = 60net.netfilter.nf_conntrack_tcp_timeout_syn_sent = 120net.netfilter.nf_conntrack_tcp_timeout_time_wait = 120... 最重要的有三个: net.netfilter.nf_conntrack_count，表示当前连接跟踪数； net.netfilter.nf_conntrack_max，表示最大连接跟踪数； net.netfilter.nf_conntrack_buckets，表示连接跟踪表的大小。 并发请求数是 5000，而请求数是 100000。显然，跟踪表设置成，只记录 1000 个连接，是远远不够的。 实际上，内核在工作异常时，会把异常信息记录到日志中。比如前面的 ab 测试，内核已经在日志中报出了 “nf_conntrack: table full” 的错误。执行 dmesg 命令，你就可以看到： 123456$ dmesg | tail[104235.156774] nf_conntrack: nf_conntrack: table full, dropping packet[104243.800401] net_ratelimit: 3939 callbacks suppressed[104243.800401] nf_conntrack: nf_conntrack: table full, dropping packet[104262.962157] nf_conntrack: nf_conntrack: table full, dropping packet 其中，net_ratelimit 表示有大量的日志被压缩掉了，这是内核预防日志攻击的一种措施。而当你看到 “nf_conntrack: table full” 的错误时，就表明 nf_conntrack_max 太小了。 接下来，我们将 nf_conntrack_max 改大一些，比如改成 131072（即 nf_conntrack_buckets 的 2 倍）： 12$ sysctl -w net.netfilter.nf_conntrack_max=131072$ sysctl -w net.netfilter.nf_conntrack_buckets=65536 然后再切换到终端二中，重新执行 ab 命令。 2.6 查看链接追踪表conntrack 命令行工具，来查看连接跟踪表的内容12345678910111213141516171819# -L表示列表，-o表示以扩展格式显示$ conntrack -L -o extend|headipv4 2 tcp 6 27 TIME_WAIT src=192.168.1.18 dst=192.168.1.18 sport=60162 dport=8080 src=172.17.0.2 dst=192.168.1.18 sport=8080 dport=60162 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 use=1ipv4 2 tcp 6 27 TIME_WAIT src=192.168.1.18 dst=192.168.1.18 sport=60398 dport=8080 src=172.17.0.2 dst=192.168.1.18 sport=8080 dport=60398 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 use=1# 统计总的连接跟踪数$ conntrack -L -o extended | wc -l# 统计TCP协议各个状态的连接跟踪数$ conntrack -L -o extended | awk '/^.*tcp.*$/ &#123;sum[$6]++&#125; END &#123;for(i in sum) print i, sum[i]&#125;'conntrack v1.4.4 (conntrack-tools): 13852 flow entries have been shown.CLOSE 2075ESTABLISHED 4SYN_SENT 3579TIME_WAIT 8192# 统计各个源IP的连接跟踪数$ conntrack -L -o extended | awk '&#123;print $7&#125;' | cut -d "=" -f 2 | sort | uniq -c | sort -nr | head -n 10 可以看到，大部分 TCP 的连接跟踪，都处于 TIME_WAIT 状态，这些处于 TIME_WAIT 的连接跟踪记录，会在超时后清理，而默认的超时时间是 120s，你可以执行下面的命令来查看： 12$ sysctl net.netfilter.nf_conntrack_tcp_timeout_time_waitnet.netfilter.nf_conntrack_tcp_timeout_time_wait = 120 所以，如果你的连接数非常大，确实也应该考虑，适当减小超时时间。更多 conntrack 选项参见nf_conntrack文档 2.7 总结Linux 这种通过连接跟踪机制实现的 NAT，也常被称为有状态的 NAT，而维护状态，也带来了很高的性能成本。所以，除了调整内核行为外，在不需要状态跟踪的场景下（比如只需要按预定的 IP 和端口进行映射，而不需要动态映射），我们也可以使用无状态的 NAT （比如用 tc 或基于 DPDK 开发），来进一步提升性能。 3. 网络丢包分析前面我们分析了由于连接跟踪导致的网络丢包，但这只是网络丢包众多原因中的一个。如下图所示，可能发生丢包的位置，实际上贯穿了整个网络协议栈 从下往上: 在两台 VM 连接之间，可能会发生传输失败的错误，比如网络拥塞、线路错误等； 在网卡收包后，环形缓冲区可能会因为溢出而丢包； 在链路层，可能会因为网络帧校验失败、QoS 等而丢包； 在 IP 层，可能会因为路由失败、组包大小超过 MTU 等而丢包； 在传输层，可能会因为端口未监听、资源占用超过内核限制等而丢包； 在套接字层，可能会因为套接字缓冲区溢出而丢包； 应用层，可能会因为应用程序异常而丢包； 此外，如果配置了 iptables 规则，这些网络包也可能因为 iptables 过滤规则而丢包。 3.1 实践案例本次我们使用一个存在丢包的 Nginx 服务作为案例。 123456789101112131415161718192021# 1. 镜像构建git clone https://github.com/feiskyer/linux-perf-examples.gitcd linux-perf-examplescd packet-dropsudo make buildmake run# 2. 问题发现，验证 nginx 服务是否可以访问# -c表示发送10个请求，-S表示使用TCP SYN，-p指定端口为80$ hping3 -c 10 -S -p 80 192.168.0.30HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data byteslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=5120 rtt=7.5 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=5120 rtt=7.4 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=3.3 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=5120 rtt=3.0 ms# 3s 的 RTT ，很可能是因为丢包后重传导致的len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=3027.2 ms--- 192.168.0.30 hping statistic ---10 packets transmitted, 5 packets received, 50% packet loss # 50% 丢包round-trip min/avg/max = 3.0/609.7/3027.2 ms 接下来我们就按照上面的排查思路，看看到底是哪里发生了丢包？ 3.2 链路层网卡丢包首先，来看最底下的链路层。当缓冲区溢出等原因导致网卡丢包时，Linux 会在网卡收发数据的统计信息中，记录下收发错误的次数。通过 ethtool 或者 netstat ，来查看网卡的丢包记录。 12345root@nginx:/# netstat -iKernel Interface tableIface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgeth0 100 31 0 0 0 8 0 0 0 BMRUlo 65536 0 0 0 0 0 0 0 0 LRU RX-OK、RX-ERR、RX-DRP、RX-OVR ，分别表示接收时的总包数、总错误数、进入 Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。 netstat -i 的输出表明容器的虚拟网卡没有丢包。 注意，由于 Docker 容器的虚拟网卡，实际上是一对 veth pair，一端接入容器中用作 eth0，另一端在主机中接入 docker0 网桥中。veth 驱动并没有实现网络统计的功能，所以使用 ethtool -S 命令，无法得到网卡收发数据的汇总信息。 Qos接下来，我们还要检查一下 eth0 上是否配置了 tc 规则，并查看有没有丢包。 1234root@nginx:/# tc -s qdisc show dev eth0qdisc netem 800d: root refcnt 2 limit 1000 loss 30% Sent 432 bytes 8 pkt (dropped 4, overlimits 0 requeues 0) backlog 0b 0p requeues 0 tc 输出显示， eth0 上面配置了一个网络模拟排队规则（qdisc netem），并且配置了丢包率为 30%（loss 30%）。netem 模块导致了 Nginx 丢包，我们直接删掉 netem 模块就可以 1234567891011121314root@nginx:/# tc qdisc del dev eth0 root netem loss 30%$ hping3 -c 10 -S -p 80 192.168.0.30HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data byteslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=5120 rtt=7.9 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=2 win=5120 rtt=1003.8 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=5120 rtt=7.6 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=5120 rtt=7.4 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=5120 rtt=3.0 ms--- 192.168.0.30 hping statistic ---10 packets transmitted, 5 packets received, 50% packet lossround-trip min/avg/max = 3.0/205.9/1003.8 ms 但是 hping3 显示丢包问题仍然存在。既然链路层已经排查完了，我们就继续向上层分析，看看网络层和传输层有没有问题。 3.3 网络层和传输层netstat -s，可以查看各网络协议的收发汇总，以及错误信息: 123456789101112131415161718192021222324252627282930313233343536root@nginx:/# netstat -sIp: Forwarding: 1 //开启转发 31 total packets received //总收包数 0 forwarded //转发包数 0 incoming packets discarded //接收丢包数 25 incoming packets delivered //接收的数据包数 15 requests sent out //发出的数据包数Icmp: 0 ICMP messages received //收到的ICMP包数 0 input ICMP message failed //收到ICMP失败数 ICMP input histogram: 0 ICMP messages sent //ICMP发送数 0 ICMP messages failed //ICMP失败数 ICMP output histogram:Tcp: 0 active connection openings //主动连接数 0 passive connection openings //被动连接数 11 failed connection attempts //失败连接尝试数 + 0 connection resets received //接收的连接重置数 0 connections established //建立连接数 25 segments received //已接收报文数 21 segments sent out //已发送报文数 4 segments retransmitted //重传报文数 0 bad segments received //错误报文数 0 resets sent //发出的连接重置数Udp: 0 packets received ...TcpExt: 11 resets received for embryonic SYN_RECV sockets //半连接重置数 + 0 packet headers predicted TCPTimeouts: 7 //超时数 + TCPSynRetrans: 4 //SYN重传数 + ... TCP 协议有多次超时和失败重试，并且主要错误是半连接重置。换句话说，主要的失败，都是三次握手失败。netstat -s 告诉了我们出错的位置，但是没有告诉我们具体的出错原因，我们还要继续向下进行分析。 3.4 iptables除了网络层和传输层的各种协议，iptables 和内核的连接跟踪机制也可能会导致丢包。 连接追踪要确认是不是连接跟踪导致的问题，其实只需要对比当前的连接跟踪数和最大连接跟踪数即可。 12345678910# 容器终端中执行exit，连接追踪是操作系统级的，需要在宿主机上查看root@nginx:/# exitexit# 主机终端中查询内核配置$ sysctl net.netfilter.nf_conntrack_maxnet.netfilter.nf_conntrack_max = 262144$ sysctl net.netfilter.nf_conntrack_countnet.netfilter.nf_conntrack_count = 182 262144 &gt; 182 没有问题 iptables对于丢包问题来说，最大的可能就是被 filter 表中的规则给丢弃了。要弄清楚这一点，就需要我们确认，那些目标为 DROP 和 REJECT 等会弃包的规则，有没有被执行到。iptables -nvL 命令，查看各条规则的统计信息。 123456789101112131415# 在主机中执行$ docker exec -it nginx bash# 在容器中执行root@nginx:/# iptables -t filter -nvLChain INPUT (policy ACCEPT 25 packets, 1000 bytes) pkts bytes target prot opt in out source destination 6 240 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destinationChain OUTPUT (policy ACCEPT 15 packets, 660 bytes) pkts bytes target prot opt in out source destination 6 264 DROP all -- * * 0.0.0.0/0 0.0.0.0/0 statistic mode random probability 0.29999999981 statistic 模块，执行了 30% 的随机丢包。并且 pkts 显示的确有包被丢弃了。显然把这两条规则直接删除即可: 1234567891011121314root@nginx:/# iptables -t filter -D INPUT -m statistic --mode random --probability 0.30 -j DROProot@nginx:/# iptables -t filter -D OUTPUT -m statistic --mode random --probability 0.30 -j DROP$ hping3 -c 10 -S -p 80 192.168.0.30HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data byteslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=5120 rtt=11.9 mslen=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=1 win=5120 rtt=7.8 ms...len=44 ip=192.168.0.30 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=5120 rtt=15.0 ms--- 192.168.0.30 hping statistic ---10 packets transmitted, 10 packets received, 0% packet lossround-trip min/avg/max = 3.3/7.9/15.0 ms hping3 显示已经没有丢包了。不过，到目前为止，我们只能验证案例 Nginx 的 80 端口处于正常监听状态，却还没有访问 Nginx 的 HTTP 服务。 12$ curl --max-time 3 http://192.168.0.30curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received http 连接超时了，说明我们的服务还有问题。 3.5 应用层抓包对于应用层，抓包工具就是我们的大杀器了。 1234567891011121314151617181920# 1. 抓包root@nginx:/# tcpdump -i eth0 -nn port 80tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes# 2.发送请求$ curl --max-time 3 http://192.168.0.30/curl: (28) Operation timed out after 3000 milliseconds with 0 bytes received# 3. 抓包输出# seq14:40:00.589235 IP 10.255.255.5.39058 &gt; 172.17.0.2.80: Flags [S], seq 332257715, win 29200, options [mss 1418,sackOK,TS val 486800541 ecr 0,nop,wscale 7], length 0# ack14:40:00.589277 IP 172.17.0.2.80 &gt; 10.255.255.5.39058: Flags [S.], seq 1630206251, ack 332257716, win 4880, options [mss 256,sackOK,TS val 2509376001 ecr 486800541,nop,wscale 7], length 0# seq，ack 三次握手完成14:40:00.589894 IP 10.255.255.5.39058 &gt; 172.17.0.2.80: Flags [.], ack 1, win 229, options [nop,nop,TS val 486800541 ecr 2509376001], length 0# 时间超过 3 秒，客户端发起来断开连接请求 FIN14:40:03.589352 IP 10.255.255.5.39058 &gt; 172.17.0.2.80: Flags [F.], seq 76, ack 1, win 229, options [nop,nop,TS val 486803541 ecr 2509376001], length 0# 服务器端重复ACK14:40:03.589417 IP 172.17.0.2.80 &gt; 10.255.255.5.39058: Flags [.], ack 1, win 40, options [nop,nop,TS val 2509379001 ecr 486800541,nop,nop,sack 1 &#123;76:77&#125;], length 0 使用 Wireshark 显示TCP交互流程图: 服务器端回应了两次相同的ACK，说明中间出现了丢包。并且也没有看到 curl 发送的 GET 请求。那么，究竟是网卡丢包了，还是客户端压根儿就没发过来呢？ netstat -i 命令，确认一下网卡有没有丢包问题：12345root@nginx:/# netstat -iKernel Interface tableIface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgeth0 100 157 0 344 0 94 0 0 0 BMRUlo 65536 0 0 0 0 0 0 0 0 LRU 接收丢包数（RX-DRP）是 344。不过问题也来了，为什么刚才用 hping3 时不丢包，现在换成 GET 就收不到了呢？ 其实，仔细观察上面 netstat 的输出界面，第二列正是每个网卡的 MTU 值。eth0 的 MTU 只有 100，而以太网的 MTU 默认值是 1500。HTTP GET ，本质上也是一个 TCP 包，但跟 SYN 包相比，它还携带了 HTTP GET 的数据。因此其大小超过 MTU 所以被丢包了。 1root@nginx:/# ifconfig eth0 mtu 1500 修改完成后，再次执行 curl 命令，问题得到了解决。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.8 容器的性能分析工具]]></title>
    <url>%2F2020%2F02%2F18%2Flinux_perf%2F49_%E5%AE%B9%E5%99%A8%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[本节我们来介绍一些专门用于容器性能分析的工具。 1. 工具简介本节我们将介绍如下一些性能分析工具的使用: nsenter: 可以进入容器命名空间 sysdig: 用于容器的动态追踪，汇集了一些列性能工具的优势 2. nsenternsenter 作用: 可以进入容器命名空间 12345678910111213# 1. 安装docker run --rm -v /usr/local/bin:/target jpetazzo/nsenter# 2. 使用# 由于这两个容器共享同一个网络命名空间，所以我们只需要进入app的网络命名空间即可$ PID=$(docker inspect --format &#123;&#123;.State.Pid&#125;&#125; app)# -i表示显示网络套接字信息$ nsenter --target $PID --net -- lsof -iCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEredis-ser 9085 systemd-network 6u IPv4 15447972 0t0 TCP localhost:6379 (LISTEN)redis-ser 9085 systemd-network 8u IPv4 15448709 0t0 TCP localhost:6379-&gt;localhost:32996 (ESTABLISHED)python 9181 root 3u IPv4 15448677 0t0 TCP *:http (LISTEN)python 9181 root 5u IPv4 15449632 0t0 TCP localhost:32996-&gt;localhost:6379 (ESTABLISHED) 3. sysdig]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.8 systemtap-lwtools]]></title>
    <url>%2F2020%2F02%2F17%2Flinux_perf%2F48_systemtap_lwt%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.7 DTraceToolkit]]></title>
    <url>%2F2020%2F02%2F16%2Flinux_perf%2F47_DTraceToolkit%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.6 bcc]]></title>
    <url>%2F2020%2F02%2F15%2Flinux_perf%2F46_bcc%2F</url>
    <content type="text"><![CDATA[1. bcc 简介BCC 软件包是使用 eBPF 开发的工具包。这些工具是提供的编写 eBPF 工具的参考示例，并且很实用。它们的使用场景如下图所示： 不过需要注意的是很多 eBPF 的新特性，都需要比较新的内核版本（如下图所示） 1.2 安装123456# 注意：bcc-tools 需要内核版本为 4.1 或者更新的版本， CentOS，需要手动升级内核版本后再安装。yum install bcc -yrpm -ql bcc-tools# bcc 工具位于 /usr/share/bcc/tools/ 目录中cd /usr/share/bcc/tools/ 2. CPU 监测3. 内存监测3.1 cachestatcachestat [t [n]] 作用: 查看整个操作系统缓存的读写命中情况 参数: 123456$ cachestat 1 3 TOTAL MISSES HITS DIRTIES BUFFERS_MB CACHED_MB 2 0 2 1 17 279 2 0 2 1 17 279 2 0 2 1 17 279 指标含义: TOTAL: 表示总的 I/O 次数； MISSES: 表示缓存未命中的次数； HITS: 表示缓存命中的次数； DIRTIES: 表示新增到缓存中的脏页数； BUFFERS_MB: 表示 Buffers 的大小，以 MB 为单位； CACHED_MB: 表示 Cache 的大小，以 MB 为单位。 3.2 cachetopcachetop [interval] 作用: 类似 top，实时查看间隔时间内每个进程的缓存命中情况 输出: 默认按照缓存的命中次数（HITS）排序 说明: cachetop 并不会把直接 I/O 算进来。因此观察缓存命中率的同时，我们也需要注意 HITS 命中次数，看起是否匹配应用程序实际I/O大小，以免遗漏直接I/O造成的影响 12345$ cachetop11:58:50 Buffers MB: 258 / Cached MB: 347 / Sort: HITS / Order: ascendingPID UID CMD HITS MISSES DIRTIES READ_HIT% WRITE_HIT%13029 root python 1 0 0 100.0% 0.0% 指标含义: MISSES: 表示缓存未命中的次数； HITS: 表示缓存命中的次数； DIRTIES: 表示新增到缓存中的脏页数； READ_HIT: 表示读缓存命中率 WRITE_HIT: 表示写缓存命中率 3.3 memleakmemleak [t [c]] 作用: memleak 可以跟踪系统或指定进程的内存分配、释放请求，然后定期输出一个未释放内存和相应调用栈的汇总情况（默认 5 秒）。 参数: -p PID, –pid PID: 执行跟踪的进程，不指定跟踪内核的内存分配和释放 -a, –show-allocs: 表示显示每个内存分配请求的大小以及地址 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758./memleak -husage: memleak [-h] [-p PID] [-t] [-a] [-o OLDER] [-c COMMAND] [--combined-only] [-s SAMPLE_RATE] [-T TOP] [-z MIN_SIZE] [-Z MAX_SIZE] [-O OBJ] [--percpu] [interval] [count]Trace outstanding memory allocations that weren\'t freed.Supports both user-mode allocations made with libc functions and kernel-modeallocations made with kmalloc/kmem_cache_alloc/get_free_pages and correspondingmemory release functions.positional arguments: interval interval in seconds to print outstanding allocations count number of times to print the report before exitingoptional arguments: -h, --help show this help message and exit -p PID, --pid PID the PID to trace; if not specified, trace kernel allocs -t, --trace print trace messages for each alloc/free call -a, --show-allocs show allocation addresses and sizes as well as call stacks -o OLDER, --older OLDER prune allocations younger than this age in milliseconds -c COMMAND, --command COMMAND execute and trace the specified command --combined-only show combined allocation statistics only -s SAMPLE_RATE, --sample-rate SAMPLE_RATE sample every N-th allocation to decrease the overhead -T TOP, --top TOP display only this many top allocating stacks (by size) -z MIN_SIZE, --min-size MIN_SIZE capture only allocations larger than this size -Z MAX_SIZE, --max-size MAX_SIZE capture only allocations smaller than this size -O OBJ, --obj OBJ attach to allocator functions in the specified object --percpu trace percpu allocationsEXAMPLES:./memleak -p $(pidof allocs) Trace allocations and display a summary of "leaked" (outstanding) allocations every 5 seconds./memleak -p $(pidof allocs) -t Trace allocations and display each individual allocator function call./memleak -ap $(pidof allocs) 10 Trace allocations and display allocated addresses, sizes, and stacks every 10 seconds for outstanding allocations./memleak -c "./allocs" Run the specified command and trace its allocations./memleak Trace allocations in kernel mode and display a summary of outstanding allocations every 5 seconds./memleak -o 60000 Trace allocations in kernel mode and display a summary of outstanding allocations that are at least one minute (60 seconds) old./memleak -s 5 Trace roughly every 5th allocation, to reduce overhead 下面是 memleak 定位内存泄漏的一个示例:123456789101112$ /usr/share/bcc/tools/memleak -p $(pidof app) -aAttaching to pid 12512, Ctrl+C to quit.[03:00:41] Top 10 stacks with outstanding allocations: addr = 7f8f70863220 size = 8192 addr = 7f8f70861210 size = 8192 addr = 7f8f7085b1e0 size = 8192 addr = 7f8f7085f200 size = 8192 addr = 7f8f7085d1f0 size = 8192 40960 bytes in 5 allocations from stack fibonacci+0x1f [app] child+0x4f [app] start_thread+0xdb [libpthread-2.27.so] 4. 磁盘I/O分析4.1 filetopfiletop 作用: 主要跟踪内核中文件的读写情况，并输出线程 ID（TID）、读写大小、读写类型以及文件名称。 123456789101112131415# 切换到工具目录 $ cd /usr/share/bcc/tools # -C 选项表示输出新内容时不清空屏幕 $ ./filetop -C TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 0 1 0 2832 R 669.txt 514 python 0 1 0 2490 R 667.txt ...TID COMM READS WRITES R_Kb W_Kb T FILE 514 python 2 0 5957 0 R 651.txt 514 python 2 0 5371 0 R 112.txt 指标含义: 输出了 8 列内容，分别是线程 ID、线程命令行、读写次数、读写的大小（单位 KB）、文件类型以及读写的文件名称。 4.2 opensnoopopensnoop:s 作用: 动态跟踪内核中的 open 系统调用 1234$ opensnoop 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/650.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/651.txt 12280 python 6 0 /tmp/9046db9e-fe25-11e8-b13f-0242ac110002/652.txt 4.3 biosnoop4.4 biotop]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.5 perf-tool]]></title>
    <url>%2F2020%2F02%2F14%2Flinux_perf%2F45_perf_tool%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.3 ps]]></title>
    <url>%2F2020%2F02%2F13%2Flinux_perf%2F43_ps%2F</url>
    <content type="text"><![CDATA[ps 命令 psps [options] 作用：ps 用于查看进程状态信息 说明：ps 命令参数很乱，我们以常用命令的方式来说明其使用，下面只列出过滤参数 过滤参数: u user: 指定用户的所有进程 o [field1,field2…]: 指定显示的字段 k [-]field: 以指定字段排序 -h：去掉标题栏 -H: 显示线程详细信息 -f: 以树形结构显示进程间关系 pstree1234567# -t表示显示线程，-a表示显示命令行参数$ pstree -t -a -p 27458mysqld,27458 --log_bin=on --sync_binlog=1... ├─&#123;mysqld&#125;,27922 ├─&#123;mysqld&#125;,27923 └─&#123;mysqld&#125;,28014 ps aux fps aux f 作用：显示所有进程，并显示进程树 参数: a表示所有用户，u表示面向用户的扩展信息，x表示没有终端的进程 12345ps aux fUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 2 0.0 0.0 0 0 ? S Feb11 33:45 [kthreadd]root 3 0.0 0.0 0 0 ? S Feb11 2:21 \_ [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; Feb11 0:00 \_ [kworker/0:0H] 输出: PID: 进程ID %CPU: CPU 使用率 %MEM: 常驻内存占用百分比 VSZ: 虚拟内存大小 RSS: 常驻内存大小 TTY: 所属终端 STAT: 进程的状态： TIME: 进程使用的总cpu时间 COMMAND: 启动命令 说明: RSS 显示主存使用，它也包括如系统库在内的映射共享段，可能会被几十个进程共享。如果 RSS 求和，可能会发现超过系统可用内存，这是由于重复计算了共享内存。分析共享内存可以使用 pmap 命令。 ps -efTps -efT 作用: 显示所有线程信息 参数: e 表示所有进程，f 表示完整信息，T 表示显示线程 12345ps -efT|headUID PID SPID PPID C STIME TTY TIME CMDroot 1 1 0 0 11:44 ? 00:00:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 22root 2 2 0 0 11:44 ? 00:00:00 [kthreadd]root 3 3 2 0 11:44 ? 00:00:00 [ksoftirqd/0] 指标含义: SPID: 线程ID ps -eflps -efl 作用: 显示所有进程 参数: e 表示所有进程，f 表示完整信息 123ps -efl k -rss|head -10F S UID PID PPID C PRI NI ADDR SZ WCHAN STIME TTY TIME CMD4 S analyzer 58379 58363 99 80 0 - 585639778 futex_ Feb29 ? 30277:59 /opt/jdk-10.0.2/bin/java 输出: UID： 用户ID（effective User ID） PID： 进程ID（Process ID） PPID： 父进程的进程ID（Parent Process id） C: cpu 使用率，百分比但没有 % PRI：进程优先级 NI： Nice 值 ADDR： 这个是 kernel function，指出该程序在内存的那个部分。如果是个 running的程序，一般就是 “-“ SZ： 使用掉的内存大小 WCHAN： STIME： 启动时间 TTY： 与进程关联的终端（tty） TIME： 进程使用的总cpu时间 CMD： 正在执行的命令行命令 ps axZps axZ 作用: 显示进程的安全信息(selinux) 1234567ps axZ|head -10LABEL PID TTY STAT TIME COMMANDsystem_u:system_r:init_t:s0 1 ? Ss 138:29 /usr/lib/systemd/systemd --switched-root --system --deserialize 21system_u:system_r:kernel_t:s0 2 ? S 33:45 [kthreadd]system_u:system_r:kernel_t:s0 3 ? S 2:21 [ksoftirqd/0]system_u:system_r:kernel_t:s0 5 ? S&lt; 0:00 [kworker/0:0H]system_u:system_r:kernel_t:s0 8 ? S 3:23 [migration/0] 输出: label: selinux 的进程标识 ps axjfps axjf 作用: 显示进程树 123456ps axjf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 0 2 0 0 ? -1 S 0 33:46 [kthreadd] 2 3 0 0 ? -1 S 0 2:21 \_ [ksoftirqd/0] 2 5 0 0 ? -1 S&lt; 0 0:00 \_ [kworker/0:0H] 2 8 0 0 ? -1 S 0 3:23 \_ [migration/0] 输出: PPID: 父进程ID PID: 进程ID PGID: 进程组 ID，等于 leader 进程的pid SID: session id TTY: 进程关联的终端 TPGID: 后台进程组关联的终端id？ STAT: 进程状态 UID: effective User ID ps -eo自定义 ps 显示的列1234567ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,commps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,commps -Ao pid,tt,user,fname,tmout,f,wchanps -eo pid,maj_flt,min_flt # 显示主次缺页异常数 ps -U root -u root ups -U root -u root u 作用: 显示real user &amp; effective user 为 root 的进程 ps -C syslogd -o pid= 作用: 打印 syslogd 的进程 id ps -q 42 -o comm= 作用: 打印进程id 为 42 的进程名]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.4 pidstat]]></title>
    <url>%2F2020%2F02%2F13%2Flinux_perf%2F44.pidstat%2F</url>
    <content type="text"><![CDATA[pidstat 命令 pidstatpidstat options [ interval [ count ]] 作用: 监控全部或指定进程的cpu、内存、线程、设备IO等系统资源的占用情况 内容参数: -u：默认的参数，显示各个进程的cpu使用统计 -r：显示各个进程的内存使用统计 -d：显示各个进程的IO使用情况 -w：显示每个进程的上下文切换情况 -t：显示选择任务的线程的统计信息外的额外信息，显示线程统计信息时，必须使用 过滤参数: -l：显示命令名和所有参数 -p：指定进程号 -T { TASK | CHILD | ALL }这个选项指定了pidstat监控的。TASK表示报告独立的task，CHILD关键字表示报告进程下所有线程统计信息。ALL表示报告独立的task和task下面的所有线程。注意：task和子线程的全局的统计信息和pidstat选项无关。这些统计信息不会对应到当前的统计间隔，这些统计信息只有在子线程kill或者完成的时候才会被收集。 pid -u123456 pidstat -u 2 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU)04:34:07 PM UID PID %usr %system %guest %CPU CPU Command04:34:09 PM 0 926 0.51 0.00 0.00 0.51 0 python04:34:09 PM 0 1100 0.51 0.00 0.00 0.51 0 docker-containe 输出： UID: real user id PID: 进程ID %usr: 用户态 CPU 使用率，包括以低优先级运行的CPU时间(nice 时间)，但不包活运行虚拟化程序的时间 %system: 内核态 CPU 使用率 %guest: 运行虚拟化程序的 CPU 使用率 %CPU: 总的 CPU 占用率 CPU: Processor number to which the task is attached. Command: 进程的启动命令 pidstat -r1234567pidstat -r 2 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU)04:44:53 PM UID PID minflt/s majflt/s VSZ RSS %MEM Command04:44:55 PM 0 926 0.51 0.00 784756 37600 0.23 python04:44:55 PM 1000 3648 12.76 0.00 1132080 118140 0.73 node04:44:55 PM 0 8343 297.96 0.00 108496 1228 0.01 pidstat 输出： minflt/s: 每秒次缺页异常数 majflt/s: 每秒主缺页异常书 VSZ: 虚拟内存大小 RSS: 实际占用的物理内存大小 %MEM: 物理内存占用百分比 pidstat -d123456pidstat -d 2 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU)04:47:46 PM UID PID kB_rd/s kB_wr/s kB_ccwr/s Command04:47:48 PM 0 923 0.00 2.02 0.00 python04:47:48 PM 1000 2994 0.00 6.06 0.00 java 输出： kB_rd/s: 读请求速率，单位KB/s kB_wr/s: 写请求速率，单位KB/s kB_ccwr/s: 任务取消的写入磁盘的KB。当任务截断脏页时会发生 pidstat -w1234567pidstat -w 2 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/10/2020 _x86_64_ (1 CPU)04:52:37 PM UID PID cswch/s nvcswch/s Command04:52:39 PM 0 3 5.08 0.00 ksoftirqd/004:52:39 PM 0 9 92.39 0.00 rcu_sched04:52:39 PM 0 11 0.51 0.00 watchdog/0 输出： cswch/s: 每秒主动任务上下文切换数量 nvcswch/s: 每秒被动任务上下文切换数量]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.2 Sar]]></title>
    <url>%2F2020%2F02%2F12%2Flinux_perf%2F42_sar%2F</url>
    <content type="text"><![CDATA[sar 命令 1. sarsar [options] [-A] [-o file] t [n] 作用：查看系统各种使用信息 控制参数： -o file：将命令结果以二进制格式存放在文件中 t：采样间隔 =0 :表示统计系统启动以来的平均值 t被设置，n未被设置，会按照时间间隔循环输出 n：采样次数，可选，默认值是1 内容参数： -A：等于 -bBdFHqSvwWy -I SUM -m ALL -n ALL -r ALL -u ALL -I ALL -P ALL 显示所以内容 CPU统计信息: -u：CPU利用率 -q: 查看系统平均负载 -w: 统计任务创建和上下文切换 内存统计信息: -B：换页的统计信息 -H: 大页面统计信息 -r：内存使用率 -R: 内存分配和释放速率统计信息 -S: 交换空间统计信息 -W：swap分区交换速率统计信息 磁盘统计信息 -b：磁盘 IO 传送速率 -d：块使用信息 -I：中断统计信息 网络统计信息: -n: 统计网络使用情况 2. CPU 统计信息2.1 sar -usar -u -P { cpu_list | ALL } 作用：CPU利用率 -P { cpu_list | ALL }：选定要展示的 cpu，ALL 展示所有 CPU 及其合计 123456sar -u 1 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU)06:32:44 PM CPU %user %nice %system %iowait %steal %idle06:32:45 PM all 41.02 0.00 3.61 6.22 0.00 49.15Average: all 41.02 0.00 3.61 6.22 0.00 49.15 指标含义： CPU： %user：us，代表用户态 CPU 时间，包括应用运用虚拟化的时间 %usr：表用户态 CPU 时间，不包括应用运用虚拟化的时间 %nice：代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间 %system：代表内核态 CPU 时间，包括运行软终端，硬中断的时间 %sys：代表内核态 CPU 时间，不包括运行软终端，硬中断的时间 %iowait：wa，代表等待 I/O 的 CPU 时间 %steal：st，代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间 %idle：id，代表空闲时间。注意，它不包括等待 I/O 的时间（iowait） %irq：hi，代表处理硬中断的 CPU 时间 %softirq：si，代表处理软中断的 CPU 时间 %guest：代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间 %guest_nice：gnice，代表以低优先级运行虚拟机的时间 2.2 sar -qsar -q 作用: 查看平均负载1234567sar -q 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月01日 _x86_64_ (1 CPU)00时34分09秒 runq-sz plist-sz ldavg-1 ldavg-5 ldavg-15 blocked00时34分10秒 1 164 0.00 0.01 0.05 000时34分11秒 1 164 0.00 0.01 0.05 0平均时间: 1 164 0.00 0.01 0.05 0 指标含义: runq-sz: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 plist-sz: 任务队列中的任务总数 ldavg-1 最后1分钟的CPU平均负载 ldavg-5 最后5分钟的CPU平均负载 ldavg-15 最后15分钟的CPU平均负载 2.3 sar -w1234567sar -w 1Linux 3.10.0-957.el7.x86_64 (lv) 2020年06月03日 _x86_64_ (2 CPU)11时31分13秒 proc/s cswch/s11时31分14秒 0.00 136.0011时31分15秒 0.00 157.0011时31分16秒 0.00 142.57 指标含义: proc/s: 每秒创建的任务数(进程数) cswch/s: 每秒发生的上下文切换次数 3. 内存统计信息3.1 sar -B作用: 换页统计信息123456sar -B 2 1Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU)16:13:02 pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff16:13:04 0.00 0.00 30.50 0.00 14.50 0.00 0.00 0.00 0.00Average: 0.00 0.00 30.50 0.00 14.50 0.00 0.00 0.00 0.00 指标含义： pgpgin/s：操作系统每秒从磁盘换入的分页大小，单位 KB pgpgout/s：操作系统每秒从磁盘换出的分页大小，单位 KB fault/s：每秒的缺页异常，包括主次缺页异常(major + minor) majflt/s：每秒主缺页异常数(major 大小) pgfree/s：每秒放回空闲链表(free list)的页的数量 pgscank/s：kswapd 后台进程每秒扫描的分页数 pgscand/s：每秒直接扫描的分页数 pgsteal/s：为了满足其他内存需求，每秒从 cache 缓存中回收的分页数 – 包括页面及交换高速缓存 %vmeff：=(pgsteal / pgscan), 用于衡量分页的回收效率 高数值意味着成功从非活动列表回收了页(健康) 接近 100%：高数值，健康 接近 30%：标识虚拟内存很紧张，因为没有页可以被回收 =0：标识时间间隔内没有分页被扫描 内存分页机制: http://linuxperf.com/?p=97 https://www.jianshu.com/p/ea7ed85918ac 3.2 sar -H作用: 大页面统计信息1234567&gt; sar -H 1 422时14分00秒 kbhugfree kbhugused %hugused22时14分01秒 0 0 0.0022时14分02秒 0 0 0.0022时14分03秒 0 0 0.0022时14分04秒 0 0 0.00 指标含义: kbhugfree: 空闲大页面的大小 kbhugused: 已经使用的大页面 %hugused: 大页面使用百分比 3.3 sar -r作用: 内存使用率，包括页缓存和可回收的slab 缓存 123456sar -r 1 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU)07:14:04 PM kbmemfree kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty07:14:05 PM 721588 114505136 99.37 0 19673952 153573644 133.28 65880260 11269348 783372Average: 721588 114505136 99.37 0 19673952 153573644 133.28 65880260 11269348 783372 指标含义： kbmemfree:这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间. kbmemused:这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间. %memused:这个值是kbmemused和内存总量(不包括swap)的一个百分比. kbbuffers和kbcached:这两个值就是free命令中的buffer和cache. kbcommit:保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap)，估计值. %commit:这个值是kbcommit与内存总量(包括swap)的一个百分比. kbactive: 活跃内存，也就是最近使用过的内存，一般不会被系统回收 kbinact: 表示非活跃内存，也就是不常访问的内存，有可能会被系统回收 kbdirty：需要写入磁盘的脏页大小 kbanonpg：用户控件的 non-file 内存大小 kbslab：slab 内存大小 kbkstack：内核栈空间大小 3.4 sar -R作用: 内存分配和释放速率12345sar -R 1 222时27分44秒 frmpg/s bufpg/s campg/s22时27分45秒 0.00 0.00 0.0022时27分46秒 0.00 0.00 0.00 指标含义: frmpg/s: 每秒释放的分页数，负数表示分配 bufpg/s: 每秒增加的用于 buffer 的分页数 campg/s: 每秒增加的用于 cache 的分页数 3.4 sar -S作用: 交换空间统计信息12345&gt; sar -S 1 222时31分57秒 kbswpfree kbswpused %swpused kbswpcad %swpcad22时31分58秒 2097148 0 0.00 0 0.0022时31分59秒 2097148 0 0.00 0 0.00 指标含义: kbswpfree: 释放的 swap 空间大小 kbswpused: 占用的 swap 空间大小 %swpused: swap 空间占用百分比 kbswpcad: 高速缓存 cache 的交换空间大小，同时保存在主存和交换设备中，因此不需要磁盘IO就能被页面换出 %swpcad: kbswpcad占用百分比 3.5 sar -W作用: swap 交换速率12345sar -W 1 222时35分27秒 pswpin/s pswpout/s22时35分28秒 0.00 0.0022时35分29秒 0.00 0.00 指标含义: pswpin/s: swap换入速率，页面/s pswpout/s: swap 换出速率，页面/s 4. 磁盘信息统计4.1 sar -b作用：磁盘 IO 传送速率123456sar -b 1 1Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU)16:53:21 tps rtps wtps bread/s bwrtn/s16:53:22 0.00 0.00 0.00 0.00 0.00Average: 0.00 0.00 0.00 0.00 0.00 指标含义： tps：每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的，一般情况下tps=(rtps+wtps) rtps：每秒的读请求数 wtps：每秒的写请求数 bread/s: 每秒读磁盘的数据块数(in blocks 1 block = 512B, 2.4以后内核) bwrtn/s:每秒写磁盘的数据块数(in blocks 1 block = 512B, 2.4以后内核) bdscd/s：磁盘每秒丢失的数据块数 4.2 sar -dsar -dp –dev=[dev_list] 作用：块设备(磁盘)统计信息 参数： -p：显示磁盘名称，默认情况磁盘显示为devM-n(M-主设备号，n-次设备号) –dev=[dev_list]：指定要显示的设备 1234567 sar -dp 1 1Linux 3.10.0-957.el7.x86_64 (lv) 03/09/20 _x86_64_ (2 CPU)18:38:56 DEV tps rd_sec/s wr_sec/s avgrq-sz avgqu-sz await svctm %util18:38:57 sda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0018:38:57 centos-root 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0018:38:57 centos-swap 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标含义： DEV：设备名称 tps：每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的 rd_sec/s：每秒从磁盘读取的数据量，扇区数 wr_sec/s：每秒写入磁盘的数据量，扇区数 avgrq-sz：I/O 请求的平均大小，单位 KB avgqu-sz：平均请求队列的长度 await：I/O 请求的平均时间，包括等待时间，单位 milliseconds svctm：IO的处理时间，不包括等待时间，推断值，可能不准确 %util：磁盘处理IO的时间百分比，即使用率，因此可能存在并行，100% 不一定代表磁盘饱和 4.3 sar -Isar -I { int_list | SUM | ALL } 作用：统计中断信息 5. 网络统计信息5.1 sar -nsar -n { keyword [,…] | ALL } 作用：统计网络使用情况 keyword: 统计对象，可选值包括 DEV, EDEV, FC, ICMP, EICMP, ICMP6,EICMP6 IP, EIP, IP6, EIP6, NFS, NFSD SOCK, SOCK6, SOFT, TCP,ETCP, UDP and UDP6 常用选项: -n DEV: 网络接口统计信息 -n EDEV: 网络接口错误 -n IP: IP 数据报统计信息 -n EIP: IP 错误统计信息 -n TCP: TCP 统计信息 -n ETCP: TCP 错误统计信息 -n SOCK: 套接字使用 sar -n DEV统计网卡的PPS与发送速率 12345678910111213sar -n DEV 1 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU)06:21:04 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s06:21:05 PM veth934832e 0.00 0.00 0.00 0.00 0.00 0.00 0.0006:21:05 PM vethc869b5c 0.00 0.00 0.00 0.00 0.00 0.00 0.0006:21:05 PM eth0 10287.00 6519.00 13892.42 7946.05 0.00 0.00 20.0006:21:05 PM eth1 2.00 0.00 0.12 0.00 0.00 0.00 1.0006:21:05 PM lo 2958.00 2958.00 31135.78 31135.78 0.00 0.00 0.0006:21:05 PM virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.0006:21:05 PM virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.0006:21:05 PM veth145e746 0.00 0.00 0.00 0.00 0.00 0.00 0.0006:21:05 PM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标含义： rxpck/s：接收的 PPS，单位为包 / 秒 txpck/s：发送的 PPS，单位为包 / 秒 rxkB/s： 接收的吞吐量，单位是 KB/ 秒 txkB/s： 发送的吞吐量，单位是 KB/ 秒 rxcmp/s：接收的压缩数据包数，单位是包 / 秒 txcmp/s：发送的压缩数据包数，单位是包 / 秒 rxmcst/s：广播包的 PPS，单位为包 / 秒 %ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。 sar -n EDEV12345678sar -n EDEV 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU)15时36分56秒 IFACE rxerr/s txerr/s coll/s rxdrop/s txdrop/s txcarr/s rxfram/s rxfifo/s txfifo/s15时36分57秒 enp0s3 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0015时36分57秒 lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0015时36分57秒 virbr0-nic 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0015时36分57秒 virbr0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标: rxerr/s: 接收数据包错误，数据包/s txerr/s: 传输数据包错误，数据包/s coll/s: 碰撞，数据包/s rxdrop/s: 接收数据包丢包(缓冲满)，数据包/s txdrop/s: 传输数据包丢包，数据包/s txcarr/s: 发送数据包时，每秒载波错误数 rxfram/s: 每秒接收数据包的帧对齐错误数 rxfifo/s: 接收的数据包 FIFO 超限错误，数据包/s txfifo/s: 传输的数据包 FIFO 超限错误，数据包/s sar -n IP1234567sar -n IP 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU)15时42分15秒 irec/s fwddgm/s idel/s orq/s asmrq/s asmok/s fragok/s fragcrt/s15时42分16秒 1.00 0.00 1.00 1.00 0.00 0.00 0.00 0.0015时42分17秒 1.01 0.00 1.01 1.01 0.00 0.00 0.00 0.00平均时间: 1.01 0.00 1.01 1.01 0.00 0.00 0.00 0.00 指标: irec/s: [ipInReceives] 输入的数据报文(接收)，数据报文/s fwddgm/s:[ipForwDatagrams] 转发的数据报文，数据报文/s idel/s: [ipInDelivers] 每秒向应用程序传输的数据报文数量 orq/s: [ipOutRequests] 输出/传输的数据报文，数据报文/s asmrq/s: [ipReasmReqds] 每秒收到需要被重新组装的 IP fragments 数量 asmok/s: [ipReasmOKs] 每秒成功重新组装的(re-assembled)的数据报数量 fragok/s: [ipFragOKs] 每秒成功被分段(fragmented )的数据包数量 fragcrt/s: [ipFragCreates] 每秒对数据包成功分段产生的IP分段数 sar -n EIP1234567sar -n EIP 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU)15时48分42秒 ihdrerr/s iadrerr/s iukwnpr/s idisc/s odisc/s onort/s asmf/s fragf/s15时48分43秒 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0015时48分44秒 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00平均时间: 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 指标: ihdrerr/s: [ipInHdrErrors] 每秒由于 IP Header 错误而丢弃的数据包数量 iadrerr/s: [ipInAddrErrors] 每秒由于 IP header’s 里的IP地址不合法而丢弃的数据包数量 iukwnpr/s: [ipInUnknownProtos] 每秒由于未知的网络协议而丢弃的数据包数量 idisc/s: [ipInDiscards] 数据包本身没有问题，因为其他原因比如缓冲满而丢弃的输入数据包数量 odisc/s: [ipOutDiscards] 数据包本身没有问题，因为其他原因比如缓冲满而丢弃的输出数据包数量 onort/s: [ipOutNoRoutes] 由于没有转发的路由而丢弃的数据包数量 asmf/s: [ipReasmFails] The number of failures detected per second by the IP re-assembly algorithm (for whatever reason: timed out, errors, etc) fragf/s: [ipFragFails] 因为需要分片但无法分片(fragmented)，而被丢弃的数据包数量 sar -n TCP1234567sar -n TCP 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU)15时50分54秒 active/s passive/s iseg/s oseg/s15时50分55秒 0.00 0.00 1.00 1.0015时50分56秒 0.00 0.00 1.01 1.01平均时间: 0.00 0.00 1.01 1.01 指标: active/s: [tcpActiveOpens] 新的主动 TCP 连接(connect()) passive/s: [tcpPassiveOpens] 新的被动 TCP 连接(listen()) iseg/s: [tcpInSegs] 输入的段，段/s oseg/s: [tcpOutSegs] 输出的段，段/s sar -n ETCP1234567sar -n ETCP 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月22日 _x86_64_ (1 CPU)15时51分29秒 atmptf/s estres/s retrans/s isegerr/s orsts/s15时51分30秒 0.00 0.00 0.00 0.00 0.0015时51分31秒 0.00 0.00 0.00 0.00 0.00平均时间: 0.00 0.00 0.00 0.00 0.00 atmptf/s: [tcpAttemptFails] 每秒发生的以下状态转换的连接数 SYN-SENT or SYN-RCVD -&gt;CLOSED SYN-RCVD -&gt; LISTEN estres/s: [tcpEstabResets]每秒由 ESTABLISHED or CLOSE-WAIT -&gt; CLOSED 状态的连接数 retrans/s: [tcpRetransSegs]每秒重发的段数 isegerr/s: [tcpInErrs]每秒收到的错误段数 orsts/s: [tcpOutRsts]每秒收到的包含 RST flag TCP段数 sar -n SOCK统计套接字的使用情况 123456sar -n SOCK 1 1Linux 3.10.0-862.el7.x86_64 (ZS-ISP) 03/09/2020 _x86_64_ (40 CPU)06:25:57 PM totsck tcpsck udpsck rawsck ip-frag tcp-tw06:25:58 PM 4957 821 47 0 0 201Average: 4957 821 47 0 0 201 指标含义： totsck：在使用的 socket 数量 tcpsck：在使用的 tcp socket 数量 udpsck：在使用的 udp socket 数量 rawsck：在使用的 raw socket 数量 ip-frag：当前队列中的 IP 数据片 tcp-tw：处于 TIME_WAIT 状态的 TCP数量 6. 文件系统6.1 sar -v报告文件系统缓存123456&gt; sar -v 1Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月21日 _x86_64_ (1 CPU)18时08分59秒 dentunusd file-nr inode-nr pty-nr18时09分00秒 14637 2080 24198 118时09分01秒 14637 2080 24198 1 指标含义: dentunusd: 目录项缓存未用计数 file-nr: 使用中的文件描述符个数 inode-nr: 使用中的 inode 个数]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.1 top]]></title>
    <url>%2F2020%2F02%2F11%2Flinux_perf%2F41_top%2F</url>
    <content type="text"><![CDATA[top 命令 toptop [options] 选项： -b：批处理模式 -n max：设置迭代数量，通常与 -b 一起使用 -d：屏幕刷新间隔 -u user：指定用户名 -p pid(s)：指定进程 交互命令： h：显示帮助画面，给出一些简短的命令总结说明 k：终止一个进程 i：忽略闲置和僵死进程，这是一个开关式命令 q：退出程序 r：重新安排一个进程的优先级别 S：切换到累计模式 l：切换显示平均负载和启动时间信息 m：切换显示内存信息 t：切换显示进程和CPU状态信息 c：切换显示命令名称和完整命令行 M：根据驻留内存大小进行排序 P：根据CPU使用百分比大小进行排序 T：根据时间/累计时间进行排序 w：将当前设置写入~/.toprc文件中 缺陷: top 自身的 CPU用量可能会变得很大，因为 top 会遍历 /proc 内的很多进程项目 top 会对 /proc 做快照，因此会错过一些寿命较短的进程，这些进程在快照之前已经退出了 可以使用 atop 替代top，它使用进程核算技术来捕获短寿命进程并显示，也可以使用 pidstat 捕获短时进程 指标含义123456789top - 14:58:20 up 4:33, 3 users, load average: 0.09, 0.11, 0.13Tasks: 252 total, 3 running, 249 sleeping, 0 stopped, 0 zombie%Cpu(s): 2.5 us, 0.8 sy, 0.0 ni, 95.9 id, 0.0 wa, 0.0 hi, 0.8 si, 0.0 stKiB Mem : 16267424 total, 2198240 free, 12617508 used, 1451676 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 3264332 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 3653 analyzer 20 0 3214268 611932 17464 S 2.4 3.8 6:45.42 java 2994 analyzer 20 0 5456164 108580 9244 S 0.8 0.7 0:11.13 java 系统运行时间1top - 14:58:20 up 4:33, 3 users, load average: 0.09, 0.11, 0.13 输出: top - 14:58:20: 系统当前时间 up 4:33: 系统已运行时间 3 users：当前在线用户 load average：平均负载：最近1分钟、5分钟、15分钟系统的平均负载 说明： 平均负载：平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数 可运行状态：正在使用 CPU 或者正在等待 CPU 的进程，对应 ps R 状态（Running 或 Runnable）进程 不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的，对应 ps D 状态（Uninterruptible Sleep，也称为 Disk Sleep）进程 tasks1Tasks: 252 total, 3 running, 249 sleeping, 0 stopped, 0 zombie 输出： 标准： 基于线程转态切换的任务数统计，统计的是线程数 shows total tasks or threads, depending on the state of the Threads-mode toggle. total：总的线程数 running：处于运行状态的线程数 sleeeping：处于休眠状态的线程数 stopped：被跟踪或已停止 Stopped的线程数 zombie：僵尸进程数 CPU1%Cpu(s): 2.5 us, 0.8 sy, 0.0 ni, 95.9 id, 0.0 wa, 0.0 hi, 0.8 si, 0.0 st 输出：|名称|缩写|含义||:–|:–|:–||user|us|用户态 CPU 时间，不包括下面的 nice 时间，但包括 guest 时间。||nice|ni|代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。 nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。||system|sys,sy|代表内核态 CPU 时间。||idle|id|代表空闲时间。注意，它不包括等待 I/O 的时间（iowait）||iowait|wa|代表等待 I/O 的 CPU 时间，出现 iowait 有两个条件，一是进程在等io，二是等io时没有进程可运行||irq|hi|代表处理硬中断的 CPU 时间。||softirq|si|代表处理软中断的 CPU 时间。||steal|st|代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间||guest|guest|代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间||guest_nice|gnice|代表以低优先级运行虚拟机的时间| 注意：通常我们收的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 memery swap12KiB Mem : 16267424 total, 2198240 free, 12617508 used, 1451676 buff/cacheKiB Swap: 0 total, 0 free, 0 used. 3264332 avail Mem 输出: total: 总的内存或 swap 分区大小 free：处于空闲状态的内存或 swap 分区大小 used：已经的内存或 swap 分区大小 buff/cache: 用于buff/cache 的内存大小 avail Mem：可用内存，包括 free，以及可回收的页缓存，内存，和slab 缓存 进程信息 PID Process Id 进程ID USER Effective User Name 进程的有效属主，用于判断进程对文件系统的访问权限 PR Priority 进程优先级 NI Nice Value nice值 VIRT Virtual Image (KiB) 进程使用的虚拟内存大小，包括换到 swap 分区，以及隐射了但未分配内存 RES Resident Size (KiB) 实际占用的物理内存大小 SHR Shared Memory (KiB) 共享内存大小 S Process Status 进程状态 %CPU CPU Usage 基于CPU时间片计算的CPU使用率并没有细分进程的用户态 CPU 和内核态 CPU %MEM Memory Usage (RES) 内存占用百分比 TIME+ CPU Time, hundredths 进程使用的CPU时间总计，单位1/100秒 COMMAND Command Name/Line 进程名称及命令 PPID Parent Process pid 父进程ID UID Effective User Id RUID Real User Id 由启动进程的用户决定 RUSER Real User Name SUID Saved User Id SUSER Saved User Name GID Group Id GROUP Group Name PGRP Process Group Id TTY Controlling Tty 所属终端 TPGID Tty Process Grp Id SID Session Id 会话ID nTH Number of Threads 包含的线程数 P Last Used Cpu (SMP) 最后运行该进程的CPU TIME CPU Time 同TIME+，但没有TIME+精确 SWAP Swapped Size (KiB) 使用的swap分区大小 CODE Code Size (KiB) 代码段占用内存大小 DATA Data+Stack (KiB) 数据段占用内存大小 nMaj Major Page Faults 累计主缺页异常次数 nMin Minor Page Faults 累计次缺页异常次数 nDRT Dirty Pages Count 待刷新的脏页数 WCHAN Sleeping in Function Flags Task Flags 进程调度标识 CGROUPS Control Groups SUPGIDS Supp Groups IDs SUPGRPS Supp Groups Names TGID Thread Group Id 所属线程组ID ENVIRON Environment vars 进程依赖的环境变量 vMj Major Faults delta 当前时间间隔内的主缺页异常 vMn Minor Faults delta USED Res+Swap Size (KiB) nsIPC IPC namespace Inode 进程所属的IPC命令空间 nsMNT MNT namespace Inode nsNET NET namespace Inode nsPID PID namespace Inode nsUSER USER namespace Inode nsUTS UTS namespace Inode]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 高级工具包]]></title>
    <url>%2F2020%2F02%2F10%2Flinux_perf%2F40_%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E5%8C%85%2F</url>
    <content type="text"><![CDATA[从本文开始我们将进入Linux性能优化的第二阶段，高级工具包。 1. 内容概要这一部分我们将分成两个部分，介绍如下工具的使用: 高级命令: top sar pidstat ps 高级工具包 perf-tool bcc dtrace-toolkit systemtap-lwt 容器分析工具]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.18 监控系统构建]]></title>
    <url>%2F2020%2F02%2F01%2Flinux_perf%2F38.%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[我们不能总是去当救火队员，更重要的是监控系统。 1. 监控系统线上的系统 24 小时运转，有一些问题稍纵即逝，我们总不能 24 小时盯着。对于线上业务更重要的是一套完备的监控系统，把系统和应用程序的运行状况监控起来，并定义一系列的策略，在发生问题时第一时间告警通知。 要做好监控，最核心的就是全面的、可量化的指标。接下来我们就从系统和应用两个方面来看看如何构建我们的监控指标体系。 2. 系统资源2.1 USE法USE 法把系统资源的性能指标，简化成了三个类别，即使用率、饱和度以及错误数。 使用率，表示资源用于服务的时间或容量百分比。100% 的使用率，表示容量已经用尽或者全部时间都用于服务。 饱和度，表示资源的繁忙程度，通常与等待队列的长度相关。100% 的饱和度，表示资源无法接受更多的请求。 错误数表示发生错误的事件个数。错误数越多，表明系统的问题越严重。 这三个类别的指标，涵盖了系统资源的常见性能瓶颈，所以常被用来快速定位系统资源的性能瓶颈。 2.1 系统资源指标下面是 USE 法建立的系统资源指标体系: 需要注意的是，USE 方法只关注能体现系统资源性能瓶颈的核心指标，但这并不是说其他指标不重要。诸如系统日志、进程资源使用量、缓存使用量等其他各类指标，也都需要我们监控起来。只不过，它们通常用作辅助性能分析。 3. 应用应用程序的核心指标，不再是资源的使用情况，而是请求数、错误率和响应时间。这指标可以帮助我们快速确定应用是否发生了性能问题。如何想确定程序的问题所在，我们还需要监控以下指标: 第一个，是应用进程的资源使用情况，比如进程占用的 CPU、内存、磁盘 I/O、网络等。使用过多的系统资源，导致应用程序响应缓慢或者错误数升高，是一个最常见的性能问题。 第二个，是应用程序之间调用情况，比如调用频率、错误数、延时等。由于应用程序并不是孤立的，如果其依赖的其他应用出现了性能问题，应用自身性能也会受到影响。 第三个，是应用程序内部核心逻辑的运行情况，比如关键环节的耗时以及执行过程中的错误等。由于这是应用程序内部的状态，从外部通常无法直接获取到详细的性能数据。所以，应用程序在设计和开发时，就应该把这些指标提供出来，以便监控系统可以了解其内部运行状态。 4. 监控系统4.1 监控系统一个完整的监控系统通常由数据采集、数据存储、数据查询和处理、告警以及可视化展示等多个模块组成。现在已经有很多开源的监控工具可以直接使用，比如最常见的 Zabbix、Nagios、Prometheus 等等。 4.2 全链路跟踪系统业务系统通常会涉及到一连串的多个服务，形成一个复杂的分布式调用链。为了迅速定位这类跨应用的性能瓶颈，还可以使用 Zipkin、Jaeger、Pinpoint 等各类开源工具，来构建全链路跟踪系统。 全链路跟踪除了可以帮你快速定位跨应用的性能问题外，还可以帮你生成线上系统的调用拓扑图。这些直观的拓扑图，在分析复杂系统（比如微服务）时尤其有效。 4.3 日志监控同样的一个接口，当请求传入的参数不同时，就可能会导致完全不同的性能问题。所以，除了指标外，我们还需要对这些指标的上下文信息进行监控，而日志正是这些上下文的最佳来源。 对比来看，指标是特定时间段的数值型测量数据，通常以时间序列的方式处理，适合于实时监控。而日志则完全不同，日志都是某个时间点的字符串消息，通常需要对搜索引擎进行索引后，才能进行查询和汇总分析。 日志监控来说，最经典的方法，就是使用 ELK 技术栈，即使用 Elasticsearch、Logstash 和 Kibana 这三个组件的组合。 Logstash 资源消耗比较大。所以，在资源紧张的环境中，我们往往使用资源消耗更低的 Fluentd，来替代 Logstash。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.17 总结-内核线程]]></title>
    <url>%2F2020%2F01%2F31%2Flinux_perf%2F37_%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本节我们来看看，操作系统内都有哪些内核线程。 1. 内核线程Linux 中，用户态进程的“祖先”，都是 PID 号为 1 的 init 进程(或者 systemd)。那么，内核态线程又是谁来管理的呢？ 实际上，Linux 在启动过程中，有三个特殊的进程，也就是 PID 号最小的三个进程。 0 号进程为 idle 进程，这也是系统创建的第一个进程，它在初始化 1 号和 2 号进程后，演变为空闲任务。当 CPU 上没有其他任务执行时，就会运行它。 1 号进程为 init 进程，通常是 systemd 进程，在用户态运行，用来管理其他用户态进程。 2 号进程为 kthreadd 进程，在内核态运行，用来管理内核线程。 所以可以像下面这样查看所有内核线程:1234567891011121314151617# 1. 通过 2 号进程查看所有内核线程$ ps -f --ppid 2 -p 2UID PID PPID C STIME TTY TIME CMDroot 2 0 0 12:02 ? 00:00:01 [kthreadd]root 9 2 0 12:02 ? 00:00:21 [ksoftirqd/0]root 10 2 0 12:02 ? 00:11:47 [rcu_sched]root 11 2 0 12:02 ? 00:00:18 [migration/0]...root 11094 2 0 14:20 ? 00:00:00 [kworker/1:0-eve]root 11647 2 0 14:27 ? 00:00:00 [kworker/0:2-cgr]# 2. 内核线程的名称（CMD）都在中括号里$ ps -ef | grep "\[.*\]"root 2 0 0 08:14 ? 00:00:00 [kthreadd]root 3 2 0 08:14 ? 00:00:00 [rcu_gp]root 4 2 0 08:14 ? 00:00:00 [rcu_par_gp]... 1.1 常见的内核线程性能分析中经常会碰到如下几个内核线程: ksoftirqd: 处理软中断的内核线程，每个 CPU 上都有一个 kswapd0：用于内存回收 kworker：用于执行内核工作队列，分为 绑定 CPU （名称格式为 kworker/CPU86330）和 未绑定 CPU（名称格式为 kworker/uPOOL86330）两类 migration：在负载均衡过程中，把进程迁移到 CPU 上，每个 CPU 一个 jbd2/sda1-8： jbd 是 Journaling Block Device 的缩写 用来为文件系统提供日志功能，以保证数据的完整性； 名称中的 sda1-8，表示磁盘分区名称和设备 每个使用了 ext4 文件系统的磁盘分区，都会有一个 jbd2 内核线程 pdflush：用于将内存中的脏页（被修改过，但还未写入磁盘的文件页）写入磁盘（已经在 3.10 中合并入了 kworker 中） 2. 内核线程性能剖析对于普通进程，我们要观察其行为有很多方法，比如 strace、pstack、lsof 等等。但这些工具并不适合内核线程，比如，如果你用 pstack ，或者通过 /proc/pid/stack 查看 ksoftirqd/0（进程号为 9）的调用栈时，分别可以得到以下输出： 1234567891011# pstack 报出的是不允许挂载进程的错误$ pstack 9Could not attach to target 9: Operation not permitted.detach: No such process# /proc/9/stack 方式虽然有输出，但输出中并没有详细的调用栈情况。$ cat /proc/9/stack[&lt;0&gt;] smpboot_thread_fn+0x166/0x170[&lt;0&gt;] kthread+0x121/0x140[&lt;0&gt;] ret_from_fork+0x35/0x40[&lt;0&gt;] 0xffffffffffffffff 内核的追踪，我们需要借助动态追踪技术，比如 perf，Systemtap, eBPF。借助于这些工具我们可以生成火焰图，帮助我们分析各种问题。各种工具的使用，我们在这个系列文章的开始都作了详细介绍。希望大家多多练习，熟练掌握。下面我举几个例子，让大家看看，这些工具是如何达到异曲同工之妙的。 3. 跟踪网络丢包4. 火焰图追踪 ksoftirqd 调用栈]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.16 C10K 与网络I/O模型]]></title>
    <url>%2F2020%2F01%2F31%2Flinux_perf%2F35_c10k%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[各种网络I/O模型是面试的必考考点，那么到底有哪些I/O模型，C10K 问题到底又是怎么解决的呢？ 1. C10K问题所谓 C10K 问题就是如何在单机中同时处理 1 万个请求（并发连接 1 万）的问题。从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I/O 模型问题。 到目前为止有两种最基本的I/O模型: 同步阻塞: 也就是每个请求都分配一个进程或者线程。当并发请求数增加到 10000 时，10000 个进程或线程的调度、上下文切换乃至它们占用的内存，都会成为瓶颈。 非阻塞I/O: 非阻塞I/O 可以让我们周期性轮询检查某个文件描述符上的I/O是否可以执行。我们可以在一个线程内同时轮询多个文件描述，但是如果轮询的频率不高，那么应用程序响应I/O事件的延时可能达到难以接受的程度。但是一个紧凑的轮询是非常浪费CPU的。 显然通过每个请求分配一个线程的方式不合适，通过轮询的方式也不合适。那么核心问题就变成如何在一个线程内处理多个请求呢？这需要我们解决以下几个问题: 如何同时检查多个文件描述，在它们准备就绪时(即网络请求到来时)，及时处理。我们需要新的I/O模型。 一个线程内处理多个I/O请求，需要维护每个请求的上下文信息，这就引申出另外两种并发机制: 回调和协程 1.1 I/O 模型“新的”I/O模型有下列几种备选方案: I/O多路复用: 允许进程同时检查多个文件描述符，看其中任何一个是否可以执行I/O操作，系统调用 select，poll 可以用来执行I/O多路复用 信号驱动I/O: 指当有输入或者数据可以写到指定的文件描述符时，内核向请求数据的进程发送一个信号。 epoll: Linux 专有特性，select，poll 的升级版本，使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。 I/O多路复用，信号驱动，epoll 都是用来实现同一个目标技术: 同时检查多个文件描述符，看它们是否准备好了执行I/O操作。 1.2 事件通知方式在深入讨论各种I/O机制之前，我们需要先区分两种文件描述符准备就绪的通知模式: 水平触发: 只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。 边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。 select,pool 支持水平触发，信号驱动I/O支持边缘触发。epoll 同时支持水平触发和边缘触发，默认情况下提供的是水平触发机制。 2. I/O模型的对比下面是几种I/O模型之间的对比图: 在具体比较这几种 I/O 模式的区别之前，我们需要明白下面几个要点: 同步阻塞，非阻塞I/O 通常都是用在单个进程每次只在一个文件描述符上执行I/O操作 I/O多路复用，信号驱动则是用来同时检查多个文件描述符，因为需要同时处理多个I/O请求，所以在单个文件描述符上采用的仍然是非阻塞的I/O模式。 非阻塞I/O需要在I/O发生时，通知进程及时进行I/O操作，“通知”包含以下几个方面: 什么时候通知: 水平触发还是边缘触发 在I/O栈的什么位置通知: 数据到达时即通知，还是在内核将数据完全拷贝到用户空间时在通知 通知什么: 回调注册在每个文件描述符上的回调函数，每个文件描述符上的回调函数即维护了每个请求的上下文信息。 最开始我们提到了两种并发机制: 回调和协程，本质上协程也是回调，因为协程最终也是要为每个描述符注册回调函数。 但是协程与回调的区别在于，协程保存了回调前后的上下文信息，简单的理解，协程在通知的前后位于同一个函数栈中，其保留了程序执行的上下文信息，可以让我们像编写同步代码一样编写异步调用，避免了“回调地狱”的问题。 2.1 I/O多路复用I/O多路复用包括 select，poll 和 epoll。epoll 是 select，poll 的升级版。 select 和 poll 存在下面这些问题: 每次调用 select 和 poll，内核都必须检查所有被指定的文件描述符 每次调用 select 和 poll 时，程序都必须传递一个表示所有需要被检查的文件描述符的结构到内核，内核检查过后，要把这个结构返回给用户程序，显然随着文件描述符的增多，拷贝所有文件描述所需的内存和CPU都会增多 select 和 poll调用完成后，程序还必须检查返回的数据结构中的每个元素才能知道哪些描述符可用 epoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。 epoll 使用事件驱动的机制，只关注有 I/O 事件发生的文件描述符，不需要轮询扫描整个集合。 3.1 信号驱动I/O信号驱动I/O使用信号作为I/O就绪的触发机制。在效率上甚至比I/O多路复用更高。但是使用信号的I/O的问题在于: 内核可用的信号类型有限，不太容易随着I/O事件的类型而扩展。I/O多路复用为不同描述符定义了不同的I/O事件集合，并且可以指定希望检查的事件类型。 可排队的实时信号的数量是有限的，超过限制信号就会丢失，这样I/O请求就无法及时得到处理。使用信号驱动I/O 需要复杂的信号处理流程，I/O多路复用不需要。 4.1 异步I/O信号驱动I/O有时也被称为异步I/O，这一点从打开的文件标志O_ASYNC 中就能看出(注: 使用信号驱动I/O必须要使用 O_ASYNC 标识打开文件描述符)。现在异步I/O专指有POSIX_AIO 规范所提供的功能。 异步I/O与I/O多路复用不同在于在I/O栈的什么位置通知。异步I/O使用的较少，详细内容后续在补充。 5. 工作模型使用 I/O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型: 第一种，主进程 + 多个 worker 子进程，这也是最常用的一种模型 第二种，监听到相同端口的多进程模型 5.1 主进程 + 多个 worker 子进程主进程 + 多个 worker 子进程: 主进程执行 bind() + listen() 后，创建多个子进程； 然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。 最常用的反向代理服务器 Nginx 就是这么工作的。主进程主要用来初始化套接字，并管理子进程的生命周期；而 worker 进程，则负责实际的请求处理。 这里要注意，accept() 和 epoll_wait() 调用，还存在一个惊群的问题。换句话说，当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠。 其中，accept() 的惊群问题，已经在 Linux 2.6 中解决了； epoll 的问题，到了 Linux 4.5 ，才通过 EPOLLEXCLUSIVE 解决。 为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒。 当然，也可以用线程代替进程：主线程负责套接字初始化和子线程状态的管理，而子线程则负责实际的请求处理。由于线程的调度和切换成本比较低，实际上你可以进一步把 epoll_wait() 都放到主线程中，保证每次事件都只唤醒主线程，而子线程只需要负责后续的请求处理。 5.2 监听到相同端口的多进程模型在这种方式下，所有的进程都监听相同的接口，并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。比如，Nginx 在 1.9.1 中就已经支持了这种模式。想要使用 SO_REUSEPORT 选项，需要用 Linux 3.9 以上的版本才可以。 6. C1000K,C10M 问题随着并发请求的进一步提高，原本不是瓶颈的地方也会出现问题。 从软件资源上来说，大量的连接也会占用大量的软件资源，比如文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等。 大量请求带来的中断处理，也会带来非常高的处理成本。这样，就需要多队列网卡、中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。 在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了。无论你怎么优化应用程序和内核中的各种网络参数，想实现 1000 万请求的并发，都是极其困难的。 究其根本，还是 Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了。 要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。 6.1 DPDKDPDK，是用户态网络的标准。它跳过内核协议栈，直接由用户态进程通过轮询的方式，来处理网络接收。 6.2 XDPXDP（eXpress Data Path），则是 Linux 内核提供的一种高性能网络数据路径。它允许网络包，在进入内核协议栈之前，就进行处理，也可以带来更高的性能。XDP 底层跟我们之前用到的 bcc-tools 一样，都是基于 Linux 内核的 eBPF 机制实现的。 详细的原理参见: xdp 6.3 分布式在大多数场景中，我们并不需要单机并发 1000 万的请求。通过调整系统架构，把这些请求分发到多台服务器中来处理，通常是更简单和更容易扩展的方案。常见的CDN，LVS，Nginx 负载均衡等就是可选解决方案之一。 7. 文件描述符7.1 打开标识前面我们说的信号驱动I/O，非阻塞I/O都有文件的打开文件描述符有关。 open() 调用的flags 有如下参数:|标志|作用||:—|:—||O_ASYNC|信号驱动I/O，当操作可行是，产生信号通知进程||O_ASYNC|信号驱动I/O，仅对特定的文件有效||O_CLOSEXEC|为新创建的文件描述符设置close-on-exec标志||O_DSYNC|根据同步I/O数据完整性的完成要求来执行写操作，与内核I/O 缓冲有关||O_SYNC|同步I/O，与内核I/O 缓冲有关||O_NONBLOCK|非阻塞方式打开文件| O_NONBLOCK: 非阻塞方式打开文件。管道，FIFO，设备都支持非阻塞模式。 由于内核缓冲区保证了普通文件I/O不会陷入阻塞，故而打开普通文件时一般会忽略 O_NONBLOCK 标志。 当使用强制文件锁时，O_NONBLOCK 对普通文件也是起作用的。 O_CLOSEXEC: 为新创建的文件描述符设置close-on-exec标志 在创建进程，成功执行 exec()系统调用之前关闭文件描述符。如果 exce() 失败，文件描述符会保持打开状态。 7.2 I/O事件I/O 多路复用为不同描述符何时就绪定义了不同的I/O事件。不同的I/O事件表示文件描述符可执行的不同I/O操作。 对于普通文件的文件描述符总是被 select 标记为可读可写。但是 epoll 没有普通文件的I/O事件，不能将普通文件的文件描述符添加到 epoll 中。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.15 网络动态追踪]]></title>
    <url>%2F2020%2F01%2F30%2Flinux_perf%2F34_%E7%BD%91%E7%BB%9C%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[本节我们来介绍网络的动态追踪技术 1. Systemtab 磁盘网络Dtrace/Systemtab 可以在内核和应用程序内部检查网络事件，包括 套接字连接 套接字I/O TCP事件 数据包重传 积压队列丢包 TCP重传 这些功能能够支持工作负载特征归纳和延时分析 1.1 Dtrace下面列出了用来跟踪网络的 Dtrace provider|层次|稳定 provider|不稳定 provider||:—|:—|:—||应用程序|取决于应用|pid||系统库||pid||系统调用||syscall||套接字||fbt||TCP|tcp,mib|fbt||UDP|udp,mib|fbt||IP|ip,mib|fbt||链路层||fbt||设备驱动||fbt| 1.2 SystemtapSystemtap 提供了如下了 tapset 进行网络追踪: Socket Tapset Networking Tapset 2.网络跟踪2.1 套接字连接由处理网络的应用程序函数，系统套接字库，系统调用层，或者在内核中都可以跟踪套接字活动。通常偏好在系统调用层，因为文档最全，系统开销最低并且是系统级的。 除了 connect() 和 accept() 还能跟踪 socket() 和 close() 系统调用，这允许在创建时发现文件描述符，并用时间差衡量套接字的持续时间。 Dtrace123456789101112# 1. 用 connect() 计数出站连接dtrace -n 'syscall::connect:entry &#123; @[execname] =count(); &#125;'# 2. 用 accept() 计算入站连接dtrace -n 'syscall::accept:entry &#123; @[execname] =count(); &#125;'# 3. 通过检查用户栈可以揭示为什么会执行套接字dtrace -n 'syscall::connect:entry /execname == 'ssh'/ &#123; ustack(); &#125;'# 4. 检查系统调用的参数，源自 Gregg# https://github.com/brendangregg/bpf-perf-tools-booksoconnect.d Systemtap12345678910111213141516171819202122232425262728293031# 1. 用 connect() 计数出站连接stap -ve 'global s;probe syscall.connect &#123; s[execname()] &lt;&lt;&lt; 1&#125; probe end &#123; foreach(i in s- limit 10) &#123;printf("%s: %d\n", i, @count(s[i]))&#125;&#125;'# 2. 用 accept() 计算入站连接stap -ve 'global s;probe syscall.accept &#123; s[execname()] &lt;&lt;&lt; 1&#125; probe end &#123; foreach(i in s- limit 10) &#123;printf("%s: %d\n", i, @count(s[i]))&#125;&#125;' # 3. 通过检查用户栈可以揭示为什么会执行套接字stap -ve 'global s; probe syscall.connect &#123; s[ubacktrace()] &lt;&lt;&lt; 1&#125; probe end &#123; foreach(i in s- limit 10) &#123;print_ustack(i); printf("%d\n", @count(s[i]))&#125;&#125;'# 4. 检查系统调用的参数，源自 Gregg# https://github.com/brendangregg/bpf-perf-tools-booksoconnect.d # bpftrace 安装sudo yum install epel-releasesudo yum install snapdsudo systemctl enable --now snapd.socketsudo ln -s /var/lib/snapd/snap /snapsudo snap install --devmode bpftracesudo snap connect bpftrace:system-trace# 执行 soconnect.dtgit clone https://github.com/brendangregg/bpf-perf-tools-book.gitcd bpf-perf-tools-book/originals/Ch10_Networking/bpftrace soconnect.bt 2.2 套接字I/ODtrace1234567# 1. 按 execname 计数套接字读取次数dtrace -n 'syscall::read:entry,syscall::recv:entry /fds[arg0].fi_fs == "sockfs"/ &#123; @[execname]=count() &#125;'# 2. 按 execname 计数套接字读取次数dtrace -n 'syscall::write:entry,syscall::send:entry /fds[arg0].fi_fs == "sockfs"/ &#123; @[execname]=count() &#125;' Systemtapsocket tapset 提供套接字读取的详细信息123456789# 1. 按 execname 计数套接字读取次数stap -ve 'global s; probe socket.receive &#123; s[execname()] &lt;&lt;&lt; 1 &#125; probe end &#123; foreach(i in s- limit 10) &#123; printf("%s: %d\n", i, @count(s[i]))&#125; &#125;'# 2. 按 execname 计数套接字读取次数stap -ve 'global s; probe socket.send &#123; s[execname()] &lt;&lt;&lt; 1 &#125; probe end &#123; foreach(i in s- limit 10) &#123; printf("%s: %d\n", i, @count(s[i]))&#125; &#125;' 2.3 套接字延时延时包括: 连接延时: 同步系统调用: 就是 connect() 耗时 异步系统调用: 这是执行 connect() 至 poll() 或者 select() 或其他系统调用报告套接字就绪的时间 首字节延时: 自执行 connect() 或从 accept() 返回，直到第一字节数据由任何一个 I/O 系统调用从套接字接收到的时间 套接字持续时间: 同一个套接字从 socket() 到 close() 的时间要聚焦连接时长可以由connect() 或者 accetp() 开始计时 Dtrace1234```#### Systemtap```bash 2.4 套接字内部活动Dtrace利用 fbt provider 能跟踪套接字的内核运行。12# linux 查看套接字内核函数探针dtrace -ln 'fbt::sock*:entry' Systemtap12345678910# linux 查看套接字内核函数探针&gt; stap -l 'kernel.function("sock*")'kernel.function("sock_aio_dtor@net/socket.c:890")kernel.function("sock_aio_read@net/socket.c:959")kernel.function("sock_aio_write@net/socket.c:1001")kernel.function("sock_alloc@net/socket.c:535").....&gt; stap -L 'kernel.function("sock_recv_drops@net/socket.c:788")'kernel.function("sock_recv_drops@net/socket.c:788") $skb:struct sk_buff* $sk:struct sock* $msg:struct msghdr* 2.5 TCP 事件DtraceTCP 的内核运行也能用 fbt provider，但是 tcp 有专属的 tcp provider|TCP 探针|描述||:—|:—||tcp:::accept-established|接受一个入站连接，被动 open||tcp:::connect-request|启动一个出站连接，主动 open||tcp:::connect-established|建立一个出站连接，完成三次握手||tcp:::accetp-refused|拒绝一个连接请求，关闭本地端口||tcp:::connect-refused|拒绝一个连接请求，关闭远程端口||tcp:::send|发送一个数据段，ip可能直接将数据段映射到一个数据包||tcp:::receive|接受一个数据段，ip可能直接将数据段映射到一个数据包||tcp:::state-change|一个会话发生状态改变| tcp provider 提供了协议包头细节以及内核内部状态，其中包含”缓冲”的进程ID，通常DTrace 内置的 execname 跟踪的进程名不一定有效，因为内核 TCP 时间可能与进程非同步发生。 12# 以频率计数接受的 TCP 连接(被动)以及远程 IP 地址和本地端口dtrace -n 'tcp:::accept-established&#123; @[args[3]-&gt;tcps_raddr, args[3]-&gt;tcps_lport] = count(); &#125;' Systemtap12345# 以频率计数接受的 TCP 连接(被动)以及远程 IP 地址和本地端口stap -ve 'global s; probe kernel.&#123;function("tcp_accept"),function("inet_csk_accept")&#125;.return? &#123;sock = $return;if (sock != 0)&#123;s[inet_get_local_port(sock), inet_get_ip_source(sock)] &lt;&lt;&lt; 1&#125;&#125; probe end &#123; foreach([i,j] in s- limit 10) &#123; printf("%s,%d: %d\n", j,i, @count(s[i,j]))&#125; &#125;' tcp 连接监控12345678910111213#! /usr/bin/env stapprobe begin &#123; printf("%6s %16s %6s %6s %16s\n", "UID", "CMD", "PID", "PORT", "IP_SOURCE")&#125;probe kernel.&#123;function("tcp_accept"),function("inet_csk_accept")&#125;.return? &#123; sock = $return if (sock != 0) printf("%6d %16s %6d %6d %16s\n", uid(), execname(), pid(), inet_get_local_port(sock), inet_get_ip_source(sock))&#125; 2.6 数据包传输tcp provider 提供的功能有限，跟踪内核函数是跟踪网络传输的根本方法。一个快速穿越网络栈的方法是跟踪一个深层次的事件并且检查它的调用栈。 Dtrace123456789# 1. 跟踪网络调用内核栈&gt; dtrace -n 'fbt::ip_output:entry &#123; @[stack(100)] = count(); &#125;'..... kernel`tcp_sendmsg_Ox895` # 网络调用内核栈中的一个函数.....# 2. 跟踪调用栈中的特定系统调用比如 tcp_sendmsg，查看他的参数# 假设 tcp_sendmsg 的第四个参数是以字节为单位的长度，我们就可以统计 TCP 发送段的长度&gt; dtrace -n 'fbt::tcp_sendmsg:entry &#123; @['TCP send bytes']=quantize(arg3); &#125;' Systemtap1234567891011```### 2.7 重传跟踪研究 TCP 重传有助于调查网络健康程度#### Dtrace```bashtcp_retransmit_skb.d# 云计算性能优化工具包中用于跟踪重传的 dtrace 脚本# https://github.com/brendangregg/dtrace-cloud-toolstcpretranssnoop.d Systemtap12git clone https://github.com/brendangregg/systemtap-lwtools.git# 未找到类似工具 2.8 积压队列丢包Dtrace123# 云计算性能优化工具包中用于跟踪 积压队列丢包的 dtrace 脚本# https://github.com/brendangregg/dtrace-cloud-toolstcpconnreqmaxq-pid_sdc6.d Systemtap1# 未找到类似工具 3. 高级网络跟踪脚本 Dtrace 云计算性能优化工具包 DTraceBook 的 Network Lower-Level Protocals 章节 https://github.com/brendangregg/bpf-perf-tools-book Systemtap https://sourceware.org/systemtap/SystemTap_Beginners_Guide/useful-systemtap-scripts.html#mainsect-network https://github.com/brendangregg/bpf-perf-tools-book https://github.com/brendangregg/systemtap-lwtools.git]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.14 网络监测命令]]></title>
    <url>%2F2020%2F01%2F29%2Flinux_perf%2F33_%E7%BD%91%E7%BB%9C%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本节我们来介绍内存相关的监测工具。 1. 命令总览下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了网络相关的性能检测工具: 从网络的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握网络分析的套路 我们会介绍如下网络统计信息的工具 Linux Solaris 作用 说明 netstat,ss netstat 多种网络栈和接口统计信息 sar 统计信息历史 ifconfig ifconfig 接口配置 ip ip 网络配置接口统计信息 nicstat nicstat 网络接口吞吐量和使用率 ethtool ethtool 查看网络接口的带宽 ping ping 测试网络连通性 traceroute traceroute 测试网络路由 pathchar pathchar 确定网络路径特征 tcpdump tcpdump/snoop 网络数据报嗅探器 nethogs nethogs 查看进程的网络收发情况 iftop iftop 查看IP的网络收发情况 conntrack conntrack 查看和管理连接跟踪状况 ts ts 网络Qos设置 Wireshark Wireshark 图形化网络数据包检查器 DTrace,perf DTrace TCP/IP栈跟踪: 连接、数据包、丢包、延时 除此之外，还包括以下内容: 网络基准测试 网络调优 1.1 网络相关的理论阅读中遇到下面不理解的概念，记录如下: TCP TIME-WAIT CPU 扇出 链路聚合 2. 网络统计命令网络的统计信息由以下两个文件提供: /proc/net/snmp /proc/net/netstat 2.1 ssss options 作用: 多种网络栈和接口统计信息 选项: 套接字: 默认: 列出连接的套接字 -a: 列出所有套接字的信息 -4：只显示ipv4的套接字； -6：只显示ipv6的套接字； -t：只显示tcp套接字； -n：不解析服务名称，以数字方式显示； -l：显示处于监听状态的套接字； -u：只显示udp套接字； -d：只显示DCCP套接字； -w：仅显示RAW套接字； -x：仅显示UNIX域套接字 -S: display only SCTP sockets -f: 显示 FAMILY类型的套接字，FAMILY可选包括 inet|inet6|link|unix|netlink|vsock|help 套接字相关资源: -m：显示套接字的内存使用情况 -p：显示使用套接字的进程信息 -E: continually display sockets as they are destroyed -Z: display process SELinux security contexts -z: display process and socket SELinux security contexts -K: forcibly close sockets, display what was closed 统计信息: -s: 网络栈统计信息 -i: 网络接口信息 输出控制: -o: 显示计时器信息 -D, –diag=FILE 将原始TCP套接字（sockets）信息转储到文件 -N: switch to the specified network namespace name -e: show detailed socket information -A, –query=QUERY, –socket=QUERY，QUERY 包括: all|inet|tcp|udp|raw|unix unix_dgram|unix_stream|unix_seqpacket|packet| netlink|vsock_stream|vsock_dgram123456789101112 ss -sTotal: 283 (kernel 0)# ss 只显示已经连接、关闭、孤儿套接字等简要统计TCP: 14 (estab 2, closed 1, orphaned 0, synrecv 0, timewait 0/0), ports 0Transport Total IP IPv6* 0 - -RAW 0 0 0UDP 11 8 3TCP 13 8 5INET 24 16 8FRAG 0 0 0 2.2 netsatnetstat [-vWeenNcCF] [&lt;Af&gt;] -rnetstat [-vWnNcaeol] [&lt;Socket&gt; ...]netstat { [-vWeenNac] -I[&lt;Iface&gt;] | [-veenNac] -i | [-cnNe] -M | -s [-6tuw] } [delay] 选项: 统计选项: -i: 显示网络接口信息 -s: 显示网络栈统计信息 系统信息: -p: 显示使用套接字的进程信息 -r: 显示路由表 -g：显示多重广播功能群组组员名单 -M: 显示伪装的网络连线 -F: display Forwarding Information Base (default) -C: display routing cache instead of FIB -Z: 显示套接字的 SELinux 信息 显示控制: -v, –verbose be verbose -W, –wide don’t truncate IP addresses -n: 显示 IP 地址 -N: 显示网络硬件外围设备的符号连接名称； -e: 显示扩展信息 -o: 显示计时器 -c: 持续输出 套接字筛选: -a: 列出所有套接字的信息 -l: 显示处于监听状态的套接字 -t|–tcp -u|–udp -U|–udplite -S|–sctp -w|–raw -x|–unix –ax25 –ipx –netrom -6: inet6 (IPv6) -4: inet (IPV4) netstat -i常与 -c 一起使用，每秒输出下面的累计计数。123456Kernel Interface tableIface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgenp0s3 1500 140998 0 0 0 12029 0 0 0 BMRUlo 65536 107 0 0 0 107 0 0 0 LRUvirbr0 1500 0 0 0 0 0 0 0 0 BMUvirbr0-nic 1500 0 0 0 0 0 0 0 0 BMU 输出: ifcae: 网络接口 MTU 一系列的接收(RX-)和传输(TX-) OK: 成功传输的数据包 ERR: 错误数据包 DRP: 丢包 - 网络接口是否饱和指针 OVR: 超限 - 网络接口是否饱和指针 netstat -s123456789101112131415161718192021222324252627282930$ netstat -sIp: 21721 total packets received 0 forwarded 0 incoming packets discarded 15111 incoming packets delivered 10909 requests sent out 98 dropped because of missing routeIcmp: 0 ICMP messages received 0 input ICMP message failed. ICMP input histogram: 244 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 244IcmpMsg: OutType3: 244Tcp: 14 active connections openings 17 passive connection openings 0 failed connection attempts 0 connection resets received 2 connections established 14307 segments received 9608 segments send out 4 segments retransmited 0 bad segments received. 8 resets sent.... 理解上面的信息需要对 TCP行为有着深刻的理解。下面是值的查找的示例指标: 相比接收的总数据包更高速率的包转发，检查服务器是否需要转发数据包 更高的数据段重传输率 套接字缓冲超限导致的数据包从接收队列中删除 重要字段: tcpListenDrops： tcp 丢包数量 netstat -nlp查询套接字信息：12345678# -l 表示只显示监听套接字# -t 表示只显示 TCP 套接字# -n 表示显示数字地址和端口(而不是名字)# -p 表示显示进程信息$ ss -ltnp | head -n 3State Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 127.0.0.53%lo:53 0.0.0.0:* users:(("systemd-resolve",pid=840,fd=13))LISTEN 0 128 0.0.0.0:22 0.0.0.0:* users:(("sshd",pid=1459,fd=3)) 其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。 套接字处于连接状态（Established）时: Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。 套接字处于监听状态（Listening）时 Recv-Q 表示全连接队列的长度(全连接队列的长度就是上一篇文章所说的侦听积压队列的长度) Send-Q 表示全连接队列的最大长度 2.3 ifconfig/ip12345678910111213141516ifconfigens33: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.44.128 netmask 255.255.255.0 broadcast 192.168.44.255 ether 00:0c:29:74:60:60 txqueuelen 1000 (Ethernet) # txqueuelen 为接口发送队列的长度 RX packets 59072 bytes 32261953 (30.7 MiB) # 同 netstat -i 的输出 RX errors 0 dropped 0 overruns 0 frame 0 TX packets 14288 bytes 2090118 (1.9 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0ip -s link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 RX: bytes packets errors dropped overrun mcast # 同 netstat -i 的输出 10284 108 0 0 0 0 TX: bytes packets errors dropped carrier collsns 10284 108 0 0 0 0 指标含义: 网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。 ifconfig txqueuelen: 表示接口发送队列的长度 对于速度较低的高延时设备，设置较小的值有助于预防高速的大量传输影响 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions errors 表示发生错误的数据包数，比如校验错误、帧同步错误等； dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包； overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包； carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等； collisions 表示碰撞数据包数。 2.4 pathcharpathchar ip: 作用: 类似于 traceroute，并且包括了每一跳间的带宽 缺点: 找不到可运行的版本，并且运行非常耗时 2.5 tcpdumptcpdump [选项] [过滤表达式] 作用: 捕获并分析网络数据包 原理: 基于 libpcap ，利用内核中的 AF_PACKET 套接字，抓取网络接口中传输的网络包 注意: CPU 和存储而言，捕获数据包是昂贵的，应在尽可能短的时间内使用 选项: -w file: -c NUM: 限制要抓取的网络包的个数 -A: 以 ASCII 格式显示网络包内容，不指定时只显示头部信息 -i: 指定网络接口卡 -nn: 禁止 IP 地址反解 -v: 显示数据包详细细节 -e: 显示链路层报头 -x: 十六进制地址转换 -ttt: 时间戳显示为数据包间的时间差 -tttt: 时间戳显示为第一个数据包以来的时间差 123456789101112131415# 1. 将 eth4 接口的数据写入文件tcpdump -i etch4 -w /tmp/out.tcpdump# 2. 从导出的文件中检查数据包tcpdump -nr /tmp/out.tcpdump# 3. 监听 etho0 tcp 80 端口的网络包tcpdump -i eth0 -n tcp port 80# 4. 监听DNS解析# -nn ，表示不解析抓包中的域名（即不反向解析）、协议以及端口号。# udp port 53 ，表示只显示 UDP 协议的端口号 53# host 35.190.27.188 ，表示只显示 IP 地址（包括源地址和目的地址）为 35.190.27.188 的包。# 中间的“ or ”，表示或的关系tcpdump -nn udp port 53 or host 35.190.27.188 2.6 WiresharkWireshark 也是最流行的一个网络分析工具，它最大的好处就是提供了跨平台的图形界面。跟 tcpdump 类似，Wireshark 也提供了强大的过滤规则表达式，同时，还内置了一系列的汇总分析工具。在实际分析网络性能时，先用 tcpdump 抓包，后用 Wireshark 分析，是一种常用的方法。 123$ tcpdump -nn udp port 53 or host 35.190.27.188 -w ping.pcap$ scp host-ip/path/ping.pcap .# 再用 Wireshark 打开 2.7 ethtoolethtool DEVICENAME 作用: 查看网络接口的各种信息 123456789101112131415161718192021222324252627ethtool enp0s3Settings for enp0s3: Supported ports: [ TP ] Supported link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Supported pause frame use: No Supports auto-negotiation: Yes Supported FEC modes: Not reported Advertised link modes: 10baseT/Half 10baseT/Full 100baseT/Half 100baseT/Full 1000baseT/Full Advertised pause frame use: No Advertised auto-negotiation: Yes Advertised FEC modes: Not reported Speed: 1000Mb/s # 网络接口的带宽 Duplex: Full Port: Twisted Pair PHYAD: 0 Transceiver: internal Auto-negotiation: on MDI-X: off (auto) Supports Wake-on: umbg Wake-on: d Current message level: 0x00000007 (7) drv probe link Link detected: yes 2.8 iftop2.9 nethogs3. 网络基准测试我们将从下往上，了解不同协议层的网络性能测试方法，包括: 转发性能 TCP/UDP 性能 HTTP 性能 应用负载性能 3.1 转发性能网络接口层和网络层，主要负责网络包的封装、寻址、路由以及发送和接收。在这两个网络协议层中，每秒可处理的网络包数 PPS，就是最重要的性能指标，特别是 64B 小包的处理能力。 hping3 和 pktgen 是网络性能测试的常用工具。 hping3hping3 作用: 可以构造 TCP/IP 协议数据包的工具 可以对系统进行安全审计、防火墙测试等 参数: -S: 表示设置TCP协议的SYN（同步序列号）， -p: 表示目的端口为80 -i u100: 表示每隔100微秒发送一个网络帧 –flood: 尽可能按最快速度发,不用回应 –rand-source: 使用随机源地址 123456# 1. 通过 TCP 测量网络延时# -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80$ hping3 -c 3 -S -p 80 baidu.com# --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析$ traceroute --tcp -p 80 -n baidu.com pktgenpktgen 是一个内核线程，需要加载 pktgen 内核模块，并通过 /proc 文件系统来交互。 123456$ modprobe pktgen$ ps -ef | grep pktgen | grep -v greproot 26384 2 0 06:17 ? 00:00:00 [kpktgend_0]root 26385 2 0 06:17 ? 00:00:00 [kpktgend_1]$ ls /proc/net/pktgen/kpktgend_0 kpktgend_1 pgctrl pktgen 在每个 CPU 上启动一个内核线程，并可以通过 /proc/net/pktgen 下面的同名文件，跟这些线程交互；而 pgctrl 则主要用来控制这次测试的开启和停止。 在使用 pktgen 测试网络性能时，需要先给每个内核线程 kpktgend_X 以及测试网卡，配置 pktgen 选项，然后再通过 pgctrl 启动测试。 3.2 TCP/UDP 性能传输层的 TCP 和 UDP，它们主要负责网络传输。对它们而言，吞吐量（BPS）、连接数以及延迟，就是最重要的性能指标。可以用 iperf 或 netperf ，来测试传输层的性能。 不过要注意，网络包的大小，会直接影响这些指标的值。所以，通常，需要测试一系列不同大小网络包的性能。 iperf1234567891011121314151617181920# 1. 安装yum install iperf3# 2. 在目标机器上启动 iperf 服务端：# -s表示启动服务端，-i表示汇报间隔，-p表示监听端口$ iperf3 -s -i 1 -p 10000# 3. 运行客户端，执行测试# -c表示启动客户端，192.168.0.30为目标服务器的IP# -b表示目标带宽(单位是bits/s)# -t表示测试时间# -P表示并发数，-p表示目标服务器监听端口$ iperf3 -c 192.168.0.30 -b 1G -t 15 -P 2 -p 10000# 4. 服务器端输出的测试报告# 包括测试时间、数据传输量以及带宽等[ ID] Interval Transfer Bandwidth...[SUM] 0.00-15.04 sec 0.00 Bytes 0.00 bits/sec sender[SUM] 0.00-15.04 sec 1.51 GBytes 860 Mbits/sec receiver 3.3 HTTP 性能应用层，最需要关注的是吞吐量（BPS）、每秒请求数以及延迟等指标。ab、webbench 是常用的 HTTP 压力测试工具。 ab1234567891011121314151617181920212223242526272829303132333435363738394041424344$ yum install -y httpd-tools# -c表示并发请求数为5000，# -n表示总的请求数为10万# -r表示套接字接收错误时仍然继续执行，# -s表示设置每个请求的超时时间为2s$ ab -c 5000 -n 100000 -r -s 2 http://192.168.0.30/# -c表示并发请求数为1000，-n表示总的请求数为10000$ ab -c 1000 -n 10000 http://192.168.0.30/...Server Software: nginx/1.15.8Server Hostname: 192.168.0.30Server Port: 80...Requests per second: 1078.54 [#/sec] (mean)# 平均延迟，包括了线程运行的调度时间和网络请求响应时间# 所有并发用户(这里是100)都请求一次的平均时间Time per request: 927.183 [ms] (mean)# 单个用户请求一次的平均时间Time per request: 0.927 [ms] (mean, across all concurrent requests)# 吞吐量Transfer rate: 890.00 [Kbytes/sec] receivedConnection Times (ms)# 建立连接、请求、等待以及汇总的时间 min mean[+/-sd] median maxConnect: 0 27 152.1 1 1038Processing: 9 207 843.0 22 9242Waiting: 8 207 843.0 22 9242Total: 15 233 857.7 23 9268Percentage of the requests served within a certain time (ms) 50% 23 66% 24 75% 24 80% 26 90% 274 95% 1195 98% 2335 99% 4663 100% 9268 (longest request) 3.4 应用负载性能 iperf 或者 ab 等测试工具得到某个页面的访问性能，但是真实的用户请求时带负载的。为了得到应用程序的实际性能，就要求性能工具本身可以模拟用户的请求负载。我们还可以用 wrk、TCPCopy、Jmeter 或者 LoadRunner 等实现这个目标。 ####wrk &lt;选项&gt; &lt;被测HTTP服务的URL&gt; Options: -c, –connections &lt;N&gt; 跟服务器建立并保持的TCP连接数量 -d, –duration &lt;T&gt; 压测时间 -t, –threads &lt;N&gt; 使用多少个线程进行压测 -s, –script &lt;S&gt; 指定Lua脚本路径 -H, –header &lt;H&gt; 为每一个HTTP请求添加HTTP头 –latency 在压测结束后，打印延迟统计信息 –timeout 超时时间 -v, –version 打印正在使用的wrk的详细版本信息 说明: &lt;N&gt;代表数字参数，支持国际单位 (1k, 1M, 1G) &lt;T&gt;代表时间参数，支持时间单位 (2s, 2m, 2h) wrk 工具本身不提供 yum 或 apt 的安装方法，需要通过源码编译来安装。 123456yum groupinstall 'Development Tools'yum install -y openssl-devel git git clone https://github.com/wg/wrk.git wrkcd wrkmakecp wrk /usr/local/bin/ 下面是 wrk 执行类似 ab 测试的示例:1234567891011# -c表示并发连接数1000，-t表示线程数为2$ wrk -c 1000 -t 2 http://192.168.0.30/Running 10s test @ http://192.168.0.30/ 2 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 65.83ms 174.06ms 1.99s 95.85% # 延迟 Req/Sec 4.87k 628.73 6.78k 69.00% 96954 requests in 10.06s, 78.59MB read Socket errors: connect 0, read 0, write 0, timeout 179Requests/sec: 9641.31 # 每秒请求数Transfer/sec: 7.82MB # 吞吐量 wrk 最大的优势，是其内置的 LuaJIT，可以根据实际需求，生成所需的请求负载，或者自定义响应的处理方法。wrk 在调用 Lua 脚本时，可以将 HTTP 请求分为三个阶段，即 setup、running、done，如下图所示： 12# -s 指定 lua 脚本$ wrk -c 1000 -t 2 -s auth.lua http://192.168.0.30/ 3.5 DNS 解析nslookup 和 dig 是DNS 解析的常用工具12345678910111213# 执行 dns 解析# -debug 开启 nslookup 的调试输出nslookup -debug time.geekbang.org# 反向解析nslookup -type=PTR 35.190.27.188 8.8.8.8# +trace表示开启跟踪查询# +nodnssec表示禁止DNS安全扩展$ dig +trace +nodnssec time.geekbang.org# -n 选项禁止名称解析$ ping -n -c3 geektime.org DNS 缓存DNS 通常使用UDP 协议，受网络抖动影响比较大。我们可以使用DNS 缓存来加速DNS解析。dnsmasq 是最常用的 DNS 缓存服务之一，还经常作为 DHCP 服务来使用。 12345# 启动 dnsmasq 服务systemctl start dnsmasq# 修改 /etc/resolv.conf，将 DNS 服务器改为 dnsmasq 的监听地址echo nameserver 127.0.0.1 &gt; /etc/resolv.conf 4. 网络内核优化4.1 TCP 优化 SYN FLOOD为了缓解 SYN FLOOD 等，利用 TCP 协议特点进行攻击而引发的性能问题，你可以考虑优化与 SYN 状态相关的内核选项: 增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）。 减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries 123456789101112131415# 1. 查看和就该积压队列的容量# 查看积压队列的容量sysctl net.ipv4.tcp_max_syn_backlog# 修改积压队列的容量sysctl -w net.ipv4.tcp_max_syn_backlog=1024net.ipv4.tcp_max_syn_backlog = 1024# 2. 查看和修改建立连接时，发送 SYN_RECV 失败重试次数sysctl -w net.ipv4.tcp_synack_retries=1net.ipv4.tcp_synack_retries = 1 # 3. 开启 TCP SYN cookiesysctl -w net.ipv4.tcp_syncookies=1net.ipv4.tcp_syncookies = 1 并发请求高在请求数比较大的场景下，会有大量处于 TIME_WAIT 状态的连接(短连接的方式，http 会成为主动断开连接的一方)，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项: 增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets 增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。 减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。 开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。 增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力。 增加最大文件描述符的数量。你可以使用 fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。 长连接在长连接的场景中，通常使用 Keepalive 来检测 TCP 连接的状态，以便对端连接断开后，可以自动回收。但是，系统默认的 Keepalive 探测间隔和重试次数，一般都无法满足应用程序的性能要求。所以，这时候你需要优化与 Keepalive 相关的内核选项，比如： 缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time； 缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl； 减少 Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes。 4.2 Socket 缓冲区为了提高网络的吞吐量，你通常需要调整这些缓冲区的大小，可调内核参数和参考值如下图所示: 需要注意的是: tcp_rmem 和 tcp_wmem 的三个数值分别是 min，default，max，系统会根据这些设置，自动调整 TCP 接收 / 发送缓冲区的大小。 udp_mem 的三个数值分别是 min，pressure，max，系统会根据这些设置，自动调整 UDP 发送缓冲区的大小。 表格中的数值只提供参考价值，具体应该设置多少，还需要你根据实际的网络状况来确定。比如，发送缓冲区大小，理想数值是吞吐量 * 延迟，这样才可以达到最大网络利用率。 4.3 网络层网络层，负责网络包的封装、寻址和路由，包括 IP、ICMP 等常见协议。在网络层，最主要的优化，其实就是对路由、 IP 分片以及 ICMP 等进行调优。 路由和转发从路由和转发的角度出发，可以调整下面的内核选项: 在需要转发的服务器中，比如用作 NAT 网关的服务器或者使用 Docker 容器时，开启 IP 转发，即设置 net.ipv4.ip_forward = 1。 调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl = 64。注意，增大该值会降低系统性能。 开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter = 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题。 MTU从分片的角度出发，最主要的是调整 MTU（Maximum Transmission Unit）的大小。在使用 VXLAN、GRE 等叠加网络技术时，要注意，网络叠加会使原来的网络包变大，导致 MTU 也需要调整。 比如，就以 VXLAN 为例，它在原来报文的基础上，增加了 14B 的以太网头部、 8B 的 VXLAN 头部、8B 的 UDP 头部以及 20B 的 IP 头部。换句话说，每个包比原来增大了 50B。所以，我们就需要把交换机、路由器等的 MTU，增大到 1550， 或者把 VXLAN 封包前（比如虚拟化环境中的虚拟网卡）的 MTU 减小为 1450。 现在很多网络设备都支持巨帧，如果是这种环境，你还可以把 MTU 调大为 9000，以提高网络吞吐量。 ICMP为了避免 ICMP 主机探测、ICMP Flood 等各种网络问题，你可以通过内核选项，来限制 ICMP 的行为。 可以禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all = 1。这样，外部主机就无法通过 ICMP 来探测主机 可以禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts = 1。 4.4 链路层链路层负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。自然，链路层的优化，也是围绕这些基本功能进行的。接下来，我们从不同的几个方面分别来看。 网络中断负载网络中断会消耗大量的CPU，需要在多个CPU间平衡负载： 你可以为网卡硬中断配置 CPU 亲和性（smp_affinity），或者开启 irqbalance 服务。 再如，你可以开启 RPS（Receive Packet Steering）和 RFS（Receive Flow Steering），将应用程序和软中断的处理，调度到相同 CPU 上，这样就可以增加 CPU 缓存命中率，减少网络延迟。 网络功能卸载现在的网卡都有很丰富的功能，原来在内核中通过软件处理的功能，可以卸载到网卡中，通过硬件来执行。 TSO（TCP Segmentation Offload）和 UFO（UDP Fragmentation Offload）：在 TCP/UDP 协议中直接发送大包；而 TCP 包的分段（按照 MSS 分段）和 UDP 的分片（按照 MTU 分片）功能，由网卡来完成 。 GSO（Generic Segmentation Offload）：在网卡不支持 TSO/UFO 时，将 TCP/UDP 包的分段，延迟到进入网卡前再执行。这样，不仅可以减少 CPU 的消耗，还可以在发生丢包时只重传分段后的包。 LRO（Large Receive Offload）：在接收 TCP 分段包时，由网卡将其组装合并后，再交给上层网络处理。不过要注意，在需要 IP 转发的情况下，不能开启 LRO，因为如果多个包的头部信息不一致，LRO 合并会导致网络包的校验错误。 GRO（Generic Receive Offload）：GRO 修复了 LRO 的缺陷，并且更为通用，同时支持 TCP 和 UDP。 RSS（Receive Side Scaling）：也称为多队列接收，它基于硬件的多个接收队列，来分配网络接收进程，这样可以让多个 CPU 来处理接收到的网络包。 VXLAN 卸载：也就是让网卡来完成 VXLAN 的组包功能。 网络接口卡最后，对于网络接口本身，也有很多方法，可以优化网络的吞吐量。 比如，你可以开启网络接口的多队列功能。这样，每个队列就可以用不同的中断号，调度到不同 CPU 上执行，从而提升网络的吞吐量。 再如，你可以增大网络接口的缓冲区大小，以及队列长度等，提升网络传输的吞吐量（注意，这可能导致延迟增大）。 你还可以使用 Traffic Control 工具，为不同网络流量配置 QoS。 DPDK 和 XDP使用 DPDK 技术，跳过内核协议栈，直接由用户态进程用轮询的方式，来处理网络请求。同时，再结合大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。 使用内核自带的 XDP 技术，在网络包进入内核协议栈前，就对其进行处理，这样也可以实现很好的性能。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.13 网络]]></title>
    <url>%2F2020%2F01%2F28%2Flinux_perf%2F32_%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[本节我们讲解网络相关的操作系统原理。网络分析的目的除了改进网络延时和吞吐量外，另一个常见的任务是消除可能由丢包引起的延时异常。网络分析是跨硬件和软件的。硬件指的是物理网络包括网络接口卡，交换机，路由器和网管。软件指的是内核协议栈。 1. 网络本节我们将从以下几个方面介绍网络相关的操作系统原理: 网络协议栈 TCP 连接状态转移 TCP 拥塞控制 操作系统的网络栈 最后我们会介绍网络相关的检测指标。想对网络深入了解，推荐大家阅读: CCNA学习指南 TCP/IP详解 卷1：协议 1. 网络协议栈网络的五层和七层模型想必大家都听过，下面是这两个协议栈模型的示意图: 数据经过网络协议栈时，通过包封装将每层协议的元数据添加到负载前(包头)，之后(包后)，或者二者，但不会修改负载数据。下面展示了以太网 TCP/IP 的栈封装过程: 数据就是这样经过封装，并通过路由器等网络设备在网络上进行传播，并最后被目标主机接收和解析。 2. TCP 状态转移下面是TCP建立连接三次握手和断开连接四次挥手，TCP 状态示意图: 实际传输过程中，服务器端收到客户端的 FIN 后，服务器端可以同时关闭连接，这样就可以把 ACK 和 FIN 合并到一起发送，节省了一个包，变成了“三次挥手”。 而如果服务器端收到客户端的 FIN 后，还没发送完数据，就会先回复客户端一个 ACK 包。稍等一会儿，完成所有数据包的发送后，才会发送 FIN 包。这也就是四次挥手了。 更详细的状态转移过程参见: TCP 状态转移 2.1 长连接和短连接长连接和短连接除了关闭连接的时机，更重要的是长连接需要有一个保活机制。 3. TCP 拥塞控制TCP 的滑动窗口，拥塞控制可以看这篇文章图解TCP 重传、滑动窗口、流量控制、拥塞控制发愁，图文并茂很容易理解。 3.1 Socket 连接选项Socket Api 提供了众多选项用于控制 TCP 的传输。常见的会影响传输性能的选项包括: TCP_QUICKACK: 取消延迟确认 延迟确认是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。 只有 TCP 套接字专门设置了 TCP_QUICKACK ，才会开启快速确认模式；否则，默认情况下，采用的就是延迟确认机制： TCP_NODELAY: 禁用 Nagle 算法 Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。它通过合并 TCP 小包，提高网络带宽的利用率。 Linux 上默认会启用 Nagle 算法，只有设置了 TCP_NODELAY 后才会禁用 当客户端的延迟确认和服务器端的 Negle 算法同时启用时会对网络性能造成非常明显的网络延时。通常都需要关闭Nagle 算法。 TCP_CORK: 开启 TCP_CORK 后，可以让小包聚合成大包后再发送（会阻塞小包的发送） SO_SNDBUF 和 SO_RCVBUF ，可以分别调整套接字发送缓冲区和接收缓冲区的大小 使用 strace 可以跟踪网络发送的系统调用，从而确认网络连接启用的 Socket 连接选项。 4. 操作系统的网络栈网络通信软件包括网络栈、TCP和设备驱动程序。下面是一个通用的网络栈模型。 ARP: 地址解析协议 Data Link(generic net driver): 数据链路，通用网络驱动软件 NIC: 网卡: 网卡是发送和接收网络包的基本设备。在系统启动过程中，网卡通过内核中的网卡驱动程序注册到系统中。而在网络收发过程中，内核通过中断跟网卡进行交互。 网络的收发的过程中，网卡硬中断只处理最核心的网卡数据读取或发送，而协议栈中的大部分逻辑，都会放到软中断中处理。 4.1 网络包收发过程 网络包的收过程当一个网络帧到达网卡后: 网卡会通过 DMA 方式，把这个网络包放到收包队列中；然后通过硬中断，告诉中断处理程序已经收到了网络包。 DMA(Direct Memory Access，直接存储器访问) 允许不同速度的硬件装置来沟通，而不需要依赖于 CPU 的大量中断负载 网卡中断处理程序会为网络帧分配内核数据结构（sk_buff），并将其拷贝到 sk_buff 缓冲区中；然后再通过软中断，通知内核收到了新的网络帧。 内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧。 在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。 网络层取出 IP 头，判断网络包下一步的走向,当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理 传输层取出 TCP 头或者 UDP 头后，根据 &lt; 源 IP、源端口、目的 IP、目的端口 &gt; 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。 最后，应用程序就可以使用 Socket 接口，读取到新接收到的数据了。 环形缓冲区，由于需要 DMA 与网卡交互，属于网卡设备驱动的范围。 sk_buff 缓冲区，是一个维护网络帧结构的双向链表，链表中的每一个元素都是一个网络帧（Packet）。虽然 TCP/IP 协议栈分了好几层，但上下不同层之间的传递，实际上只需要操作这个数据结构中的指针，而无需进行数据复制。 套接字缓冲区，则允许应用程序，给每个套接字配置不同大小的接收或发送缓冲区。应用程序发送数据，实际上就是将数据写入缓冲区；而接收数据，其实就是从缓冲区中读取。至于缓冲区中数据的进一步处理，则由传输层的 TCP 或 UDP 协议来完成。 sk_buff、套接字缓冲、连接跟踪等，都通过 slab 分配器来管理。你可以直接通过 /proc/slabinfo，来查看它们占用的内存大小。 网络包的发送过程网络包的发送方向，正好跟接收方向相反: 应用程序调用 Socket API（比如 sendmsg）发送网络包。由于这是一个系统调用，所以会陷入到内核态的套接字层中。套接字层会把数据包放到 Socket 发送缓冲区中。 接下来，网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理。 这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。 最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。 更加详细的收发过程详见Linux网络包收发总体过程 4.2 LinuxLinux 中 TCP，IP以及通用网络驱动软件是内核的核心组件，设备驱动程序是附加模块，数据包以 struct_sk_buff 数据类型穿过这些内核组件。通用驱动程序能通过合并中断提高性能。 数据包的高处理器率通过调用多个 CPU 处理包和 TCP/IP 栈。Linux3.7 记录了如下不同的方法: RSS，接收端缩放: 现代 NIC 支持多个队列并且计算包哈希以放置不同的队列，而后依次按直接中断由不同的 CPU 处理。这个哈希值可能基于 IP和TCP 端口，因此源自同一连接的包能被同一个 CPU 处理。 RPS，接收数据包转向: 对于不支持多队列的NIC的RSS关键实现。一个短中断服务例行程序映射传入的数据包给 CPU 处理，用一个类似的哈希按数据包头的字段映射数据包到 CPU RFS，接收流转向: 类似 RPS，不过偏向前一个处理套接字的CPU，以提高CPU缓存命中率和内存本地性 加速接收数据流转向: 对于支持该功能的NIC，这是 RFS 的硬件实现。它用流信息更新NIC以确定中断哪个CPU XPS，传输数据包转向: 对于支持多个传输队列的NIC，这支持多个 CPU传输队列 当缺乏数据包的CPU负载均衡时，NIC会中断同一个CPU，进而达到100% 的使用率并成为瓶颈。 基于例如RFS 实现的缓存一致性等因素而映射中断到多个 CPU，能显著提升网络性能。这样能通过 irqbalancer 进程实现，它能分配中断请求 IRQ 给 CPU。 注:NIC 是网络接口卡的简称 4.3 积压队列和缓冲积压队列突发的链接由积压队列处理。这里有两个队列: 一个在TCP 握手完成前处理未完成的连接，又称为SYN积压队列 另一个处理等待应用程序接受的已建立的会话，又称为侦听积压队列 有两个队列的情况下第一个可作为潜在的伪造连接的集结地，仅在连接建立后才迁移到第二个队列，此队列可以设置的很长以吸收海量 SYN，并且优化为仅存放最少的必要元数据第二个队列可由应用程序 listent() 的积压队列参数设置。 123456# 查看积压队列的容量sysctl net.ipv4.tcp_max_syn_backlog# 修改积压队列的容量sysctl -w net.ipv4.tcp_max_syn_backlog=1024net.ipv4.tcp_max_syn_backlog = 1024 缓冲利用套接字的发送和接收缓冲能够提升数据的吞吐量: 对于写通道，数据缓冲在 TCP发送缓冲区，然后送往IP发送。尽管IP协议有能力分段数据包，TCP仍试图发送 MSS 长度的段给IP以避免这种情况。这意味重发送单位对应分段的单位，否则一个被丢弃的数据段会导致整个分段前的数据包被重新传输。由于避免了分段和组装常规数据包，这种实现方式提升了 TCP/IP 栈的效率。 缓冲区的大小是可调整的。Linux 会基于连接的活跃度自动调节缓冲区大小。 网络设备驱动网络设备驱动通常还有一个附加的缓冲区(环形缓冲区 DMA)用于在内核内存与NIC间发送和接收数据包。 随着10GbE以太网网的引入，利用中断结合模式的利于性能的功能愈发常见。一个中断仅仅在计时器激活或者达到一定数据量的包时才被发送，而不是每当有数据包达到就中断内核。这降低了内核与 NIC 通信的频率。允许缓冲更多的发送，从而达到更高的吞吐量。 5. 网络监测下面是网络常用的性能测量指标: 延时 带宽: 表示链路的最大传输速率 吞吐量: 表示单位时间内成功传输的数据量，吞吐量 / 带宽，也就是该网络的使用率。 PPS: PPS，是 Packet Per Second（包 / 秒），表示以网络包为单位的传输速率。 PPS 通常用来评估网络的转发能力。基于 Linux 服务器的转发，很容易受到网络包大小的影响 交换机通常不会受到太大影响，可以做到线性转发 对于数据库、缓存等系统，快速完成网络收发，即低延迟，是主要的性能目标 应用层指标: 网络的可用性（网络能否正常通信） 并发连接数（TCP 连接数量） 丢包率（丢包百分比） 重传率（重新传输的网络包比例）等也是常用的性能指标。 DNS DDos 拒绝服务攻击 总的来说，先要获得网络基准测试报告，然后通过相关性能工具，定位出网络性能瓶颈。在优化网络性能时，可以结合 Linux 系统的网络协议栈和网络收发流程，然后从应用程序、套接字、传输层、网络层再到链路层等，进行逐层优化。 5.1 延时延时是一个重要的网络性能指标，并且有多种测量方法，包括: 主机名解析延时 ping 延时: 往返延时 RTT（Round-Trip Time） 连接延时 首字节延时 往返延时 除了使用 ping， traceroute 或 hping3 的 TCP 和 UDP 模式，也可以获取网络延迟。 12345678910# 1. 通过 TCP 测量网络延时# -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80$ hping3 -c 3 -S -p 80 baidu.com# --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析$ traceroute --tcp -p 80 -n baidu.com# 使用 wrk 可以测量并发连接的延时# 测试80端口性能$ wrk --latency -c 100 -t 2 --timeout 2 baidu.com 网络延时的排查思路在发现网络延迟增大后，你可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如: 使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。 使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。 使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。 使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。 这样，就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源。 5.2 带宽、吞吐量和PPS网络吞吐量和 PPS 可以使用 sar 命令查看。带宽的查看可以使用 ethtool 工具。 使用率网络连接口的使用率可以用当前的吞吐量除以最大带宽来计算。但是考虑到可变的带宽和自动协商的双工模式，计算不像看上去那么简单。对于全双工，使用率适合每个方向且用该方向当前的吞吐量除以当前协商的带宽来计算。 饱和度测量连接积压队列导致的丢包是一种衡量网络连接饱和度的方法 5.2 DNSDNS 不仅方便了人们访问不同的互联网服务，更为很多应用提供了，动态服务发现和全局负载均衡（Global Server Load Balance，GSLB）的机制。这样，DNS 就可以选择离用户最近的 IP 来提供服务。即使后端服务的 IP 地址发生变化，用户依然可以用相同域名来访问。 DNS 解析是基础而重要的一个环节。我们需要关注它的性能。 可以借助 nslookup 或者 dig 的调试功能，分析 DNS 的解析过程，再配合 ping 等工具调试 DNS 服务器的延迟，从而定位出性能瓶颈。 DNS 有如下几种常见的优化方法: 对 DNS 解析的结果进行缓存 对 DNS 解析的结果进行预取。这是浏览器等 Web 应用中最常用的方法 使用 HTTPDNS 取代常规的 DNS 解析。这是很多移动应用会选择的方法，特别是如今域名劫持普遍存在，使用 HTTP 协议绕过链路中的 DNS 服务器，就可以避免域名劫持的问题。 基于 DNS 的全局负载均衡（GSLB）。这不仅为服务提供了负载均衡和高可用的功能，还可以根据用户的位置，返回距离最近的 IP 地址。 5.3 DDos 拒绝服务攻击DDos 的类型DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。 DDoS 可以分为下面几种类型。 第一种，耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。 第二种，耗尽操作系统资源 第三种，耗尽应用程序资源 DDoS 并不一定是因为大流量或者大 PPS，有时候，慢速的请求也会带来巨大的性能下降（这种情况称为慢速 DDoS）。比如，很多针对应用程序的攻击，都会伪装成正常用户来请求资源。这种情况下，请求流量可能本身并不大，但响应流量却可能很大，并且应用程序内部也很可能要耗费大量资源处理。 DDos 的缓解方案针对DDos 我们有一下方法缓解其影响: 单源Dos攻击: 通过防火墙禁止特定源的访问 限制syn并发数 限制单个IP在60秒新建立的连接数 扩大半开状态的连接数 减少每个 SYN_RECV 失败时的重试次数 使用 TCP SYN Cookies 多源DDos: 只能缓解，而无法彻底解决 在服务器外部的网络设备中，设法识别并阻断流量（当然前提是网络设备要能扛住流量攻击）。比如，购置专业的入侵检测和防御设备，配置流量清洗设备阻断恶意流量等。 针对应用，需要应用程序考虑识别，并尽早拒绝掉这些恶意流量，比如合理利用缓存、增加 WAF（Web Application Firewall）、使用 CDN 等等。 下面是用 hping3 模拟 Dos，并尝试缓解 Dos 攻击的示例:123456789101112131415161718192021222324252627# 1. 构造一个 SYN 泛洪攻击# -S参数表示设置TCP协议的SYN（同步序列号），# -p表示目的端口为80# -i u10表示每隔10微秒发送一个网络帧# --flood 尽可能按最快速度发,不用回应# --rand-source 使用随机源地址$ hping3 -S -p 80 -i u10 --flood --rand-source 192.168.0.30# 1. SYN 泛洪攻击对策 -- 针对单个源# 限制syn并发数为每秒1次$ iptables -A INPUT -p tcp --syn -m limit --limit 1/s -j ACCEPT# a.限制单个IP在60秒新建立的连接数为10$ iptables -I INPUT -p tcp --dport 80 --syn -m recent --name SYN_FLOOD --update --seconds 60 --hitcount 10 -j REJECT# b.查看半连接容量并修改积压队列的容量sysctl net.ipv4.tcp_max_syn_backlogsysctl -w net.ipv4.tcp_max_syn_backlog=1024net.ipv4.tcp_max_syn_backlog = 1024# c.连接每个 SYN_RECV 时，如果失败的话，内核还会自动重试，# 默认的重试次数是 5 次。可将其减小为 1 次：sysctl -w net.ipv4.tcp_synack_retries=1net.ipv4.tcp_synack_retries = 1# d.TCP SYN Cookies 也是一种专门防御 SYN Flood 攻击的方法 TCP SYN Cookies: 是基于连接信息（包括源地址、源端口、目的地址、目的端口等）以及一个加密种子（如系统启动时间），计算出一个哈希值（SHA1），这个哈希值称为 cookie。 然后，这个 cookie 就被用作序列号，来应答 SYN+ACK 包，并释放连接状态。 当客户端发送完三次握手的最后一次 ACK 后，服务器就会再次计算这个哈希值，确认是上次返回的 SYN+ACK 的返回包，才会进入 TCP 的连接状态。 因而，开启 SYN Cookies 后，就不需要维护半开连接状态了，进而也就没有了半连接数的限制。 开启 TCP syncookies 后，内核选项 net.ipv4.tcp_max_syn_backlog 也就无效了。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.12 磁盘动态追踪]]></title>
    <url>%2F2020%2F01%2F27%2Flinux_perf%2F32_%E7%A3%81%E7%9B%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[本节我们来介绍磁盘的动态追踪技术 1. Systemtab 磁盘追踪Dtrace/Systemtab 能从内核角度检查磁盘 I/O 时间，包括: 块设备接口 I/O I/O 调度器事件 目标驱动 I/O 设备驱动 I/O 1.1 Dtrace下面列出了用来跟踪磁盘 I/O 的Dtrace provider 层次 稳定 provider 不稳定 provider 应用程序 取决于应用 pid 系统库 pid 系统调用 syscall VFS fsinfo fbt 文件系统 fbt 块设备接口 io fbt 目标驱动 fbt 设备驱动 fbt io providerio provider 使得外界可以从块设备几口的角度进行观察，以支持工作负载特征归纳和延时分析。其提供了如下的探测器: io:::start: 一个I/O请求被发到设备上 io:::end: 一个 I/O请求在设备上完成(完成中断) io:::wait-start: 一个线程开始等待一个 I/O 请求 io:::wait-down: 一个线程等完了一个 I/O 请求 探测器有一些稳定的参数提供 I/O 的详细信息，如下所示:|语法|作用|说明||:—|:—|:—||args[0]-&gt;b_count|I/O 大小(字节数)|||args[0]-&gt;b_blkno|设备 I/O 偏移量(块)|||args[0]-&gt;b_flags|位元标志位，包括表示读I/O的B_READ|||args[0]-&gt;b_error|错误状态|||args[0]-&gt;dev_statname|设备实例名+实例/小编号|||args[0]-&gt;dev_pathname|设备路径名|||args[0]-&gt;fi_pathname|文件系统名|||args[0]-&gt;fi_fs|文件系统类型|| I/O方向(读写) 可以使用表达式 args[0]-&gt;b_flags &amp; B_READ ? &quot;read&quot;: &quot;write&quot; 1.2 SystemtapSystemtap 提供了用于跟踪磁盘 I/O 的 ioblock.stp tapset，其包含了下面这些探针: DTrace Systemtap 描述 io:::start ioblock.request io:::done ioblock.end ioblock.requestioblock.request 内置了下面的变量来提供 I/O 的详细信息。|变量|内容||:—|:—||name | probe point 名称||devname | 设备名称||ino | inode number of the mapped file||sector | beginning sector for the entire bio||flags | see belowBIO_UPTODATE 0 ok after I/O completionBIO_RW_BLOCK 1 RW_AHEAD set, and read/write would blockBIO_EOF 2 out-out-bounds errorBIO_SEG_VALID 3 nr_hw_seg valid BIO_CLONED 4 doesn’t own dataBIO_BOUNCED 5 bio is a bounce bioBIO_USER_MAPPED 6 contains user pagesBIO_EOPNOTSUPP 7 not supported||rw | binary trace for read/write request||vcnt | bio vector count which represents number of array element (page, offset, length) which make up this I/O request||idx | offset into the bio vector array||phys_segments | number of segments in this bio after physical address coalescing is performed||hw_segments | number of segments after physical and DMA remapping hardware coalescing is performed||size | total size in bytes||bdev | target block device||bdev_contains | points to the device object which contains the partition (when bio structure represents a partition)||p_start_sect | points to the start sector of the partition structure of the device| ioblock.end除了上面这些变量，ioblock.end 还提供了下面这些变量来提供I/O的结果|变量|内容||:—|:—||bytes_done |number of bytes transferred||error|0 on succes| 2. 磁盘跟踪示例下面的 Dtrace 脚本位于 https://github.com/opendtrace/toolkit/blob/master/Disk/seeksize.d 2.1 事件跟踪以下跟踪的是每一个磁盘I/O请求12345# dtrace:&gt; dtrace -n 'io:::start &#123;printf("%d %s %d", pid, execname, args[0]-&gt;b_bcount);&#125;'# stap&gt; stap -ve 'probe ioblock.request &#123;printf("%d %s %d\n", pid(), execname(), size)&#125;' 2.2 按照应用程序名汇总磁盘 I/O 大小123456# dtrace:&gt; dtrace -n 'io:::start &#123;@[execname]=quantize(arg[0]-&gt;b_bcount)&#125;'# stap&gt; stap -ve 'global s;probe ioblock.request &#123;s[execname()] &lt;&lt;&lt; size&#125; probe end &#123;foreach (k in s)&#123;printf("%s\n", k);print(@hist_log(s[k]))&#125;;&#125;' 2.3 I/O 寻道汇总下面的脚本跟踪同一应用程序，同一设备的连续 I/O 之间寻道距离，按照进程输出直方图。 dtrace 脚本1234567891011121314151617181920212223242526272829303132333435363738#!/usr/sbin/dtrace -sdtrace:::BEGIN&#123; printf("Tracing... Hit Ctrl-C to end.\n");&#125;self int last[dev_t];/* * Process io start */io:genunix::start/self-&gt;last[args[0]-&gt;b_edev] != 0/&#123; /* calculate seek distance */ this-&gt;last = self-&gt;last[args[0]-&gt;b_edev]; this-&gt;dist = (int)(args[0]-&gt;b_blkno - this-&gt;last) &gt; 0 ? args[0]-&gt;b_blkno - this-&gt;last : this-&gt;last - args[0]-&gt;b_blkno; /* store details */ @Size[pid, curpsinfo-&gt;pr_psargs] = quantize(this-&gt;dist);&#125;io:genunix::start&#123; /* save last position of disk head */ self-&gt;last[args[0]-&gt;b_edev] = args[0]-&gt;b_blkno + args[0]-&gt;b_bcount / 512;&#125;/* * Print final report */dtrace:::END&#123; printf("\n%8s %s\n", "PID", "CMD"); printa("%8d %S\n%@d\n", @Size);&#125; stap 脚本未完成 2.3 I/O 延时汇总下面的脚本跟踪块I/O开始和结束的时间123456789101112131415# dtrace&gt; dtrace -n 'io:::start &#123;start[arg0] = timestamp;&#125; io:::done /start[arg0]/ &#123;@["block I/O(ns)"] = quantize(timestamp - start[arg0]);start[arg0] = 0&#125;'# stap&gt; stap -ve 'global t,s; probe ioblock.request &#123;t[$bio] = gettimeofday_ns();&#125; probe ioblock.end &#123;if (t[$bio]) &#123;s &lt;&lt;&lt; gettimeofday_ns() - t[$bio];delete t[$bio];&#125; &#125; probe end&#123;print(@hist_log(s))&#125;' 3.高级工具磁盘常用的高级跟踪脚本: DTrace: https://github.com/opendtrace/toolkit Systemp: https://sourceware.org/systemtap/SystemTap_Beginners_Guide/mainsect-disk.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.11 磁盘监测命令]]></title>
    <url>%2F2020%2F01%2F26%2Flinux_perf%2F31_%E7%A3%81%E7%9B%98%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本节我们来介绍磁盘相关的监测工具。 1. 命令总览下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了磁盘相关的性能检测工具: 从磁盘的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握磁盘分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍如下磁盘专用的分析工具的使用 Linux Solaris 作用 说明 iostat iostat 各种单个磁盘的统计信息 pidstat,iotop iotop 按进程列出磁盘I/O使用情况 blktrace iosnoop 磁盘I/O事件追踪 MegaCli MegaCli LSI控制统计信息 smartctl smartctl 磁盘控制器统计信息 sar sar 磁盘历史统计信息 通用命令，位于独立的一节中 lsof lsof 查看进程打开的文件列表 biosnoop biosnoop 跟踪进程的块设备I/O大小 bcc工具包 biotop biotop 跟踪进程块I/O大小并实时排序 bcc工具包 除此之外，还包括以下内容: 磁盘性能测试 磁盘性能调优 2. 磁盘统计命令2.1 iostatiostat options [interval [count]] 作用: 单个磁盘的统计信息，统计信息的来源直接由内核维护，几乎没有开销 默认: 打印自启动以来的 -c和-d 选项的汇总报告 说明: SCSI 设备包括磁带和 CD-ROM 在当前Linux 不会显示 来源: iostat 的数据来自 /proc/diskstats 参数: -c: 显示 CPU 报告 -d: 显示磁盘报告 -k: 使用 KB代替(512B)块数量 -m: 使用 MB代替(512B)块数量 -p: 包括单个分区的统计信息 -t: 时间戳输出 -x: 扩展统计信息 -z: 不显示空活动汇总 1234567891011 iostat Linux 3.10.0-1062.el7.x86_64 (hostname) 2020年04月21日 _x86_64_ (1 CPU)# 启动以来的CPU和磁盘设备统计信息avg-cpu: %user %nice %system %iowait %steal %idle 0.39 0.00 0.22 0.01 0.00 99.37Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtnsda 1.71 67.68 5.39 925064 73658dm-0 1.64 65.32 5.24 892891 71574dm-1 0.01 0.16 0.00 2204 0 输出: tps: IOPS 每秒事务数 kB_read/s: 每秒读KB数 kB_wrtn/s: 每秒写KB数 kB_read: 总读取KB数 kB_wrtn: 总写入KB数 扩展输出1234567iostat -xkdz 1Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月21日 _x86_64_ (1 CPU)Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilsda 0.00 0.07 1.37 0.29 65.70 5.25 85.36 0.00 1.38 0.69 4.60 0.48 0.08dm-0 0.00 0.00 1.28 0.32 63.41 5.10 85.88 0.00 1.67 0.72 5.46 0.49 0.08dm-1 0.00 0.00 0.01 0.00 0.16 0.00 50.09 0.00 0.23 0.23 0.00 0.17 0.00 输出 含义 rrqm/s 每秒合并放入驱动请求队列的读请求数 wrqm/s 每秒合并放入驱动请求队列的写请求数 r/s 每秒发给磁盘设备的读请求书，这是实际发给磁盘的请求数 w/s 每秒发给磁盘设备的写请求书，这是实际发给磁盘的请求数 rkB/s 每秒从磁盘设备读取的 KB 数 wkB/s 每秒向磁盘设备写入的 KB 数 avgrq-sz 平均请求大小，单位为扇区(512B) avgqu-sz 在驱动请求队列和在设备中活跃的平均请求数 await 平均I/O响应时间，包括在驱动请求队列里等待和设备的I/O响应时间(ms) r_await 同awit，不过只针对读 w_await 同awit，不过只针对写 svctm 推断的磁盘设备的I/O平均响应时间 %util 使用率，设备忙处理I/O请求的百分比 说明: 非零的 rrqm/s 和 wrqm/s 说明为了提高性能，连续的请求在发往设备之前已经被合并了，这个指标也是工作负载为连续的标志 avgrq-sz 是合并之后的数字，小尺寸(16个扇区或者更小)可以视为无法合并的随机I/O负载。大尺寸有可能是大I/O，或者是合并的连续负载 r/s+w/s ，就是 IOPS； rkB/s+wkB/s ，就是吞吐量； r_await+w_await ，就是响应时间。 2.2 iotopiotop options 作用: 参数: -o, –only只显示正在产生I/O的进程或线程。除了传参，可以在运行过程中按o生效 -P, –processes仅显示进程，默认iotop显示所有线程 -a, –accumulated显示累积的I/O，而不是带宽 -d SEC, –delay=SEC设置每次监测的间隔，默认1秒，接受非整形数据例如1.1 -p PID, –pid=PID指定监测的进程/线程 -u USER, –user=USER指定监测某个用户产生的I/O -k, –kilobytes使用kB单位，而不是对人友好的单位。在非交互模式下，脚本编程有用 -b, –batch非交互模式，一般用来记录日志。 -n NUM, –iter=NUM设置监测的次数，默认无限。在非交互模式下很有用 -t, –time 加上时间戳，非交互非模式 -q, –quiet 禁止头几行，非交互模式。有三种指定方式 -q 只在第一次监测时显示列名 -qq 永远不显示列名 -qqq 永远不显示I/O汇总。 交互按键： left和right方向键：改变排序 r：反向排序 o：切换至选项–only p：切换至–processes选项 a：切换至–accumulated选项 q：退出 i：改变线程的优先级 123456$ iotopTotal DISK READ : 0.00 B/s | Total DISK WRITE : 7.85 K/s Actual DISK READ: 0.00 B/s | Actual DISK WRITE: 0.00 B/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO&gt; COMMAND 15055 be/3 root 0.00 B/s 7.85 K/s 0.00 % 0.00 % systemd-journald 指标含义: SWAPIN, IO&gt;: 表示换入和等待 I/O 的时钟百分比等。 2.3 disktop.stp 作用: disk 值的是从用户角度看的磁盘的读写 原理: 通过跟踪VFS实现 安装: https://github.com/dengliu/systemtap 123456789101112131415&gt; git clone git clone https://github.com/dengliu/systemtap&gt; cd systemtap&gt; stap -v disktop.stpTue Apr 21 14:59:27 2020 , Average: 5Kb/sec, Read: 27Kb, Write: 0Kb UID PID PPID CMD DEVICE T BYTES 0 9084 9083 pgrep dm-0 R 17864 0 9081 9080 awk dm-0 R 2888 0 9086 9082 awk dm-0 R 2888 0 9087 801 sleep dm-0 R 1224 0 9081 9080 ksmtuned dm-0 R 788 0 9084 9083 ksmtuned dm-0 R 788 0 9086 9082 ksmtuned dm-0 R 788 0 9087 801 ksmtuned dm-0 R 788 0 1067 1 rs:main Q:Reg dm-0 W 120 2.4 iosnoopiosnoop [-hQst] [-d device] [-i iotype] [-p PID] [-n name] 原理: 通过块设备接口同时跟踪所有磁盘，并为每个磁盘I/O打印一条输出 作用: 有助于跟踪和延时分析 位置: https://github.com/brendangregg/perf-tools 参数 -d device # device string (eg, “202,1) -i iotype # match type (eg, ‘R‘ for all reads) -n name # process name to match on I/O issue -p PID # PID to match on I/O issue -Q # use queue insert as start time -s # include start time of I/O (s) -t # include completion time of I/O (s) -h # this usage message duration # duration seconds, and use buffers 命令选项组合 作用 iosnoop watch block I/O live (unbuffered) iosnoop 1 trace 1 sec (buffered) iosnoop -Q include queueing time in LATms iosnoop -ts include start and end timestamps iosnoop -i &#39;*R*&#39; trace reads iosnoop -p 91 show I/O issued when PID 91 is on-CPU iosnoop -Qp 91 show I/O queued by PID 91, queue time 输出12345678910&gt; git clone https://github.com/brendangregg/perf-tools&gt; cd perf-tools/bin&gt; ll iosnooplrwxrwxrwx. 1 tao tao 10 4月 21 23:03 iosnoop -&gt; ../iosnoop&gt; sudo ./iosnoopTracing block I/O. Ctrl-C to end.COMM PID TYPE DEV BLOCK BYTES LATms&lt;idle&gt; 0 WM 8,0 10911200 16384 1.48&lt;idle&gt; 0 WM 8,0 30932994 512 1.47&lt;idle&gt; 0 WM 8,0 30933056 16384 1.47 iosnoop 输出: COMM: 进程名 PID TYPE: DEV: BLOCK: 磁盘块地址，可以看出IO是否随机 BYTES: I/O 大小 LATms: 2.5 blktraceblktrace 是一个 Linux 块设备I/O事件，包括 用来跟踪和缓冲数据的内核组件 供用户态工具使用的控制和报告机制 命令: blktrace: 启用内核驱动跟踪机制获取跟踪裸数据 blkparse: 处理blktrace的数据并产生输出 btrace: 合并调用上述两个程序，下面的程序是等价的 12&gt; blktrace -d /dev/sda -o -|blkparse -i -&gt; btrace /dev/sda btrace 使用btrace [-s] [-t] [-w N] [-n N] [-b N] [-r &lt;dbg mnt&gt;] [-a &lt;trace&gt;...] &lt;dev&gt;... 选项: -a trace: 设置活动的过滤条件 -a issue: 值跟踪 D活动(发出I/O) -a read: 仅跟踪读 -a write: 仅跟踪写 -a sync: 跟踪同步操作 活动标识 活动标识 作用 A IO was remapped to a different device B IO bounced C IO completion D IO issued to driver F IO front merged with request on queue G Get request I IO inserted onto request queue M IO back merged with request on queue P Plug request Q IO handled by request queue code S Sleep request T Unplug due to timeout U Unplug request X Split 12345678910111213141516171819&gt; sudo btrace /dev/sda 8,0 0 1 0.000000000 0 C R 82106200 + 32 [0] 8,2 0 2 0.000152172 11194 A R 80007032 + 64 &lt;- (253,0) 75810680 8,0 0 3 0.000152439 11194 A R 82106232 + 64 &lt;- (8,2) 80007032 8,0 0 4 0.000153208 11194 Q R 82106232 + 64 [blkparse] 8,0 0 5 0.000155426 11194 G R 82106232 + 64 [blkparse] 8,0 0 6 0.000155991 11194 P N [blkparse] 8,0 0 7 0.000157235 11194 I R 82106232 + 64 [blkparse] 8,0 0 8 0.000157845 11194 U N [blkparse] 1 8,0 0 9 0.000158495 11194 D R 82106232 + 64 [blkparse] 8,0 0 10 0.000561421 0 C R 82106232 + 64 [0]^CCPU0 (8,0): Reads Queued: 1, 32KiB Writes Queued: 0, 0KiB Read Dispatches: 1, 32KiB Write Dispatches: 0, 0KiB Reads Requeued: 0 Writes Requeued: 0 Reads Completed: 2, 48KiB Writes Completed: 0, 0KiB Read Merges: 0, 0KiB Write Merges: 0, 0KiB Read depth: 1 Write depth: 0 IO unplugs: 1 Timer unplugs: 0 输出默认情况下有 7 列: 设备主次号 CPU ID 序号 活动时间 进程ID 活动标识符 RWBS 描述: R-读，W-写，D-块丢弃，B-屏蔽操作，S-同步 后面的输出取决于活动，82106232 + 64 [blkparse] 表示一个位于地址 82106232，大小为 64 扇区，来源于 blkparse 进程 2.6 MegaCli磁盘控制器(主机总线适配器)由系统外部的硬件和固件组成。操作系统分析工具，甚至是动态追踪都无法直接观察他们。某些特定的磁盘控制器有专门的分析工具，例如 LSI 的MegaClie 2.6 smartctl磁盘有控制磁盘操作的逻辑，包括排队、缓存和错误处理。与磁盘控制器类似，操作系统不能直接看到磁盘的内部行为，这些信息通过观察 I/O请求和延时来推断。 许多现代驱动器提供了 SMART(自监控分析和报告分析)数据。 2.7 lsoflsof options 作用: 查看进程打开文件列表，文件包括了普通文件、目录、块设备、动态库、网络套接字等。 参数: -p: 指定进程ID -a：列出打开文件存在的进程； -c&lt;进程名&gt;：列出指定进程所打开的文件； -g：列出GID号进程详情； -d&lt;文件号&gt;：列出占用该文件号的进程； +d&lt;目录&gt;：列出目录下被打开的文件； +D&lt;目录&gt;：递归列出目录下被打开的文件； -n&lt;目录&gt;：列出使用NFS的文件； -i&lt;条件&gt;：列出符合条件的进程。（4、6、协议、:端口、 @ip ） -u：列出UID号进程详情； -h：显示帮助信息； -v：显示版本信息。 1234567$ lsof -p 18940 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME python 18940 root cwd DIR 0,50 4096 1549389 / python 18940 root rtd DIR 0,50 4096 1549389 / … python 18940 root 2u CHR 136,0 0t0 3 /dev/pts/0 python 18940 root 3w REG 8,1 117944320 303 /tmp/logtest.txt 指标含义: FD: 表示文件描述符号 TYPE: 表示文件类型 NAME: 表示文件路径 DEVICE: 主次设备号 3. I/O 性能测试在基准测试时，一定要注意根据应用程序 I/O 的特点，来具体评估指标。这就需要你测试出，不同 I/O 大小（一般是 512B 至 1MB 中间的若干值）分别在随机读、顺序读、随机写、顺序写等各种场景下的性能情况。 3.1 hdparm4.磁盘调优4.1 操作系统ioniceionice -c 3 -p 1623 作用: 设置一个进程的 I/O 调度级别和优先级 级别: 0: 无，不指定优先级，内核会挑选一个默认值-尽力 1: 实时，对磁盘的最高级别访问，如果误用会导致其他进程饿死 2: 尽力，默认调度级别，包括优先级 0-7,0 为最高级 3: 空闲，在一段磁盘空闲的期间过后才允许进行 I/O 参数: -c: 指定级别 -p: 指定进程 可调参数 /sys/block/sda/queue/scheduler 作用: 选择I/O调度策略 /sys/block/sdb/queue/read_ahead_kb 作用: 调整 /dev/sdb 磁盘预读的大小 默认大小是 128 KB，单位为 KB /sys/block/sdb/queue/nr_requests 作用: 调整内核磁盘队列的长度 适当增大队列长度，可以提升磁盘的吞吐量（当然也会导致 I/O 延迟增大）。 磁盘故障检测可以通过 dmesg 查看是否有硬件 I/O 故障的日志。 还可以使用 badblocks、smartctl 等工具，检测磁盘的硬件问题，或用 e2fsck 等来检测文件系统的错误。如果发现问题，你可以使用 fsck 等工具来修复。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.10 磁盘]]></title>
    <url>%2F2020%2F01%2F25%2Flinux_perf%2F30_%E7%A3%81%E7%9B%98%2F</url>
    <content type="text"><![CDATA[本节我们来介绍磁盘相关的操作系统原理。磁盘I/O可能会造成严重性能的问题(注意是可能)。在高负载下，磁盘成为瓶颈，CPU 持续空转以等待磁盘磁盘I/O结束。 1. 磁盘相关的操作原理我们将从下面几个方面入手来讲解磁盘相关的操作系统原理: 磁盘的基础知识 磁盘I/O栈 最后我们会说一说磁盘检测的相关指标。 2. 磁盘的基础知识这一部分内容与磁盘的构造相关，能帮助解释为什么磁盘慢。目前我们使用的磁盘主要有两种类型: 磁性旋转机械盘，也就是我们常说的机械硬盘 基于闪存的 SSD 2.1 机器硬盘机械硬盘(hard disk drive HDD) 由机械手臂，磁头，盘片组成。慢I/O通常由磁头寻道时间,盘片旋转时间造成。 磁盘缓存这些磁盘共有的一个部件是一小块内存(RAM)用来缓存读取的结果和缓冲要写入的数据。还允许I/O命令在设备上排队，以更高效的方式重新排序。 电梯寻道电梯算法又名电梯寻道是提高命令队列效率的一种方式。它根据磁盘位置把I/O重新排序，最小化磁头的移动。电梯算法会容易对偏移量远的I/O操作造成饥饿。 ECC磁盘在每个扇区的结尾存储了一个纠错码，以便在数据读取时进行验证并有可能纠错。如果验证失败，可能发生重读，这可能是异常缓慢I/O的原因。检查操作系统和磁盘上的错误计数器以确认。 2.2 SSD固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，所以，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。 固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还是差了很多。 3. 磁盘I/O栈磁盘I/O栈的组件和层次取决于操作系统、版本和采用的软硬件技术。下面延时了一个通用模型: Block Device Interface: 块设备接口 Buffer Cache: 缓冲区高速缓存 Target I/O Driver: 目标I/O驱动 Multpathing I/O Driver: 多路I/O驱动 Host Bus Adaptor Driver: 主机总线适配器 3.1 Linux的块层Linux 中，磁盘实际上是作为一个块设备来管理的。每个块设备都会被赋予两个设备号，分别是主、次设备号。主设备号用在驱动程序中，用来区分设备类型；而次设备号则是用来给多个同类设备编号。 块I/O设备一般可以通过 iostat 监控。Linux 改进了内核组成了块层。通用块层，其实是处在文件系统和磁盘驱动中间的一个块设备抽象层，主要有两个作用: 第一个功能跟虚拟文件系统的功能类似。向上，为文件系统和应用程序，提供访问块设备的标准接口；向下，把各种异构的磁盘设备抽象为统一的块设备，并提供统一框架来管理这些设备的驱动程序。 第二个功能 I/O调度器: 通用块层会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。 下面是 Linux 块层的示意图: Virtual Block Driver: 虚拟快驱动 Elevator Layer: 电梯层 I/O Scheduler: I/O 调度器 Physical Block Driver: 物理块驱动 电梯层提供了通用功能，例如排序，合并以及聚合请求发送。 I/O调度器使 I/O 能够排队排序或者重新调度以优化发送，具体由调度策略决定，可用的策略如下: 空操作: 不调度 截止时间: 试图强制给延迟设置截止时间 预期: 通过启发式方法预测I/O CFQ: 完全公平调度器 3.2 I/O 栈结合文件系统和今天的内容，我们可以把 Linux 存储系统的 I/O 栈，由上到下分为三个层次: 文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据 通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统和应用程序的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层。 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。 4.磁盘检测下面是磁盘常用的性能测量指标: IOPS 使用率 饱和度 IOPS 很难横向比较，有意义的IOPS需要包含其他细节: 随机I/O还是连续I/O I/O大小 读写比例 基于时间的指标使用率和饱和度可以更简单的进行比较。 在介绍这些指标之前，我们先来看看磁盘性能领域的一些重要概念：测量时间 4.1 测量时间存储设备的响应时间指的是从I/O请求到结束的时间，由服务和等待时间组成: 等待时间: I/O在队列中等待服务的时间 服务时间: I/O 得到处理的时间 响应时间，服务时间，等待时间取决于测量所处的位置。在上面的磁盘io 栈的示意图中，io 栈的每一层都有可能实现自己的队列，在不同的测量位置可以得到不同的等待时间和服务时间。iostat 展示的磁盘设备接口的服务时间只是一种简化。 4.2 使用率使用率通过某段时间内磁盘运行时间的忙时间的比例计算得出。为了确定高使用率是否会导致应用程序性能问题，需要研究磁盘的反映时间和应用程序是否阻塞在此I/O上。 4.3 饱和度饱和度可以通过操作系统的磁盘等待队列的长度计算得出。 4.4 磁盘I/O vs 应用程序I/O最后犹如文件系统一章所提到的，文件系统性能比磁盘性能更加重要。最快的I/O就是没有I/O，所以要充分利用缓存来降低磁盘I/O的次数。 由于经过了中间的层层组件，磁盘I/O与应用程序I/O在频率和大小上都不匹配。所以需要细致研究磁盘I/O与应用程序阻塞之间的关系。而不能仅仅通过数值的大小去评判。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.9 文件系统动态追踪]]></title>
    <url>%2F2020%2F01%2F24%2Flinux_perf%2F29_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[本节我们来介绍文件系统的动态追踪技术 1. 使用 Systemtap 进行文件系统分析Dtrace/Systemtap 能从系统调用、VFS 接口或文件系统内部的角度来查看文件系统行为。这些功能能用在负载特征分析和延时分析上。 1.1 操作计数按照应用程序和类型统计文件系统操作，为负载特征归纳提供有用测量信息。 DTrace123456789101112# Solaris# 1. 按照应用程序名统计文件系统操作&gt; dtrace -n 'fsinfo:::&#123;@[execname] = count();&#125;'# 2. 按秒统计&gt; dtrace -n 'fsinfo:::&#123;@[execname] = count();&#125; tick-1s&#123;printa(@);&#125;'# 3. 按 probename 统计&gt; dtrace -n 'fsinfo::: /execname == "splunkd"/ &#123; @[probename] = count();&#125;'# Linux# 1. fsinfo provider 无法使用，文件系统操作可以通过 syscall 和 fbt provider 观察&gt; dtrace -n 'fbt::vfs_*:entry &#123; @[execname] = count(); &#125;'&gt; dtrace -n 'fbt::vfs_*:entry /execname == "sysbench"/ &#123; @[probename] = count(); &#125;' Systemtap1234567891011# 1.&gt; stap -ve 'global c; probe kernel.function("vfs_*") &#123; c[execname()] &lt;&lt;&lt; 1&#125; probe end &#123;foreach (k in c+)&#123;printf("%-36s %d\n", k, @count(c[k]))&#125;&#125;'# 2. 每秒统计&gt; stap -ve 'global c; probe begin, timer.s(1) &#123;printf("%-36s %s\n", "execname", "count")&#125; probe kernel.function("vfs_*") &#123; c[execname()] &lt;&lt;&lt; 1&#125; probe timer.s(1) &#123;foreach (k in c+)&#123;printf("%-36s %d\n", k, @count(c[k]))&#125;; delete c&#125;'# 3. 按probename 统计&gt; stap -ve 'global c; probe kernel.function("vfs_*") &#123; if ( execname() == "sshd" )&#123; c[probefunc()] &lt;&lt;&lt; 1&#125;;&#125;' 1.2 文件打开DtraceToolkit 工具箱中包含了如下的工具: opensnoop: 显示了进程打开的所有文件，和错误信息 rwsnoop: 跟踪和统计逻辑 I/O，包括 read()和write() 系统调用 rwtop: 跟踪和统计逻辑 I/O，使用 sysinfo proveder 统计吞吐量 DTrace123&gt; opensnoop&gt; rwsnoop&gt; rwtop Linux12345678910&gt; yum install bcc&gt; rpm -ql bcc-tools&gt; cd /usr/share/bcc/tools&gt; ./opensnoopPID COMM FD ERR PATH506 systemd-journal 22 0 /proc/2016/cgroup506 systemd-journal 22 0 /proc/2016/comm506 systemd-journal 22 0 /proc/2016/cmdline506 systemd-journal 22 0 /proc/2016/status506 systemd-journal 22 0 /proc/2016/sessionid 1.3 系统调用延时DTrace12345# 1. 系统调用接口级别测量了文件系统的超时&gt; dtrace -n 'syscall::read:entry /fds[arg0].fi_fs == "zfs"/ &#123;self-&gt;start = timestamp;&#125; syscall::read:return /self-&gt;start/ &#123;@["ns"] = quantize(timestamp - self.start);self-&gt;start = 0&#125;' 说明: 这个方法跟踪单个系统调用 read()，为了捕获所有的系统调用，所有系统调用都要跟踪包括他们的变体 这个方法跟踪了 zfs 文件系统的活动，也可以跟踪其他文件系统包括，非存储类型的文件系统入 sockfs 如果应用程序使用非阻塞I/O或者这是一个后台异步的后台任务，可能并不会应用程序性能产生影响 通过捕获用户态系统调用 I/O 的调用栈可以更准确的反映应用程序性能，比如使用 @[ustack(), ‘ns’],不过这是一个耗时操作深度调查 Systemp123456789101112131415161718192021222324252627# 1. 获取 read 系统调用的文件系统stap -ve ' probe syscall.read &#123; file = @cast(task_current(), "task_struct")-&gt; files-&gt;fdt-&gt;fd[fd] &amp; ~3; if(!file) next; dentry = @cast(file, "file")-&gt;f_path-&gt;dentry; inode = @cast(dentry, "dentry")-&gt;d_inode; device = kernel_string(@cast(inode, "inode")-&gt;i_sb-&gt;s_id); filesystem_type = kernel_string(@cast(dentry, "dentry")-&gt;d_sb-&gt;s_type-&gt;name); printf("READ %d: file '%s' of size '%d' on device: %s, with filesystem: %s \n", fd, d_name(dentry), @cast(inode, "inode")-&gt;i_size, device, filesystem_type); &#125; ' -c 'cat /etc/passwd &gt; /dev/null'# 2. 统计 xfs 文件系统级别 read 的调用延迟stap -ve 'global s; probe syscall.read.return &#123; file = @cast(task_current(), "task_struct")-&gt;files-&gt;fdt-&gt;fd[fd] &amp; ~3; if(!file) next; dentry = @cast(file, "file")-&gt;f_path-&gt;dentry; filesystem_type = kernel_string(@cast(dentry, "dentry")-&gt;d_sb-&gt;s_type-&gt;name); if (filesystem_type == "xfs") &#123;s &lt;&lt;&lt; gettimeofday_ns() - @entry(gettimeofday_ns());&#125;&#125; probe end&#123;print(@hist_log(s))&#125;' 1.4 VFS 缓存DTrace1234567891011121314# 1. Solaris 上 VFS 可通过 fop_* 函数跟踪&gt; dtrace -ln 'fbt::fop_*:entry'# 可以匹配所有的读调用变体&gt; dtrace -n 'fbt::ftop_read:entry /stringof(arg[0]-&gt;v_op_&gt;vnop_name) == "zfs"/ &#123;self-&gt;start = timestamp;&#125; fbt::ftop_read:return /self-&gt;start/ &#123;@["ns"] = quantize(timestamp - self.start);self-&gt;start = 0&#125;' # 2. Linux &gt; dtrace -n 'fbt::vfs_read:entry /stringof(((struct file *)arg0)-&gt;f_path.dentry-&gt;d_sb-&gt;s_type-&gt;name) == "ext4"/' &#123;self-&gt;start = timestamp;&#125; fbt::vfs_read:return /self-&gt;start/ &#123;@["ns"] = quantize(timestamp - self.start);self-&gt;start = 0&#125;' Systemp12345678910111213# 1. 获取 read 系统调用的文件系统# 2. 统计 xfs 上所有读调用的延迟&gt; stap -ve 'global s; probe kernel.function("vfs_read").return &#123; file = @cast(task_current(), "task_struct")-&gt;files-&gt;fdt-&gt;fd[fd] &amp; ~3; if(!file) next; dentry = @cast(file, "file")-&gt;f_path-&gt;dentry; filesystem_type = kernel_string(@cast(dentry, "dentry")-&gt;d_sb-&gt;s_type-&gt;name); if (filesystem_type == "xfs") &#123;s &lt;&lt;&lt; gettimeofday_ns() - @entry(gettimeofday_ns());&#125;&#125; probe end&#123;print(@hist_log(s))&#125;'# 3. 列出 VFS 函数入口&gt; stap -l 'kernel.function("vfs_*")' 1.5 块设备 I/O调用栈查看块设备 I/O调用栈和发出磁盘 I/O 的代码路径，是理解文件系统内部工作机制的绝佳方法。 DTrace12# 1. # 统计发出块设备 I/O 时内核调用栈的内容及次数&gt; dtrace 'io:::start &#123; @[stack()] =count();&#125;' Systemp参考: https://groups.google.com/forum/#!topic/openresty/u-puKWWONMk1234# 1. 未成功&gt; stap -ve 'global s; probe ioblock.request &#123; s[backtrace()] &lt;&lt;&lt; 1;&#125; probe end &#123; foreach (k in s- limit 1000) &#123;print(@count(s[k]))&#125;;&#125;' 1.6 跟踪文件系统内部对于同步读，直接跟踪文件系统的内核函数是可行的，但是对于异步执行的I/O操作，测量读延时 I/O 发起的和结束时间需要一一关联和对比，或者跟踪更高一级调用栈。 DTrace1234567# 1. 列出 zfs 内核函数 &gt; dtrace -ln 'fbt:zfs::entry'# 2. 跟踪 zfs 同步读的读延时&gt; dtrace -n 'fbt::zfs_read:entry &#123;self-&gt;start = timestamp;&#125; syscall::read:return /self-&gt;start/ &#123;@["ns"] = quantize(timestamp - self.start);self-&gt;start = 0&#125;' Systemp12# 1. 未找到 xfs 内核函数&gt; 1.7 慢事件跟踪由于文件系统缓存命中，在文件系统级别跟踪会产生大量的输出。一个解决办法是仅仅打印出慢操作。 DTrace1&gt; ./zfsslower.d Systemp12345678910111213&gt; cd /user/share/bcc/tools ll|grep lower-rwxr-xr-x. 1 root root 10096 8月 9 2019 btrfsslower-rwxr-xr-x. 1 root root 7321 1月 12 2019 dbslower-rwxr-xr-x. 1 root root 10431 8月 9 2019 ext4slower-rwxr-xr-x. 1 root root 7712 8月 9 2019 fileslower-rwxr-xr-x. 1 root root 10726 1月 12 2019 funcslower-rwxr-xr-x. 1 root root 3286 1月 12 2019 mysqld_qslower-rwxr-xr-x. 1 root root 9550 8月 9 2019 nfsslower-rwxr-xr-x. 1 root root 7396 8月 9 2019 runqslower-rwxr-xr-x. 1 root root 8397 8月 9 2019 xfsslower&gt; ./xfsslower 1.8 高级跟踪:DTrace文件系统常用的高级跟踪脚本: DTrace: https://github.com/brendangregg/DTrace-book-scripts/tree/master/Chap5 Systemp: https://sourceware.org/systemtap/SystemTap_Beginners_Guide/mainsect-disk.html]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.8 文件系统监测命令]]></title>
    <url>%2F2020%2F01%2F23%2Flinux_perf%2F28_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本节我们来介绍文件系统相关的监测工具。 1. 命令总览我们会介绍如下文件系统统计信息的工具 Linux Solaris 作用 说明 vfsstat 文件系统统计信息，包括平均延时 fsstat 文件系统统计信息 kstat 各种文件系统和缓存统计信息 fcachestat 各种缓存命令中率和大小 free 缓存容量统计信息 strace truss 系统调用调试器 slaptop mdb:kmastat 内核 slab 分配器统计信息 /proc/memeinfo mdb:memstat 内核内存使用情况 sar sar 内存，swap使用统计信息 通用命令，位于独立的一节中 除此之外，还包括以下内容: 文件系统基准测试 文件系统调优 2. 文件系统统计命令2.1 LatencyTopLatencyTop 是一个报告延时根源的工具。可以针对整个系统，也可以针对单个进程。 启用 LatencyTop 需要两个内核选项的支持: CONFIG_LATENCYTOP CONFIG_HAVE_LATENCYTOP_SUPPORT 12345# 1. LatencyTop 启用&gt; yum install latencytop&gt; rpm -ql latencytop# 2. LatencyTop 查看&gt; cat /proc/latency_stats 3. 文件系统测试3.1 dd可以执行文件系统连续读写负载的特定性能测试12&gt; dd if=/dev/zero of=file1 bs=1024k count=1k&gt; dd if=file1 of=/dev/null bs=1024 3.2 Bonnie是一个在单文件上一单线程测试集中负载的简单 C程序 3.3 fio有很多高级功能的可定制文件系统基准测试工具: 非标准随机分布，可以更准确的模拟真实的访问模式 延时百分位数报告，包括 99,99.5,99.9,99.99 使用fio（Flexible I/O Tester）正是最常用的文件系统和磁盘 I/O 性能基准测试工具，并且提供了大量定制化的选项。下面是对随机读、随机写、顺序读以及顺序写的基准测试。1234567891011121314# 随机读fio -name=randread -direct=1 -iodepth=64 -rw=randread -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb# 随机写fio -name=randwrite -direct=1 -iodepth=64 -rw=randwrite -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb# 顺序读fio -name=read -direct=1 -iodepth=64 -rw=read -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb# 顺序写fio -name=write -direct=1 -iodepth=64 -rw=write -ioengine=libaio -bs=4k -size=1G -numjobs=1 -runtime=1000 -group_reporting -filename=/dev/sdb # mysql IOPS innodb_io_capacity 参数确定fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 示例命令中包含的参数的含义如下: direct，表示是否跳过系统缓存。上面示例中，我设置的 1 ，就表示跳过系统缓存。 iodepth，表示使用异步 I/O（asynchronous I/O，简称 AIO）时，同时发出的 I/O 请求上限。在上面的示例中，我设置的是 64。 rw，表示 I/O 模式。我的示例中， read/write 分别表示顺序读 / 写，而 randread/randwrite 则分别表示随机读 / 写。 ioengine，表示 I/O 引擎，它支持同步（sync）、异步（libaio）、内存映射（mmap）、网络（net）等各种 I/O 引擎。上面示例中，我设置的 libaio 表示使用异步 I/O。bs，表示 I/O 的大小。示例中，我设置成了 4K（这也是默认值）。 filename，表示文件路径，当然，它可以是磁盘路径（测试磁盘性能），也可以是文件路径（测试文件系统性能）。示例中，我把它设置成了磁盘 /dev/sdb。不过注意，用磁盘路径测试写，会破坏这个磁盘中的文件系统，所以在使用前，你一定要事先做好数据备份。 I/O 重放fio 支持 I/O 的重放。借助前面提到过的 blktrace，再配合上 fio，就可以实现对应用程序 I/O 模式的基准测试。比如像下面这样:123456789101112# 使用blktrace跟踪磁盘I/O，注意指定应用程序正在操作的磁盘$ blktrace /dev/sdb# 查看blktrace记录的结果# lssdb.blktrace.0 sdb.blktrace.1# 将结果转化为二进制文件$ blkparse sdb -d sdb.bin# 使用fio重放日志$ fio --name=replay --filename=/dev/sdb --direct=1 --read_iolog=sdb.bin 输出123456789101112131415161718192021222324252627282930313233read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=64fio-3.1Starting 1 processJobs: 1 (f=1): [R(1)][100.0%][r=16.7MiB/s,w=0KiB/s][r=4280,w=0 IOPS][eta 00m:00s]read: (groupid=0, jobs=1): err= 0: pid=17966: Sun Dec 30 08:31:48 2018 read: IOPS=4257, BW=16.6MiB/s (17.4MB/s)(1024MiB/61568msec) slat (usec): min=2, max=2566, avg= 4.29, stdev=21.76 clat (usec): min=228, max=407360, avg=15024.30, stdev=20524.39 lat (usec): min=243, max=407363, avg=15029.12, stdev=20524.26 clat percentiles (usec): | 1.00th=[ 498], 5.00th=[ 1020], 10.00th=[ 1319], 20.00th=[ 1713], | 30.00th=[ 1991], 40.00th=[ 2212], 50.00th=[ 2540], 60.00th=[ 2933], | 70.00th=[ 5407], 80.00th=[ 44303], 90.00th=[ 45351], 95.00th=[ 45876], | 99.00th=[ 46924], 99.50th=[ 46924], 99.90th=[ 48497], 99.95th=[ 49021], | 99.99th=[404751] bw ( KiB/s): min= 8208, max=18832, per=99.85%, avg=17005.35, stdev=998.94, samples=123 iops : min= 2052, max= 4708, avg=4251.30, stdev=249.74, samples=123 lat (usec) : 250=0.01%, 500=1.03%, 750=1.69%, 1000=2.07% lat (msec) : 2=25.64%, 4=37.58%, 10=2.08%, 20=0.02%, 50=29.86% lat (msec) : 100=0.01%, 500=0.02% cpu : usr=1.02%, sys=2.97%, ctx=33312, majf=0, minf=75 IO depths : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=0.1%, 32=0.1%, &gt;=64=100.0% submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &gt;=64=0.0% complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.1%, &gt;=64=0.0% issued rwt: total=262144,0,0, short=0,0,0, dropped=0,0,0 latency : target=0, window=0, percentile=100.00%, depth=64Run status group 0 (all jobs): READ: bw=16.6MiB/s (17.4MB/s), 16.6MiB/s-16.6MiB/s (17.4MB/s-17.4MB/s), io=1024MiB (1074MB), run=61568-61568msecDisk stats (read/write): sdb: ios=261897/0, merge=0/0, ticks=3912108/0, in_queue=3474336, util=90.09% 这个报告中，需要我们重点关注的是， slat、clat、lat ，以及 bw 和 iops: slat ，是指从 I/O 提交到实际执行 I/O 的时长（Submission latency）； clat ，是指从 I/O 提交到 I/O 完成的时长（Completion latency） lat ，指的是从 fio 创建 I/O 到 I/O 完成的总时长。 bw ，它代表吞吐量 iops ，其实就是每秒 I/O 的次数 对同步 I/O 来说，由于 I/O 提交和 I/O 完成是一个动作，所以 slat 实际上就是 I/O 完成的时间，而 clat 是 0。而从示例可以看到，使用异步 I/O（libaio）时，lat 近似等于 slat + clat 之和。 3.4 SysBench3.5 丢弃缓存Linux 提供了丢弃缓存的方法，可用于缓存开始执行的基准测试12345678# 丢弃页缓存&gt; ehco 1 &gt; /proc/sys/vm/drop_cache# 丢弃 dentries 和 inodes 缓存&gt; ehco 2 &gt; /proc/sys/vm/drop_cache# 丢弃所有缓存&gt; ehco 3 &gt; /proc/sys/vm/drop_cache 4. 调优4.1 应用程序调优应用程序可以给内核提供信息，来提高缓存和预期的效率，包括: posix_fadvise() madvise() posix_fasvise()int posix_fasvise(int fd, off_t offset, off_t len, int advice) 作用: 这个库函数调用操作文件的一个区域 advice: 建议标志位: POSIX_FAD_SEQUENTIAL: 指定的数据范围会被连续访问 POSIX_FAD_RANDOM: 指定的数据范围会被随机访问 POSIX_FAD_NOREUSE: 数据不会被重用 POSIX_FAD_WILLNEED: 数据会在不远的将来重用 POSIX_FAD_DONTNEED: 数据不会在不远的将来重用 madvise()int madvise(void *addr, size_t length, int advice 作用: 库函数调用对一块内存映射进行操作 advice: 建议标志位 MADV_RANDOM: 偏移量将以随机顺序访问 MADV_SEQUENTIAL: 偏移量将以连续顺序访问 MADV_WILLNEED: 数据还会再用，请缓存 MADV_DONTNEED: 数据不会再用，无缓存 4.2 文件系统调优ext 文件系统12345678910# 1. 查看文件系统配置&gt; tunefs -l dev_name&gt; mount # 2. 可以使用选项 noatime 禁用文件访问时间戳更新# 3. tunefs 提升性能的关键选项 -- 使用哈希B数提高大目录的查找速度&gt; tune2fs -O dir_index /dev/hdX# 4. 重建文件系统目录的索引&gt; e2fsck -D -f /dev/hdX]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.7 文件系统]]></title>
    <url>%2F2020%2F01%2F22%2Flinux_perf%2F27_%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[本节我们来介绍文件系统相关的操作系统原理。文件系统性能比磁盘性能更加重要。文件系统通过缓存，缓冲以及异步I/O等手段来缓和了磁盘延时对应用程序的影响。 1. 文件系统相关的操作原理我们从下面几个方面入手来讲解文件系统相关的操作系统原理: 文件系统I/O栈 文件系统缓存 I/O的多种方式 最后我们会说一说文件系统检测的相关指标。 2. 文件系统 I/O 栈下面是文件系统I/O栈的一般模型，具体的模块和层次依赖于使用的操作系统。 Volume Manager: 卷管理器 Block Device Interface: 块设备接口 Host Bus Adaptor Driver: 主机总线适配器驱动 Disk Devices: 磁盘设备 2.1 VFS虚拟文件系统 VFS 是一个文件系统类型作抽象的内核界面。VFS 接口让内核添加新的文件系统时更加简单。 VFS 接口可以作为测量文件系统性能的通用平台，能够利用操作系统提供的统计信息，静态及动态追踪技术。 3. 文件系统缓存UNIX 原本只有缓冲区高速缓存，如今 Linux 和 Solaris 都有多种缓存。 3.1 Solaris 的文件系统缓存下图是基于 Solaris 系统的文件系统缓存的概览。 其中有三种缓存是文件系统里通用的，其他的都是每个文件系统特有的，这三种缓存包括: Old Buffer Cache: 旧式的缓冲区高速缓存 page Cache: 页缓存 DNLC: 目录名查找缓存 旧式的缓冲区高速缓存(buffer cache)最初 UNIX 在块设备接口使用缓冲区高速缓存来缓存磁盘设备块。页缓存的加入带来了优化问题，比如: 如何平衡二者之间的负载 双重缓存和同步开销 这些问题后来基本被 SunOS 中的统一缓冲区高速缓存解决了，方法是使用页缓存来存储缓冲区高速缓存 在 Solaris 旧式的缓冲区高速缓存依然存在，不过仅用于 UFS inode 和文件系统的元数据，这些数据通过它们的块号寻址，与文件无关。 页缓存页缓存就是我们在内存一章所说的文件系统页缓存。它缓存了虚拟内存页面映射过的文件系统页面。 DNLCDNLC 目录名查找缓存记录了目录项到 vnode 的映射关系。用于加速文件的查找。 3.2 Linux 的文件系统缓存与 Solaris 类似，Linux 也经历旧式的缓冲区高速缓存到统一缓冲区高速缓存的过程。方法也是类似的，即缓冲区高速缓存被存在了页缓存中。 缓冲区高速缓存的功能仍在，用于缓存文件系统的元数据，提升了块设备I/O的性能。 写回缓存写回缓存的原理是当数据写入主存(页缓存)后，就认为写入已经结束并返回，之后再异步的把数据刷入磁盘。文件系统写入”脏页”的过程称为刷新，就是我们经常说的刷脏页。 刷新的机制牺牲了可靠性，因为基于DRAM的主存是不可靠的，主机掉电写入的数据就会丢失。应用程序可能认为数据写入完成，但是实际上未被写入，甚至不完整写入。如果文件系统的元数据遭到破坏，可能无法加载，对业务造成严重的影响。 为了平衡系统对于速度和可靠性的需求，文件系统默认采用写回缓存，但同时提供了同步写的选项绕过这个机制。 页缓存管理文件系统使用的内存脏页由内核线程写回到磁盘，现在这个写回线程为 flusher thread，线程名为 flush，每个设备分配一个线程。这样能平衡每个设备的负载，提高吞吐量。 写脏页的时机包括: 过了一段时间(30s) 调用了 sync()，fsync(), msync() 等系统调用 过多的脏页(dirty_ratio) 页缓存没有可用的页面 如果系统内存不足，另一个内核线程，页面换出守护进程kswapd() 会定位并安排把脏页面写入到磁盘上，腾出可重用的内存页面。 目录项缓存和 inode 缓存目录项缓存记录了从目录项到 VFS inode 的映射关系。inode 缓存缓存的对象是 VFS inode，每一个都描述了文件系统一个对象的属性。 内核使用 Slab 机制，管理目录项和索引节点的缓存。通过 /proc/slabinfo 可以查看到各种 inode与目录项缓存的大小: 1234567891011$ cat /proc/slabinfo | grep -E '^#|dentry|inode' # name &lt;active_objs&gt; &lt;num_objs&gt; &lt;objsize&gt; &lt;objperslab&gt; &lt;pagesperslab&gt; : tunables &lt;limit&gt; &lt;batchcount&gt; &lt;sharedfactor&gt; : slabdata &lt;active_slabs&gt; &lt;num_slabs&gt; &lt;sharedavail&gt; xfs_inode 0 0 960 17 4 : tunables 0 0 0 : slabdata 0 0 0 ... ext4_inode_cache 32104 34590 1088 15 4 : tunables 0 0 0 : slabdata 2306 2306 0hugetlbfs_inode_cache 13 13 624 13 2 : tunables 0 0 0 : slabdata 1 1 0 sock_inode_cache 1190 1242 704 23 4 : tunables 0 0 0 : slabdata 54 54 0 shmem_inode_cache 1622 2139 712 23 4 : tunables 0 0 0 : slabdata 93 93 0 proc_inode_cache 3560 4080 680 12 2 : tunables 0 0 0 : slabdata 340 340 0 inode_cache 25172 25818 608 13 2 : tunables 0 0 0 : slabdata 1986 1986 0 dentry 76050 121296 192 21 1 : tunables 0 0 0 : slabdata 5776 5776 0 指标含义: inode_cache: VFS 索引节点缓存 dentry 行表示目录项缓存 其余的则是各种文件系统的索引节点缓存。 3.3 buffer 和 cache目前为止我们在两个地方提到了 buffer，cache: 第一地方是页缓存，我们说页缓存统一了缓冲区高速缓存(buffer cache)。 第二地方是内存一节我们提到 /proc/meminfo 文件记录了各种内存指标的统计信息，其中包括 Buffers 和 Cached 1234567cat /proc/meminfoMemTotal: 2895444 kBMemFree: 2498868 kBMemAvailable: 2535384 kBBuffers: 3108 kBCached: 165872 kB..... 那么问题是buffer, cache, 页缓存与Buffers, Cached 之间到底有什么关系。 man proc 可以看到 /proc/meminfo 文件内各个字段的准确含义: Buffers: 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。 通过 Buffer 内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等 Cached: 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据 以前看到的文章说 Buffer 是对将要写入磁盘数据的缓存，Cache 是对从文件读取数据的缓存。但事实上: Buffers 既可以用作“将要写入磁盘数据的缓存”，也可以用作“从磁盘读取数据的缓存”。 Cached 既可以用作“从文件读取数据的页缓存”，也可以用作“写文件的页缓存” 简单来说， Buffers 是对磁盘数据的缓存，而 Cached 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。 页缓存统一了缓冲区高速缓存(buffer cache) 但是并没有改变它的作用: 缓冲区高速缓存(buffer cache)用来缓存磁盘设备块的写和读， 被用作缓冲区高速缓存(buffer cache) 的页缓存保存的是磁盘设备块 对磁盘的直接读写，数据以磁盘设备块，保存在用作缓冲区高速缓存(buffer cache) 的页缓存中 对文件系统的读写，数据以文件内容，保存在页缓存中 文件内容和磁盘设备块不会同时保存，因此才避免了双重缓存和同步开销 Buffers 统计的是用作缓冲区高速缓存(buffer cache) 的页缓存大小 Cached 统计的是文件系统的页缓存大小 最后需要说明的是，free，top，vmstat，显示的 buffer/cache 依计算规则不同而有所不同，但是数据都来自/proc/meminfo 文件。 4. I/O 的多种方式4.1 顺序与随机I/O按照I/O的文件偏移量，I/O分为: 顺序 I/O: 顺序I/O里每个 I/O 都开始于上一个 I/O 结束的地址 随机 I/O: 随机 I/O则找不出I/O之间的关系 由于存储设备的性能特性，顺序I/O的速度要远远高于随机I/O。文件系统可以测量逻辑I/O的访问模式，从中识别出顺序I/O，然后通过预取或者预读来提高性能。 预取预取指当文件系统检测出当前为顺序读负载时，在应用程序请求前向磁盘发出读指令，以填充文件系统缓存。如果应用程序真的发出顺序读请求，就会命中缓存。 预期一旦命中读性能将会有显著提升，但是如果预测不准，文件系统会发起应用程序不需要的I/O，不仅污染了缓存，也消耗了磁盘和I/O传输的资源。 预取一般被认为是预读。Linux 的 readahead(2) 系统调用允许应用程序显示的预热文件系统缓存，此时二者就不同了。 4.2 同步写和非阻塞I/O在前面的文件系统缓存，我们提到了文件系统的写回缓存和 buffer 机制，为了控制文件写入过程，操作系统提供了同步写。同步用于指绕过写回缓存机制，写操作必须等待至所有的数据以及必要的文件系统元数据完整的写入到存储设备中。写操作支持如下标识: O_DSYNC: 表示，写操作必须要等文件数据写入磁盘后，才能返回； O_SYNC: 则是在 O_DSYNC 基础上，要求文件元数据也要写入磁盘后，才能返回。 4.3 裸I/O和直接I/O 裸I/O: 如上图所示，绕过整个文件系统，直接发送磁盘地址 数据库会使用裸I/O，因为它们能比文件系统更好地缓存自己的数据 直接I/O: 绕过缓存使用文件系统 可用于备份文件系统，放置污染文件系统缓存裸I/O和直接I/O还可以用于那些在进程堆里自建缓存的应用程序，避免双重缓存的问题。kafka 应该就是舍弃了堆缓存，直接使用了操作系统的页缓存。 4.4 内存映射文件内存映射文件可以把文件映射到进程地址空间，并直接存取内存地址的方法来提高文件系统I/O性能。这样可以避免调用 read() 和 write() 存取文件数据时产生的系统调用和上下文切换开下。 如果内核支持直接复制文件数据缓冲到进程进程地址空间，那么还能防止数据被复制两次。(It can also avoiddouble copying of data, if the kernel supports direct copying of the file data bufferto the process address space)(数据为什么会复制两次: 意思是如果 mmap 映射的文件正在被另一进程写，它们是无法共享相同的页缓存的？) 内存映射文件通过系统调用 mmap() 创建，通过 munmap() 销毁，映射可以通过 madvise() 调整。 如果系统问题是由于磁盘设备高I/O延时所至，用 mmap() 消除小小的系统调用是无济于事的。 在多处理器上使用内存映射文件的缺点在于同步每个 CPU MMU 的开销。尤其是跨 CPU 的映射删除调用(TLB 击落)。延时 TLB 更新可能把影响最小化，这取决于内核和映射项。(A disadvantage of using mappings on multiprocessor systems can be the overhead to keep each CPU MMU in sync, specifically the CPU cross calls to removemappings (TLB shootdowns). Depending on the kernel and mapping, these may beminimized by delaying TLB updates (lazy shootdowns) [Vahalia 96]) 4.5 逻辑I/O 与物理I/O 逻辑I/O 指向文件系统发起的I/O 物理I/O: 磁盘I/O与应用程序I/O相比，磁盘I/O有时显得无关、间接、放大或者缩小。 6. 文件系统监测指标与 CPU 相关的专业术语或者指标包括: 文件系统延时 6.1 文件系统延时文件系统延时指的是一个文件系统逻辑从开始到结束的时间，它包括消耗在文件系统，内核磁盘I/O子系统以及等待磁盘设备(物理I/O)的时间。 文件系统延时是否会影响应用程序，取决于应用程序的 I/O 方式，同步I/O会有直接影响，非阻塞I/O或异步I/O则不会。文件系统一直以来未开放查看文件系统延时的接口。相反提供了磁盘设备级别的指标信息。但是多数情况下这些指标跟应用程序并无直接关系。原因同样是实际发生的物理I/O并不与应用程序的执行同步。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.6 内存动态追踪]]></title>
    <url>%2F2020%2F01%2F21%2Flinux_perf%2F26_%E5%86%85%E5%AD%98%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[本节我们来介绍内存动态追踪技术 1. Systemtap 进行 内存 分析Systemtap 可以用来剖析 跟踪用户和内核的内存分配 主次缺页异常 页面换出守护进程的运行 这些功能支持负载特征分析、向下挖掘分析。 1.1 分配跟踪用户级别的分配跟踪使用 pid provider，内核的分配跟踪使用 fbt provider Dtrace123456789101112131415# 1. 按进程汇报用户级 malloc 请求的长度# arg0 参数记录了 malloc 请求的字节数dtrace -n 'pid$target::malloc:entry &#123; @["request"] = quantize(arg0); &#125;' -p PIDdtrace -n 'pid$target::malloc:entry &#123; @[ustack()] = quantize(arg0); &#125;' -p PID# 2. 计算libumem函数调用# 列出libumem分配器的入口探针dtrace -ln 'pid$target:libumem::entry' -p PIDdtrace -n 'pid$target:libumem::entry &#123; @[probefunc] = count(); &#125;' -p PID# 3. 按堆增长(通过 brk())计算用户栈dtrace -n 'syscall::brk:entry &#123; @[execname, ustack()] = count(); &#125;'# 4. 按照缓存名称和栈跟踪内核 slab 分配器dtrace -n 'fbt::kmem_cache_alloc:entry' &#123; @[stringof(arg[0]-&gt;cache_name), stack()] = count(); &#125; Systemtap1234567891011# 1. 汇报用户级 malloc 请求的长度stap -ve 'global s; probe vm.kmalloc &#123; s[execname(),caller_function] &lt;&lt;&lt; bytes_req&#125; probe end &#123; foreach([i,j] in s)&#123;printf("%s %s: %d\n", i, j, @count(s[i,j]))&#125;&#125;'# 3. stap -ve 'global s; probe vm.brk &#123; s[ubacktrace()] &lt;&lt;&lt; 1&#125; probe end &#123; foreach(i in s- limit 10) &#123;print_ustack(i); printf("%d\n", @count(s[i]))&#125;&#125;'# 4. stap -ve 'global s; probe vm.kmem_cache_alloc &#123; s[caller_function] &lt;&lt;&lt; 1; &#125; probe end &#123; foreach(i in s- limit 10) &#123;printf("%s: %d\n", i, @count(s[i]))&#125;&#125;' 1.2 缺页跟踪跟踪缺页异常能更深入解释系统如何分配内存，可以利用 fbt provider，或者在可用的情况下使用稳定的 vminfo provider Dtrace123456# 1.跟踪 beam.smp 进程的缺页异常# as_fault 次缺页异常，maj_fault 主缺页异常dtrace -n 'vminfo:::as_fault /execname == 'beam.smp' / &#123; @[ustack(4)] = count();&#125;'# 2. 匿名页面换入探测, 跟踪整个系统，按频率统计引起匿名页面换入进程ID和进程名dtrace -n 'vminfo:::anonpgin &#123; @[pid, execname] = count();&#125;' Systemtap123456# 1. 跟踪系统的主缺页异常stap -ve 'global s; probe vm.pagefault.return &#123; if (fault_type == VM_FAULT_MAJOR)&#123;s[execname()] &lt;&lt;&lt; 1&#125;&#125; probe end &#123; foreach(i in s- limit 10)&#123;printf("%s: %d\n", i, @count(s[i]))&#125;&#125;'# 2. 跟踪整个系统，按频率统计引起匿名页面stap -ve 'global s; probe vm.pagefault.return &#123; if (fault_type == VM_FAULT_SIGBUS)&#123;s[execname()] &lt;&lt;&lt; 1&#125;&#125; probe end &#123; foreach(i in s- limit 10)&#123;printf("%s: %d\n", i, @count(s[i]))&#125;&#125;']]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.5 内存监测工具]]></title>
    <url>%2F2020%2F01%2F20%2Flinux_perf%2F25_%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本节我们来介绍内存相关的监测工具。 1. 命令总览下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了内存相关的性能检测工具: 从内存的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握内存分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍如下内存专用的分析工具的使用 Linux Solaris 作用 说明 vmstat vmstat 虚拟和物理内存统计信息 slabtop ::kmastat 内核块分配统计信息 pmap pmap 进程地址空间统计信息 pcstat pcstat 查看文件在内存中的缓存大小以及缓存比例 cachetop cachetop 实时查看间隔时间内每个进程的缓存命中情况 bcc工具包中 cachestat cachestat 查看整个操作系统缓存的读写命中情况 bcc工具包中 memleak memleak 内存泄漏跟踪 bcc工具包中 ps ps 进程状态 通用命令，位于独立的一节中 top prstat 监控进程内存使用 通用命令，位于独立的一节中 sar sar 内存，swap使用统计信息 通用命令，位于独立的一节中 Systemtap Dtrace 动态追踪 通用命令，位于独立的一节中 除此之外，还包括以下内容: 内存调优 2. 内存统计命令2.1 vmstat123456789101112131415161718192021222324252627282930313233343536373839&gt; vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 1077816 2116 620312 0 0 65 43 34 53 0 0 99 0 0# 说明:# 除了 r 列外，第一行是系统启动以来的总结信息&gt; vmstat -aprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free inact active si so bi bo in cs us sy id wa st 2 0 0 342188 472012 815924 0 0 68 84 160 72 9 1 90 0 0&gt; vmstat -s 1882152 K total memory 250252 K used memory 815892 K active memory 472012 K inactive memory 341924 K free memory 172 K buffer memory 1289804 K swap cache 2097148 K total swap 0 K used swap 2097148 K free swap 99051 non-nice user cpu ticks 0 nice user cpu ticks 12143 system cpu ticks 998690 idle cpu ticks 360 IO-wait cpu ticks 0 IRQ cpu ticks 358 softirq cpu ticks 0 stolen cpu ticks 758858 pages paged in 934798 pages paged out 0 pages swapped in 0 pages swapped out 1777012 interrupts 803881 CPU context switches1586602557 boot time 31172 forks vmstat [t [n]] 作用: 虚拟内存统计命令 参数: -t：采样间隔 -n：采样次数，可选，默认值是1 -S: -Sm 以MB 为单位显示结果 -a: 输出非活动和活动页缓存的明细 -s: 以列表显示内存统计信息 输出: r: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 cpu: 系统全局范围内的平均负载 第一行统计的系统启动以来的平均负载 – 新版本可能不会显示 其余行统计的是时间间隔周期内的平均负载 memory: swpd: 交换出的内存量 free: 空闲可用内存 buff: 用于缓冲缓存的内存 cache: 用于页缓存的内存 swap: si: 换入的内存 so: 换出的内存 2.2 slabtop1234567891011121314&gt; sudo slabtop -sc Active / Total Objects (% used) : 1079865 / 1085229 (99.5%) # slab 管理的对象数量 Active / Total Slabs (% used) : 27647 / 27647 (100.0%) # Slab 数量 Active / Total Caches (% used) : 69 / 97 (71.1%) # 缓存的 slab 数量 Active / Total Size (% used) : 151423.96K / 153971.68K (98.3%) # slab 管理的内存大小 Minimum / Average / Maximum Object : 0.01K / 0.14K / 8.00K OBJS ACTIVE USE OBJ SIZE SLABS OBJ/SLAB CACHE SIZE NAME 50440 50440 100% 0.94K 6305 8 50440K xfs_inode 81879 81087 99% 0.19K 3899 21 15596K dentry 15392 15266 99% 1.00K 1924 8 15392K kmalloc-1024139737 139737 100% 0.10K 3583 39 14332K buffer_head 16419 16419 100% 0.58K 1263 13 10104K inode_cache 17262 17262 100% 0.57K 1233 14 9864K radix_tree_node slabtop: 作用: 内核内存信息统计，等同于 vmstat -m 来源: slab 统计信息来自 /proc/slabinfo 参数 -d n：每n秒更新一次显示的信息，默认是每3秒； -s S：指定排序标准进行排序； -o：显示一次后退出 -V：显示版本 2.3 pmap12345678910111213141516171819&gt; sudo pmap -x 792|head792: /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopidAddress Kbytes RSS Dirty Mode Mapping0000000000400000 4 4 0 r-x-- python2.70000000000600000 4 4 4 r---- python2.70000000000601000 4 4 4 rw--- python2.700000000017b4000 8800 8684 8684 rw--- [ anon ]....&gt; sudo pmap -d 792 |head792: /usr/bin/python2 -Es /usr/sbin/firewalld --nofork --nopidAddress Kbytes Mode Offset Device Mapping0000000000400000 4 r-x-- 0000000000000000 0fd:00000 python2.70000000000600000 4 r---- 0000000000000000 0fd:00000 python2.70000000000601000 4 rw--- 0000000000001000 0fd:00000 python2.700000000017b4000 8800 rw--- 0000000000000000 000:00000 [ anon ]00007fa0ac000000 132 rw--- 0000000000000000 000:00000 [ anon ].....mapped: 359028K writeable/private: 30856K shared: 36K pmap PID 作用: 列出进程的内存映射，显示它们的大小，权限和映射对象 参数: -x：显示扩展格式； -d：显示设备格式； -q：不显示头尾行； -V：显示指定版本 输出: pid -X Address: 映射的起始地址 Kbytes: 虚拟内存大小 RSS: 主存大小 Dirty: 脏页大小 Mode: 映像权限: r=read, w=write, x=execute, s=shared, p=private (copy on write) Mapping: 映像的文件,[anon]为已分配内存 [stack]为程序堆栈 pid -d Offset: 文件偏移 Device: 设备名 mapped: 进程映射的虚拟地址空间大小，也就是该进程预先分配的虚拟内存大小，即ps出的vsz writeable/private: 进程所占用的私有地址空间大小，也就是该进程实际使用的内存大小 shared: 表示进程和其他进程共享的内存大小 2.4 pcstatpcstat 是一个基于 Go 语言开发的工具，所以安装它之前，首先需要安装 Go 语言。由于不可描述的原因，go 包的安装可能会遇到问题，建议像下面这样设置一下代理后在安装: 12345678910111213# go 安装cd /usr/localwget https://dl.google.com/go/go1.14.4.linux-amd64.tar.gztar -C /usr/local -xzf go1.14.4.linux-amd64.tar.gzecho 'export PATH=$PATH:/usr/local/go/bin' &gt; /etc/profile.d/go.sh# 设置代理 https://goproxy.io/zh/go env -w GO111MODULE=ongo env -w GOPROXY=https://goproxy.io,direct# 安装 pcstatgo get golang.org/x/sys/unixgo get github.com/tobert/pcstat/pcstat pcstat 作用: 查看文件在内存中的缓存大小以及缓存比例 参数: 123456$ pcstat /bin/ls+---------+----------------+------------+-----------+---------+| Name | Size (bytes) | Pages | Cached | Percent ||---------+----------------+------------+-----------+---------|| /bin/ls | 133792 | 33 | 0 | 000.000 |+---------+----------------+------------+-----------+---------+ 指标含义: Cached: /bin/ls 在缓存中的大小 Percent: 缓存的百分比 2.5 smem2.6 其他命令 命令 作用 dmesg 检查 OOM valgrind 包含一个 memcheck 性能分析套件，可用于发现泄漏，会有严重的系统开销 swapon 添加和观察swap分区 iostat 如果 swap 是物理磁盘或块，可用此命令观测系统是否在换页 /proc/zoneinfo 内存区域 NUMA 节点的统计信息NUMA 非均匀访存模型 /proc/buddyinfo 内核页面伙伴分配器统计信息伙伴分配器:Linux 的页面分配器 3. 内存调优最重要的内存调优是保证应用程序保留在主存中，并且避免换页和交换经常发生。 3.1 可调参数Documention/sysctl/vm.txt 的内核源码文档介绍了多种内存可调参数。常用示例如下 参数 默认值 作用 vm.dirty_background_ratio 10 触发pdflush后台回写的脏页百分比 vm.dirty_ratio 20 触发一个写入进程开始回写脏页比例 vm.dirty_expire_centisecs 3000 使用pdflush的脏存储器最小时间 vm.dirty_writeback_centisecs 5000 pdflush 活跃时间间隔，0为停用 vm.min_free_kbytes dynamic 设置期望的空闲内存大小，dynamic为系统自动设置 vm.overcommit_memory 0 0: 利用探索算法允许合理的过度使用1: 一致过度使用3: 不允许过度使用 vm.swappiness 60 相对于页面高速缓存回收更倾向于用交换释放内存的程度高数值更倾向于交换应用程序而保留页缓存 3.2 配置大页面更大的页面能通过提高 TLB 缓存命令率，来提升内存 IO 性能。现在处理器支持多个页面大小。设置大页面(巨页面)参考文档hugetlbpage.txt。关于大页面的使用详见文档 3.3 分配器应用程序的用户级分配器可以在编译阶段选择，也可以在执行时用 LD_PRELOAD 环境变量设置。 3.4 资源控制主存限制和虚拟内存限制，可通过 ulimit 实现。Linux cgroup 内存子系统可提供多种附加控制: memory.memsw.limit_in_bytes: 允许的最大内存和交换空间 memory.limit_in_bytes: 允许的最大用户内存，包括文件缓存 memory.swappiness: 类似 vm.swappiness，作用于 cgroups memory.oom_control: 设置为 0，允许 OOM 应用于此 cgroup，1 不允许]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.4 内存]]></title>
    <url>%2F2020%2F01%2F19%2Flinux_perf%2F24.%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[本节我们来介绍内存相关的操作系统原理。 1. 内存相关的操作原理我们从下面几个方面入手来讲解内存相关的操作系统原理: 虚拟内存和页: 内存架构 内存管理 进程地址空间 最后我们会说一说内存检测的相关指标。 2. 虚拟内存和换页虚拟内存是一个抽象概念，它向每个进程和内核提供巨大的、线性的并且私有的地址空间。它简化了软件开发，把物理内存的分配交给操作系统管理。 从上面的图可以看到进程的地址空间由虚拟内存子系统隐射到主内存和物理交换设备。当内存不够用时，内核需要按需在它们之间移动内存页，称为换页。 换页分为两种类型: 为交换共享文件系统的页缓存而产生的文件系统换页 虚拟内存的匿名换页 文件系统换页文件系统换页由读写位于内存中的映射文件页引发。映射文件产生自: 使用文件内存映射 mmap 的应用程序 使用了页缓存的文件系统 文件系统页可能因为在主存修改过(“脏的”)在换出时需要写回磁盘。如果没有修改过(干净的)因为磁盘已有副本，换页仅仅需要释放内存即可。 匿名换页匿名换页涉及进程私有数据: 堆和栈，要求数据保存至交换设备，因为这些数据磁盘没有副本。匿名页换入会给应用程序带来同步延时，因为必然发生读磁盘I/O，换出可能不会直接应用程序性能，因为换出是内核异步执行的。 2.1 按需换页按需换页将CPU创建和映射内存的开销延时到实际访问或需要，而不是初次分配内存时。访问一个未映射的内存页将产生一个缺页异常。 虚拟内存页存在以下几种状态: 未分配 已分配，未映射 已分配，已映射到主存 已分配，已映射到物理交换空间(磁盘) 从 2-&gt;3就是缺页，如果需要磁盘读写就是严重缺页异常，否则就是次缺页异常。从这几种状态出发可以定义另外两个内存时术语: 常驻集合大小 RSS: 已分配的主存(状态3)大小 虚拟内存大小: 所有已分配区域(2+3+4) 除此之外我们还能经常看到另一个内存术语，共享内存 SHR，它标识与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等所占用的内存。要注意共享内存 SHR 并不一定是共享的，比方说，程序的代码段、非共享的动态链接库，也都算在 SHR 里。当然，SHR 也包括了进程间真正共享的内存。 3.内存架构3.1 UMA 架构内存硬件包括主存，总线，CPU 缓存和 MMU(内存管理单元)。下面展示了一个普通双处理器均匀访问模型(UMA) 系统的主存架构，又称对称多处理器架构 SMP 通过共享总线，每个 CPU 访问所有内存都有均匀的访问延时。 3.2 NUMA作为对照下面是一个双处理器非均匀访问模型 NUMA 系统，其中采用一个 CPU 互联(CPU 原理一章有提到)。 在 NUMA 架构下，多个处理器被划分到不同 Node 上，对主存的访问时间随着相对 CPU 的位置不同而变化。与 CPU 直接相连的内存称为本地内存。 既然 NUMA 架构下的每个 Node 都有自己的本地内存空间，那么，在分析内存的使用时，我们也应该针对每个 Node 单独分析。 可以通过 numactl 命令，来查看处理器在 Node 的分布情况，以及每个 Node 的内存使用情况。 12345678numactl --hardwaravailable: 1 nodes (0)node 0 cpus: 0 # Node 0 包含的CPU编号node 0 size: 2047 MB # Node 0 内存大小node 0 free: 534 MB # Node 0 剩余内存大小node distances:node 0 0: 10 4.内存管理内存管理软件包括虚拟内存系统，地址转换，换页。与性能相关的内容包括: 内存释放 内存分配 4.1 内存分配内存分配器用于内存分配。下图展示了分配器的作用，以及分配器的一些常见类型: slab: 内核级分配器 libc: 用户级分配器的统称，包括 libmalloc, libumem, mumalloc Page Allocator: Linux 用于管理页的伙伴分配器，在下面的空闲链表中会详细介绍 slab内核 slab 分配器管理特定大小的对象缓存，使它们能被快速的回收利用，并且避免页分配开销。这对经常处理固定大小结构的内核内存分配来说特别有效。slab 大小固定，因此可以一次分配 M 个 slab 大小的缓存，也就避免了多次页分配的开销。大小固定类似于数组也便于回收利用。 Linux 基于 slab 分配器提供了另一个分配器 SLUB。SLUB 为解决多个问题设计，特别是 slab 分配器的复杂性。包括移除对象队列，以及每 CPU 缓存，吧 NUMA 优化留个页分配器(Page Allocator) SLUB 现在是 Linux 的默认选项. 用户级分配器有多种用户级分配器，他们的性能也有所差异： libc: 不建议使用，性能较差，容易导致内存碎片化 glibc: 分配基于分配请求的长度，是结合了多种分配策略的高效分配器 较小的分配来自内存集合，包括伙伴关系算法合并长度相似的单位 较大的分配用树高效搜索空间 非常大的分配转到 mmap() 4.2 内存释放 内存过低时，系统会按照上面的高到低的次序释放内存: 空闲链表: 未使用的页列表，能立即用于分配。通常每个 NUMA 的内存有一个 回收: 内核释放可以轻易释放的内存 换页: 对于 Linux 可以配置一个交换倾向的可调参数/proc/sys/vm/swappiness，范围为 0-100，默认值为 40。 值越高: 倾向于”换页”来释放内存，此处的换页指匿名换页 值越低: 倾向于收回页缓存，即文件系统换页 这就通过在保留热文件系统缓存的同时，换出冷应用程序的内存来提高系统的吞吐量 OOM: 搜索并杀死可牺牲的进程来释放内存。Linux 采用 select_band_process() 搜索后用 omm_kill_process() 杀死进程 空闲链表 类UNIX系统使用空闲链表和页面换出守护进程来管理内存，如上图所示: 回收的内存添加到空闲链表表头以便将来分配 通过页面换出守护进程释放的内存被加到表尾。kswapd 释放的内存包括有价值的文件系统缓存，这些文件系统缓存在未被重用前，如有对任一页的请求，它能被取回并从空闲链表中移除 空闲链表通常由分配器消耗，如内核的 slab 分配器，以及用户空间的 libc malloc。上面的单个空闲链表是一种简化，具体实现依内核版本不同。 Linux 使用伙伴分配器管理页。它以2的幂的方式向不同尺寸的内存分配器提供多个空闲链表。术语伙伴指找到相邻的空闲内存页以被同时分配。 回收回收大多是从内核的slab 分配器缓存释放内存。这些缓存包括 slab 大小的未使用内存块，以供重用。回收将这些内存交还给系统进行分配。 文件系统部分我们会说到内核使用 Slab 机制来管理目录项和索引节点的缓存，/proc/sys/vm/vfs_cache_pressure 可以定义目录项缓存和索引节点缓存的回收倾向，默认值 100，数值越大，就表示越容易回收。 换页页面换出守护进程管理利用换页释放内存。当主存中可用的空闲链表低于阀值时，kswapd就会开始页扫描。页扫描仅会按需启动，通常平衡的系统不会经常做页扫描并且仅以短期爆发方式扫描。因此如果页扫描多于几秒通常是内存压力问题的预兆。 Linux 的页面换出守护进程称作 kswapd()，如下图所示，它扫描非活动和活动内存的 LRU 页列表以释放页面。 页的活动列表和非活动列表采用 LRU 方式工作，kswapd 先扫描非活动列表，然后按需扫描活动列表。扫描会遍历列表检查页面，找出可以释放的页面: 如果是干净的页直接释放 如果是脏页会需要先将脏页写回磁盘然后释放。kswapd 只有在系统严重不足才会选择脏页释放，其他情况下脏页由 flush 内核线程写回磁盘。脏页的管理详见文件系统的操作系统原理部分。 kswapd 的激活基于空闲内存和两个提供滞后的阀值。如下图所示: 一旦空闲内存达到最低阀值，kswapd 运行于同步模式，按需求释放内存页(内核排除在外)，此时只有内核才可以分配内存。 最低阀值通过 vm.min_free_kbytes 设置，其他阀值基于此按比例放大两倍，三倍。 在 NUMA 架构下，三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看。 某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项： 默认的 0 ，也就是刚刚提到的模式，表示既可以从其他 Node 寻找空闲内存，也可以从本地回收内存。 1、2、4 都表示只回收本地内存，2 表示可以回写脏数据回收内存，4 表示可以用 Swap 方式回收内存。 OOMOOM（Out of Memory），其实是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分： 一个进程消耗的内存越大，oom_score 就越大 一个进程运行占用的 CPU 越多，oom_score 就越小 这样，进程的 oom_score 越大，代表消耗的内存越多，也就越容易被 OOM 杀死。 可以通过 /proc 文件系统，手动设置进程的 oom_adj ，从而调整进程的 oom_score。oom_adj 的范围是 [-17, 15]，数值越大，表示进程越容易被 OOM 杀死；数值越小，表示进程越不容易被 OOM 杀死，其中 -17 表示禁止 OOM。 12# 调整 sshd 进程的 oom_adjecho -16 &gt; /proc/$(pidof sshd)/oom_adj 5. 进程地址空间 用户空间内存，从低到高分别是五种不同的内存段。 只读段，包括代码和常量等 数据段，包括全局变量等 堆，包括动态分配的内存，从低地址开始向上增长，堆上的内存是匿名页 文件映射段，包括动态库、共享内存等，从高地址开始向下增长， 栈，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB 堆和文件映射段的内存是动态分配的。比如使用 C 标准库 malloc(): 可以在堆动态分配内存 mmap(): 可以在文件映射段动态分配内存 对于大多数分配器，free() 不会将内存换给操作系统，相反会保留它们以备将来分配。这意味着对会不停增长，进程的常驻内存只会增加，并且是正常现象。 使用 mmap() 分配，使用 munmap() 释放的内存则会归还给操作系统。 6. 内存监测指标与内存相关的专业术语或者指标包括: 内存统计: 包括各种内存的使用统计 缓存命中率 内存泄漏 swap 的影响 6.1 内存统计各种内存的统计信息记录在下面几个文件中: /proc/meminfo: 系统各内存统计 /proc/zoneinfo: 各 NUMA Node 内存以及页缓存统计信息 /proc/pid: 进程的各项统计信息 /proc/buddyinfo: 内核页面伙伴分配器统计信息 meminfo123456789101112131415 cat /proc/meminfoMemTotal: 2895444 kBMemFree: 2498868 kBMemAvailable: 2535384 kBBuffers: 3108 kBCached: 165872 kBSwapCached: 0 kBActive: 115656 kBInactive: 126632 kBActive(anon): 73964 kBInactive(anon): 9412 kBActive(file): 41692 kBInactive(file): 117220 kBUnevictable: 0 kB..... 其中: Buffers 是内核缓冲区用到的内存 Cache 是内核页缓存 Reclaimable 是 Slab 的一部分。Slab 包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录。 执行 man proc 我们可以看到这些指标的准确含义，有关 Buffers 和 Cached 的区别我们在文件系统一节再详述。 zoneinfo1234567891011121314151617 head -15 /proc/zoneinfoNode 0, zone DMA pages free 1937 min 95 low 118 high 142 scanned 0 spanned 4095 present 3998 managed 3977 nr_free_pages 1937 nr_alloc_batch 24 nr_inactive_anon 26 nr_active_anon 158 nr_inactive_file 579 nr_active_file 1040.... 其中: pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是剩余内存页数，它跟后面的 nr_free_pages 相同。 nr_zone_active_anon 和 nr_zone_inactive_anon，分别是活跃和非活跃的匿名页数。 nr_zone_active_file 和 nr_zone_inactive_file，分别是活跃和非活跃的文件页数。 后面我们看到的诸如 top，free，sar 命令输出的内存统计信息基本上都是基于这两个文件。 6.2 缓存命中率所谓缓存命中率，是指直接通过缓存获取数据的请求次数，占所有数据请求次数的百分比。 不过 Linux 系统中并没有直接提供查询缓存命中率的接口。基于 Linux 内核的 eBPF（extended Berkeley Packet Filters）机制的软件包bcc 提供了查询缓存命中率的工具: cachestat 提供了整个操作系统缓存的读写命中情况。 cachetop 提供了每个进程的缓存命中情况。 最后，Buffers 和 Cache 都是操作系统来管理的，应用程序并不能直接控制这些缓存的内容和生命周期。所以，在应用程序开发中，一般要用专门的缓存组件，来进一步提升性能。比如，程序内部可以使用堆或者栈明确声明内存空间，来存储需要缓存的数据。再或者，使用 Redis 这类外部缓存服务，优化数据的访问效率。 6.3 内存泄漏堆和文件映射段由应用程序自己来分配和管理，如果应用程序没有正确释放内存，就会造成内存泄漏。内存泄漏的危害这么大，因此我们需要有能检测内存泄漏的方法 – memleak。memleak 同样是位于 bcc工具包中的命令。 6.4 swap 影响1234567891011121314151617181920212223# 间隔1秒输出一组数据# -r表示显示内存使用情况，-S表示显示Swap使用情况$ sar -r -S 1# -d 表示高亮变化的字段# -A 表示仅显示Normal行以及之后的15行输出$ watch -d grep -A 15 'Normal' /proc/zoneinfoNode 0, zone Normal pages free 21328 min 14896 low 18620 high 22344 spanned 1835008 present 1835008 managed 1796710 protection: (0, 0, 0, 0, 0) nr_free_pages 21328 nr_zone_inactive_anon 79776 nr_zone_active_anon 206854 nr_zone_inactive_file 918561 nr_zone_active_file 496695 nr_zone_unevictable 2251 nr_zone_write_pending 0 像上面这样，使用后面讲到的诸如sar, free, cachetop 命令可以帮我找到Swap 发生的根源。但另一个问题是 Swap 到底影响了哪些应用程序呢？ 通过 /proc/pid/status 中的 VmSwap 字段，我们可以查到进程 Swap 换出的虚拟内存大小: 1234567# 按VmSwap使用量对进程排序，输出进程名称、进程ID以及SWAP用量$ for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid/&#123;printf $2 " " $3&#125;END&#123; print ""&#125;' $file; done | sort -k 3 -n -r | headdockerd 2226 10728 kBdocker-containe 2251 8516 kBsnapd 936 4020 kBnetworkd-dispat 911 836 kBpolkitd 1004 44 kB 或者直接使用 smem --sort swap可以直接将进程按照swap使用量排序显示。 最后要想从根本上降低 swap 带来的影响可以按需使用下面几种方法: 禁止 Swap，现在服务器的内存足够大，所以除非有必要，禁用 Swap 就可以了。随着云计算的普及，大部分云平台中的虚拟机都默认禁止 Swap。 如果实在需要用到 Swap，可以尝试降低 swappiness 的值，减少内存回收时 Swap 的使用倾向。 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以用库函数 mlock() 或者 mlockall() 锁定内存，阻止它们的内存换出。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.3 CPU 动态追踪]]></title>
    <url>%2F2020%2F01%2F18%2Flinux_perf%2F23_CPU%E5%8A%A8%E6%80%81%E8%BF%BD%E8%B8%AA%2F</url>
    <content type="text"><![CDATA[本节我们来介绍 CPU 动态追踪技术，包括 perf，systemtap，dtrace 1. Systemtap 进行 CPU 分析Systemtap 可以用来剖析用户级和内核级的 CPU 用量，也能跟踪 函数执行 CPU 交叉调用 中断 内核调度器 这些功能支持负载特征分析、剖析、下钻分析和延时分析。 1.1 内核剖析Dtrace123456789101112131415# solaris# 1. 以 997Hz 频率取样内核栈dtrace -n 'profile-997 /agr0/ &#123; @[stack()] = count()&#125;'# 2. 以 997Hz 频率取样内核栈，仅输出最频繁的 10 个dtrace -n 'profile-997 /agr0/ &#123; @[stack()] = count()&#125; END &#123; trunc(@, 10); &#125;'# 3. 以 997Hz 频率取样内核栈，每个栈只取 5 个帧dtrace -n 'profile-997 /agr0/ &#123; @[stack(5)] = count()&#125;'# 4. 以 997Hz 频率取样在 CPU 上运行的函数dtrace -n 'profile-997 /arg0/ @[func(arg0)] = count()'# 5. 以 997Hz 频率取样在 CPU 上运行的模块dtrace -n 'profile-997 /arg0/ @[mod(arg0)] = count()' Systemtap1234567891011121314151617# 1.以 997Hz 频率取样内核栈stap -d kernel -ve 'global s; probe timer.profile &#123; s[backtrace()] &lt;&lt;&lt; 1 &#125; probe end &#123;foreach (i in s+)&#123; print_stack(i); printf("\t%d\n", @count(s[i]));&#125;&#125;'# 2. 以 997Hz 频率取样内核栈，仅输出最频繁的 10 个stap -d kernel -ve 'global s; probe timer.hz(997) &#123; s[backtrace()] &lt;&lt;&lt; 1 &#125; probe end &#123; foreach (i in s- limit 10) &#123;print_stack(i); printf("\t%d\n", @count([s[i]]));&#125; &#125;'# 4. 以 997Hz 频率取样在 CPU 上运行的函数 - 未确认stap -d kernel -ve 'global s; probe timer.profile &#123; s[caller()] &lt;&lt;&lt; 1 &#125; probe end &#123;foreach (i in s+)&#123;printf("\t%s - %d\n", i, @count(s[i]));&#125;&#125;'# 5. 以 997Hz 频率取样在 CPU 上运行的模块 - 未确认stap -d kernel -ve 'global s; probe timer.profile &#123; s[module_name()] &lt;&lt;&lt; 1 &#125; probe end &#123;foreach (i in s+)&#123;printf("\t%s - %d\n", i, @count(s[i]));&#125;&#125;' 2. 用户剖析Dtrace1234567891011121314151617181920212223# solaris# 1. 以 997Hz 频率取样进程的用户栈dtrace -n 'profile-997 /agr1 &amp;&amp; pid == 123/ &#123; @[ustack()] = count()&#125;'dtrace -n 'profile-997 /agr1 &amp;&amp; execname == "sshd"/ &#123; @[ustack()] = count()&#125;'dtrace -n 'profile-997 /agr1/ &#123; @[execname, ustack()] = count()&#125;' # 取样所有进程的用户栈# 无 arg1 筛选，此时统计将包括用户栈被冻结的时间(一般是系统调用期间)dtrace -n 'profile-997 /pid == 123/ &#123; @[ustack()] = count()&#125;'# 2. 以 997Hz 频率取样用户栈，仅输出最频繁的 10 个dtrace -n 'profile-997 /agr1 &amp;&amp; pid == 123/ &#123; @[ustack()] = count()&#125; END &#123; trunc(@, 10); &#125;'# 3. 以 997Hz 频率取样用户栈，每个栈只取 5 个帧dtrace -n 'profile-997 /agr1 &amp;&amp; pid == 123/ &#123; @[ustack(5)] = count()&#125;'# 4. 以 997Hz 频率取样用户栈，仅输出在 CPU 上运行的函数名dtrace -n 'profile-997 /arg1 &amp;&amp; pid == 123/ @[ufunc(arg1)] = count()'# 5. 以 997Hz 频率取样用户栈，仅输出在 CPU 上运行的模块名dtrace -n 'profile-997 /arg1 &amp;&amp; pid == 123/ @[umod(arg1)] = count()'# 6.以 997Hz 频率取样用户进程的运行 CPUdtrace -n 'profile-997 /pid == 123/ &#123;@[cpu] == count()&#125;' Systemtap12345# 1. 未确认stap -ve 'global s; probe timer.hz(97) &#123;if (execname() == "mysqld") &#123;s[ubacktrace()] &lt;&lt;&lt; 1 &#125;&#125; probe end &#123; foreach (i in s- limit 10) &#123;print_ustack(i); printf("\t%d\n", @count(s[i]));&#125; &#125;' 3. 函数跟踪统计函数的 CPU 时间12345678# Dtracedtrace -n 'fbt::zio_checksum_generate:entry &#123;self-&gt;v = vtimestamp;&#125; fbt::zio_checksum_generate:return /self-&gt;v/ &#123;@["ns"] = quantize(vtimestamp - self-&gt;v);self-&gt;v=0 &#125;'# Systemtapstap -ve 'global s; probe kernel.function("sys_open").return &#123;s &lt;&lt;&lt; gettimeofday_ns() - @entry(gettimeofday_ns());&#125; probe end &#123;print(@hist_log(s))&#125;' 4. CPU 交叉调用打印CPU交叉调用以及这些调用的代码路径12345678# Dtracedtrace -n 'sysinfo:::xcalls &#123; @[stack()] = count(); &#125;'# Systemtapstap -d kernel -ve 'global s;probe scheduler.migrate &#123;s[backtrace()] &lt;&lt;&lt; 1&#125; probe end &#123; foreach (i in s- limit 10) &#123;print_stack(i); printf("\t%d\n", @count([s[i]]));&#125; &#125;' 5. 中断1234567891011121314151617181920212223242526# Dtrace 通过 intrstat 命令intrstat 1# Systemtapcd /usr/share/systemtap/tapset/linux/vim irq.stp probe irq_handler.exit = kernel.trace("irq_handler_exit") ? &#123; irq = $irq // the tracepoint doesn't have the struct definition, so we must @cast action = &amp; @cast($action, "irqaction", "kernel&lt;linux/interrupt.h&gt;") ret = $ret handler = action-&gt;handler flags = action-&gt;flags flags_str = irqflags_str(flags) dev_name = action-&gt;name dev_id = action-&gt;dev_id next_irqaction = action-&gt;next dir = action-&gt;dir thread_fn = action-&gt;thread_fn thread = action-&gt;thread thread_flags = action-&gt;thread_flags &#125;stap -ve 'global s; probe irq_handler.exit &#123; s[dev_id] &lt;&lt;&lt; 1&#125; probe end &#123; foreach (i in s+) &#123;printf("%s: %d\n", i, s[i])&#125;&#125;' 6. 调度器跟踪Dtracesched provider 提供了对内核 CPU 调度器的跟踪操作。12345# 跟踪 sshd 在 CPU 上的运行时间dtrace -n 'sched::on-cpu /execname == "sshd"/ &#123;self-&gt;ts = timestamp;&#125; sched::off-cpu / self-&gt;ts / &#123; @["ns"] = quantize(timestamp - self-&gt;ts); self-&gt;ts = 0; &#125;' Systemtap1234# 跟踪 sshd 在 CPU 上的运行时间stap -ve 'global s, t; probe scheduler.cpu_on &#123; if (execname() == "sshd") &#123; t[tid()] = gettimeofday_ns(); &#125;&#125; probe scheduler.cpu_off &#123; if (t[tid()]) &#123;s &lt;&lt;&lt; gettimeofday_ns() - t[tid()];delete t[tid()]&#125;&#125; probe end&#123;print(@hist_log(s))&#125;']]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.2 CPU 监测工具]]></title>
    <url>%2F2020%2F01%2F17%2Flinux_perf%2F22_CPU%E7%9B%91%E6%B5%8B%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[本节我们来介绍 CPU 相关的监测工具，这类工具属于我们前面所说的第一类计数器类命令。 1. 命令总览下面的图片摘录自极客时间专栏-Linux性能优化实战，分别从下面 3 个方面总结了 CPU 相关的性能检测工具: 从 CPU 的性能指标出发，根据指标找工具 从工具出发，根据工具找指标 根据工具指标之间的内在联系，掌握 CPU 分析的套路 有些工具是通用的分析工具，后面会在单独的章节中详细说明他们的使用。本节会介绍 CPU 专用的分析工具的使用 Linux Solaris 作用 说明 uptime uptime 平均负载 vmstat vmstat 系统范围的CPU平均负载 mpstat mpstat 单个CPU统计信息 time ptime 命令计时，带CPU用量分解 dstat 等于 vmstat + iostat + ifstat可同时观察CPU、磁盘 I/O、网络以及内存使用情况 通用命令，位于独立的一节中 sar sar 可统计包括内存，磁盘，中断等各种信息 通用命令，位于独立的一节中 ps ps 进程状态 通用命令，位于独立的一节中 top prstat 监控每个进程的基本信息 通用命令，位于独立的一节中 pidstat prstat 统计每个进程的内存，IO，上下文切换等信息 通用命令，位于独立的一节中 stap，perf Dtrace CPU剖析和跟踪 通用命令，位于独立的一节中 perf cpustat CPU性能计数器分析 通用命令，位于独立的一节中 除了上述命令之外，还包括以下内容: CPU 调度延迟统计 CPU 的调优手段 2. CPU 统计工具2.1 uptime12&gt; uptime 23:51:13 up 1:34, 3 users, load average: 0.00, 0.01, 0.05 输出: top - 14:58:20: 系统当前时间 up 4:33: 系统已运行时间 3 users：当前在线用户 load average：平均负载：最近1分钟、5分钟、15分钟系统的平均负载 说明： 平均负载：平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数 可运行状态：正在使用 CPU 或者正在等待 CPU 的进程，对应 ps R 状态（Running 或 Runnable）进程 不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的，对应 ps D 状态（Uninterruptible Sleep，也称为 Disk Sleep）进程 2.2 vmstat123456&gt; vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 2 0 0 1077816 2116 620312 0 0 65 43 34 53 0 0 99 0 0# 说明:# 除了 r 列外，第一行是系统启动以来的总结信息 -- 取决于 vmstat 的版本，最新的版本不是 vmstat [t [n]] 作用: 虚拟内存统计命令 说明: 完成的使用方法见内存相关部分的内容，CPU 中重点关注 procs 中 r 值的输出 参数: -t：采样间隔 -n：采样次数，可选，默认值是1 -S: -Sm 以MB 为单位显示结果 -a: 输出非活动和活动页缓存的明细 -s: 以列表显示内存统计信息 输出: procs: r: 可运行线程数，所有等待加上正在运行的线程数，不包括处于不可中断睡眠状态的线程 b: 等待IO的进程数量 cpu: 系统全局范围内的平均负载 第一行统计的系统启动以来的平均负载 – 新版本可能不会显示 其余行统计的是时间间隔周期内的平均负载 memory: swpd: 交换出的内存量 free: 空闲可用内存 buff: 用于缓冲缓存的内存 cache: 用于页缓存的内存 swap: si: 换入的内存 so: 换出的内存 2.3 mpstat1234567891011121314&gt; mpstat -P ALL 1 2Linux 3.10.0-1062.el7.x86_64 (localhost.localdomain) 2020年04月01日 _x86_64_ (1 CPU)00时22分51秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle00时22分52秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0000时22分52秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0000时22分52秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle00时22分53秒 all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.0000时22分53秒 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle平均时间: all 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00平均时间: 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 mpstat [t [n]] 作用: 报告每个 CPU的统计信息 参数: -P {cpu [，...] | ON | ALL}: 指示要报告统计信息的处理器编号，从 0 开始 ON: 表示在线的 CPU ALL: 表示所有 CPU I {SUM | CPU | ALL}: 报告中断统计信息 使用SUM关键字，mpstat命令报告每个处理器的中断总数 使用CPU关键字，显示CPU或CPU每秒接收的每个中断的数量 ALL关键字等效于指定上面的所有关键字，因此显示所有中断统计信息。 -A: 等效于 mpstat -I ALL -u -P ALL -u: 报告CPU使用率，默认参数 2.4 timetime command 作用: 运行命令并报告 CPU用量 其他: /usr/bin/time -v command 可以输出更详细的信息 1234567891011121314151617181920212223242526272829303132&gt; time lsdocker_print.pyreal 0m0.002s # 实际耗时user 0m0.001s # 用户空间耗时sys 0m0.001s # 内核空间耗时&gt; /usr/bin/time -v lsdocker_print.py Command being timed: "ls" User time (seconds): 0.00 System time (seconds): 0.00 Percent of CPU this job got: 100% Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.00 Average shared text size (kbytes): 0 Average unshared data size (kbytes): 0 Average stack size (kbytes): 0 Average total size (kbytes): 0 Maximum resident set size (kbytes): 968 Average resident set size (kbytes): 0 Major (requiring I/O) page faults: 0 Minor (reclaiming a frame) page faults: 309 Voluntary context switches: 1 Involuntary context switches: 0 Swaps: 0 File system inputs: 0 File system outputs: 0 Socket messages sent: 0 Socket messages received: 0 Signals delivered: 0 Page size (bytes): 4096 Exit status: 0 3. CPU 延时统计getdelays.c 4. CPU 调优4.1 sysbenchCPU 性能测试 4.2 chrtnice/renice系统调用: setpriority(): 调整优先级 sched_setscheduler(): 设置优先级和调度策略 4.3 调度器选项/proc/sys/sched 4.4 进程绑定taskset 4.5 独占CPU组4.6 资源控制 cgroups]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.1 CPU]]></title>
    <url>%2F2020%2F01%2F16%2Flinux_perf%2F21_CPU%2F</url>
    <content type="text"><![CDATA[本节我们来介绍 CPU 相关的操作系统原理。 1. CPU 相关的操作原理我们从下面几个方面入手来讲解 CPU 相关的操作系统原理: CPU 架构 中断处理 调度器: CPU 分配的内核子系统 进程: 上下文切换 僵尸进程 最后我们会说一说 CPU 检测的相关指标 2. CPU 架构2.1 CPU 的组成 一颗通用的双核处理器的组成如上。具体的组件就不一一解释了。 可以看到内存可能会同时被缓存在不同处理的多个 CPU 缓存中，缓存一致性确保了 CPU 永远访问正确的内存状态。 2.2 CPU 互联多处理器架构的 CPU 互联与系统的内存架构(同一内存访问 UMA，或者 NUMA)有关。常见的CPU有两种连接方式: 共享系统总线: 在处理器数量增加增加的情况下，会因为共享总线而出现扩展性问题 专用互联: 互联不仅仅是处理器，还可以是其他组件。 处理器之间的私有连接提供了无须竞争的访问以及比共享系统总线更高的带宽。除了外部互联，处理器还有核间通信用的内部互联。 一个早期的 intel 共享总线的四处理器如下所示: 一个四处理器的Intel QPI 架构如下所示: 2.3 MMU 和 TLB I$: 一级指令缓存: 按照虚拟地址空间寻址 D$: 一级数据缓存: 按照虚拟地址空间寻址 TLB: 转移后备缓冲器 E$: 二级缓存：按照物理内存地址寻址 MMU 负责虚拟地址到物理地址的转换，主存里的页表由MMU(硬件)直接读取，处理缓存未命中情况。 2.4 指令的执行CPU 指令的执行包括预期，解码，执行，内存访问，寄存器写回。内存访问往往需要几十个CPU周期，这段期间指令执行陷入停滞，这段时间称为停滞周期，因此需要CPU缓存降低内存访问的周期数。 CPI和IPC: CPI: 每指令周期数，IPC 的倒数，代表了指令处理的效率，是 CPU 使用率的本质，CPI 较高代表 CPU 经常陷入停滞 IPC: 每周期指令数， instructions per cycle 2.5 CPU性能计数器CPU性能计数器(CPC) 有很多别名包括性能监测点计数器(PIC)、性能监控单元(PMU)、硬件时间和性能监控事件。它们是可以计数低级 CPU 活动的处理器寄存器。通常包括下列计数器: CPU 周期: 包括停滞周期和停滞周期类型 CPU 指令: 一级，二级，三级缓存访问: 命中，未命中 浮点单元操作 内存 I/O: 读写停滞周期 资源 I/O: 读写停滞周期 每个 CPU 有少量，通常是 2-8 个，可编程记录类似事件的寄存器，哪些寄存器可用取决于处理器的型号。计数器计量哪些事件通过事件选择和 UMASK 确定。事件选择确定要计数的事件类型，UMASK 确定子类型或者子类型组。 3. 中断处理3.1 中断和中断线程 中断被内核用来响应设备的服务请求，分为: 中断服务程序: 需要通过注册来处理设备中断，这类程序需要运行的尽可能块，以减少对活动线程中断的影响。如果中断要做的工作不少，尤其是可能被阻塞，最好通过中断线程来处理，由内核调度 从中断开始到中断被服务之间的时间叫做中断延时 中断是一种异步的事件处理机制，用来提高系统的并发处理能力。 3.2 Linux 中断处理Linux 将中断处理过程分成了两个阶段: 上半部分: 用于快速处理中断，运行在中断禁止模式，会推迟新的中断的产生 主要处理跟硬件紧密相关的或时间敏感的工作。 下半部分: 可以作为tasklet 或者工作队列，之后通常作为内核线程由内核做调度 用来延迟处理上半部未完成的工作 以网络接收到数据包为例: 对上半部来说，既然是快速处理，其实就是要把网卡的数据读到内存中，然后更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个软中断信号，通知下半部做进一步的处理。 而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。 所以: 上半部直接处理硬件请求，也就是我们常说的硬中断，特点是快速执行； 下半部则是由内核触发，也就是我们常说的软中断，特点是延迟执行。 实际上上半部会打断 CPU 正在执行的任务，然后立即执行中断处理程序。而下半部以内核线程的方式执行，并且每个 CPU 都对应一个软中断内核线程，名字为 “ksoftirqd/CPU 编号”，比如说， 0 号 CPU 对应的软中断内核线程的名字就是 ksoftirqd/0。 3.1 软中断 tasklet 和工作队列首先软中断有三种实现方式: softirq: 也叫软中断，为避免歧义，用英文表示 tasklet: work queue: 4. 调度器4.1 调度器简介分时系统，通过划分执行时间，让多个进程同时运行。进程在处理器上和CPU间的调度是由调度器完成的。调度器操作线程(Linux 中是任务 task)，并将它们隐射到 CPU 上。 VCX: 资源上下文切换 ICX: 非自愿上下文切换 Premption: 抢占 Time Sharing: 分时 ON-PROC: 运行中 RUNNABLE: 可运行 调度器功能及实现调度器要实现如下功能: 分时: 可运行多线程 抢占: 高优先级线程在变为可运行状态时，能抢占当前运行的线程 负载均衡: CPU 之间的负载均衡 在 Linux 上 分时通过系统时钟中断调用 scheduler_tick() 实现 scheduler_tick 调用调度器类函数管理优先级和称为时间片的 CPU时间单位的到期事件 当线程变成可运行状态后就出发抢占，调度类函数 check_preempt_curr() 被调用 线程切换有 _schedule()管理，后者通过 pick_next_task() 选择最高优先级的线程运行 负载均衡由 load_balance() 函数负责执行 空闲线程内核”空闲”线程只在没有其他可运行线程的时候才在 CPU 上运行，通常被设计为通知CPU执行停止指令或者减速以节省资源，CPU会在下一次硬件中断醒来。 4.2 CPU 运行队列运行队列由调度器管理。花在等待 CPU 运行上的时间称为运行队列延时，又称调度器延时。 对于多处理器系统，内核通常为每个 CPU 提供一个运行队列，并尽量使得线程每次都被放到同一队列之中。目的是为了提高内存本地性，更高效的使用缓存。为每个 CPU 提供一个运行队列避免了队列操作的线程同步开销(mutex 锁)。 5.进程进程包括进程地址空间内的数据和内核里的元数据(上下文)： 内核上下文包含各种进程属性和统计信息 每一线程都包含一些元数据，包括在内核上下文里自己的优先级以及用户地址空间里自己的栈。 5.1上下文切换在前面的文章我们说过，用户进程通过系统调用执行内核特权操作时，会做上下文切换，从用户态进入到内核态。但是根据切换的任务的不提供，上下文切换包括多种类型: 进程上下文切换 线程上下文切换 中断上下文切换 系统调用的上下文切换 首先我们要明白的是，无论什么类型的上下文切换， CPU 寄存器和程序计数器（Program Counter，PC）都需要保存和重载，这一部又分称为CPU 上下文切换。其次不同的类型上下文切换因为不同任务间共享层次不同，需要交换的内容也就不同。 系统调用的上下文切换前面我们说过，执行系统调用时，一个进程的线程有两个栈: 一个用户级别栈和一个内核级别的栈。线程被阻塞时，用户级别的栈在系统调用期间不会改变。所以系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，上下文交换需要完成的操作其实很少。 进程上下文切换 进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。这些资源在进程上下文切换时都要保存和恢复。 Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新。在多处理器系统上，缓存是被多个处理器共享的，进程切换也会导致缓存被刷新。 由此可见进程上下文切换成本较高。 线程切换通常线程切换说的是同一进程内的线程，因为不同进程内的线程切换叫做进程切换。 线程会共享相同的虚拟内存和全局变量等资源。这些在上下文切换时是不需要修改的。需要保存的仅仅是线程的私有数据，比如栈和寄存器等。 中断上下文切换为了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。因此中断上下文切换并不涉及到进程的用户态，只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。 可以查看上下文切换到工具有 vmstat, pidstat -tw 5.2 僵尸进程正常情况下，当一个进程创建了子进程后，它应该通过系统调用 wait() 或者 waitpid() 等待子进程结束，回收子进程的资源；而子进程在结束时，会向它的父进程发送 SIGCHLD 信号，所以，父进程还可以注册 SIGCHLD 信号的处理函数，异步回收资源。如果父进程没这么做，或是子进程执行太快，父进程还没来得及处理子进程状态，子进程就已经提前退出，那这时的子进程就会变成僵尸进程。子进程的回收可以参考Python: 僵尸进程的产生和清除方法 通常，僵尸进程持续的时间都比较短，在父进程回收它的资源后就会消亡；或者在父进程退出后，由 init 进程回收后也会消亡。一旦父进程没有处理子进程的终止，还一直保持运行状态，那么子进程就会一直处于僵尸状态。大量的僵尸进程会用尽 PID 进程号，导致新进程不能创建，所以这种情况一定要避免。 对于僵尸进程，我们通常需要通过 pstree 找到其父进程，然后在父进程中解决。 5.3 进程状态进程状态有如下几种 状态 含义 D 不可中断睡眠，表示进程正在跟硬件交互，并且交互过程不允许被其他进程或中断打断目的是为了保护进程数据和硬件的一致性 R 正在运行或可运行（处于就绪排队中） S 可中断睡眠 (休眠中, 受阻, 在等待某个条件的形成或接受到信号) T 已停止的 进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行收到 SIGCONT 信号进程会回复运行 W 正在换页(2.6.内核之前有效) X 死进程 (未开启) Z 僵尸进程，进程已终止, 进程资源未被回收(比如进程的描述符、PID 等) I Idle 的缩写，也就是空闲状态，用在不可中断睡眠的内核线程上，没有任何负载D 状态的进程会导致平均负载升高，I 状态的进程不会 &lt; 高优先级(not nice to other users) N 低优先级(nice to other users) L 页面锁定在内存（实时和定制的IO） s 表示这个进程是一个会话的领导进程会话是指共享同一个控制终端的一个或多个进程组。 l 多线程（使用 CLONE_THREAD，像NPTL的pthreads的那样） + 在前台进程组，进程组表示一组相互关联的进程 6. CPU 监测指标与 CPU 相关的专业术语或者指标包括: 系统负载 CPU 使用率 中断计数 上下文切换 CPU 缓存命中率 6.1 进程状态与系统负载12345678&gt; uptime# 过去 1 分钟、5 分钟、15 分钟的平均负载（Load Average） 05:10:14 up 8:37, 2 users, load average: 0.21, 0.06, 0.06 &gt; watch -d uptime# 查看 CPU 个数&gt; grep 'model name' /proc/cpuinfo | wc -l uptime 中定义的系统负载与进程状态有关，平均负载是指单位时间内，系统处于可运行状态(R)和不可中断状态(D)的平均进程数,因此平均负载跟CPU使用率没有必然联系。 6.2 CPU 使用率CPU 使用率是通过测量 CPU 未运行内核空闲线程的时间得出的。CPU 使用率的测量包括了除此之外的所有时钟周期，包括内核停滞周期。CPU 可能会因为经常停滞等待 I/O 而导致高使用率，而不仅是执行指令。 如何测量时间跟 CPU 时间片有关: Linux 通过事先定义的节拍率（内核中表示为 HZ），来定义时间片的长短。HZ 是内核的可配选项，可以通过查询 /boot/config 内核选项来查看它的配置值。 时间片到期时，会触发系统计时器中断即clock()例程，会更新系统时钟和 jiffies 计数器；为了方便用户空间程序，内核还提供了一个用户空间节拍率 USER_HZ，它总是固定为 100，也就是 1/100 秒 根据计数器操作系统统计 CPU 运行不同运行程序的时间 /proc/stat 提供了 CPU 运行不同程序的计数信息 /proc/[pid]/stat 提供了每个进程运行情况的计数信息 123456789101112grep 'CONFIG_HZ=' /boot/config-$(uname -r)cat /proc/statcpu 772 0 812 17070 27 0 20 0 0 0cpu0 772 0 812 17070 27 0 20 0 0 0intr 38176 154 74 0 0 0 0 0 0 0 0 0 0 208 0 0 280 0 0 0 395 0 6282 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0ctxt 83630btime 1591280448processes 2288procs_running 2procs_blocked 0softirq 52342 1 20713 43 422 6208 0 100 0 0 24855 诸如 top, ps, mpstat, pidstat -u 正是使用上面的数据计算的 CPU 使用率，不同的是计算的方式和周期不同而已。对于CPU使用率的深入分析，需要借助 perf 等高级分析工具。 短时进程top, ps, pidstat -u 这类展示系统概要和进程快照的工具很难发现短时进程导致 CPU 使用率高的问题，需要使用记录事件的工具来配合诊断。下面是一些常见的分析思路: 需要时刻关注处于 Running 状态的进程数(top 命令 Tasks 行有不同状态进程的计数) 使用 pstree 可以查看进程树，有助于发现多进程问题 sar -w 1: 可以实时统计系统每秒创建的任务数(进程数) execsnoop: 是一个专为短时进程设计的工具，它通过 ftrace 实时监控进程的 exec() 行为，并输出短时进程的基本信息 对于CPU使用率的深入分析，需要借助 perf 等高级分析工具。 CPU 使用率的相关指标下面这些指标在各种 CPU 监测工具中都能看到，使用 man proc 可以看到他们的说明，但是最好是能记住: 指标 缩写 含义 user us 代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。 nice ni 代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。 system sys 代表内核态 CPU 时间。 idle id 代表空闲时间。注意，它不包括等待 I/O 的时间 iowait wa 代表等待 I/O 的 CPU 时间，出现 iowait 有两个条件，一是进程在等io，二是等io时没有进程可运行 irq hi 代表处理硬中断的 CPU 时间。 softirq si 代表处理软中断的 CPU 时间。 steal st 代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间。 guest guest 代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。 guest_nice gnice 代表以低优先级运行虚拟机的时间。而我们通常所说的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 注意：通常我们收的 CPU 使用率，就是除了空闲时间外的其他时间占总 CPU 时 6.3 中断计数中断的计数信息位于: /proc/softirqs: 提供了软中断的计数信息 /proc/interrupts: 提供了硬中断的计数信息 12345# 动态查看中断计数器的变化&gt; watch -d cat /proc/interrupts# 动态查看软中断的变化&gt; watch -d cat /proc/softirqs 硬中断硬中断的类型很多，常见的需要我们知道，包括: 重调度中断(RES): 又称处理器中断，与CPU之间实现缓存一致性和负载均衡有关 软中断1234567891011121314151617# 查看软中断计数&gt; cat /proc/softirqs CPU0 HI: 1 TIMER: 526599 NET_TX: 4262 NET_RX: 121304 BLOCK: 42438BLOCK_IOPOLL: 0 TASKLET: 358 SCHED: 0 HRTIMER: 0 RCU: 113508# 查看软中断内核线程&gt; ps aux | grep softirqroot 6 0.0 0.0 0 0 ? S 09:13 0:00 [ksoftirqd/0] /proc/softirqs 文件记录了所有的软中断类型以及它们在 CPU 上的发生次数。除了发生次数，我们要注意的是同一种软中断在不同 CPU 上的分布情况。正常情况下，同一种中断在不同 CPU 上的累积次数应该差不多。 6.4 上下文切换次数从性能分析角度，上下文切换可以分为: 无法获取资源而导致的自愿上下文切换: 通常意味发生了锁，磁盘等资源竞争 被系统强制调度导致的非自愿上下文切换: 通常以为的应用程序负载较高 但过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，缩短进程真正运行的时间，成为性能瓶颈。可以使用 vmstat, pidstat -w 查看系统和进程的上下文切换次数。 6.5 CPU 缓存命中率]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4. 操作系统]]></title>
    <url>%2F2020%2F01%2F15%2Flinux_perf%2F20_%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[从本文开始我们将进入Linux性能优化的第二阶段，操作系统部分。操作系统原理是复杂的，不可能也没有能力把操作系统都将清楚。我们会列出每个部分相关的关键术语，并就其中与性能优化相关的关键部分进行讲解。本文是一个关于操作系统和内核知识的概览，为后面做一点准备。 与操作系统相关的术语: 进程: 一个 OS 的抽象概念，是用来执行程序的环境，运行在用户模式(用户态)，通过系统调用或自陷来进入内核模式 线程: 可被调度的运行在 CPU上的可执行上下文 系统调用: 一套明确定义的协议，为用户程序请求内核执行特权操作 自陷: 信号发送到内核，请求执行一段系统程序(特权操作)，自陷类型包括系统调用、处理器异常以及中断 中断: 由物理设备发送到内核的信号，通常是请求 I/O 服务，中断是自陷的一种类型 时钟: 是一个驱动所有处理器逻辑的数字信号，CPU 以一个特定的时钟频率执行 1. 内核1.1 时钟UNIX 内核的一个核心组件是 clock() 例程，从一个计时器中断执行，每执行一次成为一个 tick。功能包括更新系统时间，计时器和线程调度时间片的到时结束，维护CPU计数器，以及执行 callout(内核调度例程)。 但是 clock() 曾经有过性能问题。现代内核已经把许多功能移出了 clock 例程，放到了按需中断中，这是为了努力创造无 tick 内核。包括 Linux 在内，clock 例程即系统计时器中断，除了更新系统时钟和更新 jiffies 计数器之外，执行的工作很少。jiffies 是 Linux 的时间单元与 tick 类似。 1.2 内核态用户进程通过系统调用执行内核特权操作时，会做上下文切换，从用户态到内核态。 无论是用户态还是内核态，都有自己的软件执行上下文，包括栈和寄存器。这些状态切换上下文是会耗费 CPU 周期的，这对每次I/O都增加了一小部分的时间开销。 1.3 用户栈和内核栈执行系统调用时，一个进程的线程有两个栈: 一个用户级别栈和一个内核级别的栈。线程被阻塞时，用户级别的栈在系统调用期间不会改变，当执行在内核上下文时，线程用的是一个单独的内核级别栈。此处有一个例外，信号处理程序取决于其配置，可以借用用户级别的栈。 2. Linux 性能监测工具接下来我们会按照操作系统的组成，讲解各个部分的监测工具和基准测试工具，下面是这些工具的概览，来自brendangregg 2.1 监测工具 2.2 测试工具 2.3 内核调参工具]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.6 Systemtap 与 Dtrace 的语法比较]]></title>
    <url>%2F2020%2F01%2F13%2Flinux_perf%2F16_dtrace_stap%2F</url>
    <content type="text"><![CDATA[《性能之巅》内对 Dtrace 和 Systemtap 的语法做了一个对比，对于学习二者是一个不错的资源，现整理如下。 1. DTrace To Systemtap下面是一份 DTrace 转换成 Systemtap 的简易指南，包括如下几个部分 语法 探针 内置变量 函数 转换示例 2. 语法 DTrace Systemtap 描述 探针名 probe 探针名 探针名 {var[a] = } global var; probe 探针名 {var[a]=} systemtap 的全局变量必须事先声明 /predicate/ {if (test) {}} @a = count(x)printa(@a) a &lt;&lt;&lt; xprint(count(a)) 聚合变量使用 arg0 …. agrNargs[0] … args[N] 目标变量 $var全局变量 @var(“file_stat@fs/file_table.c”) 如何获取探针中的变量 3. 探针 DTrace Systemtap 描述 BEGINdtrace:::BEGIN beginprobe begin ENDdtrace:::END endprobe end syscall:::entry syscall.* syscall:::return syscall.*.return syscall::read:entry syscall.read syscall::read:return syscall.read.return sched:::on-cpu scheduler.cup_on sched:::off-cpu scheduler.cpu_off profile:::profile-100 timer.profile profile:::tick-10s timer.s(10) fbt::foo:entry kernel.function(“foo”) fbt::foo:return kernel.function(“foo”).return io:::start ioblock.request io:::done ioblock.end 4. 内置变量 DTrace Systemtap 描述 execname execname() 执行在CPU上的进程名 uid uid() 执行在CPU上的用户ID pid pid() 执行在CPU上的进程PID cpu cpu() 进程当前所在的 CPU timestamp gettimeofday_s() 自启动以来的纳秒数 vtimestamp CPU上的线程时间，单位是纳秒 arg0..N 目标变量 探针参数(uint64_t) args[0]…[N] 目标变量 探针参数(类型化的) curthread task_current() 指向当前线程内核结构的指针 probefunc probefunc() 打印探针所在位置的内核函数名称 probename 当前探针名称 curpsinfo 当前进程信息 curpsinfo-&gt;pr_psargs cmdline_str() 进程启动的命令 $target target() 返回stap,dtrace 通过命令行设置的进程 pid 5. 函数 Dtrace Systemtap 描述 stringof(addr) kernel_string() 返回来自内核空间的字符串 copyinstr(addr) user_tring() 返回用户空间地址的字符串内核会执行一次从用户空间到内核空间的复制 stack(count) print_backtrace() 打印内核级别栈追踪 ustack(count) print_ubacktrace() 打印用户级别栈追踪 exit(status) exit() 退出DTrace并返回状态 quantize(value) @hist_log() 用 2 的幂次方直方图统计 value lquantize(value,min,max,step) @hist_linear() 用给定最下值，最大值和步进值做线性直方图记录 value 6. 转换示例列出系统调用入口探针1234567&gt; dtrace -ln syscall:::entry&gt; stap -l 'syscall.*'syscall.acceptsyscall.accept4syscall.access..... 统计 read() 返回大小1234567891011# dtrae1: arg1 作为系统调用 read() 的返回&gt; dtrace -n 'syscall::read:return &#123; @bytes = quantize(arg1); &#125;'# stap1: 查看 stap 目标变量，$return 是read() 的返回&gt; stap -L 'syscall.read.return'syscall.read.return name:string retval:long retstr:string $return:long int $fd:long int $buf:long int $count:long int $ret:long int# stap2: &gt; stap -e 'global bytes;probe syscall.read.return &#123; bytes &lt;&lt;&lt; $return &#125; probe end &#123; print(@hist_log(bytes)); &#125;' 根据进程名统计系统调用123456789# dtrace1:&gt; dtrace -n 'syscall:::entry &#123; @x[execname] = count(); &#125;'# stap1: 不便阅读&gt; stap -e 'global x; probe syscall.* &#123; x[execname()] &lt;&lt;&lt; 1 &#125; '# stap2: 格式化输出&gt; stap -ve 'global x; probe syscall.* &#123; x[execname()] &lt;&lt;&lt; 1 &#125; probe end &#123; foreach (k in x+) &#123;printf("%-36s %8d\n", k, @count(x[k])); &#125; &#125;' 对 PID 为 123 的进程，根据系统调用名统计系统调用次数123456# dtrace1: pid&gt; dtrace -n 'syscall:::entry /pid == 123/ &#123; @x[probefunc] == count(); &#125;'# stap1:&gt; stap -ve 'global x; probe syscall.* &#123; if (pid() == 123) &#123; x[probefunc()] &lt;&lt;&lt; 1 &#125;; &#125; probe end &#123; foreach (k in x+) &#123;printf("%-36s %8d\n", k, @count(x[k])); &#125; &#125;' 对 httpd 进程，根据系统调用名统计系统调用次数123456# dtrace1: execname&gt; dtrace -n 'syscall:::entry /execname == "httpd"/ &#123; @x[probefunc] == count(); &#125;'# stap1:&gt; stap -ve 'global x; probe syscall.* &#123; if (execname() == "httpd") &#123; x[probefunc()] &lt;&lt;&lt; 1 &#125;; &#125; probe end &#123; foreach (k in x+) &#123;printf("%-36s %8d\n", k, @count(x[k])); &#125; &#125;' 用进程名和路径名跟踪文件的open()123456# dtrace&gt; dtrace -l 'syscall::open.entry &#123; printf("%s, %s", execname, copyinstr(arg0)); &#125;'# stap&gt; stap -ve 'probe syscall.open &#123; filename = user_string_quoted($filename); printf("%s %s\n", execname(), filename); &#125;' 对 mysqld 进程统计 read() 延时123456789101112131415161718192021222324252627# dtrace1:&gt; dtrace -n 'syscall::read:entry /execname == "mysqld"/ &#123;self-&gt;ts = timestamp;&#125; syscall::read:return /self-&gt;ts/ &#123; @["ns"] = quantize(timestamp - self-&gt;ts);self-&gt;ts=0&#125;'&gt; stap1: gobal t,s; probe syscall.read &#123; if (execname() == "mysqld")&#123; t[tid()] = gettimeofday_ns(); &#125;&#125; probe syscall.read.return &#123; if (t[tid()])&#123; s &lt;&lt;&lt; gettimeofday_ns() - t[tid()]; delete t[tid()]; &#125;&#125;probe end &#123; printf("ns\n"); print(@hist_log(s))&#125;&gt; stap2: 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值&gt; stap -ve 'global s; probe syscall.read.return &#123;if (execname() == "mysqld") &#123;s &lt;&lt;&lt; gettimeofday_ns() - @entry(gettimeofday_ns());&#125;&#125; probe end&#123;print(@hist_log(s))&#125;' 根据进程名和参数跟踪新进程12345# dtrace: &gt; dtrace -n 'proc::exec-success &#123; trace(curpsinfo-&gt;pr_psargs) &#125;'# stap&gt; stap -ve 'probe process.begin &#123; printf("%s\n", cmdline_str()) &#125;' 以100Hz对内核栈采样1234567# dtrace&gt; dtrace -n 'profile-100 &#123; @[stack()]=count() &#125;'# stap&gt; stap -e 'global s; probe timer.profile &#123; s[backtrace()] &lt;&lt;&lt; 1 &#125; probe end &#123;foreach (i in s+)&#123; print_stack(i); printf("\t%d\n", @count(s[i]));&#125;&#125;']]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.5 Systemtap Python]]></title>
    <url>%2F2020%2F01%2F12%2Flinux_perf%2F15_stap_python%2F</url>
    <content type="text"><![CDATA[本节我们来看看如何使用 Systemtap 来追踪 Python 程序的执行。 1. 环境配置从 Python 3.6 开始，CPython 可以使用嵌入式“标记”，也称为“探测器”，使得可以通过 DTrace 或 SystemTap 来追踪 Cpython。 在 Linux 上，为了Systemtap 能够动态追踪 Cpython 的执行，必须按照如下步骤配置系统环境: 必须安装 SystemTap 开发工具 CPython 必须启用 –with-dtrace 编译选项 1.1 安装 SystemTap 开发工具1yum install systemtap-sdt-devel 1.2 Cpython 启用 –with-dtrace默认情况下，通过 yum 安装的 Python 都已启用 –with-dtrace 编译选项。可使用如下方式进行确认 123&gt; import sysconfig&gt; sysconfig.get_config_vars()&gt; sysconfig.get_config_var('WITH_DTRACE') 1.3 验证 Cpython 支持 Systemtap在 Linux 上，可以通过查看程序是否包含“.note.stapsdt”部分来验证构建的二进制文件中是否存在 SystemTap 静态标记。 如果 Cpython 未启用 –enable-shared 选项，可使用如下两种方式进行确认:12345&gt; readelf -S ./python | grep .note.stapsdt[30] .note.stapsdt NOTE 0000000000000000 00308d78&gt; readelf -n ./python# 显示的元数据或包含 SystemTap 的信息 stapsdt 通常情况下 yum 安装的 python 都会启用 –enable-shared 编译选项，因此需要通过下面的方式进行验证:12&gt; readelf -S /usr/lib64/libpython3.6m.so.1.0 |grep -i .note.stapsdt[28] .note.stapsdt NOTE 0000000000000000 002f5bcc 2. 使用 Systemtap 追踪 Python2.1 直接使用 Python 的静态标记使用 Systemtap 动态追踪 Python 的第一种方式是直接使用 Python 的静态标记。 12345678910111213141516171819# Python 未启用 --enable-shared 时probe process("python").mark("function__entry") &#123; filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf("%s =&gt; %s in %s:%d\\n", thread_indent(1), funcname, filename, lineno);&#125;# Python 启用 --enable-shared 时，静态标记包含在 libpython shared library 中probe process("python").library("libpython3.6m.so.1.0").mark("function__entry") &#123; filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf("%s =&gt; %s in %s:%d\\n", thread_indent(1), funcname, filename, lineno);&#125; Python 为 Systemtap 提供了以下静态标记: function__entry(str filename，str funcname，int lineno) 作用: 表示开始 Python 函数调用 说明: 这个静态标记，等同于内核函数，可以通过目标变量访问静态标记内的变量 参数: filename，funcname，lineno，必须使用$arg1，$arg2，$arg3访问 $arg1：(const char *) filename，使用user_string($arg1)获取 filename 的值 $arg2：(const char *) function name，使用user_string($arg2)获取funcname的值 $arg3：int 行号 function__return(str filename，str funcname，int lineno) 作用: 表示Python 函数调用结束，即return 或 exception 参数: 同 function__entry line(str filename，str funcname，int lineno) 作用: 此标记表示即将执行 Python 脚本一行，相当于使用 Python 探查器进行 line-by-line 跟踪 参数: 同 function__entry gc__start(int generation) 作用: Python interpreter 启动垃圾回收周期时触发 gc__done(long collected) 作用: Python interpreter 完成垃圾回收周期时触发 参数: $arg0: int 回收的对象数量。 import__find__load__start(str modulename) 作用: 在importlib尝试查找并加载模块之前触发 参数: $arg0: (const char *) modulename，使用user_string($arg0)获取modulename的值 import__find__load__done(str modulename，int found) 作用: 调用importlib的 find_and_load function 后触发。 参数: $arg0: (const char *) modulename，使用user_string($arg0)获取modulename的值 $arg1: int 表示模块是否已成功加载 追踪示例追踪Python调用的脚本123456789101112131415161718# stap 脚本probe process(&quot;python3.6&quot;).library(&quot;/usr/lib64/libpython3.6m.so.1.0&quot;).mark(&quot;function__entry&quot;) &#123; filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(&quot;%s =&gt; %s in %s:%d\n&quot;, thread_indent(1), funcname, filename, lineno);&#125;probe process(&quot;python3.6&quot;).library(&quot;/usr/lib64/libpython3.6m.so.1.0&quot;).mark(&quot;function__return&quot;) &#123; filename = user_string($arg1); funcname = user_string($arg2); lineno = $arg3; printf(&quot;%s &lt;= %s in %s:%d\n&quot;, thread_indent(-1), funcname, filename, lineno);&#125; 试验的 Python 脚本1234567891011# test.pydef two(): c = 1 + 2 return cdef one(): d = two() return done() 执行 Python 动态追踪1234567891011# stap 监测&gt; stap stap_test.stp -c "python3.6 test.py"......0 python3.6(29732): =&gt; __init__ in &lt;frozen importlib._bootstrap_external&gt;:800 4 python3.6(29732): &lt;= __init__ in &lt;frozen importlib._bootstrap_external&gt;:804 0 python3.6(29732): =&gt; &lt;module&gt; in test.py:2 5 python3.6(29732): =&gt; one in test.py:6 8 python3.6(29732): =&gt; two in test.py:210 python3.6(29732): &lt;= two in test.py:413 python3.6(29732): &lt;= one in test.py:816 python3.6(29732): &lt;= &lt;module&gt; in test.py:11 2.2 使用 Systemtap 提供的 typesettypeset 提供的函数库，可以帮助我们隐藏一些Python 静态标记的细节。从目前提供的 typeset 来看，提供的库还是很低级。 1234ll /usr/share/systemtap/tapset/|grep python-rw-r--r--. 1 root root 522 8月 7 2019 libpython2.7-64.stp-rw-r--r--. 1 root root 31021 10月 19 00:12 python2.stp-rw-r--r--. 1 root root 30405 10月 19 00:12 python3.stp]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.4 Systemtap 用户空间探测]]></title>
    <url>%2F2020%2F01%2F11%2Flinux_perf%2F14_stap%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[本节我们继续来学习 Systemtap 的使用 – 用户空间的动态追踪 1. 用户空间探测SystemTap从0.6版本开始也支持探测用户空间的进程。SystemTap可以探测用户空间进程内函数的调用和退出，可以探测用户代码中预定义的标记，可以探测用户进程的事件。 SystemTap进行用户空间探测需要uprobes模块。如果Linux内核版本大于等于3.5, 它已经内置了uprobes。 不过，SystemTap的用户空间事件跟踪功能依然需要你的内核支持utrace拓展。要想验证当前内核是否提供了必要的utrace支持，在终端中输入下面的命令： 12&gt; grep CONFIG_UTRACE /boot/config-`uname -r`CONFIG_UTRACE=y # 输出此，表示支持 2. 用户空间事件所有的用户空间事件都以process开头: 可以通过进程ID指定要检测的进程 也可以通过可执行文件名的路径名指定 SystemTap会查看系统的PATH环境变量，所以既可以使用绝对路径，也可以使用在命令行中运行可执行文件时所用的名字。以下将两者统称为PATH。 下面列出的事件都需要进程ID或可执行文件的路径。不在其中的process事件不需要PID和可执行文件路径名。 process(&quot;PATH&quot;).function(&quot;function&quot;) 进入可执行文件PATH的用户空间函数function 相当于内核空间中的kernel.function(“function”) 允许使用通配符和.return后缀 process(&quot;PATH&quot;).statement(&quot;statement&quot;) 代码中第一次执行statement的地方 相当于内核空间中的kernel.statement(“statement”) process(&quot;PATH&quot;).mark(&quot;marker&quot;) 在PATH中定义的静态探测点 可以使用通配符 有些用户空间下的可执行程序提供了这些静态探测点，比如Java process(&quot;PATH&quot;).begin 创建了一个用户空间下的进程 可以限定某个进程ID或可执行文件的路径 如果不限定，任意进程的创建都会触发该事件 process(&quot;PATH&quot;).thread.begin 创建了一个用户空间下的线程 可以限定某个进程ID或可执行文件的路径，也可以不限定 process(&quot;PATH&quot;).end 销毁了一个用户空间下的进程 可以限定某个进程ID或可执行文件的路径，也可以不限定 process(&quot;PATH&quot;).thread.end 销毁了一个用户空间下的线程。你可以限定某个进程ID或可执行文件的路径。 process(&quot;PATH&quot;).syscall 一个用户空间进程调用了系统调用 可以通过上下文变量$syscall获取系统调用号 还可以通过$arg1到$arg6分别获取前六个参数 添加.return后缀后会捕获退出系统调用的事件 在syscall.return中，可以通过上下文变量$return获取返回值 可以用某个进程ID或可执行文件的路径进行限定 123# java Hotspot 虚拟机，静态探测点 probe hotspot.gc_begin = process("/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64/jre/lib/amd64/server/libjvm.so").mark("gc__begin") 3.目标变量访问用户空间目标变量，所用的语法与访问内核空间目标变量的语法相同。同样的对于指向基本类型（如整数和字符串）的指针，可以使用下列的函数访问用户空间的数据。这些函数都是在process(PATH).xxx事件的处理程序中使用的 函数 作用 user_char(address) 从用户空间地址中获取char变量 user_short(address) user_long(address) user_int(address) user_string(address) user_string_n(address, n) 从用户空间地址中获取长为n的字符串 4. 用户空间栈回溯pp（probe point）函数可以返回触发当前处理程序的事件名（包含展开了的通配符和别名）。如果该事件与特定的函数相关，pp的输出会包括触发了该事件的函数名。 许多情况下触发同一个事件的函数可能来自于程序中不同的模块；特别是在该函数位于某个共享库的情况下。还好SystemTap提供了用户空间栈的回溯（backtrace）功能，便于查看事件是怎么被触发的。 编译器优化代码时会消除栈帧指针（stack frame pointers），这将混淆用户空间栈回溯的结果。所以要想查看栈回溯，需要有编译器生成的调试信息。 SystemTap用户空间栈回溯机制可以利用这些调试信息来重建栈回溯的现场。要想使用这些调试信息来重建栈回溯，给可执行文件加上-d executable选项，并给共享库加上-ldd选项。 1234# 需要安装 coreutils的debuginfostap -d /bin/ls --ldd \-e 'probe process("ls").function("xmalloc") &#123;print_usyms(ubacktrace())&#125;' \-c "ls /" 关于在用户空间栈回溯中可用的函数的更多内容，请查看ucontext-symbols.stp和ucontext-unwind.stp两个tapset。上述tapset中的函数的描述信息也可以在SystemTap Tapset Reference Manual找到。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.3 Systemtap 内核空间探测]]></title>
    <url>%2F2020%2F01%2F10%2Flinux_perf%2F13_stap%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E6%8E%A2%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[本节我们继续来学习 Systemtap 的使用 – 内核的动态追踪 1. 内核变量的获取本节我们来看如何获取内核空间中的变量，包括: 目标变量获取 全局以及静态变量获取 内置的便捷变量 2. 内核变量获取跟内核代码相关的事件，如kernel.function(“function”)和kernel.statement(“statement”)，允许使用目标变量获取这部分代码中可访问到的变量的值。stap -L 可以列出特定探测点下可用的目标变量。 12&gt; stap -L `kernel.function("vfs_read")`kernel.function("vfs_read@fs/read_write.c:277") $file:struct file* $buf:char* $count:size_t $pos:loff_t* stap -L 输出的每个目标变量前面都以$开头，并以:加变量类型结尾。上面的输出表示，vfs_read函数入口处有4个变量可用: $file（指向描述文件的结构体） $buf（指向接收读取的数据的用户空间缓冲区） $count（读取的字节数） $pos（读开始的位置） 下面使用目标变量的一个示例:1234567891011121314&gt; stap -L 'syscall.read'stap -L 'syscall.read'syscall.read name:string fd:long buf_uaddr:long count:long argstr:string $fd:long int $buf:long int $count:long int $ret:long intprobe syscall.read.return &#123; p = pid() fd = $fd # 引用目标变量 bytes = $return time = gettimeofday_us() - @entry(gettimeofday_us()) if (bytes &gt; 0) fileread[p, fd] += bytes time_io[p, fd] &lt;&lt;&lt; time&#125; 2.全局变量获取对于那些不属于本地变量的变量，像是全局变量或一个在文件中定义的静态变量，可以用@var(&quot;varname@src/file.c&quot;)获取。 SystemTap会保留目标变量的类型信息，并且允许通过-&gt;访问其中的成员。 -&gt;既可以用来访问指针指向的值，也可以用来访问子结构体中的成员。在获取复杂结构体中的信息时，-&gt;可以链式使用。下面是一个获取 fs/file_table.c中的静态目标变量files_stat 的示例，files_stat存储着一些当前文件系统中可调节的参数。 12345probe kernel.function(vfs_read) &#123; printf("current file_stat max_files: %d\n", @var("file_stat@fs/file_table.c")-&gt;max_files) exit()&#125; 有许多函数可以通过指向基本类型的指针获取内核空间对应地址上的数据：|函数|作用||:—|:—||kernel_char(address)|从内核空间地址中获取char变量||kernel_short(address)|||kernel_long(address)|||kernel_int(address)|||kernel_string(address)|||kernel_string_n(address, n)|从内核空间地址中获取长为n的字符串| 3. 内置变量某些场景中，我们可能需要输出当前可访问的各种变量，以便于记录底层的变化。SystemTap提供了一些操作，可以生成描述特定目标变量的字符串： $$vars: 输出作用域内每个变量的值 等同于 sprintf(&quot;parm1=%x ... parmN=%x var1=%x ... varN=%x&quot;, parm1, ..., parmN, var1, ..., varN) $$locals: 同$$vars，只输出本地变量 $$parms: 同$$vars，只输出函数入参。 $$return: 仅在带return的探针中可用 如果被监控的函数有返回值，它等价于sprintf(“return=%x”, $return)，否则为空字符串。 12345678910111213&gt; stap -e 'probe kernel.function("vfs_read") &#123;printf("%s\n", $$parms); exit(); &#125;'# vfs_read的入参有四个：file，buf，count，和pos# $$params会给这些入参生成描述字符串。在这个例子里，四个变量都是指针file=0xffff8800b40d4c80 buf=0x7fff634403e0 count=0x2004 pos=0xffff8800af96df48# 要想输出指针指向的值，我们可以加上$后缀&gt; stap -e 'probe kernel.function("vfs_read") &#123;printf("%s\n", $$parms$); exit(); &#125;'file=&#123;.f_u=&#123;...&#125;, .f_path=&#123;...&#125;, .f_op=0xffffffffa06e1d80, .f_lock=&#123;...&#125;, ....# 要想展开嵌套的结构体，你需要使用$$后缀。下面是一个使用$$的例子：# $$的输出，会受到字符串最长长度的限制而被截断&gt; stap -e 'probe kernel.function("vfs_read") &#123;printf("%s\n", $$parms$$); exit(); &#125;' 4. 如何使用 tapsettapset 是 systemtap 提供的函数库，提供了: 可用的内置函数 对于常见的目标变量，已将其提取为直接可用的内置变量。 我们以 ioblock 为例，来看看如何使用 tapset。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&gt; /usr/share/systemtap/tapset/linux/ioblock.stp/** * probe ioblock.request - Fires whenever making a generic block I/O request. * * @name - name of the probe point * @devname - block device name * @ino - i-node number of the mapped file * @sector - beginning sector for the entire bio * @flags - see below * BIO_UPTODATE 0 ok after I/O completion * BIO_RW_BLOCK 1 RW_AHEAD set, and read/write would block * BIO_EOF 2 out-out-bounds error * BIO_SEG_VALID 3 nr_hw_seg valid * BIO_CLONED 4 doesn't own data * BIO_BOUNCED 5 bio is a bounce bio * BIO_USER_MAPPED 6 contains user pages * BIO_EOPNOTSUPP 7 not supported * * @rw - binary trace for read/write request * @vcnt - bio vector count which represents number of array element (page, offset, length) which make up this I/O request * @idx - offset into the bio vector array * @phys_segments - number of segments in this bio after physical address coalescing is performed * @hw_segments - number of segments after physical and DMA remapping hardware coalescing is performed * @size - total size in bytes * @bdev - target block device * @bdev_contains - points to the device object which contains the partition (when bio structure represents a partition) * @p_start_sect - points to the start sector of the partition structure of the device * * Context: * The process makes block I/O request */probe ioblock.request = kernel.function ("generic_make_request")&#123; name = "ioblock.request" devname = __bio_devname($bio) ino = __bio_ino($bio) sector = $bio-&gt;bi_sector flags = $bio-&gt;bi_flags rw = $bio-&gt;bi_rw vcnt = $bio-&gt;bi_vcnt idx = $bio-&gt;bi_idx phys_segments = $bio-&gt;bi_phys_segments hw_segments = (@defined($bio-&gt;bi_hw_segments) ? $bio-&gt;bi_hw_segments : 0) size = $bio-&gt;bi_size bdev = $bio-&gt;bi_bdev bdev_contains = $bio-&gt;bi_bdev-&gt;bd_contains p_start_sect = __bio_start_sect($bio)&#125; 说明: 上面是 ioblock.stp 内容的一部分 probe ioblock.request 将常用的目标变量定义成了直接可用内部变量，eg: 通过 devname，我们可以直接获取设备名称，而不需要通过目标变量去获取 __bio_ino 是 ioblock.stap 内定义的函数，但是 __ 开头的属于内置函数不能使用。 1stap -ve 'probe ioblock.request &#123;printf("%s,%s\n", "devname: ", devname)&#125;']]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.2 stap 脚本]]></title>
    <url>%2F2020%2F01%2F09%2Flinux_perf%2F12_stap%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[本节我们来看看 stap 脚本的基本语法。 1. Systemtap 执行细节SystemTap脚本运行时，会启动一个对应的SystemTap会话。整个会话大致流程如下： 首先，SystemTap会检查脚本中用到的tapset，确保它们都存在于tapset库中（通常是/usr/share/systemtap/tapset/） SystemTap会把找到的tapset替换成在tapset库中对应的定义 tapset是tap（听诊器）的集合，指一些预定义的SystemTap事件或函数 SystemTap接着会把脚本转化成C代码，运行系统的C编译器编译出一个内核模块。 SystemTap随即加载该模块，并启用脚本中所有的探,这一步由system-runtime包的staprun完成 每当被监控的事件发生，对应的处理程序就会被执行。 一旦SystemTap会话终止，探针会被禁用，内核模块也会被卸载。 1.1 tapsetstapsets是一些包含常用的探针和函数的内置脚本，你可以在SystemTap脚本中复用它们。当用户运行一个SystemTap脚本时，SystemTap会检测脚本中的事件和处理程序，并在翻译脚本成C代码之前，加载用到的tapset。 与 SystemTap脚本一样，tapset的拓展名也是.stp。默认情况下tapset位于/usr/share/systemtap/tapset/。跟SystemTap脚本不同的是，tapset不能被直接运行；它只能作为库使用。 tapset库让用户能够在更高的抽象层次上定义事件和函数。tapset提供了一些常用的内核函数的别名，这样用户就不需要记住完整的内核函数名了（尤其是有些函数名可能会因内核版本的不同而不同）。另外tapset也提供了常用的辅助函数，比如下面将介绍的 thread_indent()。 1.2 SystemTap脚本SystemTap脚本由两部分组成：事件和处理程序。一旦SystemTap会话准备就绪，SystemTap会监控操作系统中特定的事件，并在事件发生的时候触发对应的处理程序。 一个事件和它对应的处理程序合称探针。一个SystemTap脚本可以有多个探针。 一个探针的处理程序部分通常称之为探针主体（probe body） 下面是一个 Systemtap 脚本的简单示例。需要注意的是 SystemTap脚本会一直运行，直到执行了exit()函数。如果你想中途退出一个脚本，可以用Ctrl+c中断 12345probe begin&#123; printf ("hello world\n") exit ()&#125; 2. SystemTap脚本的基本语法2.1 Systemtap 探针定义SystemTap脚本的后缀是.stp，并以这样的语句表示一个探针：probe event,event1 {statment} 1234# 1. 定义探针# 一个探针指定多个事件；每个事件以逗号隔开# 语句块由花括号（&#123;&#125;）括住，语句间通常不需要特殊的分隔符或终止符probe event,event1 &#123;statment&#125; 2.2 Systemtap 事件SystemTap事件大致分为两类：同步事件和异步事件。 同步事件会在任意进程执行到内核特定位置时触发。 syscall.system_call: 作用: 名为 system_call 的系统调用的调用事件 syscall.system_call.return: .return 表示 system_call 系统调用的退出事件 vfs.file_operation: 作用: 进入虚拟文件系统（VFS）名为file_operation的文件操作 vfs.file_operation.return: .return 表示 file_operation 的退出事件 file_operation取值的范畴，取决于当前内核中struct file_operations的定义的操作（可能位于include/linux/fs.h中，不同版本位置不同，建议上http://lxr.free-electrons.com/ident 查找 kernel.function(&quot;func_name@file_name[:line_num]&quot;): 作用: 内核调用和返回事件 参数: func_name: 函数名，可使用 * 通配 file_name: 文件名 [:line_num]: 指定行号，可选，如从行x到y，使用:x-y这样格式作为行号 eg: kernel.function(“sys_open”)即内核函数sys_open被调用时所触发的事件 eg: kernel.function(“sys_open”)即内核函数sys_open被调用时所触发的事件 eg: kernel.function(&quot;*@net/socket.c&quot;): net/socket.c中的所有函数的调用事件 kernel.trace(&quot;tracepoint&quot;): 作用: 跟踪内核的静态探测点。 表示到达名为tracepoint的静态内核探测点 eg: kernel.trace(“kfree_skb”)表示内核释放了一个网络缓冲区的事件 sudo perf list: 列出所有的静态内核探测点 module(&quot;module&quot;).function(&quot;function&quot;) 作用: 进入指定模块module的function函数 eg: module(&quot;ext3&quot;).function(&quot;*&quot;) 表示 ext3 模块中的每个函数调用 系统内的所有内核模块通常都在/lib/modules/$(uname -r) find -name &#39;*.ko&#39; -printf &#39;%f\n&#39; | sed &#39;s/\.ko$//&#39;: 列出所有的内核模块 除了上面的这些基础事件，Systemtap 按照特定的功能集合，创建了不同的 tapset，常见的包括: ioblock: 作用: 块设备接口和 I/O 调度器 scheduler: 作用: 内核 CPU 调度器事件 memeory: 进程和虚拟内存的使用 scsi: 作用: SCSI 目标的事件 networking: 作用: 网络设备事件，包括接收和传输 tcp 作用: TCP 协议事件，包括发送和接收事件 socket 作用: 套接字事件 异步事件跟特定的指令或代码的位置无关。 这部分事件主要包含计数器、定时器和其它类似的东西 begin: 作用: SystemTap会话的启动事件，会在脚本开始时触发 end: 作用: SystemTap会话的结束事件，会在脚本结束时触发。 timer events 作用: 用于周期性执行某段处理程序 说明: 定时事件总是跟其它事件搭配使用。其它事件负责收集信息，而定时事件定期输出当前状况，让你看到数据随时间的变化情况。 eg: probe timer.s(4) { printf(&quot;hello world\n&quot;) }: 每隔4秒就会输出hello world 其它规格的定时器: timer.ms(milliseconds) timer.us(microseconds) timer.ns(nanoseconds) timer.hz(hertz) timer.jiffies(jiffies): jiffies 表示时钟中断 timer.profile: 按照内核时钟频率对所有 CPU 都触发的探针，用于采样/剖析 2.3 函数内置函数 函数 作用 printf 格式化输出 execname 获取触发事件的进程名，下面将触发时间发生的进程称为当前进程 pid 当前进程ID tid 当前线程ID uid 当前进程的UID cpu 当前CPU gettimeofday_s 自epoch以来的秒数 ctime 将 gettimeofday_s 返回的秒数转化成时间字符串 pp 返回描述当前处理的探测点的字符串 thread_indent 打印空白，组织输出，以反映函数的调用次序和调用层级 name 返回系统调用的名字。只能在syscall.system_call触发的处理程序中使用 target 返回 -x PID 或 -c command 指定的PID或命令名 自定义函数SystemTap允许你编写函数来提取探针间公共的逻辑，函数的定义和使用如下所示:123456# 函数定义function function_name(arguments) &#123;statements&#125;# 函数使用# arguments是传递给函数的可选的入参probe event &#123;function_name(arguments)&#125; 下面是Systemtap 脚本的使用示例:123456789101112131415# 示例1 probe syscall.open&#123; printf (&quot;%s(%d) open\n&quot;, execname(), pid())&#125;# 示例2probe kernel.function(&quot;*@net/socket.c&quot;).call&#123; printf (&quot;%s -&gt; %s\n&quot;, thread_indent(1), probefunc())&#125;probe kernel.function(&quot;*@net/socket.c&quot;).return&#123; printf (&quot;%s &lt;- %s\n&quot;, thread_indent(-1), probefunc())&#125; 2.4 变量定义下面是 Systemtap 脚本内使用变量的一个示例，通过示例可以发现: global 用于定义全局变量，可在所有探针内使用 探针内的局部变量(eg: hz) 仅限探针内使用 SystemTap可以自动判定变量的类型，且属于强类型语言 1234567891011# 计算内核的CONFIG_HZ配置global count_jiffies, count_msprobe timer.jiffies(100) &#123; count_jiffies ++ &#125;probe timer.ms(100) &#123; count_ms ++ &#125;probe timer.ms(12345)&#123; hz=(1000*count_jiffies) / count_ms printf ("jiffies:ms ratio %d:%d =&gt; CONFIG_HZ=%d\n", count_jiffies, count_ms, hz) exit ()&#125; 2.5 关联数组关联数组即字典，Systemtap 中关联数组需要定义为全局变量。在一个数组语句中你最多可以指定九个表达式，每个表达式间以,隔开。这样做可以给单个键附加多个信息。 1234567891011121314151617181920212223242526272829# 1. 数组赋值foo["tom"] = 23foo["dick"] = 24foo["harry"] = 25# 2. 数组读取# 如果数组中没有对应的键，默认情况下在数值计算中返回 0，在字符串操作中返回空字符串printf("%s", foo["harry"]) # 3. 删除数组和数组中的元素delete foodelete foo['tom']# 4. 数组的键可以指定多个表达式device[pid(),execname(),uid(),ppid(),"W"] = devnameglobal readsprobe vfs.read&#123; reads[execname(),pid()] &lt;&lt;&lt; 1&#125;probe timer.s(3)&#123; foreach([var1,var2] in reads) printf("%s (%d) : %d \n", var1, var2, @count(reads[var1,var2]))&#125; 2.6 条件与循环SystemTap支持C风格的条件语句，另外对于数组还支持foreach (VAR in ARRAY) {}形式的遍历。123456789101112131415161718192021222324252627282930# 1. if 条件probe syscall.*&#123; if (pid() == target()) printf("if condition")&#125;# 2. 判断键是否在数组中if (index_expression in array_name) # 3. foreach 循环global readsprobe vfs.read&#123; reads[execname()] ++&#125;probe timer.s(3)&#123; foreach (count in reads) printf("%s : %d \n", count, reads[count])&#125;# 4. foreach 遍历控制# 可以给数组名加个后缀+来表示按升序遍历，或-按降序遍历。# 可以用limit加一个数字来限制迭代的次数probe timer.s(3)&#123; foreach (count in reads- limit 10) printf("%s : %d \n", count, reads[count])&#125; 2.7 聚合变量聚合变量用于实现对数据的流式处理，其可以是全局变量，也可以是数组中的值。使用&lt;&lt;&lt;运算符可以往聚集变量中添加新数据。 12345global readsprobe vfs.read&#123; reads[execname()] &lt;&lt;&lt; $count&#125; 在上面示例中: $count的值是一段时间内当前进程的读次数 &lt;&lt;&lt;会把$count的值存储到reads数组execname()关联的聚集变量中 &lt;&lt;&lt; 是把值存储在聚集变量里面；它们既没有加到原来的值上，也没有覆盖掉原来的值,就像是reads数组值每个键都有多个关联的值 要想从聚集变量中获取汇总的结果，使用这样的语法@extractor(variable/array_index _expression), eg： @sum(reads[execname()])。extractor可以取以下的函数： @count @sum @min @max @avg 1234567891011global readsprobe vfs.read&#123; reads[execname(),pid()] &lt;&lt;&lt; 1&#125;probe timer.s(3)&#123; foreach([var1,var2] in reads) printf("%s (%d) : %d \n", var1, var2, @count(reads[var1,var2]))&#125; 2.8 命令行参数通过$或@加个数字的形式可以访问对应位置的命令行参数 $会把用户输入当作整数，eg: $1,$2 @会把用户输入当作字符串, eg: @1,@2 2.9 @表示的操作符在Systemtap 中 @cast,@entry，表示的是一个操作符，操作符就是我们程序中的 “&lt;&gt;=&amp;” 等等操作: @cast 表示的是一个类型转换的操作符 @entry 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值 @hist_log,@count 等等，都是用来操作聚合变量的操作符 下面是 @entry 的一个使用示例1234&gt; stap2: 在.return探针中，有一个特殊的操作符@entry，用于存储该探针的入口处的表达式的值&gt; stap -ve 'global s; probe syscall.read.return &#123;if (execname() == "mysqld") &#123;s &lt;&lt;&lt; gettimeofday_ns() - @entry(gettimeofday_ns());&#125;&#125; probe end&#123;print(@hist_log(s))&#125;']]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.1 Systemp 简介]]></title>
    <url>%2F2020%2F01%2F08%2Flinux_perf%2F11_stap%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[从今天开始我们将学习第一个可编程的动态追踪工具 Systemtap。本节是 Systemtap 的一个基本介绍。 1. Systemtap 简介动态追踪技术起源于 Solaris 系统的 DTrace。Dtrace 有 Linux Mac OS X 等系统的移植版，但是实现的都差强人意，不支持很多高级特性。Systemtap 是 Redhat 开源的 Linux 上的动态追踪工具，是 Linux 上目前最成熟的动态追踪框架。 1.1 Systemtap 框架 Systemtap 的框架如上图所示: Systemtap 并不是 Linux 内核的一部分，因此第一步需要把 Systemtap 自己的“小语言”脚本（有点像 D 语言）动态编译成一个 Linux 内核模块的 C 源码，并加载到内核才能运行 Systemtap 使用的我们前面介绍的内核工具框架 DWARF 是Linux的调试符号表格式 整个SystemTap脚本所做的，无非就是声明感兴趣的事件，然后添加对应的处理程序。当SystemTap脚本运行时，SystemTap会监控声明的事件；一旦事件发生，Linux内核会临时切换到对应的处理程序，完成后再重拾原先的工作。 可供监控的事件种类繁多：进入/退出某个函数，定时器到期，会话终止，等等。处理程序由一组SystemTap语句构成，指明事件发生后要做的工作。其中包括从事件上下文中提取数据，存储到内部变量中，输出结果。 1.2 Systemtap 的优缺点Systemtap 有如下的优缺点: 首先，它并不是 Linux 内核的一部分，就是说它并没有与内核紧密集成，所以它需要一直不停地追赶主线内核的变化。 另一个缺点是，它需要动态编译，因此经常需要在线部署 C 编译器工具链和 Linux 内核的头文件。出于这些原因，SystemTap 脚本的启动相比 DTrace 要慢得多 无论是 DTrace 还是 SystemTap，其实都不支持编写完整的调试工具，因为它们都缺少方便的命令行交互的原语。所以我们才看到现实世界中许多基于它们的工具，其实最外面都有一个 Perl、Python 或者 Shell 脚本编写的包裹。比如 stap++ SystemTap 的优点是它有非常成熟的用户态调试符号的自动加载，同时也有循环这样的语言结构可以去编写比较复杂的探针处理程序，可以支持很多很复杂的分析处理。 GitHub 上面，有很多针对像 Nginx、LuaJIT 和操作系统内核这样的系统软件，也有一些是针对更高层面的像 OpenResty 这样的 Web 框架。有兴趣的朋友可以查看 GitHub 上面的 nginx-systemtap-toolkit、perl-systemtap-toolkit 和 stappxx 这几个代码仓库。 2. stap 安装SystemTap需要内核信息，这样才能注入指令。此外，这些信息还能帮助SystemTap生成合适的检测代码。这些必要的内核信息分别包括在特定内核版本所对应的-devel，-debuginfo和-debuginfo-common包中。对于“标准版”内核（指按照常规配置编译的内核），所需的-devel和-debuginfo等包命名为： kernel-debuginfo kernel-debuginfo-common kernel-devel: 通常已经安装 下面是Centos7 安装过程的示例： 12345678910111213141516171819202122232425262728293031323334# 方法一，直接执行 stap-prep，如果不起作用，需要手动安装方法二中的包stap-prep## 方法二# 1. 配置yum 源[debug]name=CentOS-$releasever - DebugInfobaseurl=http://debuginfo.centos.org/$releasever/$basearch/gpgcheck=0enabled=1protect=1priority=1# 2.安装 kernel-debuginfoyum --enablerepo=debug install -y kernel-debuginfo-$(uname -r)# 3. rpm 包位置，可直接下载手动 yum install http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-3.10.0-957.el7.x86_64.rpmhttp://debuginfo.centos.org/7/x86_64/kernel-debuginfo-3.10.0-957.el7.x86_64.rpmhttp://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-3.10.0-1062.el7.x86_64.rpmhttp://debuginfo.centos.org/7/x86_64/kernel-debuginfo-3.10.0-1062.el7.x86_64.rpm## 4. 运行下面命令开始检查，显示 pass 5 表示运行成功stab-prepstap -v -e 'probe vfs.read &#123;printf("read performed\n"); exit()&#125;'Pass 1: parsed user script and 474 library scripts using 251936virt/49240res/3488shr/45992data kb, in 80usr/330sys/411real ms.Pass 2: analyzed script: 1 probe, 1 function, 7 embeds, 0 globals using 416832virt/210188res/4872shr/210888data kb, in 1100usr/960sys/2058real ms.Pass 3: translated to C into "/tmp/stapdYWPVH/stap_5e2f013414e74a4de164b8e5c7459ef6_2765_src.c" using 416832virt/210444res/5128shr/210888data kb, in 10usr/70sys/85real ms.Pass 4: compiled C into "stap_5e2f013414e74a4de164b8e5c7459ef6_2765.ko" in 1090usr/660sys/1643real ms.Pass 5: starting run.read performancePass 5: run completed in 10usr/70sys/373real ms. 2.1 为其他计算机生成检测模块为了避免为所有带监测机器配置 Systemtap 环境的问题，SystemTap提供了交叉检测（cross-instrumentaion）的功能: 在一台计算机上运行SystemTap脚本，生成在另一台机器上可用的SystemTap检测模块 目标机器仅需安装 systemtap-runtime 来使用生成的SystemTap检测模块 创建和分发的过程如下:12345678# 1. 创建检测模块stap -r kernel_version script -m module_name&gt; stap -r `uname -r` -e 'probe vfs.read &#123;printf("read performance\n"); exit()&#125;' -m test&gt; ll test.ko-rw-r--r-- 1 root root 97392 4月 9 10:23 test.ko# 2. 分发运行检测模块&gt; staprun test.ko 3. stapstap 作用: 从SystemTap脚本中读取探测指令，把它们转化为C代码，构建一个内核模块，并加载到当前的Linux内核中运行 参数: -v 让SystemTap会话输出更加详细的信息.重复该选项多次来提高执行信息的详尽程度 -o file_name: 将输出重定向到file_name -S size[,count]: 将输出文件的最大大小限制成sizeMB，存储文件的最大数目为count -x process_id: 设置SystemTap处理函数target()为指定PID，target() 是 systemtap 脚本的内置函数 -c &#39;command&#39;: 运行command，并在command结束时退出。同时会把target()设置成command运行时的PID -e script: 直接执行给定的脚本 -F: 进入SystemTap的飞行记录仪模式，并在后台运行该脚本 man: man probe::ioblock.request 3.1 stap 飞行记录模式SystemTap的飞行记录仪模式允许你长时间运行一个SystemTap脚本，并关注最新的输出。飞行记录仪模式会限制输出的生成量。 飞行记录仪模式还可以分成两种：内存型（in-memory）和文件型（file）。无论哪一种 SystemTap脚本都是作为后台进程运行。 内存型:有 -F 选项，但没有指定 -o 选项时启用，SystemTap会把脚本输出结果存储在内核内存的缓冲区内。默认情况下，缓冲区大小为1MB.你可以使用-s(小s)来调整这个值 1234567&gt; stap -F iotime.stpDisconnecting from systemtap module.To reconnect, type "staprun -A stap_5dd0073edcb1f13f7565d8c343063e68_19556"# 重连，得到输出结果&gt; staprun -A stap_5dd0073edcb1f13f7565d8c343063e68_19556 文件型同时指定 -F,-o 选项时启用，-S选项来控制输出文件的大小和数目-S选项来控制输出文件的大小和数目。 12345&gt; stap -F -o /tmp/pfaults.log -S 1,2 pfaults.stp7590 # stap 进程的 PID# 终止 stap 进程&gt; kill -s SIGTERM 7590]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.6 eBPF]]></title>
    <url>%2F2020%2F01%2F07%2Flinux_perf%2F08.eBPF%2F</url>
    <content type="text"><![CDATA[今天我们来讲第二动态追踪技术 eBPF，eBPF 就是 Linux 版的 DTrace，可以通过 C 语言自由扩展。 1. eBPF 简介eBPF 的工作原理如下图所示: eBPF 通过 C 语言自由扩展（这些扩展通过 LLVM 转换为 BPF 字节码后，加载到内核中执行。从图中你可以看到，eBPF 的执行需要三步： 从用户跟踪程序生成 BPF 字节码； 加载到内核中运行； 向用户空间输出结果。 实际上，在 eBPF 执行过程中，编译、加载还有 maps 等操作，对所有的跟踪程序来说都是通用的。把这些过程通过 Python 抽象起来，也就诞生了 BCC（BPF Compiler Collection）。 BCC 把 eBPF 中的各种事件源（比如 kprobe、uprobe、tracepoint 等）和数据操作（称为 Maps），也都转换成了 Python 接口（也支持 lua）。这样，使用 BCC 进行动态追踪时，编写简单的脚本就可以了。 不过要注意，因为需要跟内核中的数据结构交互，真正核心的事件处理逻辑，还是需要我们用 C 语言来编写。 1.1 bcc 安装123456# REHL 7.6$ yum install bcc-tools# 安装后，BCC 会把所有示例（包括 Python 和 lua），放到 /usr/share/bcc/examples 目录中$ ls /usr/share/bcc/exampleshello_world.py lua networking tracing 1.2 eBPF 与 Systemtap在 eBPF 出现之前，SystemTap 是 Linux 系统中，功能最接近 DTrace 的动态追踪机制。SystemTap 在很长时间以来都游离于内核之外（而 eBPF 自诞生以来，一直根植在内核中。从稳定性上来说，SystemTap 只在 RHEL 系统中好用，在其他系统中则容易出现各种异常问题。当然，反过来说，支持 3.x 等旧版本的内核，也是 SystemTap 相对于 eBPF 的一个巨大优势。 2. eBPF 编码示例接下来，以 do_sys_open 为例，我们一起来看看，如何用 eBPF 和 BCC 来动态跟踪 do_sys_open 系统调用。 如下面的代码所示，通常我们可以把 BCC 应用，拆分为下面这四个步骤。 第一，跟所有的 Python 模块使用方法一样，在使用之前，先导入要用到的模块 BPF 第二，需要定义事件以及处理事件的函数。这个函数需要用 C 语言来编写，作用是初始化刚才导入的 BPF 对象。这些用 C 语言编写的处理函数，要以字符串的形式送到 BPF 模块中处理： 定义一个输出函数，并把输出函数跟 BPF 事件绑定 最后一步，就是执行事件循环，开始追踪 do_sys_open 的调用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# 1. 导入模块from bcc import BPF# 2. 定义事件以及处理事件的函数# define BPF program (""" is used for multi-line string).# '#' indicates comments for python, while '//' indicates comments for C.prog = """#include &lt;uapi/linux/ptrace.h&gt;#include &lt;uapi/linux/limits.h&gt;#include &lt;linux/sched.h&gt;// define output data structure in Cstruct data_t &#123; u32 pid; u64 ts; char comm[TASK_COMM_LEN]; char fname[NAME_MAX];&#125;;BPF_PERF_OUTPUT(events);// define the handler for do_sys_open.// ctx is required, while other params depends on traced function.int hello(struct pt_regs *ctx, int dfd, const char __user *filename, int flags)&#123; struct data_t data = &#123;&#125;; data.pid = bpf_get_current_pid_tgid(); data.ts = bpf_ktime_get_ns(); if (bpf_get_current_comm(&amp;data.comm, sizeof(data.comm)) == 0) &#123; bpf_probe_read(&amp;data.fname, sizeof(data.fname), (void *)filename); &#125; events.perf_submit(ctx, &amp;data, sizeof(data)); return 0;&#125;"""# load BPF programb = BPF(text=prog)# attach the kprobe for do_sys_open, and set handler to hellob.attach_kprobe(event="do_sys_open", fn_name="hello")# 3. 定义一个输出函数，并把输出函数跟 BPF 事件绑定# process eventstart = 0def print_event(cpu, data, size): global start # event’s type is data_t event = b["events"].event(data) if start == 0: start = event.ts time_s = (float(event.ts - start)) / 1000000000 print("%-18.9f %-16s %-6d %-16s" % (time_s, event.comm, event.pid, event.fname))# loop with callback to print_eventb["events"].open_perf_buffer(print_event)# 4. 就是执行事件循环，开始追踪 do_sys_open 的调用# print headerprint("%-18s %-16s %-6s %-16s" % ("TIME(s)", "COMM", "PID", "FILE"))# start the event polling loopwhile 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit() 通过这个简单的示例，你也可以发现，eBPF 和 BCC 的使用，其实比 ftrace 和 perf 有更高的门槛。想用 BCC 开发自己的动态跟踪程序，至少要熟悉 C 语言、Python 语言、被跟踪事件或函数的特征（比如内核函数的参数和返回格式）以及 eBPF 提供的各种数据操作方法。 BCC 软件包也内置了很多已经开发好的实用工具，默认安装到 /usr/share/bcc/tools/ 目录中，后面我们会详细介绍各个工具的使用。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.5 Dtrace]]></title>
    <url>%2F2020%2F01%2F06%2Flinux_perf%2F07.dtrace%2F</url>
    <content type="text"><![CDATA[今天我们来讲解第一个动态追踪技术 DTrace， 它是动态追踪技术的鼻祖 1. Dtrace 简介Solaris 系统的 DTrace 是动态追踪技术的鼻祖，它提供了一个通用的观测框架，并可以使用 D 语言进行自由扩展。 DTrace 的工作原理如下图所示。它的运行常驻在内核中，用户可以通过 dtrace 命令，把 D 语言编写的追踪脚本，提交到内核中的运行时来执行。 DTrace 本身依然无法在 Linux 中运行。很多工程师都尝试过把 DTrace 移植到 Linux 中，这其中，最著名的就是 RedHat 主推的 SystemTap。 2. DTrace 语法2.1 探针provider:module:function:name: provider: 相关探针的集合 module,function: 探针指示的代码位置的代号 name: 探针的名字 可以使用通配符，”::” == “:*:” providerDTrace 包含的 provider 如下所示:|provider|作用||:—|:—||syscal|系统调用||vminfo|虚拟内存统计||sysinfo|系统统计||profile|任意频率的采样||sched|内核调度事件||proc|进程级别事件||io|块设备接口跟踪，即磁盘I/O||pid|用户级别动态跟踪||tcp|TCP协议事件，连接、发送和接收||ip|IP 协议事件，发送和接收||fbt|内核级别动态追踪||高级语言的 provider|| 参数探针通过一组称为参数的变量来提供数据。例如系统调用 syscal 给每一个系统调用都做了入口(entry)和返回(return)探针。这组参数变量如下: 入口: arg0….argN，表示系统调用的参数 返回: arg0 或 arg1，表示返回值，errno 也会设置 2.2 D 语言D 语言定义了DTrace 的语法。DTrace 语句如下: probe_description /predicate/ {action}: probe_description: 探针 predicate: 可选的过滤表达式 action: 探针触发时执行的操作，分号分隔的语句 12proc:::exec-success /execname == "httpd"/ &#123;trace&#123;pid&#125;;&#125;# exec-success 用于跟踪新进程的创建和系统调用 exec() 的执行 内置变量内置变量用来计算和判断|变量|描述||:—|:—||execname|执行在CPU上的进程名||uid|执行在CPU上的用户ID||pid|执行在CPU上的进程PID||timestamp|自启动以来的纳秒数||vtimestamp|CPU上的线程时间，单位是纳秒||arg0..N|探针参数(uint64_t)||args[0]…[N]|探针参数(类型化的)||curthread|指向当前线程内核结构的指针||probefunc|探针描述的函数组件||probename|当前探针名称||curpsinfo|当前进程信息| 变量类型 类型 前缀 作用域 开销 多CPU安全 赋值示例 聚合变量 @ 全局 低 是 @x = count(); 带键聚合变量 @[] 全局 低 是 @x[pid] = count(); 从句局部变量 this-&gt; 从句实例 非常低 是 this-&gt;x = 1; 线程局部变量 self-&gt; 线程内 中等 是 self-&gt;x = 1; 标量 无 全局 中下 否 x = 1; 关联数组 无 全局 中上 否 x[y] = 1 说明: 线程局部变量: 作用域线程内，像时间戳这样的数据容易与线程关联 从句局部变量: 用于中间计算，只在针对同一探针描述的 action 子句有效 聚合变量: 可以由 CPU 单独计算汇总后在传递到用户空间 action action 作用 trace(arg) 打印arg printf(format, arg…) 格式化输出 stringof(addr) 返回来自内核空间的字符串 copyinstr(addr) 返回用户空间地址的字符串内核会执行一次从用户空间到内核空间的复制 stack(count) 打印内核级别栈追踪，如果有 count 按 count 截断 ustack(count) 打印用户级别栈追踪，如果有 count 按 count 截断 func(pc) 从内核程序计数器，返回内核函数名 ufunc(pc) 从用户程序计数器，返回用户函数名 exit(status) 退出DTrace并返回状态 聚合变量的特有的 action|action|作用||:—|:—||trunc(@agg, count)|截断聚合变量删除全部键，或者按照 count 指定的键数目截断||clear(@agg)|删除聚合变量的值，键保留||printa(format, @agg)|格式化打印聚合变量||count()|发生计数||sum(value)|value 求和||min(value)|||max(value)|||quantize(value)|用 2 的幂次方直方图统计 value||lquantize(value,min,max,step)|用给定最下值，最大值和步进值做线性直方图记录 value| 1234567891011# 显示系统调用 read(),返回的尺寸,使用2的幂次直方图显示&gt; dtrace -n 'syscall::read:return &#123; @["rval (bytes)"] = quantize(arg0); &#125;'# 跟踪系统调用 open()，打印进程名和文件路径名&gt; dtrace -n 'syscall::open:entry &#123; printf("%s, %s", execname, copyinstr(arg0)); &#125;'# 按进程名归纳所有的 CPU 交叉调用&gt; dtrace -n 'sysinfo:::xcalls &#123; @[execname] = count(); &#125;'# 按 99Hz 采样内核级栈&gt; dtrace -n 'profile:::profile-99 &#123; @[stack()] = count() &#125;' 2.3 DTrace 脚本123456789101112131415161718#!/usr/sbin/dtrace -sdtrace:::BEGIN&#123; printf(&quot;Tracing .... Hit Ctrl-C to end. \n&quot;)&#125;io:::start&#123; this-size = arg[0]-&gt;b_bcount; @Size[pid, curpsinfo-&gt;pr_psargs] = quantize(this-&gt;size)&#125;dtrace:::END&#123; printf(&quot;\n%8s %s\n&quot;, &quot;PID&quot;, &quot;CMD&quot;) printa(&quot;%8d %S\n%@d\n&quot;, @Size)&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.4 perf 的使用]]></title>
    <url>%2F2020%2F01%2F05%2Flinux_perf%2F06_perf_use%2F</url>
    <content type="text"><![CDATA[上一节我们学习了 perf 的基本原理，对 perf 有了一个整体上的认识，本节我们来学如何使用 perf 进行性能分析。 我们将按照如下几个部分来介绍 perf 的使用: perf 的辅助性命令，包括 perf list，perf probe 等 perf 的三种使用方式，计数模式，采样事件，以及事件上的 bp 程序 perf 提供的特殊用途的子命令，包括 perf sched，perf mem 等等 perf.data 的处理，这一部分命令用于格式化输出 perf.data 的内容便于生成类似火焰图等更复杂的图表 1. perf 命令概览作为开始，我们先来回顾一下 perf 命令的一个概览 perf [--version] [--help] [OPTIONS] COMMAND [ARGS] 子命令 作用 list List all symbolic event types列出当前系统支持的所有事件名,可分为三类：硬件事件、软件事件，检查点 probe Define new dynamic tracepoints用于定义动态检查点 stat Run a command and gather performance counter statistics对程序运行过程中的性能计数器进行统计 record Run a command and record its profile into perf.data 对程序运行过程中的事件进行分析和记录，并写入perf.data report Read perf.data (created by perf record) and display the profile读取perf.data(由perf record生成) 并显示分析结果 top System profiling tool.对系统的性能进行分析，类似top命令 sched Tool to trace/measure scheduler properties (latencies)针对调度器子系统的分析工具 lock Analyze lock events分析内核中的锁信息，包括锁的争用情况，等待延迟等 mem Profile memory accesses分析内存访问 kmem Tool to trace/measure kernel memory properties分析内核内存的使用 kvm Tool to trace/measure kvm guest os分析kvm虚拟机上的guest os timechart Tool to visualize total system behavior during a workload对record结果进行可视化分析输出，record命令需要加上timechart记录 script Read perf.data (created by perf record) and display trace output读取perf.data(由perf record生成)，生成trace记录，供其他分析工具使用 data Data file related processing把perf.data文件转换成其他格式 diff Read perf.data files and display the differential profile读取多个perf.data文件，并给出差异分析 evlist List the event names in a perf.data file列出perf.data中采集的事件列表 bench General framework for benchmark suitesperf提供的基准套件的通用框架，可以对当前系统的调度，IPC，内存访问进行性能评估 test Runs sanity tests. perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能 trace strace inspired tool类似于strace，跟踪目标的系统调用，但开销比strace小 ftrace simple wrapper for kernel ftrace functionality annotate Read perf.data (created by perf record) and display annotated code读取perf.data(由perf record生成)显示反汇编后的代码 archive Create archive with object files with build-ids found in perf.data file根据perf.data(由perf record生成)文件中的build-id将相关的目标文件打包 buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file c2c Shared Data C2C/HITM Analyzer. config Get and set variables in a configuration file. inject Filter to augment the events stream with additional information kallsyms Searches running kernel for symbols version display the version of perf binary 1. perf 辅助性命令1.1 perf listperf list [--no-desc] [--long-desc] [event_class] 作用: 列出perf可以支持的所有事件 event_class: 事件的分类，包括: hw|sw|cache|pmu|sdt|metric|metricgroup tracepoint: 静态探针 event_glob: 事件的通配符 12345678910perf listList of pre-defined events (to be used in -e): alignment-faults [Software event] bpf-output [Software event] context-switches OR cs [Software event] cpu-clock [Software event] cpu-migrations OR migrations [Software event] .......... perf list给出的事件是厂家上传上去给Linux社区的，但有些厂家会有自己的事件统计，没有上传出去，这需要从厂家的用户手册中获得，这种事件称为原始事件，可以直接用编号表示，格式为:rUUEE，其中UU == umask, EE ==事件编号。比如在我们的芯片里面，0x13号表示跨芯片内存访问，你就可以用-e r0013来跟踪软件的跨片访问次数。 1.2 perf probeperf probe 用来定义一个动态探针，定义的方式有如下几种: 用户空间: 通过 -x 指定二进制文件的路径，可以为该二进制程序添加库函数的动态探针 内核: 通过符号表和寄存器来添加，这种方式不需要内核调试信息(即 kernel-debuginfo) 通过 C 函数，C 函数中的特定行，并且可以附加函数上下文中的变量，这种方式需要内核调试信息。 命令使用1234567891011121314151617181920212223242526272829303132Usage: perf probe [&lt;options&gt;] 'PROBEDEF' ['PROBEDEF' ...] or: perf probe [&lt;options&gt;] --add 'PROBEDEF' [--add 'PROBEDEF' ...] or: perf probe [&lt;options&gt;] --del '[GROUP:]EVENT' ... or: perf probe --list [GROUP:]EVENT ... or: perf probe [&lt;options&gt;] --line 'LINEDESC' or: perf probe [&lt;options&gt;] --vars 'PROBEPOINT' or: perf probe [&lt;options&gt;] --funcs -a, --add &lt;[EVENT=]FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT [[NAME=]ARG ...]&gt; probe point definition, where GROUP: Group name (optional) EVENT: Event name FUNC: Function name OFF: Offset from function entry (in byte) %return: Put the probe at function return SRC: Source code path RL: Relative line number from function entry. AL: Absolute line number in file. PT: Lazy expression of line code. ARG: Probe argument (local variable name or kprobe-tracer argument format.) -D, --definition &lt;[EVENT=]FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT [[NAME=]ARG ...]&gt; Show trace event definition of given traceevent for k/uprobe_events. -d, --del &lt;[GROUP:]EVENT&gt; delete a probe event. -f, --force forcibly add events with existing name -F, --funcs &lt;[FILTER]&gt; Show potential probe-able functions. -L, --line &lt;FUNC[:RLN[+NUM|-RLN2]]|SRC:ALN[+NUM|-ALN2]&gt; -V, --vars &lt;FUNC[@SRC][+OFF|%return|:RL|;PT]|SRC:AL|SRC;PT&gt; Show accessible variables on PROBEDEF 添加动态探针123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# 一: 基于 uprobes ，为用户空间库函数添加动态探针# 想要查看普通应用的函数名称和参数，那么在应用程序的二进制文件中，同样需要包含调试信息。# 为/bin/bash添加readline探针，获取其返回值，并作为 string 类型返回$ perf probe -x /bin/bash 'readline'$ perf probe -x /bin/bash 'readline%return +0($retval):string'Added new event: probe_bash:readline__return (on readline%return in /usr/bin/bash with +0($retval):string)You can now use it in all perf tools, such as: perf record -e probe_bash:readline__return -aR sleep 1# 查询所有的函数$ perf probe -x /bin/bash --funcs# 查询函数的参数$ perf probe -x /bin/bash -V readlineAvailable variables at readline @&lt;readline+0&gt; char* prompt# 二: 基于 kprobes，为内核函数添加动态探针# 1. 通过符号表和寄存器添加 malloc 探针$ perf probe -x /lib64/libc-2.17.so '--add=malloc'$ perf probe --del "malloc"$ perf probe -x /lib64/libc-2.17.so '--add=malloc size=%di'# 2. 通过 C 扩展$ yum --enablerepo=base-debuginfo install -y kernel-debuginfo-$(uname -r)$ perf probe --add tcp_sendmsgAdded new event: probe:tcp_sendmsg (on tcp_sendmsg)You can now use it in all perf tools, such as: # 自动显示使用方式 perf record -e probe:tcp_sendmsg -aR sleep 1 # 获取 tcp_sendmsg 的返回值$ perf probe 'tcp_sendmsg%return $retval'# 2.1 列出tcp_sendmsg()可用的变量$ perf probe -V tcp_sendmsgAvailable variables at tcp_sendmsg @&lt;tcp_sendmsg+0&gt; size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk# 2.2 添加带参数的探针$ perf probe --add 'tcp_sendmsg size'# 2.3 列出tcp_sendmsg()可用的行探测:$ perf probe -L tcp_sendmsg&lt;tcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0&gt; 0 int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg, size_t size) 2 &#123; struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; 6 int iovlen, flags, err, copied = 0; 7 int mss_now = 0, size_goal, copied_syn = 0, offset = 0; bool sg; long timeo;[...]# 2.4 检查在第81行有哪些变量可用$ perf probe -V tcp_sendmsg:81Available variables at tcp_sendmsg:81 @&lt;tcp_sendmsg+537&gt; bool sg int copied int copied_syn int flags int mss_now int offset int size_goal long int timeo size_t seglen struct iovec* iov struct sock* sk unsigned char* from# 2.5. 跟踪第81行，并使用循环中的seglen变量$ perf probe --add 'tcp_sendmsg:81 seglen' 2. perf stat(计数模式)perf stat 是 perf 三种使用模式中的第一种模式计数模式。 perf stat: 命令格式: perf stat [-e &lt;EVENT&gt; | --event=EVENT] [-a] &lt;command&gt; perf stat [-e &lt;EVENT&gt; | --event=EVENT] [-a] — &lt;command&gt; [&lt;options&gt;] perf stat [-e &lt;EVENT&gt; | --event=EVENT] [-a] record [-o file] — &lt;command&gt; [&lt;options&gt;] perf stat report [-i file] 作用: 可以对程序运行过程中的性能计数器(包括Hardware，software counters)进行统计，分析程序的整体消耗情况 参数: -d, -dd, -ddd 输出更详细的信息 2.1 perf stat 默认输出默认情况 perf stat 只会对 Software Events 和 Hardware Events 进行计数分析。下面是 perf stat 的使用示例 123456789101112131415$ perf stat lsPerformance counter stats for 'ls': 2.164836 task-clock (msec) # 0.808 CPUs utilized 51 context-switches # 0.024 M/sec 4 cpu-migrations # 0.002 M/sec 333 page-faults # 0.154 M/sec 5506056 # 2.543 GHz 0 stalled-cycles-frontend # 0.00% frontend cycles idle 0 stalled-cycles-backend # 0.00% backend cycles idle 6100570 instructions # 1.11 insns per cycle 1298744 branches # 599.927 M/sec 18509 branch-misses # 1.43% of all branches 0.002679758 seconds time elapsed 指标含义: task-clock (msec): cpu处理task所消耗的时间，单位ms 0.808 CPUs utilized的表示cpu使用率为80.8%，该值越高代表程序是CPU bound而非IO bound 类型 instructions： 执行的指令条数， insns per cycle: 即IPC，每个cpu周期执行的指令条数，IPC比上面的CPU使用率更能说明CPU的使用情况 更高的IPC值意味着更高的指令吞吐量，更低的值表示更多的停顿周期。 一般来说，我认为IPC值越高(例如，超过1.0)就越好，表示工作的最佳处理。但是，需要检查执行指令是什么，以防这是一个旋转循环: 指令率高，但实际完成的工作率低。 stalled-cycles-frontend和stalled-cycles-backend: 表示CPU停滞统计 前端和后端指标指的是CPU管道，统计的是它们的停顿次数 前端按顺序处理CPU指令。它包括指令获取，以及分支预测和解码。 解码后的指令成为后端处理的微操作(uops)，并且可能会乱序地执行。 每条指令的停滞周期类似于IPC(反向)，但是，只计算停滞周期，这将用于内存或资源总线访问。 branches：这段时间内发生分支预测的次数。现代的CPU都有分支预测方面的优化。 branches-misses：这段时间内分支预测失败的次数，这个值越小越好。 详细模式可以使用 -d 选项输出更详细的信息，带 -d 选项的输出会包含用于一级数据缓存事件和最后一级缓存(LLC)事件的额外计数器。-dd,-ddd可输出更加详细的信息。 123456789101112131415161718192021$ perf stat -d gzip file1 Performance counter stats for 'gzip file1': 1610.719530 task-clock # 0.998 CPUs utilized 20 context-switches # 0.012 K/sec 0 CPU-migrations # 0.000 K/sec 258 page-faults # 0.160 K/sec 5,491,605,997 cycles # 3.409 GHz [40.18%] 1,654,551,151 stalled-cycles-frontend # 30.13% frontend cycles idle [40.80%] 1,025,280,350 stalled-cycles-backend # 18.67% backend cycles idle [40.34%] 8,644,643,951 instructions # 1.57 insns per cycle # 0.19 stalled cycles per insn [50.89%] 1,492,911,665 branches # 926.860 M/sec [50.69%] 53,471,580 branch-misses # 3.58% of all branches [51.21%] 1,938,889,736 L1-dcache-loads # 1203.741 M/sec [49.68%] 154,380,395 L1-dcache-load-misses # 7.96% of all L1-dcache hits [49.66%] 0 LLC-loads # 0.000 K/sec [39.27%] 0 LLC-load-misses # 0.00% of all LL-cache hits [39.61%] 1.614165346 seconds time elapsed 2.2 指定 Hardware Events 计数器下面是对 Hardware Events 指定计数的示例。如果 -e 指定的硬件事件包含“ cycle ”和“ instructions ”计数器，那么 perf 的输出中将包含 IPC。硬件事件通常是特定于处理器模型的，许多可能无法从虚拟化环境中获得。 12345678910111213141516171819202122232425262728# 指定硬件计数器$ perf stat -e L1-dcache-loads,L1-dcache-load-misses,L1-dcache-stores gzip file1 Performance counter stats for 'gzip file1': 1,947,551,657 L1-dcache-loads 153,829,652 L1-dcache-misses # 7.90% of all L1-dcache hits 1,171,475,286 L1-dcache-stores 1.538038091 seconds time elapsed# 使用原始事件$ perf stat -e cycles,instructions,r80a2,r2b1 gzip file1 Performance counter stats for 'gzip file1': 5,586,963,328 cycles # 0.000 GHz 8,608,237,932 instructions # 1.54 insns per cycle 9,448,159 raw 0x80a2 11,855,777,803 raw 0x2b1 1.588618969 seconds time elapsed# PMCs: counting cycles and frontend stalls via raw specification:$ perf stat -e cycles -e cpu/event=0x0e,umask=0x01,inv,cmask=0x01/ -a sleep 5 2.3 通过静态探针统计系统调用通过 -e 指定 Kernel Tracepoint Events，perf stat 可以统计程序执行的系统调用: 12345678910# 统计系统调用统计系统调用并打印摘要(非零计数)$ perf stat -e &apos;syscalls:sys_enter_*&apos; gzip file1 2&gt;&amp;1 | awk &apos;$1 != 0&apos;Performance counter stats for &apos;gzip file1&apos;: 1 syscalls:sys_enter_utimensat 1 syscalls:sys_enter_unlink 5 syscalls:sys_enter_newfstat 1,603 syscalls:sys_enter_read 3,201 syscalls:sys_enter_write 使用系统调用跟踪程序strace -c可以看到类似的报告，但是它可能导致比perf高得多的开销，因为perf在内核中缓冲数据。strace的当前实现使用ptrace(2)附加到目标进程并在系统调用期间停止它，就像调试器一样。这是暴力的，并可能导致严重的开销。 perf trace 子命令提供与 strace 类似的功能，但开销要低得多。perf trace 还可以进行系统级的系统调用跟踪（即跟踪所有进程），而 strace 只能跟踪特定的进程。 3. 采样事件perf record 是perf 的第二种使用方式，采样事件，他包含如下几种模式: Timed Profiling，以固定间隔采样，使用 -F 选项 Event Profiling，基于事件采样(通常是硬件事件，软件事件较少)，使用 -e 指定采样事件 Static Kernel Tracing: 基于内核的静态探针，使用 -e 指定静态探针类型。 perf-record用来启动一次跟踪: perf record在当前目录产生一个perf.data文件，用来记录过程数据 如果这个文件已经存在，旧的文件会被改名为perf.data.old perf.data只包含原始数据，perf report 需要访问本地的符号表，pid和进程的对应关系等信息来生成报告。 所以perf.data不能直接拷贝，可以通过perf-archive命令把所有这些数据打包，然后复制 3.1 perf record/report 命令perf record 命令格式: perf record [-e &lt;EVENT&gt; | --event=EVENT] [-a] &lt;command&gt; perf record [-e &lt;EVENT&gt; | --event=EVENT] [-a] — &lt;command&gt; [&lt;options&gt;] 参数: -p, --pid &lt;pid&gt;: 指定跟踪固定的一组进程，即仅仅跟踪发生在特定pid的事件 -a, --all-cpus: 跟踪整个系统的性能，常用选项 -c, --count &lt;n&gt;: 累计多少个事件记录一次 -g: 开启堆栈追踪，通常无需使用 -F: 事件采样的频率, 单位HZ, 更高的频率会获得更细的统计，但会带来更多的开销 sleep: 采样的时间 perf.data 文件可以用多种方法处理。perf report命令启动ncurses导航器来检查调用图。或者使用 –stdio 选项将调用图打印成树状，并标注百分比: perf report [-i &lt;file&gt; | --input=file] 使用: 显示的是一个菜单项，回车可以查看折叠的代码，esc 或者 q 可以退出返回上一级 参数: --pid=: 指定 pid --tid=: 指定 tid -S, --symbols=: Only consider these symbols. --stdio: 在终端将调用图以树状图打印 3.2 Timed Profilingperf 可以基于对指令指针或堆栈跟踪的固定间隔采样(定时分析)来分析CPU使用情况。入下例所示以99赫兹(-F 99)，对整个系统(-a，对所有CPU)采样CPU堆栈，采样10秒，并记录堆栈(-g，调用图): 1$ perf record -F 99 -a -g -- sleep 30 选择99赫兹而不是100赫兹，是为了避免偶然地与某些周期性活动同步采样，以免产生扭曲的结果。这也是粗糙的:你可能想要增加到更高的速率(例如，高达997赫兹)以获得更好的分辨率，请记住，更高的频率意味着更高的开销。 3.3 Event Profiling除了按时间间隔采样外，由CPU硬件计数器触发的采样是CPU分析的另一种形式。某些事件发生的频率非常高，在每次出现时都收集堆栈会导致过多的开销并降低系统速度并改变目标的性能特征。通常，只测量它们出现的一小部分，而不是全部，就足够了。这可以通过使用“-c” 指定触发事件收集的阈值来实现。“-c count”机制是由处理器实现的，它只在达到阈值时中断内核。 例如，下面的一行程序统计 1级数据缓存加载失败次数，每10000次失败收集一次堆栈跟踪: 12# 每 1000 次收集一次堆栈跟踪perf record -e L1-dcache-load-misses -c 10000 -ag -- sleep 5 3.4 Static Kernel Tracing通过内核静态探针，可以跟踪内核的系统调用。 跟踪新进程的创建1234567891011121314151617# perf record -e sched:sched_process_exec -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ]# perf report -n --sort comm --stdio[...]# Overhead Samples Command# ........ ............ .......# 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff 跟踪出站连接12345678910111213141516$ perf record -e syscalls:sys_enter_connect -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.057 MB perf.data (~2489 samples) ]# perf report --stdio# ========# Samples: 21 of event 'syscalls:sys_enter_connect'# Event count (approx.): 21# Overhead Command Shared Object Symbol ........ ....... .................. ........................... 52.38% sshd libc-2.15.so [.] __GI___connect_internal 19.05% groups libc-2.15.so [.] __GI___connect_internal 9.52% sshd libpthread-2.15.so [.] __connect_internal 9.52% mesg libc-2.15.so [.] __GI___connect_internal 9.52% bash libc-2.15.so [.] __GI___connect_internal 记录connect()的堆栈跟踪可以解释为什么会出现这些出站连接: 1234$ perf record -e syscalls:sys_enter_connect -ag^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.057 MB perf.data (~2499 samples) ]$ perf report --stdio 跟踪套接字缓冲区消耗跟踪套接字缓冲区的消耗和堆栈跟踪是识别导致套接字或网络I/O的原因的一种方法。 1234$ perf record -e 'skb:consume_skb' -ag^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.065 MB perf.data (~2851 samples) ]$ perf report 3.4 Static User Tracing在4.x 的内核中，添加了用户态静态追踪机制。下面演示了Linux 4.10(附加了一个补丁集)，如何跟踪Node.js 的USDT探针:1234567891011121314151617# perf buildid-cache --add `which node`# perf list | grep sdt_node sdt_node:gc__done [SDT event] sdt_node:gc__start [SDT event] sdt_node:http__client__request [SDT event] sdt_node:http__client__response [SDT event] sdt_node:http__server__request [SDT event] sdt_node:http__server__response [SDT event] sdt_node:net__server__connection [SDT event] sdt_node:net__stream__end [SDT event]# perf record -e sdt_node:http__server__request -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.446 MB perf.data (3 samples) ]# perf script node 7646 [002] 361.012364: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.204718: sdt_node:http__server__request: (dc2e69) node 7646 [002] 361.363043: sdt_node:http__server__request: (dc2e69) 3.5 Dynamic Tracing使用动态追踪需要启用如下的内核参数: 内核动态跟踪需要启用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y 用户级动态跟踪需要启用 CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y 为避免内核栈指针优化，需要启用 CONFIG_FRAME_POINTER=y 下面是几个在 Linux 使用 perf 进行动态追踪的示例 检测内核tcp_sendmsg()函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# 1. 添加动态探针$ perf probe --add tcp_sendmsgFailed to find path of kernel module.Added new event: probe:tcp_sendmsg (on tcp_sendmsg)You can now use it in all perf tools, such as: perf record -e probe:tcp_sendmsg -aR sleep 1# 2. 使用动态探针$ perf record -e probe:tcp_sendmsg -a -g -- sleep 5# 3. 输出追踪报告$ perf report --stdio# 如果内核有debuginfo (CONFIG_DEBUG_INFO=y)，那么可以从函数中提取内核变量。# 这是在Linux 3.13.1上检查size_t(整数)的一个简单示例。# 5.列出tcp_sendmsg()可用的变量$ perf probe -V tcp_sendmsgAvailable variables at tcp_sendmsg @&lt;tcp_sendmsg+0&gt; size_t size struct kiocb* iocb struct msghdr* msg struct sock* sk# 6. 使用变量“size”为tcp_sendmsg()创建一个探针:$ perf probe --add 'tcp_sendmsg size'# 7. 跟踪此探针$ perf record -e probe:tcp_sendmsg -a$ perf script# 内核:将显示 tcp_sendmsg()行号和本地变量值# ========# sshd 1301 [001] 502.424719: probe:tcp_sendmsg: (ffffffff81505d80) size=b0# 使用debuginfo, perf_events可以为内核函数中的行创建跟踪点。# 必须安装 kernel-debuginfo 包，或者启用CONFIG_DEBUG_INFO=y# 8. 列出tcp_sendmsg()可用的行探测:$ perf probe -L tcp_sendmsg&lt;tcp_sendmsg@/mnt/src/linux-3.14.5/net/ipv4/tcp.c:0&gt; 0 int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg, size_t size) 2 &#123; struct iovec *iov; struct tcp_sock *tp = tcp_sk(sk); struct sk_buff *skb; 6 int iovlen, flags, err, copied = 0; 7 int mss_now = 0, size_goal, copied_syn = 0, offset = 0; bool sg; long timeo;[...]# 9. 检查在第81行有哪些变量可用$ perf probe -V tcp_sendmsg:81Available variables at tcp_sendmsg:81 @&lt;tcp_sendmsg+537&gt; bool sg int copied int copied_syn int flags int mss_now int offset int size_goal long int timeo size_t seglen struct iovec* iov struct sock* sk unsigned char* from# 10. 跟踪第81行，并使用循环中的seglen变量$ perf probe --add 'tcp_sendmsg:81 seglen'$ perf record -e probe:tcp_sendmsg -a$ perf script sshd 4652 [001] 2082360.931086: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x80 app_plugin.pl 2400 [001] 2082360.970489: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x20 postgres 2422 [000] 2082360.970703: probe:tcp_sendmsg: (ffffffff81642ca9) seglen=0x52[...] 跟踪 malloc 函数调用12345678# 1. 添加 malloc 探针$ perf probe -x /lib64/libc-2.17.so '--add=malloc'$ perf record -e probe_libc:malloc -a$ perf report -n# 2. 添加带 size 参数的 malloc 探针# size 保存的寄存器信息，依赖于你的处理器架构$ perf probe -x /lib64/libc-2.17.so '--add=malloc size=%di' malloc()调用非常频繁，因此需要考虑跟踪这样的调用的开销。 4. perf eBPF5. perf 特殊功能子命令说完了 perf 的三种基础使用方式，我们来看perf 提供特殊功能的子命令。 5.1 perf traceperf trace 类似于 strace 用于跟踪进程的系统调用，前面我们也提到了，相对于 strace 使用的 ptrace 机制来说，perf trace 基于内核事件，比进程跟踪的性能好很多。perf trace 还可以进行系统级的系统调用跟踪（即跟踪所有进程），而 strace 只能跟踪特定的进程。 1234567891011121314151617181920Usage: perf trace [&lt;options&gt;] [&lt;command&gt;] or: perf trace [&lt;options&gt;] -- &lt;command&gt; [&lt;options&gt;] or: perf trace record [&lt;options&gt;] [&lt;command&gt;] or: perf trace record [&lt;options&gt;] -- &lt;command&gt; [&lt;options&gt;] -a, --all-cpus system-wide collection from all CPUs -C, --cpu &lt;cpu&gt; list of cpus to monitor -D, --delay &lt;n&gt; ms to wait before starting measurement after program start -e, --event &lt;event&gt; event/syscall selector. use 'perf list' to list available events -f, --force don't complain, do it -F, --pf &lt;all|maj|min&gt; Trace pagefaults -G, --cgroup &lt;name&gt; monitor event in cgroup name only -i, --input &lt;file&gt; Analyze events in file -m, --mmap-pages &lt;pages&gt; number of mmap data pages -o, --output &lt;file&gt; output file name -p, --pid &lt;pid&gt; trace events on existing process id --sched show blocking scheduler events --syscalls Trace syscalls 下面是 perf trace 的使用示例:1$ perf trace --syscalls ls 5.1 perf topperf top [-e &lt;EVENT&gt; | --event=EVENT] [&lt;options&gt;] 作用: 可以动态收集和更新统计列表 options: -e: 指定跟踪的事件，包括 perf list提供的所有事件以及 tracepoint 可以多次使用，也可以一次指定多个事件，事件使用逗号分隔 对于厂家为上传的事件可以直接是用编号，eg: -e r0013 事件可以指定后缀，用于限定跟踪范围 -s: 指定按什么参数来进行分类 默认会按函数进行分类，按照 pid 分类需要指定 -s pid -s也可以指定多个域（用逗号隔开） 可选值包括: pid, comm, dso, symbol, parent, srcline, weight, local_weight, abort, in_tx, transaction, overhead, sample, period -a：显示在所有CPU上的性能统计信息 -p：指定进程PID -t：指定线程TID -K：隐藏内核统计信息 -U：隐藏用户空间的统计信息 -S, –symbols: Only consider these symbols -g, –call-graph: 得到函数的调用关系图 格式: &lt;print_type,threshold[,print_limit],order,sort_key[,branch],value&gt; print_type: flat: single column, linear exposure of call chains. graph: use a graph tree, displaying absolute overhead rates. (default) fractal: like graph, but displays relative rates. Each branch of the tree is considered as a new profiled object. folded: call chains are displayed in a line, separated by semicolons none: disable call chain display. 123456789# 1. -e 指定多个事件&gt; sudo perf top -e branch-misses,cycles# 2. 指定后缀，只跟踪用户态发生的分支预测失败&gt; sudo perf top -e branch-misses:u,cycles&gt; sudo perf top -e '&#123;branch-misses,cycles&#125;:u'# 3. 指定分类&gt; sudo perf top -e 'cycle' -s comm,pid,dso 5.2 perf schedperf sched子命令提供了许多用于分析内核CPU调度器行为的工具。您可以使用它来识别和量化调度器延迟的问题。 这个命令的开销很大。如果开销是一个问题，可以使用eBPF/bcc工具。其中runqlat和runqlen，只记录内核内的调度器事件摘要，进一步减少开销。perf sched转储所有事件的一个优点是不局限于摘要，对于分析问题而言可以获取更全面的信息。 12345678# perf sched -h Usage: perf sched [] &#123;record|latency|map|replay|script|timehist&#125; -D, --dump-raw-trace dump raw trace in ASCII -f, --force don't complain, do it -i, --input input file name -v, --verbose be more verbose (show symbol address, etc) perf sched 有{record|latency|map|replay|script|timehist}使用模式，我们来一一介绍。 perf sched recordperf sched latencyperf sched latency 将按任务统计调度程序延迟，包括平均延迟和最大延迟: 12345678# perf sched latency ----------------------------------------------------------------------------------------------------------------- Task | Runtime ms | Switches | Average delay ms | Maximum delay ms | Maximum delay at | ----------------------------------------------------------------------------------------------------------------- cat:(6) | 12.002 ms | 6 | avg: 17.541 ms | max: 29.702 ms | max at: 991962.948070 s ar:17043 | 3.191 ms | 1 | avg: 13.638 ms | max: 13.638 ms | max at: 991963.048070 s rm:(10) | 20.955 ms | 10 | avg: 11.212 ms | max: 19.598 ms | max at: 991963.404069 s perf sched mapperf sched map 显示所有CPU和上下文切换事件，其中的列表示每个CPU正在做什么以及何时做。 1234567# perf sched map *A0 991962.879971 secs A0 =&gt; perf:16999 A0 *B0 991962.880070 secs B0 =&gt; cc1:16863 *C0 A0 B0 991962.880070 secs C0 =&gt; :17023:17023 *D0 C0 A0 B0 991962.880078 secs D0 =&gt; ksoftirqd/0:6 D0 C0 *E0 A0 B0 991962.880081 secs E0 =&gt; ksoftirqd/3:28 D0 C0 *F0 A0 B0 991962.880093 secs F0 =&gt; :17022:17022 perf sched replayperf sched scriptperf sched timehist5.3 perf mem6. perf.data 处理6.1 perf diffperf diff [baseline file] [data file1] [[data file2] ... ] 作用: 比较两次运行的区别 场景: 可以用不同参数运行程序，看看两次运行的差别 6.2 perf scriptperf script [&lt;options&gt;] 作用: 对 perf.data 数据做格式转换 12345678910111213141516171819# 1. 导出原始分析数据&gt; perf record&gt; perf script # 导出 perf record 中记录的原始数据&gt; perf script | ./stackcollapse-perf.pl | ./flamegraph.pl &gt; perf-kernel.svg# List all perf.data events, with customized fields (&lt; Linux 4.1):perf script -f time,event,trace# List all perf.data events, with customized fields (&gt;= Linux 4.1):perf script -F time,event,trace# List all perf.data events, with my recommended fields (needs record -a; newer kernels):perf script --header -F comm,pid,tid,cpu,time,event,ip,sym,dso # List all perf.data events, with my recommended fields (needs record -a; older kernels):perf script -f comm,pid,tid,cpu,time,event,ip,sym,dso# Dump raw contents from perf.data as hex (for debugging):perf script -D 7. perf 数据可视化7.1 perf chartperf timechart输出的是进程运行过程中系统调度的情况，无法对程序的具体代码段进行性能分析，但可以看出总结运行情况：running，idle，I/O等， 12perf timechart record ./a.out # 记录数据perf timechart # 生成 output.svg 7.2 火焰图Brendangregg写了两款对perf采样结果进行可视化分析的开源工具： FlameGraphs即所谓的火焰图，能清晰的展示程序各个函数的性能消耗 HeatMap可以从采样数据中的延迟数据来进行消耗展示 123456# 生成火焰图git clone https://github.com/brendangregg/FlameGraph # or download it from githubcd FlameGraphperf record -F 99 -ag -- sleep 60perf script | ./stackcollapse-perf.pl &gt; out.perf-foldedcat out.perf-folded | ./flamegraph.pl &gt; perf-kernel.svg 参考 brendangregg-perf 在Linux下做性能分析3：perf]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.2 perf 的原理]]></title>
    <url>%2F2020%2F01%2F04%2Flinux_perf%2F04_perf%2F</url>
    <content type="text"><![CDATA[perf 感觉像是一个完全版的 top，可以帮助我们看到操作系统运行的全貌。perf 的使用非常复杂，本文只是一个入门，推荐大家去阅读大神 Brendangregg 的文章perf Examples。 1. perf 简介1.1 perf event perf 的使用依赖我们前面所说的 event(事件)。event 是不同内核工具框架的统一接口，上面的图片说明了 event 来源: Hardware Events: CPU性能监视计数器 PMCs Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点，即静态探针 User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 使用perf -FHz选项以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 list子命令列出当前可用的事件，使用动态跟踪时，就是在扩展下面这个列表。这个列表中的 probe:tcp_sendmsg 探针就是动态插入 tcp_sendmsg() 的示例。 123456789101112131415161718192021222324252627282930313233# perf listList of pre-defined events (to be used in -e): cpu-cycles OR cycles [Hardware event] instructions [Hardware event] cache-references [Hardware event] cache-misses [Hardware event] branch-instructions OR branches [Hardware event] branch-misses [Hardware event] bus-cycles [Hardware event] stalled-cycles-frontend OR idle-cycles-frontend [Hardware event] stalled-cycles-backend OR idle-cycles-backend [Hardware event] ref-cycles [Hardware event] cpu-clock [Software event] task-clock [Software event] page-faults OR faults [Software event] L1-dcache-loads [Hardware cache event] L1-dcache-load-misses [Hardware cache event] L1-dcache-stores [Hardware cache event][...] rNNN [Raw hardware event descriptor] cpu/t1=v1[,t2=v2,t3 ...]/modifier [Raw hardware event descriptor] (see 'man perf-list' on how to encode it) mem:&lt;addr&gt;[:access] [Hardware breakpoint] probe:tcp_sendmsg [Tracepoint event][...] sched:sched_process_exec [Tracepoint event] sched:sched_process_fork [Tracepoint event] sched:sched_process_wait [Tracepoint event] sched:sched_wait_task [Tracepoint event] sched:sched_process_exit [Tracepoint event][...]# perf list | wc -l 657 采样事件perf -FHz 是这样的：perf 每隔一个固定的时间，就在CPU上（每个核上都有）产生一个中断，在中断上看看，当前是哪个pid，哪个函数，然后给对应的pid和函数加一个统计值，这样，我们就知道CPU有百分几的时间在某个pid，或者某个函数上了。 这种方式可以推广到各种事件，此时使用的不再是 -FHz 指定的频率，而是 -e 参数指定的各种 event。当指定的事件发生的时候，perf 就会上来冒个头，看看击中了谁，然后算出分布，我们就知道谁会引发特别多的那个事件了。 所以本质上 perf 属于一种抽样统计。既然是抽样统计我们就要警惕抽样带来的抽样误差。每次看perf report的报告，首先要去注意一下总共收集了多少个点，如果你只有几十个点，你这个报告就可能很不可信了。 1.2 perf 事件说明软件事件perf提供了少量固定的软件事件，这些也记录在手册页perf_event_open(2) 中。软件事件可能有一个默认的周期。这意味着当使用它们进行抽样时，是在对事件的子集进行抽样，而不是跟踪每个事件。你可以通过 perf record -vv 查看: 12345678910111213141516# perf record -vv -e context-switches /bin/trueUsing CPUID GenuineIntel-6-55------------------------------------------------------------perf_event_attr: type 1 size 112 config 0x3 &#123; sample_period, sample_freq &#125; 4000 sample_type IP|TID|TIME|PERIOD disabled 1 inherit 1 mmap 1 comm 1 freq 1 enable_on_exec 1[...] 有关这些字段的描述，请参见perf_event_open(2)手册页。这个默认的意思是内核调整采样率，以便它每秒捕获大约4000个上下文切换事件。如果你真的想把它们全部记录下来，请使用-c1: 1234567891011121314# perf record -vv -e context-switches -c 1 /bin/trueUsing CPUID GenuineIntel-6-55------------------------------------------------------------perf_event_attr: type 1 size 112 config 0x3 &#123; sample_period, sample_freq &#125; 1 sample_type IP|TID|TIME disabled 1 inherit 1 mmap 1 comm 1 enable_on_exec 1 首先使用perf stat检查事件的速率，这样您就可以估计将要捕获的数据量。在默认情况下对子集进行采样可能是一件好事，特别是对于上下文切换这样的高频率事件。许多其他事件(比如跟踪点)的默认值都是1。对于许多软件和硬件事件，您将遇到非1的缺省值。 其他事件参见前文”Linux 性能调优概览”中的说明 1.3 perf 使用注意事项idle 进程现代CPU基本上已经不用忙等的方式进入等待了，所以，如果CPU在idle，击中任务也会停止，所以，在Idle上是没有点的。看到Idle函数本身的点并非CPU Idle的点，而是准备进入Idle前后花的时间。所以，perf的统计不能用来让你分析CPU占用率的。ftrace和top等工具才能看CPU占用率，perf是不行的。 中断perf还有一个问题是对中断的要求，perf很多事件都依赖中断，但Linux内核是可以关中断的，关中断以后，你就无法击中关中断的点了，你的中断会被延迟到开中断的时候，所以，在这样的平台上，你会看到很多开中断之后的函数被密集击中。但它们是无辜的。但更糟糕的是，如果在关中断的时候，发生了多个事件，由于中断控制器会合并相同的中断，你就会失去多次事件，让你的统计发生错误。 现代的Intel平台，基本上已经把PMU中断都切换为NMI中断了（不可屏蔽），所以前面这个问题不存在。但在大部分ARM/ARM64平台上，这个问题都没有解决，所以看这种平台的报告，都要特别小心，特别是你看到_raw_spin_unlock()一类的函数击中极高，你就要怀疑一下你的测试结果了（注意，这个结果也是能用的，只是看你怎么用）。 2.perf 使用2.1 安装perf的源代码就是Linux的源代码目录中，因为它在相当程度上和内核是关联的。一般Linux 的各种发行版本都会安装好与内核相对应的 perf 命令。perf 有两种安装方式 通过包管理进行安装，perf工具在 linux-tools-common工具包里，通过包管理软件安装的时候还需要依赖linux-tools-kernelversion包 源码编译：找到对应内核版本的源码包，在tools/perf目录下进行编译 2.2 使用前提符号表与其他调试工具一样，perf_events需要符号信息(符号)。它们被用来将内存地址转换成函数和变量名，以便我们人类能够读取它们。如果没有符号，您将看到十六进制数字表示所分析的内存地址。 类似于 Java Node 这些使用虚拟机编写的程序，使用虚拟机自行管理执行函数和管理堆栈，perf 只能查看到虚拟机级别堆栈，是无法解析语言本身的上下文的。使用 perf 分析java，node 等语言需要需要语言的JIT 提供支持。下面是一些常见语言如何支持 perf 的参考链接: java perf-map-agent Java in flame Java火焰图部分 Java Performance Analysis on Linux with Flame Graphs. node: Node.js火焰图在Linux上的步骤 通常软件包的符号表通过类似 -dbgsym 命令符号的调试包提供。libc6-dbgsym和coreutils-dbgsym 可以提供用户级 OS 代码页的一些符号表。实在不行只能自己编译软件，保留符号表。 123456# 安装内核符号表yum search debuginfo|grep kernelyum install kernel-debuginfo# 安装应用程序符号表，如果其提供了调试的 yum 包debuginfo-install bash 省略帧指针优化问题省略帧指针是编译器默认的优化选项，使得 perf 无法看到完整的堆栈。 有下面几种方法可以解决这个问题: 使用dwarf数据展开堆栈: 从3.9内核开始，perf_events 支持用户级栈中缺少帧指针的解决方案:libunwind，叫做 dwarf 使用”–call-graph dwarf”(或“-g dwarf”)启用此功能 perf 可以在没有 dwarf 支持的情况下构建。因此是否支持 dwarf 要查阅安装信息 使用可用的最后一个分支记录(LBR)(如果处理器特性支持) LBR，全称是 Last Branch Record，需要处理器支持，通常在云环境中都是禁用的 LBR通常限制了堆栈深度(8、16或32帧)，所以它可能不适合深度堆栈或火焰图生成 返回帧指针 还有其他堆栈遍历技术，比如BTS(分支跟踪存储)和新的ORC解卷器 内核也有类似省略帧指针的问题。启动 CONFIG_FRAME_POINTER=y 内核选项可以避免此问题。 堆栈追踪深度问题使用堆栈跟踪要注意的是: 堆栈跟踪受扫描深度的限制，太深的堆栈可能回溯不过去，这是有可能影响结果的。 有些我们从源代码看来是函数调用的，其实在汇编一级并不是函数调用 比如inline函数，宏，都不是函数调用 另外，gcc在很多平台中，会自动把很短的函数变成inline函数，这也不产生函数调用 还有一种是，fastcall函数，通过寄存器传递参数，不会产生调用栈，也有可能不产生调用栈 部分平台使用简化的堆栈回溯机制，在堆栈中看见一个地址像是代码段的地址，就认为是调用栈 2.3 perf 的运行方式perf_events有三种使用方式: 计数模式: 对应 perf stat 命令，对内核上下文中的事件进行计数，并输出统计的摘要信息 此模式不生成perf.data文件 开销最小 采样事件： 通过采样的方式，将事件数据写入内核缓冲区； 然后以异步的方式，将内核缓冲区的内容写入 perf.data 文件 perf report 或 perf script 命令读取 perf.data 并输出结果 开销取决于正在跟踪的事件的频率 事件上的bpf程序: 这是Linux 4.4+内核中的一个新特性，它可以在内核空间中执行自定义用户定义的程序，可以执行高效的数据筛选和总结。 bpf 是先筛选在写入内核缓冲区，相比于采样事件模式高效的多 下面是 perf 三种使用方式的一些示例，我们会在后面详细 perf 的使用。 1234567891011121314151617181920212223242526# gzip命令的性能计数器总结，包括IPC:perf stat gzip largefile# 按照静态探针对进程调度事件进行计数，持续 5sperf stat -e 'sched:sched_process_*' -a sleep 5# 按照静态探针跟踪进程调度事件，持续 5sperf record -e 'sched:sched_process_*' -a sleep 5perf report# 按照静态探针跟踪进程调度事件，持续 5s，并转储事件信息信息perf record -e 'sched:sched_process_*' -a sleep 5perf script# 跟踪请求的字节小于10 的 read() 系统调用perf record -e 'syscalls:sys_enter_read' --filter 'count &lt; 10' -a# 以 99hz 的频率抽样CPU堆栈perf record -F 99 -ag -- sleep 5perf report# 添加 tcp_sendmsg 动态探针，追踪 5s，并记录堆栈perf probe --add tcp_sendmsgperf record -e probe:tcp_sendmsg -ag -- sleep 5perf probe --del tcp_sendmsgperf report 2.3 perf 命令概览除此上面介绍的三种使用方式之外， perf 还有许多子命令提供特殊用途的功能。这些子命令都是在 perf 三种检测功能的基础上，记录特定的事件并以定制的方式报告，包括: perf c2c (Linux 4.10+): cache-2-cache and cacheline false 共享分析 perf kmem: 内核内存分配分析。 perf kvm：KVM虚拟客户端分析。 perf lock: 锁分析 perf mem: 内存访问分析。 perf sched: 内核调度器的统计数据 下面是 perf 子命令的一个完整列表。 perf [--version] [--help] [OPTIONS] COMMAND [ARGS] 子命令 作用 list List all symbolic event types列出当前系统支持的所有事件名,可分为三类：硬件事件、软件事件，检查点 stat Run a command and gather performance counter statistics对程序运行过程中的性能计数器进行统计 top System profiling tool.对系统的性能进行分析，类似top命令 record Run a command and record its profile into perf.data 对程序运行过程中的事件进行分析和记录，并写入perf.data report Read perf.data (created by perf record) and display the profile读取perf.data(由perf record生成) 并显示分析结果 sched Tool to trace/measure scheduler properties (latencies)针对调度器子系统的分析工具 lock Analyze lock events分析内核中的锁信息，包括锁的争用情况，等待延迟等 mem Profile memory accesses分析内存访问 kmem Tool to trace/measure kernel memory properties分析内核内存的使用 kvm Tool to trace/measure kvm guest os分析kvm虚拟机上的guest os timechart Tool to visualize total system behavior during a workload对record结果进行可视化分析输出，record命令需要加上timechart记录 script Read perf.data (created by perf record) and display trace output读取perf.data(由perf record生成)，生成trace记录，供其他分析工具使用 data Data file related processing把perf.data文件转换成其他格式 diff Read perf.data files and display the differential profile读取多个perf.data文件，并给出差异分析 evlist List the event names in a perf.data file列出perf.data中采集的事件列表 bench General framework for benchmark suitesperf提供的基准套件的通用框架，可以对当前系统的调度，IPC，内存访问进行性能评估 test Runs sanity tests. perf对当前软硬件平台进行健全性测试，可用此工具测试当前的软硬件平台是否能支持perf的所有功能 probe Define new dynamic tracepoints用于定义动态检查点 trace strace inspired tool类似于strace，跟踪目标的系统调用，但开销比strace小 ftrace simple wrapper for kernel ftrace functionality annotate Read perf.data (created by perf record) and display annotated code读取perf.data(由perf record生成)显示反汇编后的代码 archive Create archive with object files with build-ids found in perf.data file根据perf.data(由perf record生成)文件中的build-id将相关的目标文件打包 buildid-cache Manage build-id cache. buildid-list List the buildids in a perf.data file c2c Shared Data C2C/HITM Analyzer. config Get and set variables in a configuration file. inject Filter to augment the events stream with additional information kallsyms Searches running kernel for symbols version display the version of perf binary 2.4 perf 一些重要的选项参数perf 有一些重要的选项参数包括: -g/--child/--cal-graph 下面我们来一一讲解 -gperf record 和 perf report 都有 -g 选项。perf record 中 -g 用于启用堆栈追踪。perf report 中 -g/--call-graph 用于指定堆栈的显示方式，这是我们讲解的重点。 -g/--call-graph 参数格式为 &lt;print_type,threshold[,print_limit],order,sort_key[,branch],value&gt; print_type: 指定堆栈调用图的显示方式 可选值包括 (graph|flat|fractal|folded|none) 默认值为 graph 表示以调用关系图的方式显示堆栈，通常无须更改 threshold: 一个百分比值，当函数调用所占用的CPU小于这个百分比值的时候，不显示堆栈信息 默认值为 0.5(表示的是百分之0.5) print_limit: 调用关系图显示的最大行数，可不指定 order: 调用关系图的显示方式，可选值包括 (caller|callee) caller: 默认值，表示基于调用者的调用图 callee: caller 的反转，基于被调用者的调用图，也可以使用 -G 或者 --children sort_key: 调用关系图的排序键，可选值包括(function|address)，通常无须更改 branch: include last branch info to call graph (branch) 可不指定 value: call graph value (percent|period|count) 调用关系图中显示什么，CPU占用百分比，CPU周期数，还是调用总次数 默认为 percent，同行无须更改 默认值为: graph,0.5,caller,function,percent 这之中最难理解的是 order。我们看下面这个例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# perf report --stdio# ========# captured on: Mon Jan 26 07:26:40 2014# hostname : dev2# os release : 3.8.6-ubuntu-12-opt# perf version : 3.8.6# arch : x86_64# nrcpus online : 8# nrcpus avail : 8# cpudesc : Intel(R) Xeon(R) CPU X5675 @ 3.07GHz# cpuid : GenuineIntel,6,44,2# total memory : 8182008 kB# cmdline : /usr/bin/perf record -F 99 -a -g -- sleep 30 # event : name = cpu-clock, type = 1, config = 0x0, config1 = 0x0, config2 = ...# HEADER_CPU_TOPOLOGY info available, use -I to display# HEADER_NUMA_TOPOLOGY info available, use -I to display# pmu mappings: software = 1, breakpoint = 5# ========## Samples: 22K of event 'cpu-clock'# Event count (approx.): 22751## Overhead Command Shared Object Symbol# ........ ....... ................. ...............................# 94.12% dd [kernel.kallsyms] [k] _raw_spin_unlock_irqrestore | --- _raw_spin_unlock_irqrestore | |--96.67%-- extract_buf | extract_entropy_user | urandom_read | vfs_read | sys_read | system_call_fastpath | read | |--1.69%-- account | | | |--99.72%-- extract_entropy_user | | urandom_read | | vfs_read | | sys_read | | system_call_fastpath | | read | --0.28%-- [...] | |--1.60%-- mix_pool_bytes.constprop.17[...] 默认情况下 perf report 使用 caller 即显示基于调用者的调用图。 最顶端显示的是最终被调用的子函数。从上往下是调用它的父函数。 其中最热(最频繁)的堆栈跟踪发生频率是 90.99%(extract_buf 部分)，它是Overhead列的百分比和顶部堆栈叶(94.12% x 96.67%)的乘积。 96.67% 表示的是调用 _raw_spin_unlock_irqrestore 函数的相对百分比，即_raw_spin_unlock_irqrestore的调用次数中，extract_buf 占了 96.67%。 Overhead 列显示的是这个进程的CPU占用百分比 通过使用-G， -g caller 或者 –children 来反转调用关系图 说明: 在我的Linux 上 perf 默认是按照绝对百分显示的 CPU 调用，即extract_buf 显示的是90.99%，不是 96.67%。 -s-s 用于在 perf record 中指定调用关系图的排序字段。可选值包括: overhead: 默认值，Overhead percentage of sample，抽样占比 overhead_sys: Overhead percentage of sample running in system mode overhead_us: Overhead percentage of sample running in user mode comm: command (name) of the task which can be read via /proc//comm pid: command and tid of the task socket: processor socket number the task ran at the time of sample …. -F-F 用于指定 perf report 中显示的字段，可选值与 -s 类似。 下面是一个跟踪进程创建的例子，使用-n来打印“Samples”列，使用--sort comm来定制其余的列。1234567891011121314151617# perf record -e sched:sched_process_exec -a^C[ perf record: Woken up 1 times to write data ][ perf record: Captured and wrote 0.064 MB perf.data (~2788 samples) ]# perf report -n --sort comm --stdio[...]# Overhead Samples Command# ........ ............ .......# 11.11% 1 troff 11.11% 1 tbl 11.11% 1 preconv 11.11% 1 pager 11.11% 1 nroff 11.11% 1 man 11.11% 1 locale 11.11% 1 grotty 11.11% 1 groff –filter在使用 perf record 进行追踪时，可以通过 –filter 选项对堆栈进行过滤，只记录满足条件的堆栈信息。 12]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2.1 ftrace 的原理与使用]]></title>
    <url>%2F2020%2F01%2F03%2Flinux_perf%2F03_ftrace%2F</url>
    <content type="text"><![CDATA[最早 ftrace 是一个 function tracer，仅能够记录内核的函数调用流程。如今 ftrace 已经成为一个 framework，采用 plugin 的方式支持开发人员添加更多种类的 trace 功能。 1. ftrace 简介Ftrace 最初是在 2.6.27 中出现，那时 systemTap 已经开始崭露头角，其他的 trace 工具包括 LTTng 等也已经发展多年。那为什么人们还要再开发一个 trace 工具呢？ SystemTap 目标是达到甚至超越 Dtrace 。因此 SystemTap 设计比较复杂，在真正的产品环境，人们依然无法放心的使用她。不当的使用和 SystemTap 自身的不完善都有可能导致系统崩溃。 Ftrace 的设计目标简单，本质上是一种静态代码插装技术，不需要支持某种编程接口让用户自定义 trace 行为。静态代码插装技术更加可靠，不会因为用户的不当使用而导致内核崩溃。 ftrace 代码量很小，稳定可靠。实际上，即使是 Dtrace，大多数用户也只使用其静态 trace 功能。因此 ftrace 的设计非常务实。 ftrace一个比较明显的缺点是没有用户态的跟踪点支持。perf-tools 对Ftrace的功能进行了很好的封装和集成，建议大家用perf-tools来使用Ftrace，则效果更佳更简单。后面会介绍 perf-tools 的使用，在此之前我们先来看看怎么使用 ftrace。 2. ftrace 原理Ftrace 有两大组成部分: 一是 framework 二是一系列的 tracer， 每个 tracer 完成不同的功能，它们统一由 framework 管理 ftrace 的 trace 信息保存在 ring buffer(内存缓冲区) 中，由 framework 负责管理 ftrace有两种主要跟踪机制可以往缓冲区中写数据 一是函数: 即动态探针，可以跟踪内核函数的调用栈，包括 function tracer，function graph tracer 两个 tracer 二是事件: 即静态探针，包括其他大多数的 tracer Framework 利用 debugfs 系统在 /debugfs 下建立 tracing 目录，对用户空间输出 trace 信息，并提供了一系列的控制文件 ftrace的目录设置和sysfs类似，都是把目录当作对象，把里面的文件当作这个对象的属性。debugfs/tracing 目录可以理解成一个独立的监控实例 instance，在 tracing 目录或者子目录创建任何目录相当于创建了一个新的 ftrace 实例，ftrace 会为这个 ftrace 实例自动创建 ring buffer 内存缓冲区，并在这个目录下创建 ftrace 实例所需的与 tracing 目录完全相同的文件。 debugfs在大部分发行版中都mount在/sys/kernel/debug目录下，而ftrace就在这个目录下的tracing目录中。如果系统没有mount这个文件系统，可以手动 mount。 123456789101112# 1. 重新挂在 debugfs mount -t debugfs none /debugs# 2. debugfs/tracing 目录ll /debugs/tracing# 3. 创建新的 ftrace trace 实例mkdir /debugs/tracing/instance/python# ftrace 会创建新的内存缓冲区并生成 ftrace 相关文件ll tracing/instances/python/ 3. ftrace 控制机制在讲解 ftrace 的 tracer 之前，我们先来看看 tracing 目录下的文件，它们提供了对 ftrace trace 过程的控制。 12345678910lsavailable_events free_buffer printk_formats snapshot trace_statavailable_filter_functions function_profile_enabled README stack_max_size tracing_cpumaskavailable_tracers hwlat_detector saved_cmdlines stack_trace tracing_max_latencybuffer_size_kb instances saved_cmdlines_size stack_trace_filter tracing_onbuffer_total_size_kb kprobe_events set_event trace tracing_threshcurrent_tracer kprobe_profile set_ftrace_filter trace_clock uprobe_eventsdyn_ftrace_total_info max_graph_depth set_ftrace_notrace trace_marker uprobe_profileenabled_functions options set_ftrace_pid trace_optionsevents per_cpu set_graph_function trace_pipe tracing 目录下的文件分成了下面四类: 提示类：显示当前系统可用的event，tracer 列表 控制类：控制 ftrace 的跟踪参数 显示类：显示 trace 信息 辅助类：一些不明或者不重要的辅助信息 提示类 ftrace 文件 作用 available_events 可用事件列表，也可查看 events/ 目录 available_filter_functions 当前内核导出的可以跟踪的函数 dyn_ftrace_total_info 显示available_filter_functins中跟中函数的数目 available_tracers 可用的 tracer，不同的 tracer 有不同的功能 events 1. 查看可用事件列表以及事件参数(事件包含的内核上下文信息)cat events/sched/sched_switch/format2.设置事件的过滤条件echo ‘next_comm ~ “cs”‘ &gt; events/sched/sched_switch/filter 控制类 适用 tracer ftrace 文件 作用 通用 tracing_on 用于控制跟踪打开或停止，0停止跟踪，1继续跟踪 通用 tracing_cpumask 设置允许跟踪特定CPU 通用 tracing_max_latency 记录Tracer的最大延时 通用 tracing_thresh 延时记录Trace的阈值，当延时超过此值时才开始记录Trace。单位是ms，只有非0才起作用 通用 events 1. 查看可用事件列表以及事件参数(事件包含的内核上下文信息)cat events/sched/sched_switch/format2.设置事件的过滤条件echo ‘next_comm ~ “cs”‘ &gt; events/sched/sched_switch/filter 通用 set_event 设置跟踪的 event 事件，与通过events目录内的 filter 文件设置一致 通用 current_tracer 1. 设置或者显示当前使用的跟踪器列表2. 系统缺省为nop，可以通过写入nop重置跟踪器3. 使用echo将跟踪器名字写入即可打开echo function_graph &gt; current_tracer 通用 buffer_size_kb 设置单个CPU所使用的跟踪缓存的大小如果跟踪太多，旧的信息会被新的跟踪信息覆盖掉不想被覆盖需要先将current_trace设置为nop才可以 通用 buffer_total_size_kb 显示所有CPU ring buffer 大小之和 通用 trace_options trace 过程的复杂控制选项控制Trace打印内容或者操作跟踪器也可通过 options/目录设置 通用 options/ 显示 trace_option 的设置结果也可以直接设置，作用同 trace_options func function_profile_enabled 打开此选项，trace_stat就会显示function的统计信息echo 0/1 &gt; function_profile_enabled func set_ftrace_pid 设置跟踪的pid func set_ftrace_filter 用于显示指定要跟踪的函数 func set_ftrace_notrace 用于指定不跟踪的函数，缺省为空 graph max_graph_depth 函数嵌套的最大深度 graph set_graph_function 设置要清晰显示调用关系的函数缺省对所有函数都生成调用关系 Stack stack_max_size 当使用stack跟踪器时，记录产生过的最大stack size Stack stack_trace 显示stack的back trace Stack stack_trace_filter 设置stack tracer不检查的函数名称 输出类 ftrace 文件 作用 printk_formats 提供给工具读取原始格式trace的文件 trace 查看 ring buffer 内跟踪信息echo &gt; trace可以清空当前RingBuffer trace_pipe 输出和trace一样的内容，但输出Trace同时将RingBuffer清空可避免RingBuffer的溢出保存文件内容: cat trace_pipe &gt; trace.txt &amp; snapshot 是对trace的snapshotecho 0清空缓存，并释放对应内存echo 1进行对当前trace进行snapshot，如没有内存则分配echo 2清空缓存，不释放也不分配内存 trace_clock 显示当前Trace的timestamp所基于的时钟，默认使用local时钟local：默认时钟；可能无法在不同CPU间同步global：不同CUP间同步，但是可能比local慢counter：跨CPU计数器，需要分析不同CPU间event顺序比较有效 trace_marker 从用户空间写入标记到trace中，用于用户空间行为和内核时间同步 trace_stat 每个CPU的Trace统计信息 per_cpu/ trace等文件的输出是综合所有CPU的，如果你关心单个CPU可以进入per_cpu目录，里面有这些文件的分CPU版本 enabled_functions 显示有回调附着的函数名称 saved_cmdlines 放pid对应的comm名称作为ftrace的cache，这样ftrace中不光能显示pid还能显示comm saved_cmdlines_size saved_cmdlines的数目 trace、trace_pipe和snapshot的区别: trace是从RingBuffer中取出内容 trace_pipe会一直读取Buffer流。 snapshot是trace的一个瞬间快照： 辅助类 ftrace 文件 作用 free_buffer 此文件用于在一个进程被关闭后，同时释放RingBuffer内存，并将调整大小到最小值 instances 空目录，可在此目录创建新的 ftrace 实例 hwlat_detector kprobe_events kprobe_profile uprobe_events uprobe_profile 4. ftrace tracer下面是 ftrace tracer 的不完全列表，每一个 tracer 输出的内容和格式都不一样，对于我们比较常用的是 Function，Graph，Schedule switch，softirq。 ftrace 作用 Function 跟踪函数调用 Function graph tracer 跟踪函数调用，显示调用关系 Schedule switch 跟踪进程调度情况 Wakeup 跟踪进程的调度延迟，即高优先级进程从进入 ready 状态到获得 CPU 的延迟时间。该 tracer 只针对实时进程 Irqsoff 当中断被禁止时，系统无法相应外部事件，比如键盘和鼠标，时钟也无法产生 tick 中断。这意味着系统响应延迟，irqsoff 这个 tracer 能够跟踪并记录内核中哪些函数禁止了中断，对于其中中断禁止时间最长的，irqsoff 将在 log 文件的第一行标示出来，从而使开发人员可以迅速定位造成响应延迟的罪魁祸首 Preemptoff 和前一个 tracer 类似，preemptoff tracer 跟踪并记录禁止内核抢占的函数，并清晰地显示出禁止抢占时间最长的内核函数 Preemptirqsoff 同上，跟踪和记录禁止中断或者禁止抢占的内核函数，以及禁止时间最长的函数 Branch 跟踪内核程序中的 likely/unlikely 分支预测命中率情况。 Branch tracer 能够记录这些分支语句有多少次预测成功。从而为优化程序提供线索 Hardware branch 利用处理器的分支跟踪能力，实现硬件级别的指令跳转记录。在 x86 上，主要利用了 BTS 这个特性 Initcall 记录系统在 boot 阶段所调用的 init call Mmiotrace 记录 memory map IO 的相关信息 Power 记录系统电源管理相关的信息 Sysprof 缺省情况下，sysprof tracer 每隔 1 msec 对内核进行一次采样，记录函数调用和堆栈信息 Kernel memory 内存 tracer 主要用来跟踪 slab allocator 的分配情况。包括 kfree，kmem_cache_alloc 等 API 的调用情况，用户程序可以根据 tracer 收集到的信息分析内部碎片情况，找出内存分配最频繁的代码片断，等等 Workqueue statistical 这是一个 statistic tracer，统计系统中所有的 workqueue 的工作情况，比如有多少个 work 被插入 workqueue，多少个已经被执行等。开发人员可以以此来决定具体的 workqueue 实现，比如是使用 single threaded workqueue 还是 per cpu workqueue Event 跟踪系统事件，比如 timer，系统调用，中断等 5. ftrace 的实战5.1 跟踪进程调度示例一我们来看看如何跟踪 Python 进程执行过程发生的进程调度: 123456789101112131415161718192021# 1. 假设我们要跟踪一个 Python 文件执行中的进程调度&gt; vim run.pywith open("./content.csv") as bf: print(bf.readlines())# 2. 将 ftrace 的选项写入脚本中&gt; vim ftrace.shpy=/home/tao/debugs/tracing/mkdir -pv $pyecho nop &gt; $py/current_tracerecho 0 &gt; $py/tracing_onecho $$ &gt; $py/set_ftrace_pidecho "sched:*" &gt; $py/set_event#replace test_proc_show by your function name#echo test_proc_show &gt; $py/set_graph_functionecho 1 &gt; $py/tracing_onexec "$@"# 3.启动跟踪并查看结果&gt; bash ftrace.sh python ftrace.py &amp;&amp; echo 0 &gt; /home/tao/debugs/tracing/tracing_on&gt; vim /home/tao/debugs/tracing/trace 5.2 跟踪系统调用示例2 我们来看看如何跟踪系统调用。以 ls 命令为例，显示 do_sys_open 调用栈。 12345678910111213141516171819202122232425262728293031323334353637383940414243# 这次使用系统默认挂载的 debugfs$ cd /sys/kernel/debug/tracing/# 1. 设置要显示调用栈的函数$ echo do_sys_open &gt; set_graph_function # 2. 配置跟踪选项，开启函数调用跟踪，并跟踪调用进程$ echo function_graph &gt; current_tracer$ echo funcgraph-proc &gt; trace_options# 3. 开启追踪$ echo 1 &gt; tracing_on# 4. 执行一个 ls 命令后，再关闭跟踪：$ ls$ echo 0 &gt; tracing_on# 5.查看追踪结果$ cat trace# tracer: function_graph## CPU TASK/PID DURATION FUNCTION CALLS# | | | | | | | | | 0) ls-12276 | | do_sys_open() &#123; 0) ls-12276 | | getname() &#123; 0) ls-12276 | | getname_flags() &#123; 0) ls-12276 | | kmem_cache_alloc() &#123; 0) ls-12276 | | _cond_resched() &#123; 0) ls-12276 | 0.049 us | rcu_all_qs(); 0) ls-12276 | 0.791 us | &#125; 0) ls-12276 | 0.041 us | should_failslab(); 0) ls-12276 | 0.040 us | prefetch_freepointer(); 0) ls-12276 | 0.039 us | memcg_kmem_put_cache(); 0) ls-12276 | 2.895 us | &#125; 0) ls-12276 | | __check_object_size() &#123; 0) ls-12276 | 0.067 us | __virt_addr_valid(); 0) ls-12276 | 0.044 us | __check_heap_object(); 0) ls-12276 | 0.039 us | check_stack_object(); 0) ls-12276 | 1.570 us | &#125; 0) ls-12276 | 5.790 us | &#125; 0) ls-12276 | 6.325 us | &#125;... 输出: 第三列是函数执行延迟；最后一列，则是函数调用关系图。 6. trace-cmdtrace-cmd 可以把上面这些步骤给包装起来，通过同一个命令行工具，就可完成上述所有过程。下面是示例2 中跟踪 do_sys_open 的 trace-cmd 版本。 123456789101112131415161718192021222324252627# 1. 安装$ yum install trace-cmd# 2. 启动追踪$ trace-cmd record -p function_graph -g do_sys_open -O funcgraph-proc ls# 3. 查看追踪结果$ trace-cmd report... ls-12418 [000] 85558.075341: funcgraph_entry: | do_sys_open() &#123; ls-12418 [000] 85558.075363: funcgraph_entry: | getname() &#123; ls-12418 [000] 85558.075364: funcgraph_entry: | getname_flags() &#123; ls-12418 [000] 85558.075364: funcgraph_entry: | kmem_cache_alloc() &#123; ls-12418 [000] 85558.075365: funcgraph_entry: | _cond_resched() &#123; ls-12418 [000] 85558.075365: funcgraph_entry: 0.074 us | rcu_all_qs(); ls-12418 [000] 85558.075366: funcgraph_exit: 1.143 us | &#125; ls-12418 [000] 85558.075366: funcgraph_entry: 0.064 us | should_failslab(); ls-12418 [000] 85558.075367: funcgraph_entry: 0.075 us | prefetch_freepointer(); ls-12418 [000] 85558.075368: funcgraph_entry: 0.085 us | memcg_kmem_put_cache(); ls-12418 [000] 85558.075369: funcgraph_exit: 4.447 us | &#125; ls-12418 [000] 85558.075369: funcgraph_entry: | __check_object_size() &#123; ls-12418 [000] 85558.075370: funcgraph_entry: 0.132 us | __virt_addr_valid(); ls-12418 [000] 85558.075370: funcgraph_entry: 0.093 us | __check_heap_object(); ls-12418 [000] 85558.075371: funcgraph_entry: 0.059 us | check_stack_object(); ls-12418 [000] 85558.075372: funcgraph_exit: 2.323 us | &#125; ls-12418 [000] 85558.075372: funcgraph_exit: 8.411 us | &#125; ls-12418 [000] 85558.075373: funcgraph_exit: 9.195 us | &#125;... 参考 ftrace 简介 在Linux下做性能分析2：ftrace Linux ftrace框架介绍及运用 宋宝华：关于Ftrace的一个完整案例]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.2 Linux 性能调优概览]]></title>
    <url>%2F2020%2F01%2F02%2Flinux_perf%2F02_Linux%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[为了调试和追踪程序的运行过程，Linux 提供了众多的分析工具，本节我们先对它们做一个宏观概览。 1. 我们到底要优化什么在我们了解接下来的各种工具之前，我们首先应该问自己，我们要追踪或者说我们要优化什么。我们都知道程序的运行会占用包括 CPU，内存，文件描述符，锁，磁盘，网络等等在内的各种操作系统资源。根据2/8定律，当其中的某一个或多个资源出现瓶颈的时候，我们需要找到程序中耗费资源最大的地方，并对其优化。 那么我们可能需要做如下这些事情: 对系统资源持续进行观测以及时发现哪些资源出现了瓶颈 统计各个程序(进程)，确定哪个或哪些进程占用了过多的资源 分析问题进程，找出其占用过量资源的原因。 所谓追踪技术本质上就是获取操作系统记录中程序运行的各种信息，所以尽管工具多种多样，但本质上都是查询操作系统”数据”的工具。在了解这些工具之前，我们非常有必要先去看看操作系统都提供了哪些数据查询接口，即操作系统提供给我们的观测来源。 2. 观测源Linux 中的观测源被称为 event ，它是不同内核工具框架的统一接口，上面的图片说明了 event 来源: Hardware Events: CPU性能监视计数器 PMCs Software Events: 这些是基于内核计数器的低级事件。例如，CPU迁移、主次缺页异常等等。 Kernel Tracepoint Events: 硬编码在内核中的静态内核级的检测点，即静态探针 User Statically-Defined Tracing (USDT): 这些是用户级程序和应用程序的静态跟踪点。 Dynamic Tracing: 可以被放置在任何地方的动态探针。对于内核软件，它使用kprobes框架。对于用户级软件，uprobes。 Timed Profiling: 以指定频率收集的快照。这通常用于CPU使用情况分析，其工作原理是周期性的产生时钟中断事件。 内核维护了部分事件的计数器，通过 /proc 和 /sys 文件系统对外输出。 /proc 是一个提供内核统计信息的文件系统接口，将内核和进程的统计数据用目录树的形式暴露给用户空间。 /sys 最初设计用于提供设备驱动的统计信息，不过现在已经扩展到了提供所有信息的统计，/sys 同时也是调整内核参数的入口。 我们也可以各种分析工具，使用抽样的方式收集这些事件发生时内核的上下文信息。 2.1 PMCsPMCs 又称 PMU 全称为硬件计数器，也叫做性能监视计数器(pmmc)或性能仪表计数器(PICs)。它监测低层次的处理器活动，例如，CPU周期，指令退役，内存失速周期，二级缓存丢失，等等。其中一些将作为硬件缓存事件列出。 PMU计数器大部分CPU都有的功能。它可以在这些计数器的计数超过一个特定的值的时候产生一个中断，这个中断，我们可以用和时钟一样的方法，来抽样判断系统中哪个函数发生了最多的Cache失效，分支预测失效等。 典型的处理器将以以下方式实现pmc:在可用的数千个pmc中，只能同时记录几个pmc。这是因为它们是处理器上的固定硬件资源(寄存器的有限数量)，并且被编程为开始计算所选事件。 2.2 Software Events除了 PMU 外，内核也维护了各种统计数据，称为计数器，包括 CPU migrations(处理器迁移次数), minor faults(soft page faults), major faults(hard page faults) 等等。这些数据一般都通过 /proc 文件系统对外输出。 如果开启了Linux 的CONFIG_TASK_DELAY_ACCT 选项，Linux 会跟踪每个任务的延时包括: 调度器延时: 等待 CPU 的延时 块 I/O: 等待块 I/O 的延时 交换: 等待换页的延时 内存回收: 等待内存回收的延时 用户空间的工具通过 taskstats 可以读取这些统计数据，部分统计数据也会通过 /proc 对外提供。 2.3 Kernel Tracepoints静态探针 tracepoints ，是散落在内核源代码中的一些 hook，开启后，它们便可以在特定的代码被运行到时被触发。可以用来跟踪特定的事件。 如果你看过内核源码，经常会看到下面这种 trace_开头的函数调用：1234567891011if (likely(prev != next)) &#123; rq-&gt;nr_switches++; rq-&gt;curr = next; ++*switch_count; trace_sched_switch(preempt, prev, next); # trace_ 开头的函数调用 rq = context_switch(rq, prev, next, cookie); /* unlocks the rq */ &#125; else &#123; lockdep_unpin_lock(&amp;rq-&gt;lock, cookie); raw_spin_unlock_irq(&amp;rq-&gt;lock); &#125; trace_sched_switch 就是一个事件，程序执行到这个地方就会把这个点（就是一个整数，而不是函数名），加上后面的三个参数（preempt, prev, next)都写到缓冲区中。ftrace 可以读取并保存这些信息，perf 可以在事件被触发时收到通知，dtrace 和 systemtap 可以在事件触发时执行指定的 “action”。 这些跟踪点被硬编码在内核的有用的位置上，以便更高层次的行为可以很容易地被跟踪。例如，系统调用、TCP事件、文件系统I/O、磁盘I/O等等。它们被分组到跟踪点库中;例如，“sock:”表示套接字事件，“sched:”表示CPU调度器事件。跟踪点的一个关键价值是它们应该有一个稳定的API，因此如果您编写的工具在一个内核版本上使用它们，那么它们也应该适用于以后的版本。 Tracepoints 通常通过放置在 include/trace/events/*.XXX 中的宏添加到内核代码中来实现。 下面是 Linux4.10 系统上对 tracepoint 库和数量的统计。 1234567891011121314151617181920&gt; perf list | awk -F: '/Tracepoint event/ &#123; lib[$1]++ &#125; END &#123; for (l in lib) &#123; printf " %-16.16s %d\n", l, lib[l] &#125; &#125;' | sort | column alarmtimer 4 i2c 8 page_isolation 1 swiotlb 1 block 19 iommu 7 pagemap 2 syscalls 614 btrfs 51 irq 5 power 22 task 2 cgroup 9 irq_vectors 22 printk 1 thermal 7 clk 14 jbd2 16 random 15 thermal_power_ 2 cma 2 kmem 12 ras 4 timer 13 compaction 14 libata 6 raw_syscalls 2 tlb 1 cpuhp 3 mce 1 rcu 1 udp 1 dma_fence 8 mdio 1 regmap 15 vmscan 15 exceptions 2 migrate 2 regulator 7 vsyscall 1 ext4 95 mmc 2 rpm 4 workqueue 4 fib 3 module 5 sched 24 writeback 30 fib6 1 mpx 5 scsi 5 x86_fpu 14 filelock 10 msr 3 sdt_node 1 xen 35 filemap 2 napi 1 signal 2 xfs 495 ftrace 1 net 10 skb 3 xhci-hcd 9 gpio 2 nmi 1 sock 2 huge_memory 4 oom 1 spi 7 这些包括: block: 块设备I/O ext4: 文件系统操作 kmem: 内核内存分配事件 random: 内核随机数生成器事件 sched: CPU调度器事件 random: 系统调用的进入和返回 task: 任务事件 在每次内核升级之后，都有必要检查跟踪点列表，看看是否有新的跟踪点。添加它们是经过充分考虑的，包括评估有多少人会使用它们。需要实现一个平衡:我将包括尽可能少的探测，以充分满足常见需求，任何不寻常或不常见的情况都可以留给动态跟踪。 有关使用跟踪点的示例，请参见静态内核跟踪。 2.4 User-Level Statically Defined Tracing (USDT)与内核跟踪点类似，这些跟踪点是硬编码的(通常通过将宏放置在应用程序源代码中)，并作为稳定的API呈现(事件名称和参数)。许多应用程序已经包括跟踪点，这些跟踪点是为了支持DTrace而添加的。然而，许多这些应用程序在Linux上默认情况下并不编译它们。通常需要使用—with-dtrace标志自己编译应用程序。 例如，用这个版本的Node.js编译USDT事件: 123456$ sudo apt-get install systemtap-sdt-dev # adds "dtrace", used by node build$ wget https://nodejs.org/dist/v4.4.1/node-v4.4.1.tar.gz$ tar xvf node-v4.4.1.tar.gz $ cd node-v4.4.1$ ./configure --with-dtrace$ make -j 8 检查产生的二进制程序是否包含了 USDT 探测点: 1$ readelf -n node 有关使用USDT事件的示例，请参见静态用户跟踪。 2.5 Dynamic Tracing静态探针跟动态探针之间的区别在于: 静态探针是在编译之前就已经存在代码中的。动态探针是在编译之后软件运行时才加入的，本质上是内核地址空间的现场修改(live patching)，所采用的的技术会因处理器类型的不同而有所不同。它们覆盖的范围如下图所示: 虽然动态跟踪可以看到所有东西，但它也是一个不稳定的接口，因为它检测的是原始代码。这意味着您开发的任何动态跟踪工具在内核补丁或更新之后可能会中断。首先尝试使用静态跟踪点，因为它们的接口应该更加稳定。它们也更容易使用和理解，因为它们是为跟踪最终用户而设计的。 动态跟踪的一个好处是，它可以在活动的系统上启用，而不需要重新启动任何东西。您可以使用一个已经运行的内核或应用程序，然后开始动态检测，它(安全地)在内存中修补指令以添加检测。这意味着在您开始使用此功能之前，此功能的开销或税收为零。这一刻，您的二进制文件还在以全速运行，而下一刻，它又在运行一些您动态添加的额外的检测指令。当您使用完动态跟踪会话后，这些指令最终应该被删除。 在使用动态跟踪和执行额外指令时的开销，与插装事件的频率乘以在每个插装上所做的工作有关。 kprobes 和 uprobeskprobes 和 uprobes 机制就是我们所说的动态探针。它们可以在指定的探测点(比如函数的某行, 函数的入口地址和出口地址, 或者内核的指定地址处)插入一组处理程序。kprobes 主要用于调试内核，uprobes 类似 kprobes, 不过主要用于用户空间的追踪调试。它们作用的位置如下图所示: 内核参数使用动态追踪需要启用如下的内核参数: 内核动态跟踪需要启用CONFIG_KPROBES=y和CONFIG_KPROBE_EVENTS=y 用户级动态跟踪需要启用 CONFIG_UPROBES=y和CONFIG_UPROBE_EVENTS=y 为避免内核栈指针优化，需要启用 CONFIG_FRAME_POINTER=y 3. 观测工具按照使用的观测源的不同，我们可以将调优工具分为以下三种: 计数器类 跟踪 剖析 3.1 计数器类计数器类工具读取并展示内核和进程各种统计信息，包括 top，vmstat，mpstat，iostat 等绝大多数我们常用的系统命令。它们的使用可以认为是无成本，因为计数器由内核维护的。 3.2 跟踪跟踪指的是跟踪每一个事件的详细数据，相关的工具包括: tcpdump: 网络报跟踪 blktrace: 块 I/O 跟踪 execsnoop: 跟踪新进程(位于后面要讲的高级工具中) 跟踪捕获数据会有 CPU 开销，还需要存储空间存放数据，会拖慢跟踪对象，因此在使用时需要注意工具自身对观测对象的影响。 3.3 剖析剖析通过对目标收集采样或快照来归纳目标特征。跟踪是查看事件的详细数据，剖析可以理解为对事件的统计，以了解系统和程序当前运行的全貌。各种静态和动态追踪技术是完成跟踪和剖析的主要工具。也是我们接下来要介绍的难点内容。 4. 动态追踪技术下面是一个追踪技术的不完全列表。 工具 使用的 event 特点 ftrace 静态探针内核的动态探针 1.总体跟踪法，统计了一个事件到下一个事件所有的时间长度2.可以知道整个系统运行在时间轴上的分布3.方法很准确，但跟踪成本很高，只能跟踪内核程序 perf 全部的 event 1.抽样跟踪，需要注意抽样导致的结果是否准确2.直接跟踪到整个系统的所有程序perf通常是我们分析系统性能的第一步 Dtrace Solaris 的动态追踪技术 Systemtap Linux 的动态追踪技术 eBPF Linux 4.x 以上版本的动态追踪技术 在介绍这些工具之前，需要强调的是，无论什么动态追踪技术依赖的都是上面所说的内核工具框架的统一接口-events。它们都需要通过 event 去采集内核或者应用程序的运行信息。 4.1 ftraceftrace 最早用于函数跟踪，后来又扩展支持了各种事件跟踪功能。ftrace 的使用接口跟我们之前提到的 procfs 类似，它通过 debugfs（4.1 以后也支持 tracefs），以普通文件的形式，向用户空间提供访问接口。 4.2 perfperf 主要功能是事件记录和分析，这实际上只是一种最简单的静态跟踪机制。你也可以通过 perf ，来自定义动态事件（perf probe），只关注真正感兴趣的事件。 4.3 DtraceSolaris 系统的 DTrace 是动态追踪技术的鼻祖，它提供了一个通用的观测框架，并可以使用 D 语言进行自由扩展。 4.4 SystemtapDTrace 本身依然无法在 Linux 中运行。很多工程师都尝试过把 DTrace 移植到 Linux 中，这其中，最著名的就是 RedHat 主推的 SystemTap。 同 DTrace 一样，SystemTap 也定义了一种类似的脚本语言，方便用户根据需要自由扩展。不过，不同于 DTrace，SystemTap 并没有常驻内核的运行时，它需要先把脚本编译为内核模块，然后再插入到内核中执行。这也导致 SystemTap 启动比较缓慢，并且依赖于完整的调试符号表。 为了追踪内核或用户空间的事件，Dtrace 和 SystemTap 都会把用户传入的追踪处理函数（一般称为 Action），关联到被称为探针的检测点上。这些探针的检测点就是各种 events。 4.3 eBPFeBPF 则在 BPF（Berkeley Packet Filter）的基础上扩展而来，不仅支持事件跟踪机制，还可以通过自定义的 BPF 代码（使用 C 语言）来自由扩展。所以，eBPF 实际上就是常驻于内核的运行时，可以说就是 Linux 版的 DTrace。 参考 Linux 系统动态追踪技术介绍 在Linux下做性能分析2：ftrace]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1.1 Linux 性能调优入门指南]]></title>
    <url>%2F2020%2F01%2F01%2Flinux_perf%2F01_Linux%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E6%A6%82%E8%A7%88%2F</url>
    <content type="text"><![CDATA[这个系列文章，目的是学习一下 Linux 的性能优化，希望下一次服务器出问题时，不是只会一个 top。Linux 性能优化与 Linux 操作系统密切相关，所以想要学好非常不容易。 1. 系列大纲下面是 Linux 性能优化系列文章的大纲: 动态追踪: 将介绍常见的静态和动态追踪技术的原理和使用，包括 ftrace，perf，DTrace，Systemtap 等 操作系统：将介绍 CPU，内存，文件系统，磁盘，网络的基本原理以及可监测它们的工具(命令) 高级工具: 将介绍基于动态追踪技术的一些高级工具，包括: perf-tool systemtap-lwtools DTraceToolkit bpf-perf-tools bpf-bcc openresty-systemtap openresty_stapxx 高级语言性能优化: 将介绍如何利用上面介绍的工具，对 Python，Go，Java 进行性能调优，使用这些工具的好处是语言无关，更加具有普适性。 2. 学习资源下面是我在学习过程中发现的学习资源，推荐大家阅读。本系列的文章也参考了很多他们的内容，在此特别说明。 《性能之巅》 极客时间专栏-Linux性能优化实战 动态追踪技术漫谈 Systemtap: 优秀的systemtap学习资源 SystemTap新手指南中文 SystemTap Tapset Reference Manual Python: 使用 DTrace 和 SystemTap 检测 CPython]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux性能调优</tag>
        <tag>入门指南</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. k8s集群安装与配置]]></title>
    <url>%2F2019%2F11%2F15%2FK8S%2Fk8s%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8Ek8s%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[k8s集群安装与配置 1. k8s 安装1.1 准备 yum 源12345678910111213141516cd /etc/yum.repo.d/# docker-ce 源wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# kubernetes 源vim kubernetes.repo[kuberneters]name=kuberneters repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1enabled=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg# 设置 docker kubelet 开机自启动systemctl enable docker kubelet 1.2 安装配置相关组件1234567891011121314151617181920# 安装相关组件yum install docker-ce kubectl kubelet kubeadm# 配置 docer 的 unit file 添加 https 代理，以便能下载相关被墙的镜像# 不过依旧不能用，此步骤省略# vim /usr/lib/systemd/system/docker.service # 添加# Environment="HTTPS_PROXY=http://www.ik8s.io:10080"systemctl daemon-reloadsystemctl restart dockerdocker info # 看到 HTTPS_PROXY 行即可# 配置 kuberneters 不受 swap 分区的影响vim /etc/sysconfig/kubeletKUBELET_EXTRA_ARGS="--fail-swap-on=false"# 系统参数初始化sysctl -w net.bridge.bridge-nf-call-ip6tables=1sysctl -w net.bridge.bridge-nf-call-iptables=1iptables -F 1.3 准备 kubeadm 所需镜像因为某种不可描述的原因，kubeadm 使用到的镜像无法访问，因此需要手动准备 kubeadm 所需的镜像文件。这里有片文章可以指导你去构建相应的 镜像 https://ieevee.com/tech/2017/04/07/k8s-mirror.html 12345678&gt; kubeadm config images listk8s.gcr.io/kube-apiserver:v1.12.2k8s.gcr.io/kube-controller-manager:v1.12.2k8s.gcr.io/kube-scheduler:v1.12.2k8s.gcr.io/kube-proxy:v1.12.2k8s.gcr.io/pause:3.1k8s.gcr.io/etcd:3.2.24k8s.gcr.io/coredns:1.2.2 我是自己去阿里云自建的镜像，使用下面的脚本对镜像进行重命名12345678910#!/bin/bashbase=k8s.gcr.ioaliyun="registry.cn-qingdao.aliyuncs.com/htttao"images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for i in $&#123;images[@]&#125;do docker pull $aliyun/$i docker tag $aliyun/$i $base/$idone 1.4 初始化 Master 节点12345678910111213141516kubeadm init --kubernetes-version=v1.12.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swap# 运行完成之后，会提示将 Node 节点加入集群的命令kubeadm join 192.168.1.106:6443 --token z5fqxu.dn3awhi0u5n2i6eb --discovery-token-ca-cert-hash sha256:dc333a8af6ee0c7cd1e180b43251800685b90d6338929fa508e42f76579ce50c# 按照初始化后的提示，创建一个普通用户，并复制相应文件# user: kubernetesmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# 测试kubectl get cskubectl get nodeskubectl get podskubectl get ns 1.5 部署网络组件初始化 Master 还有非常重要的一步，就是部署网络组件，否则各个 pod 等组件之间是无法通信的123kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.ymlkubectl get pods 1.6 k8s 集群重至如果配置过程中出现了错误，想重新配置集群， 可以使用 kubeadm reset 对整个集群进行重至，然后重新使用 kubeadm init 进行初始化创建。但是需要注意的时，kubeadm reset 不会重至 flannel 网络，想要完全重至可使用以下脚本 12345678910111213#!/bin/bashkubeadm resetsystemctl stop kubeletsystemctl stop dockerrm -rf /var/lib/cni/rm -rf /var/lib/kubelet/*rm -rf /etc/cni/ifconfig cni0 downifconfig flannel.1 downifconfig docker0 downip link delete cni0ip link delete flannel.1systemctl start docker 2. 安装脚本整个集群安装比较复杂，因此我将上述过程写成了两个脚本。因此按次序执行下面脚本然后进行 kubeadm init 进行集群初始化即可完成配置。 2.1 基础环境配置脚本1234567891011121314151617181920212223242526272829#!/bin/bash# 1. 设置系统参数mount /dev/cdrom /cdromiptables -F# 2. 准备 yum 源wget -P /etc/yum.repos.d/ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repocat &lt;&lt; EOF &gt;&gt; /etc/yum.repos.d/kubernetes.repo[kuberneters]name=kuberneters repobaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/gpgcheck=1enabled=1gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 3. 配置 kuberneters 不受 swap 分区的影响yum install docker-ce kubelet kubeadm kubectl -yecho 'KUBELET_EXTRA_ARGS="--fail-swap-on=false"' &gt; /etc/sysconfig/kubelet# 4. 启动相关服务systemctl start dockersystemctl enable docker kubeletcat &lt;&lt; EOF &gt; /etc/docker/daemon.json&#123; "registry-mirrors": ["https://osafqkzd.mirror.aliyuncs.com"]&#125;EOF 2.2 镜像下载脚本执行下面的下载脚本 /root/kubernetes.sh123456789101112131415161718#!/bin/bashsudo docker login --username=1556824234@qq.com registry.cn-qingdao.aliyuncs.comsysctl net.bridge.bridge-nf-call-ip6tables=1sysctl net.bridge.bridge-nf-call-iptables=1base=k8s.gcr.ioaliyun="registry.cn-qingdao.aliyuncs.com/htttao"images=(kube-apiserver:v1.12.2 kube-controller-manager:v1.12.2 kube-scheduler:v1.12.2 kube-proxy:v1.12.2 pause:3.1 etcd:3.2.24 coredns:1.2.2)for i in $&#123;images[@]&#125;do docker pull $aliyun/$i docker tag $aliyun/$i $base/$idoneflannel=flannel:v0.10.0-amd64docker pull $aliyun/$flanneldocker tag $aliyun/$flannel quay.io/coreos/$flannel 2.3 集群初始化1234567891011kubeadm init --kubernetes-version=v1.12.2 --pod-network-cidr=10.244.0.0/16 --service-cidr=10.96.0.0/12 --ignore-preflight-errors=Swapmkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config# Node 节点的加入集群的命令kubeadm join 192.168.1.184:6443 --token w1b9i6.ryqstfgjmob2z8xp --discovery-token-ca-cert-hash sha256:0d3404f3919116e7efa56b2e0694c1397cd44915ed13f16d9e6e7600ada64c4c --ignore-preflight-errors=Swapkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml 3. Node 节点配置Node 节点的配置与 Master 过程类似，以此执行上述两个脚本即可，唯一的区别是在初始化时执行的是 kubeadm join. 1234# 1. 基础环境配置脚本# 2. 执行镜像下载脚本，准备好相关镜像# 3. 将节点加入集群, 需要注意节点的主机名不能与 Master 节点同名kubeadm join 192.168.1.184:6443 --token w1b9i6.ryqstfgjmob2z8xp --discovery-token-ca-cert-hash sha256:0d3404f3919116e7efa56b2e0694c1397cd44915ed13f16d9e6e7600ada64c4c --ignore-preflight-errors=Swap]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>K8S</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 Mariadb 复制]]></title>
    <url>%2F2019%2F10%2F11%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F6_%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Mariadb 主从复制 1.复制的基本原理复制简介: 复制功用： 负载均衡：读操作，适用于读密集型的应用 备份 高可用和故障切换 MySQL升级测试 主从复制系统架构： 从服务器： I/O线程：从master请求二进制日志信息，并保存至中继日志； SQL线程：从relay log中读取日志信息，在本地完成重放； 异步模式：async: 从服务器落后于主服务器，会出现主从数据不一致； 2.主从复制配置过程：主从复制的配置过程: 配置时间同步 复制的起始位置: 如果主服务器数据较小，且二进制日志完整，复制的起点可以从 0 位置开始 如果主服务器数据很多，或二进制日志不完成，应先以 xtrabackup 备份恢复的方式启动从节点，复制的起点为备份操作时主节点所处的日志文件及事件位置 master 启用二进制日志； 设置一个在当前集群中惟一的server-id； 创建一个有复制权限(REPLICATION SLAVE, REPLICATION CLIENT)账号； slave 启用中继日志； 设置一个在当前集群中惟一的server-id； 使用有复制权限用户账号连接至主服务器，并启动复制线程； 2.1 主从配置示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 关闭 iptables# 1. 主节点配置&gt; yum intall mariadb-server&gt; vim /etc/my.cnf.d/server.cnf [server] datadir = /data innodb_file_per_table = ON skip_name_resolve = ON server_id=1 log_bin = master-log slow_query_log = ON&gt; mkdir /data /backup&gt; chown -R mysql:mysql /data /backup&gt; chcon /data/ /backup/ -R --reference /var/lib/mysql/&gt; mysql_install_db --user=mysql --datadir=/data&gt; mysql_secure_installation&gt; systemctl start mariadb# 配置同步账号MariaDB [(none)]&gt; GRANT REPLICATION CLIENT,REPLICATION SLAVE ON *.* TO &quot;repluser&quot;@&quot;%&quot; IDENTIFIED BY &quot;replpass&quot;;Query OK, 0 rows affected (0.019 sec)MariaDB [(none)]&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.019 sec)# 2. 从节点配置&gt; yum intall mariadb-server&gt; vim /etc/my.cnf.d/server.cnf [server] datadir = /data innodb_file_per_table = ON skip_name_resolve = ON read_only = ON server_id = 2 log_bin = slave-log relay_log = relay-log slow_query_log = ON log_error = error-log&gt; mkdir /data /backup&gt; chown -R mysql:mysql /data /backup&gt; chcon /data/ /backup/ -R --reference /var/lib/mysql/&gt; mysql_install_db --user=mysql --datadir=/data&gt; mysql_secure_installation&gt; systemctl start mariadb&gt; mysql -uroot -p MariaDB [(none)]&gt; CHANGE MASTER TO MASTER_HOST=&quot;192.168.1.18&quot;, MASTER_USER=&quot;repluser&quot;, MASTER_PASSWORD=&quot;replpass&quot;,MASTER_PORT=3306,MASTER_LOG_FILE=&quot;master-log.000004&quot;,MASTER_LOG_POS=1222;Query OK, 0 rows affected (0.018 sec)MariaDB [(none)]&gt; SHOW SLAVE STATUS;MariaDB [(none)]&gt; START SLAVE;Query OK, 0 rows affected (0.004 sec) 2.2 CHANGE MASTER 命令使用CHANGE MASTER TO option [, option] … 作用: slave 连接至主服务器 option: MASTER_HOST = ‘host_name’ 主服务器地址 MASTER_USER = ‘user_name’ 有复制权限的用户名 MASTER_PASSWORD = ‘password’ 用户密码 MASTER_PORT = port_num 主服务器的端口 MASTER_CONNECT_RETRY = interval 连接重试时间间隔 MASTER_HEARTBEAT_PERIOD = interval 心跳检测时间间隔 MASTER_LOG_FILE = ‘master_log_name’ 主服务器二进制日志文件 MASTER_LOG_POS = master_log_pos 二进制日志文件中的位置 2.3 主从复制的注意事项 复制如何开始: 主节点运行很长时间，且已经有一定规模的数据，如何启动复制？ 在主节点做一个完全备份，并记录二进制日志文件及位置； 在从节点恢复此完全备份，并在启动复制时从记录的二进制日志文件和位置开始； 从服务器限制只读: 在从服务器启动read_only；但仅对非具有SUPER权限的用户有效； 阻止所有用户 ：MariaDB&gt; FLUSH TABLES WITH READ LOCK; 保证主从复制时的事务安全 在master节点启用参数： sync_binlog = on: 事务提交时，同步二进制日志 sync_master_info = 1 如果用到的为InnoDB存储引擎，应该启用以下参数： innodb_flush_logs_at_trx_commit: 事务提交时，同步事务日志到文件中 innodb_support_xa=on: 启用分布式事务 slave 节点启用参数： skip_slave_start: 从服务器意外终止时，尽量避免自动重启复制线程，以防止从服务器未执行完事务导致的数据不一致 sync_master_info = 1: 同步 master-info 日志文件 sync_relay_log_info = 1: 同步 relay-info 日志文件 sync_relay_log = 1 12345# 从节点 ll /data/*.info-rw-rw----. /data/master.info # 记录了主节点当前同步的位置-rw-rw----. /data/multi-master.info-rw-rw----. /data/relay-log.info # 记录了relay-log 与 master-log 二进制文件事件位置的对应关系 跟复制功能相关的文件： master.info：用于保存slave连接至master时的相关信息； relay-log.info：保存了当前slave节点上已经复制的当前二进制日志和本地relay log日志对应关系； 2.4 半同步复制1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# 1. 主节点：# 查看 Mairadb 所有插件MariaDB [(none)]&gt; SHOW PLUGINS;MariaDB [(none)]&gt; INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';Query OK, 0 rows affected (0.05 sec) MariaDB [(none)]&gt; SHOW GLOBAL VARIABLES LIKE '%semi%';+------------------------------------+-------+| Variable_name | Value |+------------------------------------+-------+| rpl_semi_sync_master_enabled | OFF || rpl_semi_sync_master_timeout | 10000 | # 毫秒 10s，等待同步节点的超时时长| rpl_semi_sync_master_trace_level | 32 || rpl_semi_sync_master_wait_no_slave | ON | # 在没有同步的从节点时，是否等待 +------------------------------------+-------+4 rows in set (0.00 sec)MariaDB [(none)]&gt; SET GLOBAL rpl_semi_sync_master_enabled=1;Query OK, 0 rows affected (0.00 sec)MariaDB [(none)]&gt; SET GLOBAL rpl_semi_sync_master_timeout=2000;Query OK, 0 rows affected (0.00 sec) # 2. 从节点：MariaDB [(none)]&gt; INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';Query OK, 0 rows affected (0.05 sec)MariaDB [(none)]&gt; SHOW GLOBAL VARIABLES LIKE '%semi%';+---------------------------------+-------+| Variable_name | Value |+---------------------------------+-------+| rpl_semi_sync_slave_enabled | OFF || rpl_semi_sync_slave_trace_level | 32 |+---------------------------------+-------+2 rows in set (0.00 sec)MariaDB [(none)]&gt; SET GLOBAL rpl_semi_sync_slave_enabled=1;Query OK, 0 rows affected (0.00 sec)# 重启复制线程，以使得半同步生效MariaDB [(none)]&gt; STOP SLAVE IO_THREAD;Query OK, 0 rows affected (0.013 sec)MariaDB [(none)]&gt; START SLAVE IO_THREAD;Query OK, 0 rows affected (0.002 sec)# 3.半同步状态查看 -- 主节点MariaDB [(none)]&gt; SHOW GLOBAL STATUS LIKE "rpl%";+--------------------------------------------+-------------+| Variable_name | Value |+--------------------------------------------+-------------+| Rpl_semi_sync_master_clients | 0 | # 作为同步复制的从节点个数| Rpl_semi_sync_master_get_ack | 0 || Rpl_semi_sync_master_net_avg_wait_time | 0 || Rpl_semi_sync_master_net_wait_time | 0 || Rpl_semi_sync_master_net_waits | 0 || Rpl_semi_sync_master_no_times | 0 || Rpl_semi_sync_master_no_tx | 0 || Rpl_semi_sync_master_request_ack | 0 || Rpl_semi_sync_master_status | OFF || Rpl_semi_sync_master_timefunc_failures | 0 || Rpl_semi_sync_master_tx_avg_wait_time | 0 || Rpl_semi_sync_master_tx_wait_time | 0 || Rpl_semi_sync_master_tx_waits | 0 || Rpl_semi_sync_master_wait_pos_backtraverse | 0 || Rpl_semi_sync_master_wait_sessions | 0 || Rpl_semi_sync_master_yes_tx | 0 || Rpl_semi_sync_slave_send_ack | 0 || Rpl_semi_sync_slave_status | OFF || Rpl_status | AUTH_MASTER || Rpl_transactions_multi_engine | 0 |+--------------------------------------------+-------------+ 3. 双主模型互为主从的潜在问题: 数据不一致； 自动增长id 定义一个节点使用奇数id auto_increment_offset=1 auto_increment_increment=2 定义另一个节点使用偶数id auto_increment_offset=2 auto_increment_increment=2 配置要点: 各自使用不同的server id 都启用binlog和relay log 定义自动增长的id字段的增长方式 都授权有复制权限的用户账号 各自把对方指定为主服务器 12345678910111213141516171819202122232425262728293031# 1. 主节点配置&gt; vim /etc/my.cnf.d/server.cnf [server] datadir = /data innodb_file_per_table = ON skip_name_resolve = ON server_id=1 log_bin = master-log relay_log = relay-log slow_query_log = ON log_error = error-log auto_increment_offset=1 auto_increment_increment=2# 2. 从节点配置&gt; vim /etc/my.cnf.d/server.cnf [server] datadir = /data innodb_file_per_table = ON skip_name_resolve = ON server_id = 2 log_bin = slave-log relay_log = relay-log slow_query_log = ON log_error = error-log auto_increment_offset=2 auto_increment_increment=2 4. 复制过滤器让slave仅复制有限的几个数据库，而非所有，有两种实现思路： 主服务器仅向二进制日志中记录有特定数据库相关的写操作； 问题：时间点还原将无法全面实现；不建议 配置: binlog_do_db=: 数据库白名单，只允许指定库的写操作记录到二进制日志中 binlog_ignore_db=: 数据库黑名单 从服务器的SQL_THREAD仅在中断日志中读取特定数据相关的语句并应用在本地； 问题：会造成网络带宽和磁盘IO的浪费； 配置: Replicate_Do_DB=: 数据库白名单 Replicate_Ignore_DB= Replicate_Do_Table=: 表级别白名单 Replicate_Ignore_Table= Replicate_Wild_Do_Table=: 通配符匹配表的白名单 Replicate_Wild_Ignore_Table=1234567891011121314151617181920212223242526272829MariaDB [(none)]&gt; STOP SLAVE;Query OK, 0 rows affected (0.014 sec)MariaDB [(none)]&gt; SET @@GLOBAL.replicate_do_db=mydb;Query OK, 0 rows affected (0.000 sec)MariaDB [(none)]&gt; START SLAVE;Query OK, 0 rows affected (0.002 sec)MariaDB [(none)]&gt; SHOW SLAVE STATUS \G*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.1.18 Master_User: repluser Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-log.000006 Read_Master_Log_Pos: 472 Relay_Log_File: relay-log.000007 Relay_Log_Pos: 556 Relay_Master_Log_File: master-log.000006 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: mydb Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: 6. 复制的监控和维护6.1 二进制日志清理PURGE {BINARY|MASTER} LOGS TO &quot;log_name&quot; 作用: 清理二进制日志文件，会自动更新二进制的 .index 文件 1234567891011121314151617181920212223242526272829# 备份二进制文件&gt; cp /data/slave-log* /backup# 删除二进制文件MariaDB [(none)]&gt; SHOW MASTER LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| slave-log.000001 | 351 || slave-log.000002 | 28636 || slave-log.000003 | 1705 || slave-log.000004 | 365 || slave-log.000005 | 342 |+------------------+-----------+5 rows in set (0.000 sec)MariaDB [(none)]&gt; PURGE MASTER LOGS TO "slave-log.000005";Query OK, 0 rows affected (0.010 sec)MariaDB [(none)]&gt; SHOW MASTER LOGS;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| slave-log.000005 | 342 |+------------------+-----------+1 row in set (0.000 sec)&gt; sudo cat slave-log.index./slave-log.000005 6.2 复制监控 SHOW MASTER STATUS SHOW BINLOG EVENTS SHOW BINARY LOGS SHOW SLAVE STATUS: 判断slave是否落后于master: Seconds_Behind_Master: 0 6.3 主从节点数据是否一致 检查方法: 通过表自身的CHECKSUM检查 使用percona-tools中pt-table-checksum 数据不一致的修复方法：重新复制]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7. performance_schema]]></title>
    <url>%2F2019%2F10%2F11%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F7.performance%2F</url>
    <content type="text"><![CDATA[Mariadb 的系统库 performance_schema。 参考 Mariadb Document 初相识｜performance_schema全方位介绍 Naridb Plugin 1. performance_schema1.1 简介MySQL的performance schema 用于监控MySQL server在一个较低级别的运行过程中的资源消耗、资源等待等情况，它具有以下特点： 提供了一种在数据库运行时实时检查server的内部执行情况的方法，主要关注数据库运行过程中的性能相关的数据，使用performance_schema存储引擎 与information_schema不同，information_schema主要关注server运行过程中的元数据信息 sys schema是一组对象（包括相关的视图、存储过程和函数），可以方便地访问performance_schema收集的数据。同时检索的数据可读性也更高 performance_schema通过监视server的事件来实现监视server内部运行情况 PERFORMANCE_SCHEMA存储引擎使用server源代码中的“检测点”来实现事件数据的收集。 1.2 启用performance_schema 被视为存储引擎。使用 INFORMATION_SCHEMA.ENGINES表来查询你的数据库实例是否支持 PERFORMANCE_SCHEMA 引擎。 performance_schema 通过参数performance_schema=ON|OFF启用或关闭。使用 SHOW VARIABLES LIKE &#39;performance_schema&#39;; 可以查看当前 mariadb 实例是否启用 performance_schema。 1.3 performance_schema 配置项performance_schema中的配置是保存在内存中的(会在后面 performance_schema的使用中说明)。想要持久化配置，就需要在mariadb 的配置文件中配置。 通过如下命令行命令进行查看 performance_schema 配置项 12345678910111213141516mysqld --verbose --help |grep performance-schema |grep -v '\-\-' |sed '1d' |sed '/[0-9]\+/d'2020-06-25 11:19:47 0 [Note] Plugin 'FEEDBACK' is disabled.2020-06-25 11:19:47 0 [Warning] Could not open mysql.plugin table. Some options may be missing from the help textperformance-schema-consumer-events-stages-current FALSEperformance-schema-consumer-events-stages-history FALSEperformance-schema-consumer-events-stages-history-long FALSEperformance-schema-consumer-events-statements-current TRUEperformance-schema-consumer-events-statements-history FALSEperformance-schema-consumer-events-statements-history-long FALSEperformance-schema-consumer-events-waits-current FALSEperformance-schema-consumer-events-waits-history FALSEperformance-schema-consumer-events-waits-history-long FALSEperformance-schema-consumer-global-instrumentation TRUEperformance-schema-consumer-statements-digest TRUEperformance-schema-consumer-thread-instrumentation TRUEperformance-schema-instrument 2. performance_schema 表分类performance_schema库下的表可以按照监视不同的纬度进行了分组，例如：或按照不同数据库对象进行分组，或按照不同的事件类型进行分组，或在按照事件类型分组之后，再进一步按照帐号、主机、程序、线程、用户等，如下： 2.1 语句事件记录表语句事件记录表，这些表记录了语句事件信息，包括: events_statements_current: 当前语句事件表 events_statements_history: 历史语句事件表 events_statements_history_long: 长语句历史事件表 summary: 聚合后的摘要表，summary表还可以根据帐号(account)，主机(host)，程序(program)，线程(thread)，用户(user)和全局(global)再进行细分) 123456789101112131415MariaDB [performance_schema]&gt; show tables like "events_statement%";+----------------------------------------------------+| Tables_in_performance_schema (events_statement%) |+----------------------------------------------------+| events_statements_current || events_statements_history || events_statements_history_long || events_statements_summary_by_account_by_event_name || events_statements_summary_by_digest || events_statements_summary_by_host_by_event_name || events_statements_summary_by_thread_by_event_name || events_statements_summary_by_user_by_event_name || events_statements_summary_global_by_event_name |+----------------------------------------------------+9 rows in set (0.000 sec) 2.2 等待事件记录表等待事件记录表，与语句事件类型的相关记录表类似： 123456789101112131415 show tables like "events_wait%";+-----------------------------------------------+| Tables_in_performance_schema (events_wait%) |+-----------------------------------------------+| events_waits_current || events_waits_history || events_waits_history_long || events_waits_summary_by_account_by_event_name || events_waits_summary_by_host_by_event_name || events_waits_summary_by_instance || events_waits_summary_by_thread_by_event_name || events_waits_summary_by_user_by_event_name || events_waits_summary_global_by_event_name |+-----------------------------------------------+9 rows in set (0.001 sec) 2.3 阶段事件记录表阶段事件记录表，记录语句执行的阶段事件的表，与语句事件类型的相关记录表类似：1234567891011121314 show tables like "events_stage%";+------------------------------------------------+| Tables_in_performance_schema (events_stage%) |+------------------------------------------------+| events_stages_current || events_stages_history || events_stages_history_long || events_stages_summary_by_account_by_event_name || events_stages_summary_by_host_by_event_name || events_stages_summary_by_thread_by_event_name || events_stages_summary_by_user_by_event_name || events_stages_summary_global_by_event_name |+------------------------------------------------+8 rows in set (0.000 sec) 2.4 事务事件记录表事务事件记录表，记录事务相关的事件的表，与语句事件类型的相关记录表类似。Mariadb 没有事务记录表。 1234567891011121314MySQL&gt; show tables like &apos;events_transaction%&apos;;+------------------------------------------------------+| Tables_in_performance_schema (%transaction%) |+------------------------------------------------------+| events_transactions_current || events_transactions_history || events_transactions_history_long || events_transactions_summary_by_account_by_event_name || events_transactions_summary_by_host_by_event_name || events_transactions_summary_by_thread_by_event_name || events_transactions_summary_by_user_by_event_name || events_transactions_summary_global_by_event_name |+------------------------------------------------------+8 rows in set (0.00 sec) 2.5 监视文件系统层调用的表123456789show tables like "%file%";+---------------------------------------+| Tables_in_performance_schema (%file%) |+---------------------------------------+| file_instances || file_summary_by_event_name || file_summary_by_instance |+---------------------------------------+3 rows in set (0.000 sec) 2.5 监视内存使用的表Mariadb 没有监视内存使用的表 1234567891011MySQL &gt; show tables like '%memory%';+-----------------------------------------+| Tables_in_performance_schema (%memory%) |+-----------------------------------------+| memory_summary_by_account_by_event_name || memory_summary_by_host_by_event_name || memory_summary_by_thread_by_event_name || memory_summary_by_user_by_event_name || memory_summary_global_by_event_name |+-----------------------------------------+5 rows in set (0.01 sec) 2.6 动态对 performance_schema 进行配置的配置表1234567891011MariaDB [performance_schema]&gt; show tables like "%setup%";+----------------------------------------+| Tables_in_performance_schema (%setup%) |+----------------------------------------+| setup_actors || setup_consumers || setup_instruments || setup_objects || setup_timers |+----------------------------------------+5 rows in set (0.000 sec) 2.7 instance 表instance表记录了哪些类型的对象会被检测。这些对象在被server使用时，在该表中将会产生一条事件记录，例如，file_instances表列出了文件I/O操作及其关联文件名：12345678910111213141516171819202122MariaDB [performance_schema]&gt; show tables like "%inst%";+---------------------------------------+| Tables_in_performance_schema (%inst%) |+---------------------------------------+| cond_instances || events_waits_summary_by_instance || file_instances || file_summary_by_instance || mutex_instances || rwlock_instances || setup_instruments || socket_instances || socket_summary_by_instance |+---------------------------------------+9 rows in set (0.000 sec)MariaDB [performance_schema]&gt; select * from file_instances limit 1 \G*************************** 1. row ***************************FILE_NAME: /usr/share/mysql/charsets/Index.xmlEVENT_NAME: wait/io/file/mysys/charsetOPEN_COUNT: 01 row in set (0.000 sec) 2.8 事件计时器1234567891011121314151617181920MariaDB [performance_schema]&gt; show tables like "%time%";+---------------------------------------+| Tables_in_performance_schema (%time%) |+---------------------------------------+| performance_timers || setup_timers |+---------------------------------------+2 rows in set (0.001 sec)MariaDB [performance_schema]&gt; select * from performance_timers;+-------------+-----------------+------------------+----------------+| TIMER_NAME | TIMER_FREQUENCY | TIMER_RESOLUTION | TIMER_OVERHEAD |+-------------+-----------------+------------------+----------------+| CYCLE | 2902800995 | 1 | 19 || NANOSECOND | 1000000000 | 1 | 109 || MICROSECOND | 1000000 | 1 | 79 || MILLISECOND | 1000 | 1000 | 41 || TICK | 103 | 1 | 3040 |+-------------+-----------------+------------------+----------------+5 rows in set (0.001 sec) performance_timers表中记录了server中有哪些可用的事件计时器（注意：该表中的配置项不支持增删改，是只读的。有哪些计时器就表示当前的版本支持哪些计时器），setup_timers配置表中的配置项引用此表中的计时器 3. performance_schema 的使用performance_schema 包括事件的采集和保存，包括两个概念: instruments: 事件采集项，生产者，用于采集MySQL 中各种各样的操作产生的事件信息，对应配置表中的配置项我们可以称为监控采集配置项 consumers: 消费者，对应的消费者表用于存储来自instruments采集的数据，对应配置表中的配置项我们可以称为消费存储配置项 默认不会收集所有的事件，可能你需要检测的事件并没有打开，需要进行设置，可以使用如下两个语句打开对应的instruments和consumers（行计数可能会因MySQL版本而异），例如，我们以配置监测等待事件数据为例进行说明： 3.1 等待事件第一步打开等待事件的采集器配置项开关，需要修改setup_instruments 配置表中对应的采集器配置项: 123456789101112131415161718MariaDB [performance_schema]&gt; select * from setup_instruments where name like "wait%" limit 10;+-------------------------------------------------------------------+---------+-------+| NAME | ENABLED | TIMED |+-------------------------------------------------------------------+---------+-------+| wait/synch/mutex/sql/PAGE::lock | NO | NO || wait/synch/mutex/sql/TC_LOG_MMAP::LOCK_sync | NO | NO || wait/synch/mutex/sql/TC_LOG_MMAP::LOCK_active | NO | NO || wait/synch/mutex/sql/TC_LOG_MMAP::LOCK_pool | NO | NO || wait/synch/mutex/sql/TC_LOG_MMAP::LOCK_pending_checkpoint | NO | NO || wait/synch/mutex/sql/LOCK_des_key_file | NO | NO || wait/synch/mutex/sql/MYSQL_BIN_LOG::LOCK_index | NO | NO || wait/synch/mutex/sql/MYSQL_BIN_LOG::LOCK_xid_list | NO | NO || wait/synch/mutex/sql/MYSQL_BIN_LOG::LOCK_binlog_background_thread | NO | NO || wait/synch/mutex/sql/MYSQL_BIN_LOG::LOCK_binlog_end_pos | NO | NO |+-------------------------------------------------------------------+---------+-------+10 rows in set (0.001 sec)MariaDB [performance_schema]&gt; UPDATE setup_instruments SET ENABLED = 'YES', TIMED = 'YES' where name like 'wait%'; 第二步打开等待事件的保存表配置开关，需要修改 setup_consumers 配置表中对应的配置项: 1234567891011MariaDB [performance_schema]&gt; select * from setup_consumers where name like "%wait%" limit 10;+---------------------------+---------+| NAME | ENABLED |+---------------------------+---------+| events_waits_current | NO || events_waits_history | NO || events_waits_history_long | NO |+---------------------------+---------+3 rows in set (0.000 sec)MariaDB [performance_schema]&gt; UPDATE setup_consumers SET ENABLED = 'YES' where name like '%wait%'; 第三步配置好之后，就可以通过查询 events_waits_current 查看 server 当前正在做什么，表中每个线程只包含一行数据，用于显示每个线程的最新监视事件（正在做的事情） 123456789101112131415161718192021MariaDB [performance_schema]&gt; select * from events_waits_current \G*************************** 1. row *************************** THREAD_ID: 25 EVENT_ID: 126 END_EVENT_ID: 126 EVENT_NAME: wait/synch/rwlock/sql/MDL_lock::rwlock SOURCE: mdl.cc:820 TIMER_START: 2590966109403096 TIMER_END: 2590966109688960 TIMER_WAIT: 285864 SPINS: NULL OBJECT_SCHEMA: NULL OBJECT_NAME: NULL INDEX_NAME: NULL OBJECT_TYPE: NULLOBJECT_INSTANCE_BEGIN: 0 NESTING_EVENT_ID: NULL NESTING_EVENT_TYPE: NULL OPERATION: write_lock NUMBER_OF_BYTES: NULL FLAGS: NULL 事件的记录和保留是这样的: _current 表中每个线程只保留一条记录，且一旦线程完成工作，该表中不会再记录该线程的事件信息 _history 表中记录每个线程已经执行完成的事件信息，但每个线程的只事件信息只记录10条，再多就会被覆盖掉 _history_long 表中记录所有线程的事件信息，但总记录数量是10000行，超过会被覆盖掉 _summary表提供所有事件的汇总信息。该组中的表以不同的方式汇总事件数据 _by_event_name: 记录了不同事件的次数，最大，最小平均执行时长 _by_host_by_event_name: 按主机记录了不同事件的次数，最大，最小平均执行时长 1234567891011121314151617181920MariaDB [performance_schema]&gt; SELECT * FROM events_waits_summary_global_by_event_name limit 1 \G*************************** 1. row *************************** EVENT_NAME: wait/synch/mutex/sql/PAGE::lock COUNT_STAR: 0SUM_TIMER_WAIT: 0MIN_TIMER_WAIT: 0AVG_TIMER_WAIT: 0MAX_TIMER_WAIT: 01 row in set (0.000 sec)MariaDB [performance_schema]&gt; select * from events_waits_summary_by_host_by_event_name limit 1 \G*************************** 1. row *************************** HOST: NULL EVENT_NAME: wait/synch/mutex/sql/PAGE::lock COUNT_STAR: 0SUM_TIMER_WAIT: 0MIN_TIMER_WAIT: 0AVG_TIMER_WAIT: 0MAX_TIMER_WAIT: 01 row in set (0.000 sec) 3.3 结语我们大多数时候并不会直接使用 performance_schema 来查询性能数据，而是使用sys sys schema 中的数据实际上主要是从performance_schema、 information_schema 中获取，所以要想玩转 sys schema，全面了解performance_schema必不可少。 对于 Mariadb 已经没有 sys schema 库了，原本的 sys schema 通过插件和 information_schema 来提供。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8. sys]]></title>
    <url>%2F2019%2F10%2F11%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F8.sys%2F</url>
    <content type="text"><![CDATA[MySQL 的系统库 sys。 参考 Mariadb Document 初相识｜performance_schema全方位介绍 Naridb Plugin 1. sys1.1 简介sys 系统库下包含许多视图，它们以各种方式对performance_schema表进行聚合计算展示。这些视图中大部分都是成对出现，两个视图名称相同，但有一个视图是带’x$’字符前缀的 例如：host_summary_by_file_io和x$host_summary_by_file_io，代表按照主机进行汇总统计的文件I/O性能数据，两个视图访问数据源是相同的，但是创建视图的语句中，不带x$的视图是把相关数值数据经过单位换算再显示的(显示为毫秒、秒、分钟、小时、天等)，带x$前缀的视图显示的是原始的数据(皮秒) 12345678910111213141516# x$host_summary_by_file_io视图汇总数据，显示未格式化的皮秒单位延迟时间，没有x$前缀字符的视图输出的信息经过单位换算之后可读性更高mysql&gt; SELECT * FROM host_summary_by_file_io;+------------+-------+------------+| host | ios | io_latency |+------------+-------+------------+| localhost | 67570 | 5.38 s || background | 3468 | 4.18 s |+------------+-------+------------+# 对于带x$的视图显示原始的皮秒单位数值，对于程序或工具获取使用更易于数据处理mysql&gt; SELECT * FROM x$host_summary_by_file_io;+------------+-------+---------------+| host | ios | io_latency |+------------+-------+---------------+| localhost | 67574 | 5380678125144 || background | 3474 | 4758696829416 |+------------+-------+---------------+ 1.2 使用条件在使用sys系统库之前，需要确保数据库环境满足如下条件： 要充分使用sys系统库的功能，则必须启用某些performance_schema的instruments和consumers，如下： 所有wait instruments 所有stage instruments 所有statement instruments 对于所启用的类型事件的instruments，还需要启用对应类型的consumers(xxx_current和xxx_history_long)，要了解某存储过程具体做了什么事情可能通过show create procedure procedure_name;语句查看 1.3 查看 sys 中的对象要查看sys 系统库对象定义语句，可以使用适当的SHOW语句或INFORMATION_SCHEMA库查询。例如，要查看session视图和format_bytes()函数的定义，可以使用如下语句： 12mysql&gt; SHOW CREATE VIEW session;mysql&gt; SHOW CREATE FUNCTION format_bytes; 要查看更易读的格式对象定义语句，可以访问sys 系统库开发网站 https://github.com/mysql/mysql-sys 上的各个.sql文件，或者使用mysqldump与mysqlpump工具导出sys库 `bash mysqldump --databases --routines sys&gt; sys_dump.sql mysqlpump sys&gt; sys_dump.sql]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8. sys]]></title>
    <url>%2F2019%2F10%2F11%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F9.information_schema%2F</url>
    <content type="text"><![CDATA[Mariadb 的系统库 information_schema. 参考 Mariadb Document 初相识｜performance_schema全方位介绍 Naridb Plugin]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 MYSQL 备份与恢复]]></title>
    <url>%2F2019%2F10%2F10%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F5_%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[Mariadb 备份与恢复 1. 备份的简介 备份类型: 热备份、温备份和冷备份： 热备份：在线备份，读写操作不受影响； 温备份：在线备份，读操作可继续进行，但写操作不允许； 冷备份：离线备份，数据库服务器离线，备份期间不能为业务提供读写服务； 物理备份和逻辑备份： 物理备份：直接复制数据文件进行的备份； 逻辑备份：从数据库中“导出”数据另存而进行的备份，与存储引擎无关 规则备份时需要考虑的因素： 持锁的时长 备份过程时长 备份负载 恢复过程时长 备份什么: 数据、额外的数据（二进制日志和InnoDB的事务日志） 代码（存储过程和存储函数、触发器、事件调度器等）、服务器配置文件 设计备份方案: 全量备份+增量备份，binlog 全量备份+差异备份，binlog 2.备份工具备份工具: mysqldump: 逻辑备份工具，适用于所有存储引擎，温备；完全备份，部分备份，不支持差异和增量备份 对InnoDB存储引擎支持热备 MyISAM 温备 cp, tar等文件系统工具: 物理备份工具，适用于所有存储引擎；冷备；完全备份，部分备份； lvm2的快照：请求一个全局锁，之后立即释放，几乎热备 mysqlhotcopy: 几乎冷备；仅适用于MyISAM存储引擎； xtrabackup: Innodb 热备的物理备份工具，支持全量，增量和差异备份 备份方案工具选择: mysqldump+binlog: mysqldump 完全备份，通过备份二进制日志实现增量备份； lvm2快照+binlog：几乎热备，物理备份 xtrabackup + binlog: 对InnoDB：热备，支持完全备份和增量备份 对MyISAM引擎：温备，只支持完全备份 2.1 mysqldumpmysqldump: 格式: mysqldump [options] database [tables]: 单库，多表备份 mysqldump --databases [options] DB1 [DB2....]: 单库，多库备份 mysqldump --all-databases [options]: 备份所有库 作用: mysql 客户端，通过mysql协议连接至mysqld，支持逻辑，完全，部分备份 生成: Schema和数据存储一起保存为巨大的SQL语句、单个巨大的备份文件 二次封装工具: mydumper, phpMyAdmin 参数: 温备: 支持MyISAM INNODB，MyISAM 必须显示指定 -x, –lock-all-tables：锁定所有表 -l, –lock-tables：锁定备份的表 热备: 支持 INNODB –single-transaction：启动一个大的单一事务实现备份 选库: -A, –all-databases -B, –databases db_name1 db_name2 …：备份指定的数据库 -C, –compress：压缩传输； 其他: -E, –events：备份指定库的事件调度器； -R, –routines：备份存储过程和存储函数； –triggers：备份触发器 --master-data[=#]: 记录备份开始时刻，二进制文件所处的文件和位置，可选值为 =1：记录CHANGE MASTER TO语句，此语句未被注释； =2：记录CHANGE MASTER TO语句，为注释语句，CHANGE MASTER TO 只对从服务有效，通常应该注释掉 –flush-logs, -F：锁定表之后执行flush logs命令，这样二进制日志就会滚动到新的文件，在利用二进制日志进行回滚时就不用进行日志截取了 1234567891011121314# mysqsldump + binlog 做备份的示例# 1. mysqldump 全量备份mysqldump -uroot -p --single-transaction -R -E --triggers --master-data=2 --flush-logs --databases tsong &gt; /home/tao/tsong-fullback-$(date +%F).sql# 2. 将 binlog 生成 sql 语句, 对应的二进制文件已经记录在 mysqldump 内的CHANGE MASTER TO 语句内sudo mysqlbinlog /data/master-log.000004 &gt; binlog.sql# 3. 启动新的 mairadb 服务器，执行上述两个 sql 脚本mysql&gt; SET SESSION sql_log_bin=0; # 避免重放的 sql 语句记录到新的二进制文件中mysql&gt; SOURCE /path/from/somefile.sql; # 重放上述两个 sql 脚本mysql&gt; SET SESSION sql_log_bin=1;# 4. 对恢复的数据库重新做一次全量备份mysqldump -uroot -p --single-transaction -R -E --triggers --master-data=2 --flush-logs --databases tsong &gt; /home/tao/tsong-fullback-$(date +%F).sql 2.2 Xtrabackup在MariaDB10.3.x及以上版本的redo日志格式发生了更改，因此已经无法使用 Xtrabackup，需要使用 Mariadb 提供的 mariabackup，两个命令使用的方式类似，我们将主要介绍 mariabackup 的使用12345&gt; yum install MariaDB-backup&gt; rpm -ql MariaDB-backup/usr/bin/mariabackup # 等同于 xtrabackup /usr/bin/mariadb-backup/usr/bin/mbstream Mariabackup 恢复过程1完全备份 --&gt; 增量备份1 ---&gt; 增量备份2 如上所示，在第一次完整备份之后，mariabackup 增加了两次增量备份。在进行恢复时，mariabackup 并不是将完全备份，增量备份1，增量备份2 依次拿到 mairadb 上进行重放，而是先将增量备份1 合并到完全备份，再将增量备份2 合并到完全备份，最后使用完成完整备份进行数据恢复。因此 mariabackup 有以下几个与阶段参数: –prepare: 将增量备份合并到完全备份，合并前完全备份也要执行 –prepare –aply-log-only: 对Innodb 事务日志中，已提交日志(redo log)进行合并 1234567891011# 第一步：准备全备数据mariabackup --prepare --target-dir /backup/fullbackup/ --user root --password centos --apply-log-only# 第二步：将增量备份与全备合并mariabackup --prepare --target-dir /backup/fullbackup/ \ --user root --password centos \ --incremental-dir /backup/inc1 --apply-log-only第三步：还原(保证data目录为空)mariabackup --copy-back --target-dir /backup/fullbackup/ \ --user root --password centos 2.3 备份注意事项:备份注意事项 将数据和二进制文件放置于不同的设备；二进制日志也应该周期性地备份； 将数据和备份分开存放，建议不在同一设备、同一主机、同一机房、同一地域； 每次灾难恢复后都应该立即做一次完全备份； 备份后的数据应该周期性地做还原测试； 从备份中恢复应该遵循的步骤： 停止MySQL服务器； 记录服务器配置和文件权限； 将备份恢复到MySQL数据目录；此步骤依赖具体的备份工具； 改变配置和文件权限； 以限制方式启动MySQL服务器：比如通过网络访问；skip-networking socket=/tmp/mysql-recovery.sock 载入额外的逻辑备份；而检查和重放二进制日志； 检查已经还原的数据； 以完全访问模式重启服务器；]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 MYSQL 日志]]></title>
    <url>%2F2019%2F10%2F09%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F4_%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[Mariadb 日志 1. Mariadb 日志Mariadb 日志类别: 查询日志： 慢查询日志：查询执行时长超过指定时长的查询操作所记录日志 错误日志： Mariadb 错误信息 主从复制，从服务复制线程的启动和关闭信息 事件调度器被调度执行的信息 二进制日志：binlog，记录能改变或能潜在改变 Mariadb 数据的 SQL 语句 中继日志：relay_log，从服务器从主服务器通过过来的二进制日志 事务日志：Innodb 事务日志包括 REDO LOG, UNDO LOG 1.1 查询日志 作用: 记录查询语句，一般不用启用 配置: general_log = {ON|OFF}: 是否启用查询日志 log_output = {TABLE|FILE|NONE}: 查询语句的输出位置 TABLE: 输出到表 mysql.general_log 中 FILE: 输出到 mariadb 存储目录下的文件中，文件名由 general_log_file 参数指定 None: 不输出，即不开启查询日志 general_log_file = HOSTNAME.log: 当log_output=FILE类型时，日志信息的记录位置，文件名默认为主机名 1.2 慢查询日志： 作用: 查询执行时长超过指定时长的查询操作所记录日志 位置: 受 log_output 参数的影响 =FILE: 保存位置由 slow_query_log_file 参数指定 =TABLE: 保存在表 mysql.slow_log 中 配置: long_query_time: 慢查询判定的时间界限 slow_query_log = {ON|OFF}：是否启用慢查询日志 slow_query_log_file: 慢查询日志文件路径 log_slow_filter: 设置慢查询记录的语句类型，可选值如下，多个值由逗号隔开 admin,filesort,filesort_on_disk full_join,full_scan query_cache,query_cache_miss tmp_table,tmp_table_on_disk log_slow_rate_limit =: 慢日志记录的速率 log_slow_verbosity =: 123456789101112131415161718192021222324252627SELECT @@GLOBAL.long_query_time;+--------------------------+| @@GLOBAL.long_query_time |+--------------------------+| 10.000000 |+--------------------------+show global variables like "slow%";+---------------------+--------------------+| Variable_name | Value |+---------------------+--------------------+| slow_launch_time | 2 || slow_query_log | OFF || slow_query_log_file | localhost-slow.log |+---------------------+--------------------+ show global variables like "log_slow_%";+------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+| Variable_name | Value |+------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+| log_slow_admin_statements | ON || log_slow_disabled_statements | sp || log_slow_filter | admin,filesort,filesort_on_disk,filesort_priority_queue,full_join,full_scan,query_cache,query_cache_miss,tmp_table,tmp_table_on_disk || log_slow_rate_limit | 1 || log_slow_slave_statements | ON || log_slow_verbosity | |+------------------------------+--------------------------------------------------------------------------------------------------------------------------------------+ 1.3 错误日志 内容: mysqld启动和关闭过程中输出的信息； mysqld运行中产生的错误信息； event scheduler运行一个event时产生的日志信息； 在主从复制架构中的从服务器上启动从服务器线程时产生的日志信息； 配置: log_error: OFF|/path/to/somefile，不启用或者记录到指定文件中 log_warnings = {ON|OFF}：是否记录警告信息于错误日志中； 2. 二进制日志2.1 二进制日志配置 作用: 记录能改变或能潜在改变 Mariadb 数据的 SQL 语句 文件的构成： 日志文件：文件名前缀.XXXXX 索引文件：文件名前缀.index，记录当前所有的二进制日志文件名 EVENT: 二进制文件里每个 SQL 语句的记录都称为一个事件 EVENT 配置: binlog_format: STATEMENT: 基于“语句”记录； ROW: 基于“行”记录 MIXED: statement 与 row 的混合模式，由 mariadb 决定采用何种格式 log_bin: OFF|log_path 不启用或者二进制日志的保存路径，只能在服务启动前配置 sql_log_bin = ON: 当前会话产生的修改操作是否记录到二进制日志，ON-记录，OFF-不记录 max_binlog_size: 二进制日志文件的单文件大小上限； max_binlog_cache_size: max_binlog_stmt_cache_size: sync_binlog = [0|+N]: 设定多久个事务提交之后，同步一次二进制日志文件 0: 0表示不同步 +N: 任何正值表示记录 N 个事务提交之后同步一次 123456789101112131415161718192021222324252627# 查看主服务器端处于由mysqld维护状态中的二进制日志文件；SHOW &#123;BINARY | MASTER&#125; LOGS# 查看正在使用的二进制日志的状态SHOW [MASTER|BINARY] STATUS # 显示指定的二进制日志文件中的相关事件SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]# 滚动二进制日志，每次重启 Mairadb 时，也会滚动二进制日志FLUSH LOGSshow global variables like "log_bin";+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | OFF |+---------------+-------+show global variables like "max_bin%";+----------------------------+----------------------+| Variable_name | Value |+----------------------------+----------------------+| max_binlog_cache_size | 18446744073709547520 || max_binlog_size | 1073741824 || max_binlog_stmt_cache_size | 18446744073709547520 |+----------------------------+----------------------+ 2.2 日志记录格式：mysqlbinlog [options] log_file 作用: 查看 mysql 的二进制日志 参数: -j, --start-position=#：从指定的事件位置查看 --stop-position=#：只显示到指定的事件位置 --start-datetime=datetime: --stop-datetime=datetime: datetiem format - YYYY-MM-DD hh:mm:ss 二进制日志的格式 事件的起始位置(at) 事件发生的日期和时间；(140829 15:50:07) 事件发生在服务器的标识（server id） 事件的结束位置：（end_log_pos 19486） 事件的类型：(Query) 事件发生时所在的服务器执行此事件的线程的ID：（thread_id=13） 语句的时间戳与将其写入二进制文件中的时间差：（exec_time=0） 错误代码：（error_code=0) 事件内容：（SET TIMESTAMP=1409298607/!/;GRANT SELECT ON tdb.* TO tuser@localhost） GTID事件专属：事件所属的全局事务的GTID：（GTID 0-1-2） 123456# at 19364#140829 15:50:07 server id 1 end_log_pos 19486 Query thread_id=13 exec_time=0 error_code=0SET TIMESTAMP=1409298607/*!*/;GRANT SELECT ON tdb.* TO tuser@localhost/*!*/;# at 19486 3. 事务日志（innodb存储引擎） 作用: Innodb 用于实现事务的日志 位置: ib_logfileN, 位于数据存储目录下，以组的方式出现 配置: innodb_log_group_home_dir: 事务日志目录 innodb_log_files_in_group: 事务日志组中包含的文件数 12345678910111213141516171819202122232425262728293031323334show variables like "innodb_log%";+-----------------------------+----------+| Variable_name | Value |+-----------------------------+----------+| innodb_log_buffer_size | 16777216 || innodb_log_checksums | ON || innodb_log_compressed_pages | ON || innodb_log_file_size | 50331648 || innodb_log_files_in_group | 2 || innodb_log_group_home_dir | ./ || innodb_log_optimize_ddl | ON || innodb_log_write_ahead_size | 8192 |+-----------------------------+----------+ll /data/总用量 122936-rw-rw----. 1 mysql mysql 24576 3月 10 16:58 aria_log.00000001 # MyISAM 日志-rw-rw----. 1 mysql mysql 52 3月 10 16:58 aria_log_control# 缓存池，存放部分最近的查询记录和索引等，可以通过show variables like 'innodb%pool%'查看相关参数-rw-rw----. 1 mysql mysql 1004 3月 10 16:58 ib_buffer_pool-rw-rw----. 1 mysql mysql 12582912 3月 10 16:58 ibdata1 # Innodb 全局表空间-rw-rw----. 1 mysql mysql 50331648 3月 10 16:58 ib_logfile0 # Innodb 事务日志-rw-rw----. 1 mysql mysql 50331648 3月 10 00:14 ib_logfile1-rw-rw----. 1 mysql mysql 12582912 3月 10 16:58 ibtmp1 # 临时表空间-rw-rw----. 1 mysql mysql 142 3月 10 16:58 localhost.log # 查询日志-rw-rw----. 1 mysql mysql 6 3月 10 16:58 localhost.pid -rw-rw----. 1 mysql mysql 142 3月 10 16:58 localhost-slow.log # 慢查询日志-rw-rw----. 1 mysql mysql 329 3月 10 16:58 master-log.000001 # 二进制日志# # 二进制日志文件索引，存放二进制日志文件列表-rw-rw----. 1 mysql mysql 20 3月 10 16:58 master-log.index -rw-rw----. 1 mysql mysql 0 3月 10 00:27 multi-master.infodrwx------. 2 mysql mysql 4096 3月 10 00:15 mysqldrwx------. 2 mysql mysql 20 3月 10 00:15 performance_schemadrwx------. 2 mysql mysql 94 3月 10 01:35 test 4. 日志相关的服务器参数详解：通用日志选项: log_output={TABLE|FILE|NONE}: 定义一般查询日志和慢查询日志的保存方式，可以是TABLE、FILE、NONE，也可以是TABLE及FILE的组合(用逗号隔开)，默认为TABLE。如果组合中出现了NONE，那么其它设定都将失效，同时，无论是否启用日志功能，也不会记录任何相关的日志信息。作用范围为全局级别，可用于配置文件，属动态变量 慢查询日志: log_slow_queries={YES|NO}: 是否记录慢查询日志。慢查询是指查询的执行时间超出long_query_time参数所设定时长的事件。MySQL 5.6将此参数修改为了slow_query_log。作用范围为全局级别，可用于配置文件，属动态变量 slow_query_log={ON|OFF}: 设定是否启用慢查询日志。0或OFF表示禁用，1或ON表示启用。日志信息的输出位置取决于log_output变量的定义，如果其值为NONE，则即便slow_query_log为ON，也不会记录任何慢查询信息。作用范围为全局级别，可用于选项文件，属动态变量。 slow_query_log_file=/PATH/TO/SOMEFILE: 设定慢查询日志文件的名称。默认为hostname-slow.log，但可以通过–slow_query_log_file选项修改。作用范围为全局级别，可用于选项文件，属动态变量。 sql_log_bin={ON|OFF}: 用于控制二进制日志信息是否记录进日志文件。默认为ON，表示启用记录功能。用户可以在会话级别修改此变量的值，但其必须具有SUPER权限。作用范围为全局和会话级别，属动态变量。 sql_log_off={ON|OFF}: 用于控制是否禁止将一般查询日志类信息记录进查询日志文件。默认为OFF，表示不禁止记录功能。用户可以在会话级别修改此变量的值，但其必须具有SUPER权限。作用范围为全局和会话级别，属动态变量。 sync_binlog=#: 设定多久同步一次二进制日志至磁盘文件中，0表示不同步，任何正数值都表示对二进制每多少次写操作之后同步一次。当autocommit的值为1时，每条语句的执行都会引起二进制日志同步，否则，每个事务的提交会引起二进制日志同步。 二进制日志: log-bin={YES|NO}: 是否启用二进制日志，如果为mysqld设定了–log-bin选项，则其值为ON，否则则为OFF。其仅用于显示是否启用了二进制日志，并不反应log-bin的设定值。作用范围为全局级别，属非动态变量 binlog-format={ROW|STATEMENT|MIXED}: 指定二进制日志的类型，默认为STATEMENT。如果设定了二进制日志的格式，却没有启用二进制日志，则MySQL启动时会产生警告日志信息并记录于错误日志中。作用范围为全局或会话，可用于配置文件，且属于动态变量 expire_logs_days={0..99}: 设定二进制日志的过期天数，超出此天数的二进制日志文件将被自动删除。默认为0，表示不启用过期自动删除功能。如果启用此功能，自动删除工作通常发生在MySQL启动时或FLUSH日志时。作用范围为全局，可用于配置文件，属动态变量 log_query_not_using_indexes={ON|OFF}: 设定是否将没有使用索引的查询操作记录到慢查询日志。作用范围为全局级别，可用于配置文件，属动态变量。 log_bin_trust_function_creators={TRUE|FALSE}: 此参数仅在启用二进制日志时有效，用于控制创建存储函数时如果会导致不安全的事件记录二进制日志条件下是否禁止创建存储函数。默认值为0，表示除非用户除了CREATE ROUTING或ALTER ROUTINE权限外还有SUPER权限，否则将禁止创建或修改存储函数，同时，还要求在创建函数时必需为之使用DETERMINISTIC属性，再不然就是附带READS SQL DATA或NO SQL属性。设置其值为1时则不启用这些限制。作用范围为全局级别，可用于配置文件，属动态变量 long_query_time=#: 设定区别慢查询与一般查询的语句执行时间长度。这里的语句执行时长为实际的执行时间，而非在CPU上的执行时长，因此，负载较重的服务器上更容易产生慢查询。其最小值为0，默认值为10，单位是秒钟。它也支持毫秒级的解析度。作用范围为全局或会话级别，可用于配置文件，属动态变量。 max_binlog_cache_size: {4096 .. 18446744073709547520} 二进定日志缓存空间大小，5.5.9及以后的版本仅应用于事务缓存，其上限由max_binlog_stmt_cache_size决定。作用范围为全局级别，可用于配置文件，属动态变量。 max_binlog_size={4096 .. 1073741824}: 设定二进制日志文件上限，单位为字节，最小值为4K，最大值为1G，默认为1G。某事务所产生的日志信息只能写入一个二进制日志文件，因此，实际上的二进制日志文件可能大于这个指定的上限。作用范围为全局级别，可用于配置文件，属动态变量。 查询日志: general_log={ON|OFF}: 设定是否启用查询日志，默认值为取决于在启动mysqld时是否使用了–general_log选项。如若启用此项，其输出位置则由–log_output选项进行定义，如果log_output的值设定为NONE，即使用启用查询日志，其也不会记录任何日志信息。作用范围为全局，可用于配置文件，属动态变量| general_log_file=FILE_NAME: 查询日志的日志文件名称，默认为“hostname.log”。作用范围为全局，可用于配置文件，属动态变量| log={YES|NO}: 是否启用记录所有语句的日志信息于一般查询日志(general query log)中，默认通常为OFF。MySQL 5.6已经弃用此选项 错误日志: log_error=/PATH/TO/ERROR_LOG_FILENAME: 定义错误日志文件。作用范围为全局或会话级别，可用于配置文件，属非动态变量 log_warnings=#: 设定是否将警告信息记录进错误日志。默认设定为1，表示启用；可以将其设置为0以禁用；而其值为大于1的数值时表示将新发起连接时产生的“失败的连接”和“拒绝访问”类的错误信息也记录进错误日志 中继日志: log_slave_updates: 用于设定复制场景中的从服务器是否将从主服务器收到的更新操作记录进本机的二进制日志中。本参数设定的生效需要在从服务器上启用二进制日志功能。 max_relay_log_size={4096..1073741824}: 设定从服务器上中继日志的体积上限，到达此限度时其会自动进行中继日志滚动。此参数值为0时，mysqld将使用max_binlog_size参数同时为二进制日志和中继日志设定日志文件体积上限。作用范围为全局级别，可用于配置文件，属动态变量。 relay_log=file_name: 设定中继日志的文件名称，默认为host_name-relay-bin。也可以使用绝对路径，以指定非数据目录来存储中继日志。作用范围为全局级别，可用于选项文件，属非动态变量。 relay_log_index=file_name: 设定中继日志的索引文件名，默认为为数据目录中的host_name-relay-bin.index。作用范围为全局级别，可用于选项文件，属非动态变量。 relay-log-info-file=file_name: 设定中继服务用于记录中继信息的文件，默认为数据目录中的relay-log.info。作用范围为全局级别，可用于选项文件，属非动态变量。 relay_log_purge={ON|OFF}: 设定对不再需要的中继日志是否自动进行清理。默认值为ON。作用范围为全局级别，可用于选项文件，属动态变量。 relay_log_space_limit=#: 设定用于存储所有中继日志文件的可用空间大小。默认为0，表示不限定。最大值取决于系统平台位数。作用范围为全局级别，可用于选项文件，属非动态变量。 Innodb事务日志: innodb_log_buffer_size: ={262144 .. 4294967295}设定InnoDB用于辅助完成日志文件写操作的日志缓冲区大小，单位是字节，默认为8MB。较大的事务可以借助于更大的日志缓冲区来避免在事务完成之前将日志缓冲区的数据写入日志文件，以减少I/O操作进而提升系统性能。因此，在有着较大事务的应用场景中，建议为此变量设定一个更大的值。作用范围为全局级别，可用于选项文件，属非动态变量。 innodb_log_file_size:={108576 .. 4294967295}设定日志组中每个日志文件的大小，单位是字节，默认值是5MB。较为明智的取值范围是从1MB到缓存池体积的1/n，其中n表示日志组中日志文件的个数。日志文件越大，在缓存池中需要执行的检查点刷写操作就越少，这意味着所需的I/O操作也就越少，然而这也会导致较慢的故障恢复速度。作用范围为全局级别，可用于选项文件，属非动态变量。 innodb_log_files_in_group={2 .. 100}: 设定日志组中日志文件的个数。InnoDB以循环的方式使用这些日志文件。默认值为2。作用范围为全局级别，可用于选项文件，属非动态变量。 innodb_log_group_home_dir=/PATH/TO/DIR 设定InnoDB重做日志文件的存储目录。在缺省使用InnoDB日志相关的所有变量时，其默认会在数据目录中创建两个大小为5MB的名为ib_logfile0和ib_logfile1的日志文件。作用范围为全局级别，可用于选项文件，属非动态变量。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 MARIADB 基础使用]]></title>
    <url>%2F2019%2F10%2F08%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F3_mysql%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[mariadb 基础使用 1.Mariadb 架构图2. Mariadb 存储引擎123456789101112# 查看支持的所有存储引擎&gt; show engines# 显示表状态信息&gt; use mysql&gt; show table status where engine="Aria" # 显示 Innodb 引擎的状态信息&gt; show engine innodb status \G# 显示 myisam 引擎的状态信息&gt; show engine aria status; 2.1 Innodb 存储引擎特性: 适用于处理大量短事务，但不适用于处理长事务 基于 MVCC 并发访问控制，支持四种隔离级别 使用聚集索引，支持自适应 hash 索引，左前缀索引 锁粒度: 行锁，间隙锁 支持热备份 Innodb 表空间(tablespace)1234567891011121314151617181920ll /data/总用量 122920-rw-rw----. 1 mysql mysql 24576 3月 10 00:31 aria_log.00000001-rw-rw----. 1 mysql mysql 52 3月 10 00:17 aria_log_control-rw-rw----. 1 mysql mysql 888 3月 10 00:17 ib_buffer_pool-rw-rw----. 1 mysql mysql 12582912 3月 10 00:17 ibdata1-rw-rw----. 1 mysql mysql 50331648 3月 10 00:27 ib_logfile0 # 事务日志，通常以组的形式出现-rw-rw----. 1 mysql mysql 50331648 3月 10 00:14 ib_logfile1 # 事务日志-rw-rw----. 1 mysql mysql 12582912 3月 10 00:27 ibtmp1-rw-rw----. 1 mysql mysql 6 3月 10 00:27 localhost.pid-rw-rw----. 1 mysql mysql 0 3月 10 00:27 multi-master.infodrwx------. 2 mysql mysql 4096 3月 10 00:15 mysqldrwx------. 2 mysql mysql 20 3月 10 00:15 performance_schemadrwx------. 2 mysql mysql 20 3月 10 00:15 test ll /data/test/总用量 120-rw-rw----. 1 mysql mysql 65 3月 10 00:15 db.opt-rw-rw----. 1 mysql mysql 1822 3月 10 00:54 test.frm-rw-rw----. 1 mysql mysql 114688 3月 10 00:54 test.ibd Innodb 的数据存储在表空间文件中，依据 innodb_file_per_table 是否启用分为两种不同的保存方式。 innodb_file_per_table=off 位置: 所有数据库的所有存储引擎为Innodb的表使用同一个表空间文件 datadir/ibdata[N]: 共用的表空间文件，用于保存所有Innodb表的数据和索引 数据库目录/db_name.frm: 表结构定义保存在各个数据库目录下 特性: 不支持单表导入等高级特性 innodb_file_per_table=on 位置: 每表使用单独的表空间文件，位于各个数据库目录下 db_name.ibd: 表单独的表空间文件，用于存储单独表的数据和索引 db_name.frm: 用于存储表结构定义 2.2 Aria(MyISAM)123456ll总用量 140-rw-rw----. 1 mysql mysql 65 3月 10 00:15 db.opt-rw-rw----. 1 mysql mysql 1820 3月 10 01:35 t1.frm-rw-rw----. 1 mysql mysql 8192 3月 10 01:35 t1.MAD-rw-rw----. 1 mysql mysql 8192 3月 10 01:35 t1.MAI 存储: 每表有三个文件，保存在对应的数据库目录中 db_name.frm: 表结构定义文件 db_name.MAD: 数据文件 db_name.MAI: 索引文件 3.Mariadb 锁策略Mariadb 的锁分为 Sever 级别锁: 又称为显示锁，可在 SQL 语句中自行决定是否加锁 存储引擎级别锁: 存储引擎为了实现并发访问控制而自行施加的锁 3.1 显示锁的使用1234567891011# 锁定单表LOCK TABLE tb_name [READ|WRITER]UNLOCK TABLES # 锁定所有数据库所有表FLUSH TABLES WITH [READ|WRITER] LOCKUNLOCK TABLES# 行锁SELECT CLUASE FOR UPDATE SELECT CLUASE LOCK IN SHARE MODE 4.用户与权限4.1 权限类别Mariadb 的权限分为以下几种类别 库，表级别的权限 ALTER, CREATE, DROP CREATE VIEW, SHOW VIEW INDEX GRANT OPTION：能够把自己获得的权限赠经其他用户一个副本； 字段级别: [SELECT, INSERT, UPDATE](col1,col2,…)DELETE 管理类: CREATE TEMPORARY TABLES CREATE USER FILE SUPER SHOW DATABASES RELOAD SHUTDOWN REPLICATION SLAVE REPLICATION CLIENT LOCK TABLES PROCESS 程序类: [CREATE, ALTER, DROP, EXCUTE] * [FUNCTION, PROCEDURE, TRIGGER] 所有权限: ALL PRIVILEGES, ALL 4.2 权限保存位置所有的授权都保存在 mariadb 的元数据数据库 mysql 的如下表中: db, user columns_priv tables_priv procs_priv proxies_priv global_priv 4.3 账号管理123456789101112131415# 创建用户：CREATE USERCREATE USER 'USERNAME'@'HOST' [IDENTIFIED BY 'password']；# 查看用户获得的授权：SHOW GRANTS FORSHOW GRANTS FOR 'USERNAME'@'HOST'# 用户重命名：RENAME USERRENAME USER old_user_name TO new_user_name# 删除用户DROP USER 'USERNAME'@'HOST'# 修改密码：SET PASSWORD FOR 'bob'@'%.loc.gov' = PASSWORD('newpass');UPDATE mysql.user SET password=PASSWORD('your_password') WHERE clause; 修改密码还可以使用 mysqladmin命令: mysqladmin password &quot;new_password&quot; -uroot -h -p 4.4 忘记管理员密码1234567891011systemctl stop mariadb# 1. 为 mariadb 添加 --skip-grant-tables --skip-networking 参数vim /usr/lib/systemd/system/mariadb.service # 在 ExecStart 后添加systemctl start mariadb# 2. 登录mariadb 并使用 UPDATE 命令修改管理员密码update mysql.user set password=PASSWORD("1234") where user="root";# 3. 关闭mysqld进程，移除上述两个选项，重启mysqld; 4.5 授权授权: GRANT priv_type[,...] ON [{table|function|procedure}] db.{table|routine} TO &#39;USERNAME&#39;@&#39;HOST&#39; [IDENTIFIED BY &#39;password&#39;] [REQUIRE SSL] [WITH with_option] 查看授权:SHOW GRANTS [FOR &quot;user&quot;@&quot;host&quot;] 收回授权: REVOKE priv_type[,...] ON [{table|function|procedure}] db.{table|routine} FROM user [, user] 7.查询缓存查询缓存： 如何判断是否命中：通过查询语句的哈希值判断：哈希值考虑的因素包括查询本身、要查询的数据库、客户端使用协议版本。查询语句任何字符上的不同，都会导致缓存不能命中； 哪此查询可能不会被缓存: 查询中包含UDF、存储函数、用户自定义变量、临时表、mysql库中系统表、或者包含列级权限的表、有着不确定值的函数(Now()); 7.1 查询缓存相关的服务器变量 query_cache_min_res_unit: 查询缓存中内存块的最小分配单位； 较小值会减少浪费，但会导致更频繁的内存分配操作； 较大值会带来浪费，会导致碎片过多； query_cache_limit：能够缓存的最大查询结果，对于有着较大结果的查询语句，建议在SELECT中使用SQL_NO_CACHE query_cache_size：查询缓存总共可用的内存空间；单位是字节，必须是1024的整数倍； query_cache_type: 可选值: OFF: 不启用，显示指定 SQL_CACHE 也不会缓存 ON: 启用，可以使用 SQL_NO_CACHE 显示指定不缓存查询结果 DEMAND: 按需启用，即可以使用 SQL_CACHE 显示指定缓存查询结果 query_cache_wlock_invalidate：如果某表被其它的连接锁定，是否仍然可以从查询缓存中返回结果；默认值为OFF，表示可以在表被其它连接锁定的场景中继续从缓存返回数据；ON则表示不允许； 7.2 查询相关的状态变量缓存命中率的评估：Qcache_hits/Com_select 1234567891011121314151617181920&gt; SHOW GLOBAL STATUS LIKE 'Qcache%';+-------------------------+----------+| Variable_name | Value |+-------------------------+----------+| Qcache_free_blocks | 1 || Qcache_free_memory | 16759688 | # 分配未使用的缓存块| Qcache_hits | 0 | # 缓存命中次数| Qcache_inserts | 0 | # 已经插入的缓存条目| Qcache_lowmem_prunes | 0 | # 因为内存太小，而被动失效缓存| Qcache_not_cached | 0 || Qcache_queries_in_cache | 0 | # 缓存的查询语句数| Qcache_total_blocks | 1 | # 已经分配的缓存块+-------------------------+----------+&gt; show global status like "Com_select";+---------------+-------+| Variable_name | Value |+---------------+-------+| Com_select | 26 | # 查询次数+---------------+-------+ 8.索引索引优点： - 索引可以降低服务需要扫描的数据量，减少了IO次数； - 索引可以帮助服务器避免排序和使用临时表； - 索引可以帮助将随机I/O转为顺序I/O； 高性能索引策略： - 独立使用列，尽量避免其参与运算； - 左前缀索引：索引构建于字段的左侧的多少个字符，要通过索引选择性来评估 - 索引选择性：不重复的索引值和数据表的记录总数的比值； - 多列索引：AND操作时更适合使用多列索引； - 选择合适的索引列次序：将选择性最高放左侧； 12# 查看表的索引&gt; SHOW INDEX FROM tb_name 8.1 B+ TreeB+ Tree索引： 特点: 顺序存储，每一个叶子节点到根结点的距离是相同的；左前缀索引，适合查询范围类的数据； 适用: 可以使用B-Tree索引的查询类型：全键值、键值范围或键前缀查找； 全值匹配：精确某个值, “Jinjiao King”； 匹配最左前缀：只精确匹配起头部分，”Jin%” 匹配范围值： 精确匹配某一列并范围匹配另一列： 只访问索引的查询 不适用: 如果不从最左列开始，索引无效； (Age,Name) 不能跳过索引中的列；(StuID,Name,Age) 如果查询中某个列是为范围查询，那么其右侧的列都无法再使用索引优化查询；(StuID,Name) 8.2 Hash 索引Hash索引： 特点: 基于哈希表实现，特别适用于精确匹配索引中的所有列； 注意：只有Memory存储引擎支持显式hash索引； 适用： 只支持等值比较查询，包括=, IN(), &lt;=&gt;; 不适合: 存储的非为值的顺序，因此，不适用于顺序查询； 不支持模糊匹配； 8.3 EXPLAINEXPLAIN SELECT clause 作用: 获取查询执行计划信息，用来查看查询优化器如何执行查询； 输出： id: 当前查询语句中，每个SELECT语句的编号； select_type： 简单查询为SIMPLE 复杂查询： SUBQUERY: 简单子查询； DERIVED: 用于FROM中的子查询； PRIMARY: 联合查询中的第一个查询 UNION: 联合查询中的第一个查询之后的其他查询 UNION RESULT: 联合查询生成的临时表 注意：UNION查询的分析结果会出现一外额外匿名临时表； table：SELECT语句关联到的表； type：关联类型，或访问类型，即MySQL决定的如何去查询表中的行的方式； ALL: 全表扫描； index：根据索引的次序进行全表扫描；如果在Extra列出现“Using index”表示了使用覆盖索引，而非全表扫描； range：有范围限制的根据索引实现范围扫描；扫描位置始于索引中的某一点，结束于另一点； ref: 根据索引返回表中匹配某单个值的所有行； eq_ref: 根据索引返回表中匹配某单个值的单一行，仅返回一行； const, system: 与常量比较，直接返回单个行； possible_keys：查询可能会用到的索引； key: 查询中使用了的索引； key_len: 在索引使用的字节数； ref: 在利用key字段所表示的索引完成查询时所有的列或某常量值； rows：MySQL估计为找所有的目标行而需要读取的行数； Extra：额外信息 Using index condition：使用索引进行条件过滤 Using index：MySQL将会使用覆盖索引，以避免访问表； Using where：MySQL服务器将在存储引擎检索后，再进行一次过滤； Using temporary：MySQL对结果排序时会使用临时表； Using filesort：对结果使用一个外部索引排序；]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 MYSQL 常用服务端参数]]></title>
    <url>%2F2019%2F10%2F07%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F2_%E5%B8%B8%E7%94%A8%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[mariadb 常用服务端参数 1. mariadb 特性参数1.1 SQL_MODESQL_MODE 作用: 设置 sql 模式，sql 模式会影响值溢出等行为的处理方式 1.2 QUERY_CACHE_TYPEQUERY_CACHE_TYPE 作用: 是否启用查询缓存 可选值: OFF: 不启用，显示指定 SQL_CACHE 也不会缓存 ON: 启用，可以使用 SQL_NO_CACHE 显示指定不缓存查询结果 DEMAND: 按需启用，即可以使用 SQL_CACHE 显示指定缓存查询结果 1.3 事务隔离级别设置TX_ISOLATION 作用: 设置事务的隔离级别 可选值: REPEATABLE-READ: 可重复度 READ-UNCOMMITTED: 读未提交 READ-COMMITTED: 读提交 SERIALIZABLE: 串行化 事务日志配置: innodb_log_files_in_group: 一个事务日志组中包含几个文件 innodb_log_group_home_dir：事务日志所在的目录 innodb_log_file_size：事务日志的大小 12345678910111213141516171819202122232425select @@session.tx_isolation;show global variables like "innodb%log%";+----------------------------------+-----------+| Variable_name | Value |+----------------------------------+-----------+| innodb_encrypt_log | OFF || innodb_flush_log_at_timeout | 1 || innodb_flush_log_at_trx_commit | 1 || innodb_locks_unsafe_for_binlog | OFF || innodb_log_buffer_size | 16777216 || innodb_log_checksums | ON || innodb_log_compressed_pages | ON || innodb_log_file_size | 50331648 || innodb_log_files_in_group | 2 || innodb_log_group_home_dir | ./ || innodb_log_optimize_ddl | ON || innodb_log_write_ahead_size | 8192 || innodb_max_undo_log_size | 10485760 || innodb_online_alter_log_max_size | 134217728 || innodb_scrub_log | OFF || innodb_scrub_log_speed | 256 || innodb_undo_log_truncate | OFF || innodb_undo_logs | 128 |+----------------------------------+-----------+ 2. 网络连接2.1 WAIT_TIMEOUTWAIT_TIMEOUT: 作用: 空闲连接的最大连接时长 连接管理: 连接分为短连接，长连接，长时间空闲的链接连接称为空闲连接 空闲连接的保持时长由 wait_timeout 参数配置，默认为 8 小时，超时后连接就会自动断开 全部使用长连接后，有些时候 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了，解决办法有如下两个: 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 MySQL&gt;=5.7，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 2.2 max_connectionsmax_connections 参数，用来控制一个 MySQL 实例同时存在的连接数的上限，超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。 2.3 net_buffer_lengthnet_buffer_length 作用: 设置用于向客户端发送数据的，网络缓冲区大小(net_buffer)。mysql 会在 net_buffer 写满之后调用网络接口发送出去。 3. 日志redo log innodb_flush_log_at_trx_commit: 作用: 事务提交之后多久更新 redo log 可选值: 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ; 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘； 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache 建议: 设置为 1 表示每次事务的 redo log 都直接持久化到磁盘。建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失 innodb_log_buffer_size: 设置 redo log buffer 的大小 bin log sync_binlog: 作用: 表示事务提交之后多久更新 bin log 可选值: sync_binlog=1 的时候，表示每次提交事务都会执行 fsync； sync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync 建议: 设置为 1 表示每次事务的 binlog 都持久化到磁盘。建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失 binlog_cache_size 作用: 用于控制单个线程内 binlog cache 所占内存的大小 binlog 组提交 binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync; binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync binlog_format=row: 设置binlog 日志格式 binlog_row_image=FULL change buffer innodb_change_buffer_max_size: 作用: change buffer 用的是 buffer pool 里的内存，此参数用于控制 changer buffer 能够占用 buffer pool 最大百分比 示例: =50 表示 change buffer 的大小最多只能占用 buffer pool 的 50%。 刷脏页 innodb_io_capacity: 设置磁盘的 IO 能力 innodb_max_dirty_pages_pct: 脏页比例的上线 innodb_flush_neighbors: 刷脏页时是否刷新邻居脏页 回滚日志 innodb_undo_directory[=/opt/mysql/undo] 作用: undo log 独立表空间的相对或绝对路径。 默认目录为innodb默认创建它的其他日志文件的目录 innodb_undo_logs[=128] 作用: 定义在一个事务中innodb使用的系统表空间中回滚段的个数 如果观察到同回滚日志有关的互斥争用，可以调整这个参数以优化性能。 该变量可以动态调整，但是物理上的回滚段不会减少，只是会控制用到的回滚段的个数 innodb_undo_tablespaces[=4] 作用: 用于设定创建的undo表空间的个数，在mysql_install_db时初始化后，就再也不能被改动了 可选值: 0，表示不独立设置undo的tablespace，默认记录到ibdata中 &gt;0，在undo目录下创建这么多个undo文件，每个文件的默认大小为10M MySQL IO 性能优化如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？ 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。 不建议把 innodb_flush_log_at_trx_commit 设置成 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样做 MySQL 异常重启时就不会丢数据了，相比之下风险会更小。 4. innodbinnodb_file_per_table=off 位置: 所有数据库的所有存储引擎为Innodb的表使用同一个表空间文件 datadir/ibdata[N]: 共用的表空间文件，用于保存所有Innodb表的数据和索引 数据库目录/db_name.frm: 表结构定义保存在各个数据库目录下 特性: 不支持单表导入等高级特性 innodb_file_per_table=on 位置: 每表使用单独的表空间文件，位于各个数据库目录下 db_name.ibd: 表单独的表空间文件，用于存储单独表的数据和索引 db_name.frm: 用于存储表结构定义 innodb_thread_concurrency: 作用: 控制 InnoDB 的并发线程上限 默认值: 0，表示不限制并发线程数量。但是，不限制并发线程数肯定是不行的。因为，一个机器的 CPU 核数有限，线程全冲进来，上下文切换的成本就会太高。 通常情况下，我们建议把 innodb_thread_concurrency 设置为 64~128 之间的值。 innodb_buffer_pool_size: 作用: 设置 InnoDB Buffer Pool 的大小， 建议: 一般建议设置成可用物理内存的 60%~80% innodb_old_blocks_time: 作用: innodb LRU 缓存淘汰算法相关 5. 锁 innodb_lock_wait_timeout: 设置锁等待超时时长 innodb_deadlock_detect: 开启死锁检测 6. 索引innodb_stats_persistent 作用: 设置Innodb 索引的统计方式 方法: InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数 当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计 可选值: =ON: 表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10 =OFF: 表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16 7. 排序 sort_buffer_size: 作用: MySQL 为每个线程分配的用以排序的内存（sort_buffer）的大小 如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成 如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。 max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。单行的长度超过这个值，就会使用 rowid 算法 joinjoin_buffer_size: 作用: 设置 join_buffer 的大小，默认值是 256k。 read_rnd_buffer_size 作用: 设置 read_rnd_buffer 的大小是，read_rnd_buffer 是MRR 优化中，用于存放 id 的buffer 大小 8. 内存临时表 tmp_table_size: 作用: 配置内存临时表的大小，默认值是 16M 如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。 internal_tmp_disk_storage_engine 作用: 设置磁盘临时表使用的引擎 默认: InnoDB 9. 主从复制slave_parallel_workers: 作用:主从复制中用于执行 binlog 的线程数 把这个值设置为 8~16 之间最好（32 核物理机的情况），毕竟备库还有可能要提供读查询，不能把 CPU 都吃光了。 slave-parallel-type: 作用: 设置控制并行复制策略 可选值: 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略； 配置为 LOGICAL_CLOCK，表示利用组提交策略进行并行复制 binlog-transaction-dependency-tracking: 作用: MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。 此参数用于控制是否启用这个策略 可选值: COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。 WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。 WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。 注意: 对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。 9.1 GTIDgtid_mode=on 和 enforce_gtid_consistency=on： 作用: 使用 GTID 模式进行主从同步复制的位点判断 在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值。 gtid_next=automatic gtid_next 是一个指定的 GTID 的值 gtid_next=automatic 代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’; 把这个 GTID 加入本实例的 GTID 集合 如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next=’current_gtid’指定为 current_gtid，那么就有两种可能： 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略； 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1 怎么能够让 MySQL 在执行事务后，返回包中带上 GTID 呢？你只需要将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值即可。 10 自增值auto_increment_offset 和 auto_increment_increment 分别用来表示自增的初始值和步长，默认值都是 1。 10.1 自增锁的优化史自增 id 锁并不是一个事务锁，而是每次申请完就马上释放，以便允许别的事务再申请。接下来，我们先看一下自增锁设计的历史: 在 MySQL 5.0 版本的时候，自增锁的范围是语句级别。也就是说，如果一个语句申请了一个表自增锁，这个锁会等语句执行结束以后才释放。显然，这样设计会影响并发度。 MySQL 5.1.22 版本引入了一个新策略，新增参数 innodb_autoinc_lock_mode，默认值是 1。 =0 时，表示采用之前 MySQL 5.0 版本的策略 =1 时: 普通 insert 语句，自增锁在申请之后就马上释放； 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放； =2 时，所有的申请自增主键的动作都是申请后就释放锁。 那么，为什么默认设置下，insert … select 要使用语句级的锁？为什么这个参数的默认值不是 2？答案是，这么设计还是为了数据的一致性。在生产上，尤其是有 insert … select 这种批量插入数据的场景时，从并发插入数据性能的角度考虑，我建议你这样设置：innodb_autoinc_lock_mode=2 ，并且 binlog_format=row. 这样做，既能提升并发性，又不会出现数据一致性问题。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 MYSQL 安装配置]]></title>
    <url>%2F2019%2F10%2F06%2Fmysql%2F%E9%A9%AC%E5%93%A5_MySQL%2F1_mysql%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mariadb 安装配置 1. mariadb 简介自从 mysql 被 Oracle 收购之后，由于担心版权问题，mysql 的创始人就新建了另一开源分支 mariadb，在 Centos6 中默认安装的是 mysql，而在 Centos7 中默认安装的已经是 mariadb。mariadb 跟 mysql 底层的基础特性是类似的，但是高级特性有很大不同，彼此支持的高级功能也不相同。除了 mariadb，mysql还有很多二次发行版本，比如Percona，AllSQL(阿里的mysql 发行版)以及，TIDB mysql 与 mariadb 的官网分别是： www.mysql.com MariaDB: www.mariadb.org 1.1 mariadb 特性mariadb 有两个比较重要的特性，一个是它是一个单进程多线程程序，另一个是支持插件式存储引擎，即存储管理器有多种实现版本，彼此间的功能和特性可能略有区别；用户可根据需要灵活选择。存储引擎也称为“表类型”。常见的存储引擎就是 MyISAM:不支持事务和表级锁，奔溃后不保证安全恢复； InnoDB: 支持事务，行级锁，外键和热备份； MyISAM 在 mariadb 中被扩展为 Aria，支持安全恢复, InnoDB 在 Mariadb 中的开源实现为 XtraDB。在 mysql 的客户端中输入 show engines 即可查看 mariadb 支持的所有存储引擎。 123456789101112131415MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| CSV | YES | CSV storage engine | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ 1.2 MariaDB程序的组成mariadb 是 C/S 架构的服务，其命令分为服务器端和客户端两个部分 C：Client mysql：CLI交互式客户端程序； mysqldump：备份工具； mysqladmin：管理工具； mysqlbinlog： … S：Server mysqld：默认的 mariadb 启动的守护进程 mysqld_safe：mariadb 线程安全版本，通常在线上环境安装的是此服务而不是 mysqld； mysqld_multi：用于在单主机上运行多 mariadb 实例的服务 msyql 服务器可监听在两种套接字上 IPV4/6 的 tcp 的 3306 端口上，支持远程通信 Unix Sock，监听在 socket 文件上，仅支持本地通信，套接子文件通常位于 /var/lib/mysql/mysql.sock或 /tmp/mysql.sock 由配置文件指定。 12ll /var/lib/mysql/mysql.socksrwxrwxrwx. 1 mysql mysql 0 8月 21 11:10 /var/lib/mysql/mysql.sock 2. MariaDB 安装与其他软件一样，Mariadb 常见的安装方式有如下三种: rpm包；由OS的发行商提供，或从程序官方直接下载 源码包编译安装: 编译安装，除非需要定制功能，否则一般不推荐编译安装 通用二进制格式的程序包: 展开至特定路径，并经过简单配置后即可使用，这种方式便于部署，无需解决环境依赖 通常情况下，为了便于自动化安装配置，我们都会以 rpm 包的方式进行安装，Centos7 中安装 mariadb 的命令如下： 1234yum install mariadb-server# 如果修改了mysql 默认保存数据的存储目录 datadir，需要重新执行 mysql_install_dbmysql_install_db --user=mysql --datadir=/data 2.1 初始化配置mysql的用户账号由两部分组成：&#39;USERNAME&#39;@&#39;HOST&#39;; HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务.HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 1234vim /etc/my.cnf # 添加三个选项：datadir = /mydata/datainnodb_file_per_table = ONskip_name_resolve = ON 2.2 mysql 安全初始化默认安装的情况下 mysql root 帐户是没有密码的，可通过 mysql 提供的安全初始化脚本，快速进行安全初始化。1234567# 查看mysql用户及其密码mysql&gt; use mysql;&gt; select user,host,password from user;# 运行脚本安全初始化脚本/user/local/mysql/bin/mysql_secure_installation 3. Mariadb 配置3.1 配置文件格式mysql 的配置文件是 ini 风格的配置文件；客户端和服务器端的多个程序可通过一个配置文件进行配置，使用 [program_name] 标识配置的程序即可： mysqld：配置 mysqld 服务 mysqld_safe：配置 mysqld_safe 服务 server：适用于所有服务 mysql：mysql 命令行客户端配置 mysqldump：mysqldump 配置 client：适用于所有客户端 1234567891011vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid# include all files from the config directory!includedir /etc/my.cnf.d 3.2 配置文件读取次序mysql 的各类程序启动时都读取不止一个配置文件，配置文件将按照特定的顺序读取，最后读取的为最终生效的配置。可以使用 my_print_defaults 查看默认的配置文件查找次序。 123$ my_print_defaultsDefault options are read from the following files in the given order:/etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf 除了默认配置文件，mariadb 还可以通过命令行参数传入配置文件的位置： --default-extra-file=/PATH/TO/CONF_FILE: 默认的配置文件之外在加一个配置文件 --default-file : 修改默认读取的配置文件 配置文件查找次序默认情况下 OS Vendor提供mariadb rpm包安装的服务的配置文件查找次序： /etc/mysql/my.cnf /etc/my.cnf /etc/my.cnf.d/ --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 通用二进制格式安装的服务程序其配置文件查找次序 /etc/my.cnf /etc/my.cnf.d/ /etc/mysql/my.cnf --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 12345678910# os rpm 包安装的 mariadb 配置文件ll -d /etc/my*-rw-r--r--. 1 root root 570 6月 8 2017 /etc/my.cnfdrwxr-xr-x. 2 root root 67 2月 27 09:57 /etc/my.cnf.dll /etc/my.cnf.d总用量 12-rw-r--r--. 1 root root 295 4月 30 2017 client.cnf-rw-r--r--. 1 root root 232 4月 30 2017 mysql-clients.cnf-rw-r--r--. 1 root root 744 4月 30 2017 server.cnf 3.3 运行时参数修改123MariaDB [(none)]&gt; help 'show variables'MariaDB [(none)]&gt; show global variables like 'skip_name_resolve'MariaDB [(none)]&gt; show variables where variable_name="innodb_version"; 运行时参数查看： SHOW GLOBAL VARIABLES [LIKE &#39;pattern&#39; | WHERE expr]: 查看全局默认参数 SHOW SESSION VARIABLES [LIKE &#39;pattern&#39; | WHERE expr]: 查看当前会话的参数 运行时参数修改: SET GLOBAL VARIABLES= 或者 SET @@GLOBAL.VARIABLES=: 修改全局默认参数，仅对修改后新建的会话有效 SET SESSION VARIABLES= 或者 SET @@SESSION.VARIABLES=: 修改当前会话参数 3.4 查看 mariadb 状态变量SHOW [GLOBAL | SESSION] STATUS [LIKE &#39;pattern&#39; | WHERE expr] 4 mysql 客户端启动命令mysql [OPTIONS] [database] 常用选项： -u, --user=name：用户名，默认为root； -h, --host=name：远程主机（即mysql服务器）地址，默认为localhost; -p, --password：USERNAME所表示的用户的密码； 默认为空； -P, --port: 指定 mysql 服务监听的端口，默认为 3306 -D, --database：连接到服务器端之后，设定其处指明的数据库为默认数据库； -e, --execute=&#39;SQL COMMAND;&#39;：连接至服务器并让其执行此命令后直接返回； -S, --socket: 指定本地通信的套接字路经 mysql 客户端内可输入的命令分为两类: 客户段命令: 只在客户端运行的命令，使用 help 可获取此类命令的帮助 服务段命令: 通过 mysql 的协议送到服务段运行的命令，所以必须要有命令结束符,默认为 ;；使用 help contents 获取服务器端命令使用帮助。 4.1 查看本地命令mysql&gt; help \u db_name：设定哪个库为默认数据库 \q：退出 \d CHAR：设定新的语句结束符，默认为 ; \g：语句结束标记，默认就相当于 ; 作用 \G：语句结束标记，结果竖排方式显式 \! COMMAND: 在客户端内运行 shell 命令 \. PATH: 在客户端内执行 sql 脚本(包含 sql 的文本) 12345678910111213141516171819202122232425262728293031323334353637$ mysql -uroot -p1234MariaDB [(none)]&gt; help # help 查看 mysql 的所有命令List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.clear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.For server side help, type &apos;help contents&apos;# 执行 shell 命令MariaDB [(none)]&gt; \! ls /varaccount cache db games iso lib lock mail nis preserve spool tmp ypadm crash empty gopher kerberos local log named opt run target www 4.2 查看服务端命令12345678910111213141516171819202122232425262728293031323334MariaDB [(none)]&gt; help contents # 查看 mysql 命令的组成部分For more information, type 'help &lt;item&gt;', where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation.........MariaDB [(none)]&gt; help 'Account Management' # 查看特定命令组内的命令topics: CREATE USER DROP USER GRANT RENAME USER REVOKE SET PASSWORDMariaDB [(none)]&gt; help 'CREATE USER' # 查看特定命令使用帮助Name: 'CREATE USER'Description:Syntax:CREATE USER user_specification [, user_specification] ...user_specification: user [ IDENTIFIED BY [PASSWORD] 'password' | IDENTIFIED WITH auth_plugin [AS 'auth_string'] ]...............]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>马哥 MySQL 运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5. 索引使用策略]]></title>
    <url>%2F2019%2F10%2F05%2Fmysql%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84mysql%2F05_%E7%B4%A2%E5%BC%95%E4%BD%BF%E7%94%A8%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[如何使用 mysql 的索引 1. 前言这是与索引相关的第二篇文章，上一篇我们讲解了索引的基本原理，介绍了各种不同类型的索引的适用情景。本文我们将介绍高效适用索引的策略。下面介绍的索引适用策略大多数于 Innodb 的 B-Tree 索引相关。我们会介绍: mysql 通用的索引适用技巧 B-Tree 索引所使用的聚簇索引原理 B-Tree 索引的使用技巧(或者叫优化策略) 2. mysql 通用索引技巧2.1 独立的列“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。在 mysql 中，如果查询中的列不是独立的，则MySQL就不会使用索引。例如:12# 1. mysql 不会使用 actor_id 上的索引mysql&gt; SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 我们应该养成简化WHERE条件的习惯，始终将索引列单独放在比较符号的一侧。 2.2 索引选择性对于字符串索引，mysql 支持只索引开始的部分字符，称为前缀索引。像下面这样: 12# 1. 添加前缀索引。mysql&gt; ALTER TABLE sakila.city_demo ADD KEY (city(7)); 前缀索引能使索引更小、大大节约索引空间，从而提高索引效率。但是其也有缺点: 降低索引的选择性，并且MySQL无法使用前缀索引做ORDER BY和GROUP BY，也无法使用前缀索引做覆盖扫描。对于BLOB、TEXT或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度。 而如何选择前缀索引的长度以及在哪些列上创建索引，要看索引的选择性。索引的选择性是指，不重复的索引值（也称为基数，cardinality）和数据表的记录总数（#T）的比值。对于前缀索引要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引整个列。 通常我们要按照如下的步骤取选择前缀的长度: 首先我们要计算不同前缀长度的索引选择性，选择长度合适且与整列选择性接近索引长度 只看平均选择性是不够的，如果数据分布很不均匀，可能就会有陷阱，需要考虑最坏情况下的选择性。即出现次数最多头部数据的选择性。 最后，可能还需要根据那些运行频率最高的查询来调整索引列的顺序， 下面是一个对城市名字段创建前缀索引的探索过程:123456789101112131415# 1. 计算不同索引长度的选择性select COUNT(distinct LEFT(city, 3)) / COUNT(*) AS sel3, COUNT(distinct LEFT(city, 4)) / COUNT(*) AS sel3, COUNT(distinct LEFT(city, 5)) / COUNT(*) AS sel3, COUNT(distinct LEFT(city, 6)) / COUNT(*) AS sel3, COUNT(distinct LEFT(city, 7)) / COUNT(*) AS sel3, COUNT(distinct city) / COUNT(*) AS selfrom city_demo# 2. 观察使用前缀为 4，和使用整列的头部数据出现次数select COUNT(*) as cnt, LEFT(city, 4) as preffrom city_demo group by pref order by cnt desc limit 5;select COUNT(*) as cnt, cityfrom city_demo group by city order by cnt desc limit 5; MySQL原生并不支持反向索引，但是可以把字符串反转后存储，并基于此建立前缀索引。可以通过触发器来维护这种索引。索引的内容的选择并不只有前缀后缀两种，需要我们根据数据特征去截取选择性最高的数据部分。比如一段数据的前后都是重复的，而中间部分选择性足够高可以作为索引，我们就需要节取中间部分数据用作索引，这其实也是模拟哈希索引的一种，只不过这里的哈希函数只针对特定数据。 2.3 多列索引我们先来说一说，多列索引的一个误区: 为每个列创建独立的索引。在多个列上建立独立的单列索引大部分情况下并不能提高MySQL的查询性能。MySQL 5.0和更新版本引入了“索引合并”(index merge)策略来优化多列索引的使用。 1234567891011121314151617181920212223mysql&gt; SELECT film_id, actor_id FROM sakila.film_actor -&gt; WHERE actor_id = 1 OR film_id = 1;# 1. 在老的MySQL版本中，MySQL对这个查询会使用全表扫描。除非改写成如下的两个查询UNION的方式mysql&gt; SELECT film_id, actor_id FROM sakila.film_actor WHERE actor_id = 1 -&gt; UNION ALL -&gt; SELECT film_id, actor_id FROM sakila.film_actor WHERE actor_id &lt;&gt; 1 AND film_id = 1# 2. mysql5.1及更高版本引入了 索引合并，查询能够同时使用这两个单列索引进行扫描，并将结果进行合并mysql&gt; EXPLAIN SELECT film_id, actor_id FROM sakila.film_actor -&gt; WHERE actor_id = 1 OR film_id = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: film_actor type: index_mergepossible_keys: PRIMARY,idx_fk_film_id key: PRIMARY,idx_fk_film_id key_len: 2,2 ref: NULL rows: 29 Extra: Using union(PRIMARY,idx_fk_film_id); Using where 索引合并有三个变种： OR条件的联合（union） AND条件的相交（intersection） 组合前两种情况的联合及相交 索引合并策略有时候是一种优化的结果，但实际上更多时候说明了表上的索引建得很糟糕： 当出现服务器对多个索引做相交操作时（通常有多个AND条件），通常意味着需要一个包含所有相关列的多列索引，而不是多个独立的单列索引 当服务器需要对多个索引做联合操作时（通常有多个OR条件），通常需要耗费大量CPU和内存资源在算法的缓存、排序和合并操作上。特别是当其中有些索引的选择性不高，需要合并扫描返回的大量数据的时候 更重要的是，优化器不会把这些计算到“查询成本”（cost）中，优化器只关心随机页面读取。这会使得查询的成本被“低估”，导致该执行计划还不如直接走全表扫描。这样做不但会消耗更多的CPU和内存资源，还可能会影响查询的并发性，但如果是单独运行这样的查询则往往会忽略对并发性的影响。通常来说，还不如像在MySQL 4.1或者更早的时代一样，将查询改写成UNION的方式往往更好 如果在EXPLAIN中看到有索引合并，应该好好检查一下查询和表的结构，看是不是已经是最优的。也可以通过参数optimizer_switch来关闭索引合并功能。也可以使用IGNORE INDEX提示让优化器忽略掉某些索引。 3. Innodb 聚簇索引3.1 聚簇索引的原理聚簇索引指的是一种数据存储方式。术语“聚簇”表示数据行和相邻的键值紧凑地存储在一起。即数据行实际上存放在索引的叶子页（leaf page）中。InnoDB通过主键聚集数据，主键索引中同时保存了B-Tree索引和数据行。 如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有这样的索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB只聚集在同一个页面中的记录。包含相邻键值的页面可能会相距甚远。 因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。我们就以Innode 和 MyISAM为例来讲解聚簇和非聚簇索引的区别，他们都是用了B-Tree索引。 1234567CREATE TABLE layout_test ( col1 int NOT NULL, col2 int NOT NULL, PRIMARY KEY(col1), KEY(col2)); 假设该表的主键取值为1～10000，按照随机顺序插入并使用OPTIMIZE TABLE命令做了优化。换句话说，数据在磁盘上的存储方式已经最优，但行的顺序是随机的。列col2的值是从1～100之间随机赋值，所以有很多重复的值。 MyISAMMyISAM按照数据插入的顺序存储在磁盘上，如下图最左边的行号就是物理页的指针。 MyISAM—SAVE 当创建索引时，如下图所示，索引包含了”行号”。MyISAM中主键索引和其他索引在结构上没有什么不同。主键索引就是一个名为PRIMARY的唯一非空索引。 MyISAM—SAVE InnodeInnode 的聚簇索引按如下图的方式存储数据: Innodb—SAVE 主键索引上保存了整个表的数据，聚簇索引的每一个叶子节点都包含了主键值、事务ID、用于事务和MVCC的回滚指针以及所有的剩余列。在InnoDB中，聚簇索引“就是”表，不像MyISAM那样需要独立的行存储。因为数据行是按照主键顺序存储的，在插入新行，或者主键被更新导致需要移动行的时候，可能面临“页分裂（page split）”的问题。当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行，这就是一次页分裂操作。页分裂会导致表占用更多的磁盘空间。 对于二级索引，索引的叶子节点中存储的不是“行指针”，而是主键值。如下图所示: Innodb—INDEX 这样的策略减少了当出现行移动或者数据页分裂时二级索引的维护工作。使用主键值当作指针会让二级索引占用更多的空间，换来的好处是，InnoDB在移动行时无须更新二级索引中的这个“指针” 对比下面是聚簇和非聚簇索引的对比示意图:myisam_innodb_compare 聚簇索引特性聚簇索引由于存储上的特点，使得它具有如下特性: 优点: 可以把相关数据保存在一起，数据访问更快 使用覆盖索引扫描的查询可以直接使用页节点中的主键值 最大限度地提高了I/O密集型应用的性能，但如果数据全部都放在内存中，聚簇索引也就没什么优势了 缺点: 插入和更新时的叶分裂问题，因此插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到InnoDB表中速度最快的方式。但如果不是按照主键顺序加载数据，那么在加载完成后最好使用OPTIMIZE TABLE命令重新组织一下表 更新聚簇索引列的代价很高，因为会强制InnoDB将每个被更新的行移动到新的位置。 簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。 二级索引（非聚簇索引）可能比想象的要更大，因为在二级索引的叶子节点包含了引用行的主键列。 二级索引访问需要两次索引查找，而不是一次，因为i需要根据主键在查找一次主键的B-Tree索引，又称为回表 3.2 Innodb 的主键管理如果正在使用InnoDB表并且没有什么数据需要聚集，那么可以定义一个代理键（surrogate key）作为主键。最简单的方法是使用AUTO_INCREMENT自增列。这样可以保证数据行是按顺序写入，对于根据主键做关联操作的性能也会更好。 最好避免随机的（不连续且值的分布范围非常大）聚簇索引。例如:使用UUID来作为聚簇索引则会很糟糕：它使得聚簇索引的插入变得完全随机，这是最坏的情况，使得数据没有任何聚集特性。因为新行的主键值不一定比之前插入的大，所以InnoDB无法简单地总是把新行插入到索引的最后，而是需要为新的行寻找合适的位置——通常是已有数据的中间位置——并且分配空间。这会增加很多的额外工作，并导致数据分布不够优化。因为写入是乱序的，InnoDB不得不频繁地做行数据移动和页分裂操作，由于频繁的页分裂，页会变得稀疏并被不规则地填充，所以最终数据会有碎片。 3.3 顺序主键的问题对于高并发工作负载，在InnoDB中按主键顺序插入可能会造成明显的争用。主键的上界会成为“热点”。因为所有的插入都发生在这里，所以并发插入可能导致间隙锁竞争。另一个热点可能是AUTO_INCREMENT锁机制；如果遇到这个问题，则可能需要考虑重新设计表或者应用，或者更改innodb_autoinc_lock_mode配置。如果你的服务器版本还不支持innodb_autoinc_lock_mode参数，可以升级到新版本的InnoDB，可能对这种场景会工作得更好。 4.B-Tree 索引的使用技巧4.1 索引列顺序正确的顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要。 对于如何选择索引的列顺序有一个经验法则：将选择性最高的列放到索引最前列。这在某些场景可能有帮助，但通常不如避免随机IO和排序那么重要。 当不需要考虑排序和分组时，将选择性最高的列放在前面通常是很好的，然而，性能不只是依赖于所有索引列的选择性（整体基数），也和查询条件的具体值有关，也就是和值的分布有关。可能需要根据那些运行频率最高的查询来调整索引列的顺序。对于索引列顺序的选择，与索引前缀的选择考虑是类似的。以下面的查询为例: 1234567891011121314SELECT * FROM payment WHERE staff_id = 2 AND customer_id = 584;# 1. 首先要考虑，staff_id, customer_id 的选择性mysql&gt; SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity, &gt; COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity, &gt; COUNT(*) &gt; FROM payment\G*************************** 1. row *************************** staff_id_selectivity: 0.0001customer_id_selectivity: 0.0373 COUNT(*): 16049# 2. 考虑数据分布，及热点数据对索引性能的影响# 3. 从诸如pt-query-digest这样的工具的报告中提取“最差”查询，运行频率最高的查询，进行定向优化 最后，尽管关于选择性和基数的经验法则值得去研究和分析，但一定要记住别忘了WHERE子句中的排序、分组和范围条件等其他因素，这些因素可能对查询的性能造成非常大的影响。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>高性能的MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 索引基本原理]]></title>
    <url>%2F2019%2F10%2F04%2Fmysql%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84mysql%2F04_%E7%B4%A2%E5%BC%95%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[mysql 索引的基本原理 1. 前言索引对性能至关重要，接下来的 3 篇文章我们将会讲解索引的相关内容。本文是第一篇有关的索引的基本原理。在MySQL中，索引是在存储引擎层而不是服务器层实现的。所以，并没有统一的索引标准，每一种存储引擎都有自己的索引实现。常见的索引类型有如下几种: B-Tree索引 哈希索引 空间数据索引（R-Tree） 全文索引 我们将分别介绍他们的实现原理和适用的查询类型 2. B-Tree 索引B-Tree 索引顾名思义就是使用 B-Tree 结构实现的索引。实际上大多数存储引擎包括 Innodb 使用的是 B+ 树。下面是 B+ 数索引的结构示意图: B+树索引 一个 B+ 树在结构上有如下一些特点: 一个 B+ 树是一个平衡多叉树，每一个叶子页到根的距离相同 叶子节点除了被索引的列，还保存了对应行的引用，在 Innodb 中保存的就是对应的行的主键 索引列在每个叶子节点中都是顺序保存的 每个叶子节点都包含指向下一个叶子节点的指针，便于进行范围查找 B+ 索引的顺序存储特性，使得 B-Tree索引适用于全键值、键值范围或键前缀查找。其中键前缀查找只适用于根据最左前缀的查找。因为索引树中的节点是有序的，所以除了按值查找之外，索引还可以用于查询中的ORDER BY和GROUP BY操作。 因为最左前缀匹配，如果不是按照索引的最左列开始查找，则无法使用索引，同时也不能跳过索引中的列使用索引。因此索引列的顺序变得至关重要。如果查询中有某个列的范围查询，则其右边所有列都无法使用索引优化查找。如果范围查询列值的数量有限，那么可以通过使用多个等于条件来代替范围条件。 3. 哈希索引哈希索引即基于哈希实现的索引。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（hash code）。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。 哈希的特性是只支持精确匹配，因此哈希索引有如下一些限制: 哈希索引只包含哈希值和行指针，而不存储字段值，因此不存在覆盖索引 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序 不支持索引列部分匹配，只支持等值比较查询，不支持范围查询 在MySQL中，只有Memory引擎显式支持哈希索引。值得一提的是，Memory引擎是支持非唯一哈希索引的，这是与众不同的。除了Memory引擎外，NDB集群引擎也支持唯一哈希索引。当InnoDB注意到某些索引值被使用得非常频繁时，它会在内存中基于B-Tree索引之上再创建一个哈希索引。这是一个完全自动的、内部的行为，用户无法控制或者配置，不过如果有必要，完全可以关闭该功能。 可以在 Innodb 中模拟哈希索引，还是使用B-Tree进行查找，但是它使用哈希值而不是键本身进行索引查找。例如需要存储大量的URL，并需要根据URL进行搜索查找。如果使用B-Tree来存储URL，存储的内容就会很大，因为URL本身都很长。可以删除原来URL列上的索引，而新增一个被索引的url_crc列，使用CRC32做哈希，就可以使用下面的方式查询： 1234567891011121314151617181920212223242526272829# 1. 添加一个 CRC32(url_crc) 的 B-Tree 索引CREATE TABLE pseudohash ( id int unsigned NOT NULL auto_increment, url varchar(255) NOT NULL, url_crc int unsigned NOT NULL DEFAULT 0, PRIMARY KEY(id), INDEX(url_crc));# 2. 查询必须待上原值，因为哈希可能存在哈希冲突mysql&gt; SELECT id FROM url WHERE url="http://www.mysql.com" -&gt; AND url_crc=CRC32("http://www.mysql.com");# 3. 使用触发器实现 url_crc 的维护DELIMITER // # 先临时修改一下语句分隔符，这样就可以在触发器定义中使用分号：CREATE TRIGGER pseudohash_crc_ins BEFORE INSERT ON pseudohash FOR EACH ROW BEGINSET NEW.url_crc=crc32(NEW.url);END;//CREATE TRIGGER pseudohash_crc_upd BEFORE UPDATE ON pseudohash FOR EACH ROW BEGINSET NEW.url_crc=crc32(NEW.url);END;//DELIMITER ; 注意如果采用这种方式，记住不要使用SHA1()和MD5()作为哈希函数。因为这两个函数计算出来的哈希值是非常长的字符串，会浪费大量空间，比较时也会更慢。还可以使用如FNV64()函数作为哈希，哈希值为64位，速度快，且冲突比CRC32()要少很多。 4. 其他索引类别mysql 还有很多存储引擎使用不同的数据结构来存储索引，包括: 全文索引，查找的是文本中的关键词，而不是直接比较索引中的值 TokuDB使用分形树索引，既有B-Tree的很多优点，也避免了B-Tree的一些缺点 5. 索引的优点索引有众多优点，总结下来包括如下三个：1.索引大大减少了服务器需要扫描的数据量 – 快速定位行位置2.索引可以帮助服务器避免排序和临时表 – B-Tree 索引的有序存储，可以实现 ORDER BY和GROUP BY3.索引可以将随机I/O变为顺序I/O – 覆盖索引优化 Lahdenmaki和Leach在书中介绍了如何评价一个索引是否适合某个查询的“三星系统”（three-star system）: 索引将相关的记录放到一起则获得一星 如果索引中的数据顺序和查找中的排列顺序一致则获得二星 如果索引中的列包含了查询中需要的全部列则获得“三星” 6. 索引的适用索引并不总是最好的工具。总的来说，只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是有效的。对于中到大型的表，索引非常有效。但对于特大型的表，建立和使用索引的代价将随之增长。这种情况下，则需要一种技术可以直接区分出查询需要的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。 如果表的数量特别多，可以建立一个元数据信息表，用来查询需要用到的某些特性。对于TB级别的数据，定位单条记录的意义不大，所以经常会使用块级别元数据技术来替代索引。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>高性能的MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 Schema 设计]]></title>
    <url>%2F2019%2F10%2F03%2Fmysql%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84mysql%2F03_schema%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[mysql 的 Schema 设计 1. 前言上一节我们简述了 MySQL 中的数据类型，本节我们来说一说 MySQL 的 Schema 设计，包括以下内容: MySQL 特有的 Schema 设计问题，这是由 MySQL 特定的实现机制导致的 Schema 设计的范式和反范式 为提升读性能，而常采用的技巧，缓存表和汇总表 最后我们会简单说一下加快 ALTER TABLE 操作速度的方法。下面大部分内容摘自：《高性能MySQL》 — 〔美〕施瓦茨 (Baron Schwartz) 〔美〕扎伊采夫 (Peter Zaitsev) 〔美〕特卡琴科 (Vadim Tkachenko)在豆瓣阅读书店查看：https://read.douban.com/ebook/35648568/ 2. MySQL schema设计中的陷阱有一些问题是由MySQL的实现机制导致的，我们需要避免下面只会在 MySQL 中发生的特定问题: 太多的列 MySQL的存储引擎，需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列 从行缓冲中将编码过的列转换成行数据结构的代价依赖于列的数量 如果计划使用数千个字段，必须意识到服务器的性能运行特征会有一些不同。 太多的关联 MySQL限制了每个关联操作最多只能有61张表 事实上在许多关联少于61张表的情况下，解析和优化查询的代价也会成为MySQL的问题 经验法则，单个查询最好在12个表以内做关联 NULL 的使用: 避免使用NULL的好处，但是也不能走极端 在一些场景中，使用NULL可能会比某个神奇常数更好，以避免引入Bug 伪造的全0值可能导致很多问题（可以配置MySQL的SQL_MODE来禁止不可能的日期） MySQL会在索引中存储NULL值，而Oracle则不会 2. 范式和反范式范式和反范式反映的是 MySQL 数据冗余程度。在范式化的数据库中，每个事实数据会出现并且只出现一次。相反，在反范式化的数据库中，信息是冗余的，可能会存储在多个地方。范式和反范式有他们各自的有缺点。 2.1 范式的优缺点范式，特别适用于写密集的场景，原因在于: 当数据较好地范式化时，就只有很少或者没有重复数据，所以只需要修改更少的数据 很少有多余的数据意味着检索列表数据时更少需要DISTINCT或者GROUP BY语句 范式化的缺点是通常需要关联。这不但代价昂贵，也可能使一些索引策略无效。例如，范式化可能将列存放在不同的表中，而这些列如果在一个表中本可以属于同一个索引。 2.2 反范式的优点和缺点反范式化的schema因为所有数据都在一张表中，所以有下面这些优点: 可以很好地避免关联 当数据比内存大时这可能比关联要快得多，因为这样避免了随机I/O 单独的表也能使用更有效的索引策略。 2.3 混用范式化和反范式化范式化和反范式化的schema各有优劣，在实际应用中经常需要混用，可能使用部分范式化的schema、缓存表，以及其他技巧。最常见的反范式化数据的方法是复制或者缓存，在不同的表中存储相同的特定列。在MySQL 5.0和更新版本中，可以使用触发器更新缓存值，这使得实现这样的方案变得更简单。另一个从父表冗余一些数据到子表的理由是排序的需要。 3. 缓存表和汇总表为了提升读查询的速度，经常会需要建一些额外索引，增加冗余列，甚至是创建缓存表和汇总表。下面这方面技巧的专用术语: 缓存表: 来表示存储那些可以比较简单地从schema其他表获取（但是每次获取的速度比较慢）数据的表 汇总表: 用来保存使用GROUP BY语句聚合数据的表 物化视图: 实际上是预先计算并且存储在磁盘上的表，可以通过各种各样的策略刷新和更新 计数器表: 专用来计数的表 下面我们来一一介绍这些使用技巧。 3.1 汇总表以网站为例，假设需要计算之前24小时内发送的消息数，我们可以每小时生成一张汇总表，并使用下面的 SQL 进行计算:1234567891011121314151617CREATE TABLE msg_per_hr ( hr DATETIME NOT NULL, cnt INT UNSIGNED NOT NULL, PRIMARY KEY(hr));mysql&gt; SELECT SUM(cnt) FROM msg_per_hr -&gt; WHERE hr BETWEEN -&gt; CONCAT(LEFT(NOW(), 14), '00:00') - INTERVAL 23 HOUR -&gt; AND CONCAT(LEFT(NOW(), 14), '00:00') - INTERVAL 1 HOUR;mysql&gt; SELECT COUNT(*) FROM message -&gt; WHERE posted &gt;= NOW() - INTERVAL 24 HOUR -&gt; AND posted &lt; CONCAT(LEFT(NOW(), 14), '00:00') - INTERVAL 23 HOUR;mysql&gt; SELECT COUNT(*) FROM message -&gt; WHERE posted &gt;= CONCAT(LEFT(NOW(), 14), '00:00'); 3.2 缓存表缓存表的一个有用的技巧是对缓存表使用不同的存储引擎例如，如果主表使用InnoDB，用MyISAM作为缓存表的引擎将会得到更小的索引占用空间，并且可以做全文搜索。有时甚至可以把整个表导出MySQL，插入到专门的搜索系统中获得更高的搜索效率。 在使用缓存表和汇总表时，必须决定是实时维护数据还是定期重建。哪个更好依赖于应用程序，但是定期重建并不只是节省资源，也可以保持表不会有很多碎片，以及有完全顺序组织的索引（这会更加高效）。 当重建汇总表和缓存表时，通常需要保证数据在操作时依然可用。这就需要通过使用“影子表”来实现，下面是影子表的使用技巧: 1234mysql&gt; DROP TABLE IF EXISTS my_summary_new, my_summary_old;mysql&gt; CREATE TABLE my_summary_new LIKE my_summary;-- populate my_summary_new as desiredmysql&gt; RENAME TABLE my_summary TO my_summary_old, my_summary_new TO my_summary; 3.3 物化视图(额外学习)。MySQL并不原生支持物化视图。可以使用开源工具Flexviews 在 MySQL中实现物化视图。 对比传统的维护汇总表和缓存表的方法，Flexviews通过提取对源表的更改，可以增量地重新计算物化视图的内容。这意味着不需要通过查询原始数据来更新视图。 3.2 计数器表计数器表可以统计计数，但是计数器表可能会碰到并发问题。 要获得更高的并发更新性能，一种方案是可以将计数器保存在多行中，每次随机选择一行进行更新。像下面这样 123456789# 1. 创建如下计数表mysql&gt; CREATE TABLE hit_counter ( -&gt; slot tinyint unsigned not null primary key, -&gt; cnt int unsigned not null -&gt; ) ENGINE=InnoDB;# 2. 预先增加100行数据# 3. 现在选择一个随机的槽（slot）进行更新mysql&gt; UPDATE hit_counter SET cnt = cnt + 1 WHERE slot = RAND() * 100; 如果像每天开始一个计数器，可以像下面这样:123456789101112131415161718192021222324# 1. 创建下表mysql&gt; CREATE TABLE daily_hit_counter ( -&gt; day date not null, -&gt; slot tinyint unsigned not null, -&gt; cnt int unsigned not null, -&gt; primary key(day, slot) -&gt; ) ENGINE=InnoDB;# 2. 使用 ON DUPLICATE 进行更新mysql&gt; INSERT INTO daily_hit_counter(day, slot, cnt) -&gt; VALUES(CURRENT_DATE, RAND() * 100, 1) -&gt; ON DUPLICATE KEY UPDATE cnt = cnt + 1;# 3. 希望减少表的行数，避免表变大，可以写一个周期执行的任务，# 合并所有结果到0号槽，并且删除所有其他的槽：mysql&gt; UPDATE daily_hit_counter as c -&gt; INNER JOIN ( -&gt; SELECT day, SUM(cnt) AS cnt, MIN(slot) AS mslot -&gt; FROM daily_hit_counter -&gt; GROUP BY day -&gt; ) AS x USING(day) -&gt; SET c.cnt = IF(c.slot = x.mslot, x.cnt, 0), -&gt; c.slot = IF(c.slot = x.mslot, 0, c.slot);mysql&gt; DELETE FROM daily_hit_counter WHERE slot &lt;&gt; 0 AND cnt = 0; 4. 加速ALTER TABLE操作MySQL的ALTER TABLE操作的性能对大表来说是个大问题。MySQL执行大部分修改表结构操作的方法是用新的结构创建一个空表，从旧表中查出所有数据插入新表，然后删除旧表。这样操作可能需要花费很长时间，如果内存不足而表又很大，而且还有很多索引的情况下尤其如此。 大部分ALTER TABLE操作将导致MySQL服务中断，常见场景中，避免中断的技巧只有两个: 一种是先在一台不提供服务的机器上执行ALTER TABLE操作，然后和提供服务的主库进行切换 另外一种技巧是“影子拷贝”。影子拷贝的技巧是用要求的表结构创建一张和源表无关的新表 一些工具可以帮助完成影子拷贝工作： Facebook数据库运维团队的“online schema change”工具 Shlomi Noach的openark toolkit Percona Toolkit 如果使用Flexviews，也可以通过其CDC工具执行无锁的表结构变更 一些特殊的 ALTER TABLE 操作则有特殊的优化技巧。 4.1 更改列的默认值默认像下面更改列的默认值会导致表重建:12345# 1. 所有的MODIFY COLUMN操作都将导致表重建。mysql&gt; ALTER TABLE sakila.film -&gt; MODIFY COLUMN rental_duration TINYINT(3) NOT NULL DEFAULT 5;mysql&gt; SHOW STATUS显 理论上，MySQL可以跳过创建新表的步骤。列的默认值实际上存在表的.frm文件中，所以可以直接修改这个文件而不需要改动表本身。另外一种方法是通过ALTER COLUMN操作来改变列的默认值： 123mysql&gt; ALTER TABLE sakila.film -&gt; ALTER COLUMN rental_duration SET DEFAULT 5; 这个语句会直接修改.frm文件而不涉及表数据。所以，这个操作是非常快的。ALTER TABLE允许使用ALTER COLUMN、MODIFY COLUMN和CHANGE COLUMN语句修改列。这三种操作都是不一样的。 4.2 只修改.frm文件下面要演示的技巧是不受官方支持的，也没有文档记录，并且也可能不能正常工作，采用这些技术需要自己承担风险。建议在执行之前首先备份数据！下面这些操作是有可能不需要重建表的： 移除（不是增加）一个列的AUTO_INCREMENT属性。 增加、移除，或更改ENUM和SET常量。如果移除的是已经有行数据用到其值的常量，查询将会返回一个空字串值。 基本的技术是为想要的表结构创建一个新的.frm文件，然后用它替换掉已经存在的那张表的.frm文件，像下面这样： 创建一张有相同结构的空表，并进行所需要的修改（例如增加ENUM常量）。 执行FLUSH TABLES WITH READ LOCK 这将会关闭所有正在使用的表，并且禁止任何表被打开 交换.frm文件 执行UNLOCK TABLES来释放第2步的读锁 4.3 快速创建MyISAM索引为了高效地载入数据到MyISAM表中，有一个常用的技巧是先禁用索引、载入数据，然后重新启用索引： 123mysql&gt; ALTER TABLE test.load_data ENABLE KEYS;-- load the datamysql&gt; ALTER TABLE test.load_data ENABLE KEYS; 这个技巧能够发挥作用，是因为构建索引的工作被延迟到数据完全载入以后，这个时候已经可以通过排序来构建索引了。这样做会快很多，并且使得索引树的碎片更少、更紧凑。 这个办法对唯一索引无效，因为DISABLE KEYS只对非唯一索引有效。MyISAM会在内存中构造唯一索引，并且为载入的每一行检查唯一性。一旦索引的大小超过了有效内存大小，载入操作就会变得越来越慢。 在现代版本的InnoDB版本中，有一个类似的技巧，这依赖于InnoDB的快速在线索引创建功能。这个技巧是，先删除所有的非唯一索引，然后增加新的列，最后重新创建删除掉的索引。Percona Server可以自动完成这些操作步骤。 也可以使用像前面说的ALTER TABLE的骇客方法来加速这个操作，但需要多做一些工作并且承担一定的风险。这对从备份中载入数据是很有用的，例如，当已经知道所有数据都是有效的并且没有必要做唯一性检查时就可以这么来操作。下面是操作步骤： 用需要的表结构创建一张表，但是不包括索引。 载入数据到表中以构建.MYD文件。 按照需要的结构创建另外一张空表，这次要包含索引。这会创建需要的.frm和.MYI文件。 获取读锁并刷新表。 重命名第二张表的.frm和.MYI文件，让MySQL认为是第一张表的文件。 释放读锁。 使用REPAIR TABLE来重建表的索引。该操作会通过排序来构建所有索引，包括唯一索引。这个操作步骤对大表来说会快很多。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>高性能的MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 MySQL 数据类型]]></title>
    <url>%2F2019%2F10%2F02%2Fmysql%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84mysql%2F02_mysql%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[mysql 的数据类型。 1. 前言本章是mysql 的数据类型方面的内容。这一部分内容大家可能都比较熟悉，但是其中的一些细节依然值得一在强调。 本文大部分内容摘自：《高性能MySQL》 — 〔美〕施瓦茨 (Baron Schwartz) 〔美〕扎伊采夫 (Peter Zaitsev) 〔美〕特卡琴科 (Vadim Tkachenko)可在豆瓣阅读书店查看：https://read.douban.com/ebook/35648568/ 2. 数据类型在详细介绍具体的数据类型之前，简单说一下选择最优的数据类型的几个简单原则: 更小的通常更好 应该尽量使用可以正确存储数据的最小数据类型 但是要确保没有低估需要存储的值的范围 简单就好 简单数据类型的操作通常需要更少的CPU周期 尽量避免NULL 通常情况下最好指定列为NOT NULL，除非真的需要存储NULL值。 如果查询中包含可为NULL的列，对MySQL来说更难优化 因为可为NULL的列使得索引、索引统计和值比较都更复杂 可为NULL的列会使用更多的存储空间，在MySQL里也需要特殊处理 如果计划在列上建索引，就应该尽量避免设计成可为NULL的列。 InnoDB是一个例外，它使用单独的位（bit）存储NULL值，所以对于稀疏数据有很好的空间效率 与VARCHAR（5）相比 更长的列 VARCHAR（5）会消耗更多的内存，因为MySQL通常会分配固定大小的内存块来保存内部值。尤其是使用内存临时表进行排序或操作时会特别糟糕。在利用磁盘临时表进行排序时也同样糟糕。所以最好的策略是只分配真正需要的空间。 在为列选择数据类型时，第一步需要确定合适的大类型：数字、字符串、时间等。下一步是选择具体类型，相同大类型的不同子类型数据有时也有一些特殊的行为和属性。接下来我们就简要说明一下 MySQL 中基本类型的一些重要特性。 2.1 整数整数类型有：TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT。分别使用8，16，24，32，64位存储空间，可以存储−2^{（N−1）}到2^{（N−1）}−1 的值，其中N是存储空间的位数。MySQL可以为整数类型指定宽度，但它不会限制值的合法范围，对于存储和计算来说，INT（1）和INT（20）是相同的。整数的类型只影响存储，整数计算一般使用64位的BIGINT整数。 2.2 实数FLOAT和DOUBLE类型支持使用标准的浮点运算进行近似计算。DECIMAL类型用于存储精确的小数。在MySQL 5.0和更高版本，DECIMAL类型支持精确计算。因为CPU不支持对DECIMAL的直接计算，而支持原生浮点计算，所以FLOAT和DOUBLE比 DECIMAL 计算快。 MySQL 5.0和更高版本将 DECIMAL 打包保存到一个二进制字符串中（每4个字节存9个数字）。例如，DECIMAL（18,9）小数点两边将各存储9个数字，一共使用9个字节：小数点前的数字用4个字节，小数点后的数字用4个字节，小数点本身占1个字节。MySQL 5.0和更高版本中的DECIMAL类型允许最多65个数字。 有多种方法可以指定浮点列所需要的精度，但是浮点数的精度定义是非标准的，所以建议只指定数据类型，不指定精度。和整数类型一样，能选择的只是浮点数的存储类型；MySQL使用DOUBLE作为内部浮点计算的类型。 2.2 字符串从MySQL 字符串类型有很多变种，包括: VARCHAR和CHAR: 两种最主要的字符串类型。 BINARY和VARBINARY: 存储的是二进制字符串，二进制字符串存储的是字节码而不是字符 BLOB和TEXT: 为存储很大的数据而设计的字符串数据类型，分别为二进制和字符 VARCHAR 和 CHAR很难精确地解释VARCHAR和CHAR是怎么存储在磁盘和内存中的，因为这跟存储引擎的具体实现有关。下面论述以InnoDB和/或者MyISAM为基础。需要注意的是存储引擎存储CHAR或者VARCHAR值的方式在内存中和在磁盘上可能不一样，所以MySQL服务器从存储引擎读出的值可能需要转换为另一种存储格式。下面 VARCHAR 与 CHAR 的典型对比 VARCHAR: 存储可变长字符串，需要使用1或2个额外字节记录字符串的长度，列的最大长度小于或等于255字节，则只使用1个字节表示，否则使用2个字节 VARCHAR节省了存储空间，但在UPDATE时可能使行变得比原来更长时需要做额外的工作，如果一个行占用的空间增长，并且在页内没有更多的空间可以存储，则需要进一步处理(不同的存储引擎处理方式不一样) VARCHAR 节省存储空间有一个例外情况，即 MySQL 表使用ROW_FORMAT=FIXED创建，此时每一行都会使用定长存储 在5.0或者更高版本，MySQL在存储和检索时会保留末尾空格。但在4.1或更老的版本，MySQL会剔除末尾空格 CHAR: CHAR类型是定长的 当存储CHAR值时，MySQL会删除所有的末尾空格 CHAR适合存储很短的字符串，或者所有值都接近同一个长度 对于经常变更的数据，CHAR也比VARCHAR更好，因为定长的CHAR类型不容易产生碎片 对于非常短的列，CHAR比VARCHAR在存储空间上也更有效率 BINARY和VARBINARYMySQL填充BINARY采用的是\0（零字节）而不是空格，在检索时也不会去掉填充值 当需要存储二进制数据，并进行二进制比较时 BINARY和VARBINARY 非常有用。二进制比较的优势并不仅仅体现在大小写敏感上。MySQL比较BINARY字符串时，每次按一个字节，并且根据该字节的数值进行比较。因此，二进制比较比字符比较简单很多，所以也就更快 BLOB 和 TEXTMySQL把每个BLOB和TEXT值当作一个独立的对象处理。当BLOB和TEXT值太大时，InnoDB会使用专门的“外部”存储区域来进行存储，此时每个值在行内需要1～4个字节存储一个指针，然后在外部存储区域存储实际的值。 BLOB和TEXT家族之间仅有的不同是BLOB类型存储的是二进制数据，没有排序规则或字符集，而TEXT类型有字符集和排序规则。 MySQL对BLOB和TEXT列进行排序与其他类型是不同的：它只对每个列的最前max_sort_length字节而不是整个字符串做排序。如果只需要排序前面一小部分字符，则可以减小max_sort_length的配置，或者使用ORDER BY SUSTRING（column，length）。 MySQL不能将BLOB和TEXT列全部长度的字符串进行索引，也不能使用这些索引消除排序。 因为Memory引擎不支持BLOB和TEXT类型，所以，如果查询使用了BLOB或TEXT列并且需要使用隐式临时表，将不得不使用MyISAM磁盘临时表，即使只有几行数据也是如此。这会导致严重的性能开销。即使配置MySQL将临时表存储在内存块设备上（RAM Disk），依然需要许多昂贵的系统调用。 最好的解决方案是尽量避免使用BLOB和TEXT类型。如果实在无法避免，有一个技巧是在所有用到BLOB字段的地方都使用SUBSTRING（column，length）将列值转换为字符串（在ORDER BY子句中也适用），这样就可以使用内存临时表了。但是要确保截取的子字符串足够短，不会使临时表的大小超过max_heap_table_size或tmp_table_size，超过以后MySQL会将内存临时表转换为MyISAM磁盘临时表。最坏情况下的长度分配对于排序的时候也是一样的，所以这一招对于内存中创建大临时表和文件排序，以及在磁盘上创建大临时表和文件排序这两种情况都很有帮助。 2.3 枚举（ENUM）类型MySQL在存储枚举时非常紧凑，会根据列表值的数量压缩到一个或者两个字节中。MySQL在内部会将每个值在列表中的位置保存为整数，并且在表的.frm文件中保存“数字-字符串”映射关系的“查找表”。 但是让人吃惊的地方是，枚举字段是按照内部存储的整数而不是定义的字符串进行排序的。一种绕过这种限制的方式是按照需要的顺序来定义枚举列。另外也可以在查询中使用FIELD()函数显式地指定排序顺序，但这会导致MySQL无法利用索引消除排序。 枚举最不好的地方是，字符串列表是固定的，添加或删除字符串必须使用ALTER TABLE。因此，对于一系列未来可能会改变的字符串，使用枚举不是一个好主意，除非能接受只在列表末尾添加元素，这样在MySQL 5.1中就可以不用重建整个表来完成修改。 把列都转换成ENUM以后，关联变得很快。在特定情况下，把CHAR/VARCHAR列与枚举列进行关联可能会比直接关联CHAR/VARCHAR列更慢。这是一个通用的设计实践，在“查找表”时采用整数主键而避免采用基于字符串的值进行关联。 使用 ENUM 替换字符串类型最大好处是，可以使得表更小，相比于字符串主键，转换后主键以及依赖于主键的非主键索引也会更小。 2.4 日期和时间MySQL可以使用许多类型来保存日期和时间值，例如YEAR和DATE。大部分时间类型都没有替代品，因此没有什么是最佳选择的问题。唯一的问题是如何保存日期和时间，MySQL提供两种相似的日期类型：DATETIME和TIMESTAMP。 DATETIME: 这个类型能保存大范围的值，从1001年到9999年，精度为秒 它把日期和时间封装到格式为YYYYMMDDHHMMSS的整数中，与时区无关。使用8个字节的存储空间 TIMESTAMP UNIX时间戳，只使用4个字节的存储空间，只能表示从1970年到2038年 FROM_UNIXTIME()把Unix时间戳转换为日期，UNIX_TIMESTAMP()把日期转换为Unix时间戳 TIMESTAMP显示的值也依赖于时区，MySQL服务器、操作系统，以及客户端连接都有时区设置 默认情况下，如果插入时没有指定第一个TIMESTAMP列的值，MySQL则设置这个列的值为当前时间 在更新一行记录时，MySQL默认也会更新第一个TIMESTAMP列的值 可以配置任何TIMESTAMP列的插入和更新行为 最后，TIMESTAMP列默认为NOT NULL，这也和其他的数据类型不一样 除了特殊行为之外，通常也应该尽量使用TIMESTAMP，因为它比DATETIME空间效率更高。有时候人们会将Unix时间截存储为整数值，但这不会带来任何收益。用整数保存时间截的格式通常不方便处理。 MySQL能存储的最小时间粒度为秒，如果需要存储比秒更小粒度的日期和时间值可以使用 BIGINT 模拟也可以改使用 MariaDB （MariaDB支持微秒级别的时间类型）。 2.5 位数据类型MySQL有少数几种存储类型使用紧凑的位存储数据。所有这些位类型，不管底层存储格式和处理方式如何，从技术上来说都是字符串类型。 BIT:可以使用BIT列在一列中存储一个或多个true/false值，最大长度是64个位。 BIT的行为因存储引擎而异。MyISAM会打包存储所有的BIT列，所以17个单独的BIT列只需要17个位存储（假设没有可为NULL的列），这样MyISAM只使用3个字节就能存储这17个BIT列。其他存储引擎例如Memory和InnoDB，为每个BIT列使用一个足够存储的最小整数类型来存放，所以不能节省存储空间。 MySQL把BIT当作字符串类型，而不是数字类型。但是 BIT 的使用依赖于其使用的上下文。例如，如果存储一个值b’00111001’（二进制值等于57）到BIT（8）的列并且检索它，得到的内容是字符码为57的字符串。也就是说得到ASCII码为57的字符“9”。但是在数字上下文场景中，得到的是数字57： 所以我们认为应该谨慎使用BIT类型。对于大部分应用，最好避免使用这种类型。 SETSET: 在MySQL内部是以一系列打包的位的集合,如果需要保存很多true/false值，可以考虑合并这些列到一个SET FIND_IN_SET()和FIELD()这样的函数，方便地在查询中使用 缺点是改变列的定义的代价较高：需要ALTER TABLE，一般来说，也无法在SET列上通过索引查找 一种替代SET的方式是使用一个整数包装一系列的位，并且按位操作来使用。好处是可以不使用ALTER TABLE改变字段代表的“枚举”值，缺点是查询语句更难写，并且更难理解。最后 MySQL在内部使用整数存储ENUM和SET类型，然后在做比较操作时转换为字符串。 2.6 选择标识符为标识列（identifier column）选择合适的数据类型非常重要，不仅仅需要考虑存储类型，还需要考虑MySQL对这种类型怎么执行计算和比较。一旦选定了一种类型，要确保在所有关联表中都使用同样的类型。类型之间需要精确匹配，包括像UNSIGNED这样的属性。混用不同数据类型可能导致性能问题，即使没有性能影响，在比较操作时隐式类型转换也可能导致很难发现的错误。下面是各类型作为标识符的适用情况: 整数: 通常是标识列最好的选择，很快并且可以使用AUTO_INCREMENT EMUM和SET: 通常是一个糟糕的选择，它们仅适合在存储固定信息作为标识列类型 字符串: 如果可能，应该避免使用字符串类型作为标识列，因为它们很消耗空间，并且通常比数字类型慢 MyISAM默认对字符串使用压缩索引，这会导致查询慢得多 特别的对于像 MD5() 生成的随机字符串，作为标识符需要注意。随机字符串分布在很大的空间内，会导致INSERT以及一些SELECT语句变得很慢。 因为插入值会随机地写到索引的不同位置，所以使得INSERT语句更慢。这会导致页分裂、磁盘随机访问，以及对于聚簇存储引擎产生聚簇索引碎片 SELECT语句会变得更慢，因为逻辑上相邻的行会分布在磁盘和内存的不同地方。 随机值导致缓存对所有类型的查询语句效果都很差，因为会使得缓存赖以工作的访问局部性原理失效。 如果存储UUID值，则应该移除“-”符号；更好的做法是，用UNHEX()函数转换UUID值为16字节的数字，并且存储在一个BINARY（16）列中。检索时可以通过HEX()函数来格式化为十六进制格式。 UUID()生成的值与加密散列函数例如SHA1()生成的值有不同的特征：UUID值虽然分布也不均匀，但还是有一定顺序的。尽管如此，但还是不如递增的整数好用。 2.7 IP 的存储应该用无符号整数存储IP地址。MySQL提供INET_ATON()和INET_NTOA()函数在这两种表示方法之间转换。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>高性能的MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 MYSQL EXPLAIN]]></title>
    <url>%2F2019%2F10%2F01%2Fmysql%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84mysql%2F01_explain%2F</url>
    <content type="text"><![CDATA[你以为很懂，其实一点也不懂的 mysql。 1. mysql 开篇说来惭愧，相比于入程序员这行的时间，对 mysql 的了解太少了。接下来的两个月里，希望借助于 高性能的MySQL 一书和林晓斌老师的专栏 MySQL实战45讲 来系统的学习 MySQL。 在我们正式学习其他内容之前，我想先介绍一下如何调用“EXPLAIN”来获取关于查询执行计划的信息，以及如何解释输出。这将能帮助我们了解 mysql 在执行 sql 背后的每一步。我们将分成以下 4 个部分来介绍 EXPLAIN 的相关内容: EXPLAIN 的三种用法 EXPLAIN 的数据 EXPLAIN 的缺陷 MySQL5.6 对EXPLAIN 的改进 2. EXPLAIN2.1 EXPLAIN 用法EXPLAIN 有三种用法: EXPLAIN SELECT ...: 显示出执行计划中的每一部分和执行的次序 在查询中每个表在输出中只有一行,如果查询是两个表的联接，那么输出中将有两行 别名表单算为一个表，“表”的意义在这里相当广，可以是一个子查询，一个UNION结果，等等 输出中的行以MySQL实际执行的查询部分的顺序出现，而这个顺序不总是与其在原始SQL中的相一致，因为 MySQL查询优化器会优化 SQL 的执行顺序。 EXPLAIN EXTENDED SELECT ...: 看起来和正常的EXPLAIN的行为一样，但它会告诉服务器“逆向编译”执行计划为一个SELECT语句 可以通过紧接其后运行SHOW WARNINGS看到这个生成的语句。这个语句直接来自执行计划，而不是原SQL语句，到这点上已经变成一个数据结构。 EXPLAIN PARTITIONS: 会显示查询将访问的分区，如果查询是基于分区表的话 下面是使用EXPLAIN EXTENDED的一个示例: 1234567891011121314151617181920explain extended select * from floatTest \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: floatTest type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 2 filtered: 100.00 Extra:show warnings \G*************************** 1. row *************************** Level: Note Code: 1003Message: select `enlightent_daily`.`floatTest`.`dd` AS `dd` from `enlightent_daily`.`floatTest` 需要注意的时，认为执行 EXPLAIN 时MySQL不会执行查询是错误。事实上，如果查询在FROM子句中包括子查询，那么MySQL实际上会执行子查询，将其结果放在一个临时表中，然后完成外层查询优化。 MySQL 必须在可以完成外层查询优化之前处理所有类似的子查询，这对于EXPLAIN来说是必须要做的。这意味着如果语句包含开销较大的子查询或使用临时表算法的视图，实际上会给服务器带来大量工作。这个限制将在 MySQL5.6 之后取消。 2.2 EXPLAIN 中的列要想明白 EXPLAIN 的输出，首先我们要明白EXPLAIN 中的列的含义，其次是每个列可能的取值范围，以及每个值代表的含义。下面 EXPLAIN 输出的每一列的含义: 列名 含义 id 标识SELECT所属的行，内层的SELECT语句一般会顺序编号，对应于其在原始语句中的位置 select_type 表示对应行是简单还是复杂查询，如果复杂查询对应的是哪种复杂查询 table 对应行正在访问的表名 type 访问类型,即MySQL决定如何查找表中的行 possible_keys 显示了查询可以使用哪些索引 key MySQL 决定采用哪个索引来优化对该表的访问，可以是不出现在 possible_keys 的索引 key_len MySQL在索引里使用的字节数，可以用这个值来算出具体是哪些列 ref 显示了在key列记录的索引中查找值所用的列或常量 rows MySQL估计为了找到所需的行而要读取的行数。这个数字是内嵌循环关联计划里的循环数目 filter 它显示的是针对表里符合某个条件（WHERE子句或联接条件）的记录数的百分比所做的一个悲观估算 Extra 不适合在其他列显示的额外信息 idid 标识的是SELECT出现的顺序(不是表出现的顺序)。MySQL将SELECT查询分为简单和复杂类型，复杂类型可分成三大类：简单子查询、所谓的派生表（在FROM子句中的子查询），以及UNION查询。FROM子句中的子查询和联合给id列增加了更多复杂性。 select_typeselect_type 表示查询的类型，有如下几种取值: SIMPLE: 意味着查询不包括子查询和UNION PRIMARY: 如果查询有任何复杂的子部分，则最外层部分标记为 PRIMARY,其他部分标记为下面几种类型 SUBQUERY: 表示在SELECT列表中的子查询中的SELECT（换句话说，不在FROM子句中） DERIVED: 表示包含在FROM子句的子查询中的SELECT UNION: UNION中的第二个和随后的SELECT被标记为UNION，SUBQUERY和UNION还可以被标记为DEPENDENT和UNCACHEABLE UNION RESULT: 表示用来从UNION的匿名临时表检索结果的SELECT DEPENDENT: 意味着SELECT依赖于外层查询中发现的数据 UNCACHEABLE: 意味着SELECT中的某些特性阻止结果被缓存于一个Item_cache中 tabletable 对应行正在访问的表名，可以在这一列中从上往下观察MySQL的关联优化器为查询选择的关联顺序。当FROM子句中有子查询或有UNION时，table列会变得复杂得多: 当在FROM子句中有子查询时，table列是的形式，其中N是子查询的id 当有UNION时，UNION RESULT的table列包含一个参与UNION的id列表 下面是一个复杂SELECT的示例12345678910111213141516171 EXPLAIN2 SELECT actor_id,3 (SELECT 1 FROM sakila.film_actor WHERE film_actor.actor_id =4 der_1.actor_id LIMIT 1)5 FROM (6 SELECT actor_id7 FROM sakila.actor LIMIT 58 ) AS der_19 UNION ALL10 SELECT film_id,11 (SELECT @var1 FROM sakila.rental LIMIT 1)12 FROM (13 SELECT film_id,14 (SELECT 1 FROM sakila.store LIMIT 1)15 FROM sakila.film LIMIT 516 ) AS der_2; typetype 表示 MySQL 决定如何查找表中的行，从最差到最优有如下几种取值: ALL: 全表扫描，通常意味着MySQL必须扫描整张表，从头到尾，去找到需要的行 有例外，如在查询里使用了LIMIT，或者在Extra列中显示“Using distinct/not exists” index: 这个跟全表扫描一样，只是MySQL扫描表时按索引次序进行而不是行，主要优点是避免了排序 缺点是要承担按索引次序读取整个表的开销。这通常意味着若是按随机次序访问行，开销将会非常大 如果在Extra列中看到“Using index”，说明MySQL正在使用覆盖索引，它只扫描索引的数据，而不是按索引次序的每一行 range： 范围扫描就是一个有限制的索引扫描，比全索引扫描好一些，因为它用不着遍历全部索引 当MySQL使用索引去查找一系列值时，例如IN()和OR列表，也会显示为范围扫描。然而，这两者其实是相当不同的访问类型，在性能上有重要的差异 ref: 一种索引访问（有时也叫做索引查找），它返回所有匹配某个单个值的行 只有当使用非唯一性索引或者唯一性索引的非唯一性前缀时才会发生 ref_or_null 是ref之上的一个变体，它意味着MySQL必须在初次查找的结果里进行第二次查找以找出NULL条目 eq_ref 一种索引访问，MySQL知道最多只返回一条符合条件的记录 在MySQL使用主键或者唯一性索引查找时发生 const, system 当MySQL能对查询的某部分进行优化并将其转换成一个常量时，就会使用这些访问类型 例如，如果你通过将某一行的主键放入WHERE子句里的方式来选取此行的主键，MySQL 就能把这个查询转换为一个常量。然后就可以高效地将表从联接执行中移除。 NULL 这种访问方式意味着MySQL能在优化阶段分解查询语句，在执行阶段甚至用不着再访问表或者索引 例如，从一个索引列里选取最小值可以通过单独查找索引来完成，不需要在执行时访问表。 possible_keyspossible_keys 显示了查询可以使用哪些索引,这个列表是在优化过程的早期，基于查询访问的列和使用的比较操作符创建的 key_lenMySQL在索引里使用的字节数， 它并不总显示一个索引真正使用了多少。例如，如果对一个前缀模式匹配执行LIKE查询，它会显示列的完全宽度正在被使用。 rowsrows 显示的行数不是MySQL认为它最终要从表里读取出来的行数，而是MySQL为了找到符合查询的每一点上标准的那些行而必须读取的行的平均数。根据表的统计信息和索引的选用情况，这个估算可能很不精确。在MySQL 5.0及更早的版本里，它也反映不出LIMIT子句。同时很多优化手段，例如关联缓冲区和缓存，无法影响到行数的显示。 filteredMySQL 5.1里新加进去的，在使用EXPLAIN EXTENDED时出现。如果你把rows列和这个百分比相乘，就能看到MySQL估算它将和查询计划里前一个表关联的行数。 ExtraExtra 是额外的提示信息，常见的最重要的值如下： Using index: MySQL将使用覆盖索引，以避免访问表 Using where: MySQL服务器将在存储引擎检索行后再进行过滤 不是所有带WHERE子句的查询都会显示“Using where”，因为在索引列上的 where在存储引擎就可以过滤 有时“Using where”的出现就是一个暗示：查询可受益于不同的索引。 Using temporary: MySQL在对查询结果排序时会使用一个临时表。 Using filesort: 这意味着MySQL会对结果使用一个外部索引排序，而不是按索引次序从表里读取行 MySQL有两种文件排序算法，两种方式都可以在内存或磁盘上完成。EXPLAIN不会告诉你MySQL将使用哪一种文件排序，也不会告诉你排序会在内存里还是磁盘上完成。 Range checked for each record (index map: N): 意味着没有好用的索引，新的索引将在联接的每一行上重新估算 N是显示在possible_keys列中索引的位图，并且是冗余的 3. EXPLAIN 缺陷EXPLAIN只是个近似结果，存在以下缺陷: EXPLAIN根本不会告诉你触发器、存储过程或UDF会如何影响查询。 它并不支持存储过程，尽管可以手动抽取查询并单独地对其进行EXPLAIN操作。 它并不会告诉你MySQL在查询执行中所做的特定优化。 它并不会显示关于查询的执行计划的所有信息 它并不区分具有相同名字的事物。例如，它对内存排序和临时文件都使用“filesort”，并且对于磁盘上和内存中的临时表都显示“Using temporary”。 可能会误导 MySQL EXPLAIN只能解释SELECT查询，并不会对存储程序调用和INSERT、UPDATE、DELETE或其他语句做解释。你可以重写某些非SELECT查询以利用EXPLAIN；MySQL5.6 之后将允许解释非 SELECT 操作 4. MySQL 5.6 对 EXPLAIN 的改进MySQL 5.6中将包括一些对EXPLAIN的重要改进： 能对类似UPDATE、INSERT等的查询进行解释。 允许匿名的临时表尽可能晚地被具体化，而不总是在优化和执行使用到此临时表的部分查询时创建并填充它们。这将允许MySQL可以直接解释带子查询的查询语句，而不需要先实际地执行子查询 这些改进可以帮助我们更好的查看MySQL的执行计划，最后使用 Percona Toolkit包含的 pt-visual-explain 工具可以以树形格式查看查询计划，更加直观容易理解。]]></content>
      <categories>
        <category>存储</category>
      </categories>
      <tags>
        <tag>高性能的MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13. 数据系统的未来]]></title>
    <url>%2F2019%2F04%2F13%2Fdb%2Fdb_100%2F</url>
    <content type="text"><![CDATA[如何构建现代数据系统 1. 构建现代系统前面我们讨论当前流行的技术，接下来我们综合之前所说的所有知识，来谈谈未来的系统应该是什么样子。 1.1 数据集成首先每个软件，即使所谓的通用数据库，也是针对特定的使用模式而设计，第一个挑战就是弄清楚软件产品与他们适合运行环境之间的关系。 其次在复杂的应用中，数据通常以多种不同的方式使用，不太可能存在适用于所有不同环境的软件，因此我们需要数据继承。 当同样的数据的多个副本需要保存在不同的存储系统，以满足不同的访问模式需求时。我们需要弄清楚数据的输入和输出。通过变更数据捕获我们可以保证异构数据系统的一致性。 允许应用程序同时向搜索索引和数据库写入会带来问题。两个客户端同时发送冲突的写操作，两个存储系统以不同的顺序执行它们。 如果可以通过单个系统来决定所有输入的写入顺序，那么以相同的顺序处理写操作就可以更容易的派生出数据的其他形式。无论是使用变更数据捕获还是事件获取日志，都不如简化总体顺序的原则重要。 根据事件日志来更新一个派生系统通常会比较好实现，并且可以实现确定性和幂等性，也因此使系统很容易从故障中恢复。 1.1 派生数据与分布式事务保证异构数据系统的一致性，经典的方法是通过分布式事务。与分布式事务相比，上面描述的派生数据系统怎么样呢？ 抽象点说，它们通过不同的方式达到类似的目标: 分布式事务 通过使用锁机制进行互斥来决定写操作的顺序 使用原子提交保证更改只生效一次 CDC 和事件溯源 使用日志进行排序 基于确定性重试和幂等保证更改只生效一次 最大的不同在于事务系统通常提供线性化，这意味着它可以保证读自己的写等一致性。派生系统通常是异步封信的，所以默认情况下无法提供类似级别的保证。 分布式事务的容错性和性能不尽如意，考虑到好的分布式事务协议未得到广泛支持，基于日志的派生数据是集成不同数据系统最有前途的方法。但是一些保证仍是非常有用的，后面我们会讨论在异步派生系统之上实现更强保证的一些方法。 1.2 全序的局限非常小的系统，构建一个完全有序的事件日志是完全可行的，但是当负载增加时，瓶颈就会出现: 大多数情况下，构建一个完全有序的日志需要所有事件都通过一个主节点来决定排序。如果事件吞吐量大于单节点处理上限，则需要将其分区到多台节点上，这样就是的不同分区的事件顺序变得不明确。 如果服务部署在多个地理位置不同的数据中心，为了高可用，每个数据中心都有自己的主节点。这意味着来自两个不同数据中心的事件顺序不确定 微服务的设计目的是将每个服务与其持久化状态作为独立单元部署，服务之间不共享持久化状态。当两个事件来自不同服务时，事件顺序不确定 从形式上讲，决定事件的全序关系被称为全序关系广播(性能瓶颈)，它等价于共识。大多数共识算法是针对当节点吞吐量足以处理整个事件流而设计的，这些算法不提供支持多节点共享事件排序的机制。 1.3 排序事件以捕获因果关系排序事件是为了捕获因果关系，但是这个问题没有简单的答案。 2. 围绕数据流设计应用程序2.1 应用程序代码与状态分离现在大多数Web 应用程序都被部署为无状态服务，状态势必保存在某个地方，通常是数据库。在这种 Web应用程序模型中，数据库充当一种可以通过网络同步访问的可变共享变量。应用程序如果想知道数据的内容是否变化唯一的选择就是轮询。 从数据流的角度思考应用意味着重新协调应用代码和状态管理之间的关系。我们不是简单将数据库视为被应用程序所操纵的被动变量，而是更多的考虑状态、状态变化以及处理代码之间的相互作用和协调关系。应用程序代码在某个地方会触发状态变化，而在另一个地方有队状态变化做出响应。变更数据捕获和基于日志的事件流可以让我们做到这一点。 维护派生数据与异步作业执行不同: 当维护派生数据时，状态更改的顺序通常很重要 容错性是派生数据的关键，丢失单个消息都将导致派生数据集与数据源不同步。消息传递和派生状态更新都必须可靠。 对稳定的消息排序和可容错的消息处理的要求都非常严格，但是它们比分布式事务代价要小得多，并且在操作上更加稳健。现代流式处理可以对大规模环境提供排序和可靠性保证，并允许应用代码作为stream operator 运行。 订阅变化的流，而不是在需要时去查询状态，使得我们更接近电子表格那样的计算模型: 当某些数据发生更改时，依赖于此的所有派生数据都可以快速更新。 2.2 观察派生状态从数据源到生成派生数据系统，我们把这个过程称为写路径。当用户访问时，所做的数据读取，我们成为读路径。写路径和读路径涵盖了数据的整个过程: 从数据收集到数据使用。读写路径在派生数据上交会，某种程度上，我们所做的系统架构设计就是在写入时需要完成的工作量和读取时需要完成的工作量之间进行的一种权衡。从这个角度看，缓存、索引、实体化视图的角色主要是调整读、写路径之间的边界。 随着 WebSocket 的出现，使得服务器可以主动推送消息至Web应用。就我们的读写路径模型而言，主动推送状态至客户端意味着将写路径一直延伸至终端用户。因此状态变化可以通过端到端的写路径流动: 某个设备上交互行为触发了状态变化，通过事件日志，派生数据系统和流式处理等，一直到另一台设备上用户观察到状态。这种状态变化传播可以做到很低的延迟。 那为什么我们看到的大多数应用都不是这种实现方式呢。这源于目前数据库、开发框架、交互协议对无状态客户端和请求/响应交互根深蒂固的假设。许多数据存储系统的读写操作都是一个请求对应一个响应，很少支持订阅更改。 为了将写路径扩展到最终用户，我们需要从根本上重新思考构建这些系统的方式: 从请求/响应转向发布/订阅数据流。更具响应性的用户界面和更好的离线支持是绝对值得尝试的。 读也是事件我们讨论了当流式处理将派生数据写入存储时，以及请求查询存储时，存储充当了上述写路径和读路径之间的一种可调边界。对存储的写入是通过事件日志进行的，而读取则是即时的网络请求，查询直接路由到那些存储数据节点。这样的流程是合理的，但不是唯一的设计方案。 也可以将读请求表示为事件流，发送至流处理系统，流处理系统则将读结果发送至输出流来响应读事件。这是一种设想，原书接下来的内容已经看不太懂了。 3. 端到端的正确性3.1 Exactly-once 执行操作要想实现呢 exactly-one 语义，最有效的方法之一是使用幂等。但是如果操作本身不是幂等，将其改造成幂等需要一定努力。比如可能需要维护额外的元数据，并确保在节点失效、切换过程中采取必要的 fencing 措施。 3.2 操作标识符为了实现跨多次网络跳转请求而操作仍然具有幂等性，仅仅依靠数据库提供的事务机制是不够的，需要考虑请求的端到端过程。 例如可以为操作生成一个唯一的标识符(如UUID)，并将其作为一个移仓的表单字段包含在客户机应用程序中；或者对所有相关表单字段计算一个哈希值来代表操作ID。如果浏览器两次提交Post请求，则两个请求具有相同的操作ID，然后可以将该操作ID一直传递到数据库，检查确保对一个给定的ID只执行一个操作。 消除重复事务，只是一种更为普遍的端到端论点原则的一例。端到端原则指的是: 只要具备应用程序充分的知识，并且站在通信系统端点的角度的情况下，才能完全正确的实现所关注的功能。因此以通信系统本身的特征来提供这种被质疑的功能是不可能的。 要想实现从Web应用到最终数据的重复消除。单独依赖 TCP 协议在连接层消除重复的包、流处理系统在消息处理级别的 exactly-once 语义是不行的，因为它们都不能防止用户在第一次超时后提交重复的请求。解决这个问题需要一个端到端的解决方案: 从终端用户客户端一致传递到数据库的唯一事务标识符。 端到端的参数也适用于检查数据的完整性: 以太网、TCP 内置的校验码可以检测网络包的损坏情况，但是不能防止收发两端的bug和磁盘的异常。如果想要捕获所有可能的数据源损坏，还是需要端到端的校验和。类似的讨论也适用于加密。底层的功能可以降低更高层次的问题，但不足以确保端到端的正确性。 3.3 在数据系统中采用端到端的思路长期以来，事务被认为是一个非常好的抽象，它将诸多问题归结为两种可能结果: 提交或中止。 事务处理的代价却很高，特别是异构系统。当我们因此代价而放弃分布式事务，就不得不在应用程序代码中重新实现容错机制时。但是关于并发性和部分错误的推理非常困难而且不直观，所以应用程序的容错机制几乎难以正确工作，最终结果是丢失或损坏数据。 更好的容错是非常必要的: 它能够更容易提供特定应用的端到端正确保证，并在大规模分布式环境中依然具有良好的性能和良好的操作。 4. 强制约束4.1 唯一性约束唯一性约束需要达成共识: 多个相同值的并发请求，系统需要决定接受哪个并决绝所有其他的。达成这一共识最简单方法是单一主节点，并负责作出所有决定。如果需要容忍主节点出错，那么又重新回到共识问题上了。采用分区方案可以提高唯一性检查的扩展性，即基于要求唯一性的字段进行分区。但是它无法支持异步的多主节点复制，因为可能会发生不同的主节点同时接受冲突写入，无法保证值唯一。 4.2 基于日志的消息传递唯一性(重要)日志机制可以保证所有消费者以相同的顺序查看消息，这种保证在形式上被称为全序关系广播，它等价于共识。流处理系统在单线程上严格按照顺序来消费处理日志分区中的所有消息。因此如果根据需要保证唯一性的字段进行日志分区，则流处理系统可以清晰、明确地确定多个冲突操作哪一个先到达。 典型的例子: 多个用户尝试声明相同的用户名: 按照用户名哈希值确定分区 流处理顺序读取日志中的消息，并在数据库中跟踪已经使用的用户名，用户名未创建则向输出流发送成功消息，否则发送失败消息 请求用户名客户端观察输出流，并等待请求是否成功或失败 这种方法可以适用于很多类型的约束，其原理是: 任何可能冲突的写入都被路由到特定分区并按顺序处理 4.3 多分区请求处理(重要)当涉及多个分区时，确保操作原子执行且同时满足各种约束条件是很有趣的事情。比如可能有三个分区，一个包含请求ID，一个包含收款人账户，一个包含付款人账户。在传统的数据库中，执行一个转账事务需要横跨所有三个分区进行原子提交。这相当于对三个分区上的所有事务执行了全序排列。由于跨分区协调，性能往往很低。 我们可以实现同等的正确性，但不需要原子提交: 转账请求首先需要客户端生成唯一的请求ID，并基于请求ID追加到对应的日志分区 流处理系统读取请求日志，对每个请求，发送两条输出消息: 到付款人的付款指令，以及到收款人收款指令，请求ID 需要包含在两条消息中 后续操作接收上述指令完成更改应用于账户余额，并通过请求ID进行重复数据消除 如果想确保付款人不发生透支，可以在步骤一前添加另一个流处理操作符: 维护账户余额并验证转账金额，只有不透支才能放入请求日志中。 上述过程中，我们首先持久化地将请求记录为单条消息，然后从第一条消息派生出收款和支付两条指令。单一对象写入在几乎所有的数据系统中都是原子的。而如果是客户端直接发送收款和付款指令，则需要在两个分区之间进行原子提交以确保两者都成功或者都不成功。 如果步骤二崩溃，从上一个快照检查点，这样做不会跳过任何消息，但可能多次处理消息，步骤3中基于端到端的请求ID可以轻松实现重复消除。 通过将多分区事务划分为不同分区的处理阶段，并使用端到端的请求ID，我们实现了同样的正确性。 5. 时效性和完整性(重要)事务的一个重要属性是可线性化: 数据写入后立即对所有读者可见。但是跨多个处理阶段的流操作，情况并非如此。日志的消费者模式是基于异步设计的。因此发送者不等待消息处理，完事客户端可能会等待消息出现在输出流中。 概括将，一致性将两个值的分开考虑的不同需求: 时效性和完整性合二为一了: 时效性: 意味着确保用户观察到系统的最新状态 CAP提供基于线性化的一致性，这是实时性的强有力保证 弱实时性，比如读自己写也很有用 完整性 意味着避免数据损坏，即没有数据丢失，也没有互相矛盾或错误的数据 总而言之，违反实时性导致最终一致性，违反完整性则是永久不一致，显然完整性比实时性重要的多。 5.1 数据流系统的正确性ACID 事务通常既提供实时性保证(线性化)，也提供完整性保证(原子提交)。因此对于ACID 事务，时效性和完整性之间的区别无关紧要。 基于事件的数据流系统，将时效性和完整性分开了。在异步处理事件流时，除非在返回之前明确创建了等待消息到达的消费者，否则不能保证实时性。完整性是流处理系统的核心。 只执行一次是一种保证完整性的机制。如果事件丢失或者发生两次，数据系统的完整性可能会被破坏，因此容错的消息传递和重复消除对面对故障时保持数据系统的完整性非常重要。 正如我们前面看到的，可靠的流处理系统可以在不需要分布式事务和原子提交协议的情况下保证完整性。我们主要是通过一下机制实现这一完整性的(非常重要): 将写入操作的内容表示为单条消息，可以轻松采用原子方式 使用确定性派生函数，从这条消息派生所有其他状态的更新操作 通过所有这些级别的处理来传递客户端生成的请求ID，实现端到端重复清楚和幂等性 消息不可变，并支持多次重新处理派生数据，从而使得错误恢复变得更容易 5.2 宽松的约束(重要)如前所述，保证唯一性约束需要共识，通常通过单个节点汇集特定分区的所有事件来实现。如果想达到传统的唯一性约束，上述处理限制对于流处理系统必可避免。 但是实际上许多应用程序采用了较弱的唯一性来摆脱该限制。在许多商业环境中，实际上可以接受暂时违反约束，稍后通过道歉流程来修复。不如超售机票，然后道歉。道歉成本是否可接受是一个商业决策。如果可接受，在写入数据库之前检查所有约束的传统模型是不必要的限制，并且不需要线性化的约束。继续写入操作，并在既成事实之后检查约束，可能成为一个合理的选择。你仍然可以在发生恢复代价昂贵的事情之前进行验证，但并不意味着在写入数据之前必须进行验证。 而这些应用程序都需要完整性。 5.3 无需协调的数据系统现在我们有两个有趣的结论: 数据流系统可以保证派生数据的完整性，无需原子提交，线性化或跨分区的同步协调 虽然严格的唯一性约束要求时效性和完整性，但是只要整体上保证完整性即使发生暂时约束损坏，也可以事后修复，因此许多应用程序实际采用宽松式的约束并没有问题 总之数据流系统在提供强大完整性的同时，避免了分区之间的协调。与需要执行同步协调的系统相比，可以实现更好的性能和容错能力。在这种情况下: 可串行化事务作为维护派生状态的一部分仅在限定的范围内有效 异构分布式事务(如XA)并不是必须的 同步协调只在需要的地方引入(例如在不可恢复的操作之前执行严格的限制)，但是如果只有一小部分应用程序需要，就没有必要所有事务都进行协调。 另一种理解协调和约束的方法是: 它们减少了由于不一致而引发的道歉数量，但是也可能降低系统的性能和可用性，并由此可能增加业务中断和引发的道歉数量。你需要在这之间找到最佳的折中方案: 既不能有太多的不一致，也不能出现太多可用性问题。 6. 信任，但要确认我们所有关于正确性、完整性、容错性的讨论都是基于某些事情会出错，而其他事情不会出错的假定基础上。我们将这些假设称为我们的系统模型。例如我们假定进程会崩溃、网络会丢包，但我们也假设写入磁盘并且强制同步命令 fsync 执行后不会丢失，内存中的数据结构不会被破坏，CPU 的乘法指令总是返回正确的结果。基于怎样的假设，依赖于事件发生的概览。 如果有足够多的的设备来运行你的软件，即便再不可能的事情也有可能发生。除了由于硬件故障或辐射导致的随机内存损坏之外，某些不合规的存储器访问模式可以在内存完好情况下导致位翻转。(这是极限情况下，才可能发生的) 6.1 不要盲目信任承诺软硬件并不能总处于理想撞他，因此我们至少需要有办法查明数据是否已经损坏，以便之后修复这些数据。检查数据的完整性也被称为审计。成熟的系统会考虑不太可能的事情出错的可能性，并主动管理这些风险。例如 HDFS 和 Amazon S3 等大型存储系统不完全信任磁盘: 它们运行后台进程，不断读取文件，将其与其他副本进行比较，并将文件从一个磁盘移动到另一个磁盘，以减轻无提示数据损坏的风险。 我们需要这样自我验证和自我审计的系统。 检查数据系统的完整性最好以端到端的方式。 7. 做正确的事7.1 预测性分析我们将数据作为一个抽象的东西来讨论，但是许多数据集都是有关人的。我们必须以人性和尊重来对待这些数据。 预测分析系统只是基于过去而推断，如果过去有偏见，它们就会把这种偏见编码下来。如果我们希望未来比过去更好，你妈就需要道德想象力。数据和模型应该只是工具而不是我们的主人。 当预测分析影响人们的生活时，特别是由于自我强化反馈环路而出现一些有害问题。比如信用评分低的人，越受到社会的不信赖，信用评分越低。在我们设计一个系统时，我们需要系统的思考，尝试理解一个数据分析系统是如何响应不同的行为、结构和特征。系统是否强化好饿扩大了人们之前的差异。还试图打击不公平性。 7.2 数据隐私与跟踪我们所使用的应用无时无刻不在收集有关个人的隐私数据。对于不同意被监视的用户，唯一的选择就是不使用服务。但是这个选择也不是免费的: 如果某一项服务非常受欢迎以至于被大多数人认为是基本的社会参与所需要的，那么指望人们选择退出这项服务是不合理的，使用它编程一种实时性强制约束，比如微信。对于大多数普通人，选择自由没有意义，被监视变得不可避免。 数据隐私和使用拥有隐私并不意味着一切事情都要保密，它意味着你可以自由选择向谁展示，并展示哪些东西，要公开什么，要保密什么。隐私权是一个决定权：每个人都能够决定在各种情况下如何在保密和透明之间取舍。这事关个人的自由和自主。 通过各种应用从人们身上提取数据，隐私不一定被破坏，而知转移到了数据收集者。作为应用和数据系统的开发者，我们有责任明确的设计程序使得它们尊重人类的需求，否则算法对此没有概念。我们必须前序、乐于接受并为之做好准备。 审视他人但避免自我审查是最重要的权利形式之一，尽管今天的科技公司并没有公开的寻求某些权利，但是它们锁积累的数据和知识给了它们很大的控制权利，而且很多是私下进行，不在公众的监督之内。 作为工程师，我们有责任为我们赖以生存的世界而努力: 一个以人性和尊重来对待人的世界。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12. 流处理系统]]></title>
    <url>%2F2019%2F04%2F12%2Fdb%2Fdb_12%2F</url>
    <content type="text"><![CDATA[派生数据 1. 流处理系统前面讨论的批处理系统存在一个重要的假设: 输入是有界的，是已知的有限大小，所以批处理知道何时读完他们。比如MapReduce 核心的排序操作必须读取整个输入，然后才开始生成输出。 而实际上，有很多数据是无限的，而且随着时间的推移逐渐到达。数据集永远不会以任何有意义的方式”完成”。而批处理则必须人为将数据划分为固定时间段的数据库分批处理。批处理的问题是，输入的更改只会在一天之后的输出中反映出来。为了更快的响应用户，我们需要完全放弃固定的时间片，每当有事件就开始处理，这就是流处理背后的思想。 1.1 发送事件流在流处理的上下文中，记录通常被称为事件，改事件或者说对象，包含某个时间点发生的事件的细节。每个事件通常包含一个时间戳，用于指示事件发生的墙上时间。 事件由生产者生成一次，然后可能由多个消费者处理。相关的事件通常被组合成主题或流。为了更低的响应延时，当新事件出现时，最好通知消费者。 1.2 消息系统向消费者通知新事件的常见方法是使用消息系统。在这种发布/订阅模式中，不同的系统采用了不同的方法，为了区分这些系统，提出以下两个问题对区分很有帮助: 如果生产者发送消息的速度比消费者能处理的快，会发生什么？ 一般有三种选择: 系统丢弃消息；将消息缓存在队列中；激活背压(流量控制，即阻止生产者发送消息) 如果消息被缓存在队列中，那么队列增长时会发生什么非常重要 如果内存无法容纳所有队列，系统是否会崩溃，还是消息会被写入磁盘 如果消息会落盘，又会如何影响消息传递系统的性能 如果节点崩溃或者暂时离线，是否会有消息丢失? 持久化需要写入磁盘或者结合复制方案，这些都是有成本的 如果能够接受消息丢失，那么同样的硬件上可以获得更高的吞吐量和更低的延迟 消息传递有如下几种方式: 生产者与消费者之间直接消息传递 消息代理 生产者与消费者之间直接消息传递这种方式通常要求应用程序意识消息丢失的可能性，它们只支持有限的容错。通常还假定生产者和消费者同时在线。诸如 RPC 和 HTTP 请求，webhooks 都是这种消息传递方式 消息代理消息代理本质上是一种针对处理消息而优化的数据库。将数据集中在代理上，可以更容易的适应不断变化的客户端。持久性问题被转移到代理。消息写入代理的结果也通常导致消费以异步方式工作。 多个消费者当多个消费者读取同一主题中的消息时，有两种主要的消息传递模式: 负载均衡式: 每一条消息都只被传递给其中一个消费者，所以消费者可以共享主题中处理消息的工作 通过增加消费者可以并行处理消息 扇出式: 每条消息都被传递给所有的消费者 独立的消费者独立接收相同的消息广播 这两种模式可以组合使用 确认和重传消费者可能在未处理完消息时就已经奔溃，为了确保消息不会丢失，消息代理使用确认: 客户端必须在处理完消息后显示的告诉代理，以便代理可以将其从队列中移除。 但是消息的确认/重传会导致以下两个问题: 消息重复: 确认的消息可能在发送给代理的过程中丢失，导致代理重复发送和消息 消息乱序: 与负载均衡结合时，重传机制不可避免的会导致消息被重新排序，为了避免这个问题，可以为每个消费者使用单独的队列(即不使用负载均衡) 注意如果消息之间存在因果依赖关系，消息的顺序就是至关重要的。 2. 分区日志消息代理是基于瞬间的消息传递思想构建的，因此尽管可以永久记录消息，但通常也不会这么做。如果将新的消费者添加到消息系统，通常它只会开始接收在它注册后发送的消息；任何之前的消息已经消失。 那为什么不把数据库的持久存储和消息传递的低延迟结合起来呢？这正是日志消息代理背后的思想。 2.1 基于日志的消息存储日志是磁盘上一个仅支持追加式修改记录的序列。与日志结构化存储引擎类似，我们可以使用相同结构来实现消息代理: 生产者通过将消息追加到日志的末尾来发送消息 消费者通过一次读取日志来接受消息 为了提升吞吐量，可以对日志进行分区，在每个分区中，代理为每个消息分配一个单调递增的序列号或偏移量。因为分区日志只能追加，所以分区内的消息是完全有序的。不同分区之间则没有顺序保证。 kafka、Amazon Kinesis Stream 和 Twitter DistributedLog 都是这种基于日志的消息代理系统。尽管这些消息代理将所有消息写入磁盘，但是通过多台机器进行分区，能够实现每秒数百万条消息的吞吐量，并且通过复制消息实现容错性。 因为多个消费者可以独立读取日志而不相互有影响，而且消息不会从日志中删除，所以基于日志的方法很自然的支持扇出式消息传递。通过将整个分区分配给消费者组中的节点，每一个节点消费一个分区，可以在一组消费者之间实现负责均衡。 通常当消费者被分配了一个日志分区时，它会以直接的单线程方式顺序读取分区中的消息，这种粗粒度的负载均衡有一些缺点: 消费者的最大数量等于主题的分区数 如果单个消息处理缓慢，会阻碍分区中后续消息的处理。可以将消息处理扩展至线程池，但这种方法消息的确认和消费者偏移管理变得复杂，通常单线程是优选。 对比日志与传统消息系统AMQP 类型的消息代理更适合如下场景: 消息处理的代价很高，希望在逐个消息的基础上并行处理 而且消息排序又不那么重要的情况下，并且需要在他们处理后返回并在此读取旧消息时 更可取 相反，基于日志的消息系统更适用于: 在消息吞吐量高，每个消息处理速度快 消息顺序有很重要 需要读取已经确认的旧消息 消费者偏移量消费者偏移量用于记录消费者已经消费的消息位置，这样就无须跟踪每条消息的确认，减少记录开销。这种偏移量与主从复制数据库中的日志序列号非常相似。 如果消费者节点失败，消费者组中的另一节点将被分配到失败的消费者分区，并以最后记录的偏移量开始使用消息。 磁盘使用不断追加的日志，磁盘空间最终会被耗尽。为了回收磁盘空间，日志实际上被分割成段，并不时地将旧段删除或归档保存。实际上，日志实现了一个有限大小的缓冲区，当缓冲区变满时，旧的消息被丢弃，该缓冲区被称为环形缓冲区。由于缓冲区在磁盘上，因此可以非常大。 消费者跟不上生产者时一开始我们讨论消费者跟不上生产者发送消息的速度时由三种选择。基于日志的方法是一种缓冲形式，它具有较大但固定大小的缓冲区。因此消费者落后太多，代理将丢弃缓冲区容量不能容纳的旧消息。可以监控消费者落后日志头部的距离，并在落后明显时发出警告。由于缓冲区很大，通常有足够的时间去修复缓慢的消费者，并允许它在开始丢失消息之前赶上。 即便落后太多并开始丢失消息也只有该消费者会受到影响，他不会中断其他消费者的服务。这是基于日志方法的消息代理带来的运营优势。在传统的消息代理中，需要小心删除消费者已经关闭的任何队列，否则他们讲继续不必要的积累消息，并占用其他活动消费者的内存。 重新处理消息使用AMQP 风格的消息代理，由于会导致消息在代理上被删除，因此处理和确认操作可视为带有一定破坏性。另一方面基于日志的消息代理中，使用消息更像是从文件读取，并不会更改日志。除了消费者的输出外，唯一的副作用是消费偏移量前移了。但是偏移量在消费者的控制之下，可以轻松对其进行操作了。 这个特点使得基于日志的消息系统更像之前讲的批处理系统过程。派生数据通过可重复的转换过程与输入数据明确分离。支持更多的实验性尝试，也更容易从错误和故障中进行恢复。从而成为集成数据流的不错选择。 3. 数据库与流事件是某个时刻发生的事情的记录，发生的事件可以是用户的操作，当然也可以是写入数据库。将内容写入数据库的事实是一个可以被捕获、存储和处理的事件。这一观察结果表明，数据库和数据流之间的联系比磁盘上日志的物理存储更紧密。 实际上复制日志是数据库写入事件的流，由主节点在处理事务时生成。从节点将写入流应用于他们自己的数据库副本，从而最终得到相同数据的准确副本。复制日志的事件描述了数据变化。 我们还在全序广播的中讨论了状态机复制原理，该原理指出: 如果每个事件代表对数据库的写入，并且每个副本按照相同的顺序处理相同的事件，则所有副本都将收敛于相同的最终状态。 3.1 保持系统同步没有一个系统能够满足所有的数据存储、查询和处理需求。一个大型应用通常由多个异构系统组成，这些异构系统都有自己的数据副本，以自己的表示方法存储，并针对自己的设计目标优化。由于相同和相关的数据出现在多个不同的地方，因此它们需要保持同步: 如果数据库中的某项更新，则也需要在缓存、搜索引擎、数据仓库中进行更新。 保证异构系统数据同步的一种方法是使用 ETL，即批处理。如果定期的完整数据库转储过于缓慢，有时使用的替代方法是双重写入，由程序代码在数据更改时显示的写入每个系统。但是双重写入有一些严重的问题: 因为写入是有不同客户端在并发写请求同时完成的，因此可能存在竞争条件(入下图) 其中一个写入可能成功，而另一个可能失败，确保他们都成功或者失败属于原子提交范畴 3.2 变更捕获变更数据捕获(Change Data Capture CDC) 记录了写入数据库的所有更改，兵役可复制到其他系统的形式提取数据。如果在写入时立即将更改作为一种流来发布(更改日志)，其他派生数据系统知识变更流的消费者，只要所有异构系统以相同的顺序应用于更改日志，那么所有异构系统将与数据库匹配。注意数据库系统会保证写入顺序，而在双重写入中并没有任何机制来保证多个客户端对所有系统都具有相同的写入顺序。 实现变更数据捕获从本质上讲，变更数据捕获使得一个数据库称为主节点(捕获变化的数据库)，并将其他编程从节点。由于基于日志的消息代理保留了消息的顺序，因此它非常适合从源数据库传输更改时间。 解析复制日志一捕获变更数据的好办法。LinkedIn Databus、Facebook Wormhole 和 Yahoo Sherpa 已经大规模部署。Bottled Water 使用解码雨鞋日志的 API 实现了 PostgreSQL 的 CDC，Maxwell 和 Debezinum 通过解析 binlog 为 MySQL 做类似的事情，Mongoriver 读取 MongoDB 的 oplog，Oracle GoldenGate 也提供类似功能。 像消息代理一样，变更数据捕获通常是异步的: 记录系统不会再提交变更之前等待应用于消费者。这样做的优势是添加缓慢的消费者不会对记录系统产生影响，但是所有复制滞后问题在这里全部适用。 越来越多的数据库开始支持将变更流作为标准接口，例如 RethinkDB 支持订阅查询结果发生变化的通知，Firebase 和 CouchDB 的数据同步基于 change feed 并同时提供给应用层，而Meteor 适用 MongoDB oplog 来订阅数据更改消息并更新用户界面。 VoltDB 支持事务以流的形式连续从数据库导出数据。kafka Connect致力于将广泛的数据库系统变更数据采集工具与kafka 集成。一旦更改事件流汲取到 kafka，它就可以用来更新派生数据系统。 4. 事件溯源事件溯源类似于变更数据捕获，但是它在不同的抽象层次上应用了这个想法。事件溯源类似于编年史数据模型，其小心的区分命令和事件，用户的请求到达时，它最初是一个命令，它必须被验证。如果验证成功，它将变成一个持久且不可变的事件。 与批处理受益于其输入文件的不变形。这种不变形原则也是事件溯源和变更数据捕获如此强大的原因。 我们通常将数据库看成是用来存储应用程序的当前状态，这种表示针对读取进行了优化。每当状态变卦，改状态就反映了随着时间推移而变化的事件的结果。无论状态如何变化，总有一系列事件导致这些变化。关键思路是可变的状态和不变事件的追加日志不想矛盾。 应用状态是事件流对时间的积分得到的，而变化流式状态对时间求导得到的。 事务日志记录了对数据库所做的所有更改。高速追加式更改日志的唯一方法。从这个角度看，数据库的内容保存了日志中最新记录值的缓存。日志是事实，数据库是日志子集的缓存。日志压缩则是链接日志和数据库区别的一种方式，它保留每条记录的最新版本，并丢弃被覆盖的版本。通过不可变事件的追加日志，诊断问题和从问题中恢复就要容易得多。 4.1 相同的事件日志派生多个视图此外通过从不变事件日志中分离可变状态，可以从相同的时间日志派生出多个面向读取的表示方式。分析型数据库Druid使用这种方式直接从Kafka摄取数据，Pistachio是一个分布式的键值存储，使用Kafka作为提交日志，Kafka Connect sinks能将来自Kafka的数据导出到各种不同的数据库与索引。 从事件日志到数据库有一个明确的转换步骤，可以更加容易的随时间来演进应用程序: 如果想要引入一个新的方式呈现现有数据，可以使用事件日志来构建一个单独针对新功能的读取优化视图，并与现有的系统一起运行，而不要修改它们。 如果不必担心如何去查询和访问数据，那么存储数据通常是非常简单的。模式设计、索引和存储引擎的许多复杂性多是源于希望支持某些查询和访问模式。因此将数据写入形式与读取形式分开，并允许多个不同的读取视图，可以获得更大的灵活性。这个想法有时被称为命令查询责任分离。 数据库和模式设计的传统方法是基于数据查询和数据写入的形式必须相同这一谬误。如果可以将数据从针对写入优化的事件日志转换为针对读取优化的应用状态，那么有关规范化和非规范化的争论就变得无关紧要了（参阅“多对一和多对多的关系”）：由于转换过程提供了响应机制使其与源事件日志保持一致，因此在度优化的视图中对数据进行反规范化处理完全合理的。 4.2 不可变的限制事件捕获和变更数据捕获的最大缺点是事件日志的消费者是异步的，所有用户可能会写入日志，然后日志派生的视图中读取，却发现这些写操作还没有反应在读取视图中。 此外对于频换变化的数据集，保留所有变化的历史是不可行的，碎片化也可能称为一个问题，并且压缩和垃圾回收的性能对于运维的健壮性变得至关重要。 除了性能，还可能在某些情况下，由于监管方面的原因需要删除数据，尽管要求这些数据都是不可变的。比如法规要求用户关闭账户后必须删除个人所有数据。在这种情况下，标记删除是明显不够的。真正的删除数据反而会变得非常困难，因为数据副本可能在很多地方都有。 5. 流处理前面我们已经讨论了流的来源，讨论了流是如何传输的，接下来我们要讨论的是: 有了流之后，可以用它来做什么，即怎么处理它，通常有三种选择: 数据同步: 将数据写入数据库，缓存，搜索引擎等其他异构系统 通过某种方式推送给用户 处理一个或多个输入流以产生一个或多个输出流 接下来我们将讨论选项3: 处理流以产生其他派生流。它与前面讨论 MapReduce 密切相关，并且数据流的模式是类似的: 流处理器以只读的方式接收输入流，并以仅追加方式将处理输出写入新的位置。流与批量作业的一个关键区别是，流不会结束。这种差别有很多含义: 排序对无界数据集没有意义，因此不能使用排序合并 join 容错机制必须改变: 对于已经运行了几分钟的批处理作业，可以简单从头开始重新执行，但是对于运行了好几年的流处理作业，重新执行几乎不可能 5.1 流处理的适用场景流长期以来一直被用于监控目的，随着时间推移也出现了如下的新用途: 复杂事件处理: 流分析: 按照一个时间窗口对数据进行聚合操作 维护物化视图: 变更数据捕获来保持不同数据系统间的数据同步 在流上搜索 消息传递和 RPC 5.2 流的时间问题流处理系统经常需要和时间打交道: 许多流处理框架使用处理节点上的本地系统时钟(处理时间)来确定窗口，但这个有效的前提是事件发生和事件处理的间隔可以忽略不计，然而显著滞后的情况也时有发生。 事件时间和处理时间事件处理时间比发生时间滞后的原因有很多，例如排队、网络故障、重启动消费者、重新处理过去的事件等等。而且消息延迟还可能导致消息的不可预知排序。混淆事件发生时间和处理会导致错误的结果。 什么时候准备就绪如果基于事件发生时间而定义窗口，面临一个棘手的问题是，你无法确定什么时候能收到特定窗口内的所有事件，或者是否还有一些事件尚未到来。由于网络中断和延迟，可能某些发生的事件还缓存在另一台机器上。需要能够处理在窗口已经声明完成后才到达的这样的滞后事件。大体上行有两种选择: 忽略这些滞后事件 发布一个更正: 针对滞后事件的一个更新值 你用谁的时间当事件可能在系统的多个点缓冲时，为事件分配事件比较困难。考虑一个可离线使用的应用: 事件可能在本地离线缓存，在下一次连接网络时被发送至服务器。这时事件的时间戳实际上指的是发生交互时的时间，然后用户设备上的时间通常是不可信的 服务器收到事件的时间可能更准确，但在描述用户交互方面的意义不大 为了调整不正确的设备时钟，一种方法是记录三个时间戳: 根据设备的时钟，记录事件发生的时间 根据设备的时钟，记录事件发送到服务器的时间 根据服务器时钟，记录服务器收到事件的时间 3-2 可以估计出设备和服务器时钟之间的偏移量，从而估算出事件实际发生的时间。 5.3 窗口类型一旦明确了如何确定事件的时间戳，下一步就是决定如何定义时间段即窗口，有如下几种常见的窗口类型: 轮转窗口: 翻滚窗口的长度固定，每一个事件都属于一个窗口 跳跃窗口: 跳跃窗口也有固定长度，但允许窗口重叠以提供一些平滑过渡 滑动窗口： 滑动窗口包含在彼此的某个时间间隔内的所有事件 会话窗口：没有固定的持续时间，通过将同一用户在时间上机密相关的所有事件分组在一起而定义 5.3 流式 join因为流的无界，以及新事件随时可能出现在流中，使得流式join比批处理作业更具挑战性，我们区分了三种不同类型的join: 流与流join 流与表join 表与表join 流与流join流与表join表与表join这三种类型的 join 有很多相似之处，它们都需要流处理系统根据一个 join 输入 来维护某些状态，并在来自另一个 join 输入的消息上查询状态。 维持这个状态的事件的顺序非常关键。在分区日志中单个分区内的事件顺序被保留，但是通常不同流或分区之间没有排序保证。这就产生一个问题: 如果不同流中的事件发生在相近的时间里，它们按照何种顺序进行处理。在流与表的join 中，如果用户更新了资料，哪些活动事件会与旧资料join，哪些又与新资料join。换句话说，如果状态随时间改变，join 操作需要输入状态信息，那么应该使用什么时间点的状态来 join 呢？ 如果垮流的时间排序是不确定的，那么 join 也变成非确定性的。这意味着不能在相同的输入上重新运行同一作业来得到相同的结果: 因为再次运行任务时，输入流上的事件可能以不同的方式交叉在一起。 5.4 流处理容错流处理面临和批处理一样失败任务重试的问题。但是处理起来并不简单: 流处理无法像批处理一样，在使输出结果可见之前等待某个任务完成，因为流是无限的，因此几乎永远无法完成这个任务。 微批处理和校验点一种解决方案是将流分解成多个小块，冰箱小型批处理一样处理每个块。这种方法称为微批处理，已经用于 SparkStreaming。批处理大小通常约为 1s，这是一个折中的考虑: 较小的批处理会导致更大的调度和协调开销 较大的批处理意味着流处理器的结果需要更长的延迟才能看见 微批处理隐含的设置了与批处理大小相等的轮转窗口(基于处理时间而不是事件时间)。任何需要更大窗口的作业都需要显示的将状态从一个微批处理保留至下一个微批处理。 Apache Flink 中使用了该方法的一个变体，它定期生成状态滚动检查点并将其写入持久化存储。如果流操作发生崩溃，他可以从最近的检查点重新启动，并丢弃检查点和崩溃之间的所有输出。检查点由消息流中的barrier 触发，类似于微批处理的边界，但不强制特定的窗口大小。 在流处理框架内，微批处理和检查点提供了与批处理一样的恰好一次语义，但是一旦输出脱离了流处理系统，框架将无法丢失失败批处理的输出。 微批处理存在处理之后消息和跨批量边界的窗口等问题。 重新审视原子提交在出现故障时，为了看起来实现恰好一次语义，我们需要确保当且仅当处理成功时，所有输出和副作用才生效。这包括发送给下游的操作和外部消息传递系统的任何消息。所有数据库写入，以及对操作状态的更改和任何对输入消息的确认。 这些事要么原子的发生，要么都不发生，我们在之前分布式事务和共识中已经有所讨论。 幂等性我们的目标是丢弃任何失败的部分输出，以便可以安全的重试而不会两次生效。分布式事务是实现的一种方式，另一种方式则是依赖幂等性。即使操作本身不具有幂等，往往也可以使用一些额外的元数据(唯一键)使其变得幂等。 依赖幂等性意味着基于一些假设: 重启失败的任务必须以相同的顺序重新处理相同的消息，处理必须是确定的，并且没有其他节点并发更新相同的值。 任何需要状态的流处理，都必须确保在故障发生后状态可以恢复。有两种选择: 将状态保存在远程存储中并采取复制，然而为每个消息去查询远程数据库可能会很慢 将状态保存在本地，并定期进行复制 当流处理器从故障中恢复时，新任务可以读取副本并在不丢失数据的情况下恢复处理。在某些情况下，甚至可能不需要复制状态，而是从输入流开始重建。 所有权衡取决于底层基础架构的性能表现，网络延迟和磁盘访问延迟，网络带宽和磁盘带宽到底谁大，都是需要权衡的因素。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11. 批处理系统]]></title>
    <url>%2F2019%2F04%2F11%2Fdb%2Fdb_11%2F</url>
    <content type="text"><![CDATA[派生数据 1. 组合的数据系统前面我们讨论了分布式系统所有主要注意事项，但是这些讨论都只包含一个数据库。事实上数据系统是复杂的，通常需要以多种方式访问和处理数据，并且一个数据库往往无法同时满足所有不同的需求。因此应用程序需要使用若干不同的数据存储区、索引、高速缓存、分析系统等的组合，并实现数据从一个存储系统移动到另一个存储系统。 接下来我们将讨论如何将不同数据系统(具有不同数据模型，并针对不同访问模式进行过优化)整合至一致的应用程序体系结构中。 整合不同系统是大型应用中最为关键的任务之一。 1.1 记录系统与派生数据系统存储和处理数据的系统可以分成两类: 记录系统: 真实数据系统，拥有数据的权威版本 派生数据系统: 从其他系统中获取已有数据并转换或处理而来 非规范化数值、索引、物化视图都属于派生数据类别 派生数据是冗余的，但是其对于获取良好的读取查询性能至关重要 作这样的区分是为了明确系统中的数据流: 明确系统中的某部分有哪些输入和输出，以及它们之间的依赖关系。通过弄清楚数据的来龙去脉，来帮助厘清复杂的系统架构。 2. 批处理系统按照交互的不同方式，我们可以区分出三种不同类型的系统: 在线服务(在线系统) 服务等待客户请求，服务尽快处理并发回响应 响应时间通常是服务性能的衡量指标，而可用性同样重要 批处理系统(离线系统) 接收大量的输入数据，运行一个作业来处理输出，并产出数据 作业执行需要一定时间，用户通常不对等待作业完成 吞吐量是这类系统的衡量标准 流处理系统(近实时系统): 介于在线与离线系统之间 接下来我们将介绍 MapReduce 和其他一些批处理算法和框架。 3. MapReduce 和分布式文件系统MapReduce 有点像分布在数千台机器上的 UNIX 工具，与 UNIX 命令行工具类似，这是一个相当直接、蛮力、却有效的神奇组件: 需要一个或多个输入，并产生一个或多个输出 不会修改输入，处理生成输出外没有任何副作用 输出文件以序列方式一次性写入 UNIX 使用 stdin 和 stdout 作为输出和输出，MapReduce 作业在分布式文件系统上读写文件 3.1 分布式文件系统分布式文件系统有很多，譬如: Hadoop 的 HDFS GlusterFS 和 Quantcast File System(QFS) 诸如 Amazon S3，Azure Blob 存储和 OpenStack Swift 对象存储服务也有很多相似之处 与网络连接存储 NAS 和 存储区域网络 SAN 架构的共享磁盘方法相比，HDFS 基于无共享原则。共享磁盘存储由集中式存储设备实现，通常使用定制硬件和特殊网络基础设施。而无共享方法则只需要通过传统数据中心网络连接的计算机。 HDFS 有以下几个部分组成: HDFS 的每台机器上运行着一个是守护进程，并会开放一个网络服务以允许其他节点访问存储在该机器上的文件 名为 NameNode 的中央服务器会跟踪哪个文件块存储在哪台机器上 考虑机器和磁盘的容错，文件块被复制在多台机器上 计算时计算任务会就近安排在存储所需文件的机器上，避免大量的数据传输成本(被称为: 将计算靠近数据) 3.2 MapReduce 的分布式执行MapReduce 分为 map 和 reduce 两个过程，map 的输出始终会在排序之后在传递给 reducer: Mapper 每个输入记录都会调用一次 mapper 程序 任务是从输入记录中提取关键字和值 每个记录可以生成任意个键值对 Reducer: MpaReduce 框架使用由 mapper 生成的键值对，收集属于同一个关键字的所有值，并使用迭代器调用 reducer 以使用该值集合。 MapReduce 的并行化是基于分区的，作业的输入通常是 HDFS 的一个目录。输入目录中的每个文件或文件块都被视为一个分区。每个分区由一个单独的 map 任务处理。MapReduce 调度器会尝试在输入文件副本的某台机器上运行 mapper 任务(计算靠近数据)，避免数据的复制，提高访问的局部性。 如上图所示，分布式的计算过程分成了如下几个步骤: 代码分发: 将 map 任务所运行的应用程序代码分配到运行任务的节点上 map 任务执行: 启动 map 任务，每次读取一条记录传递给回调函数 mapper，输出键值对 键值排序: 为了确保具有相同关键字的所有键值对都在相同的 reducer 任务中处理，框架使用关键字的哈希值来确定哪个 reducer 任务接收特定的键值对 键值对必须排序，排序是分阶段进行的 首先每个 map 任务都基于关键字哈希值，按照reducer对输出进行分块 每个分块都被写入 mapper 程序所在本地磁盘上的已排序文件，使用的计数类似于 SSTable 和 LVS-Trees shuffle: mapper 读取完输入并写入经过排序的输出文件后，reducer 与 mapper 相连接，并按照其分块从 mapper 中下载排序后的键值对文件 reduce 从 mapper 获取文件并将它们合并在一起，同时保持数据的排序 reducer 执行: reducer 通过关键字和迭代器进行调用，迭代器逐步扫描所有具有相同关键字的记录，并将输出结果写入 HDFS 中 3.3 MapReduce 工作流单个 MapReduce 作业可以解决的问题有限，将 MapReduce 作业链接到工作流非常普遍。一个作业的输出将成为下一个作业的输入。Hadoop MapReduce 对工作流没有任何特殊的支持，作业的链接是通过目录名隐式完成的。每个MapReduce 作业的输出被写入到临时文件，下一个 MapReduce 命令从临时文件中读取(这被称为中间状态实体化)。 工作流中的一个作业只有在先前的作业成功完成时才能开始，为了处理这些作业执行之间的依赖关系，已经开发了各种 Hadoop 的工作流调度器，包括: Oozie,Azkaban, Luigi, Airflow 和 Pinball。Hadoop 的各种高级工具(如 Pig，Hive，Cascading，Crunch 和 FlumeJava) 则支持设置多个 MapReduce 阶段的工作流，这些不同的阶段会被恰当的自动链接起来。 3.4 Reduce 端的 Join 与分组数据集通常存在关联，在批处理的背景下讨论 join，我们主要是解决数据集内在关联的所有事件。 join 的最简单实现是逐个遍历活动事件，并在远程服务器上的用户数据库中查询每个遇到的用户 ID。但是这一个方案性能非常差，原油是: 吞吐量受到数据库服务器的往返时间限制，本地缓存的有效性将很大程度上取决于数据的分布 同时运行的大量并行查询很容易是数据库不堪重负 远程数据库中的数据可能会发生变化，查询远程数据库意味着增加批处理作业的不确定性 因此更好的方式是获取用户数据库的副本(ETL)，并将其放入与用户活动事件日志相同的分布式文件系统，并使用 MapReduce 进行数据合并。 排序-合并join以用户 ID 为键执行的 reduce 端排序-合并join 如下图所示: 经过 mapper 对键进行排序分区的结果是所有活动事件和用户ID相同的用户记录在reducer 的输入中彼此相邻。MapReduce 作业甚至可以对记录进行排序，一边 reducer 会首先看到用户数据库中的记录，然后按时间戳排序查看活动事件。这种技术称为次级排序。经过排序和分区后，reducer 可以很容易执行真正的 join 逻辑。 上面这个算法被称为排序-合并-join，因为 mapper 的输出是按关键字排序的，然后 reducer 将来自join两侧的已排序记录列表合并在一起。mapper 和排序过程确保了所有需要的数据已经预先排列好了，所以 reducer 可以相当简单。 使用 MapReduce 编程模型将计算中的物理网络通信部分(从正确的机器获取数据) 从 应用逻辑(处理数据) 中分离出来。这种分离与数据库的典型使用形成鲜明对比: 从数据库中获取数据的请求经常发生在应用程序代码的深处。 由于 MapReduce 能够处理所有的网络通信，因此它也避免了在应用程序中处理局部故障，例如某个节点的崩溃: MapReduce 会在不影响应用程序逻辑的情况下透明的重试失败任务。 处理数据倾斜3.5 map 段join之前我们描述了 reduce 端 join 即 mapper 负责准备输入数据: 从每个输入记录中提取关键字和值，将键值对分配给 reducer 分区，并按关键字排序。 Reduce 端 join 方法的优点是不需要对输入数据做任何假设。然而不利的一面是，所有这些排序，复制到 reducer 以及合并 reducer 输入可能会是非常昂贵的操作，这取决于可用缓冲区。 另一方面如果可以对输入数据进行某些假设，则可以通过使用所谓的 map 端join 来加快速度。这种方法使用了缩减版的 MapReduce ，其中没有 reducer，也没有排序。相反每个 mapper 只需从分布式文件系统中读取输入文件块，然后处理输出即可。 map 端 join 实现有如下几种方法: 广播哈希 join: 适用: 大数据集和小数据集join，尤其是小数据集可以全部加载到每个 mapper 内存中 应用: pig(replicated join)，hive(MapJoin) 分区哈希 join 适用: 两个 join的输入具有相同数量的分区 算法: 根据相同的关键字和相同的哈希函数将记录分配至分区中 应用: hive 中的 bucketed map join 3.6 对比map 端或 reduce 端join 的不同选择会影响到输出结构: reduce 端 join 的输出按 join 关键字进行分区和排序 map 端 join 的输出按照与大数据集相同的方式进行分区和排序 正如讨论的， map 端 join 也存在对输入数据集的大小、排序和分区方面的假设。在优化 join 策略时，了解分布式文件系统中的物理布局非常重要: 仅仅知道编码格式和数据存储目录的名称是不够的，还必须知道数据分区数量，以及分区和排序的关键字。 4. 批处理系统的优缺点4.1 批处理系统与分布式数据库4.2 中间状态实体化4.3 批处理系统与流处理系统4.4 图与迭代处理5. 总结分布式批处理框架需要解决两个主要问题: 分区: MapReduce 中 mappper 根据输入文件进行分区，mapper 的输出被重新分区、排序、合并成一个可配置数量的 reducer 分区 目的是把所有相关数据放在一起 除非必要，MapReduce 的数据流引擎都尽量避免排序，但它们采用了类似的分区方法 容错: MapReduce 需要频繁写入磁盘，这使得可以从单个失败任务中轻松恢复，而无需重启整个作业，但在无故障下会减慢执行速度 数据流引擎执行较少的中间状态实体化并保留更多内存，这意味着如果节点出现故障，他们需要重新计算更多的数据。确定性运算符减少了需要重新计算的数据量 分布式批处理引擎有一个有意限制的编程模型: 回调函数(mapper 和 reducer) 被设定为无状态，并且除了指定输出之外没有外部可见的任何副作用。这个限制使得框架隐藏了抽象背后的一些困难的分布式问题，从而在面对崩溃和网络问题时，可以安全的重试任务，并丢弃任何失败任务的输出。 得益于这样的框架，批处理作业中的代码无须考虑容错机制: 框架可以保证作业的最终输出与没有发生错误的情况相同。而在线服务在处理用户请求时，将写入数据库作为请求的副作用，与之相比批处理的可靠性语义要强大的多。 批处理系统的显著特点是读取一些输入数据，至关重要的是输入数据是有界的: 数据大小固定已知。因为有界所以总是可以知道作业何时结束。在下一章中我们 将转向流处理，其输入是无界的。即作业的输入是永无止境的数据流。我们将看到流处理与批处理有很多相似之处，但是流数据无界的假设也会深刻改变我们设计系统的方法。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10. 一致性与共识]]></title>
    <url>%2F2019%2F04%2F10%2Fdb%2Fdb_10%2F</url>
    <content type="text"><![CDATA[一致性与共识 1. 共识算法的概述本节我们将讨论构建容错式分布式系统的相关算法和协议。这里我们假设第 8 章中所有的故障都可能发生: 网络会丢失、顺序紊乱、重复发送或延迟；时钟也有一定偏差，节点可能发生暂停甚至随时崩溃。为了构建容错系统，最好先建立一套通用的抽象机制和与之对应的技术保证，这样只需实现一次，其上的各种应用程序都可以安全的信赖底层的保证。这与引入事务是一样的道理。 接下来我们将沿着这个思路，尝试建立让分布式应用忽略内部各种问题的抽象机制，比如共识，即所有的节点就某一项提议达成一致。我们将研究解决共识问题的相关算法，以及讨论分布式系统可提供的若干保证和抽象机制。 我们需要了解系统能力的边界，在什么情况下，系统可以容忍故障并继续工作。我们将探索分布式系统下比最终一致性更强的一致性模型(之前介绍复制的内容时，我们已经介绍了一部分)。 分布式一致性模型与之前讨论的多种事务隔离级别有相似之处，但总体上他们有着显著的不同: 事务隔离主要是为了处理并发执行事务时的各种临界条件 分布式一致性则主要是针对延迟和故障等问题来协调副本之间的状态 分布式一致性包括: 写后读 单调读 前缀一致读 线性化 顺序一致性，满足线性化的写，不满足线性化的读 因果一致性 前面三个我们已经介绍过了，接下来我们将讨论: 线性化: 这是最强的一致性模型 分布式系统中事件顺序问题，特别是因果关系和全局顺序 如果自动提交分布式事务，并最终解决共识问题 2. 可线性化可线性化的基本想法是让一个系统看起来好像只有一个数据副本，且所有的操作都是原子的。有了这个保证，应用程序就不需要多副本带来的复制延迟问题，每个客户端都拥有相同的数据视图。这种看似单一副本的假设意味着，它可以保证读取最近最新值，而不是过期的缓存。换句话说,可线性化是一种就近保证。 可线性化的基本思想很简单，但是它有更多的含义: 一旦某个读操作返回了新值，之后所有的读(包括相同和不同的客户端)都必须返回新值 某个客户端读取了新值，即使写操作尚未提交，那么所有后续的读取也必须全部返回新值(当然尚未提交，数据库完全可以不让客户端读取到新值) 对于可线性化的系统要格外注意时序依赖关系，在下面的读写时序中: 客户端 A 读取到新值 1，在 A 读取返回之后，B 开始读取，由于 B 的读取严格在 A 的读取发生之后，因此即使 C 的写入仍在进行之中，也必须返回 1。 可以进一步细化时序图来可视化每部操作具体在哪个时间点生效，如下图所示。这里我们引入了第三种类型的操作: Cas(x, V-old, V-new) 在上图中每个操作都有一条竖线，表示实际的执行时间点，这些标记以前后关系依次连接起来，最终的结果必须是一个有效的寄存器读写顺序，即每个读操作返回最近写操作所设置的值。 可线性化要求，如果连接这些标记的竖线，它们必须总是按时间箭头(从左往右)向前移动，而不能向后移动。这个要求确保了之前所讨论的就近性保证: 一旦新值被写入或读取，所有后续的读都看到的是最新的值，直到被再次覆盖。 上图中有一些细节值得仔细研究: 模型没有假定事务间的隔离，即另一个并发客户端可能随时会修改值。我们可以使用原子比较和设置(Cas)操作来检查是否被其他并发客户端修改 客户端 B 的最后一次读取不满足线性化。该操作与 C 的 Cas 写操作同时发生，后者将 x 从 2 变成 4。在没有其他请求时，B读取可以返回 2。但在 B 读取开始之前，A 已经读取了新值 4，所以不允许 B 读取到比A更老的值。 通过记录所欲请求和响应的时序，然后检查他们是否可以顺序排列，可以用来测试系统是否可线性化 2.1 可线性化与可串行化(重要)注意可线性化与可串行化非常容易混淆，但它们完全不同: 可串行化 是事务的隔离属性，每个事务可以读写多个对象 用来确保事务执行的结果与串行执行(每次执行一个事务)的结果完全相同，即使串行执行的顺序与事务实际执行的顺序不同 可线性化: 是读写寄存器(单个对象)的最新值保证 不要求将操作组合到事务中，因此无法避免写倾斜等问题，除非采取其他额外措施 数据库可以同时支持可串行化和线性化，这种组合被称为严格的可串行化或强的单副本可串行化。基于两阶段加锁或者实际以串行执行都是典型的可线性化。但是可串行化的快照隔离则不是线性化的: 按照设计，它可以从一致性快照中读取，以避免读写之间的竞争。一致性快照的要点在于它里面不包括快照点创建时刻之后的写入数据，因此从快照读取肯定不满足线性化。 2.2 线性化的依赖条件那么什么时候需要线性化呢？在下列场景中，线性化对于保证系统正确工作至关重要: 主节点的选举: 选举主节点通常的方式是使用锁，谁获取锁谁就是主节点 不管锁如何实现，它必须满足可线性化: 所有节点都必须同意那个节点持有锁 线性化存储服务是所有协调服务的基础 约束与唯一性保证: 与加锁类似，都要求所有节点就某个最新值达成一致 跨通道的时间依赖 线性化违例之所以被注意到，是因为系统中存在其他的通信渠道 什么叫系统中存在其他的通信渠道，我们看下面这个示例: 用户上传图片至 Web 服务器，Image resizer 用于产生缩略图方便快速加载 Web 服务通过消息队列通知调整器，因为消息队列通常不适合大数据流而照片可能数兆大小，Web 服务会先将图片写入文件存储服务，写入完成后发消息通知调整器 注意这里 Web 服务器和图片调整器之间存在两个不同的通信通道: 文件存储器和消息队列(注: 文件存储服务这里是分布式的) 如果没有线性化的就近保证，这两个通道之间存在竞争条件: 消息队列(步骤3)可能比存储服务内部的复制(步骤4)执行更快，这种情况下步骤5 可能会看到图片的旧版本或根本读不到任何内容。如果文件存储服务是可线性化的系统将可以正常工作。 线性化并非避免这种竞争的唯一方法，但却是最容易理解的。例如可以控制某一个通信通道(消息队列)”读自己写”，但会引入额外的复杂性。 2.3 实现线性化系统由于线性化的本质意味着”表现得好像只有一个数据副本 + 所有操作都是原子的”。所以最贱的方案自然是只用一个数据副本，但是这样无法容错。系统容错最常见的方法是采用复制机制。前面我们介绍了多种复制机制，那么它们符合线性化要求么? 主从复制: 读写必须都从主节点才满足线性化要求，但此时无法容错 多主复制: 无法满足 无主复制: 无法满足 直觉上对于 Dynamo 风格的复制模型(无主复制)，如果读写遵从严格的 quorum，应该是可线性化的，然而如果遭遇不确定的网络延迟，就会出现竞争条件，如下图所示: x 初始值为 0，写客户端向所有三个副本发送写请求将 x 置为 1 A 从两个节点读取到新值 1 B 在 A 之后，但在写请求同步到副本 2/3 之前读取，读到旧值 0 显然这不符合线性化要求。可以通过牺牲性能为代价来满足线性化: 读操作在返回结果给应用之前，必须同步执行读修复；而写操作在发送结果之前，必须读取 quorum 节点以获取最新值。当然这个的前提是数据不会采用最终写入这获胜的方法来处理写冲突。此外这种方法只能支持线性化读、写操作，但不能支持线性化的比较和设置操作。 总而言之最安全的假设是类似 Dynamo 风格的无主复制系统无法保证线性化。线性化的唯一实现方式是共识算法。 2.4 CAP 理论的误解无论是主从复制还是多主复制，任何可线性化的数据库都存在这样的问题: 如果应用要求线性化，但由于网络的问题，某些副本与其他副本断开连接后无法继续处理请求，就必须等待网络修复，服务不可用 如果应用不要求线性化，那么断开连接之后，每个副本可独立处理请求，此时服务可用，但结果行为不符合线性化 因此，不要求线性化的应用更能容忍网络故障，这被称为 CAP 理论。CAP 代表一致性、可用性、分区容错性系统只能支持其中两个特性。但是这种理解存在误导性: 网络分区是一种故障，无法选择。网络正常时可以同时保证可用性和一致性，一旦发生网络故障，要么选择一致性，要么选择可用性。 一致性指的是线性化，很多博客和文章在讲解 CAP 时都没有明确说明过 可用性存在争议，其形式化定理中的可用性与通常意义上的理解有些差别(记得没错的话，CAP 的可用性指的是可访问的到的所有节点中，每一个都可用)。许多所谓的”高可用性”(容错)系统实际上并不符合 CAP 对可用性的特殊定义。 总之避免使用 CAP。 2.5 可线性化与网络延迟实际上很少有系统真正满足线性化。例如现代多核 CPU 上的内存就是非线性化的(这个就是为什么类似 Go 语言有所谓的内存模型)。如果某个 CPU 核上运行的线程修改了一个内存地址，紧接着另一个 CPU 核上的线程尝试读取，则系统无法保证可以读到刚刚写入的值，除非使用了内存屏障或 fence 指令。 出现这种现象的原因是每个 CPU 都有自己独立的 cache 和寄存器。内存访问受限进入 cache系统，所有修改默认会异步刷新到主存。由于访问 cache 比访问主存快得多，所以这样的异步刷新对于现代 CPU 性能至关重要。但是，这就导致出现了多个数据副本(主存+几个不同级别cache)，而副本更新是异步的，无法保证线性化。 CAP 理论不适用于当今的多核-内存一致性模型: 在计算机内部，我们通常假设通信是可靠的，我们会假设一个 CPU核在于其他核断开之后操作系统还没down机。之所以放弃线性化的原因是性能，而不是为了容错。 许多分布式数据库也是类似，他们选择不支持线性化是为了提高性能，而不是为了保住容错特性。无论是否发生故障，线性化对性能的影响都是巨大的。 是否存在一个更有效的线性化实现方案呢？目前来看是否定的，已经有证明: 如果想要满足线性化，读、写请求的响应时间至少要与网络延迟成正比。考虑到网络高度不确定的网络延迟，线性化读写的性能势必非常差。 虽然没有足够快的线性化算法，但弱一致性模型的性能则快得多，这种取舍对于延迟敏感的系统非常重要。后面我们将讨论一些避免线性化但有可以保证正确性的方法。 所以可线性化的缺点就是读写性能必然非常差。 3. 顺序保证线性化寄存器对外呈现的好像只有一份数据拷贝，并且每一个操作都是原子性生效。这意味着操作是按照某种顺序执行的。顺序是一个非常重要的概念，我们已经多次提及: 主从复制中主节点的主要作用就是确定复制日志的写入顺序，正因为有主节点确定写入顺序，主从复制才不会出现并发写冲突 可串行化是确保事务的执行结果与按照某种顺序方式执行一样 分布式系统的时间戳和时钟，试图将顺序引入无序的操作，比如确定两个写操作哪一个先发生。 排序、可线性化与共识存在着某种深刻的联系。理解它们对于理解系统能做什么不能做什么非常有帮助。 3.1 顺序与因果关系之所以反复出现顺序问题，其中一个原因是它有助于保持因果关系。因果关系对所发生的事件施加了某种顺序: 发送消息先于收到消息，问题出现在答案之前等等。这些因果关系的依赖链条定义了系统中的因果顺序，即某件事应该发生在另一件事情之前。 如果系统服从因果关系所规定的顺序，我们称之为因果一致性。例如快照隔离级别提供了因果一致性: 当从数据库中读数据时，如果查询到了某些数据，也一定能看到触发该数据的前序事件(假设期间没有发生删除操作)。 3.2 因果顺序并非全序全序关系支持任何两个元素之间进行比较，但是某些集合并不符合全序，例如集合{a,b} 和 {b,c} 无法直接比较，数据集合只能是偏序，即某些情况下一个集合可以包含另一个，否则无法比较。 全序和偏序的差异也体现在不同的数据库一致性模型中: 可线性化: 存在全序操作关系，总是可以指出哪个操作在先 因果关系: 如果两个操作都没有发生在对方之前，这两操作是并发关系，Happen-before 如果两个事件是因果关系，那么这两个事件可以被排序 并发的事先无法排序比较 因果关系至少可以定位为偏序，而非全序 因此根据这个定义，可线性化数据存储中不存在并发操作，一定有一个时间线将所有操作都全序执行，所以单个时间轴，单个数据副本，没有并发。可能存在多个请求，但出于等待状态。 并发意味着时间线会出现分支和合并，而不同分支上的操作无法直接比较。 3.3 可线性化与因果一致性可线性化一定意味着因果关系，特别是如果系统存在多个通信通道，可线性化确保了因果关系会自动全部保留，而不需要额外的工作。 但是线性化会显著降低性能和可用性，尤其是在严重网络延迟的情况下。 线性化并非是保证因果关系的唯一途径。还有其他方法使得系统可以满足因果一致性而免于线性化所带来的的性能问题。因果一致性可以认为是，不会由于网络延迟而显著影响性能，又能对网络故障提供容错的最强一致性模型。 许多情况，看似需要线性化的系统实际真正需要的是因果一致性。这也正是当下数据库发展的方向: 新的数据库保证因果关系，性能与可用性与最终一致性类似。 3.4 捕获因果依赖关系为保持有听过关系，需要知道哪一个操作发生在前，如果一个操作发生在另一个操作之前，那么每个副本都应该按照相同的顺序处理。我们需要一些手段来描述系统中节点所知道的”知识”。与前面介绍的检测并发写的方法类似: 无主复制中的因果关系，需要去检查对同一个主键的并发写请求，从而避免更新丢失 因果一致性则要更近异步，需要跟踪整个数据库请求的 因果关系，而不仅仅是某个主键，版本向量可以推广为一种通用的解决方案。 为了确定因果关系，数据库需要知道应用程序读取的是哪个版本的数据 因果关系很重要，但实际上跟踪所有的因果关系不切实际。客户端可能在写之前读取大量数据，系统无法了解写入究竟是依赖于全部读取内容内容，还仅仅是其中一部分。更好的办法是可以使用序列号或时间戳来排序时间。 在主从复制中，主节点可以简单为每个操作递增某个计数器，从而为复制日中的每个操作赋值一个单调递增的序列号。但如果系统不存在唯一的主节点，序列号的产生就不简单了。序列号要保证与因果关系一致，特别是保证跨节点操作的顺序。 Lamport 时间戳有一种简单方法可以产生与因果关系一致的序列号，叫做兰伯特时间戳。下面是 Lamport 时间戳的示例: 每一个节点都有一个唯一的标识符，且每个节点都有一个计数器来记录各自已处理的请求总数 Lamport 时间戳是一个值对(计数器，节点ID) 给定两个 Lamport 时间戳，计数器较大那个时间戳大，如果计数器值相等，节点 ID 越大，时间戳越大 Lamport 时间戳的核心亮点在于使它们与因果关系保持一致: 每个节点以及每个客户端都跟踪迄今为止所见到的最大计数器值 并在每个请求中附带该最大计数器值 当节点收到某个请求或回复时，如果发现请求内嵌的最大计数器值大于节点自身的计数器值，则立即把自己的计数器修改为改最大值 只要把最大计数器值嵌入到每一个请求中，该方案可以确保 Lamport 时间戳与因果关系一致性，而请求的因果依赖性一定会保证后发生的请求得到更大的时间戳 Lamport 时间戳与版本向量存在相似之处，但它们的目的不同: 版本向量用以区分两个操作是并发还是因果依赖 Lamport 时间戳则主要用于确保全序关系，但是即便 Lamport 时间戳与因果序一致，但根据其全序关系却无法区分两个操作属于并发关系，还是因果依赖关系。(Lamport 时间戳中，并发操作也被排序) 时间戳排序依然不够虽然Lamport时间戳定义了与因果序一致的全序关系，但还不足以解决实际分布式系统中许多常见的问题，例如账号的全局唯一性。乍看总是选择时间戳最小的作为获胜者是可行的，但是这个方法有一个前提条件: 需要收集系统中所有的用户创建请求，然后才可以比较它们的时间戳。当节点刚刚收到用户的创建请求时，它无法当时就做出决定该请求应该成功还是失败。此时节点根本不知道是否有另一个节点在同时创建相同的用户名。 为了获取以上两点信息，系统必须检查每个节点，如果因为节点故障或网络问题无法连接，这个方法就无法正常运转。 这个问题的关键是: 只有收集了所有的请求信息之后才能清楚这些请求之间的全序关系。如果另一个节点执行了某些操作，但你无法知道那是什么，就无法构造出最终的序列。也许，来自该位置操作确实需要插入到全序集合中才能正确评估出下一步。 总而言之，为了实现像用户名唯一性约束，仅仅对操作进行全序排序还是不够的，还需要知道这些操作是否发生、何时确定等。假如能够在创建用户时，已经确定知道了没有其他节点正在执行相同用户名的创建，大可直接安全返回成功。 要想知道什么时候全序关系已经确定就需要全序关系广播。 4. 全序关系广播在分布式系统上，让所有节点就全序关系达成一致面临巨大挑战。在分布式系统文献中，这些问题被称为全序关系广播或者原子广播。 全序关系广播通常指节点之间交换信息的某种协议。下面是一个非正式的定义: 可靠发送: 没有消息丢失，如果消息发送到某一节点，一定发送到所有节点 严格有序: 消息总以相同的顺序发送给每个节点 4.1 使用全序关系广播想 Zookeeper 和 etcd 这样的共识服务实际上就实现了全序关系广播，这也暗示了全序关系广播与共识之间有着密切联系。 全序关系广播: 正是数据库复制所需要的，如果每条消息代表数据库写请求，并且每个副本都按相同的顺序处理这些写请求，那么所有副本可以保持一致(或许有滞后)，该原则也被称为状态机复制 可以实现串行化事务: 每条消息表示一个确定性事务，并且作为存储过程来执行，且每个节点遵从相同的执行顺序，可以保证数据库各分区以及各副本的一致性 另一个要点是: 顺序在发送消息时已经确定，如果消息发送成功，节点不允许追溯地将某条消息插入到先前的某个位置上(重要)。这一点是的全序关系广播比基于时间戳排序要求更强。 全序关系广播中，消息就像追加方式更新日志。 4.2 采用全序关系广播实现线性化存储(非常重要)一个可线性化的系统中有全序操作集合。这是否意味着可线性化与全序关系广播是完全相同的呢？不完全是，但它们有着密切的联系: 全序关系广播是基于异步模型: 保证消息以固定的顺序可靠发送，但是不保证消息何时发送成功。某个接收者可能明显落后于其他接收者。可线性化则强调就近性: 读取时保证能够看到最新的写入值 如果有了全序关系广播，就可以在其上构建线性化的存储系统。 基于全序关系广播实现线性化存储通过使用全序关系广播以追加日志的方式来实现线性化的原子比较-设置: - 在日志中追加一条消息，并指明想要的用户名 - 读取日志，将其广播给所有节点，并等待回复 - 检查是否有任何消息生成用户名已被占用，如果没有其他节点回复已占用，可以提交该获取声明并返回客户端。反之则中止操作 由于日志条目以相同的顺序发送到所有节点，如果存在多个并发写入，则所有节点将首先决定哪个请求在先，选择第一个写请求作为获胜者，并中止其他请求，以确保所有节点同意一个写请求最终要么提交成功要么中止。类似的方法还可以用来在日志之上实现可串行化的多对象事务。 虽然此过程可以确保线性化写入，但它无法保证线性化读取。即从异步日志更新的存储中读取数据时，可能是旧值。具体来说，这里只提供了顺序一致性，也称为时间线一致性，它弱于线性化保证。 为了同时满足线性化读取，有以下几个方案: 采用追加的方式把读请求排序、广播，然后各个节点获取该日志，当本节点收到消息时才执行真正的读操作。消息在日志中的位置已经决定了读取发生的时间点。etcd 的 quorum 读取和这个思路有相似之处 如果可以以线性化的方式获取当前最新日志中消息的位置，则查询位置，等待直到该位置之前的所有条目都已经发送给你，接下来再执行读取。这与 Zookeeper的 sync() 操作思想相同。 可以从同步更新的副本上读取，这样确保总是读取最新值 采用线性化存储实现全序关系广播最简单的方法是假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增-读取操作或者原子比较-设置操作。 思路很简单: 对于每个要通过全序关系广播的消息，原子递增并读取该线性化的计数，然后将其作为序列号附加到消息中。接下来广播到所有节点，接收者也严格按照序列化来发送回复消息。 这与 Lamport 时间戳不同，通过递增线性化寄存器获得的数字不会存在任何间隙。因此节点完成了消息 4 的发送，且收到了序列化 6 的消息，那么在它对消息 6 回复之前必须等待消息 5。Lamport时间戳不是这样的，这样是区别全序关系广播和基于时间戳排序的关键。 原子自增操作的线性化整数有多难？如果没有失效很容易，难点在于如何处理网络故障和节点失效。事实上，如果对线性化的序列号发生器深入思考之后所得到的的最终结果，毫无意外的指向了共识算法。 可以证明(非常重要): 线性化的原子比较-设置(或自增)寄存器与全序关系广播二者都等价于共识问题 如果你能解决其中的一个问题，那么就可以把方案用于解决其他问题 接下来我们就正式进入共识问题。 概念的递推关系总结(重要)在可线性化，因果关系一致性，全序关系广播他们之间存在这样的关系: 可线性化是分布式系统中最强的一致性模型，但是不能容错 退而求次，大多数系统需要的是因果关系一致性，因果关系一致性可以容忍网络异常，提供和最终一致性一样的性能和容错性 要捕获全局因果关系是不现实的，系统转而去捕获因果依赖关系，通过确定事件顺序来间接实现因果关系一致性 通过 Lamport 时间戳可以获取全序关系，但是仅仅对操作进行全序排列还是不够的，需要确切知道操作是否发生、何时确定 要想获取操作的全序关系，同时让所有节点达成共识就是全序关系广播。 基于全序关系广播就可以实现线性化存储，反之亦然 5. 分布式事务与共识在讨论了复制、事务、系统模型、线性化和全序关系广播等问题之后，我们终于可以直面共识问题了。有很多重要的场景都需要集群节点达成某种一致: 主节点选举: 所有节点对谁来当主节点达成共识 原子事务提交: 支持跨节点或跨分区事务，所有节点必须对事务的结果达成一致，要么全部提交，要么中止/回滚，这个共识的例子被称为原子提交问题 接下来我们将首先研究原子提交问题，我们将集中于两阶段提交(2PC)算法，2PC 是一种共识算法，虽然不是很有优秀。之后我们将讨论更好的共识算法，比如 Zookeeper(Zab)和 etcd(Raft)所使用的算法。 5.1 两阶段提交原子性可以为应用程序提供非常简单的语义: 事务的结果要么成功提交，要么失败回滚，避免形成部分成功夹杂着部分失败。这对于多对象事务和维护二级索引格外重要。原子性可以确保二级索引与主数据库总是保持一致。 单节点原子提交实现单节点数据库节点上事务的原子性由存储引擎负责: 数据库首先使事务的写入持久化，通常是保存在预写日志中，然后把提交记录追加写入到磁盘的日志文件中 如果在数据的写入过程中数据库奔溃，此时: 如果奔溃之前预写日志未完成，则回滚事务 如果预写日志完成，提交记录未成功，节点重启后，事务可以从日志中恢复重新提交 如果提交记录已完成则认为事务已安全提交 当事务涉及多个节点时，向所有节点简单发送一个提交请求，然后各个节点独立执行事务提交是绝对不够的。因为节点可能因为校验规则、网络异常、节点故障而提交失败。如果某些节点提交了事务，而其他节点放弃了事务就会出现不一致。 而且某个节点一旦提交了事务，即使事后发现其他节点发生中止，它也没法撤销已提交的事务。 事务提交不可撤销的深层次原因是，一旦数据提交，就被其他事务可见，继而其他客户端会基于此做出相应的决策。这个原则构成了读-提交隔离级别的基础。如果允许事务在提交之后还能中止，会违背之后所有读-提交的事务，进而被迫产生级联式的追溯和撤销。 两阶段提交2PC 是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。2PC 的基本流程如下图所示: 2PC 引入了单节点事务所没有的一个新组件: 协调者(又称事务管理器)。整个事务过程如下: 事务从应用程序执行数据读/写开始 当应用程序准备提交事务时，协调者开始阶段 1：发送一个准备请求到所有节点(这些节点被称为参与者)，询问他们是否可以提交 协调者然后跟踪参与者的回应: 所有参与者回答是，那么协调者在接下来的阶段2提交请求 如果有任何参与者回复否，则协调者在阶段2中向所有节点发送放弃请求 对于 2PC 准备和提交请求也一样可能丢失，那 2PC 是如何处理的，我们来详细分解上面过程: 应用程序从协调者请求事务ID，该ID 全局唯一 应用程序想每个参与节点发送请求，执行单节点事务，如果出现问题，协调者和其他参与者都可以安全中止 进入提交阶段，第一阶段发送准备请求，参与者确保事务不会有任何异常可以提交后，回复可以提交。一旦节点回复是，节点就承诺会提交事务 事务提交第二阶段，协调者收到所有是的准备答复后，先将最后的决定写入到磁盘的事务日志之后，接下来向所有参与者发送提交请求 第一阶段中，任何一个准确请求发生了失败或超时，协调者就会中止事务 第二阶段发生提交请求失败，协调者将无限期重试 2PC 中每一步都会记录在事务日志中，因此当协调者崩溃重启后，就可以根据事务日志判断，哪些事务未完成需要中止，哪些事务已经决定提交还未收到参与者回复需要重复发送阶段二的提交请求 2PC 有两个关键的不归路: 阶段1，当参与者投票是时，它做出了肯定提交的承诺，如果协调者决定提交事务，参与者必须提交不可撤销 阶段2，协调者做出了提交(或放弃)的决定，这个决定也是不可撤销的 正是这两个承诺确保了2PC的原子性。 协调者故障如果协调者本身发生故障会出现什么情况呢? 在协调者发送准备请求之前故障，参与者可以安全的中止交易 参与者收到了准备请求并投票是，参与者不能单方面放弃，它必须等待协调者的决定，如果决定到达之前，协调者崩溃或网络故障，则参与者只能无奈等待，此时参与者处于一种不确定的状态。2PC 能顺利完成的唯一方法是等待协调者恢复。这就是为什么协调者必须在向参与者发送提交或中止请求之前要将决定写入磁盘的事务日志: 等待协调者恢复之后，通过读取事务日志来确定所有未决的事务状态。如果协调者日志中没有完成提交记录就会中止。此时 2PC 的提交点归结为协调者在常规单节点上的原子提交。 两阶段提交也被称为阻塞式原子提交协议，因为 2PC 可能在等待协调者恢复时卡住。 5.2 实践中的分布式事务2PC由于操作上的缺陷、性能问题、承诺不可靠等问题遭受诟病，其性能下降的主要原因是为了防崩溃恢复而做的磁盘I/O，以及额外的网络往返开销。要不要使用分布式事务，我们首先要明确分布式事务的确切含义，现在有两种截然不同的分布式事务概念: 数据库内部的分布式事务: 支持跨数据库节点的内部事务，所有参与者运行着相同数据库软件 异构分布式事务: 存在两种或以上不同的参与者，即完全不同的系统，跨系统的分布式事务 旨在无缝集成多种不同的系统，提供Exactly-one 语义 只有在所有受影响的系统都使用相同的原子提交协议的前提下，这种分布式事务才是可行的 X/Open X/A 是异构环境下实施两阶段提交的一个工业标准。 5.3 停顿时持有锁为什么我们非常关注陷入停顿的参与者节点，问题的关键在于锁，数据库事务通常持有带修改行的独占锁。可串行化隔离级别下还有读-共享锁 在事务提交和终止前，数据库不会释放这些锁。所以在两阶段提交时，事务在整个停顿期间一直持有锁；如果协调者的日志由于某种原因而彻底丢失，这些数据对象将永远处于加锁状态，需要管理员手动介入。数据加锁时，其他事务就无法执行修改甚至无法读取。这可能会导致很多上层应用基本处于不可用状态。所以必须解决处于停顿状态的那些事务。 5.5 分布式事务的限制XA 事务解决了多个参与者如何达成一致这样一个非常重要的问题。但是核心的事务协调者本身就是一种数据库，需要格外小心: 如果协调者不支持数据复制，那么它就是单点故障 XA 需要与各种数据库保持兼容，它最终其实是多环境可兼容的最低标准，比如无法检测死锁，不适用于SSI 数据库内部的分布式事务限制少很多。然而 2PC要成功提交事务要求必须所有参与者都投票赞成，如果部分发生故障整个事务只能失败。所以分布式事务有扩大事务失败的风险，这与我们构建容错系统的目标有背道而驰。 如何保持多个系统一直，后面我们会继续讨论，现在我们应该可以总结一下共识问题。 6. 支持容错的共识共识是让几个节点就某项提议达成一致。可以用共识算法来决定不相同的操作之中谁是获胜者。共识问题通常形式描述如下: 一个或多个节点可以提议某些值，由共识算法来决定最终值 比如多个客户预定相同的座位，处理客户请求的每个节点都可以提议它所服务的客户ID，共识算法决定哪个客户获得座位 共识算法必须满足以下性质: 协商一致性: 所有节点都接受相同的决议 诚实性: 所有节点不能反悔，即对一项提议不能有两次决定 有效性: 如果决定了值 v，则 v 一定是有某个节点所提议的 可终止性: 节点如果不崩溃则最终一定可以达成决议 协商一致和诚实性定义了共识的核心: 决定一致的结果，一旦决定，就不能改变。如果不关心容错，前三个属性很容易满足: 可以强行指定某个节点为独裁者，但如果它失效了，系统就无法继续做出任何决定。其实这就是2PC所看到的: 如果协调者失败，那些处于不确定状态的参与者就无从知道下一步该做什么。 可终止性引入了容错的思想。它重点强调一个共识算法不能原地空转，换句话说，它必须取得实质性进展。即使某些节点故障，其他节点也必须最终做出决定。可终止性属于一种活性，另外三个属性属于安全性方面的属性。 上述共识的系统模型假设: 当某个节点发生崩溃后，节点就彻底消失，永远不再回来。在这样的系统模型下，所有采取等待节点恢复的算法都无法满足终止性，特别是2PC 不符合可终止性要求。(我的理解是这里节点彻底消失不是一个限制条件，即不是不允许节点偶尔失效之后又回来) 可终止性的前提是，发生崩溃或者不可用的节点数必须小于半数节点。并且大多数共识算法都假定系统不存在拜占庭式错误。 6.1 共识算法与全序广播著名的共识算法包括 VSR、Paxos、Raft、Zab。他们有诸多相似之处，但又不完全相同。除非你要实现他们中的一个，否则只需了解它们共同的设计思想即可。 这些算法大部分其实不是直接使用上述的形式化模型(提议并决定某个值，同时满足上面4个属性)。相反他们是决定了一系列值，然后采用全序关系广播算法。 全序关系广播算法的要点是，消息按照相同的顺序发送到所有节点，有且只有一次。这其实相当于进行了多轮共识过程: 在每一轮，节点提出他们接下来想要发送的消息，然后决定下一个消息的全局顺序。 所以全序广播相当于持续的多轮共识，每一轮共识决定一条消息 由于协商一致性，所有节点决定以相同的顺序发送相同的消息 由于诚实性，消息不能重复 由于合法性，消息不会被破坏，也不能凭空捏造 由于可终止性，消息不会丢失 VSR、Raft、Zab 都直接采用了全序关系广播，这比重复性的一轮共识只解决一个提议更加高效。而Paxos则有对应的优化版本。 6.2 主从复制与共识主从复制中，所有的写入操作都由主节点负责，并以相同的顺序发送到从节点。这不就是全序关系广播么？那为什么我们没有在主从复制中说过共识。 答案取决于如何选择主节点。 如果主节点由运营人员手动配置，这就是一种独裁性质的一致性算法。这个方案在实际中也很好的发挥作用，但是不满足共识的可终止性。 如果主节点是数据库自动选举的，这样更接近容错式全序关系广播，从而达成共识。但是这里出现了一个逻辑循环: 共识算法实际上是全序关系广播 全序关系广播是主从复制 主从复制有需要选举主节点 看起来要选举一个主节点，我们首先需要有一个主节点。要解决共识，必须先处理共识。怎么摆脱呢？ 6.3 Epoch和Quorum(非常重要)目前所讨论的所有共识协议在其内部都使用了某种形式的主节点，虽然主节点并不是固定的。相反他们都采用了一种弱化的保证: 协议定义了一个世代编号(epoch number)，对应于 Paxos 中的 ballot number，VSP 中的 view number，Raft 中的 term number。并保证每个世代里，主节点是唯一确定的 如果发现当前的主节点失效，节点就开始一轮投票选举新的主节点。选举会赋予一个单调递增的 epoch 号。如果出现了两个不同的主节点对应于不同的 epoch 号，则更高 epoch 号的主节点将获胜。 在主节点做出任何决定之前，它必须首先检查是否存在比它更高的 epoch 号码(每轮提议都要进行的)。主节点如何知道它是否它已经被其他节点所取代呢？它必须从 quorum 节点中收集投票。主节点如果想要做出某个决定，须将提议发送给其他所有节点，等待 quorum 节点的响应。quorum 通常由多数节点组成。并且只有当没有发现更高 epoch 主节点存在时，节点才会当前的提议(带有 epoch号)进行投票。 因此这里实际存在两轮不同的投票: 首先是投票决定谁是主节点 – 准确来说是判断主节点有没有发生变化 然后对主节点的提议进行投票 关键点是两轮投票的quorum 必须由重叠: 如果某个提议获得通过，那么其中参与投票的节点必须至少有一个也参加了最近一次的主节点选举。换言之如果在针对提议的投票中没有出现更高 epoch号码，那么可以得出这样的结论: 因为没有发生更高 epoch 的主节点选举，当前的主节点低位没有变化，所以可以安全的就提议投票。 对比2PC投票过程看起来很像 2PC，两者的区别在于: 2PC 的协调者是运营人员配置的，不是徐阿奴的 容错共识算法只需要多数节点的投票即可通过决议，2PC 必须要所有参与者通过 共识算法还定义了恢复过程，出现故障后，通过该过程节点可以选举出新的主节点然后进入一致的状态，确保总是能够满足安全绳属性。 6.4 共识的局限性共识算法对分布式系统至关重要，它为一切不确定的系统带来了明确的安全属性(一致性、完整性、有效性)，还支持容错(只要大多数节点还在工作和服务可达)。 共识算法可以提供全序关系广播，以容错的方式实现线性化的原子操作。但是共识是有代价的: 在达成一致性决议前，节点投票的过程是一个同步复制过程 共识体系需要严格的多数节点才能运行 多数共识算法假定一组固定参与投票的节点集，这意味着不能动态添加或删除节点 共识系统通常依靠超时机制来检测节点失效，在网络延迟高度不确定的环境中，会因为网络延迟的原因，导致节点错误的认为主节点发生了故障。虽然这种误判不会损害安全属性，但频繁的主节点选举显著降低了性能，系统最终会花费更多的时间和资源在选举主节点上而不是原本的服务本身。 共识算法往往对网络问题特别敏感。例如 Raft 已被发现存在不合理的边界条件处理: 如果整个网络中存在某一条网络连接持续不可靠，Raft 会进入一种奇怪的状态: 它不断在两个节点之间反复切换主节点，当前主节点不断被赶下台，这最终导致系统根本无法安心提供服务。其他共识算法也有类似的问题，所以面对不可靠网络，如何设计更具鲁棒性的共识算法仍然是一个开放性的研究问题。 7. 成员与协调服务Zookeeper 和 etcd 通常被称为分布式键值存储或协调与配置服务。Zookeeper 和 etcd 主要针对保存少量、可以完全载入内存的数据(虽然数据最终还是有写入磁盘以支持持久化)而设计，所以不要用他们保存大量的数据。它们通常采用容错的全序广播算法在所有节点上复制这些数据从而实现高可靠。全序广播主要用来实现数据库复制: 每条消息代表的是数据库写请求，然后按照相同的顺序在多个节点上应用写操作，从而达到多副本之间的一致性。 7.1 ZookeeperZookeeper 的实现模仿了 Google 的 Chubby 分布式锁服务，但它不仅实现了全序广播(因此实现了共识)，还提供了其他很多有趣的特性，所有这些特性在构建分布式系统时格外重要: 线性化的原子操作: 使用原子比较-设置操作，可以实现分布式加锁服务 分布式锁通常实现为一个带有到期时间的租约，保证万一客户发生故障，可以最终释放锁 锁和租约需要 fencing 令牌来防止客户端由于发生进程暂停而引发锁冲突 操作全序 fencing 令牌确保每次加锁时数字总是单调增加的 Zookeeper 在实现该功能时，采用了对所有操作执行全局排序，然后为每个操作都赋予一个单调递增的事务ID(zxid)和版本号 cversion 故障检测: 客户端与Zookeeper节点维护一个长期会话，客户端会周期性地与Zookeeper服务节点互相交换心跳信息，会检查对方是否存活。 即使出现闪断或者某些Zookeeper节点发生失效，会话仍处于活动状态 但是，如果长时间心跳停止且超过了会话超时设置，Zookeeper 会声明会话失败，此时所有该会话持有的锁资源可以配置为自动全部释放 更改通知: 客户端不仅可以读取其他客户端所创建的锁和键值，还可以监视它们的变化 因此客户端可以知道其他客户端何时加入集群，以及客户端是否发生故障 通过订阅通知机制，客户端不需要频繁的轮询服务即可知道感兴趣对象的变化情况 在上述特征中，只有线性化的原子操作才依赖共识。 7.2 节点任务分配Zookeeper 和 Chubby 非常适合如下场景: 如果系统由多个流程或服务的实例，并且需求其中的一个示例充当主节点，而如果主节点失效，由其他某个节点来接管 对于一些分区资源，需要决定将哪个分区分配给哪个节点。当有新节点加入集群时，需要将某些现有分区从当前节点迁移到新节点，从而实现负载动态均衡。而当节点移除或失败时，其他节点还要接管失败节点 试图在数千个节点的集群上进行多数者投票会非常低效。Zookeeper通常是在固定数量的节点上运行投票，可以非常高效的支持大量的客户端。因此 Zookeeper 其实提供了一种将跨节点协调服务(包括共识，操作排序和故障检测)专业外包的方式。 通常情况下，Zookeeper 管理的数据变化非常缓慢。它不适合保存那些应用实时运行的状态数据，后者可能每秒产生数千甚至百万次更改。 7.3 服务发现Zookeeper 和 etcd 还经常用于服务发现。可以这样配置服务，每当节点启动时将其网络端口信息向Zookeeper等服务注册，然后其他人只需向Zookeeper的注册表询问即可。 但是，服务发现是否需要达成共识还不太清楚。 DNS是查找服务名称的IP地址的传统方式，它使用多层缓存来实现良好的性能和可用性。从DNS读取是绝对不线性一致性的，如果DNS查询的结果有点陈旧，通常不会有问题【109】。 DNS的可用性和对网络中断的鲁棒性更重要。 尽管服务发现并不需要共识，但领导者选举却是如此。因此，如果你的共识系统已经知道领导是谁，那么也可以使用这些信息来帮助其他服务发现领导是谁。为此，一些共识系统支持只读缓存副本。这些副本异步接收共识算法所有决策的日志，但不主动参与投票。因此，它们能够提供不需要线性一致性的读取请求。 7.4 成员服务Zookeeper等还可以看作是成员服务范畴的一部分。成员服务用来确定当前哪些节点处于活动状态并属于集群的有效成员。由于网络等原因无法可靠的检测一个节点究竟是否发生故障。但可以将故障检测和共识绑定在一起，让所有节点就节点的存活达成一致。 虽然可能存在误判，即节点其实处于活动状态，却被错误的宣判为故障。即便这样，系统就成员资格问题的决定是全体一致的，这是最重要的。例如选举主节点的方式可能是简单的投票选择编号最小的节点，一旦节点对于当前包含哪些成员出现了不同意见，那么共识过程就无法继续。 7.5 为什么要使用 Zookeeper 要在多节点集群中达成共识，可以自己实现一个共识算法(很难)，所以可以直接使用 Zookeeper 提供的服务 Zookeeper 通常在固定数量的节点上运行投票，相比于在 1000 甚至更多的节点上达成共识效率更高 因此我们需要某种算法对写入的最终顺序进行确定，即达成共识。这就涉及到两个问题: 如何达成共识 如何让客户端感知到共识发生了变化 如果我们假设网络始终稳定，且不存在单点故障(类似单机情况下)通过锁就可以解决并发问题。但是这些问题无法避免单点故障可能导致数据丢失，这就需要多台机器提供冗余，此时就需要对同一项配置达成共识，我们需要共识算法。 共识算法需要解决的另一个问题是，当配置发生变化时，如何让客户端感知到共识发生了变化。我们可以让所有节点抖注册监听器，但是这样会引起惊群效应。因此我们只能让少量节点，即所谓的主节点注册监听器。然后通过版本矢量，让与主节点同步的从节点感知配置的变化。 kafka 为什么要引入 Zookeeper 是因为如果对所有 kafka 的节点都通过共识算法解决数据一致性问题，效率将非常低。数据一致性是以吞吐量为代价的。 8. 总结事实证明，多个广泛的问题最终都可以归结为共识，并且彼此等价，这些等价问题包括； 可线性化的比较-设置寄存器 原子事务提交: 决定是否提交或中止分布式事务 全序广播: 消息系统要决定以何种顺序发送消息 锁与租约: 当多个客户端抢锁或租约时，决定哪一个成功 成员/协调服务: 决定节点的存活状态 唯一性约束: 多个事务在相同的主键上并发创建冲突资源时，决定哪一个能成功 简单的实现是只有一个主节点，有主节点负责所有的决策事宜。这样就可以提供线性化操作、唯一性约束、完全有序的复制日志等。 但是如果唯一的主节点故障或网络中断导致主节点不可达，这样就陷入停顿状态。有三种方法可以处理这个问题: 系统停止服务，等待主节点恢复 许多 XA/JTA 事务协调者采用这种方式 本质上这种方法没有解决共识问题，因为它不满足终止性条件 如果主节点无法恢复，系统就会永远处于停顿状态 人为介入来选择新的主节点，并重新配置系统使之生效: 本质上引入了一种上帝旨意的共识 故障切换的速度取决于人类的操作 采用算法自动选择新的主节点，需要一个共识算法 尽管如此，并不是每个系统都需要共识。例如无主复制和多主复制系统通常不支持全局共识。正因为如此，这些系统可能会发生冲突。但也可以接受或者寻找其他方案，处理冲突。 接下来的地方部分，我们将面向实际环境，讨论如何基于异构模块来构建强大的应用系统。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9. 分布式系统的挑战]]></title>
    <url>%2F2019%2F04%2F09%2Fdb%2Fdb_9%2F</url>
    <content type="text"><![CDATA[分布式系统面临的挑战 1. 分布式系统中的故障在分布式系统中，故障来自于下面的方方面面: 网络分区不可避免 – 网络不可靠 时钟和时序问题，时钟无法精确同步 — 时钟不可靠 分布式系统中的一个节点必须假设，执行过程中的任何时刻都可能被暂停相当长一段时间，包括运行在某个函数中间。暂停期间，整个集群其他部分都照常运行，甚至会一致将暂停的节点宣告为故障节点，最终暂停的节点可能会回来继续执行，除非再次检查时钟，否则对刚刚过去的暂停毫无意识 让系统容忍失效并不容易，在典型的分布式环境下，没有全局变量，没有共享内存，没有约定的尝试或其他跨节点的共享状态。节点甚至不太清楚现在的准确时间。信息的流动只能通过不可靠的网络来发送。 我们将探讨如何认清分布式系统的状态本质，并据此来评估所发生的各种故障。 2. 故障与部分失效在单节点上开发应用程序，通常是以一种确定性的方式运行: 要么工作，要么出错，相同的操作通常总会产生相同的结果(即确定性)，而不应该出现模棱两可的现象。这背后涉及一个非常慎重的选择: 如果发生了某种内部错误，我们宁愿使计算机全部奔溃，而不是返回一个错误的结果，错误的结果往往更难处理。因此计算机隐藏了一切模糊的物理世界，呈现出一个理想的系统模型。 然而对于分布式系统，这种理想化的标准正确模型不再适用，分布式系统中可能会出现系统的一部分工作正常，但其他某些部分出现难以预测的故障，我们称之为”部分失效”。问题的难点就在于这种部分失效是不确定的。正是由于这种不确定性和部分失效大大提高了分布式系统的复杂度。 故障处理是软件设计的重要组成部分，作为系统运维者，需要知道在发生故障时，系统的预期行为是什么。不能假定故障不可能发生而总是期待理想情况。可以说，在分布式系统中，怀疑、悲观和偏执狂才能生存。 3. 不可靠的网络我们关注的是分布式无共享系统，即通过网络连接的多个节点。网络是跨节点通信的唯一方式。但网络并不保证它神秘时候到达，甚至它是否一定到达。发送之后等待响应过程中，有很多事情可能会出错: 如上图所示，请求响应可能在很多地方法神错误: 请求丢失 请求在队列中，无法马上发送 远程节点失效 远程节点无法立即响应 响应丢失 请求处理已经完成，但回复被延迟处理 如果请求没有得到响应，无法区分是(a) 请求丢失 (b)远程节点关闭 (c)响应丢失 3.1 现实中的网络故障现实中可能因为各种原因出现各种硬件故障，这些原因处理物理原因外，很大一部分是认为造成的。当网络的一部分由于网络故障而与其他部分断开，称之为网络分区。 处理网络故障并不意味着总是需要复杂的容错机制，一种简单的方法是对用户提示错误信息。但前提是必须非常清楚接下来软件会如何应对网络故障，以确保系统最终可以恢复。推荐有计划的人为触发网络问题，来测试系统的反应情况。 3.2 故障检测系统通常都需要自动检测节点失效，然而由于网络的不确定性很难准确判断节点是否确实失效。如果超时是故障检测唯一可行办法，那超时应该设置多长时间呢？: 较长的时间意味着更长时间才能宣告节点失效，在此期间用户只能等待或拿到错误信息 较短的时间可以快速检测故障，但是很可能出现误判(只是网络波动或者性能波动而非故障) 节点宣告失效，需要转移负载，会给网络和其他节点带来额外的负担，如果系统已经处于高负载装填，很可能导致失效扩散。 网络拥塞与排队计算机网络上数据包延时的变化根源往往在于排队: 高流量下，在网络交换机出现排队 CPU高负载下，在操作系统出现排队 虚拟化下，入向的包可能会被虚拟机管理器排队缓存 TCP 执行流量控制意味着数据甚至在进入网络之前，已经在发送方开始排队 TCP 重传也会引入额外的延迟 以上因素都会导致网络延时的变化和不确定性，特别是当系统接近最大设计上限时，负载过高，队列深度就会显著加大，排队对延时的影响变得特别明显。 网络超时设置最好的办法不是设置一个不变的常量，而是持续测量响应时间及其变化，然后根据最新的响应时间分布来自动调整。可以使用 Phi Accrual 故障检测器，改检测器已在 Akka 和 Cassandra 中使用。 4. 不可靠的时钟时钟和计时非常重要，但由于网络的不确定延迟，精确测量面临很多挑战，这使得多节点通信时很难确定事情发生的先后顺序。而且每台机器都维护自己本地的时间版本，可能比其他机器稍快或更慢。NTP通常用来同步机器之间的时钟，一定程度上可以同步机器之间的时钟。 4.1 单调时钟和墙上时钟现在计算机内部至少有两种不同的时钟，本质上他们是服务于不同目的的: 墙上时钟: 钟表时钟，可以与 NTP 同步 因为时钟同步会导致时间出现突然的跳跃，特别是跳回到先前的某个时间点，导致其不适合测量时间间隔 单调时钟: 名字来源于其保证总是向前，不会出现回拨，更适合测量持续时间段(时间间隔) 绝对值没有任何意义，有意义的时钟的间隔 如果服务器有多路CPU，则每个 CPU 可能有单独的计时器，其不与其他CPU同步，由于应用程序的线程可能会调度到不同的 CPU上，操作系统会补偿多个计时器之间的偏差，从而为应用程序提供统一的单调递增计时，不过最好还是对这种偏差补偿持谨慎态度 NTP 不会直接调整单调时钟 分布式系统中可以采用单调时钟测量一段任务的持续时间，它不假设节点间有任何的时钟同步，且可以容忍轻微测量误差。 4.2 时钟同步与准确性墙上时钟需要根据 NTP服务器或其他外部时间做必要的同步，但硬件时钟和 NTP 可能会出现一些莫名其妙的现象: 计算机中的石英钟不够精确，存在漂移现象，即速度加快或减慢 时钟与 NTP 时间差别太大，可能会出现拒绝同步，或者同步后出现时间的突变 网络延时会影响 NTP 同步的准确性 NPT 本身的故障 闰秒 虚拟机中，硬件时钟也是虚拟化的，时间可能出现跳跃 如果应用需要精确同步的时钟，最好仔细监控所有节点上的时钟偏差。如果某个节点的时钟漂移超出上限，应该将其宣告失效，并从集群中移除。 4.3 时间戳与事件顺序跨节点的事件顺序，如果高度依赖时钟计时，就存在一定的技术风险，因为各个节点的时间戳很可能不能对所有事件正确排序。由于时钟精度限制，两个节点可能产生了相同的时间戳。 依赖时间戳确定的事件顺序，无法区分连续快速发生的连续写和并发写入，需要额外的因果关系跟踪机制(版本向量)来防止因果冲突。 因此通过保持最新值并丢弃其他值的最后写入获胜(LWW)冲突解决策略看起来不错，但是最新的定义如果取决于墙上时钟就会引入偏差。 对于排序来说，基于递增计数器而不是震荡石英晶体的逻辑时钟是更可靠的方式。逻辑时钟不测量一天的某个时间点或时间间隔，而是事件的相对顺序(事件发生的相对前后顺序)。相应的墙上时钟和单调时钟都属于物理时钟。 4.4 分布式全局快照的同步时钟(重要)常见的快照隔离需要单调递增事务ID，单节点上，一个简单的计数器足以生成事务ID。但是当数据分布在多台机器，跨越多个数据中心时，由于需要复杂的协调以产生全局的单调递增的事务 ID(跨所有分区)。 事务ID要求必须反映因果关系: 事务B要读取事务A写入的值，B的事务ID，必须大于A的事务ID 考虑到大量，频繁的小包，在分布式系统中创建事务ID通常会引入瓶颈。那能否**用同步后的墙上时钟作为事务ID呢？如果时钟足够可靠其同步，自然符合事务ID属性要求: 后发生的事务具有更大的时间戳。然而问题还是时钟精度不精确。 Googgle Spanner以这种方式实现跨数据中心的快照隔离。它使用TrueTime API报告的时钟置信区间，并基于以下观察结果：如果有两个置信区间，每个置信区间包含最早和最近可能的时间戳（ $A = [A{earliest}, A{latest}]$， $B=[B{earliest}, B{latest}] $），这两个区间不重叠（即：$A{earliest} &lt; A{latest} &lt; B{earliest} &lt; B{latest}$），那么B肯定发生在A之后——这是毫无疑问的。只有当区间重叠时，我们才不确定A和B发生的顺序。 ​ 为了确保事务时间戳反映因果关系，Spanner在提交读写事务之前故意等待置信区间长度的时间。通过这样，它可以确保任何可能读取数据的事务足够晚发生，避免与先前的事务的置信区间产生重叠。为了保持尽可能短的等待时间，Spanner需要使时钟的误差范围尽可能小，为此，Google在每个数据中心都部署了一个GPS接收器或原子钟，保证所有时钟同步在约 7ms 内完成。 借助时钟同步来处理分布式事务语义，除了 Google 以外，目前主流数据库都没有更多的实现。 5. 进程暂停在分布式锁或者 Leader 选举中，通常我们都会只用租约: 某节点获得租约之后，在租约到期之前，它就持有锁或者成为主节点，为了维持主节点身份，节点必须在到期之前定时去更新租约。 典型的流程如下所示: 123456789101112while(true)&#123; request=getIncomingRequest(); // 确保租约还剩下至少10秒 if (lease.expiryTimeMillis-System.currentTimeMillis()&lt; 10000)&#123; // 更新租约 lease = lease.renew(); &#125; // 租约有效 if(lease.isValid())&#123; process(request); &#125;&#125;&#125; 这段代码有什么问题？ 首先，他依赖于同步的时钟，租约到期时间又另一台机器所设置 如果程序执行出现了暂停，例如在 lease.isValid() 消耗了30s，那么当开始处理请求时，租约已经过期了，另一个节点已经成为了主节点。后面代码也不会注意到租约到期，除非运行到下一个循环。不过到那个时候当前的这个进程已经做了一些不安全的请求处理了。 那么什么会导致线程暂停很长时间呢？ GC 暂停 虚拟环境下的，虚拟机暂停 操作系统的上下文切换或者虚拟机管理程序切换到另一虚拟机，虚拟机中断的 CPU 时间称为窃取时间 线程可能暂停并等待 I/O 完成 内存访问可能触发缺页异常 分布式系统的一个节点必须假定，执行过程中的任何时刻都可能被暂停相当长一段时间，包括运行在某个函数中间。暂停期间，整个集群的其他部分都在照常运行，甚至会一致将暂停的节点宣告为故障节点。最终，暂停的节点可能会回来继续运行，除非再次检查时钟，否则它对刚刚过去的暂停毫无意识。 6. 少数服从多数前面我们已经了解了分布式系统面临的种种障碍。那如何去解决这些问题呢？ 在分布式系统中，我们可以明确列出对系统行为(系统模型)所做的若干假设，然后以满足这些假设条件为目标来构建实际运行的系统。我们的目的是确定可以做出哪些合理假设，可以提供哪些保证。 6.1 真相由多数决定节点不能根据自己的信息来判断自身的状态，由于节点可能随时失效，可能会暂停-家私，甚至最终无法恢复。因此分布式系统不能完全依赖于单节点。目前许多分布式算法都依靠法定票数，即在节点之间进行投票(读写 quorum)。任何决策都需要来自多个节点的最小投票数，从而减少对特定节点的依赖。这包括关于宣告节点失效的决定。 由于系统只可能存在一个多数，绝不会有两个多数在同时做出相互冲突的决定，因此系统的决议是可靠的。 6.2 主节点与锁很多情况下，我们需要在系统范围内只能有一个实例： 只有一个分区主节点 只有一个事务或客户端持有锁 唯一ID 在分布式系统中需要格外注意: 及时某个节点自认为它是”唯一的那个”，但不一定获得了系统法定票数的同意。当多数节点声明节点已失效，而该节点还继续充当”唯一的那个”，如果系统设计不周就会导致负面后果。该节点会按照自认为正确的信息向其他节点发送消息，其他节点如果还选择相信它，那么系统就会出现错误的行为。 如下图所示: 不正确的分布式锁实现，客户端1的锁租约已经过期，但他自认为有效，最终导致文件破坏 6.3 Fencing 令牌(重要)当使用锁和租约机制来保护资源的并发访问时，必须确保过期的唯一的那个节点不能影响其他正常部分。有一个简单的办法可以实现: 锁服务在授予锁或租约时，同时返回一个 fencing 令牌，令牌每授予一次就递增一次 要求客户端每次向村粗系统发送写请求时，都必须包含所持有的 fencing 令牌 存储服务器由于记录了最近已经完成了更高令牌号，因此会拒绝低版本令牌的写操作 注: 如果客户端2已经获取锁，但写请求在客户端1的写请求只有达到，会出现什么现象。 如果将ZooKeeper用作锁定服务，则可将事务标识zxid或节点版本cversion用作 fencing令牌，这两个都满足单调递增的需求。 注意这种机制要求资源本身必须主动检查所持令牌信息，如果发现已经处理过更高令牌的请求，要拒绝持有低令牌的所有写请求。总之为了避免在锁保护外发生请求处理，需要进行额外的检查机制。 6.4 拜占庭故障​ fencing 令牌可以检测和阻止那些无意的误操作。如果节点存在撒谎，我们称之为拜占庭故障。在不信任的环境中需要达成共识的问题也称为拜占庭将军问题。 在我们讨论的系统中，可以安全的假设没有拜占庭式的故障。我们假设节点虽然不可靠但一定是诚实的，其一旦做出相应，则一定是完全基于其所知的全局信息和事先约定好的行为准则，响应代表了”真相”。 6.5 理想系统模型与现实(重要)我们通过定义一些系统模型来形式化描述算法的前提条件。 关于计时，有三种常见的系统模型: 同步模型: 假定有上界的网络延迟 有上界的进程暂停 有上界的时钟误差 大多数实际系统的实现模型并非同步模型，因为无限延迟和暂停确实可能发生 部分同步模型: 个系统在大多数情况下像一个同步系统一样运行 但有时候会超出网络延迟，进程暂停和时钟漂移的界限 这是一个比较现实的模型 异步模型: 一个算法不会对时机做任何假设，甚至里面根本没有时钟(也没有超时) 不常见 崩溃-中止模型: 算法假定一个节点只能一种方式发生故障，即遭遇系统崩溃 意味着节点可能在任何时候突然停止响应，且该节点以后永远消失，无法恢复 崩溃-恢复模型: 节点可能在任何时候崩溃，且可能会在一段未知的时间之后得到恢复并在此响应 节点上持久性存储的数据在崩溃恢复之后不会丢失，而内存中的状态可能丢失 拜占庭失效模型: 节点可能发生任何事情，包括作弊和欺诈 真实的系统模型，最普遍的组合是奔溃-恢复模型 + 部分同步模型。 6.6 真实模型映射到现实世界在奔溃-恢复模型中，算法通常假设保存到磁盘的数据可以安然无恙，但是现实可能并非如此。 Quorum 算法要求节点必须记录之前对外所宣告的数据。如果节点发生意外而丢弃存储的数据，会打破法定条件并破坏算法的正确性。或许此时我们需要一个新的系统模型，它假设通常情况下数据存储非常可靠，但还是有丢失的可能。 所以真实模型会更加复杂。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8. 事务]]></title>
    <url>%2F2019%2F04%2F08%2Fdb%2Fdb_8%2F</url>
    <content type="text"><![CDATA[事务 1. 为什么需要事务事务将应用程序的多个读、写操作捆绑在一起成为一个逻辑单元，要么全部成功(提交)、要么失败(中止或回滚)。如果失败，应用程序可以安全地重试。这样无需担心部分失败的情况。事务存在的目的是简化应用层的编程模型。有了事务，应用程序可以不用考虑某些内部潜在的错误以及复杂的并发性问题，这些都交给数据库负责处理(称之为安全性保证)。 要判断什么时候需要事务，我们需要确切理解事务能提供哪些安全性保证，背后的代价是什么。 2. 深入理解事务事务所提供的安全性保证即大家熟悉的 ACID，分表代表: Atomicity: 原子性 Consistency: 一致性 Isolation: 隔离性 Durability: 持久性 但实际上各种数据库所实现的 ACID 并不相同，它们能提供的安全保证也各不相同。 而不符合 ACID 的系统有时被称为 BASE: Basically Available: 基本可用性 Soft State: 软状态 Eventual Consistency: 最终一致性 接下来我们一一来介绍 原子性、一致性、隔离性和持久性的确切含义。 2.1 原子性ACID 的原子性并不关乎多个操作的并发性，它没有描述多个线程视图访问相同的数据会发生情况，后者其实是由 ACID 的隔离性所定义。原子性其实描述了客户端发起一个包含多个写操作的请求时可能发生的情况。把多个写操作纳入到一个原子事务，万一出现了故障而导致没法完成最终提交时，事务会中止，并且数据库会丢弃或撤销哪些局部完成的更改。 原型性大大简化了: 如果事务已经中止，应用程序可以确定没有实质发生任何更改，可以安全的重试。 因此 ACID 中原子性所定义的特征是: 在出错时中止事务，并将部分完成的写入全部丢弃。也许可中止性更为准确。 2.2 一致性很多场景都存在一致性，比如: 副本一致性以及异步复制中，引出的最终一致性问题 一致性哈希 CPA 理论中，一致性用来表示线性化 ACID 中一致性主要指数据库处于应用程序所期待的预期状态 ACID 的一致性主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束(或者恒等条件)。 这种一致性本质上要求应用层来维护状态一致或恒等，应用程序有责任正确的定义事务来保持一致。即如果提供的数据修改为了恒等条件，数据很难检查而组织操作。应用程序可以借助数据库提供的原子性、隔离性达到一致性，但一致性并不源于数据库。因此C 其实不属于 ACID。 2.3 隔离性隔离性意味着并发执行的多个事务相互隔离，不能相互交叉，不会相互影响，比如一个事务不应该看到其他事务部分执行的中间结果。 隔离性意味着可以假装事务是数据库上运行的唯一事务，尽管实际上可能多个事务在同时运行，数据库系统要保证当事务提交时，其结果与串行执行完全相同。 实际上为了权衡性能和安全性，存在多种隔离级别，待会我们在详述。 2.4 持久化持久化保证一旦事务提交成功，及时存在硬件故障或数据奔溃，事务所写入的任何数据也不会丢失: 对于单节点数据库，持久性意味着数据已经写入非易失性存储设备，写入的过程中，通常还涉及预写日志等，以保证磁盘数据损坏可恢复 对于支持远程复制的数据库，持久化意味着数据已成功复制到多个节点 为了实现持久化，数据库必须等到这些写入或者复制完成之后才能报告事务成功提交。现实情况是没有哪一项技术可以提供绝对的持久性保证，包括写入磁盘、复制到远程以及备份，这些都是降低风险的手段，应该组合使用。 3. 多对象事务与单对象事务3.1 多对象事务多对象事务是指一个事务中会修改多个对象，多对象事务会保证多个数据对象之间保持同步。 多对象事务要求确定知道事务包含了哪些读写操作。对于关系型数据库，客户端通常与数据库服务器建立 TCP 连接，因而对于特定的链接，SQL 语句 BEGIN TRANSACTION 和 COMMIT 之间的所有操作都属于同一个事务。但是这种方式并不完美。如果 TCP 连接中断，事务必须终止。假定中断发生在事务提交之后，服务器确认提交完成之前，客户端最后不知道该事务是否已提交。为了解决这个问题，事务管理器需要定义一个唯一的事务标识来逻辑上绑定一组写操作，该事务标识符独立于 TCP 链接。 而许多非关系型数据库则可能不支持多对象事务 3.2 单对象事务原子性和隔离性也同样适用于单个对象的更新，比如像数据库写入 20KB 的JSON 文档: 发送第一个 10KB 之后网络连接中断，数据库是否会存储无法完整解析的片段 数据库覆盖磁盘现有数据时故障，新旧值会不会混杂在一起 另一个客户端是否能看到部分更新的文档 因此存储引擎必须实现的就是单节点、单个对象层面上提供原子性和隔离性，例如: 基于日志恢复实现原子性，对每个对象加锁来实现隔离 3.3 多对象事务的必要性许多分布式数据库不支持多对象事务，主要是因为当出现跨分区时，多对象事务非常难以正确实现，同时在高可用或者极致性能场景下会带来很多负面影响。但是分布式数据库实现事务并非不可能，不存在原理上的限制。 我们是否需要多对象事务？是否有可能只用键值数据模型和单对象操作来实现任何应用程序？的确有可能，但是还有许多情况需要协调写入几个不同的对象: 在关系数据模型中，一个表中的行通常具有对另一个表中的行的外键引用。多对象事务使你确信这些引用始终有效 缺乏连接功能的文档数据库会鼓励非规范化。当需要更新非规范化的信息时，如 图7-2 所示，需要一次更新多个文档。事务在这种情况下非常有用 在具有二级索引的数据库中（除了纯粹的键值存储以外几乎都有），每次更改值时都需要更新索引。如果没有事务隔离性，记录可能出现在一个索引中，但没有出现在另一个索引中，因为第二个索引的更新还没有发生 3.4 处理错误和终止ACID数据库基于这样的哲学：如果数据库有违反其原子性，隔离性或持久性的危险，则完全放弃整个事务，而不是部分放弃。然后并不是所欲的系统都遵循上述理念。例如无主复制的数据存储，主要是在“尽力而为”的基础上进行工作。可以概括为“数据库将做尽可能多的事，运行遇到错误时，它不会撤消它已经完成的事情“ ——所以，从错误中恢复是应用程序的责任。 支持安全的重试机制才是中止流程的重点。尽管重试一个中止的事务是一个简单而有效的错误处理机制，但它并不完美： 如果事务实际上成功了，但是在服务器试图向客户端确认提交成功时网络发生故障（所以客户端认为提交失败了），那么重试事务会导致事务被执行两次——除非你有一个额外的应用级除重机制。 如果错误是由于负载过大造成的，则重试事务将使问题变得更糟，而不是更好。 仅在临时性错误（例如，由于死锁，异常情况，临时性网络中断和故障切换）后才值得重试。在发生永久性错误（例如，违反约束）之后重试是毫无意义的 如果客户端进程在重试中失效，任何试图写入数据库的数据都将丢失 如果事务在数据库之外也有副作用，即使事务被中止，也可能发生这些副作用。如果你想确保几个不同的系统一起提交或放弃，二阶段提交（2PC, two-phase commit） 可以提供帮助 4. 弱隔离级别只有出现某个事务修改数据而另一个事务同时要读取改数据，或者两个事务同时修改相同数据时，才会引发并发问题。并发问题通常难以测试和发现，所以数据库试图通过事务隔离来对应用程序隐藏内部的各种并发问题。隔离是假装没有发生并发，保证事务最终的执行结果与串行执行结果相同。 但是串行化的隔离会严重影响隔离，许多数据库倾向于采用较弱的隔离级别。这些较弱的隔离级别可以防止但是不是全部的并发问题。 接下来我们就来详细分析几个实际中经常用到的弱级别(非串行化)隔离，并详细讨论可能发生的竞争条件。有了这些认识后，可以帮助我们判断哪些场景适合什么样的隔离级别，最后我们将介绍串行化。 4.1 读-提交读-提交时最基本的事务隔离级别，值提供以下两个保证: 读数据库时，只能看到已成功提交的数据(防止，脏读) 写数据库时，只会覆盖已成功提交的数据(防止，脏写) 防止脏读脏读是指事务可以看到其他尚未提交事务部分写入的数据，读-提交意味着事务的任何写入只有在成功提交后，才能被其他事务观察到(并且所有的写全部可见)。 当有一些需求时，需要防止脏读: 事务需要更新多个对象 如果事务中止，则所有写入操作都需要回滚。如果数据库允许脏读，那就意味着一个事务可能会看到稍后需要回滚的数据，而这些数据并未实际提交到数据库中。 防止脏写脏写是指事务会覆盖尚未提交的其他事务的部分写入。读-提交隔离级别可以防止脏写，通常的方式是推迟第二个写请求，直至前面的事务完成提交。 防止脏写，可以避免下面的并发问题: 事务需要更新多个对象 实现读-提交数据库通常采用行级锁来防止脏读: 当事务想要修改特定对象（行或文档）时，它必须首先获得该对象的锁。然后必须持有该锁直到事务被提交或中止。 使用加锁的方式实现脏读，因为会导致许多只读事务等待太长时间，大多数据库采用这样的方法防止脏读: 对每个待更新的对象，数据库都会维护其旧值和当前持有锁事务将要设置的新值两个版本。在事务提交之前，所有其他读操作都读取旧值，仅当写事务提交之后，才会切换到读取新值。 4.2 快照级别隔离与可重复读读-提交，会产生不可重复读，即一个事务内，两次相同的读取可能会读到不同的值。有些场景不能容忍这种暂时的不一致: 备份场景: 备份过程中会继续写入数据，最终的备份数据里可能包含部分旧版本和部分新版本数据 分析查询和完整性检查场景 究其原因，读-提交无法获取数据库的一致性视图。快照级别隔离可以解决这个问题。其总体想法是: 每个事物都从数据库的一致性快照中读取，事物一开始所看到的是最近提交的数据，即使数据随后可能被另一个事物修改，但保证每个事物都只看到改特定时间点的旧数据。 快照级别隔离对长时间运行的只读查询(备份和分析)非常有用。 实现快照级别隔离与读取提交的隔离类似，快照隔离的实现通常使用写锁来防止脏写，读取不需要加锁，读操作不会阻止写操作，反之亦然。 快照级别隔离的实现使用的是多版本并发控制(Multi Version Concurrency Control, MVCC)。每个版本对应正在进行的多个事务在不同的时间点查看到的数据。 如果一个数据库只需要提供读已提交的隔离级别，而不提供快照隔离，那么保留一个对象的两个版本就足够了：提交的版本和被覆盖但尚未提交的版本。所以支持快照隔离的存储引擎往往直接采用MVCC来实现读已提交隔离级别。做法是对每一个不同的查询单独创建一个快照。 在 MVCC的实现中，事务开始时，首先会被赋予一个唯一的、单调递增的事务ID，每当事务向数据库写入新内容时，所写的数据都会被标记写入者的事务ID。当事务读取数据库时，通过事务ID决定哪些对象可见。仅当以下两个条件都成立时，数据对事务可见: 事务开始时，创建该对象的事务已经完成了提交 对象没有被删除，或者删除了，但是删除事务在当前事务开始时还未提交 索引与快照级别隔离MVCC 如何支持索引呢？ 一种防范是索引直接指向对象的所有版本，然后想办法过滤对当前是事务不可见的那些版本。当后台的垃圾回收进程决定删除某个旧对象是，对应的索引条目也需要删除。 在CouchDB，Datomic和LMDB中使用另一种方法。虽然它们也使用B树，但它们使用的是一种仅追加/写时拷贝（append-only/copy-on-write） 的变体，它们在更新时不覆盖树的页面，而为每个修改页面创建一份副本。从父页面直到树根都会级联更新，以指向它们子页面的新版本。任何不受写入影响的页面都不需要被复制，并且保持不变。 这种追加式的 Btree，每个写入事务都会创建一个新的 B-tree root，代表该时刻数据库的一致性快照。这时就没有必要更具事务 ID 再去过滤某些对象，每笔修改都会修改现有的 Btree，因为之后的查询可以直接作用于特定快照 Btree(有利于查询性能)。采用这种方法依然需要后台进程来执行压缩和垃圾回收。 4.3 防止更新丢失总结一下，读-提交和快照级别隔离主要都是为了解决只读事务遇到并发写时可以看到什么。虽然中间也涉及脏写的问题，但是脏写只是写并发的一个特例。总体而言这两种弱隔离级别还没有触及另一种情况，即两个写事务并发。 写事务并发会带来其他一些值的关注的冲突问题，典型的就是更新丢失问题。更新丢失可能发生在这样一个操作场景中: 应用程序从数据库读取某些值，根据应用逻辑做出修改，然后写回新值(read-modify-write)。当两个事务在同样的数据对象上执行类似操作时，由于隔离性，第二个写操作并不包含第一个事务修改后的值，最终会导致第一个事务的修改值可能丢失。这种冲突可能发生在下列场景中: 递增计数器、更新账户余额(read-modify-write) 对某个复杂对象的一部分内容执行修改 两个用户同时编辑 wiki 页面 并发写事务冲突，目前有多种可行的解决方案，包括: 原子写操作 显示加锁 自动检测更新丢失 原子比较和设置 冲突解决与复制 原子写操作许多数据库提供了原子更新操作，以避免在应用层代码完成读-修改-写回操作。无论如何，如果原子操作可行，那么它就是推荐的最佳方式。 原子操作有两种常见的实现方式: 对读取对象加独占锁，这样在更新被提交之前，其他事务不可读取 强制所有的原子操作都在单线程上执行 显示加锁防止更新丢失的另一种方法是应用程序显示锁定待更新的对象，然后执行读-修改-写回这样的操作序列。此时如果有其他事务尝试同时读取对象，则必须等待当前正在执行的序列全部完成。 在 mysql 中就是使用 SELECT … FOR UPDATE;。FOR UPDATE 指令指示数据库对返回的所有结果行加锁。 首先该方法是可行的，但要做到这一点，需要仔细考虑应用层的逻辑。很多代码会忘记在必要的地方加锁，结果很容易引入竞争冲突。 自动检测更新丢失原子操作和锁都是通过强制读-修改-写回操作序列串行执行来防止丢失更新。另一种思路是先让他们并发执行，如果事务管理器检测到了更新丢失风险，则会中止当前事务，并强制回退到安全的读-修改-写回方式。 该方法的一个优点是数据库完全可以借助快照级别隔离来高效地执行检查。PostgreSQL、Oracle 的快照隔离级别都可以自动检测何时发生了更新丢失，然后终止违规的那个事务。但是 MySQL InnoDB 的可重复度并不支持检测更新丢失。 自动检测更新丢失是非常好的功能，应用层代码因此不用依赖数据库提供的特殊功能，且自动生效有效避免这类错误。 原子比较和设置原子比较和设置，即只有在上次读取的数据没有发生变化时才允许更新。否则更新失败，需要应用层再次检查并在必要时进行重试。注意原子比较和设置不能基于快照隔离级别的旧值，而必须是当前的最新值，否则无法防止更新丢失。 冲突解决与复制防止丢失更新需要考虑另一个维度：多个节点上的多个数据副本，并且不同节点上的数据可能被并发修改时。 加锁和原子修改都有个前提:只有一个最新的数据副本。然后对于多主节点或者无主节点的多副本数据库，由于支持多个并发写，且通常以异步方式来同步更新。所以会出现多个最新的数据副本。此时加锁和原子修改比较将不再适用。 如果操作可交换(即顺序无关，在不同的副本上以不同的顺序执行执行仍然得到相同的结果)，则原子操作在多副本情况下也可以工作。 4.4 写倾斜与幻读写倾斜脏读和更新丢失是多事务并发写同一个对象时引发的两种竞争条件，但不是并发写所引发的全部问题。写倾斜和幻读是并发写引发的另外两个问题。 如果两个事务读取相同的一组对象，然后更新其中一部分 如果不同的事务更新不同的对象，则可能发生写倾斜 如果不同的事务更新相同的对象，则可能发生脏读或更新丢失 所以写倾斜可以视为一种更广义的更新丢失问题。所有产生写倾斜的场景都遵循下面类似的模式: 首先输入一些匹配条件，即采用 SELECT 查询所有满足条件的行 根据查询的结果，应用层代码来决定下一步的操作，可能继续或者报告错误 如果应用程序决定继续执行，它将发起数据库写入并提交事务 而对数据库的更新操作会改变第二步做出决定的前提条件 换句话说，如果提交写入之后在重复执行步骤 SELECT 查询，应用层会做出完全不同的判断结果。原因是刚刚的写操作改变了决定的前提条件。比如下面这个值班室必须要有一个医生值班的例子: 医生可以调整班次，但是至少要确保一位医生在该班次值班。 入上图所示，Bob 和 Alice 医生分别申请调班，由于数据库正在使用快照级别隔离，两次检查都返回有两名医生，两个事务都判断可以继续执行，最终的结果是该班次没有医生值班。 这是示例中，步骤 3 中所修改的行恰好是步骤 1 查询结果的一部分，导致了写倾斜。对于这个例子，一种解决方案是: 先修改值班记录并加锁在查询或者加锁读(SELECT FOR UPDATE)，可以保证事务安全，避免写倾斜。 幻读医生值班里的解决方案对于其他一些例子并不适用，比如下面这个声明一个用户名的例子: 网站通常要求每个用户有唯一的用户名，两个用户可能同时尝试创建相同的用户名。可以采用实物的方式首先检查用户名是否被使用，如果没有，则使用该名称创建账户。这个医生值班的例子类似，依然存在写倾斜。但是这个例子更加的特殊无法使用 SELECT FOR UPDATE 通过读加锁来解决，它检查的是不满足给定搜索条件的行(预期结果为空)，接下来添加符合条件的行。因为一开始的读请求根本不会返回任何行，SELECT FOR UPDATE 也就无从加锁。这种在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。快照级别隔离可以避免只读查询时的幻读，但是对于这里讨论的读-写事务，无法解决棘手的写倾斜问题。(注: 这里唯一用户名的问题可以通过数据库的唯一键解决)。 实体化冲突对于幻读，问题的关键是查询结果中没有对象可以加锁，可以人为引入一些可加锁的对象(比如行的间隙，又称为间隙锁)。 比如会议室预定系统的例子: 同一时间，同一个会议室不能被预定两次。我们可以构建一个事件-房间表，表的每一行对应于特定时间段的特定房间。预定事务可以查询并锁定时间-房间表中对应查询房间和时间段的行。 这种方法称为实体化冲突(或物化冲突)，它把幻读问题转变为针对数据库中一组具体行的锁冲突问题。因为弄清楚如何实现实体化具有挑战性，这种把一个并发控制降级为数据模型的思路总是不够优雅。除非没有别的方案可行，否则我们不推荐采用实体化冲突。而在大多数情况下串行化隔离方案更为可行。 有关写倾斜和幻读的一些问题关于幻读有如下几个值的回答的问题。 问题一: 为什么防止更新丢失中的方法很难解决幻读和写倾斜: 首先写倾斜和幻读设计一组对象，原子操作不起作用 快照隔离级别下，几乎所有的关系型数据库都不支持检测写倾斜，自动防止写倾斜要求真正的可串行化隔离 数据不支持复杂的自定义约束条件，我们无法将上面各个例子中的限制条件检测放到数据库中执行 问题二: 读提交隔离级别下会产生写倾斜和幻读么？ 对于医生值班的例子，如果 Alice 调整值班的事务提交后，Bob 的事务在执行的查询，那么可以看到 Alice 已经调整了班次，Bob 调整值班的事务将中止。但是如果 Bob 事务的查询在 Alice 事务提交前，此时依旧会产生类似的错误。所以读提交隔离级别下，依旧存在写倾斜的问题。 对于会议室预定的例子，显然同医生值班的例子一样存在类似的写倾斜问题。但是读提交不会产生幻读问题。因为读提交和幻读在概念定义下没有交集。在读提交下，事务总是能查询到最新事务提交的结果，所以肯定能看到最新插入的数据，也就不存在一个事务中的写入改变了另一个事务查询结果的现象。所以幻读是可重复读隔离级别下才会产生的特定现象。 写倾斜/幻读/可重复读隔离级别之间的关系写倾斜/幻读/可重复读隔离级别，之间的关系是这样的: 可重复读隔离级别下会产生更新丢失和写倾斜问题 使用 SELECT FOR UPDATE(又称为当前读)可以解决更新丢失和部分写倾斜问题(不是全部) 使用 SELECT FOR UPDATE 又会导致幻读问题 幻读和无法用 SELECT FOR UPDATE 解决的写倾斜问题，都是因为无法对不存在行进行加锁的问题，MySQL 里面通过间隙锁解决了幻读问题，间隙就是认为施加的可加锁对象 幻读到底是什么幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。对于幻读需要在注意: 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。而当前读的规则，就是要能读到所有已经提交的记录的最新值。因此，幻读只在“当前读”下才会出现。 修改结果，被之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行” 幻读到底会造成什么影响，请参考文章MySQL 幻读与间隙锁 5. 串行化上面我们分析读-提交、快照隔离，它们可以解决一部分问题，但不是全部，最后你会面临以下挑战: 隔离级别通常难以理解，不同数据库实现还不一致 很难判断应用程序代码，在特定隔离级别下是否安全 缺乏工具帮助分析并发问题 可串行化隔离通常被认为是最强的隔离级别，它保证事务可能会并发执行，但最终的结果与每此一个即串行执行结果相同。换句话说数据库可以防止所有可能的竞争条件。目前大多数谁提供可串行化的数据库都使用一下三种技术之一: 严格按照串行顺序执行 两阶段加锁 乐观并发控制技术 5.1 严格按照串行顺序执行解决并发的问题的直接方法是避免并发，即在一个线程上按顺序每次只执行一个事务。这样我们完全回避了诸如检测、防止事务冲突等问题，对应的隔离级别一定是严格串行化的。但是为什么我们不一开始就只使用单线程，或者说为什么我们又开始考虑只是用单线程顺序执行呢。原因有以下几点: 内存越来越便宜，现在许多应用程序都将整个活动数据集加载到内存。当事务所需的所有数据都在内存时，事务的执行速度要比等待磁盘 I/O 快的多 OLTP 事务通常执行很快，只产生少量读写，相比之下，运行时间较长的分析查询则通常是只读的，可以在快照隔离级别下运行，而不需要运行在串行主循环里 通常的事务处理机制希望囊括用户的所有操作: 事务总是需要等待来自用户的输入，同时还要支持潜在大量并发需求，那么系统大部分时间处于空闲状态。 于此同时事务总体沿用交互式客户端/服务器风格，一次一个请求有语句。请求与结果在应用代码和数据库服务器之间来回交互。这种交互式的事务处理，大量时间耗费在应用程序与数据库之间的网络通信上。数据库总是在等待应用程序提交下一个请求。 在这种类型的数据库中，为了获得足够的吞吐量，需要能够同时处理多个事务 单线程串行的系统则将人为交互从事务中移除，并且不支持交互式的多语句事务。应用程序必须提交整个事务代码作为存储过程打包发送到数据库，同时事务所需的所有数据已经全部加载到内存中，使得存储过程高效执行，而无需等待网络和磁盘I/O VoltDB/H-Store、Redis、Datomic 等采用串行方式执行事务它们的存储已经放弃传统关系型数据库的 PL/SQL，转而使用现有的通用编程语言，Redis 使用 Lua。通用的编程语言克服了传统的 PL/SQL的弊端 存储过程与内存式数据存储使得单线程上执行所有事物变得可行，它们不需要等待I/O，避免加锁开销等复杂的并发控制机制，可以得到相当不错的性能。VoltDB 还借助存储过程来执行复制: 不同通过复制事务的执行结果而是在每个副本上执行相同的存储过程。不过这要求存储过程必须具备确定性。 分区串行执行所有事务使得并发控制更加简单，但是数据的吞吐量被限制在单机单个 CPU核上。虽然只读事务可以在单独的快照上执行，但是对于高写入需求的应用程序，但线程事务处理很容易造成严重的性能瓶颈。 为了扩展到多个CPU核和多节点，可以对数据进行分区。每个事务只在单个数据分区上读写数据，此时每个分区一个CPU核。但是对于跨分区的事务，数据库必须在涉及的所欲分区之间协调事务，存储过程要跨越所有分区加锁执行，以确保整个系统的可串行化。 事务是否能只在单分区上执行很大程度上取决于应用层的数据结构。简单的键值数据比较容易切分，而带有多个二级索引的数据则需要大量的跨区协调，因此不太合适。 使用场景当满足一下条件时，串行执行事务可以实现串行化隔离: 事务必须剪短而高效，否则一个缓慢的事务会影响到所有其他事务的执行 仅限于活动数据集可以完全加载到内存的场景 写入吞吐量必须足够低，才能在单个 CPU核上处理，否则就需要采用分区，最好没有跨分区事务 跨分区事务虽然可以支持，但是占比必须很小 如果事务需要访问那些不在内存的数据，最好的解决方案可能是终止事务，异步的将数据提取到内存中，同时继续处理其他事务，然后在数据加载完成后重启事务 5.2 两阶段加锁首先两阶段加锁 2PL 不是两阶段提交 2PC。两阶段加锁要求，多个事务可以同时读取同一个对象，但只要出现任何写操作，则必须加锁以独占访问。因为2PL 不仅在并发写操作之间互斥，读取也会和修改产生互斥。快照级别隔离的口号读写互不干扰非常准确的点明了它和两阶段加锁的关键区别。2PL 提供了串行化，可以防止前面讨论的所有竞争条件，包括更新丢失和写倾斜(不包括好幻读问题)。 目前2PL已经在 MySQL 可串行化隔离级别中实现。此时数据库的每一个对象都有一个读写锁来隔离读写操作。事务启动时第一阶段要获取所锁，即对读取对象加读锁，对修改对象加写锁，第二阶段事务提交时释放锁。 由于使用了这么多锁，很容易出现死锁现象。 缺陷两阶段锁的主要缺点是: 其事务吞吐量和查询响应时间相比其他弱隔离级别下降非常多。部分原因在于锁的获取和释放本身的开销，更重要的原因是其降低了事务的并发性。 由于传统的关系型数据不限制事务的执行时间，且通常支持人为交互和交互式的多语句事务，事务等待另一个事务完成的时间理论上无上限，如果多个事务操作同一对象，出现严重竞争。如果一个事务很慢且访问了大量数据，将导致所有其他事务停顿。最后2PL 下死锁会更加频繁，从而导致如果事务由于死锁而中止，应用层必须重试，如果死锁过于频繁，性能必然大打折扣。 幻读问题可串行化隔离必须防止幻读问题。有如下几种解决方案: 谓词锁 索引区间锁 他们的核心目的都是为了保护数据中心那些上不存在的但可能马上会被插入的对象(幻读)。谓词锁的问题是性能不佳，所以大多数使用 2PL的数据库试讲实现的是索引区间锁(next-key locking)，本质上他是对为此所的简化或者近似。 索引区间锁简化谓词锁的方式是将其保护的对象扩大化，包括对象和对象所在索引的区间(注，具体原理可以参考 MySQL 间隙锁的实现)。索引区间不像谓词锁那么准确，会锁更大范围的对象，而超出了串行化的要求，但由于开销低的多是一个很好的折中方案。如果没有合适的索引施加区间锁，数据库可以回退到对整个表施加共享锁。 5.3 乐观并发控制技术两阶段加锁可以保证串行化，但性能差强人意；弱隔离级别性能不错，但容易引发各种边界条件。那么串行化隔离与性能是不是无法兼得呢？可串行化的快照隔离(Serializable Snapshot Isolation SSI)提供了完整的可串行性保证，而性能相比于快照隔离损失很小。目前在单节点数据库(PostgreSQL 9.1之后的可串行化隔离)中实现。 悲观与乐观的并发控制两阶段锁是一种所谓的悲观并发控制机制（pessimistic） ：它是基于这样的原则：如果有事情可能出错（例如与其他并发事务发生了锁冲突），那么直接放弃，采用等待方式直至绝对安全。 从某种意义上说，串行执行(单线程执行)悲观到了极致：事务执行期间，等价于事务对整个数据库（或数据库的一个分区）持有锁。我们只能假定事务执行得足够快、持有锁的时间足够短。 相比之下，可串行化的快照隔离则是一种乐观并发控制: 如果可能发生冲突，事务继续执行而不是中止；而当事务提交时(只有可串行化的事务被允许提交)，数据库会检查是否确实发生了冲突(即违反了隔离性的原则)，如果是的话，中止事务并接下来重试。 乐观并发控制的优点和缺点已经争论了很长时间。如果冲突很多(许多事务访问相同的对象)，则性能不佳，大量事务必须中止。如果系统已接近其最大吞吐量，反复重试事务会使系统性能变得更差。如果不存在大量冲突，乐观锁的控制机制比悲观锁高效很多。 SSI 基于快照隔离，也就是说事务中的所有读取操作都是基于数据库的一致性快照。在快照隔离的基础上，SSI 新增了相关算法来检测写入之间的串行化冲突从而决定中止哪些事务。 基于过期的条件做决定当应用程序进行查询时（例如，“当前有多少医生正在值班？”），数据库不知道应用逻辑如何使用该查询结果。安全起见，数据库假定对查询结果(决策的前提条件)的任何改变都会使得写事务失效。 换而言之，事务中的查询与写入可能存在因果依赖。为了提供可串行化的隔离，数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下中止写事务。如果知道查询结果是否发生了变化呢？可以分以下两种情况: 读取是否作用于一个(即将)过期的 MVCC对象，即读取之前已经有未提交的写入 检查写入是否影响即将完成的读取，即读取之后，又有新的写入 检测是否读取了过期的 MVCC对象数据库需要跟踪那些由于 MVCC 可见性规则而被忽略的写操作。当事务提交时，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是则必须中止当前事务。 为什么要等到提交，在执行检查？因为即便是存在未提交的写入，事务也可能会回滚而未最终生效。 如上图: 事务 42 对 Alice 值班的修改未提交，事务 43 可继续执行 当事务 42 提交时，事务 43 从快照读取时被忽略的写入已经生效，并导致其作出决定的前提条件已经失效 事务 43 被终止 检测写是否影响了之前的读第二种要考虑的情况是，在读取数据之后，另一个事务修改了数据。如下图所示: 事务 42/43 都查询了轮班 1234 期间的值班医生 通过索引区间锁，数据库可以通过索引条目 1234 来记录事务 42/43 都查询了相同的结果，SSI 下索引区间锁不会阻止事务继续执行 如果没有索引可以在表级别跟踪此信息，该记录只需要保留很小一段时间，当并发的所有事务都处理完了即可丢弃 当另个一尝试修改时，它首先检查索引，从而确定是否最近存在一些读目标数据的其他事务。这个过程类似在受影响的字段上获取写锁，但是不阻塞读取，而是直到事务提交时才通知他们: 所读到的数据现在已经发生了变化。 事务 43/42 会相互通知对象先前的读已经失效，事务42提交时，事务 43 还未提交所以可以成功提交，而事务 43 则不得不中止。 可串行化快照隔离的性能与两阶段加锁相比，可串行化快照隔离的一大优点是事务需要等待其他事务所持有的锁，读写通常不会相互阻塞，特别是在一致性快照上执行的只读查询需要要任何锁。 与串行执行相比，可串行化快照隔离可以突破单个 CPU 核的限制，从而提高吞吐量。即使数据可以能跨多台机器进行分区，事务也可以在多个分区上读、写数据并保证可串行化隔离。 需要注意，事务中止的比例会显著影响 SSI 的性能表现。例如，一个运行很长时间的事务，读取和写入了大量数据，产生冲突和并中止的概率会恨到，因此SSI要求读-写型事务要简短（而长时间执行的只读事务没有此限制）。总体来说，相比于两阶段加锁和串行执行，SSI 更能容忍哪些执行缓慢的事务。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7. 分区]]></title>
    <url>%2F2019%2F04%2F07%2Fdb%2Fdb_7%2F</url>
    <content type="text"><![CDATA[数据分区 1. 分区分区的存在为了存储海量数据集或者分摊非常大的查询压力。分区通常是这样定义的，每一条数据(记录)只属于某个特定分区。每个分区都可以视为一个完整的小型数据库。采用数据分区通过将负载分摊到更多的机器上来提高系统的可扩展性。分区和复制通常结合使用，即每个分区在多个节点上都存有副本。 分区的主要目的主要是将数据和查询负载均匀分布在所有节点上。这包括以下几个层面的含义: 数据的分区是均衡的，注意是每个分区包含的读写负载是均衡而不是物理上的数据量 每个节点包含的分区数是均衡的 如果分配不均，某些分区承担过多的负载，称之为倾斜。倾斜会导致分区效率严重下降。负载严重不成比例的分区即成为系统热点。 避免热点最简单的方法是将记录随机分配到所有节点，但是当试图读取特定数据时，因为不知道数据保存的节点，不得不并行查询所有节点。而分区的难点就是如何在分区均匀和查询效率上进行权衡。 有关分区，记下来我们将介绍一下内容: 数据分区的方法 数据索引对分区的影响 分区的再均衡，即如何将分区对应到节点上 如何将请求路由到正确的分区 2. 键值数据的分区首先我们来讨论键值数据模型，它有如下几种分区方法: 基于关键字区间分区: 基于关键字哈希值分区 2.1 基于关键字区间分区基于关键字区间分区: 方法: 为每个分区分配一段连续的关键字区间 注意: 数据本身可能不均匀，分区边界需要适配数据本身的分布特征 实践: 采用这种分区方式的数据有 Bigtable，HBase 优点: 分区内可以按照关键字排序保存，可以轻松支持关键字的区间查询 缺点: 应用程序经常访问与排序一致的某段关键字，就会出现热点，比如以天作为关键字的区间分区，会导致查询特定天的读负载集中在一个分区上2.2 基于关键字哈希值分区基于关键字哈希值分区，可以有效均衡负载，但是缺点是失去了良好的区间查询特性，区间查询不得不发送到所有分区上。 但是需要注意的基于哈希的分区不能完全避免倾斜，比如微博里的大V带来的消息洪峰。大多数系统都无法自动消除这种高度倾斜的负载，只能通过应用层来减少倾斜程度。 一个简单的方法是在主键的开始或结尾添加一个随机数。只要一个两位数的十进制随机数就可以将主键分散为100种不同的主键,从而存储在不同的分区中。但随之而来的问题就是，任何读取都要从所有 100 个分区中读取并合并。 3. 分区与二级索引二级索引带来的挑战是它们不能一对一的映射到分区。有两种方法来支持对二级索引进行分区: 基于文档分区的二级索引 方法: 每个分区独立维护自己的二级索引，而不关心其他分区中的数据 优点: 数据的增删改查带来的索引更新也仅限于本分区内 缺点: 基于二级索引的查询需要并行访问所有分区，然后合并所有结果 基于词条的二级索引分区 方法: 构建全局索引，然后对索引页进行分区存储，索引分区的方式可以是基于区间或者哈希的 优点: 读取更加高效，无须访问所有分区，因为可以定位索引所在分区，通过索引可以知道数据所在分区 缺点: 写入慢且非常复杂，首先单文档更新会涉及多个二级索引，多个二级索引可能在不同的分区甚至不同节点上，必然引入显著的写放大 理想情况下，索引应该与数据同步更新，这需要一个跨多个分区的分布式事务支持写入速度非常慢，所以现有的数据库都不支持同步更新二级索引 4. 分区再均衡查询压力增加、数据规模增加、节点故障和添加都会导致数据和请求从一节点转移到另一个节点。此时我们就需要动态调整节点的负载称为分区再均衡。分区再均衡涉及到分区数据的迁移是一个成本很高的操作。 将分区对应到节点上有多种分配方法，包括: 固定数量分区: 有确定的分区数 动态分区: 每个分区有固定范围的的大小 按节点比例分区: 每个节点有固定数量的分区 分区在均衡是一个复杂的操作，特别是自动化再均衡和自动故障检测结合时可能会导致级联式失效扩散。因此让管理员介入到再均衡可能是个更好的选择。 5. 请求路由分区的请求路由属于经典的服务发现问题，任何通过网络访问的系统都有这样的问题。即后台的服务，端口，数据等发生变化时，如何通知客户端做出对应的更改。这个问题有以下几个不同的处理策略: 允许客户端链接任意的节点，由节点负责寻找合适的节点 将所有客户端请求发送到一个路由层，路由层仅是一个分区感知的负载均衡器 客户端感知分区和节点的分配关系 无论哪种方法，问题的核心是:做出路由决策的组件，如何知道分区与节点的对应关系，以及变化情况。需要在所有节点间达成共识。 许多分布式数据系统依赖独立的协调服务，比如 Zookeeper 跟踪集群范围内的元数据，Zookeeper 维护了分区到节点的最终映射关系。其他参与者可以向 Zookeeper 订阅此消息。一旦分区发生变化，Zookeeper 主动通知路由层。 Cassandra 和 Riak 则在节点之间使用 gossip 协议同步集群状态的变化。请求可以发送到任意节点，有该节点转发到目标分区节点。 当使用路由层或向随机节点发送请求时，客户端仍然需要找到要连接的IP地址。这些地址并不像分区的节点分布变化的那么快，所以使用DNS通常就足够了。 理论上每个分区基本保持独立运行，这也是为什么我们试图将分区数据库分布扩展到多台机器上。但是如果写入需要跨多个分区，情况会格外复杂。比如一个分区写入成功，另一个发生错误，这时我们就需要事务为我们提供更加强的一致性保证。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6. 复制]]></title>
    <url>%2F2019%2F04%2F06%2Fdb%2Fdb_6%2F</url>
    <content type="text"><![CDATA[系统可扩展性 1. 系统的可扩展性当负载增加需要更强的处理能力时，我们有两种扩展系统的方式: 垂直扩展: 购买更强大的机器 水平扩展: 组合更多数量的机器 垂直扩展通过共享内存和共享磁盘的方式，让操作系统管理更多的 CPU、内存和磁盘，从何获取更强劲的性能。但是这种方式有明显的缺陷: 成本增长过快，并且由于性能，一台拥有两倍的硬件指标的机器不一定能处理两倍的负载 共享架构只能提供优先的容错能力，并且局限在特定的地理位置，无法提供异地的容错能力 水平扩展的无共享架构不需要专门的硬件，具有较高的性价比，可以跨多个地区。当采用这种架构时，运行软件的机器或者虚拟机称为节点，每个节点独立使用本地的 CPU、内存和磁盘。节点之间的所有协调通信等任务全部运行在传统网络之上且核心逻辑主要依靠软件来实现。 《微服务架构设计模式》阐述了一个概念扩展立方体，它定义在水平扩展下三种不同的扩展应用程序的方法: X轴扩展: 又称为水平复制，通过克隆实例的方式扩展 在多个相同实例之间实现请求的负载均衡 Y轴扩展: 又称为功能性分解 根据功能将应用拆分为服务 Z轴扩展: 又称为数据分区，通过类似客户ID的方式，把相似的数据分区进行扩展 根据请求的属性路由请求 所谓的 Z 轴扩展就与我们接下来要讲述的分布式数据系统有关。将数据分布在多个节点是有另种常见的方式: 复制: 在多个节点上保存相同数据的副本，提供冗余 分区: 将一大块数据拆分成多个较小的子集即分区，不同分区分配给不同节点，用来解决单台机器无法容纳整个数据集的情况 数据的复制和分区经常组合使用。本节我们将介绍数据复制的相关内容。 那么为什么需要多台机器上分布数据呢。通过数据复制，通常希望达到以下目的: 在地理位置上更接近用户，从而降低访问延迟 当部分组件出现故障，系统依然可以继续工作，从而提高可用性 扩展至多台机器以同时提供数据访问服务，从而提高读吞吐量 复制的技术挑战在于处理那些持续更改的数据。接下来我们将讨论三种流行的复制数据变化的方法: 主从复制 多主节点复制 无主节点复制 复制技术存在许多需要考虑的地方，例如采用同步复制还是异步复制，如何处理失败的副本，以及数据的一致性问题。接下来我们会一一详述。数据库复制其实是一个古老的问题，因为网络的基本约束条件至今没有发生本质的改变。 1. 主从复制每个保存数据库完整数据集的节点称之为副本，当有多个副本时，不可避免的引入一个问题: 如何确保所有副本之间的数据是一致的。主从复制就是我们经典的解决方案。主从复制的工作原理如下: 指定一个副本为主副本(主节点)，所有写请求必须发送给主节点，主节点首先将更新数据写入本地存储 其他所有副本称为从副本(从节点)，主副本将数据更改作为复制日志或者更改的流发送给所有从节点。从节点获得更改日志后，严格按照与主节点相同的写入顺序更新本地存储 从节点都是只读的 在复制的过程中就有可能存在以下问题: 采用同步复制还是异步复制 如何新增从节点 节点失效如何处理，包括从节点失效和主节点失效问题 复制滞后问题 在介绍这些问题之前，我们先来看看复制日志的实现。 1.1 复制日志的实现复制日志主要有如下几种实现方式: 基于语句的复制 基于预写日志(WAL)的复制 基于行的逻辑日志复制 基于触发器的复制 基于语句的复制主节点记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库。这种复制有一些不适用的场景: 任何调用非确定性函数（nondeterministic）的语句，可能会在每个副本上生成不同的值，日入 NOW() 获取的当前时间 如果语句使用了自增列（auto increment），或者依赖于数据库中的现有数据（例如，UPDATE … WHERE &lt;某些条件&gt;），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。当有多个并发执行的事务时，这可能成为一个限制。 有副作用的语句（例如，触发器，存储过程，用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定的。 的确有办法绕开这些问题，但是由于边缘情况实在太多了，现在通常会选择其他的复制方法。 基于预写日志的复制前面我们介绍存储引擎的索引时，说到写操作通常会先以追加的方式写入到预写日志中: 对于日志结构存储引擎（请参阅“SSTables和LSM树”），日志是主要的存储位置。日志段在后台压缩，并进行垃圾回收。 对于覆写单个磁盘块的B-tree，每次修改都会先写入预写式日志（Write Ahead Log, WAL），以便崩溃后索引可以恢复到一个一致的状态 所以无论哪种情况，都可以通过分发日志的方式进行复制。基于预写日志的方式主要缺点是日志记录的数据非常底层：WAL包含哪些磁盘块中的哪些字节发生了更改。这使复制与存储引擎紧密耦合。如果数据库将其存储格式从一个版本更改为另一个版本，通常不可能在主库和从库上运行不同版本的数据库软件。 看上去这可能只是一个微小的实现细节，但却可能对运维产生巨大的影响。如果复制协议允许从库使用比主库更新的软件版本，则可以先升级从库，然后执行故障切换，使升级后的节点之一成为新的主库，从而执行数据库软件的零停机升级。如果复制协议不允许版本不匹配（传输WAL经常出现这种情况），则此类升级需要停机。 基于行的逻辑日志复制另一种方法是，复制和存储引擎使用不同的日志格式，这样可以使复制日志从存储引擎内部分离出来。这种复制日志被称为逻辑日志，以将其与存储引擎的（物理）数据表示区分开来。 关系数据库的逻辑日志通常是以行的粒度描述对数据库表的写入的记录序列： 对于插入的行，日志包含所有列的新值。 对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，但是如果表上没有主键，则需要记录所有列的旧值。 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列的新值（或至少所有已更改的列的新值）。 MySQL的二进制日志（当配置为使用基于行的复制时）使用这种方法。 对于外部应用程序来说，逻辑日志格式也更容易解析。如果要将数据库的内容发送到外部系统（如数据），这一点很有用，例如复制到数据仓库进行离线分析，或建立自定义索引和缓存。 这种技术被称为 数据变更捕获（change data capture） 基于触发器的复制到目前为止描述的复制方法是由数据库系统实现的，一些工具，如 Oracle Golden Gate ，可以通过读取数据库日志，使得其他应用程序捕获数据变更，从而将复制控制交给应用层，实现特定的复制逻辑。 另一种方式是借助关系型数据的触发器和存储过程实现类似的功能: 触发器将数据变更记录到一个单独的表中 外部处理逻辑通过访问该表获取变更数据 Databus for Oracle 和Bucardo for Postgres 就是这样工作的。 基于触发器的复制通常比其他复制方法具有更高的开销，并且比数据库的内置复制更容易出错，也有很多限制。然而由于其灵活性，仍然是很有用的。 主从复制的原理至此我们就说的差不多，接下来我们来解决主从复制中的那些棘手问题。 1.2 同步复制与异步复制复制非常重要的一个设计选项是：同步复制（synchronously）异步复制（asynchronously）。下面是一个用户更新头像的流程: 从节点1的复制是同步的，主节点需要等待直至从节点1确认了写入，才能向用户报告完成，并将最新的写入对其他客户端可见 从节点2的复制是异步的，主节点发送完消息后立即返回，无需等待从节点2的完成确认 同步复制对于同步复制: 优点是: 从库保证有与主库一致的最新数据副本，主库崩溃后，不会丢失最近的更新 缺点是: 如果同步的从节点无法完成确认，写入就不能成功，主节点会阻塞其后的所有的写操作直至同步完成 显然，把所有从节点都设置成同步的有些不切实际，因为任何一个节点的中断都会导致整个系统停滞不前。更常见的配置是半同步: 某一个从节点是同步的，其他节点是异步的 同步的从节点不可用，将另一个异步从节点提升为同步模式 这样可以保证至少有两个节点拥有最新数据 异步复制异步复制跟同步复制刚好相反，主节点不用任何等待因此系统的吞吐量更好，但是如果主节点失效期不可恢复，那尚未复制到从节点的写请求就会丢失。意味着即使向客户端确认了写操作，仍然无法保证数据的持久化。 异步模式的这种弱化的持久性听起来非常不靠谱，但是异步复制还是被广泛使用，特别是那些从节点数量巨大或者分布与广域地理环境。 因为异步复制无法保证主从节点什么时候，是否一定完成复制，就会产生”复制滞后问题”。 1.3 复制滞后问题主从复制要求所有写请求必须发送给主节点，从节点都是只读的，对于读操作密集的负载是可行。创建多个副本，就可以提高读请求的吞吐量。但是这种情况下只能使用异步复制，因为试图同步所有副本，任何一个节点的中断都会导致整个系统停滞不前。 使用异步复制，因为主节点不会等待从节点确认，主从复制会存在延时。在主从同步的过程中，主从节点可能处于不一致的状态，这种不一致只是一种暂时状态，从节点最终会赶上主节点保持，这种效应被称为最终一致性。最终一致性是一个非常弱的保证，副本落后的程度理论上没有上线。接下来我们就来介绍复制滞后可能出现的三个问题: 读自己写 单调读 前缀一致性读 读自己写读自己写描述的是，用户发起读请求，然后在滞后副本上读取数据，而无法立即查看到自己写入的数据。这种情况下我们需要写后读一致性。 写后读一致性，又称为读写一致性，保证如果用户重新加载页面，总是能看到自己最近提交的更新。但对其他用户没有任何保证。实现读写一致性有如下几个方法: 如果用户可能访问被修改的内容，直接从主节点读取 如果数据分布在多个数据中心，必须把请求路由到主节点所在的数据中心 使用同步位点的方式，判断从节点是否已经包含用户最近的更新 如果用户可能从多个设备访问数据，例如在桌面 Web 浏览器修改，在移动端设备上立刻查看，情况会更复杂，此时要提供跨设备的读写一致性。 如果副本分布在不同的数据中心，很难保证来自不同设备的连接会路由到同一数据中心。 （例如，用户的台式计算机使用家庭宽带连接，而移动设备使用蜂窝数据网络，则设备的网络路线可能完全不同）。如果你的方法需要读主库，可能首先需要把来自同一用户的请求路由到同一个数据中心。 单调读单调读描述的是: 用户看到了最新内容之后又读到了过期的内容，好像时间被回拨。此时需要单调读一致性。 单调读是一个比强一致性弱，但比最终一致性强的保证，其保证某个用户一次进行多次读取，不会看到回滚现象(在读取较新值之后又发生读旧值的情况)。 实现单调读取的一种方式是确保每个用户总是从同一个副本进行读取（不同的用户可以从不同的副本读取）。例如，可以基于用户ID的散列来选择副本，而不是随机选择副本。但是，如果该副本失败，用户的查询将需要重新路由到另一个副本。 前缀一致读前缀一致读描述的是: 分区数据经多副本复制后出现了不同程度的之后，导致用户先看到果(后发生的事)后看到因(先发生的事)。 这是分区数据库中出现的一个特殊问题，如果数据库总是以相同的顺序写入，则读取总是看到一致的序列，不会发生这种反常。然而在许多分布式数据库中，不同的分区独立运行，因此不存在全局写入顺序。这就导致当用户从数据库中读取数据时，可能看到数据库的某部分旧值和另一部分新值。 前缀一致读保证的是，对于一系列按照某个顺序发生的写请求，读取这些内容时也会按照当时写入的顺序。 一种解决方案是，确保**任何具有因果顺序关系的写入交给一个分区来完成。但这个方案的真实效果会打打折扣，难点就在于如何判断不同操作之间的因果关系。还有一些显式跟踪因果依赖关系的算法，我们待会再来详细介绍。 总结使用最终一致性系统时，最好先考虑这样的问题: 如果复制延迟增加到几分钟甚至几小时，那么应用层的行为会是什么样子。如果带来糟糕的用户体验，那么在设计系统时 就要考虑提供一个更强的一致性保证，比如写后读一致性，单调读，前缀读。 在应用层可以提供比底层数据库更强有力的保证，而代价是应用层代码处理这些问题通常会非常复杂。如果假定数据库在做正确的事，情况会变得简单，而这也是事务存在的原因，事务是数据库提供更强保证的一种方式。 1.4 配置新的从节点如果需要增加新的副本，如何确保新的从节点与主节点保持一致呢，逻辑上的主要操作如下: 在某个时刻获取主库的一致性快照 将此快照拷贝到新的节点 从库连接到主库，并拉取快照之后发生的所有数据变更，这要求快照与主库复制日志中的位置精确关联 1.5 处理节点失效节点失效与系统的高可用性有关，我们的目标是，尽管个别节点会出现中断，但要保持系统总体的持续运行，并尽可能减少节点中断带来的影响。那如何使用主从复制实现系统的高可用呢? 从节点失效: 追赶式恢复 主节点失效: 节点切换 从节点失效在主从复制下，失效的从节点在恢复正常后会自动恢复 主节点失效主节点失效需要进行节点切换: 选择某一从节点为主节点 客户端需要更新，保证后续写请求路由到新的主节点 其他从节点需要更新，以从新的主节点接收并更数据 切换可以手动进行，也可以自动切换，通常步骤如下: 确认主节点失效，大多数都基于超时机制，节点之间相互发送心跳信息 选取新的主节点 可以通过选举方式进行，让所有从节点同意新的主节点属于典型的共识问题， 也可以让系统中的控制器来指定新的主节点，候选节点最好与原主节点的数据差异最小，最小化数据丢失 重新配置系统使得主节点生效，包括客户端、从节点的主节点指向 确保原来的主节点恢复后降级为从节点，并认可新的主节点 切换过程中充满变数: 产生冲突写 有外部数据库依赖当前数据库进行协同使用 脑裂 超时时间设置 系统已经处于高压状态或者出现网络拥堵导致主节点失效，不必要的切换会加重系统负担。因此有些运维团队更加愿意手动控制整个切换过程 上述这些问题，包括节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间的各种细微权衡。没有简单的解决方案。 2. 多主复制主从复制有一个明显缺点，系统只有一个主节点，所有写入必须经由主节点。对主从复制的自然扩展就是配置多个主节点，每个主节点都可以接受写操作。 在一个数据中心内部使用多个主节点基本没有太大意义，其复杂度已经超过所能带来的好处。但是在多数据中心下，多主复制是合理的: 为了容忍数据中心级别故障或者更接近用户，设置多个数据中心；每个数据中心一个主节点，在数据中心内部采用主从复制，数据中心之间，由各个数据中心的主节点负责同其他数据中心主节点进行数据交换和更新。多个数据中心之间采用异步复制，可以更好的容忍广域网带来的网络延迟。CouchDB 是为这种操作模式而设计的。 多主复制的最大问题是可能发生写冲突。 2.1 处理写冲突多主复制会产生冲突的原因在于多个主节点都只是按照它所看到的写入顺序执行，缺乏全局的写入顺序。数据库最终将处于不一致的状态。 所有的复制模型至少应该确保数据在所有副本中最终状态一定是一致的。因此数据库必须以一种收敛趋同的方式来解决冲突。这也意味着所有更改最终被复制、同步之后，所有副本的最终值是相同的。 实现收敛的冲突解决有以下几种可能的方式: 最终写入者获胜: 给每个写入分配一个唯一 ID，挑选最高 ID 的写入作为胜利者，覆盖其他写入。这种方法很容造成数据丢失 值组合: 记录和保留冲突相关的所有信息，由用户或者应用程序逻辑决定如何解决写入冲突 理论上我们还有两种方式解决写冲突问题:1.同步冲突检测: - 可以在多主复制中同步进行冲突检测，即等待写请求完成对所有副本的同步，然后在通知用户写入成功。 - 但是这样做将失去多主节点的优势: 允许每个主节点独立接收写请求 - 如果想实现同步冲突检测，或许更应该考虑采用单主节点的主从复制。 避免冲突: 应用程序保证对特定记录的写请求总是路由到同一主节点，从用户角度这基本等价于主从复制模型 但是无法保证路由的始终一致，比如数据中心已经发生故障，或者用户已经漫游到另一位置，因而更靠近新的数据中心，所以从冲突无法根本避免 最后冲突解决通常用于单个行或文档。因此如果一个原子事务包括多个不同写请求，每个写请求仍然是分开解决冲突的。 2.2 自动冲突解决有一些有趣的研究来自动解决由于数据修改引起的冲突。 无冲突复制数据类型（Conflict-free replicated datatypes）（CRDT）是可以由多个用户同时编辑的集合，映射，有序列表，计数器等的一系列数据结构，它们以合理的方式自动解决冲突。一些CRDT已经在Riak 2.0中实现 可合并的持久数据结构（Mergeable persistent data structures）显式跟踪历史记录，类似于Git版本控制系统，并使用三向合并功能（而CRDT使用双向合并） 可执行的转换（operational transformation）是Etherpad 和Google Docs 等合作编辑应用背后的冲突解决算法。它是专为同时编辑项目的有序列表而设计的，例如构成文本文档的字符列表。 2.3 复制拓扑复制拓扑描述了写请求从一个节点传播到其他节点的通信路径。如果存在多个主节点，会有多个可能的同步拓扑: 复制拓扑需要解决的一个问题是防止无限循环，每个节点需要赋予一个唯一的标识符，在复制日中的每个写请求都标记了已通过的节点标识。如果节点收到了包含自身标识符的数据修改则忽略请求，避免重复转发。 另一个问题则是复制拓扑中可能存在某些网络链路比其他链路更快的情况，从而导致复制日志之间的覆盖: 在上图的更新序列中，主节点3 是执行插入然后在更新，新插入的行被更新。但是在主节点2 中，由于网络延迟先执行了更新后执行的插入，插入的行则未被更新。 这里涉及到一个因果关系问题，类似前面的前缀一致读: 更新操作一定是依赖于先前完成的插入，因此我们需要确保所有节点上一定要先接收插入之日，在处理更新。在每笔写入中简单添加时间戳是不够的，因为无法保证时钟同步。 为了使得日志消息正确有序，可以使用一种称为版本矢量的计数(后面会详细介绍)。需要指出冲突检测计数在许多多主复制系统中还不够完善。 3. 无主节点复制单主节点和多主节点复制都基于这样一种核心思路，即客户端先向某个节点(主节点)发送写请求，然后数据库系统负责将写请求复制到其他副本。主节点决定操作的写入顺序，从节点按照相同的顺序来应用主节点所发送的写日志。 而对于无主节点复制的系统，允许任何副本直接接受来自客户端的写请求，并没有固定的写入顺序。 Riak，Cassandra和Voldemort是由Dynamo启发的无主节点、开源数据库，所以这类数据库也被称为Dynamo风格。 3.1 无主节点的 quorum 读写无主节点复制模型允许多个客户端对相同的键同时发起写操作: 如果总共有 n 个副本，写入需要 w 个节点确认，读取需要查询 r 个节点，则只要 w + r &gt; n，读取的节点中一定包含最新值。 仲裁条件 w + r &gt; n 定义了系统可容忍的失效节点数: w,r 参数只是决定要等待的节点数，读写请总是并行发送到所有 n 个副本的 quorum 不一定非得是多数，读写的节点集合有一个重叠的节点才是最关键的。 最后，无主节点的数据库使用版本矢量确定哪个值更新，版本矢量技术我们待会详述。 3.2 无主模型的数据复制因为读写请总是并行发送到所有 n 个副本的，所以在没有节点失效的情况下，无需进行数据的复制操作。但是节点失效后恢复上线，如何确保所有数据复制到这些失效副本中。通常有两种机制: 读修复: 客户端读取时，可以检测到过期的返回值，并在此时执行复制 此方法适用于频繁读取的场景 反熵过程: 又后台进程不断查找副本之间的数据差异并执行复制 与基于主从复制中的复制日志不同，此反熵过程不保证以特定的顺序复制写入，并且会引入明显的同步滞后 3.3 quorum 一致性的局限性与多主复制一样，无主复制一样缺乏全局的写入顺序，如果两个写操作同时发生，会导致数据冲突。而且即便 w + r &gt; n 的情况下，也可能返回旧值: 如果写操作与读操作同时发生，写操作还未返回，但是可能已经反映在某些副本上。在这种情况下，不能确定读取的是旧值还是新值 如果写操作在某些副本上成功，而在其他节点上失败（例如，因为某些节点上的磁盘已满），在小于w个副本上写入成功。所以整体判定写入失败，但整体写入失败并没有在写入成功的副本上回滚。这意味着如果一个写入虽然报告失败，后续的读取仍然可能会读取这次失败写入的值 如果携带新值的节点失败，但是恢复数据来自某个旧值，则总的新值副本数会低于 w，这就打破了 w + r &gt; n 的判定条件 因此，尽管 quorum 设计上似乎可以保证读取最新值，但在实践中并不那么简单。 Dynamo风格的数据库通常针对最终一致性场景而优化。但是最好不要把 w 和 r 视为绝对的保证。而是一种灵活可调的读取新值的概率。 无法保证得到前面所说的任意一致性保证，包括: 写后读、单调读、前缀一致读。如果需要更强的保证，需要考虑事务和共识。 4. 检测并发写前面我们多次提到版本矢量技术。这是一种确定并发写入顺序以解决写入冲突的一种技术。副本应该收敛于相同的内容，这样才能达到最终一致。因此我们必须了解数据库内部冲突处理机制。在详细介绍冲突处理之前，我们首先需要确定如何判断两个操作是并发的？。 4.1 happen before 和并发我们可以简单的说，如果两个操作都不在另一个之前发生，那么操作就是并发的(或者两者都不知道对方的存在)。我们需要一个算法来判断两个操作是否并发: 如果一个操作发生在另一个操作之前，则后面的操作可以覆盖较早的操作 如果属于并发，就需要解决潜在的冲突问题 4.2 版本矢量我们来看一个确定操作并发性的算法–版本矢量，算法的工作流程如下: 服务器为每个主键维护一个版本号，每当主键对应的记录变化时，递增版本号，并将新的版本号和写入的值一起保存 客户端读取主键时，服务器返回所有当前值，以及最新的版本号，其要求写之前，客户端必须先发送读请求，即确定新的写请求依赖哪些的版本号 客户端写主键，写请求必须包含之前读到的版本号、读到的值和新值合并后的集合(执行数据合并，合并并发写) 当服务器接收到带有特定版本号的写入时，覆盖该版本号或更低版本的所有值(因为知道这些值已经被合并到新传入的集合中)。但是必须保存更高版本号的所有值(因为这些值和当前的写操作属于并发)。 版本矢量保证不会发生数据丢失，客户端需要做一些额外工作: 如果多个操作并发，客户端必须通过合并并发写入的值来继承旧值。考虑到数据合并非常复杂且容易出错，因此可以设计一些专门的数据结构来自动执行合并。例如 Riak 支持称为 CRDT 一系列数据结构，以合理的方式高效自动合并，包括支持删除标记。 注意上面描述的是只有一个副本的情况，如果存在多个副本(多主复制中的多个主节点，无主复制中的所有副本)需要为每个副本和每个主键都定义一个版本号，每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。所有副本的版本号集合称为版本矢量。具体的工作流程与上面介绍的类似。 版本矢量技术是数据库可以区分哪些值更新，应该覆盖写还是保留并发值。 4.2 最终写入者获胜解决写入冲突是为了让副本趋于一致，所以我们也可以不管是否发生并发写入，只要保证数据一致即可，只要我们有一个明确的方法确定哪一个写入时最新的，副本就可以最终收敛到相同的值。即便无法确定写请求的自然顺序，我们也可以强制进行排序。 这种冲突解决算法被称为最后写入胜利（LWW, last write wins），是Cassandra 唯一支持的冲突解决方法。 LWW实现了最终收敛的目标，但以持久性为代价：如果同一个Key有多个并发写入，即使它们都被报告为客户端成功（因为它们被写入 w 个副本），但只有一个写入将存活，而其他写入将被静默丢弃。如果丢失数据不可接受，LWW是解决冲突的一个很烂的选择。 要确保 LWW 安全无副作用的唯一方法是，值写入一次然后视为不可变，这样就避免了对同一主键的并发写。例如，Cassandra推荐使用的方法是使用UUID作为键，从而为每个写操作提供一个唯一的键。 4.4 总结写入冲突的根本原因是没有全局的写入顺序，因此写入冲突不会发生在主从复制中，因为只有单一的主节点，它掌握了全局的写入顺序。 主从复制非常流行，因为它很容易理解，也不需要担心冲突问题，但是万一出现节点失效、网络中断和抖动，多主节点和无主节点则更加可靠，不过背后的代价是系统的复杂性和弱一致性保证。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5. 数据编码与演化]]></title>
    <url>%2F2019%2F04%2F05%2Fdb%2Fdb_5%2F</url>
    <content type="text"><![CDATA[构建可适应变化的系统 1. 数据的演化应用程序不可避免的需要随时间而变化，大多数情况下，应用程序的更改也需要更改其存储的数据: 增删字段或者以新的方式呈现数据。当数据格式或模式发生变化时，同样也需要对应用程序代码进行相应调整。 代码的升级往往需要一定时间，这意味着新旧版本的代码，以及新旧数据格式，可能会同时在系统内共存。此时我们就需要双向兼容: 向后兼容: 新代码可以读取由旧代码编写的旧数据 向前兼容: 就代码可以读取由新代码编写的新数据 向前兼容比较棘手，需要旧代码预知未来，忽略新版本的代码所做的添加。接下来将介绍多种编码数据的格式，包括 JSON，XML，Protocol Buffers、Thrift、Avro。我们将讨论它们如何处理模式变化、如何支持新旧数据和新旧代码共存。还将讨论这些格式如何用于数据存储和通信，包括 Web 服务，具象状态传输(REST)、远程过程调用以及消息传递系统。 向前向后兼容对于可演化性非常重要，通过允许独立升级系统的不同部分，而不是一次改变所有，是的更改更加容易。兼容性是执行编码的一个进程有u执行解码的另一进程之间的关系。 2. 数据编码格式程序通常使用至少两种不同的数据表示形式: 内存中，数据保存在对象、结构体等等数据结构中，这些数据结构针对 CPU 高效访问和操作进行了优化(使用指针) 将数据写入文件或者通过网络发送时，必须将其编码为某种自包含的字节序列(指针对其他进程没有意义) 从内存中的表示到字节序列称为编码(序列化)，相反的过程称为解码(反序列化)。数据编码格式分为如下几类: 语言特定格式 JSON、XML与二进制变体 Thrift 与 Protocol Buffers Avro 2.1 语言特定格式编程语言都内置架构内存中的对象编码为字节序列，比如 Java io.Serializable、Ruby Marshal、Python pickle。通常在语言内部使用起来非常方便，但他们都存在下面这些问题: 跨语言非常困难 安全问题 便捷性是首要，通常忽略向前和向后兼容等问题 效率问题 所以使用语言内置的编码方案通常不是个好主意，仅作为临时尝试。 2.2 JSON、XML与二进制变体JSON，XML和CSV是文本格式，因此具有人类可读性，但它们都有一些微妙问题: 数字的编码多有歧义之处: XML和CSV不能区分数字和字符串（除非引用外部模式） JSON 不区分整数和浮点数，而且不能指定精度 JSON和XML对Unicode字符串（即人类可读的文本）有很好的支持，但是它们不支持二进制数据（不带字符编码(character encoding)的字节序列），使用Base64将二进制数据编码为文本来绕开这个限制 XML 和 JSON都有可选的模式支持，但是学习和实现起来都比较复杂(模式，就是数据类型的说明) CSV 没有任何模式，完全由应用程序定义 尽管存在这些那些缺陷，但JSON，XML和CSV已经足够用于很多目的。特别是作为数据交换格式（即将数据从一个组织发送到另一个组织），它们很可能仍然很受欢迎。这种情况下，只要人们对格式是什么意见一致，格式多么美观或者高效就没有关系。让不同的组织达成一致的难度超过了其他大多数问题。 2.3 二进制编码数据到达一定规模后，数据格式的选择会产生很大的 影响。与二进制格式相比，JSON 和 XML 非常冗长，因此出现了大量二进制编码，用于 JSON和 XML 的补充。但是所有这些都没有规定模式，所以需要在编码数据时包含所有的对象字段名称。。而这些都可以通过引入带模式的编码格式来优化。 3. Thrift 与 Protocol BuffersApache Thrift(Facebook) 和 Protocol Buffers(Google) 是基于相同原理的两种二进制编码，都需要模式来编码任意的数据。 12345&#123; "userName": "Martin", "favoriteNumber": 1337, "interests": ["daydreaming", "hacking"]&#125; 使用Thrift 与 Protocol Buffers 编码上面的 JSON 数据，需要如下几个步骤: 模式定义: 使用接口定义语言(IDL)来描述模式 代码生成: 使用代码生成工具和定义的模式生成编程语言的特定类，编程语言可以直接使用生成的代码编码和解码改模式编码的数据 3.1 模式定义12345678910111213# Thriftstruct Person &#123; 1: required string userName, 2: optional i64 favoriteNumber, 3: optional list&lt;string&gt; interests&#125;# protobufmessage Person &#123; required string user_name = 1; optional int64 favorite_number = 2; repeated string interests = 3;&#125; 3.2 数据格式ThriftThrift有两种不同的二进制编码格式iii，分别称为BinaryProtocol和CompactProtocol。先来看看 BinaryProtocol : 注: 16 进制中，一个字节 8 个bit 位，需要两个 16 进制字符表示。 如上图: 编码数据包含数字类型的字段标签(field tag)，而不是具体的字段名，这样更加节省空间并且紧凑 每个字段都有一个类型注释、并且在需要时指定长度，然后是字段的具体值 CompactProtocol 与 BinaryProtocol 类似，但是使用可变长的类型来编码数据。 CompactProtocol 中: 将字段类型和标签号打包到单个字节中 int64 使用可变长度整数来实现 每个字节的最高位用来指示是否还有更多的字节来 这意味着-64到63之间的数字被编码为一个字节，-8192和8191之间的数字以两个字节编码 Protocol BuffersProtocol Buffers 与 Thrift的CompactProtocol非常相似: 需要注意的一个细节：在前面所示的模式中，每个字段被标记为必需或可选，但是这对字段如何编码没有任何影响（二进制数据中没有任何字段指示是否需要字段）。所不同的是，如果未设置该字段，则所需的运行时检查将失败，这对于捕获错误非常有用。 3.3 字段标签和模式演化Thrift 与 Protocol Buffers 使用字段标签号(1,2,3)对于模式演化非常重要: 可以轻松更改模式中字段的名称，而编码永远不直接引用字段名称 但不能随便更改字段的标签号，它会导致所有编码数据无效 一条编码记录只是一组编码字段的拼接，如果没有设置字段值，将其从编码的记录中简单忽略即可 模式演化: 添加新字段时: 必须给字段一个新的字段标识，并且不能是必需字段 向前兼容: 旧代码读取新数据时，可以简单忽略新加的字段，实现时通过数据类型的注释来通知解析器跳过特定的字节数即可 向后兼容: 只要字段标识唯一，新代码总是可以读取旧数据，只要新字段不是必需的，否则运行时检查失败 删除字段: 与添加字段相同，只不过向前向后兼容正好相反 只能删除非必须字段，而且不能再次使用删除的字段标识 数据类型变更: 数据类型变更是可能的，但是会有丢失精度和被截断的风险 Protobuf的一个奇怪的细节是，它没有列表或数组数据类型，而是有一个字段的重复标记 repeated（这是第三个选项旁边必要和可选）。，重复字段的编码正如它所说的那样：同一个字段标记只是简单地出现在记录中。这具有很好的效果，可以将可选（单值）字段更改为重复（多值）字段: 读取旧数据的新代码会看到一个包含零个或一个元素的列表（取决于该字段是否存在） 读取新数据的旧代码只能看到列表的最后一个元素 Thrift有一个专用的列表数据类型，它使用列表元素的数据类型进行参数化。这不允许Protocol Buffers所做的从单值到多值的相同演变，但是它具有支持嵌套列表的优点。 4. AvroApache Avro 是另一种二进制编码格式，与Protocol Buffers和Thrift有趣的不同。 它是作为Hadoop的一个子项目在2009年开始的，因为Thrift不适合Hadoop的用例。 Avro也使用模式来指定正在编码的数据的结构。 它有两种模式语言： 一种（Avro IDL）用于人工编辑 一种（基于JSON），更易于机器读取 1234567891011121314151617# IDLrecord Person &#123; string userName; union &#123; null, long &#125; favoriteNumber = null; array&lt;string&gt; interests;&#125;# JSON&#123; &quot;type&quot;: &quot;record&quot;, &quot;name&quot;: &quot;Person&quot;, &quot;fields&quot;: [ &#123;&quot;name&quot;: &quot;userName&quot;, &quot;type&quot;: &quot;string&quot;&#125;, &#123;&quot;name&quot;: &quot;favoriteNumber&quot;, &quot;type&quot;: [&quot;null&quot;, &quot;long&quot;], &quot;default&quot;: null&#125;, &#123;&quot;name&quot;: &quot;interests&quot;, &quot;type&quot;: &#123;&quot;type&quot;: &quot;array&quot;, &quot;items&quot;: &quot;string&quot;&#125; ] &#125; Avro 的模式没有标签编号，编码后的二进制数据如下: 在 Avro 编码的数据中: 没有字段标识号和数据类型 编码只是长度加值，但是编码数据里没有告诉你值的类型 整数使用可变长度编码 为了解析数据，需要按照他们在模式中的顺序遍历这些字段，由模式确定字段类型 4.1 读/写模式Avro 写模式指的是，应用程序使用模式的任何版本来编码数据，读模式指的是应用程序解码时，期望数据符合某个模式。Avro 的关键思想是写模式和读模式不必是完全一模一样，它们只需保持兼容: 当读取时，Avro 库通过对比查看写模式和读模式并将数据从写模式转换为读模式来解决其差异 即便读写模式字段顺序不同也可以，模式解析通过字段名匹配字段，原理入下图所示 4.2 模式演化使用 Avro，向前兼容意味着可以将新版本的模式作为 writer，旧版本的模式作为 reader；向后兼容意味着可以将新版本的模式作为 reader，旧版本的模式作为 writer。具体实现如下: 新增/删除字段: 读模式遇到出现在写模式但不在读模式的字段则忽略 读模式需要但是写模式不包含，则使用在读模式中声明的默认值填充 类型变化: 只要 Avro 可以转换类型，就可以改变字段的数据类型 更改字段名: 更改字段名是可能的，reader 模式可以包含字段名称的别名，因此可以将旧 writer 模式字段名称与别名进行匹配。这意味更改字段名可以向后兼容(新代码知道旧模式的别名，但是旧代码不知道新增的别名) 同理向联合类型添加分支也是向后兼容的 在 Avro 中如果要允许字段为 null，必须使用联合类型，例如 union{null, long, string}。只有 null 是联合的分支之一时，才可以使用它作为默认值。因此Avro 不像Protocol Buffers和 Thrift 那样具有可选和必需的标签，而是有联合类型和默认值。 4.3 如何记录写模式目前为止忽略了一个重要问题: reader 如何知道特定的数据采用哪个版本的 writer。这取决于 Avro 的使用上下文: 有很多记录的大文件 eg: hadoop 的上下文中 在文件的开头包含 writer 的模式信息 具有单独写入记录的数据库: 不同记录可能使用不同的 writer 模式 解决方案是在每条记录中包含一个版本号，并在数据库保留一个模式版本列表 通过网络连接发送记录 通过网络交互的进程可以在建立连接是协商模式版本 4.4 Avro 优势Avro的一个优点是不包括任何标签号，这对于动态生成的模式更友好。因为 Avro 通过字段名自动关联记录和读取模式，相比于明确写死的字段标签号更加灵活。更加适用于动态类型的编程语言。如果一个 Avro 对象容器嵌入了 writer 模式，该文件就是自描述的，可以使用 Avro 库直接查看，就像查看 JSON 文件一样。 5. 模式的优点Protocol Buffer、Thrift、Avro 都使用了模式来描述二进制编码格式，相比于 JSON和XML 的模式他们更加简单，并支持更详细的验证规则。它们有如下的优点: 比各种二进制JSON变体更加紧凑，可以节省空间 模式数据库允许在部署任何内容之前检查模式更改的向前和向后兼容 通过支持演化支持与读时模式的 JSON 数据库相同的灵活性，同时还提供了相关数据和工具方面更好的保障。 6. 数据流模式所谓数据流模式指的是进程间数据流动的方式，常见的包括: 通过数据库 通过服务调用，包括 REST和RPC 通过异步消息传递 6.1 基于数据库的数据流基于数据库的数据流有以下特点: 写入数据库相当于编码，读取数据时相当于解码 因为服务的滚动升级，数据库通常也需要向前向后兼容 在模式更改时，将数据库中的所有进行重写的代价是昂贵的。因此大多数据库都避免此操作。大多数关系型数据库允许简单的模式变更，例如添加具有默认值的新列，而不重写现有数据。读取就行时，数据库自动为磁盘上编码数据缺失的列添加默认值。 模式演化支持整个数据库看起来像是单个编码模式，即便底层存储可能包含各个版本模式所编码的记录 应用程序可能随时变化，但是数据库内容包含的多年前的数据可能一直未变，除非明确的重写它，即所谓数据比代码更长久 有一个坑，较新的代码将该新字段的值写入数据库。随后，旧版本的代码（尚不知道新字段）将读取记录，更新记录并将其写回。在这种情况下，理想的行为通常是旧代码保持新的领域完整，即使它不能被解释。需要特别注意应用程序中的 ORM 模型对象，它很可能在读取和重新生成记录的过程中丢失未知字段。 基于数据库的数据流的模式演化取决于所使用的数据库。关系数据库通常假设数据库中的所有数据都符合一种模式，尽管模式可以改变，但是任意给定时间点都只有一个有效模式，数据库的模式必须是所有应用程序模式的交集。相比之下，读时模式数据库不强制执行模式，数据库包含了不同时间写入的新旧数据混合体，此时需要额外的方法记录数据的模式，数据库支持或者应用程序本身做兼容，这个依数据库自身使用的编码技术而异。 6.2 REST/RPC需要通过网络技术进行通信的继承，有多种不同的通信方式，最常见的就是 REST和RPC。 RESTREST 是基于 HTTP 协议的，它不是一个协议，而是一个基于 HTTP 原则的设计理念，它强调简单的使用方式，并使用 HTTP 功能就行缓存控制、身份验证和内容类型协商。通常涉及较少的代码生成和自动化工具。定义格式入 OpenAPI 也称为 Swagger，可用于描述 RESTful API 并帮助生成文档。 RPCRPC(Remote Procedure Call)模型试图是向远程网络服务发出请求看起来与在同一进程中调用编程语言中的函数和方法相同。这种方法在根本上是有缺陷的，网络请求与本地函数调用非常不同: 本地函数调用是可预测的，要么成功要么失败要么永远不返回(死循环)。网络请求是不可预知的：由于网络问题，请求或响应可能会丢失，所以必须有所准备，例如通过重试失败的请求 网络请求超时，根本不知道发生了什么，如果重试失败的网络请求，可能会发生请求实际上正在通过，只有响应丢失。在这种情况下，重试将导致该操作被执行多次，除非您在协议中引入除重（ 幂等（idempotence））机制。本地函数调用没有这个问题。 网络请求很因为网络波动而导致延迟变化很大 调用本地函数时，可以高效地将引用（指针）传递给本地内存中的对象。当你发出一个网络请求时，所有这些参数都需要被编码成可以通过网络发送的一系列字节。没关系，如果参数是像数字或字符串这样的基本类型，但是对于较大的对象很快就会变成问题。 尽管有这样那样的问题，RPC不会消失。在本章提到的所有编码的基础上构建了各种RPC框架：例如，Thrift和Avro带有RPC支持，gRPC是使用Protocol Buffers的RPC实现，Finagle也使用Thrift，Rest.li使用JSON over HTTP。gRPC支持流，其中一个调用不仅包括一个请求和一个响应，还包括一系列的请求和响应。 这种新一代的RPC框架更加明确的是，远程请求与本地函数调用不同。使用二进制编码格式的自定义RPC协议可以实现比通用的JSON over REST更好的性能。但是，RESTful API还有其他一些显著的优点：对于实验和调试（只需使用Web浏览器或命令行工具curl，无需任何代码生成或软件安装即可向其请求），它是受支持的所有的主流编程语言和平台，还有大量可用的工具（服务器，缓存，负载平衡器，代理，防火墙，监控，调试工具，测试工具等）的生态系统。由于这些原因，REST似乎是公共API的主要风格。 RPC框架的主要重点在于同一组织拥有的服务之间的请求，通常在同一数据中心内。 RPC 方案的向前向后兼容性取决于它所使用的具体编码技术。 6.3 基于消息传递的数据流与直接RPC相比，使用消息代理有几个优点： 如果收件人不可用或过载，可以充当缓冲区，从而提高系统的可靠性。 它可以自动将消息重新发送到已经崩溃的进程，从而防止消息丢失。 避免发件人需要知道收件人的IP地址和端口号（这在虚拟机经常出入的云部署中特别有用）。 它允许将一条消息发送给多个收件人。 将发件人与收件人逻辑分离（发件人只是发布邮件，不关心使用者） 然而，与RPC相比，差异在于消息传递通信通常是单向的：发送者通常不期望收到其消息的回复。一个进程可能发送一个响应，但这通常是在一个单独的通道上完成的。 消息代理最近像RabbitMQ，ActiveMQ，HornetQ，NATS和Apache Kafka这样的开源实现已经流行起来。详细的传递语义因实现和配置而异。消息代理通常不会强制任何特定的数据模型，消息只是包含一些元数据的字节序列，因此可以使用任何编码格式。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4. 数据存储和检索]]></title>
    <url>%2F2019%2F04%2F04%2Fdb%2Fdb_4%2F</url>
    <content type="text"><![CDATA[数据如何存储，如何检索 1. 存储引擎上一节我们讨论了数据模型和查询语言，即应用开发人员向数据库执行数据格式并在之后如何查询的机制。接下来我们从数据的角度在此探讨同样的问题，即如何存储输入的数据，并在收到查询请求时，如何重新找到数据。 接下来我们将比较两个存储引擎家族: 日志结构的存储引擎和面向页的存储引擎。 数据结构的核心是数据结构，为了高效的查询数据库中的数据，我们需要新的数据结构: 索引。索引背后的基本思想是保留一些额外的元数据，这些元数据作为路标，帮助定位想要的数据。索引是基于原始数据派生而来的额外数据结构，它只会影响查询性能，维护额外的结构势必会引入开销，由于每次写数据时，需要更新索引，因此任何类型的索引都会降低写速度。 一个存储引擎通常需要解决以下问题: 文件格式: 数据存储的方式，影响数据解析的效率，影响索引的选择，数据增删改查的方式 数据分段: 数据和日志不可能只保存在一个文件中 奔溃恢复 部分写入的处理 并发控制 2. 索引2.1 哈希索引内存中的 hash map 把每个键一一映射到数据文件中特定的字节偏移量。只要所有的 key 可以放入内存，只需要一次磁盘寻址，就可以查询到key 对应的 value 值。 哈希索引也有其局限性: 哈希表必须全部放入内存 哈希变满时，继续增长代价昂贵，并且哈希冲突时需要复杂的处理逻辑 不支持区间查询。 使用 hash map 的典型存储引擎是 Bitcash(Riak 中的默认存储引擎，是一个 key-value 键值数据库)。Bitcash 是如何解决存储引擎的上述问题的呢？ 文件格式: 二进制格式，首先以字节为单位来记录字符串的长度，之后跟上原始字符串 数据分段: 数据被分解成一定大小的段，多个数据段可以按键合并压缩(数据也是以key-value存储的) 每个段都有自己的内存哈希表，查询时按照新旧程度顺序索引哈希表 增删改查: 数据删除需要使用墓碑，以便在合并数据段时丢弃删除的记录 奔溃恢复: 数据库重启 hash map 需要重建，此时需要扫描整个数据库文件 Bitcash 通过将 hash map 的快照存储在磁盘上，来加速索引的重建 部分写入: 记录需要添加校验来发现部分写入的记录 并发控制: 由于 Bitcash 采用追加写的方式，严格按照写入的先后顺序进行写入，并且数据是不可修改的，通常的实现是只有一个写线程。 通过实践证明追加写的设计非常合理，理由是: 追加和分段主要是顺序写，通常比随机写快很多 如果段文件是追加的和不可变的，并发和崩溃恢复要简单的多 合并旧段可以避免随着时间推移数据文件出现碎片化的问题。 2.2 SSLTable 和 LVS-Tree前面介绍采用追加写的数据分段中，key-value 是按照顺序写入的，后出现的值将覆盖之前的值。除此之外文件中 key-value 的顺序并不重要。而 SSLTable(排序字符串表)要求每个键在每个段中只能出现一次，且 key-value 是顺序排序的。 SSLTable 相比哈希索引的数据分段具有以下优点: 合并段更加简单高效，即使文件大于内存，也可以使用类似归并排序的算法进行合并 查询时，不需要再内存中保存所有键的索引，因为键是有序的，使用间隔的稀疏内存索引和二分查找就可以快速检索数据 由于读请求往往需要扫描请求范围内的多个key-value，可以考虑将这些记录保存到一个块中并在写磁盘之前将其压缩，然后稀疏内存索引的每个条目指向压缩块的开头。 构建和维护 SSLTableSSLTables 构建的核心是如何让数据按键排序，有很多树结构支持按任意顺序插入并以排序后的顺序的读取。存储引擎的基本工作流程如下: 写入时，将其添加至内存中的平衡树结构中(比如红黑树)，这个树又称为内存表 当内存表大于一个阈值时，将其作为 SSLTable 写入磁盘文件 SSLTable 写入磁盘就可以创建新的内存表实例 读请求，先从内存表读取，然后是磁盘段文件 后台进程周期性执行段合并和压缩 写入时，会同时写入内存表和追加至日志文件中，已进行崩溃恢复 以上正是 LevelDB RocksDB key-value 键值数据库所使用的。类似的存储引擎还包括 Cassandra 和 HBase。 SSLTable 最初以 LSM-Tree 命名，基于合并和压缩排序文件原理的存储引擎通常被称为 LSM 存储引擎。 性能优化查找数据库不存在的键时，LSM-Tree 算法可能很慢，因为要从内存表追溯到最旧的段文件。为了优化这种访问，存储引擎通常使用布隆过滤器。 不同的策略会影响 SSLTable 压缩和合并的具体顺序和时机。常见的两种方式是: 大小分级和分层压缩: 大小分级: 较新和较小的 SSLTable 被连续合并到较旧和较大的 SSLTable 分层压缩: 键的范围分裂成多个更小的 SSLTable，旧数据被移动到单独的纷呈，这样压缩可以逐步进行并节省磁盘空间 SSLTable 总结对于使用 SSLTable的存储殷勤: 即使数据集远远地大于可用内存，仍然能正常工作 由于数据集按排序存储，因此可以有效执行区间查询 由于磁盘顺序写入，SSLTable 可以支持非常高的写入吞吐量。 2.3 B-trees和 SSLTable 一样，B-tree 保留了按键顺序的 key-value，可以实现高效的 key-value 查找和区间查询。但相似仅此而已，B-tree 有着非常不同的设计理念: B-tree 将数据库分解成固定大小的页，通常为 4KB，也是内存读写的最小单元，这种设计更接近底层硬件，因为磁盘也是固定大小的块 每个页都有地址或位置标识，可以让一个页引用另一个页，这样所有的页将构造成一个树状页集合 更新现有键的值，首先搜索包含该键的叶子页，然后更新，并将整个页写回磁盘 插入时类似，找到其范围包含新键的页，添加至该页，然后写入整个页，如果也没有足够的空间就会分裂 插入算法会自动保证树的平衡，具有 n 个键的 B-tree 具有 Ologn 的深度，大多数数据库都只有 3-4层的 B-tree B-tree 的可靠性B-tree 底层的基本写操作是使用新数据覆盖磁盘的旧页，在也分裂时，需要写多个页，并更新父页内对子页的引用。这是比较危险的，因为如果数据库在完成部分页写入后发生奔溃，会导致索引破坏。 为了从奔溃中恢复，数据库中的 B-tree 实现需要支持磁盘上的额外数据结构: 预写日志(write-ahead log, WAL)，也称为重做日志。这是一个仅追加写的文件，每个 B-tree 的修改必须先更新 WAL 然后在修改树本身的页。 原地更新页的另一个复杂因素是，多线程并发访问控制，否则线程可能会看到树处于不一致的状态。通常使用锁存器(轻量级的锁)保护树的结构来完成。这方面，日志结构化的方法(LVS-tree)显得更简单，因为它们在后台执行合并，不干扰前端的查询。 2.4 B-tree 与LSM-tree 对比根据经验，LSM-tree 通常写入更快，B-tree 读取更快，具体也依据实际使用场景不同。 LSM-tree 的优点: 顺序写，具有较低的写放大，支持更高的写入吞吐量 支持更好的压缩，通常更小。相反 B-tree 存在碎片导致占据更大的空间 LSM-tree 的缺点: 压缩过程中，有时会干扰正在进行的读写操作，及时存储引擎尝试增量执行压缩，不影响并发访问，但是磁盘并发资源有限，执行昂贵的压缩时，很容易发生读写等待，相反 B-tree 的响应延迟则更具确定性 如果写入吞吐量很高可能会发生压缩无法匹配数据写入速率的情况，此时数据段将不断增多，读取速率也会降低 B-tree 的优点: 每个键都唯一对应于索引中的某个位置，而日志结构的存储引擎可能在不同的段中具有相同键的多个副本 如果希望提供强大的事务语义，B-tree 更具吸引力。在许多关系型数据库中，事务隔离是通过键范围上的锁实现的，在B-tree 索引中这些锁直接定义在树中 2.5 其他索引聚簇非聚簇索引 聚簇索引: 就是记录直接保存在索引中 非聚簇索引: 索引值保存的是数据的引用，实际数据存放在堆文件中 每个索引只引用堆文件中数据的位置信息，可以避免数据重复 当更新值而不是更新键时，堆文件非常高效，只要新值不大于旧值就可以原地更新 如果更新的新值比旧值大，就需要移动数据同时更新所有索引中数据的指向 从索引到堆文件的额外跳转对于读取是很大的性能损失 多列索引和多维度索引 多列索引: 由多列数据组成的索引 多维度索引: 一次查询多列的方法，比如地理空间查询，标准的 B-tree 和 LSM-tree 都无法高效的完成此类查询 多维度索引的一种选择是将多维转换为一维然后使用 B-tree 索引。更常见的是使用专门的空间索引，比如 PostGIS 使用 Post供热SQL 的广义搜索树。另一种多维索引技术是 HyperDex 全文索引和模糊索引前面介绍的索引都是查询确切的数据，而全文索引或者模糊索引支持对一个单词的所有同义词进行查询，并忽略单词语法上的变体，即一种模糊查询。 在内存中保存所有内容目前讨论的所有数据结构都是为了适应磁盘限制。与内存相比，磁盘更难处理，需要精心安排磁盘上的数据布局。这些都是值得的，因为磁盘可以进行数据持久化并且每 GB 容量成本更低。 随着内存的更便宜更大，内存数据库也随之出现和发展。一些内存 key-value 数据库主要用于缓存，数据丢失是可接受到。但是其他内存数据库通过一些技术，比如: 用特殊的硬件(电池供电内存)，将更改记录磁盘，定期快照至磁盘、复制内存到其他机器等方式实现持久化。尽管写入磁盘，但是磁盘仅仅用于持久化目的，读取完全靠内存服务。 内存数据库有: VoltDB/MemSQL/Oracle TimesTen：具有关系模型的内存数据 RAMCloud: 开源的具有持久性的内存 key-value 数据库，对内存和磁盘上的数据使用日志结构 Redis/Couchbase: 通过异步写入磁盘提供较弱的持久性。 与直觉相反，内存数据库的性能欧式并不是因为它们不需要从磁盘读取。如果有足够的内存，即便是基于磁盘的存储引擎，也可能不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存中。相反内存数据库可以更快是因为它们避免使用写磁盘的格式对内存数据结构编码的开销。 内存数据库另一个有意思地方是提供了基于磁盘索引难以实现的数据结构，典型的是 Redis。内存数据库使用所谓的反缓存方法，在内存不够用时将最近最少使用的数据写到磁盘，可以支持比内存更大的数据集。 将来非易失性存储得到广泛普及后，存储引擎将会进一步更新。 3. 列式存储3.1 事务处理和分析处理数据库的使用有另种典型的应用场景: 事务处理: OLTP(online transaction processing) 应用程序使用索引中的某些键查找少量记录，根据用户输入插入或者更新记录。因为这些应用程序是交互的，所以访问模式被称为在线事务处理 事务，主要指组成一个逻辑单元的一组读写操作 分析处理: OLAP(online ayalytic processing) 分析查询需要扫描大量记录，每个记录只读取少数激烈，并计算汇总统计信息，而不是返还原始数据给用户 为了区分使用数据库与事务处理的模式，称之为在线分析处理 属性 OLTP OLAP 主要读特征 基于键，每次返回少量的记录 对大量记录进行汇总 主要写特征 随机访问，低延迟写入用户输入 批量导入(ETL)或事件流 典型使用场景 终端用户，通过网络应用程序 内部分析师，为决策提供支持 数据表征 最终的数据状态(当前时间点) 随时间而变化的所有事件历史 数据规模 GB到TB TB到PB 请求数 大量用户请求，使用索引查找数据，磁盘寻道是瓶颈 请求数量少，扫描行数多，磁盘带宽是瓶颈 当查询需要在大量行中顺序扫描是，索引的关联性就会显著降低，相反最重要的是非常紧凑的编码数据，以尽量减少磁盘读取的数据量. 3.2 数据仓库单独的用于数据分析的数据库，被称为数据仓库。企业可能有十几种不同的交易数据，数据仓库包含公司所有 OLTP 系统的只读副本。将数据导入数据仓库的过程称为提取-转换-加载(Extract-Transform-Load, ETL)。 OLAP 通常要扫描大量数据，代价昂贵，使用单独的数据仓库可以避免对 OLTP 业务产生影响，保证其高可用和并发执行事务的性能。于此同时单独的数据仓库可以针对分析访问模式进行优化，这就是我们接下来要说的列式存储，它可以实现我们前面所说的紧凑的编码数据的目的。 数据仓库的数据模型最常见的是关系型，因为 SQL 通常适合分析查询。表面上数据仓库和关系型 OLTP 数据库看起来很相似，因为他们都具有 SQL 查询接口，但是系统内部差异很大，针对不同的查询模式进行了各自的优化。 开源的数据仓库包括: Apache Hive、Spark SQL、Cloudera Impala、FaceBook Presto、Apache Tajo、Apache Drill 3.3 分析业务的数据模型分析业务的数据模型非常少，许多数据仓库都实用了星型模式，又称维度建模，包括: 事实表: 模式的中心 每一行表示在特定时间发生的事件 每一列是属性，与维度表关联的外键 维度表: 维度表记录了时间的对象、什么、地点、时间、方法以及原因 日期和时间通常使用维度表示，这样可以对日期时间进行分组对比分析 3.4 列式存储星型模式中的数据仓库中，事实表通常列数非常多，因为要记录所有事件占据的存储非常大，对其高效的存储和查询是一个挑战。虽然事实表列数非常多，但典型的查询往往值访问其中4、5列。 大多数 OLTP 数据库中，存储以面向行的方式布局: 来自表的一行的所有值彼此相邻存储。即便只需要一行中的个别列，但是仍然需要将过滤出的行的所有列从磁盘加载到内存并解析它们，最后丢弃不需要的列。 面向列存储则，不需要将一行中的所有值存储在一起，而是将每列中的所有值存储在一起，查询时只需要读取和解析需要的列，从而节省大量的工作。面向列存储依赖一组文件，每个文件以相同顺序保存着数据行。 面向列的存储还非常适合压缩。通常列中的不同值的数量要远小于行数，我们可以使用位图编码进行压缩，具体的做法是: 假如一列有 n 个不同值，每个值有独立的一行位图，一个位对应一行 如果行具有该值，该位为 1 如果 n 很大，大多数位图将会有很多零，此时位图可以进行游程编码 说起来比较复杂我们看下面的图示 位图索引非常适合下面这样的查询: 12WHERE product_sk IN（30，68，69）WHERE product_sk = 31 AND store_sk = 3 只要加载相应的位图行，执行按位与计算即可。对于不同类型，还有各种其他的压缩算法。 注意: Cassandra 和 HBase 有一个列族的概念，他们继承自 Google Bigtable，但是它们每个列族中，都将一行中的所有列与行主键一起存储，并且不使用列压缩。因此，Bigtable模型仍然主要是面向行的。 处理数据存储，OLAP 数据库还有其他问题需要考虑: 从磁盘获取数据到内存的带宽 如何高效的将内存带宽用于CPU缓存 而列式存储除了有效降低数据量外，还有利于高效利用 CPU 周期。 3.5 列存储中的排序列存储中每列独自排序是没有意义的，因为那样我们就不会知道列中的哪些项属于同一行。我们可以基于常见查询的知识，将列存储中的数据，按照常见查询的键进行排序后存储。这样一方面可以加快常见查询查询速度，另一方面可以增加排序键的压缩效果。 第一个排序键的压缩效果最强。第二和第三个排序键的压缩情况会变得更加复杂，因为通常不会有太多相邻的重复值。排序优先级进一步下降的列基本上会呈现接近随机的顺序。 不同的查询受益于不同的排序顺序，那么为什么不以多种不同的方式存储相同的数据呢？无论如何，数据需要复制到多台机器来保证数据不丢失。因此存储不同方式排序的冗余数据，正是商业数据仓库 Vertica 使用的方式。 3.6 列存储的写操作面向列的存储，压缩和排序都有助于更快地读取这些查询。然而，他们有写更加困难的缺点。 使用B树的更新就地方法对于压缩的列是不可能的。如果你想在排序表的中间插入一行，你很可能不得不重写所有的列文件。由于行由列中的位置标识，因此插入必须始终更新所有列。 幸运的是，本章前面已经看到了一个很好的解决方案：LSM树。所有的写操作首先进入一个内存中的存储，在这里它们被添加到一个已排序的结构中，并准备写入磁盘。内存中的存储是面向行还是列的，这并不重要。当已经积累了足够的写入数据时，它们将与磁盘上的列文件合并，并批量写入新文件。这基本上是Vertica所做的。 查询需要检查磁盘上的列数据和最近在内存中的写入，并将两者结合起来。但是，查询优化器隐藏了用户的这个区别。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3. 数据模型与查询语言]]></title>
    <url>%2F2019%2F04%2F03%2Fdb%2Fdb_3%2F</url>
    <content type="text"><![CDATA[用于数据存储和查询的通用数据模型 1. 数据的抽象大多数应用程序是通过一层一层叠加数据模型来构建的，每一层都面临的关键问题是: 如何将其用下一层来表示？例如: 应用程序开发人员通过对象或数据结构，以及操作这些数据结构的API对数据进行建模 存储时，需要通过特定的数据模型(JSON/XML/图/关联的行)对这些数据进行序列化 数据库工程师决定使用什么硬件以及字节格式来存储序列化之后的数据 从应用程序到最后的磁盘存储可能会有很多的中间层，但基本的思想是相同的: 每层都通过提供一个简洁的数据模型来隐藏下层的复杂性。采用什么样的数据模型决定了层与层之间转换的效率和复杂度，以及数据支持的查询方式。 目前大多数应用程序开发都使用面向对象的编程语言来开发，程序运行时，数据是程序中的对象，保存在程序的数据结构中，数据之间通过引用，可以进行任意关联。当数据被存储时，程序中的对象被转换成数据模型，数据结构之间的任意引用反映在模型构造的数据关系中。因此，对于数据而言，应用的需求就是如何更加便利的表示程序中的对象，并反应应用内数据之间的关系(一对一，一对多，多对一还是多对多)。 接下来我们将比较关系模型、文档模型和一些基于图的数据模型。 2. 数据模型2.1 关系模型关系模型中，数据被组织成关系（SQL中称作表），其中每个关系是元组（SQL中称作行)的无序集合。在这种模型中: 表具有固定的模式，并通过外键和连接，来表示数据之间的关系 将应用程序中的对象以及他们的之间的引用关系，保存在关系型数据库中的表，行，列时需要一个显示的中间转换层，虽然对象关系映射（object-relational mapping, ORM） 框架可以减少这个转换层所需的样板代码的数量，但是它们不能完全隐藏这两个模型之间的差异。模型之间的脱离有时被称为阻抗失谐。 但是除此之外关系模型在数据的规范化、查询的便捷性、联合的支持上都表现优秀。关系数据库的查询优化器称得上是一个复杂的怪兽，但是其核心是: 只需构建一次然后所有使用该数据库的应用程序都可以从中受益。 2.2 文档模型文档有多种形式，比如 xml，json，最常见属 json。 json 通过在其父记录中存储嵌套记录，而不是在单独的表中，可以很自然的表示一对多关系。嵌套存储意味着数据存在树状结构，JSON 表示将该树结构现实化。这种自包含的文档比关系型中的多表模式具有更好的局部性。 这种局部性的性能优势，只有在应用程序经常需要访问整个文档时才会显现。只访问其中的一小部分，这对于大型文档来说是很浪费的。更新文档时，通常需要整个重写。只有不改变文档大小的修改才可以容易地原地执行。因此，通常建议保持相对小的文档，并避免增加文档大小的写入。这些性能限制大大减少了文档数据库的实用场景。 文档模型的另一个显著缺点是在文档数据库中，对联合的支持通常很弱。不支持联合导致在表示多对一和多对多时产生内容的重复问题。显然文档模型也很难表示多对多关系。 比如用户所在地区的表示，无论是存储ID还是文本字符串，都涉及内容重复的问题。当使用ID时，对人类有意义的信息只存储在一个地方，引用它的所有内容都使用 ID。当直接存储文本时，则使用它的每条记录都保存了一份这样可读信息。使用 ID 的好处是，因为它对人类没有任何直接意义，所以永远不需要直接改变：及时 ID 标识的信息发生了变化，它也可以保持不变。相反以文本存储的信息将产生冗余副本，在这些信息发生变化时这些冗余副本都需要更新，并且存在数据不一致的风险。消除这种重复正是数据库规范化的核心思想(模式和反模式)。 2.3 网络模型在网络模型中，记录之间的链接不是外键，而更像是编程语言的指针。访问记录的唯一方法是选择一条始于根记录的路径，并沿着相关链接依次访问。这种命令式的查询方式(你必须告诉数据库如何去查询，而不是告诉它你需要什么)使得查询和更新数据变得异常复杂而没有灵活性。所以网络模型基本已不再使用。 2.4 数据模型的灵活性文档数据库有时称为无模式（schemaless） 一个更精确的术语是读时模式（schema-on-read） （数据的结构是隐含的，只有在数据被读取时才被解释） ，相应的是写时模式（schema-on-write） （传统的关系数据库方法中，模式明确，且数据库确保所有的数据都符合其模式） 当由于某种原因（例如，数据是异构的） 集合中的项目并不都具有相同的结构时,读时模式更具优势。例如， 如果：存在许多不同类型的对象，将每种类型的对象放在自己的表中是不现实的。 数据的结构由外部系统决定。你无法控制外部系统且它随时可能变化。 在上述情况下，模式的坏处远大于它的帮助，无模式文档可能是一个更加自然的数据模型。但是，要是所有记录都具有相同的结构，那么模式是记录并强制这种结构的有效机制。 2.5 模型比较总结起来文档数据模型具有如下优点: 架构灵活性，有一定的局限性，因局部性而拥有更好的性能 对于某些应用程序而言更接近于应用程序使用的数据结构 文档数据库对连接的糟糕支持也许或也许不是一个问题，这取决于应用程序 因此如果应用程序中的数据具有类似文档的结构（即，一对多关系树，通常一次性加载整个树），那么使用文档模型可能是一个好主意。如果你的应用程序确实使用多对多关系，那么文档模型就没有那么吸引人了。通过反规范化可以减少对连接的需求，但是应用程序代码需要做额外的工作来保持数据的一致性。通过向数据库发出多个请求，可以在应用程序代码中模拟连接，但是这也将复杂性转移到应用程序中，并且通常比由数据库内的专用代码执行的连接慢。在这种情况下，使用文档模型会导致更复杂的应用程序代码和更差的性能 关系模型则具有如下优点: 为连接提供更好的支持 支持多对一和多对多的关系 对于高度相联的数据，选用文档模型是糟糕的，选用关系模型是可接受的，而选用图形模型（参见“图数据模型”） 是最自然的 2.6 模型的融合随着时间的推移，关系模型和文档模型已经开始相互借鉴。SQL 标准增加了对结构化数据类型， XML 和 json 数据的支持；这允许将多值存储在单行内，并支持在这些文档内的查询和索引。 文档数据也越来越多的支持连接。RethinkDB在其查询语言中支持类似关系的连接，一些MongoDB驱动程序可以自动解析数据库引用。在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同。在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为外键，在文档模型中称为文档引用。该标识符在读取时通过连接或后续查询来解析。 随着时间的推移，关系数据库和文档数据库似乎变得越来越相似，这是一件好事：数据模型相互补充 ，如果一个数据库能够处理类似文档的数据，并能够对其执行关系查询，那么应用程序就可以使用最符合其需求的功能组合。关系模型和文档模型的混合是未来数据库一条很好的路线。 3. 查询语言我们将数据存入数据库的目的是为了在需要的时候将其读取出来再次使用。数据库的查询有两种明显不同的方式: 声明式语言: 指定所需数据的模式，即结果必须符合哪些条件，以及如何将数据转换（ 例如，排序，分组和集合） 但不是如何实现这一目标 数据库系统的查询优化器决定使用哪些索引和哪些连接方法，以及以何种顺序执行查询的各个部分 命令式代码: 告诉计算机以特定顺序执行某些操作 声明式查询语言通常比命令式API更加简洁和容易。但更重要的是，它还隐藏了数据库引擎的实现细节，这使得数据库系统可以在无需对查询做任何更改的情况下进行性能提升。 最后，声明式语言通常适合与并行执行，而命令式代码由于指定了特定的执行顺序，很难在多核和多台机器上并行化。声明式语言则对于并行执行更为友好，它们仅指定了结果所满足的模式，而不是如何得到结果的具体算法。 4. 图数据模型多对多关系是不同数据模型之间的重要区别特征: 如果数据大多是一对多关系(树结构数据)或者记录之间没有关系，那么文档模型最合适 关系模型能够处理简单的多对多关系 随着数据之间的连接变得更加复杂，将数据建模为图形显得更加自然。 图真正强大的地方在于，提供了单个数据存储区中保存完全不同类型对象的一致方式。图中的顶点可以表示任意类型，边可以表示任意对象之间的任意关系。 图模型与文档模型有一个共同点，它们通常不会对存储的数据强加某个模式，这可以使应用程序更加适应不断变化的需求。但是应用程序仍然会假定数据具有一定的结构，只不过是模式是显示(写时强制)还是隐式(读时处理)的问题。 图分为属性图模型和三元存储模型，并有三种常见的声明式图查询语言: Cypher/SPARQL/Datalog。 4.1 属性图属性图中，图存储看作由两个关系表组成，一个用于顶点，另一个用于边。 Cypher 是一种用于属性图的声明式查询语言，最早为 Neo4j 图数据库创建。 4.2 三元存储在三元存储中，所有信息都以非常简单的三部分形式存储(主体，谓语，客体): 主体相当于图的顶点 客体是以下两种: 原始数据类型中的值，入字符串和数字。在这种情况下，三元组的谓语和客体分别相当于主体属性中的键和值，比如(lucy, age, 32) 图中的另一个顶点，此时谓语是图中的边，主体是尾部顶点，客体是头部顶点，比如(lucy, marriedTo, alian) SPARQL 是一种采用RDF数据模型的三元存储查询语言。 4.3 DatalogDatalog 是比 Cypher/SPARQL 更古老的语言，Datalog 的数据模型类似于三元存储，它采用谓语(主体，客体)的表达式，比如 age(lucy, 33)，marriedTo(lucy, alian)。 图的模型查询语言都比较复杂，这里我们就只做非常简单的介绍，详细内容大家可以在需要时自行查阅相关文档。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2. 构建怎样的数据系统]]></title>
    <url>%2F2019%2F04%2F02%2Fdb%2Fdb_2%2F</url>
    <content type="text"><![CDATA[构建数据密集型应用的目标 1. 构建怎样的系统影响数据系统设计的因素很多，每个因素都需要具体问题具体分析。而我们着重讨论三个在大多数软件系统中都很重要的问题： 可靠性(Reliability) 可扩展性(Scalability) 可维护性(Maintainability) 相比于模棱两可的概念，我们需要清楚的知道它们意味着什么，如何系统的衡量和评估他们。 1.1 说明要想说清楚这些概念非常不容易，它们其实涵盖了非常广泛的话题。下面大多数内容都是摘录自原著的开源翻译版本，特此说明。 2. 可靠性可靠性可粗略理解为“即使出现问题，也能继续正确工作”。造成错误的原因叫做故障（fault） ，能预料并应对故障的系统特性可称为容错（faulttolerant）或韧性（resilient）。但显然系统不能容忍所有错误，所以在讨论容错时，只有谈论特定类型的错误才有意义。 注意故障（fault）不同于失效（failure） 。故障通常定义为系统的一部分状态偏离其标准，而失效则是系统作为一个整体停止向用户提供服务。故障的概率不可能降到零，因此最好设计容错机制以防因故障而导致失效。 尽管比起阻止错误（prevent error），我们通常更倾向于容忍错误。但也存在预防错误的情况，比如安全问题就属于这种情况。但我们主要讨论的是可以恢复的故障种类，包括: 硬件故障(hardware faults) 软件错误 人为错误 3. 可扩展性可扩展性（Scalability）意味着即使在负载增加的情况下也有保持性能的策略,是用来描述系统应对负载增长能力的术语。讨论可扩展性意味着考虑诸如 “如果系统以特定方式增长，有什么选项可以应对增长？” “如何增加计算资源来处理额外的负载？”等问题。在我们讨论可扩展性之前，我们需要能够衡量系统的负载和性能。 3.1 系统负载负载可以用一些称为负载参数（load parameters） 的数字来描述。参数的最佳选择取决于系统架构，它可能是每秒向Web服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西。除此之外，也许平均情况对你很重要，也许你的瓶颈是少数极端场景。你需要基于对系统的监控，找到系统中最耗费资源的地方。 3.2 描述性能量化了系统负载之后，我们要简单地看一下如何描述系统性能。 对于Hadoop这样的批处理系统，通常关心的是吞吐量（throughput） ，即每秒可以处理的记录数量，或者在特定规模数据集上运行作业的总时间 。对于在线系统，通常更重要的是服务的响应时间（response time） ，即客户端发送请求到接收响应之间的时间。 响应时间延迟（latency） 和响应时间（response time）经常用作同义词，但实际上它们并不一样。响应时间是客户所看到的，除了实际处理请求的时间（服务时间 service time）之外，还包括网络延迟和排队延迟。延迟是某个请求等待处理的持续时长，在此期间它处于休眠（latent） 状态，并等待服务。 通常使用百分位点来衡量系统的响应时间。中位数是一个好的度量标准，中位数也被称为第50百分位点，有时缩写为p50。为了弄清异常值有多糟糕，可以看看更高的百分位点，例如第95、99和99.9百分位点（缩写为p95，p99和p999） 响应时间的高百分位点（也称为尾部延迟 tail latencies） 非常重要，因为它们直接影响用户的服务体验。例如亚马逊在描述内部服务的响应时间要求时以99.9百分位点为准。这是因为请求响应最慢的客户往往也是数据最多的客户，也可以说是最有价值的客户 —— 因为他们掏钱了 另一方面，优化第99.99百分位点（一万个请求中最慢的一个） 被认为太昂贵了，减小高百分位点处的响应时间相当困难，因为它很容易受到随机事件的影响，这超出了控制范围，而且效益也很小。 排队延迟（queueing delay） 通常占了高百分位点处响应时间的很大一部分。由于服务器只能并行处理少量的事务（如受其CPU核数的限制），所以只要有少量缓慢的请求就能阻碍后续请求的处理，这种效应有时被称为头部阻塞（head-of-line blocking） 。 在多重调用的后端服务里，高百分位数变得特别重要。即使并行调用，最终用户请求仍然需要等待最慢的并行呼叫完成。如果您想将响应时间百分点添加到您的服务的监视仪表板，则需要持续有效地计算它们。有一些算法能够以最小的CPU和内存成本（如前向衰减，t-digest 或HdrHistogram）来计算百分位数的近似值。 3.3 应对负载增加应对负载增加，包括两种方式: 纵向扩展: scaling up 又称 垂直扩展（vertical scaling），即转向更强大的机器 横向扩展: scaling out 又称 水平扩展（horizontal scaling），即将负载分布到多台小机器上 可以在单台机器上运行的系统通常更简单，但高端机器可能非常贵，所以非常密集的负载通常无法避免地需要横向扩展。现实世界中的优秀架构需要将这两种方法务实地结合，因为使用几台足够强大的机器可能比使用大量的小型虚拟机更简单也更便宜。 跨多台机器部署无状态服务（stateless services） 非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。出于这个原因，常识告诉我们应该将数据库放在单个节点上（纵向扩展），直到扩展成本或可用性需求迫使其改为分布式。 ​随着分布式系统的工具和抽象越来越好，至少对于某些类型的应用而言，这种常识可能会改变。可以预见分布式数据系统将成为未来的默认设置，即使对不处理大量数据或流量的场景也如此。 大规模的系统架构通常是应用特定的—— 没有一招鲜吃遍天的通用可扩展架构。应用的问题可能是读取量、写入量、要存储的数据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。 一个良好适配应用的可扩展架构，是围绕着假设（assumption） 建立的：哪些操作是常见的？哪些操作是罕见的？这就是所谓负载参数。如果假设最终是错误的，那么为扩展所做的工程投入就白费了，最糟糕的是适得其反。 尽管这些架构是应用程序特定的，但可扩展的架构通常也是从通用的积木块搭建而成的，并以常见的模式排列。在本书中，我们将讨论这些构件和模式。 4. 可维护性软件的大部分开销并不在最初的开发阶段，而是在持续的维护阶段，包括修复漏洞、保持系统正常运行、调查失效、适配新的平台、为新的场景进行修改、偿还技术债、添加新的功能等等。 为此，我们将特别关注软件系统的三个设计原则： 可操作性（Operability）: 意味着对系统的健康状态具有良好的可见性，并拥有有效的管理手段 便于运维团队保持系统平稳运行，意味着更轻松的日常工作，进而运维团队能专注于高价值的事情 简单性（Simplicity）: 从系统中消除尽可能多的复杂度（complexity），使新工程师也能轻松理解系统 复杂度（complexity）有各种可能的症状，例如：状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的Hack、需要绕开的特例等 用于消除额外复杂度的最好工具之一是抽象（abstraction） 可演化性（evolability）: 使工程师在未来能轻松地对系统进行更改，当需求变化时为新应用场景做适配 也称为可扩展性（extensibility），可修改性（modifiability） 或可塑性（plasticity）]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1. 构建数据密集型应用]]></title>
    <url>%2F2019%2F04%2F01%2Fdb%2Fdb_1%2F</url>
    <content type="text"><![CDATA[《构建数据密集型应用》读书笔记 1. 写在开始2014 年我开始自学编程的时候，在各种培训机构的课程里 Mysql 几乎还是唯一的数据库系统。现如今每一个工程师可能都听过 NoSQL，hadoop，Elasticsearch。”大数据”已经成为了几乎所有公司看中的技能。 然后当我尝试去学习所谓的”大数据”时，却只能用不知所措去形容我所面临的处境。到处都是有关大数据的零散知识点(诸如CAP, Paxos,Mapreduce)，以及无处不在推荐的 Google 三大论文。很难弄清楚充斥在这些文章中的专业术语到底是什么含义。 显然对于相我这样的初学者，需要有一本系统的书来帮我们搭建起“大数据”学习的知识框架。而《构建数据密集型应用》正是我梦寐以求的书。 我想我也无需去吹赞这本书，只想把他推荐给需要的人。好记性不如烂笔头，这个系列的博客就是《构建数据密集型应用》的读书笔记。 2. 本书结构什么是数据密集型应用，一个应用，如果数据是其主要挑战(数据量，数据复杂度和数据变化速度) ，它就被称为数据密集型应用。本书就是围绕应用中的数据问题展开的，分为如下三个部分： 1. 第一部分讨论了设计数据密集型应用所赖的基本思想。这些事数据系统底层的基础概念，无论是在单台机器上运行的单点数据系统，还是分布在多台机器上的分布式数据系统都适用: 第一章: 介绍应用设计的目标。可靠性，可扩展性和可维护性 ，这些词汇到底意味着什么，如何实现这些目标 第二章: 将对几种不同的数据模型和查询语言进行比较。从程序员的角度看，这是数据库之间最明显的区别。不同的数据模型适用于不同的应用场景 第三章: 将深入存储引擎内部，研究数据库如何在磁盘上摆放数据。不同的存储引擎针对不同的负载进行优化，选择合适的存储引擎对系统性能有巨大影响 第四章: 将对几种不同的 数据编码进行比较。特别研究了这些格式在应用需求经常变化、模式需要随时间演变的环境中表现如何 2. 第二部分我们从讨论存储在一台机器上的数据转向讨论分布在多台机器上的数据。这对于可扩展性通常是必需的，但带来了各种独特的挑战。我们首先讨论复制（ 第5章） ，分区/分片（ 第6章） 和事务（ 第7章） 。然后我们将探索关于分布式系统问题的更多细节（ 第8章） ，以及在分布式系统中实现一致性与共识意味着什么（ 第9章） 。 3. 第三部分我们讨论那些从其他数据集衍生出一些数据集的系统。衍生数据经常出现在异构系统中：当没有单个数据库可以把所有事情都做的很好时，应用需要集成几种不同的数据库，缓存，索引等。在第10章中我们将从一种衍生数据的批处理方法开始，然后在此基础上建立在第11章中讨论的流处理。最后，在第12章中，我们将所有内容汇总，讨论在将来构建可靠，可伸缩和可维护的应用程序的方法。 3. 资源收录除了内容外，本书还引用了大量的论文，博客，这些都是扩展学习非常好的学习资料。下面是与本书相关的学习资源: 书中引用持续维护的github仓库 原著的开源翻译版本，对于英文不好的同学真是福音 耗子叔在极客时间的专栏左耳听风，《构建数据密集型应用》是这个专栏推荐的书，也推荐这个专栏。 可扩展的Web架构和分布式系统]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>数据密集型应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 分布式并发原语二]]></title>
    <url>%2F2019%2F02%2F21%2Fgo%2Fgo_sync%2Fgo_sync_21%2F</url>
    <content type="text"><![CDATA[今天，我们来学习下基于 etcd 的分布式队列、栅栏和 STM。 1. 分布式队列1.1 基础使用etcd 通过 github.com/coreos/etcd/contrib/recipes 包提供了分布式队列这种数据结构。其类型和方法的签名如下: 12345678// 创建队列func NewQueue(client *v3.Client, keyPrefix string) *Queue// 入队func (q *Queue) Enqueue(val string) error//出队func (q *Queue) Dequeue() (string, error) 需要注意的是，如果这个分布式队列当前为空，调用 Dequeue 方法的话，会被阻塞，直到有元素可以出队才返回。 1.2 使用示例我们可以启动多个下面的程序来模拟分布式的环境，进行测试: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package mainimport ( "bufio" "flag" "fmt" "log" "os" "strings" "github.com/coreos/etcd/clientv3" recipe "github.com/coreos/etcd/contrib/recipes")var ( addr = flag.String("addr", "http://127.0.0.1:2379", "etcd addresses") queueName = flag.String("name", "my-test-queue", "queue name"))func main() &#123; flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, ",") // 创建etcd的client cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() // 创建/获取队列 q := recipe.NewQueue(cli, *queueName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() &#123; action := consolescanner.Text() items := strings.Split(action, " ") switch items[0] &#123; case "push": // 加入队列 if len(items) != 2 &#123; fmt.Println("must set value to push") continue &#125; q.Enqueue(items[1]) // 入队 case "pop": // 从队列弹出 v, err := q.Dequeue() // 出队 if err != nil &#123; log.Fatal(err) &#125; fmt.Println(v) // 输出出队的元素 case "quit", "exit": //退出 return default: fmt.Println("unknown action") &#125; &#125;&#125; 1.3 优先级队列etcd 还提供了优先级队列（PriorityQueue）,用法和队列类似，只不过，在入队的时候，我们还需要提供 uint16 类型的一个整数，作为值的优先级，优先级高的元素会优先出队。 12345678type PriorityQueue struct &#123; // contains filtered or unexported fields&#125;func NewPriorityQueue(client *v3.Client, key string) *PriorityQueuefunc (q *PriorityQueue) Dequeue() (string, error)func (q *PriorityQueue) Enqueue(val string, pr uint16) error 2. 分布式栅栏循环栅栏 CyclicBarrie 和 WaitGroup 本质上是同一类并发原语，都是等待同一组 goroutine 同时执行或者等待同一组 goroutine 都完成。分布式环境中，我们也会遇到这样的场景：一组节点协同工作，共同等待一个信号，在信号未出现前，这些节点会被阻塞住，而一旦信号出现，这些阻塞的节点就会同时开始继续执行下一步的任务。 etcd 也提供了相应的分布式并发原语: Barrier：分布式栅栏。如果持有 Barrier 的节点释放了它，所有等待这个 Barrier 的节点就不会被阻塞，而是会继续执行。 DoubleBarrier：计数型栅栏。在初始化计数型栅栏的时候，我们就必须提供参与节点的数量，当这些数量的节点都 Enter 或者 Leave 的时候，这个栅栏就会放开。所以，我们把它称为计数型栅栏。 2.1 Barrier12345type Barrier func NewBarrier(client *v3.Client, key string) *Barrier func (b *Barrier) Hold() error func (b *Barrier) Release() error func (b *Barrier) Wait() error Hold 方法是创建一个 Barrier。如果 Barrier 已经创建好了，有节点调用它的 Wait 方法，就会被阻塞。 Release 方法是释放这个 Barrier，也就是打开栅栏。如果使用了这个方法，所有被阻塞的节点都会被放行，继续执行。 Wait 方法会阻塞当前的调用者，直到这个 Barrier 被 release。如果这个栅栏不存在，调用者不会被阻塞，而是会继续执行。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package mainimport ( "bufio" "flag" "fmt" "log" "os" "strings" "github.com/coreos/etcd/clientv3" recipe "github.com/coreos/etcd/contrib/recipes")var ( addr = flag.String("addr", "http://127.0.0.1:2379", "etcd addresses") barrierName = flag.String("name", "my-test-queue", "barrier name"))func main() &#123; flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, ",") // 创建etcd的client cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() // 创建/获取栅栏 b := recipe.NewBarrier(cli, *barrierName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() &#123; action := consolescanner.Text() items := strings.Split(action, " ") switch items[0] &#123; case "hold": // 持有这个barrier b.Hold() fmt.Println("hold") case "release": // 释放这个barrier b.Release() fmt.Println("released") case "wait": // 等待barrier被释放 b.Wait() fmt.Println("after wait") case "quit", "exit": //退出 return default: fmt.Println("unknown action") &#125; &#125;&#125; 2.2 DoubleBarrierDoubleBarrier 在初始化时提供了一个计数的 count 1234type DoubleBarrier func NewDoubleBarrier(s *concurrency.Session, key string, count int) *DoubleBarrier func (b *DoubleBarrier) Enter() error func (b *DoubleBarrier) Leave() error Enter: 当调用者调用 Enter 时，会被阻塞住，直到一共有 count（初始化这个栅栏的时候设定的值）个节点调用了 Enter，这 count 个被阻塞的节点才能继续执行。所以，你可以利用它编排一组节点，让这些节点在同一个时刻开始执行任务。 Leave: 节点调用 Leave 方法的时候，会被阻塞，直到有 count 个节点，都调用了 Leave 方法，这些节点才能继续执行。 3. STM3.1 etcd 事务etcd 提供了在一个事务中对多个 key 的更新功能，这一组 key 的操作要么全部成功，要么全部失败。etcd 的事务实现方式是基于 CAS 方式实现的，融合了 Get、Put 和 Delete 操作。 etcd 的事务操作如下，分为条件块、成功块和失败块，条件块用来检测事务是否成功，如果成功，就执行 Then(…)，如果失败，就执行 Else(…)： 1Txn().If(cond1, cond2, ...).Then(op1, op2, ...,).Else(op1’, op2’, …) 下面是利用 etcd 实现转账的例子: 12345678910111213141516171819202122232425262728293031func doTxnXfer(etcd *v3.Client, from, to string, amount uint) (bool, error) &#123; // 一个查询事务 getresp, err := etcd.Txn(ctx.TODO()).Then(OpGet(from), OpGet(to)).Commit() if err != nil &#123; return false, err &#125; // 获取转账账户的值 fromKV := getresp.Responses[0].GetRangeResponse().Kvs[0] toKV := getresp.Responses[1].GetRangeResponse().Kvs[1] fromV, toV := toUInt64(fromKV.Value), toUint64(toKV.Value) if fromV &lt; amount &#123; return false, fmt.Errorf(“insufficient value”) &#125; // 转账事务 // 条件块 txn := etcd.Txn(ctx.TODO()).If( v3.Compare(v3.ModRevision(from), “=”, fromKV.ModRevision), v3.Compare(v3.ModRevision(to), “=”, toKV.ModRevision)) // 成功块 txn = txn.Then( OpPut(from, fromUint64(fromV - amount)), OpPut(to, fromUint64(toV + amount)) //提交事务 putresp, err := txn.Commit() // 检查事务的执行结果 if err != nil &#123; return false, err &#125; return putresp.Succeeded, nil&#125; 虽然可以利用 etcd 实现事务操作，但是逻辑还是比较复杂的。所以 etcd 又在这些基础 API 上进行了封装，新增了一种叫做 STM 的操作，提供了更加便利的方法。要使用 STM，你需要先编写一个 apply 函数，这个函数的执行是在一个事务之中的：apply func(STM) error。这个方法包含一个 STM 类型的参数，它提供了对 key 值的读写操作。 STM 提供了 4 个方法，分别是 Get、Put、Receive 和 Delete，代码如下： 123456type STM interface &#123; Get(key ...string) string Put(key, val string, opts ...v3.OpOption) Rev(key string) int64 Del(key string)&#125; 我们通过下面这个例子来看看如何使用 STM 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package mainimport ( "context" "flag" "fmt" "log" "math/rand" "strings" "sync" "github.com/coreos/etcd/clientv3" "github.com/coreos/etcd/clientv3/concurrency")var ( addr = flag.String("addr", "http://127.0.0.1:2379", "etcd addresses"))func main() &#123; flag.Parse() // 解析etcd地址 endpoints := strings.Split(*addr, ",") cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() // 设置5个账户，每个账号都有100元，总共500元 totalAccounts := 5 for i := 0; i &lt; totalAccounts; i++ &#123; k := fmt.Sprintf("accts/%d", i) if _, err = cli.Put(context.TODO(), k, "100"); err != nil &#123; log.Fatal(err) &#125; &#125; // STM的应用函数，主要的事务逻辑 exchange := func(stm concurrency.STM) error &#123; // 随机得到两个转账账号 from, to := rand.Intn(totalAccounts), rand.Intn(totalAccounts) if from == to &#123; // 自己不和自己转账 return nil &#125; // 读取账号的值 fromK, toK := fmt.Sprintf("accts/%d", from), fmt.Sprintf("accts/%d", to) fromV, toV := stm.Get(fromK), stm.Get(toK) fromInt, toInt := 0, 0 fmt.Sscanf(fromV, "%d", &amp;fromInt) fmt.Sscanf(toV, "%d", &amp;toInt) // 把源账号一半的钱转账给目标账号 xfer := fromInt / 2 fromInt, toInt = fromInt-xfer, toInt+xfer // 把转账后的值写回 stm.Put(fromK, fmt.Sprintf("%d", fromInt)) stm.Put(toK, fmt.Sprintf("%d", toInt)) return nil &#125; // 启动10个goroutine进行转账操作 var wg sync.WaitGroup wg.Add(10) for i := 0; i &lt; 10; i++ &#123; go func() &#123; defer wg.Done() for j := 0; j &lt; 100; j++ &#123; if _, serr := concurrency.NewSTM(cli, exchange); serr != nil &#123; log.Fatal(serr) &#125; &#125; &#125;() &#125; wg.Wait() // 检查账号最后的数目 sum := 0 accts, err := cli.Get(context.TODO(), "accts/", clientv3.WithPrefix()) // 得到所有账号 if err != nil &#123; log.Fatal(err) &#125; for _, kv := range accts.Kvs &#123; // 遍历账号的值 v := 0 fmt.Sscanf(string(kv.Value), "%d", &amp;v) sum += v log.Printf("account %s: %d", kv.Key, v) &#125; log.Println("account sum is", sum) // 总数&#125; 使用 etcd STM 的时候，我们只需要定义一个 apply 方法(上面的 exchange函数)，然后通过 concurrency.NewSTM(cli, exchange)，就可以完成转账事务的执行了。总结一下，当你利用 etcd 做存储时，是可以利用 STM 实现事务操作的，一个事务可以包含多个账号的数据更改操作，事务能够保证这些更改要么全成功，要么全失败。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20 分布式并发原语一]]></title>
    <url>%2F2019%2F02%2F20%2Fgo%2Fgo_sync%2Fgo_sync_20%2F</url>
    <content type="text"><![CDATA[Leader 选举、互斥锁、读写锁 1. 分布式并发原语概述在前面的课程里，我们学习的并发原语都是在进程内使用的，即一个运行程序为了控制共享资源、实现任务编排和进行消息传递而提供的控制类型。布式的并发原语实现更加复杂，因为在分布式环境中，网络不可靠、时钟不一致、以及不可预测的程序暂停，使得节点之间的通信相对于内存具有非常的不确定性。不过还好有相应的软件系统去做这些事情。这些软件系统会专门去处理这些节点之间的协调和异常情况，并且保证数据的一致性。我们要做的就是在它们的基础上实现我们的业务。etcd 就提供了非常好的分布式并发原语，比如分布式互斥锁、分布式读写锁、Leader 选举，等等。所以，今天，我就以 etcd 为基础，给你介绍几种分布式并发原语。 2. etcd 单节点集群安装etcd 集群的安装配置参考其官方文档。本地独立集群的安装如下: 123yum install etcdetcd -listen-client-urls=http://192.168.108.55:2379 --advertise-client-urls=http://192.168.108.55:2379 2.1 etcd go 模块安装123# 1. 安装 gRPCgo get -u google.golang.org/grpcgo get github.com/grpc-ecosystem/go-grpc-middleware 3. Leader 选举Leader 选举常常用在主从架构的系统中。主从架构中的服务节点分为主（Leader、Master）和从（Follower、Slave）两种角色，实际节点包括 1 主 n 从，一共是 n+1 个节点。主节点常常执行写操作，从节点常常执行读操作，如果读写都在主节点，从节点只是提供一个备份功能的话，那么，主从架构就会退化成主备模式架构。 主从架构中最重要的是如何确定节点的角色，在同一时刻，系统中不能有两个主节点，否则，如果两个节点都是主，都执行写操作的话，就有可能出现数据不一致的情况，所以，我们需要一个选主机制，选择一个节点作为主节点，这个过程就是 Leader 选举。当主节点宕机或者是不可用时，就需要新一轮的选举，从其它的从节点中选择出一个节点，让它作为新主节点，宕机的原主节点恢复后，可以变为从节点，或者被摘掉。 接下来，我们将介绍业务开发中跟 Leader 选举相关的选举、查询、Leader 变动监控等功能。 3.1 选举如果业务集群还没有主节点，或者主节点宕机了，就需要发起新一轮的选主操作，主要会用到 Campaign 和 Proclaim。如果你需要主节点放弃主的角色，让其它从节点有机会成为主节点，就可以调用 Resign 方法。 Campaign: 作用：把一个节点选举为主节点，并且会设置一个值 签名: func (e *Election) Campaign(ctx context.Context, val string) error 说明: 这是一个阻塞方法，在调用它的时候会被阻塞，直到满足下面的三个条件之一，才会取消阻塞 成功当选为主； 此方法返回错误； ctx 被取消 Proclaim: 作用: 重新设置 Leader 的值，但是不会重新选主 返回: 新值设置成功或者失败的信息 签名: func (e *Election) Proclaim(ctx context.Context, val string) error Resign: 作用: 开始新一次选举 返回: 新的选举成功或者失败的信息 签名: func (e *Election) Resign(ctx context.Context) (err error) 3.2 查询程序在启动的过程中，或者在运行的时候，还有可能需要查询当前的主节点是哪一个节点？主节点的值是什么？此外查询主节点以便把读写请求发往相应的主从节点上。etcd 提供了查询当前主几点的 Leader 的方法 Leader: 作用：查询当前的主节点 返回: 如果当前还没有 Leader，就返回一个错误 签名: func (e *Election) Leader(ctx context.Context) (*v3.GetResponse, error) Rev: 作用: 查询版本号信息 说明: 每次主节点的变动都会生成一个新的版本号 签名: func (e *Election) Rev() int64 3.3 监控有了选举和查询方法，我们还需要一个监控方法。毕竟，如果主节点变化了，我们需要得到最新的主节点信息。我们可以通过 Observe 来监控主的变化： Observe 作用: 监控主节点的变化 签名: func (e *Election) Observe(ctx context.Context) &lt;-chan v3.GetResponse 返回: 一个 chan，显示主节点的变动信息，它不会返回主节点的全部历史变动信息，而是只返回最近的一条变动信息以及之后的变动信息。 3.4 使用示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114package mainimport ( "bufio" "context" "flag" "fmt" "log" "os" "strings" "go.etcd.io/etcd/client/v3/concurrency" "go.etcd.io/etcd/clientv3")var ( nodeID = flag.Int("id", 0, "node ID") addr = flag.String("addr", "http://192.168.108.55:2379", "etcd address") electName = flag.String("name", "my-test-elect", "election name") count int)func main() &#123; endpoints := strings.Split(*addr, ",") cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() session, err := concurrency.NewSession(cli) defer session.Close() el := concurrency.NewElection(session, *electName) consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() &#123; action := consolescanner.Text() switch action &#123; case "elect": go elect(el, *electName) case "proclaim": proclaim(el, *electName) case "resign": resign(el, *electName) case "watch": go watch(el, *electName) case "query": query(el, *electName) case "rev": rev(el, *electName) default: fmt.Println("unkonw error") &#125; &#125;&#125;// 选主func elect(e1 *concurrency.Election, electName string) &#123; log.Println("acampaigning for ID:", *nodeID) // 调用Campaign方法选主,主的值为value-&lt;主节点ID&gt;-&lt;count&gt; if err := e1.Campaign(context.Background(), fmt.Sprintf("value-%d-%d", *nodeID, count)); err != nil &#123; log.Println(err) &#125; log.Println("campaigned for ID:", *nodeID) count++&#125;// 为主设置新值func proclaim(e1 *concurrency.Election, electName string) &#123; log.Println("proclaiming for ID:", *nodeID) // 调用Proclaim方法设置新值,新值为value-&lt;主节点ID&gt;-&lt;count&gt; if err := e1.Proclaim(context.Background(), fmt.Sprintf("value-%d-%d", *nodeID, count)); err != nil &#123; log.Println(err) &#125; log.Println("proclaimed for ID:", *nodeID) count++&#125;// 重新选主，有可能另外一个节点被选为了主func resign(e1 *concurrency.Election, electName string) &#123; log.Println("resigning for ID:", *nodeID) // 调用Resign重新选主 if err := e1.Resign(context.TODO()); err != nil &#123; log.Println(err) &#125; log.Println("resigned for ID:", *nodeID)&#125;// 查询主的信息func query(e1 *concurrency.Election, electName string) &#123; // 调用Leader返回主的信息，包括key和value等信息 resp, err := e1.Leader(context.Background()) if err != nil &#123; log.Printf("failed to get the current leader: %v", err) &#125; log.Println("current leader:", string(resp.Kvs[0].Key), string(resp.Kvs[0].Value))&#125;// 可以直接查询主的rev信息func rev(e1 *concurrency.Election, electName string) &#123; rev := e1.Rev() log.Println("current rev:", rev)&#125;// 监控主节点的变化func watch(e1 *concurrency.Election, electName string) &#123; ch := e1.Observe(context.TODO()) log.Println("start to watch for ID:", *nodeID) for i := 0; i &lt; 10; i++ &#123; resp := &lt;-ch log.Println("leader changed to", string(resp.Kvs[0].Key), string(resp.Kvs[0].Value)) &#125;&#125; 4. 互斥锁前面说的互斥锁都是用来保护同一进程内的共享资源的，今天我们要重点学习下分布在不同机器中的不同进程内的 goroutine，如何利用分布式互斥锁来保护共享资源。 互斥锁的应用场景和主从架构的应用场景不太一样。使用互斥锁的不同节点是没有主从这样的角色的，所有的节点都是一样的，只不过在同一时刻，只允许其中的一个节点持有锁。 4.1 Lockeretcd 提供了一个简单的 Locker 原语，它类似于 Go 标准库中的 sync.Locker 接口，也提供了 Lock/UnLock 的机制： 1func NewLocker(s *Session, pfx string) sync.Locker 下面的代码是一个使用 Locker 并发原语的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package mainimport ( "flag" "log" "math/rand" "strings" "time" "github.com/coreos/etcd/clientv3" "github.com/coreos/etcd/clientv3/concurrency")var ( addr = flag.String("addr", "http://127.0.0.1:2379", "etcd addresses") lockName = flag.String("name", "my-test-lock", "lock name"))func main() &#123; flag.Parse() rand.Seed(time.Now().UnixNano()) // etcd地址 endpoints := strings.Split(*addr, ",") // 生成一个etcd client cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() useLock(cli) // 测试锁&#125;func useLock(cli *clientv3.Client) &#123; // 为锁生成session s1, err := concurrency.NewSession(cli) if err != nil &#123; log.Fatal(err) &#125; defer s1.Close() //得到一个分布式锁 locker := concurrency.NewLocker(s1, *lockName) // 请求锁 log.Println("acquiring lock") locker.Lock() log.Println("acquired lock") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(30)) * time.Second) locker.Unlock() // 释放锁 log.Println("released lock")&#125; 4.2 MutexLocker 是基于 Mutex 实现的，只不过，Mutex 提供了查询 Mutex 的 key 的信息的功能 12345678910111213141516171819202122232425262728func useMutex(cli *clientv3.Client) &#123; // 为锁生成session s1, err := concurrency.NewSession(cli) if err != nil &#123; log.Fatal(err) &#125; defer s1.Close() m1 := concurrency.NewMutex(s1, *lockName) //在请求锁之前查询key log.Printf("before acquiring. key: %s", m1.Key()) // 请求锁 log.Println("acquiring lock") if err := m1.Lock(context.TODO()); err != nil &#123; log.Fatal(err) &#125; log.Printf("acquired lock. key: %s", m1.Key()) //等待一段时间 time.Sleep(time.Duration(rand.Intn(30)) * time.Second) // 释放锁 if err := m1.Unlock(context.TODO()); err != nil &#123; log.Fatal(err) &#125; log.Println("released lock")&#125; 可以看到，Mutex 并没有实现 sync.Locker 接口，它的 Lock/Unlock 方法需要提供一个 context.Context 实例做参数，这也就意味着，在请求锁的时候，你可以设置超时时间，或者主动取消请求。 5. 读写锁etcd 也提供了分布式的读写锁。不过，互斥锁 Mutex 是在 github.com/coreos/etcd/clientv3/concurrency 包中提供的，读写锁 RWMutex 却是在 github.com/coreos/etcd/contrib/recipes 包中提供的。 etcd 提供的分布式读写锁的功能和标准库的读写锁的功能是一样的。只不过，etcd 提供的读写锁，可以在分布式环境中的不同的节点使用。它提供的方法也和标准库中的读写锁的方法一致，分别提供了 RLock/RUnlock、Lock/Unlock 方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697package mainimport ( "bufio" "flag" "fmt" "log" "math/rand" "os" "strings" "time" "github.com/coreos/etcd/clientv3" "github.com/coreos/etcd/clientv3/concurrency" recipe "github.com/coreos/etcd/contrib/recipes")var ( addr = flag.String("addr", "http://127.0.0.1:2379", "etcd addresses") lockName = flag.String("name", "my-test-lock", "lock name") action = flag.String("rw", "w", "r means acquiring read lock, w means acquiring write lock"))func main() &#123; flag.Parse() rand.Seed(time.Now().UnixNano()) // 解析etcd地址 endpoints := strings.Split(*addr, ",") // 创建etcd的client cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;) if err != nil &#123; log.Fatal(err) &#125; defer cli.Close() // 创建session s1, err := concurrency.NewSession(cli) if err != nil &#123; log.Fatal(err) &#125; defer s1.Close() m1 := recipe.NewRWMutex(s1, *lockName) // 从命令行读取命令 consolescanner := bufio.NewScanner(os.Stdin) for consolescanner.Scan() &#123; action := consolescanner.Text() switch action &#123; case "w": // 请求写锁 testWriteLocker(m1) case "r": // 请求读锁 testReadLocker(m1) default: fmt.Println("unknown action") &#125; &#125;&#125;func testWriteLocker(m1 *recipe.RWMutex) &#123; // 请求写锁 log.Println("acquiring write lock") if err := m1.Lock(); err != nil &#123; log.Fatal(err) &#125; log.Println("acquired write lock") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(10)) * time.Second) // 释放写锁 if err := m1.Unlock(); err != nil &#123; log.Fatal(err) &#125; log.Println("released write lock")&#125;func testReadLocker(m1 *recipe.RWMutex) &#123; // 请求读锁 log.Println("acquiring read lock") if err := m1.RLock(); err != nil &#123; log.Fatal(err) &#125; log.Println("acquired read lock") // 等待一段时间 time.Sleep(time.Duration(rand.Intn(10)) * time.Second) // 释放写锁 if err := m1.RUnlock(); err != nil &#123; log.Fatal(err) &#125; log.Println("released read lock")&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19 分组操作]]></title>
    <url>%2F2019%2F02%2F19%2Fgo%2Fgo_sync%2Fgo_sync_19%2F</url>
    <content type="text"><![CDATA[分组操作 1. 分组操作概述共享资源保护、任务编排和消息传递是 Go 并发编程中常见的场景，而分组执行一批相同的或类似的任务则是任务编排中一类情形，本节我们来介绍一下分组编排的一些常见场景和并发原语，包括: ErrGroup gollback Hunch schedgroup 2. ErrGroupErrGroup: 包位置: golang.org/x/sync/errgroup 适用场景: 将一个通用的父任务拆成几个小任务并发执行的场景 底层实现: 基于 WaitGroup 提供功能: 和 Context 集成 error 向上传播，可以把子任务的错误传递给 Wait 的调用者 2.1 基本用法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package errgroupimport ( "context" "sync")// A Group is a collection of goroutines working on subtasks that are part of// the same overall task.//// A zero Group is valid and does not cancel on error.type Group struct &#123; cancel func() wg sync.WaitGroup errOnce sync.Once err error&#125;// WithContext returns a new Group and an associated Context derived from ctx.//// The derived Context is canceled the first time a function passed to Go// returns a non-nil error or the first time Wait returns, whichever occurs// first.func WithContext(ctx context.Context) (*Group, context.Context) &#123; ctx, cancel := context.WithCancel(ctx) return &amp;Group&#123;cancel: cancel&#125;, ctx&#125;// Wait blocks until all function calls from the Go method have returned, then// returns the first non-nil error (if any) from them.func (g *Group) Wait() error &#123; g.wg.Wait() if g.cancel != nil &#123; g.cancel() &#125; return g.err&#125;// Go calls the given function in a new goroutine.//// The first call to return a non-nil error cancels the group; its error will be// returned by Wait.func (g *Group) Go(f func() error) &#123; g.wg.Add(1) go func() &#123; defer g.wg.Done() if err := f(); err != nil &#123; g.errOnce.Do(func() &#123; g.err = err if g.cancel != nil &#123; g.cancel() &#125; &#125;) &#125; &#125;()&#125; ErrGroup 有三个方法分别是 WithContext、Go 和 Wait。 WithContext: 作用: 创建一个 Group 对象 签名: func WithContext(ctx context.Context) (*Group, context.Context) 返回: Group 实例和使用 context.WithCancel(ctx) 生成的新 Context，一旦有一个子任务返回错误，或者 Wait 调用返回，新的 Context 就会被 cancel 注意: Group 的零值也是合法的，只不过，你就没有一个可以监控是否 cancel 的 Context 了 如果传递给 WithContext 的 ctx 参数，是一个可以 cancel 的 Context 的话，那么，它被 cancel 的时候，并不会终止正在执行的子任务 Go 方法: 作用: 执行子任务 签名: func (g *Group) Go(f func() error) 执行: 子任务函数 f 是类型为 func() error 的函数，如果任务执行成功，就返回 nil，否则就返回 error，并且会 cancel 那个新的 Context 注意: 可能有多个子任务执行失败返回 error，Wait 方法只会返回第一个错误，所以，如果想返回所有的错误，需要特别的处理 处理方式是使用全局的 result slice 保存子任务的执行结果 Wait: 作用: 所有的子任务都完成后，它才会返回，否则只会阻塞等待 签名: func (g *Group) Wait() error 返回: 如果有多个子任务返回错误，它只会返回第一个出现的错误，如果所有的子任务都执行成功，就返回 nil 2.2 使用示例使用 20 goroutine 计算传入目录下所有文件的 md5 值: 12 2.3 bilibili ErrGroup 扩展如果我们无限制地直接调用 ErrGroup 的 Go 方法，就可能会创建出非常多的 goroutine，太多的 goroutine 会带来调度和 GC 的压力，就像go#34457指出的那样，当前 Go 运行时创建的 g 对象只会增长和重用，不会回收，所以在高并发的情况下，也要尽可能减少 goroutine 的使用。 常用的一个手段就是使用 worker pool(goroutine pool)，或者是类似containerd/stargz-snapshotter的方案，使用前面我们讲的信号量，信号量的资源的数量就是可以并行的 goroutine 的数量。 bilibili 实现了一个扩展的 ErrGroup bilibili/errgroup，可以使用一个固定数量的 goroutine 处理子任务。如果不设置 goroutine 的数量，那么每个子任务都会比较“放肆地”创建一个 goroutine 并发执行。 除了可以控制并发 goroutine 的数量，它还提供了 2 个功能： cancel，失败的子任务可以 cancel 所有正在执行任务； recover，而且会把 panic 的堆栈信息放到 error 中，避免子任务 panic 导致的程序崩溃。 是，有一点不太好的地方就是，一旦你设置了并发数，超过并发数的子任务需要等到调用者调用 Wait 之后才会执行，而不是只要 goroutine 空闲下来，就去执行。如果不注意这一点的话，可能会出现子任务不能及时处理的情况，这是这个库可以优化的一点。 另外，这个库其实是有一个并发问题的。在高并发的情况下，如果任务数大于设定的 goroutine 的数量，并且这些任务被集中加入到 Group 中，这个库的处理方式是把子任务加入到一个数组中，但是，这个数组不是线程安全的，有并发问题，问题就在于，下面图片中的标记为 96 行的那一行，这一行对 slice 的 append 操作不是线程安全的： 我们可以写一个简单的测试程序，运行这个程序的话，你就会发现死锁问题 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( "context" "fmt" "sync/atomic" "time" "github.com/bilibili/kratos/pkg/sync/errgroup")func main() &#123; var g errgroup.Group g.GOMAXPROCS(1) // 只使用一个goroutine处理子任务 var count int64 g.Go(func(ctx context.Context) error &#123; time.Sleep(time.Second) //睡眠5秒，把这个goroutine占住 return nil &#125;) total := 10000 for i := 0; i &lt; total; i++ &#123; // 并发一万个goroutine执行子任务，理论上这些子任务都会加入到Group的待处理列表中 go func() &#123; g.Go(func(ctx context.Context) error &#123; atomic.AddInt64(&amp;count, 1) return nil &#125;) &#125;() &#125; // 等待所有的子任务完成。理论上10001个子任务都会被完成 if err := g.Wait(); err != nil &#123; panic(err) &#125; got := atomic.LoadInt64(&amp;count) if got != int64(total) &#123; panic(fmt.Sprintf("expect %d but got %d", total, got)) &#125;&#125; 2.4 neilotoole/errgroup 扩展neilotoole/errgroup 是今年年中新出现的一个 ErrGroup 扩展库，它可以直接替换官方的 ErrGroup，方法都一样，原有功能也一样，只不过增加了可以控制并发 goroutine 的功能。它的方法集如下： 12345type Group func WithContext(ctx context.Context) (*Group, context.Context) func WithContextN(ctx context.Context, numG, qSize int) (*Group, context.Context) func (g *Group) Go(f func() error) func (g *Group) Wait() error 新增加的方法 WithContextN，可以设置并发的 goroutine 数，以及等待处理的子任务队列的大小。当队列满的时候，如果调用 Go 方法，就会被阻塞，直到子任务可以放入到队列中才返回。如果你传给这两个参数的值不是正整数，它就会使用 runtime.NumCPU 代替你传入的参数。 2.5 facebookgo/errgroupfacebookgo/errgroup Facebook 提供的这个 ErrGroup，其实并不是对 Go 扩展库 ErrGroup 的扩展，而是对标准库 WaitGroup 的扩展。 标准库的 WaitGroup 只提供了 Add、Done、Wait 方法，而且 Wait 方法也没有返回子 goroutine 的 error。而 Facebook 提供的 ErrGroup 提供的 Wait 方法可以返回 error，而且可以包含多个 error。子任务在调用 Done 之前，可以把自己的 error 信息设置给 ErrGroup。接着，Wait 在返回的时候，就会把这些 error 信息返回给调用者。 12345type Group func (g *Group) Add(delta int) func (g *Group) Done() func (g *Group) Error(e error) // 设置 error 给 ErrorGroup，Wait 返回时会返回这些 error func (g *Group) Wait() error 3. 其他分组执行的并发原语下面这些并发原语都是控制一组子 goroutine 执行的面向特定场景的并发原语，当你遇见这些特定场景时，就可以参考这些库。 3.1 go-pkgz/syncsgo-pkgz/syncs 提供了两个 Group 并发原语，分别是 SizedGroup 和 ErrSizedGroup: SizedGroupSizedGroup 内部是使用信号量和 WaitGroup 实现的，它通过信号量控制并发的 goroutine 数量，或者是不控制 goroutine 数量，只控制子任务并发执行时候的数量（通过）。 默认情况下，SizedGroup 控制的是子任务的并发数量，而不是 goroutine 的数量。在这种方式下，每次调用 Go 方法都不会被阻塞，而是新建一个 goroutine 去执行。如果想控制 goroutine 的数量，你可以使用 syncs.Preemptive 设置这个并发原语的可选项。如果设置了这个可选项，但在调用 Go 方法的时候没有可用的 goroutine，那么调用者就会等待，直到有 goroutine 可以处理这个子任务才返回，这个控制在内部是使用信号量实现的。 12345678910111213141516171819202122232425262728293031package mainimport ( "context" "fmt" "sync/atomic" "time" "github.com/go-pkgz/syncs")func main() &#123; // 设置goroutine数是10 swg := syncs.NewSizedGroup(10) // swg := syncs.NewSizedGroup(10, syncs.Preemptive) var c uint32 // 执行1000个子任务，只会有10个goroutine去执行 for i := 0; i &lt; 1000; i++ &#123; swg.Go(func(ctx context.Context) &#123; time.Sleep(5 * time.Millisecond) atomic.AddUint32(&amp;c, 1) &#125;) &#125; // 等待任务完成 swg.Wait() // 输出结果 fmt.Println(c)&#125; ErrSizedGroupErrSizedGroup 为 SizedGroup 提供了 error 处理的功能，它的功能和 Go 官方扩展库的功能一样，就是等待子任务完成并返回第一个出现的 error。不过，它还提供了额外的功能 可以控制并发的 goroutine 数量，这和 SizedGroup 的功能一样 如果设置了 termOnError，子任务出现第一个错误的时候会 cancel Context，而且后续的 Go 调用会直接返回，Wait 调用者会得到这个错误，这相当于是遇到错误快速返回。如果没有设置 termOnError，Wait 会返回所有的子任务的错误 不过，ErrSizedGroup 和 SizedGroup 设计得不太一致的地方是，SizedGroup 可以把 Context 传递给子任务，这样可以通过 cancel 让子任务中断执行，但是 ErrSizedGroup 却没有实现 3.2 gollbackgollback也是用来处理一组子任务的执行的，不过它解决了 ErrGroup 收集子任务返回结果的痛点。它的方法会把结果和 error 信息都返回。 gollback 提供了如下三个方法: All, Race, Retry AllAll: 签名: func All(ctx context.Context, fns ...AsyncFunc) ([]interface{}, []error) 执行: 它会等待所有的异步函数（AsyncFunc）都执行完才返回，而且返回结果的顺序和传入的函数的顺序保持一致。 返回: 第一个返回参数是子任务的执行结果，第二个参数是子任务执行时的错误信息 异步函数: type AsyncFunc func(ctx context.Context) (interface{}, error) ctx 会被传递给子任务。如果你 cancel 这个 ctx，可以取消子任务 1234567891011121314151617181920212223242526272829package mainimport ( "context" "errors" "fmt" "github.com/vardius/gollback" "time")func main() &#123; rs, errs := gollback.All( // 调用All方法 context.Background(), func(ctx context.Context) (interface&#123;&#125;, error) &#123; time.Sleep(3 * time.Second) return 1, nil // 第一个任务没有错误，返回1 &#125;, func(ctx context.Context) (interface&#123;&#125;, error) &#123; return nil, errors.New("failed") // 第二个任务返回一个错误 &#125;, func(ctx context.Context) (interface&#123;&#125;, error) &#123; return 3, nil // 第三个任务没有错误，返回3 &#125;, ) fmt.Println(rs) // 输出子任务的结果 fmt.Println(errs) // 输出子任务的错误信息&#125; RaceRace: 签名: func Race(ctx context.Context, fns ...AsyncFunc) (interface{}, error) 返回: 跟 All 方法类似，只不过，在使用 Race 方法的时候，只要一个异步函数执行没有错误，就立马返回，而不会返回所有的子任务信息。如果所有的子任务都没有成功，就会返回最后一个 error 信息 注意: 如果有一个正常的子任务的结果返回，Race 会把传入到其它子任务的 Context cancel 掉，这样子任务就可以中断自己的执行 RetryRetry: 签名: func Retry(ctx context.Context, retires int, fn AsyncFunc) (interface{}, error) 作用: Retry 不是执行一组子任务，而是执行一个子任务 返回: 如果子任务执行失败，它会尝试一定的次数， 如果一直不成功 ，就会返回失败错误 如果执行成功，它会立即返回 如果 retires 等于 0，它会永远尝试，直到成功 1234567891011121314151617181920212223package mainimport ( "context" "errors" "fmt" "github.com/vardius/gollback" "time")func main() &#123; ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() // 尝试5次，或者超时返回 res, err := gollback.Retry(ctx, 5, func(ctx context.Context) (interface&#123;&#125;, error) &#123; return nil, errors.New("failed") &#125;) fmt.Println(res) // 输出结果 fmt.Println(err) // 输出错误信息&#125; 3.3 HunchHunch 提供的功能和 gollback 类似，不过它提供的方法更多包括: All Take Last Retry Waterfall 它定义了执行子任务的函数，这和 gollback 的 AyncFunc 是一样的： 1type Executable func(context.Context) (interface&#123;&#125;, error) AllAll: 签名: func All(parentCtx context.Context, execs ...Executable) ([]interface{}, error) 作用: 传入一组可执行的函数（子任务），返回子任务的执行结果 区别: 和 gollback 的 All 方法不一样的是，一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil。 TakeTake: 签名: func Take(parentCtx context.Context, num int, execs ...Executable) ([]interface{}, error) 作用: 可以指定 num 参数，只要有 num 个子任务正常执行完没有错误，这个方法就会返回这几个子任务的结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil。 LastLast: 签名: func Last(parentCtx context.Context, num int, execs ...Executable) ([]interface{}, error) 作用: 只返回最后 num 个正常执行的、没有错误的子任务的结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil RetryRetry: 签名: func Retry(parentCtx context.Context, retries int, fn Executable) (interface{}, error) 作用: 它的功能和 gollback 的 Retry 方法的功能一样，如果子任务执行出错，就会不断尝试，直到成功或者是达到重试上限。 如果达到重试上限，就会返回错误 如果 retries 等于 0，它会不断尝试 WaterfallWaterfall: 签名: func Waterfall(parentCtx context.Context, execs ...ExecutableInSequence) (interface{}, error) 作用: 它其实是一个 pipeline 的处理方式，所有的子任务都是串行执行的， 前一个子任务的执行结果会被当作参数传给下一个子任务，直到所有的任务都完成，返回最后的执行结果 一旦一个子任务出现错误，它就会返回错误信息，执行结果（第一个返回参数）为 nil 总结gollback 和 Hunch 是属于同一类的并发原语，对一组子任务的执行结果，可以选择一个结果或者多个结果 3.4 schedgroupschedgroup 是一个和时间相关的处理一组 goroutine 的并发原语，是 Matt Layher 开发的 worker pool，可以指定任务在某个时间或者某个时间之后执行。他在 GopherCon Europe 2020 大会上专门介绍了这个并发原语：schedgroup: a timer-based goroutine concurrency primitive schedgroup 包含的方法如下： 123456type Group func New(ctx context.Context) *Group func (g *Group) Delay(delay time.Duration, fn func()) func (g *Group) Schedule(when time.Time, fn func()) func (g *Group) Wait() error Delay 和 Schedule: 功能其实是一样的，都是用来指定在某个时间或者之后执行一个函数。 Wait: 会阻塞调用者，直到之前安排的所有子任务都执行完才返回。如果 Context 被取消，那么，Wait 方法会返回这个 cancel error 如果调用了 Wait 方法，你就不能再调用它的 Delay 和 Schedule 方法，否则会 panic。 Wait 方法只能调用一次，如果多次调用的话，就会 panic 你可能认为，简单地使用 timer 就可以实现这个功能。其实，如果只有几个子任务，使用 timer 不是问题，但一旦有大量的子任务，而且还要能够 cancel，那么，使用 timer 的话，CPU 资源消耗就比较大了。所以，schedgroup 在实现的时候，就使用 container/heap，按照子任务的执行时间进行排序，这样可以避免使用大量的 timer，从而提高性能。 123456789101112131415sg := schedgroup.New(context.Background())// 设置子任务分别在100、200、300之后执行for i := 0; i &lt; 3; i++ &#123; n := i + 1 sg.Delay(time.Duration(n)*100*time.Millisecond, func() &#123; log.Println(n) //输出任务编号 &#125;)&#125;// 等待所有的子任务都完成if err := sg.Wait(); err != nil &#123; log.Fatalf("failed to wait: %v", err)&#125; 3.5 go-waitgroupgo-waitgroup]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18 CyclicBarrier 循环栅栏]]></title>
    <url>%2F2019%2F02%2F18%2Fgo%2Fgo_sync%2Fgo_sync_18%2F</url>
    <content type="text"><![CDATA[CyclicBarrier 1. CyclicBarrier 概述CyclicBarrier 是一个可重用的栅栏并发原语，常常应用于重复进行一组 goroutine 同时执行的场景中。 CyclicBarrier允许一组 goroutine 彼此等待，到达一个共同的执行点。同时，因为它可以被重复使用，所以叫循环栅栏。具体的机制是，大家都在栅栏前等待，等全部都到齐了，就抬起栅栏放行。 1.1 CyclicBarrier 与 WaitGroup你可能会觉得，CyclicBarrier 和 WaitGroup 的功能有点类似，确实是这样。不过，CyclicBarrier 更适合用在“固定数量的 goroutine 等待同一个执行点”的场景中，而且在放行 goroutine 之后，CyclicBarrier 可以重复利用，不像 WaitGroup 重用的时候，必须小心翼翼避免 panic。 处理可重用的多 goroutine 等待同一个执行点的场景的时候，CyclicBarrier 和 WaitGroup 方法调用的对应关系如下： 如果使用 WaitGroup 实现的话，调用比较复杂，不像 CyclicBarrier 那么清爽。更重要的是，如果想重用 WaitGroup，你还要保证，将 WaitGroup 的计数值重置到 n 的时候不会出现并发问题。WaitGroup 更适合用在“一个 goroutine 等待一组 goroutine 到达同一个执行点”的场景中，或者是不需要重用的场景中。 1.2 CyclicBarrier 使用CyclicBarrier 有两个初始化方法： 第一个是 New 方法，它只需要一个参数，来指定循环栅栏参与者的数量； 第二个方法是 NewWithAction 它额外提供一个函数，可以在每一次到达执行点的时候执行一次 执行具体的时间点是在最后一个参与者到达之后，但是其它的参与者还未被放行之前。我们可以利用它，做放行之前的一些共享状态的更新等操作。 123func New(parties int) CyclicBarrierfunc NewWithAction(parties int, barrierAction func() error) CyclicBarrier CyclicBarrier 是一个接口，定义的方法如下： 1234567891011121314151617type CyclicBarrier interface &#123; // 等待所有的参与者到达，如果被ctx.Done()中断，会返回ErrBrokenBarrier Await(ctx context.Context) error // 重置循环栅栏到初始化状态。如果当前有等待者，那么它们会返回ErrBrokenBarrier Reset() // 返回当前等待者的数量 GetNumberWaiting() int // 参与者的数量 GetParties() int // 循环栅栏是否处于中断状态 IsBroken() bool&#125; 循环栅栏的使用也很简单。循环栅栏的参与者只需调用 Await 等待，等所有的参与者都到达后，再执行下一步。当执行下一步的时候，循环栅栏的状态又恢复到初始的状态了，可以迎接下一轮同样多的参与者。下面是一个使用示例: 生产水原子，每生产一个水分子，就会打印出 HHO、HOH、OHH 三种形式的其中一种。 1234567891011121314151617181920212223242526272829303132333435363738package waterimport ( "context" "github.com/marusama/cyclicbarrier" "golang.org/x/sync/semaphore")// 定义水分子合成的辅助数据结构type H2O struct &#123; semaH *semaphore.Weighted // 氢原子的信号量 semaO *semaphore.Weighted // 氧原子的信号量 b cyclicbarrier.CyclicBarrier // 循环栅栏，用来控制合成&#125;func New() *H2O &#123; return &amp;H2O&#123; semaH: semaphore.NewWeighted(2), //氢原子需要两个 semaO: semaphore.NewWeighted(1), // 氧原子需要一个 b: cyclicbarrier.New(3), // 需要三个原子才能合成 &#125;&#125;func (h2o *H2O) hydrogen(releaseHydrogen func()) &#123; h2o.semaH.Acquire(context.Background(), 1) releaseHydrogen() // 输出H h2o.b.Await(context.Background()) //等待栅栏放行 h2o.semaH.Release(1) // 释放氢原子空槽&#125;func (h2o *H2O) oxygen(releaseOxygen func()) &#123; h2o.semaO.Acquire(context.Background(), 1) releaseOxygen() // 输出O h2o.b.Await(context.Background()) //等待栅栏放行 h2o.semaO.Release(1) // 释放氢原子空槽&#125; 下面是对应的单元测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package waterimport ( "math/rand" "sort" "sync" "testing" "time")func TestWaterFactory(t *testing.T) &#123; //用来存放水分子结果的channel var ch chan string releaseHydrogen := func() &#123; ch &lt;- "H" &#125; releaseOxygen := func() &#123; ch &lt;- "O" &#125; // 300个原子，300个goroutine,每个goroutine并发的产生一个原子 var N = 100 ch = make(chan string, N*3) h2o := New() // 用来等待所有的goroutine完成 var wg sync.WaitGroup wg.Add(N * 3) // 200个氢原子goroutine for i := 0; i &lt; 2*N; i++ &#123; go func() &#123; time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) h2o.hydrogen(releaseHydrogen) wg.Done() &#125;() &#125; // 100个氧原子goroutine for i := 0; i &lt; N; i++ &#123; go func() &#123; time.Sleep(time.Duration(rand.Intn(100)) * time.Millisecond) h2o.oxygen(releaseOxygen) wg.Done() &#125;() &#125; //等待所有的goroutine执行完 wg.Wait() // 结果中肯定是300个原子 if len(ch) != N*3 &#123; t.Fatalf("expect %d atom but got %d", N*3, len(ch)) &#125; // 每三个原子一组，分别进行检查。要求这一组原子中必须包含两个氢原子和一个氧原子，这样才能正确组成一个水分子。 var s = make([]string, 3) for i := 0; i &lt; N; i++ &#123; s[0] = &lt;-ch s[1] = &lt;-ch s[2] = &lt;-ch sort.Strings(s) water := s[0] + s[1] + s[2] if water != "HHO" &#123; t.Fatalf("expect a water molecule but got %s", water) &#125; &#125;&#125; 如果你没有学习 CyclicBarrier，你可能只会想到，用 WaitGroup 来实现这个水分子制造工厂的例子。 123456789101112131415161718192021222324252627282930313233343536373839404142type H2O struct &#123; semaH *semaphore.Weighted semaO *semaphore.Weighted wg sync.WaitGroup //将循环栅栏替换成WaitGroup&#125;func New() *H2O &#123; var wg sync.WaitGroup wg.Add(3) return &amp;H2O&#123; semaH: semaphore.NewWeighted(2), semaO: semaphore.NewWeighted(1), wg: wg, &#125;&#125;func (h2o *H2O) hydrogen(releaseHydrogen func()) &#123; h2o.semaH.Acquire(context.Background(), 1) releaseHydrogen() // 标记自己已达到，等待其它goroutine到达 h2o.wg.Done() h2o.wg.Wait() h2o.semaH.Release(1)&#125;func (h2o *H2O) oxygen(releaseOxygen func()) &#123; h2o.semaO.Acquire(context.Background(), 1) releaseOxygen() // 标记自己已达到，等待其它goroutine到达 h2o.wg.Done() h2o.wg.Wait() //都到达后重置wg h2o.wg.Add(3) h2o.semaO.Release(1)&#125; 使用 WaitGroup 非常复杂，而且，重用和 Done 方法的调用有并发的问题，程序可能 panic，远远没有使用循环栅栏更加简单直接。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17 SingleFlight 请求合并]]></title>
    <url>%2F2019%2F02%2F17%2Fgo%2Fgo_sync%2Fgo_sync_17%2F</url>
    <content type="text"><![CDATA[SingleFlight 1. SingleFlight 栅栏概述SingleFlight 的作用是将并发请求合并成一个请求，以减少对下层服务的压力。当多个 goroutine 同时调用同一个函数的时候，只让一个 goroutine 去调用这个函数，等到这个 goroutine 返回结果的时候，再把结果返回给这几个同时调用的 goroutine，这样可以减少并发调用的数量。 如果你学会了 SingleFlight，在面对秒杀等大并发请求的场景，而且这些请求都是读请求时，你就可以把这些请求合并为一个请求，这样，你就可以将后端服务的压力从 n 降到 1。尤其是在面对后端是数据库这样的服务的时候，采用 SingleFlight 可以极大地提高性能。 Go 标准库的代码中就有一个 SingleFlight 的实现，而扩展库中的 SingleFlight(golang.org/x/sync/singleflight) 就是在标准库的代码基础上改的，逻辑几乎一模一样。 1.1 SingleFlight 与 Sync.Once标准库中的 sync.Once 也可以保证并发的 goroutine 只会执行一次函数 f，那么，SingleFlight 和 sync.Once 有什么区别呢？ sync.Once 不是只在并发的时候保证只有一个 goroutine 执行函数 f，而是会保证永远只执行一次，而 SingleFlight 是每次调用都重新执行，并且在多个请求同时调用的时候只有一个执行。它们两个面对的场景是不同的，sync.Once 主要是用在单次初始化场景中，而 SingleFlight 主要用在合并并发请求的场景中，尤其是缓存场景。 2. 实现原理SingleFlight 使用互斥锁 Mutex 和 Map 来实现。Mutex 提供并发时的读写保护，Map 用来保存同一个 key 的正在处理（in flight）的请求。SingleFlight 的数据结构是 Group，它提供了三个方法： 12345import "golang.org/x/sync/singleflight"type Group func (g *Group) Do(key string, fn func() (interface&#123;&#125;, error)) (v interface&#123;&#125;, err error, shared bool) func (g *Group) DoChan(key string, fn func() (interface&#123;&#125;, error)) &lt;-chan Result func (g *Group) Forget(key string) Do： 这个方法执行一个函数，并返回函数执行的结果 需要提供一个 key，对于同一个 key，在同一时间只有一个在执行，同一个 key 并发的请求会等待。第一个执行的请求返回的结果，就是它的返回结果 函数 fn 是一个无参的函数，返回一个结果或者 error，而 Do 方法会返回函数执行的结果或者是 error shared 会指示 v 是否返回给多个请求。 DoChan： 类似 Do 方法，只不过是返回一个 chan，等 fn 函数执行完，产生了结果以后，就能从这个 chan 中接收这个结果 Forget： 告诉 Group 忘记这个 key 这样一来，之后这个 key 请求会执行 f，而不是等待前一个未完成的 fn 函数的结果 2.1 辅助 call 对象SingleFlight 定义一个辅助对象 call，这个 call 就代表正在执行 fn 函数的请求或者是已经执行完的请求。Group 代表 SingleFlight。 12345678910111213141516171819202122// 代表一个正在处理的请求，或者已经处理完的请求type call struct &#123; wg sync.WaitGroup // 这个字段代表处理完的值，在waitgroup完成之前只会写一次 // waitgroup完成之后就读取这个值 val interface&#123;&#125; err error // 指示当call在处理时是否要忘掉这个key forgotten bool dups int chans []chan&lt;- Result&#125;// group代表一个singleflight对象type Group struct &#123;mu sync.Mutex // protects mm map[string]*call // lazily initialized &#125; 2.2 Do 方法我们只需要查看一个 Do 方法，DoChan 的处理方法是类似的。 123456789101112131415161718192021222324252627282930313233343536373839func (g *Group) Do(key string, fn func() (interface&#123;&#125;, error)) (v interface&#123;&#125;, err error, shared bool) &#123; g.mu.Lock() if g.m == nil &#123; g.m = make(map[string]*call) &#125; if c, ok := g.m[key]; ok &#123;//如果已经存在相同的key c.dups++ g.mu.Unlock() c.wg.Wait() //等待这个key的第一个请求完成 return c.val, c.err, true //使用第一个key的请求结果 &#125; c := new(call) // 第一个请求，创建一个call c.wg.Add(1) g.m[key] = c //加入到key map中 g.mu.Unlock() g.doCall(c, key, fn) // 调用方法 return c.val, c.err, c.dups &gt; 0 &#125; func (g *Group) doCall(c *call, key string, fn func() (interface&#123;&#125;, error)) &#123; c.val, c.err = fn() c.wg.Done() g.mu.Lock() // 在默认情况下，forgotten==false，所以第 8 行默认会被调用 // 也就是说，第一个请求完成后，后续的同一个 key 的请求又重新开始新一次的 fn 函数的调用 if !c.forgotten &#123; // 已调用完，删除这个key delete(g.m, key) &#125; for _, ch := range c.chans &#123; ch &lt;- Result&#123;c.val, c.err, c.dups &gt; 0&#125; &#125; g.mu.Unlock() &#125; 3. 应用场景Go 代码库中有两个地方用到了 SingleFlight: 第一个是在net/lookup.go中，如果同时有查询同一个 host 的请求，lookupGroup 会把这些请求 merge 到一起，只需要一个请求就可以了 第二个是 Go 在查询仓库版本信息时，将并发的请求合并成 1 个请求： 12345678910111213141516171819func metaImportsForPrefix(importPrefix string, mod ModuleMode, security web.SecurityMode) (*urlpkg.URL, []metaImport, error) &#123; // 使用缓存保存请求结果 setCache := func(res fetchResult) (fetchResult, error) &#123; fetchCacheMu.Lock() defer fetchCacheMu.Unlock() fetchCache[importPrefix] = res return res, nil // 使用 SingleFlight请求 resi, _, _ := fetchGroup.Do(importPrefix, func() (resi interface&#123;&#125;, err error) &#123; fetchCacheMu.Lock() // 如果缓存中有数据，那么直接从缓存中取 if res, ok := fetchCache[importPrefix]; ok &#123; fetchCacheMu.Unlock() return res, nil &#125; fetchCacheMu.Unlock() ...... 设计缓存问题时，我们常常需要解决缓存穿透、缓存雪崩和缓存击穿问题。缓存击穿问题是指，在平常高并发的系统中，大量的请求同时查询一个 key 时，如果这个 key 正好过期失效了，就会导致大量的请求都打到数据库上。这就是缓存击穿。用 SingleFlight 来解决缓存击穿问题再合适不过了。因为，这个时候，只要这些对同一个 key 的并发请求的其中一个到数据库中查询，就可以了，这些并发的请求可以共享同一个结果。因为是缓存查询，不用考虑幂等性问题。 在 Go 生态圈知名的缓存框架 groupcache 中，就使用了较早的 Go 标准库的 SingleFlight 实现。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 信号量]]></title>
    <url>%2F2019%2F02%2F16%2Fgo%2Fgo_sync%2Fgo_sync_16%2F</url>
    <content type="text"><![CDATA[信号量 1. 信号量概述信号量（Semaphore）是用来控制多个 goroutine 同时访问多个资源的并发原语。最简单的信号量就是一个变量加一些并发控制的能力，更复杂的信号量类型，就是使用抽象数据类型代替变量，用来代表复杂的资源类型。实际上，大部分的信号量都使用一个整型变量来表示一组资源，并没有实现太复杂的抽象数据类型。 信号量这个并发原语在多资源共享的并发控制的场景中被广泛使用，有时候也会被 Channel 类型所取代，因为一个 buffered chan 也可以代表 n 个资源。 1.1 P/V 操作信号量包含两个操作 P 和 V: P 操作（descrease、wait、acquire）是减少信号量的计数值 V 操作（increase、signal、release）是增加信号量的计数值 初始化信号量 S 有一个指定数量（n）的资源，它就像是一个有 n 个资源的池子。P 操作相当于请求资源，如果资源可用，就立即返回；如果没有资源或者不够，那么，它可以不断尝试或者阻塞等待。V 操作会释放自己持有的资源，把资源返还给信号量。信号量的值除了初始化的操作以外，只能由 P/V 操作改变。 所以信号量的实现包括： 初始化信号量：设定初始的资源的数量。 P 操作：将信号量的计数值减去 1，如果新值已经为负，那么调用者会被阻塞并加入到等待队列中，否则获取一个资源继续执行 V 操作：将信号量的计数值加 1，如果先前的计数值为负，就说明有等待的 P 操作的调用者。它会从等待队列中取出一个等待的调用者，唤醒它，让它继续执行。 1.2 信号量和互斥锁信号量可以分为计数信号量（counting semaphre）和二进位信号量（binary semaphore）。在特殊的情况下，如果计数值只能是 0 或者 1，那么，这个信号量就是二进位信号量，提供了互斥的功能（要么是 0，要么是 1），所以，有时候互斥锁也会使用二进位信号量来实现。我们一般用信号量保护一组资源，如果信号量蜕变成二进位信号量，那么，它的 P/V 就和互斥锁的 Lock/Unlock 一样了。 1.3 Go 运行时实现在运行时，Go 内部使用信号量来控制 goroutine 的阻塞和唤醒，在 Mutex 的实现上就使用了信号量 12345678910type Mutex struct &#123; state int32 sema uint32&#125;// 信号量的 P/V 操作func runtime_Semacquire(s *uint32)func runtime_SemacquireMutex(s *uint32, lifo bool, skipframes int)func runtime_Semrelease(s *uint32, handoff bool, skipframes int) 遗憾的是，它是 Go 运行时内部使用的，并没有封装暴露成一个对外的信号量并发原语，原则上我们没有办法使用。Go 在它的扩展包中提供了信号量semaphore，不过这个信号量的类型名并不叫 Semaphore，而是叫 Weighted。 1.4 Weighted12345type Weighted func NewWeighted(n int64) *Weighted func (s *Weighted) Acquire(ctx context.Context, n int64) error func (s *Weighted) Release(n int64) func (s *Weighted) TryAcquire(n int64) bool Acquire 方法： 相当于 P 操作，你可以一次获取多个资源，如果没有足够多的资源，调用者就会被阻塞 第一个参数是 Context，可以通过 Context 增加超时或者 cancel 的机制。如果是正常获取了资源，就返回 nil；否则，就返回 ctx.Err()，信号量不改变。 Release 方法：相当于 V 操作，可以将 n 个资源释放，返还给信号量。 TryAcquire 方法：尝试获取 n 个资源，但是它不会阻塞，要么成功获取 n 个资源，返回 true，要么一个也不获取，返回 false 下面是 Weighted 使用示例，我们创建和 CPU 核数一样多的 Worker，让它们去处理一个 4 倍数量的整数 slice。每个 Worker 一次只能处理一个整数，处理完之后，才能处理下一个。当然，这个问题的解决方案有很多种，这一次我们使用信号量，代码如下： 12345678910111213141516171819202122232425262728293031import "golang.org/x/sync/semaphore"var ( maxWorkers = runtime.GOMAXPROCS(0) // worker数量 sema = semaphore.NewWeighted(int64(maxWorkers)) //信号量 task = make([]int, maxWorkers*4) // 任务数，是worker的四倍)func main() &#123; ctx := context.Background() for i := range task &#123; // 如果没有worker可用，会阻塞在这里，直到某个worker被释放 if err := sema.Acquire(ctx, 1); err != nil &#123; break &#125; // 启动worker goroutine go func(i int) &#123; defer sema.Release(1) time.Sleep(100 * time.Millisecond) // 模拟一个耗时操作 task[i] = i + 1 &#125;(i) &#125; // 请求所有的worker,这样能确保前面的worker都执行完 if err := sema.Acquire(ctx, int64(maxWorkers)); err != nil &#123; log.Printf("获取所有的worker失败: %v", err) &#125; fmt.Println(task)&#125; 在这个例子中，还有一个值得我们学习的知识点，就是最后的那一段处理（第 25 行）。如果在实际应用中，你想等所有的 Worker 都执行完，就可以获取最大计数值的信号量。 1.5 常见错误在使用信号量时，最常见的几个错误如下： 请求了资源，但是忘记释放它； 释放了从未请求的资源； 长时间持有一个资源，即使不需要它； 不持有一个资源，却直接使用它。 不过，即使你规避了这些坑，在同时使用多种资源，不同的信号量控制不同的资源的时候，也可能会出现死锁现象，比如哲学家就餐问题。 就 Go 扩展库实现的信号量来说，在调用 Release 方法的时候，你可以传递任意的整数。但是，如果你传递一个比请求到的数量大的错误的数值，程序就会 panic。如果传递一个负数，会导致资源永久被持有。如果你请求的资源数比最大的资源数还大，那么，调用者可能永远被阻塞。 所以，使用信号量遵循的原则就是请求多少资源，就释放多少资源。 2. semaphore/Weighted 实现Go 扩展库中的信号量是使用互斥锁 +List 实现的。互斥锁实现其它字段的保护，而 List 实现了一个等待队列，等待者的通知是通过 Channel 的通知机制实现的。 2.1 Weighted 数据结构我们来看一下信号量 Weighted 的数据结构： 123456type Weighted struct &#123; size int64 // 最大资源数 cur int64 // 当前已被使用的资源 mu sync.Mutex // 互斥锁，对字段的保护 waiters list.List // 等待队列&#125; 2.2 Acquire 方法在信号量的几个实现方法里，Acquire 是代码最复杂的一个方法，它不仅仅要监控资源是否可用，而且还要检测 Context 的 Done 是否已关闭。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func (s *Weighted) Acquire(ctx context.Context, n int64) error &#123; s.mu.Lock() // fast path, 如果有足够的资源，都不考虑ctx.Done的状态，将cur加上n就返回 if s.size-s.cur &gt;= n &amp;&amp; s.waiters.Len() == 0 &#123; s.cur += n s.mu.Unlock() return nil &#125; // 如果是不可能完成的任务，请求的资源数大于能提供的最大的资源数 if n &gt; s.size &#123; s.mu.Unlock() // 依赖ctx的状态返回，否则一直等待 &lt;-ctx.Done() return ctx.Err() &#125; // 否则就需要把调用者加入到等待队列中 // 创建了一个ready chan,以便被通知唤醒 ready := make(chan struct&#123;&#125;) w := waiter&#123;n: n, ready: ready&#125; elem := s.waiters.PushBack(w) s.mu.Unlock() // 等待 select &#123; case &lt;-ctx.Done(): // context的Done被关闭 err := ctx.Err() s.mu.Lock() select &#123; case &lt;-ready: // 如果被唤醒了，忽略ctx的状态 err = nil default: 通知waiter isFront := s.waiters.Front() == elem s.waiters.Remove(elem) // 通知其它的waiters,检查是否有足够的资源 if isFront &amp;&amp; s.size &gt; s.cur &#123; s.notifyWaiters() &#125; &#125; s.mu.Unlock() return err case &lt;-ready: // 被唤醒了 return nil &#125; &#125; 2.3 ReleaseRelease 方法将当前计数值减去释放的资源数 n，并唤醒等待队列中的调用者，看是否有足够的资源被获取。 1234567891011func (s *Weighted) Release(n int64) &#123; s.mu.Lock() s.cur -= n if s.cur &lt; 0 &#123; s.mu.Unlock() panic("semaphore: released more than held") &#125; s.notifyWaiters() s.mu.Unlock()&#125; notifyWaiters 方法就是逐个检查等待的调用者，如果资源不够，或者是没有等待者了，就返回： 1234567891011121314151617181920func (s *Weighted) notifyWaiters() &#123; for &#123; next := s.waiters.Front() if next == nil &#123; break // No more waiters blocked. &#125; w := next.Value.(waiter) if s.size-s.cur &lt; w.n &#123; //避免饥饿，这里还是按照先入先出的方式处理 break &#125; s.cur += w.n s.waiters.Remove(next) close(w.ready) &#125; &#125; notifyWaiters 方法是按照先入先出的方式唤醒调用者。这样做的目的是避免饥饿，否则的话，资源可能总是被那些请求资源数小的调用者获取，这样一来，请求资源数巨大的调用者，就没有机会获得资源了。 2.4 总结官方扩展的信号量最大的优势是可以一次获取多个资源。在批量获取资源的场景中，建议使用此官方扩展的信号量。 3. Channel 实现的信号量除了官方扩展库的实现，还有很多方法实现信号量，比较典型的就是使用 Channel 来实现。使用一个 buffer 为 n 的 Channel 很容易实现信号量: 123456789101112131415161718192021222324// Semaphore 数据结构，并且还实现了Locker接口type semaphore struct &#123;sync.Lockerch chan struct&#123;&#125;&#125;// 创建一个新的信号量func NewSemaphore(capacity int) sync.Locker &#123;if capacity &lt;= 0 &#123; capacity = 1 // 容量为1就变成了一个互斥锁&#125;return &amp;semaphore&#123;ch: make(chan struct&#123;&#125;, capacity)&#125;&#125;// 请求一个资源func (s *semaphore) Lock() &#123;s.ch &lt;- struct&#123;&#125;&#123;&#125;&#125;// 释放资源func (s *semaphore) Unlock() &#123;&lt;-s.ch&#125; 官方的实现方式有这样一个功能：它可以一次请求多个资源，这是通过 Channel 实现的信号量所不具备的。 4. 其他实现除了 Channel，marusama/semaphore也实现了一个可以动态更改资源容量的信号量，也是一个非常有特色的实现。如果你的资源数量并不是固定的，而是动态变化的，可以考虑使用这个库。 5. 信号量]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 Golang 内存模型]]></title>
    <url>%2F2019%2F02%2F15%2Fgo%2Fgo_sync%2Fgo_sync_15%2F</url>
    <content type="text"><![CDATA[内存模型 1. Go 内存模型概述Go 内存模型 描述的是并发环境中多 goroutine 读相同变量的时候，变量的可见性条件。具体点说，就是指，在什么条件下，goroutine 在读取一个变量的值的时候，能够看到其它 goroutine 对这个变量进行的写的结果。 由于 CPU 指令重排和多级 Cache 的存在，保证多核访问同一个变量这件事儿变得非常复杂。编程语言需要一个规范，来明确多线程同时访问同一个变量的可见性和顺序（ Russ Cox 在麻省理工学院 6.824 分布式系统 Distributed Systems 课程 的一课，专门介绍了相关的知识）。在编程语言中，这个规范被叫做内存模型。 为什么这些编程语言都要定义内存模型呢？在我看来，主要是两个目的。 向广大的程序员提供一种保证，以便他们在做设计和开发程序时，面对同一个数据同时被多个 goroutine 访问的情况，可以做一些串行化访问的控制，比如使用 Channel 或者 sync 包和 sync/atomic 包中的并发原语。 允许编译器和硬件对程序做一些优化。这一点其实主要是为编译器开发者提供的保证，这样可以方便他们对 Go 的编译器做优化。 1.1 重排和可见性的问题首先，我们要先弄明白重排和可见性的问题，因为它们影响着程序实际执行的顺序关系。 由于指令重排，代码并不一定会按照你写的顺序执行。举个例子: 当两个 goroutine 同时对一个数据进行读写时 假设 goroutine g1 对这个变量进行写操作 w，goroutine g2 同时对这个变量进行读操作 r， 如果 g2 在执行读操作 r 的时候，已经看到了 g1 写操作 w 的结果，那么，也不意味着 g2 能看到在 w 之前的其它的写操作 1234567891011121314151617181920// 排以及多核 CPU 并发执行导致程序的运行和代码的书写顺序不一样的情况var a, b intfunc f() &#123; a = 1 // w之前的写操作 b = 2 // 写操作w&#125;func g() &#123; // 即使这里打印出的值是 2，但是依然可能在打印 a 的值时，打印出初始值 0，而不是 1 // 因为，程序运行的时候，不能保证 g2 看到的 a 和 b 的赋值有先后关系。 print(b) // 读操作r print(a) // ???&#125;func main() &#123; go f() //g1 g() //g2&#125; g() 函数内要打印 b 的值。需要注意的是，即使这里打印出的值是 2，但是依然可能在打印 a 的值时，打印出初始值 0，而不是 1。这是因为，程序运行的时候，不能保证 g2 看到的 a 和 b 的赋值有先后关系。 123456789101112131415var a stringvar done boolfunc setup() &#123; a = "hello, world" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; print(a)&#125; 在这段代码中，主 goroutine main 即使观察到 done 变成 true 了，最后读取到的 a 的值仍然可能为空。 更糟糕的情况是，main 根本就观察不到另一个 goroutine 对 done 的写操作，这就会导致 main 程序一直被 hang 住。甚至可能还会出现半初始化的情况，比如： 12345678910111213141516171819type T struct &#123; msg string&#125;var g *Tfunc setup() &#123; t := new(T) t.msg = "hello, world" g = t&#125;func main() &#123; go setup() for g == nil &#123; &#125; print(g.msg)&#125; 即使 main goroutine 观察到 g 不为 nil，也可能打印出空的 msg（第 17 行）。 2. hanppen-before刚刚说了，程序在运行的时候，两个操作的顺序可能不会得到保证，怎么办呢？接下来，我们要了解一下 Go 内存模型中很重要的一个概念：happens-before，这是用来描述两个时间的顺序关系的。如果某些操作能提供 happens-before 关系，那么，我们就可以 100% 保证它们之间的顺序。 在一个 goroutine 内部，程序的执行顺序和它们的代码指定的顺序是一样的，即使编译器或者 CPU 重排了读写顺序，从行为上来看，也和代码指定的顺序一样。 在下面的代码中，即使编译器或者 CPU 对 a、b、c 的初始化进行了重排，但是打印结果依然能保证是 1、2、3，而不会出现 1、0、0 或 1、0、1 等情况。 12345678910func foo() &#123; var a = 1 var b = 2 var c = 3 println(a) println(b) println(c)&#125; 但是，对于另一个 goroutine 来说，重排却会产生非常大的影响。因为 Go 只保证 goroutine 内部重排对读写的顺序没有影响。 如果两个 action（read 或者 write）有明确的 happens-before 关系，你就可以确定它们之间的执行顺序（或者是行为表现上的顺序）。Go 内存模型通过 happens-before 定义两个事件（读、写 action）的顺序： 如果事件 e1 happens before 事件 e2，那么，我们就可以说事件 e2 在事件 e1 之后发生（happens after）。 如果 e1 不是 happens before e2， 同时也不 happens after e2，那么，我们就可以说事件 e1 和 e2 是同时发生的。 如果要保证对“变量 v 的读操作 r”能够观察到一个对“变量 v 的写操作 w”，并且 r 只能观察到 w 对变量 v 的写，没有其它对 v 的写操作，也就是说，我们要保证 r 绝对能观察到 w 操作的结果，那么就需要同时满足两个条件： w happens before r； 其它对 v 的写操作（w2、w3、w4, …） 要么 happens before w，要么 happens after r，绝对不会和 w、r 同时发生，或者是在它们之间发生。 对于单个的 goroutine 来说，它有一个特殊的 happens-before 关系: 在单个的 goroutine 内部， happens-before 的关系和代码编写的顺序是一致的。即在 goroutine 内部对一个局部变量 v 的读，一定能观察到最近一次对这个局部变量 v 的写。如果要保证多个 goroutine 之间对一个共享变量的读写顺序，在 Go 语言中，可以使用并发原语为读写操作建立 happens-before 关系，这样就可以保证顺序了。 说到这儿，先补充三个 Go 语言中和内存模型有关的小知识: 在 Go 语言中对变量进行零值的初始化就是一个写操作。 如果对超过机器 word（64bit、32bit 或者其它）大小的值进行读写，那么，就可以看作是对拆成 word 大小的几个读写无序进行。 Go 并不提供直接的 CPU 屏障（CPU fence）来提示编译器或者 CPU 保证顺序性，而是使用不同架构的内存屏障指令来实现统一的并发原语。 接下来，我们就来学习 Go 语言中提供的 happens-before 关系保证，包括: init 函数 goroutine Channel Mutex/RWMutex WaitGroup Once 2. init 函数应用程序的初始化是在单一的 goroutine 执行的。如果包 p 导入了包 q，那么，q 的 init 函数的执行一定 happens before p 的任何初始化代码。而main 函数一定在导入的包的 init 函数之后执行。 Go 采用依赖分析技术，确定包的初始化顺序: 包级别的变量在同一个文件中是按照声明顺序逐个初始化的，除非初始化它的时候依赖其它的变量 同一个包下的多个文件，会按照文件名的排列顺序进行初始化。这个顺序被定义在Go 语言规范中，而不是 Go 的内存模型规范中。 依赖分析技术保证的顺序只是针对同一包下的变量，而且，只有引用关系是本包变量、函数和非接口的方法，才能保证它们的顺序性。 3. goroutine首先，我们需要明确一个规则：启动 goroutine 的 go 语句的执行，一定 happens before 此 goroutine 内的代码执行。根据这个规则，我们就可以知道，如果 go 语句传入的参数是一个函数执行的结果，那么，这个函数一定先于 goroutine 内部的代码被执行。 我们看下面这个例子: 第 8 行 a 的赋值和第 9 行的 go 语句是在同一个 goroutine 中执行的，所以，在主 goroutine 看来，第 8 行肯定 happens before 第 9 行 又由于刚才的保证，第 9 行子 goroutine 的启动 happens before 第 4 行的变量输出 我们就可以推断出，第 8 行 happens before 第 4 行。也就是说，在第 4 行打印 a 的值的时候，肯定会打印出“hello world” 12345678910var a stringfunc f() &#123; print(a) // 4&#125;func hello() &#123; a = "hello, world" // 8 go f()&#125; 刚刚说的是启动 goroutine 的情况，goroutine 退出的时候，是没有任何 happens-before 保证的。所以，如果你想观察某个 goroutine 的执行效果，你需要使用同步机制建立 happens-before 关系，比如 Mutex 或者 Channel。 4. channel通用的 Channel happens-before 关系保证有 4 条规则，我分别来介绍下: 往 Channel 中的发送操作，happens before 从该 Channel 接收相应数据的动作完成之前，即第 n 个 send 一定 happens before 第 n 个 receive 的完成 close 一个 Channel 的调用，肯定 happens before 从关闭的 Channel 中读取出一个零值 对于 unbuffered 的 Channel，也就是容量是 0 的 Channel，从此 Channel 中读取数据的调用一定 happens before 往此 Channel 发送数据的调用完成 如果 Channel 的容量是 m（m&gt;0），那么，第 n 个 receive 一定 happens before 第 n+m 个 send 的完成 12345678910111213var ch = make(chan struct&#123;&#125;, 10) // buffered或者unbufferedvar s stringfunc f() &#123; s = "hello, world" // 5 ch &lt;- struct&#123;&#125;&#123;&#125; // 6&#125;func main() &#123; go f() &lt;-ch // 11 print(s)&#125; 在这个例子中： s 的初始化（第 5 行）happens before 往 ch 中发送数据 往 ch 发送数据 happens before 从 ch 中读取出一条数据（第 11 行）， 第 12 行打印 s 的值 happens after 第 11 行 所以，打印的结果肯定是初始化后的 s 的值“hello world” 如果你把第 6 行替换成 close(ch)，也能保证同样的执行顺序。因为第 11 行从关闭的 ch 中读取出零值后，第 6 行肯定被调用了。 12345678910111213var ch = make(chan int)var s stringfunc f() &#123; s = "hello, world" &lt;-ch // 6&#125;func main() &#123; go f() ch &lt;- struct&#123;&#125;&#123;&#125; // 11 print(s)&#125; 这个例子中: 如果第 11 行发送语句执行成功（完毕），那么根据规则 3，第 6 行（接收）的调用肯定发生了（执行完成不完成不重要，重要的是这一句“肯定执行了”），那么 s 也肯定初始化了，所以一定会打印出“hello world”。 5. Mutex/RWMutex对于互斥锁 Mutex m 或者读写锁 RWMutex m，有 3 条 happens-before 关系的保证: 第 n 次的 m.Unlock 一定 happens before 第 n+1 m.Lock 方法的返回； 对于读写锁 RWMutex m，如果它的第 n 个 m.Lock 方法的调用已返回，那么它的第 n 个 m.Unlock 的方法调用一定 happens before 任何一个 m.RLock 方法调用的返回，只要这些 m.RLock 方法调用 happens after 第 n 次 m.Lock 的调用的返回。这就可以保证，只有释放了持有的写锁，那些等待的读请求才能请求到读锁。 对于读写锁 RWMutex m，如果它的第 n 个 m.RLock 方法的调用已返回，那么它的第 k （k&lt;=n）个成功的 m.RUnlock 方法的返回一定 happens before 任意的 m.Lock 方法调用，只要这些 m.Lock 方法调用 happens after 第 n 次 m.RLock。这样就可以保证，只有 m.Lock 调用前，所有的读锁释放了，写锁才能请求到锁。 6. WaitGroup对于一个 WaitGroup 实例 wg，在某个时刻 t0 时，它的计数值已经不是零了，假如 t0 时刻之后调用了一系列的 wg.Add(n) 或者 wg.Done()，并且只有最后一次调用 wg 的计数值变为了 0，那么，可以保证这些 wg.Add 或者 wg.Done() 一定 happens before t0 时刻之后调用的 wg.Wait 方法的返回。 这个保证的通俗说法，就是 Wait 方法等到计数值归零之后才返回。 7. OnceOnce 提供的保证是：对于 once.Do(f) 调用，f 函数的那个单次调用一定 happens before 任何 once.Do(f) 调用的返回。换句话说，就是函数 f 一定会在 Do 方法返回之前执行。 8. atomic其实，Go 内存模型的官方文档并没有明确给出 atomic 的保证，有一个相关的 issue go# 5045记录了相关的讨论。Russ Cox 想让 atomic 有一个弱保证，这样可以为以后留下充足的可扩展空间，所以，Go 内存模型规范上并没有严格的定义。 对于 Go 1.15 的官方实现来说，可以保证使用 atomic 的 Load/Store 的变量之间的顺序性。在下面的例子中，打印出的 a 的结果总是 1，但是官方并没有做任何文档上的说明和保证。 12345678910111213func main() &#123; var a, b int32 = 0, 0 go func() &#123; atomic.StoreInt32(&amp;a, 1) atomic.StoreInt32(&amp;b, 1) &#125;() for atomic.LoadInt32(&amp;b) == 0&#123; runtime.Gosched() &#125; fmt.Println(atomic.LoadInt32(&amp;a))&#125; 依照 Ian Lance Taylor 的说法，Go 核心开发组的成员几乎没有关注这个方向上的研究，因为这个问题太复杂，有很多问题需要去研究，所以，现阶段还是不要使用 atomic 来保证顺序性。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 Atomic 原子操作]]></title>
    <url>%2F2019%2F02%2F12%2Fgo%2Fgo_sync%2Fgo_sync_12%2F</url>
    <content type="text"><![CDATA[Atomic 原子操作 1. Atomic 概述1.1 原子操作Package sync/atomic 实现了同步算法底层的”原子的内存操作”原语。之所以叫原子操作，是因为一个原子在执行的时候，其它线程不会看到执行一半的操作结果。在其它线程看来，原子操作要么执行完了，要么还没有执行，就像一个最小的粒子 - 原子一样，不可分割。 CPU 提供了基础的原子操作，不过，不同架构的系统的原子操作是不一样的: 对于单处理器单核系统: 如果一个操作是由一个 CPU 指令来实现的，那么它就是原子操作 如果操作是基于多条指令来实现的，那么，执行的过程中可能会被中断，并执行上下文切换，这样的话，原子性的保证就会被打破 在多处理器多核系统中: 由于 cache 的存在，单个核上的单个指令进行原子操作的时候，你要确保其它处理器或者核不访问此原子操作的地址，或者是确保其它处理器或者核总是访问原子操作之后的最新的值 不同的 CPU 架构提供了不同的 CPU 指令来完成原子操作 因为不同的 CPU 架构甚至不同的版本提供的原子操作的指令是不同的，所以，要用一种编程语言实现支持不同架构的原子操作是相当有难度的，Go 语言为我们做好了这一切 Go 提供了一个通用的原子操作的 API，将更底层的不同的架构下的实现封装成 atomic 包，提供了修改类型的原子操作（atomic read-modify-write，RMW）和加载存储类型的原子操作（Load 和 Store）的 API 1.2 原子操作应用场景原子操作适用以下场景: 首先 atomic 原子操作适用于”不涉及到对资源复杂的竞争逻辑” 基于 atomic 可以实现自定义的基本并发原语，原子操作是解决并发问题的根本 atomic 原子操作还是实现 lock-free 数据结构的基石，lock-freeze 数据结构的实现可以参考这篇文章Lockless Programming Considerations for Xbox 360 and Microsoft Windows 1.3 atomic 的使用目前的 Go 的泛型的特性还没有发布，多个类型会实现很多类似的方法，尤其是 atomic 包。 atomic 为了支持 int32、int64、uint32、uint64、uintptr、Pointer（Add 方法不支持）类型，分别提供了 AddXXX、CompareAndSwapXXX、SwapXXX、LoadXXX、StoreXXX 等方法。 atomic 操作的对象是一个地址，你需要把可寻址的变量的地址作为参数传递给方法，而不是把变量的值传递给方法。下面我们就来看看 atomic 提供的方法。 Add12345func AddInt32(addr *int32, delta int32) (new int32)func AddInt64(addr *int64, delta int64) (new int64)func AddUint32(addr *uint32, delta uint32) (new uint32)func AddUint64(addr *uint64, delta uint64) (new uint64)func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) Add 方法: Add 方法就是给第一个参数地址中的值增加一个 delta 值 对于有符号的整数来说，delta 可以是一个负数，相当于减去一个值 对于无符号的整数和 uinptr 类型来，减去一个值需要利用计算机补码规则，吧减法编程加法 123// 以 uint32/unit64 类型为例，实现减 c 操作AddUint32(&amp;x, ^uint32(c-1))AddUint32(&amp;x, ^uint32(c-1)) CSA(CompareAndSwap)123456func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) CSA 方法: 这个方法会比较当前 addr 地址里的值是不是 old，如果不等于 old，就返回 false；如果等于 old，就把此地址的值替换成 new 值，返回 true Swap123456func SwapInt32(addr *int32, new int32) (old int32)func SwapInt64(addr *int64, new int64) (old int64)func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)func SwapUint32(addr *uint32, new uint32) (old uint32)func SwapUint64(addr *uint64, new uint64) (old uint64)func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) Swap 方法: 不需要比较旧值，直接将 addr 地址内的值替换为 new，并返回旧值 Load123456func LoadInt32(addr *int32) (val int32)func LoadInt64(addr *int64) (val int64)func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)func LoadUint32(addr *uint32) (val uint32)func LoadUint64(addr *uint64) (val uint64)func LoadUintptr(addr *uintptr) (val uintptr) Load 方法: 取出 addr 地址中的值，即使在多处理器、多核、有 CPU cache 的情况下，这个操作也能保证 Load 是一个原子操作 Store123456func StoreInt32(addr *int32, val int32)func StoreInt64(addr *int64, val int64)func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)func StoreUint32(addr *uint32, val uint32)func StoreUint64(addr *uint64, val uint64)func StoreUintptr(addr *uintptr, val uintptr) Store 方法: 把一个值存入到指定的 addr 地址中，即使在多处理器、多核、有 CPU cache 的情况下，这个操作也能保证 Store 是一个原子操作。 别的 goroutine 通过 Load 读取出来，不会看到存取了一半的值。 Value 类型123type Value func (v *Value) Load() (x interface&#123;&#125;) func (v *Value) Store(x interface&#123;&#125;) Value 类型: 可以原子地存取对象类型，但也只能存取，不能 CAS 和 Swap，常常用在配置变更等场景中 接下来，我们以一个配置变更的例子，来演示 Value 类型的使用。 12345678910111213141516171819202122232425262728293031323334353637383940type Config struct &#123; NodeName string Addr string Count int32&#125;func loadNewConfig() Config &#123; return Config&#123; NodeName: "北京", Addr: "10.77.95.27", Count: rand.Int31(), &#125;&#125;func main() &#123; var config atomic.Value config.Store(loadNewConfig()) var cond = sync.NewCond(&amp;sync.Mutex&#123;&#125;) // 设置新的config go func() &#123; for &#123; time.Sleep(time.Duration(5+rand.Int63n(5)) * time.Second) config.Store(loadNewConfig()) cond.Broadcast() // 通知等待着配置已变更 &#125; &#125;() go func() &#123; for &#123; cond.L.Lock() cond.Wait() // 等待变更信号 c := config.Load().(Config) // 读取新的配置 fmt.Printf("new config: %+v\n", c) cond.L.Unlock() &#125; &#125;() select &#123;&#125;&#125; 2. Atomic 的扩展atomic 的 API 已经算是很简单的了，它提供了包一级的函数，可以对几种类型的数据执行原子操作。有些人就对这些函数做了进一步的包装，跟 atomic 中的 Value 类型类似，这些类型也提供了面向对象的使用方式，比如关注度比较高的uber-go/atomic。 uber-go/atomic 定义和封装了几种与常见类型相对应的原子操作类型，这些类型提供了原子操作的方法。这些类型包括 Bool、Duration、Error、Float64、Int32、Int64、String、Uint32、Uint64 等。s 1234var running atomic.Boolrunning.Store(true)running.Toggle()fmt.Println(running.Load()) // false atomic.Value 只有 Load/Store 方法，可以参考这篇文章为其增加 Swap 和 CompareAndSwap 方法。 3. 使用 atomic 实现 Lock-Free queueatomic 常常用来实现 Lock-Free 的数据结构，这里我们实现一个 Lock-Free queue。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package queueimport ( "sync/atomic" "unsafe")// lock-free的queuetype LKQueue struct &#123; head unsafe.Pointer tail unsafe.Pointer&#125;// 通过链表实现，这个数据结构代表链表中的节点type node struct &#123; value interface&#123;&#125; next unsafe.Pointer&#125;func NewLKQueue() *LKQueue &#123; n := unsafe.Pointer(&amp;node&#123;&#125;) return &amp;LKQueue&#123;head: n, tail: n&#125;&#125;// 入队func (q *LKQueue) Enqueue(v interface&#123;&#125;) &#123; n := &amp;node&#123;value: v&#125; for &#123; tail := load(&amp;q.tail) next := load(&amp;tail.next) if tail == load(&amp;q.tail) &#123; // 尾还是尾 if next == nil &#123; // 还没有新数据入队 if cas(&amp;tail.next, next, n) &#123; //增加到队尾 cas(&amp;q.tail, tail, n) //入队成功，移动尾巴指针 return &#125; &#125; else &#123; // 已有新数据加到队列后面，需要移动尾指针 cas(&amp;q.tail, tail, next) &#125; &#125; &#125;&#125;// 出队，没有元素则返回nilfunc (q *LKQueue) Dequeue() interface&#123;&#125; &#123; for &#123; head := load(&amp;q.head) tail := load(&amp;q.tail) next := load(&amp;head.next) if head == load(&amp;q.head) &#123; // head还是那个head if head == tail &#123; // head和tail一样 if next == nil &#123; // 说明是空队列 return nil &#125; // 只是尾指针还没有调整，尝试调整它指向下一个 cas(&amp;q.tail, tail, next) &#125; else &#123; // 读取出队的数据 v := next.value // 既然要出队了，头指针移动到下一个 if cas(&amp;q.head, head, next) &#123; return v // Dequeue is done. return &#125; &#125; &#125; &#125;&#125;// 将unsafe.Pointer原子加载转换成nodefunc load(p *unsafe.Pointer) (n *node) &#123; return (*node)(atomic.LoadPointer(p))&#125;// 封装CAS,避免直接将*node转换成unsafe.Pointerfunc cas(p *unsafe.Pointer, old, new *node) (ok bool) &#123; return atomic.CompareAndSwapPointer( p, unsafe.Pointer(old), unsafe.Pointer(new))&#125; 4. 对一个地址的赋值是原子操作吗？如何理解 atomic 和直接内存操作的区别？(参见Dave Cheney) 在现在的系统中，write 的地址基本上都是对齐的（aligned），对齐地址的写，不会导致其他人看到只写了一半的数据，因为它通过一个指令就可以实现对地址的操作 如果地址不是对齐的话，那么，处理器就需要分成两个指令去处理，如果执行了一个指令，其它人就会看到更新了一半的错误的数据，这被称做撕裂写（torn write） 所以，你可以认为赋值操作是一个原子操作，这个“原子操作”可以认为是保证数据的完整性。 对于现代的多处理多核的系统来说，由于 cache、指令重排，可见性等问题，我们对原子操作的意义有了更多的追求。在多核系统中，一个核对地址的值的更改，在更新到主内存中之前，是在多级缓存中存放的。这时，多个核看到的数据可能是不一样的，其它的核可能还没有看到更新的数据，还在使用旧的数据。 多处理器多核心系统为了处理这类问题，使用了一种叫做内存屏障（memory fence 或 memory barrier）的方式。一个写内存屏障会告诉处理器，必须要等到它管道中的未完成的操作（特别是写操作）都被刷新到内存中，再进行操作。此操作还会让相关的处理器的 CPU 缓存失效，以便让它们从主存中拉取最新的值。 atomic 包提供的方法会提供内存屏障的功能，所以，atomic 不仅仅可以保证赋值的数据完整性，还能保证数据的可见性，一旦一个核更新了该地址的值，其它处理器总是能读取到它的最新值。但是，需要注意的是，因为需要处理器之间保证数据的一致性，atomic 的操作也是会降低性能的。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 Channel]]></title>
    <url>%2F2019%2F02%2F12%2Fgo%2Fgo_sync%2Fgo_sync_13%2F</url>
    <content type="text"><![CDATA[Channel 是 Go 语言内建的 first-class 类型，也是 Go 语言与众不同的特性之一 1. Channel 概述1.1 CSP 模型要想了解 Channel，我们要先追溯到 CSP 模型。CSP 是 Communicating Sequential Process 的简称，中文直译为通信顺序进程，或者叫做交换信息的循序进程，是用来描述并发系统中进行交互的一种模式。CSP 允许使用进程组件来描述系统，它们独立运行，并且只通过消息传递的方式通信。有关Go 中如何通过 Channel 实现 CSP 参见这边文章CSP 的发展。 Channel 类型是 Go 语言内置的类型，Channel 和 Go 的另一个独特的特性 goroutine 一起为并发编程提供了优雅的、便利的、与传统并发控制不同的方案，并演化出很多并发模式。 1.2 Channel 的应用场景Go 语言的哲学: Don’t communicate by sharing memory, share memory by communicating – 执行业务处理的 goroutine 不要通过共享内存的方式通信，而是要通过 Channel 通信的方式分享数据。 “communicate by sharing memory”和“share memory by communicating”是两种不同的并发处理模式: “communicate by sharing memory”是传统的并发编程处理方式，就是指，共享的数据需要用锁进行保护，goroutine 需要获取到锁，才能并发访问数据。 “share memory by communicating”则是类似于 CSP 模型的方式，通过通信的方式，一个 goroutine 可以把数据的“所有权”交给另外一个 goroutine。 综合起来，我把 Channel 的应用场景分为五种类型: 数据交流：当作并发的 buffer 或者 queue，解决生产者 - 消费者问题。多个 goroutine 可以并发当作生产者（Producer）和消费者（Consumer） 数据传递：一个 goroutine 将数据交给另一个 goroutine，相当于把数据的拥有权 (引用) 托付出去。 信号通知：一个 goroutine 可以将信号 (closing、closed、data ready 等) 传递给另一个或者另一组 goroutine 任务编排：可以让一组 goroutine 按照一定的顺序并发或者串行的执行，这就是编排的功能 锁：利用 Channel 也可以实现互斥锁的机制 1.3 Channel 使用Channel 类型和声明Channel 分为只能接收、只能发送、既可以接收又可以发送三种类型: 1234567// 1. 语法定义ChannelType = ( "chan" | "chan" "&lt;-" | "&lt;-" "chan" ) ElementType .// 2. 类型声明chan string // 可以发送接收stringchan&lt;- struct&#123;&#125; // 只能发送struct&#123;&#125;&lt;-chan int // 只能从chan接收int 类型声明中 “&lt;-”表示单向的 chan，这个箭头总是射向左边的，元素类型总在最右边。如果箭头指向 chan，就表示可以往 chan 中塞数据；如果箭头远离 chan，就表示 chan 会往外吐数据。 chan 中的元素是任意的类型，所以也可能是 chan 类型，下面的 chan 类型都是合法的: 1234chan&lt;- chan int chan&lt;- &lt;-chan int &lt;-chan &lt;-chan intchan (&lt;-chan int) 怎么判定箭头符号属于哪个 chan 呢？其实，“&lt;-”有个规则，总是尽量和左边的 chan 结合.因此，上面的定义和下面的使用括号的划分是一样的： 12345chan&lt;- （chan int） // &lt;- 和第一个chan结合chan&lt;- （&lt;-chan int） // 第一个&lt;-和最左边的chan结合，第二个&lt;-和左边第二个chan结合&lt;-chan （&lt;-chan int） // 第一个&lt;-和最左边的chan结合，第二个&lt;-和左边第二个chan结合 chan (&lt;-chan int) // 因为括号的原因，&lt;-和括号内第一个chan结合 Channel 初始化通过 make，我们可以初始化一个 chan，未初始化的 chan 的零值是 nil。可以设置它的容量，设置容量的 chan 叫做 buffered chan；如果没有设置，它的容量是 0，这样的 chan 叫做 unbuffered chan。 12make(chan int, 9527) Channel 阻塞与 panic向 chan 读写数据时: 如果 chan 中还有数据，那么，从这个 chan 接收数据的时候就不会阻塞 如果 chan 还未满（“满”指达到其容量），给它发送数据也不会阻塞，否则就会阻塞 unbuffered chan 只有读写都准备好之后才不会阻塞 nil 是 chan 的零值，是一种特殊的 chan，对值是 nil 的 chan 的发送接收调用者总是会阻塞。 close channel 时: 如果 chan 为 nil，close 会 panic； 如果 chan 已经 closed，再次 close 也会 panic 如果 chan 不为 nil，chan 也没有 closed，就把等待队列中的 sender（writer）和 receiver（reader）从队列中全部移除并唤醒。 值得注意的点是，只要一个 chan 还有未读的数据，即使把它 close 掉，你还是可以继续把这些未读的数据消费完，之后才是读取零值数据。 Channel 常见操作chan 常见操作分为: 发送数据: ch &lt;- value 接受数据: &lt;-ch，可以返回两个值 第一个值是返回的 chan 中的元素 第二个值是 bool 类型，代表是否成功地从 chan 中读取到一个值 如果第二个参数是 false，chan 已经被 close 而且 chan 中没有缓存的数据，这个时候，第一个值是零值 所以，如果从 chan 读取到一个零值，可能是 sender 真正发送的零值，也可能是 closed 的并且没有缓存元素产生的零值 关闭: close(ch) 其他: cap 返回 chan 的容量，len 返回 chan 中缓存的还未被取走的元素数量 123456789101112131415161718192021222324252627282930// 往 chan 中发送一个数据使用“ch&lt;-”，发送数据是一条语句ch &lt;- 200// 从 chan 中接收一条数据使用“&lt;-ch”，接收数据也是一条语句：x := &lt;-ch // 把接收的一条数据赋值给变量xfoo(&lt;-ch) // 把接收的一个的数据作为参数传给函数&lt;-ch // 丢弃接收的一条数据// ch 可以作为 select 语句的 case clausefunc main() &#123; var ch = make(chan int, 10) for i := 0; i &lt; 10; i++ &#123; select &#123; case ch &lt;- i: case v := &lt;-ch: fmt.Println(v) &#125; &#125;&#125;// chan 还可以用在 for-range 语句中:for v:= range ch &#123; fmt.Println(v)&#125;// 清空 chanfor range ch &#123;&#125; 2. Channel 的实现2.1 Channel 数据结构chan 类型的数据结构如下图所示，它的数据类型是runtime.hchan qcount：代表 chan 中已经接收但还没被取走的元素的个数。内建函数 len 可以返回这个字段的值。 dataqsiz：队列的大小。chan 使用一个循环队列来存放元素，循环队列很适合这种生产者 - 消费者的场景 buf：存放元素的循环队列的 buffer elemtype 和 elemsize：chan 中元素的类型和 size， chan 一旦声明，它的元素类型是固定的 sendx：处理发送数据的指针在 buf 中的位置。一旦接收了新的数据，指针就会加上 elemsize，移向下一个位置。buf 的总大小是 elemsize 的整数倍，而且 buf 是一个循环列表。 ecvx：处理接收请求时的指针在 buf 中的位置。一旦取出数据，此指针会移动到下一个位置。 recvq：chan 是多生产者多消费者的模式，如果消费者因为没有数据可读而被阻塞了，就会被加入到 recvq 队列中。 sendq：如果生产者因为 buf 满了而阻塞，会被加入到 sendq 队列中。 2.1 初始化Go 在编译的时候，会根据容量的大小选择调用 makechan64，还是 makechan。 makechan64 只是做了 size 检查，底层还是调用 makechan 实现的。makechan 的目标就是生成 hchan 对象。 makechan 会根据 chan 的容量的大小和元素的类型不同，初始化不同的存储空间: 123456789101112131415161718192021222324252627282930313233func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // 略去检查代码 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) // var c *hchan switch &#123; case mem == 0: // chan的size或者元素的size是0，不必创建buf c = (*hchan)(mallocgc(hchanSize, nil, true)) c.buf = c.raceaddr() case elem.ptrdata == 0: // 元素不是指针，分配一块连续的内存给hchan数据结构和buf c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) // hchan数据结构后面紧接着就是buf c.buf = add(unsafe.Pointer(c), hchanSize) default: // 元素包含指针，那么单独分配buf c = new(hchan) c.buf = mallocgc(mem, elem, true) &#125; // 元素大小、类型、容量都记录下来 c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(&amp;c.lock, lockRankHchan) return c &#125; 2.2 sendGo 在编译发送数据给 chan 的时候，会把 send 语句转换成 chansend1 函数，chansend1 函数会调用 chansend，我们分段学习它的逻辑： 最开始，第一部分是进行判断：如果 chan 是 nil 的话，就把调用者 goroutine park（阻塞休眠）， 调用者就永远被阻塞住了，所以，第 11 行是不可能执行到的代码。 123456789101112131415func chansend1(c *hchan, elem unsafe.Pointer) &#123; chansend(c, elem, true, getcallerpc())&#125;func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; // 第一部分 if c == nil &#123; if !block &#123; return false &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw("unreachable") &#125; ...... &#125; 第二部分的逻辑是当你往一个已经满了的 chan 实例发送数据时，并且想不阻塞当前调用，那么这里的逻辑是直接返回。chansend1 方法在调用 chansend 的时候设置了阻塞参数，所以不会执行到第二部分的分支里。 12345// 第二部分，如果chan没有被close,并且chan满了，直接返回 if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false&#125; 第三部分显示的是，如果 chan 已经被 close 了，再往里面发送数据的话会 panic。 1234567// 第三部分，chan已经被close的情景 lock(&amp;c.lock) // 开始加锁 if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError("send on closed channel"))&#125; 第四部分，如果等待队列中有等待的 receiver，那么这段代码就把它从队列中弹出，然后直接把数据交给它（通过 memmove(dst, src, t.size)），而不需要放入到 buf 中。(注: 队列中有等待的 receiver 说明buf 中没有数据，所以不会影响消息的顺序性) 1234567 // 第四部分，从接收队列中出队一个等待的receiver if sg := c.recvq.dequeue(); sg != nil &#123; // send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true&#125; 第五部分说明当前没有 receiver，需要把数据放入到 buf 中，放入之后，就成功返回了。 1234567891011121314151617// 第五部分，buf还没满 if c.qcount &lt; c.dataqsiz &#123; qp := chanbuf(c, c.sendx) if raceenabled &#123; raceacquire(qp) racerelease(qp) &#125; typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz &#123; c.sendx = 0 &#125; c.qcount++ unlock(&amp;c.lock) return true&#125; 第六部分是处理 buf 满的情况。如果 buf 满了，发送者的 goroutine 就会加入到发送者的等待队列中，直到被唤醒。这个时候，数据或者被取走了，或者 chan 被 close 了。 12345678 // 第六部分，buf满。 // chansend1不会进入if块里，因为chansend1的block=true if !block &#123; unlock(&amp;c.lock) return false&#125; ...... 2.3 recv在处理从 chan 中接收数据时，Go 会把代码转换成 chanrecv1 函数，如果要返回两个返回值，会转换成 chanrecv2，chanrecv1 函数和 chanrecv2 会调用 chanrecv。 chanrecv1 和 chanrecv2 传入的 block 参数的值是 true，都是阻塞方式，所以我们分析 chanrecv 的实现的时候，不考虑 block=false 的情况。第一部分是 chan 为 nil 的情况。和 send 一样，从 nil chan 中接收（读取、获取）数据时，调用者会被永远阻塞。123456789101112131415161718func chanrecv1(c *hchan, elem unsafe.Pointer) &#123; chanrecv(c, elem, true)&#125;func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123; _, received = chanrecv(c, elem, true) return&#125; func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // 第一部分，chan为nil if c == nil &#123; if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw("unreachable") &#125; 第二部分你可以直接忽略，因为chanrecv1 和 chanrecv2 传入的 block 参数的值是 true12345// 第二部分, block=false且c为空 if !block &amp;&amp; empty(c) &#123; ...... &#125; 第三部分是 chan 已经被 close 的情况。如果 chan 已经被 close 了，并且队列中没有缓存的元素，那么返回 true、false。 1234567891011 // 加锁，返回时释放锁 lock(&amp;c.lock) // 第三部分，c已经被close,且chan为空emptyif c.closed != 0 &amp;&amp; c.qcount == 0 &#123; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false&#125; 第四部分是处理 buf 满的情况。这个时候，如果是 unbuffer 的 chan，就直接将 sender 的数据复制给 receiver，否则就从队列头部读取一个值，并把这个 sender 的值加入到队列尾部。 123456 // 第四部分，如果sendq队列中有等待发送的sender if sg := c.sendq.dequeue(); sg != nil &#123; recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true&#125; 第五部分是处理没有等待的 sender 的情况。这个是和 chansend 共用一把大锁，所以不会有并发的问题。如果 buf 有元素，就取出一个元素给 receiver。 123456789101112131415161718192021222324 // 第五部分, 没有等待的sender, buf中有数据if c.qcount &gt; 0 &#123; qp := chanbuf(c, c.recvx) if ep != nil &#123; typedmemmove(c.elemtype, ep, qp) &#125; typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.qcount-- unlock(&amp;c.lock) return true, true&#125;if !block &#123; unlock(&amp;c.lock) return false, false&#125; // 第六部分， buf中没有元素，阻塞 ...... 第六部分是处理 buf 中没有元素的情况。如果没有元素，那么当前的 receiver 就会被阻塞，直到它从 sender 中接收了数据，或者是 chan 被 close，才返回。 2.3 close通过 close 函数，可以把 chan 关闭，编译器会替换成 closechan 方法的调用。 close chan 的主要逻辑是: 如果 chan 为 nil，close 会 panic； 如果 chan 已经 closed，再次 close 也会 panic 如果 chan 不为 nil，chan 也没有 closed，就把等待队列中的 sender（writer）和 receiver（reader）从队列中全部移除并唤醒。 1234567891011121314151617181920212223242526272829303132333435363738394041 func closechan(c *hchan) &#123; if c == nil &#123; // chan为nil, panic panic(plainError("close of nil channel")) &#125; lock(&amp;c.lock) if c.closed != 0 &#123;// chan已经closed, panic unlock(&amp;c.lock) panic(plainError("close of closed channel")) &#125; c.closed = 1 var glist gList // 释放所有的reader for &#123; sg := c.recvq.dequeue() ...... gp := sg.g ...... glist.push(gp) &#125; // 释放所有的writer (它们会panic) for &#123; sg := c.sendq.dequeue() ...... gp := sg.g ...... glist.push(gp) &#125; unlock(&amp;c.lock) for !glist.empty() &#123; gp := glist.pop() gp.schedlink = 0 goready(gp, 3) &#125;&#125; 3. Channel 采坑点使用 Channel 最常见的错误是 panic 和 goroutine 泄漏。panic 的情况，总共有 3 种： close 为 nil 的 chan； send 已经 close 的 chan； close 已经 close 的 chan。 goroutine 泄漏的问题也很常见，下面的代码也是一个实际项目中的例子： 1234567891011121314151617func process(timeout time.Duration) bool &#123; ch := make(chan bool) go func() &#123; // 模拟处理耗时的业务 time.Sleep((timeout + time.Second)) ch &lt;- true // block fmt.Println("exit goroutine") &#125;() select &#123; case result := &lt;-ch: return result case &lt;-time.After(timeout): return false &#125;&#125; 在上面的代码中如果发生超时，process 函数就返回了，这就会导致 unbuffered 的 chan 从来就没有被读取。unbuffered chan 必须等 reader 和 writer 都准备好了才能交流，否则就会阻塞。超时导致未读，结果就是子 goroutine 就阻塞在第 7 行永远结束不了，进而导致 goroutine 泄漏。解决这个 Bug 的办法很简单，就是将 unbuffered chan 改成容量为 1 的 chan。 4. 如何选择Channel 并不是处理并发问题的“银弹”，有时候使用并发原语更简单，下面是一套如何选择的简化方法: 共享资源的并发访问使用传统并发原语 复杂的任务编排和消息传递使用 Channel； 消息通知机制使用 Channel，除非只想 signal 一个 goroutine，才使用 Cond； 简单等待所有任务的完成用 WaitGroup 需要和 Select 语句结合，使用 Channel； 需要和超时配合时，使用 Channel 和 Context。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 Channel 应用]]></title>
    <url>%2F2019%2F02%2F12%2Fgo%2Fgo_sync%2Fgo_sync_14%2F</url>
    <content type="text"><![CDATA[应用 1. 使用反射操作 Channel在学习如何使用 Channel 之前，我们来看看如何通过反射的方式执行 select 语句，这在处理很多的 case clause，尤其是不定长的 case clause 的时候，非常有用。 为了便于操作 Select，reflect 提供了如下几个函数: func Select(cases []SelectCase) (chosen int, recv Value, recvOK bool): 参数: SelectCase 表示 Select 语句的一个分支 返回值: chosen: select 是伪随机的，它在执行的 case 中随机选择一个 case，并把选择的这个 case 的索引（chosen）返回 recv: 如果 select 选中的 recv case，recvValue 表示接收的元素 recvOK: 表示是否有 case 成功被选择，false 表示没有可用的 case 返回 SelectCase: struct 表示一个 select case 分支 12345678910111213141516const ( SelectSend // case Chan &lt;- Send SelectRecv // case &lt;-Chan: SelectDefault // default)type SelectCase struct &#123; Dir SelectDir // case的方向 Chan Value // 使用的通道（收/发） Send Value // 用于发送的值&#125;type SelectDir intfunc Select(cases []SelectCase) (chosen int, recv Value, recvOK bool) 下面是动态创建 Select 的一个示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243func main() &#123; var ch1 = make(chan int, 10) var ch2 = make(chan int, 10) // 创建SelectCase var cases = createCases(ch1, ch2) // 执行10次select for i := 0; i &lt; 10; i++ &#123; chosen, recv, ok := reflect.Select(cases) if recv.IsValid() &#123; // recv case fmt.Println("recv:", cases[chosen].Dir, recv, ok) &#125; else &#123; // send case fmt.Println("send:", cases[chosen].Dir, ok) &#125; &#125;&#125;func createCases(chs ...chan int) []reflect.SelectCase &#123; var cases []reflect.SelectCase // 创建recv case for _, ch := range chs &#123; cases = append(cases, reflect.SelectCase&#123; Dir: reflect.SelectRecv, Chan: reflect.ValueOf(ch), &#125;) &#125; // 创建send case for i, ch := range chs &#123; v := reflect.ValueOf(i) cases = append(cases, reflect.SelectCase&#123; Dir: reflect.SelectSend, Chan: reflect.ValueOf(ch), Send: v, &#125;) &#125; return cases&#125; 上一节我们说了 Channel 的五种使用场景: 数据交流：当作并发的 buffer 或者 queue，解决生产者 - 消费者问题。多个 goroutine 可以并发当作生产者（Producer）和消费者（Consumer） 数据传递：一个 goroutine 将数据交给另一个 goroutine，相当于把数据的拥有权 (引用) 托付出去。 信号通知：一个 goroutine 可以将信号 (closing、closed、data ready 等) 传递给另一个或者另一组 goroutine 任务编排：可以让一组 goroutine 按照一定的顺序并发或者串行的执行，这就是编排的功能 锁：利用 Channel 也可以实现互斥锁的机制 接下来我们一一举例说明。 2.消息交流从 chan 的内部实现看，它是以一个循环队列的方式存放数据，所以，它有时候也会被当成线程安全的队列和 buffer 使用。我们来看几个例子。 2.1 worker 池Marcio Castilho 在 使用 Go 每分钟处理百万请求 这篇文章中，就介绍了他们应对大并发请求的设计。他们将用户的请求放在一个 chan Job 中，这个 chan Job 就相当于一个待处理任务队列。除此之外，还有一个 chan chan Job 队列，用来存放可以处理任务的 worker 的缓存队列。下面核心代码实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102// 1. 定义Worker 池和消息队列的长度var ( MaxWorker = os.Getenv("MAX_WORKERS") MaxQueue = os.Getenv("MAX_QUEUE"))// 2. 定义任务队列 type Job struct &#123; Payload Payload&#125;var JobQueue chan Job// 3. 定义 Workertype Worker struct &#123; WorkerPool chan chan Job JobChannel chan Job // 接收任务 quit chan bool // Worker 退出&#125;func NewWorker(workerPool chan chan Job) Worker &#123; return Worker&#123; WorkerPool: workerPool, JobChannel: make(chan Job), quit: make(chan bool)&#125;&#125;// 3.1 启动任务func (w Worker) Start() &#123; go func() &#123; for &#123; // 重要: register the current worker into the worker queue. w.WorkerPool &lt;- w.JobChannel select &#123; case job := &lt;-w.JobChannel: // we have received a work request. if err := job.Payload.UploadToS3(); err != nil &#123; log.Errorf("Error uploading to S3: %s", err.Error()) &#125; case &lt;-w.quit: // we have received a signal to stop return &#125; &#125; &#125;()&#125;// 3.2 停止任务func (w Worker) Stop() &#123; go func() &#123; w.quit &lt;- true &#125;()&#125;// 4. 创建 Worker Pooltype Dispatcher struct &#123; WorkerPool chan chan Job&#125;func NewDispatcher(maxWorkers int) *Dispatcher &#123; pool := make(chan chan Job, maxWorkers) return &amp;Dispatcher&#123;WorkerPool: pool&#125;&#125;func (d *Dispatcher) Run() &#123; // starting n number of workers for i := 0; i &lt; d.maxWorkers; i++ &#123; worker := NewWorker(d.pool) worker.Start() &#125; go d.dispatch()&#125;// 4.1 将任务从 JobQueue 放入到 Woker Pool 中某一个 Workder 的 JobChannel 中，来调用 Workerfunc (d *Dispatcher) dispatch() &#123; for &#123; select &#123; case job := &lt;-JobQueue: // a job request has been received go func(job Job) &#123; // try to obtain a worker job channel that is available. // this will block until a worker is idle jobChannel := &lt;-d.WorkerPool // dispatch the job to the worker job channel jobChannel &lt;- job &#125;(job) &#125; &#125;&#125;// 5. 使用 Worker Poolfunc payloadHandler(w http.ResponseWriter, r *http.Request) &#123; for _, payload := range content.Payloads &#123; // let's create a job with the payload work := Job&#123;Payload: payload&#125; // Push the work onto the queue. JobQueue &lt;- work &#125;&#125; 3. 数据传递下面是一个数据传递(任务编排)的例子，让四个 goroutine 顺序打印 1,2,3,4 123456789101112131415161718192021222324type Token struct&#123;&#125;func newWorker(id int, ch chan Token, nextCh chan Token) &#123; for &#123; token := &lt;-ch // 取得令牌 fmt.Println((id + 1)) // id从1开始 time.Sleep(time.Second) nextCh &lt;- token &#125;&#125;func main() &#123; chs := []chan Token&#123;make(chan Token), make(chan Token), make(chan Token), make(chan Token)&#125; // 创建4个worker for i := 0; i &lt; 4; i++ &#123; go newWorker(i, chs[i], chs[(i+1)%4]) &#125; //首先把令牌交给第一个worker chs[0] &lt;- struct&#123;&#125;&#123;&#125; select &#123;&#125;&#125; 这类场景有一个特点，就是当前持有数据的 goroutine 都有一个信箱，信箱使用 chan 实现，goroutine 只需要关注自己的信箱中的数据，处理完毕后，就把结果发送到下一家的信箱中。 4. 信号通知chan 类型有这样一个特点：chan 如果为空，那么，receiver 接收数据的时候就会阻塞等待，直到 chan 被关闭或者有新的数据到来。利用这个机制，我们可以实现 wait/notify 的设计模式。 除了正常的业务处理时的 wait/notify，我们经常碰到的一个场景，就是程序关闭的时候，我们需要在退出之前做一些清理（doCleanup 方法）的动作。这个时候，我们经常要使用 chan。 比如，使用 chan 实现程序的 graceful shutdown，在退出之前执行一些连接关闭、文件 close、缓存落盘等一些动作。 123456789101112131415func main() &#123; go func() &#123; ...... // 执行业务处理 &#125;() // 处理CTRL+C等中断信号 termChan := make(chan os.Signal) signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) &lt;-termChan // 执行退出之前的清理动作 doCleanup() fmt.Println("优雅退出")&#125; 有时候，doCleanup 可能是一个很耗时的操作，我们需要设置一个最长的等待时间。只要超过了这个时间，程序就不再等待，可以直接退出。所以，退出的时候分为两个阶段： closing，代表程序退出，但是清理工作还没做； closed，代表清理工作已经做完。 123456789101112131415161718192021222324252627282930313233343536373839func main() &#123; var closing = make(chan struct&#123;&#125;) var closed = make(chan struct&#123;&#125;) go func() &#123; // 模拟业务处理 for &#123; select &#123; case &lt;-closing: return default: // ....... 业务计算 time.Sleep(100 * time.Millisecond) &#125; &#125; &#125;() // 处理CTRL+C等中断信号 termChan := make(chan os.Signal) signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM) &lt;-termChan close(closing) // 执行退出之前的清理动作 go doCleanup(closed) select &#123; case &lt;-closed: case &lt;-time.After(time.Second): fmt.Println("清理超时，不等了") &#125; fmt.Println("优雅退出")&#125;func doCleanup(closed chan struct&#123;&#125;) &#123; time.Sleep((time.Minute)) close(closed)&#125; 5. 锁使用 chan 也可以实现互斥锁。在 chan 的内部实现中，就有一把互斥锁保护着它的所有字段。从外在表现上，chan 的发送和接收之间也存在着 happens-before 的关系，保证元素放进去之后，receiver 才能读取到。 要想使用 chan 实现互斥锁，至少有两种方式。一种方式是先初始化一个 capacity 等于 1 的 Channel，然后再放入一个元素。这个元素就代表锁，谁取得了这个元素，就相当于获取了这把锁。另一种方式是，先初始化一个 capacity 等于 1 的 Channel，它的“空槽”代表锁，谁能成功地把元素发送到这个 Channel，谁就获取了这把锁。 我们以第一种为例实现一个锁: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 使用chan实现互斥锁type Mutex struct &#123; ch chan struct&#123;&#125;&#125;// 使用锁需要初始化func NewMutex() *Mutex &#123; mu := &amp;Mutex&#123;make(chan struct&#123;&#125;, 1)&#125; mu.ch &lt;- struct&#123;&#125;&#123;&#125; return mu&#125;// 请求锁，直到获取到func (m *Mutex) Lock() &#123; &lt;-m.ch&#125;// 解锁func (m *Mutex) Unlock() &#123; select &#123; case m.ch &lt;- struct&#123;&#125;&#123;&#125;: default: panic("unlock of unlocked mutex") &#125;&#125;// 尝试获取锁func (m *Mutex) TryLock() bool &#123; select &#123; case &lt;-m.ch: return true default: &#125; return false&#125;// 加入一个超时的设置func (m *Mutex) LockTimeout(timeout time.Duration) bool &#123; timer := time.NewTimer(timeout) select &#123; case &lt;-m.ch: timer.Stop() return true case &lt;-timer.C: &#125; return false&#125;// 锁是否已被持有func (m *Mutex) IsLocked() bool &#123; return len(m.ch) == 0&#125;func main() &#123; m := NewMutex() ok := m.TryLock() fmt.Printf("locked v %v\n", ok) ok = m.TryLock() fmt.Printf("locked %v\n", ok)&#125; 6. 任务编排消息交流的场景是一个特殊的任务编排的场景： 前面我们介绍的顺序答应1,2,3,4 s 也被称为流水线模式 WaitGroup 可以实现等待模式，Channel 也可以实现这种等待模式 任务编排既指安排 goroutine 按照指定的顺序执行，也指多个 chan 按照指定的方式组合处理的方式。我们通过编排数据在 channel 之间的流转，就可以控制 goroutine 的执行。接下来我们着重介绍 channel 编排的五种典型模式L Or-Done 扇入 扇出 Stream map-reduce 6.1 Or-Done 模式Or-Done 模式是信号通知模式中更宽泛的一种模式。我们会使用“信号通知”实现某个任务执行完成后的通知机制，在实现时: 我们为这个任务定义一个类型为 chan struct{}类型的 done 变量 等任务结束后，我们就可以 close 这个变量，然后，其它 receiver 就会收到这个通知。 这是有一个任务的情况，如果有多个任务，只要有任意一个任务执行完，我们就想获得这个信号，这就是 Or-Done 模式。比如发送同一个请求到多个微服务节点，只要任意一个微服务返回结果就算成功。下面是Or-Done 的一个实现: 12345678910111213141516171819202122232425262728293031func or(channels ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; // 特殊情况，只有零个或者1个chan switch len(channels) &#123; case 0: return nil case 1: return channels[0] &#125; orDone := make(chan interface&#123;&#125;) go func() &#123; defer close(orDone) switch len(channels) &#123; case 2: // 2个也是一种特殊情况 select &#123; case &lt;-channels[0]: case &lt;-channels[1]: &#125; default: //超过两个，二分法递归处理 m := len(channels) / 2 select &#123; case &lt;-or(channels[:m]...): case &lt;-or(channels[m:]...): &#125; &#125; &#125;() return orDone&#125; 这里的实现使用了一个巧妙的方式，当 chan 的数量大于 2 时，使用递归的方式等待信号。在 chan 数量比较多的情况下，递归并不是一个很好的解决方式，根据这一讲最开始介绍的反射的方法，我们也可以实现 Or-Done 模式： 1234567891011121314151617181920212223242526272829func or(channels ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; //特殊情况，只有0个或者1个 switch len(channels) &#123; case 0: return nil case 1: return channels[0] &#125; orDone := make(chan interface&#123;&#125;) go func() &#123; defer close(orDone) // 利用反射构建SelectCase var cases []reflect.SelectCase for _, c := range channels &#123; cases = append(cases, reflect.SelectCase&#123; Dir: reflect.SelectRecv, Chan: reflect.ValueOf(c), &#125;) &#125; // 随机选择一个可用的case reflect.Select(cases) &#125;() return orDone&#125; 6.2 扇入Channel 扇入模式来说，是指有多个源 Channel 输入、一个目的 Channel 输出的情况。每个源 Channel 的元素都会发送给目标 Channel，相当于目标 Channel 的 receiver 只需要监听目标 Channel，就可以接收所有发送给源 Channel 的数据。 扇入模式也可以使用反射、递归，或者是用最笨的每个 goroutine 处理一个 Channel 的方式来实现。 反射实现1234567891011121314151617181920212223242526func fanInReflect(chans ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; out := make(chan interface&#123;&#125;) go func() &#123; defer close(out) // 构造SelectCase slice var cases []reflect.SelectCase for _, c := range chans &#123; cases = append(cases, reflect.SelectCase&#123; Dir: reflect.SelectRecv, Chan: reflect.ValueOf(c), &#125;) &#125; // 循环，从cases中选择一个可用的 for len(cases) &gt; 0 &#123; i, v, ok := reflect.Select(cases) if !ok &#123; // 此channel已经close cases = append(cases[:i], cases[i+1:]...) continue &#125; out &lt;- v.Interface() &#125; &#125;() return out&#125; 递归实现12345678910111213141516171819202122232425262728293031323334353637383940414243func fanInRec(chans ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; switch len(chans) &#123; case 0: c := make(chan interface&#123;&#125;) close(c) return c case 1: return chans[0] case 2: return mergeTwo(chans[0], chans[1]) default: m := len(chans) / 2 return mergeTwo( fanInRec(chans[:m]...), fanInRec(chans[m:]...)) &#125;&#125;func mergeTwo(a, b &lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; c := make(chan interface&#123;&#125;) go func() &#123; defer close(c) for a != nil || b != nil &#123; //只要还有可读的chan select &#123; case v, ok := &lt;-a: if !ok &#123; // a 已关闭，设置为nil a = nil continue &#125; c &lt;- v case v, ok := &lt;-b: if !ok &#123; // b 已关闭，设置为nil b = nil continue &#125; c &lt;- v &#125; &#125; &#125;() return c&#125; 6.3 扇出扇出模式只有一个输入源 Channel，有多个目标 Channel，经常用在设计模式中的观察者模式中，将一个一个对象的状态变化通知到多个观察者中。扇入模式也可以使用反射、递归，或者是用最笨的每个 goroutine 处理一个 Channel 的方式来实现。 反射实现123456789101112131415161718192021222324func fanOut(ch &lt;-chan interface&#123;&#125;, out []chan interface&#123;&#125;, async bool) &#123; go func() &#123; defer func() &#123; //退出时关闭所有的输出chan for i := 0; i &lt; len(out); i++ &#123; close(out[i]) &#125; &#125;() for v := range ch &#123; // 从输入chan中读取数据 v := v for i := 0; i &lt; len(out); i++ &#123; i := i if async &#123; //异步 go func() &#123; out[i] &lt;- v // 放入到输出chan中,异步方式 &#125;() &#125; else &#123; out[i] &lt;- v // 放入到输出chan中，同步方式 &#125; &#125; &#125; &#125;()&#125; 递归实现123456789101112131415161718192021222324252627282930```### 6.4 Stream把 Channel 当作流式管道使用，提供跳过几个元素，或者是只取其中的几个元素等方法。在下面的实现中，我们首先创建流，然后为流定义以下方法:1. takeN：只取流中的前 n 个数据；2. takeFn：筛选流中的数据，只保留满足条件的数据；3. takeWhile：只取前面满足条件的数据，一旦不满足条件，就不再取；4. skipN：跳过流中前几个数据；5. skipFn：跳过满足条件的数据；6. skipWhile：跳过前面满足条件的数据，一旦不满足条件，当前这个元素和以后的元素都会输出给 Channel 的 receiver。这些方法的实现很类似，我们以 takeN 为例。#### 创建流```gofunc asStream(done &lt;-chan struct&#123;&#125;, values ...interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; s := make(chan interface&#123;&#125;) //创建一个unbuffered的channel go func() &#123; // 启动一个goroutine，往s中塞数据 defer close(s) // 退出时关闭chan for _, v := range values &#123; // 遍历数组 select &#123; case &lt;-done: return case s &lt;- v: // 将数组元素塞入到chan中 &#125; &#125; &#125;() return s&#125; 流上的方法123456789101112131415func takeN(done &lt;-chan struct&#123;&#125;, valueStream &lt;-chan interface&#123;&#125;, num int) &lt;-chan interface&#123;&#125; &#123; takeStream := make(chan interface&#123;&#125;) // 创建输出流 go func() &#123; defer close(takeStream) for i := 0; i &lt; num; i++ &#123; // 只读取前num个元素 select &#123; case &lt;-done: return case takeStream &lt;- &lt;-valueStream: //从输入流中读取元素 &#125; &#125; &#125;() return takeStream&#125; 6.5 map-reduce这里我们要讲的是单机单进程的 map-reduce 方法。map-reduce 分为两个步骤，第一步是映射（map），处理队列中的数据，第二步是规约（reduce），把列表中的每一个元素按照一定的处理方式处理成结果，放入到结果队列中。 map1234567891011121314151617func mapChan(in &lt;-chan interface&#123;&#125;, fn func(interface&#123;&#125;) interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; out := make(chan interface&#123;&#125;) //创建一个输出chan if in == nil &#123; // 异常检查 close(out) return out &#125; go func() &#123; // 启动一个goroutine,实现map的主要逻辑 defer close(out) for v := range in &#123; // 从输入chan读取数据，执行业务操作，也就是map操作 out &lt;- fn(v) &#125; &#125;() return out&#125; reduce12345678910111213func reduce(in &lt;-chan interface&#123;&#125;, fn func(r, v interface&#123;&#125;) interface&#123;&#125;) interface&#123;&#125; &#123; if in == nil &#123; // 异常检查 return nil &#125; out := &lt;-in // 先读取第一个元素 for v := range in &#123; // 实现reduce的主要逻辑 out = fn(out, v) &#125; return out&#125; 应用12345678910111213141516171819202122232425262728293031323334// 生成一个数据流func asStream(done &lt;-chan struct&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; s := make(chan interface&#123;&#125;) values := []int&#123;1, 2, 3, 4, 5&#125; go func() &#123; defer close(s) for _, v := range values &#123; // 从数组生成 select &#123; case &lt;-done: return case s &lt;- v: &#125; &#125; &#125;() return s&#125;func main() &#123; in := asStream(nil) // map操作: 乘以10 mapFn := func(v interface&#123;&#125;) interface&#123;&#125; &#123; return v.(int) * 10 &#125; // reduce操作: 对map的结果进行累加 reduceFn := func(r, v interface&#123;&#125;) interface&#123;&#125; &#123; return r.(int) + v.(int) &#125; sum := reduce(mapChan(in, mapFn), reduceFn) //返回累加结果 fmt.Println(sum)&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 Context]]></title>
    <url>%2F2019%2F02%2F11%2Fgo%2Fgo_sync%2Fgo_sync_11%2F</url>
    <content type="text"><![CDATA[Context 上下文管理器 1. Context 概述所谓上下文指的是在 API 之间或者方法调用之间，所传递的除了业务参数之外的额外信息，比如服务追踪。Go 标准库中的 Context 不仅仅传递上下文信息还提供了超时（Timeout）和取消（Cancel）的机制。 1.1 Context 来历最初提供了 golang.org/x/net/context 库用来提供上下文信息，Go 在 1.7 的版本中才正式把 Context 加入到标准库中。 Go 1.7 发布之后，出现了标准库 Context 和 golang.org/x/net/context 并存的状况。新的代码使用标准库 Context 的时候，没有办法使用这个标准库的 Context 去调用旧有的使用 x/net/context 实现的方法。 所以，在 Go1.9 中，还专门实现了一个叫做 type alias 的新特性，然后把 x/net/context 中的 Context 定义成标准库 Context 的别名，以解决新旧 Context 类型冲突问题 12345678// +build go1.9package contextimport "context"type Context = context.Contexttype CancelFunc = context.CancelFunc 1.2 Context 的问题Context 包含了太多了功能，导致它也出现了一些争议: Go 布道师 Dave Cheney 还专门写了一篇文章讲述这个问题：Context isn’t for cancellation 有批评者专门写了一篇文章 Context should go away for Go 2 Go 核心开发者 Ian Lance Taylor 专门开了一个issue 28342，用来记录当前的 Context 的问题： Context 包名导致使用的时候重复 ctx context.Context； Context.WithValue 可以接受任何类型的值，非类型安全； Context 包名容易误导人，实际上，Context 最主要的功能是取消 goroutine 的执行； Context 漫天飞，函数污染。 1.3 Context 适用场景尽管有很多的争议，但是，在很多场景下，使用 Context 其实会很方便，比如下面这些场景: 上下文信息传递 （request-scoped），比如处理 http 请求、在请求处理链路上传递信息； 控制子 goroutine 的运行； 超时控制的方法调用； 可以取消的方法调用。 2. Context 使用2.1 接口定义包 context 定义了 Context 接口，Context 的具体实现包括 4 个方法，分别是 Deadline、Done、Err 和 Value，如下所示： 123456type Context interface &#123; Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct&#123;&#125; Err() error Value(key interface&#123;&#125;) interface&#123;&#125;&#125; Deadline 方法 返回这个 Context 被取消的截止日期。如果没有设置截止日期，ok 的值是 false 后续每次调用这个对象的 Deadline 方法时，都会返回和第一次调用相同的结果 Done 方法 返回一个 Channel 对象 在 Context 被取消时，此 Channel 会被 close，如果没被取消，可能会返回 nil 后续的 Done 调用总是返回相同的结果。当 Done 被 close 的时候，你可以通过 ctx.Err 获取错误信息。 即: 如果 Done 没有被 close，Err 方法返回 nil；如果 Done 被 close，Err 方法会返回 Done 被 close 的原因。 Value 返回此 ctx 中和指定的 key 相关联的 value 2.2 生成函数Context 中实现了 2 个常用的生成顶层 Context 的方法。 context.Background()： 返回一个非 nil 的、空的 Context，没有任何值，不会被 cancel，不会超时，没有截止日期 一般用在主函数、初始化、测试以及创建根 Context 的时候 context.TODO()： 返回一个非 nil 的、空的 Context，没有任何值，不会被 cancel，不会超时，没有截止日期 当你不清楚是否该用 Context，或者目前还不知道要传递一些什么上下文信息的时候，就可以使用这个方法 其实，你根本不用费脑子去考虑，可以直接使用 context.Background。事实上，它们两个底层的实现是一模一样的： 12345678910111213var ( background = new(emptyCtx) todo = new(emptyCtx))func Background() Context &#123; return background&#125;func TODO() Context &#123; return todo&#125; 2.3 使用约定在使用 Context 的时候，有一些约定俗成的规则: 一般函数使用 Context 的时候，会把这个参数放在第一个参数的位置。 从来不把 nil 当做 Context 类型的参数值，可以使用 context.Background() 创建一个空的上下文对象，也不要使用 nil。 Context 只用来临时做函数之间的上下文透传，不能持久化 Context 或者把 Context 长久保存。把 Context 持久化到数据库、本地文件或者全局变量、缓存中都是错误的用法。 key 的类型不应该是字符串类型或者其它内建类型，否则容易在包之间使用 Context 时候产生冲突。使用 WithValue 时，key 的类型应该是自己定义的类型。 常常使用 struct{}作为底层类型定义 key 的类型。对于 exported key 的静态类型，常常是接口或者指针。这样可以尽量减少内存分配。 如果你能保证别人使用你的 Context 时不会和你定义的 key 冲突，那么 key 的类型就比较随意，因为你自己保证了不同包的 key 不会冲突，否则建议你尽量采用保守的 unexported 的类型。 Context 包中有几种创建特殊用途 Context 的方法：WithValue、WithCancel、WithTimeout 和 WithDeadline，包括它们的功能以及实现方式。 2.4 WithValueWithValue 基于 parent Context 生成一个新的 Context，保存了一个 key-value 键值对。它常常用来传递上下文。WithValue 方法其实是创建了一个类型为 valueCtx 的 Context，它的类型定义如下： 1234type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125; 它覆盖了 Value 方法，优先从自己的存储中检查这个 key，不存在的话会从 parent 中继续检查。Go 标准库实现的 Context 还实现了链式查找。如果不存在，还会向 parent Context 去查找，如果 parent 还是 valueCtx 的话，还是遵循相同的原则：valueCtx 会嵌入 parent，所以还是会查找 parent 的 Value 方法的。 12345678ctx = context.TODO()ctx = context.WithValue(ctx, "key1", "0001")ctx = context.WithValue(ctx, "key2", "0001")ctx = context.WithValue(ctx, "key3", "0001")ctx = context.WithValue(ctx, "key4", "0004")fmt.Println(ctx.Value("key1")) 2.5 WithCancelWithCancel 方法返回 parent 的副本，只是副本中的 Done Channel 是新建的对象，它的类型是 cancelCtx。返回值中的第二个值是一个 cancel 函数。 我们常常在一些需要主动取消长时间的任务时，创建这种类型的 Context，然后把这个 Context 传给长时间执行任务的 goroutine。当需要中止任务时，我们就可以 cancel 这个 Context，长时间执行任务的 goroutine，就可以通过检查这个 Context，知道 Context 已经被取消了。 记住，不是只有你想中途放弃，才去调用 cancel，只要你的任务正常完成了，就需要调用 cancel，这样，这个 Context 才能释放它的资源（通知它的 children 处理 cancel，从它的 parent 中把自己移除，甚至释放相关的 goroutine）。很多同学在使用这个方法的时候，都会忘记调用 cancel，切记切记，而且一定尽早释放。 1234567891011func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; c := newCancelCtx(parent) propagateCancel(parent, &amp;c)// 把c朝上传播 return &amp;c, func() &#123; c.cancel(true, Canceled) &#125;&#125;// newCancelCtx returns an initialized cancelCtx.func newCancelCtx(parent Context) cancelCtx &#123; return cancelCtx&#123;Context: parent&#125;&#125; propagateCancel 方法会顺着 parent 路径往上找，直到找到一个 cancelCtx，或者为 nil。如果不为空，就把自己加入到这个 cancelCtx 的 child，以便这个 cancelCtx 被取消的时候通知自己。如果为空，会新起一个 goroutine，由它来监听 parent 的 Done 是否已关闭。 当这个 cancelCtx 的 cancel 函数被调用的时候，或者 parent 的 Done 被 close 的时候，这个 cancelCtx 的 Done 才会被 close。 cancel 是向下传递的，如果一个 WithCancel 生成的 Context 被 cancel 时，如果它的子 Context（也有可能是孙，或者更低，依赖子的类型）也是 cancelCtx 类型的，就会被 cancel，但是不会向上传递。parent Context 不会因为子 Context 被 cancel 而 cancel。cancelCtx 被取消时，它的 Err 字段就是下面这个 Canceled 错误： 12var Canceled = errors.New("context canceled") 2.6 WithTimeout/WithDeadlineWithTimeout 其实是和 WithDeadline 一样，只不过一个参数是超时时间，一个参数是截止时间。 1234func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; // 当前时间+timeout就是deadline return WithDeadline(parent, time.Now().Add(timeout))&#125; WithDeadline 会返回一个 parent 的副本，并且设置了一个不晚于参数 d 的截止时间，类型为 timerCtx（或者是 cancelCtx）。 如果它的截止时间晚于 parent 的截止时间，那么就以 parent 的截止时间为准，并返回一个类型为 cancelCtx 的 Context，因为 parent 的截止时间到了，就会取消这个 cancelCtx。 如果当前时间已经超过了截止时间，就直接返回一个已经被 cancel 的 timerCtx。否则就会启动一个定时器，到截止时间取消这个 timerCtx。 综合起来，timerCtx 的 Done 被 Close 掉，主要是由下面的某个事件触发的： 截止时间到了； cancel 函数被调用； parent 的 Done 被 close。 1234567891011121314151617181920212223242526func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; // 如果parent的截止时间更早，直接返回一个cancelCtx即可 if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; propagateCancel(parent, c) // 同cancelCtx的处理逻辑 dur := time.Until(d) if dur &lt;= 0 &#123; //当前时间已经超过了截止时间，直接cancel c.cancel(true, DeadlineExceeded) return c, func() &#123; c.cancel(false, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; // 设置一个定时器，到截止时间后取消 c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125; 和 cancelCtx 一样，WithDeadline（WithTimeout）返回的 cancel 一定要调用，并且要尽可能早地被调用，这样才能尽早释放资源。，不要单纯地依赖截止时间被动取消。 123456func slowOperationWithTimeout(ctx context.Context) (Result, error) &#123; ctx, cancel := context.WithTimeout(ctx, 100*time.Millisecond) defer cancel() // 一旦慢操作完成就立马调用cancel return slowOperation(ctx)&#125; 如果你要为 Context 实现一个带超时功能的调用，比如访问远程的一个微服务，超时并不意味着你会通知远程微服务已经取消了这次调用，大概率的实现只是避免客户端的长时间等待，远程的服务器依然还执行着你的请求。 所以，有时候，Context 并不会减少对服务器的请求负担。如果在 Context 被 cancel 的时候，你能关闭和服务器的连接，中断和数据库服务器的通讯、停止对本地文件的读写，那么，这样的超时处理，同时能减少对服务调用的压力，但是这依赖于你对超时的底层处理机制。 3. Context 采坑点4. Context 的扩展]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 Pool]]></title>
    <url>%2F2019%2F02%2F10%2Fgo%2Fgo_sync%2Fgo_sync_10%2F</url>
    <content type="text"><![CDATA[Pool 1. Pool 概述Go 是一个自动垃圾回收的编程语言，采用三色并发标记算法标记对象并回收。但是，如果你想使用 Go 开发一个高性能的应用程序的话，就必须考虑垃圾回收给性能带来的影响。对象池化， 可以有效地减少新对象的创建次数，是性能优化的重要方式。 Go 标准库中提供了一个通用的 Pool 数据结构，也就是 sync.Pool，我们使用它可以创建池化的对象。sync.Pool 有一个缺陷，就是它池化的对象可能会被垃圾回收掉，这对于数据库长连接等场景是不合适的。因此接下来我们将介绍: sync.Pool 的使用、实现和采坑点 其他 Pool 包括 TCP 连接池、数据库连接池 Worker Pool: goroutine pool，使用有限的 goroutine 资源去处理大量的业务数据 如果你发现程序中有一种 GC 耗时特别高，有大量的相同类型的临时对象，不断地被创建销毁，这时，你就可以考虑看看，是不是可以通过池化的手段重用这些对象。 1.1 sync.Pool 使用sync.Pool 用来保存一组可独立访问的临时对象，临时两个字表明”它池化的对象会在未来的某个时候被毫无预兆地移除掉”。如果没有别的对象引用这个被移除的对象的话，这个被移除的对象就会被垃圾回收掉。 sync.Pool 有两个知识点需要记住: sync.Pool 本身就是线程安全的，多个 goroutine 可以并发地调用它的方法存取对象； sync.Pool 使用之后不可再复制使用 sync.Pool 只提供了三个对外方法: New 字段: 类型为func() interface{} 当 Get 方法从池中获取元素，没有更多空闲元素可返回时，就会调用 New 方法来创建新的元素。 如果你没有设置 New 字段，没有更多的空闲元素可返回时，Get 方法将返回 nil，表明当前没有可用的元素 New 是可变的字段，这意味着可以在程序运行的时候改变创建元素的方法，但是没必要这么做 Get 方法: 调用这个方法，就会从 Pool取走一个元素(从 Pool 中移除)，并返回给调用者 除了正常实例化的元素，Get 方法的返回值还可能会是一个 nil（Pool.New 字段没有设置，又没有空闲元素可以返回），使用时需要判断 Put 方法: 用于将一个元素返还给 Pool，Pool 会把这个元素保存到池中，并且可以复用 如果 Put 一个 nil 值，Pool 就会忽略这个值 1234567891011121314151617type Pool struct &#123; noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface&#123;&#125;&#125;func (p *Pool) Put(x interface&#123;&#125;) &#123;&#125;func (p *Pool) Get() interface&#123;&#125; &#123;&#125; 下面是 sync.Pool 实现的 buffer 池(缓冲池)。注意下面这段代码是有问题的，你一定不要将这段代码应用到实际的产品中，它可能会有内存泄漏的问题。 12345678910111213141516import bytesvar buffers = sync.Pool&#123; New: func() interface&#123;&#125; &#123; return new(bytes.Buffer) &#125;&#125;func GetBuffer() *bytes.Buffer &#123; return buffers.Get().(*bytes.Buffer)&#125;func PutBuffer(* bytes.Buffer)&#123; buf.Reset() buffer.Put(buf)&#125; 2. Pool 实现Go 1.13 之前的 sync.Pool 的实现有 2 大问题： 每次 GC 都会回收创建的对象: 如果缓存元素数量太多，就会导致 STW 耗时变长；缓存元素都被回收后，会导致 Get 命中率下降，Get 方法不得不新创建很多对象。 底层实现使用了 Mutex，对这个锁并发请求竞争激烈的时候，会导致性能的下降 在 Go 1.13 中，sync.Pool 做了大量的优化。优化的方式就是避免使用锁，同时将加锁的 queue 改成 lock-free 的 queue 的实现，给即将移除的元素再多一次“复活”的机会。sync.Pool 的数据结构如下图所示： Pool 实现中: 每次垃圾回收的时候，Pool 会把 victim 中的对象移除，然后把 local 的数据给 victim victim 就像一个垃圾分拣站，里面的东西可能会被当做垃圾丢弃了，但是里面有用的东西也可能被捡回来重新使用 victim 中的元素如果被 Get 取走，他就会被重用；没有被 Get 取走，那么就会被移除掉，因为没有别人引用它的话，就会被垃圾回收掉 2.1 Pool 的垃圾回收下面的代码是垃圾回收时 sync.Pool 的处理逻辑： 123456789101112131415161718func poolCleanup() &#123; // 丢弃当前victim, STW所以不用加锁 for _, p := range oldPools &#123; p.victim = nil p.victimSize = 0 &#125; // 将local复制给victim, 并将原local置为nil for _, p := range allPools &#123; p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 &#125; oldPools, allPools = allPools, nil&#125; 2.2 locallocal 字段包含一个 poolLocalInternal 字段，并提供 CPU 缓存对齐，从而避免 false sharing。而 poolLocalInternal 也包含两个字段：private 和 shared。 private，代表一个缓存的元素，而且只能由相应的一个 P 存取。因为一个 P 同时只能执行一个 goroutine，所以不会有并发的问题。 shared，可以由任意的 P 访问，但是只有本地的 P 才能 pushHead/popHead，其它 P 可以 popTail，相当于只有一个本地的 P 作为生产者（Producer），多个 P 作为消费者（Consumer），它是使用一个 local-free 的 queue 列表实现的。 2.3 Get 方法1234567891011121314151617181920func (p *Pool) Get() interface&#123;&#125; &#123; // 把当前goroutine固定在当前的P上 l, pid := p.pin() x := l.private // 1. 优先从local的private字段取，快速 l.private = nil if x == nil &#123; // 2. 从当前的local.shared弹出一个，注意是从head读取并移除 x, _ = l.shared.popHead() if x == nil &#123; // 3. 如果没有，则去偷一个 x = p.getSlow(pid) &#125; &#125; runtime_procUnpin() // 如果没有获取到，尝试使用New函数生成一个新的 if x == nil &amp;&amp; p.New != nil &#123; x = p.New() &#125; return x&#125; 这里的重点是 getSlow 方法，它首先要遍历所有的 local，尝试从它们的 shared 弹出一个元素。如果还没找到一个，那么，就开始对 victim 下手了。在 vintim 中查询可用元素的逻辑还是一样的，先从对应的 victim 的 private 查找，如果查不到，就再从其它 victim 的 shared 中查找。 123456789101112131415161718192021222324252627282930313233343536func (p *Pool) getSlow(pid int) interface&#123;&#125; &#123; size := atomic.LoadUintptr(&amp;p.localSize) locals := p.local // 从其它proc中尝试偷取一个元素 for i := 0; i &lt; int(size); i++ &#123; l := indexLocal(locals, (pid+i+1)%int(size)) if x, _ := l.shared.popTail(); x != nil &#123; return x &#125; &#125; // 如果其它proc也没有可用元素，那么尝试从vintim中获取 size = atomic.LoadUintptr(&amp;p.victimSize) if uintptr(pid) &gt;= size &#123; return nil &#125; locals = p.victim l := indexLocal(locals, pid) if x := l.private; x != nil &#123; // 同样的逻辑，先从vintim中的local private获取 l.private = nil return x &#125; for i := 0; i &lt; int(size); i++ &#123; // 从vintim其它proc尝试偷取 l := indexLocal(locals, (pid+i)%int(size)) if x, _ := l.shared.popTail(); x != nil &#123; return x &#125; &#125; // 如果victim中都没有，则把这个victim标记为空，以后的查找可以快速跳过了 atomic.StoreUintptr(&amp;p.victimSize, 0) return nil&#125; 这里没列出 pin 代码的实现，你只需要知道，pin 方法会将此 goroutine 固定在当前的 P 上，避免查找元素期间被其它的 P 执行。固定的好处就是查找元素期间直接得到跟这个 P 相关的 local。有一点需要注意的是，pin 方法在执行的时候，如果跟这个 P 相关的 local 还没有创建，或者运行时 P 的数量被修改了的话，就会新创建 local。 2.4 Put 方法123456789101112131415func (p *Pool) Put(x interface&#123;&#125;) &#123; if x == nil &#123; // nil值直接丢弃 return &#125; l, _ := p.pin() if l.private == nil &#123; // 如果本地private没有值，直接设置这个值即可 l.private = x x = nil &#125; if x != nil &#123; // 否则加入到本地队列中 l.shared.pushHead(x) &#125; runtime_procUnpin()&#125; Put 的逻辑相对简单，优先设置本地 private，如果 private 字段已经有值了，那么就把此元素 push 到本地队列中。 3. Pool 采坑点使用 Once 有两个常见错误:分别是内存泄漏和内存浪费。 3.1 内存泄漏文章开始，我们用 sync.Pool 实现了一个 buffer pool，这个实现可能存在内存泄漏。取出来的 bytes.Buffer 在使用的时候，我们可以往这个元素中增加大量的 byte 数据，这会导致底层的 byte slice 的容量可能会变得很大。这个时候，即使 Reset 再放回到池子中，这些 byte slice 的容量不会改变，所占的空间依然很大。而且，因为 Pool 回收的机制，这些大的 Buffer 可能不被回收(被重复使用，但只使用了很小一部分)，而是会一直占用很大的空间，这属于内存泄漏的问题。 在使用 sync.Pool 回收 buffer 的时候，一定要检查回收的对象的大小。如果 buffer 太大，就不要回收了，否则就太浪费了。 3.2 内存浪费除了内存泄漏以外，还有一种浪费的情况，就是池子中的 buffer 都比较大，但在实际使用的时候，很多时候只需要一个小的 buffer，这也是一种浪费现象。 要做到物尽其用，尽可能不浪费的话，我们可以将 buffer 池分成几层，比如分成 512byte，1k，2k，4k 的多层 buffer 池。获取 buffer 时根据需要，到所需大小的池子中获取 buffer 即可。在标准库 net/http/server.go中的代码中，就提供了 2K 和 4K 两个 writer 的池子。 YouTube 开源的知名项目 vitess 中提供了bucketpool的实现，它提供了更加通用的多层 buffer 池。你在使用的时候，只需要指定池子的最大和最小尺寸，vitess 就会自动计算出合适的池子数。而且，当你调用 Get 方法的时候，只需要传入你要获取的 buffer 的大小，就可以了。 1234type Pool func New(minSize, maxSize int) *Pool func (p *Pool) Get(size int) *[]bytes func (p *Pool) Put(b *[]bytes) 4. buffer 的其他第三方库除了这种分层的为了节省空间的 buffer 设计外，还有其它的一些第三方的库也会提供 buffer 池的功能: bytebufferpool 基本功能和 sync.Pool 相同，它的底层也是使用 sync.Pool 实现的 包括会检测最大的 buffer，超过最大尺寸的 buffer，就会被丢弃 提供了校准（calibrate，用来动态调整创建元素的权重）的机制，可以“智能”地调整 Pool 的 defaultSize 和 maxSize 一般来说，我们使用 buffer size 的场景比较固定，所用 buffer 的大小会集中在某个范围里。有了校准的特性，bytebufferpool 就能够偏重于创建这个范围大小的 buffer，从而节省空间。 oxtoacart/bpool 提供了以下几种类型的 buffer: bpool.BufferPool： 提供一个固定元素数量的 buffer 池，元素类型是 bytes.Buffer 如果超过这个数量，Put 的时候就丢弃 如果池中的元素都被取光了，会新建一个返回 Put 回去的时候，不会检测 buffer 的大小 bpool.BytesPool： 提供一个固定元素数量的 byte slice 池，元素类型是 byte slice Put 回去的时候不检测 slice 的大小 bpool.SizedBufferPool： 提供一个固定元素数量的 buffer 池 如果超过这个数量，Put 的时候就丢弃 如果池中的元素都被取光了，会新建一个返回 Put 回去的时候，会检测 buffer 的大小，超过指定的大小的话，就会创建一个新的满足条件的 buffer 放回去 bpool 最大的特色就是能够保持池子中元素的数量，一旦 Put 的数量多于它的阈值，就会自动丢弃，而 sync.Pool 是一个没有限制的池子，只要 Put 就会收进去。bpool 是基于 Channel 实现的，不像 sync.Pool 为了提高性能而做了很多优化，所以，在性能上比不过 sync.Pool。 5. 连接池Pool 的另一个很常用的一个场景就是保持 TCP 的连接。我们很少会使用 sync.Pool 去池化连接对象，原因就在于，sync.Pool 会无通知地在某个时候就把连接移除垃圾回收掉了，而我们的场景是需要长久保持这个连接，所以，我们一般会使用其它方法来池化连接，包括: 标准库中的 http client 池 TCP 连接池 数据库连接池 Memcached Client 连接池 Worker Pool 5.1 标准库中的 http client 池标准库的 http.Client 是一个 http client 的库，可以用它来访问 web 服务器。http.Client 实现连接池的代码是在 Transport 类型中，它使用 idleConn 保存持久化的可重用的长连接： 5.2 TCP 连接池最常用的一个 TCP 连接池是 fatih 开发的fatih/pool。 123456789101112131415161718192021222324// 工厂模式，提供创建连接的工厂方法factory := func() (net.Conn, error) &#123; return net.Dial("tcp", "127.0.0.1:4000") &#125;// 创建一个tcp池，提供初始容量和最大容量以及工厂方法p, err := pool.NewChannelPool(5, 30, factory)// 获取一个连接conn, err := p.Get()// Close并不会真正关闭这个连接，而是把它放回池子，所以你不必显式地Put这个对象到池子中conn.Close()// 通过调用MarkUnusable, Close的时候就会真正关闭底层的tcp的连接了if pc, ok := conn.(*pool.PoolConn); ok &#123; pc.MarkUnusable() pc.Close()&#125;// 关闭池子就会关闭=池子中的所有的tcp连接p.Close()// 当前池子中的连接的数量current := p.Len() 虽说是 TCP，但是它管理的是更通用的 net.Conn，不局限于 TCP 连接。它通过把 net.Conn 包装成 PoolConn，实现了拦截 net.Conn 的 Close 方法，避免了真正地关闭底层连接，而是把这个连接放回到池中。 123456789101112131415161718192021 type PoolConn struct &#123; net.Conn mu sync.RWMutex c *channelPool unusable bool&#125; //拦截Closefunc (p *PoolConn) Close() error &#123; p.mu.RLock() defer p.mu.RUnlock() if p.unusable &#123; if p.Conn != nil &#123; return p.Conn.Close() &#125; return nil &#125; return p.c.put(p.Conn)&#125; 它的 Pool 是通过 Channel 实现的，空闲的连接放入到 Channel 中，这也是 Channel 的一个应用场景： 12345678910type channelPool struct &#123; // 存储连接池的channel mu sync.RWMutex conns chan net.Conn // net.Conn 的产生器 factory Factory &#125; 5.3 数据库连接池标准库 sql.DB 还提供了一个通用的数据库的连接池，通过 MaxOpenConns 和 MaxIdleConns 控制最大的连接数和最大的 idle 的连接数。默认的 MaxIdleConns 是 2，这个数对于数据库相关的应用来说太小了，我们一般都会调整它。 1234567891011121314151617181920212223type DB func Open(driverName, dataSourceName string) (*DB, error) func OpenDB(c driver.Connector) *DB func (db *DB) Begin() (*Tx, error) func (db *DB) BeginTx(ctx context.Context, opts *TxOptions) (*Tx, error) func (db *DB) Close() error func (db *DB) Conn(ctx context.Context) (*Conn, error) func (db *DB) Driver() driver.Driver func (db *DB) Exec(query string, args ...interface&#123;&#125;) (Result, error) func (db *DB) ExecContext(ctx context.Context, query string, args ...interface&#123;&#125;) (Result, error) func (db *DB) Ping() error func (db *DB) PingContext(ctx context.Context) error func (db *DB) Prepare(query string) (*Stmt, error) func (db *DB) PrepareContext(ctx context.Context, query string) (*Stmt, error) func (db *DB) Query(query string, args ...interface&#123;&#125;) (*Rows, error) func (db *DB) QueryContext(ctx context.Context, query string, args ...interface&#123;&#125;) (*Rows, error) func (db *DB) QueryRow(query string, args ...interface&#123;&#125;) *Row func (db *DB) QueryRowContext(ctx context.Context, query string, args ...interface&#123;&#125;) *Row func (db *DB) SetConnMaxIdleTime(d time.Duration) func (db *DB) SetConnMaxLifetime(d time.Duration) func (db *DB) SetMaxIdleConns(n int) func (db *DB) SetMaxOpenConns(n int) func (db *DB) Stats() DBStats DB 的 freeConn 保存了 idle 的连接，这样，当我们获取数据库连接的时候，它就会优先尝试从 freeConn 获取已有的连接（conn）。 5.4 Memcached Client 连接池Brad Fitzpatrick 是知名缓存库 Memcached 的原作者，gomemcache是他使用 Go 开发的 Memchaced 的客户端，其中也用了连接池。 gomemcache Client 有一个 freeconn 的字段，用来保存空闲的连接。当一个请求使用完之后，它会调用 putFreeConn 放回到池子中，请求的时候，调用 getFreeConn 优先查询 freeConn 中是否有可用的连接。它采用 Mutex+Slice 实现 Pool： 12345678910111213141516171819202122232425262728293031 // 放回一个待重用的连接 func (c *Client) putFreeConn(addr net.Addr, cn *conn) &#123; c.lk.Lock() defer c.lk.Unlock() if c.freeconn == nil &#123; // 如果对象为空，创建一个map对象 c.freeconn = make(map[string][]*conn) &#125; freelist := c.freeconn[addr.String()] //得到此地址的连接列表 if len(freelist) &gt;= c.maxIdleConns() &#123;//如果连接已满,关闭，不再放入 cn.nc.Close() return &#125; c.freeconn[addr.String()] = append(freelist, cn) // 加入到空闲列表中&#125; // 得到一个空闲连接func (c *Client) getFreeConn(addr net.Addr) (cn *conn, ok bool) &#123; c.lk.Lock() defer c.lk.Unlock() if c.freeconn == nil &#123; return nil, false &#125; freelist, ok := c.freeconn[addr.String()] if !ok || len(freelist) == 0 &#123; // 没有此地址的空闲列表，或者列表为空 return nil, false &#125; cn = freelist[len(freelist)-1] // 取出尾部的空闲连接 c.freeconn[addr.String()] = freelist[:len(freelist)-1] return cn, true&#125; 5.4 Worker Poolgoroutine 是一个很轻量级的“纤程”，一个 goroutine 初始的栈大小是 2048 个字节，并且在需要的时候可以扩展到 1GB(不同架构的配置)。 所以，大量的 goroutine 还是很耗资源的。同时，大量的 goroutine 对于调度和垃圾回收的耗时还是会有影响的，因此，goroutine 并不是越多越好。特别是在网络请求处理中，我们需要一个 Worker pool，即 goroutine 的池。由这一组 Worker 去处理连接，比如 fasthttp 中的Worker Pool。 大部分的 Worker Pool 都是通过 Channel 来缓存任务的，因为 Channel 能够比较方便地实现并发的保护，有的是多个 Worker 共享同一个任务 Channel，有些是每个 Worker 都有一个独立的 Channel。 下面三款比较常用的 Worker Pool 库: gammazero/workerpool：gammazero/workerpool 可以无限制地提交任务，提供了更便利的 Submit 和 SubmitWait 方法提交任务，还可以提供当前的 worker 数和任务数以及关闭 Pool 的功能。 ivpusic/grpool：grpool 创建 Pool 的时候需要提供 Worker 的数量和等待执行的任务的最大数量，任务的提交是直接往 Channel 放入任务。 dpaks/goworkers：dpaks/goworkers 提供了更便利的 Submi 方法提交任务以及 Worker 数、任务数等查询方法、关闭 Pool 的方法。它的任务的执行结果需要在 ResultChan 和 ErrChan 中去获取，没有提供阻塞的方法，但是它可以在初始化的时候设置 Worker 的数量和任务数。 类似的 Worker Pool 的实现非常多，比如还有panjf2000/ants、Jeffail/tunny 、benmanns/goworker、go-playground/pool、Sherifabdlnaby/gpool等第三方库。pond也是一个非常不错的 Worker Pool，关注度目前不是很高，但是功能非常齐全。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 线程安全的 map]]></title>
    <url>%2F2019%2F02%2F09%2Fgo%2Fgo_sync%2Fgo_sync_9%2F</url>
    <content type="text"><![CDATA[线程安全的 map 1. 线程安全的 map 概述1.1 map 的基本使用键类型Go 内建的 map 类型如下： 1map[K]V 其中，key 类型的 K 必须是可比较的（comparable），在 Go 语言中，bool、整数、浮点数、复数、字符串、指针、Channel、接口都是可比较的，包含可比较元素的 struct 和数组，这俩也是可比较的，而 slice、map、函数值都是不可比较的。通常情况下，我们会选择内建的基本类型，比如整数、字符串做 key 的类型，因为这样最方便。 这里有一点需要注意，如果使用 struct 类型做 key 其实是有坑的，因为如果 struct 的某个字段值修改了，查询 map 时无法获取它 add 进去的值，如下面的例子。如果要使用 struct 作为 key，我们要保证 struct 对象在逻辑上是不可变的，这样才会保证 map 的逻辑没有问题。 123456789101112131415161718type mapKey struct &#123; key int&#125;func main() &#123; var m = make(map[mapKey]string) var key = mapKey&#123;10&#125; m[key] = "hello" fmt.Printf("m[key]=%s\n", m[key]) // 修改key的字段的值后再次查询map，无法获取刚才add进去的值 key.key = 100 fmt.Printf("再次查询m[key]=%s\n", m[key])&#125; 索引返回值在 Go 中，map[key]函数返回结果可以是一个值，也可以是两个值。原因在于，如果获取一个不存在的 key 对应的值时，会返回零值。为了区分真正的零值和 key 不存在这两种情况，可以根据第二个返回值来区分 12345678910func main() &#123; var m = make(map[string]int) m["a"] = 0 fmt.Printf("a=%d; b=%d\n", m["a"], m["b"]) av, aexisted := m["a"] bv, bexisted := m["b"] fmt.Printf("a=%d, existed: %t; b=%d, existed: %t\n", av, aexisted, bv, bexisted)&#125; 遍历无序map 是无序的，如果我们想要保证遍历 map 时元素有序，可以使用辅助的数据结构，比如orderedmap。 常见错误map 最常犯的两个错误，就是未初始化和并发读写。 map 对象必须在使用之前初始化。如果不初始化就直接赋值的话，会出现 panic 异常。但是从一个 nil 的 map 对象中获取值不会 panic，而是会得到零值。map 作为一个 struct 字段的时候，就很容易忘记初始化了，这个要特别注意。 123456func main() &#123; var m map[int]int fmt.Println(m[100]) // 返回 0 m[100] = 100 // panic&#125; Go 内建的 map 对象不是线程（goroutine）安全的，并发读写的时候运行时会有检查，遇到并发问题就会导致 panic。解决方法就是实现一个线程安全的 map。 2. 线程安全 map 实现线程安全 map 有多种实现方式: 利用读写锁：map 对象的操作，分为读和写两类，其中，查询和遍历可以看做读操作，增加、修改和删除可以看做写操作。 分片加锁：降低加锁的粒度，具有更高的并发性 sync.Map: 适用于特殊场景 如何选择线程安全的 map，建议通过性能测试来决定。 2.1 加读写锁的 map12345678910111213141516171819202122232425262728293031323334353637383940414243444546type RWMap struct &#123; // 一个读写锁保护的线程安全的map sync.RWMutex // 读写锁保护下面的map字段 m map[int]int&#125;// 新建一个RWMapfunc NewRWMap(n int) *RWMap &#123; return &amp;RWMap&#123; m: make(map[int]int, n), &#125;&#125;func (m *RWMap) Get(k int) (int, bool) &#123; //从map中读取一个值 m.RLock() defer m.RUnlock() v, existed := m.m[k] // 在锁的保护下从map中读取 return v, existed&#125;func (m *RWMap) Set(k int, v int) &#123; // 设置一个键值对 m.Lock() // 锁保护 defer m.Unlock() m.m[k] = v&#125;func (m *RWMap) Delete(k int) &#123; //删除一个键 m.Lock() // 锁保护 defer m.Unlock() delete(m.m, k)&#125;func (m *RWMap) Len() int &#123; // map的长度 m.RLock() // 锁保护 defer m.RUnlock() return len(m.m)&#125;func (m *RWMap) Each(f func(k, v int) bool) &#123; // 遍历map m.RLock() //遍历期间一直持有读锁 defer m.RUnlock() for k, v := range m.m &#123; if !f(k, v) &#123; return &#125; &#125;&#125; 2.2 分片加锁虽然使用读写锁可以提供线程安全的 map，但是在大量并发读写的情况下，锁的竞争会非常激烈。在并发编程中，我们的一条原则就是尽量减少锁的使用。即尽量减少锁的粒度和锁的持有时间。你可以优化业务处理的代码，以此来减少锁的持有时间，比如将串行的操作变成并行的子任务执行。这是业务相关的优化，在线程安全 map 的实现上，重点是如何减少锁的粒度 减少锁的粒度常用的方法就是分片（Shard），将一把锁分成几把锁，每个锁控制一个分片。Go 比较知名的分片并发 map 的实现是orcaman/concurrent-map。其中 GetShard 是一个关键的方法，能够根据 key 计算出分片索引。 123456789101112131415161718192021222324252627282930313233343536373839404142434445var SHARD_COUNT = 32// 分成SHARD_COUNT个分片的maptype ConcurrentMap []*ConcurrentMapShared// 通过RWMutex保护的线程安全的分片，包含一个maptype ConcurrentMapShared struct &#123;items map[string]interface&#123;&#125;sync.RWMutex // Read Write mutex, guards access to internal map.&#125;// 创建并发mapfunc New() ConcurrentMap &#123;m := make(ConcurrentMap, SHARD_COUNT)for i := 0; i &lt; SHARD_COUNT; i++ &#123; m[i] = &amp;ConcurrentMapShared&#123;items: make(map[string]interface&#123;&#125;)&#125;&#125;return m&#125;// 根据key计算分片索引func (m ConcurrentMap) GetShard(key string) *ConcurrentMapShared &#123;return m[uint(fnv32(key))%uint(SHARD_COUNT)]&#125;func (m ConcurrentMap) Set(key string, value interface&#123;&#125;) &#123; // 根据key计算出对应的分片 shard := m.GetShard(key) shard.Lock() //对这个分片加锁，执行业务操作 shard.items[key] = value shard.Unlock()&#125;func (m ConcurrentMap) Get(key string) (interface&#123;&#125;, bool) &#123; // 根据key计算出对应的分片 shard := m.GetShard(key) shard.RLock() // 从这个分片读取key的值 val, ok := shard.items[key] shard.RUnlock() return val, ok&#125; 2.3 sync.MapGo 内建的 map 类型不是线程安全的，所以 Go 1.9 中增加了一个线程安全的 map，也就是 sync.Map。但是，这个 sync.Map 并不是用来替换内建的 map 类型的，它只能被应用在一些特殊的场景里。 官方的文档中指出，在以下两个场景中使用 sync.Map，会比使用 map+RWMutex 的方式，性能要好得多： 只会增长的缓存系统中，一个 key 只写入一次而被读很多次； 多个 goroutine 为不相交的键集读、写和重写键值对。 官方建议针对自己的场景做性能评测，如果确实能够显著提高性能，再使用 sync.Map。我们能用到 sync.Map 的场景确实不多。即便使用不多，也不妨碍我们去研究 sync.Map 的实现。 sync.Map 的实现有几个优化点，我们先列出来: 空间换时间。通过冗余的两个数据结构（只读的 read 字段、可写的 dirty），来减少加锁对性能的影响。对只读字段（read）的操作不需要加锁。 优先从 read 字段读取、更新、删除，因为对 read 字段的读取不需要锁。 动态调整。miss 次数多了之后，将 dirty 数据提升为 read，避免总是从 dirty 中加锁读取。 double-checking。加锁之后先还要再检查 read 字段，确定真的不存在才操作 dirty 字段。延迟删除。删除一个键值只是打标记，只有在提升 dirty 字段为 read 字段的时候才清理删除的数据。 3. map 的扩展还有一些扩展其它功能的 map 实现，比如带有过期功能的timedmap、使用红黑树实现的 key 有序的treemap等。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 Cond 条件变量]]></title>
    <url>%2F2019%2F02%2F06%2Fgo%2Fgo_sync%2Fgo_sync_7%2F</url>
    <content type="text"><![CDATA[Cond 条件变量 1. Cond 概述Go 标准库提供 Cond 原语的目的是，为等待 / 通知场景下的并发问题提供支持。Cond 通常应用于等待某个条件的一组 goroutine，等条件变为 true 的时候，其中一个 goroutine 或者所有的 goroutine 都会被唤醒执行。顾名思义，Cond 是和某个条件相关: 条件没有满足时，所有等待这个条件的 goroutine 都被阻塞 条件满足时，等待的 goroutine 可以继续进行执行 Cond 在实际项目中被使用的机会比较少，原因总结起来有两个: 因为一旦遇到需要使用 Cond 的场景，我们更多地会使用 Channel 的方式去实现，因为 channel 才是更地道的 Go 语言的写法 对于简单的 wait/notify 场景，比如等待一组 goroutine 完成之后继续执行余下的代码，我们会使用 WaitGroup 来实现 但是 Cond 有三点特性是 Channel 无法替代的： Cond 和一个 Locker 关联，可以利用这个 Locker 对相关的依赖条件更改提供保护 Cond 可以同时支持 Signal 和 Broadcast 方法，而 Channel 只能同时支持其中一种 Cond 的 Broadcast 方法可以被重复调用。等待条件再次变成不满足的状态后，我们又可以调用 Broadcast 再次唤醒等待的 goroutine。这也是 Channel 不能支持的，Channel 被 close 掉了之后不支持再 open 本质上 WaitGroup 和 Cond 是有区别的: WaitGroup 是主 goroutine 等待确定数量的子 goroutine 完成任务； Cond 是等待某个条件满足，这个条件的修改可以被任意多的 goroutine 更新，而且 Cond 的 Wait 不关心也不知道其他 goroutine 的数量，只关心等待条件 而且 Cond 还有单个通知的机制，也就是 Signal 方法 1.1 Cond 使用标准库中的 Cond 并发原语初始化的时候，需要关联一个 Locker 接口的实例，一般我们使用 Mutex 或者 RWMutex。Cond 初始化和提供的方法如下: 12345type Cond func NeWCond(l Locker) *Cond func (c *Cond) Broadcast() func (c *Cond) Signal() func (c *Cond) Wait() 首先，Cond 关联的 Locker 实例可以通过 c.L 访问，它内部维护着一个先入先出的等待队列 Signal 方法: 允许调用者 Caller 唤醒一个等待此 Cond 的 goroutine Cond 等待队列中有多个等待的 goroutine 时，需要从等待队列中移除第一个 goroutine 并唤醒 调用 Signal 方法时，不强求你一定要持有 c.L 的锁 Broadcast 方法: 允许调用者 Caller 唤醒所有等待此 Cond 的 goroutine 如果 Cond 等待队列中有一个或者多个等待的 goroutine，则清空所有等待的 goroutine，并全部唤醒 调用 Broadcast 方法时，也不强求你一定持有 c.L 的锁 Wait 方法: 把调用者 Caller 放入 Cond 的等待队列中并阻塞 调用 Wait 方法时必须要持有 c.L 的锁 至于为什么调用 Wait() 必须要持有锁，我的理解是，所有调用 Wait() 的方法都需要检查条件是否满足，甚至会改变检查条件，它们彼此应该是互斥的，需要使用锁保护检查条件 下面是 Cond 的使用示例: 12345678910111213141516171819202122232425262728293031323334func main() &#123; c := sync.NewCond(&amp;sync.Mutex&#123;&#125;) var ready int for i := 0; i &lt; 10; i++ &#123; go func(i int) &#123; time.Sleep(time.Duration(rand.Int63n(10)) * time.Second) // 加锁更改等待条件 // 注意点一: 条件变量的更改，其实是需要原子操作或者互斥锁保护的 c.L.Lock() ready++ c.L.Unlock() log.Printf("运动员#%d 已准备就绪\n", i) // 广播唤醒所有的等待者 c.Broadcast() &#125;(i) &#125; // 注意点三: Wait() 方法调用前需要先获取锁 c.L.Lock() // 注意点二: Wait 唤醒后需要检查条件 // 我们一定要记住，waiter goroutine 被唤醒不等于等待条件被满足 for ready != 10 &#123; c.Wait() log.Println("裁判员被唤醒一次") &#125; c.L.Unlock() //所有的运动员是否就绪 log.Println("所有运动员都准备就绪。比赛开始，3，2，1, ......")&#125; 2. Cond 实现Cond 的实现非常简单，或者说复杂的逻辑已经被 Locker 或者 runtime 的等待队列实现了。 12345678910111213141516171819202122232425262728293031323334353637type Cond struct &#123; noCopy noCopy // 当观察或者修改等待条件的时候需要加锁 L Locker // 等待队列 notify notifyList checker copyChecker&#125;func NewCond(l Locker) *Cond &#123; return &amp;Cond&#123;L: l&#125;&#125;func (c *Cond) Wait() &#123; c.checker.check() // 增加到等待队列中 t := runtime_notifyListAdd(&amp;c.notify) // 把当前调用者加入到 notify 队列之中后会释放锁 c.L.Unlock() // 阻塞休眠直到被唤醒 // 等调用者被唤醒之后，又会去争抢这把锁 runtime_notifyListWait(&amp;c.notify, t) c.L.Lock()&#125;func (c *Cond) Signal() &#123; c.checker.check() runtime_notifyListNotifyOne(&amp;c.notify)&#125;func (c *Cond) Broadcast() &#123; c.checker.check() runtime_notifyListNotifyAll(&amp;c.notify）&#125; 在 Cond 实现中: runtime_notifyListXXX 是运行时实现的方法，实现了一个等待 / 通知的队列，代码位于 runtime/sema.go 中 copyChecker 是一个辅助结构，可以在运行时检查 Cond 是否被复制使用 Signal 和 Broadcast 只涉及到 notifyList 数据结构，不涉及到锁 Wait 把调用者加入到等待队列时会释放锁，在被唤醒之后还会请求锁。在阻塞休眠期间，调用者是不持有锁的，这样能让其他 goroutine 有机会检查或者更新等待变量。 3. Cond 采坑点使用 Cond 时有两个常见错误 一个是调用 Wait 的时候没有加锁 另一个是没有检查条件是否满足程序就继续执行了 我们一定要记住，waiter goroutine 被唤醒不等于等待条件被满足，只是有 goroutine 把它唤醒了而已，等待条件有可能已经满足了，也有可能不满足，我们需要进一步检查。你也可以理解为，等待者被唤醒，只是得到了一次检查的机会而已。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 WaitGroup]]></title>
    <url>%2F2019%2F02%2F06%2Fgo%2Fgo_sync%2Fgo_sync_6%2F</url>
    <content type="text"><![CDATA[WaitGroup 任务编排 1. WaitGroup 使用WaitGroup 很简单，就是 package sync 用来做任务编排的一个并发原语。它要解决的就是并发 - 等待的问题: goroutine A 等待一组 goroutine 全部完成。 很多操作系统和编程语言都提供了类似的并发原语。比如，Linux 中的 barrier、Pthread（POSIX 线程）中的 barrier、C++ 中的 std::barrier、Java 中的 CyclicBarrier 和 CountDownLatch 等。 WaitGroup 非常适用于此类场景: 需要启动多个 goroutine 执行任务，主 goroutine 需要等待子 goroutine 都完成后才继续执行。 1.1 WaitGroup 使用Go 标准库中的 WaitGroup 提供了三个方法:123func (wg *WaitGroup) Add(delta int)func (wg *WaitGroup) Done()func (wg *WaitGroup) Wait() Add，用来设置 WaitGroup 的计数值； Done，用来将 WaitGroup 的计数值减 1，其实就是调用了 Add(-1)； Wait，调用这个方法的 goroutine 会一直阻塞，直到 WaitGroup 的计数值变为 0 下面是 WaitGroup 的使用示例: 123456789101112131415161718192021222324252627282930313233343536373839// 线程安全的计数器type Counter struct &#123; mu sync.Mutex count uint64&#125;// 对计数值加一func (c *Counter) Incr() &#123; c.mu.Lock() c.count++ c.mu.Unlock()&#125;// 获取当前的计数值func (c *Counter) Count() uint64 &#123; c.mu.Lock() defer c.mu.Unlock() return c.count&#125;// sleep 1秒，然后计数值加1func worker(c *Counter, wg *sync.WaitGroup) &#123; defer wg.Done() time.Sleep(time.Second) c.Incr()&#125;func main() &#123; var counter Counter var wg sync.WaitGroup wg.Add(10) // WaitGroup的值设置为10 for i := 0; i &lt; 10; i++ &#123; // 启动10个goroutine执行加1任务 go worker(&amp;counter, &amp;wg) &#125; // 检查点，等待goroutine都完成任务 wg.Wait() // 输出当前计数器的值 fmt.Println(counter.Count())&#125; 2. WaitGroup 实现1234567891011121314151617181920212223type WaitGroup struct &#123; // 避免复制使用的一个技巧，可以告诉vet工具违反了复制使用的规则 noCopy noCopy // 64bit(8bytes)的值分成两段，高32bit是计数值，低32bit是waiter的计数 // 另外32bit是用作信号量的 // 因为64bit值的原子操作需要64bit对齐，但是32bit编译器不支持，所以数组中的元素在不同的架构中不一样，具体处理看下面的方法 // 总之，会找到对齐的那64bit作为state，其余的32bit做信号量 state1 [3]uint32&#125;// 得到state的地址和信号量的地址func (wg *WaitGroup) state() (statep *uint64, semap *uint32) &#123; // %8 表示 8 个字节，注意不是位 // 32位还是64位计算机不是关键点，关键点是 state1 有没有按照 64 位对齐，32位计算机上 state1 也可能刚好对齐到 64 位上 if uintptr(unsafe.Pointer(&amp;wg.state1))%8 == 0 &#123; // 如果地址是64bit对齐的，数组前两个元素做state，后一个元素做信号量 return (*uint64)(unsafe.Pointer(&amp;wg.state1)), &amp;wg.state1[2] &#125; else &#123; // 如果地址是32bit对齐的，数组后两个元素用来做state，它可以用来做64bit的原子操作，第一个元素32bit用来做信号量 return (*uint64)(unsafe.Pointer(&amp;wg.state1[1])), &amp;wg.state1[0] &#125;&#125; WaitGroup 的数据结构包括两个字段: noCopy noCopy: 辅助字段，主要就是辅助 vet 工具检查是否通过 copy 赋值这个 WaitGroup 实例 state1 [3]uint32: 一个具有复合意义的字段，包含 WaitGroup 的计数、阻塞在检查点的 waiter 数和信号量。 因为64bit值的原子操作需要64bit对齐，但是32bit编译器不支持，所以数组中的元素在不同的架构中不一样，处理方法在 state() 方法中 在 64 位环境下，state1 的第一个元素是 waiter 数，第二个元素是 WaitGroup 的计数值，第三个元素是信号量 在 32 位环境下，如果 state1 不是 64 位对齐的地址，那么 state1 的第一个元素是信号量，后两个元素分别是 waiter 数和计数值 接下来我们来看 Add、Done 和 Wait 这三个方法的实现。在查看这部分源码实现时，除了这些方法本身的实现外，还会有一些额外的代码，主要是 race 检查和异常检查的代码。其中，有几个检查非常关键，如果检查不通过，会出现 panic。我们在介绍完这三个方法的实现之后再来统一介绍。 2.1 Add 方法实现Add 方法主要操作的是 state 的计数部分，可以为计数值增加一个 delta 值，内部通过原子操作把这个值加到计数值上，delta 也可以是个负数，相当于为计数值减去一个值，Done 方法内部其实就是通过 Add(-1) 实现的。 1234567891011121314151617181920212223242526func (wg *WaitGroup) Add(delta int) &#123; statep, semap := wg.state() // 高32bit是计数值v，所以把delta左移32，增加到计数上 state := atomic.AddUint64(statep, uint64(delta)&lt;&lt;32) v := int32(state &gt;&gt; 32) // 当前计数值 w := uint32(state) // waiter count if v &gt; 0 || w == 0 &#123; return &#125; // 如果计数值v为0并且waiter的数量w不为0，那么state的值就是waiter的数量 // 将waiter的数量设置为0，因为计数值v也是0,所以它们俩的组合*statep直接设置为0即可。此时需要并唤醒所有的waiter // Add(-n) 的处理逻辑 *statep = 0 for ; w != 0; w-- &#123; runtime_Semrelease(semap, false, 0) &#125;&#125;// Done方法实际就是计数器减1func (wg *WaitGroup) Done() &#123; wg.Add(-1)&#125; 2.2 Wait 方法实现Wait 方法的实现逻辑是： 不断检查 state 的值。如果其中的计数值变为了 0，那么说明所有的任务已完成，调用者不必再等待，直接返回 如果计数值大于 0，说明此时还有任务没完成，那么调用者就变成了等待者，需要加入 waiter 队列，并且阻塞住自己。 123456789101112131415161718192021func (wg *WaitGroup) Wait() &#123; statep, semap := wg.state() for &#123; state := atomic.LoadUint64(statep) v := int32(state &gt;&gt; 32) // 当前计数值 w := uint32(state) // waiter的数量 if v == 0 &#123; // 如果计数值为0, 调用这个方法的goroutine不必再等待，继续执行它后面的逻辑即可 return &#125; // 否则把waiter数量加1。期间可能有并发调用Wait的情况，所以最外层使用了一个for循环 if atomic.CompareAndSwapUint64(statep, state, state+1) &#123; // 阻塞休眠等待 runtime_Semacquire(semap) // 被唤醒，不再阻塞，返回 return &#125; &#125;&#125; 2.3 异常检测前面我们分析 Add 和 Wait 实现的时候删除了异常检测的代码，这些异常检测的逻辑就是我们使用 WaitGroup 的避坑指南。通常使用 WaitGroup 时会出现以下三个问题: 计数器设置为负值: 检查点: WaitGroup 的计数器的值必须大于等于 0。我们在更改这个计数值的时候，WaitGroup 会先做检查，如果计数值被设置为负数，就会导致 panic。 错误点: 一般情况下，有两种方法会导致计数器设置为负数 调用 Add 的时候传递一个负数，导致计数器加上这个负值后小于 0 调用 Done 方法的次数过多，超过了 WaitGroup 的计数值 建议: 使用 WaitGroup 的正确姿势是，预先确定好 WaitGroup 的计数值，然后调用相同次数的 Done 完成相应的任务 不期望的 Add 时机: 在使用 WaitGroup 的时候，你一定要遵循的原则就是，等所有的 Add 方法调用之后再调用 Wait，否则就可能导致 panic 或者不期望的结果 前一个 Wait 还没结束就重用 WaitGroup WaitGroup 是可以重用的。只要 WaitGroup 的计数值恢复到零值的状态，那么它就可以被看作是新创建的 WaitGroup，被重复使用。 但是，如果我们在 WaitGroup 的计数值还没有恢复到零值的时候就重用，就会导致程序 panic 2.4 错误示例在这个例子中，我们原本设想的是，等四个 goroutine 都执行完毕后输出 Done 的信息，但是它的错误之处在于，将 WaitGroup.Add 方法的调用放在了子 gorotuine 中。等主 goorutine 调用 Wait 的时候，因为四个任务 goroutine 一开始都休眠，所以可能 WaitGroup 的 Add 方法还没有被调用，WaitGroup 的计数还是 0，所以它并没有等待四个子 goroutine 执行完毕才继续执行，而是立刻执行了下一步。 12345678910111213141516171819202122232425// 不期望的 Add 时机func main() &#123; var wg sync.WaitGroup // 解决方法一: // wg.Add(4) // 预先设定WaitGroup的计数值 go dosomething(100, &amp;wg) // 启动第一个goroutine go dosomething(110, &amp;wg) // 启动第二个goroutine go dosomething(120, &amp;wg) // 启动第三个goroutine go dosomething(130, &amp;wg) // 启动第四个goroutine wg.Wait() // 主goroutine等待完成 fmt.Println("Done")&#125;func dosomething(millisecs time.Duration, wg *sync.WaitGroup) &#123; duration := millisecs * time.Millisecond time.Sleep(duration) // 故意sleep一段时间 wg.Add(1) fmt.Println("后台执行, duration:", duration) wg.Done()&#125; 在下面的例子中，第 6 行虽然让 WaitGroup 的计数恢复到 0，但是因为第 9 行有个 waiter 在等待，如果等待 Wait 的 goroutine，刚被唤醒就和 Add 调用（第 7 行）有并发执行的冲突，所以就会出现 panic。 1234567891011// 前一个 Wait 还没结束就重用 WaitGroupfunc main() &#123; var wg sync.WaitGroup wg.Add(1) go func() &#123; time.Sleep(time.Millisecond) wg.Done() // 计数器减1 wg.Add(1) // 计数值加1 &#125;() wg.Wait() // 主goroutine等待，有可能和第7行并发执行&#125; 总结一下：WaitGroup 虽然可以重用，但是是有一个前提的，那就是必须等到上一轮的 Wait 完成之后，才能重用 WaitGroup 执行下一轮的 Add/Wait，如果你在 Wait 还没执行完的时候就调用下一轮 Add 方法，就有可能出现 panic。 2.4 noCopy 辅助 vet 检查noCopy 就是指示 vet 工具在做检查的时候，这个数据结构不能做值复制使用。更严谨地说，是不能在第一次使用之后复制使用 ( must not be copied after first use)。noCopy 是一个通用的计数技术，其他并发原语中也会用到。 我们在前面学习 Mutex 的时候用到了 vet 工具。vet 会对实现 Locker 接口的数据类型做静态检查，一旦代码中有复制使用这种数据类型的情况，就会发出警告。WaitGroup 同步原语不就是 Add、Done 和 Wait 方法吗？vet 能检查出来吗？其实是可以的。通过给 WaitGroup 添加一个 noCopy 字段，我们就可以为 WaitGroup 实现 Locker 接口，这样 vet 工具就可以做复制检查了。而且因为 noCopy 字段是未输出类型，所以 WaitGroup 不会暴露 Lock/Unlock 方法。 noCopy 字段的类型是 noCopy，它只是一个辅助的、用来帮助 vet 检查用的类型: 12345type noCopy struct&#123;&#125;// Lock is a no-op used by -copylocks checker from `go vet`.func (*noCopy) Lock() &#123;&#125;func (*noCopy) Unlock() &#123;&#125; 如果你想要自己定义的数据结构不被复制使用，或者说，不能通过 vet 工具检查出复制使用的报警，就可以通过嵌入 noCopy 这个数据类型来实现。 2.5 总结关于如何避免错误使用 WaitGroup 的情况，我们只需要尽量保证下面 5 点就可以了： 不重用 WaitGroup。新建一个 WaitGroup 不会带来多大的资源开销，重用反而更容易出错 保证所有的 Add 方法调用都在 Wait 之前 不传递负数给 Add 方法，只通过 Done 来给计数值减 1 不做多余的 Done 方法调用，保证 Add 的计数值和 Done 方法调用的数量是一样的 不遗漏 Done 方法的调用，否则会导致 Wait hang 住无法返回]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 Once 有且仅有]]></title>
    <url>%2F2019%2F02%2F06%2Fgo%2Fgo_sync%2Fgo_sync_8%2F</url>
    <content type="text"><![CDATA[Once 有且仅有一次执行 1. Once 概述Once 可以用来执行且仅仅执行一次动作：Once 常常用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。 1.1 单例对象初始化初始化单例资源有很多方法，比如定义 package 级别的变量: 12345package abcimport timevar startTime = time.Now() 或者在 init 函数中 12345678package abcvar startTime time.Timefunc init() &#123; startTime = time.Now()&#125; 又或者在 main 函数开始执行的时候: 1234567891011package abcvar startTime time.Timefunc initApp() &#123; startTime = time.Now()&#125;func main() &#123; initApp()&#125; 这三种方法都是线程安全的，并且后两种方法还可以根据传入的参数实现定制化的初始化操作。 1.2 延迟初始化但是很多时候我们是要延迟进行初始化，比如下面初始化网络连接的示例: 1234567891011121314151617181920212223242526272829package mainimport ( "net" "sync" "time")var connMu sync.Mutexvar conn net.Connfunc getConn() net.Conn &#123; connMu.Lock() defer connMu.Unlock() if conn != nil &#123; return conn &#125; conn, _ = net.DialTimeout("tcp", "baidu.com:80", 10*time.Second) return conn&#125;func main()&#123; conn:=getConn() if conn == nil&#123; panic("conn is nil") &#125;&#125; 这种方式虽然实现起来简单，但是有性能问题。一旦连接创建好，每次请求的时候还是得竞争锁才能读取到这个连接。这时候我们就需要 Once 并发原语了。 1.3 Once 的使用sync.Once 只暴露了一个方法 Do: 你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数 因为当且仅当第一次调用 Do 方法的时候参数 f 才会执行，即使第二次、第三次、第 n 次调用时 f 参数的值不一样，也不会被执行 因为这里的 f 参数是一个无参数无返回的函数，所以你可能会通过闭包的方式引用外面的参数 1func (o *Once) Do(f func()) 1234567891011121314151617package mainimport ( "net" "sync")var addr = "baidu.com"var conn net.Connvar err errorvar once sync.Onceonce.Do(func()&#123; conn, err = net.Dial("tcp", addr)&#125;) 有很多标准库中都有 Once 的身影，典型的 math/big/sqrt.go 中实现的一个数据结构，它通过 Once 封装了一个只初始化一次的值： 1234567891011121314 // 值是3.0或者0.0的一个数据结构 var threeOnce struct &#123; sync.Once v *Float&#125; // 返回此数据结构的值，如果还没有初始化为3.0，则初始化func three() *Float &#123; threeOnce.Do(func() &#123; // 使用Once初始化 threeOnce.v = NewFloat(3.0) &#125;) return threeOnce.v&#125; 2. Once 实现很多人觉得 Once 只需要使用一个 flag 标记是否初始化即可，最多使用 atomic 原子操作这个 flag 比如下面这个实现: 1234567891011type Once struct &#123; done uint32&#125;func (o *Once) Do(f func()) &#123; if !atomic.CompareAndSwapUint32(&amp;o.done, 0, 1) &#123; return &#125; f()&#125; 但是，这个实现有一个很大的问题，就是如果参数 f 执行很慢的话，后续调用 Do 方法的 goroutine 虽然看到 done 已经设置为执行过了，但是获取某些初始化资源的时候可能会得到空的资源，因为 f 还没有执行完。 所以一个正确的 Once 实现同事需要互斥锁和 flag 的双重检测机制: 互斥锁的机制保证只有一个 goroutine 进行初始化，并在 f() 未执行完成时，其他 goroutine 等待 flag 用于 f() 执行之后快速成功，以及保证 只有一次初始化 1234567891011121314151617181920212223type Once struct &#123; done uint32 m Mutex&#125;func (o *Once) Do(f func()) &#123; // 1. flag 用于快速成功，不用在 f() 完成后，仍去竞争锁 if atomic.LoadUint32(&amp;o.done) == 0 &#123; o.doSlow(f) &#125;&#125;func (o *Once) doSlow(f func()) &#123; // 2. f() 未执行完时，多个 goroutine 都会争抢锁，从而等待 f() 执行完成 o.m.Lock() defer o.m.Unlock() // 3. 双检查机制保证只有 f() 只执行一次 if o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) f() &#125;&#125; 3.Once 采坑点使用 Once 有两个常见错误: 死锁: Do 方法会执行一次 f，但是如果 f 中再次调用这个 Once 的 Do 方法的话，就会导致死锁的情况出现 初始化未完成: 如果 f 方法执行的时候 panic，或者 f 执行初始化资源的时候失败了，这个时候，Once 还是会认为初次执行已经成功了，即使再次调用 Do 方法，也不会再次执行 f。 Once 有一个比较典型的采坑案例，场景是这样的: Once Do 方法只能初始化一次，有时候我们需要能够重新初始化，即为 Once 增加一个 Reset 方法，Reset 之后再调用 once.Do 就又可以初始化了。Go 的核心开发者 Ian Lance Taylor 给了一个简单的解决方案，即 Reset 的时候将 原有的 Once 变量(例如变量ponce)赋值一个新的 Once 实例即可 (ponce = new(sync.Once))。这样在新的 ponce 就可以再次执行初始化。但是我们不能像这样: ponce.Do(ponce.Reset()) 在 Do 方法中，重新给 ponce 赋值。原因在于 在执行 ponce.Reset 的时候 Once 内部的 Mutex 首先会加锁， 在 Reset 中更改了 Once 指针的值之后，结果在执行完 Reset 释放锁的时候，释放的是一个刚初始化未加锁的 Mutex，所以就 panic 了 下面的 doSlow 方法就演示了这个错误: 1234567891011121314151617181920212223package mainimport ( "sync")type Once struct &#123; m sync.Mutex&#125;func (o *Once) doSlow() &#123; o.m.Lock() defer o.m.Unlock() // 这里更新的o指针的值!!!!!!!, 会导致上一行Unlock出错 *o = Once&#123;&#125;&#125;func main() &#123; var once Once once.doSlow()&#125; Ian Lance Taylor 介绍的 Reset 方法没有错误，但是你在使用的时候千万别再初始化函数中 Reset 这个 Once，否则势必会导致 Unlock 一个未加锁的 Mutex 的错误。 4. Once 的扩展4.1 可多次初始化的 Once针对初始化未完成的情况，我们可以自己实现一个类似 Once 的并发原语，既可以返回当前调用 Do 方法是否正确完成，还可以在初始化失败后调用 Do 方法再次尝试初始化，直到初始化成功才不再初始化了。 123456789101112131415161718192021222324252627// 一个功能更加强大的Oncetype Once struct &#123; m sync.Mutex done uint32&#125;// 传入的函数f有返回值error，如果初始化失败，需要返回失败的error// Do方法会把这个error返回给调用者func (o *Once) Do(f func() error) error &#123; if atomic.LoadUint32(&amp;o.done) == 1 &#123; //fast path return nil &#125; return o.slowDo(f)&#125;// 如果还没有初始化func (o *Once) slowDo(f func() error) error &#123; o.m.Lock() defer o.m.Unlock() var err error if o.done == 0 &#123; // 双检查，还没有初始化 err = f() if err == nil &#123; // 初始化成功才将标记置为已初始化 atomic.StoreUint32(&amp;o.done, 1) &#125; &#125; return err&#125; 4.2 可获取是否初始化的 Once目前的 Once 实现可以保证你调用任意次数的 once.Do 方法，它只会执行这个方法一次。但是，有时候我们需要一个是否初始化的标记。标准库的 Once 并不会告诉你是否初始化完成了。所以通常我们需要一个辅助变量，自己去检查是否初始化完成: 1234567891011121314type AnimalStore struct &#123;once sync.Once;inited uint32&#125;func (a *AnimalStore) Init() // 可以被并发调用 a.once.Do(func() &#123; longOperationSetupDbOpenFilesQueuesEtc() atomic.StoreUint32(&amp;a.inited, 1) &#125;)&#125;func (a *AnimalStore) CountOfCats() (int, error) &#123; // 另外一个goroutine if atomic.LoadUint32(&amp;a.inited) == 0 &#123; // 初始化后才会执行真正的业务逻辑 return 0, NotYetInitedError &#125; //Real operation&#125; 另一个解决方案是，我们可以自己去扩展 Once 的并发原语，为其提供一个返回是否已初始化的 Done 方法: 1234567891011121314151617181920212223// Once 是一个扩展的sync.Once类型，提供了一个Done方法type Once struct &#123; sync.Once&#125;// Done 返回此Once是否执行过// 如果执行过则返回true// 如果没有执行过或者正在执行，返回falsefunc (o *Once) Done() bool &#123; return atomic.LoadUint32((*uint32)(unsafe.Pointer(&amp;o.Once))) == 1&#125;func main() &#123; var flag Once fmt.Println(flag.Done()) //false flag.Do(func() &#123; time.Sleep(time.Second) &#125;) fmt.Println(flag.Done()) //true&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 RWMutex]]></title>
    <url>%2F2019%2F02%2F05%2Fgo%2Fgo_sync%2Fgo_sync_5%2F</url>
    <content type="text"><![CDATA[读写锁 RWMutex 1. RWMutex 使用标准库中的 RWMutex 是一个 reader/writer 互斥锁，用来解决并发读写问题，特别适用于读多写少的场景。RWMutex 在某一时刻只能由任意数量的 reader 持有，或者是只被单个的 writer 持有。 1.1 RWMutexRWMutex 的方法也很少，总共有 5 个: Lock/Unlock： 写操作时调用的方法 如果锁已经被 reader 或者 writer 持有，那么，Lock 方法会一直阻塞，直到能获取到锁； Unlock 则是配对的释放锁的方法 RLock/RUnlock： 读操作时调用的方法 如果锁已经被 writer 持有的话，RLock 方法会一直阻塞，直到能获取到锁，否则就直接返回 RUnlock 是 reader 释放锁的方法 RLocker：这个方法的作用是为读操作返回一个 Locker 接口的对象。它的 Lock 方法会调用 RWMutex 的 RLock 方法，它的 Unlock 方法会调用 RWMutex 的 RUnlock 方法 下面是使用 RWMutex 的简单示例: 123456789101112131415161718192021222324252627282930313233343536func main() &#123; var counter Counter for i := 0; i &lt; 10; i++ &#123; // 10个reader go func() &#123; for &#123; counter.Count() // 计数器读操作 time.Sleep(time.Millisecond) &#125; &#125;() &#125; for &#123; // 一个writer counter.Incr() // 计数器写操作 time.Sleep(time.Second) &#125;&#125;// 一个线程安全的计数器type Counter struct &#123; mu sync.RWMutex count uint64&#125;// 使用写锁保护func (c *Counter) Incr() &#123; c.mu.Lock() c.count++ c.mu.Unlock()&#125;// 使用读锁保护func (c *Counter) Count() uint64 &#123; c.mu.RLock() defer c.mu.RUnlock() return c.count&#125; 在实际使用 RWMutex 的时候，如果我们在 struct 中使用 RWMutex 保护某个字段，一般会把它和这个字段放在一起，用来指示两个字段是一组字段。除此之外，我们还可以采用匿名字段的方式嵌入 struct，这样，在使用这个 struct 时，我们就可以直接调用 Lock/Unlock、RLock/RUnlock 方法了。 2. RWMutex 实现RWMutex 一般都是基于互斥锁、条件变量（condition variables）或者信号量（semaphores）等并发原语来实现。Go 标准库中的 RWMutex 是基于 Mutex 实现的。 readers-writers 问题一般有三类，基于对读和写操作的优先级，读写锁的设计和实现也分成三类: Read-preferring： 读优先的设计可以提供很高的并发性，但是，在竞争激烈的情况下可能会导致写饥饿 这是因为，如果有大量的读，这种设计会导致只有所有的读都释放了锁之后，写才可能获取到锁 Write-preferring： 写优先的设计意味着，如果已经有一个 writer 在等待请求锁的话，它会阻止新来的请求锁的 reader 获取到锁，所以优先保障 writer。 当然，如果有一些 reader 已经请求了锁的话，新请求的 writer 也会等待已经存在的 reader 都释放锁之后才能获取。 所以，写优先级设计中的优先权是针对新来的请求而言的。这种设计主要避免了 writer 的饥饿问题。 不指定优先级： 这种设计比较简单，不区分 reader 和 writer 优先级 某些场景下这种不指定优先级的设计反而更有效，因为第一类优先级会导致写饥饿，第二类优先级可能会导致读饥饿，这种不指定优先级的访问不再区分读写，大家都是同一个优先级，解决了饥饿的问题 Go 标准库中的 RWMutex 设计是 Write-preferring 方案。一个正在阻塞的 Lock 调用会排除新的 reader 请求到锁。 2.1 RWMutex 的定义12345678910type RWMutex struct &#123; w Mutex // 互斥锁解决多个writer的竞争 writerSem uint32 // writer信号量 readerSem uint32 // reader信号量 readerCount int32 // reader的数量 readerWait int32 // writer等待完成的reader的数量&#125;const rwmutexMaxReaders = 1 &lt;&lt; 30 RWMutex 包含如下几个字段: 字段 w：为 writer 的竞争锁而设计； 字段 readerCount：记录当前 reader 的数量（以及是否有 writer 竞争锁）； readerWait：记录 writer 请求锁时需要等待 read 完成的 reader 的数量； writerSem 和 readerSem：都是为了阻塞设计的信号量。 常量 rwmutexMaxReaders，定义了最大的 reader 数量。 2.2 RLock/RUnlock 的实现123456789101112131415161718func (rw *RWMutex) RLock() &#123; if atomic.AddInt32(&amp;rw.readerCount, 1) &lt; 0 &#123; // rw.readerCount是负值的时候，意味着此时有writer等待请求锁，因为writer优先级高，所以把后来的reader阻塞休眠 runtime_SemacquireMutex(&amp;rw.readerSem, false, 0) &#125;&#125;func (rw *RWMutex) RUnlock() &#123; if r := atomic.AddInt32(&amp;rw.readerCount, -1); r &lt; 0 &#123; rw.rUnlockSlow(r) // 有等待的writer &#125;&#125;func (rw *RWMutex) rUnlockSlow(r int32) &#123; if atomic.AddInt32(&amp;rw.readerWait, -1) == 0 &#123; // 最后一个reader了，writer终于有机会获得锁了 runtime_Semrelease(&amp;rw.writerSem, false, 1) &#125;&#125; 在上面的实现，要注意 readerCount 可能为负数，这是因为 readerCount 这个字段有双重含义： 没有 writer 竞争或持有锁时，readerCount 和我们正常理解的 reader 的计数是一样的； 有 writer 竞争锁或者持有锁时，那么，readerCount 不仅仅承担着 reader 的计数功能，还能够标识当前是否有 writer 竞争或持有锁 当 writer 请求锁的时候，是无法改变既有的 reader 持有锁的现实的，也不会强制这些 reader 释放锁，它的优先权只是限定后来的 reader 不要和它抢。 2.3 Lock为了避免 writer 之间的竞争，RWMutex 就会使用一个 Mutex 来保证 writer 的互斥。一旦一个 writer 获得了内部的互斥锁，就会反转 readerCount 字段，把它从原来的正整数 readerCount(&gt;=0) 修改为负数（readerCount-rwmutexMaxReaders），让这个字段保持两个含义（既保存了 reader 的数量，又表示当前有 writer）。 这样做的目的是为了将减少 reader 数量和判断是否有 writer 实现在一个原子操作内。 12345678910111213func (rw *RWMutex) Lock() &#123; // 首先解决其他writer竞争问题 rw.w.Lock() // 反转readerCount，告诉reader有writer竞争锁 // 还会记录当前活跃的 reader 数量，所谓活跃的 reader，就是指持有读锁还没有释放的那些 reader r := atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // 如果当前有reader持有锁，那么需要等待 // 并把当前 readerCount 赋值给 readerWait 字段 if r != 0 &amp;&amp; atomic.AddInt32(&amp;rw.readerWait, r) != 0 &#123; runtime_SemacquireMutex(&amp;rw.writerSem, false, 0) &#125;&#125; 2.4 Unlock1234567891011func (rw *RWMutex) Unlock() &#123; // 告诉reader没有活跃的writer了 r := atomic.AddInt32(&amp;rw.readerCount, rwmutexMaxReaders) // 唤醒阻塞的reader们 for i := 0; i &lt; int(r); i++ &#123; runtime_Semrelease(&amp;rw.readerSem, false, 0) &#125; // 释放内部的互斥锁 rw.w.Unlock()&#125; 在 Lock 方法中，是先获取内部互斥锁，才会修改的其他字段；而在 Unlock 方法中，是先修改的其他字段，才会释放内部互斥锁，这样才能保证字段的修改也受到互斥锁的保护。 3. RWMutex 采坑点RWMutex有三个采坑点: 不可复制: 原因: 互斥锁是不可复制的，再加上四个有状态的字段，RWMutex 就更加不能复制使用了 解决方案也和互斥锁一样。你可以借助 vet 工具检查是否有读写锁隐式复制的情景 重入导致死锁 writer 重入调用 Lock 的时候，就会出现死锁的现象 有活跃 reader 的时候，writer 会等待，如果我们在 reader 的读操作时调用 writer 的写操，此时Reader 想等待 writer 完成后再释放锁，而 writer 需要这个 reader 释放锁之后，才能不阻塞地继续执行，导致死锁 writer 依赖活跃的 reader -&gt; 活跃的 reader 依赖新来的 reader -&gt; 新来的 reader 依赖 writer 释放未加锁的 RWMutex: Lock 和 Unlock 的调用总是成对出现的，RLock 和 RUnlock 的调用也必须成对出现 使用读写锁最需要注意的一点就是尽量避免重入，重入带来的死锁非常隐蔽，而且难以诊断。 另外我们也可以扩展 RWMutex，不过实现方法和互斥锁 Mutex 差不多，在技术上是一样的，都是通过 unsafe 来实现。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 Mutex 扩展]]></title>
    <url>%2F2019%2F02%2F04%2Fgo%2Fgo_sync%2Fgo_sync_4%2F</url>
    <content type="text"><![CDATA[如何基于 Mutex 实现一个可重入锁 1. Mutex 的扩展上一节我们介绍了 Mutex 的实现原理，这一节我们来看看如何基于标准库的 Mutex 来扩展 Mutex 提供的并发原语，包括: 实现一个可重入锁 TryLock 获取等待者的数量 实现一个线程安全的队列 2. 可重入锁实现可重入锁的关键是要锁能记住当前哪个 goroutine 持有锁，这里有两个方案: 通过 hacker 的方式获取到 goroutine id，记录下获取锁的 goroutine id，它可以实现 Locker 接口 调用 Lock/Unlock 方法时，由 goroutine 提供一个 token，用来标识它自己，而不是我们通过 hacker 的方式获取到 goroutine id，但是，这样一来，就不满足 Locker 接口了 可重入锁（递归锁）解决了代码重入或者递归调用带来的死锁问题，同时它也带来了另一个好处: 只有持有锁的 goroutine 才能 unlock 这个锁。接下来我们来看看这两个方案具体如何实现。 2.1 goroutine id这个方案的关键第一步是获取 goroutine id，方式有两种，分别是 简单方式：通过 runtime.Stack 方法获取栈帧信息，栈帧信息里包含 goroutine id hacker 方式: 原理: 我们获取运行时的 g 指针，反解出对应的 g 的结构。每个运行的 goroutine 结构的 g 指针保存在当前 goroutine 的一个叫做 TLS 对象中 第一步：我们先获取到 TLS 对象 第二步：再从 TLS 中获取 goroutine 结构的 g 指针 第三步：再从 g 指针中取出 goroutine id。 需要注意的是，不同 Go 版本的 goroutine 的结构可能不同，所以需要根据 Go 的不同版本进行调整。没必要重复造轮子，直接使用第三方库就可以: petermattis/goid 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import ( "fmt" "runtime" "strconv" "strings" "sync" "sync/atomic" "github.com/petermattis/goid" // 使用第三方包通过 hacker 方式获取 goroutine id )// 简单方式func GoID() int &#123; var buffer [64]byte n := runtime.Stack(buffer[:], false) idField := strings.Fields(strings.TrimPrefix(string(buffer[:n]), "goroutine "))[0] d, err := strconv.Atoi(idField) if err != nil &#123; panic(fmt.Sprintf("can not get goroutine id %v", err)) &#125; return d&#125;// RecursiveMutex 包装一个Mutex,实现可重入type RecursiveMutex struct &#123; sync.Mutex owner int64 // 当前持有锁的goroutine id recursion int32 // 这个goroutine 重入的次数&#125;func (m *RecursiveMutex) Lock() &#123; gid := goid.Get() // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入 if atomic.LoadInt64(&amp;m.owner) == gid &#123; m.recursion++ return &#125; m.Mutex.Lock() // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1 atomic.StoreInt64(&amp;m.owner, gid) m.recursion = 1&#125;func (m *RecursiveMutex) Unlock() &#123; gid := goid.Get() // 非持有锁的goroutine尝试释放锁，错误的使用 if atomic.LoadInt64(&amp;m.owner) != gid &#123; panic(fmt.Sprintf("wrong the owner(%d): %d!", m.owner, gid)) &#125; // 调用次数减1 m.recursion-- if m.recursion != 0 &#123; // 如果这个goroutine还没有完全释放，则直接返回 return &#125; // 此goroutine最后一次调用，需要释放锁 atomic.StoreInt64(&amp;m.owner, -1) m.Mutex.Unlock()&#125; 2.2 token通过 token 的实现方式需要调用者自己提供一个 token，获取锁的时候把这个 token 传入，释放锁的时候也需要把这个 token 传入。通过用户传入的 token 替换方案一中 goroutine id，其它逻辑和方案一一致。 1234567891011121314151617181920212223242526272829303132// Token方式的递归锁type TokenRecursiveMutex struct &#123; sync.Mutex token int64 recursion int32&#125;// 请求锁，需要传入tokenfunc (m *TokenRecursiveMutex) Lock(token int64) &#123; if atomic.LoadInt64(&amp;m.token) == token &#123; //如果传入的token和持有锁的token一致，说明是递归调用 m.recursion++ return &#125; m.Mutex.Lock() // 传入的token不一致，说明不是递归调用 // 抢到锁之后记录这个token atomic.StoreInt64(&amp;m.token, token) m.recursion = 1&#125;// 释放锁func (m *TokenRecursiveMutex) Unlock(token int64) &#123; if atomic.LoadInt64(&amp;m.token) != token &#123; // 释放其它token持有的锁 panic(fmt.Sprintf("wrong the owner(%d): %d!", m.token, token)) &#125; m.recursion-- // 当前持有这个锁的token释放锁 if m.recursion != 0 &#123; // 还没有回退到最初的递归调用 return &#125; atomic.StoreInt64(&amp;m.token, 0) // 没有递归调用了，释放锁 m.Mutex.Unlock()&#125; 3. TryLock我们可以为 Mutex 添加一个 TryLock 请求锁的方法: 如果 goroutine 获取锁成功，则持有锁，并返回 true 如果这把锁已经被其他 goroutine 所持有，或者是正在准备交给某个被唤醒的 goroutine，那么 TryLock 直接返回 false，不会阻塞在方法调用上 具体实现如下: 12345678910111213141516171819202122232425262728293031// 复制Mutex定义的常量const ( mutexLocked = 1 &lt;&lt; iota // 加锁标识位置 mutexWoken // 唤醒标识位置 mutexStarving // 锁饥饿标识位置 mutexWaiterShift = iota // 标识waiter的起始bit位置)// 扩展一个Mutex结构type Mutex struct &#123; sync.Mutex&#125;// 尝试获取锁func (m *Mutex) TryLock() bool &#123; // 如果能成功抢到锁 if atomic.CompareAndSwapInt32((*int32)(unsafe.Pointer(&amp;m.Mutex)), 0, mutexLocked) &#123; return true &#125; // 如果处于唤醒、加锁或者饥饿状态，这次请求就不参与竞争了，返回false old := atomic.LoadInt32((*int32)(unsafe.Pointer(&amp;m.Mutex))) if old&amp;(mutexLocked|mutexStarving|mutexWoken) != 0 &#123; return false &#125; // 尝试在竞争的状态下请求锁 new := old | mutexLocked return atomic.CompareAndSwapInt32((*int32)(unsafe.Pointer(&amp;m.Mutex)), old, new)&#125; 4. 获取等待者的数量Mutex 结构中的 state 字段有很多个含义，通过 state 字段，你可以知道锁是否已经被某个 goroutine 持有、当前是否处于饥饿状态、是否有等待的 goroutine 被唤醒、等待者的数量等信息。但是要想获取这些信息，我们需要将他们从 state 字段中一一解析出来，代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota)type Mutex struct &#123; sync.Mutex&#125;func (m *Mutex) Count() int &#123; // 获取state字段的值 v := atomic.LoadInt32((*int32)(unsafe.Pointer(&amp;m.Mutex))) isLock = v &amp; mutexLocked v = v &gt;&gt; mutexWaiterShift //得到等待者的数值 v = v + isLock //再加上锁持有者的数量，0或者1 return int(v)&#125;// 锁是否被持有func (m *Mutex) IsLocked() bool &#123; state := atomic.LoadInt32((*int32)(unsafe.Pointer(&amp;m.Mutex))) return state&amp;mutexLocked == mutexLocked&#125;// 是否有等待者被唤醒func (m *Mutex) IsWoken() bool &#123; state := atomic.LoadInt32((*int32)(unsafe.Pointer(&amp;m.Mutex))) return state&amp;mutexWoken == mutexWoken&#125;// 锁是否处于饥饿状态func (m *Mutex) IsStarving() bool &#123; state := atomic.LoadInt32((*int32)(unsafe.Pointer(&amp;m.Mutex))) return state&amp;mutexStarving == mutexStarving&#125; 需要注意的是在获取 state 字段的时候，并没有通过 Lock 获取这把锁，所以获取的这个 state 的值是一个瞬态的值。 5. 实现一个线程安全的队列1234567891011121314151617181920212223242526272829type SliceQueue struct &#123; data []interface&#123;&#125; mu sync.Mutex&#125;func NewSliceQueue(n int) (q *SliceQueue) &#123; return &amp;SliceQueue&#123;data: make([]interface&#123;&#125;, 0, n)&#125;&#125;// Enqueue 把值放在队尾func (q *SliceQueue) Enqueue(v interface&#123;&#125;) &#123; q.mu.Lock() q.data = append(q.data, v) q.mu.Unlock()&#125;// Dequeue 移去队头并返回func (q *SliceQueue) Dequeue() interface&#123;&#125; &#123; q.mu.Lock() if len(q.data) == 0 &#123; q.mu.Unlock() return nil &#125; v := q.data[0] q.data = q.data[1:] q.mu.Unlock() return v&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 Mutex 锁]]></title>
    <url>%2F2019%2F02%2F03%2Fgo%2Fgo_sync%2Fgo_sync_3%2F</url>
    <content type="text"><![CDATA[Go 第一个并发原语 Mutex 互斥锁 1. Mutex 的使用互斥锁是最基本的并发原语，基本上所有编程语言都会提供，Go 中互斥锁为 Mutex，Mutex 位于标准库 sync 中，其实现了 sync 中的 Locker 接口: 1234type Locker interface&#123; Lock() Unlock()&#125; 简单来说，互斥锁 Mutex 就提供了这两个方法 Lock 和 Unlock：进入临界区之前调用 Lock 方法，退出临界区的时候调用 Unlock 方法。很多时候 Mutex 会嵌入到其他 struct 中，比如: 12345678910111213141516171819202122type Counter struct&#123; Mutex Count uint64&#125;var c Counterc.Lock()c.Unlock()// 将锁封装不暴露锁type Counter struct &#123; CounterType int Name string mu sync.Mutex count uint64&#125;func (c *Counter) Incr() &#123; c.mu.Lock() c.count++ c.mu.Unlock()&#125; 如果嵌入的 struct 有多个字段，我们一般会把 Mutex 放在要控制的字段上面，然后使用空格把字段分隔开来。以便于代码更容易理解和维护。甚至，你还可以把获取锁、释放锁、计数加一的逻辑封装成一个方法，对外不需要暴露锁等。 2. Mutex 实现Mutex 的实现经过了一个由简单到考虑公平，性能，复杂度复杂实现过程，整个实现过程大体分成了如下四个阶段: 接下来我们会一一介绍 Mutex 各个版本的实现，我觉得下面几点对理解 Mutex 的实现会有所帮助: 调用 Mutext.Lock 和 Mutex.Unlock 是独立的 Goroutine，他们内部会维护一些变量来记录当前的 Goroutine 的状态，比如是被唤醒的，或者已处于饥饿状态 Mutex 中的字段类似于共享内存，每个 Goroutine 都会根据自身的状态更新 Mutex 的值，因此对 Mutex 的修改都需要借助原子操作，来避免数据竞争 阻塞在信号量上的 Goroutine 是一个先进先出队列，位于队列头部的 Goroutine 一定是暂停时间最长的 Goroutine 3. 初版 Mutex初版 Mutex 实现如下: 1234567891011121314151617181920212223242526272829303132333435// CAS操作，当时还没有抽象出atomic包func cas(val *int32, old, new int32) boolfunc semacquire(*int32)func semrelease(*int32)// 互斥锁的结构，包含两个字段type Mutex struct &#123; key int32 // 锁是否被持有的标识 sema int32 // 信号量专用，用以阻塞/唤醒goroutine&#125;// 保证成功在val上增加delta的值func xadd(val *int32, delta int32) (new int32) &#123; for &#123; v := *val if cas(val, v, v+delta) &#123; return v + delta &#125; &#125; panic("unreached")&#125;// 请求锁func (m *Mutex) Lock() &#123; if xadd(&amp;m.key, 1) == 1 &#123; //标识加1，如果等于1，成功获取到锁 return &#125; semacquire(&amp;m.sema) // 否则阻塞等待&#125;func (m *Mutex) Unlock() &#123; if xadd(&amp;m.key, -1) == 0 &#123; // 将标识减去1，如果等于0，则没有其它等待者 return &#125; semrelease(&amp;m.sema) // 唤醒其它阻塞的goroutine&#125; Mutex 结构体包含两个字段： key： 是一个 flag，用来标识这个排外锁是否被某个 goroutine 所持有 如果 key 大于等于 1，说明这个排外锁已经被持有； key 不仅仅标识了锁是否被 goroutine 所持有，还记录了当前持有和等待获取锁的 goroutine 的数量 sema：是个信号量变量，用来控制等待 goroutine 的阻塞休眠和唤醒。 3.1 如何释放锁初版Mutex 的整体设计非常简洁，但是 Unlock 方法可以被任意的 goroutine 调用释放锁，即使是没持有这个互斥锁的 goroutine，也可以进行这个操作。这是因为，Mutex 本身并没有包含持有这把锁的 goroutine 的信息，所以，Unlock 也不会对此进行检查。Mutex 的这个设计一直保持至今。 所以，我们在使用 Mutex 的时候，必须要保证 goroutine 尽可能不去释放自己未持有的锁，一定要遵循“谁申请，谁释放”的原则。从 1.14 版本起，Go 对 defer 做了优化，采用更有效的内联方式，取代之前的生成 defer 对象到 defer chain 中，defer 对耗时的影响微乎其微，基本上都可以将锁的释放放在 defer 中，像下面这样: 1234567891011121314func (f *Foo) Bar() &#123; f.mu.Lock() defer f.mu.Unlock() if f.count &lt; 1000 &#123; f.count += 3 return &#125; f.count++ return&#125; 但是，如果临界区只是方法中的一部分，为了尽快释放锁，还是应该第一时间调用 Unlock，而不是一直等到方法返回时才释放。 3.3 缺陷初版的 Mutex 实现有一个问题：请求锁的 goroutine 会排队等待获取互斥锁。虽然这貌似很公平，但是从性能上来看，却不是最优的。因为如果我们能够把锁交给正在占用 CPU 时间片的 goroutine 的话，那就不需要做上下文的切换，在高并发的情况下，可能会有更好的性能。 4. 给新人机会4.1 state 字段第一次大调整之后，Mutex 实现如下: 123456789101112type Mutex struct &#123; state int32 sema uint32&#125;const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexWaiterShift = iota) 新的 Mutex 中 state 是一个复合型字段: 第一位（最小的一位）来表示这个锁是否被持有 第二位代表是否有唤醒的 goroutine 剩余的位数代表的是等待此锁的 goroutine 数 4.2 Lockstate 变得复杂，请求锁的方法 Lock 也变得复杂。 1234567891011121314151617181920212223242526272829303132333435func (m *Mutex) Lock() &#123; // Fast path: 幸运case，能够直接获取到锁 // 1. state 为 0，表示 如果没有 goroutine 持有锁，也没有等待持有锁的 gorutine if atomic.CompareAndSwapInt32(&amp;m.state, 0, mutexLocked) &#123; return &#125; // 2. for 循环是不断尝试获取锁，如果获取不到，就通过 runtime.Semacquire(&amp;m.sema) 休眠， // 休眠醒来之后 awoke 置为 true，尝试争抢锁。 awoke := false for &#123; old := m.state new := old | mutexLocked // 新状态加锁 // 3. 如果旧锁已经被持有，增加 waiter if old&amp;mutexLocked != 0 &#123; new = old + 1&lt;&lt;mutexWaiterShift //等待者数量加一 &#125; if awoke &#123; // goroutine是被唤醒的， // 4. 新状态清除唤醒标志 new &amp;^= mutexWoken &#125; // 5. 过 CAS 把这个新值赋予 state，尝试抢锁 if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123;//设置新状态 if old&amp;mutexLocked == 0 &#123; // 锁原状态未加锁 break &#125; // 锁原状态已经加锁，休眠 runtime.Semacquire(&amp;m.sema) // 请求信号量 // 唤醒后标识 goroutine 是被唤醒的 awoke = true &#125; &#125;&#125; 在上面的实现中: 因为判断是否能获取锁只会判断最后的 mutexLocked 位，所以新的需要获取锁的 goroutine 也可以获取锁(给新人机会)，让 CPU 中正在执行的 goroutine 有更多的机会获取到锁，在一定程度上提高了程序的性能 所以已睡眠的 goroutine 被唤醒后并不能像先前一样直接获取到锁，还是要和正在请求锁的 goroutine 进行竞争 请求锁的 goroutine 有两类，一类是新来请求锁的 goroutine，另一类是被唤醒的等待请求锁的 goroutine。锁的状态也有两种：加锁和未加锁，下面是 goroutine 不同来源不同状态下的处理逻辑 4.3 Unlock释放锁的逻辑如下: 12345678910111213141516171819202122func (m *Mutex) Unlock() &#123; // Fast path: drop lock bit. new := atomic.AddInt32(&amp;m.state, -mutexLocked) //去掉锁标志 if (new+mutexLocked)&amp;mutexLocked == 0 &#123; //本来就没有加锁 panic("sync: unlock of unlocked mutex") &#125; old := new for &#123; if old&gt;&gt;mutexWaiterShift == 0 || old&amp;(mutexLocked|mutexWoken) != 0 &#123; // 没有等待者，或者有唤醒的waiter，或者锁原来已加锁 return &#125; new = (old - 1&lt;&lt;mutexWaiterShift) | mutexWoken // 新状态，准备唤醒goroutine，并设置唤醒标志 // 对 state 状态的更新始终通过原子操作，保证不会数据竞争 if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; runtime.Semrelease(&amp;m.sema) return &#125; // for 循环重试必须更新 old 变量 old = m.state &#125;&#125; 将加锁置为未加锁的状态，这个方法也不能直接返回，因为还可能有一些等待这个锁的 goroutine(成为 waiter) 需要通过信号量唤醒，所以接下来的逻辑有4种种情况： 如果没有其它的 waiter 如果有其他 waiter 并且有被唤醒的 waiter 直接返回 如果有其他 waiter 但此时锁已经被其他 goroutine 加锁直接返回 如果有等待者，并且没有唤醒的 waiter，锁仍然处于未加锁状态，需要唤醒一个等待的 waiter 前三种情况就对应条件1234// // 没有等待者，或者有唤醒的 waiter，或者锁原来已加锁if old&gt;&gt;mutexWaiterShift == 0 || old&amp;(mutexLocked|mutexWoken) != 0 &#123; return&#125; 所有对 state 的操作都通过原子操作完成，保证了不会发生数据竞争，其余通过快速失败逻辑，快速结束。需要注意的是 for 循环重试必须更新 old 变量。 4.4 改进相对于初版的设计，这次的改动主要就是，新来的 goroutine 也有机会先获取到锁，甚至一个 goroutine 可能连续获取到锁，打破了先来先得的逻辑。但是，代码复杂度也显而易见。 这一版的 Mutex 已经给新来请求锁的 goroutine 一些机会，让它参与竞争，没有空闲的锁或者竞争失败才加入到等待队列中。但是其实还可以进一步优化。 5. 多给些机会在 2015 年 2 月的改动中，如果新来的 goroutine 或者是被唤醒的 goroutine 首次获取不到锁，它们就会通过自旋（spin，通过循环不断尝试，spin 的逻辑是在runtime 实现的）的方式，尝试检查锁是否被释放。在尝试一定的自旋次数后，再执行原来的逻辑。 1234567891011121314151617181920212223242526272829303132333435363738394041func (m *Mutex) Lock() &#123; // Fast path: 幸运之路，正好获取到锁 if atomic.CompareAndSwapInt32(&amp;m.state, 0, mutexLocked) &#123; return &#125; awoke := false iter := 0 for &#123; // 不管是新来的请求锁的goroutine, 还是被唤醒的goroutine，都不断尝试请求锁 old := m.state // 先保存当前锁的状态 new := old | mutexLocked // 新状态设置加锁标志 // ################## 新增的自旋逻辑 ####################### if old&amp;mutexLocked != 0 &#123; // 锁还没被释放 if runtime_canSpin(iter) &#123; // 还可以自旋 if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; atomic.CompareAndSwapInt32(&amp;m.state, old, old|mutexWoken) &#123; awoke = true &#125; runtime_doSpin() iter++ continue // 自旋，再次尝试请求锁 &#125; // ################## 新增的自旋逻辑 ####################### new = old + 1&lt;&lt;mutexWaiterShift &#125; if awoke &#123; // 唤醒状态 if new&amp;mutexWoken == 0 &#123; panic("sync: inconsistent mutex state") &#125; new &amp;^= mutexWoken // 新状态清除唤醒标记 &#125; if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; if old&amp;mutexLocked == 0 &#123; // 旧状态锁已释放，新状态成功持有了锁，直接返回 break &#125; runtime_Semacquire(&amp;m.sema) // 阻塞等待 awoke = true // 被唤醒 iter = 0 &#125; &#125;&#125; 对于临界区代码执行非常短的场景来说，新增的自旋逻辑是一个非常好的优化，因为临界区的代码耗时很短，锁很快就能释放，而抢夺锁的 goroutine 不用通过休眠唤醒方式等待调度，直接 spin 几次，可能就获得了锁。 这里我们来详细介绍一下自旋里面的判断逻辑: runtime_canSpin(iter): 表示 goroutine 可以继续执行持续抢锁 !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0: 当前还没有被唤醒的 waiter，锁仍处于加锁状态，等待锁的 goroutine 大于 0 此时将锁的 mutexWoken 和 awoke 设为 1，表示有 goroutine 处于唤醒状态 continue: 自旋，再次尝试请求锁，如果此时锁被释放，可以执行下面的抢锁逻辑 new = old + 1&lt;&lt;mutexWaiterShift: 如果 goroutine 已经不能自旋，将等待的 waiter 加一，符合 mutexWaiterShift 表示的当前等待锁的 goroutine 数的含义 123456789101112if old&amp;mutexLocked != 0 &#123; // 锁还没被释放 if runtime_canSpin(iter) &#123; // 还可以自旋 if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; atomic.CompareAndSwapInt32(&amp;m.state, old, old|mutexWoken) &#123; awoke = true &#125; runtime_doSpin() iter++ continue // 自旋，再次尝试请求锁 &#125; // ################## 新增的自旋逻辑 ####################### new = old + 1&lt;&lt;mutexWaiterShift 因为新来的 goroutine 也参与竞争，有可能每次都会被新来的 goroutine 抢到获取锁的机会，在极端情况下，等待中的 goroutine 可能会一直获取不到锁，这就是饥饿问题。 6. 解决饥饿2016 年 Go 1.9 中 Mutex 增加了饥饿模式，让锁变得更公平，不公平的等待时间限制在 1 毫秒，并且修复了一个大 Bug：总是把唤醒的 goroutine 放在等待队列的尾部，会导致更加不公平的等待时间。之后 2018 年，Go 开发者将 fast path 和 slow path 拆成独立的方法，以便内联，提高性能。2019 年也有一个 Mutex 的优化，虽然没有对 Mutex 做修改，但是，对于 Mutex 唤醒后持有锁的那个 waiter，调度器可以有更高的优先级去执行，这已经是很细致的性能优化了。 当前 Mutex 代码已经复杂得接近不可读的状态了，而且代码也非常长，我们慢慢来看。整个实现的逻辑大概是: 正常模式下，waiter 都是进入先入先出队列，因此阻塞在信号量中的第一个 goroutine 就是等待最久的那个。 所以在饥饿模式下，Mutex 的拥有者将直接把锁交给队列最前面的 waiter。新来的 goroutine 不会尝试获取锁，即使看起来锁没有被持有，它也不会去抢，也不会 spin，它会乖乖地加入到等待队列的尾部。 因为等待最久的 goroutine 总是处于信号量队列中的第一个，所以他总是被第一个唤醒，所以饥饿模式下，处于运行中的 goroutine 只能是新的 goroutine 和当前饥饿的 goroutine，只有处于饥饿的 goroutine 才能将锁的饥饿位设置为 1 6.1 state 字段state 在原有的基础上增加了饥饿模式: 12345678910111213type Mutex struct &#123; state int32 sema uint32&#125;const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexStarving // 从state字段中分出一个饥饿标记 mutexWaiterShift = iota starvationThresholdNs = 1e6) 6.2 Lock添加饥饿模式后，Lock 增加了如下逻辑: 自旋部分: old&amp;(mutexLocked|mutexStarving) == mutexLocked 锁是非饥饿状态，锁还没被释放，才尝试自旋 是否去抢锁: 如果存在饥饿 goroutine ，当前 goroutine 直接等待，不抢锁 if old&amp;(mutexLocked|mutexStarving) != 0 {new += 1 &lt;&lt; mutexWaiterShift} if old&amp;(mutexLocked|mutexStarving) == 0 {break} 保持等待最久的 goroutine 始终处于信号量队列的队首: runtime_SemacquireMutex(&amp;m.sema, queueLifo, 1)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485func (m *Mutex) Lock() &#123; // Fast path: 幸运之路，一下就获取到了锁 // 1. 1. state 为 0，表示 如果没有 goroutine 持有锁，也没有等待持有锁的 gorutine，直接加锁 if atomic.CompareAndSwapInt32(&amp;m.state, 0, mutexLocked) &#123; return &#125; // Slow path：缓慢之路，尝试自旋竞争或饥饿状态下饥饿goroutine竞争 m.lockSlow()&#125;func (m *Mutex) lockSlow() &#123; var waitStartTime int64 starving := false // 此goroutine的饥饿标记 awoke := false // 唤醒标记 iter := 0 // 自旋次数 old := m.state // 当前的锁的状态 for &#123; // 锁是非饥饿状态，锁还没被释放，尝试自旋 if old&amp;(mutexLocked|mutexStarving) == mutexLocked &amp;&amp; runtime_canSpin(iter) &#123; if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; atomic.CompareAndSwapInt32(&amp;m.state, old, old|mutexWoken) &#123; awoke = true &#125; runtime_doSpin() iter++ old = m.state // 再次获取锁的状态，之后会检查是否锁被释放了 continue &#125; new := old if old&amp;mutexStarving == 0 &#123; new |= mutexLocked // 非饥饿状态，加锁 &#125; // 如果存在饥饿 goroutine ，当前 goroutine 直接等待，不抢锁 if old&amp;(mutexLocked|mutexStarving) != 0 &#123; new += 1 &lt;&lt; mutexWaiterShift // waiter数量加1 &#125; if starving &amp;&amp; old&amp;mutexLocked != 0 &#123; new |= mutexStarving // 设置饥饿状态 &#125; if awoke &#123; if new&amp;mutexWoken == 0 &#123; throw("sync: inconsistent mutex state") &#125; new &amp;^= mutexWoken // 新状态清除唤醒标记 &#125; // 成功设置新状态 if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; // 原来锁的状态已释放，并且不是饥饿状态，正常请求到了锁，返回 if old&amp;(mutexLocked|mutexStarving) == 0 &#123; break // locked the mutex with CAS &#125; // 处理饥饿状态 // 如果以前就在队列里面，加入到队列头 queueLifo := waitStartTime != 0 if waitStartTime == 0 &#123; waitStartTime = runtime_nanotime() &#125; // 阻塞等待 runtime_SemacquireMutex(&amp;m.sema, queueLifo, 1) // 唤醒之后检查锁是否应该处于饥饿状态 starving = starving || runtime_nanotime()-waitStartTime &gt; starvationThresholdNs old = m.state // 如果锁已经处于饥饿状态，直接抢到锁，返回 if old&amp;mutexStarving != 0 &#123; if old&amp;(mutexLocked|mutexWoken) != 0 || old&gt;&gt;mutexWaiterShift == 0 &#123; throw("sync: inconsistent mutex state") &#125; // 有点绕，加锁并且将waiter数减1 // - 1&lt;&lt;mutexWaiterShift 表示 waiter 减去 1 // mutexLocked 表示加锁 delta := int32(mutexLocked - 1&lt;&lt;mutexWaiterShift) if !starving || old&gt;&gt;mutexWaiterShift == 1 &#123; delta -= mutexStarving // 最后一个waiter或者已经不饥饿了，清除饥饿标记 &#125; atomic.AddInt32(&amp;m.state, delta) break &#125; awoke = true iter = 0 &#125; else &#123; old = m.state &#125; &#125;&#125; 6.3 Unlock1234567891011121314151617181920212223242526272829func (m *Mutex) Unlock() &#123; // Fast path: drop lock bit. new := atomic.AddInt32(&amp;m.state, -mutexLocked) if new != 0 &#123; m.unlockSlow(new) &#125;&#125;func (m *Mutex) unlockSlow(new int32) &#123; if (new+mutexLocked)&amp;mutexLocked == 0 &#123; throw("sync: unlock of unlocked mutex") &#125; if new&amp;mutexStarving == 0 &#123; old := new for &#123; if old&gt;&gt;mutexWaiterShift == 0 || old&amp;(mutexLocked|mutexWoken|mutexStarving) != 0 &#123; return &#125; new = (old - 1&lt;&lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; runtime_Semrelease(&amp;m.sema, false, 1) return &#125; old = m.state &#125; &#125; else &#123; runtime_Semrelease(&amp;m.sema, true, 1) &#125;&#125; 7. Mutex 采坑记录使用 Mutex 常见的错误场景有 4 类，分别是 Lock/Unlock 不是成对出现 Copy 已使用的 Mutex 重入 死锁手误和重入导致的死锁，是最常见的使用 Mutex 的 Bug。 7.1 Lock/Unlock 不是成对出现Lock/Unlock 不是成对出现Lock/Unlock 没有成对出现，就意味着会出现死锁，或者是因为 Unlock 一个未加锁的 Mutex 而导致 panic。证 Lock/Unlock 成对出现，尽可能采用 defer mutex.Unlock 的方式，把它们成对、紧凑地写在一起。 7.2 Copy 已使用的 MutexPackage sync 的同步原语在使用后是不能复制的。原因在于，Mutex 是一个有状态的对象，它的 state 字段记录这个锁的状态。如果你要复制一个已经加锁的 Mutex 给一个新的变量，那么新的刚初始化的变量居然被加锁了，这显然不符合你的期望，因为你期望的是一个零值的 Mutex。关键是在并发环境下，你根本不知道要复制的 Mutex 状态是什么，因为要复制的 Mutex 是由其它 goroutine 并发访问的，状态可能总是在变化。 Go 在运行时，有死锁的检查机制（checkdead() 方法），它能够发现死锁的 goroutine。但是显然我们不想运行的时候才发现这个因为复制 Mutex 导致的死锁问题。我们可以使用 vet 工具: go vet counter.go，把检查写在 Makefile 文件中，在持续集成的时候跑一跑，这样可以及时发现问题，及时修复。 vet 检查原理vet 检查是通过copylock分析器静态分析实现的。这个分析器会分析函数调用、range 遍历、复制、声明、函数返回值等位置，有没有锁的值 copy 的情景，以此来判断有没有问题。可以说，只要是实现了 Locker 接口，就会被分析。 7.3 重入Mutex 不是可重入的锁，因为 Mutex 的实现中没有记录哪个 goroutine 拥有这把锁。理论上，任何 goroutine 都可以随意地 Unlock 这把锁，所以没办法计算重入条件。所以，一旦误用 Mutex 的重入，就会导致报错。下一节我们将介绍如何基于 Mutex 实现一个可重入锁。 7.4 死锁要产生死锁必须具备以下几个条件： 互斥： 至少一个资源是被排他性独享的，其他线程必须处于等待状态，直到资源被释放 持有和等待：goroutine 持有一个资源，并且还在请求其它 goroutine 持有的资源 不可剥夺：资源只能由持有它的 goroutine 来释放 环路等待：一般来说，存在一组等待进程，P={P1，P2，…，PN}，P1 等待 P2 持有的资源，P2 等待 P3 持有的资源，依此类推，最后是 PN 等待 P1 持有的资源，这就形成了一个环路等待的死结 Go 死锁探测工具只能探测整个程序是否因为死锁而冻结了，不能检测出一组 goroutine 死锁导致的某一块业务冻结的情况。你还可以通过 Go 运行时自带的死锁检测工具，或者是第三方的工具（比如go-deadlock、go-tools）进行检查，这样可以尽早发现一些死锁的问题。不过，有些时候，死锁在某些特定情况下才会被触发，所以，如果你的测试或者短时间的运行没问题，不代表程序一定不会有死锁问题。 如果发现线上可能出现了死锁，我们可以通过 Go pprof 工具进行分析，它提供了一个 block profiler 监控阻塞的 goroutine。除此之外，我们还可以查看全部的 goroutine 的堆栈信息，通过它，你可以查看阻塞的 groutine 究竟阻塞在哪一行哪一个对象上了。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 Go 并发调试工具]]></title>
    <url>%2F2019%2F02%2F02%2Fgo%2Fgo_sync%2Fgo_sync_2%2F</url>
    <content type="text"><![CDATA[在我们正式介绍 Go 并发编程之前，我们先来介绍 Go 语言提供的一些并发调试工具，这些工具可以帮我们有效的发现并发编程中的 bug 1. Go race detectorGo race detector可以帮助我们自动发现程序有没有数据竞争(data race)，它是基于 Google 的 C/C++ sanitizers 技术实现的，编译器通过探测所有的内存访问，加入代码能监视对这些内存地址的访问（读还是写）。在代码运行的时候，race detector 就能监控到对共享变量的非同步访问，出现 race 时，就会打印出警告信息。 1.1 使用在编译（compile）、测试（test）或者运行（run）Go 代码的时候，加上 race 参数，就有可能发现并发问题。 12345// -race 启动 data race 检测go run -race counter.go// 显示添加 -race 后编译的 go 代码go tool compile -race -S counter.go 虽然这个工具使用起来很方便，但是，因为它的实现方式，只能通过真正对实际地址进行读写访问的时候才能探测，所以它不能再编译的时候发现 data race 问题，而且只有在运行时出现 data race 才能检测到。如果碰巧没有出现 data race 是检测不出来的。 2. 复制检测Package sync 的同步原语在使用后是不能复制的。原因在于，Mutex 是一个有状态的对象，它的 state 字段记录这个锁的状态。如果你要复制一个已经加锁的 Mutex 给一个新的变量，那么新的刚初始化的变量居然被加锁了，这显然不符合你的期望，因为你期望的是一个零值的 Mutex。关键是在并发环境下，你根本不知道要复制的 Mutex 状态是什么，因为要复制的 Mutex 是由其它 goroutine 并发访问的，状态可能总是在变化。 Go 在运行时，有死锁的检查机制（checkdead() 方法），它能够发现死锁的 goroutine。但是显然我们不想运行的时候才发现这个因为复制 Mutex 导致的死锁问题。我们可以使用 vet 工具: go vet counter.go，把检查写在 Makefile 文件中，在持续集成的时候跑一跑，这样可以及时发现问题，及时修复。 vet 检查是通过copylock分析器静态分析实现的。这个分析器会分析函数调用、range 遍历、复制、声明、函数返回值等位置，有没有锁的值 copy 的情景，以此来判断有没有问题。可以说，只要是实现了 Locker 接口，就会被分析。 1go vet counter.go 3. 死锁检测go-deadlock、go-tools 4. Go pprof]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 go 并发编程入门指南]]></title>
    <url>%2F2019%2F02%2F01%2Fgo%2Fgo_sync%2Fgo_sync_1%2F</url>
    <content type="text"><![CDATA[这个系列我们来学习 Go 中的并发编程。 1. 并发编程真难为什么会突然出现这个系列呢，原因也很简单，最近在极客时间发现了一个 Go 并发编程的专栏，越看越觉得牛逼。基本上已经看完了，但是都已经忘记差不多了。前些日子双十一，刚撺掇了我弟报了一个 Go 的培训班，我两想借此机会转型 Go 成功。所以这个系列就是 Go 并发编程专栏的读书笔记。 2. 学习资料Go 并发编程目前看到了下面一些好的学习材料 Go语言高级编程: 这本书的前几章详细介绍了 Go 中常见的并发原语的使用 Go专家编程: 这是一本讲 Go 实现原理的书，里面也有一章讲解了常见的并发原语的实现 极客专栏-Go 并发编程实战课: 从实现到使用，讲解了 Go 并发编程的几乎方方面面的内容 强烈推荐极客专栏-Go 并发编程实战课，里面介绍的一些扩展并发原语我也是第一次看到。看着就20节课，但是一节课顶两节课。Go 的学习我已经差了好几个系列的博客没写了。希望 2020 年结束前，能把这个系列和 Go 设计模式系列的博客写完。 操蛋的2020赶紧结束，预祝大家可能经历挫折，最终都能收获满满。 3. 内容大纲并发编程的核心是解决并发编程中的资源管理问题，通常包括如下场景: 共享资源: 共享资源的读写 任务编排: 让 goroutine 按照特定的顺序执行 消息传递: 不同 goroutine 之间的数据传递 这个系列我们将学习如下内容: 基本并发原语: 包括 Mutex，RWMutex，WaitGroup，Cond，Pool，Context，这些都是传统的并发原语在其他语言中也很常见 原子操作: Go 标准库提供的原子操作 Channel: Go 语言独有的类型，是 Go 实现消息传递的核心数据结构 扩展并发原语： 包括信号量，SingleFlight，循环栅栏，ErrGroup 分布式并发原语: 使用 etcd 实现一些分布式并发原语，比如 Leader选举，分布式互斥锁，分布式读写锁，分布式队列 我们将按照专栏扥内容顺序，分为使用，原理，易错场景三个部分去讲解每一块内容。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>go并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2. 创建型]]></title>
    <url>%2F2019%2F01%2F13%2Fgo%2Fgo_design%2Fgo_design_2%2F</url>
    <content type="text"><![CDATA[设计模式之创建型 1. Go 实现的设计模式Go 编程一个很大的特点就是”接口先行”，因为接口是 go 实现泛型的标准方法。因为 Go 没有面型对象中继承的概念，因此当我们为实现某个设计模式去创建一个类时，第一反应应该是先创建接口。 本节我们来学习创建型中的三种设计模式: 简单工厂函数 工厂方法 抽象工厂 创建者模式（Builder） 原型模式（Prototype） 单例模式（Singleton） 2. 简单工厂函数go 语言没有构造函数一说，所以一般会定义NewXXX函数来初始化相关类。 NewXXX 函数返回接口时就是简单工厂模式。这是 Go 中创建对象的标准方式。下面是一个简单示例: 首先我们为类定义接口 API 定义具体的类 HiAPI 实现接口 API 定义 NewHi() 创建HiAPI对象 123456789101112131415161718192021package modeimport "fmt"// API hello interfacetype API interface &#123; Say(name string) string&#125;// NewAPI API 接口的工厂函数func NewAPI() API &#123; return &amp;HiAPI&#123;&#125;&#125;// HiAPI API 实现一type HiAPI struct&#123;&#125;// Say say hifunc (*HiAPI) Say(name string) string &#123; return fmt.Sprintf("Hi %s", name)&#125; 3. 工厂方法与简单工厂在一个函数内创建多种不同的对象相比，工厂为每个待创建的对象使用单独的函数。然后再使用类似简单工厂函数的load 函数进行整合。形式上就是就是将简单工厂函数内创建不同对象的逻辑拆分到额外的不同函数中。工厂方法适用于对象创建逻辑非常复杂的场景。 比如，我们现在需要解析不同格式的配置文件: 首先我们要为配置文件的解析定义接口 ConfigParse 因为我们要为不同的对象定义不同的工场函数，所以我们要为工厂函数定义一个接口 Factory 最后创建简单的工厂函数整合对象的创建逻辑 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// ConfigParse 定义配置文件解析接口type ConfigParse interface &#123; Parse(path string) map[string]int&#125;//JSONParse 解析 jsontype JSONParse struct &#123;&#125;// Parse 解析jsonfunc (*JSONParse) Parse(path string) map[string]int &#123; return map[string]int&#123;"json": 1&#125;&#125;// XMLParse 解析 XMLtype XMLParse struct &#123;&#125;// Parse 解析 xmlfunc (*XMLParse) Parse(path string) map[string]int &#123; return map[string]int&#123;"XML": 2&#125;&#125;// ConfigFactory 工厂函数创建接口type ConfigFactory interface &#123; Create(path string) ConfigParse&#125;type XMLFactory struct &#123;&#125;func (*XMLFactory) Create(path string) XMLParse &#123; return XMLParse&#123;&#125;&#125;type JSONFactor struct &#123;&#125;func (*JSONFactor) Create(path string) JSONParse &#123; return JSONParse&#123;&#125;&#125;func NewParser(path string) ConfigParse &#123; if path == ".json" &#123; return JSONFactor&#123;&#125;.Create(path) &#125; return XMLFactory&#123;&#125;.Create(path)&#125; 4. 抽象工厂抽象工厂用于创建一组相关的对象。比如我们现在需要为一组关联的主订单对象 OrderMain 和订单详情对象 OrderDetail 定义不同的保存格式: 首先我们要为 OrderMain，OrderDetail 对象定义保存接口 实现 OrderMain，OrderDetail 的关系数据库和 XML 的保存方式 定义创建工厂函数的接口 实现创建不同保存方式的工厂函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 1. 为 OrderMain，OrderDetail 的保存定义接口import "fmt"//OrderMainDAO 为订单主记录type OrderMainDAO interface &#123; SaveOrderMain()&#125;//OrderDetailDAO 为订单详情纪录type OrderDetailDAO interface &#123; SaveOrderDetail()&#125;// 2. OrderMain，OrderDetail 的保存实现//RDBMainDAP 为关系型数据库的OrderMainDAO实现type RDBMainDAO struct&#123;&#125;//SaveOrderMain ...func (*RDBMainDAO) SaveOrderMain() &#123; fmt.Print("rdb main save\n")&#125;//RDBDetailDAO 为关系型数据库的OrderDetailDAO实现type RDBDetailDAO struct&#123;&#125;// SaveOrderDetail ...func (*RDBDetailDAO) SaveOrderDetail() &#123; fmt.Print("rdb detail save\n")&#125;// 3. 定义抽象工厂的接口//DAOFactory DAO 抽象模式工厂接口type DAOFactory interface &#123; CreateOrderMainDAO() OrderMainDAO CreateOrderDetailDAO() OrderDetailDAO&#125;// 4. 抽象工厂函数的实现//RDBDAOFactory 是RDB 抽象工厂实现type RDBDAOFactory struct&#123;&#125;func (*RDBDAOFactory) CreateOrderMainDAO() OrderMainDAO &#123; return &amp;RDBMainDAO&#123;&#125;&#125;func (*RDBDAOFactory) CreateOrderDetailDAO() OrderDetailDAO &#123; return &amp;RDBDetailDAO&#123;&#125;&#125; 5. 创建者模式创建模式用来解决对象构造参数过多，参数验证逻辑复杂的对象创建问题，通过将参数收集和验证放在创建者中来创建不可变对象或者避免创建的对象处于未定义的中间状态。 比如，我们现在要创建一个 Car 对象，它包含各种属性比如颜色，核载人数，并且核载人数有限制: 定义 Car 对象 定义创建 Car 的创建者接口 CarBuild 实现一个创建小汽车的创建者 BuildSmallCar 123456789101112131415161718192021222324252627282930313233343536/*创建者模式*/type Car struct &#123; Num int Color string&#125;type CarBuild interface &#123; SetNum(int)Build SetColor(string) Build() Car&#125;type BuildSmallCar struct &#123; Num int Color string&#125;func (b *BuildSmallCar) SetNum(num int) &#123; if num &lt; 10 &#123; b.Num = num &#125;&#125;func (b *BuildSmallCar) SetColor(color string) &#123; b.Color = color&#125;func (b *BuildSmallCar) Build() Car&#123; return Car&#123; Num: b.Num, Color: b.Color, &#125;&#125; 6. 原型链原型链表示的是一种对象属性查找次序，是实现面向对象的另一种方式，像 JavaScript、Lua 就是使用原型链来实现面向对象，Go 语言使用的比较少，在此补在详述。 6. 单例模式单例模式用于创建系统唯一对象，需要使用加锁保证并发情况下对象创建唯一。 12345678910111213import "sync"type Singleton struct&#123;&#125;var singleton *Singletonvar once sync.Once//GetInstance 用于获取单例模式对象func GetInstance() *Singleton &#123; once.Do(func() &#123; singleton = &amp;Singleton&#123;&#125; &#125;) return singleton&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 go reflect]]></title>
    <url>%2F2019%2F01%2F13%2Fgo%2Fgo_grammar%2Fgo_13%2F</url>
    <content type="text"><![CDATA[go 反射机制 1. 反射机制反射是一个复杂的内省技术。所谓内省即可以动态获取变量的类型，值，以及方法属性等元数据。需要反射的根本原因是，很多时候我们在编程时，并不能确定输入的具体类型，需要我们动态去判断。 Go语言提供的反射机制，能够让我们在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要在编译时就知道这些变量的具体类型。也可以让我们将类型本身作为第一类的值类型处理。 GO 中有两个至关重要的API是使用反射机制实现： fmt包提供的字符串格式功能 类似encoding/json和encoding/xml提供的针对特定协议的编解码功能。 本节我们就来看看如何使用 Go 的反射机制，以及上述两个包使用 reflect 的方式。 2. Reflect API反射是由 reflect 包提供的。 它定义了两个重要的类型, Type 和 Value 2.1 TypeType 是一个接口类型，唯一能反映 reflect.Type 实现的是接口的类型描述信息。 我们在接口一节说过，接口的值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。对于像Go语言这种静态类型的语言，类型是编译期的概念；因此一个类型不是一个值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。而 reflect.Type 的实现方式就与接口中的类型描述符类似。 reflect.Type 有许多办法来区分类型以及检查它们的组成部分, 例如一个结构体的成员或一个函数的参数等。 TypeOfreflect.TypeOf 接受任意的 interface{} 类型, 并以reflect.Type形式返回一个动态类型的接口值。reflect.Type 满足 fmt.Stringer 接口。 fmt.Printf 提供的 %T 参数, 内部就是使用 reflect.TypeOf 来输出接口的动态类型。 12345t := reflect.TypeOf(3) // a reflect.Typefmt.Println(t.String()) // "int"fmt.Println(t) // "int"fmt.Printf("%T\n", 3) // "int" 2.2 Valuereflect.Value 可以装载任意类型的值。函数 reflect.ValueOf 接受任意的 interface{} 类型, 并返回一个装载着其动态值的 reflect.Value。和 reflect.Type 类似, reflect.Value 也满足 fmt.Stringer 接口, 但是除非 Value 持有的是字符串, 否则 String 方法只返回其类型. 而使用 fmt 包的 %v 标志参数会对 reflect.Values 特殊处理. 1234v := reflect.ValueOf(3) // a reflect.Valuefmt.Println(v) // "3"fmt.Printf("%v\n", v) // "3"fmt.Println(v.String()) // NOTE: "&lt;int Value&gt;" 对 Value 调用 Type 方法将返回具体类型所对应的 reflect.Type:12t := v.Type() // a reflect.Typefmt.Println(t.String()) // "int" 2.3 Value 与 interface{}reflect.ValueOf 的逆操作是 reflect.Value.Interface 方法. 它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值。 1234v := reflect.ValueOf(3) // a reflect.Valuex := v.Interface() // an interface&#123;&#125;i := x.(int) // an intfmt.Printf("%d\n", i) // "3 reflect.Value 和 interface{} 都能装载任意的值. 所不同的是, 一个空的接口隐藏了值内部的表示方式和所有方法, 因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值(就像上面那样),内部值我们没法访问. 相比之下, 一个 Value 则有很多方法来检查其内容, 无论它的具体类型是什么。 与 switch x := x.(type) 相比 reflect.Value.Kind 返回的数据类型是有限的: Bool, String 和 所有数字类型的基础类型 Array 和 Struct 对应的聚合类型; Chan, Func, Ptr, Slice, 和 Map 对应的引用类型; interface 类型; 还有表示空值的 Invalid 类型 (空的 reflect.Value 的 kind 即为 Invalid.) Kind 只关心底层表示, 所有的具名类型都会归属到对应的原始类型之上。 2.4 示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func Display(name string, x interface&#123;&#125;) &#123; fmt.Printf("Display %s (%T):\n", name, x) display(name, reflect.ValueOf(x))&#125;func formatAtom(v reflect.Value) string &#123; switch v.Kind() &#123; case reflect.Invalid: return "invalid" case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return strconv.FormatInt(v.Int(), 10) case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr: return strconv.FormatUint(v.Uint(), 10) // ...floating‐point and complex cases omitted for brevity... case reflect.Bool: return strconv.FormatBool(v.Bool()) case reflect.String: return strconv.Quote(v.String()) case reflect.Chan, reflect.Func, reflect.Ptr, reflect.Slice, reflect.Map: return v.Type().String() + " 0x" + strconv.FormatUint(uint64(v.Pointer()), 16) default: // reflect.Array, reflect.Struct, reflect.Interface return v.Type().String() + " value" &#125;&#125;func display(path string, v reflect.Value) &#123; switch v.Kind() &#123; case reflect.Invalid: fmt.Printf("%s = invalid\n", path) case reflect.Slice, reflect.Array: for i := 0; i &lt; v.Len(); i++ &#123; display(fmt.Sprintf("%s[%d]", path, i), v.Index(i))&#125; case reflect.Struct: for i := 0; i &lt; v.NumField(); i++ &#123; fieldPath := fmt.Sprintf("%s.%s", path, v.Type().Field(i).Name) display(fieldPath, v.Field(i))&#125; case reflect.Map: for _, key := range v.MapKeys() &#123; display(fmt.Sprintf("%s[%s]", path, formatAtom(key)), v.MapIndex(key))&#125; case reflect.Ptr: if v.IsNil() &#123; fmt.Printf("%s = nil\n", path) &#125; else &#123; display(fmt.Sprintf("(*%s)", path), v.Elem())&#125; case reflect.Interface: if v.IsNil() &#123; fmt.Printf("%s = nil\n", path) &#125; else &#123; fmt.Printf("%s.type = %s\n", path, v.Elem().Type()) display(path+".value", v.Elem()) &#125; default: // basic types, channels, funcs fmt.Printf("%s = %s\n", path, formatAtom(v)) &#125;&#125;]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9 go 包和管理工具]]></title>
    <url>%2F2019%2F01%2F11%2Fgo%2Fgo_grammar%2Fgo_11%2F</url>
    <content type="text"><![CDATA[go 程序包组织结构和程序管理工具箱 1. 包简介包和模块的概念几乎存在于所有的编程语言之中，它的存在是为了简化大型程序的设计和维护工作。通过将一组相关的特性放进一个独立的单元以便于理解和更新，这种特性提供诸多益处: 每个包可以被其它的不同项目共享和重用 包提供了一个独立的命名空间，减少了与其他部分的命名冲突 通过控制包内名字的可见性和是否导出来实现封装 Go 通过使用名字的开头字母的大小写决定了名字在包外的可见性，小写字符开头包成员不会导出，在包外不可见。通过这种方式可以严格的隐藏包内实现的 API，通过强制用户使用特定函数来访问和更新内部变量，可以保证内部变量的一致性和并发时的互斥约束。 当我们修改了一个源文件，我们必须重新编译该源文件对应的包和所有依赖该包的其他包。即使是从头构建，Go语言编译器的编译速度也明显快于其它编译语言。Go语言的闪电般的编译速度主要得益于三个语言特性: 第一点，所有导入的包必须在每个文件的开头显式声明，这样的话编译器就没有必要读取和分析整个源文件来判断包的依赖关系 第二点，禁止包的环状依赖，因为没有循环依赖，包的依赖关系形成一个有向无环图，每个包可以被独立编译，而且很可能是被并发编译 第三点，编译后包的目标文件不仅仅记录包本身的导出信息，目标文件同时还记录了包的依赖关系。因此，在编译一个包的时候，编译器只需要读取每个直接导入包的目标文件，而不需要遍历所有依赖的的文件。 本节我们就来学习与 Go 语言包相关的内容。 2. Go 程序包2.1 包声明Go 语言的源码也是以代码包为基本组织单位的。在文件系统中，这些代码包其实是与目录一一对应的。由于目录可以有子目录，所以代码包也可以有子包。一个代码包中可以包含任意个以.go 为扩展名的源码文件，这些源码文件都需要被声明属于同一个代码包。 在每个Go语言源文件的开头都必须有包声明语句。包声明语句的主要目的是确定当前包被其它包导入时默认的标识符（也称为包名）。代码包的名称一般会与源码文件所在的目录同名。如果不同名，那么在构建、安装的过程中会以代码包名称为准。 通常来说，默认的包名就是包导入路径名的最后一段，因此即使两个包的导入路径不同，它们依然可能有一个相同的包名。例如，math/rand包和crypto/rand包的包名都是rand。这也有三种例外情况。 第一个例外，包对应一个可执行程序，也就是main包，这时候main包本身的导入路径是无关紧要的。名字为main的包是给go build 构建命令一个信息，这个包编译完之后必须调用连接器生成一个可执行程序。 第二个例外，包所在的目录中可能有一些文件名是以 _test.go为后缀的Go源文件（译注：前面必须有其它的字符，因为以 _前缀的源文件是被忽略的），并且这些源文件声明的包名也是以_test为后缀名的。这种目录可以包含两种包：一种普通包，加一种则是测试的外部扩展包。所有以_test为后缀包名的测试外部扩展包都由go test命令独立编译，普通包和测试的外部扩展包是相互独立的。测试的外部扩展包一般用来避免测试代码中的循环导入依赖，具体细节我们将在下一章讲解。 第三个例外，一些依赖版本号的管理工具会在导入路径后追加版本号信息，例如”gopkg.in/yaml.v2”。这种情况下包的名字并不包含版本号后缀，而是yaml 2.2 包的导入每个包是由一个全局唯一的字符串所标识的导入路径定位。在实际使用程序实体之前，我们必须先导入其所在的代码包。在工作区中，一个代码包的导入路径实际上就是从 src 子目录，到该包的实际存储位置的相对路径。而导入时包可以被重命名，被隐藏。下面是包导入时常用的语法: 12345678package package_nameimport fmtimport ( "crypto/rand" mrand "math/rand" // 包导入重命名，避免冲突 import _ "image/png" // 匿名导入) 需要注意的事: 包的导入必须在包声明语句之后，其它非导入声明语句之前 每个导入声明语句都明确指定了当前包和被导入包之间的依赖关系。如果遇到包循环导入的情况，Go语言的构建工具将报告错误。 Go语言的规范并没有指明包的导入路径字符串的具体含义，导入路径的具体含义是由构建工具来解释的，当使用Go语言自带的go工具箱时，一个导入路径代表一个包在文件系统的路径 2.3 包的初始化每个包在解决依赖的前提下，包会以导入声明的顺序初始化，包的初始化首先是解决包级变量的依赖顺序，然后按照包级变量声明出现的顺序依次初始化： 1234var a = b + c // a 第三个初始化, 为 3var b = f() // b 第二个初始化, 为 2, 通过调用 f (依赖c)var c = 1 // c 第一个初始化, 为 1func f() int &#123; return c + 1 &#125; 如果包中含有多个.go源文件，它们将按照发给编译器的顺序进行初始化，Go语言的构建工具首先会将.go文件根据文件名排序，然后依次调用编译器编译。 每个包只会被初始化一次。因此，如果一个p包导入了q包，那么在p包初始化的时候可以认为q包必然已经初始化过了。初始化工作是自下而上进行的，main包最后被初始化。以这种方式，可以确保在main函数执行之前，所有依赖的包都已经完成初始化工作了。 对于在包级别声明的变量，如果有初始化表达式则用表达式初始化，还有一些没有初始化表达式的，例如某些表格数据初始化并不是一个简单的赋值过程。在这种情况下，我们可以用一个特殊的init初始化函数来简化初始化工作。每个文件都可以包含多个init初始化函数 1func init() &#123; /* ... */ &#125; 这样的init初始化函数除了不能被调用或引用外，其他行为和普通函数类似。在每个文件中的init初始化函数，在程序开始执行时按照它们声明的顺序被自动调用。 匿名导入如果只是导入一个包而并不使用导入的包将会导致一个编译错误。但是有时候我们只是想利用导入包而产生的副作用：计算包级变量的初始化表达式和执行导入包的init初始化函数。我们可以用下划线 _来重命名导入的包。像往常一样，下划线 _为空白标识符，并不能被访问。 包文档Go语言中包文档注释一般是完整的句子，第一行是包的摘要说明，注释后仅跟着包声明语句。包注释可以出现在任何一个源文件中。如果包的注释内容比较长，一般会放到一个独立的源文件中；fmt包注释就有300行之多。这个专门用于保存包文档的源文件通常叫doc.go。 内部包有时候，一个中间的状态可能也是有用的，对于一小部分信任的包是可见的，但并不是对所有调用者都可见。例如，当我们计划将一个大的包拆分为很多小的更容易维护的子包，但是我们并不想将内部的子包结构也完全暴露出去。同时，我们可能还希望在内部子包之间共享一些通用的处理包，或者我们只是想实验一个新包的还并不稳定的接口，暂时只暴露给一些受限制的用户使用 为了满足这些需求，Go语言的构建工具对包含internal名字的路径段的包导入路径做了特殊处理。这种包叫internal包，一个internal包只能被和internal目录有同一个父目录的包所导入。例如，net/http/internal/chunked内部包只能被net/http/httputil或net/http包导入，但是不能被net/url包导入。不过net/url包却可以导入net/http/httputil包。1234net/httpnet/http/internal/chunkednet/http/httputilnet/url go 命令使用go get使用命令 go get可以下载一个单一的包或者用 …下载整个子目录里面的每个包。Go语言工具箱的go命令同时计算并下载所依赖的每个包，一旦 go get命令下载了包，然后就是安装包或包对应的可执行的程序 go get命令支持当前流行的托管网站GitHub、Bitbucket和Launchpad，可以直接向它们的版本控制系统请求代码。对于其它的网站，你可能需要指定版本控制系统的具体路径和协议，例如 Git或Mercurial。 123456go get github.com/golang/lint/golintcd $GOPATH/src/golang.org/x/netgit remote ‐vorigin https://go.googlesource.com/net (fetch)origin https://go.googlesource.com/net (push) 需要注意的是导入路径含有的网站域名和本地Git仓库对应远程服务地址并不相同，真实的Git地址是go.googlesource.com。这其实是Go语言工具的一个特性，可以让包用一个自定义的导入路径，但是真实的代码却是由更通用的服务提供，例如googlesource.com或github.com。因为页面 https://golang.org/x/net/html 包含了如下的元数据，它告诉Go语言的工具当前包真实的Git仓库托管地址： 12&lt;meta name=&quot;go‐import&quot;content=&quot;golang.org/x/net git https://go.googlesource.com/net&quot;&gt; 如果指定 ‐u命令行标志参数， go get命令将确保所有的包和依赖的包的版本都是最新的，然后重新编译和安装它们。如果不包含该标志参数的话，而且如果包已经在本地存在，那么代码那么将不会被自动更新。 go buildgo build命令编译命令行参数指定的每个包。如果包是一个库，则忽略输出结果；这可以用于检测包的可以正确编译的。如果包的名字是main， go build将调用连接器在当前目录创建一个可执行程序；以导入路径的最后一段作为可执行程序的名字 默认情况下， go build命令构建指定的包和它依赖的包，然后丢弃除了最后的可执行文件之外所有的中间编译结果。 go install命令和 go build命令很相似，但是它会保存每个包的编译成果，而不是将它们都丢弃。被编译的包会被保存到$GOPATH/pkg目录下，目录路径和 src目录路径对应，可执行程序被保存到$GOPATH/bin目录。 goinstall命令和 go build命令都不会重新编译没有发生变化的包，这可以使后续构建更快捷。为了方便编译依赖的包， go build ‐i命令将安装每个目标所依赖的包。 因为编译对应不同的操作系统平台和CPU架构， go install命令会将编译结果安装到GOOS和GOARCH对应的目录。例如，在Mac系统，golang.org/x/net/html包将被安装到$GOPATH/pkg/darwin_amd64目录下的golang.org/x/net/html.a文件。 针对不同操作系统或CPU的交叉构建也是很简单的。只需要设置好目标对应的GOOS和GOARCH，然后运行构建命令即可。下面交叉编译的程序将输出它在编译时操作系统和CPU类型：有些包可能需要针对不同平台和处理器类型使用不同版本的代码文件，以便于处理底层的可移植性问题或提供为一些特定代码提供优化。如果一个文件名包含了一个操作系统或处理器类型名字，例如net_linux.go或asm_amd64.s，Go语言的构建工具将只在对应的平台编译这些文件。还有一个特别的构建注释注释可以提供更多的构建过程控制。例如，文件中可能包含下面的注释： // +build linux darwin在包声明和包注释的前面，该构建注释参数告诉 go build只在编译程序对应的目标操作系统是Linux或Mac OS X时才编译这个文件。下面的构建注释则表示不编译这个文件 // +build ignore更多细节，可以参考go/build包的构建约束部分的文档 go doc go doc命令，该命令打印包的声明和每个成员的文档注释，该命令并不需要输入完整的包导入路径或正确的大小写 1234go doc timego doc time.Sincego doc time.Duration.Secondsgo doc json.decode godoc，它提供可以相互交叉引用的HTML页面，但是包含和 go doc命令相同以及更多的信息。godoc的在线服务 https://godoc.org ，包含了成千上万的开源包的检索工具。你也可以在自己的工作区目录运行godoc服务。运行下面的命令，然后在浏览器查看 http://localhost:8000/pkg 页面： $ godoc ‐http :8000 其中 ‐analysis=type和 ‐analysis=pointer命令行标志参数用于打开文档和代码中关于静态分析的结果 go listgo list命令可以查询可用包的信息。其最简单的形式，可以测试包是否在工作区并打印它的导入路径，还可以用 “…”表示匹配任意的包的导入路径。我们可以用它来列表工作区中的所有包： 123456$ go list github.com/go‐sql‐driver/mysqlgithub.com/go‐sql‐driver/mysql$ go list gopl.io/ch3/...$ go list ...xml... go list命令还可以获取每个包完整的元信息，而不仅仅只是导入路径，这些元信息可以以不同格式提供给用户。其中 ‐json命令行参数表示用JSON格式打印每个包的元信息。命令行参数 ‐f则允许用户使用text/template包（§4.6）的模板语言定义输出文本的格式。 123go list ‐json hashgo list ‐f '&#123;&#123;join .Deps " "&#125;&#125;' strconvgo list ‐f '&#123;&#123;.ImportPath&#125;&#125; ‐&gt; &#123;&#123;join .Imports " "&#125;&#125;' compress/...]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8 go 并发编程一]]></title>
    <url>%2F2019%2F01%2F08%2Fgo%2Fgo_grammar%2Fgo_8%2F</url>
    <content type="text"><![CDATA[Go 并发编程原语，Goroutines和Channels 1. GO 并发编程简介上一篇我们讲解了 Go 语言中的接口，至此对于 Go 语言的类型系统我们基本上讲的差不都了。接下来我们将深入了解 Go 最为人推广的特性并发编程。对于那些完全独立的子问题，并发是简单的，但是真正复杂的是处理那些存在资源共享的多进程多线程并发问题。我们需要有效的通信机制来处理程序中的竞争条件，同时避免可能出现的死锁问题。 Go 之所以在并发编程中被人推广，是因为它提供的 goroutine 和 channel 支持“顺序通信进程”(communicating sequential processes)简称为CSP，这是一种现代的并发编程模型。CSP的具体原理我也不是很懂，但是 Go 有一句口头禅“不要使用共享数据来通信；使用通信来共享数据” 。学完这部分内容，你就能理解这句话的含义了。 没有一招鲜吃遍天的技术，每个模型都是特定的假设条件和使用情景，CSP 也不例外。相比于 GSP 传统的并发模型：多线程共享内存，可能更容易出错(竞争条件和死锁)，但是也更加灵活。所以要想写出正确的并发程序，对操作系统提供的锁，信号量等进程间通信的底层机制的了解必不可少。我们将分为三节来介绍这些并发编程的技巧，本节我们先来学习 goroutine 和 channel。 2. Goroutine在Go语言中，每一个并发的执行单元叫作一个goroutine。当一个程序启动时，其主函数即在一个单独的goroutine中运行，我们叫它main goroutine 。 2.1 goroutine 创建新的goroutine会用go语句来创建。在语法上，go语句是一个普通的函数或方法调用前加上关键字go。go语句会使其语句中的函数在一个新创建的goroutine中运行。而go语句本身会迅速地完成。 12f() // call f(); wait for it to returngo f() // create a new goroutine that calls f(); don't wait 2.2 goroutine 退出与回收通常goroutine在执行完毕时会自动回收，当主函数返回时，所有未执行完毕的 goroutine 会被直接打断，程序退出。如果 goroutine 因为阻塞永远被卡住，我们称发生了goroutine泄漏，和垃圾变量不同，泄漏的goroutines并不会被自动回收，因此确保每个不再需要的goroutine能正常退出是重要的。 2.3 goroutine 中断除了从主函数退出或者直接终止程序之外，没有其它的编程方法能够让一个goroutine来打断另一个的执行。但是通过 goroutine 之间的通信机制，可以实现让一个 goroutine 在收到其它的 goroutine 特定信号时终止退出。这个必须得等到我们讲完 channel 时才能继续说明。 3. channels如果说goroutine是Go语言程序的并发体的话，那么 channels 则是它们之间的通信机制。一个 channels 可以让一个 goroutine 通过它给另一个 goroutine 发送值信息。 每个channel都有一个特殊的类型，也就是channels可发送数据的类型。和其它的引用类型一样，channel的零值也是nil，因此channel 可以与 nil 值比较。两个相同类型的channel可以使用==运算符比较。如果两个channel引用的是相通的对象，那么比较的结果为真。 3.1 channel 创建创建 channel 最简单的方式是使用 make 函数，第二个可选参数，用于指定 channel 的容量。 123456ch = make(chan int) // 无缓存 channel ch = make(chan int, 0) // 无缓存 channel ch = make(chan int, 3) // 待缓存的 channelcap(ch) // 获取 channel 容量len(ch) // 返回 channel 中有效元素个数 channel 与并发的先进先出队列极其相似: 发送在队尾插入元素，接收从队首删除元素 当 channel 空时，从 channel 接收值的 goroutine 将被阻塞，直至另一个 goroutine 向 channel 发送值 当 channel 满时，向 channel 发送值的 goroutine 将被阻塞，直至另一个 goroutine 从 channel 接收值 特别的对于无缓存 channels 的发送和接收操作将导致两个goroutine做一次同步操作，需要注意的是当通过一个无缓存 channels 发送数据时，接收者收到数据发生在唤醒发送者 goroutine 之前。 3.2 发送与接收channel有发送和接受两种操作: 12345ch &lt;‐ x // 向 channel 发送一个值x = &lt;‐ch // 从 channel 接收值&lt;‐ch // 从 channel 接收值，但丢弃close(ch) // 关闭 channel 为了防止 channel 被乱用，Go语言还提供了单方向的 channel 类型，即只发送或只接收的channel。 12345// 只发送和只接受的 channel 类型chan&lt;‐ int // 只发送int的channel，不能接收&lt;‐chan int // 只接收int的channel，不能发送func squarer(out chan&lt;‐ int, in &lt;‐chan int) &#123;&#125; 任何双向channel向单向channel变量的赋值操作都将导致该隐式转换。但是没有反向转换的语法，即不能将类似 chan&lt;‐ int类型的单向型的channel转换为 chan int类型的双向型的channel。 因为关闭操作只用于断言不再向channel发送新的数据，所以只有在发送者所在的 goroutine 才会调用close函数，因此对一个只接收的channel调用 close 将是一个编译错误。 3.3 关闭channel还支持close操作，用于关闭channel，对于接收方和发送方，关闭channel之后的操作是不同的: 发送方: 对一个关闭的 channel 的任何发送操作都将导致panic异常，因此关闭操作只能由发送方执行 接收方: 在 channel 关闭之后依然可以接受到之前已经成功发送的数据；如果channel中已经没有数据，后续的接收操作也不会再阻塞，而是立即返回一个零值。稍后我们就会利用这个特性，通过关闭 channel实现一种广播机制。 所以对于下面这个例子，即使 naturals变量对应的channel 被关闭，循环也不会终止，它依然会收到一个永无休止的零值序列。 1234567// Squarergo func() &#123; for &#123; x := &lt;‐naturals squares &lt;‐ x * x &#125;&#125;() 没有办法直接测试一个channel是否被关闭，但是接收操作有一个变体形式：它多接收一个结果，多接收的第二个结果是一个布尔值ok，ture表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。range 可以简化对 channels 的读取和关闭测试，下面是一些代码示例: 12345678910111213141516171819// 通过可选的第二个参数，在接收方判断 channel 是否关闭go func() &#123; for &#123; x, ok := &lt;‐naturals if !ok &#123; break // channel was closed and drained &#125; squares &lt;‐ x * x &#125; close(squares)&#125;()// range循环可直接在channels上迭代，当channel被关闭并且没有值可接收时跳出循环go func() &#123; for x := range naturals &#123; squares &lt;‐ x * x &#125; close(squares)&#125;() 最后，试图关闭一个nil值的channel也将导致panic异常。 4. select 多路复用有些时候，我们需要同时监听多个 channel 的接收和发送操作，并选择第一个可执行 channel 进行操作。此时我们就需要 select 多路复用。select 与 和 switch 语句稍微有点相似，select 也会有几个 case和最后的default选择分支。每一个case代表一个通信操作(在某个channel上进行发送或者接收)并且会包含一些语句组成的一个语句块。 12345678910select &#123;case &lt;‐ch1: // ...case x := &lt;‐ch2: // ...use x...case ch3 &lt;‐ y: // ...default: // ...&#125; select会等待case中的 channel 操作，直至出现一个可通信的 channel 时，执行通信并选择对应的 case 执行；这时候其它通信是不会执行的。一个没有任何case的select语句写作select{}，会永远地等待下去。如果多个case同时就绪时，select会随机地选择一个执行，这样来保证每一个channel都有平等的被select的机会。 对一个nil的channel发送和接收操作会永远阻塞，在select语句中操作nil的channel永远都不会被select到。这使得我们可以用nil来激活或者禁用case，来达成处理其它输入或输出事件时超时和取消的逻辑。 5. goroutine 的中断有了上面的铺垫，我们回头来看如何中断一个 goroutine 的执行。现在我们知道，当一个被关闭的 channel 被消费掉了所有已发送的值之后，对channel 的任何操作会立即被执行，并且产生零值。我们将代表取消操作的 channel 作为 select 的一个分支，一个立刻返回的分支；通过关闭 channel 让所有操作该 channel 的代码都可以立马执行，从而 select 会选择退出分支，让 goroutine 立刻终止。通过 channel 的取消操作，我们实现了一种广播机制。下面是一个简单的代码示例: 123456789101112131415161718192021222324252627# 广播机制var done = make(chan struct&#123;&#125;)func cancelled() bool &#123; select &#123; case &lt;‐done: // channel 被关闭后，立马就会执行 return true default: return false &#125;&#125;# 监听用户的取消操作go func() &#123; os.Stdin.Read(make([]byte, 1)) // read a single byte close(done) // 通过关闭 channel，进行消息广播&#125;()func walkDir(dir string, n *sync.WaitGroup, fileSizes chan&lt;‐ int64) &#123; defer n.Done() if cancelled() &#123; // 发现用户取消，立刻终止 return &#125; for _, entry := range dirents(dir) &#123; // ... &#125;&#125; 6. 使用示例接下来，我们将探究一个生成缩略图的问题来作为 goroutine 和 channel 的使用示例。下面是一个顺序执行的版本。 123456789// makeThumbnails makes thumbnails of the specified files.func makeThumbnails(filenames []string) &#123; for _, f := range filenames &#123; # 缩略图执行的函数，具体代码省略 if _, err := thumbnail.ImageFile(f); err != nil &#123; log.Println(err) &#125; &#125;&#125; 显然，我们可以使用并发来加快程序的执行速度。 123456// NOTE: incorrect!func makeThumbnails2(filenames []string) &#123; for _, f := range filenames &#123; go thumbnail.ImageFile(f) // NOTE: ignoring errors &#125;&#125; 然而上面面的程序是有问题的，makeThumbnails(下称主函数)在 go 创建的 goroutine(下称 work goroutine) 还没有完成工作之前就已经返回了。我们需要主函数等待 work goroutine 完成。我们可以使用 channel 进行同步。 123456789101112131415func makeThumbnails4(filenames []string) error &#123; errors := make(chan error) for _, f := range filenames &#123; go func(f string) &#123; _, err := thumbnail.ImageFile(f) errors &lt;‐ err &#125;(f) &#125; for range filenames &#123; if err := &lt;‐errors; err != nil &#123; return err // NOTE: incorrect: goroutine leak! &#125; &#125; return nil&#125; 这个程序有一个微秒的bug。当它遇到第一个非nil的error时会直接将error返回到调用方，使得没有一个goroutine去排空errors channel。这样剩下的worker goroutine在向这个channel中发送值时，都会永远地阻塞下去，并且永远都不会退出。即出现goroutine泄露，可能会导致整个程序卡住或者跑出out of memory的错误。 最简单的解决办法就是用一个具有合适大小的buffered channel(c h := make(chan item, len(filenames)))，这样这些worker goroutine向channel中发送错误时就不会被阻塞。另一个可选的解决办法是创建一个另外的goroutine，当maingoroutine返回第一个错误的同时去排空channel。 此外，如果文件过多，程序可能会创建成百上千的 goroutine，我们需要用计数信号量来限制并发的数量。 12345678910// 限制并发数的信号量var sema = make(chan struct&#123;&#125;, 20)go func(f string) &#123; sema &lt;‐ struct&#123;&#125;&#123;&#125; // 执行前获取 token defer func() &#123; &lt;‐sema &#125;() // 执行结束后释放 token _, err := thumbnail.ImageFile(f) errors &lt;‐ err&#125;(f) 7. 使用局限至此，我们已经掌握了goroutine 和 channel的基本使用，但是还远远不够。我们无法解决像下面这些问题:]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7 go 接口]]></title>
    <url>%2F2019%2F01%2F07%2Fgo%2Fgo_grammar%2Fgo_7%2F</url>
    <content type="text"><![CDATA[Go 的泛型编程 1. 接口概述接口是 Go 语言提供的泛型的核心概念。所谓泛型就是允许程序员在强类型程序设计语言中编写代码时使用一些以后才指定的类型，目的是增加函数的通用性。当然我们没必要去纠结概念，最重要的是搞明白，Go 如何通过接口来提高程序的灵活性。 在学习接口之前，我们需要对它有如下一个整体的认识，以把握住接口的整体脉络: Go 的接口类型是抽象类型，与 Python 中鸭子类型类似，通过类型支持的方法来约束对象的适用范围。我们将学些如何在 Go 定义接口，如何判断一个具体类型实现了哪些接口。 接口不仅是对类型的抽象和限定，也代表了将接口作为参数的函数和函数调用者之间的一个约定(正是通过这种约定提高了函数的可用性): 调用者需要提供符合接口的具体类型作为参数 函数在接受任何满足接口的值时都可以工作，函数不会调用接口限定之外的任何其他方法 有了上面的铺垫，我们将按照下面的顺序介绍接口的相关内容: 接口类型 接口的定义 接口归属判断 接口的约定 接口值 类型断言 2. 接口类型2.1 接口定义接口类型是一种抽象的类型，与字符串，整数这些具体类型相比，我们并不知道接口类型代表的具体值；它只包含方法声明，描述了一系列方法的集合。下面是 Go 接口类型的定义示例: 1234567891011121314151617package iotype Reader interface &#123; Read(p []byte) (n int, err error)&#125;type Closer interface &#123; Close() error&#125;type Writer interface &#123; Write(p []byte) (n int, err error)&#125;type ReadWriter interface &#123; Reader Writer&#125; 与结构体嵌入类似，我们也可以通过类似的方式进行接口内嵌，实现接口组合。在接口的定义中方法的定义顺序没有影响，唯一重要的是接口内的方法集合。 2.2 接口归属判断如果一个类型拥有一个接口需要的所有方法，那么这个类型就实现了这个接口，我们称这个具体类型是这个接口类型的实例。正如我们在 go 方法一章所描述的，一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了所有值方法和所有指针方法。因此对于一个自定义类型，他的类型和他的指针类型实现的接口并不相同。 1234567891011121314// 1. 表达一个类型属于某个接口只要这个类型实现这个接口var rwc io.ReadWriteCloserrwc = os.Stdout // OK: *os.File has Read, Write, Close methodsrwc = new(bytes.Buffer) // compile error: *bytes.Buffer lacks Close method// 2. 接口归属的判断同样适合接口之间w = rwc // OK: io.ReadWriteCloser has Write methodrwc = w // compile error: io.Writer lacks Close method// 3. 类型 与 类型的指针类型，实现的接口并不相同，后者可能实现了更多的接口type IntSet struct &#123; /* ... */ &#125;func (*IntSet) String() stringvar _ fmt.Stringer = &amp;s // OKvar _ fmt.Stringer = s // compile error: IntSet lacks String method 每一个具体类型的组基于它们相同的行为可以表示成一个接口类型。接口不止是一种有用的方式来分组相关的具体类型和表示他们之间的共同特定。在Go语言中我们可以在需要的时候定义一个新的抽象或者特定特点的组，而不需要修改具体类型的定义。 2.3 接口的约定正如我们开篇所说的，接口类型不仅是对类型的约束，也代表着函数和调用者之间的约定。 1234567891011121314151617181920type Writer interface &#123; Write(p []byte) (n int, err error)&#125;func Fprintf(w io.Writer, format string, args ...interface&#123;&#125;) (int, error)type ByteCounter intfunc (c *ByteCounter) Write(p []byte) (int, error) &#123; *c += ByteCounter(len(p)) // convert int to ByteCounter return len(p), nil&#125;var c ByteCounterc.Write([]byte("hello"))fmt.Println(c) // "5", = len("hello")c = 0 // reset the countervar name = "Dolly"fmt.Fprintf(&amp;c, "hello, %s", name)fmt.Println(c) // "12", = len("hello, Dolly") 如上例所述，io.Writer 接口约定了，函数调用者必须提供实现了 io.Writer 接口的具体类型作为函数参数，而 Fprintf 函数只能调用 io.Writer 接口暴露出来的方法，即使具体类型有其它的方法也不能调用。 2.4 空接口interface{}被称为空接口，空接口类型是不可或缺的。因为空接口类型对实现它的类型没有要求，所以我们可以将任意一个值赋给空接口类型。当然我们不能直接对它持有的值做操作，因为interface{}没有任何方法。我们会在稍后介绍一种用类型断言来获取interface{}中值的方法。 123456var any interface&#123;&#125;any = trueany = 12.34any = "hello"any = map[string]int&#123;"one": 1&#125;any = new(bytes.Buffer) 3. 接口的值3.1 接口赋值概念上讲一个接口的值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。对于像Go语言这种静态类型的语言，类型是编译期的概念；因此一个类型不是一个值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。 我们通过下面一个赋值的示例来了解接口的值 1234var w io.Writerw = os.Stdoutw = new(bytes.Buffer)w = nil var w io.Writer定义了变量w，变量总是被一个定义明确的值初始化，即使接口类型也不例外。对于一个接口的零值就是它的类型和值的部分都是nil。一个接口值仅基于它的动态类型被描述为空或非空，因此一个不包含任何值的nil接口值和一个刚好包含nil指针的接口值是不同的，后者不为 nil。 你可以通过使用w==nil或者w!=nil来判读接口值是否为空。调用一个空接口值上的任意方法都会产生panic。调用一个包含 nil 指针的接口上的方法是否会报错，取决于接口内包含的动态类型。 123456789101112// w，f 都是特定类型的空值，将他们赋值给 w 都将得到一个 包含nil指针的接口值var w io.Writervar f *os.Filevar buf *bytes.Buffer// 对 *os.File的类型，nil是一个有效的接收者，所以不会报错w = f w.Writer()// (*bytes.Buffer).Write方法的接收者必须非空，调用会报错w = bufbuf，Writer() w = os.Stdout这个赋值过程调用了一个具体类型到接口类型的隐式转换，这和显式的使用io.Writer(os.Stdout)是等价的。此时这个接口值的动态类型被设为*os.File指针的类型描述符，它的动态值持有os.Stdout的拷贝； w = nil这个重置将它所有的部分都设为nil值，把变量w恢复到和它之前定义时的状态。 一个接口值可以持有任意大的动态值。从概念上讲，不论接口值多大，动态值总是可以容下它。（这只是一个概念上的模型；具体的实现可能会非常不同） 3.2 接口比较接口值可以使用==和!＝来进行比较。两个接口值相等仅当它们都是nil值或者它们的动态类型相同并且动态值也根据这个动态类型的==操作相等。因为接口值是可比较的，所以它们可以用在map的键或者作为switch语句的操作数。 然而，如果两个接口值的动态类型相同，但是这个动态类型是不可比较的（比如切片），将它们进行比较就会失败并且panic: 12var x interface&#123;&#125; = []int&#123;1, 2, 3&#125;fmt.Println(x == x) // panic: comparing uncomparable type []int 考虑到这点，接口类型是非常与众不同的。其它类型要么是安全的可比较类型（如基本类型和指针）要么是完全不可比较的类型（如切片，映射类型，和函数），但接口的可比性取决接口包含的动态类型。但是在比较接口值或者包含了接口值的聚合类型时，我们必须要意识到潜在的panic。同样的风险也存在于使用接口作为map的键或者switch的操作数。只能比较你非常确定它们的动态值是可比较类型的接口值。 通过 fmt包的%T 动作，我们可以获取接口值的动态类型，在fmt包内部，使用反射来获取接口动态类型的名称。关于反射，我们后面在详述。 123456var w io.Writerfmt.Printf("%T\n", w) // "&lt;nil&gt;"w = os.Stdoutfmt.Printf("%T\n", w) // "*os.File"w = new(bytes.Buffer)fmt.Printf("%T\n", w) // "*bytes.Buffer" 4. 类型断言类型断言是我们使用 Go 语言中接口的另一种方式。前面的第一个方式中，一个接口的方法表达了实现这个接口的具体类型间的相似性，但是隐藏了代表的细节和这些具体类型本身的操作。重点在于方法上，而不是具体的类型上。 第二种使用方式利用了一个接口值可以持有各种具体类型值的能力并且将这个接口认为是这些类型的 union（联合）。类型断言用来动态地区别出接口包含的每一个类型，做不同处理。在这个方式中，重点在于具体的类型满足这个接口，而不是在于接口的方法（如果它确实有一些的话），并且没有任何的信息隐藏。我们将以这种方式使用的接口描述为discriminated unions（可辨识联合）。 通过类型断言，我们至少可以实现下面这些目标: 区别错误类型 判断对象是否支持特定的方法 4.1 语法x.(T): x - 表示待判断的接口类型，T - 表示断言的类型 如果 T 是一个具体类型，类型断言检查 x 的动态类型是否和T相同，相同，返回 x 的动态值 如果 T 是一个接口类型，类型断言检查 x 的动态类型是否满足T，满足，返回包含 x 动态类型和动态值的接口 T 的值 12345678910111213141516// 具体类型断言var w io.Writerw = os.Stdoutrw := w.(io.ReadWriter) // success: *os.File has both Read and Writew = new(ByteCounter) rw = w.(io.ReadWriter) // panic: *ByteCounter has no Read method， 断言失败触发 panic// 接口类型断言var w io.Writer = os.Stdoutf, ok := w.(*os.File) // success: ok, f == os.Stdoutb, ok := w.(*bytes.Buffer) // failure: !ok, b == nil// 通过第二个变量接受断言是否成功，替代断言失败时的异常if w, ok := w.(*os.File); ok &#123; // if 引出了新的作用域，因此这里发生的是对变量名的重新，发生了变量的覆盖，不是变量的重新赋值。// ...use w...&#125; 换句话说，对一个接口类型的断言改变了类型的表述方式，改变了可以获取的方法集合（通常更大），我们几乎不需要对一个更少限制性的接口类型（更少的方法集合）做断言，因为它表现的就像赋值操作一样，除了对于nil接口值的情况。如果断言操作的对象是一个nil接口值，那么不论被断言的类型是什么这个类型断言都会失败。 123// 对更小的接口无需断言，可直接赋值w = rw // io.ReadWriter is assignable to io.Writerw = rw.(io.Writer) // fails only if rw == nil 4.2 类型开关类型断言有一个 Switch 的便捷语法，称为类型开关，一个类型开关像普通的switch语句一样，它的运算对象是x.(type)－它使用了关键词字面量type－并且每个case有一到多个类型。一个类型开关基于这个接口值的动态类型使一个多路分支有效。一个使用示例如下所示: 1234567891011121314151617func sqlQuote(x interface&#123;&#125;) string &#123; switch x := x.(type) &#123; case nil: return "NULL" case int, uint: return fmt.Sprintf("%d", x) // x has type interface&#123;&#125; here. case bool: if x &#123; return "TRUE" &#125; return "FALSE" case string: return sqlQuoteString(x) // (not shown) default: panic(fmt.Sprintf("unexpected type %T: %v", x, x)) &#125;&#125; 这个示例还展示了，类型开关语句的一个扩展的形式，它可以将提取的值绑定到一个在每个case范围内的新变量 switch x := x.(type) { /* ... */ }。在这个版本的函数中，在每个单一类型的case内部，变量x和这个case的类型相同。例如: 变量 x 在bool的case中是bool类型和string的case中是string类型 在所有其它的情况中，变量x是 switch 运算对象的类型（接口）；在这个例子中运算对象是一个interface{} 当多个 case 需要相同的操作时，比如int和uint的情况，类型开关可以很容易的合并这些情况]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6 go 方法]]></title>
    <url>%2F2019%2F01%2F06%2Fgo%2Fgo_grammar%2Fgo_6%2F</url>
    <content type="text"><![CDATA[Go 的对象组合技术 1. 内容概要方法是面向对象编程(OOP)中的概念。有关 OOP 的定义我也说不清楚。但是与概念相比，更重要的是OOP的两个关键点:封装和组合。我们的目的是看看 Go 语言如何通过结构体嵌入等技术实现这两个关键点。 Go 语言中的方法和接口密切相关，接口是 Go 语言提供的用来支持泛型编程的核心组件，我们会在下一章详细讨论。现在我们只需要明白: 方法是与特定类型关联的函数，可以被声明到任意命名类型，包括 Go 的内置类型;但不能是一个指针或者一个接口类型 方法分为值方法和指针方法两类，这会影响到类型是否属于特定接口的判断 2. 方法2.1 方法声明在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。 123456789101112type Point struct&#123; X, Y float64 &#125;// 1. 为 Point 定义一个值方法// 参数p，叫做方法的接收器(receiver)func (p Point) Distance(q Point) float64 &#123; return math.Hypot(q.X‐p.X, q.Y‐p.Y)&#125;// 2. 调用方法p := Point&#123;1, 2&#125;q := Point&#123;4, 6&#125;fmt.Println(p.Distance(q)) // "5", method call 从上面的示例可以看出来，在方法的定义和调用等行为上，Go 与 Python 并没有什么太大差别。有一点不同的是，当出现命名冲突时，Python 的默认行为是覆盖，而 Go 在编译阶段就直接失败。此外需要注意的是方法和属性在同一命名空间，因此它们之间的命名冲突也是不允许的。 2.2 值方法与指针方法前面函数的部分我们说过，Go 中实参通过值的方式传递。类似的，传递给方法接收器的对象也是按值传递。在上面的 Distance 内接收器 p 是外部 p 对象的拷贝。相对应的我们可以像下面这样，用其指针而不是对象来声明方法。 1234func (p *Point) ScaleBy(factor float64) &#123; p.X *= factor p.Y *= factor&#125; 2.3 接收器限制只有类型(Point)和指向他们的指针(*Point)，才是可能会出现在接收器声明里的两种接收器。为了避免歧义，在声明方法时，如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的，比如下面这个例子。即我们不能为指针定义方法。 12type P *intfunc (P) f() &#123; /* ... */ &#125; // compile error: invalid receiver type 2.4 方法调用中的隐式转换原则上，类型 Point只能调用其值方法，*Point只能调用其指针方法。这样在方法的调用中会有很多转换操作。幸运的是，Go 为我们提供了隐示的转换，就像我们直接通过指针去访问结构的成员变量一样。 12345678910p := Point&#123;1, 2&#125;pptr := &amp;p// type --&gt; *typep.ScaleBy(2) // 等同于(&amp;p).ScaleBy(2)// *type --&gt; typepptr.Distance(q) // 等同于(*pptr).Distance(q) 需要特别注意的是 type --&gt; *type 转换的前提是对象是可取址的。我们不能通过一个无法取到地址的接收器来调用指针方法，比如临时变量： 1Point&#123;1, 2&#125;.ScaleBy(2) // compile error: can't take address of Point literal 2.5 类型的方法集合如上所述，正因为我们总是可以通过对一个地址解引用(*)来获取变量，但是却不一定能获取一个对象的地址(临时对象)，所以一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243//1. pkg 包内定义 animal 和 Dogpackage pkgtype animal struct &#123; Name string&#125;type Dog struct &#123; animal Weight int&#125;func NewDog() Dog &#123; return Dog&#123;animal&#123;"aaa"&#125;, 100&#125;&#125;func (g Dog) GetName() string &#123; return g.Name&#125;func (g *Dog) GetWeight() int &#123; return g.Weight&#125;// 2 mian 包内使用package mainimport ( "fmt" "mygo/pkg")func main() &#123; g := pkg.NewDog() fmt.Printf("%T, %#v\n", g, g) fmt.Println(g.Weight) // 注意: 此处我们可以直接访问 g.Weight fmt.Println(g.Name) fmt.Printf("%T\n", (*pkg.Dog).GetName) // func(*pkg.Dog) string fmt.Printf("%T\n", (*pkg.Dog).GetWeight) // func(*pkg.Dog) int fmt.Printf("%T\n", pkg.Dog.GetName) // func(pkg.Dog) string // fmt.Printf("%T\n", pkg.Dog.GetWeight)&#125; 在上面的示例中: 通过结构体直接访问方法，我们将获取一个方法值，值方法是一个函数，其接受的参数与调用的方式有关，以结构体调用，返回的函数需要接受结构体，以结构体指针调用，返回的函数需要接受结构体的指针 所有的值方法可以通过结构体，也可以通过结构体的指针进行访问，所有的指针方法只能通过结构体指针进行访问 这里也反应出一个自定义数据类型的方法集合中仅会包含它的所有值方法，而该类型的指针类型的方法集合却囊括了前者的所有方法，包括所有值方法和所有指针方法。 3. 结构体嵌入3.1 结构体嵌入与类的继承在结构体一节中，我们就已经提到了，结构体中通过匿名字段嵌入的不仅仅是结构体的成员还是其方法。以下面嵌入了 Point 的 ColoredPoint 为例，我们可以把ColoredPoint类型当作接收器来调用Point里的方法，即使ColoredPoint里没有声明这些方法。 12345678910111213141516import "image/color"type Point struct&#123; X, Y float64 &#125;type ColoredPoint struct &#123; Point Color color.RGBA&#125;red := color.RGBA&#123;255, 0, 0, 255&#125;blue := color.RGBA&#123;0, 0, 255, 255&#125;var p = ColoredPoint&#123;Point&#123;1, 1&#125;, red&#125;var q = ColoredPoint&#123;Point&#123;5, 4&#125;, blue&#125;fmt.Println(p.Distance(q.Point)) // "5"p.ScaleBy(2)q.ScaleBy(2)fmt.Println(p.Distance(q.Point)) // "10" 这种行为看起来跟 OOP 类的继承一样，但是有本质区别。最明显的地方是，在类的继承中，子类的实例也是基类的实例，但是在结构体嵌入中，ColoredPoint 类型的”实例”，并不是 Point 的”实例”。 请注意上面例子中对Distance方法的调用。尽管q有着Point这个内嵌类型，但是q并不是一个Point类，我们必须要显式地选择它。 12p.Distance(q.Point) // rightp.Distance(q) // compile error: cannot use q (ColoredPoint) as Point 在 Go 的结构体嵌入中，我们只能说 ColoredPoint has a Point 而不能说 ColoredPoint 继承自 Point。内嵌可以使我们将复杂类型的定义拆分，将字段先按小类型分组，然后定义小类型的方法，之后再把它们组合起来。 3.2 嵌入命名类型的指针在类型中内嵌的匿名字段也可能是一个命名类型的指针，添加这一层间接关系让我们可以共享通用的结构并动态地改变对象之间的关系。 12345678910111213type ColoredPoint struct &#123; *Point Color color.RGBA&#125;p := ColoredPoint&#123;&amp;Point&#123;1, 1&#125;, red&#125;q := ColoredPoint&#123;&amp;Point&#123;5, 4&#125;, blue&#125;// 注意访问 *q.Point 的区别fmt.Println(p.Distance(*q.Point)) // "5"q.Point = p.Point // p and q now share the same Pointp.ScaleBy(2)fmt.Println(*p.Point, *q.Point) // "&#123;2 2&#125; &#123;2 2&#125;" 3.3 多匿名字段的查找顺序如果结构体中嵌入了多个匿名字段，将遵循下面的字段和方法查找顺序: 直接定义在类型里方法 内嵌字段引入的方法 内嵌字段的内嵌字段引入的方法，然后一直递归向下找 如果在同一级里有两个同名的方法，编译器会报错 上面说的同一级可以理解为，由内嵌所构成的树的同一层。 12345678910111213141516171819202122232425262728293031type A struct &#123; A1&#125;type A1 struct &#123;&#125;type B struct &#123; B1&#125;type B1 struct&#123;&#125;func (a A1) name() &#123; fmt.Println("a1")&#125;func (b B1) name() &#123; fmt.Println("b1")&#125;type C struct &#123; A B&#125;c := C&#123;&#125;// 同一级的 A1，B1 的 同名 name 方法导致编译错误c.name() // ambiguous selector c.name 4. 封装一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。封装有时候也被叫做信息隐藏，同时也是面向对象编程最关键的一个方面。 Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。 这种基于名字的手段使得在语言中最小的封装单元是package。一个struct类型的字段对同一个包的所有代码都有可见性，无论你的代码是写在一个函数还是一个方法里。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 go 函数]]></title>
    <url>%2F2019%2F01%2F05%2Fgo%2Fgo_grammar%2Fgo_5%2F</url>
    <content type="text"><![CDATA[函数，代码封装的基本单元 1. 函数函数通常使用起来并不复杂，定义或声明函数后，直接使用即可。但是为了函数更加易用，编程语言会为函数添加很多特性。在 Python 和 Go 中，函数都是一等”公民”，即函数可以用在任何变量可以使用的地方，并且具有类型。因此接下来我们按照下面的顺序来讲解 Go 函数的相关内容: 第一部分: Go 函数作为基础数据类型的特性: 函数声明 函数的类型 函数的零值 第二部分: Go 函数语言层的特性 匿名函数与闭包 异常处理 Deferred 2. 函数2.1 函数声明Go 函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。函数的参数，返回值以及函数调用时的传值方式是函数的核心。 123func name(parameter‐list) (result‐list) &#123; body&#125; 下面是几个函数声明的示例:1234567891011121314151617func hypot(x, y float64) float64 &#123; return math.Sqrt(x*x + y*y)&#125;// 参数类型相同时，可以合并func f(i, j, k int, s, t string) &#123; /* ... */ &#125;func f(i int, j int, k int, s string, t string) &#123; /* ... */ &#125;//func add(x int, y int) int &#123;return x + y&#125;func sub(x, y int) (z int) &#123; z = x ‐ y; return&#125;func first(x int, _ int) int &#123; return x &#125; // _ 可以强调某个参数未被使用func zero(int, int) int &#123; return 0 &#125;// 在返回值的类型都相同时， 返回值变量名可以传达函数返回值的含义func Size(rect image.Rectangle) (width, height int)func Split(path string) (dir, file string) 返回值与 Python 默认返回 None 不同，Go 有返回值列表，但是没有默认的返回值，返回值列表就是对函数返回值的约束: 返回值列表描述了函数返回值的变量名以及类型 如果没有返回值列表，函数不能返回任何值 如果包含返回值列表，函数必须返回与返回值列表类型相符的值 返回值可以被命名，此时每个返回值被声明成一个局部变量，并根据返回值的类型，被其初始化为 0 当如果函数返回一个无名变量或者没有返回值，返回值列表的括号可以省略。 Go 的函数返回值符合 Go 强变量类型的约束。 参数Go 函数参数没有默认值，也不能通过参数名指定行参。每一次函数调用都必须按照声明顺序为所有参数提供实参（参数值）。因此形参和返回值的变量名对于函数调用者而言没有意义。 为了让函数更加通用，Go 和 Python 都提供了可变参数的特性。在 Go 中声明可变参数时，需要在参数列表的最后一个参数类型之前加上省略符号“…”，这表示该函数会接收任意数量的该类型参数。 123456789101112func sum(vals...int) int &#123;total := 0for _, val := range vals &#123; total += val &#125; return total&#125;//fmt.Println(sum()) // "0"fmt.Println(sum(3)) // "3"fmt.Println(sum(1, 2, 3, 4)) // "10" 在上面的代码中，调用者隐式的创建一个数组，并将原始参数复制到数组中，再把数组的一个切片作为参数传给被调函数。如果原始参数已经是切片类型，可以像下面这样向函数传递参数。 123//values := []int&#123;1, 2, 3, 4&#125;fmt.Println(sum(values...)) // "10" 2.2 函数类型与值Go 中函数的类型被称为函数的标识符，函数的取决于参数和返回值的类型: 如果两个函数形式参数列表和返回值列表中的变量类型一一对应，那么它们有相同的类型和标识符 形参和返回值的变量名不不会影响函数标识符 函数类型的零值是 nil。调用值为nil的函数值会引起panic错误。函数值可以与nil比较，但是函数值之间是不可比较的，也不能用函数值作为map的key。函数之间之所以不可比，是因为函数闭包，函数会保留定义函数时，存在的自由变量的绑定。我们会在下面讲解。 123456789// 此处f的值为nil, 会引起panic错误var f func(int) intf(3)// 函数与 nil 比较var f func(int) intif f != nil &#123; f(3)&#125; 2.3 函数调用的传值方式我们把调用函数时传递给函数的值称为实参，函数接收参数值的变量称为行参。 Go 中实参通过值的方式传递，因此函数的形参是实参的拷贝。对形参进行修改不会影响实参。但是，如果实参包括引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的间接引用被修改。 在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值。函数的形参和有名返回值作为函数最外层的局部变量，被存储在相同的词法块中。我们甚至可以直接修返回值变量，来修改函数的返回值。我们会在讲解 Deffer 时详述。 说完了函数作为基本类型的特性，我们再来看为了方便编程，Go 为函数提供的语言层特性。 3. 函数特性3.1 函数闭包Go 里面一个有意思的地方是拥有函数名的函数只能在包级语法块中被声明。即我们不能在函数内部使用，使用 func name(parameter‐list) (result‐list) 方式定义函数，但不带 name 的 func (parameter‐list) (result‐list) 匿名函数可以。func (parameter‐list) (result‐list) 是 Go 函数的函数字面量。函数值字面量是一种表达式，它的值被成为匿名函数（anonymousfunction） 说起来比较绕，即如果我们想在函数内定义命名函数必须使用下面这种方式；或者直接使用匿名函数。 123456789101112131415161718192021// 1. 函数内定义命名函数func f1(a, b int) (r int) &#123; v := func() &#123; r += b &#125; defer v() return a + b&#125;// 2. 直接使用匿名函数func squares() func() int &#123; var x int return func() int &#123; x++ return x * x &#125;&#125;f := squares()fmt.Println(f()) // "1"fmt.Println(f()) // "4" 注意在上面第二个示例中，squares中定义的匿名内部函数可以访问和更新squares中的局部变量，这意味着匿名函数和squares中存在变量引用。这就是函数闭包，也是函数值属于引用类型和函数值不可比较的原因。 需要注意的是函数闭包内保存的是变量的引用而不是变量的值。我们来看下面删除临时文件的示例: 12345678var rmdirs []func()for _, dir := range tempDirs() &#123; // dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) rmdirs = append(rmdirs, func() &#123; os.RemoveAll(dir) // NOTE: incorrect! &#125;)&#125; 在上面的程序中，for循环语句引入了新的词法块，循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以dir为例，后续的迭代会不断更新dir的值，当删除操作执行时，for循环已完成，dir中存储的值等于最后一次迭代的值。这意味着，每次对os.RemoveAll的调用删除的都是相同的目录。 如果你使用go语句或者defer语句会经常遇到此类问题。这不是go或defer本身导致的，而是因为它们都会等待循环结束后，再执行函数值。 3.2 Defer 机制Go 的 Defer 机制与 Python 的上下文管理器有点类似，都是为了保证某些代码一定要执行，无论代码是否出现了异常。 defer 的语法很简单，只需要在调用普通函数或方法前加上关键字defer。 当defer语句被执行时，跟在defer后面的函数会被延迟执行。 直到包含该defer语句的函数执行完毕时，defer后的函数才会被执行，不论包含defer语句的函数是通过return正常结束，还是由于panic导致的异常结束。 可以在一个函数中执行多条defer语句，它们的执行顺序与声明顺序相反。 通过defer机制，不论函数逻辑多复杂，都能保证在任何执行路径下，资源被释放。释放资源的defer应该直接跟在请求资源的语句后。需要注意的是跟在 defer 之后的是函数调用，而不是函数本身。 12345678910111213141516171819// defer 关闭文件package ioutilfunc ReadFile(filename string) ([]byte, error) &#123; f, err := os.Open(filename) if err != nil &#123; return nil, err &#125; defer f.Close() return ReadAll(f)&#125;// 释放锁var mu sync.Mutexvar m = make(map[string]int)func lookup(key string) int &#123; mu.Lock() defer mu.Unlock() return m[key]&#125; 利用 defer中的函数会在return语句更新返回值变量后再执行，以及在函数中定义的匿名函数可以访问该函数包括返回值变量在内的所有变量，我们就可以上面说到的改变函数返回值的目的。 123456func triple(x int) (result int) &#123; defer func() &#123; result += x &#125;() return double(x)&#125;fmt.Println(triple(4)) // "12 3.3 错误与异常处理严格的区分错误和异常，应该是 Go 编码风格一个最大的特点。在Go中，错误是程序运行的几个预期的结果之一。而异常是未被预料到的错误，即bug，而不是那些在健壮程序中应该被避免的程序错误。正因为如此，在 Go 的代码中你会看到很多类似下面的条件判断。Go 将对错误的处理放在了代码的逻辑控制中，让程序员更多的关注错误。 1234567891011// 导致失败的原因只有一个，额外的返回值可以是一个布尔值，通常被命名为okvalue, ok := cache.Lookup(key) if !ok &#123; // ...cache[key] does not exist…&#125;// 导致失败的原因不止一种时，额外的返回值是error类型，resp, err := http.Get(url)if err != nil&#123; return nill, err&#125; 错误处理对于那些将运行失败看作是预期结果的函数，它们会返回一个额外的返回值，通常是最后一个，来传递错误信息。调用者需要处理程序出现的潜在错误。因此Go中大部分函数的代码结构几乎相同，首先是一系列的初始检查，防止错误发生，之后是函数的实际逻辑。 对于函数返回的错误，通常有以下五种处理方式: 传播错误 重新尝试失败的操作 输出错误信息并结束程序 有时，只输出错误信息就足够了，不需要中断程序的运行 直接忽略掉错误 需要注意的是，输出错误信息并结束程序只应在main中执行。对库函数而言，应仅向上传播错误，除非该错误意味着程序内部包含不一致性，即遇到了bug，才能在库函数中结束程序。 异常处理Go 中的异常称为 Panic。一般而言，当panic异常发生时，程序会中断运行，并立即执行在该goroutine 中被延迟的函数（defer 机制），在Go的panic机制中，延迟函数的调用在释放堆栈信息之前。直接调用内置的panic函数也会引发panic异常，panic函数接受任何值作为参数。 通常来说，不应该对panic异常做任何处理，但有时候我们需要从异常中恢复，此时就需要 Go 的 Recover 机制来捕获异常。 12345678func Parse(input string) (s *Syntax, err error) &#123; defer func() &#123; if p := recover(); p != nil &#123; err = fmt.Errorf("internal error: %v", p) &#125; &#125;()// ...parser...&#125; 如上所示，如果在deferred函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。 通常我们不应该不加区分的恢复所有的panic异常，同时作为被广泛遵守的规范，也不应该试图去恢复其他包引起的panic。安全的做法是有选择性的recover。 为了标识某个panic是否应该被恢复，我们可以将panic value设置成特殊类型。在recover时对panic value进行检查，如果发现panic value是特殊类型，就将这个panic作为errror处理，如果不是，则按照正常的panic进行处理。 123456789101112func soleTitle(doc *html.Node) (title string, err error) &#123; type bailout struct&#123;&#125; defer func() &#123; switch p := recover(); p &#123; case nil: // no panic case bailout&#123;&#125;: // "expected" panic err = fmt.Errorf("multiple title elements") default: panic(p) // unexpected panic; carry on panicking &#125; &#125;()&#125; 最后某些致命错误会导致Go在运行时终止程序，无法恢复，比如内存不足。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4 go 复合数据类型]]></title>
    <url>%2F2019%2F01%2F04%2Fgo%2Fgo_grammar%2Fgo_4%2F</url>
    <content type="text"><![CDATA[Go 的类型系统 1. Go 的复合数据类型接着上一篇，我们来继续讨论 Go 里面的复合数据类型，包括数组、slice、map和结构体。数组和结构体是聚合类型；它们的值由许多元素或成员字段的值组成。slice,map 分别与 Python 中的 array.Array,dict 相对应，它们是 Go 提供给我们容器数据类型。 编程语言提供的复合数据类型应该是数据结构与算法的基础内容，如果你熟悉常用的数据结构，对复合类型的特性和支持的操作应该很容易就能理解。因此接下来的内容，我们会先简单说一说数据结构的特点，然后在介绍它们在 Go 中的实现和支持的操作。 2. 数组数组应该是最基本的数据结构，简单来说，数组具有如下特性: 数组是一段连续的内存空间，用来存储一组具有相同类型的数据 数组一经创建，大小便不能更改，连续的内存要求元素之间不能出现空洞 数组的特性决定了数组天然支持基于下标的“随机访问”(索引)。Go 中的数组我们需要关注以下几个知识点: 数组的长度是数组类型的一个组成部分，[3]int和[4]int是两种不同的数组类型 数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定 数组的可比性取决于数组的类型是否相同以及数组元素是否可比，只有当两个数组类型相同并且所有元素都是相等的时候数组才相等 下面是数组常用操作的代码示例: 1234567891011121314151617181920212223242526// 1. 数组字面量var q [3]int = [3]int&#123;1, 2, 3&#125;q := [...]int&#123;1, 2, 3&#125; // “...”省略号，表示数组的长度是根据初始化值的个数来计算r := [...]int&#123;99: ‐1&#125; // 直接按位置初始化，未初始化的为对应类型的零值// 2. 索引和切片fmt.Println(q[0]) // print the first elementfmt.Println(q[len(q)‐1]) // print the last element, q[2]e := [3]int&#123;1, 2, 3&#125;ff := e[0:2] // 对数组切片返回的是 slice 而不是原数组类型if ff == e &#123; // missmatch type []int and [3]int&#125;// 3. for 循环迭代for i, v := range q &#123; fmt.Printf("%d %d\n", i, v)&#125;// 4. 数组可比性a := [2]int&#123;1, 2&#125;d := [3]int&#123;1, 2&#125;fmt.Println(a == d) // compile error: cannot compare [2]int == [3]int 3. slice 切片因为数组的大小固定，类型限定严格，我们通常很少直接使用数组，使用更多的是数组的容器，Go 中数组的容器类型就是 slice (切片)。容器的最主要作用是能够根据元素大小对数组进行扩缩容。因此我们可以从 slice 的组成和扩缩容两个方面去理解 slice。 3.1 slice 组成Go 的 slice由三个部分构成： 指针: 指针指向第一个slice元素对应的底层数组元素的地址 容量: 容量一般是从 slice 的开始位置到底层数据的结尾位置 长度: 对应slice中元素的数目，长度不能超过容量 需要注意的是，因为 slice 底层数组是可以共享(通常是由于切片行为引起的)，因此slice 指针指向的第一个元素并不一定就是数组的第一个元素。内置的len和cap函数分别返回slice的长度和容量。下面是一个 slice 结构示意图: 1234months := [...]string&#123;1: "January", /* ... */, 12: "December"&#125;Q2 := months[4:7]summer := months[6:9] 对数组 months 的切片操作返回的是 slice []int，Q2和summer 共用了底层的 months 数组。 3.2 slice 扩缩容slice 扩缩容策略由 append 函数实现，但 append 只能向slice追加元素，Go 并没有删除 slice 中元素的函数。append扩容的过程大体是这样的: 在每次向 slice 添加时，append 会判断当前数组的大小是否足以容纳新增元素，足够则直接插入 如果数组容量不够，append 将创建一个原有数组两倍大小的新数组，并将原数组中的元素拷贝到新数组中去 最后将 slice 中的指针的指向新的底层数组 append 函数可以向 slice 追加多个元素，甚至追加一个slice: 123456var x []intx = append(x, 1)x = append(x, 2, 3)x = append(x, 4, 5, 6)x = append(x, x...) // append the slice xfmt.Println(x) // "[1 2 3 4 5 6 1 2 3 4 5 6]" 需要注意的是，通常我们要将 append 的返回值直接赋值给输入的slice变量，这么做与 Go 中函数的参数传值方式有关: Go 中的函数参数是按值传递的，因此传入 append 的是 slice 的副本，但是它们的指针指向了相同的底层数组 如果 append 函数发生了扩容，函数内的 slice 副本将指向新的内存数组，此时 append 函数将不会影响到传入的 slice 变量，为了达到修改 slice 的目的，通常要对输入的slice变量重新赋值 3.3 slice 操作说完了 slice 的实现，我们再来看看 slice 支持的操作: slice 的字面量与数组类似，只是去掉长度声明 对 slice 的切片操作如果超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了slice，新slice的长度会变长 为了避免创建 slice 多次内存分配，内置的 make 函数可以创建指定长度和容量的 slice slice之间不能比较，我们不能使用==操作符来判断两个slice是否含有全部相等元素，slice唯一合法的比较操作是和nil比较 因为 Go 没有提供删除 slice 元素的函数，只能采用覆盖的方式进行 slice 元素删除 下面是 slice 常用操作的代码示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243// 1. slice 字面量var m = []int&#123;3: 10&#125;// 2. slice 创建函数// make创建了一个匿名的数组变量，然后返回一个slicemake([]T, len)make([]T, len, cap) // same as make([]T, cap)[:len]// 3. slice 与 nil 的比较和转换if summer == nil &#123; /* ... */ &#125;var s []int // len(s) == 0, s == nils = nil // len(s) == 0, s == nils = []int(nil) // len(s) == 0, s == nil，类型转换s = []int&#123;&#125; // len(s) == 0, s != nil// 4. slice 为空测试，不应该使用 s == nilif len(s) == 0&#123;&#125;// 5. slice 复制// copy函数可以方便地将一个slice复制另一个相同类型的slice// copy函数将返回成功复制的元素的个数，等于两个slice中较小的长度copy(m, s) // 将 s 复制到 m// 6. slice 元素删除//如果要保持 slice 原来顺序func remove(slice []int, i int) []int &#123; copy(slice[i:], slice[i+1:]) return slice[:len(slice)‐1]&#125;//如果不用保持原来顺序的话，使用最后元素覆盖删除元素func remove(slice []int, i int) []int &#123; slice[i] = slice[len(slice)‐1] return slice[:len(slice)‐1]&#125;// 7. slice 模拟栈操作stack = append(stack, v) // push vtop := stack[len(stack)‐1] // top of stackstack = stack[:len(stack)‐1] // pop 4. Map 散列表在Go语言中，一个map就是一个散列表的引用，散列表是映射的一种实现方式，因此要想理清楚散列表，我们要从映射入手。所谓映射就是支持以下方法的键值对: M[k]: 返回键 k 对应的值，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 我列出了 Python 中与之对应的方法，但是 Go 中实现方式有所不同，我们会在下面讲解。散列表是映射高效的实现方式，可以实现 O(1) 时间复杂度的元素查找。那散列表是如何实现的呢？ 4.1 散列表的实现散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，有三个核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 下面是散列表实现映射的示意图: 限于篇幅的原因，有关散列表的实现，我就不过多解释，不了解的同学可以看看这篇文章散列表实现。这里我们需要关注的是散列表在使用上的限制。 首先，由于映射过程以及散列冲突的存在，所有的编程语言的散列表都会有以下两点要求: key 不可变，如果key 可变，元素的哈希值就会变化，查找就会失败 key 之间可比，当发生散列冲突时，要通过比较进行二次查找 而 Go 对散列表使用更加严格: 散列表中所有的key必须是相同的类型，所有的value也必须是相同的类型，但是 key 和 value 的类型可以不同 因为 Go 中可变的元素都是不可比的，所以上面的条件就退化成 key 必须是支持==比较运算符的数据类型,例如整数、数组或结构体等 虽然浮点数类型也是支持相等运算符比较的，但是将浮点数用做key类型则是一个坏的想法，最坏的情况是可能出现的NaN和任何浮点数都不相等 4.2 map 操作说完了散列表的实现，接下来我们看看 Go map 支持的操作。在Go语言中，一个map就是一个哈希表的引用，map类型可以写为map[K]V，其中K和V分别对应key和value。与 slice 类似，我们可以使用字面量和 make 来创建 map。 map 支持上面所说的映射操作，但是与 Python 相比 Go map 有以下两个鲜明特点: key 不存在时，执行 M[key]，不会触发异常，而是返回 value 类型对应的零值 map类型的零值是nil，也就是没有引用任何哈希表，map上的查找、删除、len和range循环都可以安全工作在nil值的map上，它们的行为和一个空的map类似。但是向一个nil值的map存入元素将导致一个panic异常 此外和slice一样，map之间也不能进行相等比较；唯一的例外是和nil进行比较。要判断两个map是否包含相同的key和value，我们必须通过一个循环实现。下面 map 操作的代码示例: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 1. 字面量ages := map[string]int&#123; "alice": 31, "charlie": 34,&#125;// 2. 初始化函数 makeages := make(map[string]int)ages["alice"] = 31ages["charlie"] = 34// 3. 元素访问与删除ages["alice"] = 32fmt.Println(ages["alice"]) // "32delete(ages, "alice") // remove element ages["alice"]// 元素不存在的判断if age, ok := ages["bob"]; !ok &#123; /* ... */ &#125; // 判断元素是否存在// 4. 迭代和遍历，迭代总是随机和无序的for name, age := range ages &#123; fmt.Printf("%s\t%d\n", name, age)&#125;// 有序遍历import "sort"var names []stringfor name := range ages &#123; names = append(names, name)&#125;sort.Strings(names)for _, name := range names &#123; fmt.Printf("%s\t%d\n", name, ages[name])&#125;// 5. 零值，以及是否为空的比较var ages map[string]intfmt.Println(ages == nil) // "true"fmt.Println(len(ages) == 0) // "true"// 6. 两个相同 map 判等func equal(x, y map[string]int) bool &#123; if len(x) != len(y) &#123; return false&#125; for k, xv := range x &#123; // 注意必须先判断，元素是否存在 if yv, ok := y[k]; !ok || yv != xv &#123; return false &#125; &#125; return true&#125; 最后，Go语言中并没有提供一个set类型，可以通过 map 实现类似set的功能，常用的 map 类型就是map[string]bool。 5. 结构体结构体是一种聚合的数据类型由零个或多个任意类型的值聚合成的实体。每个值称为结构体的成员。结构体是 Go 提供给我们创建自定义类型的载体，下面是一个创建示例: 12345678910type Employee struct &#123; ID int Name, Address string DoB time.Time Position string Salary int ManagerID int&#125;var dilbert Employee struct 定义了一个结构体，type 为这个结构体定义类型别名，便于引用，这种定义方式与 C 很接近。 在结构体的定义上，Go 中还有下面一些特性: 结构体成员的输入顺序也有重要的意义，拥有相同成员但是成员顺序不同的结构体属于不同的结构体类型 如果结构体成员名字是以大写字母开头的，那么该成员就是导出的；这是Go语言导出规则决定的。一个结构体可能同时包含导出和未导出的成员。 结构体的操作稍显复杂，我们分成下面两块来讲解 结构体通用操作，包括成员变量的引用，结构体的创建和比较 结构体的嵌入和匿名变量，这个是 Go 语言的特性，需要重点关注 5.1 结构体通用操作成员引用结构体是一个变量，它所有的成员也同样是变量，可以赋值或者取址，然后通过指针访问。结构体变量的成员可以通过点操作符访问，点操作符也可以和指向结构体的指针一起工作： 123456789101112// 通过点操作直接访问var dilbert Employeedilbert.Salary ‐= 5000// 可以对成员变量取址，然后访问position := &amp;dilbert.Position*position = "Senior " + *position // promoted, for outsourcing to Elbonia// 点操作也可以直接用在结构体指针上var employeeOfTheMonth *Employee = &amp;dilbertemployeeOfTheMonth.Position += " (proactive team player)" // 等同于(*employeeOfTheMonth).Position += " (proactive team player)" 结构体字面量结构体字面值有两种语法格式: 以结构体成员定义的顺序为每个结构体成员指定一个面值，这种方式在结构定义发生变化时就会导致编译错误，因此这种方式只在定义结构体的包内部使用，或者是在较小的结构体中使用，这些结构体的成员排列比较规则 以成员名字和相应的值来初始化，可以包含部分或全部的成员,如果成员被忽略的话将默认用零值 需要注意的是两种不同形式的写法不能混合使用。而且，你不能企图在外部包中用第一种顺序赋值的技巧来偷偷地初始化结构体中未导出的成员。 123456789101112131415// 方式一: 按照成员定义顺序，依次赋值type Point struct&#123; X, Y int &#125;p := Point&#123;1, 2&#125;// 方式二: 以成员名字和相应的值来初始化f := Point&#123;X: 1, Y: 2&#125;// 未导出变量，无法赋值package ptype T struct&#123; a, b int &#125; // a and b are not exportedpackage qimport "p"var _ = p.T&#123;a: 1, b: 2&#125; // compile error: can't reference a, bvar _ = p.T&#123;1, 2&#125; // compile error: can't reference a, b 除了字面量外，我们还可以用前面介绍的 new 函数来创建结构体变量 1234pp := &amp;Point&#123;1, 2&#125;pp := new(Point)*pp = Point&#123;1, 2&#125; 结构体的零值与比较结构体类型的零值是每个成员都是零值。如果结构体没有任何成员的话就是空结构体，写作struct{}。它的大小为0，也不包含任何信息，通常用作占位。 如果结构体的全部成员都是可以比较的，那么结构体也是可以比较的。可比较的结构体类型和其他可比较的类型一样，可以用于map的key类型。 1234567type address struct &#123; hostname string port int&#125;hits := make(map[address]int)hits[address&#123;"golang.org", 443&#125;]++ 5.2 结构体的嵌入与匿名变量结构体嵌入结构体嵌入是 Go 语言提供的类似类继承机制，形式上是让一个命名的结构体包含另一个结构体类型的匿名成员，目的是实现通过简单的点运算符x.f来访问匿名成员链中嵌套的x.d.e.f成员的机制。说起来很复杂，举个例子。考虑一个图形系统，我们需要定义点，线，圆。显然圆可以在点即园心的基础上添加半径来表示。在 Go 中可以使用下面的结构体表示这样的结构。 1234567891011121314151617181920// 点type Point struct &#123; X, Y int&#125;// 圆type Circle struct &#123; Center Point Radius int&#125;type Wheel struct &#123; Circle Circle Spokes int&#125;// 创建圆var w Wheelw.Circle.Center.X = 8w.Circle.Center.Y = 8w.Circle.Radius = 5w.Spokes = 20 如上所示，现在想访问Wheel的结构体成员 X 将变的异常繁琐。而结构嵌入就是为了在满足上面结构不变的情况，实现 w.X 成员快速访问。结构体声明如下所示: 1234567891011121314151617181920type Point struct &#123; X, Y int&#125;type Circle struct &#123; Point // 匿名成员 Radius int&#125;type Wheel struct &#123; Circle // 匿名成员 Spokes int&#125;var w Wheelw.X = 8 // equivalent to w.Circle.Point.X = 8w.Y = 8 // equivalent to w.Circle.Point.Y = 8w.Radius = 5 // equivalent to w.Circle.Radius = 5w.Spokes = 20 Point，Circle 此时为匿名成员。所谓匿名成员，就是只声明一个成员对应的数据类型而不指名成员的名字。匿名成员并不是没有名字，其名字就是命名的类型名字，但是这些名字在点操作符中是可选的。上面 w.Circle.Point.X = 8 这样的访问方式依旧是合法的。 不幸的是，结构体字面值并没有简短表示匿名成员的语法， 因此下面的语句都不能编译通过。结构体字面值必须遵循形状类型声明时的结构 12345678910111213// 错误w = Wheel&#123;8, 8, 5, 20&#125; // compile error: unknown fieldsw = Wheel&#123;X: 8, Y: 8, Radius: 5, Spokes: 20&#125; // compile error: unknown fields// 正确w = Wheel&#123;Circle&#123;Point&#123;8, 8&#125;, 5&#125;, 20&#125;w = Wheel&#123; Circle: Circle&#123; Point: Point&#123;X: 8, Y: 8&#125;, Radius: 5, &#125;, Spokes: 20, // NOTE: trailing comma necessary here (and at Radius)&#125; 匿名变量的使用要求需要注意的是 Go 对匿名成员的使用存在一些约束: 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针 因为匿名成员也有一个隐式的名字，因此不能同时包含两个类型相同的匿名成员，这会导致名字冲突 因为成员的名字是由其类型隐式地决定的，所有匿名成员也有可见性的规则约束 比如将上面改成小写字母开头的point和circle），此时在包内依旧可以使用 w.X = 8；但是在包外部，因为circle和point没有导出不能访问它们的成员，因此简短的匿名成员访问语法也是禁止的。 匿名结构的可见性只与属性和方法的获取的表达式有关，比如将上面改成小写字母开头的point和circle），在包外部不能通过 w.point.X 访问成员 X，但是可以通过 w.X 直接访问成员 X。下面是另一个例子: 12345678910111213141516171819202122232425262728293031323334353637383940414243//1. pkg 包内定义 animal 和 Dogpackage pkgtype animal struct &#123; Name string&#125;type Dog struct &#123; animal Weight int&#125;func NewDog() Dog &#123; return Dog&#123;animal&#123;"aaa"&#125;, 100&#125;&#125;func (g Dog) GetName() string &#123; return g.Name&#125;func (g *Dog) GetWeight() int &#123; return g.Weight&#125;// 2 mian 包内使用package mainimport ( "fmt" "mygo/pkg")func main() &#123; g := pkg.NewDog() fmt.Printf("%T, %#v\n", g, g) fmt.Println(g.Weight) // 注意: 此处我们可以直接访问 g.Weight fmt.Println(g.Name) fmt.Printf("%T\n", (*pkg.Dog).GetName) // func(*pkg.Dog) string fmt.Printf("%T\n", (*pkg.Dog).GetWeight) // func(*pkg.Dog) int fmt.Printf("%T\n", pkg.Dog.GetName) // func(pkg.Dog) string // fmt.Printf("%T\n", pkg.Dog.GetWeight)&#125; 最后匿名成员并不要求是结构体类型；其实任何命名的类型都可以作为结构体的匿名成员。但是为什么要嵌入一个没有任何子成员类型的匿名成员类型呢？答案是匿名类型的方法集。 简短的点运算符语法可以用于选择匿名成员嵌套的成员，也可以用于访问它们的方法。实际上，外层的结构体不仅仅是获得了匿名成员类型的所有成员，而且也获得了该类型导出的全部的方法。 这个机制可以用于将一个有简单行为的对象组合成有复杂行为的对象。组合是Go语言中面向对象编程的核心。我们在下一章将方法时会再来讨论。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3 go 基础数据类型]]></title>
    <url>%2F2019%2F01%2F03%2Fgo%2Fgo_grammar%2Fgo_3%2F</url>
    <content type="text"><![CDATA[Go 的类型系统 1. Go 中的数据类型Go语言将数据类型分为四类：基础类型、复合类型、引用类型和接口类型。基础类型，包括：数字、字符串和布尔型。复合数据类型包括数组和结构体(通过组合简单类型，来表达更加复杂的数据结构)。引用类型包括指针、切片、字典、函数、通道，虽然数据种类很多，但它们都是对程序中一个变量或状态的间接引用。函数和通道并不属于我们通常所说的数据类型，我们放在后面相关章节来介绍。 对于大多数编程语言来说，基础类型以及它们之上的可用运算符都是类似，更加需要我们注意的是，编程语言提供给我们的数据容器以及操作它们的方式。因此我们分成以下几个部分来讲解 Go 的类型系统。 数值与布尔型 字符串与编码 数组与结构体 切片 字典 本节我们先来介绍 Go 中的基本数据类型，即数值，布尔值和字符串。在介绍这些数据类型之前，我们先来谈谈变量类型的含义，这有助于加深我们对编程语言本身的理解。 1.1 变量的类型无论什么数据，在存储器内都是 0-1，那数据是数值还是字符完全取决于我们对这些二进制数据的解释。变量的类型就是用来定义对应存储值的属性特征，即它们在内部是如何表示的，支持的操作符，以及关联的方法集等。 而在一个编程语言类型系统中，除了内置的变量类型外，还有如下一些问题: 自定义类型 定义新的类型名称(类型重命名) 类型转换 1.2 自定义类型自定义类型允许我们在编程语言底层类型的基础上定义更加复杂的类型，它是面向对象编程的基础。在 Go 中自定义类型就是使用结构体。 1.2 类型重命名在任何程序中都会存在一些变量有着相同的内部结构，但是却表示完全不同的概念。例如，一个int类型的变量可以用来表示一个循环的迭代索引、或者一个时间戳、或者一个文件描述符。类型重命名就是为分隔不同概念的类型。新的类型名称使用类型声明语句创建。Go 的类型声明语法如下所示: 1type 类型名字 底层类型 新的类型和底层类型具有相同的底层结构，支持和底层类型相同的运算符。但是新类型与底层类型以及基于相同底层类型的不同新类型，是完全不不同的数据类型。 12345678import "fmt"type Celsius float64 // 摄氏温度type Fahrenheit float64 // 华氏温度// 因为 Fahrenheit，float64，Celsius 是完全不同的类型，所以它们不能直接比较// compile error: type mismatchfmt.Println(Fahrenheit(1.0) == float64(1.0))fmt.Println(Fahrenheit(1.0) == Celsius(1.0)) 1.2 类型转换对于每一个类型T，都有一个对应的类型转换操作T(x)，用于将x转为T类型。如果T是指针类型，可能会需要用小括弧包装T，比如 (*int)(0)。 在编程语言中，不同类型的变量之间是不能进行直接赋值和比较的，要这样做就需要显示或隐式的类型转换。对于不同编程语言而言，有不同的类型转换规则，但大多数规则都是类似。在 Go 中: 数值之间的转类型转换有一套特定规则，这个规则在不同的编程语言中是一样的，比如将浮点数转换为整数会损失小数部分 显示的类型转换T(x)要求 T 和 x 具有相同的底层基础类型或指向相同底层结构的指针类型；对于数据容器而言需要它们有类似的实现，比如可以将一个字符串转为 []byte类型 自定义的新类型名称，不会自动应用底层类型的隐式类型转换规则，一个命名类型的变量只能和另一个有相同类型的变量，或有着相同底层类型的未命名类型的值之间做比较；依赖相同底层类型的不同自定义类型之间想要进行比较或赋值必须进行显示的类型转换。 1234567891011121314import "fmt"// 自定义类型与其底层类型不可比较type tt intfmt.Println(tt(1) &gt; int(0)） // compile error: type mismatchvar c Celsiusvar f Fahrenheitfmt.Println(c == 0) // "true"fmt.Println(f &gt;= 0) // "true"// 依赖相同底层类型的不同自定义类型不可比较fmt.Println(c == f) // compile error: type mismatchfmt.Println(c == Celsius(f)) // "true"! 说了这么多，接下来我们开始正式讲解 Go 中的数据类型。 2. 数值Go语言的数值类型包括几种不同大小的整数、浮点数和复数，还有一些为特定用途定义的类型别名。 2.1 整数整数包括如下几种类型及类型别名： 类型 大小 含义 uint8 8 无符号 8 位整型 uint16 16 无符号 16 位整型 uint32 32 无符号 32 位整型 uint64 64 无符号 64 位整型 uint 32 或 64位 平台相关，取决于CPU平台机器字大小 int 32 或 64位 平台相关，取决于CPU平台机器字大小 int8 8 有符号 8 位整型 int16 16 有符号 16 位整型 int32 32 有符号 32 位整型 int64 64 有符号 64 位整型 byte 8, int8的别名 表示原始的二进制数据 rune 32, int32的别名 Unicode字符，表示一个Unicode码点 uintptr 无符号整数，没有明确指定大小 用于存放一个指针，GO 底层使用 其中int是应用最广泛的数值类型。内置的len函数返回一个有符号的int，虽然使用uint无符号类型似乎是一个更合理的选择。len函数返回有符号 int ，可以使我们像下面这样处理逆序循环。 1234medals := []string&#123;"gold", "silver", "bronze"&#125; for i := len(medals) ‐ 1; i &gt;= 0; i‐‐ &#123; fmt.Println(medals[i]) // "bronze", "silver", "gold"&#125; 所以尽管Go语言提供了无符号数和运算，并且在数值本身不可能出现负数的情况下，我们还是倾向于使用有符号的int类型。出于这个原因，无符号数往往只有在位运算或其它特殊的运算场景才会使用，就像bit集合、分析二进制文件格式或者是哈希和加密操作等。它们通常并不用于仅仅是表达非负数量的场合。 2.2 整数的运算符Go 的整数支持如下操作符号，其中大多数与其他语言类似，只有一个比较特殊x &amp;^ y，它表示将 x 中与 y 对应的且 y 中等于 1 的位置为 0，即位清空(AND NOT) 1234567# 优先级递减* / % # 算数运算符&lt;&lt; &gt;&gt; &amp; &amp;^ # 位运算符+ ‐ # 算数运算符| ^ # 位运算符== != &lt; &lt;= &gt; &gt;= # 比较运算符&amp;&amp;(AND) ||(or) # 逻辑运算符 2.3 浮点数Go语言提供了两种精度的浮点数，float32 和 float64 。浮点数的范围极限值可以在math包找到。常量math.MaxFloat32表示float32能表示的最大数值，对应的 float64 为 math.MaxFloat64。 一个float32类型的浮点数可以提供大约6个十进制数的精度，而float64则可以提供约15个十进制数的精度；通常应该优先使用float64类型。小数点前面或后面的数字都可能被省略（例如.707或1.）。很小或很大的数最好用科学计数法书写，通过e或E来指定指数部分。 1234567// float32的有效bit位只有23个，整数大于23bit表示范围时，将出现误差var f float32 = 16777216 // 1 &lt;&lt; 24fmt.Println(f == f+1) // "true"!const a = .909const Avogadro = 6.02214129e23 // 阿伏伽德罗常数const Planck = 6.62606957e‐34 // 普朗克常数 math包中除了提供大量常用的数学函数外，还提供了IEEE754浮点数标准中定义的特殊值的创建和测试。 123456789v := math.Inf(1) // 返回正无穷p := math.Inf(-1) // 返回负无穷n := math.NaN() // 返回 NaN 非数，一般用于表示无效的除法操作结果0/0或Sqrt(­1).t ：= math.IsNaN(n) // 测试是否为 NaN// NaN和任何数都是不相等的nan := math.NaN()fmt.Println(nan == nan, nan &lt; nan, nan &gt; nan) // "false false false" 2.4 复数Go语言提供了两种精度的复数类型：complex64 和 complex128，分别对应 float32 和 float64 两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部。复数的字面量使用 i 后缀。 123456789var x complex128 = complex(1, 2) // 1+2ivar y complex128 = complex(3, 4) // 3+4ifmt.Println(x*y) // "(‐5+10i)"fmt.Println(real(x*y)) // "‐5"fmt.Println(imag(x*y)) // "10"// 复数的字面量x := 1 + 2iy := 3 + 4i 3. 布尔值Go 布尔类型的值只有两种：true 和 false，if 和 for 语句的条件部分都是布尔值。需要特别注意的是 在 Go 中布尔之值不会与其他任何类型作隐式转换，将其他类型的值用在 if 或 for 中作为条件判断时，必须作显示的类型转换。 1234567func itob(i int) bool &#123; return i != 0 &#125;b := 0i := 0if itob(b) &#123; i = 1&#125; 4. 字符串4.1 字符串操作创建字符串最简单的方式是字符串字面量。在 Go 中，单个字符的字面量使用单引号，字符串字面量使用双引号，原生字符串使用反引号。所谓原生字符类似于 Python 中的 r&quot;&quot; 用于消除字符串中的所有转义操作。Go 的原生字符甚至可以消除换行，实现跨行，所以原生字符广泛使用再正则表达式，HTML模板、JSON面值以及命令行提示信息中。 与 Python 将大多数字符串操作作为字符串对象的方法不同，Go 大多数的字符串操作都在 strings 包，我们将这部分内容放在后面专门介绍，先来看看Go 提供的字符串基础操作。下面是一些代码示例: 123456789101112131415161718192021// 原生字符串const GoUsage = `Go is a tool for managing Go source code.Usage:go command [arguments]`s := "hello, world"// 1. len 函数获取字符串长度fmt.Println(len(s)) // "12"// 2. 索引fmt.Println(s[0], s[7]) // "104 119" ('h' and 'w')// 3. 切片fmt.Println(s[0:5]) // "hello// 4. + 拼接fmt.Println("goodbye" + s[5:]) // "goodbye, world"// 5. 不可修改s[0] = 'L' // compile error: cannot assign to s[0] 虽然字符串作为一个基本的数据类型被几乎所有的编程语言所支持，但是字符串本身确是很复杂。而复杂的地方至少有如下两点: 字符串的实现 字符的编码问题 4.1 字符串的实现 上面是字符串以及切片操作结果的示意图，在 Go 中，字符串是一个不可改变的字节序列，底层是一个字符数组，一个字符串可认为由两个部分构成:指针、长度 指针指向第一个字符对应的底层数组元素的地址 长度对应字符串中字符的个数 字符串的底层数组位于受保护的内存中，不能被修改，因此字符串是不可变的 对字符串变量进行重新赋值，不会改变字符串的底层数组，而只是改变了字符串中的指针的指向 不变性意味两个字符串可以安全的共享相同的底层数据，这使得字符串复制和切片不会发生实际的复制行为，而是直接共享原有的底层字符数组，因此操作非常迅速。 4.3 字符集在上面关于字符串的实现中，我们忽略了一个问题，即如何把字符串中的字符保存在一个数组中。我们知道在计算机上保存的数据只有二进制的 0 和 1，显然计算机没办法直接保存每个字符，于是就有了字符集的概念。 对于字符集以及字符的编码和解码，我是这样理解的: 字符集中最重要的概念就是码表，其作用是将每个字符与一个特定的数字对应起来，用特定的数字(又称码点)来表示特定的字符，因此码表就是字符集能表示的字符范围 有了码表，并没有解决保存字符的问题，显然就算是数字也要保存为整数的二进制格式。对于不同字符集而言，码点到特定的二进制也有一套特定的转换规则 因此，字符集实现了字符 --&gt; 码点 ---&gt; 码点二进制值的转换过程，码点 ---&gt; 码点二进制值被称为编码，反过来就是解码 有了上面的说明，就能解释清楚下面两个问题: ASCII 字符集 与 Unicode 字符集区别: ASCII字符集使用7bit来表示一个码点，而 Unicode 使用32bit表示一个 Unicode 码点，Unicode 显然能表示更大的字符范围 UTF8 编码与 UTF32 编码的区别: UTF32 编码直接将每个 Unicode 码点保存为 int32 的整数，而UTF8 会根据Unicode码点变长编码成二进制，它们都表示 Unicode 字符集，但是编码规则不同 4.4 字符串和 []runeGo语言的源文件采用UTF8编码，因此程序运行之后，保存在字符数组内的是 UTF8 编码的二进制值。因此前面我们所讲的字符串基础操作，操作的其实是UTF8 编码的每个字节，并不是我们理解的字符。为了处理真实的字符，我们需要对字符串进行解码。Go 将 Unicode 码点表示为 rune 整数类型，因此字符串解码后的类型就是 []rune。下面就是Go 中字符编码解码的一些代码示例: 1234567891011121314151617181920212223242526272829303132// 1. 字符串基础操作操作的是 UTF8 中的字节import "unicode/utf8"s := "Hello, 世界"fmt.Println(len(s)) // "13"fmt.Println(utf8.RuneCountInString(s)) // "9"// 2. unicode 提供了 UTF8 的解码函数for i := 0; i &lt; len(s); &#123; r, size := utf8.DecodeRuneInString(s[i:]) fmt.Printf("%d\t%c\n", i, r) i += size&#125;// 3. range 会自动对字符串解码for i, r := range "Hello, 世界" &#123; fmt.Printf("%d\t%q\t%d\n", i, r, r)&#125;// 4. []rune 字符串的类型转换s := "プログラム"fmt.Printf("% x\n", s) // "e3 83 97 e3 83 ad e3 82 b0 e3 83 a9 e3 83 a0"// 字符串 --&gt; []runer := []rune(s)fmt.Printf("%x\n", r) // "[30d7 30ed 30b0 30e9 30e0]// string 函数： []rune ---&gt; 字符串fmt.Println(string(r)) // "プログラム// 5. 生成Unicode码点字符的UTF8字符串fmt.Println(string(65)) // "A", not "65"fmt.Println(string(0x4eac)) // "京" 4.5 字符串和 []byte一个字符串是包含的只读字节数组，一旦创建，是不可变的。相比之下，一个字节slice(即 []byte，下一节我们会详述)的元素则可以自由地修改。字符串和字节slice之间可以相互转换： 123s := "abc"b := []byte(s)s2 := string(b) 4.6 字符串相关类型的包标准库中有四个包对字符串处理尤为重要：bytes、strings、strconv和unicode包 strings包提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能。 bytes包也提供了很多类似功能的函数，但是针对和字符串有着相同结构的[]byte类型 strconv包提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换 unicode包提供了IsDigit、IsLetter、IsUpper和IsLower等类似功能，它们用于给字符分类，每个函数有一个单一的rune类型的参数，然后返回一个布尔值 下面是字符串与数值转换的代码示例，我们会在后面专门讲解这些包的实现和使用。 123456789101112// 数值转字符串x := 123y := fmt.Sprintf("%d", x)fmt.Println(y, strconv.Itoa(x)) // "123 123"// 数值的进制转换fmt.Println(strconv.FormatInt(int64(x), 2)) // "1111011"s := fmt.Sprintf("x=%b", x) // "x=1111011// 字符串转数值x, err := strconv.Atoi("123") // x is an inty, err := strconv.ParseInt("123", 10, 64) // base 10, up to 64 bits 5. 常量5.1 常量的类型在讲常量之前，先问大家一个问题，你知道字面量，常量，变量，字面量类型之间的区别么？ 字面量是编程语言提供的用来创建特定值的快捷方式，因此字面量也有类型，特定的字面量代表什么类型，完全有编程语言决定。因此对于像下面的赋值语句来说，在字面量类型和变量类型之间发生了类型转换。 1var f float64 = 3 常量和变量都是变量，但是相比与变量，常量有以下特点: 常量的值不可变，并且常量的类型只能是基础类型：boolean、string或数字 常量表达式的值在编译期计算，而不是在运行期，因此常量可以是构成类型的一部分，例如用于指定数组类型的长度 因为常量也是变量，所以常量通常有确定的类型，但Go语言的常量有个不同寻常之处， Go 中的常量可以没有一个明确的基础类型。 首先在 Go 中，有六种无类型的字面量，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。例如0、0.0、0i和’\u0000’分别对应无类型的整数、无类型的浮点数、无类型的复数和无类型的字符。 其次在如下不带类型声明的常量声明语句中，不会发生隐式类型转换，常量的类型依旧为无类型的整数。 1const deadbeef = 0xdeadbeef // untyped int with value 3735928559 为了便于描述下面我们将无类型的字面量和常量统称为无类型常量，这些无类型常量有诸多好处。 编译器为这些无类型常量提供了比基础类型更高精度的算术运算。通过延迟明确常量的具体类型，无类型的常量不仅可以提供更高的运算精度，而且可以直接用于更多的表达式而不需要显式的类型转换。 只有常量可以是无类型的。当一个无类型的常量被赋值给一个变量的时候，或者出现在有明确类型的变量声明的右边，无类型的常量将会被隐式转换为对应的类型，如果转换合法的话。对于一个没有显式类型的变量声明（包括简短变量声明），字面量的形式将隐式决定变量的默认类型，Go 有一个明确的转换规则。如果要给变量一个不同的类型，我们必须显式地将无类型的常量转化为所需的类型，或给声明的变量指定明确的类型。 123456789101112131415161718192021222324252627282930// 1. 常量可以无类型，无类型常量可以提供更高的精度const ( deadbeef = 0xdeadbeef // untyped int with value 3735928559 a = uint32(deadbeef) // uint32 with value 3735928559 b = float32(deadbeef) // float32 with value 3735928576 (rounded up) c = float64(deadbeef) // float64 with value 3735928559 (exact) d = int32(deadbeef) // compile error: constant overflows int32 e = float64(1e309) // compile error: constant overflows float64 f = uint(‐1) // compile error: constant underflows uint)// 2. 无类型常量，可以直接应用在更多的表达式中，无需显示类型转换var f float64 = 3 + 0i // untyped complex ‐&gt; float64f = 2 // untyped integer ‐&gt; float64f = 1e123 // untyped floating‐point ‐&gt; float64f = 'a' // untyped rune ‐&gt; float64// 3. 有类型声明时，无类型常量将根据类型隐式类性转换var x float32 = math.Pivar y float64 = math.Pivar z complex128 = math.Pi// 4. 无类型声明时，根据字面量形式，决定变量类型i := 0 // untyped integer; implicit int(0) r := '\000' // untyped rune; implicit rune('\000')f := 0.0 // untyped floating‐point; implicit float64(0.0)c := 0i // untyped complex; implicit complex128(0i)var i = int8(0)var i int8 = 0 5.2 常量批量声明最后，Go 为常量的批量声明提供了一些便捷方式，下面是代码示例: 123456789101112131415161718192021222324252627282930313233343536// 1. 批量声明多个常量const ( e = 2.71828182845904523536028747135266249775724709369995957496696763 pi = 3.14159265358979323846264338327950288419716939937510582097494459)const ( a = 1 b // 省略初始化表达式，表示使用前面常量的初始化表达式写法， b=1 c = 2 d // d=2)// 2. iota常量生成器初始化，用于生成一组以相似规则初始化的常量type Weekday int const ( Sunday Weekday = iota // 在第一个声明的常量所在的行，iota将会被置为0， Monday // 然后在每一个有常量声明的行加一， 1 Tuesday // 2 Wednesday // 3 Thursday Friday Saturday)const ( _ = 1 &lt;&lt; (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 &lt;&lt; 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 &lt;&lt; 64) YiB // 1208925819614629174706176)]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2 go 变量及流程控制]]></title>
    <url>%2F2019%2F01%2F02%2Fgo%2Fgo_grammar%2Fgo_2%2F</url>
    <content type="text"><![CDATA[Hello World! 1. Hello World抛开数据结构，代码封装和复杂的库文件，我们接触一门新语言的第一步可能就是学会这门语言的基础语法。下面是我写的 go 的一个 “Hello World” 程序。在这个简单的代码中包含了很多 Go 基础语法的内容: 变量及常量的命名，声明和创建 条件判断和循环 变量的生命周期与作用域 下面我们就分成这几块来讲讲 Go 的基础语法。 123456789101112131415161718192021package mainimport "fmt"const defaultUser = "unsigned"func main() &#123; name := "A" if name == defaultUser &#123; fmt.Println("Helll man") &#125; else &#123; fmt.Println("Hey it is you") &#125; num := 100 r := 0 for i := 0; i &lt;= num; i++ &#123; r += i &#125; fmt.Println(r)&#125; 2. 变量及常量的命名，声明和创建2.1 命名规则几乎所有的编程语言变量，常量，函数以及类型的命名规则都是相同的，即一个名字必须以一个字母或下划线开头，后面可以跟任意数量的字母、数字或下划线。 Go 与众不同的是名称中可以包含Unicode字母(不建议使用)，并且使用名字的开头字母的大小写决定了名字在包外的可见性。关于变量的导出我们会在模块的相关内容详述。 习惯上，Go语言程序员推荐使用驼峰式命名。 2.2 声明和创建Go语言主要有四种类型的声明语句：var、const、type和func，分别对应变量、常量、类型和函数实体对象的声明。我们先说变量以及常量。 与 Python 这种动态语言不同的是，Go 是静态语言，变量必须先声名才能使用。Go 中变量可以看成一个“容器”，一个变量对应一个保存了变量对应类型值的内存空间；变量一经声明，其类型就不能再改变。下面是 Go 中声明和创建变量的几种方式: 123456789101112//方式一: var 声明语句var name string = "abc"var i, j, k intvar b, f, s = true, 2.3, "four"//方式二: 函数内的短变量声明，用于局部变量的声明和初始化t := 10i, j := 0, 1//方式三: new 函数，创建变量，并返回对应变量的指针p := new(int) // 此处创建了两个变量: new 函数创建的匿名变量，以及指向匿名变量的指针变量 p*p = 2 varvar声明语句可以创建一个特定类型的变量，然后给变量附加一个名字，并且设置变量的初始值。对于 var 变量名字 类型 = 表达式，“类型”或“= 表达式”两个部分可以省略其中的一个。 如果省略的是类型信息，那么将根据初始化表达式来推导变量的类型信息。 如果初始化表达式被省略，那么将用零值初始化该变量，规则如下 数值类型变量对应的零值是0 布尔类型变量对应的零值是false 字符串类型对应的零值是空字符串 接口或引用类型（包括slice、指针、map、chan和函数）变量对应的零值是nil 数组或结构体等聚合类型对应的零值是每个元素或字段都是对应该类型的零值 常量的声明和创建使用 const 声明语句，用法与 var 类似。 短变量声明短变量声明语句用在函数内，用于声名和初始化局部变量，语法为变量名:=表达式，变量的类型根据表达式自动推导。Go 的短变量声明有一些微妙之处: 首先“:=”是一个变量声明语句，而“=”是一个变量赋值操作 其次，简短变量声明左边的变量可以包含已经声明过的变量，对于这些变量将只是赋值，而不是再声明 最后，简短变量声明语句中必须至少要声明一个新的变量否则无法通过编译 new 函数new 是 Go 预定义的一个函数，new(T)将创建一个T类型的匿名变量，初始化为T类型的零值，然后返回变量地址。 用new创建变量和普通变量声明语句方式创建变量没有什么区别，除了不需要声明一个临时变量的名字外。因为 new 只是一个普通函数，因此可以使用在任何函数可用的地方，甚至new名字可以被重定义其他类型。 3. 条件判断和循环看完了变量创建，我们再来看看 Go 为我们提供的逻辑控制语句: if, switch, for。Go 没有 while 语句，但是 for 语句包含了 while 语句的功能。除了 if 外，switch 和 for 的用法都不简单。 除了这些基础的逻辑控制语句外，Go 还有一个特殊的与 Go 高并发相关的多路复用器 select。 3.1 ifGo 应该是类 C 风格的语言，使用 {} 来分隔代码块。一个完整的 if 语句如下所示:1234567if r == 0 &#123; fmt.Println("aaa")&#125; else if r == 1 &#123; fmt.Println("bbbb")&#125; else &#123; fmt.Println("cccc")&#125; 3.2 switchswitch 是多分支条件判断的便捷语法，用于基于不同条件执行不同动作，Go 的 switch 有如下三种使用方式。 123456789101112131415161718192021222324252627282930//方式一: 变量值判断switch var1 &#123; case v1: // var1 变量与 case 语句中的值类型必须相同 ... case v2,v3: // 逗号分隔表示可匹配多个值 ... default: ...&#125;// 方式二: 条件判断的变形switch &#123; case condition1: ... case condition2, condition3: // 逗号分隔表示可匹配多个条件 ... default: ...&#125;// 方式三: type-switch 用来判断某个 interface 变量中实际存储的变量类型// 我们会在后面讲接口类型时详述switch x.(type) &#123; case type1: .... case type2: .... default: ....&#125; 不同语言的 switch 语句差异很大，Go 的 switch 有如下特点: switch 语句的执行过程是从上直下逐一测试，直到匹配就会停止 每个 case 分支的最后不需要再加break，即默认只会执行第一个匹配到的 case 分支 Python 中没有 switch 语句，shell 脚本则必须在每个 case 分支之后添加 break，否则第一次匹配成功后后，会继续匹配之后的 case 分支。 3.3 selectselect 类似于用于通信的switch语句，它的一个使用示例如下所示:1234567891011func main() &#123; var c1, c2 chan int var i1, i2 int select &#123; case i1 = &lt;-c1: fmt.Printf("received ", i1, " from c1\n") case c2 &lt;- i2: fmt.Printf("sent ", i2, " to c2\n") default: fmt.Printf("no communication\n") &#125; 在 select 中: 每个case必须是一个通信操作，要么是发送要么是接收 所有channel表达式都会被求值，如果有多个 case 可以运行，select会随机执行一个可运行的case 如果没有case可运行，此时 如果有default子句，则执行该语句，defalut 子句应该总是可运行的 如果没有default字句，select将阻塞，直到某个通信可以运行；Go不会重新对channel或值进行求值 3.3 forGo 的 for 循环有四种常见的使用方式，如下所示。最特殊的是第四种 for 循环的 range 格式，它可以对 slice、map、数组、字符串等进行迭代循环。 12345678910111213141516171819202122232425//方式一: 典型的类 C for 循环for init; condition; post &#123;&#125;//方式二: 类 while 循环for condition &#123;&#125;//方式三: 无限循环for &#123;&#125;//无限循环的另一种方式for true &#123;&#125;//方式四: 类Python 的迭代循环for index, value := range oldMap &#123; // index: 索引 // value: 索引对应的值&#125; 4. 变量的生命周期与作用域变量的生命周期指的是在程序运行期间变量有效存在的时间间隔，变量作用域是指源代码中可以有效使用这个名字的范围。虽然我将变量的生命周期与作用域放在一起，但是其实它们之间并没有什么联系。声明语句的作用域对应的是一个源代码的文本区域；它是一个编译时的属性。一个变量的生命周期是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用；是一个运行时的概念。 Go 与 Python 类似，通过引用计数的方式，解释器会自动实现对象内存的分配和释放。变量的生命周期取决于变量是否可达，即其引用计数是否为 0，而与变量的作用域无关。虽然大多数位于函数内的局部变量的生命周期都是函数调用的存续区间，但是函数内的局部变量可以”逃逸”成为全局变量，或者从函数返回，从而延长生命周期。 变量的作用域取决于变量声明语句所在的语法块(又称词法域)，语法块通常由花括号显示限定，除此之外还有一些特殊的语法块。对于 Go 作用域从大到小依次是: 整个源代码，称为全局语法块 每个包的包语法块 每个源文件的源文件级的语法块 由显示花括号限定的由外而内的语法块 对于 if,for,switch,select 还有隐式的语法块 一个程序可能包含多个同名的声明，只要它们在不同的作用域。位于内部作用域的变量声明显然会覆盖外部的同名变量。对于大多数程序的作用于而言，都有类似规则。而 Go 比较特殊的是 if,for,switch,select引入的隐式作用域。 if, for 等的隐式作用域12345678if x := f(); x == 0 &#123; fmt.Println(x)&#125; else if y := g(x); x == y &#123; fmt.Println(x, y)&#125; else &#123; fmt.Println(x, y)&#125;fmt.Println(x, y) // compile error: x and y are not visible here 在上面的示例中存在多个作用域，从大到小依次是: 全局作用域 外层 if 语句条件部分创建隐式词法域 外层 if 语句花括弧包含的显式作用域 内层 if 语句条件部分创建隐式词法域 ….. 因此内层 if 语句的条件测试部分，能访问到外层 if 语句条件部分声明的变量 x。for 语句循环的初始化部分，switch 语句的条件测试部分都会引入类似的隐式作用域。 变量的作用域问题说起来比较复杂，但是大多数情况下，只要我们不在不同的作用域内声明同名变量，导致变量覆盖，基本上都不会现问题。但是在 Go 中要特别注意短变量声明语句的作用域。 在下面的示例中，虽然cwd在外部已经声明过，但是 := 语句还是将cwd和err重新声明为新的局部变量。因为内部声明的cwd将屏蔽外部的声明，因此上面的代码并不会正确更新包级声明的cwd变量。 1234567891011121314151617var cwd stringfunc init() &#123; cwd, err := os.Getwd() // compile error: unused: cwd if err != nil &#123; log.Fatalf("os.Getwd failed: %v", err) &#125;&#125;// 正确做法var cwd stringfunc init() &#123; var err error # 单独声明 err 变量 cwd, err = os.Getwd() if err != nil &#123; log.Fatalf("os.Getwd failed: %v", err) &#125;&#125; 最后，Go 变量遵循先声明后使用的规则，但是在包级别，声明的顺序并不会影响作用域范围，因此一个先声明的可以引用它自身或者是引用后面的一个声明，这可以让我们定义一些相互嵌套或递归的类型或函数。]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1 go 入门开篇]]></title>
    <url>%2F2019%2F01%2F01%2Fgo%2Fgo_grammar%2Fgo_1%2F</url>
    <content type="text"><![CDATA[如果编程的世界是海贼王里的”大航海时代”, go 语言可能就是”草帽海贼团” 1. 要去学 Go 了学习和使用 Python 有三四年,好想学一门新语言,打算学 Go。为什么是 Go，其实更想学 Rust。但是 Go 有谷歌这个大佬，背靠k8s，显然学 Go 好处大大的。其实也无所谓，哪天想学 Rust，就拿来看看对比着学可能更快。当然学 Go 还有另一个重要原因，想转运维开发。 2. 怎么学 Go因为已经不是第一次学编程了，之前也看过一段时间 C，想看看在学习了编程这么长时间之后，在编程领域的学习能力相比于一开始有没有提升。所以这次打算从语言特性的角度出发，有目的性的对比学习，看看能不能以更快的速度学好 Go。下面是我能想到知识面: 基础语法，包括变量，循环，判断以及运算符 Go 语言提供的基本数据结构 异常处理 函数，类与泛型 并发编程 3. 学习资料书选的《Go程序设计语言》，在写博客之前已经翻过一遍，的确是一本可以拿来入门的好书。 4. 环境搭建在学习 Go 语言之前，最重要的是搭建一个 Go 的开发环境。为了对 Go 有一个更好的整体把握，对于这个开发环境我们至少完成下面这些任务。下面涉及的 Go 专业术语，后面会详细解释，为了便于理解，我简单的跟 Python作了一个对比 安装 Go，搭建基本的go开发环境 – python 安装 Go 语言工具箱，特别是 go 程序包的查询，下载和管理 – pip 的使用 Go 语言的工作目录 – 模块的搜索路径 IDE 编程环境 我们主要讲解 Linux 下的环境搭建，Windows 的搭建类似。我们使用 VScode 作为我们的IDE，没其他原因，因为大佬们都推荐。 4.1 Go 安装Go 语言官方文档有完整的安装文档,Linux 下可直接运行下面的 bash 脚本，而唯一需要修改的是最后三个环境变量的配置。其中 PATH: 用于将 go 命令添加到环境变量的命令搜索路径中，便于直接使用 go 命令 GOPATH: 用于指定 go 的工作区，可以是单个目录路径，也可以是冒号分割的多个路径 GOBIN: 用于指定 GO 程序生成的可执行文件（executable file）的存放路径 先让你的 Go 可以运行起来，别的不用着急，马上我们就会讲解环境变量的作用，在你理解这些环境变量的含义之后就可以按需修改。 1234567891011121314151617go_vsersion=go1.12.4.linux-amd64.tar.gz# 1. 下载安装包wget https://studygolang.com/dl/golang/$&#123;go_vsersion&#125;.tar.gz# 2. 解压到指定目录tar -C /usr/local -xzf $&#123;go_version&#125;.tar.gz# 3. 配置相关环境变量# 将 go 命令添加到 PATH 环境变量中，以便直接使用，PATH 环境变量与 GO 本身无关echo 'export PATH=/usr/local/go/bin:$PATH' &gt; /etc/profile.d/go.sh# 添加 Go的工作区，下面默认为 $HOME/goecho 'export GOPATH=$(go env GOPATH)' &gt;&gt; /etc/profile.d/go.shecho 'export GOBIN=$GOPATH/bin' &gt;&gt; /etc/profile.d/go.# 4. 并通过在命令行中输入go version来验证是否安装成功。go version 4.2 Go语言工具箱在 go 安装完毕之后，在 go 安装目录的 bin 子目录下会有一个 go 命令(默认为/usr/local/go/bin)，这就是 go 语言提供给我们的管理工具箱，它是一系列功能的集合: 首先它是一个构建系统，计算文件的依赖关系，然后调用编译器、汇编器和连接器构建程序 其次它是一个包管理器（类似于python pip），用于包的查询、下载、依赖关系解决。 最后它是一个单元测试和基准测试的驱动程序 go 命令的执行依赖很多环境变量，使用 go env 可以查看所有的环境变量，大多数环境变量在 go 语言正确安装之后(主要是选择与操作系统匹配的安装包)会自动配置，唯一需要用户配置是GOPATH，用于指定go 语言的工作区，工作区是 go 语言中的一个核心概念，Go 语言项目在其生命周期内的所有操作（编码、依赖管理、构建、测试、安装等）基本上都是围绕着 GOPATH 和工作区进行的。 4.3 Go 工作区GOPATH对应的工作区目录有三个子目录: src 子目录用于存储源代码，使用 go get 下载的 go 包和自定义的 go 程序源代码都存在此目录中，同时也是代码包搜索和导入的启始根目录 pkg子目录用于保存编译后的包的目标文件 bin子目录用于保存编译后的可执行程序 go build命令编译命令行参数指定的每个包。如果 src使用命令 go get可以下载一个单一的包或者用 …下载整个子目录里面的每个包。go get 会自动下载所依赖的每个包 #### #### 4.3 GOROOT环境变量GOROOT用来指定Go的安装目录，还有它自带的标准库包的位置。GOROOT的目录结构和GOPATH类似，因此存放fmt包的源代码对应目录应该为$GOROOT/src/fmt。用户一般不需要设置GOROOT，默认情况下Go语言安装工具会将其设置为安装的目录路径。 下面是我当前工作区目录的示例:123456789101112131415161718192021$ tree -L 2 /home/tao/go/home/tao/go├── bin│ ├── a│ ├── dlv│ ├── gocode│ ├── godef│ ├── go-outline│ ├── gopkgs│ ├── goreturns│ └── helloworld├── pkg│ └── linux_amd64└── src ├── algo ├── blog ├── github.com ├── golang.org ├── gopl.io ├── sourcegraph.com └── test 你可以运行go或go help命令查看内置的帮助文档，为了查询方便，我们列出了最常用的命令 12345678910111213141516171819202122232425262728$ goGo is a tool for managing Go source code.Usage: go &lt;command&gt; [arguments]The commands are: bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packagesUse "go help &lt;command&gt;" for more information about a command. 4.3 Go 环境变量GOPATH对应的工作区目录有三个子目录。 与 Python 不同的是，Go 的包不是通过镜像的方式，而是直接从远程版本控制系统(eg: githup)直接下载的，因此当我们使用标准的 go get 下载Go包时，可能会由于不可描述的原因失败。因此我们必须手动解决一些包的安装问题。 4.2 Vscode 安装在Vscode官网 下载与你系统时配的安装包，安装即可。安装完成后在 VScode Extension 安装与 go 相关的扩展，如下图所示:]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>入门指南</tag>
        <tag>go语言入门</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[39 最小生成树]]></title>
    <url>%2F2018%2F11%2F21%2Falog%2Fgraph_use4%2F</url>
    <content type="text"><![CDATA[最小生成树 1. 最小生成树所谓最小生成树(简称MST)就是在一个无向，有权图G中，找到一颗连接所有顶点的树，并且树包含的边的权重总和最低。最小生成树有两种常见解法: Prim-Jarnik 算法: 从单个根节点生成 MST，它和 Dijkstra有很多相似之处 Kruskal 算法: 通过按照边的权重的非递减去考虑边来成群的生成 MST 无论是哪种算法，它们都基于最小生成树这样一个事实。即 G 是一个有权重的连通图，另 V1 和 V2 是两个不相交的非空集合G的顶点的一部份。此外另 e 是那些一个顶点在 V1 一个顶点在V2的有最小权重的G的边，则 e 是最小生成树的一条边。 1.1 Prim-JarnikPrim-Jarnik 算法，我们以一某一顶点 s 开始，定义初始集合 C，然后每次迭代中，我们选择一个最小权重的边 e，将 C 中的顶点连接到 C 之外的顶点 v，之后在将 v 加入 C 中。此时 e 就是最小生成树的一条边。 1.2 KruskalKruskal 算法，首先每个顶点本身是单元素集合集权。算法按照权重增加的顺序轮流考察每条边。如果一条边连接了两个不同的集群，那么 e 就是最小生成树的一条边。 2. 实现2.1 Prim-Jarnik12345678910111213141516171819202122232425262728def MST_Prim_Jarnik(g): d = &#123;&#125; tree = [] pq = AdaptableHeapPriorityQueue() # 优先队列 pdlocator = &#123;&#125; # pdlocator 此处还起到判断顶点是否已经迭代过的作用 # 初始化 for v in g.vertices(): if len(d) == 0: d[v] = 0 else: d[v] = float('inf') pdlocator[v] = pq.add(d[v], (v, None)) while not pq.is_empty(): key, value = pq.remove_min() u, edge = value if edge is not None: tree.append(edge) del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) if v in pdlocator: wgt = e.element() if wgt &lt; d[v]: d[v] = wgt pq.update(pdlocator[v], (v, e)) return tree Prim-Jarnik Dijkstra类似，时间复杂度分析也类似。 2.2 Kruskal12345678910111213141516171819202122def MST_Kruskal(g): tree = [] pq = AdaptableHeapPriorityQueue() # 优先队列 forest = Partition() position = &#123;&#125; for v in g.vertices(): position[v] = forest.make_group(v) for e in g.edges(): pq.add(e.element, e) size = g.vertice_count() while len(tree) != size - 1 and pq.is_empty(): wgt, edge = pq.remove_min() u, v = edge.endpoints() a = forest.find(position[u]) b = forest.find(position[v]) if a != b: tree.append(edge) forest.union(a, b) return tree Partition 是一个不相交集合和联合查找结构的实现。 2.3 不相交集合和联合查找结构1234567891011121314151617181920212223242526272829303132class Partition(object): __slots__ = '_container', '_element', '_size', '_parent' class Position(object): def __init__(self, container, e): self._container = container self._element = e self._size = 1 self._parent = self def element(self): return self._element def make_group(self, e): return self.Position(self, e) def find(self, p): if p._parent != p: p._parenet = self.find(p._parent) return p._parent def union(self, p, q): a = self.find(p) b = self.find(q) if a is not b: if a._size &gt; b._size: b._parent = a a._size += b._size else: a._parent = b._parent b._size += a._size]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[38 最短路经]]></title>
    <url>%2F2018%2F11%2F20%2Falog%2Fgraph_use3%2F</url>
    <content type="text"><![CDATA[最短路经 1. 最短路径广度优先算法可以计算连通图中，从一个顶点到另一顶点的最短路径，但前提是图上的每条边的权重相同。那如何计算全重不同的图的最短路径呢？最出名的莫过于 Dijkstra 算法。 1.1 DijkstraDijkstra 算法是贪心算法。贪心算法的递归过程差不多是这样:假设我们计算图 G 上顶点 u 到顶点 v 的最短距离；对于到顶点 v 的所有输入边的顶点集合 S，如果我们知道 u 到 S 中每个顶点的最短距离，那我们就能计算出 u 到 v 的最短距离。整个 Dijkstra 算法计算过程比较复杂，我们结合代码来看。 2. 实现2.1 Dijkstra12345678910111213141516171819202122232425262728293031323334def shortest_search(g, src): d = &#123;&#125; # 从 src 到 顶点的最短距离 cloud = &#123;&#125; # 收集已经计算得到最短距离的所有顶点 pre = &#123;&#125; # 还原最短路径的路径 pdlocator = &#123;&#125; # 定位顶点在优先队列中位置 pq = AdaptableHeapPriorityQueue() # 优先队列 # 初始化 for u in g.vertices(): d[u] = float('inf') d[src] = 0 pre[src] = None pdlocator[src] = pq.add(0, src) # 迭代优先队列，不断从中取出距离最小的顶点 while not pq.is_empty(): k, u = pq.remove_min() # 删除堆顶元素 cloud[u] = k del pdlocator[u] for e in g.incident_edge(u): v = e.opposite(u) n = k + e.element() if v not in cloud: if v not in pdlocator: d[v] = n # 插入堆 pdlocator[v] = pq.add(d[v], v) src[v] = u else: if n &lt; d[v]: d[v] = n # 更新堆 pq.update(pdlocator[v], n, v) src[v] = u return cloud, pre AdaptableHeapPriorityQueue 是我们在堆中实现的优先队列。之所以使用这个优先队列，是因为我们要不断的在队列中更新顶点的距离，以保证从优先队列取出的是当前距离最小的顶点。 整个代码的时间负载度分成两个部分: 一是 while + for 内对顶点和边的迭代，因为每个顶点和每条边最多被迭代一次，所以时间负载度是O(n+m); 二是对优先队列的操作，包括: add remove_min update 在堆一节中AdaptableHeapPriorityQueue被实现为一个堆，上述所有操作的时间复杂度都是 logn，因此总的时间复杂度是 O((n+m)logn)。 AdaptableHeapPriorityQueue 还有其他实现方式，比如一个未排序的数组，此时 remove_min 为 O(n)，其他两个操作的时间复杂度都是O(1)，此时总体的时间复杂度就是 O(n*n + m)。因此使用哪种实现方式更优取决于图的稀疏程度。 需要注意的是与前面类似，对于 d，pre， pdlocator，cloud 如果顶点可以用 0 到 n-1 进行编号， 它们都可以用数组代替，或者将作为顶点属性来记录。 2.2 重建最短路径树上面我们计算出从 src 到各个顶点的最短距离，但是并没有明确计算出获取最短剧路的路径。最短路径的重建有两种方式: 向上面代码中那样，使用 pre 记录到达每个顶点的前一个顶点。 是直接从 cloud 的返回值进行重建。 1234567891011121314151617181920212223242526272829# 重建最短路径树def shortest_path_tree(g, s, d): """ :param g: :param s: src 顶点 :param d: cloud 的返回值 :return: """ tree = &#123;&#125; for v in d: if v is not s: for e in g.incident_edge(v, False): u = e.opposite(v) wgt = e.element() if d[v] == d[u] + wgt: tree[v] = e return tree # 计算到顶点 v 的最短路径def shortest_path(pre, v): """ :param pre: pre :return: """ p = [v] while v in pre and pre[v] is not None: v = pre[v] p.append(v) return p.reverse()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[37 拓扑排序]]></title>
    <url>%2F2018%2F11%2F19%2Falog%2Fgraph_use2%2F</url>
    <content type="text"><![CDATA[拓扑排序 1. 拓扑排序的背景拓扑排序是一种排序，假设完成一项任务需要 n 个步骤，这 n 个步骤之间存在依赖关系，拓扑排序就是确定一个满足依赖关系的执行步骤。典型的拓扑排序用于解决如下问题: 大学课程之间的选修课的顺序 面向对象编程的类之间的继承 编译器在编译项目，按照编译的依赖关系确定编译顺序 拓扑排序是有向无环图的经典应用，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。其有两种实现方法，分别是Kahn 算法 和 DFS 深度优先搜索算法。 1.1 Kahn 算法Kahn 算法实际上用的是贪心算法思想。 定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。 我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中，并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。 Kahn 算法还能检测图是否存在环，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环 1.2 DFS 深度优先搜索算法使用 DF 实现拓扑排序的方法不好理解。假设图上的一个路径是A--&gt;B--&gt;C--&gt;D，如果我们按照输入边进行 DFS，那么顶点 A 一定在其他顶点之前输出。即所有入度为 0 的顶点一定在其他顶点之前输出，而递归调用的返回相当于对于顶点的入度减 1。最终的结果就是按照输入边对图的 DFS 和Kahn 算法一致。文字描述并不是很清楚，请结合代码查看。 2. 实现2.1 Kahn 算法123456789101112131415161718192021def topologic_sort(g): topo = [] # 拓扑排序的结果 ready = [] # 入度为 0 待加入 topo 的顶点 incount = &#123;&#125; # 记录每个顶点的入度 for u in g.vertices(): c = g.degree(u, False) if c == 0: ready.append(u) else: incount[u] = c while ready: u = ready.pop() topo.append(u) # 获取 u 的输出边，减少对应顶点的入度 for e in g.incident_edge(u): # 迭代所有顶点的传出边 v = e.opposite(u) incount[v] -= 1 if incount[v] == 0: incount.pop(v) ready.append(v) return topo 和图的遍历一样如果顶点可以用 0 到 n-1 进行编号，我们可以用数组代替 incount，或者将入度的计数作为顶点属性来记录。显然整个算法的时间复杂度为 O(n + m) 2.2 DFS 深度优先搜索算法123456789101112131415161718def DFS_income(g, u, discovered, topo): for e in g.incident_edge(u, False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS_income(g, v, discovered, topo) # 类似于后序遍历, 顶点 A 会优先加入 topo topo.append(u)def topologic_dfs(g): discovered = &#123;&#125; topo = [] for u in g.vertices: if u not in discovered: discovered[u] = None DFS_income(g, u, discovered, topo) return topo]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36 图的传递闭包]]></title>
    <url>%2F2018%2F11%2F18%2Falog%2Fgraph_use1%2F</url>
    <content type="text"><![CDATA[解决图可达性的传递闭包 1. 场景通过图上的深度和广度优先搜索算法，我们可以知道顶点 u 到顶点 v 的可达性问题，但是在某些应用中，我们可能希望更高校的回答很多可达性问题。此时对图预计算一个更高效的表示方式是非常值得的，图的传递闭包就是用来解决这个问题。 有向图 G 的传递闭包是有向 G1 使得 G1 顶点与 G 的顶点一样，并且对于所有顶点对 (u, v) 能直接表示是否有从 u 到 v 的一条路径。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[35 深度和广度优先搜索]]></title>
    <url>%2F2018%2F11%2F16%2Falog%2Fgraph_search%2F</url>
    <content type="text"><![CDATA[图的深度和广度优先搜索 1. 特性上一节我们讲解了图的存储和表示，这一节我们来介绍图上的搜索算法。图的搜索方法有很多，最常见的就是深度和广度优先搜索，除此之外还有 A、IDA 等启发式搜索算法。因为邻接表更加常用，我们就以邻接表作为图的存储方式来讲解最基础的深度和广度优先算法。 形式上，遍历是通过检查所有的边和顶点来探索图的系统化的步骤。图的遍历算法是回答许多涉及可达性概念的有关图的问题的关键，即在图中决定如何从一个顶点到达另一个顶点。 在无向图中处理可达性的问题包括: 计算从顶点 u 到顶点 v 的路经，或者报告这样的路经不存在 已知 G 的开始顶点，对每个 G 的顶点 v 计算 s 和 v 之间的边的最小数目的路经，或者报告有没有这样的路经 测试 G 是否是连通的 如果 G 是连通的，计算 G 的生成树 计算 G 的连通分支 计算 G 中的循环，或者报告 G 没有循环 在有向图中处理可达性的问题包括: 计算从顶点 u 到顶点 v 的有向路经，或者报告这样的路经不存在 找出 G 中从已知顶点 s 可达的顶点 判断 G 是否是非循环的 判断 G 是否是强连通的 1.1 深度优先搜索深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”，每次迭代时任意选择一个分岔的”顶点”进行搜索，直至没有顶点时退回到上一个顶点重新选择新的顶点继续遍历，直到所有顶点都被遍历结束。下面是一个深度优先搜索的示意图 深度优先搜索对是否从一个顶点到另一个顶点有路径和是否该图是一个连通图非常有用。 1.2 广度优先搜索广度优先搜索（Breadth-First-Search），简称为 BFS，就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。所有的顶点按照从左往右，从上往下的顺序依次迭代。为了保证迭代的次序需要用到队列，整个过程就是从顶点入队开始，将队首元素出队，并将出队顶点的下一层顶点依次入队，迭代直至队列为空的过程。为了防止顶点被重复遍历，需要对已经遍历的顶点进行表识。 2. 应用2.1 深度优先搜索12345678910111213141516def DFS(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered)# u 为开始顶点，值为 None，用于标识其为开始顶点result = &#123;u: None&#125;DFS(g, u, result) discovered 字典这里为两个目的服务，一是提供了用于判断顶点是否已被访问的机制，二是字典内保存的边就是DFS树的边。如果假设顶点可以用 0 到 n-1 进行编号，discovered可以用基于这些数子的数组替代。或者可以直接将所有顶点的发现状态以及顶点的发现边作为顶点的属性，成为顶点的一部分。 顶点 u 到 v 的可达路经基于discovered 字典我们可以很容易基于这个字典来提供从顶点 u 到达顶点 v 的可达路经的顶点列表。 1234567891011def construct_path(u, v, discovered): path = [] if v in discovered: path.append(v) walk = v while walk is not u: parent = discovered[walk].opposite[walk] path.append(parent) walk = parent path.reverse() return path 连通性测试基于 DFS 函数，我们可以很容判断图是否是连通的。在无向图的情况下，我们在任意顶点简单的开始深度有限搜索，然后测试 len(discovered) 和图的顶点数是否相同。如果相等无向图就是连通。 对于有向图，我们可能想测试它是否是强连通的。我们可以对任意顶点 s 执行深度优先搜索。注意在我们的 DFS 实现中，我们是以顶点的输出边为基础的，我们可以重新实现一个深度优先搜索函数 DFS_IN，这次以输入边作为遍历图的基础。对顶点 s 重新执行 DFS_IN。如果两次 DFS 遍历，所有顶点都是可达的则图是强连通的。 12345678910111213def DFS_IN(g, u, discovered): """ :param g: 图 :param u: 开始顶点 :param discovered: 将图的顶点映射到用于发现那个顶点的边 :return: """ # 以输入边执行反向的深度优先搜索 for e in g.incident_edge(u, outgoing=False): v = e.opposite(u) if v not in discovered: discovered[v] = e DFS(g, v, discovered) 计算所有的连通分支当图是不连通的时候，我们的下一个目标是识别无向图的所有连通分支，或有向图的强连通分支。我们首先来看无向图。 1234567def DFS_complete(g): forest = &#123;&#125; for u in g.vertices(): if u not in forest: forest[u] = None DFS(g, u, forest) return forest DFS_complete 函数返回的发现字典代表了整个图的 DFS 森林。连通分支数可以通过发现字典值为 None 的键的个数来判定。 找到有向图的强连通分支的情况更复杂，存在在 O(n+m)时间内计算这些连通分支的方法，使用两次单独的深度优先搜索遍历，细节我们之后在详述。 判断图是否存在循环循环的存在当且仅当和 DFS 遍历相关的 back 边存在。无向图搜索 back 边是容易的，因为所有的边不是树的边就是 back 边。而无向图比较困难。代码实现如下 12345def is_cycle(): passdef is_cycle_directed(): pass 2.1 广度优先搜索如下两个版本的广度有限搜索代码都是正确的，都是我们常用的形式。 123456789101112131415161718192021222324def BFS(g, s, discovered): queue = deque() queue.append(s) discovered[s] = None while queue: u = queue.popleft() for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e queue.append(v)def BFS_1(g, s, discovered): level = [] while level: next_level = [] for u in level: for e in g.incident_edge(u): v = e.opposite(u) if v not in discovered: discovered[v] = e next_level.append(v) level = next_level 广度优先搜索的应用BFS 可以遍历 s 所有的可达顶点，要探索整个图，可以从另一顶点重新开始，和代码 DFS_complete 类似。同样从顶点 s 到顶点 v 的实际路经可以使用代码段 construct_path 函数重建。 2.3 对比DFS 和 BFS 都能很高效的找到从给定源可达顶点的集合，然后判定到这些顶点的路经。然而 BFS 可保证这些路经尽可能少的使用边。对于无向图，两个算法都能用来测试连通性，识别连通分支或找出循环。对于有向图而言，DFS 可能更适合一些任务，比如在图中寻找有向循环，或识别强连通分支。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[34 图的表示]]></title>
    <url>%2F2018%2F11%2F15%2Falog%2Fgraph%2F</url>
    <content type="text"><![CDATA[如何表示一个图 1. 特性从本节开始，我们将进入图的学习。图是一种比树更复杂的非线性结构，图中有以下一些专用术语: 顶点: 图中的节点被称为顶点 边: 顶点之间存在链接关系，可以有方向，也可以有权重 有向图: 边有方向的图 带权图: 边存在权重的图 度: 顶点包含的边数，在有向图中，度分为出度和入度 出度表示以顶点作为起点的边，该边也称为顶点的输出边 入度表示以顶点作为终点的边，该边也称为顶点的入射边 很显然在表示和存储一个图时，我们需要保存图的顶点，边，以及边的方向和权重。而图的存储有两个常见方法: 邻接矩阵和邻接表 1.1 邻接矩阵邻接矩阵的底层是一个二维数组，A[i][j] 表示从节点 i 指向节点 j 的一条边，A[i][j]元素的值表示是否存在这条边或者在带权图中表示边的权重。 邻接矩阵的存储方式简单、直接，基于数组，在获取两个顶点的关系时，非常高效；可以将很多图的运算转换成矩阵之间的运算，计算方便。但是最大的缺点是浪费空间，在无向图中，有一半的空间是浪费的。如果我们存储的是稀疏图,也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵就更加浪费空间。通常我们遇到的都是稀疏图，所以邻接矩阵的存储方法并不常用。 1.2 邻接表 如上图，在邻接表中每个顶点对应一条链表，链表中存储的是与此顶点直接先连的其他顶点。与邻接矩阵相比，邻接表更加节省空间，但是使用起来就比较耗时，如果我们想确定是否存在从 i 指向 j 的边，我们必需遍历顶点 i 上的整个链表。 为了提高查找效率，我们可以将邻接表中的链表改成红黑树、跳表、散列表，甚至将链表改成有序动态数组，通过二分查找的方法来快速定位两个顶点之间否是存在边。至于如何选择，还需要看具体的业务场景。 1.3 应用示例我们以微博的用户关系为例，假设我们需要支持下面这样几个操作： 判断用户 A 是否关注了用户 B； 判断用户 A 是否是用户 B 的粉丝； 根据用户名称的首字母排序，分页获取用户的粉丝列表； 根据用户名称的首字母排序，分页获取用户的关注列表。 社交网络是一张稀疏图，更适合使用邻接表来存储。不过，此处我们需要两个图: 邻接表和逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系，分别用于关注和粉丝两种关系的判断。因为我们有排序需求，而跳表存储的数据本身就是有序的，所以我们选择用跳表来替代链表。 但是对于拥有亿级别用户的微博，显然我们没法将图存在一台机器的内存上。我们可以通过哈希算法等数据分片方式，通过对顶点的哈希然后分片，将邻接表存储在不同的机器上。当要查询顶点与顶点关系的时候，我们就利用同样的哈希算法，先定位顶点所在的机器，然后再在相应的机器上查找。 此外借助于 mysql 这样的外部存储，我们可以将 (user_id, follower_id) 这样的关注关系存储在 mysql 中。相比于图这可能是更好的解决方案。 2. 实现图是顶点和边的集合，我们将图的抽象模型定义为三种数据类型的组合: Vertex,Edge 和 Graph。 VertexVertex ADT 用来表示顶点对象，有一个用来检索所存储元素的方法 element() EdgeEdge ADT 用来表示边，并具有如下方法: element(): 返回保存的边的值 endpoint(): 返回边对应的(u, v)，u为边起点，v为边的终点 opposite(u): 传入边的一个端点，返回边的另一个端点 GraphGraph ADT 表示图，包含如下方法: vertex_count(): 返回图的顶点数量 vertices(): 迭代返回图中的所有顶点 edge_count(): 返回图的边的数量 edges(): 迭代返回图中的所有边 get_edge(u, v): 返回从顶点 u 到顶点 v 的边，不存在返回 None，对于无向图 get_edge(u, v)，get_edge(v, u) 没有区别 degree(v, out=True): 返回顶点的出度，out=False 返回顶点的出度 incident_edges(v, out=True): 迭代返回顶点 v 的输出边，out=False 迭代返回顶点的输入边 insert_vertex(v=None): 创建并返回一个顶点的 Vertex 对象 insert_edge(u, v, x=None): 创建一个从顶点u 到顶点 v，存储元素 x 的 Edge 边对象 remove_vertex(v): 删除顶点及与顶点关联的边 remove_edge(e): 删除边 e 我们接下来就以邻接表，并使用哈希表代替链表的方式实现上述的抽象数据结构。 2.1 图的邻接表实现Vertext 和 Edge 类1234567891011121314151617181920212223242526272829303132class Vertex(object): __slots__ = '_element' def __init__(self, x): self._element = x def element(self): return self._element def __hash__(self): return hash(id(self))class Edge(object): __slots__ = '_origin', '_destination', '_element' def __init__(self, u, v, x): self._origin = u self._destination = v self._element = x def endpoints(self): return self._origin, self._destination def opposite(self, v): return self._destination if v is self._origin else self._origin def element(self): return self._element def __hash__(self): return hash((self._origin, self._destination)) Graph 类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071class Graph(object): def __init__(self, directed=False): """ :param directed: 是否创建有向图，默认为 False 表示创建无向图 """ self._outgoing = &#123;&#125; # key 为起点，value 为终点的 # 设计要点: key 为终点，value 为起点的，无向图_incoming 只是 _outgoing 的别名 self._incoming = &#123;&#125; if directed else self._outgoing def is_directed(self): return self._incoming is not self._outgoing def vertex_count(self): return len(self._outgoing) def vertices(self): return self._outgoing.keys() def edge_count(self): total = sum(len(self._outgoing[u]) for u in self._outgoing) if not self.is_directed(): total /= 2 return total def edges(self): result = set() # 对于无向图，需要去重 for u in self._outgoing: result.update(u.values()) return result def get_edge(self, u, v): return self._outgoing[u].get(v) def degree(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming return len(adj[v]) def incident_edge(self, v, outgoing=True): adj = self._outgoing if outgoing else self._incoming for edge in adj[v].values: yield edge def insert_vertex(self, x=None): v = Vertex(x=x) self._outgoing[v] = &#123;&#125; if self.is_directed(): self._incoming[v] = &#123;&#125; return v def insert_edge(self, u, v, x): e = Edge(u, v, x) self._outgoing[u][v] = e self._incoming[v][u] = e def remove_vertex(self, v): # 有向图: u --&gt; v ---&gt; v1 # 无向图: u---&gt; v ---- u # 删除以 v 为起点的所有边 for v1 in self._outgoing[v].keys(): del self._incoming[v1][v] del self._outgoing[v] # 删除以 v 为终点的所有边 if self.is_directed(): for u in self._incoming[v].keys(): del self._outgoing[u][v] del self._incoming[v] def remove_edge(self, e): u, v = e.endpoints() del self._outgoing[u][v] del self._incoming[v][u]]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[33 动态规划实战]]></title>
    <url>%2F2018%2F11%2F12%2Falog%2Fdp_3%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划实战 1. 动态规划总结上一篇，我们总结了动态规划的使用场景，以及如何利用动态规划去解决问题了，总结了: 一个模型三个特征: 多阶段决策最优解模型，最优子结构，无后效性，重复子问题 状态转移表法 状态转移方程法 并总结对比了四中编程思想之间的区别。这些东西都非常理论，需要慢慢消化。本文是动态规划的实战篇，也是编程思想系列的最后一篇。 2.应用本节我们核心要解决的问题是如何量化两个字符串之间的相似程度呢？有一个非常著名的量化方法，那就是编辑距离（Edit Distance）。 编辑距离指的就是，将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如增加一个字符、删除一个字符、替换一个字符）。编辑距离越大，说明两个字符串的相似程度越小。 根据所包含的编辑操作种类的不同，编辑距离有多种不同的计算方式，比较著名的有莱文斯坦距离（Levenshtein distance）和最长公共子串长度（Longest common substring length）。其中，莱文斯坦距离允许增加、删除、替换字符这三个编辑操作，最长公共子串长度只允许增加、删除字符这两个编辑操作。莱文斯坦距离的大小，表示两个字符串差异的大小；而最长公共子串的大小，表示两个字符串相似程度的大小。 下面是两个方法的操作示例，我们的问题是如何计算两个字符串的莱文斯坦距离和最长公共子串长度。 2.1 计算莱文斯坦距离首先我们来看回溯的处理过程。如果 a[i] 与 b[j] 匹配，我们递归考察 a[i+1] 和 b[j+1]。如果 a[i] 与 b[j] 不匹配，那我们有多种处理方式可选： 可以删除 a[i]，然后递归考察 a[i+1] 和 b[j]； 可以删除 b[j]，然后递归考察 a[i] 和 b[j+1]； 可以在 a[i] 前面添加一个跟 b[j] 相同的字符，然后递归考察 a[i] 和 b[j+1]; 可以在 b[j] 前面添加一个跟 a[i] 相同的字符，然后递归考察 a[i+1] 和 b[j]； 可以将 a[i] 替换成 b[j]，或者将 b[j] 替换成 a[i]，然后递归考察 a[i+1] 和 b[j+1]。 反过来看状态 (i, j) 可能从 (i-1, j)，(i, j-1)，(i-1, j-1) 三个状态中的任意一个转移过来。我们可以尝试着将把状态转移的过程，用公式写出来。这就是我们前面讲的状态转移方程 1234567如果：a[i]!=b[j]，那么：min_edist(i, j) 就等于：min(min_edist(i-1,j)+1, min_edist(i,j-1)+1, min_edist(i-1,j-1)+1)如果：a[i]==b[j]，那么：min_edist(i, j) 就等于：min(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1))其中，min 表示求三数中的最小值。 2.2 计算最长公共子串长度首先我们先来看回溯的处理思路。我们从 a[0] 和 b[0] 开始，依次考察两个字符串中的字符是否匹配。 如果 a[i] 与 b[j] 互相匹配，我们将最大公共子串长度加一，并且继续考察 a[i+1] 和 b[j+1]。 如果 a[i] 与 b[j] 不匹配，最长公共子串长度不变，这个时候，有两个不同的决策路线： 删除 a[i]，或者在 b[j] 前面加上一个字符 a[i]，然后继续考察 a[i+1] 和 b[j]； 删除 b[j]，或者在 a[i] 前面加上一个字符 b[j]，然后继续考察 a[i] 和 b[j+1]。 反过来也就是说，如果我们要求 a[0…i] 和 b[0…j] 的最长公共长度 max_lcs(i, j)，我们只有可能通过下面三个状态转移过来： (i-1, j-1, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j-1] 的最长公共子串长度； (i-1, j, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j] 的最长公共子串长度； (i, j-1, max_lcs)，其中 max_lcs 表示 a[0…i] 和 b[0…j-1] 的最长公共子串长度。 如果我们把这个转移过程，用状态转移方程写出来，就是下面这个样子： 1234567如果：a[i]==b[j]，那么：max_lcs(i, j) 就等于：max(max_lcs(i-1,j-1)+1, max_lcs(i-1, j), max_lcs(i, j-1))；如果：a[i]!=b[j]，那么：max_lcs(i, j) 就等于：max(max_lcs(i-1,j-1), max_lcs(i-1, j), max_lcs(i, j-1))；其中 max 表示求三数中的最大值。 3. 练习3.1 最长递增子序列我们有一个数字序列包含 n 个不同的数字，如何求出这个序列中的最长递增子序列长度？比如 2, 9, 3, 6, 5, 1, 7 这样一组数字序列，它的最长递增子序列就是 2, 3, 5, 7，所以最长递增子序列的长度是 4。 12345678910111213141516171819202122232425262728293031323334class Solution(object): def lengthOfLIS(self, nums): """ :type nums: List[int] :rtype: int """ if not nums: return 0 n = len(nums) status = [None] * (n) status[0] = nums[0] end = 0 for i in range(1, n): end = max(end, self.binary_search(nums[i], status, end)) return end + 1 def binary_search(self, v, status, end, start=0): m = start if status[end] &lt; v: end += 1 status[end] = v return end while start &lt;= end: mid = start + ((end - start) &gt; 1) if status[mid] == v: return end elif status[mid] &lt; v: start = mid + 1 else: if mid == m or status[mid-1] &lt; v: status[mid] = v return end else: end = mid - 1]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[32 动态规划理论]]></title>
    <url>%2F2018%2F11%2F11%2Falog%2Fdp_2%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划理论 1. 再论动态规划动态规划比起其三个算法思想更难懂。上一篇文章我们从实践角度介绍了如何利用动态规划解决问题。有了这个基础，接下来我们来解决如下几个问题: 什么样的问题可以用动态规划解决？ 解决动态规划问题的一般思考过程是什么样的？ 贪心、分治、回溯、动态规划这四种算法思想又有什么区别和联系？ 1.1 适用场景动态规划适合解决的问题可以概括为“一个模型三个特征”。 一个模型: 多阶段决策最优解模型。动态规划通常被用来解决最优问题，而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。 三个特征: 最优子结构 无后效性 重复子问题 最优子结构最优子结构指的是，问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。 无后效性无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。 重复子问题这个概念比较好理解。前面一节，我已经多次提过。如果用一句话概括一下，那就是，不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。 1.2 解题思路解决动态规划问题，一般有两种思路。我把它们分别叫作，状态转移表法和状态转移方程法。 状态转移表法一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。所以，这种方法与回溯算法相关，通常我们需要进行如下几步: 使用回溯算法，定义状态，画出递归树；判断是否存在重复子问题，看是否能用动态规划解决 画出状态转移表，根据递推关系，分阶段填充状态表中的每个状态 最后，将递推填表的过程，翻译成代码，就是动态规划代码了 状态表一般都是二维的，所以可以把它想象成二维数组。其中，每个状态包含三个变量，行、列、数组值。尽管大部分状态表都是二维的，但是如果问题的状态比较复杂，需要很多变量来表示，那对应的状态表可能就是高维的，比如三维、四维。那这个时候，我们就不适合用状态转移表法来解决了。一方面是因为高维状态转移表不好画图表示，另一方面是因为人脑确实很不擅长思考高维的东西。 状态转移方程法状态转移方程法有点类似递归的解题思路。状态转移方程法的大致思路可以概括为，找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码。我们需要分析，某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，我们有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。 状态转移方程是解决动态规划的关键。如果我们能写出状态转移方程，那动态规划问题基本上就解决一大半了，而翻译成代码非常简单。但是很多动态规划问题的状态本身就不好定义，状态转移方程也就更不好想到。 1.3 四种算法思想比较如果我们将这四种算法思想分一下类，那贪心、回溯、动态规划可以归为一类，而分治单独可以作为一类。前三个算法解决问题的模型，都可以抽象成我们今天讲的那个多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但是，大部分都不能抽象成多阶段决策模型。 回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，我们都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。 尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。 贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里我们不怎么强调重复子问题）。其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。 2. 应用有了上面的论述，接下来我们看看如何利用我们所说的动态规划的理论和方法来解决实际问题。 2.1 最小路经假设我们有一个 n 乘以 n 的矩阵 w[n][n]。矩阵存储的都是正整数。棋子起始位置在左上角，终止位置在右下角。我们将棋子从左上角移动到右下角。每次只能向右或者向下移动一位。从左上角到右下角，会有很多不同的路径可以走。我们把每条路径经过的数字加起来看作路径的长度。那从左上角移动到右下角的最短路径长度是多少呢？ 套用上面所讲的一个模型三个特征理论，我们来看看这个是否可以用动态规划来解: 一个模型: 从左上角到右下角可以分成多个步骤移动，显然这是一个多阶段决策问题 三个特征: 首先位置(i, j) 只能由 (i, j-1),(i-1, j) 移动得来，位置(i, j)的最短距离可以从这两个位置的最短距离得来，符合最优子结构， 其次位置(i, j)之后得如何选择与位置(i, j)之前无任何关系符合无后效性特征 最后，一个位置可以由两个位置移动得来，回溯求解中肯定会产生重复子问题因此这个问题能用动态规划解决。 123456789101112131415161718192021222324252627def min_path_in_matrix(matrix): row = len(matrix) column = len(matrix[0]) status = [[0] * column for i in range(row)] s = 0 for c in range(column): s += matrix[0][c] status[0][c] = s s = 0 for r in range(column): s += matrix[r][0] status[r][0] = s for i in range(1, row): for j in range(1, column): status[i][j] = min(status[i][j - 1], status[i - 1][j]) + matrix[i][j] print status return status[-1][-1]ss = [ [1,2,3], [4,5,6], [7,8,9]]min_path_in_matrix(ss) 2.2 硬币找零我们今天来看一个新的硬币找零问题。假设我们有几种不同币值的硬币 v1，v2，……，vn（单位是元）。如果我们要支付 w 元，求最少需要多少个硬币。比如，我们有 3 种不同的硬币，1 元、3 元、5 元，我们要支付 9 元，最少需要 3 个硬币（3 个 3 元的硬币）。 1pass 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30.2 zabbix安装与入门]]></title>
    <url>%2F2018%2F11%2F11%2Flinux_mt%2F33-zabbix%2Fzabbix%E5%AE%89%E8%A3%85%E4%B8%8E%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[zabbix安装与入门 前面我们对一个完整的监控系统包含的内容做了一个简单概述，各种监控系统的开源实现无非都是围绕我们介绍的内容展开。在监控系统的众多实现中 zabbix 最为常见，功能也最为强大，本节我们首先对 zabbix 做个详细介绍，内容包括: zabbix 的框架与组成 zabbix 的安装和配置 1. zabbixzabbix 当前长期维护的版本有三个，2.2，3.0，4.0，本节我们就以3.0 为例来讲解。 1.1 zabbix 特性zabbix 支持以下特性: 数据采样: snmp, agent, ipmi, jmv 报警升级功能 数据存储: mysql, pgsql 展示: php 程序，实时绘图，支持 支持模板: 支持网络主机自动发现 通过监控代理，支持分布式监控 支持二次开发 1.2 zabbix 系统架构 agent 监控模式 数据采集的有两种方式: 被动模式: zabbix server 向 zabbix agent pull 数据 主动模式: zabbix agent 主动向 zabbix server push 数据 1.3 zabbix 逻辑组件 2. zabbix 安装配置2.1 zabbix serve 安装配置默认的 epel 在配置 zabbix 过程中出现了问题，因此需要为 zabbix 配置 yum 源。参考 zabbix document 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109# 1. zabbix database - mysql## 1.1 安装配置 mysqlyum install mariadb-servervim /etc/my.cnf [mysqld] skip_name_resolve = ON innodb_file_per_table = ONsystemctl start mariadb-serversystemctl enabled mariadb-servermysql_secure_installation### 1.2 为 zabbix 创建 mysql 用户mysql -uroot -p1234&gt; create database zabbix character set utf8 collate utf8_bin;&gt; grant all on zabbix.* to &apos;zabbix&apos;@&apos;192.168.%.%&apos; identified by &apos;zbxpass&apos;;&gt; grant all on zabbix.* to &apos;zabbix&apos;@&apos;127.0.0.1&apos; identified by &apos;zbxpass&apos;;&gt; flush privileges;# 2. zabbix server## 2.1 配置 zabbix yum 源rpm -i http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm## 2.2 安装 zabbix server$ yum list zabbix-*已安装的软件包zabbix-release.noarch 3.0-1.el7 installed可安装的软件包zabbix-agent.x86_643.0.22-1.el7 zabbix zabbix-get.x86_64 3.0.22-1.el7 zabbix zabbix-java-gateway.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-proxy-sqlite3.x86_64 3.0.22-1.el7 zabbix zabbix-sender.x86_64 3.0.22-1.el7 zabbix zabbix-server-mysql.x86_64 3.0.22-1.el7 zabbix zabbix-server-pgsql.x86_64 3.0.22-1.el7 zabbix zabbix-web.noarch 3.0.22-1.el7 zabbix zabbix-web-japanese.noarch 3.0.22-1.el7 zabbix zabbix-web-mysql.noarch 3.0.22-1.el7 zabbix zabbix-web-pgsql.noarch 3.0.22-1.el7 zabbixyum install zabbix-server-mysql.x86_64$ rpm -ql zabbix-server-mysql.x86_64/etc/zabbix/zabbix_server.conf # zabbix server 配置文件/usr/lib/systemd/system/zabbix-server.service # unit file/usr/lib/zabbix/alertscripts/usr/lib/zabbix/externalscripts/usr/sbin/zabbix_server_mysql/usr/share/doc/zabbix-server-mysql-3.0.22/usr/share/doc/zabbix-server-mysql-3.0.22/create.sql.gz # zabbix 数据库初始化## 2.3 导入数据库脚本生成数据库环境gzip -d /usr/share/doc/zabbix-server-mysql-3.0.22/create.sql -c &gt;&gt;/root/create.sqlmysql -uroot -p1234 zabbix &lt; /root/create.sql## 2.4 zabbix serve 配置启动$ grep ^##### /etc/zabbix/zabbix_server.conf############ GENERAL PARAMETERS ############################# ADVANCED PARAMETERS ####################### LOADABLE MODULES ############## TLS-RELATED PARAMETERS #######SourceIP=192.168.1.106LogFile=/var/log/zabbix/zabbix_server.logLogFileSize=0PidFile=/var/run/zabbix/zabbix_server.pidDBHost=192.168.1.106DBName=zabbixDBUser=zabbixDBPassword=zbxpassSNMPTrapperFile=/var/log/snmptrap/snmptrap.logTimeout=4AlertScriptsPath=/usr/lib/zabbix/alertscriptsExternalScripts=/usr/lib/zabbix/externalscriptsLogSlowQueries=3000## 2.5 服务启动systemctl start zabbix-server# 3. 安装 zabbix web gui## 3.1 安装 lamp 以及 zabbix webyum install zabbix-web.noarch zabbix-web-mysql.noarchyum install httpd php php-mysql php-mbstring php-gd php-bcmath php-ldap php-xml -y## 3.2 zabbix web httpd 配置文件rpm -ql zabbix-web/etc/httpd/conf.d/zabbix.conf/etc/zabbix/web # web 根目录vim /etc/httpd/conf.d/zabbix.conf php_value date.timezone Asia/ShangHai # 根改时区## 3.3 启动 httpdsystemctl start httpd## 3.4 web 初始化http://192.168.1.106/zabbix/setup.php## 3.5 初始化生成的配置文件位于/etc/zabbix/web/zabbix.conf.php## 3.6 登陆，初始化的帐号: Admin 密码: zabbix## 密码保存在 mysql zabbix.users 中## select * from zabbix.users 2.2 zabbix agent 配置123456789101112131415161718192021222324252627282930313233# 1. 安装yum install zabbix-sender.x86_64 zabbix-agent.x86_64 -y# 2. 配置$ rpm -ql zabbix-agent/etc/logrotate.d/zabbix-agent/etc/zabbix/zabbix_agentd.conf # agent 配置文件/etc/zabbix/zabbix_agentd.d/etc/zabbix/zabbix_agentd.d/userparameter_mysql.conf/usr/lib/systemd/system/zabbix-agent.service # unit file/usr/lib/tmpfiles.d/zabbix-agent.conf/usr/sbin/zabbix_agentd$ grep -i &quot;^####&quot; /etc/zabbix/zabbix_agentd.conf############ GENERAL PARAMETERS ###################### Passive checks related # 被动监控配置项##### Active checks related # 主动监控配置############ ADVANCED PARAMETERS ######################## USER-DEFINED MONITORED PARAMETERS ####### # 用户自定义的监控参数 UserParamter####### LOADABLE MODULES ############## TLS-RELATED PARAMETERS ############ Passive checks relatedServer=IP1,IP2... # 访问控制授权，允许哪些主机过来采集数据ListenIP=0.0.0.0StartAgents=3##### Active checks relatedServerActive=IP1,IP2... # 主动报告的目标主机地址Hostname=node1 # 当前被监控主机在 zabbix 中的 id# 3. 启动服务systemctl start zabbix-agent 3. 监控配置在 zabbix 中快速配置一个监控需要按照如下顺序: 监控配置: host group--&gt; host--&gt; application--&gt; item--&gt;trriger---&gt;action(conditons, operations) 展示配置: item --&gt; simple graph items --&gt; graphs ---&gt; screen --&gt; slide show 每一个监控项 item 对应着一个 item key，其代表了在被检控主机上要执行的命令。 3.1 zabbix 监控测试12yum install zabbix-get.x86_64zabbix_get -s 192.168.1.155 -k &quot;system.cpu.switches&quot;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[31 初识动态规划]]></title>
    <url>%2F2018%2F11%2F10%2Falog%2Fdp_1%2F</url>
    <content type="text"><![CDATA[编程思想之动态规划初识 1. 动态规划动态规划是几个编程思想中最难的一个，它与回溯密切相关。回溯问题是在一组可能的解中，搜索满足期望的解；采用的方法类似枚举，找出所有解，筛选符合要求的解；而动态规划比较适合用来求解最优问题，比如求最大值、最小值等等。基本上所有的动态规划问题都能用回溯算法解决，但是动态规划能有效避免回溯算法中的重复计算，提高代码执行效率。 1.1 解决思路上一节我们用回溯算法解决了0-1背包问题，并阐述了回溯算法中可能存在重复计算的问题，借助于对子问题的缓存，我们能有效避免重复计算。但是需要注意的是这种方法并不是总是有效。 与回溯算法类似，动态规划中，我们同样把问题分解为多个阶段，每个阶段对应一个决策。我们记录每一个阶段可达的状态集合并去重，然后通过当前阶段的状态集合，来推导下一个阶段的状态集合，直至达到最终状态，并从中选择一个最优解。通过记录每个阶段的所有可达状态并去重来避免重复计算。 尽管动态规划的执行效率提高了，但是动态规划的空间复杂度也提高了，所以，很多时候，我们会说，动态规划是一种空间换时间的算法思想。 2.1 应用2.1 动态规划解0-1背包问题现在我们用动态规划来解决上一节的0-1背包问题，我们把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个物品决策（放入或者不放入背包）完之后，背包中的物品的重量会有多种情况，也就是说，会达到多种不同的状态，对应到递归树中，就是有很多不同的节点。 我们把每一层重复的状态（节点）合并，只记录不同的状态，然后基于上一层的状态集合，来推导下一层的状态集合。我们可以通过合并每一层重复的状态，这样就保证每一层不同状态的个数都不会超过 w 个（w 表示背包的承载重量），也就是例子中的 9。于是，我们就成功避免了每层状态个数的指数级增长。 我们用一个二维数组 states[n][w+1]，来记录每层可以达到的不同状态。n表示第n个物品，w+1 表示当前背包的重量。 12345678910111213141516171819202122232425262728def rucksack_hold(items, weight): status = [[0] * (weight + 1) for i in range(len(items))] status[0][0] = 1 status[0][items[0]] = 1 for i in range(1, len(items)): for j in range(weight + 1): if status[i - 1][j]: status[i][j] = status[i - 1][j] if j + items[i] &lt;= weight: status[i][j + items[i]] = 1 for l in status: print l # 判断可放置的最大重量 j = weight n = len(items) - 1 while j &gt;= 0: if status[n][j]: break print j # 打印最大重量，放置的物品 for i in range(n, 1, -1): if j - items[i] &gt;= 0 and status[i - 1][j - items[i]]: print i, items[i] j -= items[i]rucksack_hold([2, 2, 4, 6, 3], 9) 实际上我们可以有一个比上面空间复杂度更小的解法，代码如下:12345678910111213def rucksack_hold_2(items, weight): status = [0] * (weight + 1) status[0] = 1 status[items[0]] = 1 print status for i in range(1, len(items)): for j in range(weight - items[i], -1, -1): if status[j]: status[j + items[i]] = 1 print statusrucksack_hold_2([2, 2, 4, 6, 3], 9) 2.2 升级的 0-1 背包问题这次我们引入物品价值，要求计算在满足背包最大重量限制的前提下，背包中可装入物品的最大总价值。 使用动态规划的求解过程与上面类似，只不过现在 status 数组记录的不再是0或1，而是当前状态对应的最大总价值。我们把每一层中 (i, cw) 重复的状态（节点）合并，只记录 cv 值最大的那个状态，然后基于这些状态来推导下一层的状态。如果用回溯算法，这个问题就没法再用“备忘录”解决了。 12345678910111213141516171819 def rucksack_hold_3(items, weight, values): status = [[None] * (weight + 1) for i in range(len(items))] status[0][0] = 0 status[0][items[0]] = values[0] for i in range(1, len(items)): for j in range(weight + 1): if status[i - 1][j] &gt;= 0: status[i][j] = status[i - 1][j] if j + items[i] &lt;= weight: v = status[i - 1][j] + values[i] if status[i][j + items[i]] &lt; v: status[i][j + items[i]] = v for l in status: print lprint '------------------'a = [3, 4, 8, 9, 6]# a = [1, 1, 1, 1, 1]rucksack_hold_3([2, 2, 4, 6, 3], 9, a) 3. 练习3.1 练习一杨辉三角我们对杨辉三角进行一些改造。每个位置的数字可以随意填写，经过某个数字只能到达下面一层相邻的两个数字。假设你站在第一层，往下移动，我们把移动到最底层所经过的所有数字之和，定义为路径的长度。请你编程求出从最高层移动到最底层的最短路径长度。 1234567891011121314151617181920212223242526272829303132333435def path_pascal_triangle(pt): """ :param pt: :return: 计算杨辉三角的最短路径 """ n = len(pt) status = [] for i in range(0, n): s = [float('inf')] * (i + 1) row = pt[i] if i == 0: s[0] = row[0] s[-1] = row[-1] else: s[0] = row[0] + status[i - 1][0] s[-1] = row[-1] + status[i - 1][-1] status.append(s) print status for i in range(2, n): for j in range(1, i): left = j - 1 right = j status[i][j] = min(status[i - 1][left], status[i-1][right]) + pt[i][j] print status return min(status[-1])ss = [ [3], [1, 2], [5, 6, 7], [1, 1, 1, 1]]print path_pascal_triangle(ss) 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30.1 运维故障发现与监控系统应用]]></title>
    <url>%2F2018%2F11%2F10%2Flinux_mt%2F33-zabbix%2F%E6%95%85%E9%9A%9C%E5%8F%91%E7%8E%B0%E4%B8%8E%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[运维故障发现思路与监控系统应用 运维领域有一句话”我们不应该允许没有被监控的系统上线的”，显然监控对于我们快速发现问题解决问题至关重要。本章我们就来学习最常用的监控系统 zabbix 的安装，配置和使用。 在学习 zabbix 之前，我们首先需要对 zabbix 本身有所理解，因为无论是 zabbix 还是其他开源实现都是一种特定的解决方案，而不便的是怎样构建监控系统本身。 假设我们从头构建一个监控系统，应该如何做呢？我们需要思考以下几个问题: 监控哪些内容? 如何对监控项进行数据采集 如何判断系统是否处于非稳定状态，并在确定异常之后预警 如何能快速了解当前系统的状态及展示的问题。 这些问题就是我们构建一个监控系统的关键。因此一个完整的监控系统至少应该包含以下几个功能: 数据采集: 定期的采集监控指标的数据 数据存储: 将采集的数据保存起来，以便通过对比了解当前系统的状态 数据展示: 将存储的指标数据，直观的展示出来，以便运维工程师快速的了解整个系统的运行状态 报警: 当系统出现问题时，能发出报警及时通知管理员进行修复 1. 监控系统1.1 监控内容监控包含多个层面: 硬件: 硬件状态是否，硬件设备的资源是否满足业务需要，比如 CPU 使用率是否一直超过 90% 软件: 软件是否正成工作，比如我们的 nginx 服务进程是否正常 业务: 当前系统的并发请求数是否过高 不同的监控内容需要不同的监控设备以帮助我们收集监控数据，我们将监控设备称之为“传感器”(sensor)。 1.2 数据采集监控系统采集数据的通道通常包括 ssh/telnet agent: master/agent IPMI: 英特尔智慧平台接口，允许在硬件层级直接收集系统硬件状态信息 SNMP: Simple Network Management Protocol JMX: java 管理扩展，用于监控 jvm 虚拟机 1yum info net-snmp # linux snmp 协议的实现 1.3 存储系统监控数据分为两类: 历史数据: 每一次的采样数据，保存时间长较短 趋势数据: 一段时间内的聚合数据，保存时间较长 1.4 报警预警有多种方式，包括邮件，短信，微信，除了通用的邮件预警外，其他大多数的预警方式都是通过脚本来实现的。 1.5 展示数据展示有 WebGui，GUI，APP 等方式 1.6 监控系统的实现cactl， nagios: 功能有限zabbix: 功能强大]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.9 ansible 最佳实践]]></title>
    <url>%2F2018%2F11%2F09%2Flinux_mt%2F32-ansible%2Fansible_practice%2F</url>
    <content type="text"><![CDATA[ansible 最佳实践 当我们刚开始学习运用 playbook 时，可能会把 playbook 写成一个很大的文件，到后来可能你会希望这些文件是可以方便去重用的，所以需要重新去组织这些文件。ansible 支持 include 语法对 tasks, handlers, playbook 进行引用，从而我们可以对基础的通用功能进行封装，通过 “include” 对通用的功能进行组装从而实现复用。 1. include1.1 task include123456789101112131415161718tasks: - include: wordpress.yml wp_user=timmy - include: wordpress.yml wp_user=alice - include: wordpress.yml wp_user=bob# Ansible 1.4 及以后的版本tasks: - &#123; include: wordpress.yml, wp_user: timmy, ssh_keys: [ &apos;keys/one.txt&apos;, &apos;keys/two.txt&apos; ] &#125; # 传递结构化变量 tasks: - include: wordpress.yml vars: wp_user: timmy some_list_variable: - alpha - beta - gamma 1.2 playbook include12345678910111213- name: this is a play at the top level of a file hosts: all remote_user: root tasks: - name: say hi tags: foo shell: echo &quot;hi...&quot;- include: load_balancers.yml- include: webservers.yml- include: dbservers.yml 2. ansible 最佳实践2.1 项目目录结构一个完整的 ansible 项目，顶层目录结构应当包括下列文件和目录，如果你正在使用云服务，使用动态清单会更好。 1234567891011121314151617181920212223242526272829303132333435363738production # inventory file for production servers 关于生产环境服务器的清单文件stage # inventory file for stage environment 关于 stage 环境的清单文件group_vars/ group1 # here we assign variables to particular groups 这里我们给特定的组赋值 group2 # &quot;&quot;host_vars/ hostname1 # if systems need specific variables, put them here 如果系统需要特定的变量,把它们放置在这里. hostname2 # &quot;&quot;library/ # if any custom modules, put them here (optional) 如果有自定义的模块,放在这里(可选)filter_plugins/ # if any custom filter plugins, put them here (optional) 如果有自定义的过滤插件,放在这里(可选)site.yml # master playbook 主 playbookwebservers.yml # playbook for webserver tier Web 服务器的 playbookdbservers.yml # playbook for dbserver tier 数据库服务器的 playbookroles/ common/ # this hierarchy represents a &quot;role&quot; 这里的结构代表了一个 &quot;role&quot; tasks/ # main.yml # &lt;-- tasks file can include smaller files if warranted handlers/ # main.yml # &lt;-- handlers file templates/ # &lt;-- files for use with the template resource ntp.conf.j2 # &lt;------- templates end in .j2 files/ # bar.txt # &lt;-- files for use with the copy resource foo.sh # &lt;-- script files for use with the script resource vars/ # main.yml # &lt;-- variables associated with this role defaults/ # main.yml # &lt;-- default lower priority variables for this role meta/ # main.yml # &lt;-- role dependencies webtier/ # same kind of structure as &quot;common&quot; was above, done for the webtier role monitoring/ # &quot;&quot; fooapp/ # &quot;&quot; 2.2 playbook通过 include 将独立分散的 ansible 任务整合在一起 123456789101112---# file: site.yml # 顶层的 site- include: webservers.yml- include: dbservers.yml---# file: webservers.yml # webservers 的配置- hosts: webservers roles: - common - webtierv 理念是我们能够通过 “运行”(running) site.yml 来选择整个基础设施的配置.或者我们能够通过运行其子集 webservers.yml 来配置. 这与 Ansible 的 --limit 类似,而且相对的更为显式: 12ansible-playbook site.yml --limit webserversansible-playbook webservers.yml 2.3 任务执行1234567891011# 想重新配置整个基础设施,如此即可:ansible-playbook -i production site.yml# 那只重新配置所有的 NTP 呢？太容易了.:ansible-playbook -i production site.yml --tags ntp# 只重新配置我的 Web 服务器呢？:ansible-playbook -i production webservers.yml#只重新配置我在波士顿的 Web服务器呢?:ansible-playbook -i production webservers.yml --limit boston]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.8 ansible role]]></title>
    <url>%2F2018%2F11%2F08%2Flinux_mt%2F32-ansible%2Fansible_roles%2F</url>
    <content type="text"><![CDATA[ansible role role 角色，基于一个已知的文件结构，去自动的加载某些 vars_files，tasks 以及 handlers。基于 roles 对内容进行分组，使得我们可以容易地与其他用户分享 roles。 roles 是 playbook 的一个独立自包含目录，包含了执行 playbook 任务所有的配置文件及被操作文件，使得 playbook 的执行不需要依赖于任何外部环境。 1. roles 使用1.1 roles 目录结构一个包含 roles 的典型项目结构如下所示，如果你在 playbook 中同时使用 roles 和 tasks，vars_files 或者 handlers，roles 将优先执行。 1234567891011webservers.ymlroles/ webservers/ # 与 playbook 对应的 roles 目录 files/ # copy tasks，script tasks，引用 roles/x/files/ 中的文件无需指明路经 templates/ # template tasks 可以引用 roles/x/templates/ 中的文件，不需要指明文件的路径 tasks/ # main.yml 存在, 其中列出的 tasks 将被添加到 webservers.yml 中 handlers/ # main.yml 存在, 其中列出的 handlers 将被添加到 play 中 vars/ # main.yml 存在, 其中列出的 variables 将被添加到 play 中 defaults/ # main.yml 用于定义默认变量，这些变量在所有可用变量中拥有最低优先 meta/ # main.yml 存在, 其中列出的 “角色依赖” 将被添加到 roles 列表中 (1.3 and later) 1.2 roles 使用角色的使用，只需在 playbook 的 roles 语句中添加角色即可 123456# vim webservers.yml---- hosts: webservers roles: - common - webservers 也可以使用参数化的 roles，这种方式通过添加变量来实现 1234567---- hosts: webservers roles: - common - &#123; role: foo_app_instance, dir: &apos;/opt/a&apos;, port: 5000 &#125; - &#123; role: foo_app_instance, dir: &apos;/opt/b&apos;, port: 5001 &#125; 也可以为 roles 设置触发条件 12345---- hosts: webservers roles: - &#123; role: some_role, when: &quot;ansible_os_family == &apos;RedHat&apos;&quot; &#125; 最后，也可以给 roles 分配指定的 tags。比如: 12345---- hosts: webservers roles: - &#123; role: foo, tags: [&quot;bar&quot;, &quot;baz&quot;] &#125; 1.3 执行顺序如果 play 同时包含 tasks 和roles，这些 tasks 将在所有 roles 应用完成之后才被执行。如果你希望定义一些 tasks，让它们在 roles 之前以及之后执行，你可以这样做: 123456789101112131415---- hosts: webservers pre_tasks: - shell: echo &apos;hello&apos; roles: - &#123; role: some_role &#125; tasks: - shell: echo &apos;still busy&apos; post_tasks: - shell: echo &apos;goodbye&apos; 1.4 角色依赖角色依赖可以自动地将其他 roles 拉取到现在使用的 role 中。角色依赖保存在 roles 目录下的 meta/main.yml 文件中。这个文件应包含一列 roles 和 为之指定的参数 12345---dependencies: - &#123; role: common, some_parameter: 3 &#125; - &#123; role: apache, port: 80 &#125; - &#123; role: postgres, dbname: blarg, other_parameter: 12 &#125; “角色依赖” 总是在 role （包含”角色依赖”的role）之前执行，并且是递归地执行。默认情况下，作为 “角色依赖” 被添加的 role 只能被添加一次，如果另一个 role 将一个相同的角色列为 “角色依赖” 的对象，它不会被重复执行。但这种默认的行为可被修改，通过添加 allow_duplicates: yes 到 meta/main.yml 文件中。 1234567891011121314# wheel 角色中---allow_duplicates: yesdependencies:- &#123; role: tire &#125;- &#123; role: brake &#125;# 引用 wheel 的其他角色---dependencies:- &#123; role: wheel, n: 1 &#125;- &#123; role: wheel, n: 2 &#125;- &#123; role: wheel, n: 3 &#125;- &#123; role: wheel, n: 4 &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[30 回溯算法]]></title>
    <url>%2F2018%2F11%2F07%2Falog%2Fbacktracking%2F</url>
    <content type="text"><![CDATA[编程思想之回溯算法 1. 回溯算法回溯算法很多时候都应用在“搜索”这类问题上。即在一组可能的解中，搜索满足期望的解。 回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。 很多经典的数学问题都可以用回溯算法解决，比如数独、八皇后、0-1 背包、图的着色、旅行商问题、全排列等等。我们将以其中的几个问题为例来讲解如何使用回溯算法解决问题。 1.1 解决步骤回溯算法非常适合用递归来实现，在实现的过程中，剪枝操作是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。 与递归算法一样，回溯算法容易理解，但是写起来丝毫不容易。个人觉得，相比于找到递归终止条件和递推公式，更难的是确定递归函数的变量和函数的返回值。关于函数变量的选择有一个可参考的经验，就是始终关注的是在计算中会使用到的随着计算不断变动的量；对于函数返回值，回溯算法是枚举所有的解，期望的解通常不是通过函数直接返回，而通常位于递归终止条件中。 2. 应用2.1 八皇后问题所谓八皇后问题是这样的，我们往一个 8x8 的棋盘中放 8 个棋子（皇后），每个棋子所在的行、列、对角线都不能有另一个棋子，找出所有满足要求的摆放方式。下面是一个满足条件和不满足条件的示例。 我们把这个问题划分成 8 个阶段，依次将 8 个棋子放到第一行、第二行、第三行……第八行。在放置的过程中，我们不停地检查当前的方法，是否满足要求。如果满足，则跳到下一行继续放置棋子；如果不满足，那就再换一种方法，继续尝试。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253def queens_eight(num=8): def cal_queens(row): if row == num: output_chessboard(chessboard, num) return for column in range(num): if is_ok(chessboard, row, column, num): # print chessboard, row, column chessboard[row] = column cal_queens(row + 1) # 下标表示行，值表示列 chessboard = [0] * num cal_queens(0) return chessboarddef is_ok(chessboard, row, column, num): """ :param chessboard: :param row: :param column: :return: 检查最新的(row, column)摆放是否符合规则 """ left_up, right_up = column - 1, column + 1 last = row - 1 # 从最后一行往上检查 while last &gt;= 0: # 检查同列 if chessboard[last] == column: return False # 检查左上角对角线 if 0 &lt;= left_up == chessboard[last]: return False # 检查右上角对角线 if num &gt; right_up == chessboard[last]: return False last -= 1 left_up -= 1 right_up += 1 return Truedef output_chessboard(result, num): print result for i in range(num): column = result[i] c = ['*'] * num c[column] = '1' print ' '.join(c)queens_eight() 2.2 0-1 背包问题0-1 背包是非常经典的算法问题，这个问题的经典解法是动态规划，不过还有一种简单但没有那么高效的解法，那就是回溯算法。因此这个示例将是我们理解回溯算法和动态规划区别的很重要一个例子。 0-1 背包问题有很多变体，我这里介绍一种比较基础的。背包总的承载重量是 Wkg，有 n 个物品，每个物品的重量不等，并且不可分割。期望在不超过背包所能装载重量的前提下，让背包中物品的总重量最大。 对于每个物品来说，都有两种选择，装或者不装。n 个物品共有 2^n 种装法，去掉超过 Wkg，从剩下的选择种选择总重量最接近 Wkg 的。不过，我们如何才能不重复地穷举出这 2^n 种装法呢？ 我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。下面是代码实现: 1234567891011121314151617181920212223242526class RucksackHold(object): def __init__(self, weight, items): self.weight = weight self.items = items self.hold = 0 def _get_max_hold(self, i, cw): """ :param i: 考察的第 i 个物品 :param cw: 当前背包的总重量 :return: """ if i == len(self.items) or cw == self.weight: if cw &gt; self.hold: self.hold = cw return self._get_max_hold(i + 1, cw) if self.items[i] + cw &lt;= self.weight: self._get_max_hold(i + 1, cw + self.items[i]) def __call__(self, *args, **kwargs): self._get_max_hold(0, 0) return self.holdpk = RucksackHold(items=[1, 2, 4], weight=10)print pk() 回溯中的重复计算在回溯算法中，有些子问题的求解可能是重复的。假设背包的最大承载重量是 9，有 5 个不同的物品，重量分别是 2，2，4，6，3。如果我们把这个例子的回溯求解过程，用递归树画出来，就是下面这个样子： 递归树中的f(i, cw）表示一次函数调用。从递归树中可以发现，有些子问题的求解是重复的，比如图中的 f(2, 2) 和 f(3,4) 都被重复计算了两次。借助于对子问题结果的缓存，我们可以有效避免冗余计算提高计算效率。 2.3 正则表达式正则表达式中，最重要的就是通配符，简单期间，假设正表达式中只包含“*”和“\?”这两种通配符，并且“*”匹配任意多个（大于等于 0 个）任意字符，“\?”匹配零个或者一个任意字符。基于如上假设，如何用回溯算法，判断一个给定的文本，能否跟给定的正则表达式匹配？ 正则表达式中的特殊字符就是所谓的岔路口，比如“*”可以匹配任意个文本串中的字符，我们就先随意的选择一种匹配方案，然后继续考察剩下的字符。如果中途发现无法继续匹配下去了，我们就回到这个岔路口，重新选择一种匹配方案，然后再继续匹配剩下的字符。 12345678910class Pattern(): def __init__(self, pattern): self.pattern = pattern self.is_match = False def _match(self, S, i, j): pass def match(self, S): return self._match(S, 0, 0) 2.4 图的着色1234```### 2.5 旅行商问题```python 2.6 全排列1234```### 2.7 数独```python 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.7 ansible playbook]]></title>
    <url>%2F2018%2F11%2F07%2Flinux_mt%2F32-ansible%2Fansible_playbook%2F</url>
    <content type="text"><![CDATA[ansible playbook playbook 是 基于 yaml 语法的一种编排 ansible 命令的”脚本”，类似与 shell scritp；但是 playbook 并不是一门语言。我的理解是 playbook 就是一个配置文件，必需按照 ansible 要求的特定格式编排 ansible 的任务，这样 ansible 才能对其进行解释并执行。其能提供的功能是由 ansible 决定的。我们的目的就是学习 playbook 特定的编写要求。 相对于 ad-doc 的好处类似于 shell script 之与 shell 命令，可以重复执行，拥有更加强大的逻辑控制，因此便于执行更复杂的任务。 1. playbook 配置语法下面是一个 playbook 的示例，我们将以这个示例为基础讲解如何编写 playbook。playbook 使用的 yaml 语法，因此在学习接下来的内容之前你需要先了解一下 yaml。 123456789101112131415161718---- hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: pkg=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running service: name=httpd state=started handlers: - name: restart apache service: name=httpd state=restarted 1.1 playbook的核心元素123456789101112131415161718- host: vars: remote_user: tasks: - - - variables: - - - handlers: - -- host:- host: 我们将 playbook 的配置语法分成两个部分来看，第一部分是基本的核心元素，使用这些元素我们就完全可以定义 ansible 的任务，包括 host: 任务要操作的主机，用法与 ansible &lt;host-pattern&gt; 选项相同 remote_user: 登陆的被管控主机的用户 tasks: 任务列表 handlers: 触发器， 第二部分是为了提高任务编排效率而额外提供的扩展语法包括 var: 变量 templates: 模板，模板可以利用 ansible 中的变量，为主机定义配置文件 when: 条件判断，比如可以依据操作系统类型决定安装什么，怎么安装模块，启动服务等 with_item: 循环，比如可以批量安装多个程序包，而不用定义多个任务 roles: 角色，抽象和独立 ansible 任务，使其可以自包含，便于移植。 1.2 核心元素host &amp; remote_userhost &amp; remote_user 定义要操作的主机以及以哪个用户身份去完成要执行的步骤。host 是一个或多个组或主机的 patterns与 ansible 的 &lt;host-pattern&gt; 选项使用完全一致，详细内容已经在上一节阐述在此不再累述。 12345678910---- hosts: webservers remote_user: yourname sudo: yes sudo_user: postgres tasks: - service: name=nginx state=started remote_user: root sudo: yes sudo_user: root tasktask 用于定义任务列表，任务的执行是从上而下顺序执行的，且只有在所有匹配到的 host 均执行完当前的任务之后，才会继续执行下一个任务。如果某一 host 在执行任务中失败，它将会从 host 中移除，不会继续执行接下来的任务。 每个 task 的目标在于执行一个 moudle, 通常是带有特定的参数来执行.在参数中可以使用变量（variables）。 123456789101112131415# 任务用于执行特定的模块，且必需具有 nametasks: - name: make sure apache is running service: name=httpd state=running# shell|command 执行命令的成功返回状态码非 0 时tasks: - name: run this command and ignore the result shell: /usr/bin/somecommand || /bin/true tag: run# 使用命令tasks: - name: create a virtual host file for &#123;&#123; vhost &#125;&#125; template: src=somefile.j2 dest=/etc/httpd/conf.d/&#123;&#123; vhost &#125;&#125; 需要注意的是还可以为每个任务定义标签，在执行 ansible-playbook 时通过 -t TAGS, --tags=TAGS 选项，只运行指定标签对应的任务。 handlersHandlers 也是一些 task 的列表,通过名字来引用,它们和一般的 task 并没有什么区别.Handlers 是由通知者进行 notify, 如果没有被 notify,handlers 不会执行.不管有多少个通知者进行了 notify,等到 play 中的所有 task 执行完成之后,handlers 也只会被执行一次. Handlers 最佳的应用场景是用来重启服务,或者触发系统重启操作.除此以外很少用到了. 1234567891011tasks - name: template configuration file template: src=template.j2 dest=/etc/foo.conf notify: # 按名称触发 handlers - restart memcached - restart apachehandlers: - name: restart memcached service: name=memcached state=restarted - name: restart apache service: name=apache state=restarted 2. 变量与模板为了为不同的目标主机自定义配置文件，ansible 引入了 python jinja2 的模板。通过将配置文件中与目标主机相关的配置参数(比如网卡，绑定的 ip 地址)定义成模板中变量，来达到为每个主机自定义配置文件的目的。 2.1 模板ansible 中使用的模板是 python 的 jinja2，因此在创建模板之前，有必要学习一下如何定义 jinja2 模板，而将模板填充为文件，需要使用 ansible template 模块 123task - name: nginx confiure - template: src=/var/template/nginx.j2 dest=/etc/nginx/nginx.conf 2.1 变量的定义ansible 中变量的定义有如下几种方式: Facts中生成的变量: facts 生成的是远程目标主机的所有系统信息，可通过 ansible -m setup 查看 命令行中传递变量： ansible-playbook --extra-vars &quot;name=value name=value&quot; 或 --extra-vars &quot;@some_file.json&quot; 通过 inventory 主机清单传递变量，这种方式我们在 32.5 ansible简介 详细讲解过配置方法 通过 var 在 playbook 中自定义变量，这种定义方式还可以将变量独立到特定的文件中 通过 role 定义的变量，这种定义变量的方式我们会在下一节详细介绍 12345- hosts: webservers vars: - http_port: 80 vars_files: - /vars/external_vars.yml 2.2 变量的作用顺序在 ansible 中最好不要重复定义变量，保持 ansible 配置文件的简洁有助于我们维护和排错，如果相同的变量出现在不同的，其作用顺序由高到低如下所示 123456* extra vars (在命令行中使用 -e)优先级最高* 然后是在inventory中定义的 inventory 参数(比如ansible_ssh_user)* 接着是大多数的其它变量(命令行转换,play中的变量,included的变量,role中的变量等)* 然后是在inventory定义的其它变量* 然后是由系统发现的facts* 然后是 &quot;role默认变量&quot;, 这个是最默认的值,很容易丧失优先权 3. 逻辑控制3.1 判断whenansible 中的条件判断使用 when 语句，而 when 语句的值是 Jinja2 表达式 1234tasks: - name: &quot;shutdown Debian flavored systems&quot; command: /sbin/shutdown -t now when: ansible_os_family == &quot;Debian&quot; 一系列的Jinja2 “过滤器” 也可以在when语句中使用, 但有些是Ansible中独有的. 比如我们想忽略某一错误,通过执行成功与否来做决定,我们可以像这样: 12345678910tasks: - command: /bin/false register: result ignore_errors: True - command: /bin/something when: result|failed - command: /bin/something_else when: result|success - command: /bin/still/something_else when: result|skipped 在playbooks 和 inventory中定义的变量在 when 语句中都可以使用. 下面一个例子,就是基于布尔值来决定一个任务是否被执行: 12345vars: - epic: truetasks: - shell: echo &quot;This certainly is epic!&quot; when: epic 下面是 when 语句的几个常用示例 12345678910111213# 依据变量是否定义进行判断tasks: - shell: echo &quot;I&apos;ve got &apos;&#123;&#123; foo &#125;&#125;&apos; and am not afraid to use it!&quot; when: foo is defined - fail: msg=&quot;Bailing out. this play requires &apos;bar&apos;&quot; when: bar is not defined # 与 with_items 一起使用tasks: - command: echo &#123;&#123; item &#125;&#125; with_items: [ 0, 2, 4, 6, 8, 10 ] when: item &gt; 5 3，2 循环with_itemansible 中标准循环使用 with_item 语句实现，典型的使用方式如下 1234567891011- name: add several users user: name=&#123;&#123; item.name &#125;&#125; state=present groups=&#123;&#123; item.groups &#125;&#125; with_items: - &#123; name: &apos;testuser1&apos;, groups: &apos;wheel&apos; &#125; - &#123; name: &apos;testuser2&apos;, groups: &apos;root&apos; &#125;- name: add several users user: name=&#123;&#123; item &#125;&#125; state=present groups=wheel with_items: - testuser1 - testuser2 除此之外， ansible 还提供了多种循环方式，迭代包括哈希表，文件列表等诸多内容。 前套循环12345- name: give users access to multiple databases mysql_user: name=&#123;&#123; item[0] &#125;&#125; priv=&#123;&#123; item[1] &#125;&#125;.*:ALL append_privs=yes password=foo with_nested: - [ &apos;alice&apos;, &apos;bob&apos; ] - [ &apos;clientdb&apos;, &apos;employeedb&apos;, &apos;providerdb&apos; ] 对文件列表使用循环123456789101112---- hosts: all tasks: # first ensure our target directory exists - file: dest=/etc/fooapp state=directory # copy each file over that matches the given pattern - copy: src=&#123;&#123; item &#125;&#125; dest=/etc/fooapp/ owner=root mode=600 with_fileglob: - /playbooks/files/fooapp/*]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.6 ansible 常用模块]]></title>
    <url>%2F2018%2F11%2F06%2Flinux_mt%2F32-ansible%2Fansible_module%2F</url>
    <content type="text"><![CDATA[ansible 常用模块 上一节我们对 ansible 做了一个概括性的介绍，本节我们来看看 ansible 主程序与常见模块的使用，模块是我们定义服务配置的关键。 1. ansible 核心程序ansible 的核心程序有三个 ansible: ad-hoc 执行命令 ansible-doc: ansible 插件(模块)文档查看工具 ansible-playbook: playbook 执行命令 1，1 ansibleansible &lt;host-pattern&gt; [-m module_name] [-a args] options 作用: ansible 命令行工具 模块: [-m module_name]: 指定使用的模块 [-a args]: 传递给模块的参数 选项: ansible 命令行工具的选项可分为三类 通用选项 连接选项 权限选项 通用选项: -C, --check: 不实际执行，只显示程序执行可能的结果 -D, --diff: 当执行的命令改变了文件或模板的内容时，显示更改前后的内容比较，最好和 -C, --check 一起使用 -e EXTRA_VARS, --extra-vars=EXTRA_VARS: 向 ansible 传递的额外参数，参数值必需是行如key=value的键值对 -f FORKS, --forks=FORKS: 并发操作的最大机器数 -i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY: 定义 inventory 文件位置 --list-hosts: 只显示被操作的主机 --syntax-check:只对 playbook 执行语法检查, 不执行 -t TREE, --tree=TREE: 日志的输出目录 --version: 显示 ansible 的版本信息 连接选项: --private-key=PRIVATE_KEY_FILE: 指定连接的密钥文件 --key-file=PRIVATE_KEY_FILE:指定连接的密钥文件 -u,--user=REMOTE_USER: 连接到被管控主机的帐户，默认为 None -c, --connection=CONNECTION: 连接的类型，默认为 smart -T, --timeout=TIMEOUT: 连接超时时长 权限选项: -b, --become: --become-user=BECOME_USER: 提权限操作切换到的用户，默认为 root --become-method=BECOME_METHOD: 进行权限升级时使用的操作，默认为 sudo，可选值包括sudo | su --ask-become-pass: 使用 sudo 或 su 时，使用的密码 host-patternansible 支持多种主机匹配方式，以便我们能灵活的控制要操作的主机范围。常见的方式有如下几种 12345678910111213141516171819202122232425262728293031# 1. 全部主机all*# 2. IP地址或系列主机名one.example.comone.example.com:two.example.com192.168.1.50192.168.1.*# 3. 一个或多个groupswebservers # 单个组webservers:dbservers # 多个组的并集webservers:&amp;staging # 多个组的交集webservers:!phoenix # ! 表示排除关系，隶属 webservers 组但同时不在 phoenix组# 4. host names, IPs , groups都支持通配符*.example.com*.com# 5. 通配和groups的混合使用one*.com:dbservers# 6. 应用正则表达式，只需要以 ‘~’ 开头~(web|db).*\.example\.com# 7. 通过 --limit 标记来添加排除条件ansible-playbook site.yml --limit datacenter2# 8. 从文件读取hosts,文件名以@为前缀即可ansible-playbook site.yml --limit @retry_hosts.txt 1.2 ansible-docansible-doc options 作用: ansible 文档查看工具 选项: -l, --list: 显示所有可用插件及模块 -s, --snippet=module: 显示指定插件的的帮助信息 -t, --type=TYPE: 指定被选择的插件类型，默认为 module 1234567891011~$ ansible-doc -s shell- name: Execute commands in nodes. shell: chdir: # cd into this directory before running the command creates: # a filename, when it already exists, this step will *not* be run. executable: # change the shell used to execute the command. Should be an absolute path to the executable. free_form: # (required) The shell module takes a free form command to run, as a string. There&apos;s not an actual option named &quot;free form&quot;. See the examples! removes: # a filename, when it does not exist, this step will *not* be run. stdin: # Set the stdin of the command directly to the specified value. warn: # if command warnings are on in ansible.cfg, do not warn about this particular line if set to no/false. ansible-doc 显示的参数都是可以在 ansible 命令中 通过 -a 选项中传递给模块的参数 1ansible -m shell -a &quot;echo &apos;test&apos; chdir=/root&quot; ansible-playbookansible-playbook [options] playbook.yml [playbook2 ...] 作用: playbook 的执行命令 参数: playbook.yml... 表示 playbook 的路经 选项: ansible-playbook 与 ansible 命令行工具的选项基本类似 --playbook-dir=BASEDIR: playbook 的根目录，这个根目录的设置会影响 roles/ group_vars/ 等目录的查找路经 -t TAGS, --tags=TAGS: 运行指定标签对应的任务 2.ansible 常用模块ansible 命令的执行是为了达到期望的状态，如果被管控主机的当前状态与命令指定的状态不一致，则执行命令，所以ansible 的命令都是通过 state 参数指定要进行的操作。 2.1 基本模块useransible -m user -a &quot;options&quot; 作用: 用户管理 选项: name: 用户名 uid: 指定创建用户的 uid shell: 设置默认shell group: 设置默认组 groups: 设置附加组，默认操作是替换 append: groups 操作为追加而不是替换 home: 家目录 system: yes|no 是否为系统用户 move: 更新用户家目录时，是否将原有家目录的内容移动到新的目录中去 state: 用户操作 present: 创建用户 absent: 删除用户 12$ ansible-doc -s user$ ansible all -m user -a &quot;name=test uid=3000 shell=/bin/tsh groups=testgrp&quot; groupansible -m user -a &quot;options&quot; 作用: 用户组管理 选项: name: 组名 gid: 指定gid system: yes|no 是否为系统用户 state: 目标状态 present|absent copyansible -m copy -a &#39;options&#39; 作用: 文件复制和创建 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no content：用于替代”src”,可以直接设定指定文件的值 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 directory_mode：递归的设定目录的权限，默认为系统默认权限 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes others：所有的file模块里的选项都可以在这里使用 src：要复制到远程主机的文件在本地的地址，可以是绝对路径，也可以是相对路径。如果路径是一个目录，它将递归复制。在这种情况下，如果路径使用”/“来结尾，则只复制目录里的内容，如果没有使用”/“来结尾，则包含目录在内的整个内容全部复制，类似于rsync remote_src: yes|no，指定 scr 参数的源是本机还是远程的被管理主机，no 为本机 owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 12ansible -m copy -a &quot;src=/etc/fstab dest=/tmp/fstab.ansible&quot;ansible -m copy -a &quot;content=&apos;hi ansible\n&apos; dest=/tmp/fstab.ansible mode=600&quot; fileansible -m file -a &quot;options&quot; 作用: 文件属性管理 选项: force：yes|no 是否强制创建软连接 一种是源文件不存在但之后会建立的情况下，强制创建 另一种是目标软链接已存在,需要先取消之前的软链，然后创建新的软链 group：定义文件/目录的属组 mode：定义文件/目录的权限 owner：定义文件/目录的属主 path：必选项，定义文件/目录的路径 recurse：递归的设置文件的属性，只对目录有效 src：要被链接的源文件的路径，只应用于state=link的情况 dest：被链接到的路径，只应用于state=link的情况 state： directory：如果目录不存在，创建目录 file：即使文件不存在，也不会被创建 link：创建软链接 hard：创建硬链接 touch：如果文件不存在，则会创建一个新的文件，如果文件或目录已存在，则更新其最后修改时间 absent：删除目录、文件或者取消链接文件 123ansible test -m file -a &quot;src=/etc/fstab dest=/tmp/fstab state=link&quot;ansible test -m file -a &quot;path=/tmp/fstab state=absent&quot;ansible test -m file -a &quot;path=/tmp/test state=touch&quot; templateansible -m template -a &#39;option&#39; 作用: 基于 python jinja2 模板生成文件并复制到目标主机 选项: backup：在覆盖之前将原文件备份，备份文件包含时间信息。有两个选项：yes|no src：要被链接的源文件的路径，只应用于state=link的情况 dest：必选项。要将源文件复制到的远程主机的绝对路径，如果源文件是一个目录，那么该路径也必须是个目录 force：如果目标主机包含该文件，但内容不同，如果设置为yes，则强制覆盖，如果为no，则只有当目标主机的目标位置不存在该文件时，才复制。默认为yes owner: 设置目标文件的属主 group: 设置目标文件的属组 mode: 设置目标文件的权限 2.2 命令执行commandansible -m command -a &#39;option&#39; 作用: 命令执行，但是无法解析 bash 中的特殊字符，比如 |，只能执行简单命令 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 1ansible -m command -a &quot;ifconfig&quot; shellansible -m shell -a &#39;option&#39; 作用: 命令执行，能正常解析 shell 语法 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 1ansible -m command -a &quot;echo pswd|password --stdin tao&quot; scriptansible -m script -a &#39;option&#39; 作用: 将脚本复制到管控主机并执行 选项: free_form: 非参数名称，指代任何可执行命令 creates: 文件名，2.0 后支持通配符，表示指定的文件存在时不执行命令 removes: 与 creates 相反，表示文件不存在时不执行命令 chdir: 指定命令运行的当前目录 executable: 执行运行命令的 shell 解释器，必需是绝对路经 1ansible -m script -a &quot;mount.sh&quot; pingansible -m ping -a &#39;option&#39; 作用: 测试主机是否是通的 选项：无 12345ansible 10.212.52.252 -m ping10.212.52.252 | success &gt;&gt; &#123; &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot;&#125; 2.3 程序安装yumansible -m yum -a &#39;option&#39; 作用: 文件属性管理 选项： config_file：yum的配置文件 disable_gpg_check：关闭gpg_check disablerepo：不启用某个源 enablerepo：启用某个源 name：要进行操作的软件包的名字，可附带版本信息，也可以传递一个url或者一个本地的rpm包的路径 allow_downgrade: 是否允许降级安装，默认为 no；默认的安装操作相当于 yum -y update，如果 name 指定的版本相对于已安装的版本较低，则不会安装 state：状态（present，absent，latest） 123ansible test -m yum -a &apos;name=httpd state=latest&apos;ansible test -m yum -a &apos;name=&quot;@Development tools&quot; state=present&apos;ansible test -m yum -a &apos;name=http://nginx.org/packages/centos/6/noarch/RPMS/nginx-release-centos-6-0.el6.ngx.noarch.rpm state=present&apos; pipansible -m pip -a &#39;option&#39; 作用: 文件属性管理 选项： chdir: pip 命令运行前切换到此目录 executable: 指定运行 pip的版本，pip 的名称或绝对路经；不能与virtualenv同时使用 extra_args: 传给 pip的额外参数 name: 安装的程序包名称，可以是一个 url version: 指定的Python库的安装版本 virtualenv：virtualenv 虚拟环境目录，不能与 executable 同时使用，如果虚拟环境不存在，将自动创建 virtualenv_command: 虚拟环境使用的管理命令或绝对路经，eg:pyvenv, ~/bin/virtualenv virtualenv_python: 虚拟环境中的 python 版本，当virtualenv_command使用pyvenv或-m venv模块时，不应使用此参数 state: present:默认的，表示为安装 lastest: 安装为最新的版本 absent：表示删除 forcereinstall：“forcereinstall”选项仅适用于可ansible 2.1及更高版本 12# 支持 pipenv 么？ansible -m pip -a &quot;name=ipython virtualenv=/opt/vdd/project virtualenv_command=pipenv&quot; 2.4 服务管理cronansible -m cron -a &#39;option&#39; 作用: 周期性任务管理 选项： backup：对远程主机上的原任务计划内容修改之前做备份 cron_file：如果指定该选项，则用该文件替换远程主机上的cron.d目录下的用户的任务计划 day：日 hour：小时 minute：分钟 month：月 weekday：周 job：要执行的任务，依赖于state=present name：该任务的描述 special_time：指定什么时候执行，参数包括 reboot,yearly,annually,monthly,weekly,daily,hourly state：确认该任务计划是创建还是删除，present or absent user：以哪个用户的身份执行 1234ansible test -m cron -a &apos;name=&quot;a job for reboot&quot; special_time=reboot job=&quot;/some/job.sh&quot;&apos;ansible test -m cron -a &apos;name=&quot;yum autoupdate&quot; weekday=&quot;2&quot; minute=0 hour=12 user=&quot;rootansible 10.212.52.252 -m cron -a &apos;backup=&quot;True&quot; name=&quot;test&quot; minute=&quot;0&quot; hour=&quot;2&quot; job=&quot;ls -alh &gt; /dev/null&quot;&apos;ansilbe test -m cron -a &apos;cron_file=ansible_yum-autoupdate state=absent&apos; serviceansible -m service -a &#39;option&#39; 作用: 管理服务管理 选项： arguments：给命令行提供一些选项 enabled：是否开机启动 yes|no name：必选项，服务名称 pattern：定义一个模式，如果通过status指令来查看服务的状态时，没有响应，就会通过ps指令在进程中根据该模式进行查找，如果匹配到，则认为该服务依然在运行 runlevel：运行级别 sleep：如果执行了restarted，在则stop和start之间沉睡几秒钟 state：对当前服务执行启动，停止、重启、重新加载等操作（started,stopped,restarted,reloaded） 1ansible -m service -a &quot;name=httpd state=started enabled=yes&quot; 2.5 变量获取setupansible -m setup -a &#39;option&#39; 作用: 获取被管控主机的所有系统参数信息 选项： filter: 参数过滤，支持 shell 通配语法 gather_subset: 限制返回的参数范围，可选值包括 all, min, hardware, network, virtual, ohai,值前的 ! 表示取反 gather_timeout: 参数收集的超时时长 123ansible 10.212.52.252 -m setup -a &apos;filter=ansible_*_mb&apos; //查看主机内存信息ansible 10.212.52.252 -m setup -a &apos;filter=ansible_eth[0-2]&apos; //查看地接口为eth0-2的网卡信息ansible all -m setup --tree /tmp/facts //将所有主机的信息输入到/tmp/facts目录下，每台主机的信息输入到主机名文件中]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29 分治算法]]></title>
    <url>%2F2018%2F11%2F05%2Falog%2Fdivide%2F</url>
    <content type="text"><![CDATA[编程思想之分治算法 1. 分治算法分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。 这个定义看起来有点类似递归的定义。关于分治和递归的区别，我们在排序（下）的时候讲过，分治算法是一种处理问题的思想，递归是一种编程技巧。实际上，分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及这样三个操作： 分解：将原问题分解成一系列子问题； 解决：递归地求解各个子问题，若子问题足够小，则直接求解； 合并：将子问题的结果合并成原问题。 1.1 适用情景分治算法能解决的问题，一般需要满足下面这几个条件： 原问题与分解成的小问题具有相同的模式； 原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别，等我们讲到动态规划的时候，会详细对比这两种算法； 具有分解终止条件，也就是说，当问题足够小时，可以直接求解； 可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。 1.2 分治在大数据中的应用我们前面讲的数据结构和算法，大部分都是基于内存存储和单机处理。但是，如果要处理的数据量非常大，没法一次性放到内存中，这个时候，这些数据结构和算法就无法工作了。 要解决这种数据量大到内存装不下的问题，我们就可以利用分治的思想。将海量的数据集合根据某种方法，划分为几个小的数据集合，每个小的数据集合单独加载到内存来解决，然后再将小数据集合合并成大数据集合。实际上，利用这种分治的处理思路，不仅仅能克服内存的限制，还能利用多线程或者多机处理，加快处理的速度。 2.应用归并排序和快速排序是分治算法的典型应用，这两个算法我们在之前的排序章节已经讲过了。所以我们以另一个例子: 如何编程求出一组数据的有序对个数或者逆序对个数，来讲解如何应用分治算法。 2.1 计算数据有序度我们套用分治的思想来求数组 A 的逆序对个数。我们可以将数组分成前后两半 A1 和 A2，分别计算 A1 和 A2 的逆序对个数 K1 和 K2，然后再计算 A1 与 A2 之间的逆序对个数 K3。那数组 A 的逆序对个数就等于 K1+K2+K3。 使用分治算法其中一个要求是，子问题合并的代价不能太大，否则就起不了降低时间复杂度的效果了。那如何快速计算出两个子问题 A1 与 A2 之间的逆序对个数呢？这里就要借助归并排序算法了。 1234567891011121314151617181920212223242526272829303132333435363738def reverse_count(A): """ :param A: :return: 计算数组 A 的逆序度 """ if len(A) &lt;= 1: return 0 mid = len(A) // 2 S1 = A[:mid] c1 = reverse_count(S1) S2 = A[mid:] c2 = reverse_count(S2) c3 = merge(S1, S2, A) return c1 + c2 + c3def merge(S1, S2, S): """ :param S1: :param S2: :param S: :return: 归并排序，并计算两个数组的逆序度 """ c = i = j = 0 while i + j &lt; len(S): if i == len(S1) or (j &lt; len(S2) and S1[i] &gt; S2[j]): S[i + j] = S2[j] j += 1 c += (len(S1) - i) else: S[i + j] = S1[i] i += 1 return cs = [1, 5, 6, 7] + [2, 3, 4]print reverse_count(s)print s 3.练习下面是分治算法的一些典型练习题 3.1 练习一二维平面上有 n 个点，如何快速计算出两个距离最近的点对？1pass 3.2 练习二有两个 n*n 的矩阵 A，B，如何快速求解两个矩阵的乘积 C=A*B？1pass 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.5 ansible简介]]></title>
    <url>%2F2018%2F11%2F05%2Flinux_mt%2F32-ansible%2Fansible%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[ansible简介 在本章的开篇我们说过自动化运维的几个层次 BootStraping: 引导安装操作系统 Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理 Command &amp; Control: 批量运行程序 ansible 正是配置系统，和批量命令执行两个层面的轻量级强大的解决方案。 为了批量的管理主机，我们需要与本管控主机进行通信，目前”通信”存在两种方式。一种是以 saltstack 为代表的 agent 模式，及在被管控主机之上必需部署客户端代理，由其接收指令并在被管控主机之上执行。另一种是以 ansible 为代表的 less agent 模式，通过 ssh 连接直接远程执行命令。本节开始我们就来学习 ansible 的安装配置及使用。 1. ansible 简介1.1 程序框架 上图是 ansible 架构示意图，ansible 是高度模块化，由如下几个部分组成 Ansible： 作用: Ansible的核心程序 Host Inventory： 作用: 记录了每一个由Ansible管理的主机信息，信息包括ssh端口，root帐号密码，ip地址等等 Connection Plugins： 作用: 连接插件，Ansible和Host通信使用 Core Modules： 作用: Ansible执行任何管理任务都不是由Ansible自己完成，而是由核心模块完成；Ansible管理主机之前，先调用core Modules中的模块，然后指明管理Host Inventory中的主机，就可以完成管理主机。 Custom Modules: 作用: 自定义模块，完成Ansible核心模块无法完成的功能，此模块支持任何语言编写。 Playbooks： 作用: YAML格式文件，多个任务定义在一个文件中，使用时可以统一调用，类似于“剧本”用来定义那些主机需要调用那些模块来完成的功能. 模块Ansible 任务的执行则是通过模块实现的，ansible 的模块通常是 Linux 中的命令是或者特定工具是一一对应，要学习 ansible 配置主要内容之一就是学习常见模块的应用。 playbookAnsible提供了两种方式去完成任务,一是 ad-hoc 命令,一是写 Ansible playbook，两者的关系类似于在命令行敲入shell命令和 写shell scripts playbook 中最重要的概念称为role(角色)，角色是一个自包涵的任务集合，不仅包含 playbook，也包含 playbook 内每一个命令所需的文件。role 存在的目的是让 ansible 更加容易移植。 1.2 ansible 安装1234567891011121314151617181920212223242526272829$ sudo yum install ansible$ ansible --version$ rpm -ql ansible |egrep -v &quot;(python|man|doc)&quot;/etc/ansible/etc/ansible/ansible.cfg # ansible 自身的配置文件/etc/ansible/hosts # Host Inventory/etc/ansible/roles # roles 所在目录/usr/bin/ansible # ad-hoc 执行命令/usr/bin/ansible-2/usr/bin/ansible-2.7/usr/bin/ansible-config/usr/bin/ansible-connection /usr/bin/ansible-console/usr/bin/ansible-console-2/usr/bin/ansible-console-2.7/usr/bin/ansible-galaxy/usr/bin/ansible-galaxy-2/usr/bin/ansible-galaxy-2.7/usr/bin/ansible-inventory/usr/bin/ansible-playbook # playbook 执行命令/usr/bin/ansible-playbook-2/usr/bin/ansible-playbook-2.7/usr/bin/ansible-pull/usr/bin/ansible-pull-2/usr/bin/ansible-pull-2.7/usr/bin/ansible-vault/usr/bin/ansible-vault-2/usr/bin/ansible-vault-2.7 1.3 ansible 认证机制使用 ansible 之前最主要的任务是配置 Host Inventory，即定义 ansible 管控的主机。但是在定义 Host Inventory 之前，我们有必要先了解一下 Ansible是如何通过SSH与远程服务器连接。 备注: 参考马哥Linux Ansible 权威教程 Ansible 1.3及之后Ansible 1.3及之后的版本默认会在本地的 OpenSSH可用时会尝试用其进行远程通讯.这会启用ControlPersist(一个性能特性),Kerberos,和在~/.ssh/config中的配置选项如 Jump Host setup。 然而,当你使用Linux企业版6作为主控机(红帽企业版及其衍生版如CentOS),其OpenSSH版本可能过于老旧无法支持ControlPersist. 在这些操作系统中,Ansible将会退回并采用 paramiko (由Python实现的高质量OpenSSH库). 如果你希望能够使用像是Kerberized SSH之类的特性,烦请考虑使用Fedora, OS X, 或 Ubuntu 作为你的主控机直到相关平台上有更新版本的OpenSSH可供使用,或者启用Ansible的“accelerated mode”.参见 Accelerated Mode. Ansible 1.2 及之前在Ansible 1.2 及之前的版本,默认将会使用 paramiko. 本地OpenSSH必须通过-c ssh 或者 在配置文件中设定. 偶尔会遇到不支持SFTP的设备.虽然这很少见,但你会有概率中奖.你可以通过在配置文件(Ansible的配置文件)中切换至 SCP模式来与之链接. 说起远程设备,Ansible会默认假定你使用 SSH Key(我们推荐这种)但是密码也一样可以.通过在需要的地方添加 –ask-pass选项 来启用密码验证.如果使用了sudo 特性,当sudo需要密码时,也同样适当的提供了–ask-sudo-pass选项. 1.4 ansible 初始化配置ansible 初始化配置很容易分为两步: 配置主控机与被管控主机基于 SSH 密钥通信 在 Host Inventory 定义被管控的主机 下面是一个配置示例123456789101112# SSH Key 免密码登陆ssh-kengen -t rsa -P &quot;&quot;ssh-copy-id ~/.ssh/id_rsa.pub root@172.168.0.3# 配置 Host Inventoryvim /etc/ansible/hosts[webservers]172.16.0.3# 测试ansible webservers --list-hostsansible webservers -m ping 2. 配置 Host InventoryHost Inventory 用于定义 ansible 管理的主机及主机组。默认的文件路径为 /etc/ansible/hosts 除默认文件外,你还可以同时使用多个 inventory 文件,也可以从动态源,或云上拉取 inventory 配置信息。下面是 Host Inventory 配置示例 12345mail.example.com[webservers]foo.example.combar.example.com Host Inventory 是 ini 风格的配置文件，使用 [组名] 定义组。组用于对系统进行分类，便于对不同系统进行统一管理。一个主机可以属于不同组。 2.1 主机定义12345678910mail.example.com # 1. 标准形式172.16.0.1badwolf.example.com:5309 # 2. 自定义端口www[01:50].example.com # 3. 扩展形式db-[a:f].example.comjumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 # 4. 通过参数定义[targets]localhost ansible_connection=localother1.example.com ansible_connection=ssh ansible_ssh_user=mpdehaan Host Inventory 内主机有多种定义方式，我的理解核心就是 IP/FQDN [Lnventory 参数] IP/FQDN: 指明管控的主机，可以 ip 地址也可以是域名 Inventory 参数: 控制 ansible 与远程主机的交互方式 在 jumper ansible_ssh_port=5555 ansible_ssh_host=192.168.1.50 的示例中 jumper 是主机的别名，通过参数 ansible_ssh_host 设置主机的 IP 地址。 Inventory 参数Inventory 有如下常用参数 12345678910111213141516171819202122232425262728293031323334ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置.ansible_ssh_user 默认的 ssh 用户名ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本)ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用 paramiko. 1.2 以后默认使用 &apos;smart&apos;,&apos;smart&apos; 方式会根据是否支持 ControlPersist, 来判断&apos;ssh&apos; 方式是否可行.ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 &apos;sh&apos; 语法,可设置为 &apos;csh&apos; 或 &apos;fish&apos;.ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是&quot;/usr/bin/python&quot;, 比如 \*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 &quot;/usr/bin/env&quot; 机制, 因为这要求远程用户的路径设置正确,且要求 &quot;python&quot; 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径.... 2.1 变量定义除了定义主机和组，Inventory 内还能主机和组定义特定的变量。这些变量定义后可在 playbooks 中使用。但是不建议在Inventory 中定义变量。变量定义的其他方式我们会在 playbook 中在详细介绍。 主机变量123[atlanta]host1 http_port=80 maxRequestsPerChild=808host2 http_port=303 maxRequestsPerChild=909 组变量1234567[atlanta]host1host2[atlanta:vars]ntp_server=ntp.atlanta.example.comproxy=proxy.atlanta.example.com 分文件定义 Host 和 Group 变量在 inventory 主文件中保存所有的变量并不是最佳的方式.还可以保存在独立的文件中,这些独立文件与 inventory 文件保持关联. 不同于 inventory 文件(INI 格式),这些独立文件的格式为 YAML。 1234567# 假设 inventory 文件的路径为:/etc/ansible/hosts# 分文件为 groups 和 host 定义的变量文件/etc/ansible/group_vars/raleigh # raleigh 组变量/etc/ansible/group_vars/webservers # webservers 组变量/etc/ansible/host_vars/foosball # foosball 主机变量 还有更进一步的运用,你可以为一个主机,或一个组,创建一个目录,目录名就是主机名或组名.目录中的可以创建多个文件, 文件中的变量都会被读取为主机或组的变量。注意,分文件定义变量的方式只适用于 Ansible 1.4 及以上版本.12/etc/ansible/group_vars/raleigh/db_settings/etc/ansible/group_vars/raleigh/cluster_settings Ansible 1.2 及以上的版本中,group_vars/ 和 host_vars/ 目录可放在 inventory 目录下,或是 playbook 目录下. 如果两个目录下都存在,那么 playbook 目录下的配置会覆盖 inventory 目录的配置。把你的 inventory 文件 和 变量 放入 git repo 中,以便跟踪他们的更新,这是一种非常推荐的方式.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28 贪心算法]]></title>
    <url>%2F2018%2F11%2F04%2Falog%2Fgreedy%2F</url>
    <content type="text"><![CDATA[编程思想之贪心算法 1. 贪心算法前面我们讲完了字符串匹配相关的算法，接下来的几章与编程思想有关，包括贪心，分治，回溯和动态规划。它们都非常抽象，但是理解透了可以帮我们解决很多问题。这些算法在一定程度上很相近，因此学习过程中，我们首先要搞清楚它们的适用场景，其次是掌握怎么运用它们去解决问题。今天，我们先来学习贪心算法。 1.1 适用场景贪心，回溯，动态规划都适合解决“分阶段决策问题”。而贪心算法不适合前面的选择，会影响后面的选择这类情景。贪心算法的求解过程中，只会保留每个阶段的最优解，不会保留其他非最优状态。对于后面的选择依赖前面选择的分阶段决策问题，如果考虑前面的选择，计算将无法回溯，不可行；如果只考虑每个阶段的最优，最后很可能无法得出最优解。 1.2 解决步骤利用贪心算法，我们可以按照如下步骤去解决问题: 第一步，当我们看到这类问题的时候，首先要联想到贪心算法，贪心算法格外适用于针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。 第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。 第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。 2. 应用贪心算法有很多经典应用包括钱币找零，区间覆盖，霍夫曼编码等等。我们就以其中几个例子来实战贪心算法的应用。 2.1 钱币找零假设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元面额的纸币， 张数分别是: c1、c2、c5、c10、c20、c50、c100。我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？ 思路: 在贡献相同期望值（纸币数目）的情况下，我们希望多贡献点金额，这样就可以让纸币数更少，这就是一种贪心算法的解决思路。 123456789101112def cion(k): coin = [100, 50, 20, 10, 5, 2, 1] coin_map = [(i, 20) for i in coin] i = 0 coin_count = 0 while i &lt; len(coin) and k &gt; 0: use = coin_map[i] c = min(use[1], k // use[0]) k -= use[0] * c coin_count += c i += 1 return coin_count 2.2 区间覆盖假设我们有 n 个区间，区间的起始端点和结束端点分别是 [l1, r1]，[l2, r2]，[l3, r3]，……，[ln, rn]。我们从这 n 个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间呢？lintcode-1242. 无重叠区间就是这个问题的变形。 思路：我们假设这 n 个区间中最左端点是 lmin，最右端点是 rmax。这个问题就相当于，我们选择几个不相交的区间，从左到右将 [lmin, rmax] 覆盖上。我们按照起始端点从小到大的顺序对这 n 个区间排序。我们每次选择的时候，左端点跟前面的已经覆盖的区间不重合的，右端点又尽量小的，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间。这实际上就是一种贪心的选择方法。 123456789101112131415161718192021class Solution(object): def eraseOverlapIntervals(self, intervals): """ :type intervals: List[List[int]] :rtype: int """ if not intervals: return 0 intervals.sort(key=lambda x: x[0]) collect = [intervals[0]] rm = 0 for i in intervals[1:]: low, up = collect[-1] if i[0] &gt;= up: collect.append(i) elif i[1] &lt;= up: collect[-1] = i rm += 1 else: rm += 1 return rm 2.3 霍夫曼编码霍夫曼编码不仅会考察文本中有多少个不同字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。如何给不同频率的字符选择不同长度的编码呢？根据贪心的思想，我们可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。为了避免解压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。 12 3. 练习leetcode 上有很多贪心算法的练习题，下面是一些练习题以及它们的解答 3.1 练习一在一个非负整数 a 中，我们希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？ 123456789101112131415161718class Solution: def removeKdigits(self, num, k): numStack = [] # Construct a monotone increasing sequence of digits for digit in num: while k and numStack and numStack[-1] &gt; digit: numStack.pop() k -= 1 numStack.append(digit) # - Trunk the remaining K digits at the end # - in the case k==0: return the entire list finalStack = numStack[:-k] if k else numStack # trip the leading zeros return "".join(finalStack).lstrip('0') or "0" 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.4 运维自动化入门]]></title>
    <url>%2F2018%2F11%2F04%2Flinux_mt%2F32-ansible%2F%E8%BF%90%E7%BB%B4%E8%87%AA%E5%8A%A8%E5%8C%96%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[运维自动化入门 1. 运维工作]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27 AC 自动机]]></title>
    <url>%2F2018%2F11%2F03%2Falog%2Fac%2F</url>
    <content type="text"><![CDATA[敏感词过滤]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.3 pxe与cobbler]]></title>
    <url>%2F2018%2F11%2F03%2Flinux_mt%2F32-ansible%2Fpxe%E4%B8%8Ecobbler%2F</url>
    <content type="text"><![CDATA[pxe与cobbler cobbler 就是 pex 环境的二次封装，为用户提供了一个管理工具，能将多个 pxe 环境整合在一起，让用户自行选择安装的系统。 1， cobbler 安装1.1 rpm 包组成123456789101112131415161718192021222324yum install cobbler$ rpm -ql cobbler|egrep -v &quot;(man|python|doc)&quot;/etc/cobbler # 配置文件/etc/cobbler/settings # 自身运行的配置文件/etc/cobbler/auth.conf/etc/cobbler/cheetah_macros/etc/cobbler/cobbler_bash/etc/cobbler/completions/etc/cobbler/dhcp.template/etc/cobbler/dnsmasq.template/etc/cobbler/import_rsync_whitelist/etc/cobbler/iso/etc/cobbler/iso/buildiso.template/etc/cobbler/ldap/etc/cobbler/ldap/ldap_authconfig.template/etc/cobbler/modules.conf/etc/cobbler/mongodb.conf/etc/cobbler/named.template/etc/cobbler/power # 服务的配置模板/etc/cobbler/power/fence_apc_snmp.template......../etc/cobbler/pxe/etc/cobbler/pxe/bootcfg_esxi5.template........ 2. cobbler 环境配置2.1 cobbler 启动cobbler 配置文件提供了对多种环境的配置，默认配置通常就可以直接使用。我们可以根据 cobbler 启动时的报错信息对必要的参数作出调整即可。 1234567891011121314systemctl restart httpdsystemctl start cobblerd.servicecobbler check #1 : The &apos;server&apos; field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the &apos;next_server&apos; field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.3 : SELinux is enabled. Please review the following wiki page for details on ensuring cobbler works correctly in your SELinux environment: https://github.com/cobbler/cobbler/wiki/Selinux4 : change &apos;disable&apos; to &apos;no&apos; in /etc/xinetd.d/tftp5 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run &apos;cobbler get-loaders&apos; to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The &apos;cobbler get-loaders&apos; command is the easiest way to resolve these requirements.6 : enable and start rsyncd.service with systemctl7 : debmirror package is not installed, it will be required to manage debian deployments and repositories8 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to &apos;cobbler&apos; and should be changed, try: &quot;openssl passwd -1 -salt &apos;random-phrase-here&apos; &apos;your-password-here&apos;&quot; to generate new one9 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use them cobbler 启动之后使用 check 对 cobbler 环境进行检查，会显示当前 cobbler 环境存在的问题，我们只要相应的修改配置文件解决这些问题，我们的 cobbler 环境也就准备好了。现在我们来解决这些问题 2.2 环境配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 1. server 绑定地址，改为外网地址，以便其他主机能访问到vim /etc/cobbler/settingsserver: 172.16.0.2# 2. next server 指向改为 tftp server 地址vim /etc/cobbler/settingsnext_server: 172.16.0.2# 3. SELinux 设置为 Permissive，无影响# 4. 编辑 /etc/xinetd.d/tftp 启动 tftp 服务vim /etc/xinetd.d/tftpservice tftp&#123; socket_type = dgram protocol = udp wait = yes user = root server = /usr/sbin/in.tftpd server_args = -s /var/lib/tftpboot disable = no # disable 改为 no per_source = 11 cps = 100 2 flags = IPv4&#125;# 5. 某些 bootloader 不在 /var/lib/cobbler/loaders 文件夹内yum install syslinuxcp /usr/share/syslinux/&#123;menu.c32, pxelinux.0&#125; /var/lib/cobbler/loaders# 6. 启用 rsync 服务systemctl start rsyncd.servicesystemctl enable rsyncd.service# 7. 安装 debmirror 包yum install debmirror# 8. 修改 default_password_crypted 为超级用户设置的密码# openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'openssl passwd -1 -salt dgea 1234$1$dgea$nPoeNaw5o4mv6kkXjhzVI1vim /etc/cobbler/settingsdefault_password_crypted: $1$dgea$nPoeNaw5o4mv6kkXjhzVI1# 9. 安装 fence-agents，这个是高可用集群所使用的组件，此处可以先忽略 2.3 配置 pxe 所依赖的服务cobbler 虽然依赖于 pxe 环境，但是对 pxe 支持自动配置，只需要提供 pex 对应服务的配置文件，cobbler 能实现自动安装，配置和启动。相比于使用 cobber 自动安装，可能我们手动配置其他服务器可能更熟悉快捷。所以接下来我们也是以手动配置为主。 手动管理 pxe 所需服务，还是由 cobbler 自己管理需要在配置文件中进行配置。如果是由 cobbler 自动配置，还需要在 /etc/cobbler/modules.conf 配置文件内为各服务提供配置参数。 12345678910111213vim /etc/cobbler/settingsmanage_dhcp: 0 # 0 表示手动配置，1 表示 cobbler 自动配置manage_dns: 0manage_tftpd: 1manage_rsync: 0# 为各服务配置服务参数$ cat /etc/cobbler/modules.conf |grep &quot;^\[&quot;[authentication][authorization][dns][dhcp][tftpd] 3. 配置 cobbler 服务3.1 cobbler 服务组成如下图，cobbler 服务由如下几个部分组成，我们的目的就是配置好这几个组成部分。 Disribution : distro, 表示一个发行版，包括内核，initrd Repository: repo 创建仓库，比如yum仓库等，可以直接创建，也可以导入光盘的 yum 仓库 system： system 通过mac地址来定制化系统 profile： profile 对需要安装某个系统的所有配置，包括 kickstart 配置文件 3.2 cobbler 命令使用123456# cobblerusage=====cobbler &lt;distro|profile|system|repo|image|mgmtclass|package|file&gt; ... [add|edit|copy|getks*|list|remove|rename|report] [options|--help]cobbler &lt;aclsetup|buildiso|import|list|replicate|report|reposync|sync|validateks|version|signature|get-loaders|hardlink&gt; [options|--help] 子命令首先 cobbler 有众多字命令，每一个子命令用于配置 cobbler 服务的一部份 distro: 用于配置 Disribution，核心是定义 kernel 和 initrd profile: 配置 profile repo: 配置 Repository yum 源 system: 配置 system 定制系统 操作其次每个组件都有相关的管理操作: add edit copy getks* list remove rename report 12cobbler distro listcobbler distro add --help 辅助命令最后剩下的部分是 cobbler 的辅助命令，可以基于当前已有的光盘和 yum 仓库快速配置相应组件，也包括其他一些辅助功能 buildiso import: 通过导入光盘自动生成一个 distro sync: cobbler 同步，每次执行新的操作之后最好都同步一次 3.2 distro 管理cobbler import [options] 作用: 通过导入光盘自动生成一个 distro 过程: 会在 /var/www/cobbler/ks_mirror 下自动创建一个--name参数的文件夹，将光盘内的所有内容复制到该目录下 import 会自动为导入的 distro 生成一个 profile Options: -h, --help: 帮助 --arch=ARCH: 被导入操作系统的平台架构 --breed=BREED: the breed being imported --os-version=OS_VERSION: the version being imported --path=PATH: 光盘镜像挂载点 --name=NAME: distro 名称 --available-as=AVAILABLE_AS: tree is here, don’t mirror --kickstart=KICKSTART_FILE: assign this kickstart file --rsync-flags=RSYNC_FLAGS: pass additional flags to rsync 12345678cobbler import --name=Centos-7.1-x86_64 --path=/cdromls /var/www/cobbler/ks_mirrorCentos-7.1-x86_64cobbler distro listcobbler profile listcobbler sync 3.3 profile 管理12345678910111213# cobbler profile --helpusage=====cobbler profile addcobbler profile copycobbler profile dumpvarscobbler profile editcobbler profile findcobbler profile getkscobbler profile listcobbler profile removecobbler profile renamecobbler profile report addcobbler profile add options 作用: 添加 profile options: --name --distro --kickstart 1234cobbler profile add --name=Centos-7.1-x86_64_service --distro=Centos-7.1-x86_64 --kickstart=/var/lib/cobbler/kickstarts/ks.cfgcobbler sync # 将新增的 profile 添加到 /var/lib/tfpt/pexlinux.cfg/default 的开机菜单中 editcobbler profile edit options renamecobbler profile rename options --name --newname 4. cobbler webcobbler web 提供了以web 界面供我们配置 cobbler 服务使用。在使用 cobbler web 之前我们需要进行认证配置。其认证分为如下几种形式 4.1 cobbler web 认证auth_pam 认证此配置是基于系统帐户完成认证 123456789101112131415vim /etc/cobbler/modules.conf[authentication]module = authn_pam# 添加帐户useradd cblradminecho cblpass |passwd --stdin cblradmin# 将用户添加至 cobbler user 组中vim /etc/cobbler/users[admins]admin = cblradmin# 重启服务systemctl restart cobblerd authn_configfile此认证是基于帐号密码文件完成认证 123456789vim /etc/cobbler/modules.conf[authentication]module = authn_configfile# 创建认证文件htdigest -c /etc/cobbler/users.digest Cobbler cblradmin# 重启服务systemctl restart cobblerd htdigest [-c] passwordfile realm username 4.2 cobbler web 配置1234567891011121314# 1. 安装yum install cobbler-web# 2. 配置 authn_configfile 认证htdigest -c /etc/cobbler/users.digest Cobbler cblradminAdding password for cblradmin in realm Cobbler.New password:Re-type new password:# 3. 重启 httpdsystemctl restart httpd# 4. 访问http://ip/colbbler_web]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26 Trie 树]]></title>
    <url>%2F2018%2F11%2F02%2Falog%2Ftrie%2F</url>
    <content type="text"><![CDATA[一组字符串的快速匹配]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.2 PXE 系统自动化部署]]></title>
    <url>%2F2018%2F11%2F02%2Flinux_mt%2F32-ansible%2FPXE%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[PXE 系统自动化部署 PXE 全称是 preboot execute environment 由 Intel 公司开发，用于为完成基于网络的引导安装。 1. PXE 工作过程 pxe 要求客户端主机的网卡必需支持网络引导机制，并将网络设置为第一引导设备。整个过程如上图所示: 未安装操作系统的主机启动时，网卡首先发送一个 rarp 协议报文，从局域网中的 dhcp 服务获取一个 IP 地址，并同时获取引导文件，和引导文件所在的文件服务器(dhcp 的 filename,next-server 参数指定) 主机加载引导文件后，会依据引导文件继续向文件服务器获取内核和 initrd 文件，启动Linux 内核，并依据之前获取的 IP 地址，配置好网络属性 内核加载完成之后，会依据开机启动配置文件中指定的 yum 仓库获取操作系统安装程序 anaconda，并启动安装过程 此后的安装过程就与我们通过硬盘安装操作系统的过程类似，Centos 系可借助 kickstart 文件完成自动安装，这部分请参阅 15.2 Centos安装过程 因此整个 PXE 依赖于以下服务: dhcp: 提供 IP 地址，引导文件和文件服务器的指向(执行 tftp server) tftp: 文件服务器，用于提供引导文件，操作系统内核，initrd yum repository: 一个 yum 仓库，为系统安装提供源，可通过 http,https, ftp,nfs 任意服务提供 2. tftp servertftp 监听在 udp 的 69 号端口上 1234567891011121314151617# 安装yum install tftp-server tftprpm -ql tftp-server|egrep -v "(man|doc)"/etc/xinetd.d/tftp/usr/lib/systemd/system/tftp.service/usr/lib/systemd/system/tftp.socket/usr/sbin/in.tftpd/var/lib/tftpboot # tftp 默认文件目录# centos 7 启动systemctl start tftp.socket# centos 6 启动chkconfig tftp onservice xinetd restart 3. CentOS 7 PXE1234567891011121314151617181920212223242526272829303132# 1. 配置 DHCP 服务，配置见上节# 2. 配置 tftp 服务yum install -y dhcpyum -y install syslinux tftp-server# 2.1 复制内核，开机启动的所需的配置文件mount /dev/cdrom /cdromcp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/cp /cdrom/images/pxelinux/&#123;vmlinuz,initrd.img&#125; /var/lib/tftp/boot/cp /usr/share/syslinux/&#123;chain.c32,mboot.c32,menu.c32,memdisk&#125; /var/lib/tftpboot/# 2.2 配置开机启动菜单mkdir /var/lib/tftpboot/pxelinux.cfg/vim /var/lib/tftpboot/pxelinux.cfg/defaultdefault menu.c32 prompt 5 timeout 30 MENU TITLE CentOS 7 PXE Menu LABEL linux MENU LABEL Install CentOS 7 x86_64 KERNEL vmlinuz APPEND initrd=initrd.img inst.repo=http://172.16.0.2/centos ks=http://172.16.0.2/ks.cfg # 3. 准备 yum 仓库yum install httpdmount -B /cdrom /var/www/html/centos# 4. 准备 kickstart 文件vim /var/www/html/ks.cfg# ks 文件内需要通过 url --url="http://172.16.0.2/centos" 指明 yum 源 4. CentOS 6 PXE12345678910111213141516# 2.1 复制内核，开机启动的所需的配置文件yum -y install syslinux tftp-servercp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/cp /media/cdrom/images/pxelinux/&#123;vmlinuz,initrd.img&#125; /var/lib/tftp/boot/cp /media/cdrom/isolinux/&#123;boot.msg,vesamenu.c32,splash.png&#125; /var/lib/tftp/boot/# 2.2 配置开机启动菜单mkdir /var/lib/tftpboot/pxelinux.cfg/cp /media/cdrom/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/defaultvim /var/lib/tftpboot/pxelinux.cfg/default # 添加label autoinst menu label ^Auto menu default kernel vmlinuz append initrd=initrd.img ks=http://172.16.0.2/ks.cfg]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25 字符串匹配之 BM 算法]]></title>
    <url>%2F2018%2F11%2F01%2Falog%2Fstr_match2%2F</url>
    <content type="text"><![CDATA[最优匹配的 BM 算法 1. BM 算法本节我们继续介绍另一个高效的字符串匹配算法 BM(Boyer-Moore)。BM 与 KMP 优化思路类似，都是希望尽可能增加发生不匹配时，模式串后移的位数来提高字符串的匹配效率。BM 要想达到更高的匹配效率，必需利用更多的已知信息。 这里依旧推荐阮一峰老师有关 BM算法的博客。因为阮一峰老师讲的已经不能在通俗易懂，这里我就简单总结一下 BM 算法所使用的匹配规则。示例采用博客中的示例，即在”HERE IS A SIMPLE EXAMPLE”，中搜索 “EXAMPLE”。 1.1 坏字符规则 开始匹配时，主串与模式串头部对齐，从尾部开始比较。此时”S”与”E”不匹配。我们称”S”为”坏字符”（bad character），即不匹配的字符。 利用坏字符以及坏字符是否出现在模式串中，BR 算法使用的第一个移位规则被称为坏字符规则: 后移位数 = 坏字符的位置 - 搜索词中的上一次出现位置。如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。道理很显而易见，如果出现坏字符，我们就直接把模式串移动到能跟坏字符匹配的位置上来。 示例中”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位 1.2 好后缀规则借鉴 KMP 算法，利用已经匹配的字符串和已匹配部分是否出现在模式串中，BR 算法使用的第二个移位规则被称为 好后缀规则:后移位数 = 好后缀的位置 - 搜索词中的上一次出现位置 “好后缀”的位置以最后一个字符为准。假定”ABCDEF”的”EF”是好后缀，则它的位置以”F”为准，即5（从0开始计算）。 如果”好后缀”在搜索词中只出现一次，则它的上一次出现位置为 -1。比如，”EF”在”ABCDEF”之中只出现一次，则它的上一次出现位置为-1（即未出现）。 如果”好后缀”有多个，则除了最长的那个”好后缀”，其他”好后缀”的上一次出现位置必须在头部。比如，假定”BABCDAB”的”好后缀”是”DAB”、”AB”、”B”，请问这时”好后缀”的上一次出现位置是什么？回答是，此时采用的好后缀是”B”，它的上一次出现位置是头部，即第0位 道理也很显而易见，如果已经匹配的部分多次出现在模式串，当发生不匹配时，就直接把模式串移动到上一次匹配的位置上。显然 BM 与KMP 不同，BM 不要求后缀匹配的部分必需是模式串的前缀。 “MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。此时，所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”还出现在头部，所以后移 6 - 0 = 6位。 1.3 移位选择Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。更巧妙的是，这两个规则的移动位数，只与模式串有关，与主串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。 2. 实现显然 BR 算法的核心是要先生成《坏字符规则表》和《好后缀规则表》，然后利用这两个规则表进行字符串匹配。 2.1 坏字符规则表2.2 好后缀规则表2.3 字符串匹配参考: 王争老师专栏-数据结构与算法之美 阮一峰-Boyer-Moore算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[29.1 dhcp服务简介]]></title>
    <url>%2F2018%2F11%2F01%2Flinux_mt%2F32-ansible%2Fdhcp%E6%9C%8D%E5%8A%A1%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[dhcp服务简介 当集群内的主机达到一定规模时，我们就需要由手动运维转向自动化运维，以提高我们运维的效率，同时也是为减少我们平均故障修复时间。自动化运维的最新技术是docker，而更加传统的方法则是以 ansible 为代表的配置系统。配置系统的基础是标准化，我们需要为我们的主机配置同样的操作系统，并为相同服务集群内的主机提供相同的配置文件。 不考虑虚拟技术，我们的自动化运维工具可以如下几个层面: BootStraping: 用于引导安装操作系统的，os isntallation，常用工具就是 pxe，cobbler Configuration: 配置系统，定义好了每一个被管理主机的目标状态，被管理主机能基于 agent 或 ssh 被配置系统所管理， 常用工具包括 ansible，puppet,saltstack Command &amp; Control: 批量运行程序，常用工具包括 ansible 本章的内容主要包括两个部分 自动化安装: 基于 PXE 自动化安装系统 配置系统: 基于 ansible 的配置系统 1. DHCP 简介DHCP(Dynamic Host Configuration Protocol) 全称是动态主机配置协议，主要用于为主机配置IP 地址。将一台主机接入互联网时，我们需要为其配置 IP/Netmask,Gateway,DNS Server等等网络参数。我们可以手动配置，也可以借助于 DHCP 协议实现动态分配。dhcp 的前身是 bootp 引导协议，出现于无盘工作站，这种类型的机器没有硬盘，所以操作系统不会安装在本地。此时需要借助网卡的特定功能，它能在开机时被唤醒，并能作为 bootp 协议客户端去请求服务端去获取地址，并加载属于自己的操作系统文件。第一次获取地址时是动态，之后获取的地址则是固定的，因为要实现客户端操作系统与 IP 地址绑定。 1.1 工作过程dhcp 可以理解成引入租约概念的 bootp 协议，能在主机开机时自动分配地址，并在主机关机时收回临时分配的 IP 地址并在分配，同时也保留了 bootp 保留地址的功能。 dhcp 在动态分配地址的过程中，首先在局域网中有一台 dhcp 服务，其维护着一组可用地址列表(地址池)，也包含要为其他主机配置的网关，DNS 服务器等等。某主机开机之后如果其配置了通过 DHCP 动态获取地址，其将发送一个 RARP 的广播报文 arp: address resolving Protocol，IP -&gt; MAC rarp: reverse arp, MAC -&gt; IP 服务器收到，主机的 Rarp 请求之后，就会为其提供一个地址，整个过程如下所示: dhcp 提供的 IP 地址时存在续租期限的，一般主机要在租约期限到一半时进行续租，此时 Client: 向服务器发送一个 dhcp request Server: 如果同意续租则回复 dhcp ack，不同意在回复 dhcp nak 服务器端不允许续租的原因可能是因为管理员更改了可用的地址池，客户端的IP 地址已经不可用。如果不能续租，此时客户端要重新进行广播获取 IP 地址。 如果客户端在续租时服务器端没有响应，客户端会在剩余时间过去一半的时候再次发起续租直至到达一个足够小的时间，此时将认定服务器不可用，客户端将重新广播获取 IP 地址。 需要注意的是开机获取 IP 地址是广播的，续租则是单播的。 1.2 dhcp 中继服务dhcp 服务不能穿越网关(路由器)，所以要为不同物理网络中的主机分配地址时，需要借助于 dhcp 的中继服务。中继的过程如下 dhcp 中继服务用的很少，了解即可。 1.3 dhcp 作用域dhcp 每一个可分配的地址范围称为一个作用域，不同的作用域可以为不同的网络分配地址，还可以定义超级作用域。 dhcp 在分配地址时，还可以告诉客户端一个网络文件服务器地址，并告诉其到这个文件服务器上请求什么文件，这就是通过网络引导系统的基础。 2. dhcp 服务Linux DHCP协议的实现程序 dhcp dnsmasq: 同时实现了dns 和dhcp 服务，用于嵌入式环境中 2.1 程序组成12345678910111213141516171819# rpm -ql dhcp|egrep -v &quot;(share|man)&quot;/etc/NetworkManager/etc/NetworkManager/dispatcher.d/etc/NetworkManager/dispatcher.d/12-dhcpd/etc/dhcp/dhcpd.conf # ipv4 的配置文件/etc/dhcp/dhcpd6.conf # ipv6 地址分配相关的配置文件/etc/dhcp/scripts/etc/dhcp/scripts/README.scripts/etc/openldap/schema/dhcp.schema/etc/sysconfig/dhcpd/usr/bin/omshell/usr/lib/systemd/system/dhcpd.service # ipv4 unit file/usr/lib/systemd/system/dhcpd6.service # ipv6 unit file/usr/lib/systemd/system/dhcrelay.service/usr/sbin/dhcpd # dhcp 服务的主程序/usr/sbin/dhcrelay # dhcp 中继服务的主程序/var/lib/dhcpd/var/lib/dhcpd/dhcpd.leases # 已经分配的的 IP 地址的相关信息/var/lib/dhcpd/dhcpd6.leases dhcp 的服务器端监听在 udp 的 67 号端口，dhcp 的客户端则监听在 68/udp，因为dhcp 协议的客户端与服务器端随时需要相互通信，所以其客户端也必须作为一个守护进程监听在特定端口上。 2.2 服务配置dhcp 的 rpm 包提供了一个dhcp 配置的参考文件 /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example，可复制直接使用 1234567891011121314151617181920212223242526# dhcpd.conf## Sample configuration file for ISC dhcpd## option definitions common to all supported networks...option domain-name &quot;tao.com&quot;; # 搜索域option domain-name-servers 172.16.0.1; # DNS 服务器地址，可指定多个，最多三个，逗号分隔default-lease-time 600; # 默认租约期限max-lease-time 7200; # 最大租约期限log-facility local7;subnet 172.16.0.0 netmask 255.255.255.0 &#123; # subnet 定义一个作用域即一个子网 range 172.16.0.3 172.16.0.10; # 可分配的ip 地址池 option broadcast-address 172.16.0.255; # 广播地址 option routers 172.16.0.1; # 默认网关 filename &quot;pxelinux.0&quot;; # 指明引导文件名称 next-server 172.16.0.2; # 提供引导文件的服务器IP地址；tftp server&#125;host fantasia &#123; # 为特定主机始终分配固定的 IP 地址 hardware ethernet 08:00:07:26:c0:a5; # 主机网卡的 MAC 地址 fixed-address 172.16.100.6; # 为其分配的固定 IP，不能在地址池内&#125; dhcp option 定义的参数可位于子域中，也可以位于全局配置中，子域中的配置优先级更高。 2.3 dhclientdhclient options 作用: dhcp 客户端程序，可手动发起 dhcp 请求 选项: -d: 将 dhclient 工作于前台，显示 dhcp 的工作过程 2.4 已分配地址123456789101112cat /var/lib/dhcpd/dhcpd.leases# The format of this file is documented in the dhcpd.leases(5) manual page.# This lease file was written by isc-dhcp-4.2.5lease 172.16.0.3 &#123; starts 2 2018/09/25 09:34:08; ends 2 2018/09/25 09:44:08; tstp 2 2018/09/25 09:44:08; cltt 2 2018/09/25 09:34:08; binding state free; hardware ethernet 08:00:27:f4:d9:52;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24 字符串匹配之 KMP 算法]]></title>
    <url>%2F2018%2F10%2F31%2Falog%2Fstr_match3%2F</url>
    <content type="text"><![CDATA[优雅的的 KMP 算法 1. KMP 算法BM（Boyer-Moore）和 KMP(Knuth-Morris-Pratt) 都是非常高效的字符串匹配算法。BM 比 KMP 更高效，有实验统计 BM 的性能 是 KMP 3-4 倍。但是他们都非常复杂难懂。除了专栏，我也非常推荐你看一看阮一峰老师有关 BM 和 KMP 算法的介绍。因为 BM 算法利用到了KMP的算法思想，本节我们就先来介绍 KMP 的实现。 1.1 优化思路KMP 算法基于这样一个实现思路: 如下图所示，对于字符串匹配过程中已经匹配的部分，我们是已知的；利用这个已知的信息，我们可以把模式串往后移动更多位，而不是 BR 算法中的一位。而最终移动的位数取决于已匹配部分的&quot;前缀&quot;和&quot;后缀&quot;的最长的共有元素的长度，我们将这个最长的公共子串称为最长可匹配(前缀/后缀)子串 在上面的图例中，已匹配部分是 ABCDAB，前后缀最长匹配的元素是 AB，因此前缀 AB就可以直接来到后缀AB的位置，直接向后移动 4 位继续匹配，如下图所示。 字符串已匹配部分永远是模式串的前缀子串，因此最长可匹配(前缀/后缀)子串我们可以提前计算出来，这个就是 KMP 中的 部分匹配表。因此，整个 KMP 的计算过程就分成了两步: 计算部分匹配表 根据部分匹配表计算每次不匹配时，模式串的移动位数，进行字符串匹配 1.2 部分匹配表部分匹配表，被称为失效函数，又称为 next 数组。在计算 next 数组之前，首先我们需要明确两个概念: “前缀”和”后缀”: “前缀”指除了最后一个字符以外，一个字符串的全部头部组合 “后缀”指除了第一个字符以外，一个字符串的全部尾部组合 12345678以&quot;ABCDAB&quot;为例0. &quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0；1. &quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0；2. &quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0；3. &quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0；4. &quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1；5. &quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2；6. &quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。 即”ABCDAB” 的 next 数组为 [0, 0, 0, 0, 1, 2, 0]。其中 next 数组的下标对应每个前缀子串结尾字符的下标 next 数组的值则是最长可匹配子串的长度 1.3 KMP 复杂度分析KMP 的空间复杂度是 O(m)，时间复杂度为 O(m+n)。分析过程在我们讲解完 KMP 的实现之后再来讲解。 2. KMP 算法实现2.1 计算部分匹配表部分匹配表的计算非常巧妙，下面是代码： 123456789101112131415def kmp_next(P): m = len(P) fail = [0] * m j = 1 # 按照下标从小到大的子串 k = 0 # 上一个子串最长可匹配子串的长度 while j &lt; m: if P[j] == P[k]: fail[j] = k + 1 j += 1 k += 1 elif k &gt; 0: k = fail[k - 1] else: j += 1 return fail 我们以”ABCDAB”为例来讲解计算过程，大家需要牢记的是P[j] 表示当前子串的最后一个字符，P[k] 表示上一个子串的最长可匹配子串的下一个字符，此时分为三种情况: P[j] == P[k]: 对应ABCDAB，前一个子串是ABCDA，最长可匹配子串是 A，此时P[5]==P[1]==B，即AB=AB,所以 ABCDAB的最长可匹配子串长度就是 2 P[j] != P[k] and k &gt; 0: 对应ABCDABD，P[6]!=P[2]，即D!=C，此时可以确定的是ABCDABD的最长可匹配子串，只能从ABD进行匹配，进而问题转换为已知AB的最长可匹配子串，求ABD的最长可匹配子串问题。 P[j] != P[k] and k == 0: 显然此时就没有任何可匹配到的子串。 这个计算过程很巧妙，不多看几次很难明白。 在next 的计算过程中，使用了一个额外的数组，因此这一部份的空间复杂度是 O(m)。在 while 循环中 j 执行的次数一定不会超过 m，而 k 变量无论是增加累计的量，还是减少累计的量都不会超过 m，因此这一部分的时间复杂度为 O(m)。 2.2 KMP 字符串匹配过程字符串匹配的过程中，最重要的一步是确定不匹配时，后移的位数，代码如下: 12345678910111213141516def kmp_match(T, P): fail = kmp_next(P) n, m = len(T), len(P) k = 0 j = 0 while j &lt; n: if T[j] == P[k]: if k == m - 1: return j - (m - 1) k += 1 j += 1 elif k &gt; 0: k = fail[k - 1] # 后移表示为 k 索引的变化 else: j += 1 return -1 整个匹配过程中，j 变量的执行次数不会超过 n，而变量 k，无论是增加的累计量还是减少的累计量都不会超过 n，因此这一部分的时间复杂度不会超过 O(n)。因此总的时间复杂度不会超过O(m+n)。 参考: 王争老师专栏-数据结构与算法之美 阮一峰-KMP算法 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23 字符串匹配之 BF & RK 算法]]></title>
    <url>%2F2018%2F10%2F30%2Falog%2Fstr_match1%2F</url>
    <content type="text"><![CDATA[粗暴匹配的 BF 与 RK 算法 1. 特性从本节开始我们将学习字符串匹配算法。字符串匹配算法有很多，大体可以分成两类: 单模式串匹配算法: 一个串跟一个串进行匹配，包括BF，RK，KMP，BM 算法 多字符串匹配算法: 一个串中同时查找多个串，包括 Trie 树和 AC 自动机 本节我们先来学习“最简单粗暴的” BF 和 RK 算法。为了便于描述，对于在字符串A中查找 B，我们将 A 称为主串，B 称为模式串，n=len(A), m=len(B)。 1.1 BF 算法BF(Brute Force) 暴力匹配算法，采用的就是我们最容易理解的穷举法。从主串的第一位开始检查主串中所有长度为 m 的子串看是否与模式串相等。主串中有(n-m+1)个长度为 m 的子串，因此总共需要比较(n-m+1)*m次 BF 算法的时间复杂度很高，为 O(m*n)，但却是一个比较常用的字符串匹配算法，而原因有两个: 大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。 算法简单，实现起来不容易出错 1.2 RK 算法RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。RK 算法可以理解为引入了哈希算法的 BF。 RK 算法希望通过计算字符串的哈希值，并通过比较哈希值，而不是比较字符串，来缩小BF算法中主串的子串与模式串的比较时间。要想达到优化的目的，我们必需使得(字符串哈希+哈希值比较的时间) &lt; (m 次字符比较的时间)。因为哈希值是整数，单次整数的比较时间可以忽略不计。但是字符串哈希值的计算也需要遍历每个字符，因此想要优化，必需精心设计此处的哈希函数。 为了减少字串哈希值的计算量，在计算第 i 个字串的哈希值时，需要能用到已经计算的第 i-1 个字串的哈希值，并且平衡好计算过程中空间占用和哈希冲突的概率。因为 RK 算法并不常用，所以这里我不再过多讲述，有兴趣的同学可以自己查看专栏的介绍。 RK 算法的时间复杂度取决于哈希函数，理想情况下，RK 算法的时间复杂度是 O(n)，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，时间复杂度就退化为 O(n*m)。 2. 实现2.1 BF 算法123456789101112131415def find_brute(T, P): """ :param T: 主串 :param P: 模式串 :return: """ n, m = len(T), len(P) for i in range(n - m + 1): j = 0 while j &lt; m and T[i + j] == P[j]: j += 1 if j == m: return i return -1 3. 应用今天讲的一维字符串匹配可以应用到二维空间中。即如下图所示，在一个二维主串中搜索另一个二维模式串。 下面是代码实现:1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22 堆的应用]]></title>
    <url>%2F2018%2F10%2F29%2Falog%2Fheap_use%2F</url>
    <content type="text"><![CDATA[动态 topK 1. 堆的应用2. 实现2.1 合并小文件2.2 高性能定时器2.3 动态 topK2.4 动态求中位数参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21 堆]]></title>
    <url>%2F2018%2F10%2F28%2Falog%2Fheap%2F</url>
    <content type="text"><![CDATA[能找到”最好学生”的堆 1. 特性堆是一种特殊的二叉树，它满足如下两个属性: 堆是一完全二叉树 堆中每个节点的值都必需大于等于(或小于等于)其子树中每个节点的值，下称为 Heap-Order 完全二叉树被定义为除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。所以完全二叉树具有如下一些特性: 非常适合使用数组进行存储，不会出现空间浪费 如果下标从 1 开始，下标为 i 的节点的左右子节点的下标是 2*i，2*i+1； 对于一个有 n 个元素的完全二叉树，树的高度为 logn 为了维护堆的Heap-Order，当我们更改堆中的元素时，我们需要在堆中上下交换堆的元素，额外交换的次数不会超过树的高度即 logn，所以堆的更新操作的时间复杂度为 O(logn)。 1.1 支持的操作堆支持以下一些常用操作: 添加一个元素: 将元素添加到数组的末尾，并对其从下往上的堆化，时间复杂度为 logn 删除堆顶元素: 删除堆顶元素，并用数组末尾元素填充堆顶，对新的堆顶元素从上往下的堆化，时间复杂度为 logn 构建堆: 自底向上的构建堆，时间复杂度为O(n) 堆排序: 包括建堆和排序，排序的时间复杂度为O(nlogn) 1.2 堆排序与快速排序堆排序与快速排序都是原地排序算法，排序的平均时间复杂度都是O(nlogn)，甚至堆排序比快排更加稳定。但是快排的性能还是比堆排序要好，原因有两个: 堆排序数据访问的方式没有快排友好。快排中数据是顺序访问的，但是堆排序是按照指数跳越访问的，对 CPU 缓存不友好 对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。 2. 实现2.1 小堆的实现我们选择小堆作为堆实现的示例，大堆的实现类似。对于堆而言最核心的就是从下往上和从上往下的堆化操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132class PriorityQueueBase(object): class _Item(object): __slots__ = '_key', '_value' def __init__(self, key, value): self._key = key self._value = value def __gt__(self, other): return self._key &gt; other._key def __lt__(self, other): return self._key &lt; other._key def __eq__(self, other): return self._key == other._keyclass HeapPriorityQueue(PriorityQueueBase): def __init__(self, content=()): """ :return: 构建堆 """ self._data = [self._Item(k,v) for k, v in content] if self._data: self._heap() def _heap(self): """ """ i = self._parent(len(self._data) - 1) while i &gt;= 0: self._downheap(i) i -= 1 def _parent(self, i): """ :param i: :return: 父节点索引 """ return (i - 1) // 2 def _left(self, i): """ :param i: :return: 左子节点索引 """ return i * 2 + 1 def _right(self, i): """ :param i: :return: 右子节点索引 """ return i * 2 + 2 def has_left(self, i): return self._left(i) &lt; len(self._data) def has_right(self, i): return self._right(i) &lt; len(self._data) def _swap(self, i, j): """ :return: 数据交换 """ self._data[i], self._data[i] = self._data[j], self._data[i] def _upheap(self, i): """ :param i: :return: 从下往上堆化 """ parent = self._parent(i) while self._data[parent] &gt; self._data[i] and i &gt; 0: self._swap(parent, i) i = parent parent = self._parent(parent) def _downheap(self, i): """ :param i: :return: 从上往下堆化 """ while self.has_left(i): small_child = self._left(i) if self.has_right(i): right = self._right(i) if self._data[small_child] &gt; self._data[right]: small_child = right if self._data[i] &gt; self._data[small_child]: self._swap(i, small_child) i = small_child else: break def __len__(self): return len(self._data) def is_empty(self): return len(self) == 0 def add(self, key, value): """ :param key: :param value: :return: 向堆中添加元素 """ self._data.append(self._Item(key, value)) self._upheap(len(self._data) - 1) def min(self): """ :return: 获取堆顶元素，但不删除 """ if not self.is_empty(): item = self._data[0] return item._key, item._value raise ValueError('Priority Queue is empty') def remove_min(self): """ :return: 获取并删除堆顶元素 """ if self.is_empty(): ValueError('Priority Queue is empty') item = self._data[0] self._data[0] = self._data.pop() self._downheap(0) return item._key, item._value 2.2 堆的原排序堆的原排序排序包括两个过程: 建堆+排序。建堆就是上面 _heap 方法展示的过程，通过由底向上构建堆，我们可以在 O(n) 的时间复杂度内实现堆构建。 排序时，我们将堆顶元素与数组最后的元素交换，然后对前 n-1 个元素组成的堆堆化，然后再将堆顶元素与数组倒数第二个元素交换，以此类推，当堆中只剩下一个元素时排序即完成。 很可惜的是，我们上面的小堆实现无法实现堆的原地排序，因为我们无法控制堆中的元素个数，以达到缩减堆范围的目的。但是实现起来也很简单，通过添加额外的可控的计数器作为堆元素个数的记录，而不是直接使用 len(self._data) 我们就可以很容易实现。 2.2 可删除和修改任意位置的堆最后我们介绍一种可更新和删除任意位置的堆。我们使用一个叫作定位器 Locator 对象作为堆中的元素，Locator记录了元素在堆中数组的索引，在执行更新和删除操作时，将Locator作为参数传递给函数，就可以直接定位元素位置，并对其执行更新操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class AdaptHeapPriorityQueue(HeapPriorityQueue): class Locator(HeapPriorityQueue._Item): __slots__ = '_index' def __init__(self, key, value, index): super(AdaptHeapPriorityQueue.Locator, self).__init__(key, value) self._index = index def __init__(self): super(AdaptHeapPriorityQueue, self).__init__() def add(self, key, value): token = self.Locator(key, value, len(self._data)) self._data.append(token) self._upheap(len(self._data) - 1) return token def _swap(self, i, j): super(AdaptHeapPriorityQueue, self)._swap(i, j) self._data[i]._index = i self._data[j]._index = j def _bubble(self, j): if j &gt; 0 and self._data[j] &lt; self._data[self._parent(j)]: self._upheap(j) else: self._downheap(j) def update(self, loc, key, value): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') loc._key = key loc._value = value self._bubble(j) def remove(self, loc): j = loc._index if not (0 &lt; j &lt; len(self) and self._data[j] is loc): raise ValueError('invalid locator') if j == len(self) - 1: self._data.pop() else: self._data[j] = self._data.pop() self._bubble(j) return loc._key, loc._value 3 算法堆有众多应用，限于篇幅，我们在接下来的一节来专门讲解。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20 递归树]]></title>
    <url>%2F2018%2F10%2F27%2Falog%2Frecursion_tree%2F</url>
    <content type="text"><![CDATA[利用树计算递归函数的时间复杂度 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19 红黑二叉树]]></title>
    <url>%2F2018%2F10%2F26%2Falog%2Fred_black_tree%2F</url>
    <content type="text"><![CDATA[搞不懂的”红黑数”…. 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18 二叉查找树与完全二叉树]]></title>
    <url>%2F2018%2F10%2F25%2Falog%2Fbinary_tree%2F</url>
    <content type="text"><![CDATA[有散列表了，为什么还要”一颗树” 1. 特性2. 实现2.1 二叉搜索树我们实现的二叉搜索树将支持: 标准映射操作: __setitem__ __getitem__ __delitem__ 有序映射操作: find_lt find_range 基于位置操作 after(p) before(p) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244from collections import MutableMappingfrom linked_tree import LinkedBinaryTreeclass MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._keyclass TreeMap(LinkedBinaryTree, MapBase): class Position(LinkedBinaryTree.Position): def key(self): return self.element()._key def value(self): return self.element()._value def _subtree_search(self, p, k): """ :param p: :param k: :return: 在子树中搜索值为 k 的节点，未搜索到返回最后搜索路经的最终位置 """ p_value = p.key() if p_value == k: return p elif p_value &gt; k: if self.left(p): return self._subtree_search(self.left(p), k) else: if self.right(p): return self._subtree_search(self.right(p), k) return p def _subtree_first_position(self, p): """ :return: 返回子树迭代时，第一个位置节点 """ walk = p while self.left(walk): walk = self.left(walk) return walk def _subtree_last_position(self, p): """ :param p: :return: 返回子树迭代时，最后一个位置节点 """ walk = p while self.right(walk): walk = self.right(walk) return walk ################# 引导方法 ####################### def first(self): """ :return: 返回树迭代序列的第一个节点 """ return self._subtree_first_position(self.root()) if len(self) &gt; 0 else None def last(self): """ :return: 返回树迭代序列的最后一个节点 """ return self._subtree_last_position(self.root()) if len(self) &gt; 0 else None def before(self, p): """ :param p: :return: 返回迭代序列中位于 p 之前的，最大节点 """ self._validate(p) if self.left(p): return self._subtree_last_position(self.left(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.left(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def after(self, p): """ :param p: :return: 返回迭代序列中位于 p 之后的，最小节点 """ self._validate(p) if self.right(p): self._subtree_first_position(self.right(p)) else: walk = p ancestor = self.parent(walk) while ancestor and self.right(ancestor) is walk: walk = ancestor ancestor = self.parent(ancestor) return ancestor def find_position(self, k): """ :param k: :return: 查找值等于 k 的位置节点 """ if self.is_empty(): return None else: p = self._subtree_search(self.root(), k) # avl 平衡树的钩子函数 self._rebalance_access(p) return p ####################### 有序映射 ###################### def find_min(self): """ :return: 查找树中的最小值 """ if self.is_empty(): return None else: p = self.first() return p.key(), p.value() def find_ge(self, k): """ :param k: :return: 查找大于等于 k 的最小节点 """ p = self.find_position(k) if p and p.key() &lt; k: p = self.after(p) return p.key(), p.value() if p else None, None def find_range(self, start, stop): """ :param start: :param stop: :return: 查找值位于 start &lt;= k &lt; stop 的节点 """ if not self.is_empty(): if start is None: p = self.first() else: p = self.find_position(start) if p and p.key() &lt; start: p = self.after(p) while p and (stop is None or p.key() &lt; stop): yield p.key(), p.value() p = self.after(p) ########################### 增删改查节点操作 ################ def __getitem__(self, item): """ :param item: :return: 查找 item 映射的值 """ if not self.is_empty(): p = self.find_position(item) self._rebalance_access(p) if p.key() == item: return p.value() raise KeyError('Key Error:' + repr(item)) def __setitem__(self, key, value): """ :param key: :param value: :return: 设置键 key 的值为 value """ if self.is_empty(): leaf = self._add_root(self._Item(key, value)) else: p = self.find_position(key) if p.key() == key: p.element()._value = value self._rebalance_access(p) return else: item = self._Item(key, value) if p.key() &lt; key: leaf = self._add_right(p, item) else: leaf = self._add_left(p, item) self._rebalance_insert(leaf) def __iter__(self): """ :return: 产生键的一个迭代 """ p = self.first() while p: yield p.key() p = self.after(p) def delete(self, p): """ :param p: :return: 删除位置节点 p """ self._validate(p) if self.left(p) and self.right(p): r = self._subtree_last_position(self.left(p)) self._replace(p, r.element()) p = r parent = self.parent(p) self._delete(p) self._rebalance_delete(parent) def __delitem__(self, key): """ :param key: :return: 删除键 key """ if not self.is_empty(): p = self._subtree_search(self.root(), key) if p.key() == key: self.delete(p) return self._rebalance_access(p) raise KeyError('Key Error: ' + repr(key)) ################### 平衡二叉树的钩子函数 ############### def _rebalance_delete(self, p): pass def _rebalance_insert(self, p): pass def _rebalance_access(self, p): pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17 树的存储与遍历]]></title>
    <url>%2F2018%2F10%2F24%2Falog%2Ftree_base%2F</url>
    <content type="text"><![CDATA[如何表示和存储一颗树？ 1. 特性树是我们接触的第一种非线性结构，在树中一个”父”元素可以有一个或多个”子”元素，这种组织关系要比一个序列中两个元素之间简单的”前”,”后”关系更加复杂。 最常用的树是二叉树，即一个父节点最多只有两个子节点，在二叉树的基础上如果我们按照特定的数据分布在树的各个节点组织数据，我们就可以得到诸如二叉搜索树，堆，红黑二叉树等多种具有特定用途的数据结构。 下面就是从树到二叉树的抽象层次结构，本节我们就来介绍如何存储和实现一个树。 123 Tree(树) BinaryTree(二叉树) LinkedTreeArrayBinaryTree LinkedBinaryTree 我们将 Tree，BinaryTree 实现为抽象基类，来定义和抽象普通树和二叉树可执行操作，并以二叉树的链式存储为例来实现一颗二叉树。我们会在堆章节中实现一个基于数组的二叉树。一颗普通树的链式存储与基于数组的存储与二叉树类似，我们会简单阐述它们的实现方式。 2. 实现2.1 TreeTree 被实现为 Python 抽象基类，我们使用一种叫作 Position 的位置对象作为对树节点访问的代理。通过 Position 对象提供的辅助功能，我们可以验证待操作节点是否属于被操作的树，并抽象树的节点所表达的”父子”，以及迭代过程中的前后关系。 一个普通树能执行的操作有限，通过包括以下几种: 获取和判断树的根节点 获取节点的子节点树，并借此判断节点是否为叶子节点 获取节点的父节点和所有子节点 获取树的所有节点 获取树中节点个数，判断树是否未空 获取树或节点的高度和深度 树的前序遍历和后序遍历 需要注意的是中序是二叉树特有的遍历方式，一颗普通的树没有中序遍历。下面是一个普通树的抽象实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import abcclass Tree(object): __metaclass__ = abc.ABCMeta class Position(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def element(self): """ :return: 返回存储在 p 中的元素值 """ @abc.abstractmethod def __eq__(self, other): pass @abc.abstractmethod def __ne__(self, other): return not self == other @abc.abstractmethod def root(self): """ :return: 返回树的根节点 """ pass @abc.abstractmethod def parent(self, p): """ :param p: :return: 返回 p 节点的父节点 """ pass @abc.abstractmethod def children(self, p): """ :param p: :return: 返回 p 节点孩子的迭代 """ @abc.abstractmethod def num_children(self, p): """ :param p: :return: 返回节点 p 孩子的个数 """ pass @abc.abstractmethod def __len__(self): pass def is_root(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是根节点 """ return self.root() == p def is_leaf(self, p): """ :param p: :return: 判断位置 p 表示的节点是否是叶子节点 """ return self.num_children(p) == 0 def is_empty(self): """ :return: 判断树是否为空 """ return len(self) == 0 def depth(self, p): """ :param p: :return: 返回 p 节点的深度 """ if self.is_root(p): return 0 else: return 1 + self.depth(self.parent(p)) def height(self, p=None): """ :return: 返回树的高度 """ p = p or self.root() return self._height(p) def _height(self, p): if self.is_leaf(p): return 0 else: return 1 + max(self._height(c) for c in self.children(p)) 2.2 BinaryTree相对于普通树，二叉树是具有如下属性的树: 每个节点至多两个节点 每个节点被命名为左右子节点 在顺序上，同一个节点左孩子优于右孩子 因此二叉树与普通的树相比多了如下3个操作: 获取节点的左右孩子 获取节点的兄弟节点 需要注意的是虽然封装原则表名类的外部行为不需要依赖类的内部实现，而操作的效率却极大的依赖实现方式，所以我们更倾向于在 Tree 类的每个更具体的子类中提供合适的更新操作。因此我们不会在基类中限制树的更新操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class BinaryTree(Tree): __metaclass__ = abc.ABCMeta @abc.abstractmethod def left(self, p): """ :param p: :return: 返回节点的左孩子 """ pass @abc.abstractmethod def right(self, p): """ :param p: :return: 返回节点的右孩子 """ pass def slide(self, p): """ :param p: :return: 返回节点的兄弟节点 """ parent = self.parent(p) if parent is not None: left = self.left(parent) right = self.right(parent) if left == p: return right else: return left def children(self, p): """ :param p: :return: 返回节点的所有子节点 """ left = self.left(p) if p is not None: yield left right = self.right(p) if right is not None: yield right 2.3 LinkedBinaryTreeLinkedBinaryTree 是我们第一个具体实现的链式二叉树。除了必需实现的抽象方法，更新操作外，我们还提供了树的四中遍历方式，用来迭代树中的元素。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235from collections import dequefrom tree import BinaryTreeclass LinkedBinaryTree(BinaryTree): class _Node(object): __slots__ = "element", "parent", "left", "right" def __init__(self, element, parent=None, left=None, right=None): self.element = element self.parent = parent self.left = left self.right = right class Position(BinaryTree.Position): def __init__(self, container, node): self._node = node self._container = container def element(self): return self._node.element def __eq__(self, other): return type(other) is type(self) and self._node is other._node def _make_position(self, node): if node is not None: return self.Position(self, node) def _validate(self, p): if not isinstance(p, self.Position): raise TypeError('p must be proer Position type') if p._container is not self: raise ValueError('p not belong to this container') if p._node.parent is p._node: raise ValueError('p will no longer valid') return p._node def __init__(self): self._root = None self._size = 0 def __len__(self): return self._size def root(self): return self._make_position(self._root) def parent(self, p): node = self._validate(p) return self._make_position(node.parent) def left(self, p): node = self._validate(p) return self._make_position(node.left) def right(self, p): node = self._validate(p) return self._make_position(node.right) def num_children(self, p): node = self._validate(p) count = 0 if node.left is not None: count += 1 if node.left is not None: count += 1 return count def _add_root(self, e): """ :param e: :return: 向树添加根节点 """ if self._root is not None: raise ValueError('Root exists') self._root = self._Node(e) self._size += 1 return self._make_position(self._root) def _add_left(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.left is not None: raise ValueError('Left child exists') self._size += 1 left_node = self._Node(e, node) node.left = left_node return self._make_position(left_node) def _add_right(self, p, e): """ :param p: :param e: :return: 为节点添加左子节点 """ node = self._validate(p) if node.right is not None: raise ValueError('right child exists') self._size += 1 right_node = self._Node(e, node) node.right = right_node return self._make_position(right_node) def _replace(self, p, e): """ :param p: :param e: :return: 替换节点的元素值 """ node = self._validate(p) old = node.element node.element = e return old def _delete(self, p): """ :param p: :return: 删除节点， 不能通过移动元素值来删除元素，因为 Position 内部是通过 Node 判断是否相等的 """ node = self._validate(p) if node.left and node.right: raise ValueError('p must leaf') child = node.left if node.left else node.right if child is not None: child.parent = node.parent if node is self._root: self._root = child else: if node is node.parent.left: node.parent.left = child else: node.parent.right = child node.parent = node self._size -= 1 return node.element def attach(self, p, t1, t2): """ :param p: :param t1: :param t2: :return: 在叶子节点附加左右子树 """ node = self._validate(p) if not type(self) is type(t1) is type(t2): raise TypeError() if not self.is_leaf(p): raise ValueError('p must leaf') self._size += len(t1) + len(t2) if not t1.is_empty(): node.left = t1._root t1._root.parent = node t1._size = 0 t1._root = None if not t2.is_empty(): node.right = t2._root t2._root.parent = node t2._size = 0 t2._root = None def positions(self): """ :return: 返回树所有位置的一个迭代 """ return self.preorder() def __iter__(self): for p in self.positions(): yield p.element() def preorder(self): """ :return: 树的前序遍历 """ if not self.is_empty(): for p in self._subtree_preorder(self.root()): yield p def _subtree_preorder(self, p): yield p for i in self.children(p): for other in self._subtree_preorder(i): yield other def postorder(self): """ :return: 后序遍历 """ if not self.is_empty(): for p in self._subtree_postorder(self.root()): yield p def _subtree_postorder(self, p): for i in self.children(p): for other in self._subtree_preorder(i): yield other yield p def breadthfirst(self): """ :return: 广度优先遍历 """ if not self.is_empty(): queue = deque() queue.append(self.root()) while len(queue) &gt; 0: p = queue.popleft() for c in self.children(p): queue.append(c) yield p def inorder(self): """ :return: 中序遍历 """ if not self.is_empty(): return self._subtree_inorder(self.root()) def _subtree_inorder(self, p): left = self.left(p) if left is not None: for other in self._subtree_inorder(left): yield other yield p right = self.right(p) if right is not None: for other in self._subtree_inorder(right): yield other 3.相关算法不考虑特殊的树，仅仅是普通的二叉树就有很多应用，比如计算目录的容量，表达式树。与树相关的递归也是经常考的算法题。但是考虑篇幅的原因，我会在讲解完所有的树之后，用几篇单独的文章来说明与树相关的算法。 3.1 表达式树作为二叉树的第一个例子，我们将使用二叉树来表示算数表达式的结构。我们将定义一个 BinaryTree 的子类 ExpressionTree，在其内部的每个节点必需存储一个操作符，每个叶子节点则必需存储一个数字。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677from expression import infix_to_postfixfrom linked_tree import LinkedBinaryTreeclass ExpressionTree(LinkedBinaryTree): def __init__(self, token, left=None, right=None): super(ExpressionTree, self).__init__() if not isinstance(token, (str, unicode)): raise TypeError('Token must be a string') self._add_root(token) if left or right: if token not in '+-*/': raise ValueError('token must be in +-*/') self.attach(self.root(), left, right) def __str__(self): result = [] if not self.is_empty(): self._parenthesize_recur(self.root(), result) return ''.join(result) def _parenthesize_recur(self, p, result): if self.is_leaf(p): result.append(p.element()) else: result.append('(') self._parenthesize_recur(self.left(p), result) result.append(p.element()) self._parenthesize_recur(self.right(p), result) result.append(')') def evaluate(self): """ :return: 计算表达式树的值 """ return self._evaluate_cur(self.root()) def _evaluate_cur(self, p): if self.is_leaf(p): return float(p.element()) else: left = self._evaluate_cur(self.left(p)) op = p.element() right = self._evaluate_cur(self.right(p)) if op == '+': return left + right elif op == '-': return left - right elif op == '/': return left / right else: return left * right @staticmethod def build_expression_tree(expression): """ :param expression: 表达式默认以空格分隔 :return: 构建表达式树 """ stack = [] postfix = infix_to_postfix(expression) for i in postfix: if i not in '+-*/': stack.append(ExpressionTree(i)) else: right = stack.pop() left = stack.pop() stack.append(ExpressionTree(i, left, right)) t = stack.pop() return tif __name__ == '__main__': expression = '10 / 5 + 1 + ( 100 / 10 )' t = ExpressionTree.build_expression_tree(expression) print t print t.evaluate() 在原书 《数据结构与算法：python语言实现》 中，通过 build_expression_tree 方法构建表达式树时，要求传入的表达式必需是完全括号，即形如 2 * 6 + 2 的表达式必需写成(2 * 6) + 2 才能正确执行。对于一般的算数表达式必需先借助栈，将中缀表达式转换为后缀表达式才能正确构建表达式树，整个过程类似于栈中表达式的求值过程。 3.2 树遍历的应用树的遍历有很多应用，但是这些应用都有一个共通的特点，即他们都是在树的遍历过程的前后附加一些特殊操作。利用面向对象编程中的模板方法模式，我们可以将树的遍历过程定义为一个通用的计算机制，并在迭代的过程中定义好钩子函数。所有类似的应用都可以通过继承并自定义钩子函数的方式快速实现。 对于树的遍历而言，通常有四个变量是我们会利用的信息，我们需要在遍历的前后将它们传递给钩子函数: p: 当前节点的位置对象 d: p 的深度 path: 从根到 p 的路经 result: p 所有子节点的遍历结果 下面是树遍历过程的模板方法的实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class EulerTour(object): def __init__(self, tree): self._tree = tree def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): """ :param p: :param d: :param path: :param result: :return: """ self._hook_previsit(p, d, path) path.append(0) result = [] for c in self._tree.children(p): result.append(self._tour(c, d + 1, path)) path[-1] += 1 value = self._hook_postvisit(p, d, path, result) path.pop() return value def _hook_previsit(self, p, d, path): pass def _hook_postvisit(self, p, d, path, result): passclass BinaryEulerTour(BinaryEulerTour): def __init__(self, tree): super(BinaryEulerTour, self).__init__(tree) def execute(self): if not self._tree.is_empty(): return self._tour(self._tree.root(), 0, []) def _tour(self, p, d, path): self._hook_previsit(p, d, path) result = [None, None] if self._tree.left(p): path.append(0) result[0] = self._tour(self._tree.left(p), d + 1, path) path.pop() self._hook_invisit(p, d, path) if self._tree.right(p): path.append(1) result[1] = self._tour(self._tree.right(p), d + 1, path) path.pop() value = self._hook_postvisit(p, d, path, result) return value def _hook_invisit(self, p, d, path): pass 此时如果我们想构建一个表示目录结构的目录树，并计算目录的大小，借助于 EulerTour 可以很容易的实现 123456class DiskSpace(EulerTour): def __init__(self, tree): super(DiskSpace, self).__init__(tree) def _hook_postvisit(self, p, d, path, result): return p.element() + sum(result) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.3 haproxy 访问控制]]></title>
    <url>%2F2018%2F10%2F24%2Flinux_mt%2F31-haproxy%2Fhaproxy%E8%AE%BF%E9%97%AE%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[haproxy 访问控制 本节我们来 介绍 haproxy 配置的第二部分，acl 访问控制。 1. aclacl 能分类请求和响应报文，进而根据分类结果作出转发决策和访问控制。 1.1 acl 使用acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] [&lt;value&gt;] 作用: 根据设置的条件分类请求和响应报文 参数: &lt;aclname&gt;: 作用: acl 的名称标识，以便在后续的访问控制和转发中进行引用 命名: 可用字符包括大小写子母，数字 -，_，.， :，大小写敏感的 说明: 多个 acl 可以使用同一个名字，彼此之间属于 OR 关系 &lt;criterion&gt;: 匹配的标准，表示要检查什么内容 [operator]: 匹配操作，比如等于，小于，或正则表达式匹配 &lt;value&gt;: 标准匹配的目标值 [flags]: 比较控制标识 过程: acl 的匹配过程就是把&lt;criterion&gt;指定的匹配标准和 &lt;value&gt;指定的值基于[operator]指定的操作符作比较操作，如果符合条件则为真，否则为假 valuevalue 值可以是以下类型: boolean integer or integer range IP address / network string，字符串的比较分为如下多种类型 exact: criterion表示的值 与 value 完全匹配 substring: value 是criterion表示值的子串 suffix: value 是criterion表示值的后缀 prefix: value 是criterion表示值的前串 subdir: value 是criterion表示路经中的子路经 domain: value 是criterion表示域名的的子域 regular expression hex block flagsflags 有如下几个选项 -i : 比较时忽略大小写. -m : 使用一个特殊的模式匹配方法，很少用到 -n : 禁止 DNS 反向解析 -u : 禁止两个 acl 使用相同的名称 -- : flag的结束符标记，强制结束 flag operator比较操作有如下几种类型 匹配整数值：eq、ge、gt、le、lt 匹配字符串： exact match (-m str) : 精确匹配 substring match (-m sub) : 字串匹配 prefix match (-m beg) : 前缀匹配 suffix match (-m end) : 后缀匹配 subdir match (-m dir) : 子路经匹配，即是否是/分隔的子串 domain match (-m dom) : 域名匹配，即是否是.分隔的子串 acl作为条件时的逻辑关系 AND: 默认多个条件使用空格分隔即表示逻辑与 OR: 使用 or 或 || 表示逻辑与 Not: 使用 ! 表示取反 123if invalid_src invalid_portif invalid_src || invalid_portif ! invalid_src invalid_port criterioncriterion 用于指定匹配请求报文或响应报文的哪些内容 匹配传输层和网络层报文中的内容 dst: 目标 ip dst_port: 目标端口 integer src: 源ip src_port: 源端口 eg: acl invalid_src src 172.16.200.2 匹配 url 中的路经，即path 部分(/path;&lt;params&gt;)，string path : exact string match path_beg : prefix match path_dir : subdir match path_dom : domain match path_end : suffix match path_len : length match path_reg : regex match path_sub : substring match 匹配整个 url ，string url : exact string match url_beg : prefix match url_dir : subdir match url_dom : domain match url_end : suffix match url_len : length match url_reg : regex match url_sub : substring match 匹配请求报文首部中的特定字段，相同报文只会匹配最后一次出现，string hdr([[,]]) : exact string match hdr_beg([[,]]) : prefix match hdr_dir([[,]]) : subdir match hdr_dom([[,]]) : domain match hdr_end([[,]]) : suffix match hdr_len([[,]]) : length match hdr_reg([[,]]) : regex match hdr_sub([[,]]) : substring match 匹配响应状态码 status，integer status 123# 示例：acl bad_curl hdr_sub(User-Agent) -i curlblock if bad_curl 预订义的 ACL123456789101112131415161718192021Pre-defined ACLsACL name Equivalent to UsageFALSE always_false never matchHTTP req_proto_http match if protocol is valid HTTPHTTP_1.0 req_ver 1.0 match HTTP version 1.0HTTP_1.1 req_ver 1.1 match HTTP version 1.1HTTP_CONTENT hdr_val(content-length) gt 0 match an existing content-lengthHTTP_URL_ABS url_reg ^[^/:]*:// match absolute URL with schemeHTTP_URL_SLASH url_beg / match URL beginning with &quot;/&quot;HTTP_URL_STAR url * match URL equal to &quot;*&quot;LOCALHOST src 127.0.0.1/8 match connection from local hostMETH_CONNECT method CONNECT match HTTP CONNECT methodMETH_GET method GET HEAD match HTTP GET or HEAD methodMETH_HEAD method HEAD match HTTP HEAD methodMETH_OPTIONS method OPTIONS match HTTP OPTIONS methodMETH_POST method POST match HTTP POST methodMETH_TRACE method TRACE match HTTP TRACE methodRDP_COOKIE req_rdp_cookie_cnt gt 0 match presence of an RDP cookieREQ_CONTENT req_len gt 0 match data in the request bufferTRUE always_true always matchWAIT_END wait_end wait for end of content analysis 2. 访问控制指令use_backenduse_backend &lt;backend&gt; [{if | unless} &lt;condition&gt;] 作用: 当符合指定的条件时使用特定的backend； blockblock { if | unless } &lt;condition&gt; 作用: 当符合指定的条件时阻止七层 http 的访问 123acl invalid_src src 172.16.200.2block if invalid_srcerrorfile 403 /etc/fstab http-requesthttp-request { allow | deny } [ { if | unless } &lt;condition&gt; ] 作用: 控制七层的访问请求 tcp-requesttcp-request connection {accept|reject} [{if | unless} &lt;condition&gt;] 作用: 四层的连接请求控制 12345678listen ssh bind :22022 balance leastconn acl invalid_src src 172.16.200.2 tcp-request connection reject if invalid_src mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check backup 3. 基于ACL的动静分离示例需要注意的 haproxy 不能作为 fastcgi 的客户端，因此其后端主机不能是 phpfpm 这种 fastcgi 的应用程序服务器。后端服务器只能是 httpd 或者 nginx，并通过它们来反代 fpm。 123456789101112131415161718192021frontend web *:80 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js .html .txt .htm use_backend staticsrvs if url_static default_backend appsrvsbackend staticsrvs balance roundrobin server stcsrv1 172.16.100.6:80 checkbackend appsrvs balance roundrobin server app1 172.16.100.7:80 check server app1 172.16.100.7:8080 checklisten stats bind :9091 stats enable stats auth admin:admin stats admin if TRUE 4. 配置HAProxy支持https协议：12345678910111213# 1 支持ssl会话bind *:443 ssl crt /PATH/TO/SOME_PEM_FILE# crt后的证书文件要求PEM格式，且同时包含证书和与之匹配的所有私钥；cat demo.crt demo.key &gt; demo.pem# 2 把80端口的请求重向定443；bind *:80redirect scheme https if !&#123; ssl_fc &#125;# 3 如何向后端传递用户请求的协议和端口http_request set-header X-Forwarded-Port %[dst_port]http_request add-header X-Forwared-Proto https if &#123; ssl_fc &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 哈希算法]]></title>
    <url>%2F2018%2F10%2F23%2Falog%2Fhash%2F</url>
    <content type="text"><![CDATA[如何使用使用哈希算法？ 1 特性将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。优秀的哈希算法必需满足如下几点要求: 不能反向推导: 从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）； 输入数据敏感: 对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同； 散列冲突小: 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小； 执行效率高: 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。 1.1 应用哈希算法的应用非常多，最常见的有如下七种: 安全加密: 不能反向推导 + 散列冲突小，无法通过哈希值逆推出原文 唯一标识: 输入数据敏感 + 散列冲突小，可以通过哈希值的比较间接判断，原文是否相等 数据校验: 输入数据敏感 + 散列冲突小，数据损坏，哈希值就会发生变化 散列函数: 散列函数对哈希算法更加看重的是散列的平均性和哈希算法的执行效率 负载均衡: 利用哈希算法的唯一标识功能，可以将同一客户端 IP 或 session 路由到同一服务器 路由的服务器编号=hash(client_ip or session_id) % len(server_list) 数据分片: 利用哈希算法的唯一标识功能，无需比较就可以将相同的数据归类在一起 分配到的机器编号=hash(keyword) / len(server_list) 分布式存储: 数据分片 + 一致性哈希算法 2. 实现2.1 一致性哈希算法 利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题。下面是 Python 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657'''consistent_hashing.py is a simple demonstration of consistenthashing.'''import bisectimport hashlibclass ConsistentHash: '''ConsistentHash(n,r) creates a consistent hash object for a cluster of size n, using r replicas. It has three attributes. num_machines and num_replics are self-explanatory. hash_tuples is a list of tuples (j,k,hash), where j ranges over machine numbers (0...n-1), k ranges over replicas (0...r-1), and hash is the corresponding hash value, in the range [0,1). The tuples are sorted by increasing hash value. The class has a single instance method, get_machine(key), which returns the number of the machine to which key should be mapped.''' def __init__(self, num_machines=1, num_replicas=1): self.num_machines = num_machines self.num_replicas = num_replicas hash_tuples = [(j, k, my_hash(str(j) + "_" + str(k))) \ for j in range(self.num_machines) \ for k in range(self.num_replicas)] # Sort the hash tuples based on just the hash values hash_tuples.sort(lambda x, y: cmp(x[2], y[2])) self.hash_tuples = hash_tuples def get_machine(self, key): '''Returns the number of the machine which key gets sent to.''' h = my_hash(key) # edge case where we cycle past hash value of 1 and back to 0. if h &gt; self.hash_tuples[-1][2]: return self.hash_tuples[0][0] hash_values = map(lambda x: x[2], self.hash_tuples) index = bisect.bisect_left(hash_values, h) return self.hash_tuples[index][0]def my_hash(key): '''my_hash(key) returns a hash in the range [0,1).''' return (int(hashlib.md5(key).hexdigest(), 16) % 1000000) / 1000000.0def main(): ch = ConsistentHash(7, 3) print "Format:" print "(machine,replica,hash value):" for (j, k, h) in ch.hash_tuples: print "(%s,%s,%s)" % (j, k, h) while True: print "\nPlease enter a key:" key = raw_input() print "\nKey %s maps to hash %s, and so to machine %s" \ % (key, my_hash(key), ch.get_machine(key)) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import bisectimport md5class ConsistentHashRing(object): """Implement a consistent hashing ring.""" def __init__(self, replicas=100): """Create a new ConsistentHashRing. :param replicas: number of replicas. """ self.replicas = replicas self._keys = [] self._nodes = &#123;&#125; def _hash(self, key): """Given a string key, return a hash value.""" return long(md5.md5(key).hexdigest(), 16) def _repl_iterator(self, nodename): """Given a node name, return an iterable of replica hashes.""" return (self._hash("%s:%s" % (nodename, i)) for i in xrange(self.replicas)) def __setitem__(self, nodename, node): """Add a node, given its name. The given nodename is hashed among the number of replicas. """ for hash_ in self._repl_iterator(nodename): if hash_ in self._nodes: raise ValueError("Node name %r is " "already present" % nodename) self._nodes[hash_] = node bisect.insort(self._keys, hash_) def __delitem__(self, nodename): """Remove a node, given its name.""" for hash_ in self._repl_iterator(nodename): # will raise KeyError for nonexistent node name del self._nodes[hash_] index = bisect.bisect_left(self._keys, hash_) del self._keys[index] def __getitem__(self, key): """Return a node, given a key. The node replica with a hash value nearest but not less than that of the given name is returned. If the hash of the given name is greater than the greatest hash, returns the lowest hashed node. """ hash_ = self._hash(key) start = bisect.bisect(self._keys, hash_) if start == len(self._keys): start = 0 return self._nodes[self._keys[start]] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.2 haproxy 配置]]></title>
    <url>%2F2018%2F10%2F23%2Flinux_mt%2F31-haproxy%2Fhaproxy%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[haproxy 配置 本节开始我们来学习 haproxy 的配置。haproxy 有众多的配置选项，我打算将其分为两个部分，第一部分为haproxy 的全局配置，以及常用的代理段配置，第二部分为 haproxy 的访问控制。本节为的一部分，内容包括 global 全局配置 进程及安全管理 性能调整 代理段配置 前端服务配置 后端主机配置 haproxy 状态统计及管理页面配置 自定义错误页 首部处理 日志配置 1. global配置参数1.1 进程及安全管理123456789global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon deamon 作用: 以后端服务的方式运行 haproxy log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [max level [min level]] 作用: 定义全局的syslog服务器；最多可以定义两个； nbproc &lt;number&gt; 作用: 要启动的haproxy的进程数量 默认: 启动一个进程，无需修改 ulimit-n &lt;number&gt; 作用: 每个haproxy进程可打开的最大文件数 默认: haproxy 会自动调整，无需配置 1.2 性能调整:maxconn &lt;number&gt; 作用: 设定每个haproxy进程所能接受的最大并发连接数； maxsslconn &lt;number&gt; 作用: 设定每个haproxy进程所能接受的最大 sll 并发连接数； maxconnrate &lt;number&gt; 作用: 设定每个进程每秒种所能创建的最大连接数量； maxsessrate &lt;number&gt; 作用: 设定每个进程每秒种所能创建的最大会话数量； spread-checks &lt;0..50, in percent&gt; 作用: 设置后端服务器状态检测的速率偏斜，以免同时对所有后端主机进行状态检测，占用太多带宽 2. 代理配置段与 nginx 类似，代理配置段内的参数有受限的应用范围，下面是常用的配置参数 2.1 前端服务配置modemode { tcp|http|health } 作用: 定义haproxy的工作模式； 参数: tcp: 基于layer4实现代理；可代理mysql, pgsql, ssh, ssl等协议； http: 仅当代理的协议为http时使用； health: 工作为健康状态检查的响应模式，当连接请求到达时回应“OK”后即断开连接； 123456listen ssh bind :22022 balance leastconn mode tcp server sshsrv1 172.16.100.6:22 check server sshsrv2 172.16.100.7:22 check bindbind [&lt;address&gt;]:&lt;port_range&gt; [, ...] [param*] 作用: 定义前端服务监听的地址和端口 1234listen http_proxy bind :80,:443 # 监听多个端口 bind 10.0.0.1:10080,10.0.0.1:10443 bind /var/run/ssl-frontend.sock user root mode 600 accept-proxy # 监听本地 sock default_backenddefault_backend &lt;backend&gt; 作用: 设定默认的backend，用于frontend中 maxconnmaxconn &lt;conns&gt;: 作用: 为指定的frontend定义其最大并发连接数；默认为2000； 说明: 如果未设置，会继承 global 中的配置 2.2 后端主机配置balancebalance &lt;algorithm&gt; [ &lt;arguments&gt; ]balance url_param &lt;param&gt; [check_post] 作用: 定义后端服务器组内的服务器调度算法 algorithm: 算法 roundrobin: 动态算法, 支持权重的运行时调整，支持慢启动 每个后端中最多支持4095个server； static-rr: 静态算法，不支持权重的运行时调整及慢启动 后端主机数量无上限； leastconn: 推荐使用在具有较长会话的场景中，例如MySQL、LDAP等； first: 根据服务器在列表中的位置，自上而下进行调度； 前面服务器的连接数达到上限，新请求才会分配给下一台服务； source: 源地址hash，hash 算法下面的 hash-type 选项指定 hash-type map-based:除权取余法，这种方法不支持权重的运行时调整，也不支持慢启动，但资源耗费少 hash-type consistent: 一致性哈希，支持权重运行时调整，也支持慢启动，但是资源耗费多 uri: 目标地址 hash，对URI的左半部分做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 完整 url: `://:@:/;?#`` 左半部分: /&lt;path&gt;;&lt;params&gt; 整个uri: /&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; url_param: 对用户请求的uri的 &lt;params&gt;中的部分的参数的值作hash计算 hash 算法可由 hash-type 指定，默认是 map-based 通常用于追踪用户，以确保来自同一个用户的请求始终发往同一个Backend Server hdr(&lt;name&gt;): 对于每个http请求，此处由&lt;name&gt;指定的http首部将会被取出做hash计算 hash 算法可由 hash-type 指定，默认是 map-based 没有有效值的会被轮询调度； eg: hdr(Cookie) hash-typehash-type &lt;method&gt; &lt;function&gt; &lt;modifier&gt; 作用: 指定 hash 计算的算法 method: map-based: 除权取余法，哈希数据结构是静态的数组； consistent: 一致性哈希，哈希数据结构是一个树； function: 哈希函数，eg: sdbm, djb2, wt6 default-serverdefault-server [param*] 作用: 为backend中的各server设定默认选项 选项: 同 serve serverserver &lt;name&gt; &lt;address&gt;[:[port]] [param*] 作用: 定义后端主机的各服务器及其选项； name: 服务器在haproxy上的内部名称；出现在日志及警告信息 address: 服务器地址，支持使用主机名； [:[port]]: 端口映射；省略时，表示同bind中绑定的端口； [param*]: 参数 maxconn &lt;maxconn&gt;: 当前server的最大并发连接数； backlog &lt;backlog&gt;: 当前server的连接数达到上限后的后援队列长度； backup: 设定当前server为备用服务器； check: 对当前server做健康状态检测； addr : 检测时使用的IP地址； port : 针对此端口进行检测； inter &lt;delay&gt;: 连续两次检测之间的时间间隔，默认为2000ms; rise &lt;count&gt;: 连续多少次检测结果为“成功”才标记服务器为可用；默认为2； fall &lt;count&gt;: 连续多少次检测结果为“失败”才标记服务器为不可用；默认为3； 注意: httpchk，”smtpchk”, “mysql-check”, “pgsql-check” and “ssl-hello-chk” 用于定义应用层检测方法； cookie &lt;value&gt;: 为当前server指定其cookie值，用于实现基于cookie的会话黏性； disabled: 标记为不可用； redir &lt;prefix&gt;: 将发往此server的所有GET和HEAD类的请求重定向至指定的URL； weight &lt;weight&gt;: 权重，默认为1; cookiecookie &lt;name&gt; options 作用: 启用基于 cookie 的用户绑定 参数: &lt;name&gt; 待操作的 cookie 的键 选项: rewirte: 重写 insert: 插入 prefix: 前缀 nocache: 只对非从缓存中响应的值进行操作 indirect: 如果对应的cookie 键已经存在值，则不修改直接发送给客户端 说明: cookie 的值有 server cookie&lt;value&gt; 配置 123456# 基于cookie的session sticky的实现:backend websrvs cookie WEBSRV insert nocache indirect server srv1 172.16.100.6:80 weight 2 check rise 1 fall 2 maxconn 3000 cookie srv1 server srv2 172.16.100.7:80 weight 1 check rise 1 fall 2 maxconn 3000 cookie srv2 ` 2.3 健康状态检测option httpchkoption httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt; 作用: 对后端服务器做http协议的健康状态检测,基于http协议的7层健康状态检测机制； 参数: uri: 指定检测的链接 method: 指定检测使用的请求方法 version: 指定发送的 http 的协议版本 1234backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www server apache1 192.168.1.1:443 check port 80 http-check expecthttp-check expect [!] &lt;match&gt; &lt;pattern&gt; 作用: 指定健康状态检测的内容 [!]: 表示取反操作 match: status: 完全匹配响应码 rstatus: 以正则表达式匹配响应码 string: 完全匹配响应内容 rstring: 以正则表达式匹配响应内容 pattern: 字符串或正则表达式，表示 match 指定的选项要匹配的内容 1234567http-check expect status 200http-check expect ! string SQL\ Errorhttp-check expect ! rstatus ^5# check that we have a correct hexadecimal tag before /htmlhttp-check expect rstring &lt;!--tag:[0-9a-f]*&lt;/html&gt; 2.4 统计接口stats enable 作用: 启用统计页；基于默认的参数启用stats page； 默认启用参数: stats uri : /haproxy?stats stats realm : “HAProxy Statistics” stats auth : no authentication stats scope : no restriction stats auth &lt;user&gt;:&lt;passwd&gt; 作用: 认证时的账号和密码，可使用多次； stats realm &lt;realm&gt; 作用: 认证时的realm； `stats uri `` 作用: 自定义stats page uri stats refresh &lt;delay&gt; 作用: 设定自动刷新时间间隔； stats admin { if | unless } &lt;cond&gt; 作用: 启用stats page中的管理功能 stats hide-version 作用: 隐藏页面的有关 haproxy 的版本信息 1234567# 配置示例:listen stats bind :9099 stats enable stats realm HAPorxy\ Stats\ Page stats auth admin:admin stats admin if TRUE 2.5 自定义错误页errorfileerrorfile &lt;code&gt; &lt;file&gt; 作用: 自定义错误响应页，响应页的内容由文件指定 &lt;code&gt;: HTTP 响应码， HAProxy 目前支持自定义 200, 400, 403, 408, 500, 502, 503, and 504 &lt;file&gt;: 响应内容所在的位置 1234errorfile 400 /etc/haproxy/errorfiles/400badreq.httperrorfile 408 /dev/null # workaround Chrome pre-connect bugerrorfile 403 /etc/haproxy/errorfiles/403forbid.httperrorfile 503 /etc/haproxy/errorfiles/503sorry.http errorloc &lt;code&gt; &lt;url&gt;errorloc302 &lt;code&gt; &lt;url&gt;errorloc303 &lt;code&gt; &lt;url&gt; 作用: 自定义错误响应页，错误页的内容由 url 指定 说明: errorloc302/303 会以 302/303 响应码响应客户端而不是原本的响应码 2.6 首部处理option forwardforoption forwardfor [except &lt;network&gt;] [header &lt;name&gt;] [if-none] 作用: 用于向后端主发送真实的客户端IP 在由haproxy发往后端主机的请求报文中添加X-Forwarded-For首部，其值为前端客户端的地址 选项: [except &lt;network&gt;]: 请求报文来自此处指定的网络时不予添加此首部； [header &lt;name&gt; ]: 使用自定义的首部名称，而非X-Forwarded-For [if-none]: 只在不存在 X-Forwarded-For 时才添加此报文首部 reqadd/rspaddreqadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 作用: 向发送给后端服务器的请求添加首部字段 rspadd &lt;string&gt; [{if | unless} &lt;cond&gt;] 作用: 向发送给客户端响应中添加首部字段 eg: rspadd X-Via: HAPorxy reqdel &lt;search&gt; [{if | unless} &lt;cond&gt;]reqidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 作用: 删除正则表达式匹配到的，发往后端服务器的请求的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: reqidel 表示在进行正则表达式匹配时不区分大小写 rspdel &lt;search&gt; [{if | unless} &lt;cond&gt;]rspidel &lt;search&gt; [{if | unless} &lt;cond&gt;] 作用: 删除正则表达式匹配到的，发往客户端的的响应的的首部字段 参数: search 正则表达式，用于匹配首部字段及其值 说明: rspidel 表示在进行正则表达式匹配时不区分大小写 12345# remove X-Forwarded-For header and SERVER cookiereqidel ^X-Forwarded-For:.*reqidel ^Cookie:.*SERVER=rspidel ^Server:.* 2.7 日志系统loglog global 作用: 从 global 全局配置段继承日志配置 no log 作用: 不记录日志 log &lt;address&gt; [len &lt;length&gt;] &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]] 作用: 自定义日志记录 注意: 一个配置段内，log 日志记录只能使用两次，如果使用log global，并且global 配置了两次log，算作两次 12345# 注意：默认发往本机的日志服务器，配置如下vim /etc/rsyslog.conflocal2.* /var/log/local2.log$ModLoad imudp$UDPServerRun 514 log-formatlog-format &lt;string&gt; 作用: 自定义日志记录格式 capturecapture cookie &lt;name&gt; len &lt;length&gt; 作用: 提取并记录请求和响应的 cookie 中特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 capture request header &lt;name&gt; len &lt;length&gt; 作用: 提取并记录请求首部特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 capture response header &lt;name&gt; len &lt;length&gt; 作用: 提取并记录响应首部特定字段的值 参数: &lt;name&gt;: 指定的首部字段 len &lt;length&gt;: 最大记录的长度 123capture request header Host len 15capture request header X-Forwarded-For len 15capture request header Referer len 15 2.8 压缩功能compression algocompression algo &lt;algorithm&gt; 作用：启用http协议的压缩机制，指明压缩算法gzip, deflate； compression typecompression type &lt;mime type&gt; 作用: 指明压缩的MIMI类型； 12compression algo gzipcompression type text/html text/plain 2.9 连接超时时长timeout client &lt;timeout&gt; 作用: 客户端非活动状态的超时时长 timeout server &lt;timeout&gt; 作用: 客户端与服务器端建立连接后，等待服务器端的超时时长， timeout http-keep-alive &lt;timeout&gt; 作用: 持久连接的持久时长； timeout http-request &lt;timeout&gt; 作用: 定义保持连接的超时时长 timeout connect &lt;timeout&gt; 作用: haproxy 连接后端主机的超时时长 timeout client-fin &lt;timeout&gt; 作用: 半关闭状态连接，client端非活动超时时间 timeout server-fin &lt;timeout&gt; 作用: 半关闭状态连接，server端非活动超时时间]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 散列表与链表]]></title>
    <url>%2F2018%2F10%2F22%2Falog%2Fhash_list%2F</url>
    <content type="text"><![CDATA[“形影不离”的散列表与链表 1. 特性散列表和链表，经常会被放在一起使用。原因是散列表虽然支持高效的数据插入、删除、查找操作，但是散列后的数据都是无序存储的，无法支持按照某种顺序快速地遍历数据。散列表是动态的数据结构，如果每次按序访问都要拷贝到数组，排序然后在遍历，效率太低了。而支持动态创建的链表刚好能解决散列表的有序遍历问题。 2. 散列表的实现在讲解散列表与链表的应用之前，我们先来解决上一篇文章遗漏的散列表的实现问题。散列表的原理并复杂，但是一个高效的哈希函数可能数学家精心研究的结果。这里我们不弄的太过复杂，我们介绍两种哈希表的实现，一种使用分离链表，另一种使用包含线性探测的开放寻址。 虽然这两种实现解决冲突的方法差异很大，但是也存在很多共性，因此我们基于 MapBase 扩展一个新的 HashMapBase 类。 2.1 HashMapBase123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657from abc import abstractmethodfrom random import randrangeclass HashMapBase(MapBase): def __init__(self, cap=11, p=109345121): self._table = cap * [None] self._n = 0 # 压缩函数 MAD 的参数 # [(ai + b) mod p] mod N # - N: 散列表内部数组的大小 # - p: 比 N 大的素数 # - a，b 是从区间 [0, p-1] 任意选择的整数，并且 a &gt; 0 self._prime = p # p self._scale = 1 + randrange(p - 1) # a self._shift = randrange(p) # b def _hash_function(self, k): return (hash(k) * self._scale + self._shift) % self._prime % len(self._table) def __len__(self): return self._n def __getitem__(self, k): j = self._hash_function(k) return self._bucket_setitem(j, k) def __setitem__(self, key, value): j = self._hash_function(key) self._bucket_setitem(j, key, value) if self._n &gt; len(self._table) // 2: self._resize(2 * len(self._table) - 1) def __delitem__(self, key): j = self._hash_function(key) self._bucket_delitem(j, key) self._n -= 1 def _resize(self, c): old = list(self.items()) self._table = c * [None] self._n = 0 for k, v in old: self[k] = v @abstractmethod def _bucket_getitem(self, j, k): pass @abstractmethod def _bucket_setitem(self, j, k, v): pass @abstractmethod def _bucket_delitem(self, j, k): pass 2.2 ChainHashMap分离链表法的实现 12345678910111213141516171819202122232425262728class ChainHashMap(HashMapBase): def _bucket_getitem(self, j, k): bucket = self._table[j] if bucket is None: raise KeyError('Key error' + repr(k)) return bucket[k] def _bucket_setitem(self, j, k, v): if self._table[j] is None: # 可以使用链表，红黑树，跳表优化, # 示例使用的是 &lt;11 映射&gt; 实现的 UnsortedTableMap self._table[j] = UnsortedTableMap() oldsize = len(self._table[j]) self._table[j][k] = v if len(self._table[j]) &gt; oldsize: self._n += 1 def _bucket_delitem(self, j, k): bucket = self._table[j] if bucket is None: raise KeyError('Key error' + repr(k)) del bucket[k] def __iter__(self): for bucket in self._table: if bucket is not None: for key in bucket: yield key 2.3 ProbeHashMap线性探测的开放寻址法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class ProbeHashMap(HashMapBase): # 标记删除的哨兵 _AVAIL = object() def _is_available(self, j): return self._table[j] is None or self._table[j] is ProbeHashMap._AVAIL def _find_slot(self, j, k): # 位置探测 first_avail = None while True: if self._is_available(j): if first_avail is None: first_avail = j # 查找失败，探测到的第一个空位置 if self._table[j] is None: return False, first_avail # 查找成功，元素 k 的位置 elif k == self._table[j]._key: return True, j j = (j + 1) % len(self._table) def _bucket_getitem(self, j, k): found, s = self._find_slot(j, k) if not found: raise KeyError('Key error' + repr(k)) return self._table[s]._value def _bucket_setitem(self, j, k, v): found, s = self._find_slot(j, k) if not found: self._table[s] = self._Item(k, v) self._n += 1 else: self._table[s]._value = v def _bucket_delitem(self, j, k): found, s = self._find_slot(j, k) if not found: raise KeyError('Key error' + repr(k)) self._table[s] = self._AVAIL def __iter__(self): for j in range(len(self._table)): if not self._is_available(j): yield self._table[j]._key 3. 散列表与链表3.1 LRU 缓存淘汰算法借助于散列表和链表可以实现时间复杂度降为 O(1)的 LRU 缓存淘汰算法。这里我们使用 Python 内置的 dict 与 链表一章实现的 DoubleLink。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class LRU(object): def __init__(self, capacity=3): assert capacity &lt;= 0 self.capacity = capacity self.num = 0 self.link = DoubleLink() self.node_mp = &#123;&#125; def _re_cache(self, value): """ :return: 值存在更新缓存 """ if value in self.node_mp: node = self.node_mp[value] self.link.delete_node(node) self.node_mp[value] = self.link.insert_head(value) return True return False def cache(self, value): if not self._re_cache(value): if self.num &lt; self.capacity: # 缓存未满 self.node_mp[value] = self.link.insert_head(value) self.num += 1 else: # 缓存满 node_tail = self.link._tail._pre del self.node_mp[node_tail._element] self.link.delete_node(node_tail) self.node_mp[value] = self.link.insert_head(value) def __str__(self): r = [] s = self.link._head._next while s != self.link._tail: r.append(str(s._element)) s = s._next return '--&gt;'.join(r)lru = LRU()lru.cache(1)lru.cache(2)lru.cache(3)print lrulru.cache(1)print lrulru.cache(1)print lrulru.cache(4)print lru 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[28.1 haproxy 入门]]></title>
    <url>%2F2018%2F10%2F22%2Flinux_mt%2F31-haproxy%2Fhaproxy%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[haproxy 入门 本章我们来介绍负载均衡集群的另一种实现 haproxy。与 nginx 类似，haproxy 工作于应用层属于七层代理，但是在其 tcp 模式下也能模拟实现四层代理。本章我们就来学习如何使用 haproxy。在学习配置 haproxy 之前我们先来对其做个简单了解，看看其程序与配置文件结构。 1. haproxy 简介1.1 主站与文档对于 haproxy 介绍和性能优势这里就不多介绍，推荐大家多看看 haproxy 的主页和官方文档，特别是官方文档 主站: http://www.haproxy.org http://www.haproxy.com 文档: http://cbonte.github.io/haproxy-dconv/ 1.2 程序结构haproxy 已经被收录至 yum 的 base 仓库，可直接安装，下面是 rpm 包的程序结构1234567891011121314151617181920$ rpm -ql haproxy|egrep -v &quot;(doc|man)&quot;/etc/haproxy/etc/haproxy/haproxy.cfg # 主配置文件/usr/sbin/haproxy # 主程序/usr/sbin/haproxy-systemd-wrapper/usr/bin/halog # 辅助工具/usr/bin/iprange/usr/lib/systemd/system/haproxy.service # Unit file/etc/sysconfig/haproxy # Unit file 的配置文件 /usr/share/haproxy # 错误页/usr/share/haproxy/400.http/usr/share/haproxy/403.http/usr/share/haproxy/408.http/usr/share/haproxy/500.http/usr/share/haproxy/502.http/usr/share/haproxy/503.http/usr/share/haproxy/504.http/usr/share/haproxy/README/var/lib/haproxy/etc/logrotate.d/haproxy 1.3 配置文件结构1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#---------------------------------------------------------------------# Global settings#---------------------------------------------------------------------global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the &apos;listen&apos; and &apos;backend&apos; sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------frontend main *:80 default_backend app#---------------------------------------------------------------------# static backend for serving up images, stylesheets and such#---------------------------------------------------------------------backend app balance roundrobin server py 127.0.0.1:8888 check haproxy 的配置分成两大配置段 global：全局配置段，用于定义 进程及安全配置相关的参数 性能调整相关参数 Debug参数 proxies：代理配置段，包括四小配置段 defaults：为frontend, listen, backend提供默认配置； fronted：定义前端监听的服务，相当于nginx, server {} backend：定义后端服务器组，相当于nginx, upstream {} listen：后端服务器组与前端服务一一对应时的便捷配置方式，可同时定义前端与后端 1.4 haproxy 简单配置示例下面是两个配置示例，我们会在下一节详细介绍 haproxy 各个重要配置选项。123456789101112frontend web bind *:80 default_backend websrvsbackend websrvs balance roundrobin # 定义调度算法 server srv1 172.16.100.6:80 check server srv2 172.16.100.7:80 check listen http-in # listen 同时定义前后端 bind *:3306 server server1 127.0.0.1:3396 maxconn 32]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 散列表]]></title>
    <url>%2F2018%2F10%2F21%2Falog%2Fhash_map%2F</url>
    <content type="text"><![CDATA[散列表原理 1. 特性散列表是数组的一种扩展，利用的是数组支持按照下标随机访问的特性，其由三个核心部分组成: key: 元素的键 hash func: 散列函数，将键隐射为底层数组的下标 table: 底层的数组 散列表通过散列函数把元素的键映射为数组的下标来实现在数组中保存和查询元素。在整个散列表的实现中，下面是我们要关注的核心问题： 散列函数设计 散列冲突的解决 装载因子以及散列表的动态扩容 1.1 散列函数散列函数在设计上有三点基本要求: 因为数组下标是从 0 开始的的，所以散列函数计算得到的散列值必需是一个非负整数； 如果 key1 = key2，那 hash(key1) == hash(key2)； 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2) 第三点看起来合情合理，但是要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。因此散列过程中会产生散列冲突。而且数组的存储空间有限，也会加大散列冲突的概率。 1.2 散列冲突常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。 开放寻址法开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。重新探测新的位置有很多方法，常见有线性探测，二次探测和双重散列，我们将其统称为探测函数。散列函数和探测函数一起，确定了元素的一系列可存储位置。 插入过程就是按序探测第一个非空位置并存储 查找过程就是按照相同的探测顺序，逐一比较数组中的元素和要查找的元素直至找到相等元素(找到)或一个空位置(不存在)。 因为数组空闲位置是判断是查找的判定条件，所以不能通过直接将数组元素置空来删除散列表中的元素。我们可以将删除的元素，特殊标记为 deleted。当探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。 不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。 散列表的装载因子 = 填入表中的元素个数 / 散列表的长度 装载因子越大，说明空闲位置越少，冲突越小，散列表的性能越好。 链表法 链表法是一种更加常用的散列冲突解决办法，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。 插入时，通过散列函数计算出对应的散列槽位，将其插入到对应链表中，时间复杂度是 O(1)。 查找、删除时，通过散列函数计算出对应的槽，然后遍历链表查找或者删除。时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。 2. 实现散列表的性能与散列函数，散列冲突和装载因子有关，要想实现一个工业级的散列表就要从这三个因素入手。 2.1 散列函数设计散列函数的设计遵循以下几个要点: 散列函数不能太复杂 散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突 实际工作中，还需要综合考虑包括关键字的长度、特点、分布、还有散列表的大小等在内的各个因素 2.2 装载因子控制对于没有频繁插入和删除的静态数据集合来说，因为数据是已知的，我们可以根据数据的特点、分布等，设计出完美的、极少冲突的散列函数。 对于动态数据集，我们可以动态扩缩容: 装载因子过大时，重新申请一个更大的散列表，动态扩容。 装载因子过小时，可以启动动态缩容。如果我们更加在意执行效率，能够容忍多消耗一点内存空间，也可以不缩容 需要注意的是动态扩缩容时，因为散列表的大小发生了变化，数据存储的位置就变了，所以需要通过散列函数重新计算每个数据的存储位置。在散列表的动态扩容中，装载因子阈值的设置非常重要，太小会导致内存浪费严重，太大会导致冲突过多，要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。 2.3 避免低效扩容动态扩容一个 1G 的散列表依旧很慢，为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个到多个数据放入到新散列表。将扩容过程分散到每次的插入操作中。 2.4 冲突解决方法选择开放寻址法开放寻址法中，散列表的数据都存储在数组中，所以开放寻址法的优点与使用数组类似 可以有效地利用 CPU 缓存加快查询速度 序列化起来比较简单。 但是缺点也很明显: 删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据 所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。 使用开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。所以比起链表法更浪费内存空间。当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的 ThreadLocalMap使用开放寻址法解决散列冲突的原因. 链表法链表法利用的是链表这种离散的内存空间，因此 对内存的利用率更高。因为链表结点可以在需要的时候再创建，无需像开放寻址法那样事先申请好 对大装载因子的容忍度更高。对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。 但是缺点也很明显，链表对于存储小的数据会浪费很多空间(指针的存在)，离散的内存分布也无法利用 CPU 的缓存加速。 链表法中的链表可以改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。 所以基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。 2.5 java 的 HashMap我们以 java 中的 HashMap 来说一说如何实现一个工业及的散列表: 初始大小: HashMap 默认的初始大小是 16，这个默认值是可以设置的 装载因子和动态扩容: HashMap 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。 散列冲突解决: HashMap 底层采用链表法，在 JDK1.8 版本中引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表 3. Python 的 dict上面我们介绍了散列表的实现原理，但是实现一个工业及的散列表是在大量数学和实验的基础上实现的。因为我主要用的还是 Python ，因此我就以 Python 中的dict 实现来介绍当前工业级的散列表的最佳实践，并着手实现一个简单的散列表。 3.1 散列函数Python 中的散列函数通常有两个部分组成: 哈希码: 将一个键映射到一个整数 压缩函数: 将哈希码映射到散列表内部数组的索引 这么做的目的是将哈希码的计算与具体的散列表大小相独立，这样就可以为每个对象开发一个通用的哈希码，并且可以用于任意大小的散列表，只有压缩函数与散列表的大小有关。 3.2 哈希码不同对象的哈希码有如下几种实现方式: 对于数值类型的对象，我们可以简单的把用于表示数值 X 的各个位所表示的值作为它的哈希码。如果数值的位数超过哈希码的长度，比如将 64 位浮点数哈希为 32 位的整数，可以对前后 32 求和或做异或处理 对于字符串或元组形式表示的可变长度对象，通常使用多项式哈希和循环移位哈希，这两种方式都会考虑字符串中字符的位置 多项式哈希码的计算方式如下，其中 i 表示字符串中第 i 个字符，a 是非 0 常数。在处理英文字符串时 33，37，39，41 是合适 a 值。 1p(t)=x1 + a(x2 + a(x3 + .... + a(xn−1 + axn))) 循环移位的 Python 算法如下，在处理英文字符串时 5 位移动能产生最少的散列冲突。 1234567def hash_code(s): mask = (1 &lt;&lt; 32) - 1 h = 0 for c in s: h = (h &lt;&lt; 5 &amp; mask) | (h &gt;&gt; 27) h += ord(c) return h Python 中的哈希码Python 中只有不可变的数据类型可以哈希，以确保一个对象的生命周期中其哈希码不变。对于字符串 Python 使用类似于多项式哈希码的技术，精心设计了字符串的哈希码，没有使用异或和相加。使用相似的基于元组每个元素的哈希码的组合技术计算元组的哈希码。对于 frozenset 对象，元素的顺序是无关的，因此一个自然的选择是用异或值计算单个哈希码而不用任何移位。 用户自定义对象默认是不可哈希的，除非自定义 __hash__ 内置函数，hash() 函数会调用此方法获取对象的哈希码。通过计算组合属性的哈希码作为自定义对象的哈希码是常见方法。 123def __hash__(): return hash(self._red, self._green, self._blue) 一个重要的规则是，__eq__ 与 __hash__ 的实现必需一致，即如果x==y，则 hash(x)==hash(y)。比如 hash(1)==hash(1.0) 3.3 压缩函数一个好的压缩函数应该确保两个不同的哈希码映射到相同索引的可能性为 1/N，工业级别最常用的压缩函数是 MAD(Multiply-Add-Divide)。选择这个压缩函数是为了消除在哈希码集合中的重复模式，并且得到更好的哈希函数。 1234[(ai + b) mod p] mod N- N: 散列表内部数组的大小- p: 比 N 大的素数- a，b 是从区间 [0, p-1] 任意选择的整数，并且 a &gt; 0 3.4 散列冲突处理散列冲突解决方案中的开放寻址法，有多个变种。常见的包括线性探测，二次探测，双哈希策略。Python 中采用的是迭代地探测桶。这种方法下散列表的负载因子可以达到 2/3。12345# 迭代地探测桶A[(h(k) + f(i)) mod N]- h(k): 哈希码- f(i): 基于伪随机数产生器的函数，它提供一个基于原始哈希码位的可重复的但是随机 的，连续的地址探测序列 4. 散列表的简单实现作为散列表实现的简单示例，我们将介绍散列表的两种实现，链表法和线性探测的开放寻址法。限于篇幅，我们把这部分内容放到下一篇文章来讲解。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.6 varnish 日志查看]]></title>
    <url>%2F2018%2F10%2F21%2Flinux_mt%2F30-varnish%2Fvarnish%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[varnish 日志查看 varnish 的日志存放在特定的内存区域中，分为计数器和日志信息两个部分，查看日志需要专门的工具。本节我们来学习这部分命令的使用。 1. varnishstatvarnishstat options 作用: 显示 varnish 缓存的计数器 选项: -1: 一次输出所有统计计数 -f field_list: 列出特定的统计字段，field 支持通配符， ^ 开头表示取反 -l: 列出可供 -f 选择的所有字段 -n varnish_name: 从哪个 varnish 实例获取日志 -V: 显示 varnish 的版本信息 -w delay: 间隔输出，可结合-1, -x , -j 使用 -x: 以 xml 格式输出 -j: 以 json 格式输出 12varnishstat -1 -f MAIN.cache_hit -f MAIN.cache_missvarnishstat -l -f MAIN -f MEMPOOL 2. varnishtopvarnishtop options 作用: 对 varnish 日志排序后输出 选项: [-1]: 运行一次，输出所有日志排序后的结果 [-b]: Only display backend records [-c]: Only display client records [-f]: First field only [-i taglist]: Include tags [-I &lt;[taglist:]:regex&gt;]: Include by regex [-x taglist]: Exclude tags [-X &lt;[taglist:]:regex&gt;]: Exclude by regex [-V]: Version 3. varnishlogvarnishlog options 作用: 显示 varnish 日志 4. varnishncsavarnishncsa 作用: 以类似 httpd combined 格式显示 varnish 日志 5. 日志记录服务varnish 的日志只会记录在内存中，空间不够用时，新的日志就会覆盖老的日志。因此需要定期执行 varnishlog 或 varnishncsa 保存日志。yum 安装已经自动为我们配置了 Unit file，启用下面两个服务之一即可: /usr/lib/systemd/system/varnishlog.service /usr/lib/systemd/system/varnishncsa.service]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 跳表]]></title>
    <url>%2F2018%2F10%2F20%2Falog%2Fskip_list%2F</url>
    <content type="text"><![CDATA[跳表: 链表上的“二分查找” 1. 特性跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。实现上跳表使用空间换时间的思想，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。 1.1 跳表的结构跳表就是在有序链表的基础上添加了多层”索引”。通过每隔几个节点提取一个节点形成上层索引，每层索引的节点个数成等比数列分布，从顶向下的每次查询都会将查询区间“折半”，从而达到 O(logN) 的时间复杂度。每次查询对查询区间的缩减取决于索引构建策略，通过改变索引构建策略，有效平衡执行效率和内存消耗。待会我们会看到更加具体的分析过程。 跳表是一种各方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树。Redis 中的有序集合（Sorted Set）就是在跳表的基础上实现的。 1.2 跳表的查找假设我们每隔两个节点构建一层索引，最上层有两个节点，总共有 N 个节点。则第 h 层的节点个数为 N/2^h，包含最底层的链表在内总共有 logN 层。如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。对于每隔两个节点构建的索引 m=3。 原因是，假设我们要查找的数据是 x，在第 k 级索引中，我们遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以我们通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以，我们在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。 所以在跳表中查询任意数据的时间复杂度就是 O(logn)。而整个跳表需要额外添加的节点数为n/2+n/4+n/8…+8+4+2=n-2，所以空间复杂度为 O(n)。 如果我们每三个结点或五个结点，抽一个结点到上级索引。总的索引结点大约就是 n/3+n/9+n/27+…+9+3+1=n/2，而查询时间复杂度的系数就会从 3 变成 4。因此通过改变索引构建策略，有效平衡执行效率和内存消耗。 1.3 跳表的插入跳表的插入有两个要点: 要保证原始链表中数据的有序性 要维护索引与原始链表大小之间的平衡，避免复杂度退化 因此在插入前需要先找到插入位置，然后通过一个随机函数，来决定将这个结点插入到哪几级索引中。整个过程的时间复杂度= O(logn)(查找) + O(1)(链表的插入) 1.4 跳表的删除删除的过程只是在查找的基础上多了链表的删除操作，对于双向链表而言删除的时间复杂度也是 O(logn)。需要注意的是删除的节点也可能出现在索引中，需要一并删除。 1.5 跳表与红黑树跳表和红黑树都是非常高效的动态数据结构，在插入、删除、查找以及迭代输出有序序列上，时间复杂度都是 O(logn)。但是存在以下不同: 按照区间来查找数据，跳表比红黑树更加高效，跳表可以在 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历即可 相对于红黑树跳表更加简单灵活，通过改变索引构建策略，可以有效平衡执行效率和内存消耗 红黑树出现的更早，很多编程语言中的 Map 类型都是通过红黑树实现的。可以直接拿来用，但是跳表并没有一个现成的实现，想要使用必须自己实现。 2. 实现跳表的实现有以下几个关键点: SkipNode 表示调表中的一个节点，每个SkipNone都包含一个 next=[SkipNone]: len(next) 就是当前节点的层高 next[i] 表示第 i 层的后继节点 通过随机法，来决定一个节点的层数 无论查找，插入，还是删除，我们都需要获取带查找节点的前驱节点 查找前驱节点，必须从最顶层查找到最底层，因为需要保留每一层的前驱节点 Go 语言中，我们还需要为保存的值实现接口 下面是调表的 Python 与 Go 实现。 2.1 Python 实现下面是 Python 的跳表实现。 12 2.2 Go 实现12 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.5 varnish 后端主机配置]]></title>
    <url>%2F2018%2F10%2F20%2Flinux_mt%2F30-varnish%2Fvarnish%E5%90%8E%E7%AB%AF%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[varnish 后端主机配置 在讲解完 varnish 的缓存配置之后，我们来看看如何配置后端服务器，包括后端服务器组的定义，调度算法，以及健康状态检测。 1. 后端主机配置1.1 定义后端主机定义后端主机使用 backend 关键字，在定义主机的同时，我们可以设置后端主机的多项属性。 123456789backend BE_NAME &#123; .host = .port = .probe = # 指定健康状态检测方法 .connect_timeout = 0.5s; .first_byte_timeout = 20s; .between_bytes_timeout = 5s; .max_connections = 50;&#125; 1.2 读写分离123456789101112131415161718192021# 定义后端主机backend default &#123; .host = &quot;172.16.100.6&quot;; .port = &quot;80&quot;;&#125;backend appsrv &#123; .host = &quot;172.16.100.7&quot;; .port = &quot;80&quot;;&#125;# 对后端主机进行读写分离sub vcl_recv &#123; if (req.url ~ &quot;(?i)\.php$&quot;) &#123; set req.backend_hint = appsrv; &#125; else &#123; set req.backend_hint = default; &#125; ...&#125; 1.2 定义服务器组定义后端服务器组，并配置调度算法需要导入 varnish 的 Director 模块，使用 import directors； 12345678910111213141516171819202122232425262728293031323334353637# 1. 导入模块import directors; # load the directors# 2. 定义后端主机backend server1 &#123; .host = .port =&#125;backend server2 &#123; .host = .port =&#125;# 3. 服务器组定义，并指定调度算法sub vcl_init &#123; new GROUP_NAME = directors.round_robin(); GROUP_NAME.add_backend(server1); GROUP_NAME.add_backend(server2);&#125;# 4. 使用服务器组sub vcl_recv &#123; # send all traffic to the bar director: set req.backend_hint = GROUP_NAME.backend();&#125;# 5. 基于cookie的session sticky：sub vcl_init &#123; new h = directors.hash(); h.add_backend(one, 1); // backend &apos;one&apos; with weight &apos;1&apos; h.add_backend(two, 1); // backend &apos;two&apos; with weight &apos;1&apos;&#125;sub vcl_recv &#123; // pick a backend based on the cookie header of the client set req.backend_hint = h.backend(req.http.cookie);&#125; 1.3 健康状态检测后端服务器的健康状态检测有两种方式 使用专用 probe 关键词，定义检测方式，可复用 在使用 backend 定义后端主机时通过 .probe 单独指定 probe 配置参数12345678910111213probe PB_NAME &#123; .url ：检测时要请求的URL，默认为”/&quot;; .request ：发出的具体请求； .request = &quot;GET /.healthtest.html HTTP/1.1&quot; &quot;Host: www.magedu.com&quot; &quot;Connection: close&quot; .window ：基于最近的多少次检查来判断其健康状态； .threshold ：最近.window次检查中至有.threshhold定义的次数是成功的； .interval ：检测频度； .timeout ：超时时长； .expected_response ：期望的响应码，默认为200；&#125; 示例12345678910111213141516171819202122232425probe check &#123; .url = &quot;/.healthcheck.html&quot;; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s;&#125;backend default &#123; .host = &quot;10.1.0.68&quot;; .port = &quot;80&quot;; .probe = &#123; .url = &quot;/.healthcheck.html&quot;; .window = 5; .threshold = 4; .interval = 2s; .timeout = 1s; &#125;&#125;backend appsrv &#123; .host = &quot;10.1.0.69&quot;; .port = &quot;80&quot;; .probe = check;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 二分查找]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fbinary_search%2F</url>
    <content type="text"><![CDATA[不简单的简单二分查找 1. 特性二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。 二分查找看似简单，但是二分查找的变体一点都不简单，“你”经常看到的二分查找其实是最简单的二分查找即: 有序数组中不存在重复元素，通过二分查找值等于给定值的数据。注意不重复和等于，这里存在很多的变体。 其次二分查找存在很大的局限性: 二分查找依赖的是顺序表结构，简单点说就是数组。 主要原因是二分查找算法需要按照下标随机访问元素。数组按照下标随机访问数据的时间复杂度是 O(1) 如果是链表，随机访问的时间复杂度是 O(n)。如果数据使用链表存储，二分查找的时间复杂就会变得很高。 其他数据结构存储的数据，则无法应用二分查找。 二分查找针对的是有序数据。如果数据没有序，就要先排序。 所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中 针对频繁插入删除的动态数据集合二分查找将不再适，快速查找需要使用二叉树 数据量太大不适合二分查找: 二分查找依赖数组，而数组为了支持随机访问，需要连续的内存空间，对内存的要求苛刻。 要注意数组要求的连续内存意味着即便系统上有零散的 2G 内存也无法申请到连续的 1G 内存。虽然数组对内存要求苛刻，但是同等条件下数组却是最省内存空间的存储方式，因为除了数据本身之外，不需要额外存储其他信息。 1.1 二分查找的变形如果放开不重复和等于的限制，二分查找有很多变形，典型的包括: 查找第一个值等于给定值的元素 查找最后一个值等于给定值的元素 查找第一个大于等于给定值的元素 查找最后一个小于等于给定值的元素 凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。实际上，“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。比如今天讲的这几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。 2. 实现2.1 最简单的二分查找123456789101112def binary_search(A, value): start = 0 end = len(A) - 1 while start &lt;= end: mid = start + ((end -start) &gt;&gt; 1) if A[mid] == value: return mid elif A[mid] &lt; value: start = mid + 1 else: end = mid -1 最简单的二分查找实现中有以下几个需要注意的点: 循环退出条件是 start &lt;= end 不是 start &lt; end 使用 mid=(low+high)/2 对mid取值是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 low+((high-low)&gt;&gt;1)。因为相比除法运算来说，计算机处理位运算要快得多。 start 和 end 的更新，如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致死循环。 2.2 查找第一个值等于给定值的元素12345678910111213def bs_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为第一个出现的值 if mid == 0 or (A[mid-1] != value): return mid end = mid - 1 2.3 查找最后一个值等于给定值的元素12345678910111213def bs_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &lt; value: start = mid + 1 elif A[mid] &gt; value: end = mid - 1 else: # 判断当前 mid 是否为最后一个出现的值 if mid == n or (A[mid + 1] != value): return mid end = mid + 1 2.4 查找第一个大于等于给定值的元素1234567891011def bs_gte_first(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt;= value: # 判断是否为第一个 if mid == 0 or (A[mid - 1] &lt; value): return mid end = mid - 1 else: start = mid + 1 2.5 查找最后一个小于等于给定值的元素1234567891011def bs_lte_end(A, value): start = 0 n = end = len(A) - 1 while start &lt;= end: mid = start + ((end - start) &gt;&gt; 1) if A[mid] &gt; value: end = mid -1 else: # 判断是否为最后一个 if mid == n or (A[mid + 1] &gt; value): return mid start = mid + 1 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 映射]]></title>
    <url>%2F2018%2F10%2F19%2Falog%2Fmap%2F</url>
    <content type="text"><![CDATA[无处不在的映射 1. 映射前面我们讲解了基于数组和链表最基础的数据结构。在继续下面的内容之前，我们先来说一说映射。因为映射与我们接下来的很多数据结构与算法相关。映射可以看作是搜索或查找的扩展，后面介绍的很多数据结构都是为实现快速的增删改查。因此在继续其他数据结构的介绍之前，我想先介绍一下映射的抽象数据类型以及它的常见几种实现方式。 1.1 映射的抽象数据类型抽象基类Python 中使用抽象基类来表达抽象数据类型。如下所示，抽象基类包含两类方法 一是由 abc.abstractmethod 装饰的抽象方法，这些方法必需由继承自抽象基类的子类来提供具体实现 二是在抽象方法基础上定义的具体方法，基类上的具体方法通过继承可以实现最大化代码复用 123456789101112import abcclass ADT(object): __metaclass__ = abc.ABCMeta @abc.abstractmethod def abstract_method(self): pass def specific_method(self): return self.abstract_method() Python 中 映射 map 的 ADT 与 MutableMapping 抽象基类相对应。 映射的抽象方法映射 M 有如下五个抽象方法，这些方法必需由子类提供具体实现: M[k]: 返回键 k 对应的值，键不存在则触发异常，对应 Python __getitem__ M[k]=v: 对应 Python __setitem__ del M[k]: 对应 Python __delitem__ len(M): 对应 Python __len__ iter(M): 迭代映射 M 中的所有键，对应 Python __iter__ 映射的具体方法为了方便其他功能实现，映射包含了如下具体方法，子类通过继承 MutableMapping 可以自动获取: K in M M.get(k, d=None) M.setdefault(k, d) M.pop(k, d=None) M.popitem() M.clear() M.keys() M.values() M.items() M.update(M2) M == M2 M ！= M2 因为这些方法很容易做到见名知意，我就不再一一解释了。 1.2 map 的实现层次map ADT 有众多的实现方式，为了方便代码重用，我们使用如下层次结构 MutableMapping 是 Python 提供的映射的抽象，提供了现成的映射具体方法 MapBase: 继承自 MutableMapping，为自定义的映射类型提供扩展支持 UnsortedMap: 基于未排序数组的映射实现 HashMapBase: 映射的散列表实现 SortedTableMap: 基于二分查找的映射实现 SkipList: 映射的跳表实现 TreeMap: 二叉搜索树木及其变种的映射实现 2. 实现本节我们就以最简单的 UnsortedMap 为例，实现一个最简单的映射。更加高级的实现我们会在后面一一讲解。 2.1 MapBaseMapBase 是我们在 MutableMapping 基础上自定义的抽象基类，它提供了一个 _Item 类用于保存键与值的映射关系。12345678910111213141516171819class MapBase(MutableMapping): class _Item(object): __slots__ = '_key', '_value' def __init__(self, k, v): self._key = k self._value = v def __eq__(self, other): return self._key == other._key def __ne__(self, other): return not (self == other) def __lt__(self, other): return self._key &lt; other._key def __gt__(self, other): return self._key &gt; other._key 2.2 UnsortedMap123456789101112131415161718192021222324252627282930class UnsortedTableMap(MapBase): def __init__(self): self._table = [] def __getitem__(self, k): for item in self._table: if k == item._key: return item._value raise KeyError('Key error' + repr(k)) def __setitem__(self, k, v): for item in self._table: if k == item._key: item._value = v return self._table.append(self._Item(k, v)) def __delitem__(self, k): for j in range(len(self._table)): if k == self._table[j]._key: self._table.pop(j) return raise KeyError('Key error' + repr(k)) def __len__(self): return len(self._table) def __iter__(self): for item in self._table: yield item._key]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.4 varnish缓存策略配置]]></title>
    <url>%2F2018%2F10%2F19%2Flinux_mt%2F30-varnish%2Fvarnish%E7%BC%93%E5%AD%98%E7%AD%96%E7%95%A5%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[varnish缓存策略配置 前面我们讲解了 VCL 的语法，并通过示例讲解了一部分 varnish 缓存的配置。本节我们来看看 varnish 内置的缓存策略，然后着重来看看如何对缓存进行修剪。 1. VCL 域默认配置1.1 vcl_recv12345678910111213141516171819202122232425262728# vcl_recv 默认配置sub vcl_recv &#123; if (req.method == &quot;PRI&quot;) &#123; /* We do not support SPDY or HTTP/2.0 */ return (synth(405)); &#125; if (req.method != &quot;GET&quot; &amp;&amp; req.method != &quot;HEAD&quot; &amp;&amp; req.method != &quot;PUT&quot; &amp;&amp; req.method != &quot;POST&quot; &amp;&amp; req.method != &quot;TRACE&quot; &amp;&amp; req.method != &quot;OPTIONS&quot; &amp;&amp; req.method != &quot;DELETE&quot;) &#123; /* Non-RFC2616 or CONNECT which is weird. */ return (pipe); &#125; if (req.method != &quot;GET&quot; &amp;&amp; req.method != &quot;HEAD&quot;) &#123; /* We only deal with GET and HEAD by default */ return (pass); &#125; if (req.http.Authorization || req.http.Cookie) &#123; /* Not cacheable by default */ return (pass); &#125; return (hash); &#125;&#125; 2. 缓存修剪varnish 让缓存过期有多种方式，最常见的是通过 purge, 和ban purge: 是在 varnish 内置监视一个特殊的 PURGE 请求方法，并对请求的资源进行缓存请求 ban: 可以使用类似 purge 的方式，更常用的实在 varnishadm 内使用正则表达式对特定一组资源进行缓存处理 2.1 使用 purge12345678910111213141516171819# 1. 添加修剪操作的访问控制acl purgers &#123; &quot;127.0.0.0&quot;/8; &quot;10.1.0.0&quot;/16;&#125;# 2. 如何执行修剪，即能执行purge操作sub vcl_purge &#123; return (synth(200,&quot;Purged&quot;));&#125;# 3.何时执行purge操作sub vcl_recv &#123; if (req.method == &quot;PURGE&quot;) &#123; if (!client.ip ~ purgers) &#123; # 访问控制 return(synth(405,&quot;Purging not allowed for &quot; + client.ip)); &#125; return(purge);&#125; 2.2 使用 Banning在 varnishadm 中使用 ban 子命令，可以使用正则表达式批量修剪 command: ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; eg: ban req.url ~ ^/javascripts 在配置文件中定义，使用ban()函数； 12345if (req.method == &quot;BAN&quot;) &#123; ban(&quot;req.http.host == &quot; + req.http.host + &quot; &amp;&amp; req.url == &quot; + req.url); # Throw a synthetic page so the request won&apos;t go to the backend. return(synth(200, &quot;Ban added&quot;));&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 工业级的排序算法]]></title>
    <url>%2F2018%2F10%2F18%2Falog%2Fsort_4%2F</url>
    <content type="text"><![CDATA[实现一个通用的，高效的工业级排序函数 1. 排序算法对比前面我们介绍了最常见最经典的几个排序算法，它们有不同的时间复杂度，空间复杂度与使用情景。那么如何用它们实现一个通用的、高效率的排序函数呢？ 线性排序算法的时间复杂度比较低，但适用场景太过比较特殊，所以几乎不会使用。 为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。 归并排序由于不是原地排序算法，空间复杂度为 O(n)，数剧集大时过于占用内存，所以很少使用。 1.2 快排优化快速排序在最坏情况下的时间复杂度是 O(n2)，原因主要是我们的分区点选择不够合理。有两种比较常用合理的分区算法: 三数取中法: 每间隔某个固定的长度，取数据出来比较，将中间值作为分区点 随机法: 从要排序的区间中，随机选择一个元素作为分区点 此外快速排序是用递归来实现的，递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。 2. 实现2.1 Glibc 的 qsort我们以 Glibc 中的 qsort() 函数为例来说明如何实现一个排序函数: qsort() 会优先使用归并排序来排序输入数据，因为小数据集下，归并排序不会占用多少内存，且排序快 要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序 qsort() 使用“三数取中法”选择分区点 qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决操作系统的堆栈溢出问题 在快速排序的过程中，当排序区间的元素个数小于等于 4 时，qsort() 就退化为插入排序；因为我们前面也讲过，在小规模数据面前，插入排序比递归调用的快排更快 在 qsort() 插入排序的算法实现中，还利用了哨兵技术，来减少判断的次数 2.2 Tim-Sort1pass 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.3 VCL 语法基础]]></title>
    <url>%2F2018%2F10%2F18%2Flinux_mt%2F30-varnish%2FVCL%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[VCL 语法基础 varnish 的缓存配置，使用的是 VCL，一种与 C 类似的域专有类型的配置语言。本节我们先来对 VCL 做一个介绍。 1. VCL 组成与处理流程1.1 VCL 组成1234567891011121314151617181920vcl 4.0;# Default backend definition. Set this to point to your content server.backend default &#123; .host = &quot;127.0.0.1&quot;; .port = &quot;8080&quot;;&#125;sub vcl_recv &#123; # Happens before we check if we have this in cache already. # # Typically you clean up the request here, removing cookies you don&apos;t need, # rewriting the request, etc.&#125;sub vcl_backend_response &#123; # Happens after we have read the response headers from the backend. # # Here you clean the response headers, removing silly Set-Cookie headers # and other mistakes your backend does. VCL 可以看作是在 C 语言基础上二次开发的子语言，保留了 C 语言基本的语法，并额外附加了特性: 首先作为一门语言 VCL 具有变量，赋值，条件判断等基本语法特性，需要额外提醒的是 VCL 没有循环 为了在更高层级上抽象缓存处理逻辑， VCL 在 C 基础上添加了”状态引擎”(state engine) VCL有多个状态引擎，状态之间存在相关性，但状态引擎彼此间互相隔离；每个状态引擎可使用return(x)指明关联至哪个下一级引擎；每个状态引擎对应于vcl文件中的一个配置段，即为 subroutine 1.2 VCL 状态引擎VCL 的状态引擎可以分为三类: Client Side： 作用: 客户端请求的状态引擎 包括: vcl_recv, vcl_pass, vcl_hit, vcl_miss, vcl_pipe, vcl_purge, vcl_synth, vcl_deliver... Backend Side: 作用: 后端服务器响应相关的状态引擎 包括: vcl_backend_fetch, vcl_backend_response, vcl_backend_error 两个特殊的引擎： vcl_init: 在处理任何请求之前要执行的vcl代码：主要用于初始化VMODs； vcl_fini: 所有的请求都已经结束，在vcl配置被丢弃时调用；主要用于清理VMODs； 1.2 VCL 处理流程varnish 已经为状态引擎内置了关联逻辑，这种内在逻辑就是缓存的处理流程。varnish 不同版本缓存处理的流程并不相同，下面是 varnish4.0 流程图。 2. VCL 语法2.1 VCL 基础特性VCL的语法格式： vcl 4.0;: 必需位于开头，表示 VCL 的版本 //, #, /* foo */: 注释; sub sub_name {}: 使用 sub 关键字定义状态域,例如sub vcl_recv { ...} return(sub_name): 用于实现状态引擎转换； 没有循环, 并且受限于引擎的内建变量 VCL 有限状态机 每一个请求都会被单独的线程处理，并且在任何时间都与其他请求无关 return(action); 将请求从当前状态引擎传递到一个新的状态引擎 状态引擎存在逻辑上的关联，但是彼此是相互独立的 内置的 VCL 代码总是被附加自定义的 VCL 代码之后 2.2 三类主要语法1234567891011sub subroutine &#123; ...&#125;if CONDITION &#123; ...&#125; else &#123; ...&#125;return(), hash_data() 2.3 变量内建变量： req.*: 作用: request，表示与客户端发来的请求报文相关的变量 req.http.* 作用: http 首部字段相关变量 eg: `req.http.User-Agent, req.http.Referer, …`` bereq.*： 作用: 由varnish发往后端主机的httpd请求相关； bereq.http.* beresp.*: 由BE主机响应给varnish的响应报文相关； beresp.http.* resp.*: 由varnish响应给client相关； obj.*: 存储在缓存空间中的缓存对象的属性；只读； 123456# obj.hits是内建变量，用于保存某缓存项的从缓存中命中的次数；if (obj.hits&gt;0) &#123; set resp.http.X-Cache = &quot;HIT via &quot; + server.ip;&#125; else &#123; set resp.http.X-Cache = &quot;MISS via &quot; + server.ip;&#125; 变量组 变量 作用 bereq.* bereq.http.HEADERS bereq.request 请求方法； bereq.url 请求的url； bereq.proto 请求的协议版本； bereq.backend 指明要调用的后端主机； req.* req.http.Cookie 客户端的请求报文中Cookie首部的值 req.http.User-Agent ～ 表示使用正则表达式 beresp.* beresp.http.HEADERS beresp.status 响应的状态码 beresp.backend.name BE主机的主机名； beresp.ttl BE主机响应的内容的余下的可缓存时长 resp.* reresp.proto 协议版本 obj.* obj.hits 此对象从缓存中命中的次数 obj.* obj.ttl 对象的ttl值 server.* server.ip server.hostname client.* client.ip 用户自定义变量使用 set, unset 自定义变量和取消变量 2.3 内置操作内置函数常用内置函数: regsub(str, regex, sub): 把str中被regex第一次匹配到字符串替换为sub；主要用于URL Rewrite regsuball(str, regex, sub): 把str中被regex每一次匹配到字符串均替换为sub； ban(boolean expression): Bans所有的其URL可以被此处的regex匹配到的缓存对象； hash_data(input): 指明哈希计算的数据；减少差异，以提升命中率； synth(status,&quot;STRING&quot;)：purge操作； 关键字常见的内置关键子: call subroutine return(action) new set unset 操作符： 判断: ==, !=, ~, &gt;, &gt;=, &lt;, &lt;= 逻辑操作符: &amp;&amp;, ||, ! 变量赋值: = 正则表达式VCL 使用 ~ 表示使用正则表达式。eg: req.url ~ &quot;(?i)^/(login|admin)&quot;, 其中 (?i) 表示不区分字符大小写。 2.4 示例123456789101112131415161718192021222324252627282930# 示例1：强制对某类资源的请求不检查缓存：vcl_recv &#123; if (req.url ~ &quot;(?i)^/(login|admin)&quot;) &#123; return(pass); &#125;&#125;# 示例2：对于特定类型的资源，例如公开的图片等，取消其私有标识，并强行设定其可以由varnish缓存的时长；# 定义在 vcl_backend_response 中vcl_backend_response&#123;； if (beresp.http.cache-control !~ &quot;s-maxage&quot;) &#123; if (bereq.url ~ &quot;(?i)\.(jpg|jpeg|png|gif|css|js)$&quot;) &#123; unset beresp.http.Set-Cookie; set beresp.ttl = 3600s; &#125; &#125;&#125;# 示例 3: 向后端主机传递客户端 IP# 定义在vcl_recv中；vcl_recv&#123; if (req.restarts == 0) &#123; if (req.http.X-Fowarded-For) &#123; set req.http.X-Forwarded-For = req.http.X-Forwarded-For + &quot;,&quot; + client.ip; &#125; else &#123; set req.http.X-Forwarded-For = client.ip; &#125; &#125; &#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 线性排序]]></title>
    <url>%2F2018%2F10%2F17%2Falog%2Fsort_3%2F</url>
    <content type="text"><![CDATA[非基于比较的三个排序算法: 桶排序，计数排序，基数排序 1. 线性排序桶排序、计数排序、基数排序的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。 这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以我们今天学习重点的是掌握这些排序算法的适用场景。 桶排序和计数排序的排序思想是可以对数剧集进行有限分类，都是针对范围不大的数据，将数据划分成不同的桶来实现排序，只不过二者桶的粒度不同。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。 2. 实现2.1 桶排序桶排序的核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。 只要桶的数量接近数据的个数，并且数据在所有桶内分配均匀，桶排序的时间复杂度接近 O(n)。显然桶排序对要排序数据有苛刻的限制: 首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。 其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。 1234567891011121314151617181920from collections import dequedef sort_bucket(S): """ :param S: [(v, item)] :return: """ m = max((i[0] for i in S)) bucket_map = [deque() for i in range(m + 1)] for i in S: bucket = bucket_map[i[0]] bucket.append(i) c = 0 for i in range(m + 1): b = bucket_map[i] while len(b) &gt; 0: S[c] = b.popleft() c += 1 桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。 2.2 计数排序计数排序可视为桶排序的特殊情况，当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。计数排序之所以叫作计数排序，是因为其特殊的通过“计数”进行排序的算法得名的。 1234567891011121314151617def sort_count(S): if len(S) &lt;= 1: return S m = max(S) bucket = [0] * (m + 1) for i in S: bucket[i] += 1 for i in range(1, m + 1): bucket[i] += bucket[i - 1] tmp = [0] * len(S) for i in S: bucket[i] -= 1 tmp[bucket[i]] = i for i in range(len(S)): S[i] = tmp[i] 计数排序只能用在数据范围不大的场景，如果数据范围 k 比要排序的数据 n 大很多，就不适合用排序了。而且，而且计数排序只能用在给非负整数得排序中，如果要排序的数据是其他类型的，要其在不改变相对大小的情况下，转化为非负整数。 2.3 基数排序基数排序的核心是可以将数据分割出独立的“位”来比较，然后按照从低位到高位依次排序，只要每次按位排序的算法是稳定的就可以得到正确的排序。 根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候基数排序的时间复杂度就近似于 O(n)。 显然基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了 123456789101112131415def sort_base(S, num): if len(S) &lt;= 1: return S T = [(0, i) for i in S] for n in range(num): T = [(i[1] // 10 ** n % 10, i[1]) for i in T] sort_bucket(T) print T for i in range(len(S)): S[i] = T[i][1]aa = [43, 41, 31, 57]sort_base(aa, 2)print aa 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.2 varnish 架构及安装]]></title>
    <url>%2F2018%2F10%2F17%2Flinux_mt%2F30-varnish%2Fvarnish%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[varnish 架构及安装 varnish 是 http 缓存服务器的”新星势力”，它与 squid的关系，类似于 httpd 与 nginx。varnish 有个最大的问题是，它的配置文件随着版本的变化变化非常大。本节我们以 4.0 系列的版本来讲解 varnish 的架构，安装和程序组成 1. varnish 基础官网: https://www.varnish-cache.org 1.1 varnish 架构图 varnish 由如下几个部分组成 管理进程(The management process) Varnish主要有两个进程，管理进程和子进程，管理进程负责：管理配置的变更（包括VCL和参数）、编译VCL、监控Varnish运行、初始化Varnish，以及提供命令行接口等。管理进程会每隔几秒钟检查一下子进程，如果发现子进程挂了，会kill掉然后重新启动一个。这些操作都会记录在日志里面，以利于你检查错误。 子进程(The child process) 子进程包括几个不同类型的线程，包括但不限于： Acceptor线程：接受新的连接并代表它们 Worker线程：一个会话一个线程，通常会使用数百个Worker线程 Expiry线程：负责从缓存中清除旧的内容 shared memory log: 为提升性能，日志是直接存放在内存中的，因此需要特定的工具查看和保存 varnishlog varnishncsa varnishstat… 1.2 配置文件组成varnish 的配置文件分成两个部分 varnish 自身的配置，用于配置 varnish 自身的功能和特性 缓存策略配置， 用于配置供 Child/cache 进程使用的缓存策略。其配置接口为 VCL(Varnish Configuration Language)，通过 Management 提供的命令行接口进行配置，需要经过 VCL 编译器和 C 编译器编译，最后生成供 Child/cache 使用的共享对象(Share object) 2. varnish 程序结构1234567891011121314151617181920$ rpm -ql varnish|egrep -v &quot;(man|doc)&quot;/etc/varnish/etc/varnish/default.vcl # 配置各Child/Cache线程的缓存策略；/etc/varnish/varnish.params # 配置varnish服务进程的工作特性，例如监听的地址和端口，缓存机制；/usr/bin/varnishadm # CLI interface/usr/bin/varnishhist # Shared Memory Log交互工具/usr/bin/varnishlog/usr/bin/varnishncsa/usr/bin/varnishstat/usr/bin/varnishtop/usr/bin/varnishtest # 测试工具程序/usr/lib/systemd/system/varnish.service # varnish服务/usr/lib/systemd/system/varnishlog.service # 日志持久的服务/usr/lib/systemd/system/varnishncsa.service/usr/sbin/varnish_reload_vcl # VCL配置文件重载程序：/usr/sbin/varnishd # 主程序/var/lib/varnish/var/log/varnish/run/varnish.pid/etc/logrotate.d/varnish 2.1 varnishdvarnishd [options] 作用: varnish 主程序 配置文件: /etc/varnish/varnish.params 选项: -a address[:port][,address[:port][...]: varnish 监听的地址和端口，默认为6081 -T address[:port]: varnishadm 管理服务监听的地址和端口，默认为6082端口； -s [name=]type[,options]: 定义缓存存储机制； -u user: 运行用户 -g group: 运行用户组 -f config: VCL配置文件； -F：运行于前台； -p param=value：设定运行参数及其值； 可重复使用多次； -r param[,param...]: 设定指定的参数为只读状态； varnish 缓存存储机制varnish 缓存存储机制(Storage Types)，分三种机制通过 -s [name=]type[,options] 指定: malloc[,size]: 内存存储，[,size]用于定义空间大小；重启后所有缓存项失效； file[,path[,size[,granularity]]]: 磁盘文件存储，黑盒；重启后所有缓存项失效； persistent,path,size: 文件存储，黑盒；重启后所有缓存项有效；实验阶段 2.2 varnish_reload_vclvarnish_reload_vcl 作用: 重载vcl配置文件 2.3 varnishadmvarnishadm [-S secretfile] -T [address]:port command [...] 作用: varnish 命令行接口 选项: -S secretfile: 指定链接 varnishadm 服务的密钥文件，通常位于 /etc/varnish/secret -T [address]:port: varnishadm 服务监听的地址和端口 command: varnish 执行命令后则退出，不会进入交互命令行 1234567891011121314151617181920212223242526272829303132333435363738394041$ sudo varnishadm -S /etc/varnish/secret[sudo] tao 的密码：200 -----------------------------Varnish Cache CLI 1.0-----------------------------Linux,3.10.0-862.9.1.el7.x86_64,x86_64,-smalloc,-smalloc,-hcritbitvarnish-4.0.5 revision 07eff4c29Type &apos;help&apos; for command list.Type &apos;quit&apos; to close CLI session.help200 help [&lt;command&gt;]ping [&lt;timestamp&gt;]auth &lt;response&gt;quitbannerstatusstartstop # val 配置相关vcl.load &lt;configname&gt; &lt;filename&gt; # 装载，加载并编译 vcl 配置文件vcl.inline &lt;configname&gt; &lt;quoted_VCLstring&gt;vcl.use &lt;configname&gt; # 激活vcl.discard &lt;configname&gt; # 删除vcl.list # 查看所有 vcl 配置文件vcl.show [-v] &lt;configname&gt; # 查看指定的配置文件的详细信息 # 运行时参数相关param.show [-l] [&lt;param&gt;]param.set &lt;param&gt; &lt;value&gt;panic.showpanic.clearstorage.list # 缓存存储backend.list [&lt;backend_expression&gt;] # 后端服务器backend.set_health &lt;backend_expression&gt; &lt;state&gt; # 手动设置后端服务器状态ban &lt;field&gt; &lt;operator&gt; &lt;arg&gt; [&amp;&amp; &lt;field&gt; &lt;oper&gt; &lt;arg&gt;]...ban.list 3. varnish 运行参数varnish 运行时参数用于指定 Child/cache 子进程的工作特性。有三种配置方式: 通过 varnishd -p 选项指定 在 varnishadm 中使用 param.set 子命令配置 /etc/varnish/varnish.params 配置文件中使用 DEAMON_OPTS 选项配置，永久有效 12$ cat /etc/varnish/varnish.params |grep DAEMO#DAEMON_OPTS=&quot;-p thread_pool_min=5 -p thread_pool_max=500 -p thread_pool_timeout=300&quot; varnish有众多的运行时参数，通常需要配置包括 线程相关的参数 Timer 与超时相关的参数 3.1 线程相关的参数在线程池内部，其每一个请求由一个线程来处理； 其worker线程的最大数决定了varnish的并发响应能力； thread_pools: 线程池数量，默认值为2，其值取决于 CPU 的核心数 thread_pool_max：每个线程池创建最大线程的数量，默认5000， thread_pool_min：每个线程池保持最少线程的数量；额外意义为“最大空闲线程数”；默认100 thread_pool_timeout： 线程空闲时间，超过阈值则摧毁线程 thread_pool_add_delay：创建一个新线程的延迟时间，默认值为0s thread_pool_destroy_delay：摧毁一个线程的延迟时间，默认值为2s； varnish最大并发连接数=thread_pools * thread_pool_max，最大的并发连接数最好不要超过 3 万，否则 varnish 将不稳定。 3.2 Timer相关的参数Timer 参数用于控制 varnish 内部的各种超时时长： send_timeout：向客户端发送响应的超时时间 timeout_idle：客户端链接最大的空闲时长 timeout_req： 从客户端接收请求的超时时长 cli_timeout：child 子进程向 Management 的命令行接口进行响应的超时时长]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 基于比较的排序(下)]]></title>
    <url>%2F2018%2F10%2F16%2Falog%2Fsort_2%2F</url>
    <content type="text"><![CDATA[基于分治编程思想的归并排序和快速排序 1. 分治前面讲到的三种排序算法，平均时间复杂度都是 O(n2)，只是适合规模较小的数剧集，接下来要讲的归并排序和快速排序，平均时间复杂度都是 O(nlogn)，它们都用到了分治思想。 分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。分治与我们前面提到的递归很像，分治算法一般都是通过递归实现的。 虽然快排和归并排序都采用了分治的思想，但是它们完全不一样。归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，快排的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的但是它是非原地排序算法。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。正因为此，归并排序没有快排应用广泛。 2. 实现2.1 归并排序归并排序的核心是将数组从中间分成前后两个部分，然后对前后两个部分分别排序，再将它们合并起来。 1234567891011121314151617181920def merge(a, b, c): i = j = 0 while i + j &lt; len(c): if i == len(a) or (j &lt; len(b) and a[i] &gt; b[j]): c[i + j] = b[j] j += 1 else: c[i + j] = a[i] i += 1def sort_merge(alist): if len(alist) &lt;= 1: return alist mid = len(alist) // 2 left = alist[:mid] right = alist[mid:] sort_merge(left) sort_merge(right) merge(left, right, alist) 归并排序并不是原地排序算法，原因很简单 merge 函数在合并两个已排序数组时使用了额外的存储空间，其空间复杂度为 O(n)。最好最坏和平均时间复杂度都是 O(nlogn)，在整个比较过程并没有发生数据交换，只要 merge 函数保持元素的相对顺序，归并排序是稳定的排序算法。 2.2 快速排序快排的算法描述快排排序由以下 3 个步骤组成: 分解: 如果待排序列 S 有至少两个元素，从 S 中选择一个特定的元素 x 作为基准，将 S 中的元素分别放置在 3 个序列中: L 存储 S 中小于 x 的元素 E 存储 S 中等于 x 的元素 G 存储 S 中大于 x 的元素 递归: 递归的排序序列 L 和 G 合并: 按照 L,E,G 的顺序将元素放回 S 中 123456789101112131415161718192021222324252627def sort_quick(S): n = len(S) if len(S) &lt;= 1: return x = S.first() # 基准 x L = LinkedQueue() E = LinkedQueue() G = LinkedQueue() # 分解 while not S.empty(): if S.first() &lt; x: L.enqueue(S.dequeue()) elif S.first() &gt; x: G.enqueue(S.dequeue()) else: E.enqueue(S.dequeue()) # 递归 sort_quick(L) sort_quick(G) # 合并 while not L.is_empty(): S.enqueue(L.dequeue()) while not E.is_empty(): S.enqueue(E.dequeue()) while not G.is_empty(): S.enqueue(G.dequeue()) 快排的原地排序快排的原地排序的核心是选择数组中的一个数据项作为分区点 x，然后遍历数组通过数据交换，使得 x 左边的数据都小于 x，x 右边的数据都大于 x。x 将数组分成了两个区间，然后对这两个区间递归执行此过程直至区间长度为 1 ，完成排序。 1234567891011121314151617def sort_quick(alist, left, right): if left &gt;= right: return alist l = left + 1 r = right x = alist[left] while l &lt;= r: while l &lt;= r and alist[l] &lt; x: l += 1 while l &lt;= r and alist[r] &gt; x: r -= 1 if l &lt;= r: alist[l], alist[r] = alist[r], alist[l] alist[left], alist[r] = alist[r], alist[left] sort_quick(alist, left, r - 1) sort_quick(alist, r + 1, right) 显然这个过程发生了数据交换，但是并没有使用额外的存储空间，所以快排并不是稳定的排序算法，但是原地排序算法。 快排的最好和平均时间复杂度都是O(nlogn)，但是极端情况下，如果数组本身是有序的，并且我们选择最大或者最小(两端)的数据作为分区点，我们需要大约 n 次分区才能完成排序过程。快排的时间复杂度就会退化为 O(n2)。但是退化到 O(n2) 的概率非常小，我们可以通过合理的选择分区点来避免这种情况。 3. 算法3.1 求无序数组中的第 K 大元素利用快排的分区思想，我们可以在O(n) 时间复杂度内求无序数组中的第 K 大元素。 我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。如果 p+1=K，那 A[p] 就是要求解的元素；如果 K&gt;p+1, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找。同理，如果 K&lt;p+1，那我们就在 A[0…p-1] 区间查找。 12345678910111213141516171819def quick_select(S, left, right, k): r = right l = left + 1 pivot = S[left] while l &lt;= r: while l &lt;= r and S[l] &lt;= pivot: l += 1 while l &lt;= r and S[r] &gt;= pivot: r -= 1 if l &lt;= r: S[l], S[r] = S[r], S[l] S[left], S[r] = S[r], S[left] if r + 1 == k: return S[r] elif r + 1 &gt; k: return quick_select(S, left, r - 1, k) else: return quick_select(S, r + 1, right, k) 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[27.1 web架构缓存优化]]></title>
    <url>%2F2018%2F10%2F16%2Flinux_mt%2F30-varnish%2Fweb%E6%9E%B6%E6%9E%84%E7%BC%93%E5%AD%98%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[web架构缓存优化 上一章我们学习了如何使用 keepalived 实现一个高可用集群，接下来我们来继续完善我们的 web 站点架构，本章我们来讲解另一个重要内容，web 站点的缓存系统。 计算机组件衔接中非常常见而且重要策略就是: 两个环节连接起来不是很流畅，加中间层 两个环节连接起来在性能上不匹配，加缓存 缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在”热区”，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 本章我们就来讲解 web 缓存中一种常见实现 varnish，内容包括: web 站点架构演变 varnish 架构与安装配置 varnish 缓存策略配置 varnish 优化与进阶 1. Cache“Cache is Key”，缓存是 web 架构中一个非常重要的组件，因此在学习 varnish 之前，我们必需先了解一下缓存，以及缓存如何影响着我们 web 架构的演变。本节内容包括: 缓存的基本知识 web 架构缓存优化 http 协议的缓存机制 1.1 缓存基础缓存之所以有效是因为我们的程序运行具有局部性特征： 时间局部性：一个数据被访问过之后，可能很快会被再次访问到； 空间局部性：一个数据被访问时，其周边的数据也有可能被访问到 局部性导致我们的站点存在”热区”，即一小部分内容在一段时间内会被多个用户多次访问，因此我们可以将这些热区数据缓存下来，从而能减少中间的处理过程和传输过程，提高响应用户的速度。 因此对于缓存有一些基础的必需理解的概念 首先我们缓存的是热区数据而不是所有数据，所以缓存存在空间限制，当缓存空间耗尽时，会基于 LRU(最近最少使用) 算法来更新缓存 缓存存在时效性，需要定期对过期缓存进行清理，因此通常只会对那些读多写少的内容进行缓存 缓存的有效性使用缓存命中率 hit/(hit+miss) 进行衡量，有两个衡量的指标 页面命中率：基于页面数量进行衡量 字节命中率：基于页面的体积进行衡量 1.2 缓存的分级结构缓存存在多级结构，不同缓存级别下，有些缓存是公共的，有些缓存是私有的，公共缓存只能缓存多个用户之间可以共享的公共数据，因此我们需要在服务器指明数据是否可以被公共缓存缓存。通常 私有数据：只能被私有缓存缓存(private，private cache) 公共数据：可同时被公共和私有缓存进行缓存(public, public or private cache) 对于公共缓存，我们在设置缓存键时，应该尽量排除用户的私有信息，以提高缓存的命中率。因此非常有必要组织好缓存键，减少用户私有数据的参与。 1.3 缓存模式缓存的实现分为两种模式 代理缓存: 缓存服务器如果未能命中，缓存服务器自己需要去找后端服务器请求资源并反回给客户端，所以又称为递归缓存 旁挂缓存: 缓存服务器未命中，需要客户端自己发送请求获取结果 memcached 就是典型的旁挂缓存，所有的 http 协议的缓存都是代理。web 缓存的两个重要开源实现是 squid, varnish，它们类似于 web 服务器的 httpd 和 nginx。 2. web 架构缓存优化多看几次视频(34-1:17) 3. HTTP 缓存控制HTTP 协议在 1.1 增强了缓存控制机制，在 HTTP 协议的缓存控制中，服务器会会在响应报文中为资源”打标”，客户端则会根据”标记”来决定是否使用本地缓存以及如何请求。 3.1 响应报文的缓存控制响应报文中有两种缓存控制机制 过期时间机制 Expires: 作用: HTTP/1.0 使用，表示缓存的过期的绝对时间，在缓存未到期之前客户端会直接使用本地缓存不会发起请求 缺陷: 可能由于时区或系统时间问题而提前失效 Cache-Control: maxage=: 作用: HTTP/1.1 可用表示缓存有效时长 说明: Cache-Control 是缓存控制的专用首部，maxage 只是其使用方式之一 条件式请求机制 Last-Modified: 作用: 文件的最近一次修改时间戳，请求报文使用 If-Modified-Since 首部配合使用 局限: Last-Modified 记录的最小单位是秒，如果响应的内容在 1s 内更新了好几次，此首部是无法反映的 Etag: 作用: 基于文件的校验码来判别，请求报文使用 If-None-Match 首部配合使用 12345# 响应报文中的缓存控制首部信息示例Expires:Thu, 13 Aug 2026 02:05:12 GMT # 有效的绝对时间Cache-Control:max-age=315360000 # 有效时长ETag:&quot;1ec5-502264e2ae4c0&quot; # 内容校验码Last-Modified:Wed, 03 Sep 2014 10:00:27 GMT # 文件最近一次修改时间 3.2 条件式请求首部对于时间控制机制，客户端会自动根据 Expires 和 Cache-Control 来判断缓存是否过期，只有缓存过期时客户端才会发起新的请求。 对于条件式请求机制，用户会根据 Last-Modified 或 Etag 发起条件式请求 Last-Modified 对应的条件式请求首部包括: If-Modified-Since：从指定时间开始，内容是否发生变更 If-Unmodified-Since Etag 对应的条件式请求首部: If-Match: 当前缓存资源的 Etag 是否与服务器资源的 Etag 相同 If-None-Match: 以 Etag 为例，条件式请求的整个过程如下: 第一次客户端请求时，服务器会在响应报文的附加 Etag 首部，其值是响应内容的哈希值 客户端需要再次获取同一资源时，将发起条件式请求，请求中 If-Match 首部字段的值就是第一响应的 Etag 首部字段的值 服务器会将请求报文中的 Etag 值与当前资源进行比较 如果原始内容未改变，则仅响应首部（不附带body部分），响应码304 （Not Modified） 如果原始内容发生改变，则正常响应，响应码200； 如果原始内容消失，则响应404，此时缓存中的cache object也应该被删除； 3.3 缓存过程通常情况下，http 的缓存的过期时间和条件式请求会结合使用，客户端接收到响应之后，在过期时间到期之前都会是使用本地缓存，缓存到期之后才会发送条件式请求。这样过期时间机制减少了发送请求的次数，条件式请求减少了传输内容。可以最大程度上提升传输速率。 4. http Cache-Control 首部值http 头中的 Cache-Control 首部有特殊作用 请求报文中用于通知缓存服务如何使用缓存响应请求 no-cache:（不要缓存的实体，要求现在从WEB服务器去取） max-age：（只接受 Age 值小于 max-age 值，并且没有过期的对象） max-stale：（可以接受过去的对象，但是过期时间必须小于 max-stale 值） min-fresh：（接受其新鲜生命期大于其当前 Age 跟 min-fresh 值之和的缓存对象） 响应报文中用于通知缓存服务器如何存储上级服务器响应的内容 public: (可以用 Cached 内容回应任何用户) private:（只能用缓存内容回应先前请求该内容的那个用户） no-cache: 可缓存，但响应给客户端之前需要revalidation，即必须发出条件式请求进行缓存有效性验正 max-age：（本响应包含的对象的过期时间） no-store: 不允许存储响应内容于缓存中 12345678910111213141516171819202122232425# http 协议缓存控制指令Cache-Control = &quot;Cache-Control&quot; &quot;:&quot; 1#cache-directive cache-directive = cache-request-directive | cache-response-directive cache-request-directive = &quot;no-cache&quot; | &quot;no-store&quot; (backup) | &quot;max-age&quot; &quot;=&quot; delta-seconds | &quot;max-stale&quot; [ &quot;=&quot; delta-seconds ] | &quot;min-fresh&quot; &quot;=&quot; delta-seconds | &quot;no-transform&quot; | &quot;only-if-cached&quot; | cache-extension cache-response-directive = &quot;public&quot; | &quot;private&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] | &quot;no-cache&quot; [ &quot;=&quot; &lt;&quot;&gt; 1#field-name &lt;&quot;&gt; ] | &quot;no-store&quot; | &quot;no-transform&quot; | &quot;must-revalidate&quot; | &quot;proxy-revalidate&quot; | &quot;max-age&quot; &quot;=&quot; delta-seconds | &quot;s-maxage&quot; &quot;=&quot; delta-seconds | cache-extension]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.3 keepalived 配置示例]]></title>
    <url>%2F2018%2F10%2F15%2Flinux_mt%2F29-keepalived%2Fkeepalived%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[keepalived 配置示例 前面我们已经介绍了如何安装和配置 keepalived，本节我们就来看看如何使用 keepalived 对 nginx 的负载均衡集群做高可用。需要提醒大家注意的是无论是学习还是以后工作，当我们配置一个复杂服务时，都应该按照简单到复杂的顺序一步步进行配置，完成一步，验证一次，成功之后在进行下一步，这样便于排错。所以本节的示例我们将按照如下顺序展示，最终完成我们的LVS 双主模型的高可用集群配置。 单主模型下配置 keepalived 完成地址流动 双主模型下配置 keepalived 完成地址流动 单主模型的 LVS 高可用集群配置 双主模型的 LVS 高可用集群配置 双主模型 nginx 高可用集群配置 1. 单主模型下完成地址流动12345678910111213141516171819202122232425262728293031! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 192.168.1.168/24 dev eno16777736 &#125; notify_master "/etc/keepalived/notify.sh master" notify_backup "/etc/keepalived/notify.sh backup" notify_fault "/etc/keepalived/notify.sh fault"&#125; 通知脚本的使用方式：12345678910111213141516171819202122232425#!/bin/bash#contact='root@localhost'notify() &#123; local mailsubject="$(hostname) to be $1, vip floating" local mailbody="$(date +'%F %T'): vrrp transition, $(hostname) changed to be $1" echo "$mailbody" | mail -s "$mailsubject" $contact&#125;case $1 inmaster) notify master ;;backup) notify backup ;;fault) notify fault ;;*) echo "Usage: $(basename $0) &#123;master|backup|fault&#125;" exit 1 ;;esac 脚本的调用方法： notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot; 2. 双主模型下完成地址流动双主模型的地址流动，只需在单主模型下额外添加一个 vrrp 实例，在新的实例下: 修改 virtual_router_id 修改 vrrp 认证的密码 修改 virtual_ipaddress 绑定的地址 原来的 MASTER 变成 BACKUP，BACKUP 变成 MASTER 1234567891011121314vrrp_instance VI_2 &#123; state BACKUP interface eno16777736 virtual_router_id 15 priority 98 advert_int 1 authentication &#123; auth_type PASS auth_pass 578f07b2 &#125; virtual_ipaddress &#123; 192.168.1.169/24 dev eno16777736 &#125;&#125; 3. 双主模型的 LVS 高可用集群配置配置步骤如下: 首先要配置 LVS 集群的后端 RS，可参照27.5 LVS 4层负载均衡-DR模型 在”双主模型下完成地址流动”的基础上添加 virtual_server，配置方式如下所示 1234567891011121314151617181920212223242526272829303132333435363738virtual_server 192.168.1.168 80 &#123; delay_loop 3 lb_algo rr lb_kind DR protocol TCP sorry_server 127.0.0.1 80real_server 192.168.1.137 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125;&#125;real_server 192.168.1.107 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125;virtual_server 192.168.1.169 80 &#123; ....... # 配置同上&#125; 4. 单主模型的nginx高可用集群nginx 服务的高可用，我们需要使用 vrrp_script{} 定义 nginx 的检测方式，并将这种检测通过 track_script 添加到 vrrp 实例中去，让 vrrp 能够在检测到 nginx 服务异常时进行主备服务器切换。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; root@localhost &#125; notification_email_from keepalived@localhost smtp_server 127.0.0.1 smtp_connect_timeout 30 router_id node1 vrrp_mcast_group4 224.0.100.19&#125;vrrp_script chk_down &#123; script &quot;[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0&quot; interval 1 weight -5&#125;vrrp_script chk_nginx &#123; # 定义 script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 10.1.0.93/16 dev eno16777736 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125; 5. 双主模型的nginx高可用集群双主模型在单主模型基础上添加一个 vrrp 实例即可]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 基于比较的排序(上)]]></title>
    <url>%2F2018%2F10%2F14%2Falog%2Fsort_1%2F</url>
    <content type="text"><![CDATA[基于比较的排序算法: 冒泡排序、插入排序和选择排序 1. 排序算法要点排序算法太多了，因此除了要学习各种算法的原理，代码实现之外；我们还要搞明白如何比较和分析一个排序算法。评价一个算法可以从如下几个方面入手: 算法的执行效率: 算法的执行效率包括最好情况、最坏情况、平均情况的时间复杂度；之所以要区分这三种情况，是因为大多数排序算法在不同有序度的数据集上的时间复杂度不相同 时间复杂度的系数、常数 、低阶；通常我们要排序的数剧集并不大，因此需要将系数、常数 、低阶考虑进来 比较次数和交换（或移动）次数，基于比较的排序算法需要进行数据的比较和移动两个操作，因此需要把这两个操作考虑进来 排序算法的内存消耗，排序算法中，我们将空间复杂度为O(1) 的算法称为原地排序算法 排序算法的稳定性，稳定性指如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。 这些方面可以帮助我们分析和更好的理解每种算法的特点。 1.1 排序算法分类排序算法太多了，最经典的、最常用的包括：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。如上图所示按照时间复杂度它们分成了三类。 本节我们先来介绍基于比较的排序算法:冒泡排序、插入排序和选择排序。 这三种时间复杂度为 O(n2) 的排序算法中，冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，我会讲到，有些编程语言中的排序函数的实现原理会用到插入排序算法。 1.2 有序度有序度是数组中具有有序关系的元素对的个数，逆序度恰恰相反，完全有序的数组的有序度叫作满有序度。逆序度的定义正好跟有序度相反显然 逆序度 = 满有序度 - 有序度。排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，排序完成。 在下面的冒泡和插入排序的实现中，我们会发现无论是插入排序还是选择排序，每次数据交换只会增加 1 个有序度(因为它们只会对相邻的元素进行交换)。因此这两种排序的数据交换次数是相同的都是数剧集的逆序度。但是冒泡排序的实现更复杂需要更多次的赋值操作。所以如果将时间复杂度的系数、常数 、低阶考虑进来，冒泡排序并没有插入排序快。 2. 实现2.1 冒泡排序冒泡排序的核心是每次只会操作相临的两个数据，比较它们的大小，并在不满足大小关系时交换；在 n 次操作之后将最大或者最小值移动到最前端。 总共经过 n 次冒泡之后，排序即可完成。冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。 冒泡是原地排序算法，只要我们在代码中不交换相等的元素，冒泡排序就是稳定的排序算法 12345def sort_bubble(alist): for end in range(len(alist), 1, -1): for i in range(1, end): if alist[i] &lt; alist[i-1]: alist[i], alist[i-1] = alist[i-1], alist[i] 2.2 插入排序插入排序将数据分为已排序和未排序两个区间，然后不断取未排序区间中的元素插入到已排序区间中，并保持已排序区间的有序；重复直至未排序区间为空即可。 插入排序是原地排序算法，在插入排序中，对于值相等的元素，我们只要将后出现的元素插入到后出现元素的后面，插入排序就是稳定的排序算法。 12345678def sort_insert(alist): for end in range(1, len(alist)): tmp = alist[end] p = end - 1 while p &gt;= 0 and alist[p] &gt; tmp: alist[p + 1] = alist[p] p -= 1 alist[p + 1] = tmp 2.3 选择排序选择排序将数据分为已排序和未排序两个区间，不同的是选择排序每次会从未排序区间找出最小的元素放到已排序区间的末尾，而不是插入。 选择排序是原地排序算法，最好最坏和平均时间复杂度都是O(n2)，但是选择排序并不是稳定的排序算法。原因是选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。 1234567def sort_select(alist): for start in range(0, len(alist)): m = start for i in range(start + 1, len(alist)): if alist[i] &lt; alist[m]: m = i alist[start], alist[m] = alist[m], alist[start] 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.2 keepalived 安装和配置]]></title>
    <url>%2F2018%2F10%2F14%2Flinux_mt%2F29-keepalived%2Fkeepalived%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[keepalived 安装和配置 上一节我们对高可用集群 和 keepalived 做了一个简单介绍，本节我们来学习 keepalived 的安装配置。我们的最终目的是使用 keepalived 对 nginx 的负载均衡集群做高可用，本节内容包括: HA 集群配置的前题 keepalived 安装与组成 keepalived 配置文件格式与参数 1. HA 集群的配置前提HA 集群因为主备节点之间需要通信以协调工作，所以在配置之前需要一些准备工作: 各节点时间必须同步，参考 25.1 Linux时间服务-chrony 确保iptables及selinux不会成为阻碍 各节点之间可通过主机名互相通信 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 建议使用/etc/hosts文件实现，避免 DNS 称为单点故障所在 确保各节点的用于集群服务的网卡接口支持MULTICAST通信，以便进行组播 各节点之间的 root 用户可以基于密钥认证的 ssh 服务完成互相通信。 对 keepalived 并非必须，但是对于 heartbeat/corosync 则是必备条件 因为 corosync 需要在节点之间复制配置文件 2. keepalivedCentOS 6.4 只有 keepalived 就已经被收录至 base 仓库，因此可通过 yum 直接安装。 2.1 程序环境12345678$ rpm -ql keepalived |grep -v "share"/usr/sbin/keepalived # 主程序文件/etc/keepalived/etc/keepalived/keepalived.conf # 主配置文件/usr/bin/genhash /etc/sysconfig/keepalived # Unit File的环境配置文件/usr/lib/systemd/system/keepalived.service # Unit File/usr/libexec/keepalived 2.2 配置文件格式1234567891011121314151617181920212223242526272829303132333435363738394041# 1. GLOBAL CONFIGURATION# 1.1 Global definitionsglobal_defs &#123;&#125;# 1.2 Static routes/addressesstatic_ipaddress&#123;&#125;static_routes&#123;&#125;static_rules&#123;&#125;# 2. VRRPD CONFIGURATION# 2.1 VRRP synchronization group(s)vrrp_sync_group VG_1 &#123; group &#123; inside_network # name of the vrrp_instance (see below) outside_network # One for each movable IP ...&#125;&#125;# 2.2 VRRP instance(s)vrrp_instance inside_network &#123;&#125;# 3. LVS CONFIGURATION# 3.1 Virtual server group(s)virtual_server_group &lt;STRING&gt; &#123;&#125;# 3.2 Virtual server(s)virtual_server group string&#123;&#125; 上面是 keepalived.conf 的缩略结构，主要由如下几个配置段组成: GLOBAL CONFIGURATION: 全局配置段 Global definitions: 全局参数 Static routes/addresses: 静态地址和静态路由配置 VRRPD CONFIGURATION: vrrp 配置段 VRRP synchronization group(s)：vrrp同步组，同一组内的 vrrp 会同进同退 VRRP instance(s)：每个vrrp instance即一个vrrp路由器； LVS CONFIGURATION: lvs 规则管理配置段 Virtual server group(s): 将一组集群服务进行统一调度 Virtual server(s): ipvs集群的vs和r 3. global_defsglobal_defs 用于全局参数 12345678910111213# 示例一: global_defs 全局配置! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; # 邮件通知的管理员帐户，收件箱 root@localhost &#125; notification_email_from keepalived@localhost # 发件箱 smtp_server 127.0.0.1 smtp_connect_timeout 30 # smtp 链接超时时长 router_id node1 # 当前节点的标识，重要 vrrp_mcast_group4 224.0.100.19 # 组播域，重要&#125; 4. vrrp_instancevrrp_instance 用于定义虚拟路由器 123vrrp_instance &lt;STRING&gt; &#123; ....&#125; 4.1 vrrp_instance 常用参数 vrrp_instance 参数 作用 state MASTER/BACKUP 当前节点在此虚拟路由器上的初始状态；只能有一个是MASTER，余下的都应该为BACKUP interface IFACE_NAME 绑定为当前虚拟路由器使用的物理接口 virtual_router_id VRID 当前虚拟路由器的惟一标识，范围是0-255 priority 100 当前主机在此虚拟路径器中的优先级；范围1-254 advert_int 1 vrrp通告的时间间隔； authentication{} vrrp 认证，详细使用见下 virtual_ipaddress{} 虚拟路由器的 IP 地址，详细使用见下 virtual_routes{} 虚拟路由，详细使用见下 track_interface{} 配置要监控的网络接口，一旦接口出现故障，则转为FAULT状态,，详细使用见下 nopreempt 定义工作模式为非抢占模式，默认为抢占模式 preempt_delay 300 抢占式模式下，节点上线后触发新选举操作的延迟时长； notify_master path 当前节点成为主节点时触发的脚本 notify_backup path 当前节点转为备节点时触发的脚本 notify_fault path 当前节点转为“失败”状态时触发的脚本 notify path 通用格式的通知触发机制，一个脚本可完成以上三种状态的转换时的通知 1234567891011121314151617181920212223242526# vrrp 认证authentication &#123; auth_type AH|PASS auth_pass &lt;PASSWORD&gt; &#125;# 虚拟路由器 ipvirtual_ipaddress &#123; &lt;IPADDR&gt;/&lt;MASK&gt; brd &lt;IPADDR&gt; dev &lt;STRING&gt; scope &lt;SCOPE&gt; label &lt;LABEL&gt; 192.168.200.17/24 dev eth1 192.168.200.18/24 dev eth2 label eth2:1&#125;# 虚拟路由virtual_routes &#123; src 192.168.100.1 to 192.168.109.0/24 via 192.168.200.254 dev eth1 192.168.110.0/24 via 192.168.200.254 dev eth1 &#125;# 监控的网络接口track_interface &#123; eth0 eth1 ...&#125; 4.2 vrrp_instance 配置示例12345678910111213141516171819# 示例二: 单主模型下完成地址流动global_defs&#123; # 配置见示例一 .....&#125;vrrp_instance VI_1 &#123; state BACKUP # 节点初始状态 interface eno16777736 # 绑定虚拟地址的网卡接口 virtual_router_id 14 # 虚拟路由器 ID priority 98 # 优先级 advert_int 1 # 组播频率 authentication &#123; # vrrrp 认证 auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; # 虚拟 IP 地址 10.1.0.91/16 dev eno16777736 label eno16777736:0 &#125;&#125; 5. vrrp_sync_group5.1 vrrp_sync_group 作用VRRP synchronization group(s)：用于定义 vrrp 同步组，同一组内的 vrrp 会同进同退。所谓同进同退的意思是 vrrp 组的服务，当某一个服务发生故障转移或故障恢复时，组内的所有服务都会一同进行转移。典型的情景是高可用 NAT 模型的 LVS。 12vip ----------- VS1(100) ------ DIPvip ------------VS2(99) -------DIP 如上，前段我们将 vip 定义为虚拟路由 router1，对外提供服务，后端我们将 DIP 配置为虚拟路由器 router2 向后端服务转发请求。当 router1 因为某种原因从 VS1 转移到 VS2 时，我们的 router2 也必需要转移过去。原因是 NAT 模型的 LVS 后端的 RS 必需将网关指向VS，当 VS 由 VS1 转移到 VS2 时，如果 router2 不随之转移，RS 的报文将将默认发送至 VS1，此时将无法完成目标地址转换。 需要注意的是对于 nginx 我们无需配置 router2，因为请求报文是通过 IP 地址路由的，而 IP 地址是不会变化的。 5.2 vrrp_sync_group 配置示例123456vrrp_sync_group G1 &#123; group &#123; VI_1 # vrrp_instance 定义 vrrp 虚拟路由器名称 VI_2 VI_5&#125; 6. virtual_servervirtual_server 用于定义 ipvs 集群规则123456789virtual_server IP port | # 只支持 tcp 协议virtual_server fwmark int # 防火墙标记&#123; ... real_server &#123; ... &#125; ...&#125; 6.1 virtual_server 常用参数 delay_loop &lt;INT&gt;：健康状态检测的时间间隔 lb_algo rr|wrr|lc|wlc|lblc|sh|dh：调度方法 lb_kind NAT|DR|TUN：集群的类型 persistence_timeout &lt;INT&gt;：持久连接时长 protocol TCP：服务协议，仅支持TCP sorry_server &lt;IPADDR&gt; &lt;PORT&gt;：备用服务器地址 real_server &lt;IPADDR&gt; &lt;PORT&gt;{}：RS 定义 RS 定义1234567real_server &lt;IPADDR&gt; &lt;PORT&gt;&#123; weight &lt;INT&gt; : 权重 notify_up &lt;STRING&gt;|&lt;QUOTED-STRING&gt; : 启动的通知脚本 notify_down &lt;STRING&gt;|&lt;QUOTED-STRING&gt; : 关闭的通知脚本 HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|MISC_CHECK &#123; ... &#125;：定义当前主机的健康状态检测方法；&#125; 健康状态检测方法: HTTP_GET|SSL_GET{}：应用层检测 TCP_CHECK{}：传输层检测 应用层检测位于 real_server{}配置段内 1234567891011121314HTTP_GET|SSL_GET &#123; url &#123; path &lt;URL_PATH&gt; ：定义要监控的URL； status_code &lt;INT&gt; ：判断上述检测机制为健康状态的响应码； digest &lt;STRING&gt; ：判断上述检测机制为健康状态的响应的内容的校验码； &#125; nb_get_retry &lt;INT&gt; ：重试次数； delay_before_retry &lt;INT&gt; ：重试之前的延迟时长； connect_ip &lt;IP ADDRESS&gt; ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt; ：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt; ：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt; ：发出健康状态检测请求时使用的源端口； connect_timeout &lt;INTEGER&gt;：连接请求的超时时长；&#125; 传输层检测位于 real_server{}配置段内 123456789TCP_CHECK &#123; connect_ip &lt;IP ADDRESS&gt; ：向当前RS的哪个IP地址发起健康状态检测请求 connect_port &lt;PORT&gt; ：向当前RS的哪个PORT发起健康状态检测请求 bindto &lt;IP ADDRESS&gt; ：发出健康状态检测请求时使用的源地址； bind_port &lt;PORT&gt; ：发出健康状态检测请求时使用的源端口； nb_get_retry &lt;INT&gt; ：重试次数； delay_before_retry &lt;INT&gt; ：重试之前的延迟时长； connect_timeout &lt;INTEGER&gt; ：连接请求的超时时长；&#125; 6.2 配置示例123456789101112131415161718192021222324252627282930313233virtual_server 10.1.0.93 80 &#123; delay_loop 3 # 健康状态监测时间间隔 lb_algo rr # 调度算法 lb_kind DR # 集群类型 protocol TCP # 服务协议 sorry_server 127.0.0.1 80 # sorry server real_server 10.1.0.69 80 &#123; # RS 配置 weight 1 # 权重 HTTP_GET &#123; # 应用层健康状态监测 url &#123; path / # 检测路经 status_code 200 &#125; connect_timeout 1 # 链接超时时长 nb_get_retry 3 # 重试次数 delay_before_retry 1 # 重试间隔 &#125; &#125; real_server 10.1.0.71 80 &#123; weight 1 HTTP_GET &#123; url &#123; path / status_code 200 &#125; connect_timeout 1 nb_get_retry 3 delay_before_retry 1 &#125; &#125;&#125; 7. keepalived 高可用 nginxkeepalived 最初的设计目的是为了高可用 LVS，所以要想高可用其他服务需要借助于 keepalived 的脚本调用接口。keepalived 通过调用外部的辅助脚本进行资源监控，并根据监控的结果实现节点的优先调整，以便在主节点发生故障时实现故障转移。 对于 nginx 调度器为例，其最重要的资源是对外提供服务的 IP 地址和 nginx 进程，keepalived 的 vrrp stack 已经能自动完成 IP 转移，但是 keepalived 并没有内置判断 nginx 是否故障，以及故障之后如何转移的功能。nginx 资源的监控，以及如何进行优先级调整只能通过提供辅助脚本进行。并且此时后端服务器的健康状态检测由 nginx 自己进行，与 keepalived 无关。 因此使用 keepalived 高可用 nginx 分两步： 先定义一个 nginx 的监控脚本，使用 keepalived 的 vrrp_script{} 配置段 调用此脚本，在 vrrp_instance{} 配置段内使用 track_script{} 配置段 7.1 vrrp_script12345678vrrp_script &lt;SCRIPT_NAME&gt; &#123; script &quot;&quot; # 脚本路经 interval INT # 脚本执行的时间间隔 weight -INT # 脚本执行失败后，对优先级的调整大小 fall INT # 认定失败的检测次数 rise INT # 认定恢复正常的检测次数 user USERNAME [GROUPNAME] # 执行脚本的用户和用户组&#125; 7.2 track_script12345track_script &#123; SCRIPT_NAME_1 # vrrp_script 定义的脚本名称 SCRIPT_NAME_2 ...&#125; 7.3 配置示例1234567891011121314151617181920212223242526272829303132333435vrrp_script chk_down &#123; script &quot;[[ -f /etc/keepalived/down ]] &amp;&amp; exit 1 || exit 0&quot; interval 1 weight -5&#125;vrrp_script chk_nginx &#123; script &quot;killall -0 nginx &amp;&amp; exit 0 || exit 1&quot; interval 1 weight -5 fall 2 rise 1&#125;vrrp_instance VI_1 &#123; state MASTER interface eno16777736 virtual_router_id 14 priority 100 advert_int 1 authentication &#123; auth_type PASS auth_pass 571f97b2 &#125; virtual_ipaddress &#123; 10.1.0.93/16 dev eno16777736 &#125; track_script &#123; chk_down chk_nginx &#125; notify_master &quot;/etc/keepalived/notify.sh master&quot; notify_backup &quot;/etc/keepalived/notify.sh backup&quot; notify_fault &quot;/etc/keepalived/notify.sh fault&quot;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 递归]]></title>
    <url>%2F2018%2F10%2F13%2Falog%2Frecursion%2F</url>
    <content type="text"><![CDATA[递归是一种应用非常广泛的算法（或者编程技巧）。很多数据结构和算法的编码实现都要用到递归，比如 DFS 深度优先搜索、前中后序二叉树遍历等等。所以，搞懂递归非常重要。 1 特性基本上，所有的递归问题都可以用递推公式来表示。要想使用递归解决问题，必需满足三个前提条件: 一个问题的解可以分解为几个子问题的解，子问题就是规模更小的问题 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样 存在递归终止条件 1.1 如何写递归代码写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再找出终止条件，最后将递推公式和终止条件翻译成代码。 编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。 1.2 递归存在的问题使用递归时会存在很多问题，最常见的两个是: 递归代码要警惕堆栈溢出 递归代码要警惕重复计算 在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销。 1.3 应用递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现。 参考: 王争老师专栏-数据结构与算法之美]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[26.1 高可用集群介绍以及开源软件应用]]></title>
    <url>%2F2018%2F10%2F13%2Flinux_mt%2F29-keepalived%2F%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[高可用集群介绍以及开源软件应用 我们已经介绍了如何使用 LVS/Nginx 如何搭建一个负载均衡集群。为实现负载均衡我们需要一个前端调度器，同时为了让后端服务器共享 session，我们可能需要使用到 session 服务器，等等。调度器，session 服务器则是整个集群的单点故障所在(SPoF: Single Point of Failure)，它们一旦发生故障整个集群将不可用。 在讲解 LVS 时，我们提到了一个衡量系统可用性的标准(平均无故障时间/平均无故障时间 + 平均修复时间)。要想提升系统可用性，必需降低故障的修复时间。因此我们需要对单点故障实现高可用，以通过冗余来降低系统修复时间提高系统可用性。 本章我们就来讲解高可用集群的其中一种实现方案 keepalived。本章内容包括: 高可用集群的实现方案及原理概述 keepalived 安装配置 keepalived高可用 nginx 高可用集群有众多的解决方案，典型的包括 keepalived: 基于 VRRP 协议的实现 heartbeat/corosync: 通用的HA集群解决方案，corosync 是 heartbeat 的升级版 heartbeat/corosync 是通用的高可用集群解决方案，因此对于特定服务，它能提供了功能是有限的。因此大多数情况下，不同服务通常有各自特定的高可用解决方案。keepalived 最开始是为专门高可用 LVS 的，也可以用来高可用 nginx。本节我们就来简述这两种解决方案的基本原理。 1. 高可用集群面临的问题所谓的高可用集群就是为主服务，又称为主节点提供了一个冗余的备用节点，当主节点不可用时，备用节点能自动替代主节点对外提供服务。但是这个冗余与替换的过程有许多问题需要解决: 1.1 心跳信息首先备用节点如何判断主节点不可用。为此主节点需要不断的向备用节点发送”心跳”信息(heartbeat)，备用节点通过心跳信息判断主节点是否正常。然而我们面对的集群环境，除了主机异常之外，也很有可能出现网络异常。所以备用节点收到心跳信息时，不一定是主节点故障，而有可能是网络异常，我们称此种状况为网络发生分区(Network partition)。 其次高可用集群中的服务器可能不止一台，应该如何同步心跳信息呢？很显然一对一通信效率太低，我们需要借助组播，因此搭建高可用集群很重要的一步就是配置集群的组播域。 1.2 网络分区当网络发生分区时，原本的集群就会划分成多个集群，此时应该如何决定由哪个部分来提供服务呢？按照少数服从多数的原则，应该由包含超过半数节点的分区网络继续提供服务。确定了提供服务器的分区之后还不够，首先如果主节点并不再此分区网络中，需要重新选举一个主节点；其次为防止其他分区网络争抢资源，需要对剩余的其他分区作服务器隔离。 1.3 选举协议中心节点的选举有众多协议，其中最著名的就是分布式网络中的 Paxos，以及再次基础上衍生出来的 Raft 协议。很建议大家多读一读这两个协议相关的论文和文章。 1.4 服务隔离准确来说，高可用集群高可用的是特定的服务。以 nginx 负载均衡集群来说，我们高可用的是 nginx 调度器这个服务，这个服务由两个核心资源组成一是对外提供服务的 IP 地址，另一个是我们的 nginx 进程。对于 nginx 即成我们只需要在备用节点上配置好相同的 nginx 服务即可。因此对于负载均衡集群来说，最重要的资源是对外提供的 IP 地址。当服务发生分区时，如果不进行服务隔离，不同的分区网络就会争抢 IP，导致服务间歇性不可用。当然这种情况并不是很严重。 我们考虑另一个更加严重的情况，假设所有后端服务器都挂载到了一个共享的块存储设备上，比如 SAN 这种块级别的共享存储区域网络。网络分区发生时，如果一个分区对磁盘块做了删除操作，另一个做了修改操作，那么最终的将对导致文件系统的元数据不可用进而导致整个系统不可用。 服务隔离有两种曾经: STONITH(Shooting The Other Node In The Head)：主机级别的隔离，”爆头”直接将服务器停机处理 fence: 资源级别的隔离，限制对特定资源的访问 1.5 相关术语在高可用集群中我们有如下一些专用术语 Failover：故障切换，即某资源的主节点故障时，将资源转移至其它节点的操作； Failback：故障移回，即某资源的主节点故障后重新修改上线后，将转移至其它节点的资源重新切回的过程 接下来我们首先来介绍 heartbeat/corosync 架构。 2.heartbeat/corosync 如图是 corosync 的结构图，其由三个部分组成，由下而上是 messaging/infrastructure: 发送心跳信息 ClusterResource Manager(CRM): 资源分配层，用于定义集群服务，包括 Cluster Information Base (CIB): CIB使用XML表示整个集群的配置和当前状态信息。它包含所有集群选项、节点、资源、约束的定义和彼此之间的关系。 并且CIB同步更新至所有的集群节点。在集群内有一个通过DC维护的主CIB节点。其它所有节点存在一个CIB的副本。 Designated Coordinator (DC): 某一个CRM被推选为DC。DC 是群集中唯一可以决定需要在整个群集执行更改（例如节点屏蔽或资源移动）的实体。 其它所有的节点从当前DC获得配置和资源分配信息` Policy Engine (PE): 只要DC需要进行群集范围的更改（对新 CIB 作出反应），PE会根据当前集群状态和配置计算出下一个状态并反馈生成一列指令给DC。 PE通常在DC上运行。 Local Resource Manager (LRM): LRM是CRM的代理，代表 CRM 调用本地RA.它可以执行start/stop/monitor操作并把结果反馈给CRM。 并且可以隐藏不同RA(OCF,LSB)直接的差异。LRM 是其本地节点上所有资源相关信息的权威来源。 Resource Layer: RL包含不同的RA。RA是已写入的用来启动、停止和监视某种服务（资源）的程序（通常是shell脚本），仅能被LRM调用 3. vrrp 协议keepalived 是基于 vrrp 协议的，因此在搞清楚 keepalived 之前我们首先需要了解 vrrp 协议。 3.1 vrrp 协议概述VRRP(Virtual Router Redundancy Protocol) 虚拟路由器冗余协议，是一种容错协议，它保证当主机的下一跳路由器出现故障时，由另一台路由器来代替出现故障的路由器进行工作，从而保持网络通信的连续性和可靠性。 vrrp 架构如上图所示，vrrp 通过将多个路由器组成一个虚拟路由器，对外提供路由服务。虚拟路由器有自己的虚拟IP地址和虚拟MAC地址。局域网内的主机将虚拟路由器的IP地址设置为默认网关，通过虚拟路由器与外部网络进行通信。当主路由器发生故障时，自动选择一个备用路由器继续提供服务。 3.2 VRRP 术语在讲解 VRRP 工作过程之前，我们先来了解一下相关述语: 虚拟路由器： 由一个 Master 路由器和多个 Backup 路由器组成 主机将虚拟路由器当作默认网关。 VRID： 虚拟路由器的标识 有相同 VRID 的一组路由器构成一个虚拟路由器。 Master 路由器： 虚拟路由器中承担报文转发任务的路由器 Backup 路由器： Master 路由器出现故障时，能够代替 Master 路由器工作的路由器 虚拟 IP 地址： 虚拟路由器的 IP 地址 IP 地址拥有者： 接口 IP 地址与虚拟 IP 地址相同的路由器被称为 IP 地址拥有者 虚拟 MAC 地址： 一个虚拟路由器拥有一个虚拟 MAC 地址 3.3 工作流程 VRRP 工作时，首先需要选举出 Master 路由器，并且Master 路由器需要实时同步自己的状态信息，以让备用节点在主节点故障时及时替换，整个详细过程如下: Master 选举: 虚拟路由器中的路由器根据优先级选举出 Master。 Master 路由器通过发送免费 ARP 报文，将自己的虚拟 MAC 地址通知给与它连接的设备或者主机，从而承担报文转发任务 心跳信息: Master 路由器周期性发送 VRRP 报文，以公布其配置信息（优先级等）和工作状况； 故障转移: 如果 Master 路由器出现故障，虚拟路由器中的 Backup 路由器将根据优先级重新选举新的 Master； 虚拟路由器状态切换: Master 路由器由一台设备切换为另外一台设备，新的 Master 路由器只是简单地发送一个携带虚拟路由器的 MAC 地址和虚拟 IP 地址信息的免费 ARP 报文，这样就可以更新与它连接的主机或设备中的ARP 相关信息。网络中的主机感知不到 Master 路由器已经切换为另外一台设备。 抢占/非抢占: Backup 路由器的优先级高于 Master 路由器时，由 Backup 路由器的工作方式（抢占方式和非抢占方式）决定是否重新选举 Master 同时，为了提高安全性， VRRP 还提供了认证功能VRRP提供了三种认证方式： 无认证 简单字符认证：在一个有可能受到安全威胁的网络中，可以将认证方式设置为简单字符认证 MD5 认证：在一个非常不安全的网络中，可以将认证方式设置为 MD5 认证 3.4 工作模式 如果备用的路由只是备用，将会造成资源浪费，我们可以配置多个虚拟路由器组如上图所示: 三个路由器上配置了，三个虚拟路由器，每个虚拟路由器以某一个路由器为主服务器对外提供服务，另外两台路由器作为其备用路由器 前端主机可以将网关平均指向三个虚拟 IP，这样每个路由器都为部分主机提供了路由服务 这种模式我们称为 VRRP N/M 或 N/N 模式，即在一组路由上提供多个虚拟路由器。 4. keepalived4.1 keepalived 功能keepalived 是 vrrp协议的软件实现，原生设计的目的为了高可用ipvs服务，其提供了如下功能: 基于vrrp协议完成地址流动； 为vip地址所在的节点生成ipvs规则（在配置文件中预先定义） 为ipvs集群的各RS做健康状态检测； 基于脚本调用接口通过执行脚本完成脚本中定义的功能，进而影响集群事务，正是基于此功能，keepalived 才能实现高可用 nginx 4.2 keepalived 架构 如图，keepalived 由如下几个部分组成: vrrp stack: vrrp 协议的实现 ipvs wrapper: 生成 ipvs 规则 checkers: 后端服务器状态检测 watch dog: 监控进程 smtp: 邮件服务]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 队列]]></title>
    <url>%2F2018%2F10%2F12%2Falog%2Fqueue%2F</url>
    <content type="text"><![CDATA[先进者先出，这就是典型的”队列”。 1. 特性我们知道，栈只支持两个基本操作：入栈 push()，出栈 pop()，队列与栈类似基本操作只有两个: 入队 enqueue() 向对尾添加一个数据，出队 dequeue() 从队列头部取出一个数据。 1.1 应用队列的应用非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。 队列可以应用在任何有限资源池中，用于排队请求。对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。 1.2 阻塞队列阻塞队列其实就是在队列基础上增加了阻塞操作。它有两个显著特征: 队列空时，从队头取数据会被阻塞，直到队列中有了数据才能返回 队列满时，向队尾插入数据会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回我们可以使用阻塞队列轻松实现一个“生产者，消费者模型”。 1.3 并发队列线程安全的队列我们叫作并发队列，最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。 实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。 1.4 双端对列双端对列是一种类对列数据结构，支持在对列的头部和尾部都能进行插入和删除操作。Python 中的 collections.deque 就是一个双端对列的实现。 2. 实现跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。 2.1 顺序队列顺序队列的实现需要两个指针，head 指针指向队列头部，tail 指针指向队列尾部，即下一个入队元素将被保存的位置索引。显然随着不断的入队，出队 tail 指针出超过数组的索引范围，此时即便数组还有空闲位置也无法继续添加数据。此时借鉴在数组删除中介绍的方法，如果没有空间，我们只需要在下一次入队时集中触发以此数据移动操作，队列中的数据集中移动数组最前方即可。另一种解决方案则是使用循环队列。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657class ArrayQueue(object): __CAPACITY__ = 10 def __init__(self): self.head = self.tail = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self.tail - self.head def is_empty(self): return len(self) == 0 def is_end(self): return self.tail == self._capacity def is_full(self): return len(self) == self._capacity def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) elif self.is_end(): self._move() self._buf[self.tail] = value self.tail += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') h = self._buf[self.head] self._buf[self.head] = 0 self.head += 1 if len(self) &lt; self._capacity / 4: self._resize(self._capacity / 2) return h def _resize(self, size): buf = [0] * size base = len(self) for i in range(base): vi = self.head + i buf[i] = self._buf[vi] self._capacity = size self._buf = buf self.head = 0 self.tail = base def _move(self): i = 0 base = len(self) while i &lt; base: self._buf[i] = self._buf[self.head + i] i ++ self.head = 0 self.tail = base 2.2 链式队列基于单链表的队列，我们在链表那一章已经包含在单链表的实现中。这里我们就基于双链表来实现一个队列，也把之前遗留的循环链表的实现补上。 12345678910111213141516171819202122232425262728293031323334353637383940class LinkedCircularQueue(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, nxt=None): self._element = element self._next = nxt def __init__(self): self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') self._size -= 1 node = self._tail._next if self.is_empty(): self._tail = None else: self._tail._next = node._next node._next = None value = node.element return value def enqueue(self, value): node = self._Node(value) if self.is_empty(): node._next = node else: node._next = self._tail._next self._tail._next = node self._tail = node self._size += 1 2.3 循环对列循环对列与顺序队列类似，但是通过循环利用底层的数组有效的避免了数据移动。循环队列实现相比顺序队列更复杂，有以下几点需要注意: 追加到队尾的元素的位置不在是 tail 而是要判断 tail 是否大于 n，如果大于插入位置则为 tail % n，同时更新 tail 应该更新为 tail % n + 1 队空的条件仍然是 tail == head 但是队列满的条件则为 (tail + 1) % n == head 下面是另外一种类似的实现方式，记录头节点和队列中的元素个数，而不是尾节点，个人觉得这种实现方式更加直观。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class ArrayCircularQueue(object): __CAPACITY__ = 10 def __init__(self): self._head = 0 self._size = 0 self._capacity = self.__CAPACITY__ self._buf = [0] * self._capacity def __len__(self): return self._size def is_empty(self): return self._size == 0 def is_full(self): return self._size == len(self._buf) def enqueue(self, value): if self.is_full(): self._resize(self._capacity * 2) vi = (self._head + self._size) % self._capacity self._buf[vi] = value self._size += 1 def dequeue(self): if self.is_empty(): raise ValueError('queue is empty') value = self._buf[self._head] self._buf[self._head] = 0 self._head = (self._head + 1) % self._capacity if self._size &lt; self._capacity / 4: self._resize(self._capacity / 2) self._size -= 1 return value def _resize(self, size): buf = [0] * size for i in range(self._size): vi = (i + self._head) % self._capacity buf[i] = self._buf[vi] self._capacity = size self._buf = buf self._head = 0 2.4 双端对列链表那一章，我们实现了一个双向链表，在此基础上我们来实现一个双端队列。前面对双向链表的抽象实现是非常重要的，因为我们后面很多数据结构都是建立在双向链表的基础上。 12345678910111213141516171819202122from double_link import DoubleLinkclass LinkedDeque(DoubleLink): def __init__(self): super(LinkedDeque, self).__init__() def insert_first(self, value): self.insert_between(value, self._head, self._head._next) def insert_last(self, value): self.insert_between(value, self._tail._pre, self._tail) def delete_first(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._head._next) def delete_last(self): if self.is_empty(): raise ValueError('Deque is empty') self.delete_node(self._tail._pre) 2.5 并发对列一个基于 CAS 的无锁并发队列实现起来是很复杂的，我们暂时先把这个放一放，在这个系列的结尾会用专门的一篇文章来讲解实现。 参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.5 nginx线上部署示例]]></title>
    <url>%2F2018%2F10%2F12%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E7%BA%BF%E4%B8%8A%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[nginx线上部署示例 1. nginx 线上部署示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115user nobody nobody;worker_processes 4;worker_rlimit_nofile 51200;error_log logs/error.log notice;pid /var/run/nginx.pid;events &#123; use epoll; worker_connections 51200;&#125;http &#123; server_tokens off; include mime.types; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 20m; client_body_buffer_size 256k; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_buffer_size 128k; proxy_buffers 4 64k; proxy_busy_buffers_size 128k; proxy_temp_file_write_size 128k; default_type application/octet-stream; charset utf-8; client_body_temp_path /var/tmp/client_body_temp 1 2; proxy_temp_path /var/tmp/proxy_temp 1 2; fastcgi_temp_path /var/tmp/fastcgi_temp 1 2; uwsgi_temp_path /var/tmp/uwsgi_temp 1 2; scgi_temp_path /var/tmp/scgi_temp 1 2; ignore_invalid_headers on; server_names_hash_max_size 256; server_names_hash_bucket_size 64; client_header_buffer_size 8k; large_client_header_buffers 4 32k; connection_pool_size 256; request_pool_size 64k; output_buffers 2 128k; postpone_output 1460; client_header_timeout 1m; client_body_timeout 3m; send_timeout 3m; log_format main &apos;$server_addr $remote_addr [$time_local] $msec+$connection &apos; &apos;&quot;$request&quot; $status $connection $request_time $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; open_log_file_cache max=1000 inactive=20s min_uses=1 valid=1m; access_log logs/access.log main; log_not_found on; sendfile on; tcp_nodelay on; tcp_nopush off; reset_timedout_connection on; keepalive_timeout 10 5; keepalive_requests 100; gzip on; gzip_http_version 1.1; gzip_vary on; gzip_proxied any; gzip_min_length 1024; gzip_comp_level 6; gzip_buffers 16 8k; gzip_proxied expired no-cache no-store private auth no_last_modified no_etag; gzip_types text/plain application/x-javascript text/css application/xml application/json; gzip_disable &quot;MSIE [1-6]\.(?!.*SV1)&quot;; upstream tomcat8080 &#123; ip_hash; server 172.16.100.103:8080 weight=1 max_fails=2; server 172.16.100.104:8080 weight=1 max_fails=2; server 172.16.100.105:8080 weight=1 max_fails=2; &#125; server &#123; listen 80; server_name www.magedu.com; # config_apps_begin root /data/webapps/htdocs; access_log /var/logs/webapp.access.log main; error_log /var/logs/webapp.error.log notice; location / &#123; location ~* ^.*/favicon.ico$ &#123; root /data/webapps; expires 180d; break; &#125; if ( !-f $request_filename ) &#123; proxy_pass http://tomcat8080; break; &#125; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125; server &#123; listen 8088; server_name nginx_status; location / &#123; access_log off; deny all; return 503; &#125; location /status &#123; stub_status on; access_log off; allow 127.0.0.1; allow 172.16.100.71; deny all; &#125; &#125;&#125; 2. tornado 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103upstream pyapi_prod &#123; server 10.80.85.26:9999 max_fails=3 fail_timeout=20s;&#125;upstream pyapi_pre &#123; server 10.81.33.246:9999 max_fails=3 fail_timeout=20s;&#125;upstream prediction_prod &#123; server 10.47.208.181:8083 max_fails=3 fail_timeout=20s;&#125;upstream crawlerLink_prod &#123; server 10.47.208.181:8086 max_fails=3 fail_timeout=20s;&#125;upstream crawlerLink_pre &#123; server 10.47.208.181:8087 max_fails=3 fail_timeout=20s;&#125;server &#123; #include drop.conf; listen 80; server_name pyapi.internal.enlightent.com pyapi.enlightent.com; location /prediction/ &#123; proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /crawlerLink/ &#123; proxy_pass http://crawlerLink_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location / &#123; proxy_pass http://pyapi_prod; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125;&#125;server &#123; #include drop.conf; listen 80; server_name pre.pyapi.internal.enlightent.com pre.pyapi.enlightent.com; location / &#123; proxy_pass http://pyapi_pre; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /prediction/ &#123; proxy_pass http://prediction_prod/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125; location /crawlerLink/ &#123; proxy_pass http://crawlerLink_pre/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Scheme $scheme; proxy_set_header X-SSL-Protocol $ssl_protocol; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-HTTPS-Protocol $ssl_protocol; proxy_set_header X-Forwarded-Proto $scheme; proxy_send_timeout 300; proxy_read_timeout 300; &#125;&#125; 3. pycgi1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;VirtualHost *:8083&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/model/prediction_play_times/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8084&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/prod/weixinartical/monitor/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8085&gt; ServerName pre.pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/weixinartical/pre/weixinartical/monitor/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8086&gt; ServerName pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/prod/crawlerLink/dataPycgi/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost *:8087&gt; ServerName pre.pycgi.internal.enlightent.com DocumentRoot &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi&quot; &lt;IfModule alias_module&gt; ScriptAlias /cgi-bin/ &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/&quot; &lt;/IfModule&gt; &lt;Directory &quot;/home/yunheadmin/yunhetools/python-cgi/crawlerLink/pre/crawlerLink/dataPycgi/&quot;&gt; AllowOverride None Options Indexes FollowSymLinks ExecCGI Require all granted Require host ip &lt;/Directory&gt;&lt;/VirtualHost&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 栈]]></title>
    <url>%2F2018%2F10%2F11%2Falog%2Fstack%2F</url>
    <content type="text"><![CDATA[后进者先出，先进者后出，这就是典型的“栈”结构。 1. 特性栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。 2. 实现栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。 2.1 顺序栈顺序栈依赖一个能自动扩缩容的数组容器，我们可以像数组章节一样，自己实现一个数组容器，也可以直接使用 Python 内置的 list。list 的接口已经包含并大大超过了栈的可操作范围，这里我们采用一种称为”适配器模式”的通用方法，将栈操作委托给一个内部的 list 实例，来实现一个顺序栈。 这个实现起来很简单，就不写的过于复杂了。 1234567891011121314class ArrayStack(object): def __init__(self): self._buf = [] def __len__(self): return len(self._buf) def pop(self): if len(self._buf) &lt; 1: raise ValueError('stack is empty') return self._buf.pop() def push(self, value): self._buf.append(value) 2.2 链式栈在链表的头部插入和删除一个节点的时间复杂度都是 O(1)，因此我们很容易的就可以将链表的头部作为栈顶实现一个链式栈，并且我们的都不管链表的尾，链表只要维护一个指向头节点指针和自身大小的计数即可。 注意不要将链表的尾作为栈顶，虽然可以实现 O(1) 向链尾插入节点，但是删除尾节点需要遍历整个链表。在链表章节，我们已经实现了一个”超纲的”链式栈，这里就不再累述了。 3. 相关算法操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。这种栈被称为函数调用栈。除此之外诸如表达式求值，括号匹配以及实现浏览器的前进后退功能都与栈有关。 3.1 表达式求值对一个类似于 3-(1/4+7)*3 中缀表达式进行求值分成两步: 将中缀表达式转换为后缀表达式 对后缀表达式进行求值 这两步都用到了栈。为了简单起见，我们只处理+ - * / () 四种运算 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from stack import ArrayStackfrom operator import add, div, mul, subop_priority = &#123; '(': 1, '+': 2, '-': 2, '*': 3, '/': 3, ')': 4&#125;op_func = &#123; '+': add, '-': sub, '*': mul, '/': div&#125;def infix_to_postfix(expression): s = ArrayStack() r = [] expression = expression.split(' ') for e in expression: if e not in op_priority: r.append(e) elif e == '(': s.push(e) elif e == ')': if s.top() != '(': r.append(s.pop()) s.pop() else: while len(s) &gt; 0: t = s.top() if op_priority[t] &gt;= op_priority[e]: r.append(s.pop()) else: break s.push(e) while len(s) &gt; 0: r.append(s.pop()) return ''.join(r)def calculate_postfix(expression): s = ArrayStack() expression = expression.split(' ') for e in expression: if e not in op_priority: s.push(e) else: right = float(s.pop()) left = float(s.pop()) # print left, right value = op_func[e](left, right) s.push(value) return s.pop()def main(): print infix_to_postfix('( A + B ) * ( C + D )') print infix_to_postfix('A + B * C') print calculate_postfix('7 8 + 3 2 + /') print infix_to_postfix('6 / 3') print calculate_postfix('15 3 /') 3.2 括号匹配括号匹配有两个类似的问题，一个是类似于对形如 (1 + 2) + (10) 表达式检测括号是否成对出现；另一个更加常用的是检测 HTML 标签是否完整匹配。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from stack import ArrayStack# 括号匹配def per_check(expression): left = '(&#123;[' right = ')&#125;]' s = ArrayStack() expression = expression.replace(' ', '') for e in expression: if e in left: s.push(left.index(e)) elif e in right: i = right.index(e) if len(s) &lt;=0: return False elif i != s.pop(): return False if len(s) &gt; 0: return False return True# html 标签匹配def html_match(html_string): start = 0 s = ArrayStack() while start != -1: start = html_string.find('&lt;', start) if start == -1: break end = html_string.find('&gt;', start + 1) tag = html_string[start + 1: end] print tag if tag.startswith('/'): if len(s) &lt;= 0: return False else: top = s.pop() # print top, tag[1:] if top != tag[1:]: return False else: s.push(tag) start = end if len(s) &gt; 0: return False return Truedef main(): # print per_check('&#123;&#123;([][])&#125;()&#125;') # print per_check('()]') print html_match('&lt;a&gt;&lt;/a&gt;')if __name__ == "__main__": main() 3.3 浏览器的前进后退功能12345678910111213141516171819202122232425262728from stack import ArrayStackclass Browser(object): def __init__(self): self._back = ArrayStack() self._forward = ArrayStack() def back(self): """ :return: 后退 """ if len(self._back) &gt; 0: self._forward.push(self._back.pop()) def forward(self): """ :return: 前进 """ if len(self._forward) &gt; 0: self._back.push(self._forward.pop()) def new_click(self): """ :return: 打开新连接 """ while len(self._forward) &gt; 0: self._forward.pop() 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.4 nginx 四层代理和负载均衡]]></title>
    <url>%2F2018%2F10%2F11%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%9B%9B%E5%B1%82%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[nginx 四层代理和负载均衡 新版的 nginx 除了代理 http 服务外，还可以基于 stream 模块来实现四层协议的转发、代理或者负载均衡等等。与 LVS 不同的是，nginx 的四层代理依然工作在用户空间，”一手拖两家”，一边作为服务器接收用户请求，另一边作为客户端向后端服务器发送请求。四层的反代和负载均衡配置与 http 的反代和负载均衡基本类似。 1. 四层反代和负载均衡示例12345678910111213141516171819202122232425262728293031323334353637383940worker_processes auto;error_log /var/log/nginx/error.log info;events &#123; worker_connections 1024;&#125;stream &#123; upstream backend &#123; # stream 模块的 upstream 模块 hash $remote_addr consistent; server backend1.example.com:12345 weight=5; server 127.0.0.1:12345 max_fails=3 fail_timeout=30s; server unix:/tmp/backend3; &#125; upstream dns &#123; server 192.168.0.1:53535; server dns.example.com:53; &#125; server &#123; listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend; &#125; server &#123; listen 127.0.0.1:53 udp reuseport; proxy_timeout 20s; proxy_pass dns; &#125; server &#123; listen [::1]:12345; proxy_pass unix:/tmp/stream.socket; &#125;&#125; 2. ngx_stream_core_modulestream 模块使用 server { ... } 上下文来配置反代的四层服务，有如下特殊的配置指令 listenlisten address:port options Default: — Context: server 作用: nginx 反代服务监听的地址和端口 选项: [udp]: 默认为tcp协议, 指定监听udp协议的端口 [backlog=number] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]]; 123456server &#123; listen 12345; proxy_connect_timeout 1s; proxy_timeout 3s; proxy_pass backend;&#125; 3. ngx_stream_proxy_modulengx_stream_proxy_module 主要来实现四层代理功能，其作用与提供的指令与 ngx_http_proxy_module 基本一致 proxy_pass address;proxy_pass address; Default: — Context: location, if in location 作用: 配置后端服务器 参数: address 为后端服务器的地址，可以 IP，域名, upstream 定义的服务器组 proxy_timeout timeout;proxy_timeout timeout; Default: proxy_timeout 10m; Context: stream, server 作用: 设置 nginx 与客户端和后端服务器，超过多长时间未传输数据时则断开链接 proxy_connect_timeout`proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 设置nginx与被代理的服务器尝试建立连接的超时时长；默认为60s； 4. ngx_stream_upstream_modulengx_stream_proxy_module 主要来实现四层负载均衡功能，其作用与提供的指令与 ngx_http_upstream_module 基本一致 配置示例1234567891011121314stream &#123; upstream sshsrvs &#123; server 192.168.10.130:22; server 192.168.10.131:22; hash $remote_addr consistent; &#125; server &#123; listen 172.16.100.6:22202; proxy_pass sshsrvs; proxy_timeout 60s; proxy_connect_timeout 10s; &#125;&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 链表]]></title>
    <url>%2F2018%2F10%2F10%2Falog%2Flinkedlist%2F</url>
    <content type="text"><![CDATA[相比于数组必需使用连续的内存空间，链表通过“指针”将一组零散的内存块串联起来使用，因此更加灵活。 1. 特性我们知道数组受限于保持数据的连续，插入和删除都需要移动大量的数据，而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。 但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。 1.1 性能比较由于数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。 数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。 虽然常见的数组容器都支持动态扩容，但是当需要申请更大的内容容纳更多的数据，数据的拷贝操作是非常耗时的。 除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。 2. 实现链表有多种结构，常见的有单链表，双链表，循环链表。接下来我们就来介绍并实现这三种常见的链表。 2.1 单链表 单链表之所以叫”单”链表，是因为它的每个节点只保存了指向下一个节点的指针，而没有保存指向它自己的前一个节点的指针。因此在插入节点时，我们必需先获取插入位置之前的节点。 为了方便后续用链表去实现栈和队列，我们在单链表中显示的维护一个 _head 和_tail 的指针用于指向链表的首尾节点，并实现下面三个方法: 在链表的头部插入一个节点 删除链表的头节点 在链表尾部添加一个节点 因为我们必需遍历整个链表才能获取尾节点的前一个节点，所以很难高效的从单链表的尾部删除元素，所以我们不会实现一个删除尾节点的方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class Link(object): class _Node(object): __slots__ = "_next", "_element" def __init__(self, element, nxt=None): self._next = nxt self._element = element def __str__(self): a = self._next b = [str(self._element)] while a: b.append(str(a._element)) a = a._next return '-&gt;'.join(b) def __init__(self): self._head = None self._tail = None self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def _insert_tail(self, element): """ :param element: :return: 链表尾部追加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: self._tail._next = node self._tail = node self._size += 1 def _remove_head(self): """ :return: 链表首部删除元素 """ if self.is_empty(): raise ValueError('link is empt') answer = self._head._element self._head = self._head._next self._size -= 1 if self.is_empty(): self._tail = None return answer def _insert_head(self): """ :return: 链表首部添加元素 """ node = self._Node(element) if self.is_empty(): self._head = self._tail = node else: node._next = self._head self._head = node self._size += 1 # 栈方法 pop = _remove_head push = _insert_head # 堆方法 enqueue = _insert_tail dequeue = _remove_head 2.4 循环链表 循环链表跟单链表唯一的区别就在尾结点。单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。 和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题 双向链表的实现与单向链表大体上相同，除了尾节点的特殊处理。因此，我们暂时忽略循环链表的实现，等到下一章我们使用一个循环链表来实现一个队列，再来展示循环链表的实现。 2.3 双链表 双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。可以支持双向遍历，这样也带来了双向链表操作的灵活性。链表在插入和删除时必需先找到被操作节点的前驱节点，而单链表并不支持直接获取其前驱节点，必需从头开始重新遍历链表。而双向链表支持双向便利可直接获取，所以操作起来更加灵活。 除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。 在双链表的实现中，我们将引入头哨兵和尾哨兵；使用哨兵可以帮助我们避免处理链表中没有节点时的特殊情况帮助我们简化双向链表的实现。这里可以与上面不使用哨兵的单向链表作对比。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class DoubleLink(object): class _Node(object): __slots__ = "_element", "_next", "_pre" def __init__(self, element, pre=None, nxt=None): self._element = element self._next = nxt self._pre = pre def __init__(self): self._head = self._Node(None) self._tail = self._Node(None) self._head._next = self._tail self._tail._pre = self._head self._size = 0 def __len__(self): return self._size def is_empty(self): return self._size == 0 def insert_between(self, element, pre_node, next_node): """ :param element: :param pre_node: :param next_node: :return: 在两个节点之间插入一个节点 """ node = self._Node(element, pre=pre_node, nxt=next_node) pre_node._next = node next_node._pre = node self._size += 1 return node def insert_head(self, element): return self.insert_between(element, self._head, self._head._next) def delete_node(self, node): """ :param node: :return: 删除节点 """ element = node._element node._pre._next = node._next node._next._pre = node._pre self._size -= 1 node._pre = node._next = node._element = None return element 3. 相关算法相比与数组，链表写起来就很复杂，有如下一些算法，可以帮助我们练习链表。为了简化代码实现，下面所有函数的参数 link 都是 下面 Node 类的实例 123456789101112class Node(object): def __init__(self, data=None, nxt=None): self.data = data self.nxt = nxt def __str__(self): a = self.nxt b = [str(self.data)] while a: b.append(str(a.data)) a = a.nxt return '-&gt;'.join(b) 3.1 单链表反转123456789def reverse(link): pre = None pwd = link while pwd: # print pre.data, pwd.data # pwd.nxt, pwd, pre = pre, pwd.nxt, pwd pwd.nxt, pre, pwd = pre, pwd, pwd.nxt # pre, pwd.nxt, pwd = pwd, pre, pwd.nxt return pre 3.2 链表中环的检测12345678def has_cycle(link): one = double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if one is double: return True return False 3.3 两个有序链表的合并123456789101112131415161718def merge(link_one, link_two): link = Node() a = link_one b = link_two c = link while a and b: if a.data &lt; b.data: c.nxt = a a = a.nxt else: c.nxt = b b = b.nxt c = c.nxt if a is not None: c.nxt = a if b is not None: c.nxt = b return link.nxt 3.4 删除链表倒数第 n 个节点12345678910111213141516171819def delete_last(link, n): if link is None: return link pre = None first = link second = link for i in range(1, n): second = second.nxt if second is None: return None while second.nxt: second = second.nxt pre = first first = first.nxt if pre is None: return first.nxt else: pre.nxt = first.nxt return link 3.5 求链表的中间节点123456789101112def get_middle(link): if link is None or link.nxt is None: return link, None one = link double = link while double.nxt and double.nxt.nxt: one = one.nxt double = double.nxt.nxt if double.nxt is None: return one, None else: return one, one.nxt 3.6 基于链表实现 LRU 缓存算法实现思路如下: 我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此结点直接插入到链表的头部； 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。 实际上，我们可以继续优化这个实现思路，比如引入（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)，具体实现会在散列表与连表相关章节给出。 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.3 nginx负载均衡器]]></title>
    <url>%2F2018%2F10%2F10%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[nginx负载均衡器 nginx http 的负载均衡功能主要由 ngx_http_upstream_module 提供，其作用是将后端服务器定义为 nginx 中的服务器组，然后将服务器组作为反向代理的目标。在反代请求时，服务器组首先通过配置的调度算法选择一个后端服务器，然后向其转发请求。因此服务器组是 nginx 负载均衡功能的核心组件。 服务器组在 nginx 中是通过 upstream 上下文定义的。upstream 上下文内有特定的配置选项，用于定制后端服务器的权重，调度算法，健康状态检测策略等等。 1. ngx_http_upstream_module1.1 定义 upstream 组upstream name { ... } Default: — Context: http 作用: upstream 上下文，用于定义服务器组 应用: 可被 proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, and grpc_pass 使用 12345upstream httpdsrvs &#123; server ... server... ...&#125; 1.2 upstream 服务器配置选项serverserver address [parameters]; Default: — Context: upstream 选项: weight=num : 权重 max_conns=number: 最大并发连接数 max_fails=number: 健康状态监测: 失败多少次将被标记为不可用，为 0 表示不做健康状态检测，默认为 1 fail_timeout=tim: 健康状态检测: 定义失败的超时时长，默认为 10s backup : 指定备用服务器(sorry server) down : 将服务器标记下线，灰度发布使用 slow_start=time : 慢启动，指平滑的将请求迁移到新增的服务器上 …其他商用版本参数 123456789101112131415161718192021222324# eg： upstream 配置示例http&#123; upstream dynamic &#123; ip_hash; zone upstream_dynamic 64k; server backend1.example.com weight=5; server backend2.example.com:8080 fail_timeout=5s slow_start=30s; server 192.0.2.1 max_fails=3; server backend3.example.com resolve; server backend4.example.com service=http resolve; server backup1.example.com:8080 backup; server backup2.example.com:8080 down; server unix:/tmp/backend3; &#125; server &#123; location / &#123; proxy_pass http://dynamic; health_check; &#125; &#125;&#125; keepalivekeepalive connections; Default: — Context: upstream 作用: 激活 nginx 与后端 upstream server 之间的持久连接功能 参数: connections 表示每个 workder 进程与后端服务器总共能保持的长连接数 1234567891011121314151617# eg: memcache 启动keepalive 长连接upstream memcached_backend &#123; server 127.0.0.1:11211; server 10.0.0.2:11211; keepalive 32;&#125;server &#123; ... location /memcached/ &#123; set $memcached_key $uri; memcached_pass memcached_backend; &#125;&#125; health_checkhealth_check [parameters]; Default: — Context: location 作用: 定义对后端主机的健康状态检测机制；只能用于location上下文； 选项: interval=time：检测频率，默认为每隔5秒钟； fails=number：判断服务器状态转为失败需要检测的次数； passes=number：判断服务器状态转为成功需要检测的次数； uri=uri：判断其健康与否时使用的uri； match=name：基于指定的match来衡量检测结果的成败，name 是 match 上下文定义的检测机制 port=number：使用独立的端口进行检测； 说明: 健康状态检测 upstream 内会自动对服务器组进行健康状态检测，但检测的是服务是否存在 health_check 可在特定应用内，按照特定的方式进行额外的健康状态检测 建议在此location 中关闭访问日志 仅Nginx Plus有效； 12345678910111213141516# eg: 健康状态检测http &#123; server &#123; ... location / &#123; proxy_pass http://backend; health_check match=welcome; &#125; &#125; match welcome &#123; status 200; header Content-Type = text/html; body ~ &quot;Welcome to nginx!&quot;; &#125;&#125; matchmatch{} 上下文用来定义衡量某检测结果是否为成功的衡量机制；有如下专用指令： status：期望的响应码； status CODE status ! CODE header：基于响应报文的首部进行判断 header HEADER=VALUE header HEADER ~ VALUE body：基于响应报文的内容进行判断 body ~ &quot;PATTERN&quot; body !~ &quot;PATTERN&quot; 需要注意的是 match{}, health_check 都进在仅Nginx Plus中有效 1.2 upstream 调度算法配置least_connleast_conn Default: — Context: upstream 作用: 最少连接调度算法； 当server拥有不同的权重时为wlc；当所有后端主机的连接数相同时，则使用wrr进行调度； least_timeleast_time header | last_byte [inflight]; Default: — Context: upstream 作用: 最短平均响应时长和最少连接； 参数: header：response_header; last_byte: full_response; 说明: 仅Nginx Plus有效； ip_haship_hash; Default: — Context: upstream 作用: 源地址hash算法；能够将来自同一个源IP地址的请求始终发往同一个upstream server； hashhash key [consistent]; Default: — Context: upstream 作用: 基于指定的key的hash表实现请求调度，此处的key可以文本、变量或二者的组合； 参数: consistent 指定使用一致性hash算法； 123hash $request_uri consistent # 基于请求 url 进行绑定，lvs 的 DH算法hash $remote_addr # == ip_hashhash $cookie_name sticky用于实现基于 cookie的 session 绑定，只在商业版才能使用 1.3 http upstream 内置变量内置变量: $upstream_addr: 挑选的上游服务器地址 $upstream_cache_status: 缓存命中状态 12345# 自定义响应首部http &#123; add_header X-Via $server_addr; add_header X-Cache $upstream_cache_status&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.2 nginx反向代理facgi]]></title>
    <url>%2F2018%2F10%2F09%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86facgi%2F</url>
    <content type="text"><![CDATA[nginx反向代理facgi 在讲解 httpd 的时候，我们说过通过 php 搭建一个 动态站点时，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 nginx 与 php 结合的话则只能通过 fpm，将 php 运行为独立的应用程序服务器，nginx 通过反代的模式与 fpm 结合起来。nignx 基于 ngx_http_fastcgi_module 模块就能作为 fastcgi 协议的客户端与 fpm 通信。本节我们就来详解 nignx fastcgi 反向代理的相关配置。 1. ngx_http_fastcgi_modulengx_http_fastcgi_module 提供的配置的参数与 ngx_http_proxy_module 提供的参数几乎完全相同，只是将开头的 http 换成的 fastcgi。 1.1 fastcgi 反向代理服务配置fastcgi_passfastcgi_pass address; Default: — Context: location, if in location 参数: address为fastcgi server的地址 fastcgi_indexfastcgi_index name; Default: — Context: http, server, location 作用: fastcgi默认的主页资源; fastcgi_paramfastcgi_param parameter value [if_not_empty]; Default: — Context: http, server, location 作用: 设置传递给后端 fastcgi serve 的参数 1234567891011121314151617# 配置示例1：# 前提：配置好fpm server和mariadb-server服务；location ~* \.php$ &#123; root /usr/share/nginx/html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/share/nginx/html$fastcgi_script_name; include fastcgi_params;&#125;# 配置示例2# 通过/pm_status和/ping来获取fpm server状态信息；location ~* ^/(pm_status|ping)$ &#123; include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;&#125; 1.2 fastcgi 缓存配置fastcgi_cache_pathfastcgi_cache_path path options Default: — Context: http 作用: 定义fastcgi的缓存；缓存位置为磁盘上的文件系统，由path所指定路径来定义； 选项: levels=levels：缓存目录的层级数量，以及每一级的目录数量；levels=ONE:TWO:THREE keys_zone=name:size: k/v映射的内存空间的名称及大小 inactive=time: 非活动时长 max_size=size: 磁盘上用于缓存数据的缓存空间上限 fastcgi_cachefastcgi_cache zone | off; Default: fastcgi_cache off; Context: http, server, location 作用: 调用指定的缓存空间来缓存数据 fastcgi_cache_keyfastcgi_cache_key string; Default: — Context: http, server, location 作用: 定义用作缓存项的key的字符串； 1fastcgi_cache_key localhost:9000$request_uri; fastcgi_cache_methodsfastcgi_cache_methods GET | HEAD | POST ...; Default: fastcgi_cache_methods GET HEAD; Context: http, server, location 作用: 为哪些请求方法使用缓存； fastcgi_cache_min_uses`fastcgi_cache_min_uses number;`` Default: fastcgi_cache_min_uses 1; Context: http, server, location 作用: 缓存空间中的缓存项在inactive定义的非活动时间内至少要被访问到此处所指定的次数方可被认作活动项； fastcgi_cache_valid`fastcgi_cache_valid [code …] time;`` Default: — Context: http, server, location 作用: 不同的响应码各自的缓存时长； fastcgi_keep_connfastcgi_keep_conn on | off; Default: fastcgi_keep_conn off; Context: http, server, location 作用: 是否启动 nginx 于 fastcgi server 之间的长链接 1234567891011121314151617181920示例： fastcgi 缓存配置http &#123; ... fastcgi_cache_path /var/cache/nginx/fastcgi_cache levels=1:2:1 keys_zone=fcgi:20m inactive=120s; ... server &#123; ... location ~* \.php$ &#123; ... fastcgi_cache fcgi; fastcgi_cache_key $request_uri; fastcgi_cache_valid 200 302 10m; fastcgi_cache_valid 301 1h; fastcgi_cache_valid any 1m; ... &#125; ... &#125; ...&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 数组]]></title>
    <url>%2F2018%2F10%2F08%2Falog%2Farray%2F</url>
    <content type="text"><![CDATA[数组和链表应该是数据结构与算法中最基础的数据结构。与链表相比，数组更加简单，所以相比于数组的实现和与之相关的算法，充分认识数组的内在特性反而更加重要。 1. 特性数组（Array）是一种线性表数据结构，用一组连续的内存空间，来存储一组具有相同类型的数据。正是由于连续的内存空间和存储相同类型数据的特性，使得数组支持基于下标的“随机访问”。但是也正是为了维持这种连续的特性，使得数组的插入和删除操作必需作大量的数据移动，因为数组内不能”弯曲”也不能出现”空洞”。 1.1 插入如果数组是有序的，插入一个新的元素到第 k 位置则必需移动 k 之后的所有数据；但是如果数组中的数据本身是无序的，我们可以直接将第 k 位的数据移动到数组元素的最后，再把新的元素插入到原来的第 k 位以避免大量的数据移动。 1.2 删除数组的删除与插入类似，如果要删除第 k 位的元素，为了保证数组内的连续行，也需要移动大量的数据，不然数组就会出现空洞，内存就不连续了。如果数据内的数据是有序，则这种移动不可避免，如果是数组是无序的，可以直接用数组最后的元素覆盖第 k 位的元素。 实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。我们可以将多次删除操作集中在一起执行，来提高删除的效率。我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。 1.3 动态扩容因为需要为数组分配连续的内存空间，因此数组在使用前就需要预先确定好大小。当需要向满的数组中插入数据时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。数组的插入，删除以及由此待来的动态扩容是非常基础的操作，因此大多数编程语言除了基本的底层数组之外，都提供了包含丰富接口的数组容器，方便程序员编程适用，比如 Python 中的列表(list)。 1.4 数组与数组容器的使用选择何时使用数组何时使用编程语言提供的数组容器，专栏-数据结构与算法之美给了下面的一些建议: 容器都有额外的性能损耗，如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。 2. 实现列表和元组是 Python 提供的数组容器，它们都是引用结构，即 list 内部的底层数组存储的不是元素本身，而是列表元素的内存地址，这些内存地址指向每个列表元素。 除了数组容器之外，array 和 ctypes 提供了创建原始底层数组(即保存的不是内存地址而是元素本身的原始数组)的方法。array 模块提供的 array 类只支持基于 C 语言的原始数据类型，不支持用户自定义的数据类型，自定义类型的底层数组由 ctypes 这个底层模块提供。 下面我们就以 ctypes 提供的底层数组为基础创建了一个类似 list 的数组容器。这里的实现并不完备，目的是为了展示 Python list 的底层实现。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import ctypesclass DynamicArray(object): def __init__(self): self._n = 0 # 列表当中实际存储的元素个数 self._capacity = 1 # 当前分配的底层数组，能存储的元素个数 self._buf = self._make_array(self._capacity) # 底层数组的引用 def __len__(self): return self._n def __getitem__(self, item): """ :param item: :return: 简单起见，只支持简单的正向索引 """ if 0 &lt;= item &lt; self._n: return self._buf[item] raise IndexError('%s out of range' % self.__class__.__name__) def append(self, value): if self._n == self._capacity: self._resize(size= 2 * self._capacity) self._buf[self._n] = value self._n += 1 def _resize(self, size): """ :param c: :return: 底层数组的动态扩容 """ buf = self._make_array(size) for i in xrange(self._n): buf[i] = self._buf[i] self._buf = buf self._capacity = size @staticmethod def _make_array(size): """创建一个指定大小的底层数组""" return (size * ctypes.py_object)() def insert(self, k, value): if self._n == self._capacity: self._resize(2 * self._capacity) for i in xrange(self._n, k, -1): self._buf[i] = self._buf[i - 1] self._buf[k] = value self._n += 1 def remove(self, value): """ :param value: :return: 删除第一值等于 value 的元素 """ for i in xrange(self._n): if self._buf[i] == value: for j in xrange(i, self._n - 1): self._buf[j] = self._buf[j + 1] self._buf[self._n - 1] = None # 删除最后一个元素的引用，以便被回收 self._n -= 1 return raise ValueError('value not found') 3. 相关算法与数组专门相关的算法并不多，因为太底层了。这里我们介绍两个: 用数组实现的位图以及凯撒密码 3.1 位图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import arrayimport numbersclass BitMap(object): def __init__(self): self._buf = array.array('L') # 'L' 表示 32 位无符号的整数 @staticmethod def __check(num): if not (isinstance(num, numbers.Integral) and num &gt;= 0): raise ValueError("num is not unsigned int") return num / 32, num % 32 def __len__(self): return len(self._buf) def __getitem__(self, item): return self._buf[item] def __iter__(self): return iter(self._buf) def __contains__(self, item): i, b = self.__check(item) return i &lt; len(self._buf) and (self._buf[i] &amp; (1 &lt;&lt; b)) def __str__(self): r = [] # print self._buf for i in xrange(len(self._buf)): if self._buf[i]: for j in xrange(32): if self._buf[i] &amp; (1 &lt;&lt; j): r.append(32 * i + j) return str(r) def add(self, num): i, b = self.__check(num) while i &gt;= len(self._buf): self._buf.append(0) self._buf[i] |= (1 &lt;&lt; b) def union(self, bit_map): for i, v in enumerate(bit_map): if i &lt; len(self._buf): self._buf[i] |= v else: self._buf.append(v)def main(): bm = BitMap() bm.add(1) bm.add(144) bm.add(9) bm.add(9) print bm print 9 in bm print 8 in bm y = BitMap() y.add(9) y.add(42) print y bm.union(y) print bm 3.2 凯撒密码有关凯撒密码的说明，大家可以看看百科的说明:凯撒密码 12345678910111213141516171819202122class CaesarCipher(object): def __init__(self, shift): self.encode = [(chr(ord('A') + (i + shift) % 26)) for i in range(26)] self.decode = [(chr(ord('A') + (i - shift) % 26)) for i in range(26)] print self.encode print self.decode def encrypt(self, message): return self._transform(message, self.encode) def decrypt(self, message): return self._transform(message, self.decode) @staticmethod def _transform(message, code): m = list(message) r = [] for i in m: if i.isupper(): t = code[ord(i) - ord('A')] r.append(t) return ''.join(r) 4. linkcode 习题参考: 王争老师专栏-数据结构与算法之美 《数据结构与算法：python语言实现》]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[25.1 nginx反向代理http]]></title>
    <url>%2F2018%2F10%2F08%2Flinux_mt%2F28-nginx-7%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86http%2F</url>
    <content type="text"><![CDATA[nginx反向代理http 26 章我们讲解了 nginx 作为 web 服务的应用，除了 web 服务功能，nginx 还能作为七层的反向代理实现负载均衡功能。本章我们就来讲解 nginx 的另两项主要功能: 反向代理服务器 负载均衡调度器 nginx 是高度模块化的，只要nginx 具有实现了相关协议的模块，就可以作为相关的反向代理服务器。ngx_http_proxy_module 是 http 反向代理模块，ngx_http_fastcgi_module 是 fastcgi 协议的反代模块。 在介绍 LVS 的负载均衡集群时，我们对 LVS 和 nginx 的负载均衡能力就进行的比较。nginx 作为七层的负载均衡器，能获取应用层的报文信息，因此提供了更多的功能。但是由于工作于用户空间，需要通过套接字与客户端和后端服务器进行交互，所以并发能力受到系统套接字数量的限制。 在讲解 nginx 之前，我们再来回顾一下 LB集群的软件方式 四层调度: lvs, nginx(stream module), haproxy(mode tcp) 七层调度: nginx(http_up_stream module), haproxy(mode http) nginx 的 http 模块，和 stream 模块都具有 up_stream 模块 http 的 up_stream 主要是用来负载均衡 http 服务的 stream 本身只是一个能基于四层协议的反代模块，stream 的 up_stream 则是用来负载这类服务的 nginx 是高度模块化，http 的反向代理功能主要由 ngx_http_proxy_module 模块提供，本节我们来讲解如何将 nginx 配置成一个 http 的反向代理服务器，内容包括: nginx 七层反向代理原理 反向代理服务器参数配置 后端服务配置 代理缓存配置 http 首部字段配置 超时时长配置 1. nginx 七层反向代理原理2. ngx_http_proxy_module123456# http 反向代理示例location / &#123; proxy_pass http://localhost:8000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr;&#125; 2.1 后端服务配置proxy_passproxy_pass URL 作用: 指定被代理的后端服务器 参数: URL=http://IP:PORT[/PATH] Default: — Context: location, if in location, limit_except 123locations url_pattern&#123; proxy_pass URL&#125; nginx 通过 proxy_pass URL 传递 location 匹配到的 url 时存在一些规则和限制 proxy_pass后面的路径不带uri时，其会将location的uri传递给后端主机； proxy_pass后面的路径是一个uri时，其会将location的uri替换为proxy_pass的uri，效果是 nginx 会将 location 匹配到的剩余部分直接附加在 URL 后，传递给后端服务器，所以 locations 与 URL 通常是要么都以 / 结尾，要么都不以 / 结尾。 如果location定义其uri时使用了正则表达式的模式，或在if语句或limt_execept中使用proxy_pass指令，则proxy_pass之后必须不能使用uri; 用户请求时传递的uri将直接附加代理到的服务的之后； 1234567891011121314151617181920212223# 1.location /uri/ &#123; proxy http://hos[:port];&#125;http://HOSTNAME/uri --&gt; http://host/uri# 2.location /uri/ &#123; proxy http://host/new_uri/;&#125;http://HOSTNAME/uri/ --&gt; http://host/new_uri/location /uri/ &#123; proxy http://host/new_uri; # 错误，要么都以 `/` 结尾，要么都不以 `/` 结尾。&#125;http://HOSTNAME/uri/test --&gt; http://host/new_uritest# 3.location ~|~* /uri/ &#123; proxy http://host;&#125;http://HOSTNAME/uri/ --&gt; http://host/uri/； 2.2 代理缓存配置proxy_cache_pathproxy_cache_path path options Default: — Context: http 作用: 定义可用于proxy功能的缓存 options: [levels=levels]: 缓存的目录结构层级 keys_zone=name:size: 缓存区域名称即内存大小 [inactive=time]: 非活动链接的检测时间间隔 [max_size=size]: 缓存的文件所占用的最大磁盘大小 proxy_cacheproxy_cache zone | off Default: proxy_cache off; Context: http, server, location 作用: 指明要调用的缓存，或关闭缓存机制 参数: zone: proxy_cache_path 定义的缓存 proxy_cache_keyproxy_cache_key string Default: proxy_cache_key $scheme$proxy_host$request_uri; Context: http, server, location 作用: 缓存中用于“键”的内容； proxy_cache_validproxy_cache_valid [code ...] time; Default: — Context: http, server, location 作用: 定义对特定响应码的响应内容的缓存时长； 参数: code: 响应码 time: 缓存时长 proxy_cache_methodsproxy_cache_methods GET | HEAD | POST ... Default: proxy_cache_methods GET HEAD; Context: http, server, location 作用: 只对哪些方法获取的内容进行缓存 proxy_cache_use_staleproxy_cache_use_stale param Default: proxy_cache_use_stale off; Context: http, server, location 作用: 被代理服务器响应失败时，是否使用过期缓存进行响应 参数: 可选值包括 error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | off ...; proxy_cache_min_usesproxy_cache_min_uses number Default: proxy_cache_min_uses 1; Context: http, server, location 作用: proxy_path 定义的 inactive 非活动时间内，最少被访问多少次才不会被清理 proxy_cache_bypassproxy_cache_bypass string ... Default: — Context: http, server, location 作用: 在何种情况下，nginx 将不从缓存中取数据 12345678910111213141516171819202122# 缓存配置示例http &#123; proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m; # 配置 server &#123; ... location / &#123; proxy_pass http://backend; proxy_cache cache_zone; # 使用 proxy_cache_key $uri; proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; proxy_cache_use_stale error timeout http_500 http_502 http_503; proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment; proxy_cache_bypass $http_pragma $http_authorization; &#125; &#125;&#125; 2.3 代理 header 设置proxy_set_headerproxy_set_header field value Default: proxy_set_header Host $proxy_host; proxy_set_header Connection close; Context: http, server, location 作用: 设定发往后端主机的请求报文的请求首部的值 12proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for proxy_hide_headerproxy_hide_header field; Default: — Context: http, server, location 作用: 禁止 nginx 将哪些从后端服务器接收的响应传递给客户端，默认情况下 nignx 已经禁止将 “Date”, “Server”, “X-Pad”, and “X-Accel-…” 发送给客户端，此选项的配置值会附加到禁止列表中。 2.4 超时设置proxy_connect_timeout`proxy_connect_timeout time;`` Default: proxy_connect_timeout 60s; Context: http, server, location 作用: 与后端服务器建立链接的超时时长 proxy_read_timeoutproxy_read_timeout time; Default: proxy_read_timeout 60s; Context: http, server, location 作用: nginx 向接收后端服务器响应时，两次报文之间的超时时长 proxy_send_timeoutproxy_send_timeout time; Default: proxy_send_timeout 60s; Context: http, server, location 作用: nginx 向后端服务器发送请求时，两次报文之间的超时时长 3. ngx_http_headers_modulengx_http_headers_module 允许 nginx 配置发给用户的响应报文的 header add_headeradd_header name value [always]; Default: — Context: http, server, location, if in location 作用: 向响应报文中添加自定义首部； 12add_header X-Via $server_addr;add_header X-Accel $server_name; expiresexpires [modified] time;expires epoch | max | off; Default: expires off; Context: http, server, location, if in location 作用: 用于定义Expire或Cache-Control首部的值，或添加其它自定义首部；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 数据结构与算法学习开篇]]></title>
    <url>%2F2018%2F10%2F07%2Falog%2Falgo_start%2F</url>
    <content type="text"><![CDATA[数据结构与算法前前后后已经学习了很长时间，从一开始看《数据结构与算法分析:C语言描述》，到后来看 Python 相关实现《Problem Solving with Algorithms and Data Structures using Python》，但是一直感觉不得其法。 究其原因，一方面是自己对 C 语言一知半解，所以一开始练习太少；另一方面是工作中使用太少，知识这种东西只有到达一定的熟练程度才能真正发现其作用。现在有幸在极客时间订阅了王争老师的专栏数据结构与算法之美，看过之后感觉很好，相比与之前看的书籍有很好的发散和扩展，恰逢《数据结构与算法：python语言实现》也刚刚面市。所以决定下定决心在 2018 最后三个月好好重新学习数据结构与算法。因此就有了这个系列的博客，希望监督自己多加练习。 本系列博客会按照专栏数据结构与算法之美的结构组织，也会从中摘录部分内容，在此特地申明，也非常推荐大家订阅此专栏。然后会以《数据结构与算法：python语言实现》作为辅助来扩展内容，并且在每篇文章的最后，我会尽可能给出与当篇文章相关的 linkcode 习题。 当然作为自己的博客，目的不是复制别人的内容，是想对常用的数据结构作一个总结，然后督促自己动手实现这些数据结构和算法。最后想说一句，数据结构和算法看起来没用，我们平时大多数使用的都是语言内置好的容器和现成的函数，我们只需要知道它们的功能，无需关注它们的实现细节，我们也能写出我们的程序。但是程序的效率很大程度上依赖锁使用组件的效率，我们不关注这些细节，可能别人已经写好了，但是我们却没正确的使用。Python 就有以本书叫《Python: Faster Way》，如果我们对 Python 常见数据结构有所了解，其时很自然的就会明白它们上面所说明的用法。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.7 LVS 高可用]]></title>
    <url>%2F2018%2F10%2F07%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[LVS 高可用 前面我们搭建的负载均衡集群，一旦调度器发生故障，整个服务将不可用，我们需要对其进行高可用。keepalived 是 LVS 高可用最简单有效的解决方案，但是本节我们先不会讲解 keepalived，后面有一个章的内容专门讲解。本节的目的是通过对 LVS 高可用的讲解，让大家理解高可用集群中的重要概念，特别是健康状态检测。 1. LVS 的单点故障LVS 的单点故障 Director不可用，整个系统将不可用，这是整个集群的单点故障所在 解决方案: 高可用 实现: keepalived，heartbeat/corosync 某RS不可用时，Director依然会调度请求至此RS； 解决方案：对各RS的健康状态做检查，失败时禁用，成功时启用； 实现: keepalived, heartbeat/corosync, ldirectord 对于后端服务器的健康状态检测应该是调度器本身所具有的功能，但是因为 LVS 工作的太多底层，所以 LVS 本身不具有此功能，其需要借助外部工具来实现。 keepalived 是帮助 LVS 实现高可用的，但是额外也能帮助 LVS 实现健康状态检测，并且在服务器状态发生变化时，完成 ipvs 对服务器的增删操作。ldirectord 则主要就是为了帮助 LVS 做后端状态检测，并且在服务器状态发生变化时，完成对服务器的增删操作，除此之外没有别的功能。 1.1 健康状态检测对服务器的健康状态检测理解，可以从检查机制，检查后的操作进行理解 检查机制检查机制: 又称检查方法，即通过什么方式，怎么判断服务器已经故障或已恢复 检查方法: 网络层检测: ping 主机 传输层检测: 端口探测，检测服务端口是否存在 应用层检测: 某关键资源是否能被请求到 判断方式: 很显然，我们不能因为某一次检测失败就判定后端服务器故障，因为有可能网络出现问题，也有可能服务器繁忙还没来得及响应。因此我们需要经过多次检测结果来判断服务器的状态。 12# 服务器状态转换第一次故障时 --------&gt; 软状态 ----&gt; 多次故障 ------&gt; 硬状态(真正认定为故障) 2. ldirectord2.1 安装ldirectord 的rpm 包下载链接ftp://ftp.pbone.net/mirror/ftp5.gwdg.de/pub/opensuse/repositories/network:/ha-clustering:/Stable/CentOS_CentOS-6/x86_64/ldirectord-3.9.5-3.1.x86_64.rpm 1234567891011$ rpm -ql ldirectord/etc/ha.d # 配置文件目录/etc/ha.d/resource.d/etc/ha.d/resource.d/ldirectord # 主程序链接/etc/init.d/ldirectord/etc/logrotate.d/ldirectord/usr/lib/ocf/resource.d/heartbeat/ldirectord/usr/sbin/ldirectord # 主程序/usr/share/doc/ldirectord-3.9.5/usr/share/doc/ldirectord-3.9.5/COPYING/usr/share/doc/ldirectord-3.9.5/ldirectord.cf # 配置文件示例 2.2 配置需要在注意的是 ldirectord 会自动根据配置文件及后端服务器可用状态生成规则，因此无需在使用 ipvsadm 创建集群。 1234567891011121314151617181920212223242526272829303132cp /usr/share/doc/ldirectord-3.9.5/ldirectord.cf /etc/ha.d/vim /etc/ha.d/ldirectord.cf# 配置示例# Global Directiveschecktimeout=3 # 检测的超时时长checkinterval=1 # 检测的频率，单位秒fallback=127.0.0.1:80 # 所有后端服务器都不可用，最后的备用服务器，sorry serverautoreload=yes # 配置文件修改时，是否自动加载logfile=&quot;/var/log/ldirectord.log&quot;#logfile=&quot;local0&quot;#emailalert=&quot;admin@x.y.z&quot; # 通知管理员#emailalertfreq=3600 # 故障未修复，每隔多长时间发一次邮件#emailalertstatus=all # 对哪些状态改变发送邮件quiescent=no# virtual 对应于 LVS 一个集群virtual=3 real=192.168.1.107:80 gate 2 # RS real=192.168.1.109:80 gate 1 fallback=127.0.0.1:80 gate service=http scheduler=wrr #persistent=600 #netmask=255.255.255.255 checktype=negotiate checkport=80 request=&quot;index.html&quot; #receive=&quot;CentOS&quot; #virtualhost=www.x.y.z # 向哪个 httpd 的虚拟机主机发送请求]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.6 防火墙标记和LVS持久链接]]></title>
    <url>%2F2018%2F10%2F06%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E9%98%B2%E7%81%AB%E5%A2%99%E6%A0%87%E8%AE%B0%E5%92%8CLVS%E6%8C%81%E4%B9%85%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[防火墙标记和LVS持久链接 前面我们演示了如何使用 LVS 创建一个负载均衡服务，然而在生产环境中，我们可能要同时调度两个及以上的集群服务。典型的情景是，同时部署了 http，https 服务，用户浏览网页的时候使用的 http 服务，当用户登陆或支付时因为 http 是明文的不安全，此时必需切换成 https。如果这个两个服务是单独调度，很有可能用户登陆之后被重新调度到其他服务器上，这样用户原有的缓存就会丢失。所以我们必需将 http，https 作为一组服务进行同一调度，这就需要使用到防火墙标记。我们本节我们就来演示如何使用LVS 统一调度 http，https 服务。 1. 防火墙标记 FWM要想将一组RS的集群服务统一进行调度，我们需要借助 iptables 的防火墙标记功能(FWM) 首先在 director iptables 的 mangle 表的 PREROUTING 链上对一组服务标打上同样的防火墙标记 然后基于FWM 定义集群服务，让 ipvs 对相同标记的服务进行统一调度 2. http/https 统一调度示例上一节我们基于 LVS-DR 配置了一个 http 服务，在此基础上我们继续配置一个 https 服务，并将它们统一调度 2.1 RS https 服务https 的负载均衡 首先各个 RS 密钥和证书文件必需一致 ssh 回话会大量的耗费系统资源，因此服务器会对 ssh 会话进行缓存，为了使缓存生效，lvs 必需使用 sh 算法进行调度，但是 sh 算法会影响负载均衡的效果 如果负载均衡器是 nginx 我们可以在调度器上进行 ssh 会话的建立和缓存，发送到后端服务器请求就可以直接基于 http 协议。我们称这种方式为 ssh 会话拆除。但是 LVS 是工作在内核上，无法理解 ssh 会话，也就做不到 ssh 会话拆除。 1234567891011121314151617181920# 1. VS 上私建 CA# CA(umask 077;openssl genrsa -out private/cakey.pem 2048)openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 365# 证书(umask 077;openssl genrsa -out /root/http.key 2048)openssl req -new -key /root/http.key -out /root/http.csr -days 365openssl ca -in /root/http.csr -out /root/http.crt -days 365# 2. RS 的 https 服务配置scp /root/http.* root@192.168.1.107:/etc/httpd/sslyum install mod_sslvim /etc/httpd/cond/ssl.conf# 3.验证 https 服务# 在客户端导入证书scp /etc/pki/CA/cacert.pem root@192.168.1.106:/root/vim /etc/hosts # 添加域名curl --cacert /root/cacert.pem "https://www.tao.com/test.html" 2.2 VS 集群服务配置12345678910111213141516case $1 instart) iptables -F ipvsadm -C iptables -t mangle -A PREROUTING -d 192.168.1.99 -p tcp -m multiport --dports 443,80 -j MARK --set-mark 3 ipvsadm -A -f 3 -s sh ipvsadm -a -f 3 -r 192.168.1.107 -g -w 1 ipvsadm -a -f 3 -r 192.168.1.109 -g -w 1 ;;stop) iptables -F ipvsadm -C ;;esac 2.3 测试1for i in &#123;1..10&#125;;do curl --cacert /root/cacert.pem "https://www.tao.com/test.html";curl --cacert /root/cacert.pem "http://www.tao.com/test.html";done 3. lvs persistencelvs 持久连接 功能: 实现无论使用任何调度算法，在一段时间内，能够实现将来自同一个地址的请求始终发往同一个RS； 实现: lvs 的持久连接模板，独立于调度算法存在 类型: PPC: 每个端口对应定义为一个集群服务，每集群服务单独调度； PFWMC: 基于防火墙标记定义集群服务；可实现将多个端口上的应用统一调度，即所谓的port Affinity； PCC: 基于0端口定义集群服务，即将客户端对所有应用的请求统统调度至后端主机，必须定义为持久模式； 启用: ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] -p [timeout]: 使用 -p 参数就可以启用 lvs 持久链接功能，默认为 360 秒 12345678910# PPC:ipvsadm -A -t 192.168.1.99:80 -s rr -p [600]ipvsadm -a -t 192.168.1.99:80 -r 192.168.1.107 -gipvsadm -a -t 192.168.1.99:80 -r 192.168.1.109 -g# PFWMC -- 基于防火墙标记定义集群服务即可ipvsadm -A -f 10 -s rr -p [600]# PCC -- 端口定义为 0，此时必需使用 -p 选项ipvsadm -A -t 192.168.1.99:0 -s rr -p [600]]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.5 LVS DR模型实战]]></title>
    <url>%2F2018%2F10%2F05%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4_DR%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[LVS DR模型实战 本节我们将搭建一个 LVS-DR 的负载均衡集群。 1. 网络拓扑结构 拓扑结构说明: VS， RS1， RS2 在虚拟机内均采用桥接方式，桥接到物理机的网卡上 VIP 配置在 DIP 所在网卡的别名上 2. lvs-dr 配置示例2.1 RS 配置脚本12345678910111213141516171819202122232425262728293031#!/bin/bashvip="192.168.1.99"case $1 instart) echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 1 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 2 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce iptables -F ifconfig lo:0 $vip netmask 255.255.255.255 broadcast $vip up route add -host $vip dev lo:0 ;;stop) ifconfig lo:0 down echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore echo 0 &gt; /proc/sys/net/ipv4/conf/all/arp_announce echo 0 &gt; /proc/sys/net/ipv4/conf/lo/arp_announce ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esacecho "/proc/sys/net/ipv4/conf/all/arp_ignore:" `cat /proc/sys/net/ipv4/conf/all/arp_ignore`echo "/proc/sys/net/ipv4/conf/lo/arp_ignore:" `cat /proc/sys/net/ipv4/conf/lo/arp_ignore`echo "/proc/sys/net/ipv4/conf/all/arp_announce:" `cat /proc/sys/net/ipv4/conf/all/arp_announce`echo "/proc/sys/net/ipv4/conf/lo/arp_announce:" `cat /proc/sys/net/ipv4/conf/all/arp_announce` 2.2 VS 配置脚本123456789101112131415161718192021222324#!/bin/bashvip="192.168.1.99"ifc="enp0s3:0"port=80rs1="192.168.1.107"rs2="192.168.1.109"case $1 instart) ifconfig $ifc $vip netmask 255.255.255.255 broadcast $vip up iptables -F ipvsadm -A -t $vip:$port -s wrr ipvsadm -a -t $vip:$port -r $rs1 -g -w 1 ipvsadm -a -t $vip:$port -r $rs2 -g -w 1 ;;stop) ipvsadm -C ifconfig $ifc down ;;*) echo "Usage $(basename $0) start|stop" exit 1 ;;esac]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.4 LVS nat模型实战]]></title>
    <url>%2F2018%2F10%2F04%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4_NAT%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[LVS nat模型实战 本节我们将搭建一个 LVS-NAT 的负载均衡集群。 1. 网络拓扑结构 2. lvs-nat 配置1234567891011121314151617181920212223242526# 1. 配置 RS# - 配置 ip 地址# - 配置 httpd# - 关闭 iptables# - 关闭 SELinux# 2. 配置 Director ipvssysctl net.ipv4.ip_foward=1ipvsadm -A -t 192.168.1.254:80 -s rripvsadm -a -t 192.168.1.254:80 -r 172.16.0.251 -m -w 1ipvsadm -a -t 192.168.1.254:80 -r 172.16.0.252 -m -w 1ipvsadm -L -nipvadm -S -n &gt; /etc/sysconfig/ipvsadmipvsadm-save -n &gt; /etc/sysconfig/ipvsadmipvsadm -Cipvsadm -R &lt; /etc/sysconfig/ipvsadm# 修改规则ipvsadm -E -t 192.168.1.148:80 -s shipvsadm -L -nipvsadm -e -t 192.168.1.148:80 -r 172.16.0.2:8080 -m # 不行ipvsadm -d -t 192.168.1.148:80 -r 172.16.0.2]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.3 LVS 调度算法和 ipvsadmin]]></title>
    <url>%2F2018%2F10%2F03%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E5%92%8Cipvsadmin%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[LVS 调度算法和 ipvsadmin 命令使用 上一节我们对 LVS 的工作原理和四种模型下如何实现负载均衡做了简单介绍，本节我们来学习 LVS 种可用的调度算法以及 ipvsadmin 命令的使用。 1. lvs 调度算法LVS 的调度算法分为静态方法和动态方法两类 1.1 静态算法静态方法: 仅根据算法本身进行调度 RR: round robin, 轮调 WRR: weighted rr, 加权轮调 SH: source hash, 源地址哈希，实现 session 保持的机制 – 来自同一个IP的请求始终调度至同一RS DH: destination hash，目标地址哈希，将对同一个目标的请求始终发往同一RS 1.2 动态算法动态方法: 根据算法及各 RS 的当前负载(Overhead)状态进行调度 LC: Least Connection Overhead = Active * 256 + Inactive WLC: Weighted LC Overhead = (Active * 256 + Inactive) / weight SED: Shortest Expection Delay Overhead = (Active + 1) * 256 / weight NQ: Never Queue, 按照 SED 进行调度，但是被调度的主机，在下次调度时不会被选中 – SED 算法改进 LBLC: 定义: Locality-Based LC，即动态的 DH 算法 作用: 正向代理情形下的 cache server 调度 LBLCR: 定义: Locality-Based Least-Connection with Replication 带复制的LBLC算法 特性: 相对于 LBLC，缓存服务器之间可以通过缓存共享协议同步缓存 2. ipvsadm2.1 ipvsadmin 简介使用 ipvsadmin 定义一个负载均衡集群时 首先要定义一个集群，然后向集群内添加 RS。 一个 ipvs 主机可以同时定义多个集群服务 一个 cluster server 上至少应该有一个 real server 在适用 ipvsadmin 定义集群服务之前，首先要确定 ipvs 已在内核中启用。Centos 的 /boot/config-VERSION 文件内记录了编译内核的所有参数，通过此文件查看 ipvs 配置参数即可确定 ipvs 是否启用。 12345678910111213141516171819202122232425262728293031# 查看 ipvs 在内核中是否启用，及其配置$ grep -i -A 10 "IP_VS" /boot/config-3.10.0-514.el7.x86_64CONFIG_IP_VS=mCONFIG_IP_VS_IPV6=y# CONFIG_IP_VS_DEBUG is not setCONFIG_IP_VS_TAB_BITS=12## IPVS transport protocol load balancing support#CONFIG_IP_VS_PROTO_TCP=yCONFIG_IP_VS_PROTO_UDP=yCONFIG_IP_VS_PROTO_AH_ESP=yCONFIG_IP_VS_PROTO_ESP=yCONFIG_IP_VS_PROTO_AH=yCONFIG_IP_VS_PROTO_SCTP=y## IPVS scheduler#CONFIG_IP_VS_RR=mCONFIG_IP_VS_WRR=mCONFIG_IP_VS_LC=mCONFIG_IP_VS_WLC=mCONFIG_IP_VS_LBLC=mCONFIG_IP_VS_LBLCR=mCONFIG_IP_VS_DH=mCONFIG_IP_VS_SH=mCONFIG_IP_VS_SED=mCONFIG_IP_VS_NQ=m 2.2 ipvsadmin 程序包组成1234567$ yum install ipvsadm$ rpm -ql ipvsadm/etc/sysconfig/ipvsadm-config # 默认的规则保存文件/usr/lib/systemd/system/ipvsadm.service # unit file/usr/sbin/ipvsadm # 主程序/usr/sbin/ipvsadm-restore # 规则保存工具/usr/sbin/ipvsadm-save # 规则重载工具 ipvs 直接附加在内核之上，只要内核正常运行，ipvs 即可工作。ipvs 的 Unit file 主要是在启动时加载规则，在关闭时保存规则而已 1234567891011121314151617# cat /usr/lib/systemd/system/ipvsadm.service[Unit]Description=Initialise the Linux Virtual ServerAfter=syslog.target network.target[Service]Type=oneshot# start 加载规则ExecStart=/bin/bash -c &quot;exec /sbin/ipvsadm-restore &lt; /etc/sysconfig/ipvsadm&quot;# stop 保存规则ExecStop=/bin/bash -c &quot;exec /sbin/ipvsadm-save -n &gt; /etc/sysconfig/ipvsadm&quot;ExecStop=/sbin/ipvsadm -CRemainAfterExit=yes[Install]WantedBy=multi-user.target 2.3 ipvsadm 使用ipvsadm命令的核心功能： 集群服务管理：增、删、改； 集群服务的RS管理：增、删、改； 集群的查看 集群服务管理ipvsadm -A|E -t|u|f service-address [-s scheduler] [-p [timeout]] 作用: 集群服务的增，改 选项: -A: 添加集群服务 -E: 修改集群服务 -t|u|f service-address: 指定集群的作用的协议，地址和端口，唯一标识一个集群 -t: TCP协议 VIP:TCP_PORT -u: UDP协议，VIP:UDP_PORT -f：firewall MARK，是一个数字 -s scheduler: 调度算法，默认为 wlc ipvsadm -D -t|u|f service-address 作用: 删除集群服务 选项: -t|u|f service-address: 指定删除的集群 ipvsadm -C 作用: 清空定义的所有内容 管理集群服务上的 RSipvsadm -a|e -t|u|f service-address -r server-address [-g|i|m] [-w weight] 作用: 添加或修改集群服务的 RS 选项: -a: 添加 RS -e: 修改 RS -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 -g|i|m: 指定lvs类型，默认为 m -g: gateway, dr类型 -i: ipip, tun类型 -m: masquerade, nat类型 -w weight: 权重 ipvsadm -d -t|u|f service-address -r server-address 作用: 删除集群服务上的 RS 选项: -t|u|f service-address:指定管理的集群 -r server-address[:port]: 指定 RS 的 ip 地址端口 查看ipvsadm -L|l [options] 作用: 查看集群状态信息 选项: --numeric, -n: 基于数字格式显示ip和端口 --connection，-c: 显示当前的连接 --exact: 显示统计数据精确值 --stats: 显示统计数据 --rate : 显示速率 ipvsadm -Z [-t|u|f service-address] 作用: 清空集群的计数器 选项: -t|u|f service-address:指定管理的集群 规则保存和重载ipvsadm -R 作用: 重载 == ipvsadm-restore ipvsadm -S [-n] 作用: 保存 == ipvsadm-save]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.2 LVS 4层负载均衡原理]]></title>
    <url>%2F2018%2F10%2F02%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[LVS 4层负载均衡原理 本节我们先来讲解 LVS 实现负载均衡的原理，内容包括: LVS nginx 工作层级 LVS 负载均衡原理 LVS 负载均衡的四种模型 1. LVS nginx 工作层级 要想区分 lvs 与 nginx 实现负载均衡的区别，关键是要明白它们工作在TCP/IP 协议哪个层级。12.1 计算机网络基础知识 我们详细讲解过 TCP/IP 协议。计算机网络被分成两个层次，通信子网和资源子网，应用层是资源子网位于用户空间，下四层位于内核空间。应用层想进行网络通信，必需通过套接子接口向内核发起系统调用，而 Linux 上套接子的数量是有数量限制的。 LVSLVS 是四层的负载均衡器又称为四层路由器，四层交换机，位于内核空间，直接附加在 iptables netfilter 的 nat 表的 INPUT 链上。可直接根据请求报文的目标 IP 和 port 向后端服务器转发报文，无需创建套接字，因此没有套接字数量的限制。 LVS 通过修改请求报文的或IP地址或端口或 MAC 地址直接将报文转发至后端服务器，后端服务器看到的请求依然可能是用户的IP而与中间转发的主机无关。 nginxngxin/haproxy 则工作在应用层，同时充当服务器端和客户端，作为服务器接收外部用户请求，再作为客户端向后端服务器发起请求，将用户请求转发给后端服务器。整个过程需要创建套接字以完成网络通信，所以存在套接字数量限制。 应用对比相比于 nginx，LVS 在实际的生产环境中使用相对较少，原因有以下几点: 大多数企业并没有达到使用 LVS 进行负载均衡的规模，通常情况下使用 nginx，haproxy 就可以很好的完整负载均衡任务 LVS 工作于内核，没有很好的用户端工具，也没有操作更高应用级别的能力，比如无法通过 cookie 进行转发，所以没有 nginx/haproxy 易用 当企业的并发请求超过套接子的限制时，更加倾向于通过硬件实现负载均衡。 但是 LVS 仍然不失为高并发下负载均衡的有效解决方案，而且LVS 是我们理解其他负载均衡集群非常重要的组件，同时 LVS 也是面试重点，因此我们还是要学好 LVS。 实际工作环境中，如果并发请求达到了使用 LVS 的级别，通常采用二级调度的方式，第一级是 LVS，第二级是 nginx/haproxy. 2. LVS 负载均衡原理 如上图所示 LVS 由两个部分组成: ipvs: 工作于内核空间中 netfilter INPUT 链上的钩子函数 ipvsadmin: ipvs 的用户空间命令行工具，用于向 ipvs 添加集群服务和规则 我们需要通过ipvsadmin 向 ipvs 添加监听的服务和对应的集群。当请求报文到来时: 经过第一次路由决策，发往本机的报文会由 PREROUTING 到达 INPUT 附加在 INPUT 的 ipvs 会根据 ipvs 上集群服务的IP，协议和端口来判断报文是否需要向后端的集群进行转发 如果是需要转发的报文，LVS 会根据配置的调度算法，选择集群中某一台主机，将请求报文直接送往 POSTROUTING链转，转发至该服务器 LVS 有 4 种工作类型，不同类型下，LVS 会相应的修改请求报文的 ip，端口或 mac 地址，以将报文转发至目标服务器 因此对于 LVS 而言，报文的在内核的流经顺序为 PREROUTING --&gt; INPUT --&gt; POSTROUTING 3. LVS 术语及架构3.1 LVS 组成LVS(Linux Virtual Server) 由 VS, RS 两个部分组成 VS：Virtual Server, 负载均衡的调度器，又称为 Director, Dispatcher, Balancer rs：Real Server, 真正提供服务的集群服务器，又称为 upstream server, backend server 3.2 LVS的类型(架构)LVS 有四种不同的类型，这四中类型的工作流程实现就是我们接下来讲解的重点: lvs-nat: Network Address Translation，多目标IP的DNAT，通过修改请求报文的目标IP完整转发 lvs-dr: Direct Routing，直接路由，通过重新封装新的MAC地址完成转发 lvs-tun:IP Tunneling，在原请求IP报文之外新加一个IP首部 lvs-fullnat:修改请求报文的源和目标IP，非标准实现 3.3 LVS-NAT(MASQUERADE) 附注: IP 命名: VIP：Virtual IP DIP: Director IP RIP: Real Server IP CIP：Client IP LVS-NAT 就是一个多用途的 DNAT(iptables) 通过修改请求报文的目标IP地址(端口)至挑选出的某RS IP 地址实现转发。相比与 DNAT 只能将报文转发至固定主机，LVS-NAT 可以根据调度算法选择转发的后端主机。LVS-NAT 具有如下一些特征: RS(RIP),DIP应该使用私有地址；RS的网关必须指向DIP； 请求和响应都要经过Director；高负载场景中，Director易成为性能瓶颈； 支持端口映射； vs必须是Linux系统，rs可以是任意系统； RS 的 RIP 和 Director 的 DIP 必须在同一 IP 网络 3.4 LVS-DR(GATEWAY) LVS-DR 通过修改请求报文的目标 MAC 地址进行转发。如上图所示，报文经过了如下的转发过程: VS 接收到来自用户的请求报文 VS 通过调度算法选择一个 RS，通过修改请求报文的目标 MAC 地址为该 VS 的 mac 地址直接向其转发请求报文。因为 VS 必需要能获取 RS 的 MAC 地址，所以 RS 与 VS 必需位于同一物理网络中 RS 接收到响应报文后无需经过 VS 直接向客户端进行响应。因为客户端请求的目标地址是 VIP，所以 RS 进行响应的源地址必需是 VIP，否则客户端不会接收响应。 那我们如何确保 RS 响应的源地址是 VIP 呢？ 首先我们需要在所有的 RS 的网卡上添加 VIP 的 IP 地址 因为 VS 和 RS 都绑定了 VIP ，我们需要保证前端路由将目标地址为VIP的报文统统发往 VS，而不能发往 RS Linux 上响应报文的源IP，是由其发出的第一块网卡上的IP 地址决定，因此我们必需设置 RS 的路由条目，让所有的响应报文从 VIP 所在的网卡发出。 那我们如何保证前端路由将目标地址为VIP的报文统统发往 VS，而不能是 RS 呢？有三种方法: 在前端路由器上静态绑定 VS VIP 地址所在网卡的 MAC 地址；问题是未必有路由操作权限，且无法为 VS 实现高可用，因为 VS 发生故障转移时，VS 所在的服务器就会发生变化，VIP 所在的网卡也就发生了变化。 使用 aprtables 在 RS 上拒绝对 VIP 的 arp 响应和通告，aprtables 类似防火墙的工作于物理层，可通过 MAC 过滤，使用复杂不便于配置 修改RS上内核参数，将RS上的VIP配置在lo接口的别名上，并限制lo接口的 arp 通告和响应，这样就能阻断 RS 对 VIP 地址的解析请求，这是最佳的解决方案。 因此 VIP 必需配置的 lo 接口的别名上，同时必需设置路由，强制让响应报文先经过 lo 接口，再通过内核的转发功能从网卡发出。 LVS-DR 具有如下特征: RS可以使用私有地址；但也可以使用公网地址，此时可通过互联网通过RIP对其直接访问； RS跟Directory必须在同一物理网络中，以便能基于物理地址做转发； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS可以是大多数常见的OS； RS的网关绝不允许指向DIP； 3.5 LVS-TUN(IPIP)LVS-NAT 需要 RS 的网关必需指向 DIP，因此 RS 和 VS 必需位于同一网段中，LVS-DR VS 需要能获取到 RS 的 MAC 地址，因此 VS 和 RS 必需位于同一物理网段中；通常的传输介质，比如双绞线最大的传输距离也就只有 100 米，所以 VS 和 RS 必需位于同一机房内，所以如果各 RS 不再同一位置，比如为了灾备在不同地方分别放置了集群服务器，这两种模式就无法使用。 LVS-TUN 类似 LVS-DR 不过其能跨越地理位置的限制。 LVS-TUN 不修改请求报文的 ip 首部，而是通过在原有的 ip 首部之外，在封装一个 ip 首部。真个请求响应过程如下图所示。 与 LVS-DR 相同的是每个 RS 都必须配置 VIP，并将 VIP 所在网卡作为响应报文的出口以确保响应报文的源IP 为 VIP。但是 RS 无需限制 ARP 的通告和响应，因为此时 VS 与 RS 不再同一网络中。RS 上配置的 VIP 不会影响请求报文到达 VS，因为 VIP 不可能位于 RS 的网段中，因此 RS 中 VIP 是不可达网络，不能接收到发送到 VIP 的请求。 因为额外添加一层 IP 首部，因此 RS 必需要支持隧道协议，否则无法解析转发的报文。同时额外增加的 IP 首部会增加报文大小，如果刚好使得报文从小于 MTU 变成大于 MTU，则会发生报文拆分降低传输速度，因此 VS 上最好能针对这种情况自动拆分报文。 LVS-TUN 具有如下特性: RIP、VIP、DIP全部是公网地址； RS的网关不会也不可能指向DIP； 请求报文经由Director，但响应报文必须不能经过Director； 不支持端口映射； RS的OS必须支持隧道功能； 3.6 LVS-FULLNATLVS-TUN 虽然能跨越地理位置的限制，但是配置起来不便，很少使用。为了满足跨越机房的需求，LVS 有第四种非标准实现 LVS-FULLNAT。LVS-FULLNAT 未收录进内核，要使用需要自己编译内核才能使用。 LVS-NAT 只修改了请求报文的目标地址，因此 RS 进行响应时，为了让目标地址为 CIP 经过 VS，必需将 RS 的网关设置为 RS。LVS-FULLNAT 会同时修改请求报文的目标地址和源地址进行转发， 这样 RS 的响应报文的目标地址为 DIP 而不是 CIP，报文经过路由一定到达 VS，因此 就可以跨越同一网络的限制。 LVS-FULLNAT具有如下特性: VIP 是公网地址，RIP 和 DIP 是私网地址，二者无须在同一网络中 RS 接收到的请求报文的源地址为 DIP，因此要响应给 DIP 请求报文和响应报文都必须经由 Director 支持端口映射 RS 可以使用任意 OS 3.7 总结 lvs-nat, lvs-fullnat：请求和响应报文都经由Director lvs-nat：RIP的网关要指向DIP； lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信； lvs-dr, lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发 lvs-tun：通过在原IP报文之外封装新的IP首部实现转发，支持远距离通信 4. arp 内核控制参数LVS-DR 模型中，我们说到可以通过内核参数来控制 arp 的通告和响应，arp_ignore, apr_announce 就是控制参数。每个网卡都有对应 arp_ignore, apr_announce 控制参数 123456789101112$ ls /proc/sys/net/ipv4/confall default lo virbr0 virbr0-nic wlp1s0# all 表示所有网卡$ ll /proc/sys/net/ipv4/conf/lo/|grep arp-rw-r--r--. 1 root root 0 9月 7 09:51 arp_accept-rw-r--r--. 1 root root 0 9月 7 09:51 arp_announce-rw-r--r--. 1 root root 0 9月 7 09:51 arp_filter-rw-r--r--. 1 root root 0 9月 7 09:51 arp_ignore-rw-r--r--. 1 root root 0 9月 7 09:51 arp_notify-rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp-rw-r--r--. 1 root root 0 9月 7 09:51 proxy_arp_pvlan 4.1 arp_ignorearp_ignore 作用: 控制系统在收到外部的arp请求时，是否要返回arp响应 取值: 主要有0，1，2，3~8较少用到 0: 响应任意网卡上接收到的对本机IP地址的arp请求（包括环回网卡上的地址），而不管该目的IP是否在接收网卡上。 1: 只响应目的IP地址为接收网卡上的本地地址的arp请求 2: 只响应目的IP地址为接收网卡上的本地地址的arp请求，并且arp请求的源IP必须和接收网卡同网段。 3: 如果ARP请求数据包所请求的IP地址对应的本地地址其作用域（scope）为主机（host），则不回应ARP响应数据包，如果作用域为全局（global）或链路（link），则回应ARP响应数据包 4~7: 保留未使用 8: 不回应所有的arp请求 图示 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址允许响应。 arp_ignore=1,当 arp 从 eth1 请求 lo 接口上的 IP 地址的 MAC 地址不允许响应。 4.2 arp_announcearp_announce 作用: 控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址 取值: 0：允许使用任意网卡上的IP地址作为arp请求的源IP，通常就是使用数据包a的源IP。 1：尽量避免使用不属于该发送网卡子网的本地地址作为发送arp请求的源IP地址。 2：忽略IP数据包的源IP地址，选择该发送网卡上最合适的本地地址作为arp请求的源IP地址。 图示 arp_announce=0 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址仍然为 lo 接口的 IP。 arp_announce=1 时 数据包的源 IP 为 lo 接口的IP 地址，其从 eth2发出时，arp 请求的源地址重新选择为 eth1 的IP 地址。 4.3 修改 arp 参数1234echo 1 &gt; /proc/sys/net/ipv4/conf/all/arp_ignoreecho 1 &gt; /proc/sys/net/ipv4/conf/eth1/arp_ignoreecho 2 &gt; /proc/sys/net/ipv4/conf/all/arp_announceecho 2 &gt; /proc/sys/net/ipv4/conf/eth1/arp_announce]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[24.1 架构拓展及集群介绍]]></title>
    <url>%2F2018%2F10%2F01%2Flinux_mt%2F27-LVS4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F%E6%9E%B6%E6%9E%84%E6%8B%93%E5%B1%95%E5%8F%8A%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[架构拓展及集群介绍 前面我们已经介绍了，如何使用 nginx 或 httpd 部署一台 web 服务器，但是受限于单太服务器的资源，一台服务器能提供的响应能力有限。因此从本章开始，我们将从最简单 LAMP/LNMP 出发，不断向其添加组件来扩展我们的 web 服务框架，以提供更快，更稳定的服务。本章我们开始讲解第一个组件，如何使用 LVS 实现一个负载均衡集群，内容包括: web 架构拓展和集群简介 LVS 负载均衡原理 LVS 的 NAT 模型 LVS 的 DR 模型 负载均衡集群除了 LVS 之外还有多种其他实现包括 nginx，haproxy,我们会在后面详细介绍。 1. 架构拓展单台计算受限于本地的存储资源，计算资源等各种资源的额限制，单台服务的响应能力有限。比如我们的单台 nginx 服务最多能并发响应 2 万个用户。当并发请求数超过此限制时，我们有两种优化方式: 换一台计算能力更强的计算机，这种方式我们称之为向上扩展(scale up) 将并发请求按照特定的调度算法分散到多台计算上，这种方式称为向外扩展(scale out)，多台计算的组合就称为集群(cluster) 集群主要分为三类，此处的用于分散用户请求的集群称为负载均衡集群(Loader Balance Cluster)。分散用户请求有一个前提，每个用户请求都是独立可分离的。然后这可能会存在一些问题: 难以完全追踪用户状态，因为用户可能会被调度到不同的机器上 某用户的写操作会被单台服务器所承载，当对新上传资源的请求被调度到其他服务器，将无法获取此资源 对于第一个问题，web 服务通常使用 cookie 和 session 追踪用户，我们需要想办法让集群内的所有服务器能共享 session 信息，这样就能追踪用户状态。session 共享有三种方式: session 绑定，将来自同一用户的请求始终发送同一服务器，这种方式并没有共享 session，当服务器挂机之后 session 可能会丢失，因此需要 session 持久化。用户识别有两种方式，一是 IP，而是用户 cookie，因为 SNAT的存在 cookie 更准确 session 复制集群，每个服务器都拥有集群上所有服务器的 session 会话，因为 session 会在集群内传输，会极大的占用带宽与内存资源。 session 服务器，将 session 保存在共享的内存服务器中，每台服务器从session 服务器中获取 session。但此时 session 服务器是单点故障所在(Single Point of Failure, SPoF) 对于第二个问题，我们可以将用户写操作放到共享存储上。通常用户的数据分为三类，我们可以将其分别存放在不同存储介质中 结构化数据，通常存放在关系型数据库中 半结构化数据，通常存放在 NoSql 中，比如 mongo 非结构化数据，比如图片，我们可以存在分布式文件系统之上 用户的请求需要分散到多台服务器上，负责分散用户请求的服务器称为负载均衡器或分发器或调度器。因此我们的 web 服务框架将如下所示。调度器在分发用户请求时，有不同的调度算法，会依据不同的标准分发请求。 此时负载均衡服务器将是最大的单点故障所在，我们需要对其做冗余。我们需要提供另一台备用服务器，当负载均衡服务器迭机之后，能够取代其继续提供服务。这种提供冗余能力的服务器组合我们称为高可用集群(High Availability)。 2. 集群介绍前面我们提到了两类集群，集群(Cluster) 总共可分为三类: LB：负载均衡集群 Load Balancing HA：高可用集群，High Availability,实现包括 HP：高性能集群 High Performance， HP 集群作用在于集合 CPU，以提供更高的计算能力，最典型应用就是现在的超级计算机。当前企业面临情景主要是海量数据，以及由海量数据引发的大数据计算，HP 只能提供高的计算能力，并没有拓宽计算机的存储能力，所以 HP 集群再企业中应用很少(我是这么理解的)。企业对大数据的计算是通过分布式系统进行的。 2.1 LB 集群LB 有多种实现，包括软件实现和硬件实现: 软件实现有: lvs, haproxy(mode tcp) (传输层) haproxy, nginx (应用层) ats(apache traffic server) 硬件实现有: F5 BIG-IP Citrix Netscaler A10 A10 Array Redware 不同实现工作不同的协议层次上,按照工作的协议层次 LB集群可以划分为 传输层: 通用，包括lvs, nginx(stream), haproxy(mode tcp) 应用层: 专用，只能应用于特定协议，包括 http: nginx(http), httd, haproxy(mode http) fastcgi: nginx, httpd mysql: ProxySQL 2.2 HA 集群HA：高可用集群，常见实现包括 heartbeat corosync + pacemaker RHCS: cman + rgmanager cman + pacemaker keepalived HA 集群主要是提供系统稳定性，衡量系统稳定性有一个评价标准: A=MTBF/(MTBF + MTTR) MTBF: 系统可用时间 MTTR: 平均修复时间 这个计算公式就是我们通常所说的 3个9(99.9%)，4个9(99.99%). 2.3 分布式系统分布式系统包括分布式存储和分布式计算。对于分布式存储依据存储的是海量小文件还是单个大文件，有不同的实现方式。在后面的高级部分，我们会有专门章节来详细讲解。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.5 nginx_http配置段(功能模块)]]></title>
    <url>%2F2018%2F09%2F25%2Flinux_mt%2F26-nginx%2Fnginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E5%8A%9F%E8%83%BD%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx_http配置段(核心模块) 本节是 nginx http 配置的第三部分。上一节我们讲解了 http_core_codule 提供的配置指令，本节我们来讲解 http 的各种功能模块提供的配置指令，内容包括: 功能模块 访问控制 开启状态页 url重写和自定义日志格式 访问日志配置 文本压缩 https 服务配置 fastcgi 配置 1. 功能模块1.1 访问控制12345678910111213141516171819allow IP/Network;deny IP/Netword;# 作用: 基于 ip 的访问控制, all 表示所有# 模块: ngx_http_access_module模块auth_basic string | off;# 作用: 基于用户的访问控制# 模块: ngx_http_auth_basic_module模块auth_basic_user_file# 作用: 账号密码文件# 产生: 建议使用 htppasswd 创建location /admin/ &#123; auth_basic &quot;only for adminor&quot;; auth_basic_user_filer /etc/nginx/user/.httppasswd; &#125;htpasswd -c -m /path/user/.passwd tom 1.2 开启状态页模块: ngx_http_stub_status_module 模块 12345678910111213141516171819location /status &#123; stub_status on; allow 172.16.0.0/16; deny all;&#125;stub_status &#123;on|off&#125;;# 作用: 是否开启状态页，用于输出nginx的基本状态信息# 附注: 仅能用于 location 上下文# 显示:# Active connnections: 当前所有处于打开状态的连接数# server accept handled requests # n1 n2 n3# - n1：已经接受的客户端请求的总数；# - n2：已经处理完成的客户端请求的总数；# - n3：客户端发来的总的请求数；# Reading: n Writing: w Waiting: t# - Reading: 处于读取客户端请求报文首部的连接的连接数；# - Writing: 处于向客户端发送响应报文过程中的连接数；# - Waiting: 处于等待客户端发出请求的空闲连接数； 1.3 url 重写与自定义日志模块: ngx_http_rewrite_module 模块 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960rewrite regex replacement flag;# 作用: url 重写# eg: rewrite ^/images/(.*\.jpg)$ /imgs/$1 break;# flag:# last: 默认# 一旦被当前规则匹配并重写后立即停止检查后续的其它rewrite的规则，# 然后用重写后的规则再从头开始执行 rewriter 检查；# break:# 一旦被当前规则匹配并重写后立即停止后续的其它rewrite的规则，# 而后通过重写后的规则重新发起请求# 且不会被当前的location 内的任何 rewriter 规则所检查；# redirect: 以302临时重定向返回新的URL；# permanent: 以301永久重定向返回新的URL；# 说明:# last,break 只会发生在 nginx 内部，不会与客户端交互，客户端收到的是正常的响应# redict, permanent 则是直接返回 30x 响应，跨站重写必需使用 redirect或permanent# 如果 last 发生死循环，nginx 会在循环 10 此之后返回 50x 响应return code [text];return code URL;return URL;# 作用: 停止进程并返回特定的响应给客户端，非标准的 444 将直接关闭链接，且不会发送响应rewrite_log on | off;# 作用: 是否开启重写日志；# 示例server &#123; ... rewrite ^(/download/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)\..*$ $1/mp3/$2.ra last; return 403; ...&#125;location / &#123; rewriter ^/bbs/(.*)$ /forum/$1 break; rewriter ^/bbs/(.*)$ https://www.tao.com/$1 redirect; # http --&gt; https &#125;if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125;if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1;&#125;if ($request_method = POST) &#123; return 405;&#125;if ($slow) &#123; limit_rate 10k;&#125;if ($invalid_referer) &#123; return 403;&#125; 1.4 日志配置模块: ngx_http_log_module 模块 12345678910111213141516171819log_format name string ...;# 作用: string可以使用nginx核心模块及其它模块内嵌的变量；access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];# 作用: 访问日志文件路径，格式及相关的缓冲的配置；# buffer=size: 日志缓冲区大小# flush=timeaccess_log off;# 作用: 关闭记录日志功能，open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];open_log_file_cache off;# 作用: 缓存各日志文件相关的元数据信息；# 参数: # max：缓存的最大文件描述符数量；# min_uses：在inactive指定的时长内访问大于等于此值方可被当作活动项；# inactive：非活动时长；# valid：验正缓存中各缓存项是否为活动项的时间间隔 1.5 文本压缩模块: ngx_http_gzip_module： 123456789101112131415161718192021222324252627282930313233gzip on | off;# 作用: 是否启用压缩功能gzip_comp_level level;# 作用: 设置压缩级别，1-9gzip_disable regex ...;# 作用: 对哪些浏览器禁用压缩# 参数: regex 用于匹配请求报文 &quot;User-Agent&quot; 头信息gzip_min_length length;# 作用: 启用压缩功能的响应报文大小阈值；gzip_buffers number size;# 作用: 支持实现压缩功能时为其配置的缓冲区数量及每个缓存区的大小；gzip_proxied off | expired | no-cache | no-store | private | no_last_modified | no_etag | auth | any ...;# 作用: nginx作为代理服务器接收到从被代理服务器发送的响应报文后，在何种条件下启用压缩功能的；# 选项:# off：对代理的请求不启用# no-cache, no-store，private：表示从被代理服务器收到的响应报文首部的# Cache-Control的值为此三者中任何一个，则启用压缩功能；gzip_types mime-type ...;# 作用: 压缩过滤器，仅对此处设定的MIME类型的内容启用压缩功能；gzip on;gzip_comp_level 6;gzip_min_length 64;gzip_proxied any;gzip_types text/xml text/css application/javascript; 2. https 服务配置模块: ngx_http_ssl_module模块12345678910111213141516171819202122232425262728293031ssl on | off;# 作用: 是否 sslssl_certificate file;# 作用: 当前虚拟主机使用PEM格式的证书文件；ssl_certificate_key file;# 作用:当前虚拟主机上与其证书匹配的私钥文件；ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2];# 作用: 支持ssl协议版本，默认为后三个；ssl_session_cache off | none | [builtin[:size]] [shared:name:size];# 作用: 是否缓存 sll 会话# 选项:# builtin[:size]：使用OpenSSL内建的缓存，此缓存为每worker进程私有；# [shared:name:size]：在各worker之间使用一个共享的缓存；# 说明: 如果用户请求被不同的 worker 处理时，私有缓存可能时效，因此应该使用公共缓存ssl_session_timeout time;# 作用: 客户端一侧的连接可以复用ssl session cache中缓存 的ssl参数的有效时长；server &#123; listen 443 ssl; server_name www.magedu.com; root /vhosts/ssl/htdocs; ssl on; ssl_certificate /etc/nginx/ssl/nginx.crt; ssl_certificate_key /etc/nginx/ssl/nginx.key; ssl_session_cache shared:sslcache:20m; # 1m 空间大约能缓存 4000 个会话&#125; 3. 防盗链模块: ngx_http_referer_module模块 1234567891011121314151617181920212223valid_referers none | blocked | server_names | string ...;# 作用: 定义referer首部的合法可用值；# 参数: # none：请求报文首部没有referer首部；# blocked：请求报文的referer首部没有值；# server_names：参数，其可以有值作为主机名或主机名模式；# arbitrary_string：直接字符串，但可使用*作通配符；# regular expression：被指定的正则表达式模式匹配到的字符串；要使用~打头，例如 ~.*\.magedu\.com；$invalid_referer# 作用: 内置的变量，表示当前请求 referer首部是否不符合 valid_referers 定义的规则#配置示例：valid_referers none block server_names *.magedu.com *.mageedu.com magedu.* mageedu.* ~\.magedu\.;if($invalid_referer) &#123; return http://www.magedu.com/invalid.jpg;&#125;valid_referers none blocked server_names *.example.com example.* www.example.org/galleries/ ~\.google\.;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.4 nginx_http配置段(核心模块)]]></title>
    <url>%2F2018%2F09%2F24%2Flinux_mt%2F26-nginx%2Fnginx_http%E9%85%8D%E7%BD%AE%E6%AE%B5_%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[nginx_http配置段(核心模块) 本节我们来讲解 http 配置的第二部分，http 配置段的配置。nginx 没有中心主机的概念，所以 web 服务包括默认的都是虚拟主机，直接支持基于ip，端口和主机名的虚拟主机。http 配置段用于配置 ngnix 的 web 服务器，由ngx_http_core_codule 和其他众多的 http 功能模块组成。本节我们首先来讲解 http_core_codule 提供的配置指令，内容包括 http 配置段简介 配置框架 内置变量 if 上下文 http 基础配置 虚拟主机定义 访问路径配置 索引及错误页配置 网络连接相关的设置 客户端请求的限制 文件操作的优化 客户端请求的特殊处理 内存及磁盘资源分配 1. http 配置段简介1.1 http 配置段框架http配置段的框架如下所示，其遵循以下一些原则 必须使用虚拟机来配置站点；每个虚拟主机使用一个server {}段配置； 非虚拟主机的配置或公共配置，需要定义在server之外，http之内； 与 http 相关的指令仅能够放置于 http、server、location、upstream、if 上下文，某些指令只能用于 5 中上下文中的某一种 12345678910111213141516171819202122232425262728http &#123; sendfile on; # 各server的公共配置 tcp_nopush on; ...： upstream &#123; # 配置反向代理 ...... &#125; server &#123; # 定义一个虚拟主机；nginx支持使用基于主机名或IP的虚拟主机 # 每个 server 类似于 httpd 中的一个 &lt;virtualHost&gt; listen; server_name; root; alias; # 类似 http 中的 &lt;location&gt;, 用于定义URL与本地文件系统的关系 location URL &#123; if .... &#123; .... &#125; &#125; &#125; server &#123; &#125; ...&#125; 1.2 http核心模块的内置变量http核心模块常用的内置变量: $uri: 当前请求的uri，不带参数； $request_uri: 请求的uri，带完整参数； $host: http请求报文中host首部； 如果请求中没有host首部，则以处理此请求的虚拟主机的主机名代替； $hostname: nginx服务运行在的主机的主机名； $remote_addr: 客户端IP $remote_port: 客户端Port $remote_user: 使用用户认证时客户端用户输入的用户名； $request_filename: 用户请求中的URI经过本地root或alias转换后映射的本地的文件路径； $request_method: 请求方法 $server_addr: 服务器地址 $server_name: 服务器名称 $server_port: 服务器端口 $server_protocol: 服务器向客户端发送响应时的协议，如http/1.1, http/1.0 $scheme: 在请求中使用scheme, 如https://www.magedu.com/中的https； $http_HEADER: 匹配请求报文中指定的HEADER， $http_host匹配请求报文中的host首部 $sent_http_HEADER: 匹配响应报文中指定的HEADER， 例如$http_content_type匹配响应报文中的content-type首部； $document_root:当前请求映射到的root配置； 1.3 if 上下文http 配置段内的 if 上下文可以根据 nginx 内的变量执行判断逻辑 语法: if (condition) {.....} 应用: 可应用在 server, location 上下文中 condition: 基于 nginx 变量的测试表达式，支持以下几种测试方式 变量是否为空: 变量名为空串，或者以”0”开始，为 false，否则为 true 比较操作: = ！= 正则表达式模式匹配 ~: 区分大小写 ~*: 不区分大小写 !~ !~*: 表示取反 测试是否为文件: -f !-f 测试是否为目录: -d 测试文件存在性: -e 检查文件是否有执行权限: -x 123456# if 使用示例server &#123; if ($http_user_agent ~* MSIE) &#123; rewrite ^(.*)$ /mise/$1 break; &#125;&#125; 2. http 服务配置nginx 中所有路经都是 uri，nginx 会按照配置的 uri，按照当前配置文件重新查找一次，以找到匹配的文件。 2.1 虚拟主机定义123456789101112131415161718192021222324252627282930313233343536373839404142server &#123; listen 8080 default_server; server_name www.httttao.com; root &quot;/vhost/web/&quot;;&#125;# 作用: 定义一个虚拟主机# 特性: nginx支持使用基于主机名或IP的虚拟主机listen PORT|address[:port]|unix:/PATH/TO/SOCKET_FILElisten address[:port] [default_server] [ssl] [http2 | spdy] [backlog=number] [rcvbuf=size] [sndbuf=size] # 作用: 指定监听的地址和端口# 参数:# default_server：设定为默认虚拟主机；# ssl：限制仅能够通过ssl连接提供服务；# backlog=number：后援队列长度；# rcvbuf=size：接收缓冲区大小；# sndbuf=size：发送缓冲区大小；server_name [...];# 作用: 指明虚拟主机的主机名称；后可跟多个由空白字符分隔的字符串；# 过程: 当nginx收到一个请求时，会取出其首部的server的值，而后跟众server_name进行比较，# * 匹配任意长度字符串# ~ 正则表达式模式匹配# 主机名匹配顺序如下：# 先做精确匹配；www.magedu.com# 左侧通配符匹配；*.magedu.com# 右侧通配符匹配；www.abc.com, www.* # 正则表达式匹配: ~^.*\.magedu\.com\$server_name_hash_bucket_size 32|64|128;# 作用: 为了实现快速主机查找，nginx使用hash表来保存主机名； tcp_nodelay on|off;# 在keepalived模式下的连接是否启用TCP_NODELAY选项，建议启用；tcp_nopush on|off;# 在sendfile模式下，是否启用TCP_CORK选项，建议启用；sendfile on | off;# 是否启用sendfile功能，建议启用； 2.2 访问路径配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051root path# 作用:# 设置资源路径映射# 用于指明请求的 URL 所对应的资源所在的文件系统上的起始路径# 位置：http, server, location, if in location；alias path# 作用: 只能用于location中，定义路径别名；# 对比:# root path 用于替换 location URL 中 URL 最左侧的 &quot;/&quot;# alias path 用于替换 location URL 中 URL 最右侧的 &quot;/&quot;location /image &#123; root &apos;/vhost/web1&apos;&apos;&#125;http://www.tao.com/images/a.jpg ---&gt; /vhost/web1/images/a.jpglocation /imapge &#123; alias &quot;/www/pictures&quot;;&#125;http://www.tao.com/images/a.jpg ---&gt; /www/pictures/a.jpg########################################location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name &#123; ... &#125;# 功能：# 允许根据用户请求的URI来匹配指定的各location以进行访问配置；# url被匹配到时，将被location块中的配置所处理；# 匹配类型# =：精确匹配；# ~：正则表达式模式匹配，匹配时区分字符大小写# ~*：正则表达式模式匹配，匹配时忽略字符大小写# ^~: URI前半部分匹配，不检查正则表达式# 不带符号：匹配起始于此uri的所有的url；# 匹配优先级：精确匹配(=) ^~ ~ ~* 不带任何符号的 locationhttp &#123; server &#123; listen 80; server_name www.tao.comm; location / &#123; root &apos;/vhosts/web1&apos;; &#125; location /images/ &#123; root &apos;/vhosts/images&apos;; &#125; location ~* \.php$ &#123; fcgipass &#125; &#125; &#125; 2.2 索引及错误页配置12345678910111213141516171819202122232425262728index uri ...;# 作用: 定义默认页面，可参跟多个值；# 说明: 这里 uri 与 root，文件系统没有任何关系，# nginx 会按照当前配置的匹配逻辑，找到 uri 的位置error_page code ... [=code] uri | @name;# 作用:# 错误页面重定向# 根据 http 响应状态码来指明特用的错误页面# [=code]: 以指明的响应吗进行响应，而是默认的原来的响应error_page 500 502 503 504 =200 /50x.html;location = /50x.html &#123; root html;&#125;try_files path1 [path2 ...] uri;# 作用:# 自左至右尝试读取由path所指定路径，在第一次找到即停止并返回# 如果所有path均不存在，则返回最后一个uri; # eg:# location ~* ^/documents/(.*)\$ &#123;# root /www/htdocs;# try_files \$uri /docu/\$1 /temp.html;# &#125;# http://www.magedu.com/documents/a.html# http://www.magedu.com/docu/a.html# http://www.magedu.com/temp.html 2.3 网络连接相关的设置12345678910111213141516171819202122232425262728293031keepalive_timeout time;# 保持连接的超时时长；默认为75秒；keepalive_requests n;# 在一次长连接上允许承载的最大请求数；keepalive_disable [msie6 | safari | none ]# 对指定的浏览器(User Agent)禁止使用长连接；tcp_nodelay on|off# 对keepalive连接是否使用TCP_NODELAY选项, on 表示不启用；client_header_timeout time;# 读取http请求首部的超时时长；client_body_timeout time;# 读取http请求包体的超时时长；send_timeout time;# 发送响应的超时时长；client_body_buffer_size size;# 用于接收客户端请求报文的body部分的缓冲区大小；默认为16k；# 超出此大小时，其将被暂存到磁盘上的由client_body_temp_path指令所定义的位置；client_body_temp_path path [level1 [level2 [level3]]];# 设定用于存储客户端请求报文的body部分的临时存储路径及子目录结构和数量；client_body_temp_path /var/tmp/client_body 2 1 1# 1：表示用一位16进制数字表示一级子目录；0-f# 2：表示用2位16进程数字表示二级子目录：00-ff# 2：表示用2位16进程数字表示三级子目录：00-ff 2.4 对客户端请求的限制1234567891011121314151617limit_except method ... &#123; ... &#125;# 指定对范围之外的其它方法的访问控制；limit_except GET &#123; allow 172.16.0.0/16; deny all;&#125;client_max_body_size SIZE;# http请求包体的最大值；# 常用于限定客户所能够请求的最大包体；# 根据请求首部中的Content-Length来检测，以避免无用的传输；limit_rate speed;# 限制客户端每秒钟传输的字节数；默认为0，表示没有限制；limit_rate_after time;# nginx向客户发送响应报文时，如果时长超出了此处指定的时长，则后续的发送过程开始限速； 2.5 文件操作的优化1234567891011121314151617181920212223242526272829sendfile on|off# 是否启用sendfile功能；aio on | off | threads[=pool];# 是否启用aio功能；directio size | off;# 在Linux主机启用O_DIRECT标记，此处意味文件大于等于给定的大小时使用，例如directio 4m;open_file_cache max=N [inactive=time]|off# 作用: 是否打开文件缓存功能；# 参数：# max: 缓存条目的最大值；当满了以后将根据LRU算法进行置换；# inactive: 缓存项的非活动时长，某缓存条目在此选项指定时长内没有被访问过或# 访问次数少于open_file_cache_min_uses指令所指定的次数，则为非活动项，# 将自动被删除；默认为60s;# 缓存信息包括：# 文件句柄、文件大小和上次修改时间；# 已经打开的目录结构；# 没有找到或没有访问权限的信息；open_file_cache_min_uses number;# 在open_file_cache指令的inactive参数指定的时长内，至少应该被命中多少次方可被归类为活动项；open_file_cache_valid time;# 多长时间检查一次缓存中的条目是否超出非活动时长，默认为60s;open_file_cache_errors on|off# 是否缓存文件找不到或没有权限访问等相关信息； 2.6 客户端请求的特殊处理123456789101112131415ignore_invalid_headers on|off# 是否忽略不合法的http首部；默认为on;# off意味着请求首部中出现不合规的首部将拒绝响应；只能用于server和http;log_not_found on|off# 是否将文件找不到的信息也记录进错误日志中；resolver address;# 指定nginx使用的dns服务器地址；resover_timeout time;# 指定DNS解析超时时长，默认为30s;server_tokens on|off;# 是否在错误页面中显示nginx的版本号； 2.7 内存及磁盘资源分配123456789101112131415161718192021222324252627client_body_in_file_only on|clean|off# HTTP的包体是否存储在磁盘文件中；# 非off表示存储，即使包体大小为0也会创建一个磁盘文件；# on表示请求结束后包体文件不会被删除，clean表示会被删除；client_body_in_single_buffer on|off;# HTTP的包体是否存储在内存buffer当中；默认为off；cleint_body_buffer_size size;# nginx接收HTTP包体的内存缓冲区大小；client_body_temp_path dir-path [level1 [level2 [level3]]];client_body_temp_path /var/tmp/client/ 1 2# HTTP包体存放的临时目录；client_header_buffer_size size;# 正常情况下接收用户请求的http报文header部分时分配的buffer大小；默认为1k;large_client_header_buffers number size;# 存储超大Http请求首部的内存buffer大小及个数；connection_pool_size size;# nginx对于每个建立成功的tcp连接都会预先分配一个内存池，# 此处即用于设定此内存池的初始大小；默认为256；request_pool_size size;# nginx在处理每个http请求时会预先分配一个内存池，此处即用于设定此内存池的初始大小；默认为4k;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.3 nginx main 配置段]]></title>
    <url>%2F2018%2F09%2F23%2Flinux_mt%2F26-nginx%2Fnginx_main%E9%85%8D%E7%BD%AE%E6%AE%B5%2F</url>
    <content type="text"><![CDATA[nginx main 配置段 nginx 配置文件有众多参数，因此我们按照配置文件的配置段分别讲解 nginx 配置。本节主要是 ngnix 核心配置段。这些参数可分为如下几个类别: 正常运行的必备配置 优化性能相关的配置 事件相关的配置 用于调试、定位问题 nginx 参数的详细配置可参阅 dirindex 1. 基础核心配置最长需要修改的参数: worker_process worker_connections worker_cpu_affinity worker_priority 1.1 正常运行的必备配置：12345678910111213user username [groupname];# 指定运行worker进程的用户和组pid /path/to/pidfile_name;# 指定nginx的pid文件include file | mask;# eg: include /etc/nginx/conf.d/*.conf;# 指明包含进来的其它配置文件片断,mask 表示支持通配符；load_module file;# load_module &quot;/usr/lib64/nginx/modules/ngx_stream_module.so&quot;;# 指明要装载的动态模块； 1.2 优化性能相关的配置：123456789101112131415161718192021222324252627282930worker_processes n;# worker进程的个数；通常其数值应该小于或等于CPU的物理核心数；worker_processes auto;# nginx 将根据 cpu 数量自动选择 worker 进程数worker_cpu_affinity cpumask ...;# 作用: 对 worker 进程进行 CPU 绑定，用于提升缓存命中率 只有在系统上不存在其他耗费资源的进程时才建议开启# eg:# worker_processes 6;# worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000;worker_cpu_affinity auto; # nginx 将根据 cpu 数量自动绑定worker_priority nice;# 作用: 指明 work 进程的 nice 值, -20,19之间的值worker_rlimit_nofile n;# 指定所有worker进程所能够打开的最大文件句柄数；worker_rlimit_sigpending n;# 设定每个用户能够发往worker进程的信号的数量；ssl_engine device; # 在存在ssl硬件加速器的服务器上，指定所使用的ssl硬件加速设备；timer_resolution t# 作用:# 每次内核事件调用返回时，都会使用gettimeofday()来更新nginx缓存时钟；# timer_resolution用于定义每隔多久才会由gettimeofday()更新一次缓存时钟；# x86-64系统上，gettimeofday()代价已经很小，可以忽略此配置； 1.3 事件相关的配置此配置位于 events {} 配置段内 1234567891011121314151617181920212223work_connections nums# 设定单个 worker 进程能处理的最大并发连接数量, 尽可能大，以避免成为限制，eg: 51200use [epoll|rtsig|select|poll]# 作用: 指明使用的IO模型，建议让Nginx 自动选择accept_mutex [on|off]# 作用: 是否打开Ningx的负载均衡锁；# 功能:# 此锁能够让多个worker进轮流地、序列化地与新的客户端建立连接；# 而通常当一个worker进程的负载达到其上限的7/8，master就尽可能不再将请求调度此worker；accept_mutex_delay ms;# 作用:# accept锁模式中，一个worker进程为取得accept锁的等待时长# 如果某worker进程在某次试图取得锁时失败了，至少要等待ms才能再一次请求锁；lock_file /path/to/lock_file;# 作用: accept_mutex 用到的lock文件路径multi_accept on|off;# 作用: 是否允许一次性地响应多个用户请求；默认为Off; 1.4 用于调试、定位问题: 只调试nginx时使用12345678910111213141516daemon on|off;# 作用:# 是否以守护进程让ningx运行后台；默认为on，# 调试时可以设置为off，使得所有信息去接输出控制台；master_process on|off# 作用:# 是否以master/worker模式运行nginx；默认为on；# 调试时可设置off以方便追踪；error_log path level;# 作用:# 错误日志文件及其级别；默认为error级别；调试时可以使用debug级别，# 但要求在编译时必须使用--with-debug启用debug功能；# path: stderr | syslog:server=address[,paramter=value] | memory:size# level: debug | info | notice| warn|crit| alter| emreg]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.2 nginx基础入门]]></title>
    <url>%2F2018%2F09%2F22%2Flinux_mt%2F26-nginx%2Fnginx%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[nginx基础入门 在学习 nginx 之前，我们首先来对 nginx 做一个入门介绍，后续我们会详细介绍 nginx web server 的配置。本节内容包括: nginx 框架 nginx 安装 nginx 配置文件格式 1. nginx 架构与特性1.1 架构 ngnix 架构如上图所示: Master 进程: 作用: 主控进程负责生成和管理 Worker 进程 特性: 支持动态加载配置文件，平滑升级 Worker: 作用: 作为 web 服务，Worker 进程负责接收和处理用户请求 作为反代服务器，可通过 httpd/FastCGI 等协议向后端服务器(Backend) 转发请求 特性: 支持 http 和 https Workder 内是高度模块化的，新版本 nginx 支持部分模块动态装卸载 支持 epoll，kqueue 等高效的事件驱动的 IO 模型，一个 Worker 进程可同时响应多个用户请求，支持更高的并发链接 Cache: 作用: 支持本地缓存，Cache Loader 缓存加载，Cache manager 缓存管理 特性: 支持 AIO，senfile，mmap 拥有高效的磁盘 IO nginx 高度模块化，但其模块早期不支持DSO机制；近期版本支持动态装载和卸载.模块可分为: 核心模块: core module 标准http模块: Optional HTTP modules 可选的http模块: Standard HTTP modules 邮件模块: Mail modules 传输层代理模块:Stream modules 第三方模块 1.2 nginx 功用nginx 可实现如下功能: 静态资源的web服务器，能缓存打开的文件描述符； http, smtp, pop3 协议的反向代理服务器 缓存、负载均衡； 支持FastCGI(fpm, LNMP), uWSGI(python) 模块化，非DSO机制，过滤器gzip，SSI和图像大小调整等 支持SSL 作为web 服务支持: 基于名称和IP做虚拟主机 支持keepalive 支持平滑配置更新或程序版本升级 定制访问日志，支持使用日志缓存以提高性能 支持url rewrite 支持路径别名 支持基于IP及用户的认证； 支持速率限制，并发限制等； 2. nginx 安装2.1 rpm 包安装默认情况下 epel 仓库与 nginx 官方仓库 rpm 组织 nginx 方式有所不同。 epel 仓库Linux 上 nginx 的 rpm 包由 epel 源提供，因此在安装 nginx 之前需要配置好 epel 的 yum 源1234567891011121314$ sudo vim /etc/yum.repos.d/epel.repo[epel]name=Extra Packages for Enterprise Linux 7 - $basearchbaseurl=http://mirrors.aliyun.com/epel/7/$basearch http://mirrors.aliyuncs.com/epel/7/$basearch#mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearchfailovermethod=priorityenabled=1gpgcheck=0gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7$ sudo yum install nginx$ yum info nginx$ rpm -ql nginx nginx 官方仓库使用 nginx 官方仓库，可以安装 nginx 最新的稳定版本，安装之前首先需要配置其 yum 源，可参考 nginx yum 源 12345678910$ sudo vim /etc/yum.repos.d/nginx.repos[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1$ sudo yum install nginx$ yum info nginx$ rpm -ql nginx 2.2 编译安装123456789101112131415161718192021222324# 1. 编译环境准备yum grouplistyum groupinstall "Development Tools" yum install pcre-devel zlib-develyum install openssl openssl-devel # 2. 编译安装cd /usr/localtar xf nginx-1.14.0.tar.gzcd nginx-1.14.0./configure --helpgroupadd -r nginxuseradd -g nginx -r nginx./configure --prefix=/usr/local/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --with-http_ssl_module --with-http_v2_module --with-http_dav_module --with-http_stub_status_module --with-threads --with-file-aiomake &amp;&amp; make installmkdir -pv /var/tmp/nginx/&#123;client,proxy,fastcgi,uwsgi&#125;# 3. 启动 nginx/usr/local/nginx/sbin/nginx# 4. 可以仿照 rpm 安装时生成的 unit file 为编译安装创建一个服务管理脚本 2.3 nginx 主程序使用nginx 的主程序 nginx, 位于 /usr/sbin/nginx，其使用方式如下: nginx options: 作用: 启动和管理 nginx 服务 选项: ?,-h: 显示命令帮助 v: 显示 nginx 版本 V: 显示 nginx 版本和编译参数 t: 检查配置文件 T: 检查配置文件，并显示配置文件内容 q: nginx 启动测试 s signal: 向 nginx 发送管理信号 stop, quit, reopen, reload c filename: 设置配置文件路经 (default: /etc/nginx/nginx.conf) g directives: 设置 nginx 的全局配置参数，会负载配置文件中同名参数 p prefix: set prefix path (default: /usr/share/nginx/) 3. nginx 配置文件123456789101112# rpm -ql nginx/etc/nginx/ # 配置文件目录/etc/nginx/nginx.conf # 主配置文件/usr/sbin/nginx # 主程序/usr/bin/nginx-upgrade/usr/lib/systemd/system/nginx.service # systemctl 服务管理脚本/usr/lib64/nginx/modules # nginx 模块目录/var/log/nginx # 默认日志存放目录/etc/logrotate.d/nginx 3.1 配置文件结构nginx 配置参数由下面四个个部分组成1234567891011121314151617181920###### main 配置段 ######main block：主配置段，也即全局配置段； event &#123; ... &#125;：事件驱动相关的配置；###### http 配置段 ######http &#123; ...&#125;：http/https 协议相关的配置段；###### mail 配置段 ######mail &#123; ...&#125;###### 传输层代理段 ######stream &#123; ...&#125; main配置段: 基本核心配置，包括 用于调试、定位问题 正常运行的必备配置 优化性能的配置 事件类的配置 http 配置段: 配置 nginx web server mail 配置段: 通常没什么用 3.2 配置文件语法1234user nginx;worker_processes auto;error_log /var/log/nginx/error.log;pid /run/nginx.pid; nginx 由如下语法要求: 语法格式: directive value1 [value2....]; 必需以分号结尾 支持使用变量，自定义变量可以覆盖内置变量的值 内置变量: nginx 内置变量索引 自定义变量: set $var_name value 变量引用: $variable_name]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23.1 IO模型]]></title>
    <url>%2F2018%2F09%2F21%2Flinux_mt%2F26-nginx%2FIO%E4%BA%8B%E4%BB%B6%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[IO模型 nginx 是一个 web 服务器，同时还能作为 http 协议的反向代理服务器。相比于 http，nginx 使用了更先进的 IO 模型，异步通信以及进程间通信的技术，能支持更多的并发请求，具有更高的性能和稳定性。本章我们首先来学习如何使用 nginx 配置一个 web serve，nginx 的反向代理功能我们留在 28 章再来介绍。本章内容包括 IO 事件模型 nginx 框架与配置 nginx web 服务配置 有关 web 的基础概念和 http 协议的内容将不再此累述，大家可以回看以下几个章节: 20.1 web基础概念 20.2 http协议基础 20.3 http协议进阶 想要讲清楚 IO 模型并不容易，对于没有编程经验的来说这是一个很抽象的概念。想理解这个概念可以从以下几点入手: 我们的 web 需要同时响应多个用户请求，但是我们的程序通常是顺序执行的，一次只能响应一个用户请求 响应的内容通常位于磁盘上，而读取磁盘文件，利用网卡发送数据包都是内核提供的功能，应用程序需要发起系统调用 在系统调用返回结果之前，发起调用的应用程序通常只能等待 总结起来就是，web 程序需要同时处理多个用户请求，但是程序通常是顺序执行的，且经常经常阻塞在磁盘和网络 IO 之上。为能够为多个用户同时提供响应我们需要新的技术，这些技术目的是提高程序的 IO 效率称为 IO 模型。要想明白 IO 模型，我们首先要明白系统调用的过程。 1. IO 系统调用1.1 IO 过程 我们以读取磁盘文件为例: 当我们需要读取文件时，首先发起 read 系统调用 此时会陷入内核，执行内核代码，将数据从磁盘读取到内核缓冲区中 将内核缓冲区中的数据从内核拷贝到应用程序内存空间 1.1 同步/异步同步/异步关注的是 被调用者，如何通知调用者，即被调用者与调用者之间消息通知的机制 在 IO 上就是应用程序与操作系统的交互方式 1.2 阻塞/非阻塞阻塞/非阻塞关注的是 调用者如何等待结果，即调用程序的执行模式 1.3 IO 模型类别 同步阻塞 同步非阻塞 IO复用(事件驱动IO)：select, poll，epoll: 信号驱动I/O 异步IO 参考连接: https://songlee24.github.io/2016/07/19/explanation-of-5-IO-models/ https://blog.csdn.net/wuzhengfei1112/article/details/78242004 https://blog.csdn.net/lijinqi1987/article/details/71214974 2. httpd 的IO 模型 多进程模型：prefork, 一个进程响应一个用户请求，并发使用多个进程实现； 多线程模型：worker, 一个进程生成多个线程，一个线程响应一个用户请求；并发使用多个线程实现；n进程，n*m个线程； 事件模型：event, 一个线程响应多个用户请求，基于事件驱动机制来维持多个用户请求；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16 wrapt 模块实战]]></title>
    <url>%2F2018%2F06%2F07%2Fwrapt%2Fpython_decorator_16%2F</url>
    <content type="text"><![CDATA[装饰器和 wrapt 模块的介绍已经结束，作为整个系列的最后一篇的实战篇，我们来实现在一开始我提出的一个需求 1. 应用场景在我日常的开发过程中，经常要查询各种数据库，比如 mysql, mongo，es 。基本上所有的数据库对查询语句能添加的查询条件都有限制。对于大批量的查询条件，只能分批多次查询，然后将查询结果合并。我们能不能将这种查询分批在合并的操作抽象出来实现为一个装饰器，在需要时对查询函数包装即可？下面是我的一个实现示例。 2. 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/usr/bin/python# -*- coding: utf-8 -*-"""作用：用于优化的装饰器功能： 1. 实现分组迭代，分批查询的装饰器"""import osimport sysimport wraptimport inspectimport pandasdef get_slice(total_num, slice_num): """ :return: 等大小切片 """ r = [] n = total_num / slice_num m = total_num % slice_num end = 0 for i in range(1, n + 1): start = slice_num * (i - 1) end = slice_num * i r.append(slice(start, end)) else: if m &gt; 0: r.append(slice(end, end + m)) return rdef slice_call(iter_param, slice_num=500): @wrapt.decorator def wrapper(wrapped, instance, args, kwargs): # 函数自省 param = inspect.getcallargs(wrapped, *args, **kwargs) if instance: param.pop('self') if 'kwargs' in param: kwargs = param.pop('kwargs',&#123;&#125;) param.update(kwargs) iter_value = param.get(iter_param) if iter_value is None: return wrapped(**param) if isinstance(iter_value, pandas.DataFrame): iter_value.reset_index(drop=True, inplace=True) # 分批 total_num = len(iter_value) slice_iter = get_slice(total_num, slice_num) result = [] # 合并 for s in slice_iter: param[iter_param] = iter_value[s] result.append(wrapped(**param)) if result: return pandas.concat(result) else: return pandas.DataFrame() return wrapper# slice_call 使用示例@slice_call(iter_param='names')def get_video_by_name(self, names, c_type): where_name = "'" + "','".join(names) + "'" sql = ('select * from table' 'where a="%s" and b in (%s) and c&gt;=0;' % (c_type, where_name)) print sql df = self.mysql_obj.query('', sql) df['updateTime'] = df['updateTime'].apply(lambda x: x.strftime("%Y-%m-%d")) return df slice_call 函数在使用有一个限制条件，被包装函数的返回值必需是 pandas.DataFrame。因为在我日常的工作中，经常使用到 pandas 进行数据分析，对我来说，DataFrame 是一个非常通用的数据结构，因此就在此基础上构建了 slice_call 装饰器。整个实现中使用的额外知识就是函数的自省，由 inspect 模块提供，其他有关装饰器的部分都是前面博客介绍的内容，相信大家应该很容易就能看懂。 结语至此 Python 装饰器的内容就先到此为止，接下来想结合 wrapt, unittest, mock 来说一说如何在 Python 中作单元测试。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15 wrapt 模块使用]]></title>
    <url>%2F2018%2F06%2F06%2Fwrapt%2Fpython_decorator_15%2F</url>
    <content type="text"><![CDATA[GrahamDumpleton wrapt blog 的翻译部分到此就结束。很可惜的是作者并没有把猴子补丁部分写完，查阅了 wrapt 的官方文档，上面只介绍了 wrapt 的装饰器，代理对象以及 synchronized 同步装饰器，也没有介绍猴子补丁相关内容。不过已经介绍的内容足够用了，接下来我想结合 wrapt 的文档介绍一下 wrapt 模块的使用，算是整个博客的总结。 1. 前文回顾在阐述 wrapt 的使用之前，有必要对之前的内容做一个简单总结，因为 wrapt 模块的接口正是与之前的内容一一对应的。GrahamDumpleton 编码 wrapt 的本意是想实现为 Python 代码中添加猴子补丁，然而 Python 中装饰器，辅助测试的模拟库与猴子补丁的实现方式极其相似，因此 GrahamDumpleton 就按照如下的方式为将我们讲解了 wrapt 模块的功用。 如何在 Python 实现一个通用的装饰器 如何使用 wrapt 实现模拟库来辅助单元测试 如何为 Python 添加猴子补丁 装饰器，模拟库，猴子补丁的实现是递进的。装饰器通常是在导入时，在被装饰的函数定义之后立即运行，且永久全局有效；模拟库作用的范围变窄，需要实现只作用于特定范围，比如特定的测试函数中；猴子补丁更随意，通常在类创建一段时间之后再执行，这种延迟性导致猴子补丁存在相对导入的次序问题。对于我们而言搞清楚装饰器与模拟库的使用即可，能使用到猴子补丁的情景少之又少。 装饰器那如何实现一个装饰器？传统的通过闭包实现的装饰器存在以下问题: 无法保留函数的自省属性和签名信息，无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 为解决这些问题和解决代码复用问题，wrapt 创建了以下对象或函数: 代理对象: ObjectProxy，解决了自省问题 包装对象: FunctionWrapper, BoundFunctionWrapper 继承自 ObjectProxy，并为装饰行为实现了描述符协议 工厂函数: decorator 解决了创建装饰器的代码复用问题。 wrapt 为辅助单元测试提供了另外一个工厂函数 transient_function_wrapper，其能创建一个仅仅限于特定范围的临时补丁。 装饰器实现的核心就是包装器对象，它同时接收包装函数，和被包装函数，并作为装饰结果的返回值替换被包装函数。在被包装函数被调用时，实际调用包装函数。所以包装对象同时实现了对象代理和描述符协议。 2. wrapt 接口123456789101112# wrapt.__init__from .wrappers import (ObjectProxy, CallableObjectProxy, FunctionWrapper, BoundFunctionWrapper, WeakFunctionProxy, resolve_path, apply_patch, wrap_object, wrap_object_attribute, function_wrapper, wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper)from .decorators import (adapter_factory, AdapterFactory, decorator, synchronized)from .importer import (register_post_import_hook, when_imported, notify_module_loaded, discover_post_import_hooks) wrapt 模块提供的接口大体上分成了以下几类: 代理对象: ObjectProxy, CallableObjectProxy, WeakFunctionProxy 包装对象: FunctionWrapper, BoundFunctionWrapper 装饰器工厂函数: function_wrapper, decorator 辅助测试的工厂函数: wrap_function_wrapper, patch_function_wrapper, transient_function_wrapper 猴子补丁相关: .importer synchronized: java synchronized 的 Python 实现 接下来我们会详细介绍上述典型接口的使用方式。 2. 代理对象 ObjectProxy所谓代理包含两个层面的意思: 将上层的请求传递给后端的对象 将后端对象的返回值返回给上层的调用方 wrapt 模块的底层实现就是基于透明对象代理的包装器类。这种代理对象不仅代理了普通方法和属性的访问，也代理了众多内置方法和自省属性。这使得代理对象和被代理对象在 Python 的数据模型层面是完全一致。使用代理对象去代替被代理对象不会打破 Python 的内省机制。并且我们可以在代理对象上自定义属性和方法，以此来重载被代理对象的默认功能。 2.1 对象联动123456class ObjectProxy(with_metaclass(_ObjectProxyMetaType)): __slots__ = '__wrapped__' def __init__(self, wrapped): object.__setattr__(self, '__wrapped__', wrapped) ObjectProxy 是 wrapt 代理功能实现的基类，通常不直接使用，而是作为自定义代理对象的基类使用。代理对象实现了如下功能: 所有对代理对象的访问都会传递给被代理对象，包括比较操作，哈希这些 Python 的内置方法 在代理对象上自定义的方法会覆盖被代理对象同名方法，因此我们可以通过代理对象实现对被代理对象的方法重载 所有对代理对象属性的修改都会传递并修改后端的被代理对象 对后端被代理对象属性的直接修改也会直接反映在代理对象之上 也就是说默认情况下，对 ObjectProxy 的操作，方法是重载的，而对属性的修改，是直接作用在被代理对象上的。 123456789101112&gt;&gt;&gt; table = &#123;&#125;&gt;&gt;&gt; proxy = wrapt.ObjectProxy(table)&gt;&gt;&gt; proxy['key-1'] = 'value-1'&gt;&gt;&gt; proxy['key-2'] = 'value-2'&gt;&gt;&gt; proxy.keys()['key-2', 'key-1']&gt;&gt;&gt; table.keys()['key-2', 'key-1']&gt;&gt;&gt; isinstance(proxy, dict)True 2.2 不可变对象上述操作对于不可变对象的自操作是特例。 1234567891011121314&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; proxy += 1&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; print(proxy)2&gt;&gt;&gt; print(value)1 对于不可变对象，被代理对象保存的被代理对象的副本，因此对其自身的修改不会影响到后端的被代理对象。 2.3 类型比较由于 Python 复杂的对象模型和底层设计，以及 instance 函数内在比较逻辑，想把 ObjectProxy 类型比较的原理说清楚实在不容易。这里就不深入见解了，简而言之 ObjectProxy 类实例的__class__ 属性返回的是被代理对象的__class__ 属性值，instance()在进行类型检查时，首先比较的是 __class__，所以对代理对象进行类型比较的结果与以被代理对象本身进行比较的结果完全一致。同时由于抽象基类机制，ObjectProxy 实例与 ObjectProxy 类的类型比较也能正常进行。 12345678910111213141516171819202122232425&gt;&gt;&gt; value = 1&gt;&gt;&gt; proxy = wrapt.ObjectProxy(value)&gt;&gt;&gt; type(proxy)&lt;type 'ObjectProxy'&gt;&gt;&gt;&gt; class CustomProxy(wrapt.ObjectProxy):... pass&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; type(proxy)&lt;class '__main__.CustomProxy'&gt;# 与被代理对象的类型比较&gt;&gt;&gt; proxy.__class__&lt;type 'int'&gt;&gt;&gt;&gt; isinstance(proxy, int)True# 与代理对象的类型比较&gt;&gt;&gt; isinstance(proxy, wrapt.ObjectProxy)True&gt;&gt;&gt; isinstance(proxy, CustomProxy)True 2.4 方法重载方法重载只要在自定义代理对象上自定义同名的方法即可，在代理对象内，通过 __wrapped__ 属性可以访问到原始的被代理的对象。 123456789101112131415161718def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __call__(self, *args, **kwargs): print('entering', self.__wrapped__.__name__) try: return self.__wrapped__(*args, **kwargs) finally: print('exiting', self.__wrapped__.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function)&gt;&gt;&gt; proxy()('entering', 'function')('executing', 'function')('exiting', 'function') 2.5 属性重载因为对 ObjectProxy 属性的访问都会直接代理至后端被代理对象，那如何自定义 ObjectProxy 自身的属性呢？ 方法一，任何以 _self_ 开头的属性只会保存在 ObjectProxy 上，不会传递给后端的被代理对象 12345678910111213141516171819202122232425262728def function(): print('executing', function.__name__)class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs)def wrapper(wrapped, args, kwargs): print('entering', wrapped.__name__) try: return wrapped(*args, **kwargs) finally: print('exiting', wrapped.__name__)&gt;&gt;&gt; proxy = CallableWrapper(function, wrapper)&gt;&gt;&gt; proxy._self_wrapper&lt;function wrapper at 0x1005961b8&gt;&gt;&gt;&gt; function._self_wrapperTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function' object has no attribute '_self_wrapper' 方法二，借助于 @property，定义属性描述符1234567891011121314151617181920212223242526272829class CustomProxy(wrapt.ObjectProxy): def __init__(self, wrapped): super(CustomProxy, self).__init__(wrapped) self._self_attribute = 1 @property def attribute(self): return self._self_attribute @attribute.setter def attribute(self, value): self._self_attribute = value @attribute.deleter def attribute(self): del self._self_attribute&gt;&gt;&gt; proxy = CustomProxy(1)&gt;&gt;&gt; print proxy.attribute1&gt;&gt;&gt; proxy.attribute = 2&gt;&gt;&gt; print proxy.attribute2&gt;&gt;&gt; del proxy.attribute&gt;&gt;&gt; print proxy.attributeTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'int' object has no attribute 'attribute' 方法三，将属性定义为类属性123456789101112131415&gt;&gt;&gt; class CustomProxy(ObjectProxy):... attribute = None...&gt;&gt;&gt; def function():... print('executing', function.__name__)...&gt;&gt;&gt; j = CustomProxy(function)&gt;&gt;&gt; j.attribute = 2&gt;&gt;&gt;&gt;&gt;&gt; function.attribute = 5&gt;&gt;&gt; print(j.attribute)2&gt;&gt;&gt; print(function.attribute)5 3. 扩展的代理对象除了默认 ObjectProxy 代理基类，wrapt 还提供了另外两个通用的代理对象。 3.1 CallableObjectProxy1234class CallableObjectProxy(ObjectProxy): def __call__(self, *args, **kwargs): return self.__wrapped__(*args, **kwargs) CallableObjectProxy 代理对象专用于代理函数，只是额外的附加了__call__方法，让代理对象成为可调用对象。 3.2 WeakFunctionProxy123456# 代理有点长，不粘了，有兴趣查看 wrapt 的源码class WeakFunctionProxy(ObjectProxy): __slots__ = ('_self_expired', '_self_instance') def __init__(self, wrapped, callback=None): 默认情况下，代理对象通过 __wrapped__ 属性保存了对被代理对像的引用，这样会导致被代理对象始终被引用而无法被垃圾处理器收回，WeakFunctionProxy 的作用就是实现在代理对象中实现对被代理对象的弱引用。在代理对象中实现弱引用并不容易，特别是对绑定方法对象的处理，以及要避免在回调函数中出现循环引用。有兴趣的同学可以看看 wrapt 的源代码。 3.3 自定义代理对象如上述两个内置扩展的代理对象，通过继承 ObjectProxy，我们也可以自定代理对象。代理对象中的方法会覆盖被代理对象的同名方法，利用这个特性我们可以重载被代理对象的行为，这在单元测试中经常使用，待会会有使用的详细示例。 4. 包装对象下面是在代理对象基础上实现包装器的简单示例，包装器继承自 wrapt.ObjectProxy，并将被代理对象作为参数传递给 ObjectProxy，从而具备了代理功能，并在此基础上附加了描述协议的处理逻辑。我们需要使用或者自定义包装对象的情景很少，此处不再对其作过多描述。 123456789101112class CallableWrapper(wrapt.ObjectProxy): def __init__(self, wrapped, wrapper): super(CallableWrapper, self).__init__(wrapped) self._self_wrapper = wrapper def __get__(self, instance, owner): function = self.__wrapped__.__get__(instance, owner) return BoundCallableWrapper(function, self._self_wrapper) def __call__(self, *args, **kwargs): return self._self_wrapper(self.__wrapped__, args, kwargs) 5. 辅助测试5.1 工厂函数wrapt 中有三个辅助测试的包装对象 wrapt.wrap_function_wrapper: 创建猴子补丁的工厂函数，会创建永久有效的补丁 wrapt.patch_function_wrapper: 简化 wrapt.wrap_function_wrapper 的装饰器函数 wrapt.transient_function_wrapper: 创建一个仅仅限于特定范围的临时补丁 下面是它们的使用实例 1234567891011121314151617181920212223242526def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)class Example(object): def name(self): return 'name'import wrapt# 版本一wrapt.wrap_function_wrapper(Example, 'name', wrapper) # 等同于wrapt.wrap_function_wrapper('example', 'Example.name', wrapper)# 版本二@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)# 版本三，wrapper 只对 test_method() 函数有效@transient_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@wrapper def test_method(): pass 5.2 高阶用法除了上述简单的使用示例外，12 使用 wrapt 辅助测试 还有更高级的使用示例，下面是示例代码。 包装一个返回函数的被包装对象12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 包装一个类示例的被包装对象123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 6. synchronizedsynchronized 装饰器实现了 java 中的同步原语 synchronized 功能。synchronized 功能和实现请参阅 07 实现 java 的 @synchronized 装饰器，下面是其使用方式 6.1 作为装饰器123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 6.2 作为上下文管里器1234567891011121314151617181920class Class(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): passclass Class(object): @synchronized @classmethod def function_cm(cls): pass def function_im(self): with synchronized(Class): pass 6.3 基于任意对象作同步除了使用默认的内置锁，synchronized 支持接收任意对象实现同步。但是作为同步而传入的对象必需能添加属性，因为 synchronized 会在传入的对象上保存创建的锁对象。因此为解除这个限制，synchronized 也支持传入支持 .require 和 .release 的类锁对象实现同步。 123456789101112131415161718192021class Data(object): passdata = Data()def function_1(): with synchronized(data): passdef function_2(): with synchronized(data): pass# synchronized 使用到了 vars(data)，任何没有 `__dict__` 属性的对象，都会调用失败&gt;&gt;&gt; vars(&#123;&#125;)Traceback (most recent call last): File "/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2882, in run_code exec(code_obj, self.user_global_ns, self.user_ns) File "&lt;ipython-input-3-880c6250c41c&gt;", line 1, in &lt;module&gt; vars(&#123;&#125;)TypeError: vars() argument must have __dict__ attribute 6.4 基于传入的类锁对象作同步12345semaphore = threading.Semaphore(2)@synchronized(semaphore)def function(): pass 任何支持 acquire() 和 release() 对象均可作为 synchronized的参数，因此用户可传入包含这两个方法的自定义对象来实现额外的功能。 7. decorator12def decorator(wrapper=None, enabled=None, adapter=None): pass decorator 工厂函数是 function_wrapper 工厂函数的升级版本，在装饰器基础上添加了另外两个控制功能，enabled 和 adapter参数必需作为关键词参数被使用。 7.1 装饰启动开关静态控制enabled 参数用于控制装饰器是否被启用，接收布尔值作为参数，enabled=True 时，装饰器正常启用，enabled=False 时不会应用任何包装器。因此，这提供了一种方便的方法，可以全局禁用特定的decorator，而不必删除decorator的所有用法，或者使用decorator函数的特殊变体。 123456789101112ENABLED = False@wrapt.decorator(enabled=ENABLED)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@pass_throughdef function(): pass&gt;&gt;&gt; type(function)&lt;type 'function'&gt; 动态控制在定义修饰符时为启用的选项提供一个布尔值，从而控制修饰符是否应该应用。因此，这是一个全局开关，一旦禁用，就无法在运行时在进程执行时动态地重新启用它。类似地，一旦启用，就不能禁用它。 提供布尔值的另一种方法是为enabled提供一个可调用对象 callable，该值返回一个布尔值。每次调用修饰函数时都将调用callable。如果callable返回True，表示decorator是活动的，则将调用包装器函数。如果callable返回False，包装器函数将被绕过，原始包装函数将被直接调用。 如果enabled不是None、布尔值或可调用值，则将对提供的对象执行布尔检查。这允许使用支持逻辑操作的定制对象。如果定制对象计算为False，包装器函数将再次被绕过。 123456def _enabled(): return True@wrapt.decorator(enabled=_enabled)def pass_through(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 7.2 更改签名信息默认的包装函数的签名来自被包装对象，adapter 参数的作用用于修改包装函数的签名信息。其接收一个函数作为参数，此函数的签名信息将作为包装函数的签名信息被返回。这个用的很少，就不再累述了。 实战有关 wrapt 的模块的实现和接口到此就介绍完了，在本系列博客的开篇我提到了我使用装饰器的一个典型应用场景: 对数据库查询实现分批操作。在接下来的的博客中，作为实战篇，我们来看看如何通过 wrapt 实现这个比较通用的需求。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14 为 Python 应用自动打补丁]]></title>
    <url>%2F2018%2F06%2F05%2Fwrapt%2Fpython_decorator_14%2F</url>
    <content type="text"><![CDATA[前面我们已经决绝了猴子补丁的导入次序问题，但是这个解决方案有个前提，就是我们必需能修改应用程序代码，以在程序的最开始执行我们的注册函数。本节我们的目的是找到另一种解决方案取消这个限制。 1. 猴子补丁的问题所在在之前关于猴子的文章中，我们讨论了导入次序问题。也就是说，正确使用猴子补丁取决于，我们能在任何其他代码导入我们想要修补的模块之前为其打上打补丁。换句话说就是在我们打补丁之前，其他代码是否已经按名称导入了对模块内函数的引用，并将其存储在它自己的名称空间中。即在打补丁之前，其他模块是否已经使用了 from module import function 如果我们不能尽早进入，那么就需要对目标函数的所有使用打补丁，这在一般情况下是不可能的，因为我们不知道函数在哪里被导入。我所描述的一种解决方案是使用导入后钩子机制，使我们能够在模块被任何代码导入之前访问模块并打补丁。这种技术仍然依赖于在有效运行其他代码之前安装导入后钩子机制本身。这意味着必须手动修改应用程序的主Python脚本文件，这并不总是实用的。本文的目的是研究如何避免修改主Python脚本文件来解决导入次序问题。 2. 在 .pth 文件中执行代码作为Python导入系统的一部分，以及在哪些目录中搜索Python模块，有一种扩展机制，即可以将一个.pth扩展名文件安装到Python的site-packages目录中。用于指明Python包代码并不在默认的Python模块搜索路径上，而是存在于其他位置，通常是在site-packages的子目录中。.pth文件的目的是充当指向Python包的实际代码的指针。 在简单的情况下，.pth文件将包含与包含Python包代码的实际目录的名称相关的或绝对的路径名。如果它是一个相对路径名，那么它将相对于.pth文件所在的目录。 如果使用 .pth，当Python 解释器初始化时，它会创建Python模块的搜索路经，在添加所有默认搜索目录后，它将查找 site-packages内的所有目录，并解析每一个 .pth 文件，并将 .pth 内的目录添加到最后的搜索目录列表中。 现在，在Python的历史中，这个.pth机制被增强了，以支持一个特殊的情况。这种特殊情况是，如果.pth文件中的一行从导入开始，那么该行将作为Python代码执行，而不是简单地将其作为目录添加到要搜索模块的目录列表中。 这最初是为了允许为模块执行特殊的启动代码，以允许为Unicode注册一个非标准的编解码器。不过，它后来也被用于easy_install的实现中，如果您曾经运行过easy-install并查看了site-packages目录中的easy-install.pth文件，您会发现以下代码: 123import sys; sys.__plen = len(sys.path)./antigravity-0.1-py2.7.eggimport sys; new=sys.path[sys.__plen:]; del sys.path[sys.__plen:]; p=getattr(sys,'__egginsert',0); sys.path[p:p]=new; sys.__egginsert = p+len(new) 因此，只要能够将代码放在一行上，就可以在每次运行Python解释器时，在.pth文件中做一些非常古怪的事情。我(作者)认为可执行代码在.pth文件中的概念是非常危险的，到目前为止，我(作者)一直避免依赖.pth文件的这个特性。 我(作者)对.pth文件中的可执行代码的担心是它总是在运行。这意味着，即使您已经将预构建的RPM/DEB包或Python wheel 安装到系统中的Python安装环境中，并且认为这样做更安全，因为避免了作为根用户运行 setup.py。但是.pth文件意味着包仍然可以在您不知情的情况下运行代码，甚至不需要将模块导入任何应用程序。考虑到安全性，Python真应该有一个白名单机制，用于确定信任哪些.pth文件，以允许其在每次运行Python解释器(特别是作为根用户)时执行代码。 如果有人关心的话，我将把这个讨论留给其他人来讨论，至少现在我将展示如何使用.pth文件的这个特性(滥用)来实现对正在运行的任何Python应用程序进行自动的猴子补丁的机制。 3. 添加导入勾子在前一篇文章中，我们讨论的导入后钩子机制，在任何Python应用程序脚本文件的开头，我都需要手动添加如下代码: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 它所做的是使用环境变量作为任何使用setuptools入口点注册的包的名称来源，这些入口点包含我们想要应用的猴子补丁。 了解了可以在.pth文件执行代码的能力,现在可以使用它，让这段代码在Python解释器启动时自动执行,从而避免了每次都需要手动修改每个Python应用程序，来应用我们的猴子补丁。 但是在实践中，我们需要的代码实际上要比这个稍微复杂一些，并且不能很容易地直接添加到.pth文件中，这是由于需要将所有代码写在一行上。因此，我们要做的是将所有代码放在一个单独的模块中，然后执行该模块。我们不希望每次都导入那个模块，也许用户看到它被导入时会感到害怕，即使它没有被使用，所以我们将通过环境变量的判断使用它。因此，我们可以在我们的.pth中使用的是: 1import os, sys; os.environ.get('AUTOWRAPT_BOOTSTRAP') and __import__('autowrapt.bootstrap') and sys.modules['autowrapt.bootstrap'].bootstrap() 也就是说，如果环境变量被设置为非空值，那么我们需要导入包含引导代码的模块并执行它。至于引导代码，这就有点麻烦了。我们不能只使用以前手动修改Python应用程序脚本文件时使用的代码。这是因为.pth文件的解析发生在Python解释器初始化。 问题有两个。第一个问题发生在执行导入钩子的发现，当.pth文件被执行时，它被处理的顺序是未知的，所以在我们的代码运行的时候，最终的Python模块搜索路径可能没有设置。第二个问题是.pth文件的处理发生在任何sitecustomize.py或usercustomize.py被处理完之前。因此，Python解释器可能不在其最终配置状态。因此，我们必须对我们所做的事情小心一点。 我们真正需要的是将任何操作延迟到Python解释器的初始化完成之后。问题是我们如何做到这一点。 4. site 模块Python解释器初始化的最后部分是由site 模块的main()函数完成的 1234567891011121314151617181920212223def main(): global ENABLE_USER_SITE abs__file__() known_paths = removeduppaths() if ENABLE_USER_SITE is None: ENABLE_USER_SITE = check_enableusersite() known_paths = addusersitepackages(known_paths) known_paths = addsitepackages(known_paths) if sys.platform == 'os2emx': setBEGINLIBPATH() setquit() setcopyright() sethelper() aliasmbcs() setencoding() execsitecustomize() if ENABLE_USER_SITE: execusercustomize() # .pth 在此之后执行 # Remove sys.setdefaultencoding() so that users cannot change the # encoding after initialization. The test for presence is needed when # this module is run as a script, because this code is executed twice. if hasattr(sys, "setdefaultencoding"): del sys.setdefaultencoding 我们希望依赖的.pth解析和代码执行是在addsitepackages()函数中完成的。因此，我们真正需要的是将代码的任何执行推迟到execsitecustomize()中或execusercustomize()函数运行之后。实现这一点的方法是对这两个函数进行修改，并在它们完成时触发我们的代码。 我们需要都打上补丁，因为usercustomize.py的执行是可选的，取决于ENABLE_USER_SITE环境变量是否为真。因此，我们的bootstrap()函数应该如下 1234567891011121314151617181920def _execsitecustomize_wrapper(wrapped): def _execsitecustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: if not site.ENABLE_USER_SITE: # 判断 _register_bootstrap_functions() return _execsitecustomizedef _execusercustomize_wrapper(wrapped): def _execusercustomize(*args, **kwargs): try: return wrapped(*args, **kwargs) finally: _register_bootstrap_functions() return _execusercustomizedef bootstrap(): site.execsitecustomize = _execsitecustomize_wrapper(site.execsitecustomize) site.execusercustomize = _execusercustomize_wrapper(site.execusercustomize) 尽管我曾经说过手工构建的猴子补丁有多糟糕，并且wrapt模块应该用于创建猴子补丁，但是在这种情况下，我们实际上不能使用wrapt模块。这是因为从技术上讲，作为用户安装的包，wrapt包此时可能不能使用。如果wrapt的安装方式是这样的，那么导入它的能力本身就依赖于.pth文件的处理。因此，我们使用一个函数闭包来使用简单的包装器。 在实际的包装器中，您可以看到两个包装器中哪个最终调用 _register_bootstrap_functions() 取决于ENABLE_USER_SITE是否为真，如果启用了对usersitecustomize()的支持，那么只能在execsitecustomize()中调用它。 最后，我们现在将_register_bootstrap_functions() 定义为: 1234567891011_registered = Falsedef _register_bootstrap_functions(): global _registered if _registered: return _registered = True from wrapt import discover_post_import_hooks for name in os.environ.get('AUTOWRAPT_BOOTSTRAP', '').split(','): discover_post_import_hooks(name) 5. 初始化包我们已经解决了所有问题，但是如何安装它，特别是如何安装自定义的.pth文件。为此我们使用一个设置.py文件: 12345678910111213141516import sysimport osfrom setuptools import setupfrom distutils.sysconfig import get_python_libsetup_kwargs = dict( name = 'autowrapt', packages = ['autowrapt'], package_dir = &#123;'autowrapt': 'src'&#125;, data_files = [(get_python_lib(prefix=''), ['autowrapt-init.pth'])], entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, install_requires = ['wrapt&gt;=1.10.4'],)setup(**setup_kwargs) 为了安装.pth，我们使用了setup()调用的data_files参数。使用distutils.sysconfig模块中的get_python_lib()函数确定安装文件的实际位置。前缀“空字符串”的参数确保了Python包安装的路经为 site-packages 的相对路径，而不是绝对路径。** 安装这个包时非常重要的一点是，您不能使用easy_install或python setup.py安装。只能使用pip安装这个包。 这样做的原因是，如果不使用pip，那么包安装工具可以将包安装为egg。在这种情况下，自定义.pth文件实际上将安装在egg目录中，而不是实际安装在site-packages目录中。 .pth文件只有被添加到 site-packages 目录中，才能用于映射autowrapt包存在的子目录。从site模块调用的addsitepackages()函数并不会处理包含在.pth文件添加的目录中的.pth文件，因此我们的自定义.pth文件将被跳过。** 在使用“pip”时，默认情况下不使用eggs，所以可行。 还要注意的是，这个包不能与buildout一起工作，因为它总是将包作为eggs安装，并且在Python 安装环境中安装任何脚本时，都会显式地设置Python模块搜索路径本身。 6. 使用示例此软件包的实际完整源代码可在: https://github.com/GrahamDumpleton/autowrapt 这个包也在PyPi上作为autowrapt发布，因此您可以尝试它，如果您真的想使用它的话。为了方便快速地测试它是否有效，autowrapt包打包了一个示例monkey patch。在上面的setyp.py被设置如下:** 1entry_points = &#123;'autowrapt.examples': ['this = autowrapt.examples:autowrapt_this']&#125;, 这个entry point 定义了一个名为autowrapt.examples的猴子补丁。定义了当导入 this 模块时，模块autowrapt.examples中的猴子补丁函数autowrapt_this()将被执行。** 所以要运行这个测试需要: pip install autowrapt 如果没有所需的最小版本，也应该安装wrapt模块。现在正常运行命令行解释器，并在提示符处执行: import this 这应该会显示Python的Zen。退出Python解释器，现在运行: AUTOWRAPT_BOOTSTRAP=autowrapt.examples python 这将再次运行Python解释器，并将环境变量AUTOWRAPT_BOOTSTRAP设置为autowrapt.examples,以匹配在setup.py中为autowrapt定义的entry point。autowrapt_this()”函数的实际代码是: 1234from __future__ import print_functiondef autowrapt_this(module): print('The wrapt package is absolutely amazing and you should use it.') 所以如果我们再一次运行: import this 我们现在应该看到Python Zen的扩展版本。在本例中，我们实际上并没有对目标模块中的任何代码打补丁，但它显示了补丁函数实际上是按预期被触发。 7. 其他机制虽然这种机制相当干净，并且只需要设置环境变量，但是不能像前面提到的那样与buildout一起使用。对于buildout，我们需要研究其他可以实现同样效果的方法。我将在下一篇关于这一主题的博文中讨论这些其他选择。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13 猴子补丁在 Python 中的加载次序问题]]></title>
    <url>%2F2018%2F06%2F04%2Fwrapt%2Fpython_decorator_13%2F</url>
    <content type="text"><![CDATA[本节我们就来解决如何在 Python 中打补丁的问题。 1. 猴子补丁的加载次序问题在第 11 篇博客中，我们提到了应用猴子补丁时可能存在的问题。具体地说，如果需要被打补丁的模块已经被导入并被其他代码使用，那么它可能已经在自己的名称空间中创建了一个被打补丁的目标函数的本地引用。因此，尽管猴子补丁可以正常工作，但是仍然无法覆盖这种原始函数已经导入，并过通过本地引用直接访问原始函数的情况。 导入次序问题的解决方案之一是所谓的导入钩子。这是在PEP 369中描述的一种机制，虽然它从未进入Python核心，但是仍然可以使用现有的api将这种能力移植到Python中。然后，在模块导入目标函数并在自己的名称空间中创建对函数的引用之前，我们可以添加其他功能来发现猴子补丁代码，并在导入模块时自动应用它。 Post import hook mechanism暂时将 “Post import hook” 称为导入后勾子。导入后勾子机制在 PEP 369 中有一个使用示例: 12345import imp@imp.when_imported('decimal')def register(decimal): Inexact.register(decimal.Decimal) 其基本思想是，当看到这段代码时，它将导致在Python导入系统中注册一个回调，以便在导入decimal模块时，调用装饰器应用的register()函数。register()函数的参数是对被注册的模块的引用。然后，该函数可以对模块执行一些操作，最后再将模块返回到最初请求导入的代码中。除了使用作为装饰器的@imp.where_imported函数 ，还可以显式地使用imp.register_post_import_hook() 函数来注册导入后钩子。 123456import impdef register(decimal): Inexact.register(decimal.Decimal)imp.register_post_import_hook(register, 'decimal') 尽管PEP 369从未被合并到Python中，但是wrapt 提供了类似功能的装饰器和函数。尽管装饰器和函数被用来解决导入次序问题。但如果目标模块在导入后钩子函数执行之前就已经被导入，我们仍会面临导入次序问题。 这个问题最简单的解决方案是修改应用程序的主Python脚本，并将您需要的所有的”导入后勾子”的注册设置为绝对的第一件事。也就是说，在从应用程序导入任何其他模块包括任何解析命令行参数的标准库之前注册”导入后勾子”。 尽管你确实可以做到这一点，但是由于注册函数会发生事实上的调用，这意味注册函数的执行可能转而导入那些将要被打补丁的模块，所以依然可能发生导入错误。 有一种间接的方式可以解决所有的问题，下面是应用这个原则的例子。方法是相对于导入猴子补丁代码，我们创建一个注册函数，只有当被补丁的模块被导入，猴子补丁才会被惰性加载，之后才会被执行。 123456789101112import sysfrom wrapt import register_post_import_hookdef load_and_execute(name): def _load_and_execute(target_module): __import__(name) patch_module = sys.modules[name] getattr(patch_module, 'apply_patch')(target_module) return _load_and_executeregister_post_import_hook(load_and_execute('patch_tempfile'), 'tempfile') patch_tempfile.py代码如下: 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def apply_patch(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 使用交互式解释器运行第一个脚本，以便将我们留在解释器中，然后，我们可以显示导入tempfile模块并执行mkdtemp()函数，看看会发生什么。 123456$ python -i lazyloader.py&gt;&gt;&gt; import tempfilepatching tempfile&gt;&gt;&gt; tempfile.mkdtemp()calling mkdtemp'/var/folders/0p/4vcv19pj5d72m_bx0h40sw340000gp/T/tmpfB8r20' 上述整个导入过程是这样的: register_post_import_hook 为 tempfile 模块注册了 _load_and_execute 函数 import tempfile 时，会先执行 _load_and_execute 函数，此时会加载patch_tempfile 模块，并执行 apply_patch 函数 apply_patch 接收 tempfile 模块对象作为参数后执行，并使用 wrap_function_wrapper 函数为 mkdtemp 打上补丁。 mkdtemp 执行的就是打补丁之后的函数 整个过程，tempfile 模块被导入时，猴子补丁才被惰性加载。 换句话说，与大多数猴子补丁不同，我们并不是强行导入一个模块，以便在可能使用的基础上应用猴子补丁。相反，猴子补丁代码保持休眠和未使用，直到目标模块稍后被导入。如果没有导入目标模块，则该模块的猴子补丁代码本身甚至没有导入。 3. 发现导入后勾子如上所述，导入后钩子提供了一种稍微更好的方法来设置猴子补丁，以便应用它们。这是因为只有当包含要修补的函数的目标模块被导入时，它们才会被激活。这避免了不必要地导入可能不使用的模块，否则会增加应用程序的内存使用。 导入次序仍然很重要，因此，要确保在导入任何其他模块之前设置所有导入后钩子。并且在每次更改应用的猴子补丁后，需要修改应用程序代码。如果只是为了调试问题而频繁地添加猴子补丁，则可能不太方便。 后一个问题的解决方案是将猴子补丁分离到单独的模块中，并使用一个注册机制来宣布它们的可用性。然后，Python应用程序可以在一开始就执行通用的模板代码，该代码根据提供的配置发现应该应用哪些猴子补丁。注册机制将允许在运行时发现猴子补丁模块。 这里可以使用的一种特殊的注册机制是setuptools入口点。使用这个我们可以打包猴子补丁，这样它们就可以被单独安装以备使用。这样一套方案的结构是: 123setup.pysrc/__init__.pysrc/tempfile_debugging.py 这个包的 setup.py 代码将会是: 123456789101112131415161718192021from setuptools import setupNAME = 'wrapt_patches.tempfile_debugging'def patch_module(module, function=None): function = function or 'patch_%s' % module.replace('.', '_') return '%s = %s:%s' % (module, NAME, function)ENTRY_POINTS = [ patch_module('tempfile'),]setup_kwargs = dict( name = NAME, version = '0.1', packages = ['wrapt_patches'], package_dir = &#123;'wrapt_patches': 'src'&#125;, entry_points = &#123; NAME: ENTRY_POINTS &#125;,)setup(**setup_kwargs) 作为一种约定，我们使用命名空间包，以便我们的猴子补丁模块易于识别。在本例中，父包将是wrapt_patch，因为我们专门使用wrapt。这个特定包的名称将是wrapt_patch.tempfile_debug,表示我们将创建一些猴子补丁，以帮助我们调试使用tempfile模块。 setup.py的关键部分是定义entry_points。它将被设置成程序包名到猴子补丁映射的列表，这个列表包含了这个补丁模块要作用的所有目标Python模块。此处 ENTRY_POINTS 的值为 123ENTRY_POINTS = [ 'tempfile = wrapt_patches.tempfile_debugging:patch_tempfile',] src/init.py 将包含: 12import pkgutil__path__ = pkgutil.extend_path(__path__, __name__) 这是创建命名空间包的要求。最后，猴子补丁实际上包含在src/tempfile_debug中。代码跟以前很像。 123456789from wrapt import wrap_function_wrapperdef _mkdtemp_wrapper(wrapped, instance, args, kwargs): print 'calling', wrapped.__name__ return wrapped(*args, **kwargs)def patch_tempfile(module): print 'patching', module.__name__ wrap_function_wrapper(module, 'mkdtemp', _mkdtemp_wrapper) 定义了包后，我们将它安装到正在使用的Python安装或虚拟环境中。现在，我们可以在Python应用程序主脚本文件的开头添加显式的注册，我们将添加: 123456789101112import osfrom wrapt import discover_post_import_hookspatches = os.environ.get('WRAPT_PATCHES')if patches: for name in patches.split(','): name = name.strip() if name: print 'discover', name discover_post_import_hooks(name) 如果我们在没有为猴子补丁特定配置的情况下运行应用程序，那么什么也不会发生。如果它们是启用的，那么它们将被自动发现并根据需要应用。 1234$ WRAPT_PATCHES=wrapt_patches.tempfile_debugging python -i entrypoints.pydiscover wrapt_patches.tempfile_debugging&gt;&gt;&gt; import tempfilepatching tempfile 理想的情况是，如果PEP 369真的进入了Python的核心，那么将类似的引导机制合并到Python本身中，以便在解释器初始化过程中尽早强制对猴子补丁进行注册。有了这一点，我们就有了一种有保证的方法来解决在做猴子补丁时的导入次序问题。 由于现在PEP 369还未进入Python的核心，所以我们在本例中所做的是修改Python应用程序自己添加引导代码，以便在应用程序执行的最开始执行注册。当应用程序归自己管理时这是可以的，但是如果想要对第三方应用程序进行打补丁，并且不希望修改其代码，那该怎么办呢?在这种情况下有什么选择? 在这种情况下可以使用一些技巧。下一篇关于猴子补丁主题的博文中我们将讨论为应用程序打补丁的可用选项。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12 使用 wrapt 辅助测试]]></title>
    <url>%2F2018%2F06%2F03%2Fwrapt%2Fpython_decorator_12%2F</url>
    <content type="text"><![CDATA[前面我们说道过 Python 中使用猴子补丁典型情景之一就是使用模拟库来帮助执行单元测试，本节我们先把补丁和模块导入的相对次序问题放一放，先来看看如何使用 wrapt 模块辅助单元测试。 1. 使用 wrapt 进行测试在Python中讨论单元测试时，用于辅助该任务的比较流行的包之一是 mock 包。但是我(wrapt 的作者)觉得 mock 包不符合我的思维方式。 也可能只是我试图应用它的东西不太适合。在我想要测试的内容中，通常我不仅想要模拟更低的层，而且我想要验证传递到下一层的数据，或者修改结果。换句话说，我通常仍然需要系统作为一个整体来结束，并可能在很长一段时间内。 因此，对于我需要做的更复杂的测试，我实际上一直在依靠wrapt的猴子补丁功能。很有可能，因为我写了wrapt，我更熟悉它的范例，或者我更倾向于更明确的方式。不管怎样，至少对我来说，wrapt 能帮助我更快地完成工作。 为了进一步解释 wrapt 的猴子补丁功能，我在这篇博客文章中向大家展示了用wrapt模块实现部分 Mock 包的功能。只要记住，对于Mock模块我是一个绝对的新手，也可能也我太笨了，不能理解如何正确简单地使用它来做我想做的事情。 Return values and side effects如果你正在使用Mock，并且希望在调用时临时覆盖类的方法返回的值，一种方法是: 123456789101112from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch(__name__+'.ProductionClass.method', return_value=3)def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') mock_method.assert_called_with(3, 4, 5, key='value') assert result == 3 就我迄今为止提出的wrapt包而言，一种类似的做法是: 123456789101112131415from wrapt import patch_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@patch_function_wrapper(__name__, 'ProductionClass.method')def wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3def test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 不过，这里的一个问题是，wrapt.patch_function_wrapper()函数应用了一个永久补丁。在这个过程的生命周期中，这是可以的，但是在测试的情况下，我们通常希望一个补丁只应用于当时正在运行的单个单元测试函数。因此，补丁应该在测试结束时和调用下一个函数之前应该被删除。 对于该场景，wrapt包提供了另一个装饰器@wrapt.transient_function_wrapper。用来创建一个包装函数，该函数只应用于修饰函数所应用的特定调用的范围。因此，我们可以把上面写为: 12345678910111213141516from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return 3@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert result == 3 尽管这个示例展示了如何临时覆盖类的方法返回的值，但更典型的情况是，我们仍然希望能够调用原始的被覆盖的函数。可能验证传入的参数或从底层返回的返回值。当我尝试用Mock解决这个问题时，我想到的一般方法如下。 1234567891011121314151617from mock import Mock, patchclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, keydef wrapper(wrapped): def _wrapper(self, *args, **kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(self, *args, **kwargs) return _wrapper@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper(ProductionClass.method))def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') 这里有两个技巧 第一个是@Mock.path 的 autospec=True参数，用于执行方法绑定 第二个是需要在对它应用任何mock之前从’ProductionClass’捕获原始方法，这样当调用mock的副作用函数时，我就可以反过来调用它。 毫无疑问，有人会告诉我，我做错了，有一种更简单的方法，但这是我在阅读模拟文档10分钟后所能想到的最好的方法。 当使用wrapt执行相同的操作时，使用的方式与模拟返回值没有什么不同。这是因为wrapt函数包装器能同时适用普通函数或方法，所以在包装方法时不需要额外处理。此外，当调用wrapt包装函数时，它总是传递被包装的原始函数，因此不需要使用任何魔法来隐藏它。 123456789101112131415from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): print a, b, c, key@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): assert args == (3, 4, 5) and kwargs.get('key') == 'value' return wrapped(*args, **kwargs)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() result = real.method(3, 4, 5, key='value') 使用此功能可以轻松地拦截调用，来执行传递的数据的验证，但仍然可调用原始函数，我可以相对轻松地创建一大堆装饰器，以便对数据执行验证，因为数据可能是通过系统的不同部分传递的。然后，我可以将这些装饰器堆叠在任何需要添加它们的测试函数上。 2. 包装不同类型的返回值返回函数上面的示例包括能够返回一个假的返回值，返回原始值，或者在部分原始数据类型或集合上进行一些轻微的修改。但在某些情况下，我实际上希望在返回值周围放置一个包装器，以修改后续代码与返回值的交互方式。 第一个例子是包装函数返回另一个函数，这个函数将被调用链中更高的函数调用。在这里，我可能想在返回的函数周围放置一个包装器，以便在调用它时拦截它。 Mock 包的使用方式如下1234567891011121314151617181920212223242526from mock import Mock, patchdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return functiondef wrapper2(wrapped): def _wrapper2(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper2def wrapper1(wrapped): def _wrapper1(self, *args, **kwargs): func = wrapped(self, *args, **kwargs) return Mock(side_effect=wrapper2(func)) return _wrapper1@patch(__name__+'.ProductionClass.method', autospec=True, side_effect=wrapper1(ProductionClass.method))def test_method(mock_method): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: ProductionClass.method 函数返回值是另一个函数 side_effect 指定了第一层的包装函数 wrapper1，截获了ProductionClass.method 返回的 function 函数 wrapper1 将 function 包装再 wrapper2 内返回给了调用链中更高层的函数 更高层的函数调用 function 时，调用的则是 wrapper2 wrapt 包的使用方式: 12345678910111213141516171819202122from wrapt import transient_function_wrapper, function_wrapperdef function(): passclass ProductionClass(object): def method(self, a, b, c, key): return function@function_wrapperdef result_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): return result_function_wrapper(wrapped(*args, **kwargs))@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() func = real.method(3, 4, 5, key='value') result = func() 整个包装过程说明如下: apply_ProductionClass_method_wrapper 装饰了原始的 ProductionClass.method 方法 apply_ProductionClass_method_wrapper 内 wrapped(*args, **kwargs) 返回结果就是 function，其又被 result_function_wrapper 装饰 调用链中更高层的函数调用 ProductionClass.method，实际调用的是 result_function_wrapper 本例使用了一个名为@wrapt.function_wrapper的新装饰器。还可以使用@wrapt.decorator。@wrapt.function_wrapper 实际上只是@wrapt.decorator的一个简化版本，它缺少一些在做显式的猴子补丁时通常不需要的铃铛和口子，但除此之外，它也可以用同样的方式使用。因此，我可以对结果返回的函数应用一个包装器。我甚至可以应用相同的原理应用在当函数作为参数传递给另一个函数的情况。 返回类的实例返回函数的另一个场景是返回类的实例。在这种情况下，我可能想要对类的实例的特定方法应用一个包装器。在mock 包中，需要再次使用“Mock”类，并且必须以不同的方式应用它来实现您想要的结果。现在我将不再关注mock，只关注wrapt的实现方式。 所以，根据需求，有几种方法可以用wrapt来实现。第一个方法是用封装原始方法的包装器直接替换实例上的方法 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, function_wrapperclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storage@function_wrapperdef run_method_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) storage.run = run_method_wrapper(storage.run) return storage@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 包装过程是: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method run_method_wrapper 包装 ProductionClass.method 的返回值 storage.run 这样可以得到想要的结果，但在本例中，实际上是一种糟糕的方法。问题是返回的对象是一个在测试之外有生命时间的对象。也就是说，我们正在修改一个存储在全局范围内的对象，该对象可能用于其他测试。通过简单地替换实例上的方法，我们进行了永久性的更改。 如果它是一个仅为一次调用而按需创建的类的临时实例，那么这是可以的，但是在其他情况下不行，因为它的影响是持久的。因此，我们不能修改实例本身，需要以其他方式封装实例来拦截方法调用。 为此，我们使用了所谓的对象代理。这是一个特殊的对象类型，我们可以创建一个实例来包装另一个对象。当访问代理对象时，任何访问属性的尝试都会从包装对象返回属性。类似地，调用代理上的方法将调用包装对象上的方法。 但是，拥有一个不同的代理对象允许我们更改代理对象上的行为，从而更改代码与包装对象的交互方式。因此，我们可以避免更改原始对象本身。因此，对于这个例子，我们可以做的是: 1234567891011121314151617181920212223242526from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def run(self): passstorage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): def run(self): return self.__wrapped__.run()@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') result = data.run() 整个包装过程如下: apply_ProductionClass_method_wrapper 包装了 ProductionClass.method 使用代理对象 StorageClassProxy 代理了对 storage 实例属性和方法的访问 StorageClassProxy 覆盖了 storage 的 run 方法 也就是说，我们在代理对象上定义run()方法，以拦截原始对象上相同方法的调用。然后我们可以继续返回假值，验证参数或结果，或者根据需要修改它们。通过代理，我们甚至可以通过向代理对象添加属性来拦截对原始对象属性的访问。 123456789101112131415161718192021222324252627from wrapt import transient_function_wrapper, ObjectProxyclass StorageClass(object): def __init__(self): self.name = 'name'storage = StorageClass()class ProductionClass(object): def method(self, a, b, c, key): return storageclass StorageClassProxy(ObjectProxy): @property def name(self): return self.__wrapped__.name@transient_function_wrapper(__name__, 'ProductionClass.method')def apply_ProductionClass_method_wrapper(wrapped, instance, args, kwargs): storage = wrapped(*args, **kwargs) return StorageClassProxy(storage)@apply_ProductionClass_method_wrapperdef test_method(): real = ProductionClass() data = real.method(3, 4, 5, key='value') assert data.name == 'name' 3. 更好的使用 Mock 模块这时你可能会说Mock做的远不止这些。你甚至可能想指出 mock 如何保存了调用的细节，这样就可以回溯，而不需要进行打点测试，这样甚至可以避免打点测试触发的异常被意外捕获的情况。 这是正确的，我们的意思是不要局限于使用基本的构建块本身，可以将多个模块结合使用，wrapt 是构建更好的模拟库进行测试的一个很好的基础。因此，我留给你们最后一个例子来让你们思考，如何使用 mock 来实现。 12345678910111213141516171819202122232425262728from wrapt import transient_function_wrapperclass ProductionClass(object): def method(self, a, b, c, key): passdef patch(module, name): def _decorator(wrapped): class Wrapper(object): @transient_function_wrapper(module, name) def __call__(self, wrapped, instance, args, kwargs): self.args = args self.kwargs = kwargs return wrapped(*args, **kwargs) wrapper = Wrapper() @wrapper def _wrapper(): return wrapped(wrapper) return _wrapper return _decorator@patch(__name__, 'ProductionClass.method')def test_method(mock_method): real = ProductionClass() result = real.method(3, 4, 5, key='value') assert real.method.__name__ == 'method' assert mock_method.args == (3, 4, 5) assert mock_method.kwargs.get('key') == 'value' 这是 wrapt 包实现猴子补丁的概览。还有一些其他的东西，但这是核心部分。我使用猴子补丁将工具添加到现有代码中以支持性能监视，但是我在这里展示了如何将相同的技术用于编写代码测试，以替代Mock等包。 正如我在上一篇文章中提到的，猴子补丁的一个主要问题是模块的导入结果与打补丁完成的时间相关。我将在下一篇文章中进一步讨论这个问题。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11 在 Python 中安全的使用猴子补丁]]></title>
    <url>%2F2018%2F06%2F02%2Fwrapt%2Fpython_decorator_11%2F</url>
    <content type="text"><![CDATA[在之前 10 篇博客中，我们几乎完整的讨论了装饰器的实现。现在我们将焦点从装饰器转移到猴子补丁上来。 1. 猴子补丁通常在Python中永远不应该做的事情之一就是编写猴子补丁。但有些人认为这是一种有用的必需品，你可能无法避免修补第三方代码中的错误。其他人则可能会争辩说，现在有这么多的软件是开源的，所以您应该简单地向上游包维护人员提交一个补丁。 猴子补丁除了补丁还有其他用途。在Python中最常用的两种形式的猴子补丁是装饰器和使用模拟库来帮助执行单元测试，甚至你可能不把它与猴子补丁等同起来。另一个不常见的猴子补丁的例子是对现有的Python代码添加性能监视功能。 前面我们介绍了装饰器可能会导致什么问题。主要的问题就是，装饰器的实现方式可能没有保留适当的自省能力，当应用于类的方法时，它们可能也没有保留Python描述符协议的正确语义。当人们开始讨论如何修改任意代码，而不是简单地对自己的代码应用装饰器时，这两个问题就变得更加重要了，因为可能很容易地干扰现有代码的行为，或者以意想不到的方式打补丁。 典型的案例是，对一个类方法打补丁。与装饰器在类被创建时即运行不同，补丁代码运行时，类已经被创建，因此需要额外处理一些潜在问题。 我打算用这篇博文来解释wrapt包的猴补丁功能。尽管 wrapt 模块提供了创建装饰器的良好方式，但这并不是创建该包的主要目标。创建wrapt包的真正原因实际上是为猴子补丁代码实现健壮的机制。碰巧，安全执行猴子补丁所需的基本原则和机制也适用于实现装饰器。 2. 创建一个装饰器在开始修改任意代码之前，我们首先需要重新复述一下wrapt包如何用于创建装饰器。主要模式是: 12345678910111213141516171819import wraptimport inspect@wrapt.decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) wrapt包创建装饰器的一个特性是，在装饰器中，可以确定装饰器所使用的上下文。即可以确定修饰符是被应用于类、函数或静态方法、类方法或实例方法中的哪一个。对于将装饰器应用于实例方法的情况，为类的实例提供了一个单独的参数。对于类方法，单独的参数是对类本身的引用。在这两种情况下，它们都与“args”和“kwargs”参数相分离，因此不需要自己动手提取它们。因此，我将使用wrapt创建的装饰器称为通用装饰器。换句话说，可以创建一个单独的装饰器，它可以跨函数、方法和类使用，可以在不同的调用场景中相应地调整装饰器的行为。而不再需要创建一个装饰器的多个实现，并确保在每个场景中都使用了正确的实现。 这种装饰器的使用与其他方式创建的装饰器无异。 12345class Example(object): @universal def name(self): return 'name' 需要注意的是 @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖 12345class Example(object): def name(self): return 'name' name = universal(name) 这么写仍然可行，当以这种方式编写时，它使装饰者在某种程度上成为一种猴子补丁。这是因为猴子补丁通常所做的就是在一些现有函数周围引入一个包装器，这样就可以对原始函数进行拦截。然后，包装器函数允许在调用原始函数之前或之后执行操作，或者允许修改传递给包装函数的参数，或者以某种方式修改结果，或者甚至完全替换结果。 与装饰器的一个重要区别是，装饰器在类被创建时即运行。相比之下，猴子补丁更随意，通常在类创建一段时间之后再执行。 事实上你所作的是: 12345class Example(object): def name(self): return 'name'Example.name = universal(Example.name) 尽管使用wrapt包创建的装饰器函数可以以这种方式使用，并且仍将按预期工作，但总体而言，我不建议以这种模式给类的现有方法添加补丁。这是因为这种方式实际上并不等同于当类被定义时在类的主体内做同样的事情。特别是Example.name的访问实际上调用了描述符协议，因此返回了实例方法。我们可以通过运行代码看到这一点: 12345678910class Example(object): def name(self): return 'name' print type(name)print type(Example.name)which produces:&lt;type 'function'&gt;&lt;type 'instancemethod'&gt; 一般来说，这可能并不重要，但我看到过一些非常奇怪的情况，它们的区别很重要。因此，为了解决这个问题，wrapt包提供了执行猴子补丁的另一种实现机制。在上面为类的方法添加包装器的情况下，使用这种机制可以避免由这种细微差别所引起的任何问题。 3. 猴子补丁创建猴子补丁的创建与装饰器创建类似，首先需要创建一个包装函数，猴子补丁的包装函数与装饰器是一样的，如下图所示 12def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 不同的是不是使用装饰器工厂函数 @wrapt.decorator 创建装饰器并将其应用到被包装对象上，而是使用 wrapt.wrap_function_wrapper() 函数。 1234567class Example(object): def name(self): return 'name'import wraptwrapt.wrap_function_wrapper(Example, 'name', wrapper) 在这种情况下，我们将类放在同一个代码文件中，但是我们也可以这样做:** 1234import exampleimport wraptwrapt.wrap_function_wrapper(example, 'Example.name', wrapper) 也就是说，我们将目标所在的模块作为第一参数，第二个参数则是我们希望应用包装器的目标方法对象的路径。我们也可以完全跳过导入模块，只使用模块的名称。 123import wraptwrapt.wrap_function_wrapper('example', 'Example.name', wrapper) 为了证明任何东西都可以被装饰器简化，我们最终可以把整个东西写成: 12345import wrapt@wrapt.patch_function_wrapper('example', 'Example.name')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 在这个最后的示例中，将会发生的事情是，一旦导入了包含上述代码的模块，在“示例”模块中定义的指定目标函数将自动地使用包装器函数进行修补。 4. 延迟补丁问题现在需要着重提醒的是。在上述的操作之后应用补丁并不总是有效的。 问题的核心在于，是否正在对一个已导入的模块应用补丁。如果模块没有导入，wrap .wrap_function_wrapper() 调用将确保模块被导入，但是如果模块已经被代码的其他部分或第三方包导入，那么可能就会有问题。 特别的是，您尝试打补丁的目标函数是模块的一个正常的全局函数，其他一些代码可以通过以下步骤直接获取对它的引用: from example import function 如果你后来来了 12345import wrapt@wrapt.patch_function_wrapper('example', 'function')def wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 最后，目标模块中包含的函数的副本将应用包装器，但是其他代码创建的对它的引用将没有包装器。即在打补丁之后导入的目标函数都是被包装的，之前的都是未被包装的。 为了确保在此场景中始终使用包装器，您不仅需要在原始模块中，而且还需要在存储引用的任何模块中对其进行补丁。这只在非常有限的情况下是可行的因为在现实中，如果函数是一个普通的函数，你将不知道函数在哪里被使用。 这个问题的一个确切体现就是对gevent或eventlet等包打补丁时存在的问题。这两个包都延迟了功能的修补，因此对导入模块的顺序非常敏感。要解决这个问题，至少对于Python标准库中的模块来说，要打补丁的time.sleep()函数不仅需要在time模块中进行修补，还需要在threading模块中进行修补。 有一些技术可以用来尝试和避免这些问题，但我将把这些解释推迟到以后的一段时间。在我的下一篇博客文章中，我想介绍一些使用使用猴子补丁示例，看看如何在进行测试时使用wrapt替代 mock 模块。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10 装饰类的性能]]></title>
    <url>%2F2018%2F06%2F01%2Fwrapt%2Fpython_decorator_10%2F</url>
    <content type="text"><![CDATA[在上一篇文章中，我们对作为函数闭包实现的装饰器与前文描述的通用装饰器进行了性能比较。本节我们继续我们的性能测试，看看装饰一个类方法时，不同实现方式的性能表现。 1. 装饰函数的性能比较在上一篇文章中，函数闭包实现的装饰器与前文描述的通用装饰器性能测试结果如下 对于2012年的MacBook Pro，直接调用函数的测试结果是: 10000000 loops, best of 3: 0.132 usec per loop 使用函数闭包实现的装饰器的测试结果是: 1000000 loops, best of 3: 0.326 usec per loop 最受，使用装饰器工厂函数的测试结果是: 1000000 loops, best of 3: 0.771 usec per loop 上述是代理对象，和 function wrapper 对象的Python实现测试结果，如果将它们以Python C扩展实现，可以降低至: 1000000 loops, best of 3: 0.382 usec per loop 这与使用函数闭包实现的装饰器，性能相差无几。 将装饰器应用在类方法会怎样？ 2. 必须绑定函数的开销将装饰器应用于类的方法的问题是，如果要遵守Python执行模型，则需要将装饰器实现为描述符，并在访问时正确地将方法绑定到类或类实例。在本系列文章中描述的装饰器中，我们正是实现了此机制，以便能够确定装饰器整被应用于与普通的函数、实例方法或类方法中的哪一个。 相比于使用函数闭包实现的装饰器不会遵守任何的Python 执行模型，这个绑定过程确保了正确的操作，但是也带来了额外的开销。为了查看发生了哪些额外的步骤，我们可以再次使用Python profile挂钩机制来跟踪修饰函数调用的执行。当前即跟踪实例方法的调用 首先，让我们来跟踪函数闭包实现的装饰器调用了哪些函数: 1234567891011121314151617181920def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapperclass Class(object): @my_function_wrapper def method(self): passinstance = Class()import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)instance.method() 结果跟装饰器一个普通函数类似: 1234_my_function_wrapper call method call method return_my_function_wrapper return 因此，我们应该预期，当我们执行实际的时间测试时，开销不会有很大的不同。现在使用我们的装饰器工厂函数。为了提供上下文，我展示了完整的代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 我们的装饰器实现如下: 123@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) 装饰实例方法的测试输出结果如下: 12345678910111213('__get__', 'call') # function_wrapper ('__init__', 'call') # bound_function_wrapper ('__init__', 'call') # object_proxy ('__init__', 'return') ('__init__', 'return')('__get__', 'return')('__call__', 'call') # bound_function_wrapper ('my_function_wrapper', 'call') ('method', 'call') ('method', 'return') ('my_function_wrapper', 'return')('__call__', 'return') 可以看到，由于方法与发生在 __get__() 中的类实例的绑定，现在发生了很多事情。因此，开销也会显著增加。 3. 执行类方法的开销与前面一样，不再使用上面的实现，而是再次使用wrapt库中的实际实现。这次我们的测试代码是: $ python -m timeit -s &#39;import benchmarks; c=benchmarks.Class()&#39; &#39;c.method()&#39; 没有被装饰的实例方法，直接运行的结果是: 10000000 loops, best of 3: 0.143 usec per loop 这比普通函数调用的情况要多一点，因为发生的了实例方法的绑定。 使用函数闭包实现的装饰器。测试结果如下: 1000000 loops, best of 3: 0.382 usec per loop 再一次，比未修饰的情况稍微多一点，与被应用到函数的装饰器相差无几。因此，当应用于普通函数与实例方法时，装饰器的开销并没有太大的差异。现在轮到我们的装饰器工厂函数和 function wrapper对象。首先测试Python 实现: 100000 loops, best of 3: 6.67 usec per loop 与使用函数闭包实现装饰器相比，这在运行时开销上增加了不少负担。虽然每次执行只需要额外的6个usec，但是您需要在上下文中考虑这个问题。特别是，如果在处理web请求的过程中对一个调用了1000次的函数应用了这样的装饰器，那么在该web请求的响应时间之上增加了6 ms。 在这一点上，许多人无疑会辩称，如果运行成本太高，那么正确是不值得的。但是，装饰函数和装饰器本身也不可能什么都不做，因此所产生的额外开销可能只是运行时成本的一小部分，因此在实践中并不明显。同样的，如果使用Python C扩展模块实现呢？对于作为C扩展实现的对象代理和函数包装器，结果是: 1000000 loops, best of 3: 0.836 usec per loop 所以不是6ms，而是小于1ms的额外开销如果修饰函数被调用1000次。它仍然比使用作为函数闭包实现的装饰器要多，但再次重申，在修饰类的方法时使用函数闭包不符合Python执行模型。 4. 需要大费周折么我是在吹毛求疵、过于迂腐地想把事情做好吗？当然，对于你现在所使用的装饰器，闭包实现可能工作的很好。但是当您开始使用函数包装器执行任意代码的猴子补丁时，情况就不一样了。如果你在做猴子补丁时不遵守Python的执行模型，那么你很容易以非常微妙和晦涩的方式打破第三方代码。客户可不会喜欢你破坏了他们的web应用程序。所以至少我现在所作的是很重要的。 在本文中，我只考虑了修饰类实例方法时的开销。我没有涵盖在修饰静态方法和类方法时的开销。如果您对它们的不同之处感到好奇，您可以在wrapt文档中查看完整的案例的基准。 在下一篇文章中，我将再次讨论性能开销问题，但也将讨论实现装饰器的一些替代方法，以便尝试并解决我在第一篇文章中提出的问题。这些内容将作为，对博客中描述的实现和 PyPi 模块中的实现的对比的一部分。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[09 装饰器性能比较]]></title>
    <url>%2F2018%2F05%2F30%2Fwrapt%2Fpython_decorator_09%2F</url>
    <content type="text"><![CDATA[前面我们探讨了装饰器的实现方式，并实现了一个所谓的通用装饰器模式，并用它创建了一个类似 Java 的 @synchronized 装饰器作为使用示例。本节我们来看看不同的装饰器实现方式的性能问题。在这篇关于装饰器的实现性能这篇文章之后，我们将开始深入探讨如何实现代理，它是通用装饰器机制中的基础组件。 1. 装饰一个普通函数在这篇文章中，我将只讨论用装饰器修饰一个普通函数的开销。相关的装饰器代码如下: 123456789101112131415161718192021222324class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper ... def __get__(self, instance, owner): ... def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 如果你想回忆完整的代码，你可以去查看之前的文章，那里有完整描述。使用装饰器工厂函数，创建装饰器，并装饰器一个普通函数可以像下面这样: 1234567@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) @my_function_wrapperdef function(): pass 这与使用函数闭包以更传统的方式创建的decorator不同。使用闭包创建一个函数装饰器如下所示: 12345678def my_function_wrapper(wrapped): def _my_function_wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _my_function_wrapper@my_function_wrapperdef function(): pass 在我们调用函数时function()，这两种情况各自会发生什么? 2. 追踪函数执行为了跟踪代码的执行，我们可以使用Python的profile hook机制。 1234567import sysdef tracer(frame, event, arg): print(frame.f_code.co_name, event)sys.setprofile(tracer)function() profile hook的目的是允许注册一个回调函数，该函数在所有函数的入口和出口调用。这样就可以追踪正在进行的函数调用的序列。对于函数闭包，输出如下: 1234_my_function_wrapper call function call function return_my_function_wrapper return 我们在这里看到的是函数闭包的嵌套函数被调用。这是因为在使用函数闭包的情况下，装饰器将函数替换为对嵌套函数的引用。当这个嵌套函数被调用时，它将依次调用原来的包装函数。对于我们的工厂函数，输出如下: 123456__call__ call my_function_wrapper call function call function return my_function_wrapper return__call__ return 这里的区别是，decorator 用 function wrapper 类的实例替换了函数。作为一个类，当它作为一个函数被调用时，__call__() 方法在类的实例上被调用。__call__() 方法随后调用用户提供的包装器函数，该函数反过来调用原始包装函数。 因此，结果是我们引入了额外的间接级别，或者换句话说，在执行路径中引入了额外的函数调用。记住，__call__()实际上是一个方法，而不仅仅是一个普通的函数。作为一种方法，实际上在幕后进行的工作要比普通的函数调用多得多。特别是，在调用未绑定方法之前，需要将其绑定到函数包装器类的实例。这不会出现在调用的跟踪中，但是它正在发生，并且会产生额外的开销。 3. 函数执行时间通过执行上面的跟踪，我们知道我们的解决方案会带来额外的方法调用开销。但是这会产生多少额外的开销呢？为了尝试度量每个解决方案中开销的增加，我们可以使用timeit模块来执行我们的函数调用。作为基线，我们首先需要知道在不应用任何修饰符的情况下对函数进行调用的时间开销。 123# benchmarks.pydef function(): pass 为记录时间，我们需要使用以下命令: $ python -m timeit -s &#39;import benchmarks&#39; &#39;benchmarks.function()&#39; 以这种方式使用的timeit模块时，它将执行适当的大量函数调用，将所有调用的总时间除以调用次数，最后得到单个调用的时间值。对于2012年款的MacBook Pro来说，输出如下: 10000000 loops, best of 3: 0.132 usec per loop 接下来测试函数闭包，输出如下: 1000000 loops, best of 3: 0.326 usec per loop 最后测试我们的装饰器工厂函数: 1000000 loops, best of 3: 0.771 usec per loop 在这个最后的例子中，我使用的是wrapt模块实现，而不是本系列博文中迄今为止给出的代码。这个实现的工作方式略有不同，因为它在描述的内容上有一些额外的功能，设计也有一些不同。即便是最轻量级的实现，性能开销也差不多。 4. 加速包装器的执行在这一点上毫无疑问会有人们想要指出,即使对于方法调用而言，它更加正确的实现了描述符协议，但是这所谓的的更好的方法实在是太慢，难以在实际生产环境中使用。因此，是否可以做些什么来加速实现呢? 此时可以采用的方法是将函数包装器和对象代理实现为Python C扩展模块。为了简单起见，我们可以将装饰器工厂函数本身作为纯Python代码来实现，因为工厂函数只在修饰符应用到函数时才调用，而不是修饰函数的每次调用时都会调用，因此它的时间开销并不重要。** 我绝对不会做的一件事是写博客，讨论如何将函数包装器和对象代理作为Python C扩展模块实现。不过请放心，它的工作方式与纯Python实现相同。显然，它的运行速度要快得多，因为它是使用Python C api实现的C代码，而不是纯粹的Python代码。 将函数包装器和对象代理作为Python C扩展模块实现的开销如何呢?测试如下: 1000000 loops, best of 3: 0.382 usec per loop 因此，尽管将函数包装器和对象代理作为Python C扩展模块实现需要付出更多的努力，但这些努力是值得的，结果时现在非常接近使用函数闭包的装饰器实现。 4. 装饰类方法性能到目前为止，我们只考虑了装饰一个普通函数的情况。正如预期的那样，与function wrapper作为一个类实现类似，由于引入了额外的间接层，因此开销明显更多。尽管如此，它仍然只有半微秒。 尽管如此，通过实现我们的函数包装器和对象代理作为C代码，我们还是能够将性能达到同一量级，在这里，作为函数闭包实现的装饰器工厂函数的开销可以忽略不计。 那么装饰类方法的性能如何呢。将在下一篇博客揭晓。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[08 将 @synchronized 实现为上下文管理器]]></title>
    <url>%2F2018%2F05%2F29%2Fwrapt%2Fpython_decorator_08%2F</url>
    <content type="text"><![CDATA[在前一篇文章中，我们描述了如何使用新的通用装饰器模式来实现Python的 @synchronized 同步原语装饰器。在Java提供的两个同步机制中，同步方法和同步原语，目前为止我们只实现了同步方法。本文将描述如何将其扩展为上下文管理器，从而等效的实现Java的同步原语。 1. @synchronized 当前实现到目前为止，我们的@synchronized 装饰器的实现是。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 通过确定装饰器被用于包装普通函数、实例方法或类的方法中的哪一个，我们可以在许多场景中使用同一一个装饰器。 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 我们现在想要实现的是让同步装饰器也能完成如下操作: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，除了可以用作装饰器之外，它还能与with语句一起用作上下文管理器。通过这样做，它就能够对函数中的部分语句加锁，而不是整个函数。用作上下文管理器时，如果需要与实例方法同步，我们需要将把self参数或类实例传递给synchronized。如果需要与类方法同步，则传递类对象本身。 2. 将 function_wrapper 实现为上下文管里器在现有的synchronized实现上，当使用synchronized作为函数调用时，它将返回函数包装器类的一个实例。 12&gt;&gt;&gt; synchronized(None)&lt;__main__.function_wrapper object at 0x107b7ea10&gt; 这个函数包装器没有实现作为上下文管理器的对象所需的__enter__()和__exit__()函数。函数包装器是我们自己的类，所以我们只需要创建子类并为其添加这两个方法即可。同时这个函数包装器的创建是在@decorator的定义中绑定的，所以我们需要绕过@decorator并直接使用函数包装器。因此，第一步是重写我们的 @synchronized decorator，不使用@decorator。 123456789101112131415161718192021def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) return function_wrapper(wrapped, _synchronized_wrapper) 这与我们最初的实现相同，但是我们现在可以访问到创建函数包装器对象 function_wrapper。因此我们可以创建一个满足上下文管里器协议的 function_wrapper 的子类来替换 function_wrapper。 12345678910111213141516171819202122232425262728293031def synchronized(wrapped): def _synchronized_lock(owner): lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) return lock def _synchronized_wrapper(wrapped, instance, args, kwargs): with _synchronized_lock(instance or wrapped): return wrapped(*args, **kwargs) class _synchronized_function_wrapper(function_wrapper): def __enter__(self): self._lock = _synchronized_lock(self.wrapped) self._lock.acquire() return self._lock def __exit__(self, *args): self._lock.release() return _synchronized_function_wrapper(wrapped, _synchronized_wrapper) 3. 两种调用方式当 synchronized 作为装饰器使用时，新的function wrapper子类被用于包装被包装函数和方法。当函数或类方法被调用时，function wrapper 基类中的 __call__ 方法被调用。装饰器将在尝试获取锁之后执行被包装函数。 当synchronized作为上下文管里器使用时。子类将用于包装类实例或类本身。没有方法会被调用，取而代之的是在进入上下文时，__enter__() 会获取锁，离开上下文时，__exit__() 会释放锁。 与在之前的文章中形容的复杂度相比，现在的实现简单明了。 4. 不只是个装饰器希望这能说明的一点是，尽管@decorator被用来创建自定义装饰器，但这并不总是最合适的方式。function wrapper 对象的单独存在为修改被包装对象的行为提供了很大的灵活性。在某些情况下，还可以直接删除和使用对象代理。所有这些都提供了一个通用的工具集，用于进行任何类型的包装或修补，而不仅仅是用于装饰。现在，我将开始将这一系列博客文章的焦点转移到更一般的包装和猴子补丁上。 在此之前，在下一篇文章中，我将首先讨论与使用函数闭包实现装饰器的更传统方式相比，使用 function wrapper 隐含的性能影响。以及使用Python C扩展实现完整的对象代理和 function wrapper 后，性能改善的大小。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[07 实现 java 的 @synchronized 装饰器]]></title>
    <url>%2F2018%2F05%2F26%2Fwrapt%2Fpython_decorator_07%2F</url>
    <content type="text"><![CDATA[在之前的博客中，我们讨论了装饰器的实现，并实现了一个通用装饰器模式。作为这种模式的使用示例，本节我们来实现 java 中的 @synchronized 装饰器。 1. Java @synchronized 装饰器java 的同步原语有两种形式，分别是同步方法和同步代码块。在Java 中创建同步方法，只需要在其定义时添加synchronized关键字即可。 123456789101112public class SynchronizedCounter &#123; private int c = 0; public synchronized void increment() &#123; c++; &#125; public synchronized void decrement() &#123; c--; &#125; public synchronized int value() &#123; return c; &#125;&#125; 使一个方法同步意味着不可能在同一个对象上同时调用多个同步方法。当一个线程正在执行一个对象的同步方法时，所有其他调用相同对象的同步方法的线程将阻塞直至当前同步方法调用完成。 换句话说，类的每个实例都有一个内在的锁对象，并且在进入一个方法时，锁会被获取，当方法返回时它会被释放。锁是所谓的重入锁，这意味着线程可以在它持有锁的同时，再次获得它，而不会阻塞。正因为如此，一个同步的方法可以调用同一个对象上的另一个同步方法。 在Java中创建同步代码的第二种方法是同步代码块。与同步方法不同，同步代码块必须指定提供内在锁的对象。 1234567public void addName(String name) &#123; synchronized(this) &#123; lastName = name; nameCount++; &#125; nameList.add(name);&#125; 值得注意的是，在Java中，可以使用任何对象作为锁的源，不需要创建特定锁类型的实例来同步。如果在类中需要更细粒度的锁，那么可以简单地创建或使用现有的任意对象进行同步。 12345678910111213141516public class MsLunch &#123; private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() &#123; synchronized(lock1) &#123; c1++; &#125; &#125; public void inc2() &#123; synchronized(lock2) &#123; c2++; &#125; &#125;&#125; 这些同步原语使用起来相对简单，因此，如何才能通过装饰器在Python中让类似操作以同样简单的方式实现呢。 2.同步线程的互斥锁在Python中，不可能使用任意对象做同步。相反必要创建一个特定的锁对象，该对象内部持有一个线程互斥锁。锁对象提供了一个 acquire()和release() 方法来操作锁。同时由于上下文管理器被引入到 Python 中，所以锁也支持与with语句一起使用。使用这个特定的特性，用于实现Python的@synchronized 装饰器的典型实现是: 1234567891011121314def synchronized(lock=None): def _decorator(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper return _decoratorlock = threading.RLock()@synchronized(lock)def function(): pass 使用此方法在一段时间后变得很烦人，因为对于需要同步的每个不同的函数，必须首先创建一个线程锁。替代方法是，为每个装饰器自动创建一个线程锁。 1234567891011def synchronized(wrapped): lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function(): pass 我们甚至可以使用前面描述的模式，为每次调用提供一个可选的参数 1234567891011121314151617181920def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @functools.wraps(wrapped) def _wrapper(*args, **kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper@synchronizeddef function1(): passlock = threading.Lock()@synchronized(lock=lock)def function2(): pass 无论方法如何，基于函数闭包的装饰器都会遇到我们已经列出的所有问题。因此，我们可以采取的第一步是使用我们新的装饰器工厂函数替代它。 12345678910111213def synchronized(wrapped=None, lock=None): if wrapped is None: return functools.partial(synchronized, lock=lock) if lock is None: lock = threading.RLock() @decorator def _wrapper(wrapped, instance, args, kwargs): with lock: return wrapped(*args, **kwargs) return _wrapper(wrapped) 因为使用了我们的装饰器工厂函数，这意味着相同的代码可以安全的应在实例、类或静态方法上。需要强调的是在类方法上使用此装饰器看似简单，但并不是很有用。因为锁仅仅对被装饰的方法有用，并且会对类的所有实例在同一方法上施加同步锁。这并不是我们想要的，也不能同java的同步方法相对应。 在次重申我们要实现的目标是，被装饰器标识为同步的所有实例方法，我们希望每个类实例都有一个独立的同步锁来实现实例内的方法同步。不同类实例之间不要同步。 过去已经有一些文章描述了如何改进这一点，包括这个很复杂的尝试。个人觉得它的实现方式是相当笨拙的，甚至怀疑它实际上不是线程安全的，因为在创建一些锁的过程中有一个竞争条件。因为它使用了函数闭包，并且没有我们的通用装饰器的概念，所以还需要创建大量不同的装饰器，然后在一个装饰器入口点上尝试将它们整合在一起。显然，我们现在应该能够做得更好。 3. 将互斥锁存储在被包装对象上解决这个问题的关键在于我们可以在哪里存储线程锁。在被包装对象调用之间存储任何数据的惟一选项将是被包装对象本身，包括被包装的函数，类实例方法和类方法。因此相对于需要传入锁，或者在函数闭包中创建锁，让我们尝试在包装器本身中的创建和管理锁。** 首先考虑一个正常函数的情况。在这种情况下，我们所能做的就是将所需的线程锁存储在包装的函数对象本身上。 123456789101112131415@decoratordef synchronized(wrapped, instance, args, kwargs): lock = vars(wrapped).get('_synchronized_lock', None) if lock is None: lock = vars(wrapped).setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)@synchronizeddef function(): pass&gt;&gt;&gt; function()&gt;&gt;&gt; function._synchronized_lock&lt;_RLock owner=None count=0&gt; 我们要处理的一个关键问题是如何第一次创建线程锁。为此我们需要做的是查看线程锁是否已被创建。** lock = vars(wrapped).get(&#39;_synchronized_lock&#39;, None) 如果返回一个有效的线程锁对象，那么我们就可以继续尝试获取锁。如果锁不存在我们需要创建锁,但是我们必需小心避免竞态条件，因为当两个线程同时进入这部分代码时，它们都会判断需要第一次创建锁。我们用来解决这个问题的窍门是: lock = vars(wrapped).setdefault(&#39;_synchronized_lock&#39;, threading.RLock()) 当两个线程同时尝试创建锁时，它们都可能创建一个锁实例，但是由于使用了dict.setdefault()，只会有一个进程会成功。因为 dict.setdefault() 总是返回它第一次存储的值。所以所有的线程都会继续运行并且尝试获取相同的锁对象。其中一个线程对象会被丢弃也不存在任何问题，因为这只会在初始化并出现竞争条件时才会发生。 因此，我们已经成功地复制了最初的内容，不同之处在于线程锁存储在被包装的函数上，而不是存储在一个封闭函数的堆栈上。我们仍然有一个问题，即每个实例方法都有一个不同的锁。(而不是一个实例内的所有同步方法共用一个锁)。简单的解决方案是利用我们的通用装饰器，它提供了判断装饰器被使用的上下文的能力。 具体点说，我们需要判断当前是否在装饰一个类方法或实例方法，如果是，则将锁对象存储在 instance 参数上。 12345678910111213141516171819202122232425262728293031323334353637383940@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: context = vars(wrapped) else: context = vars(instance) lock = context.get('_synchronized_lock', None) if lock is None: lock = context.setdefault('_synchronized_lock', threading.RLock()) with lock: return wrapped(*args, **kwargs)class Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo1 = Object()o2 = Object()&gt;&gt;&gt; o1.method_im()&gt;&gt;&gt; o1._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o1._synchronized_lock)4386605392&gt;&gt;&gt; o2.method_im()&gt;&gt;&gt; o2._synchronized_lock&lt;_RLock owner=None count=0&gt;&gt;&gt;&gt; id(o2._synchronized_lock)4386605456 这个简单的改变实际上已经达到了我们想要的结果。如果同步的装饰器被用于一个正常的函数，那么线程锁将被存储在函数本身上，并且它将单独存在，并且只在调用相同的函数之间进行同步。 对于实例方法，线程锁将被存储在类的实例上，实例方法会绑定到类，因此在该类上标记为同步的任何实例方法都将在该线程锁上同步，从而模拟Java的行为 那类方法呢。在这种情况下，instance 参数实际上是类。如果线程锁被存储在类上，那么结果将是，如果有多个类方法，并且它们都被标记为synchronized，那么它们将相互排斥。这种情况下线程锁的使用方式将不同于实例方法，但这实际上也是我们想要的。 代码是否对类方法有效? 12345678&gt;&gt;&gt; Object.method_cm()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 38, in __call__ return self.wrapper(self.wrapped, instance, args, kwargs) File "synctest.py", line 176, in synchronized lock = context.setdefault('_synchronized_lock'),AttributeError: 'dictproxy' object has no attribute 'setdefault' 很不幸，有错。这种情况的原因是，类 __dict__ 不是一个普通的字典，而是一个 dictproxy 。一个 dictproxy 不与普通的dict共享相同的方法，特别是它不提供setdefault()方法。因此，我们需要一种不同的方法来为类创建同步线程锁。dictproxy 还导致了另一个问题，即它不支持属性设置。但是类本身支持属性设置 1234&gt;&gt;&gt; vars(Object)['_synchronized_lock'] = threading.RLock()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: 'dictproxy' object does not support item assignment 123&gt;&gt;&gt; setattr(Object, '_synchronized_lock', threading.RLock())&gt;&gt;&gt; Object._synchronized_lock&lt;_RLock owner=None count=0&gt; 由于函数对象和类实例都可以，所以我们需要切换更新属性的方法。 4. 存储在装饰器上的元线程锁作为dict.setdefault()第一次设置锁的原子方式的替代方法，我们可以做的是使用存储在@synchronized 装饰器本身上的元线程锁。由于元线程锁的创建仍存在竞争条件，因此需要使用dict.setdefault()实现元线程锁的原子性创建。 123456789101112131415161718192021@decoratordef synchronized(wrapped, instance, args, kwargs): if instance is None: owner = wrapped else: owner = instance lock = vars(owner).get('_synchronized_lock', None) if lock is None: meta_lock = vars(synchronized).setdefault( '_synchronized_meta_lock', threading.Lock()) with meta_lock: lock = vars(owner).get('_synchronized_lock', None) if lock is None: lock = threading.RLock() setattr(owner, '_synchronized_lock', lock) with lock: return wrapped(*args, **kwargs) 请注意，由于对封装函数的锁存在的检查与创建元锁之间的间隙，在我们获得了元锁之后，我们需要再次检查锁是否存在。这是为了避免两个线程同时在尝试创建锁而发生竞争条件。 这里有一点很重要，我们仅仅在更新被包装对象上的锁时使用了属性访问方法。而在查找被包装对象上是否存在锁时，没有使用getattr()方法，而是继续在vars()返回的__dict__中查找它。这是必要的，因为当在类的实例上使用getattr()时，如果该属性在类的实例中不存在，那么查找规则意味着如果该属性在类本身上存在，那么将返回该属性。 如果一个同步的类方法是第一个被调用的，这会导致问题，因为它会在类本身上留下一个锁。当随后调用实例方法时，如果使用了getattr()，它会找到类类型的锁并返回它，并且会被错误地使用。因此，我们继续通过 __dict__ 寻找锁，因为它只包含实例中实际存在的内容。 有了这些修改，所有锁的创建都可以自动完成，并在不同的上下文中创建一个适当的锁。 12345678910111213141516171819202122232425262728@synchronizeddef function(): passclass Object(object): @synchronized def method_im(self): pass @synchronized @classmethod def method_cm(cls): passo = Object()&gt;&gt;&gt; function()&gt;&gt;&gt; id(function._synchronized_lock)4338158480&gt;&gt;&gt; Object.method_cm()&gt;&gt;&gt; id(Object._synchronized_lock)4338904656&gt;&gt;&gt; o.method_im()&gt;&gt;&gt; id(o._synchronized_lock)4338904592 代码也适用于在静态方法或类中使用@synchronized。综上所述，@synchronized 可以被应用的场景如下: 123456789101112131415161718192021222324@synchronized # lock bound to function1def function1(): pass@synchronized # lock bound to function2def function2(): pass@synchronized # lock bound to Classclass Class(object): @synchronized # lock bound to instance of Class def function_im(self): pass @synchronized # lock bound to Class @classmethod def function_cm(cls): pass @synchronized # lock bound to function_sm @staticmethod def function_sm(): pass 5. 实现同步代码块所以，我们已经完成了对同步方法的支持，如何实现同步代码块呢。要实现的目标是能按照下面的方式编写代码: 123456789class Object(object): @synchronized def function_im_1(self): pass def function_im_2(self): with synchronized(self): pass 也就是说，我们需要 synchronized 装饰器不仅可以用作装饰器，而且还可以作为上下文管理器使用。在synchronized作为上下文管理器时，类似于Java，需要提供给它执行同步操作的对象，对于实例方法而言，这个对象是 self 参数或者类的实例。为了解释我们如何做到这一点，需要等待下一篇文章。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[06 装饰器的类实现]]></title>
    <url>%2F2018%2F05%2F25%2Fwrapt%2Fpython_decorator_06%2F</url>
    <content type="text"><![CDATA[上一篇文章中，我们讨论了如何实现一个带参数的装饰器，以及如何让装饰器可选的接收参数而不是必需输入参数。也讨论了如何让装饰器能在被包装函数的不同调用之间保持状态。保持状态的一种可用方法是使用类实现装饰器。然而我们实现的通用装饰器模式在使用类实现装饰器还存在一些问题，本文我们将来探讨问题出现的根源以及如何解决。 1. 装饰器工厂函数正如前文所述，我们通过类实现装饰器的模式如下 12345678910class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 当我们这么做时，装饰器在被应用时发生了如下错误: 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) _decorator() 是我们装饰器工厂函数的内部函数。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 错误的原因是我们使用函数闭包实现装饰器工厂函数，却希望它能同时工作在普通函数和类方法上。当类方法被访问时，将触发描述符协议，绑定将会发生；类实例的引用将自动作为第一个参数传递给类方法。而 _decorator() 却没有被定义成同时接收 self和wrapped 作为参数，所以调用失败。我们可以创建一个仅用于类实例的装饰器工厂函数。但是这与我们之前要为类方法和函数创建统一的装饰器的初衷相违背。 解决问题的方法是，使用我们的 function_wrapper 作为装饰器工厂的返回对象，而不是函数闭包。 12345678910111213141516171819def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): return function_wrapper(wrapped, wrapper) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper)class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 这种方式特别巧妙，但是很不容易理解，我们再来看看整个调用的发生过程 with_arguments(arg=1) 带参数的装饰器被使用时，将创建一个类实例 ins 在 @decorator 装饰下, ins 的 __call__ 方法此时是 function_wrapper(__call__, _wrapper) 对象 @ 将 function 对象作为参数传递给创建的类实例，将调用 ins.__call__(function) 方法，此时将触发function_wrapper的描述符协议，并进一步调用 _wrapper(__call__, ins) 函数，functions 对象则通过 arg 传递给 _execute 函数，_execute 执行返回新的 function_wrapper(functions, __call__) 对象 装饰的最终结果是，我们现在不必担心 @decorator 被应用在普通函数，实例方法还是一个类方法上。因为在所有的情况下，被绑定的实例对象不会通过 args 被传递 细心的读者很快就会发现另一个问题，在 __call__ 在被调用时，需要传入装饰器类的实例即 self 参数，而在上述的实现中并没有此步骤。(不过我没懂为什么作者在 _wrapper 内多嵌套一层_execute函数，应该是想说名这是要被执行的部分。) 2. 类的绑定要求更改之后，重新进行测试，我们遇到了一个新的问题。这次发生在被被包装函数被调用的时候。 123456&gt;&gt;&gt; function()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 243, in __call__ return self.wrapper(self.wrapped, None, args, kwargs)TypeError: __call__() takes exactly 5 arguments (4 given) 现在这个问题是__call__()方法传递给@decorator发生在 类初始化，此时它是未绑定方法，任何类实例远还没被创建。通常情况下，类实例的引用在方法被绑定时被提供，但是因为我们的装饰器实际是一个工厂函数，因此这里涉及到了两层绑定。外部包装函数的类实例被传递给工厂函数内部的 _wrapper 函数的instance参数。但是它在 function wrapper 对象被创建的时候，完全没有被使用。为了解决这个问题，我们需要根据是否绑定了一个实例方法，显示使用类实例绑定我们的包装函数 1234567891011def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 在这个示例中，有三种情况需要我们处理。 第一种情况是 instance 为 None。这对应于decorator函数被应用在普通函数，类静态方法或一个类上 第二种情况是 instance 不为 None，但是是一个类对象。这对应用于一个类方法。这种情况下，我们需要通过包装函数的get()将包装函数显示绑定到一个类对象。 第三种即最后一种情况下，instance 不是None，也不是一个类对象。这对应于实例方法。在这种情况我们仍然需要绑定包装函数，只不过这次绑定的是类实例。 3. 总结改进之后，我们解决了所有问题，而且很大程度上完善了我们的装饰器模式。所以，目前我们的通用装饰器解决方案如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__ = wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name)class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return self class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)def decorator(wrapper): def _wrapper(wrapped, instance, args, kwargs): def _execute(wrapped): if instance is None: return function_wrapper(wrapped, wrapper) elif inspect.isclass(instance): return function_wrapper(wrapped, wrapper.__get__(None, instance)) else: return function_wrapper(wrapped, wrapper.__get__(instance, type(instance))) return _execute(*args, **kwargs) return function_wrapper(wrapper, _wrapper) 尽管在之前的文章中提到过。这里给出的对象代理实现并不是一个完美实现。因此，不要使用这段代码。如果你使用了，就会发现。在被包装函数上的部分内省操作不会按照我们所预期的执行。特别的，访问函数的doc属性总是返回 None。类似Python3中的新增变量 __qualname__ 和 __module__ 也不能正确显示。 正确处理像__doc__这样的内置属性是比较费劲的，因为内置属性的获取逻辑与普通属性有时候并不相同。上述实现中我们期望的是，无论从代理对象还是代理对象的子类，我们都是从被包装函数获取并返回属性值，但是对于__doc__属性，即便是代理对象的子类没有__doc__属性，它也同样会覆盖父类的__doc__，结果是代理对象的子类拦截了对 __doc__ 属性的获取。所以这里展示的代理对象仅仅是一个参照实现。 大体上说，这里所有的代码都仅仅是参照实现。目的不是使用而是展示如何实现一个更加通用的装饰器。它只是提供给你一个学习的途径。不要期望通过简单的几行代码就能实现，事情不会那么简单。 4. wrapt 模块如果我告诉你不要使用这里的代码，那你应该怎么做呢？答案是在PyPi上已经有现成的 wrapt 模块。wrapt 模块已经上线几个月了，但是目前为止并没有广为人知。它实现了这里描述的所有细节，甚至更多。这个模块实现了一个完整的代理对象，能使所有代码正确执行。并且提供了很多和装饰器工厂函数相关的特性，也提供了很多和猴子补丁相关的特性。 虽然我指出了wrapt 模块的存在，但是博客内容不会就此停止，因为我还有其他一些主题想要阐述。这些内容包括通用装饰器的应用，启用和关闭装饰器，装饰器执行性能问题，以及代理对象，猴子补丁的实现问题等等。 接下来的博客，我将举一个通用装饰器应用的特殊示例，来说明Python 装饰器如此强大，为什么Pyhton不提供一个@synchronized装饰器。在装饰器第一次被引入编程语言时，这个装饰器被当作是如何使用装饰器的经典示例。然而我能找到的所有实现都是半成品，很少在现实世界中被使用。我相信这里的通用装饰器能帮助我们实现一个可用的@synchronized装饰器。我将在下一篇博客中详述它。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[05 带参数的装饰器]]></title>
    <url>%2F2018%2F05%2F24%2Fwrapt%2Fpython_decorator_05%2F</url>
    <content type="text"><![CDATA[在之前的博客，通过使用代理对象，装饰器工厂函数等技术，我们已经实现了一个通用装饰器。在这篇文章中，我们将使用前面文章中描述的装饰器工厂函数，介绍如何使用它来实现接受参数的装饰器，包括强制参数和可选的接收参数。 1. 装饰器创建模式前面文章中描述的关键组件是一个函数包装器对象。我不打算复制代码，所以请参阅前面的帖子。简而言之，它是一个类类型，它接受要被包装的函数和一个用户提供的包装器函数。所得到的函数包装器对象的实例被用来代替被包装函数，当调用时，会将被包装函数的调用委托给用户提供的包装器函数。这允许用户修改调用的方式，在调用被包装函数之前或之后执行操作，或者修改输入参数或结果。function_wrapper 和装饰器工厂一起使用创建装饰器的方式如下:** 12345678910111213141516171819# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator# 使用工厂函数创建的装饰器@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) print('KWARGS', kwargs) return wrapped(*args, **kwargs)# 应用装饰器包装函数@my_function_wrapperdef function(a, b): pass 在本例中，创建的最终装饰器不接受任何参数，但如果我们希望装饰器能够接受参数，在调用用户提供的包装器函数时可访问传入的参数，那么我们该如何做呢？ 2. 使用函数闭包收集参数最简单的实现一个能接收参数的装饰器的方式是使用函数闭包 123456789def with_arguments(arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments(arg=1)def function(): pass 实际上，外部函数本身是一个工厂函数，可根据传入的参数，返回不同的装饰器实例。因此，当外部工厂函数被应用到一个具有特定参数的函数时，它返回内部装饰器函数，实际上它是应用于被包装的函数。当包装器函数最终被调用时，它会调用被包装函数，并通过作为函数闭包的一部分来访问传递给外部工厂函数的原始参数。** 位置或关键字参数可以与外部装饰器工厂函数一起使用，但是我认为关键字参数可能是一个更好的惯例，我稍后会展示。现在，如果带有参数的装饰器具有默认值，使用这种方法来实现装饰器，即使不传递参数，也必需将其作为一个不同的调用来使用。也就是说，仍然需要提供空括号。 123456789def with_arguments(arg='default'): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper@with_arguments()def function(): pass 尽管这只是一个特例，但看起来不优雅。大多数更喜欢当所有参数都是可选，并没有被显示传递参数时，括号时可选的。换句话说，当没有参数被传递时，可以被写成 123@with_argumentsdef function(): pass 当我们从另一个角度看问题时，这个想法实际上是有价值的。如果一个装饰器最初不接收参数，但是之后又需要可选的接收参数。如果括号是可选的，那么原来不带参数调用装饰器的代码也无需改变。 3. 带可选参数的装饰器允许装饰器添加可选参数，可以将上面的方法更改为: 12345678910111213141516def optional_arguments(wrapped=None, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped)@optional_arguments(arg=2)def function1(): pass@optional_argumentsdef function2(): pass 当具有默认的可选参数时，外部工厂函数将被包装函数作为第一个参数并默认为 None。第一次调用时，被包装函数是 None，通过 partical 函数再一次返回装饰器工厂函数。第二次调用，被包装函数将被传入并被装饰器包装。 将装饰器被直接装饰函数时，因为默认参数的存在，我们不需要显示传递参数。因为 wrapped 惨数值不是None，装饰器直接返回工厂函数，直接装饰函数。 此时工厂函数的参数必需是关键词参数，Python 3允许您使用新的关键字参数语法来强制使用关键词参数。 123456789def optional_arguments(wrapped=None, *, arg=1): if wrapped is None: return functools.partial(optional_arguments, arg=arg) @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper(wrapped) 这样，就可以避免有人不小心将装饰器参数作为位置参数传递给 wrapped。对于一致性，关键字参数也可以被强制执行，即使它不是必需的。 12345def required_arguments(*, arg): @decorator def _wrapper(wrapped, instance, args, kwargs): return wrapped(*args, **kwargs) return _wrapper 4. 在调用之间保持状态某些时候，装饰器可能需要在函数调用之间保持状态。一个典型的例子是缓存装饰器。此时，由于包装器函数本身没有任何状态收集器，所以只能借助于装饰器能够访问到的外部数据结构作为状态收集器进行状态保持。 有几种方法可以做到这一点。 第一个是将保持状态的对象作为显式参数传递给装饰器 12345678910111213141516def cache(d): @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = wrapped(*args, **kwargs) return result return _wrapper_d = &#123;&#125;@cache(_d)def function(): return time.time() 除非有特定的需要能够传入状态对象，否则第二个更好的方法是在外部函数的调用中创建状态对象。 1234567891011121314151617def cache(wrapped): d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function(): return time.time() 这种情况下，外部包装函数在函数内部自定状态对象，而不是通过参数显示传递。如果这是一个合理的默认值，但是在某些情况下，仍然需要将状态对象作为参数传递进来，那么可以使用可选的装饰数参数。 12345678910111213141516171819202122232425262728293031def cache(wrapped=None, d=None): if wrapped is None: return functools.partial(cache, d=d) if d is None: d = &#123;&#125; @decorator def _wrapper(wrapped, instance, args, kwargs): try: key = (args, frozenset(kwargs.items())) return d[key] except KeyError: result = d[key] = wrapped(*args, **kwargs) return result return _wrapper(wrapped)@cachedef function1(): return time.time()_d = &#123;&#125;@cache(d=_d)def function2(): return time.time()@cache(d=_d)def function3(): return time.time() 5. 使用类创建装饰器在第一篇文章中，我们说过可以使用类实现装饰器。 1234567class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 就像之前已经阐述的，这种通过类实现的装饰器存在缺陷，但是作为一种替代模式，这种原始的方法也能保持状态。具体地说，类的构造函数可以将状态对象连同被包装函数保存为类实例的属性。 1234567891011121314151617class cache(object): def __init__(self, wrapped): self.wrapped = wrapped self.d = &#123;&#125; def __call__(self, *args, **kwargs): try: key = (args, frozenset(kwargs.items())) return self.d[key] except KeyError: result = self.d[key] = self.wrapped(*args, **kwargs) return result@cachedef function(): return time.time() 在装饰器逻辑特别复杂时，这种通过类实现的装饰器也存在一些好处。可以拆分封装在不同的类方法中。那么使用我们的新函数包装器和装饰器工厂，能否将装饰器实现为类呢？一种可能的方式是这样: 123456789101112class with_arguments(object): def __init__(self, arg): self.arg = arg @decorator def __call__(self, wrapped, instance, args, kwargs): return wrapped(*args, **kwargs)@with_arguments(arg=1)def function(): pass 装饰器执行逻辑是这样的，当带参数的装饰器被使用时，将创建一个类实例。在被包装函数被调用时，将调用 @decorator 装饰的实例方法 __call__()，__call__()进而调用被包装函数。因为__call__()是实例的绑定方法，所以能够访问到类实例拥有的状态对象。 那么事实上是否能正常运行呢？ 1234Traceback (most recent call last): File "test.py", line 483, in &lt;module&gt; @with_arguments(1)TypeError: _decorator() takes exactly 1 argument (2 given) 理想很丰满，显示很骨干。失败的原因就在于装饰器工厂函数的实现方式，我们将在下一篇文章种解释并解决这个特别的问题。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 作为另一种一种替代方式是，仍然使用类封装所需的逻辑，并在函数闭包类创建实例供包装函数使用。装饰器将功能委托给类实例，但是本身不作为类实现。这种方式需要额外创建一个类，使用起来并不优雅。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[04 实现一个通用装饰器]]></title>
    <url>%2F2018%2F05%2F22%2Fwrapt%2Fpython_decorator_04%2F</url>
    <content type="text"><![CDATA[本节我们将实现一个”通用装饰器”，它能够让用户提供的包装函数通过传入的参数判断其被使用的上下文，即确定，它是被应用在函数，实例方法，类方法，类对象中的哪一个。因为装饰器不是在各个环境种被单独实现，而是以一种更加统一的方式创建，所以将这种能确定上下文的装饰器称为通用装饰器。 1. 内容回顾到目前为止，我们创建装饰器的方式已经经过了几次迭代: 第一篇博客中我们介绍使用函数创建装饰器的传统方式，这种方式存在几个重大问题 为解决函数创建装饰器的问题，我们在第二篇博客中使用了代理对象，并将装饰器实现成了描述符，这种方式有效的解决了之前的问题，但是存在大量的样板代码 为了提高创建装饰器的效率，第三篇博客中我们使用了装饰器工厂函数，抽象了装饰器的创建过程，用户只需提供一个执行所需的包装函数即可。我们的目的是实现一个通用装饰器，能够让用户的包装函数通过传入参数确定其被使用的上下文。 12345678910111213# 包装函数通过传入参数确定其被使用的上下文@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 目前为止我们已经能够区分装饰器是被用于普通函数和还是实例方法，但是当通过类调用类方法和静态方法时将出现问题。本文我们将继续探索如何调整我们的装饰器工厂函数，以区分类方法和静态方法，以便找到实现通用装饰器的模式 2. 区分普通函数和实例方法目前为止，我们的通用装饰器模式实现如下: 123456789101112131415161718192021222324252627282930313233class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs)# 装饰器工厂函数def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 为了测试当前的模式能在任何情况下都能工作，我们需要使用装饰器工厂创建一个装饰器，它能在执行时打印绑定的 instance 对象，以及传递进来的参数。 12345@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs) 当装饰器被应用到一个正常的函数和实例方法时，包括通过显式传入实例调用实例方法时，我们能够得到符合预期的结果 12345678910111213141516171819202122@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 但是当装饰起被应用到类方法以及静态方法时，参数传递发生了错误。instance 按预期要么为空，要么接收的是类实例或类对象，现在却是传递给函数的第一个实参。并不符合我们通用装饰器的要求 。 12345678910111213141516171819class Class(object): @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE 1ARGS (2,) 3. 区分类方法和静态方法因此，我们要指出的是，在实例被传递为None的情况下，我们需要能够区分这三种情况: 通过类直接调用实例方法 类方法被调用 静态方法被调用 一种判断方法是查看绑定函数的__self__属性。该属性保存了函数在特定时间点绑定到的对象类型信息。我们先来看看通过类调用不同方法时，此属性的值。 123456789101112&gt;&gt;&gt; print(Class.function_im.__self__)None&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' 通过类调用实例方法的情况，__self__ 值为 None，对于类方法，它将是类对象，在静态方法的情况下，不存在 __self__ 属性。似乎检查 __self__ 是一个有效的判断方法 在我们编写一个基于此的解决方案之前，我们先检查一下Python 3，以确保我们在那里没问题，并且没有任何变化。 12345678910111213141516&gt;&gt;&gt; print(Class.function_im.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "dectest.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__'&gt;&gt;&gt; print(Class.function_cm.__self__)&lt;class '__main__.Class'&gt;&gt;&gt;&gt; print(Class.function_sm.__self__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 19, in __getattr__ return getattr(self.wrapped, name)AttributeError: 'function' object has no attribute '__self__' Python 3 与 Python 2 表现并不相同，此方法无效。但是为什么会出现这种情况？发生这种情况的原因是，Pyhton3 已经没有未绑定对象这个对象，通过类直接调用实例方法时返回的也是函数。而Python2中通过类调用实例的返回值类型依赖于 __self__ 是否为None，所以Python3中删除了此属性。因此，我们现在不能区分通过类调用实例方法和调用静态方法这两种情况。 另一个方法是在 function_wrapper 构造函数内，检查被包装对象的类型，并确定它是类方法还是静态方法。然后，将判定信息传递到 bound function wrapper 并进行进一步检查。 12345678910111213141516171819202122232425262728293031323334class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function' and self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 如果有人实际上在他们的decorator中实现了描述符协议，那么希望他们也可以在这里使用对象代理。因为对象代理拥有class属性，它将返回被包装对象的类，这意味着isinstance()检查仍然会成功，因为isinstance()会优先考虑class的返回结果，而不是对象的实际类型。 无论如何，更改后，我们重新测试如下 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE &lt;__main__.Class object at 0x101f973d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 成功，我们已经修复了调用类方法和静态方法时参数列表问题。现在的问题是，虽然对通过实例调用方法时， instance 参数没有问题。但是无论是通过实例还是类，传递给类方法和静态方法的 instance 参数都没有什么用。并且我们不能将它同其他情形区别开。理想情况下，我们希望调用类方法时 instance 参数始终为类对象，而调用静态方法时，则使用为 None。因此 对于静态方法，我们只需要在检查被包装类型时，判断 ‘staticmethod’ 即可 对于类方法的情况，如果我们回头看一下我们的测试，看看是否可以使用__self__属性，我们发现，对于类方法，__self__是类实例，对于静态方法，属性不存在。因此，我们可以做的是，如果包装对象的类型不是一个函数，那么我们可以查找__self__的值，如果它不存在的话，就会默认为None。这将满足这两种情况。进一步改进后如下 1234567891011121314151617181920212223class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding def __call__(self, *args, **kwargs): if self.binding == 'function': # 通过类调用的实例方法 if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: # 通过实例调用的实例方法 return self.wrapper(self.wrapped, self.instance, args, kwargs) else: # 调用静态方法，__self__ 属性不存在，instance 为 None # 调用类方法时，__self__ 为类对象， instance 为类对象 instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) 如果我们重新测试一次，我们将得到我们想要得结果 1234567891011121314151617181920212223&gt;&gt;&gt; c.function_im(1,2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x10c2c43d0&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 现在万事大吉了？可惜并不是。 4. 多层绑定还有一个我们还没有考虑到的特殊情况，即为方法创建别名，并通过别名调用时。 1234567891011121314151617181920212223&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE 1ARGS (2,)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "test.py", line 132, in __call__ return self.wrapper(wrapped, instance, args, kwargs) File "test.py", line 58, in my_function_wrapper return wrapped(*args, **kwargs)TypeError: unbound method function_im() must be called with Class instance as first argument (got int instance instead)&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 对于类方法或静态方法来说，一切都很好，但是对于实例方法来说却失败了。这里的问题是由于在第一次访问实例方法时，它将返回绑定的bound_function wrapper对象。然后把它作为类的属性分配回来。当通过新名称进行后续查找时，在正常情况下，绑定将再次发生，以将其绑定到实际实例。在我们的绑定函数包装器的实现中，我们不提供__get__()方法，因此不会发生这种重新绑定。结果是，在随后的调用中，它全部崩溃。 Class.function_rm = Class.function_im 设置别名时，发生第一次描述符协议，function_rm 绑定得是 bound_function_wrapper 对象，第二次通过别名调用实例方法时会发生第二次描述符协议，进行第二次绑定。 因此，解决方案是我们需要向 bound_function_wrapper 添加__get__()方法，为其提供了执行进一步绑定的能力。我们只希望在实例为None的地方执行这个操作，这表明我们处理的是实例方法，而不是类方法或静态方法。 (注: Class.function_rm = Class.function_im 第一次绑定时，self.binding 为 function，并且由于时通过类直接调用实例方法，因此 instance 参数是 None。包装普通函数时也符合此类情况，但是不会触发描述符协议，只有通过实例调用发生第二次绑定时，才会调用bound_function_wrapper 的__get__方法) 另一个问题是，我们需要绑定的是原始的被包装函数，而不是绑定后的包装函数。最简单的处理方法是将对原始函数包装器 function_wrapper 的引用传递给绑定的函数包装器bound_function_wrapper，并通过它获得原始的被包装函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper, binding, parent): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper self.binding = binding self.parent = parent # 目的是获取原始的被包装函数 def __call__(self, *args, **kwargs): if self.binding == 'function': if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) else: return self.wrapper(self.wrapped, self.instance, args, kwargs) else: instance = getattr(self.wrapped, '__self__', None) return self.wrapper(self.wrapped, instance, args, kwargs) def __get__(self, instance, owner): # 仅在通过类调用实例方法时才会发生第二次绑定 if self.instance is None and self.binding == 'function': descriptor = self.parent.wrapped.__get__(instance, owner) # instance 是第二次绑定传入的实例对象 return bound_function_wrapper(descriptor, instance, self.wrapper, self.binding, self.parent) return selfclass function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper if isinstance(wrapped, classmethod): self.binding = 'classmethod' elif isinstance(wrapped, staticmethod): self.binding = 'staticmethod' else: self.binding = 'function' def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper, self.binding, self) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 再次运行测试得到如下所示 1234567891011121314151617&gt;&gt;&gt; Class.function_rm = Class.function_im&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;__main__.Class object at 0x105609790&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_cm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)# 不会发生二次绑定&gt;&gt;&gt; Class.function_rm = Class.function_sm&gt;&gt;&gt; c.function_rm(1, 2)INSTANCE NoneARGS (1, 2) 5. 装饰器应用顺序目前为止，我们的装饰器一直被放置在将方法标记为类方法或静态方法的装饰器之外。如果我们颠倒顺序会怎样？ 1234567891011121314151617181920212223242526272829class Class(object): @classmethod @my_function_wrapper def function_cm(self, a, b): pass @staticmethod @my_function_wrapper def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_cm(1,2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE NoneARGS (&lt;class '__main__.Class'&gt;, 1, 2)&gt;&gt;&gt; c.function_sm(1,2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)INSTANCE NoneARGS (1, 2) 静态方法按预期运行，但是类方法不行。在这个特殊的例子中，它实际上可以被看作是Python本身的一个bug。具体地说，classmethod 装饰器本身并不能对它包装的所有对象都遵守描述符协议。这也是为什么当使用闭包实现装饰器会发生错误的原因。如果classmethod 装饰器能正常工作，一起都是OK 的。对于那些对细节感兴趣的人，您可以在Python bug跟踪器中查看19072。 6. 装饰器一个类除了与类方法的装饰器顺序之外，我们实现的通用装饰器的模式看起来很好。我在上一篇文章中提到过，我们的目标是，我们也可以区分什么时候装饰器被应用到一个类中。所以让我们试试 1234567@my_function_wrapperclass Class(object): pass&gt;&gt;&gt; c = Class()INSTANCE NoneARGS () 基于此，我们无法将其与普通函数或类方法区分开来。如果我们再考虑一下，在这个例子中传递给包装器函数的包装对象将是类本身。让我们输出传递给用户包装函数的 wrapped参数，看看是否能区分出这种情景 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('WRAPPED', wrapped) print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)WRAPPED &lt;function function at 0x10e13bb18&gt;INSTANCE NoneARGS (1, 2)class Class(object): @my_function_wrapper def function_im(self, a, b): pass @my_function_wrapper @classmethod def function_cm(self, a, b): pass @my_function_wrapper @staticmethod def function_sm(a, b): passc = Class()&gt;&gt;&gt; c.function_im(1,2)WRAPPED &lt;bound method Class.function_im of &lt;__main__.Class object at 0x107e90950&gt;&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_im(c, 1, 2)WRAPPED &lt;functools.partial object at 0x107df3208&gt;INSTANCE &lt;__main__.Class object at 0x107e90950&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_cm(1,2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; Class.function_cm(1, 2)WRAPPED &lt;bound method type.function_cm of &lt;class '__main__.Class'&gt;&gt;INSTANCE &lt;class '__main__.Class'&gt;ARGS (1, 2)&gt;&gt;&gt; c.function_sm(1,2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; Class.function_sm(1, 2)WRAPPED &lt;function function_sm at 0x107e918c0&gt;INSTANCE NoneARGS (1, 2)@my_function_wrapperclass Class(object): passc = Class()&gt;&gt;&gt; c = Class()WRAPPED &lt;class '__main__.Class'&gt;INSTANCE NoneARGS () 答案是肯定的，因为它是唯一一个被包装对象是类型对象的情况。 7. 通用装饰器结构我们的目标是，一个装饰器能同时被应用在普通函数，示例方法，类方法以及类上。比较特殊的是静态方法，但是实践中，静态方法与函数并没有本质上的不同，只是它被放在不同的地方。在装饰器的执行过程中区分出静态方法是必要的，但是静态方法不会包含任何连接到它所在的类的参数。如果需要，在开始更应该创建一个类方法。最后我们的通用装饰器可以被展示如下: 12345678910111213141516@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # Decorator was applied to a class. return wrapped(*args, **kwargs) else: # Decorator was applied to a function or staticmethod. return wrapped(*args, **kwargs) else: if inspect.isclass(instance): # Decorator was applied to a classmethod. return wrapped(*args, **kwargs) else: # Decorator was applied to an instancemethod. return wrapped(*args, **kwargs) 这样的通用装饰器有实际用途吗?我相信有一些很好的例子，我将在随后的博客文章中特别提到其中一个。其他一些框架，比如Django，也使用了一些技巧来创建同时适用于函数和实例方法的装饰器。事实证明，他们使用的方法是不正确的，因为它不遵守描述符协议。如果您对此感兴趣，请参见Django bug跟踪器中的第21247号问题。下一篇博客中将介绍一些具有可选参数的装饰器的问题，通用装饰器的使用实例留在以后展示。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[03 使用工厂函数创建装饰器]]></title>
    <url>%2F2018%2F05%2F12%2Fwrapt%2Fpython_decorator_03%2F</url>
    <content type="text"><![CDATA[上一篇文章描述了一种基于代理对象创建装饰器的模式，并且通过将装饰器实现为一个描述符，解决了当装饰器应用于类方法时，对象绑定问题。代理对象和描述符的组合自动确保了内省机制能正常进行。现在的问题是如何消除样本代码来解决代码复用的问题。本文我们将进一步改进创建装饰器的方式，通过使用装饰器工厂函数，来抽象装饰器的创建，用户只需提供一个执行所需功能的的包装函数即可。 1. 装饰器的实现模式如前所述，我们需要一个代理对象，其实现如下 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 正如最后一次指出的那样，这是对它所做事情的最小表示。一个通用的对象代理需要做更多的工作。 描述符本身将按照如下模式实现 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 当将装饰器应用于一个正常的函数时，将使用包装器的 __call__()方法。如果将包装器应用于类的方法，则在属性访问时调用 __get__() 方法，返回一个新的绑定对象之后的装饰器，并在被调用时调用新的装饰器的__call__()方法。这使得我们的包装器能作为描述符来传递描述符协议，以根据需要对包装的对象进行绑定。 2. 创建装饰器的装饰器正常工作的装饰器有一个固定的实现模式，因此，我们可以使用工场函数抽象装饰器创建的过程，工厂函数可以作为一个装饰器使用，创建一个装饰器的过程如下: 1234567@decoratordef my_function_wrapper(wrapped, args, kwargs): return wrapped(*args, **kwargs)@my_function_wrapperdef function(): pass 这个装饰器工厂函数 decorator 应该怎么实现呢？就像表现的一样，我们的装饰器工厂函数是非常简单的，与partial()函数并没有很大不同，在装饰器定义时接收用户提供的包装函数，在装饰器应用时接收被包装函数，并将他们传递到function wrapper对象中。 12345def decorator(wrapper): @functools.wraps(wrapper) def _decorator(wrapped): return function_wrapper(wrapped, wrapper) return _decorator 我们现在只需要修改我们的装饰器 function wrapper 对象的实现，将包装对象的实际执行委托给用户提供的包装函数。 123456789101112131415161718192021class bound_function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, args, kwargs) function_wrapper 和 bound_function_wrapper 同时接收包装函数，和被包装函数，并将 __call__() 实际执行委托给用户提供的包装函数，由用户调用被包装函数并返回值。 因此，我们可以使用工厂来简化创建装饰器的过程。现在让我们来检查一下，在所有的情况下，这将在实际工作中发挥作用，并且看看我们还能找到什么其他的问题，以及我们是否能在这些情况下改进。 3. 装饰类方法第一个可能导致问题的领域是创建一个单独的decorator，它可以同时处理类的正常函数和实例方法。为了测试我们的新decorator是如何工作的，我们可以在调用包装函数时打印传递给包装器的args，并可以比较结果。 1234@decoratordef my_function_wrapper(wrapped, args, kwargs): print('ARGS', args) return wrapped(*args, **kwargs) 首先让我们尝试包装一个普通函数: 123456@my_function_wrapperdef function(a, b): pass&gt;&gt;&gt; function(1, 2)ARGS (1, 2) 正如所期望的那样，在函数被调用时，只有两个参数被输出。包装一个实例方法会如何？ 123456789class Class(object): @my_function_wrapper def function_im(self, a, b): passc = Class()&gt;&gt;&gt; c.function_im()ARGS (1, 2) 同样，当调用实例方法时传入的两个参数被输出。因此，装饰器对正常函数和实例方法的工作方式是相同的。 这里的问题是，用户如何在他们的包装函数中获取类的实例。当函数被绑定到类的实例时，我们丢失了这个信息，因为类实例现在与传入的绑定函数关联，而不是参数列表。要解决这个问题，我们可以记住在调用绑定函数时传递给 __get__() 方法的实例是什么。在 bound wrapper被创建，作为参数传递给bound wrapper。 12345678910111213141516171819202122class bound_function_wrapper(object_proxy): def __init__(self, wrapped, instance, wrapper): super(bound_function_wrapper, self).__init__(wrapped) self.instance = instance self.wrapper = wrapper def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, self.instance, args, kwargs)class function_wrapper(object_proxy): def __init__(self, wrapped, wrapper): super(function_wrapper, self).__init__(wrapped) self.wrapper = wrapper def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped, instance, self.wrapper) def __call__(self, *args, **kwargs): return self.wrapper(self.wrapped, None, args, kwargs) 在bound wrapper中，类实例作为额外的参数传给用户创建的包装函数。对于普通函数，在顶级包装器中，对于这个新的实例参数，我们没有传递任何内容。现在，我们可以修用户的包装函数，以输出实例和传递的参数。 12345678910111213@decoratordef my_function_wrapper(wrapped, instance, args, kwargs): print('INSTANCE', instance) print('ARGS', args) return wrapped(*args, **kwargs)&gt;&gt;&gt; function(1, 2)INSTANCE NoneARGS (1, 2)&gt;&gt;&gt; c.function_im(1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 因此，这种变化能让我们在包装器函数中区分出一个普通函数调用和一个的实例方法调用。对实例的引用甚至是单独传递的，在调用原始被包装函数时，我们不必为一个实例方法去判断并移除额外的类实例参数。对于类，原始的被包装函数已经是绑定对象，所以不能在传入类实例对象。 需要注意的是实例方法可以通过类，显示传递类实例来调用，我们需要验证这种情况是否仍然符合我们的要求。 123&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE NoneARGS (&lt;__main__.Class object at 0x1085ca9d0&gt;, 1, 2) 不幸的是，将实例显式地传递给类中的函数作为参数时，类实例没有通过 instance 传递给包装函数，而是作为 arg 的第一个参数被传递。这并不是一个理想的结果 为了处理这种变化，我们可以在调用bound_function_wrapper.__call__()之前检查实例，并从参数列表的开头弹出实例。然后使用 partcial 函数将实例绑定到被包装函数上，并调用用户的包装函数。 1234567891011121314class bound_function_wrapper(object_proxy): def __call__(self, *args, **kwargs): if self.instance is None: instance, args = args[0], args[1:] wrapped = functools.partial(self.wrapped, instance) return self.wrapper(wrapped, instance, args, kwargs) return self.wrapper(self.wrapped, self.instance, args, kwargs)# We then get the same result no matter whether the instance method is called via the class or not.&gt;&gt;&gt; Class.function_im(c, 1, 2)INSTANCE &lt;__main__.Class object at 0x1085ca9d0&gt;ARGS (1, 2) 对于实例方法，一切都可以正常执行，被包装函数无论是实例方法和还是普通函数接收参数完全相同。得益与 instance 参数，在将装饰器应用于实例方法时，我们可以按需调用类方法。 对于类可以拥有的其他方法类型，特别是类方法和静态方法会怎样？ 12345678910class Class(object): @my_function_wrapper @classmethod def function_cm(cls, a, b): pass&gt;&gt;&gt; Class.function_cm(1, 2)INSTANCE 1ARGS (2,) 正如所看见得，装饰器对类方法和静态方法有非常严重得问题。这两种情况下，在函数被绑定时，instance 参数将为空。此时传递给函数的第一实参将被传递给 instance，这显然是不正确的，应该怎么做？ 4. 通用装饰器所以我们并没有完成一个通用的装饰器，但我们到底想要达到什么目的呢?我们最初的装饰模式有什么问题?这里的终极目标是我所说的“通用装饰器”。一个可以应用于普通函数、实例方法、类方法、静态方法甚至是类的修饰符，修饰符能够在使用的时候自动适用它被使用的上下文。 目前为止，实现装饰器的所有方法想达到上述目标是不可能了。只能通过复制代码，或者通过某种技巧转换装饰器，以便装饰器能在不同的上下文中使用。我的目标是能实现如下功能: 123456789101112@decoratordef universal(wrapped, instance, args, kwargs): if instance is None: if inspect.isclass(wrapped): # class. else: # function or staticmethod. else: if inspect.isclass(instance): # classmethod. else: # instancemethod. 本文中，我们已经实现了让装饰器在普通函数和实例方法上正确执行，我们现在需要了解如何处理类方法、静态方法以及将装饰器应用于类的场景。本系列的下一篇文章将继续追求这个目标，并描述如何进一步调整我们的装饰器。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[02 装饰器与描述符协议]]></title>
    <url>%2F2018%2F05%2F08%2Fwrapt%2Fpython_decorator_02%2F</url>
    <content type="text"><![CDATA[上一篇文章说明了普通函数实现的装饰器存在的问题。本文我们将着眼于之前阐述的最后一个问题，如何将装饰器应用到一个描述符上。 1. 描述符协议有关 Python 的对象模型和底层设计原理推荐大家读一读《流畅的Python》，这里不会详细解释描述符是什么以及他们的工作原理。简而言之，描述符就是存在绑定行文的对象，即属性访问会被描述符协议实现的方法所覆盖。实现描述符协议的特殊方法包括 __get__(), __set__(), 和 __delete__()。如果任意一中方法在一个对象中被定义，就可以说该对象是一个描述符** 123obj.attribute attribute.__get_(obj.type(obj))obj.attribute = value attribute.__set_(obj, value)del obj.attribute attribute.__delete_(obj, value) 上述描述的是，如果一个类的属性包含上述任意一中特殊方法，当相应操作在类属性被执行时，这些特殊方法将取代默认方法被调用。这就允许一个属性去覆盖将发生默认操作。 也许你以为你从未使用过描述符，事实上，函数对象就是描述符。当在类中定义函数时，函数就是普通的函数。当你通过’.’属性访问函数时，你将调用函数的 __get__()方法，将函数与一个类实例绑定，进而返回一个绑定方法对象** 123456789101112def f(obj): pass&gt;&gt;&gt; hasattr(f, '__get__')True&gt;&gt;&gt; f&lt;function f at 0x10e963cf8&gt;&gt;&gt;&gt; obj = object()&gt;&gt;&gt; f.__get__(obj, type(obj))&lt;bound method object.f of &lt;object object at 0x10e8ac0b0&gt;&gt; 所以当你调用类方法时，调用的不是原始函数的 __call__()，而是访问函数时临时创建的绑定方法对象的 __call__() 方法，当然，你通常不会看到所有这些中间步骤，只看到结果。 1234567&gt;&gt;&gt; class Object(object):... def f(self): pass&gt;&gt;&gt; obj = Object()&gt;&gt;&gt; obj.f&lt;bound method Object.f of &lt;__main__.Object object at 0x10abf29d0&gt;&gt; 现在回想一下在第一个博客文章中给出的例子，当我们对一个类方法应用了装饰器时，我们遇到了如下错误: 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 示例中的问题在于 @classmethod 装饰器返回的 classmethod 对象本身并没有 __call__() 方法，__call__() 方法仅存在于 classmethod 对象__get__()被调用时返回的结果中。 更具体的说， 人们使用的简单装饰器，并没有对被包装的描述符对象执行描述符协议以产生的一个可调用对象。想反，只是简单的直接调用被包装对象。因为其没有 __call__() 方法，结果当然会失败。 那为什么将装饰器应用在普通的实例方法上仍然可以运行呢？原因是一个普通函数本身具有 __call__() 方法，包装函数直接调用的是此方法。而且尽管绑定步骤被跳过，但是包装函数将 self 包含的实例对象通过第一参数显示传递给了原始的未绑定函数对象。因此对于一个普通的实例方法包装前后调用实际上是相同的，只有当被包装的对象(如@classmethod)依赖于正确应用的描述符协议时，才会崩溃。 2. 包装描述符对象解决包装器不能在类方法执行描述符协议获取绑定对象的方法是，让包装器也成为一个描述符对象。 1234567891011121314class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 如果将包装器应用于一个正常的函数，则使用包装器的 __call__()方法。如果将包装器应用于类的方法，则调用__get__()方法，该方法返回一个新的绑定包装器，并调用该方法的 __call__() 方法。这样我们的包装器就可以在描述符的传播过程中使用。 因为将装饰器实现为一个描述符对象时，使用闭包总是会失败，因此这种情况下为了让所有的事都能正常工作，我们必需总是使用类实现装饰器。装饰器类将实现描述符协议，如上所式。 现在的问题是，我们如何解决我们列出的其他问题。我们使用functools.wrap() 和 functools.update_wrapper() 解决命名问题，现在我们应该怎么做以便继续使用他们。因为 functools.wrap() 内部使用 update_wrapper(),所以我们只需要看看它如何实现。 12345678910111213141516171819WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__qualname__', '__doc__', '__annotations__')WRAPPER_UPDATES = ('__dict__',)def update_wrapper(wrapper, wrapped, assigned = WRAPPER_ASSIGNMENTS, updated = WRAPPER_UPDATES): wrapper.__wrapped__ = wrapped for attr in assigned: try: value = getattr(wrapped, attr) except AttributeError: pass else: setattr(wrapper, attr, value) for attr in updated: getattr(wrapper, attr).update( getattr(wrapped, attr, &#123;&#125;)) 如上展示的是Python3.3中的代码，事实上它还存在一个bug，在Python3.4中已经修复。 在函数体中，3件事需要被做。 第一件是将被包装函数保存为包装函数的__wrapped__属性。这就是那个bug，因为它应该在最后实现 第二步，复制诸如 __name__ 和 __doc__ 属性； 最后一步，复制被包装函数dict属性值到包装函数，结果是很多对象需要被复制 如果我们使用的是一个函数闭包或直接的类包装器，那么这个复制就可以在decorator应用的时候完成。当装饰器被实现为描述符时，也需要在 bound wrapper 中完成上述工作。 123456789class bound_function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped)class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) 因为bound wrapper 在包装器每次被作为类的绑定方法调用时都会被创建，所有将非常慢。我们需要更高效的方式处理它。 2. 代理对象性能问题的解决方法是，使用代理对象。这是一个特殊的包装类，因为它的行为跟它包装的东西看起来很像。 123456789101112131415class object_proxy(object): def __init__(self, wrapped): self.wrapped = wrapped try: self.__name__= wrapped.__name__ except AttributeError: pass @property def __class__(self): return self.wrapped.__class__ def __getattr__(self, name): return getattr(self.wrapped, name) 一个完全透明的对象代理本身就是一个复杂的怪物，所以我打算暂时把细节掩盖起来，并在一个单独的博客文章中讨论它。上面的例子是它所做事情的最小表示。实际上，它实际上需要做更多的工作。简而言之，它将有限的属性从包装的对象复制到自身，并使用特殊的方法、属性和 __getattr__() 来从包装对象中获取属性，从而避免需要复制许多可能永远不会被访问的属性。 我们现在要做的是从对象代理中派生出包装器类，并取消调用update_wrapper()。 12345678910111213141516171819class bound_function_wrapper(object_proxy): def __init__(self, wrapped): super(bound_function_wrapper, self).__init__(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) class function_wrapper(object_proxy): def __init__(self, wrapped): super(function_wrapper, self).__init__(wrapped) def __get__(self, instance, owner): wrapped = self.wrapped.__get__(instance, owner) return bound_function_wrapper(wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 现在从包装器中查询像 __name__ 和 __doc__ 这样的属性时，将从被包装函数直接返回。使用透明的对象代理也意味着像 inspect.getargspec() 和 inspection.getsource() 这样的调用也将按照预期正常工作。 3. 代码复用尽管这种模式解决了最初确定的问题，但它包含了大量的重复样板代码。此外，在现在的代码中有两个位置，调用被包装函数。因而需要在两个地方重复实现包装逻辑。因此，每次需要实现一个装饰器时都要复制这一点，因此会有点痛苦。 我们可以做的是将整个过程打包到一个装饰器工厂函数中，从而避免每次都需要手工完成这一切。如何做到这一点将成为本系列下一篇博客文章的主题。从这一点开始，我们可以开始研究如何进一步改进功能，并引入新的功能，这些都是使用常规的装饰器实现方法难以实现的。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[01 如何实现一个 Python 装饰器]]></title>
    <url>%2F2018%2F05%2F04%2Fwrapt%2Fpython_decorator_01%2F</url>
    <content type="text"><![CDATA[稍微对 Python 有所了解的程序员一定知道 Python 装饰器和函数闭包。我曾经也以为很了解，直到在《流畅的Python》中看到了 Wrapt 模块。 Wrapt 模块的作者 Graham Dumpleton 先生写了 14 篇博客详细讲解了如何在 Python 中实现一个能同时包装函数，类方法，实例方法的通用装饰器。本文以及接下来几篇文章是我对那 14 篇博客的整理和笔记。 Graham Dumpleton 先生的博文 和 Wrapt 模块请参阅: GrahamDumpleton wrapt blog wrapt 1.10.11 documentation 1. 通过函数闭包实现装饰器装饰器的典型目的是为被包装函数附加的额外的处理逻辑。我遇到的使用装饰器的最典型场景是，大多数数据库对一次查询可设置的查询的条件有数量限制，大量查询时需要将多个查询条件分组进行多次查询在合并查询结果。比如我有100000 用户需要根据ID 查询其性别，查询条件太多，只能分批多次查询，然后将查询结果合并。这种分批查询不仅对 mysql，对其他任何数据库都适用，所以非常适用用装饰器将分批查询再合并的功能抽象出来。 1.1 实现原理大多数人(我)都是通过闭包来创建一个装饰器，就像下面这样。1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper# @ 符应用一个装饰器在Python2.4 中被加入。它仅仅是如下方式的语法糖@function_wrapperdef function(): passfunction = function_wrapper(function) 整个包装的执行过程如下: 包装函数(function_wrapper)接收被包装函数(wrapped)作为参数，并将内部的另一个内部函数(_wrapper) 作为返回值 通过@装饰器或函数的调用赋值，使用 _wrapper 替换 wrapped，这样对 wrapped 的调用实际是调用的 _wrapped _wrapped 通过函数闭包保留了对 wrapped 函数的引用，这样它就可以在内部调用 wrapped 函数并返回调用结果。 _wrapped 在调用 wrapped 之前或之后可以添加其他处理逻辑，以达到为 wrapped 附加功能的目的。 虽然通常都是适用函数闭包实现装饰器，但是能展示它工作原理的更好的示例是使用一个类实现它: function_wrapper 类通过属性保留对被包装函数的引用 当被包装函数被调用时，包装类的 __call__ 方法被调用，并进而调用原始的被包装函数 __call__ 包含了附加的通用处理逻辑。 12345678class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass 1.2 局限尽管通过闭包实现装饰器很简单，但是这种方式存在很多局限，其中最重要的是打断了 Python 内部的自省，也没有遵循 Python 对象模型的执行方式。 猴子补丁与装饰器十分相似的一个技术是 monkey patching(猴子打补丁)，猴子打补丁会进入并修改其他人的代码。二者不同的是装饰器作用的时间是函数定义完成之后，而猴子补订在函数导入模块时被应用。为了能同时使用函数包装器和猴子补丁，函数包装器必需是透明的，并且内部维护了一个堆，以便多个装饰器，猴子补订能按照预期的顺序执行。 2. 自省丢失当我们讨论函数闭包时，我们会预期函数的自省属性和函数的外在表现相一致。这些包括__name__，__doc__ 属性。但是当使用函数闭包时，原函数的自省属性会被内嵌函数所替代，因为函数闭包返回的是内嵌函数。 1234567891011def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)_wrapper 当使用类实现闭包时，类实例没有 __name__ 属性，访问此属性时，会导致 AttributeError 异常 1234567891011121314class function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs)@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;AttributeError: 'function_wrapper' object has no attribute '__name__' 此处的解决方式是，在函数闭包内，将被包装函数的内省属性复制到内嵌函数上。这样函数名称和文档字符串属性就能表现正常 12345678910111213def function_wrapper(wrapped): def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) _wrapper.__name__ = wrapped.__name__ _wrapper.__doc__ = wrapped.__doc__ return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 手动复制属性是费劲的，如果未来扩展了其他自省属性，代码需要被更新。例如需要复制 __module__ 属性，在Python3 中需要复制 __qualname__ 和 __annotations__ 属性。为了避免这么做，Python 标准库为我们提供了 functools.wraps() 装饰器，完成自省属性的复制 1234567891011121314import functoolsdef function_wrapper(wrapped): @functools.wraps(wrapped) def _wrapper(*args, **kwargs): return wrapped(*args, **kwargs) return _wrapper@function_wrapperdef function(): pass&gt;&gt;&gt; print(function.__name__)function 使用类实现装饰器时，我们需要使用 functools.update_wrapper() 函数 12345678import functoolsclass function_wrapper(object): def __init__(self, wrapped): self.wrapped = wrapped functools.update_wrapper(self, wrapped) def __call__(self, *args, **kwargs): return self.wrapped(*args, **kwargs) 或许你已经认为通过 functolls.wraps 函数我们能确保函数的自省属性是正确的，但事实上它并不能一直有效。假如我们去访问函数的参数信息，返回的将是包装函数的参数信息而不是被包装函数的。即，在使用闭包的方式中，内嵌函数的参数信息被返回。因此包装器没能保留函数签名信息 123456789import inspectdef function_wrapper(wrapped): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))ArgSpec(args=[], varargs='args', keywords='kwargs', defaults=None) 类包装器更加严重，因为会触发异常，并解释称被包装函数不是一个函数。我们完全不能获取函数签名信息，即使被包装函数是可调用的 123456789101112class function_wrapper(object): ...@function_wrapperdef function(arg1, arg2): pass&gt;&gt;&gt; print(inspect.getargspec(function))Traceback (most recent call last): File "...", line XXX, in &lt;module&gt; print(inspect.getargspec(function)) File ".../inspect.py", line 813, in getargspec raise TypeError('&#123;!r&#125; is not a Python function'.format(func))TypeError: &lt;__main__.function_wrapper object at 0x107e0ac90&gt; is not a Python function 另外一个自省的示例是使用 inspect.getsource() 获取函数源代码。闭包装饰器返回的是内嵌函数的源代码，而类装饰器则会触发异常 3.描述符协议同函数类似，装饰器也可以应用于类方法。Python 包含了两个特殊的装饰器@classmethod 和 @staticmethod 将实例方法转换为特殊的类方法。装饰器应用于类方法同样隐含着几个问题 12345678910111213class Class(object): @function_wrapper def method(self): pass @classmethod def cmethod(cls): pass @staticmethod def smethod(): pass 第一即使使用了 functools.wraps 或者 functools.update_wrapper，当装饰器被用在 @classmethod，@staticmethod 上时，仍然会导致异常。这是因为这两个特殊的装饰器没能将一些必要的属性复制过来。这是一个Python2 的bug，并在Python3中通过忽略丢失的属性修复了 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): passTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 3, in Class File "&lt;stdin&gt;", line 2, in wrapper File ".../functools.py", line 33, in update_wrapper setattr(wrapper, attr, getattr(wrapped, attr))AttributeError: 'classmethod' object has no attribute '__module__' 即使我们运行在 Python3 上，我们依然会遇到问题。这是因为所有类型的装饰器都假设被包装函数是直接可调用的。事实上并非如此。Python classmethod 装饰器返回一个描述符，这个描述符不是直接可调用的，但是装饰器假设被包装函数直接可调用，因此会出错。 12345678910111213class Class(object): @function_wrapper @classmethod def cmethod(cls): pass&gt;&gt;&gt; Class.cmethod()Traceback (most recent call last): File "classmethod.py", line 15, in &lt;module&gt; Class.cmethod() File "classmethod.py", line 6, in _wrapper return wrapped(*args, **kwargs)TypeError: 'classmethod' object is not callable 4. 总结函数闭包实现的装饰器存在以下问题: 无法保留函数的自省属性 无法获取函数签名信息 无法获取函数源代码 无法将装饰器应用于另一个为实现描述符的装饰器之上.简单的装饰器实现不会遵守被包装对象的描述符协议，因而破坏了Python对象的执行模型 使用 functools.wraps() 和 functools.update_wrapper() 能保留常规的自省属性，但依旧无法保留函数签名信息和源代码，而且由于 Python2 的bug，无法将装饰器直接应用于类方法和静态方法(导入时即报错) 确实存在第三方包，尝试解决这些问题，例如PyPi上的decorator模块。这个模块虽然对前两类问题有所帮助，但仍然存在一些潜在的问题，当尝试通过猴子补丁动态应用函数包装时，可能会导致问题 这并不意味着这些问题是不可解决的，而且可以以一种不牺牲性能的方式解决。现在已经说明了要解决的问题，在随后的文章将会解释如何解决这些问题，以及提供哪些额外的功能。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>wrapt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.3 sudo]]></title>
    <url>%2F2018%2F04%2F07%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2Fsudo%2F</url>
    <content type="text"><![CDATA[sudo sudo是linux系统管理指令，它允许用户临时以其他用户(通常是root)执行一些或全部指令，其实现的是一种授权机制。普通用户想执行root 用户的特权命令时，可以使用 su 切换到管理员，但是这样做有两个坏处，一是 root 用户会被普通用户知道，二是普通用户切换为 root 后获取的是 root 的所有权限，这些都存在安全风险。而 sudo 可以实现授权普通用户执行部分或全部命令，同时无需 root 密码。本节我们就来介绍 sudo 的使用，内容如下: su 用户切换 sudo 配置 sudo 命令使用 1. su 用户切换su [OPTION]... [-] [USER [ARG]...] 作用: 用户切换 参数: USER，可省，默认为 root 选项: -l: 交互式登录shell进程，su -l user == su - user -c &#39;COMMAND&#39;: 不切换用户只执行命令后，并退出 有关交互式登陆，可以回看 6.10 bash配置文件 2. sudo 配置sudo 能够让获得授权的用户以另外一个用户的身份运行指定的命令。授权文件为 /etc/sudoers，此文件有特定的语法格式，因此有个专用的编辑命令 visudo,其在退出时，可以帮助我们检查语法错误。sudoers 配置如下 2.1 授权机制123456789$ sudo visudoroot ALL=(ALL) ALLtao ALL=(ALL) ALL%wheel ALL=(ALL) ALL# 总结:那个用户 从什么地方 以谁的身份 执行什么命令who where=(whom) commandsusers hosts=(runas) commands 授权选项格式 users: 授权用户 username: 用户名 #uid: 用户ID(UID) %groupname: 用户组名称 %#gid: 用户组ID(GID) user_alias: 用户别名 hosts: 用户登陆限制，只有在限制范围内登陆的用户才能使用授权的命令 ip: ip 地址 hostname: 域名 NetAddr: 子网 host_alias: 网络别名 runas: 以哪些用户的身份执行命令 commands: 授权的命令，必需是全路经 command: 命令 directory: 目录 sudoedit：特殊权限，可用于向其它用户授予sudo权限 cmnd_alias: 命令别名 wheel 组wheel 组是 Linux 中的特殊组即管理员组，属于 wheel 组的成员均具有所有管理员权限 123456789# root 身份执行$ usermod pythoner -a -G wheel$ su - pythoner # 必需要以交互式登陆的方式切换到 pythoner 才能生效$ id pythoneruid=1001(pythoner) gid=1001(pythoner) 组=1001(pythoner),10(wheel)$ sudo cat /etc/shadow 2.2 定义别名的方法suders 支持设置别名，用于简化配置工作。别名类似于变量，可复用，可避免重复输入。别名设置的语法格式为: ALIAS_TYPE NAME=item1, item2, item3, ... NAME：别名名称，必须使用全大写字符； ALIAS_TYPE: 别名类型，分别与上面一一对应 User_Alias Host_Alias Runas_Alias Cmnd_Alias: 包含的命令必需全路经 123456# 别名设置User_Alias NETADMIN=tom, jerryCmnd_Alias NETCMND=/usr/sbin/ip, /usr/sbin/ifconfig# 使用别名进行配置NETADMIN localhost=(root) NETCMND 2.3 sudo命令s使用sudo [options] COMMAND options -l: 列出用户能执行的命令 -k: 清除此前缓存用户成功认证结果； -u: 以哪个用户执行 默认 sudo 有检票机制，即能记录成功认证结果一段时间，默认为5分钟。-k 选项则可以手动取消，下此使用 sudo 时必需输入密码。同时需要提醒大家注意的是，执行 sudo 时输入的是用户自己的密码，不是 root 密码。 2.4 sudoers 配置示例Cmnd_Alias USERADMINCMNDS = /usr/sbin/useradd, /usr/sbin/usermod, /usr/bin/passwd [a-z]*, !/usr/bin/passwd root User_Alias USERADMIN = bob, alice USERADMIN ALL=(root) NOPASSWD:USERADMINCMNDS sudoers 中常用的标签 NOPASSWD: 标识使用命令时，无需输入密码 PASSWD: 默认，使用命令时，需要输入密码 !COMMAND: ! 表示不允许执行 COMMAND 命令]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.2 日志管理系统rsyslog]]></title>
    <url>%2F2018%2F04%2F06%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2F%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9Frsyslog%2F</url>
    <content type="text"><![CDATA[日志管理系统rsyslog rsyslog 是Linux 系统上日志管理系统，应用程序可直接调用 rsyslog 的接口将日志写入到 rsyslog 特定的 facility 中即可完成日志记录。如果应用程序通过 rsyslog 来记录日志，通常在其自己的配置文件中有专门的选项用来定义将日志存入到 rsyslog 哪个 facility。facility 可以理解为 rsyslog 日志收集器的基本单元，rsyslog 内部的配置文件定义了每个 facility 的日志存储于何处。应用程序只需要将日志信息教给 rsyslog，rsyslog 会自动根据日志所属的 facility 将日志存储到对应的位置。本节我们就来详细介绍 rsyslog 的配置使用 1. rsyslog 简介1.1 syslogsyslog 是 rsyslog 的上一版，syslog 服务分成了两个部分: syslogd： system，为 Linux 上的应用程序提供日志记录服务 klogd：kernel，为开机启动，系统内核提供日志记录服务 除了本地服务，syslog 还支持C/S架构，即可通过UDP或TCP协议为网络上的其他主机提供日志记录服务。这种模式下 12345678# C/S rsyslog --------kernel --------&gt; |本机 | | | tcp/utpssh --------&gt; |rsyslog| ------------&gt; rsyslog server | |... ---------&gt; |服务 | --------- 作为 server 的 syslog 服务监听在 tcp/utp 的 514 端口上 作为客户端的应用程序，首先将日志发送到本地的 syslog 服务上，再由 本地的 syslog 服务作为客户端将应用程序的日志发送到 server 端的 syslog 上加以记录，因此 syslog 的客户端与服务器都是 syslog rsyslog server 收到客户端发来的日志后，根据自己 facility 的配置将日志记录到特定位置。 因此应用程序只是将日志写入到特定的 facility，syslog server 只是本地 syslog 记录日志的一种方式。syslog 可定义 facility 的日志存储方式，可以是本地文件，也可以是远程的 syslog server syslog 日志格式无法自定义，统一为事件产生的日期时间 主机 进程[pid] ：事件内容，因此只能记录一些简单的日志。 1.2 rsyslogrsyslog 是 syslog 的升级版本，支持所有 syslog 特定，它只有 rsyslogd 一个服务来完成所有日志的记录功能。相比于 syslog，rsyslog 具有如下新特性: 支持多线程； 支持多种C/S连接协议，UDP，TCP，SSL，TLS，RELP； 可存储日志信息于MySQL、PGSQL、Oracle等数据管理系统； 强大的过滤器，实现过滤日志信息中任何部分的内容； 自定义输出格式 2. rsyslog 组成2.1 日志收集器单元rsyslog日志收集器有两个重要的概念: facility： 作用: 设施，从功能或程序上对日志收集进行分类 内置: rsyslog 上默认的 facility 有 auth, authpriv, cron, daemon, kern, lpr, mail, mark, news, security, user, uucp, local0-local7, syslog priority： 作用: 日志级别，用于定义日志的重要性，facility 可定义记录日志的级别范围 级别: 日志级别从低到高有 debug, info, notice, warn(warning), err(error), crit(critical), alert, emerg(panic) 2.2 程序组成12345678910111213141516$ rpm -ql rsyslog/etc/logrotate.d/syslog/etc/pki/rsyslog/etc/rsyslog.conf # 配置文件/etc/rsyslog.d/etc/sysconfig/rsyslog # rsyslog 服务的配置文件/usr/bin/rsyslog-recover-qi.pl/usr/lib/systemd/system/rsyslog.service # 服务脚本/usr/lib64/rsyslog # 模块目录/usr/lib64/rsyslog/im*.so # im 开头的为输入相关模块/usr/lib64/rsyslog/om*.so # om 开头的为输出相关模块/usr/lib64/rsyslog/lm*.so/usr/lib64/rsyslog/mm*.so/usr/lib64/rsyslog/pm*.so 3. rsyslog 配置3.1 配置文件结构12345678910111213141516171819202122$ cat /etc/rsyslog.conf |grep -v &quot;^# &quot;#### MODULES #### # 模块加载$ModLoad imuxsock # provides support for local system logging (e.g. via logger command)$ModLoad imjournal # provides access to the systemd journal#$ModLoad imklog # reads kernel messages (the same are read from journald)#$ModLoad immark # provides --MARK-- message capability$ModLoad imudp # utp 服务$UDPServerRun 514$ModLoad imtcp # tcp 服务$InputTCPServerRun 514#### GLOBAL DIRECTIVES #### # 全局目录配置$WorkDirectory /var/lib/rsyslog$IncludeConfig /etc/rsyslog.d/*.conf#### RULES #### # facility 日志记录配置*.info;mail.none;authpriv.none;cron.none /var/log/messagesmail.* -/var/log/maillog*.emerg :omusrmsg:* 配置文件由三个部分组成 MODULES: 模块加载 GLOBAL DIRECTIVES: 全局变量 RULES: 用于定义 facility 记录日志的级别和位置，格式为 facilty.priority target 1.2 RULES 格式RULES 用于定义 facility 记录日志的级别和位置，其语法为 facilty.priority target priority: 日志级别，有如下几种表示方式 *：所有级别； none：没有级别； priority：此级别以高于此级别的所有级别； =priorty：仅此级别 target: 日志输出的位置，有如下几种格式 /var/log/messages: 记录到特定文件中，默认为同步写入，大量日志记录会拖慢系统性能 -/var/log/maillog: 记录到文件，- 表示异步写入，不重要的日志可异步写入，减少系统 IO :omusrmsg:tao: 调用 omusrmsg 将日志发送到用户登陆的终端，* 表示所有登陆用户； @192.168.1.101: 将日志发送到 rsyslog server | COMMAND: 将日志送入管道 说明: target 中可使用 :module:param 调用 rsyslog 内置的模块，每个模块有自己特定的参数 1.3 默认 facilty12345678910*.info;mail.none;authpriv.none;cron.none /var/log/messagesauthpriv.* /var/log/securemail.* -/var/log/maillogcron.* /var/log/cron*.emerg :omusrmsg:*uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.loglocal2.* /var/log/haproxy.log 1.4 其他日志文件除了 rsyslog 记录的日志外，系统上还有其他一些重要的日志文件 /var/log/wtmp： 作用: 当前系统成功登录系统的日志 查看: last 命令 /var/log/btmp： 作用: 当前系统尝试登录系统失败相关的日志 查看: lastb命令 附注: lastlog命令，能显示当前系统上的所有用户最近一次登录系统的时间； /var/log/dmesg： 作用: 系统引导过程中的日志信息 查看: 也可以使用dmesg命令进行查看 4. rsyslog 高级配置4.1 rsyslog server 配置配置 C/S 架构的 rsyslog 步骤如下所示 1234567891011# 1. 服务器端: 启动 rsyslog server 监听 tcp/udp 的模块# Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514# Provides TCP syslog reception$ModLoad imtcp$InputTCPServerRun 514# 2. 客户端: 配置 facility 将日志发往服务端*.info;mail.none;authpriv.none;cron.none @192.168.1.149 4.2 记录日志于mysql中记录日志于mysql中首先要安装配置 rsyslog mysql 的模块，配置步骤如下:12345678910111213141516171819202122232425262728293031# 1. rsyslog mysql 模块安装$ yum search rsyslog$ sudo yum install rsyslog-mysql.x86_64# 2. mysql 配置$ rpm -ql rsyslog-mysql.x86_64/usr/lib64/rsyslog/ommysql.so/usr/share/doc/rsyslog-8.24.0/mysql-createDB.sql# 通过导入createDB.sql脚本创建依赖到的数据库及表$ mysql -uUSER -hHOST -pPASSWORD &lt; /usr/share/doc/rsyslog-mysql-VERSION/createDB.sql# 登陆 mysql 配置 rsyslog 使用的特定帐户$ mysql -uUSER -hHOST -pPASSWORDMariaDB [(none)]&gt; grant all on Syslog.* to &quot;rsyslog&quot;@&quot;%&quot; identified by &quot;rsyspass&quot;;MariaDB [(none)]&gt; flush privileges;mysql -ursyslog -prsyspass&gt;# 3. 配置rsyslog使用ommysql模块$ sudo vim /etc/rsyslog.conf### MODULES ####$ModLoad ommysql#### RULES ##### facility.priority :ommysql:DBHOST,DB,DBUSER,DBUSERPASSfacility.priority :ommysql:127.0.0.1,Syslog,rsyslog,rsyspass# 重启rsyslog服务$ sudo systemctl restart rsyslog]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[22.1 Linux时间服务-chrony]]></title>
    <url>%2F2018%2F04%2F05%2Flinux_mt%2F25-Linux%E6%97%A5%E5%BF%97-%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1-sudo%2FLinux%E6%97%B6%E9%97%B4%E6%9C%8D%E5%8A%A1-chrony%2F</url>
    <content type="text"><![CDATA[Linux时间服务-chrony Linux 中有一些通用原则，比如如果上下层衔接不通畅，通常的解决方法就是添加一个中间层，虚拟文件系统就是最典型的一例，再比如如果一个功能被很多应用所需要，通常会做成一个公共服务以便，认证功能 pam 还有本节将要介绍的 日志服务 rsyslog 就是典型的示例。本章我们会讲一些类似这些的 Linux 中基础的但是并不复杂的基础服务，包括: 时间同步服务 chrony 日志管理服务 rsyslog sudo 权限管理 Linux 中很多服务在跨主机通信需要保持时间同步，特别是对于一个集群而言，多台主机之间的时间必需严格一致。Linux 在启动时会从硬件中读取时间，在操作系统启动之后，系统时钟就会同硬件时钟相独立。系统始终依赖 CPU 的工作频率更新时间，因此不同主机之间的时间很难保持一致。特别是在虚拟化环境中，每个虚拟机只能获取一部份的 CPU 周期，时间基本不可能保持一致，此时就需要进行时间同步。本节我们就来 Linux 中的时间服务，内容包括: Linux 中时间同步的协议和方式 ntp 和 chrony 1. Linux 中的时间同步1.1 Linux 时间同步的方式ntp(Network Time Protocol) 是 Linux 同步时间的协议。当时间出现偏差时，Linux 不能将当前时间直接调整为准确时间，这是因为 Linux 上很多服务依赖于时间的连续性，时间不能跳越。Linux 只能通过让时间走”更快”或”更慢”来同步时间。 ntp 协议的最早实现是 ntp 服务，但是 ntp 存在一个缺陷，时间同步太慢，在时间相差较大时需要很长时间才能完成时间同步。chrony 服务是 ntp 的改进版本，它采用了一种很精巧的策略，在保证时间连续的同时能在几秒甚至更短的时间内完成时间同步。 1.2 Linux 时间同步服务ntp，chrony 既是客户端也是服务端，这是因为我们的系统需要实时同步时间，因此 ntp，chrony 要作为后台进程实时进行。ntp 和 chrony 都监听在 utp的 123 端口上，因此 chrony 是兼容 ntp 的，即 ntp 的客户端也能从 chrony 服务同步时间。 1.3 时间同步配置在 Linux 中同步时间只需要，安装 chrony，修改其配置文件，更改其同步时间服务器，如果其同时作为服务器使用，需要修改 allow 参数指定允许按些客户端过来同步；配置完成后启动 chrony 的服务，并将其设置为开机自动启动即可。 也可以使用 ntpdate 命令临时进行手动时间同步。下面我们就来详细介绍 ntp 和 chrony 的配置。Linux 上建议使用 chrony。 1234567891011# 1. 安装 chrony 服务yum install chrony# 2. 修改配置文件，详细配置见下vim /etc/chrony.confallow= # 允许同步的客户端server= # 时间同步服务器# 3. 启动服务systemctl start chronydsystemctl enable chronyd 2. ntp12345678910111213141516# rpm -ql ntp/etc/dhcp/dhclient.d/etc/dhcp/dhclient.d/ntp.sh/etc/ntp.conf # 配置文件/etc/ntp/crypto/etc/ntp/crypto/pw/etc/sysconfig/ntpd/usr/bin/ntpstat/usr/lib/systemd/ntp-units.d/60-ntpd.list/usr/lib/systemd/system/ntpd.service/usr/sbin/ntp-keygen/usr/sbin/ntpd/usr/sbin/ntpdc/usr/sbin/ntpq/usr/sbin/ntptime/usr/sbin/tickadj 2.1 配置文件123456789101112# cat /etc/ntp.conf |grep -v &quot;^#&quot;driftfile /var/lib/ntp/driftrestrict default nomodify notrap nopeer noqueryrestrict 127.0.0.1 # 允许哪些主机过来同步时间restrict ::1server 0.centos.pool.ntp.org iburst # 时间服务器地址server 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburstincludefile /etc/ntp/crypto/pwkeys /etc/ntp/keysdisable monitor 2.2 时间同步命令ntpdate server_ip 作用: 手动向 server_ip 指向的服务同步时间 3. chrony123456789101112131415# rpm -ql chrony/etc/NetworkManager/dispatcher.d/20-chrony/etc/chrony.conf # chrony 配置文件/etc/chrony.keys/etc/dhcp/dhclient.d/chrony.sh/etc/logrotate.d/chrony/etc/sysconfig/chronyd /usr/bin/chronyc # chrony 服务管理工具/usr/lib/systemd/ntp-units.d/50-chronyd.list/usr/lib/systemd/system/chrony-dnssrv@.service/usr/lib/systemd/system/chrony-dnssrv@.timer/usr/lib/systemd/system/chrony-wait.service/usr/lib/systemd/system/chronyd.service/usr/libexec/chrony-helper/usr/sbin/chronyd # 客户端亦是服务端程序 3.1 组成chrony 由如下几个部分组成: 配置文件：/etc/chrony.conf 主程序文件：chronyd 工具程序：chronyc unit file: chronyd.service 3.2 配置123456789101112131415161718192021222324252627282930313233343536373839$ cat /etc/chrony.conf# Use public servers from the pool.ntp.org project.# Please consider joining the pool (http://www.pool.ntp.org/join.html).server 0.centos.pool.ntp.org iburstserver 1.centos.pool.ntp.org iburstserver 2.centos.pool.ntp.org iburstserver 3.centos.pool.ntp.org iburst# Record the rate at which the system clock gains/losses time.driftfile /var/lib/chrony/drift# Allow the system clock to be stepped in the first three updates# if its offset is larger than 1 second.makestep 1.0 3# Enable kernel synchronization of the real-time clock (RTC).rtcsync# Enable hardware timestamping on all interfaces that support it.#hwtimestamp *# Increase the minimum number of selectable sources required to adjust# the system clock.#minsources 2# Allow NTP client access from local network.#allow 192.168.0.0/16# Serve time even if not synchronized to a time source.#local stratum 10# Specify file containing keys for NTP authentication.#keyfile /etc/chrony.keys# Specify directory for log files.logdir /var/log/chrony# Select which information is logged.#log measurements statistics tracking 核心配置选项包括: server:指明时间服务器地址，本机会向 server指向的机器同步时间 allow NETADD/NETMASK: chrony 作为服务端使用时，允许哪些网络的主机同步时间 allow all:允许所有客户端主机 deny NETADDR/NETMASK: 不允许哪些网络的主机同步时间 deny all:拒绝所有客户端 bindcmdaddress:命令管理接口监听的地址, chronc 命令连接此地址对 chrony进行远程管理，因此不要监听在公网地址上 local stratum 10:即使自己未能通过网络时间服务器同步到时间，也允许将本地时间作为标准时间授时给其它客户端 3.3 chroncchronc 是 chrony 服务的管理工具，它能远程连接 chrony 服务，chrony 会监听在 bindcmdaddress 参数配置的地址，等待 chronc 连接。chronc 是一个交互的客户端工具，最常使用的子命令为 sources，sourcestats，sourcestats -v，help。 12345678910111213# chronycchronyc&gt; sources210 Number of sources = 4MS Name/IP address Stratum Poll Reach LastRx Last sample ===============================================================================^? ns3106355.ip-37-187-100.&gt; 2 7 5 14 +20ms[ +22ms] +/- 236ms^? . 0 8 0 - +0ns[ +0ns] +/- 0ns^? cn.ntp.faelix.net 0 8 0 - +0ns[ +0ns] +/- 0ns^* ntp2.flashdance.cx 2 6 45 15 +3857us[+6412us] +/- 246mschronyc&gt; sourcestatschronyc&gt; sourcestats -vchronyc&gt; help]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.7 网络接口类型]]></title>
    <url>%2F2018%2F04%2F04%2Flinux_mt%2F24-iptables%2F%E8%99%9A%E6%8B%9F%E7%BD%91%E5%8D%A1%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[网络接口类型 网络虚拟化我们会在之后的高级篇详细讲解，但是为了方便大家理解，我们在此章节简单描述以下不同虚拟网卡的类型的作用范围。虚拟网卡分为四种主要类型: bridge:桥接，将当前主机的物理网卡与VMware 内部的虚拟交换机进行关联 nat: 在当前物理主机的物理网卡上启动 nat 转发功能，转发内部虚拟主机的网络请求，以连接外部物理主机 host-only: 功能: 虚拟主机能与其他虚拟主机以及当前物理主机进行通信，不能与外部物理主机通信 特征: 与 nat 相比，仅仅是取消了当前物理网卡的 nat 功能 私有网桥(VMnet2) 功能: 仅虚拟主机之间可以通信，不能与当前物理主机通信 1. bridge (图片来自于马哥Linux) 桥接的原理是当前主机的物理网卡与VMware 内部的虚拟交换机进行关联，原本的物理网卡被当作交换机使用，vmware 会再虚拟出一块网卡 VMNate8作为当前物理主机的网卡。所有的虚拟机和当前物理主机(VMNate0网卡)都会连接到虚拟交换机上，这样所有的虚拟主机就可以共享物理主机的网络。 2. nat nat 的原理是 vmware 在当前的物理主机上虚拟出一块网卡 VMNate8，并在其上启动 nat和 DHCP 功能，使用 nat 网络的虚拟主机会处于VMNate8 网卡所在的网络，因此会自动分配 IP 并将网关指向 VMNate8；然后由 VMNate8 做 SNAT 转发内网的主机请求以连接外部物理主机。 3. host-onlyhost-only 与 nat 功能类似，只不过 vmware 虚拟出的网卡不会启动 nat 功能，虚拟机无法与外部物理主机通信，只能当前的物理机通信 4. 私有网络私有网络更简单，vmware 会虚拟出一块网卡，而且此虚拟网卡不会添加在当前的物理主机之上。只有连接到相同私有网络的虚拟机之间才能通信，也无法与当前主机进行通信。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.6 TCP 协议简述]]></title>
    <url>%2F2018%2F04%2F03%2Flinux_mt%2F24-iptables%2Ftcp_protocol%2F</url>
    <content type="text"><![CDATA[TCP 协议简述 tcp 连接是由两个有来有往的半个连接组成的 1. 连接建立与拆除1.1 三此握手 1.2 四次挥手 1.3 连接重置tcp 连接过程中可能因为网络抖动导致双方无法通信，但是连接未拆除，过了一段时间后网络又恢复正常，双方的连接状态依旧存在，此时需要发送 RST 标识位的报文实现 tcp 连接重置。 1.4 连接过程]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.5 nat路由]]></title>
    <url>%2F2018%2F04%2F02%2Flinux_mt%2F24-iptables%2Fnat%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[nat路由 nat (network address translation) 是 iptables 另一功能，起初设计的目的是为了隐藏内网中的主机，后来为解决 ipv4 地址的紧缺问题提供了重要帮助。本节我们就来学习如何使用 nat 来隐藏内网中 主机，内容包括 源地址转换原理 目标地址转换原理 本地端口映射 iptables nat 规则配置 要想使用 nat 首先必需打开 Linux 的核心转发功能。如何修改内核参数详见 14.6 Linux内核功能及模块应用，打开核心转发功能可参考如下 12echo 1 &gt; /proc/sys/net/ipv4/ip_forwardsystcl -w net.ipv4.ip_forward=1 1. 源地址转换 如上图所示: 内部网络的报文经由网关向外部网络转发 网关服务器在 POSTROUTING 上将请求报文源地址转换为网关的外网地址并向外部服务器转发请求 外网服务收到源地址为网关服务器的请求，则向网关服务器返回响应 网关在收到来自服务端的响应时，再将目标地址从本机转换为内网主机，并转发给内网主机。 源地址转换称为 snat，可工作于 POSTROUTING 和 INPUT 链上，绝大多数都是工作于 POSTROUTING 链上。这是因为 POSTROUTING 作用于第二次路由之后，是报文离开主机的最后一个环节，此时 snat 一定是作用在发出的报文，而如果在 INPUT 上，则有可能将由本机发往本机的报文也做了地址转换，这实际上没有必要。 外部服务器，看到的请求始终是网关服务器的外网 IP，因此达到隐藏内网客户端的目的。 2. 目标地址转换 如上图所示: 外网客户端向我们的网关服务器发送请求 网关服务器在 PREROUTING 上将请求报文目标地址转换为内网服务器地址并向其转发请求 内网服务器返回响应，报文经网关服务器向外转发 网关服务将响应报文的源地址从内网服务器转换为本机地址，并向外网客户端转发响应。因为客户端发送的请求的目标地址是网关，所以返回响应的也必需是网关而不能是内网服务器。 目标地址转换称为 dnat，可工作于 PREROUTING 和 OUTPUT 链上，绝大多数都是工作于 PREROUTING 链上。这是因为第一路由决策会决定报文由 INPUT 进入用户空间，还是进入 FORWARD 转发出去，因此应该在第一路由之前就将报文的目标地址为内网服务器地址，否则报文就被送往内核而不是被转发到内网服务器。 外部客户端，发送始终是向网关服务器发送请求，根本不知道网关服务器是否转发的请求报文，因此达到了隐藏内网服务器的目的。 我们可以在内网部署多台 web 服务器，让 iptables 将请求转发到不同的内网服务器上，此时就实现了负载均衡的功能。只不过 iptables 的负载均衡功能已经独立为 lvs，并提供了更加丰富的功能，而不再由 dnat 实现。 3. 本机端口映射还有一种情形，比如本地的 tomcat 监听载 8080 端口上，但是http 默认是 80 端口，为了让客户端可通过 80 端口直接能请求到web 服务而不用修改默认端口，此时我们需要在本机做一个端口映射；将 80 端口的请求转发至 8080 上。本机端口映射是通过 iptables REDIRECT 扩展实现的。 4. iptables nat 实现iptables 实现地址转换，只需要使用 nat 特用的 target(处理动作即可) SNAT: -j SNAT options 作用: 源地址转换 选项: --to-source [ipaddr[-ipaddr]][:port[-port]]: 指定源端口和地址 DNAT: -j DNAT options 作用: 目标地址转换 选项: --to-destination [ipaddr[-ipaddr]][:port[-port]] 指定目标端口和地址 MASQUERADE: -j MASQUERADE 作用: 源地址转换，当主机的 ip 是动态获取时，会自动指定源地址 REDIRECT: -j REDIRECT options 作用: 端口重定向，做端口映射 选项: --to-ports port[-port] 指定源端口 12345678910111213# SNAT示例：&gt; iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j SNAT --to-source 172.16.100.67 # MASQUERADE示例：# 源地址转换：当源地址为动态获取的地址时，MASQUERADE可自行判断要转换为的地址；&gt; iptables -t nat -A POSTROUTING -s 192.168.12.0/24 -j MASQUERADE# DNAT示例&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j DNAT --to-destination 192.168.12.77&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 22012 -j DNAT --to-destination 192.168.12.78:22# REDIRECT&gt; iptables -t nat -A PREROUTING -d 172.16.100.67 -p tcp --dport 80 -j REDIRECT --to-ports 8080 5. dnat 于 filter在 dnat 的网关服务器上对转发报文做过滤时，由于 dnat 已经在 PREROUTING 上将报文的目标地址转和端口转换为了内网服务器地址和端口，因此在设置过滤条件时应该使用内网服务器地址作为过滤条件，而不是网关地址。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.4 网络防火墙配置]]></title>
    <url>%2F2018%2F04%2F01%2Flinux_mt%2F24-iptables%2F%E7%BD%91%E7%BB%9C%E9%98%B2%E7%81%AB%E5%A2%99%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[网络防火墙配置 前面我们讲解了 iptables 命令的使用，其中主要是以配置主机防火墙作为示例，本节将来介绍如何配置一个网络防火墙。iptables 命令的使用没变，只是网络防火墙配置载 forward 链上有一些额外注意的事项。 1. 网络防火墙配置在进行网络防火墙配置之前，我们首先需要规划一下网络拓扑结构，好方便解说 iptables 命令的作用。 如上图所示，左半部分是我们模拟的内网，右半部分是模拟的公网，在使用 virtualbox 或 vimware 模拟上述网络时，有以下几点需要注意: 内网的网卡类型选择仅主机或 nat 网络，外网的网卡选择桥接。有关虚拟网卡的几种类型请参考 24.7 虚拟网卡类型 为使得从外网 192.168.1.10 返回的响应能到达我们的内网，需要将其网关指向 192.168.1.168,或者手动添加路由条目将，发往 172.16.0.0/24 的报文的下一跳设置成 192.168.1.168 需要打开中间的网络防火墙的核心转发功能 为测试防火墙，配置，我们需要在 172.16.0.2 和 192.168.1.10 上均配置好 httpd,vsftpd 等服务 12345# 添加路由route add -net 172.16.0.0/24 gw 192.168.1.168# 打开ia核心转发sysctl -w net.ipv4.ip_forward=1 1.1 放行 httpd防火墙 filter 功能只能添加在 INPUT FORWARD OUTPUT 链上，对于网络防火墙而言，报文只会经过 FORWARD 链，因此网络防火墙只能配置在 FORWARD 链上。一次 http 事务包括请求和响应两个过程，因此我们需要在 FORWARD 上同时添加发送请求和接收响应两个方向的规则。下面是配置示例，我们的目的是，内网的主机能访问所有的外网主机，但外网主机仅能访问内网的 httpd,ftp 服务。 1234567891011modprobe nf_conntrack_ftp# 设置默认策略为拒绝$ iptables -A FORWARD -j DROP# 开放 80 端口$ iptables -I FORWARD -s 172.16.0.0/24 -p tcp --dport 80 -j ACCEPT$ iptables -I FORWARD 2 -d 172.16.0.0/24 -p tcp --sport 80 -j ACCEPT# 开放 ftp$ iptables -R FORWARD 3 -s 172.16.0.0/24 -p tcp -m state --stat RELATED -j ACCEPT$ iptables -R FORWARD 4 -p tcp -d 172.16.0.0/24 -m state --state ESTABLISHED -j ACCEPT 1.2 基于连接追踪机制配置使用连接追踪机制，可以让 iptables 规则更加简单1234567891011# 开放内网到外网的所有请求$ iptables -A FORWARD -j DROP# 1. 开放已经建立的连接$ iptables -R FORWARD 1 -p tcp -m state --state ESTABLISHED -j ACCEPT# 2. 开放由内到外的新连接,此时 ftp 也可访问，因为 RELATED 也是 NEW 连接$ iptables -I FORWARD 2 -p tcp -s 172.16.0.0/24 -m state --state NEW -j ACCEPT# 开放外网到内网特定主机的 80 访问$ iptables -I FORWARD 2 -d 172.16.0.10 -p tcp --dport 80 -m state --state NEW -j ACCEPT 2. 利用 iptables 抵御 DOS 攻击利用iptables的recent模块来抵御DOS攻击: 建立一个列表，保存有所有访问过指定的服务的客户端IP ssh: 远程连接， 1234567891011121314# one&gt; iptables -I INPUT -p tcp --dport 22 -m connlimit --connlimit-above 3 -j DROP# two&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH# three&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j LOG --log-prefix &quot;SSH Attach: &quot;# four&gt; iptables -I INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP# 也可以使用下面的这句记录日志：&gt; iptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --name SSH --second 300 --hitcount 3 -j LOG --log-prefix &quot;SSH Attack&quot; one: two: 利用connlimit模块将单IP的并发设置为3；会误杀使用NAT上网的用户，可以根据实际情况增大该值； 第二句是记录访问tcp 22端口的新连接，记录名称为SSH –set 记录数据包的来源IP，如果IP已经存在将更新已经存在的条目 three 利用recent和state模块限制单IP在300s内只能与本机建立2个新连接。被限制五分钟后即可恢复访问。 four: 第三句是指SSH记录中的IP，300s内发起超过3次连接则拒绝此IP的连接。 –update 是指每次建立连接都更新列表； –seconds必须与–rcheck或者–update同时使用 –hitcount必须与–rcheck或者–update同时使用 附注: iptables的记录：/proc/net/xt_recent/SSH]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.3 iptables扩展匹配]]></title>
    <url>%2F2018%2F03%2F31%2Flinux_mt%2F24-iptables%2Fiptables%E6%89%A9%E5%B1%95%E5%8C%B9%E9%85%8D%2F</url>
    <content type="text"><![CDATA[iptables扩展匹配 上一节我们基本上把 iptables 基本使用方法讲完了，而且我们提到过 iptables 是高度模块化的，为在报文匹配和处理动作提供了很多扩展模块，本节我们就来介绍这些扩展模块的使用。可以使用如下命令查看这些扩展模块的帮助信息 1234567# CentOS 6man iptables# CentOS 7man iptables-extensionsrpm -ql iptables|grep &apos;[[:lower:]]\+\.so$&apos; 1. iptables 可用显示扩展1.1 multiport扩展 作用: 以离散方式定义多端口匹配；最多指定15个端口； 参数: [!] --source-ports,--sports port[,port|,port:port]…：指定多个源端口； [!] --destination-ports,--dports port[,port|,port:port]…：指定多个目标端口； [!] --ports port[,port|,port:port]…：指明多个端口； 12&gt; iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp -m multiport --sports 22,80 -j ACCEPT 1.2 iprange扩展 作用: 指明连续的（但一般不能扩展为整个网络）ip地址范围； 参数: [!] --src-range from[-to]：源IP地址； [!] --dst-range from[-to]：目标IP地址； 12&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 80 -m iprange --src-range 172.16.100.5-172.16.100.10 -j DROP&gt; iptables -I INPUT -d 172.16.100.67 -p tcp -m multiport 22:23,80 -m iprange --src-range 172.16.100.1-172.168.100.120 -j ACCEPT 1.3 string扩展 作用: 对报文中的应用层数据做字符串模式匹配检测； 参数: --algo {bm|kmp}：字符串匹配检测算法； bm：Boyer-Moore kmp：Knuth-Pratt-Morris [!] --string pattern：要检测的字符串模式； [!] --hex-string pattern：要检测的字符串模式，16进制格式； 1&gt; iptables -A OUTPUT -s 172.16.100.67 -d 172.16.0.0/16 -p tcp --sport 80 -m string --algo bm --string &quot;gay&quot; -j REJECT 1.4 time扩展 作用: 根据将报文到达的时间与指定的时间范围进行匹配； 参数: --datestart YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestart hh:mm[:ss] --datestop YYYY[-MM[-DD[Thh[:mm[:ss]]]]] --timestop hh:mm[:ss] [!] --monthdays day[,day...] [!] --weekdays day[,day...] --kerneltz：使用内核上的时区，而非默认的UTC；1&gt; iptables -A INPUT -s 172.16.0.0/16 -d 172.16.100.67 -p tcp --dport 80 -m time --timestart 14:30 --timestop 18:30 --weekdays Sat,Sun --kerneltz -j DROP 1.5 connlimit扩展 作用: 根据每客户端IP(也可以是地址块)做并发连接数数量匹配； 参数: --connlimit-upto n：连接的数量小于等于n时匹配； --connlimit-above n：连接的数量大于n时匹配；1&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m connlimit --connlimit-above 2 -j REJECT 1.6 limit扩展 作用: 基于收发报文的速率做匹配，匹配的发送报文数，而不是报文大小 原理: 令牌桶过滤器，进程在发送报文之前必需获取令牌，一个报文一个，通过限制令牌的发放速率达到限制报文发送速率 参数: --limit rate[/second|/minute|/hour|/day]: 报文发送的速率 --limit-burst number: 进程在空闲时可收集的最大令排数 12&gt; iptables -I INPUT -d 172.16.100.67 -p icmp --icmp-type 8 -m limit --limit 30/minute --limit-burst 5 -j ACCEPT&gt; iptables -I INPUT 2 -p icmp -j REJECT 2. state扩展2.1 连接追踪iptables 的 state 会启动内核的连接追踪机制，即内核在会在内存中记录一段时间内与主机通信过的主机，这样在相应主机再次访问本机时，就能追踪其连接状态。iptables 就能根据”连接追踪机制“去检查连接的状态。连接追踪与通信协议没有任何关系，是内核记录连接状态的一种机制，它有如下几种状态: NEW：新发出请求；连接追踪模板中不存在此连接的相关信息条目，因此，将其识别为第一次发出的请求； ESTABLISHED：NEW状态之后，连接追踪模板中为其建立的条目失效之前期间内所进行的通信状态； RELATED：相关联的连接；如ftp协议中的数据连接与命令连接之间的关系； INVALID：无效的连接； UNTRACKED：未进行追踪的连接 连接追踪有时长限制，如果一条连接在设置的时长范围内没有再次发生连接，此连接记录就会被删除。下此与对应的主机再次建立连接时就会被当作新连接被重新记录。连接追踪机制非常耗费内容，如果连接追踪占据了所有的内存，新的连接就无法建立，因此不要在连接非常繁忙的反代服务器上开启连接追踪机制。如果一定要开启连接追踪机制，一是要准备足够大的内存，二是调大 nf_conntrack_max 的值。 2.2 连接追踪相关配置内核会在如下文件中记录连接追踪相关的信息: /proc/net/nf_conntrack: 作用: 已经追踪到并记录下来的连接 /proc/sys/net/netfilter/nf_conntrack_max 作用: 连接追踪功能所能够容纳的最大连接数量的配置文件 注意: 在一个非常繁忙的服务器上，一是要准备足够大的内存，二是将此配置调大 /proc/sys/net/netfilter/*timeout*: 不同的协议的连接追踪时长 2.3 state 扩展 作用: 对连接追踪的状态做匹配 参数: [!] --state state 配置: 1234&gt; iptables -A INPUT -d 172.16.100.67 -p tcp -m multiport --dports 22,80 -m state --state NEW,ESTABLISHED -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -p tcp -m multiport --sports 22,80 -m state --state ESTABLISHED -j ACCEPT&gt; iptables -I OUTPUT -m state --state ESTABLISHED -j ACCEPT 2.4 state 扩展相关问题iptables的链接跟踪表最大容量为/proc/sys/net/netfilter/nf_conntrack_max配置的值，链接碰到各种状态的超时后就会从表中删除；当内存满载时，后续的连接可能会超时解決方法一般有两个： 加大 nf_conntrack_max 值 降低 nf_conntrack timeout时间12345678910111213# 加大 nf_conntrack_max 值vi /etc/sysctl.confnet.ipv4.nf_conntrack_max = 393216net.ipv4.netfilter.nf_conntrack_max = 393216# 降低 nf_conntrack timeout时间vi /etc/sysctl.confnet.ipv4.netfilter.nf_conntrack_tcp_timeout_established = 300net.ipv4.netfilter.nf_conntrack_tcp_timeout_time_wait = 120net.ipv4.netfilter.nf_conntrack_tcp_timeout_close_wait = 60net.ipv4.netfilter.nf_conntrack_tcp_timeout_fin_wait = 120iptables -t nat -L -n 2.5 如何开放被动模式的ftp服务 装载ftp连接追踪的专用模块： 放行命令连接(假设Server地址为172.16.100.67)： 放行数据连接(假设Server地址为172.16.100.67)：1234567891011121314151617181920# 1. 装载ftp连接追踪的专用模块&gt; modinfo /lib/modules/3.10.0-514.el7.x86_64/kernel/net/netfilter/nf_conntrack_ftp&gt; modproble nf_conntrack_ftp&gt; lsmod# 2. 放行请求报文# 命令连接: NEW, ESTABLISHED# 数据连接: RELATED(仅数据连接的第一次连接建立), ESTABLISHED&gt; iptables -A INPUT -d 172.16.100.67 -p tcp --dport 21 -m state --state **NEW,ESTABLISHED** -j ACCEPT&gt; iptables -A OUTPUT -s 172.16.100.67 -p tcp --sport 21 -m state --state ESTABLISHED -j ACCEPT# 3. 放行响应报文 ESTABLISHED&gt; iptables -A INPUT -d 172.16.100.67 -p tcp -m state --state **RELATED,ESTABLISHED** -j ACCEPT&gt; iptables -I OUTPUT -s 172.16.100.67 -p tcp -m state --state ESTABLISHED -j ACCEPT# 4. 合并 iptables 规则iptables -t filter -A INPUT -m --state ESTABLISHED,RELATED -j ACCEPTiptables -t filter -A INPUT -p tcp -d 192.168.1.108 -m multiport --dports 21,22,80 -m state --state NEW -j ACCEPTiptable -t filter -A OUTPUT -m --state ESTABLISHED -j ACCEPT 3. iptables 规则管理3.1 规则优化我们已经学习了很多 iptables 的扩展模块，有一些通用原则可以帮助我们优化 iptables 的规则 使用自定义链管理特定应用的相关规则，模块化管理 可安全放行所有入站的状态为ESTABLISHED状态的连接； 可安全放行所有出站的状态为ESTABLISHED状态的连接； 谨慎放行入站的新请求 有特殊目的限制访问功能，要于放行规则之前加以拒绝； 载规则的最后自定义默认策略，而不是直接使用 iptables 的默认策略，放置意外将 iptables 规则清空导致 ssh 无法连接至服务器 3.2 自定义链自定义链需要被内置链调用才能生效，且自定义链最后需要定义返回内置链。返回规则使用的处理动作叫做 RETURN，默认自定义链最后会自动 return 到调用链，提前返回需要提前显示 return。下面是自定义链的一个示例 12345678$ iptables -N ping_rule # 创建自定义链# 向自定义链添加规则$ iptables -A ping_rule -d 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT# 被内置链调用$ iptables -A INPUT -d 192.168.1.168 -p icmp -j ping_rule$ iptales -L 3.3 规则的保存及重载使用iptables命令定义的规则，会立刻送往内核，手动删除之前，其生效期限为kernel存活期限。永久保存需要手动保存规则至指定的文件中，需要时可重载保存于文件中的规则。 iptables-saveiptables-save &gt; path: 作用: 输出当前的 iptables 规则至终端，保存至文件需要重定向 iptables-restoreiptables-restore options &lt; path 作用: 重载文件中的 iptables 规则 选项: -n --noflush: 默认会清除已有规则，此选项表示不清除已有规则，只追加 -t --test: 仅分析生成规则集，不提交 1234567891011# 1. 保存规则# CentOS 6：iptables-save &gt; /PATH/TO/SOME_RULES_FILEservice iptables save # 将规则保存至/etc/sysconfig/iptables文件中；# CentOS 7:iptables-save &gt; /PATH/TO/SOME_RULES_FILE# 2. 重载规则: 重新载入预存规则文件中的规则 iptables-restore &lt; /PATH/FROM/SOME_RULES_FILEservice iptables restart # 从 /etc/sysconfig/iptables文件中重载规则，仅限于Centos6 3.4 iptables 规则开机自动载入Centos 6Centos 中 iptables 是独立的服务，其管理配置如下所示123456789101112131415# 开机启动 iptableschkconfig iptables on# iptables 服务启动脚本/etc/rc.d/init.d/iptables# iptables 规则的默认配置文件/etc/sysconfig/iptables# iptables 服务的配置文件/etc/sysconfig/iptables-config IPTABLES_MODULE=&quot; # 此选项配置要装载的模块# 开机自动导入可用脚本保存各iptables命令；让此脚本开机后自动运行；# 或者载自定义脚本中使用 iptables-restore 重载规则文件即可 CentOS 7Centos7 引入了新的iptables前端管理服务工具 firewalld，其包括很多管理工具，比如 firewalld-cmd，firewalld-config。其详细使用方式参见文档: http://www.ibm.com/developerworks/cn/linux/1507_caojh/index.html 所以在 Centos7 中实现规则开机自动载入，可以 编写 Unit 配置文件通过 systemctl 调用 iptables-restore 实现 借助于 firewalld 编写脚本，对于 iptables，最好还是使用此种方式，而且最好不要开机自动载入以免产生问题 5. 练习练习：INPUT和OUTPUT默认策略为DROP；123451、限制本地主机的web服务器在周一不允许访问；新请求的速率不能超过100个每秒；web服务器包含了admin字符串的页面不允许访问；web服务器仅允许响应报文离开本机；2、在工作时间，即周一到周五的8:30-18:00，开放本机的ftp服务给172.16.0.0网络中的主机访问；数据下载请求的次数每分钟不得超过5个；3、开放本机的ssh服务给172.16.x.1-172.16.x.100中的主机，x为你的学号，新请求建立的速率一分钟不得超过2个；仅允许响应报文通过其服务端口离开本机；4、拒绝TCP标志位全部为1及全部为0的报文访问本机；5、允许本机ping别的主机；但不开放别的主机ping本机； 练习：判断下述规则的意义：12345678910111213141516171819202122# iptables -N clean_in# iptables -A clean_in -d 255.255.255.255 -p icmp -j DROP# iptables -A clean_in -d 172.16.255.255 -p icmp -j DROP# iptables -A clean_in -p tcp ! --syn -m state --state NEW -j DROP# iptables -A clean_in -p tcp --tcp-flags ALL ALL -j DROP# iptables -A clean_in -p tcp --tcp-flags ALL NONE -j DROP# iptables -A clean_in -d 172.16.100.7 -j RETURN# iptables -A INPUT -d 172.16.100.7 -j clean_in# iptables -A INPUT -i lo -j ACCEPT# iptables -A OUTPUT -o lo -j ACCEPT# iptables -A INPUT -i eth0 -m multiport -p tcp --dports 53,113,135,137,139,445 -j DROP# iptables -A INPUT -i eth0 -m multiport -p udp --dports 53,113,135,137,139,445 -j DROP# iptables -A INPUT -i eth0 -p udp --dport 1026 -j DROP# iptables -A INPUT -i eth0 -m multiport -p tcp --dports 1433,4899 -j DROP# iptables -A INPUT -p icmp -m limit --limit 10/second -j ACCEPT]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.2 iptables使用入门]]></title>
    <url>%2F2018%2F03%2F30%2Flinux_mt%2F24-iptables%2Fiptables%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[iptables使用入门 iptables 是防火墙规则的管理工具，使用复杂，但是也有规律可循，个人总结起来就是”在哪，对什么报文，作出什么样的处理”。 iptables 有四表五链，首先要确定在iptables 的哪个表，哪个链条添加规则，这取决于要实现的功能和报文的流经途径 规则添加就是要对我们要处理的报文作出处理，因此就要指定报文的匹配条件和处理动作。个人觉得按照这样的逻辑去记忆能比较容易记住 iptables 的使用方式。下面我们就来详细介绍 iptables 的使用 1. iptables 命令简介1.1 规则配置原则iptables 会按照链上的规则每次从上至下依次检查，如果报文匹配并作出处理，那么就不会继续匹配接下来的规则。因此这样的检查次序隐含一定的应用法则： 同类规则（访问同一应用），匹配范围小的放上面； 不同类的规则（访问不同应用），匹配到报文频率较大的放在上面； 将那些可由一条规则描述的多个规则合并起来； 设置默认策略；这些应用原则其实很好懂，将频率高的放在最上面是为了减少匹配的次数，匹配范围小的放上面是为了让范围小的规则优先生效，很容易明白。 1.2 命令组成1234iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 iptables 命令组成如上所示: -t: 指定操作的表，默认为 filter chain: 指定操作的链 [-m matchname [per-match-options]]: 指定匹配条件，根据协议报文特征进行报文筛选，分为 基本匹配条件: iptables 内置，不会使用扩展模块，不需要 -m 选项指定模块 扩展匹配条件: 需要使用 -m 选项指定使用的扩展模块 -j targetname [per-target-options]: 指定处理动作，可分为: 基本处理动作: iptables 内置的处理动作 扩展处理动作: 通过扩展模块扩展的处理动作 自定义处理机制: 通常指的是自定义链 1.3 iptables 的扩展机制iptables 是高度模块化的，可以通过扩展模块更细粒度设置匹配条件和处理动作，这就是上面所说的扩展匹配条件和扩展处理动作。 1234567891011121314151617$ rpm -ql iptables |grep xtables/usr/lib64/xtables/libip6t_MASQUERADE.so # IPv6 的扩展模块/usr/lib64/xtables/libip6t_REDIRECT.so/usr/lib64/xtables/libip6t_REJECT.so/usr/lib64/xtables/libip6t_SNAT.so...../usr/lib64/xtables/libip6t_ah.so/usr/lib64/xtables/libip6t_dst.so/usr/lib64/xtables/libip6t_eui64.so...../usr/lib64/xtables/libipt_MASQUERADE.so # IPv4 扩展模块/usr/lib64/xtables/libipt_MIRROR.so....../usr/lib64/xtables/libxt_CT.so # libxt/usr/lib64/xtables/libxt_DSCP.so/usr/lib64/xtables/libxt_HMARK.so..... iptables 扩展模块的命名机制: 小写子母命名的是匹配条件 大写子母命令的是处理动作 libip6t 开头的对应于 IPv6 协议 libxt 和 libxt 开头的对应于 IPv4 协议 1.4 iptables 自定义链iptables的链分为内置链和自定义链 内置链：对应于netfilter 的勾子函数(hook function) 自定义链接：用于内置链的扩展和补充，可实现更灵活的规则管理机制；但报文不会经过自定义链，只能在内置链上通过规则进行引用后生效 有了这些基本介绍，我们现在开始介绍 iptables 的详细使用。 2. iptables 命令使用1234iptables 1. [-t table] COMMAND chain -- 基本命令 2. [-m matchname [per-match-options]] -- 匹配条件 3. -j targetname [per-target-options] -- 处理动作 2.1 基本命令iptables [-t table] COMMAND chain -t: 指定操作的表，默认为 filter (raw, mangle, nat, filter) chain: 指定操作的链(PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING) COMMAND: 字命令 链管理： -N：new, 自定义一条新的规则链； -X：delete，删除自定义的空的规则链，链非空或被其他链引用无法删除 -Z：zero，将规则计数器置零； -F：flush，清空指定的规则链；省略表示清空指定表上的所有链 -P：Policy，为指定链设置默认策略；对filter表中的链而言，其默认策略有： ACCEPT：接受 DROP：丢弃 REJECT：拒绝 -E：重命名自定义链；引用计数不为0的自定义链不能够被重命名，也不能被删除； 规则管理： -A：append，追加； -I：insert, 插入，要指明位置，省略时表示第一条； -D：delete，删除； 指明规则序号； 指明匹配条件； -R：replace，替换指定链上的指定规则； 查看： -L：list, 列出指定鏈上的所有规则； -n：numberic，以数字格式显示地址和端口号(不对ip地址进行反解)； -v：verbose，详细信息，还有-vv, -vvv选项显示更详细的信息 -x：exactly，显示计数器结果的精确值； --line-numbers：显示规则的序号； 注意: -nvL 可以，-Lnv 不可以，因为 -L 是命令，其他的是 -L 的选项 12345$ sudo iptables -L -nvChain INPUT (policy ACCEPT 1368 packets, 8346K bytes) pkts bytes target prot opt in out source destination 0 0 ACCEPT udp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 udp dpt:53 0 0 ACCEPT tcp -- virbr0 * 0.0.0.0/0 0.0.0.0/0 tcp dpt:53 iptables的每条规则都有两个计数器： pkts: 统计匹配到的报文的个数； bytes: 匹配到的所有报文的大小之和； COMMAND 子命令格式12345678910111213# rule-specification = [matches...] [target] # match = -m matchname [per-match-options] # target = -j targetname [per-target-options]iptables [-t table] &#123;-A|-C|-D&#125; chain rule-specification iptables [-t table] -I chain [rulenum] rule-specification iptables [-t table] -R chain rulenum rule-specification iptables [-t table] -D chain rulenum iptables [-t table] -S [chain [rulenum]] iptables [-t table] &#123;-F|-L|-Z&#125; [chain [rulenum]] [options...] iptables [-t table] -N chain iptables [-t table] -X [chain] iptables [-t table] -P chain target iptables [-t table] -E old-chain-name new-chain-name 2.2 匹配条件：[-m matchname [per-match-options]] 基本匹配条件：无需加载任何模块，由iptables/netfilter自行提供； 扩展匹配条件： 需要加载扩展模块，方可生效； 基本匹配条件 [!] -s, --source address[/mask][,...]： 作用: 检查报文中的源IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -d, --destination address[/mask][,...]： 作用: 检查报文中的目标IP地址是否符合此处指定的地址或范围； 附注: 所有地址可使用 0.0.0.0/0 或不指定次选项即可 [!] -p, --protocol {tcp|udp|icmp}： 作用: 检查报文中的协议，即ip 首部中的 protocols 所标识的协议 protocol: tcp, udp, udplite, icmp, icmpv6,esp, ah, sctp, mh or “all” [!] -i, --in-interface IFACE： 作用: 数据报文流入的接口；只能应用于数据报文流入的环节，只能应用于PREROUTING，INPUT和FORWARD链； [!] -o, --out-interface IFACE： 作用: 数据报文流出的接口；只能应用于数据报文流出的环节，只能应用于FORWARD、OUTPUT和POSTROUTING链 扩展匹配条件扩展匹配条件可分为显示扩展和隐式扩展两种: 显式扩展：必须要手动加载扩展模块， [-m matchname [per-match-options]]； 隐式扩展：不需要手动加载扩展模块；因为它们是对协议的扩展，所以，但凡使用-p指明了协议，就表示已经指明了要扩展的模块； 常见协议的隐式扩展如下所示: tcp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； [!] --tcp-flags list1 list2 作用: 检查list1 所指明的所有标志位，且这其中，list2 所列出的标志位必须为1，余下的必须为0，没在 list1 指明的，不做检查 例如：--tcp-flags SYN,ACK,FIN,RST SYN表示，要检查的标志位为SYN,ACK,FIN,RST四个，其中SYN必须为1，余下的必须为0； [!] --syn：用于匹配第一次握手，相当于--tcp-flags SYN,ACK,FIN,RST SYN； 说明: 有关 tcp 连接的标识位，详见 24.8 tcp 协议简述 udp [!] --source-port, --sport port[-port]：匹配报文的源端口；可以是端口范围； [!] --destination-port,--dport port[-port]：匹配报文的目标端口；可以是端口范围； icmp [!] --icmp-type {type[/code]|typename} echo-request：ping 命令发送的请求的 icmp-type 为 8 echo-reply：ping 命令响应的 icmp-type 为 0 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# 允许 ssh 连接&gt; iptables -t filter -A INPUT -d 192.168.1.105 -p tcp [-m tcp] --dport 22 -j ACCEPT&gt; iptables -t filter -A OUTPUT -s 192.168.1.105 -p tcp [-m tcp] --sport 22 -j ACCEPT# 允许 ping 出，不允许 ping 入&gt; iptables -A OUTPUT -s 192.168.1.105 -p icmp --icmp-type 8 -j ACCEPT&gt; iptables -A INPUT -d 192.168.1.105 -p icmp --icmp-type 0 -j ACCEPT# 通过规则设置默认策略&gt; iptables -P INPUT ACCEPT&gt; iptables -P OUTPUT ACCEPT&gt; iptables -F&gt; iptables -A INPUT -d 192.168.1.168 -p tcp --dport 22 -j ACCEPT&gt; iptables -A OUTPUT -s 192.168.1.168 -p tcp --sport 22 -j ACCEPT&gt; iptables -A OUTPUT -s 192.168.1.168 -p icmp --icmp-type 8 -j ACCEPT&gt; iptables -A INPUT -d 192.168.1.168 -p icmp --icmp-type 0 -j ACCEPT&gt; iptables -A INPUT -i enp0s3 -j DROP&gt; iptables -A OUTPUT -o enp0s3 -j DROP&gt; # iptables -L -nvChain INPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 659 49584 ACCEPT tcp -- * * 0.0.0.0/0 192.168.1.168 tcp dpt:22 2 168 ACCEPT icmp -- * * 0.0.0.0/0 192.168.1.168 icmptype 0 10 677 DROP all -- enp0s3 * 0.0.0.0/0 0.0.0.0/0 Chain FORWARD (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt in out source destination 311 30248 ACCEPT tcp -- * * 192.168.1.168 0.0.0.0/0 tcp spt:22 2 168 ACCEPT icmp -- * * 192.168.1.168 0.0.0.0/0 icmptype 8 18 1304 DROP all -- * enp0s3 0.0.0.0/0 0.0.0.0/0``` ## 2.3 处理动作：`-j targetname [per-target-options]`- `ACCEPT`: 接受- `DROP`: 丢弃- `REJECT`: 拒绝- `RETURN`: 返回调用链- `REDIRECT`: 端口重定向- `LOG`: 记录日志- `MARK`: 做防火墙标记- `DNAT`: 目标地址转换- `SNAT`: 源地址转换- `MASQUERADE`: 地址伪装- 自定义链: 由自定义链上的规则进行匹配检查- ...... #### REJECT`REJECT --reject-with`- `--reject-with` - 设置拒绝连接的原因 - 可选值: `icmp6-no-route, no-route, icmp6-adm-prohibited, adm-prohibited, icmp6-addr-unreachable, addr-unreach, or icmp6-port-unreachable`, 默认为 `icmp-port-unreach‐able`#### LOG`LOG options`- 作用: 记录日志，默认日志保存于 `/var/log/messages`- 选项: - `--log-level`: 记录的日志级别 - `--log-prefix`: 在日志前增加的前缀 记录 telnet 连接$ iptables -I INPUT -d 192.168.1.168 -p tcp –dport 23 -m state –state NEW -j LOG``` 课后作业开放本机web服务器给非192.168.0.0/24网络中的主机访问禁止本机被非172.16.0.0/16网络中的主机进行ping请求开放本机的dns服务给所有主机]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[21.1 Linux防火墙基础理论]]></title>
    <url>%2F2018%2F03%2F29%2Flinux_mt%2F24-iptables%2FLinux%E9%98%B2%E7%81%AB%E5%A2%99%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Linux防火墙基础理论 对于大多数人包括我自己在内，在未了解防火墙之前，防火墙是一个非常抽象的存在，只知道它能保护我们的计算机免受入侵；但是对于它是什么怎么工作的完全不知道。本章我们就来学习 Linux 的防火墙，对其一窥究竟。本章我们会首先介绍Linux 防火墙的理论，让大家清楚防火墙是什么，以及其工作原理，然后再来学习怎么写防火墙的过滤规则。本章内容包含如下: Linux 防火墙的理论基础 iptables 命令的使用 实现 nat 功能 要想说清楚防火墙的工作机制并不容易，需要从网络通信说起，我们首先得明白网络通信都是通过 TCP/IP 协议进行得，无论是正常得请求响应还是非法得入侵首先必需与我们得主机建立通信，而我们得防火墙就是在数据包到达本机之后，在报文得必经之地设下”管卡”，利用我们设置得过滤对报文进行检查，放行我们允许得数据报文，阻挡可疑得报文以达到保护主机得目的。所以 Linux 中得防火墙又称为包过滤型的防火墙。下面我们就来详细解释防火墙得工作机制，本节内容包括: Linux 防火墙工作机制 Linux 防火墙 Firewall 简介 iptables 的四表五链 1. 防火墙工作机制 (图一摘录自: http://bubufx.com/detail-1702595.html) (图一摘录自: 原作者不详) 上面两幅图很好的展示了Linux 防火墙的工作机制，说清楚第一幅图也就说清楚了防火墙的工作机制。 报文解析位于内核空间前面我们说过 TCP/IP 协议可分为 4 层，应用层，传输层，网络层和物理层；应用层属于资源子网位于用户空间，用于确定数据的组织形式，其他三层属于传输子网位于内核空间，用于传输数据。网络协议报文的封装，拆封装，路由决策都位于内核空间，由内核提供。 报文流向报文到达我们的主机时，首先经由网卡进入内核，内核解析 IP 报文首部得到报文的目标主机，此时发生第一路由决策。如果目标 IP 与本机 IP 相同，则该报文是发往本机，此时需要进一步拆封装传输层首部得到报文的目标端口，将其发送至注册使用此端口的进程，报文进入用户空间。这是图一中 1-&gt;2 标识的过程。 如果目标 IP 与本机 IP 不同，并且本机打开了路由转发功能，则需要将报文转发至其它主机，此时将发生第次二路由决策，因为本机可能由多块网卡，需要根据路由表决定由哪块网卡发出报文。这是图一中 1-&gt;4-&gt;5 标识的过程。 报文也可能经由本机发出，此时也将发生第二次路由决策，内核需要更据目标 IP和路由表决定报文由哪块网卡发出，这是图一中 3-&gt;5 标识的过程。 防火墙位于报文的必经之处流经本机的报文只有三个方向: 发往本机进入用户空间 流经本机，需要转发至其他主机 由本机发出 而防火墙就是在报本的必经之处设置了勾子(hook)，我们可以在勾子上添加规则，防火墙就可以根据我们设置的规则对报文进行过滤，以达到保护主机的功能。因此防火墙由两个部分组成: netfilter: 提供防火墙框架，位于内核中，提供了钩子函数(hook function),勾子位于图一中1-5标识的五个位置 iptables: 防火墙规则管理工具，便于用户向钩子函数添加规则。这部分是可有可无的，因为 netfilter 提供了系统调用接口，可以直接调用该系统调用向勾子添加规则，iptables 只是一个辅助工具。 netfilter 提供的勾子(hook function)在 iptables 中称为链，勾子跟链是一一对应的，链是勾子名称的大写而已。 勾子–&gt;链 prerouting -&gt; PREROUTING: 报文进入主机，并在第一次路由之前 input -&gt; INPUT: 进入用户空间之前 forward -&gt; FORWARD: 转发 output -&gt; OUTPUT: 由本机发出，并在第二次路由之前 postrouting -&gt; POSTROUTING: 报文离开主机，并在第二次路由之后 总结因此报文的流向可以总结为: 流向 途径的链 流入本机 PREROUTING --&gt; INPUT 由本机流出 OUTPUT --&gt; POSTROUTING 转发 PREROUTING --&gt; FORWARD --&gt; POSTROUTING 而路由发生在： 报文进入本机后：判断目标主机是谁 报文离开本机之前：判断经由哪个接口送往下一站 2. Firewall 简介现在我们可以对防火墙下一个定义了。防火墙是一种隔离工具，工作于主机或网络边缘，对于进出本主机或本网络的报文根据事先定义的检查规则作匹配检测，对于能够被规则匹配到的报文作出相应处理的组件。 2.1 分类和版本Firewall 在 Linux 已经迭代了三个版本，详细的信息大家可以查阅其他资料 ipfw (firewall framework) ipchains (firewall framework) iptables(netfilter) netfilter：位于 kernel，是防火墙框架，提供 hook functions iptables：rules until，防火墙规则管理工具 按照防火墙提供的功能可以将防火墙分为: 主机防火墙: 位于主机上，仅为当前主前主机提供防火墙功能 网络防火墙: 位于默认网关之上，为局域网内的所有主机提供防火墙功能。 也可以按照防火墙实现的方式分成: 软件防火墙（软件逻辑） 硬件防火墙（硬件和软件逻辑) 2.2 功能防火墙除了过滤功能外，还有其他功能，并且不同功能之间具有不同的优先级，优先级从高到低如下所示: filter：过滤，防火墙； nat：network address translation；用于修改源IP或目标IP，也可以改端口； mangle：拆解报文，做出修改，并重新封装起来； raw：关闭nat表上启用的连接追踪机制； 2.3 四表五链防火墙提供的功能在 iptables 中被称为表，不同的功能只能工作于特定的链上，因此就有了 iptables 的四表五链 功能 工作的链 filter INPUT，FORWARD，OUTPUT nat PREROUTING(DNAT)，[INPUT，OUTPUT](少见)，POSTROUTING(SNAT) mangle PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING raw PREROUTING， OUTPUT iptables 规则添加就是要确定在哪个表的何处添加规则 要实现哪种功能: 判断添加在哪张表上 报文流经的路径: 判断添加在哪条链上 3. Centos 的防火墙服务3.1 CentOS 6service iptables {start|stop|restart|status} start：读取事先保存的规则，并应用到netfilter上； stop：清空netfilter上的规则，以及还原默认策略等； status：显示生效的规则； restart：清空netfilter上的规则，再读取事先保存的规则，并应用到netfilter上； 默认的规则文件：/etc/sysconfig/iptables 3.2 CentOS 7Centos7 中默认的防火墙服务是 firewalld，这是在 iptables 基础上使用 python 编写的扩展，又一个图形化节界面，可以更方便的进行防火墙规则管理。因为内部仍然使用的 iptables，想根本的学会使用，还是要学习 iptables 的使用。 12345systemctl start|stop|restart|status firewalld.service# Linux 操作练习时建议关闭systemctl disable firewalld.servicesystemctl stop firewalld.service]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[20.1 ftp基础入门]]></title>
    <url>%2F2018%2F03%2F28%2Flinux_mt%2F23-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1%2Fftp%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[ftp基础入门 计算机上的磁盘设备有 SATA，SAS；IDE，SCSI；USB 等各种接口。以 SCSI 而言，SCSI 接口可以分线，一个接口可连接多个设备，我们的操作系统想要往磁盘上写数据时，需要标识哪块磁盘哪个位置。因此 SCSI 不仅代表一种硬盘，也代表了一种操作系统如和向磁盘读写数据的协议，而且与网络协议类似，这种协议是分层的。SCSI 协议结构如下图所示 因为协议是分层，所以如果将最底下的物理层替换为光纤，并通过 TCP/IP 协议进行网络传输，我们的磁盘设备就可以被互联网上的其他访问，从而达到共享存储的目的。对于 SCSI 大家不用太关心，只需要知道数据传输的协议都是分层的，我们可以通过替换底层的传输协议达到共享存储的目的，具体怎么实现大家无需关心。 类似于磁盘这种直接附加在总线上的的设备通常被称为 DAS(Direct Attached Storage)，DAS 输出给操作系统的接口是块(block),块可以被分区格式化。按照附加到操作系统的方式，我们将存储设备分成以下几个类别: DAS: Direct Attached Storage 接口类型：输出给操作系统的接口是”块” 设备：SATA，SAS；IDE，SCSI；USB； NAS: Network Attached Storage 接口类型: 输出给操作系统的接口是”文件” 依据传输数据的协议可以分为 CIFS: samba NFS: Network File System 说明: 这种方式就是我们可以把别人共享出来的文件系统直接挂载使用 SAN：Storage Area Network 存储区域网络 接口类型：”block” 协议：iSCSI(IP-SAN), FCSAN, FCoE, … 说明: 这种方式的实现方式就是类似与我们上述所说的，将 SCSI 协议底层的物理协议替换成 TCP/IP，让磁盘设备能够通过网络向其他主机输出块接口。而为了能够进行网络传输，原来的 SCSI 磁盘将被替换为一个主机，该主机负责向外输出存储。 ftp 不能视为为一种存储，因为其基本调用接口是不能在文件系统层级进行的，只能使用专门的客户端与其交互。ftp 是应用层协议实现的共享存储。本节我们就来依次介绍这几种服务: vsftpd NFS samba 需要注意的是，如果不是当网管上述几个服务用到的很少，所以我们只需要达到基本应用即可。 1. ftp 简介ftp 全称为 file transfer protocol，文件传输协议。ftp 诞生与互联网的早期，目标是完成文件传输，所以其传输数据的方式比较奇葩，本节我们就来对 ftp 做一个简单介绍。 1.1 ftp 传输过程 如上图所示，ftp 的连接分为两类 命令连接：传输命令 数据连接：传输数据 当需要传输数据时，客户端向 ftp 服务端的 21 端口发起连接请求建立连接，此连接主要用来传输客户端的命令。然后命令的操作不能在当前连接上传输，必需新建一条连接进行数据传输。 数据连接的创建有两种模式(从服务端的角度看) 主动模式(PORT)：Server端向客户端发起连接请求，请求的端口为命令连接使用的端口向后的第一个可用端口发起连接请求 被动模式(PASV): Server端打开一个随机端口，并通过命令连接告知客户端，并等待客户端连接 数据传输完成后，数据连接即断开，下此传输时在重新建立连接。 1.2 ftp 数据传输格式ftp 不会使用 MIME 对数据进行编码，ftp 会自动根据要传输的数据是文本格式还是二进制格式来选择传输机制。 1.3 ftp 的认证机制Linux 上有一个提供认证的共享服务 PAM(Pluggable Authenticate Module),PAM 是一个认证框架包括各种库，是高度模块化的，我们 ftp 就是调用 PAM 的服务提供认证功能的。 12345678910111213141516171819202122232425$ rpm -ql pam/etc/pam.d/etc/pam.d/config-util/etc/pam.d/fingerprint-auth/etc/pam.d/other/etc/pam.d/password-auth/etc/pam.d/postlogin/etc/pam.d/smartcard-auth/etc/pam.d/system-auth/etc/security# pam 的模块目录,每一个模块可以实现一种认证功能/usr/lib64/security /usr/lib64/security/pam_access.so/usr/lib64/security/pam_chroot.so............# 所有调用 pam 进行认证的服务如何进行认证，由此目录下的配置文件配置/etc/pam.d /etc/pam.d/config-util/etc/pam.d/fingerprint-auth/etc/pam.d/other/etc/pam.d/password-auth/etc/pam.d/postlogin...... 1.4 协议实现ftp 是 C/S 架构的服务，其服务端与客户端的常见实现有 Server 端： Windows: Serv-U, IIS, Filezilla 开源：wuftpd, proftpd, pureftpd, vsftpd(Very Secure FTP daemon), … Client 端： Windows：ftp, Filezilla, CuteFTP, FlashFXP, … 开源：lftp, ftp, Filezilla, gftp, … 2. vsftpd 简介vsftpd 全称是非常安全的 ftp 服务，功能有限但是非常安全，是 Linux 上最常用的 ftp 服务的实现。 1234567891011121314rpm -ql vsftpd$ rpm -ql vsftpd/etc/logrotate.d/vsftpd/etc/pam.d/vsftpd # pam 认证配置文件/etc/vsftpd # 配置文件目录/etc/vsftpd/ftpusers/etc/vsftpd/user_list/etc/vsftpd/vsftpd.conf # 配置文件/etc/vsftpd/vsftpd_conf_migrate.sh/usr/lib/systemd/system-generators/vsftpd-generator/usr/lib/systemd/system/vsftpd.service # 作为独立服务/usr/lib/systemd/system/vsftpd.target # 作为托管服务/usr/lib/systemd/system/vsftpd@.service/usr/sbin/vsftpd 2.1 路经映射ftp 也是通过 URL 进行资源定位的 SCHEME://username:password@HOST:PORT/PATH/TO/FILE。每个用户的URL的/映射到当前用户的家目录。yum 安装 vsftpd 时默认会创建 ftp 用户，vsftpd 以 ftp 用户的身份启动进程，默认用户即为ftp用户。匿名访问 ftp 服务时，匿名用户将自动映射为 ftp 用户。匿名用户又可称为 anonymous。所以匿名用户的/ 为 ftp 用户的家目录 /var/ftp/。 123456789101112131415161718192021$ grep &quot;^ftp&quot; /etc/passwdftp:x:14:50:FTP User:/var/ftp:/sbin/nologin$ systemctl start vsftpd.service# 默认就是匿名用户登陆$ lftp 192.168.1.106lftp 192.168.1.106:~&gt; lsdrwxr-xr-x 2 0 0 6 Aug 03 2017 pub# 使用 ftp 匿名登陆$ lftp -u ftp 192.168.1.106口令:lftp ftp@192.168.1.106:~&gt; ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub# 使用 anonymous 匿名登陆$ lftp -u anonymous 192.168.1.106口令:lftp anonymous@192.168.1.106:~&gt; ls drwxr-xr-x 2 0 0 6 Aug 03 2017 pub 2.3 ftp 用户的权限一个用户通过文件共享服务访问文件系统上的文件的生效权限为此用户在共享服务上拥有的共享权限与其在本地文件系统上拥有的权限的交集。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.4 MariaDB 权限管理]]></title>
    <url>%2F2018%2F03%2F27%2Flinux_mt%2F22-mysql%2FMariaDB%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[MariaDB 权限管理 本节我们来介绍 MariaDB 中的权限管理 1. mysql 状态查询前面我们学习了 DDL 与 DML，下面是 mysql 一些常用的状态查询语句，用于查看mysql 的各种状态和变量。 作用 sql语句 -可用配置查询- ———- 查看支持的所有字符集 SHOW CHARACTER SET 查看支持的所有排序规则 SHOW COLLATION 查看数据库支持的所有存储引擎类型 SHOW ENGINES; -表状态信息- ———— 查看表状态 SHOW TABLES STATUS [LIKE &#39;tbl_name&#39;]\G 查看表上的索引的信息 SHOW INDEXES FROM tbl_name; 查看表结构 desc tbl_name; 查看表创建命令 show create table tbl_name; 查看指定用户所获得的授权 SHOW GRANTS FOR &#39;user&#39;@&#39;host&#39; 查看指定用户所获得的授权 SHOW GRANTS FOR CURRENT_USER; 2. DCL 用户账号及权限管理：2.1 用户账号mysql的用户账号由两部分组成：&#39;USERNAME&#39;@&#39;HOST&#39; USER: 表示用户名称 HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务. HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 12345vim /etc/mysql/my.cnf # 添加三个选项：[mysqld]datadir = /mydata/datainnodb_file_per_table = ONskip_name_resolve = ON # 配置禁止检查主机名 2.2 账号管理 创建用户账号：CREATE USER &#39;username&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; 删除用户账号：DROP USER ’user‘@’host&#39; [, user@host] ... 123mysqlmysql&gt; create user &apos;wpuser&apos;@&apos;%&apos; identified by &apos;wppass&apos;;mysql&gt; select * from mysql.user; 2.3 授权GRANT priv_type,... ON [object_type] db_name.tbl_name TO &#39;user&#39;@&#39;host&#39; [IDENTIFIED BY &#39;password&#39;]; priv_type： 要授权的操作 ALL: 所有操作 db_name.tbl_name： 授权的范围 *.*：所有库的所有表； db_name.*：指定库的所有表； db_name.tbl_name：指定库的特定表； db_name.routine_name：指定库上的存储过程或存储函数 [object_type]: 授权可操作额对象 TABLE，默认 FUNCTION PROCEDURE 123mysqlmysqsl&gt; grant select,delete on testdb.* to &apos;test&apos;@&apos;%&apos; identified by &apos;testpass&apos;mysql&gt; revoke delete on testdb.* from &apos;test&apos;@&apos;%&apos;; 3.4 回收权限：REVOKE priv_type, ... ON db_name.tbl_name FROM &#39;user&#39;@&#39;host&#39;; 注意：MariaDB服务进程启动时，会读取mysql库的所有授权表至内存中； GRANT或REVOKE命令等执行的权限操作会保存于表中，MariaDB此时一般会自动重读授权表，权限修改会立即生效； 其它方式实现的权限修改，要想生效，必须手动运行FLUSH PRIVILEGES命令方可；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.3 SQL DDL 与 DML]]></title>
    <url>%2F2018%2F03%2F26%2Flinux_mt%2F22-mysql%2Fsql_DDL_DML%2F</url>
    <content type="text"><![CDATA[SQL DDL 与 DML SQL 是关系型数据库专用的结构化查询语言，用来管理和查询关系型数据库中的数据。本节我们就来学习基础的 SQL 语言。 1. SQL 的分类123456789101112131415161718192021MariaDB [(none)]&gt; help contentsYou asked for help about help category: &quot;Contents&quot;For more information, type &apos;help &lt;item&gt;&apos;, where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation Data Types Functions Functions and Modifiers for Use with GROUP BY Geographic Features Help Metadata Language Structure Plugins Procedures Table Maintenance Transactions User-Defined Functions Utility 在 mysql 客户端内使用 help contents 可以查看到 SQL 语句的所有类别，最常用的是如下三类: DDL：Data Defined Language 作用: 数据定义语言，主要用于管理数据库组件，例如表、索引、视图、用户、存储过程 命令: CREATE、ALTER、DROP DML：Data Manapulating Language 作用: 数据操纵语言，主要用管理表中的数据，实现数据的增、删、改、查； 命令: INSERT， DELETE， UPDATE， SELECT DCL: 作用: 权限管理命令 命令: GRANT，REVOKE 2 MariaDB 中的数据类型MariaDB 在存储数据之前，我们首先需要创建表，创建表的核心就是定义字段和取定表使用的字符集，而定义字段，关键的一步即为确定其数据类型。 数据类型用于确定数据存储格式、能参与运算种类、可表示的有效的数据范围。字符集就是码表，在字符和二进制数字之间建立映射关系，对于非英语系的国家字符集的设置至关重要。mysql 默认的字符集是 latin1，UTF8 在 mysql 中是 utf8mb4 而不是 utf8 12show character set # 查看 mysql 支持的字符集show collation # 查看字符集支持的排序方法 2.1 数据类型MariaDB 常见的数据类型如下所示: 字符型： 定长字符型： CHAR(#)：不区分字符大小写 BINARY(#)：区分字符大小写 变长字符型： VARCHAR(#)：不区分字符大小写 VARBINARY(#)：区分字符大小写 对象存储： TEXT：不区分字符大小写 BLOB：区分字符大小写 内置类型： SET ENUM 数值型： 精确数值型： INT（TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT) DECIMAL: 十进制数 近似数值型： FLOAT DOBULE 日期时间型： 日期型：DATE 时间型：TIME 日期时间型：DATETIME 时间戳：TIMESTAMP 年份：YEAR(2), YEAR(4)` 2.3 数据类型的修饰符MariaDB 的数据类型还有修饰符的概念，用于限定字段属性，常见的修饰符如下所示: 所有类型修饰符： NOT NULL：非空； DEFAULT value：默认值； primary key unique key 整型修饰符: UNSIGNED：无符号 AUTO_INCREMENT: 自增 3. DDL3.1 数据库管理123456789101112131415# 1. 创建：CREATE &#123;DATABASE | SCHEMA&#125; [IF NOT EXISTS] db_name; [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name # 2. 修改：ALTER &#123;DATABASE | SCHEMA&#125; [db_name] [DEFAULT] CHARACTER SET [=] charset_name [DEFAULT] COLLATE [=] collation_name# 3. 删除：DROP &#123;DATABASE | SCHEMA&#125; [IF EXISTS] db_name# 4. 查看：SHOW DATABASES LIKE ’‘; 3.2 表管理：help create table 创建： CREATE TABLE [IF NOT EXISTS] tbl_name (create_defination) [table_options] create_defination: 字段：col_name data_type 键： PRIMARY KEY (col1, col2, …) UNIQUE KEY (col1, col2,…) FOREIGN KEY (column) 索引：KEY|INDEX [index_name] (col1, col2,…) table_options： ENGINE [=] engine_name 修改： ALTER [ONLINE | OFFLINE] [IGNORE] TABLE tbl_name [alter_specification [, alter_specification] ...] alter_specification: 字段： 添加：ADD [COLUMN] col_name data_type [FIRST | AFTER col_name ] 删除：DROP [COLUMN] col_name 修改： CHANGE [COLUMN] old_col_name new_col_name column_definition [FIRST|AFTER col_name] – 更改字段名称 MODIFY [COLUMN] col_name column_definition [FIRST | AFTER col_name] – 更改字段属性定义 ALTER [COLUMN] col_name [SETDEFAULT literal | DROP DEFAULT] – 更改字段默认值 键： 添加：ADD {PRIMARY|UNIQUE|FOREIGN} KEY (col1, col2,…) 删除： 主键：DROP PRIMARY KEY 外键：DROP FOREIGN KEY fk_symbol 索引： 添加：ADD {INDEX|KEY} [index_name] (col1, col2,…) 删除：DROP {INDEX|KEY} index_name 表选项：ENGINE [=] engine_name 删除： DROP TABLE [IF EXISTS] tbl_name [, tbl_name] ... 表创建的其他方式12345# 1. 复制表结构；CREATE table like table_name;# 2. 复制表数据；CREATE table select_sql; 3.3 索引管理：索引是特殊的数据结构,定义在查找时作为查找条件的字段上，实现快速查找 创建12CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX index_name [BTREE|HASH] ON tbl_name (col1, col2,,...)` 删除DROP INDEX index_name ON tbl_name 4. DML：INSERT， DELETE， UPDATE， SELECT 4.1 INSERT INSERT [INTO] tbl_name [(col1,...)] {VALUES|VALUE} (val1, ...),(...),... 注意： 字符型：引号； 数值型：不能用引号； 4.2 SELECT： SELECT * FROM tbl_name; SELECT col1, col2, ... FROM tbl_name; 显示时，字段可以显示为别名: col_name AS col_alias SELECT col1, ... FROM tbl_name WHERE clause; WHERE clause：用于指明挑选条件； col_name 操作符 value： age &gt; 30; &gt;, &lt;, &gt;=, &lt;=, ==, != 组合条件：and or not BETWEEN … AND … LIKE ‘PATTERN’ %：任意长度的任意字符； _：任意单个字符； RLIKE ‘PATTERN’ 正则表达式对字符串做模式匹配； IS NULL IS NOT NULL SELECT col1, ... FROM tbl_name [WHERE clause] ORDER BY col_name, col_name2, ... [ASC|DESC]; ASC: 升序； DESC： 降序； 4.3 DELETE： DELETE FROM tbl_name [WHERE where_condition] [ORDER BY ...] [LIMIT row_count] DELETE FROM tbl_name WHERE where_condition DELETE FROM tbl_name [ORDER BY ...] [LIMIT row_count] 4.4 UPDATE： UPDATE [LOW_PRIORITY] [IGNORE] table_reference SET col_name1=value1 [, col_name2=value2] ... [WHERE where_condition] [ORDER BY ...] [LIMIT row_count]]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.2 mysql的安装配置]]></title>
    <url>%2F2018%2F03%2F25%2Flinux_mt%2F22-mysql%2Fmariadb%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[mysql的安装配置 上一节我们对关系型数据库和 mariadb 做了一个简单介绍，接下来我们来学习 mariadb 的安装配置 1. Mariadb 配置1.1 配置文件格式mysql 的配置文件是 ini 风格的配置文件；客户端和服务器端的多个程序可通过一个配置文件进行配置，使用 [program_name] 标识配置的程序即可。 1234567891011vim /etc/my.cnf[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.sock[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid# include all files from the config directory!includedir /etc/my.cnf.d 1.2 配置文件读取次序mysql 的各类程序启动时都读取不止一个配置文件，配置文件将按照特定的顺序读取，最后读取的为最终生效的配置。可以使用 my_print_defaults 查看默认的配置文件查找次序。 123$ my_print_defaultsDefault options are read from the following files in the given order:/etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf 配置文件查找次序默认情况下 OS Vendor提供mariadb rpm包安装的服务的配置文件查找次序： /etc/mysql/my.cnf /etc/my.cnf /etc/my.cnf.d/ --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 通用二进制格式安装的服务程序其配置文件查找次序 /etc/my.cnf /etc/my.cnf.d/ /etc/mysql/my.cnf --default-extra-file=/PATH/TO/CONF_FILE: 通过命令行指定的配置文件 ~/.my.cnf: 家目录下的配置文件 12345678910# os rpm 包安装的 mariadb 配置文件ll -d /etc/my*-rw-r--r--. 1 root root 570 6月 8 2017 /etc/my.cnfdrwxr-xr-x. 2 root root 67 2月 27 09:57 /etc/my.cnf.dll /etc/my.cnf.d总用量 12-rw-r--r--. 1 root root 295 4月 30 2017 client.cnf-rw-r--r--. 1 root root 232 4月 30 2017 mysql-clients.cnf-rw-r--r--. 1 root root 744 4月 30 2017 server.cnf 1.3 初始化配置mysql的用户账号由两部分组成：&#39;USERNAME&#39;@&#39;HOST&#39;; HOST: 用于限制此用户可通过哪些远程主机连接当前的mysql服务.HOST的表示方式，支持使用通配符： %：匹配任意长度的任意字符； 172.16.%.% == 172.16.0.0/16 _：匹配任意单个字符； 默认情况下 mysql 登陆时会对客户端的 IP 地址进行反解，这种反解一是浪费时间可能导致阻塞，二是如果反解成功而 mysql 在授权时只授权了 IP 地址而没有授权主机名，依旧无法登陆，所以在配置 mysql 时都要关闭名称反解功能。 1234vim /etc/mysql/my.cnf # 添加三个选项：datadir = /mydata/datainnodb_file_per_table = ONskip_name_resolve = ON 1.4 mysql 安全初始化默认安装的情况下 mysql root 帐户是没有密码的，可通过 mysql 提供的安全初始化脚本，快速进行安全初始化。1234567# 查看mysql用户及其密码mysql&gt; use mysql;&gt; select user,host,password from user;# 运行脚本安全初始化脚本/user/local/mysql/bin/mysql_secure_installation 2. MariaDB 安装常见的安装方式有如下三种: rpm包；由OS的发行商提供，或从程序官方直接下载 源码包编译安装: 编译安装，除非需要定制功能，否则一般不推荐编译安装 通用二进制格式的程序包: 展开至特定路径，并经过简单配置后即可使用，这种方式便于部署，无需解决环境依赖 2.1 二进制程序包安装Centos 6： 准备数据目录；以/mydata/data目录为例； 安装配置mariadb 12345678910111213groupadd -r -g 306 mysqluseradd -r -g 306 -u 306 mysqltar xf mariadb-VERSION.tar.xz -C /usr/localcd /usr/localln -sv mariadb-VERSION mysqlcd /usr/local/mysqlchown -R root:mysql ./*scripts/mysql_install_db --user=mysql -datadir=/mydata/datacp support-files/mysql.server /etc/init.d/mysqldchkconfig --add mysqldchkconfig --list mysqld# 跳过名称解析，并进行安全初始化]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[19.1 mysql 数据库基础]]></title>
    <url>%2F2018%2F03%2F24%2Flinux_mt%2F22-mysql%2Fmariadb%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[mysql 数据库基础 本章我们来学习 MySQL，数据库本身是一个很复杂的内容，有很多的基本概念，想在短篇幅之内把其中的知识点讲清除并不容易。本章博客自我感觉整理的不好，后续会持续更新。本章将包括以下内容: 什么是关系型数据库 mysql 客户端的使用 mysql 的安装与配置 sql 语句的使用 mysql 中的权限管理 mariadb(mysql) 是最常用的开源关系型数据库，本节我们就对关系型数据库和 mysql 做一个简单介绍。 1. 关系型数据库1.1 数据模型数据模型有，层次模型、网状模型、关系模型。关系模型是二维关系表现为表中的列和行。数据库管理系统称为 DBMS(DataBase Management System)，关系型数据库管理系统则称为 RDBMS(Relational DataBase Management System)，常见的 RDMBS: Mysql/MariaDB/Percona-Server PostgreSQL Oracle 1.2 事务(Transaction)事务含义是将多个操作为一个整体，要么全部都执行，要么全部都不执行；其遵循 ACID： A：Atomicity,原子性； C：Consistency,一致性； I：Isolation,隔离性； D：Durability,持久性； 2. RDMBS设计范式设计关系数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。目前关系数据库有六种范式： 第一范式（1NF）: 每一列都是原子，不可在分割的 第二范式（2NF）: 每一行都可以使用其有限字段进行唯一标志(不存在重复的行) 第三范式（3NF）、巴德斯科范式（BCNF）: 任何表都不应该有依赖于其他表的非主键字段 第四范式(4NF）和 第五范式（5NF，又称完美范式） 满足最低要求的范式是第一范式（1NF）。在第一范式的基础上进一步满足更多规范要求的称为第二范式（2NF），其余范式以次类推。一般说来，数据库只需满足第三范式(3NF）就行了。 3. mysql 简介自从 mysql 被 Oracle 收购之后，由于担心版权问题，mysql 的创始人就新建了另一开源分支 mariadb，在 Centos6 中默认安装的是 mysql，而在 Centos7 中默认安装的已经是 mariadb。mariadb 跟 mysql 底层的基础特性是类似的，但是高级特性有很大不同，彼此支持的高级功能也不相同。除了 mariadb，mysql还有很多二次发行版本，比如Percona，AllSQL(阿里的mysql 发行版)以及，TIDB mysql 与 mariadb 的官网分别是： www.mysql.com MariaDB: www.mariadb.org 3.1 mariadb 特性MariaDB的 支持插件式存储引擎，即存储管理器有多种实现版本，彼此间的功能和特性可能略有区别；用户可根据需要灵活选择。存储引擎也称为“表类型”。常见的存储引擎就是 MyISAM:不支持事务和表级锁，奔溃后不保证安全恢复； InnoDB: 支持事务，行级锁，外键和热备份； MyISAM 在 mariadb 中被扩展为 Aria，支持安全恢复, InnoDB 在 Mariadb 中的开源实现为 XtraDB。在 mysql 的客户端中输入 show engines 即可查看 mariadb 支持的所有存储引擎。 123456789101112131415MariaDB [(none)]&gt; show engines;+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| Engine | Support | Comment | Transactions | XA | Savepoints |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+| CSV | YES | CSV storage engine | NO | NO | NO || MRG_MYISAM | YES | Collection of identical MyISAM tables | NO | NO | NO || MEMORY | YES | Hash based, stored in memory, useful for temporary tables | NO | NO | NO || BLACKHOLE | YES | /dev/null storage engine (anything you write to it disappears) | NO | NO | NO || MyISAM | YES | MyISAM storage engine | NO | NO | NO || InnoDB | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES | YES | YES || ARCHIVE | YES | Archive storage engine | NO | NO | NO || FEDERATED | YES | FederatedX pluggable storage engine | YES | NO | YES || PERFORMANCE_SCHEMA | YES | Performance Schema | NO | NO | NO || Aria | YES | Crash-safe tables with MyISAM heritage | NO | NO | NO |+--------------------+---------+----------------------------------------------------------------------------+--------------+------+------------+ 3.2 MariaDB程序的组成mariadb 是 C/S 架构的服务，其命令分为服务器端和客户端两个部分 C：Client mysql：CLI交互式客户端程序； mysqldump：备份工具； mysqladmin：管理工具； mysqlbinlog： … S：Server mysqld mysqld_safe：建议运行的服务端程序； mysqld_multi：多实例； msyql 服务器可监听在两种套接字上 IPV4/6 的 tcp 的 3306 端口上，支持远程通信 Unix Sock，监听在 socket 文件上，仅支持本地通信，套接子文件通常位于 /var/lib/mysql/mysql.sock或 /tmp/mysql.sock 由配置文件指定。 12ll /var/lib/mysql/mysql.socksrwxrwxrwx. 1 mysql mysql 0 8月 21 11:10 /var/lib/mysql/mysql.sock 3.3 mysql 客户端启动命令mysql [OPTIONS] [database] 常用选项： -u, --user=name：用户名，默认为root； -h, --host=name：远程主机（即mysql服务器）地址，默认为localhost; -p, --password：USERNAME所表示的用户的密码； 默认为空； -P, --port: 指定 mysql 服务监听的端口，默认为 3306 -D, --database：连接到服务器端之后，设定其处指明的数据库为默认数据库； -e, --execute=&#39;SQL COMMAND;&#39;：连接至服务器并让其执行此命令后直接返回； -S, --socket: 指定本地通信的套接字路经 mysql 客户端内可输入的命令分为两类: 客户段命令: 只在客户端运行的命令，使用 help 可获取此类命令的帮助 服务段命令: 通过 mysql 的协议送到服务段运行的命令，所以必须要有命令结束符,默认为 ;；使用 help contents 获取服务器端命令使用帮助。 查看本地命令mysql&gt; help \u db_name：设定哪个库为默认数据库 \q：退出 \d CHAR：设定新的语句结束符，默认为 ; \g：语句结束标记，默认就相当于 ; 作用 \G：语句结束标记，结果竖排方式显式 \! COMMAND: 在客户端内运行 shell 命令 \. PATH: 在客户端内执行 sql 脚本(包含 sql 的文本) 12345678910111213141516171819202122232425262728293031323334353637$ mysql -uroot -p1234MariaDB [(none)]&gt; help # help 查看 mysql 的所有命令List of all MySQL commands:Note that all text commands must be first on line and end with &apos;;&apos;? (\?) Synonym for `help&apos;.clear (\c) Clear the current input statement.connect (\r) Reconnect to the server. Optional arguments are db and host.delimiter (\d) Set statement delimiter.edit (\e) Edit command with $EDITOR.ego (\G) Send command to mysql server, display result vertically.exit (\q) Exit mysql. Same as quit.go (\g) Send command to mysql server.help (\h) Display this help.nopager (\n) Disable pager, print to stdout.notee (\t) Don&apos;t write into outfile.pager (\P) Set PAGER [to_pager]. Print the query results via PAGER.print (\p) Print current command.prompt (\R) Change your mysql prompt.quit (\q) Quit mysql.rehash (\#) Rebuild completion hash.source (\.) Execute an SQL script file. Takes a file name as an argument.status (\s) Get status information from the server.system (\!) Execute a system shell command.tee (\T) Set outfile [to_outfile]. Append everything into given outfile.use (\u) Use another database. Takes database name as argument.charset (\C) Switch to another charset. Might be needed for processing binlog with multi-byte charsets.warnings (\W) Show warnings after every statement.nowarning (\w) Don&apos;t show warnings after every statement.For server side help, type &apos;help contents&apos;# 执行 shell 命令MariaDB [(none)]&gt; \! ls /varaccount cache db games iso lib lock mail nis preserve spool tmp ypadm crash empty gopher kerberos local log named opt run target www 查看服务端命令12345678910111213141516171819202122232425262728293031323334MariaDB [(none)]&gt; help contents # 查看 mysql 命令的组成部分For more information, type &apos;help &lt;item&gt;&apos;, where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation.........MariaDB [(none)]&gt; help &apos;Account Management&apos; # 查看特定命令组内的命令topics: CREATE USER DROP USER GRANT RENAME USER REVOKE SET PASSWORDMariaDB [(none)]&gt; help &apos;CREATE USER&apos; # 查看特定命令使用帮助Name: &apos;CREATE USER&apos;Description:Syntax:CREATE USER user_specification [, user_specification] ...user_specification: user [ IDENTIFIED BY [PASSWORD] &apos;password&apos; | IDENTIFIED WITH auth_plugin [AS &apos;auth_string&apos;] ]............... 3.4 mysql 数据库组件mysql 数据库包括如下组件: 数据库: database 表: table: 行: row 列: column 索引: index 视图: view 用户: user 权限: privilege 存储过程: procedure 存储函数: function 触发器: trigger 事件调度器: event scheduler]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.5 编译安装 lamp-fpm]]></title>
    <url>%2F2018%2F03%2F23%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2F%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85lamp-fpm%2F</url>
    <content type="text"><![CDATA[编译安装 lamp-fpm 1. Centos6 编译安装 lamp-fpm1.1 编译安装步骤 httpd：编译安装，httpd-2.4 mairadb：通用二进制格式，mariadb-5.5 php5：编译安装，php-5.4 xchache 注意：任何一个程序包被编译操作依赖到时，需要安装此程序包的“开发”组件，其包名一般类似于name-devel-VERSION； 1.2 编译安装apache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 准备开发环境yum groupinstall &quot;Development Tools&quot; &quot;Server Platform Development&quot; -y# 1. 编译安装aprtar xf apr-1.5.0.tar.bz2cd apr-1.5.0./configure --prefix=/usr/local/aprmake &amp;&amp; make install# 2. 编译安装apr-utiltar xf apr-util-1.5.3.tar.bz2cd apr-util-1.5.3./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/aprmake &amp;&amp; make install# 3. httpd-2.4.9编译过程也要依赖于pcre-devel软件包，需要事先安装yum install pcre-devel -y# 4. 编译安装httpd-2.4.9tar xf httpd-2.4.9.tar.bz2cd httpd-2.4.9./configure --enable-so --enable-ssl --enable-cgi --enable-rewrite --with-zlib --with-pcre --enable-modules=most --enable-mpms-shared=all --with-mpm=event --prefix=/usr/local/apache --sysconfdir=/etc/httpd24 --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-utilmake &amp;&amp; make install# 5. 提供SysV服务脚本/etc/rc.d/init.d/httpdcd /etc/rc.d/init.dcp httpd httpd24vim http24 &gt; apachectl=/usr/local/apache/bin/apachectl &gt; httpd=$&#123;HTTPD-/usr/local/apache/bin/httpd&#125; &gt; pidfile= &gt; logfile=chkconfig --add httpd24chkconfig --list httpd24# 6. 配置系统环境vim /etc/profile.d/httpd24.sh &gt; export PATH=/usr/local/apache/bin:$PATH. /etc/profile.d/httpd24.shhttpd -tservice start httpd24# 7. 修改配置文件cd /etc/httpd24vim httpd.conf &gt; PidFile &quot;/var/run/httpd.pid&quot; # 说明:# httpd.conf 中的 PidFile 必须与 init 服务启动脚本中的pidfile 保持一致# 默认 httpd.conf 的PidFile=/usr/local/apache/logs/httpd.pid 1.3 编译安装 Mariadb123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# 1. 准备数据存放的文件系统# 新建一个逻辑卷，并将其挂载至特定目录即可# 假设挂载目录为/mydata，/mydata/data 为mysql数据的存放目录# 2. 新建用户以安全方式运行进程：groupadd -r mysqluseradd -g mysql -r -s /sbin/nologin -M -d /mydata/data mysqlchown -R mysql:mysql /mydata/data# 3. 安装并初始化mariadb# 下载通用二进制包 mariadb-5.5.60-linux-systemd-x86_64.tar.gztar xf mysql-5.5.33-linux2.6-i686.tar.gz -C /usr/localcd /usr/local/ln -sv mysql-5.5.33-linux2.6-i686 mysqlcd mysqlchown -R mysql:mysql .scripts/mysql_install_db --user=mysql --datadir=/mydata/datachown -R root .# 4. 为mysql提供主配置文件：cd /usr/local/mysqlcp support-files/my-large.cnf /etc/my.cnfvim /etc/my.cnf &gt; thread_concurrency = cpu * 2 &gt; datadir = /mydata/data &gt; innodb_file_per_table = on &gt; skip_name_resolve = on# 5. 为mysql提供sysv服务脚本：cd /usr/local/mysqlcp support-files/mysql.server /etc/rc.d/init.d/mysqldchmod +x /etc/rc.d/init.d/mysqldchkconfig --add mysqldchkconfig mysqld onservice start mysqld# 6. 删除 mysql 匿名用户cd /usr/local/mysqlscripts/mysql_secure_installation# 7. man，PATH 环境变量# 输出mysql的man手册至man命令的查找路径vim /etc/man.config &gt; MANPATH /usr/local/mysql/man# 输出mysql的头文件至系统头文件路径/usr/includeln -sv /usr/local/mysql/include /usr/include/mysql# 输出mysql的库文件给系统库查找路径echo &apos;/usr/local/mysql/lib&apos; &gt; /etc/ld.so.conf.d/mysql.confldconfig # 让系统重新载入库# 修改PATH环境变量vim /etc/profile.d/mysql.sh &gt; export PATH=/usr/local/mysql/bin:$PATH 1.4 编译安装 php1234567891011121314151617181920212223242526272829303132333435363738394041424344# 1. 解决依赖关系：yum -y groupinstall &quot;X Software Development&quot;# 如果想让编译的php支持mcrypt扩展yum install libmcryptyum install libmcrypt-develyum install mhashyum install mhash-devel# 2. 编译安装 phptar xf php-5.4.26.tar.bz2cd php-5.4.26./configure --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-openssl --with-mysqli=/usr/local/mysql/bin/mysql_config --enable-mbstring --with-freetype-dir --with-jpeg-dir --with-png-dir --with-zlib --with-libxml-dir=/usr --enable-xml --enable-sockets --enable-fpm --with-mcrypt --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.d --with-bz2# 说明： # fpm 必须启用 --enable-fpm # 需要更改的配置有 # --prefix=/usr/local/php5 --with-mysql=/usr/local/mysql --with-mysqli=/usr/local/mysql/bin/mysql_config --with-config-file-path=/etc --with-config-file-scan-dir=/etc/php.dmakemake intall# 3. 为php提供配置文件：cp php.ini-production /etc/php.ini# 4. 为php-fpm提供SysV init脚本，并将其添加至服务列表：cp sapi/fpm/init.d.php-fpm /etc/rc.d/init.d/php-fpmchmod +x /etc/rc.d/init.d/php-fpmchkconfig --add php-fpmchkconfig php-fpm on# 5. 为php-fpm提供配置文件：cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf# 配置fpm的相关选项为你所需要的值，并启用pid文件（如下最后一行）：vim /usr/local/php/etc/php-fpm.conf &gt; pm.max_children = 50 &gt; pm.start_servers = 5 &gt; pm.min_spare_servers = 2 &gt; pm.max_spare_servers = 8 &gt; pid = /usr/local/php/var/run/php-fpm.pid # 与 init 脚本一致# 启动php-fpm, 默认情况下，fpm监听在127.0.0.1的9000端口service php-fpm start ps aux | grep php-fpm 1.5 配置 httpd1234567891011121314151617181920212223242526272829303132333435# 1. 启用httpd的相关模块vim /etc/httpd/httpd.conf &gt; LoadModule proxy_module modules/mod_proxy.so &gt; LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so# 2. 配置虚拟主机支持使用fcgi# 在相应的虚拟主机中添加类似如下两行。 &gt; ProxyRequests Off &gt; ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1# ProxyRequests Off：关闭正向代理# ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。# 虚拟主机配置示例DirectoryIndex index.php&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 &lt;Directory &quot;/apps/vhosts/b.net&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; # 3. 让apache能识别php格式的页面，并支持php格式的主页,并支持php格式的主页vim /etc/httpd/httpd.conf &gt; AddType application/x-httpd-php .php &gt; AddType application/x-httpd-php-source .phps &gt; DirectoryIndex index.php index.html 1.6 安装 xcache12345678910111213# 1. 安装tar xf xcache-3.0.3.tar.gzcd xcache-3.0.3/usr/local/php/bin/phpize./configure --enable-xcache --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; make install# 安装结束时，会出现类似如下行：# Installing shared extensions: /usr/local/php/lib/php/extensions/no-debug-zts-20100525/cp xcache.ini /etc/php.dvim /etc/php.d/xcache.ini &gt; extension=&quot;上述安装结束提示的路径&quot; 1.7 php-fpm 配置vim /usr/local/php/etc/php-fpm.conf pm = static|dynamic static：固定数量的子进程； pm.max_children； dynamic：子进程数据以动态模式管理； pm.start_servers pm.min_spare_servers pm.max_spare_servers ;pm.max_requests = 500 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限；12# mkdir /var/lib/php/session# chown apache.apache /var/lib/php/session]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.4 LAMP部署示例]]></title>
    <url>%2F2018%2F03%2F22%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E9%83%A8%E7%BD%B2%E7%A4%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[LAMP部署示例 本节我们就来部署两个经典的 php 开源项目作为演示部署 LAMP 的示例 1. httpd部署示例1.1 wordpress 部署12345678910111213141516# wordpress 配置unzip wordpress-2.9.2.zipcp -a wordpress /www/htdoccd /www/htdoc/wordpresscp wp-config-sample.php wp-config.phpvim wp-config.php # 更改mysql 连接的账号，密码，数据库# mariadb 配置mysqlmysql&gt; grant all on wpdb.* to "wpuser"@"localhost" identified by "wppasswd"mysql&gt; grant all on wpdb.* to "wpuser"@"127.0.0.1" identified by "wppasswd"mysql&gt; create datebase wpdbmysql&gt; flush privilegesvim /etc/my.cnf.d/server.cnfskip-name-resolve=ON 1.2 phpMyAdmin 部署1234567891011121314151617# 系统环境yum install php-mbstring# phpMyAdmin 配置unzip phpMyAdmin-version.zipcp -a phpMyAdmin-version /www/htdoc/cd /www/htdocln -sv phpMyAdmin-version pmacd pmacp config.sample.inc.php config.inc.phpvim config.inc.php # 修改 $cfg['blowfish_secret'] = ''# mysql 账号配置:mysqlmysql&gt; set password for 'root'@'localhost' = PASSWORD('mageedu')mysql&gt; set password for 'root'@'127.0.0.1' = PASSWORD('mageedu')mysql&gt; flush privileges]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.3 LAMP安装]]></title>
    <url>%2F2018%2F03%2F21%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[LAMP安装 前面我们我们介绍了 LAMP 的原理部分，本节我们就来实践，搭建一个 LAMP。 1. php 配置1.1 httpd 与 php 结合方式前面我们介绍 LAMP 的基本原理时提到过，httpd 与 php 有三种结合方式 CGI: 由 httpd 服务创建子进程来加载和执行 php 脚本 fpm（FastCGI Process Manager): php 进程管里器，将 php 的解析执行作为独立的应用程序服务器 modules: 将 php编译成为 httpd 的模块，httpd 既是 web 服务器也是应用程序服务器 prefork MPM 下需要加载 libphp5.so 模块 event, worker MPM 下需要加载 libphp5-zts.so 模块 modules将 php 作为 http 的 modules 由 php 包提供12345678$ yum info php$ rpm -ql php/etc/httpd/conf.d/php.conf/etc/httpd/conf.modules.d/10-php.conf/usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块/usr/share/httpd/icons/php.gif/var/lib/php/session fpmfpm 由 php-fpm 包提供1234567891011$ yum info php-fpm$ rpm -ql php-fpm/etc/logrotate.d/php-fpm/etc/php-fpm.conf # php-fpm 服务的配置文件/etc/php-fpm.d/etc/php-fpm.d/www.conf/etc/sysconfig/php-fpm/run/php-fpm/usr/lib/systemd/system/php-fpm.service/usr/lib/tmpfiles.d/php-fpm.conf/usr/sbin/php-fpm 1.2 php 相关包与 php 相关的 rpm 包有如下几个: php: 实现 php 作为 httpd 的一个模块 php-fpm: fpm php-common: php 的核心文件 php-mysql: php 的 mysql 驱动模块 php-xcache: php 的加速器 1.3 php核心文件1234567891011$ rpm -ql php-common/etc/php.ini # 配置文件/etc/php.d/etc/php.d/curl.ini/etc/php.d/fileinfo.ini/etc/php.d/json.ini/etc/php.d/phar.ini/etc/php.d/zip.ini/usr/lib64/php/usr/share/php/var/lib/php php 的所有核心文件均由 php-common 包提供，配置文件为: /etc/php.ini /etc/php.d/*.ini php 的配置文件在 php 启动时被读取一次 对于服务器模块存在的 php 仅在web 服务器启动时读取一次 Modules：重启httpd服务生效； FastCGI：重启php-fpm服务生效； 对于cgi 和 cli 版本，每次调用都会读取 php.iniphp 的文档参考如下: php.ini的核心配置选项文档： http://php.net/manual/zh/ini.core.php php.ini配置选项列表：http://php.net/manual/zh/ini.list.php 注释符： 较新的版本中，已经完全使用;进行注释； #：纯粹的注释信息 ;：用于注释可启用的directive 1234# 配置方式类似 yum.respo.d, 采用分段进行# ;(分号) 表示注释符[foo]：Section Headerdirective = value 1.3 php xcache 加速器12345# 安装yum install php-xcache# 配置/etc/php.d/xcache.ini 2. modules 模式的 LAMP 安装首先我们来介绍将 php 作为 httpd 的一作模块这种模式下 LAMP 的安装配置。安装完成后 php 的配置文件位于 /etc/httpd/conf.d/php.conf 2.1 Centos 6Centos 下需要安装 httpd, php, php-mysql, mysql-server，然后启动 httpd 和 mysql 服务 123yum install -y httpd php php-mysql mysql-serverservice httpd startservice mysqld star 2.2 Centos 7Centos7 下需要安装 httpd, php, php-mysql, mariadb-server。需要注意的是 php 在不同的 MPM 下安装的方式不一样，默认 yum install php 安装要求 httpd 使用 prefork MPM。 123456789101112# 1. 安装 LAMPyum install http php php-mysql mariadb-serversystemctl start httpdsystemctl start mariadb# 2. php 的配置$ rpm -ql php/etc/httpd/conf.d/php.conf/etc/httpd/conf.modules.d/10-php.conf/usr/lib64/httpd/modules/libphp5.so # prefork MPM 的 php 所需模块/usr/share/httpd/icons/php.gif/var/lib/php/session 2.3 测试php 程序执行环境123&lt;?php phpinfo()?&gt; php 与mysql 通信12345678910# vim DocumentRoot/a.php&lt;?php $con=mysql_connect(&apos;127.0.0.1&apos;,&apos;&apos;,&apos;&apos;); if ($con) echo &quot;OK&quot;; else echo &quot;faile&quot;; mysql_close(); phpinfo();?&gt; 3. fpm 的 LAMP 安装3.1 Centos6 PHP-5.3.2：默认不支持fpm机制；需要自行打补丁并编译安装； httpd-2.2：默认不支持fcgi协议，需要自行编译此模块； 解决方案：编译安装httpd-2.4, php-5.3.3+； 3.2 Centos7 httpd-2.4：rpm包默认编译支持了fcgi模块； php-fpm包：专用于将php运行于fpm模式； 安装 msyql123456789101112131415# 1. 安装 msyqlyum isntall -y mariadb-servervim /etc/my.cnf.d/server.cnf [mysqld] skip_name_resolve=ON innodb_file_per_table=ON# 安全初始化mysql_secure_installation# 创建普通登陆用户# mysql -uroot -pmysql&gt; grant all on testdb.* to &apos;myuser&apos;@&apos;172.16.0.%&apos; indentified by &quot;mypass&quot;mysql&gt; flush priviledges 安装 php-fpm123456789101112131415161718192021222324# 2. 安装 php-fpm，最好不要与 php 包同时安装yum install php-fpm php-mysql php-mbstring$ rpm -ql php-fpm/etc/logrotate.d/php-fpm/etc/php-fpm.conf/etc/php-fpm.d/etc/php-fpm.d/www.conf# 配置 php-fpmvim /etc/php-fpm.confvim /etc/php-fpm.d/www.conf pm = static|dynamic # - static：固定数量的子进程； # - pm.max_children； # - dynamic：子进程数据以动态模式管理； # - pm.start_servers # - pm.min_spare_servers # - pm.max_spare_servers # - ;pm.max_requests = 500# 创建session目录，并确保运行php-fpm进程的用户对此目录有读写权限；mkdir /var/lib/php/sessionchown apache.apache /var/lib/php/session 配置 httpd12345678910111213141516171819202122232425262728293031# 1. 确定是否启用httpd的相关模块httpd -M|grep proxy_module# 未启用则启用代理模块vim /etc/httpd/httpd.conf &gt; LoadModule proxy_module modules/mod_proxy.so &gt; LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so# 2. 配置虚拟主机支持使用fcgi# 在相应的虚拟主机中添加类似如下两行。 &gt; ProxyRequests Off &gt; ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/PATH/TO/DOCUMENT_ROOT/$1# ProxyRequests Off：关闭正向代理# ProxyPassMatch：把以.php结尾的文件请求发送到php-fpm进程，php-fpm至少需要知道运行的目录和URI，所以这里直接在fcgi://127.0.0.1:9000后指明了这两个参数，其它的参数的传递已经被mod_proxy_fcgi.so进行了封装，不需要手动指定。# 虚拟主机配置示例DirectoryIndex index.php&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot /apps/vhosts/b.net ProxyRequests Off ProxyPassMatch ^/(.*\.php)$ fcgi://127.0.0.1:9000/apps/vhosts/b.net/$1 &lt;Directory &quot;/apps/vhosts/b.net&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 安装 php xcache12345yum install -y php-xcache$ rpm -ql php-xcache/etc/php.d/xcache.ini/usr/lib64/php/modules/xcache.so]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.2 PHP 基础]]></title>
    <url>%2F2018%2F03%2F20%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2Fphp%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[PHP 基础 “PHP 是世界上最好的语言”,因为我们后面会以 php 为例配置一个 LAMP，所以本节我们就来先了解一下 php。这里就是一个简单介绍，因为我也没学过 php，所以大多数内容都是摘录自马哥的上课笔记。 1. 关于PHP1.1 PHP 简介PHP是通用服务器端脚本编程语言，其主要用于web开发以实现动态web页面，它也是最早实现将脚本嵌入HTML源码文档中的服务器端脚本语言之一。同时，php还提供了一个命令行接口，因此，其也可以在大多数系统上作为一个独立的shell来使用。 Rasmus Lerdorf于1994年开始开发PHP，它是初是一组被Rasmus Lerdorf称作“Personal Home Page Tool” 的Perl脚本， 这些脚本可以用于显示作者的简历并记录用户对其网站的访问。后来，Rasmus Lerdorf使用C语言将这些Perl脚本重写为CGI程序，还为其增加了运行Web forms的能力以及与数据库交互的特性，并将其重命名为“Personal Home Page/Forms Interpreter”或“PHP/FI”。此时，PHP/FI已经可以用于开发简单的动态web程序了，这即是PHP 1.0。 1995年6月，Rasmus Lerdorf把它的PHP发布于comp.infosystems.www.authoring.cgi Usenet讨论组，从此PHP开始走进人们的视野。1997年，其2.0版本发布。 1997年，两名以色列程序员Zeev Suraski和Andi Gutmans重写的PHP的分析器(parser)成为PHP发展到3.0的基础，而且从此将PHP重命名为PHP: Hypertext Preprocessor。此后，这两名程序员开始重写整个PHP核心，并于1999年发布了Zend Engine 1.0，这也意味着PHP 4.0的诞生。 2004年7月，Zend Engine 2.0发布，由此也将PHP带入了PHP 5时代。PHP5包含了许多重要的新特性，如增强的面向对象编程的支持、支持PDO(PHP Data Objects)扩展机制以及一系列对PHP性能的改进。 1.2 PHP Zend EngineZend Engine是开源的、PHP脚本语言的解释器，它最早是由以色列理工学院(Technion)的学生Andi Gutmans和Zeev Suraski所开发，Zend也正是此二人名字的合称。后来两人联合创立了Zend Technologies公司。 Zend Engine 1.0于1999年随PHP 4发布，由C语言开发且经过高度优化，并能够做为PHP的后端模块使用。Zend Engine为PHP提供了内存和资源管理的功能以及其它的一些标准服务，其高性能、可靠性和可扩展性在促进PHP成为一种流行的语言方面发挥了重要作用。 Zend Engine的出现将PHP代码的处理过程分成了两个阶段： 首先是分析PHP代码并将其转换为称作Zend opcode的二进制格式(类似Java的字节码)，并将其存储于内存中； 第二阶段是使用Zend Engine去执行这些转换后的Opcode。 1.3 PHP的OpcodeOpcode: 是一种PHP脚本编译后的中间语言，就像Java的ByteCode,或者.NET的MSL。PHP执行PHP脚本代码一般经过如下4个步骤(确切的来说，应该是PHP的语言引擎Zend)： Scanning(Lexing): 将PHP代码转换为语言片段(Tokens) Parsing: 将Tokens转换成简单而有意义的表达式 Compilation: 将表达式编译成Opocdes Execution: 顺次执行Opcodes，每次一条，从而实现PHP脚本的功能 总结: 扫描–&gt;分析–&gt;编译–&gt;执行 1.4 php的加速器 原理: 基于PHP的特殊扩展机制如opcode缓存扩展也可以将opcode缓存于php的共享内存中，从而可以让同一段代码的后续重复执行时跳过编译阶段以提高性能。 由此也可以看出，这些加速器并非真正提高了opcode的运行速度，而仅是通过分析opcode后并将它们重新排列以达到快速执行的目的。 常见的php加速器有： APC (Alternative PHP Cache) 遵循PHP License的开源框架，PHP opcode缓存加速器， 目前的版本不适用于PHP 5.4 项目地址，http://pecl.php.net/package/APC。 eAccelerator 源于Turck MMCache，早期的版本包含了一个PHP encoder和PHP loader，目前encoder已经不在支持 项目地址， http://eaccelerator.net/。 XCache 快速而且稳定的PHP opcode缓存，经过严格测试且被大量用于生产环境。 项目地址，http://xcache.lighttpd.net/ yum install php-xcache Zend Optimizer和Zend Guard Loader Zend Optimizer并非一个opcode加速器，它是由Zend Technologies为PHP5.2及以前的版本提供的一个免费、闭源的PHP扩展，其能够运行由Zend Guard生成的加密的PHP代码或模糊代码。 而Zend Guard Loader则是专为PHP5.3提供的类似于Zend Optimizer功能的扩展。 项目地址，http://www.zend.com/en/products/guard/runtime-decoders NuSphere PhpExpress NuSphere的一款开源PHP加速器，它支持装载通过NuSphere PHP Encoder编码的PHP程序文件，并能够实现对常规PHP文件的执行加速。 项目地址，http://www.nusphere.com/products/phpexpress.htm 1.5 PHP源码目录结构其代码根目录中主要包含了一些说明文件以及设计方案，并提供了如下子目录： build: 顾名思义，这里主要放置一些跟源码编译相关的文件，比如开始构建之前的buildconf脚本及一些检查环境的脚本等。 ext: 官方的扩展目录，包括了绝大多数PHP的函数的定义和实现，如array系列，pdo系列，spl系列等函数的实现。 个人开发的扩展在测试时也可以放到这个目录，以方便测试等。 main: 这里存放的就是PHP最为核心的文件了，是实现PHP的基础设施，这里和Zend引擎不一样，Zend引擎主要实现语言最核心的语言运行环境。 Zend: Zend引擎的实现目录，比如脚本的词法语法解析，opcode的执行以及扩展机制的实现等等。 pear: PHP 扩展与应用仓库，包含PEAR的核心文件。 sapi: 包含了各种服务器抽象层的代码，例如apache的mod_php，cgi，fastcgi以及fpm等等接口。 TSRM: PHP的线程安全是构建在TSRM库之上的，PHP实现中常见的*G宏通常是对TSRM的封装，TSRM(Thread Safe Resource Manager)线程安全资源管理器。 tests: PHP的测试脚本集合，包含PHP各项功能的测试文件。 win32: 这个目录主要包括Windows平台相关的一些实现，比如sokcet的实现在Windows下和*Nix平台就不太一样，同时也包括了Windows下编译PHP相关的脚本。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[18.1 LAMP入门讲解]]></title>
    <url>%2F2018%2F03%2F19%2Flinux_mt%2F21-web%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84LAMP%2FLAMP%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[LAMP入门讲解 上一章我们讲解了 web 的基本概念，以及如何使用 httpd 搭建一个静态的 web 服务器。本章我们接着上一章的内容，讲解 web 服务框架 LAMP。 1. LAMP1.1 LAMP 简介最早的 web 站点只能提供静态内容，我们的 web 服务只有一个 httpd 服务器，要想展示页面我们必需事先生成静态的 web 页面。但是我们很清楚，不论哪个网站大多数页面都是类似的，只有一小部分不同，大多数页面都可以套用相同的模板动态生成。而填充模板的数组则通常放置在数据库中，最为大家所熟知的也就是 mysql。因此我们的 web 资源就分成了静态资源和动态资源两种 静态资源：原始形式与响应内容一致； 动态资源：原始形式通常为程序文件，需要在服务器端执行之后，将执行结果返回给客户端 服务器端加载动态资源的方式，按照技术的出现的时间次序分为了: CGI, Common Gateway Interface FCGI, Fast CGI 接下来我们就来详细介绍，这两种动态资源的加载方式 1.1 CGICGI(Common Gateway Interface，通用网关接口)，是一种传输协议，它规范了客户端与服务器端如何传输动态资源以及服务器端如何加载动态资源的方式。它的模型如下图所示 这种模型下并不存在后端的应用程序服务器，由前端 web 服务器完成所有工作。动态资源的请求过程如下所示： httpd 服务接收用户请求(动态资源) httpd 基于cgi 协议，在子进程中自动调用 php 的解释器执行对应的 php 脚本，并获取脚本返回结果作为响应传递给客户端 后端应用程序，无须是一个服务，无须理解 http 协议，全部由 apache 服务器完成 即由 web 服务器理解和解析 url，并由 web 服务自行调用动态资源的解释器，运行该动态资源，并获取结果响应给客户端 CGI 在每响应一个动态资源时，必须创建和销毁子进程，性能很低。 1.2 FCGIFCGI 是 CGI 的增强版本，其动态资源的请求过程如下所示 后端应用程序服务器作为独立的服务监听在特定端口，与 httpd 通过 tcp/udp 协议进行通信 httpd 接收用户请求后，作为客户端向应用程序服务器请求相同的动态资源 后端应用程序服务器加载并执行 php 脚本，并将执行结果作为响应返回给 httpd，httpd 响应给客户端 httpd 起到了反向代理的作用 后端应用程序服务器可以预先创建子进程，这样避免了每次请求都必须创建和销毁子进程带来的开销。 对于 php 而言还存在另一中 FCGI 模式。php 解释功能可作为 httpd 的一个模块存在，httpd 可直接执行 php 脚本，无需创建和销毁子进程。此时 httpd 既是一个静态 web 服务器，也充当应用程序服务器。这种模式也存在一定缺陷: web 服务器和应用程序服务器无法分离开 每个执行 php 的 httpd 进程都必需独自解析 php 脚本，无法利用 php 的加速技术。 此 LAMP 的结构如下所示 1.4 LAMP 架构 一个经典的 LAMP 架构如上图所示，包括: l: Linux a: apache httpd m: 数据库存储系统，可以是 mysql, mariadb，mongo p: 后端应用程序的开发语言，可以是 php, perl, python]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.8 httpd 辅助工具]]></title>
    <url>%2F2018%2F03%2F18%2Flinux_mt%2F20-web-apache%2Fhttpd%E8%BE%85%E5%8A%A9%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[httpd 辅助工具 本章的最后一节我们来学习 httpd 提供了辅助工具的使用，包括: httpd: httpd 服务的主程序 apachectl：httpd自带的服务控制脚本，支持start和stop,restart； htpasswd：basic认证基于文件实现时，用到的账号密码文件生成工具； apxs：由httpd-devel包提供，扩展httpd使用第三方模块的工具； rotatelogs：日志滚动工具； suexec：访问某些有特殊权限配置的资源时，临时切换至指定用户身份运行； ab： apache benchmark 1. httpdhttpd[.event|worker] OPTIONS 作用: httpd 主程序 选项: -t: 仅对配置文件执行语法检查。程序在语法解析检查结束后立即退出，或者返回”0”(OK)，或者返回非0的值(Error)。如果还指定了”-D DUMP_VHOSTS”，则会显示虚拟主机配置的详细信息 -l: 输出一个静态编译在服务器中的模块的列表。它不会列出使用LoadModule指令动态加载的模块。 -L: 输出一个指令的列表，并包含了各指令的有效参数和使用区域。 -M: 输出一个已经启用的模块列表，包括静态编译在服务器中的模块和作为DSO动态加载的模块。 -v: 显示httpd的版本，然后退出。 -V: 显示httpd和APR/APR-Util的版本和编译参数，然后退出。 -X: 以调试模式运行httpd 。仅启动一个工作进程，并且服务器不与控制台脱离 -d serverroot: 将ServerRoot指令设置初始值为serverroot。它可以被配置文件中的ServerRoot指令所覆盖。 -f config: 在启动中使用config作为配置文件。如果config不以”/“开头，则它是相对于ServerRoot的路径 -k start|restart|graceful|stop|graceful-stop: 发送信号使httpd启动、重新启动或停止 。 -C directive: 在读取配置文件之前，先处理directive的配置指令。 -c directive: 在读取配置文件之后，再处理directive的配置指令。 -D parameter: 设置参数parameter ，它配合配置文件中的段，用于在服务器启动和重新启动时，有条件地跳过或处理某些命 -e level: 在服务器启动时，设置LogLevel为level 。它用于在启动时，临时增加出错信息的详细程度，以帮助排错。 -E file: 将服务器启动过程中的出错信息发送到文件file 。 -R directory: 当在服务器编译中使用了SHARED_CORE规则时，它指定共享目标文件的目录为directory 。 -h: 输出一个可用的命令行选项的简要说明。 -S: 显示从配置文件中读取并解析的设置结果(目前仅显示虚拟主机的设置) -T: 在启动/重启的时候跳过根文件检查 (该参数在Apache 2.2.17及其以后版本有效) -t 选项的扩展: httpd -t -D DUMP_VHOSTS : 显示虚拟主机的配置 httpd -t -D DUMP_RUN_CFG : show parsed run setting httpd -t -D DUMP_MODULES : 显示所有已经启动的模块 httpd -M : httpd -t -D DUMP_MODULES 的快捷方式 1234567891011121314151617$ httpd -lCompiled in modules: core.c mod_so.c http_core.c$ httpd -MLoaded Modules: core_module (static) so_module (static) http_module (static) access_compat_module (shared) actions_module (shared) .......$ httpd -tSyntax OK 2. apachectlapachectl OPTIONS 作用: 是slackware内附Apache HTTP服务器的script文件，可供管理员控制服务器 选项: configtest: 检查设置文件中的语法是否正确。 fullstatus: 显示服务器完整的状态信息。 graceful: 重新启动Apache服务器，但不会中断原有的连接。 help: 显示帮助信息。 restart: 重新启动Apache服务器。 start: 启动Apache服务器。 status: 显示服务器摘要的状态信息。 stop: 停止Apache服务器 说明: httpd 命令的所有选项， apachectl 均可用 3. htpasswdhtpasswd OPTIONS passwordfile username [password] 作用: 用于创建和更新储存用户名、域和用户基本认证的密码文件 参数: passwordfile: 密码文件的路经，使用 -n 选项时，无需此参数 username: 用户名 password: 密码，使用-b 选项时必需，默认显示提示符让用户输入密码 选项: -c：创建一个加密文件，文件已经存在会删除重建 -b：在命令行中一并输入用户名和密码而不是根据提示输入密码 -D：删除指定的用户 -n：不更新加密文件，只将加密后的用户名密码显示在屏幕上 -m：默认采用MD5算法对密码进行加密 -d：采用CRYPT算法对密码进行加密 -p：不对密码进行进行加密，即明文密码 -s：采用SHA算法对密码进行加密 1234567$ htpasswd -c /tmp/.httpd tao # 首次创建文件，需要使用 -cNew password:Re-type new password:Adding password for user tao$ htpasswd -b /tmp/.httpd pythoner python # 非首次创建不能使用 `-c` 否则会删除已有文件Adding password for user pythoner 3. curlcurl [options] [URL...] 作用: curl是基于URL语法在命令行方式下工作的文件传输工具 支持FTP, FTPS, HTTP, HTTPS, GOPHER, TELNET, DICT, FILE及LDAP等协议 支持HTTPS认证，并且支持HTTP的POST、PUT等方法， FTP上传， kerberos认证，HTTP上传，代理服务器， cookies， 用户名/密码认证， 下载文件断点续传，上载文件断点续传, http代理服务器管道（ proxy tunneling）， 甚至它还支持IPv6， socks5代理服务器,，通过http代理服务器上传文件到FTP服务器等等，功能十分强大。 options: -e/--referer &lt;URL&gt;: 来源网址 -A/--user-agent &lt;string&gt;: 设置用户代理发送给服务器 -H/--header &lt;line&gt;: 自定义首部信息传递给服务器 -I/--head 只显示响应报文首部信息 --basic: 使用HTTP基本认证 -u/--user &lt;user[:password]&gt;: 设置服务器的用户和密码 --cacert &lt;file&gt;: CA证书 (SSL) --compressed 要求返回是压缩的格式 --limit-rate &lt;rate&gt;: 设置传输速度 -0/--http1.0: 使用HTTP 1.0 --tcp-nodelay: 使用TCP_NODELAY选项 5. elinkselinks [OPTION]... [URL]... 作用: 文本浏览器 选项: -dump: 不进入交互式模式，而直接将URL的内容输出至标准输出； 6. httpd的压力测试工具市面上常见的 web 压力测试工具有以下几种: 命令行工具: ab, webbench, http_load, seige 图形化工具: jmeter, loadrunner 模拟真实请求: tcpcopy，网易开发，复制生产环境中的真实请求，并将之保存下来； ab [OPTIONS] URL 全称: apache benchmark 选项: -n：总请求数； -c：模拟的并行数； -k：以持久连接模式 测试； 附注: ulimit -n num 调整当前用户能同时打开的文件数]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.7 httpd 配置进阶]]></title>
    <url>%2F2018%2F03%2F17%2Flinux_mt%2F20-web-apache%2Fhttpd%E9%85%8D%E7%BD%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[httpd 配置进阶 我们来继续学习 httpd 的配置，本节属于高级配置篇，核心是配置httpd支持https。 1. 指定 httpd 服务的运行身份12User apacheGroup apache User 和 Group 指令用于指定以哪个用户的身份运行httpd服务进程。该帐户决定了 httpd 进程在本机的权限。千万不能以 root 用户运行我们的 httpd 进程，以免 httpd 被劫持导致整个机器被控制。 需要注意的是如果指定的帐户没有权限访问文件系统上的内容，即便 &lt;Directory&gt; 开放了访问接口也一样无法访问。因此 httpd 提供了 SUexec，用于在特定的目录内进行用户切换以便能够方便的访问到受限的文件，而不用更改文件的权限。SUexec有安全风险，一般也很少使用。 2. 页面压缩mod_deflate 模块提供了压缩功能。压缩可以节约带宽，但是会额外消耗CPU；同时，可能有些较老浏览器不支持。是否启用压缩取决于网络带宽与 CPU 哪个更加稀缺。 有些资源是可压缩的，例如文件文件，而有些资源本身已经是压缩的，比如图片，这些则无需压缩。httpd 的压缩功能配置如下: 12345678910111213141516171819202122232425262728293031323334# 1. 首先确认是否加载了 deflate 模块$ httpd -M|grep -i deflate deflate_module (shared)# 2. 没有加载，则在配置文件中加载 deflate_moduleLoadModule deflate_module modules/mod_deflate.so# 3. 配置压缩功能$ vim /etc/httpd/conf.d/compress.conf # 在单独配置文件中配置，方便取消SetOutputFilter DEFLATE # 添加一个过滤器 # mod_deflate configuration # 向过滤器添加压缩哪些内容# Restrict compression to these MIME typesAddOutputFilterByType DEFLATE text/plainAddOutputFilterByType DEFLATE text/htmlAddOutputFilterByType DEFLATE application/xhtml+xmlAddOutputFilterByType DEFLATE text/xmlAddOutputFilterByType DEFLATE application/xmlAddOutputFilterByType DEFLATE application/x-javascriptAddOutputFilterByType DEFLATE text/javascriptAddOutputFilterByType DEFLATE text/css# Level of compression (Highest 9 - Lowest 1)DeflateCompressionLevel 9 # 默认压缩级别# Netscape 4.x has some problems. # 特殊浏览器的特殊处理BrowserMatch ^Mozilla/4 gzip-only-text/html# Netscape 4.06-4.08 have some more problemsBrowserMatch ^Mozilla/4\.0[678] no-gzip# MSIE masquerades as Netscape, but it is fineBrowserMatch \bMSI[E] !no-gzip !gzip-only-text/html 3. 配置httpd支持httpsSSL会话是基于IP地址创建；所以单IP的主机上，仅可以使用一个https虚拟主机 3.1 SSL会话的简化过程 客户端发送可供选择的加密方式，并向服务器请求证书； 服务器端发送证书以及选定的加密方式给客户端； 客户端取得证书并进行证书验正： 验正证书来源的合法性；用CA的公钥解密证书上数字签名； 验正证书的内容的合法性：完整性验正 检查证书的有效期限； 检查证书是否被吊销； 证书中拥有者的名字，与访问的目标主机要一致； 客户端生成临时会话密钥（对称密钥），并使用服务器端的公钥加密此数据发送给服务器，完成密钥交换； 服务用此密钥加密用户请求的资源，响应给客户端； 3.2 配置httpd支持https配置 https 需要如下几个步骤: 为服务器申请数字证书。本地测试时，可以私建CA发证书 配置httpd支持使用ssl，及使用的证书； 测试基于https访问相应的主机； 私建 CA 发证参见18.4 私建CA.md 配置 ssl123456789# 1. 安装 httpd 的 ssl 功能模块yum -y install mod_ssl# 2. 编辑配置文件$ vim /etc/httpd/conf.d/ssl.conf DocumentRoot &quot;/var/www/html&quot;ServerName &quot;www.magedu.com:443&quot;SSLCertificateFile &quot;/etc/httpd/ssl/http_crt.pem&quot;SSLCertificateKeyFile &quot;/etc/httpd/ssl/http_key.pem&quot; 测试 https 服务我们可以在浏览器导入我们私建的 CA 直接在浏览器中进行测试，也可以通过 openssl 的 s_client 子命令进行测试 openssl s_client OPTIONS 作用: https 连接的客户端工具 选项: [-connect host:port]: 连接的主机和端口 [-CAfile filename]: CA 证书的位置]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.6 httpd2.4 基础配置]]></title>
    <url>%2F2018%2F03%2F16%2Flinux_mt%2F20-web-apache%2Fhttpd2.4%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[httpd2.4 基础配置 上一节我们详细介绍了httpd2.2 的配置，对比着 httpd2.2 本节我们来讲解 httpd2.4 的配置。 1. httpd-2.41.1 新特性相比于 httpd2.2 httpd2.4 有如下新特性: MPM支持运行为DSO机制；以模块形式按需加载； event MPM生产环境可用； 异步读写机制； 支持每模块及每目录的单独日志级别定义； 每请求相关的专用配置: 增强版的表达式分析器； 毫秒级持久连接时长定义； 基于FQDN的虚拟主机也不再需要 NameVirutalHost 指令； 新指令，AllowOverrideList； 支持用户自定义变量； 新模块： mod_proxy_fcgi mod_raltelimit mod_remoteip 1.2 配置文件12345678ll /etc/httpd/总用量 0drwxr-xr-x. 2 root root 37 8月 17 16:10 confdrwxr-xr-x. 2 root root 151 8月 17 16:08 conf.ddrwxr-xr-x. 2 root root 205 8月 17 15:01 conf.modules.dlrwxrwxrwx. 1 root root 19 2月 10 2018 logs -&gt; ../../var/log/httpdlrwxrwxrwx. 1 root root 29 2月 10 2018 modules -&gt; ../../usr/lib64/httpd/moduleslrwxrwxrwx. 1 root root 10 2月 10 2018 run -&gt; /run/httpd 主配置文件: /etc/httpd/conf/httpd.conf 辅助配置文件: /etc/httpd/conf.d/*.conf 模块配置文件: /etc/httpd/conf.modules.d/*.conf mpm 以DSO机制提供，配置文件为 /etc/httpd/conf.modules.d/00-mpm.conf 2. httpd2.4 配置httpd2.4 官方文档 http://httpd.apache.org/docs/2.4/mod/directives.html 2.1 修改监听的IP和PORTListen [IP-address:]portnumber [protocol] protocol: 限制必需通过 ssl 通信时，protocol 可定义为 https 2.2 持久连续KeepAliveTimeout num[ms] 支持毫秒级持久时间，默认单位为秒 2.3 MPMMPM支持运行为DSO机制，在/etc/httpd/conf.modules.d/00-mpm.conf中进行配置，启用要启用的MPM相关的LoadModule指令即可。1234$ cat /etc/httpd/conf.modules.d/00-mpm.conf|grep LoadModuleLoadModule mpm_prefork_module modules/mod_mpm_prefork.so#LoadModule mpm_worker_module modules/mod_mpm_worker.so#LoadModule mpm_event_module modules/mod_mpm_event.so 3. 访问控制机制3.1 基于IP的访问控制新增访问路径必须添加 Require 进行 ip 授权，否则新增路径不允许访问，所有的IP 访问控制必须放置在 RequireAll 容器中 允许所有主机访问：Require all granted 拒绝所有主机访问：Require all deny 控制特定的IP访问： Require ip IPADDR：授权指定来源的IP访问； Require not ip IPADDR：拒绝 IPADDR： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 控制特定的主机访问： Require host HOSTNAME：授权指定来源的主机访问； Require not host HOSTNAME：拒绝 HOSTNAME： FQDN：特定主机 domin.tld：指定域名下的所有主机 1234567# IP 访问控制 &lt;Directory &quot;/www/htdoc&quot;&gt; &lt;RequireAll&gt; Require all granted Require not ip 172.16.100.2 &lt;/RequireAll&gt;&lt;/Directory&gt; 4. 虚拟主机 基于FQDN的虚拟主机也不再需要NameVirutalHost指令； 注意：任意目录下的页面只有显式授权才能被访问； 12345678910# 定义虚拟主机&lt;VirtualHost *:80&gt; ServerName www.b.net DocumentRoot &quot;/apps/b.net/htdocs&quot; &lt;Directory &quot;/apps/b.net/htdocs&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt; 5. status页面1234567LoadModule status_module modules/mod_status.so&lt;Location /server-status&gt; SetHandler server-status &lt;RequireAll&gt; Require ip 172.16 &lt;/RequireAll&gt;&lt;/Location&gt; 练习题：分别使用httpd-2.2和httpd-2.4实现1234567891. 建立httpd服务，要求： (1) 提供两个基于名称的虚拟主机： www1.stuX.com，页面文件目录为/web/vhosts/www1；错误日志为/var/log/httpd/www1/error_log，访问日志为/var/log/httpd/www1/access_log； www2.stuX.com，页面文件目录为/web/vhosts/www2；错误日志为/var/log/httpd/www2/error_log，访问日志为/var/log/httpd/www2/access_log； (2) 通过www1.stuX.com/server-status输出其状态信息，且要求只允许提供账号的用户访问； (3) www1不允许192.168.1.0/24网络中的主机访问； 2. 为上面的第2个虚拟主机提供https服务，使得用户可以通过https安全的访问此web站点； (1) 要求使用证书认证，证书中要求使用国家（CN），州（Beijing），城市（Beijing），组织为(MageEdu)； (2) 设置部门为Ops, 主机名为www2.stuX.com；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.5 httpd2.2 的基础配置]]></title>
    <url>%2F2018%2F03%2F15%2Flinux_mt%2F20-web-apache%2Fhttpd2.2%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[httpd2.2 的基础配置 本节我们来讲解 httpd2.2 的基础配置 1. httpd-2.2 配置文件格式1234$ grep &quot;^###&quot; /etc/httpd/conf/httpd.conf### Section 1: Global Environment### Section 2: &apos;Main&apos; server configuration### Section 3: Virtual Hosts httpd2.2 的主配置文件是：/etc/httpd/conf/httpd.conf，其分成三个部分: Section 1: Global Environment 全局配置 Section 2: ‘Main’ server configuration 主服务配置段 Section 3: Virtual Hosts 虚拟主机配置段 下面是一段配置示例1234567891011ServerRoot &quot;/etc/httpd&quot;Include conf.modules.d/*.conf&lt;Directory /&gt; # 目录访问权限配置 AllowOverride none Require all denied&lt;/Directory&gt;&lt;IfModule dir_module&gt; # IfModule 判断动态模块是否存在，动态配置 DirectoryIndex index.html&lt;/IfModule&gt; 配置的格式为 directive value directive：配置参数，不区分字符大小写； value：参数值，为路径时，是否区分字符大小写，取决于文件系统； 2. httpd-2.2 常用配置httpd2.2 的官方文档: http://httpd.apache.org/docs/2.2/ 2.1 修改监听的IP和PORTListen [IP:]PORT 省略IP表示监听本地所有地址 Listen指令可重复出现多次，以监听多个IP地址和端口； Listen 80 Listen 8080 修改监听socket(不是新增)，需要重启服务进程才能生效； 2.2 持久连续Persistent Connection1234# 持久链接配置相关参数KeepAlive On|Off # 是否启用持久连接KeepAliveTimeout 15 # 持久链接最大连接时长MaxKeepAliveRequests 100 # 持久链接最多处理的请求数 前面我们说过 tcp 连接有长连接短连接之分 长连接能降低请求响应的时间 但对并发访问量较大的服务器，长连接机制会使得后续某些请求无法得到正常 响应；因此通常的折衷策略是，采用长连接，但是使用较短的持久连接时长，以及较少的请求数量。 http 与长连接相关的参数包括 KeepAlive On|Off: 是否启用持久连接 KeepAliveTimeout time: 持久链接最大连接时长,httpd-2.4 支持毫秒级持久时间 MaxKeepAliveRequests: 单个持久连接能够处理的对大请求数 2.3 MPMMPM(Multipath Process Module) 多道处理模块,用来确定 httpd 响应用户请求的模型。对于 httpd2.2: 不支持同时编译多个MPM模块，所以只能编译选定要使用的那个。 CentOS 6的rpm包为此专门提供了三个应用程序文件，httpd(prefork), httpd.worker, httpd.event，分别用于实现对不同的MPM机制的支持。 默认使用的为/usr/sbin/httpd，其为prefork的MPM模块 查看 httpd2.2 当前使用的 MPM 以及修改默认的 MPM 的方式如下: 1234567891011121314151617# 1. 查看当前使用MPM模式ps aux|grep httpd# 2. 查看httpd程序的模块列表：## 查看静态编译的模块(先确定使用的MPM):httpd -lhttpd.event -lhttpd.worker -l## 查看静态编译及动态编译的模块:httpd -Mhttpd.envent -Mhttpd.woker -M# 3. 更改 service 使用的 httpd 程序vim /etc/sysconfig/httpd HTTPD=/usr/sbin/httpd.&#123;worker,event&#125; # 修改 HTTPD 参数，重启服务进程方可生效 prefork的配置参数123456789# /etc/httpd/conf/httpd.conf&lt;IfModule prefork.c&gt; StartServers 8 ＃ 服务启动时，启动的进程数 MinSpareServers 5 # 最小空闲进程数 MaxSpareServers 20 # 最大空闲进程数 ServerLimit 256 # 为 MaxClients 提供的最大进程数，通常等于 MaxClients MaxClients 256 # 并发的最大客户端请求数 MaxRequestsPerChild 4000 # 一个进程能处理的请求总数，超过会自动销毁&lt;/IfModule&gt; worker的配置参数123456789# /etc/httpd/conf/httpd.conf&lt;IfModule worker.c&gt;StartServers 4 # 服务器启动时启动的进程数MaxClients 300 MinSpareThreads 25 # 最小的空闲线程数MaxSpareThreads 75 # 最大的空闲线程数ThreadsPerChild 25 # 每个进程启动的线程数MaxRequestsPerChild 0 # 每个线成能处理的请求总数，超过会自动销毁，0 表示无限&lt;/IfModule&gt; event 的配置event 在 httpd2.2 中尚且属于测试阶段，不建议在线上使用 2.4 DSOLoadModule mod_name mod_path 作用: 实现模块加载: 参数: mod_name: 模块的名称 mod_path: 模块的路经，可使用相对路径：相对于ServerRoot 123LoadModule alias_module modules/mod_alias.so# modules/mod_alias.so -- &gt; /etc/httpd/modules/mod_alias.so# /etc/httpd/modules ---&gt; /usr/lib64/httpd/modules 2.5 ‘Main’ server配置DocumentRoot Dir 作用: 文档路径映射,DoucmentRoot指向的路径为URL路径的起始位置, 其相当于站点URL的根路径； 12DocumentRoot &quot;/var/www/html&quot;(FileSystem) /var/www/html/index.html --&gt; (URL)/index.html ServerName www.example.com:80 作用: 配置主服务的标识 默认: 未设置此参数时， httpd 会自动反解监听的 IP 地址，反解失败，则默认为当前主机的主机名 可以随意设置，如果没有注册 DNS 域名，也可以设置成 ip 地址 2.6 定义站点主页面DirectoryIndex index.html index.html.var 作用: 配置当用户访问 URL 的指向是一个目录时，httpd 应该默认响应的内容 附注: 找不到主页面时，httpd 通过 /etc/httpd/conf.d/weibocom.conf 提供了一个默认主页面 2.7 定义路径别名Alias /URL/ &quot;/PATH/TO/SOMEDIR/&quot; 作用: 定义 url 访问资源的路经别名 1234567DocumentRoot &quot;/www/htdocs&quot;http://www.magedu.com/download/a.index --&gt; /www/htdocs/download/a.indexAlias /download/ &quot;/rpms/pub/&quot;http://www.magedu.com/download/a.index --&gt; /rpms/pub/a.indexhttp://www.magedu.com/images/logo.png ---&gt; /www/htdocs/images/logo.png 2.8 设定默认字符集AddDefaultCharset UTF-8 作用: 设定默认字符集 2.9 日志设定123456789# 错误日志：ErrorLog logs/error_log # 错误日志的路经LogLevel warn # 日志的级别# 定义日志格式LogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b \&quot;%&#123;Referer&#125;i\&quot; \&quot;%&#123;User-Agent&#125;i\&quot;&quot; combinedLogFormat &quot;%h %l %u %t \&quot;%r\&quot; %&gt;s %b&quot; commonCustomLog logs/access_log combined # 访问日志的路经，combined 为 LogFormat 名 LogLevel level 作用: 日志级别 可选值：debug, info, notice, warn, error, crit, alert, emerg LogFormat 格式化字符串http://httpd.apache.org/docs/2.2/mod/mod_log_config.html#formats 标志宏 作用 %h 客户端IP地址 %l Remote User, 通常为一个减号（“-”） %u Remote user (from auth; may be bogus if return status (%s) is 401)；非为登录访问时，其为一个减号 %t 服务器收到请求时的时间 %r First line of request，即表示请求报文的首行；记录了此次请求的“方法”，“URL”以及协议版本 %&gt;s 响应状态码 %b 响应报文的大小，单位是字节；不包括响应报文的http首部 %{Referer}i 请求报文中首部“referer”的值；即从哪个页面中的超链接跳转至当前页面的 %{User-Agent}i 请求报文中首部“User-Agent”的值；即发出请求的应用程序 3. httpd2.2 访问控制3.1 访问控制机制访问控制值的时允许哪些用户访问哪些站点资源 用户可以通过来源地址 或 账号 指定， 资源可以通过文件系统路径 或 URL 指定 因此 httpd 的访问控制机制有如下四中实现方式: 基于来源地址，通过文件路径实现访问控制机制 基于来源地址，通过 url 实现访问控制机制 基于账号，过文件路径实现访问控制机制 基于账号，通过 url 实现访问控制机制 httpd2.2 与 httpd2.4 最大的不同之处在于，httpd2.4 如果未授权，默认是所有用户都无法访问的，而 http2.2 则默认允许访问。因此当在 httpd2.4 中添加 Alias 路经别名，或更改 DocumentRoot 时，必需配置相应的访问权限。 资源界定资源的文件系统路径由如下几种配置方式1234567891011&lt;Directory &quot;&quot;&gt; # 目录...&lt;/Directory&gt;&lt;File &quot;&quot;&gt; # 单文件...&lt;/File&gt;&lt;FileMatch &quot;PATTERN&quot;&gt; # 文件路经匹配的正则表达式...&lt;/FileMatch&gt; URL 有如下两种配置方式1234567&lt;Location &quot;&quot;&gt; # URL 地址...&lt;/Location&gt;&lt;LocationMatch &quot;&quot;&gt; # URL 匹配的正则表达式...&lt;/LocationMatch&gt; 3.1 Directory 中“基于源地址”实现访问控制：1234&lt;Directory &quot;/var/www/html&quot;&gt;Options All，None，Indexes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViewsAllowOverride None&lt;/Directory&gt; http2.2 访问控制参数如下: Options 作用: 后跟1个或多个以空白字符分隔的“选项”列表； 选项: Indexes：指明的URL路径下不存在与定义的主页面资源相符的资源文件时，返回索引列表给用户； – 危险，生产环境不能启用 FollowSymLinks：允许跟踪符号链接文件所指向的源文件；– 危险 None：关闭所有选项 All：启动全部选项 说明: 选项前加上-，表示关闭，但是只能要么都有-，要么都没有 AllowOverride 作用: 与访问控制相关的指令可以放在.htaccess文件，每个目录下都可以有一个；用于自定义每个目录的访问权限 启用 .htaccess 会对性能产生重大影响，不建议启用 Directory 中的配置相当于全局配置 选项: All: Directory 中的全局配置，覆盖 htaccess 中的配置 None：Directory 中的全局配置，不会覆盖 htaccess 中的配置 order和allow、deny 作用: 基于来源地址的访问控制 order：定义生效次序；写在后面的表示默认法则； Order allow，deny: 白名单 Order deny，allow: 黑名单 Allow from IP, Deny from IP: 注明来源IP 来源地址： IP NetAddr: 子网 172.16 172.16.0.0 172.16.0.0/16 172.16.0.0/255.255.0.0 1234567&lt;Directory &quot;/www/htdoc&quot;&gt; AllowOverride None Options Indexes FollowSymLinks Order allow,deny Allow from 192.168.1 # Deny from 192.168.1.104&lt;/Directory&gt; 3.2 基于用户的访问控制WWW-Authenticate（认证质询）是 http 协议早期提供的用户认证机制。当用户请求受控资源时，服务器响应 401，拒绝客户端请求，并说明要求客户端提供账号和密码；浏览器接收到响应时，会弹出认证窗口，客户端用户填入账号和密码后再次发送请求报文；认证通过时，则服务器发送响应的资源。需要用户认证后方能访问的路径；应该通过名称对其进行标识，以便于告知用户认证的原因。 WWW-Authenticate 认证方式有两种： basic认证：会明文传输帐号和密码，不安全 digest认证： 用户的账号和密码可存储在文本文件，SQL数据库，ldap目录存储。但是通常都是存在本地的文本文件中，因为 httpd 访问 mysql 的模块是非标准模块，需要单独编译安装。现在 web 站点基本都是通过表单进行身份认证，认证质询因为安全性和便利性的问题，其实很少使用。 basic认证配置示例12345678910111213# 1. 定义安全域&lt;Directory &quot;&quot;&gt; Options None AllowOverride None AuthType Basic AuthName &quot;String“ # 认证提时字符串 AuthUserFile &quot;/PATH/TO/HTTPD_USER_PASSWD_FILE&quot; # 帐号密码文件路经 Require user username1 username2 ... # 允许访问的用户 # Require valid-user # 允许账号文件中的所有用户登录访问&lt;/Directory&gt;# 2. 使用 htpassword 命令创建帐号密码文件$ htpassword -cb /etc/httpd/.httpd tao tao 基于组账号进行认证123456789101112131415161718# 1. 定义安全域&lt;Directory &quot;&quot;&gt; Options None AllowOverride None AuthType Basic AuthName &quot;String“ AuthUserFile &quot;/PATH/TO/HTTPD_USER_PASSWD_FILE&quot; AuthGroupFile &quot;/PATH/TO/HTTPD_GROUP_FILE&quot; Require group grpname1 grpname2 ...&lt;/Directory&gt;# 2. 创建用户账号和组账号文件； # 组文件：每一行定义一个组 # GRP_NAME: username1 username2 ...&gt; htpasswd -m /etc/httpd/conf.d/.http_passwd tom # 创建帐号文件&gt; vim /etc/httpd/conf.d/.http_group # 创建组文件 admin: tom jerry # tom, jerry 为 admin 组 4. 虚拟主机通常如果我们在同一主机上提供了多个彼此毫不相干的服务时，通常是将他们隔离开，放在不同的域名下进行管理，而不是放在同一域名下；以免某一站点被劫持，所有站点都被劫持。虚拟主机就是帮助我们实现一个物理服务器服务多个网站的功能。 web 服务通过 tcp 进行通信，即每个服务都监听在一个特定的套接子socket 上，socket = ip + 端口，所以实现虚拟主机就有如下几种方法: IP相同，但端口不同； IP不同，但端口均为默认端口； FQDN不同: 为不同的 web 服务配置不同的域名 需要注意的是请求报文首部中的 Host 字段会保留浏览器中用户请求的域名，因此服务器端可以通过解析Host 字段来路由请求。httpd 中心主机与虚拟主机不能混用，httpd2.2 中使用虚拟主机必需禁用’main’主机,禁用方法：注释中心主机的DocumentRoot指令即可。http2.4 中启用虚拟主机后，中心主机会自动禁用。 4.1 虚拟主机的配置方法所有能用在中心主机的配置，均可以用在虚拟主机中 123456789101112131415&lt;VirtualHost IP:PORT&gt; ServerName FQDN DocumentRoot &quot;&quot; # 其它可用指令： ServerAlias：虚拟主机的别名；可多次使用； ErrorLog： CustomLog： &lt;Directory &quot;&quot;&gt; ... &lt;/Directory&gt; Alias ...&lt;/VirtualHost&gt; 4.2 基于IP的虚拟主机示例：12345678910111213141516171819&lt;VirtualHost 192.168.1.120:80&gt; ServerName web1.tao.com DocumentRoot &quot;/vhosts/web1/htdocs&quot; &lt;Directory &quot;/vhosts/web1/htdocs&quot;&gt; Options None AllowOverride None Require all granted &lt;/Directory&gt;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.7:80&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.8:80&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 4.3 基于端口的虚拟主机：1234567891011121314&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.a.com DocumentRoot &quot;/www/a.com/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:808&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:8080&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 4.4 基于 hostname 的虚拟主机：1234567891011121314151617# 重要，http2.2 中需要指明 NameVirtualHostNameVirtualHost 172.16.100.6:80&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.a.com DocumentRoot &quot;/www/a.com/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.b.net DocumentRoot &quot;/www/b.net/htdocs&quot;&lt;/VirtualHost&gt;&lt;VirtualHost 172.16.100.6:80&gt; ServerName www.c.org DocumentRoot &quot;/www/c.org/htdocs&quot;&lt;/VirtualHost&gt; 5. status页面123456LoadModule status_module modules/mod_status.so&lt;Location /server-status&gt; SetHandler server-status Order allow,deny Allow from 172.16&lt;/Location&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.4 apache httpd 简介]]></title>
    <url>%2F2018%2F03%2F14%2Flinux_mt%2F20-web-apache%2Fapache-httpd%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[apache httpd 简介 httpd 是 ASF(apache software foundation, apache 软件基金会)下的顶级项目，也是目前市场占有率最高的 web 服务器。本节我们就来对 httpd 做一个概括行的介绍。在之后的章节我们再来详细的学习 httpd 的配置。 1. httpd 简介1.1 httpd 版本httpd 目前有如下主流的版本 httpd 1.3：官方已经停止维护； httpd 2.0： httpd 2.2: Centos6 base 仓库的默认安装版本 httpd 2.4：目前最新稳定版，Centos7 base 仓库的默认安装版本 httpd2.2 和 httpd2.4 目前都有使用，他们之间存在比较大的差异。在介绍 httpd 的配置时，我们将首先介绍 http2.2，然后针对 httpd2.4 的不同之处单独讲解。 1.2 httpd的特性httpd 具有如下的一些关键特性: 高度模块化： core + modules DSO：dynamic shared object 动态共享对象 MPM：Multipath processing Modules (多路处理模块) prefork：多进程模型, 每个进程响应一个请求； 一个主进程：负责生成子进程及回收子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； n个子进程：每个子进程处理一个请求； 工作模型：会预先生成几个空闲进程，随时等待用于响应用户请求；有最大空闲数和最小空闲数； worker：多进程多线程模型，每线程处理一个用户请求； 一个主进程：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 多个子进程：每个子进程负责生成多个线程； 每个线程：负责响应用户请求； 并发响应数量：m*n m：子进程数量 n：每个子进程所能创建的最大线程数量； event：事件驱动模型，多进程模型，每个进程响应多个请求； 一个主进程 ：负责生成子进程；负责创建套接字；负责接收请求，并将其派发给某子进程进行处理； 子进程：基于事件驱动机制直接响应多个请求； 适用版本: httpd-2.2: 仍为测试使用模型； httpd-2.4：event可生产环境中使用； 2. httpd安装httpd 可以通过 base 仓库的 rpm 包直接安装，也可以编译安装。通常除非需要定制新功能，或其它原因，不建议采用编译安装的方式。一是对规模部署不便，二是安装过程繁琐，需要准备编译环境，还需要额外的配置。 2.1 httpd2.2 与 httpd2.4 的对比下面是 httpd2.2 httpd2.4 安装，管理，以及配置文件路经的对比 1234567$ ll /etc/httpd/总用量 0drwxr-xr-x. 2 root root 37 5月 22 19:20 confdrwxr-xr-x. 2 root root 151 5月 8 09:35 conf.dlrwxrwxrwx. 1 root root 19 2月 10 2018 logs -&gt; ../../var/log/httpdlrwxrwxrwx. 1 root root 29 2月 10 2018 modules -&gt; ../../usr/lib64/httpd/moduleslrwxrwxrwx. 1 root root 10 2月 10 2018 run -&gt; /run/httpd 配置 httpd2.2 httpd2.4 配置文件 /etc/httpd/conf/httpd.conf/etc/httpd/conf.d/*.conf /etc/httpd/conf/httpd.conf/etc/httpd/conf.d/*.conf/etc/httpd/conf.modules.d/*.conf(模块配置) 服务脚本 /etc/rc.d/init.d/httpd/etc/sysconfig/httpd(脚本配置) /usr/lib/systemd/system/httpd.service 主程序 /usr/sbin/httpd/usr/sbin/httpd.event/usr/sbin/httpd.worker /usr/sbin/httpd支持MPM的动态切换 访问日志 /var/log/httpd/access_log /var/log/httpd/access_log 错误日志 /var/log/httpd/error_log /var/log/httpd/error_log 站点文档 /var/www/html /var/www/html 模块文件 /usr/lib64/httpd/modules /usr/lib64/httpd/modules 服务控制 chkconfig httpd on,off systemctl enable,disable httpd.service service {start,stop,restart,status,reload} httpd systemctl {start,stop,restart,status} httpd 2.2 http2.4 rpm 包123456$ yum list all httpd*httpd.x86_64 2.4.6-80.el7.centos.1 updateshttpd-devel.x86_64 2.4.6-80.el7.centos.1 updateshttpd-itk.x86_64 2.4.7.04-2.el7 epel httpd-manual.noarch 2.4.6-80.el7.centos.1 updateshttpd-tools.x86_64 2.4.6-80.el7.centos.1 updates httpd 相关rmp 包: httpd: httpd web 服务的主程序包 httpd-tools: httpd 相关的辅助工具 httpd-manual: httpd 文档 httpd123456789101112131415161718192021222324252627$ rpm -ql httpd|grep -v share/etc/httpd # 配置文件/etc/httpd/conf /etc/httpd/conf.d/etc/httpd/conf.d/*/etc/httpd/conf.modules.d/etc/httpd/conf/httpd.conf/etc/httpd/modules # httpd 模块所在目录/usr/lib64/httpd/modules/usr/sbin/apachectl # httpd 相关的程序/usr/sbin/fcgistarter/usr/sbin/htcacheclean/usr/sbin/httpd/usr/sbin/rotatelogs/usr/sbin/suexec/var/cache/httpd/var/cache/httpd/proxy/var/cache/httpd # 目录与日志文件/var/cache/httpd/proxy/var/lib/dav/var/log/httpd/var/www/var/www/cgi-bin/var/www/html httpd-tools1234567$ rpm -ql httpd-tools/usr/bin/ab # web 服务测试工具/usr/bin/htdbm/usr/bin/htdigest/usr/bin/htpasswd #/usr/bin/httxt2dbm/usr/bin/logresolve]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.3 http协议进阶]]></title>
    <url>%2F2018%2F03%2F13%2Flinux_mt%2F20-web-apache%2Fhttp%E5%8D%8F%E8%AE%AE%E8%BF%9B%E9%98%B6%2F</url>
    <content type="text"><![CDATA[http协议进阶 在20.2 http协议基础我们对 http 协议做了简单介绍，本节我们来学 http 协议更深入的细节,包括: http 的状态追踪机制 http 协议的报文 市面上有很多的协议抓包分析工具，常见的有 tcpdump, tshark, wireshark，常见浏览器也提供了 http 协议的网络分析工具，大家可以学习了解了解。 1 http状态追踪http 协议是无状态的(stateless),服务器无法持续追踪访问者来源。因此在 http 协议的基础上有 cookie 和 session 机制用来帮助状态追踪。 2. http 报文请求报文 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 响应报文 1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; http 报文内容http 的报文格式如上图所示，各个字段的含义如下 method: 请求方法，标明客户端希望服务器对资源执行的动作 – GET、HEAD、POST version: HTTP/&lt;major&gt;.&lt;minor&gt;，http 协议的版本 status: 三位数字，如200，301, 302, 404, 502; 标记请求处理过程中发生的情况； reason-phrase：状态码所标记的状态的简要描述； headers：每个请求或响应报文可包含任意个首部；每个首部都有首部名称，后面跟一个冒号，而后跟上一个可选空格，接着是一个值； entity-body：请求时附加的数据或响应时附加的数据； 2.1 method(方法)：http 协议的请求方法: GET：从服务器获取一个资源； HEAD：只从服务器获取文档的响应首部； POST：向服务器发送要处理的数据； PUT：将请求的主体部分存储在服务器上； DELETE：请求删除服务器上指定的文档； TRACE：追踪请求到达服务器中间经过的代理服务器； OPTIONS：请求服务器返回对指定资源支持使用的请求方法； 3.status(状态码)http 协议的状态码: 1xx：100-101, 信息提示； 2xx：200-206, 成功 3xx：300-305, 重定向 4xx：400-415, 错误类信息，客户端错误 5xx：500-505, 错误类信息，服务器端错误 常用的状态码： 200： 成功，请求的所有数据通过响应报文的entity-body部分发送；OK 301： 永久重定向，请求的URL指向的资源已经被删除；但在响应报文中通过首部Location指明了资源现在所处的新位置；Moved Permanently 302： 临时重定向，与301相似，但在响应报文中通过Location指明资源现在所处临时新位置; Found 304： 条件式请求，客户端发出了条件式请求，但服务器上的资源未曾发生改变，则通过响应此响应状态码通知客户端；Not Modified 401： 需要输入账号和密码认证方能访问资源；Unauthorized 403： 请求被禁止；Forbidden 404： 服务器无法找到客户端请求的资源；Not Found 500： 服务器内部错误；Internal Server Error 502： 代理服务器从后端服务器收到了一条伪响应；Bad Gateway 4. headers(首部)http 的首部是形如 Name: Value的键值对，可分为: 通用首部 请求首部 响应首部 实体首部 扩展首部 123456789101112131415161718Cache-Control:public, max-age=600Connection:keep-aliveContent-Type:image/pngDate:Tue, 28 Apr 2015 01:43:54 GMTETag:&quot;5af34e-ce6-504ea605b2e40&quot;Last-Modified:Wed, 08 Oct 2014 14:46:09 GMTAccept:image/webp,*/*;q=0.8Accept-Encoding:gzip, deflate, sdchAccept-Language:zh-CN,zh;q=0.8Cache-Control:max-age=0Connection:keep-aliveHost:access.redhat.comIf-Modified-Since:Wed, 08 Oct 2014 14:46:09 GMTIf-None-Match:&quot;5af34e-ce6-504ea605b2e40&quot;Referer:https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/Installation_Guide/index.htmlUser-Agent:Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36 4.1 通用首部： Date： 报文的创建时间 Connection：连接状态，如keep-alive, close Via：显示报文经过的中间节点 Cache-Control：控制缓存 Pragma： 4.2 请求首部： 基础请求首部 Accept：通知服务器自己可接受的媒体类型； Accept-Charset： Accept-Encoding：接受编码格式，如gzip Accept-Language：接受的语言 Client-IP： Host： 请求的服务器名称和端口号 Referer：包含当前正在请求的资源的上一级资源； User-Agent：客户端代理 条件式请求首部： Expect： If-Modified-Since：自从指定的时间之后，请求的资源是否发生过修改； If-Unmodified-Since： If-None-Match：本地缓存中存储的文档的ETag标签是否与服务器文档的Etag不匹配； If-Match： 安全请求首部： Authorization：向服务器发送认证信息，如账号和密码； Cookie： 客户端向服务器发送cookie Cookie2： 代理请求首部： Proxy-Authorization： 向代理服务器认证 4.3 响应首部： 信息性： Age：响应持续时长 Server：服务器程序软件名称和版本 协商首部：某资源有多种表示方法时使用 Accept-Ranges：服务器可接受的请求范围类型 Vary：服务器查看的其它首部列表； 安全响应首部： Set-Cookie：向客户端设置cookie； Set-Cookie2： WWW-Authenticate：来自服务器的对客户端的质询认证表单 4.4 实体首部： 基础实体首部 Allow： 列出对此实体可使用的请求方法 Location：告诉客户端真正的实体位于何处 Content-Encoding： 实体的编码方式 eg： gzip Content-Language： Content-Length： 主体的长度 Content-Location： 实体真正所处位置； Content-Type：主体的对象类型，MIME 类型 缓存相关： ETag：实体的扩展标签； Expires：实体的过期时间； Last-Modified：最后一次修改的时间]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.2 http协议基础]]></title>
    <url>%2F2018%2F03%2F12%2Flinux_mt%2F20-web-apache%2Fhttp%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[http协议基础 前面我们了解了 web 的基础概念，本节来对 http 协议做一个更加详细的描述。 1. http 协议http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html，有如下几个版本 http/0.9：原型版本，功能简陋 http/1.0: 增加了 cache, MIME, method, MIME：Multipurpose Internet Mail Extesion 多功能互联网邮件扩展 method：支持多种 http 方法，包括 GET， POST， HEAD，PUT， DELETE，TRACE， OPTIONS http/1.1：增强了缓存功能；spdy http/2.0：rfc 1.2 http 报文格式http 报文有请求报文，响应报文组成，一次http事务包括完整的请求&lt;--&gt;响应 过程。报文格式如下所示。我们会在之后的章节中详细讲解 http 报文中各个字段的含义及作用，目前做了解即可。 请求报文 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 示例如下:1234567Host: ss1.bdstatic.comUser-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0Accept: text/css,*/*;q=0.1Accept-Language: zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3Accept-Encoding: gzip, deflate, brReferer: https://www.baidu.com/Connection: keep-alive 响应报文 1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; 示例如下:1234567891011121314HTTP/1.1 200 OKContent-Encoding: gzipContent-Type: text/html;charset=utf-8&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot; /&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;p&gt;this is http response&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 1.1 MIMEMIME: Multipurpose Internet Mail Extesion 作用: 多功能互联网邮件扩展，通过文本协议(http)发送非文本数据 MIME 类型: 媒体类型，由 http header 的 Content-Type 字段标识，决定了资源由哪一个浏览器外部插件打开 格式: major/minor text/html text/plain image/jpeg 1234567BDPAGETYPE: 1BDQID: 0xbbfea62700012a90Cache-Control: privateConnection: Keep-AliveContent-Encoding: gzipContent-Type: text/html # MIME 类型..... 1.3 http 长短链接http请求处理中的有两种连接模式： 非保持连接（短连接）：完成当前 http 事务后即断开 tcp 链接，下次请求需要重新建立链接 保持连接（又称长连接）：keep-alive，http 会复用当前的 tcp 链接。 tcp 链接的建立与拆除需要耗费时间，因此复用 tcp 链接能降低请求响应的时间，但是 tcp 链接会占用 web server 的 socket 文件，当链接过多时，其他客户将无法建立链接。所以是否启用保持链接取决于 tcp 链接的使用状态。通常情况下，http 1.1 中默认就会启动保持链接功能，服务器会在 tcp 链接达到一定时间，或者处理足够多的请求时自动断开链接，以免资源浪费。 1.4 http请求过程一次完整的 http 请求包括了如下过程: 建立或处理连接：接收请求或拒绝请求； 接收请求：接收来自于网络上的主机请求报文中对某特定资源的一次请求的过程； 处理请求：对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； 访问资源：获取请求报文中请求的资源； 构建响应报文： 发送响应报文： 记录日志： 2. 并发访问响应模型web server 面对的时互联网上的所有潜在用户，因此同一时刻可能有多个用户访问我们的主机。面对多用户请求，web server 有如下几种访问响应模型: 单进程I/O模型：启动一个进程处理用户请求；这意味着，一次只能处理一个请求，多个请求被串行响应； 多进程I/O结构：并行启动多个进程，每个进程响应一个请求； 复用的I/O结构：一个进程响应n个请求； 多线程模式：一个进程生成n个线程，一个线程处理一个请求； 事件驱动(event-driven)：一个进程直接n个请求； 复用的多进程I/O结构：启动多个（m）个进程，每个进程生成（n）个线程； 响应的请求的数量：m*n]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[17.1 web服务基础概念]]></title>
    <url>%2F2018%2F03%2F11%2Flinux_mt%2F20-web-apache%2Fweb%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[web服务基础概念 本章开始，我们将学习 Linux 运维中最重要的 web 服务。我们将学习: web 的基本概念和 http 协议 web 服务器 apache httpd 的安装与配置 web 服务也就是我们常说的网站开发，是构建在 http 协议上的 C/S 架构的应用程序。web serve 监听在 80 端口，浏览器就是我们的客户端。通过浏览器我们就可以访问 web 站点的内容。本节我们就来对 web 框架和浏览器的请求流程做一个概括性的描述。 1. web 架构最简单的 web 应用构建在我们通常称之为 LAMP 的架构上，如下图所示。 静态层称为 web 服务器(又叫静态资源服务器)，动态层称为应用程序服务器。之所以有动态和静态之分，是因为我们 web 资源分为两种类型 静态资源: 无须服务端做出额外处理,比如 .jpg, .png, .gif, .html, txt, .js, .css, .mp3, .avi 动态资源: 服务端需要通过执行程序做出处理，发送给客户端的是程序的运行结果，比如 .php, .jsp。 即我们看到的 web 页面的部分内容不是事先就存在的，而是根据每个访问的客户动态生成的，其中定制了每个人的特定信息。动态资源能根据用户的请求，到数据库中读取用户个人信息，然后执行再生成特定的页面供用户访问。 URL通常一个页面中展示的资源可能有多个，每个资源都需要单独请求。每个资源由 URL(Uniform Resource Locator,统一资源定位符号)进行标识。URL 的格式为: &lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt; scheme: 协议类型，eg: http,https, ftp host: 主机 ip 地址 port: 端口 path: 资源在主机上的路经 params: 参数 http://www.magedu.com/bbs/hello;gender=f query： http://www.magedu.com/bbs/item.php?username=tom&amp;title=abc frag：https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/ web 服务器常见的 web 服务器与应用程序有以下几种: web 服务器(静态资源服务器) httpd (apache) nginx lighttpd 应用程序服务器： 使用 C# 作为开发语言的 .Net 服务器: IIS 使用 java jsp 作为开发语言的 .jsp 服务器: tomcat, jetty, jboss, webshpere, weblogic 抛开动态层和数据层，客户端和 web 服务器就可以构成简单的 web 站点。 通信过程web 是构建在 http 协议上的应用。http协议全称为超文本传输协议(hyper text transfer protocol),用来协议传输 html 这种超文本的应用层协议， 工作于tcp 的 80。 整个 web 请求和响应会有如下过程: web server 监听在 tcp 80 端口 用户在浏览器中输入网址，经 DNS 解析得到 ip 后，发起对 web server 的链接请求 通信双方基于 tcp 的三次握手建立 tcp 链接 web serve 收到用户的请求报文中对某一特定资源的请求 web server 对请求报文进行解析，获取客户端请求的资源及请求方法等相关信息； web server 获取请求的资源，构建响应报文，经 tcp 链接发送响应报文给客户端，并记录日志 浏览器接收响应报文并展示给用户 通信结束后，tcp 四次挥手断开 tcp 链接，通信结束。 web 技术栈web 开发，分为前段和后端开发，前端指的是浏览器展示的页面，后端通常是应用程序部分。后端依所使用的开发语言而异，前端开发运用到的技术有: html：hyper text mark language，超文本标记语言 css: Cascading Style Sheet 样式表 js：JavaScript, 客户端脚本 下面是一个简单的 html 的示例，这些技术如果了解过 web 开发很容易就会明白他们有什么作用。12345678910&lt;html&gt; &lt;head&gt; &lt;title&gt;TITLE&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;&lt;/h1&gt; &lt;p&gt; blabla... &lt;a href="http://www.magedu.com/download.html"&gt; bla... &lt;/a&gt; &lt;/p&gt; &lt;h2&gt; &lt;/h2&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.4 bind 高级配置]]></title>
    <url>%2F2018%2F03%2F10%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2Fbind%E9%AB%98%E7%BA%A7%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[bind 高级配置 本节是 bind 配置的高级篇，实现 主从 DNS 服务器配置 DNS 子域授权 定义 DNS 的转发 DNS 访问控制 智能 DNS 1. 主从服务器DNS 的主从配置，是以域名解析的区域为基本单位的，也就是说如果一台主机上配置了多个 DNS 解析域，为哪个区域配置了从域，哪个区域就实现了主从服务器配置。 配置从区域首先要在从服务器上配置 DNS 服务，但配置方法更简单，因为只要定义一个区域即可，无需配置区域解析库文件。然后在主 DNS 的解析库文件中添加从服务器。需要特别注意的是主从服务器的时间要同步否则无法实现主从同步，可使用 ntpdate命令完成时间同步。具体步骤如下 1.1 On Slave从域配置: 定义区域: 定义一个从区域； 配置文件语法检查：named-checkconf 重载配置 12345678910$ vim /etc/named.rfc1912.zones # 追加zone "ZONE_NAME" IN &#123; type slave; file "slaves/ZONE_NAME.zone"; # /var/named 目录是不允许 named 用户写的 masters &#123; MASTER_IP; &#125;; # 主服务器的 ip 地址 &#125;;$ named-checkconf$ rndc reload 1.2 On Master主域配置: 确保区域数据文件中为每个从服务配置NS记录， 并且在正向区域文件需要每个从服务器的NS记录的主机名配置一个A记录，且此A后面的地址为真正的从服务器的IP地址； 123456$ vim /var/named/ZONE_NAME.zone@ IN NS ns2 # 从服务器具的 NS 记录$ vim /var/named/ZONE_FQDN.zone # 必需在正向解析库文件中添加 A 记录@ IN NS ns2 # 从服务器具的 NS 记录ns2 IN A ip_addr # 从服务器的 ip 地址 2. 子域授权正向解析区域授权子域的方法，以在 magedu.com. 的二级域中授权 ops.magedu.com. 三级域为例: 12345$ vim /var/named/ZONE_NAME.zone # 二级域的区域数据文件ops.magedu.com. IN NS ns1.ops.magedu.com. # 子域的 NS 记录ops.magedu.com. IN NS ns2.ops.magedu.com.ns1.ops.magedu.com. IN A IP.AD.DR.ESS # 子域的 A 记录ns2.ops.magedu.com. IN A IP.AD.DR.ESS 3. 定义转发默认情况下，DNS 服务在解析非自己负责的域名时，默认会向根域发起迭代查询。我们可以定义转发域，让 DNS 服务在解析非自己负责的域名时，向被转发服务器发起第归查询而不是向根域迭代查询。因此被转发的服务器必须允许为当前服务做递归。转发可分为区域转发和全局转发: 3.1 区域转发区域转发: 仅转发对某特定区域的解析请求；配置方法如下 123456$ vim /etc/named.rfc1912.zones # 追加zone "ZONE_NAME" IN &#123; type forward; forward &#123;first|only&#125;; forwarders &#123; SERVER_IP; &#125;; &#125;; 参数说明: forward:定义转发的特性 first：首先转发；转发器不响应时，自行去迭代查询； only：只转发； forwarders: 被转发服务器的 IP 3.2 全局转发全局转发：凡本地没有通过zone定义的区域查询请求，通通转给某转发器； 1234567$ vim /etc/named.conf # 追加options &#123; ... ... forward &#123;only|first&#125;; forwarders &#123; SERVER_IP; &#125;; .. ...&#125;; 4. bind 安全配置bind 的配置文件中可以使用 acl(访问控制列表)，把一个或多个地址归并一个命名的集合，随后通过此名称即可对此集全内的所有主机实现统一调用； acl 只能先定义后使用，所以通常位于 /etc/named.conf 最上面，并且是独立的配置段。 4.1 acl12345678910acl acl_name &#123; ip; net/prelen;&#125;;# eg:acl mynet &#123; 172.16.0.0/16; 127.0.0.0/8;&#125;; 4.2 bind内置的aclbind 由四个内置的 acl: none：没有一个主机； any：任意主机； local：本机； localnet：本机所在的IP所属的网络； 4.3 访问控制指令访问控制指令位于 options 表示对全局生效，位于 zone区域段中，表示只对此区域有效，常见的控制指令有 allow-query {} 允许查询的主机；白名单，未在此范围内的不能发起查询 allow-transfer {} 允许向哪些主机做区域传送；默认为向所有主机； 应该配置仅允许从服务器；如果没有从服务器，必需设置为 None allow-recursion {} 允许哪些主机向当前DNS服务器发起递归查询请求； allow-update {} DDNS，允许动态更新区域数据库文件中内容；存在风险，一般都为 none 12345678910111213$ vim /etc/named.confacl "slaves" &#123; 172.168.100.68; 172.168.0.0/16;&#125;$ vim /etc/named.rfc1912.zones # 追加zone "magedu.com." IN &#123; type master; file "magedu.com.zone" allow-transfer &#123; slaves; &#125;; allow-update &#123; none; &#125;;&#125; 5. 智能 DNS - bind view视图主要作用是实现，来自不同的用户的请求，可以返回不同的地址。比如来自内网的用户，得到的是内网的地址，来自公网的用户得到的是公网地址。12345view VIEW_NAME &#123; zone zone zone&#125; 示例12345678910111213141516view internal &#123; # 优先匹配的位于上面 match-clients &#123; 172.16.0.0/8; &#125;; zone &quot;magedu.com&quot; IN &#123; type master; file &quot;magedu.com/internal&quot;; # 内网的解析库文件 &#125;;&#125;;view external &#123; match-clients &#123; any; &#125;; zone &quot;magecdu.com&quot; IN &#123; type master; file magedu.com/external&quot;; # 外网的解析库文件 &#125;;&#125;; whois]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.3 bind安装和配置]]></title>
    <url>%2F2018%2F03%2F09%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2Fbind%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[bind安装和配置 bind 全称为 Berkeley Internet Name Domain，是 DNS 协议的一种开源实现。由伯克利分校开发，现由 ISC 维护，也是现在使用最为广泛的DNS服务器软件，本节我们就来介绍如何使用 bind 配置一个 DNS 服务器。 1. BIND1.1 bind 安装rpm 包组成12345678$ yum install bind$ yum list all bind*已安装的软件包bind.x86_64 32:9.9.4-61.el7 @basebind-libs.x86_64 32:9.9.4-61.el7 @basebind-libs-lite.x86_64 32:9.9.4-61.el7 @basebind-license.noarch 32:9.9.4-61.el7 @basebind-utils.x86_64 32:9.9.4-61.el7 @base bind 的 rpm 包主要由以下几个: bind：提供的dns server程序、以及几个常用的测试程序； bind-utils：bind客户端程序集，例如dig, host, nslookup等，可用于测试 dns 服务； bind-libs：被bind和bind-utils包中的程序共同用到的库文件； bind-chroot：选装，让named运行于jail模式下,目的是限定 bind 的运行环境，更加安全 程序文件123456789101112131415161718192021222324$ rpm -ql bind|grep sbin/usr/sbin/arpaname/usr/sbin/ddns-confgen/usr/sbin/dnssec-checkds # DNS 安全扩展/usr/sbin/dnssec-coverage/usr/sbin/dnssec-dsfromkey/usr/sbin/dnssec-importkey/usr/sbin/dnssec-keyfromlabel/usr/sbin/dnssec-keygen/usr/sbin/dnssec-revoke/usr/sbin/dnssec-settime/usr/sbin/dnssec-signzone/usr/sbin/dnssec-verify/usr/sbin/genrandom/usr/sbin/isc-hmac-fixup/usr/sbin/lwresd/usr/sbin/named # bind serve 进程/usr/sbin/named-checkconf # bind 配置文件检查/usr/sbin/named-checkzone # DNS 数据库区域文件检查/usr/sbin/named-compilezone/usr/sbin/named-journalprint/usr/sbin/nsec3hash/usr/sbin/rndc # bind 的远程控制工具/usr/sbin/rndc-confgen bind rpm 包提供了以下核心程序: dnssec-*: Domain Name System Security Extensions,DNS 安全扩展 rndc: named 进程远程控制工具 named: bind server 的核心程序 named-checkconf: 用于检查 named 配置文件是否存在语法错误 named-checkzone: 用于检查 DNS 的区域解析库文件是否存在语法错误 named-checkconfnamed-checkconf [named.conf] 作用: 检查 named 配置文件是否存在语法错误 参数: named.conf 配置文件位置，默认为 /etc/named.conf named-checkzonenamed-checkzone zonename filename 作用: 用于检查 DNS 的区域解析库文件是否存在语法错误 参数: zonename: 区域名称 filename: 区域数据库文件所在位置 1$ named-checkzone magedu.com. /var/named/magedu.com.zone 1.2 bind 配置文件1234567891011121314151617181920$ rpm -ql bind|egrep "etc|var"|grep -v "share"/etc/logrotate.d/named/etc/named /etc/named.conf # 核心配置文件/etc/named.iscdlv.key # 核心配置文件内使用 include 包含的辅助配置文件/etc/named.rfc1912.zones/etc/named.root.key/etc/rndc.conf # rndc 配置文件/etc/rndc.key/etc/rwtab.d/named/etc/sysconfig/named/var/log/named.log # 日志文件/var/named # DNS 数据库区域解析文件默认所在的目录/var/named/data/var/named/dynamic/var/named/named.ca # 顶级域的配置文件/var/named/named.empty/var/named/named.localhost/var/named/named.loopback/var/named/slaves bind 的配置文件包括两个部分: 主配置文件：/etc/named.conf 主配置文件内使用 include 包含进来辅助配置文件: /etc/named.iscdlv.key /etc/named.rfc1912.zones /etc/named.root.key 解析库文件默认存放在 /var/named/目录下；一般名字为：ZONE_NAME.zone。一台DNS服务器可同时为多个区域提供解析，且必需包含如下几个区域解析库文件: 根区域解析库文件： named.ca localhost 的正向解析库：named.localhost 127.0.0.1 的反向解析库：named.loopback 默认情况下，上述的区域解析库文件在 bind 安装时，已由 rpm 包自动提供。 1.3 bind 进程管理123$ rpm -ql bind|grep systemd/usr/lib/systemd/system/named-setup-rndc.service/usr/lib/systemd/system/named.service bind程序安装完成之后，默认即可做缓存名称服务器使用；如果没有专门负责解析的区域，直接即可启动服务。 CentOS 6: service named start CentOS 7: systemctl start named.service named 进程启动后，默认会监听 tcp 的 953 号端口，rndc 可通过此端口对 named 进程进行远程控制。但是 named 进程默认只监听在 127.0.0.1 上，因此仅允许本地使用。 rndcrndc：remote name domain contoller1234567891011121314rndc [-b address] [-c config] [-s server] [-p port] [-k key-file ] [-y key] [-V] commandcommand is one of the following: reload Reload configuration file and zones. reload zone [class [view]] Reload a single zone. refresh zone [class [view]] Schedule immediate maintenance for a zone. stats Write server statistics to the statistics file. status Display status of the server. stop Save pending updates to master files and stop the server. stop -p Save pending updates to master files and stop the server flush Flushes all of the server&apos;s caches. flush [view] Flushes the server&apos;s cache for a view. 2. bind 配置2.1 配置格式1234567891011121314151617181920212223242526272829303132333435363738$ cat /etc/named.confoptions &#123; # 全局配置段 listen-on port 53 &#123; 127.0.0.1; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory "/var/named"; # 区域解析库文件的默认存放目录 dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; allow-query &#123; localhost; &#125;; recursion yes; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;logging &#123; # 日志配置段 channel default_debug &#123; file "data/named.run"; severity dynamic; &#125;;&#125;;zone "." IN &#123; # 顶级域解析库配置文件 type hint; file "named.ca";&#125;;include "/etc/named.rfc1912.zones"; # 包含的辅助配置文件include "/etc/named.root.key"; bind 的主配置 /etc/named.conf 由三个部分组成: 全局配置段：options { ... } 日志配置段: logging { ... } 区域配置段: zone { ... } 配置那些由本机负责解析的区域，或转发的区域 /etc/named.conf有如下语法要求: 每个配置语句必须以分号结尾 {} 左右都必需要有空格 使用 // 或 /* */ 进行注释 2.2 缓存名 DNS 服务器配置named 进程默认启动后，即可作为缓存 DNS 服务器，但是默认配置只允许本地查询，无法对外提供服务，因此需要做如下修改。 更改 named 监听的地址，使其能与外部主机通信的地址； 学习使用时，建议关闭 dnssec 关闭仅允许本地查询配置 配置文件修改后应该使用named-checkconf，检查配置文件语法是否存在错误，在重起 named 进程。下面是配置过程 123456789101112131415$ vim /etc/named.conf # 修改监听地址，使其能与外部主机通信的地址； listen-on port 53; listen-on port 53 &#123; 172.16.100.67; &#125;; # 学习时，建议关闭dnssec dnssec-enable no; dnssec-validation no; dnssec-lookaside no; # 关闭仅允许本地查询： //allow-query &#123; localhost; &#125;;# 检查配置文件语法$ named-checkconf 3. 正反向解析区域配置上一节我们学习过区域解析库文件的语法格式，现在我们就来学习，如何配置正向和反向区域。我们将以配置magedu.com 这个二级域为例。 3.1 正向区域配置配置一个正向解析区域需要: 定义区域: 在主配置文件中或主配置文件辅助配置文件中定义区域，区域名字即为域名 建立区域数据文件，正向区域的主要记录为A或AAAA记录，并更改配置文件属性 重启服务: 检查语法错误，然后让服务器重载配置文件和区域数据文件 下面是配置的详细过程: 定义区域12345$ vim /etc/named.rfc1912.zones # 追加zone "magedu.com." IN &#123; type master; file "magedu.com.zone";&#125;; 区域定义参数: type: 用于定义区域的主机类型，可选值为 master: 主服务器 slave: 从服务器 hint: 根域 forward file: 指定区域数据库文件位置，使用相对路经，则在 /etc/named.conf 配置的默认路经/var/named之下 建立区域数据文件123456789101112131415161718192021222324$ cd /var/named $ touch /var/named/magedu.com.zone # 创建区域数据文件$ chgrp named /var/named/magedu.com.zone # 更改权限及属组$ chmod o= /var/named/magedu.com.zone$ vim /var/named/magedu.com.zone$TTL 3600$ORIGIN magedu.com. # ORIGIN 会自动补全下面 ns，mx1 的域名@ IN SOA ns1.magedu.com. dnsadmin.magedu.com. ( 2017010801 1H 10M 3D 1D) IN NS ns1 IN MX 10 mx1 IN MX 20 mx2ns1 IN A 172.16.100.67mx1 IN A 172.16.100.68mx2 IN A 172.16.100.69www IN A 172.16.100.67web IN CNAME wwwbbs IN A 172.16.100.70bbs IN A 172.16.100.71 重启服务1234567# 检查语法错误$ named-checkzone magedu.com. /var/named/magedu.com.zone$ named-checkconf# 重起服务$ rndc reload # 或$ systemctl reload named.service 3.2 反向解析区域配置配置反向区域与配置正向区域类似，只不过区域名称和区域数据库文件不同: 反向区域的名字格式为: 反写的网段地址.in-addr.arpa, 例如区域 172.16.100 的区域名称为 100.16.172.in-addr.arpa 反向区域没有 MX 资源记录，主要为 PTR 资源记录 定义区域12345$ vim /etc/named.rfc1912.zones # 追加zone "100.16.172.in-addr.arpa" IN &#123; type master; file "172.16.100.zone";&#125;; 建立区域数据文件123456789101112131415161718192021$ cd /var/named $ touch /var/named/172.16.100.zone # 创建区域数据文件$ chgrp named /var/named/172.16.100.zone # 更改权限及属组$ chmod o= /var/named/172.16.100.zone$ vim /var/named/172.16.100.zone$TTL 3600$ORIGIN 100.16.172.in-addr.arpa.@ IN SOA ns1.magedu.com. nsadmin.magedu.com. ( 2017010801 1H 10M 3D 12H ) IN NS ns1.magedu.com. 67 IN PTR ns1.magedu.com. # 域名必需写全，此时 ORIGIN 不能补全68 IN PTR mx1.magedu.com.69 IN PTR mx2.magedu.com.70 IN PTR bbs.magedu.com.71 IN PTR bbs.magedu.com.67 IN PTR www.magedu.com. 重启服务1234567# 检查语法错误$ named-checkzone 100.16.172.in-addr.arpa /var/named/172.16.100.zone$ named-checkconf# 重起服务$ rndc reload # 或$ systemctl reload named.service 4. DNS 测试工具digdig [-t RR_TYPE] name [@SERVER] [query options] 作用: 用于测试dns系统，因此其不会查询hosts文件； 参数: name: DNS 资源记录的名称 @SERVER: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 +[no]trace：跟踪解析过程 +[no]recurse：进行递归解析； -x IP:进行反向解析测试 常用: 反向解析测试 : dig -x IP 模拟完全区域传送： dig -t axfr DOMAIN [@server] 12345678910111213141516171819202122232425# 正向解析测试$ dig -t NS baidu.com.$ dig -t A www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-61.el7 &lt;&lt;&gt;&gt; -t A www.baidu.com +recurse;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 36303;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 126 IN CNAME www.a.shifen.com.www.a.shifen.com. 126 IN A 61.135.169.125www.a.shifen.com. 126 IN A 61.135.169.121;; Query time: 47 msec;; SERVER: 192.168.1.1#53(192.168.1.1);; WHEN: 二 8月 14 11:54:53 CST 2018;; MSG SIZE rcvd: 90# 反向解析测试$ dig -x 61.135.169.125 hosthost [-t RR_TYPE] name [SERVER_IP] 作用: 用于测试dns系统，不会查询hosts文件； 参数: name: DNS 资源记录的名称 SERVER_IP: 可选，使用的 DNS 服务器，默认为本机 选项： -t RR_TYPE: 指定查询的资源记录类型 1234567$ host -t A www.baidu.comwww.baidu.com is an alias for www.a.shifen.com.www.a.shifen.com has address 61.135.169.125www.a.shifen.com has address 61.135.169.121$ host -t PTR 61.135.169.121Host 121.169.135.61.in-addr.arpa. not found: 3(NXDOMAIN) nslookupnslookup [-options] [name] [server] 作用: 用于测试dns系统，默认进入交互式环境 nslookup&gt; server IP # 指定DNS服务器 set q=RR_TYPE # 要查询的资源记录类型； name # 要查询的名称 $ nslookup &gt; set q=A &gt; www.baidu.com Server: 192.168.1.1 Address: 192.168.1.1#53 Non-authoritative answer: www.baidu.com canonical name = www.a.shifen.com. Name: www.a.shifen.com Address: 61.135.169.121 Name: www.a.shifen.com Address: 61.135.169.125 &gt;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.2 DNS区域数据库文件格式]]></title>
    <url>%2F2018%2F03%2F08%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2FDNS%E5%8C%BA%E5%9F%9F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[DNS区域数据库文件格式 DNS 的数据库文件记录了 FQDN 与 IP 的对应关系，有特定格式要求。本节我们就来学习DNS区域数据库文件格式 1. 资源类型DNS区域数据库文件一条记录为一行，被称为资源记录(Resource Record), 简称rr。常见的资源记录类型包括: SOA：Start Of Authority，起始授权记录； 一个区域解析库有且只能有一个SOA记录，而且必须放在第一条； NS：Name Service，域名服务记录；一个区域解析库可以有多个NS记录；其中一个为主的； A： Address, 地址记录，FQDN --&gt; IPv4； AAAA：地址记录， FQDN --&gt; IPv6； CNAME：Canonical Name，别名记录； PTR：Pointer，IP --&gt; FQDN MX：Mail eXchanger，邮件交换器；优先级：0-99，数字越小优先级越高 每种资源记录有特定的格式要求，接下来我们来分别介绍 2. DNS 资源记录的定义格式name [TTL] IN RR_TYPE value 作用: DNS 资源记录定义的语法 参数: name: 名称 value: 名称对应的值与属性 TTL: Time To Live,有效是长 IN: 关键字 RR_TYPE： 资源类型 注意： TTL可以从全局继承； @表示当前区域的名称； 相邻的两条记录其name相同时，后面的可省略； 对于正向区域来说，各MX，NS等类型的记录的value为FQDN，此FQDN应该有一个A记录； 配置文件内 ; 后跟注释 FQDN 最后的根域名.不可省略 下面是各个资源记录的配置示例 12345678910111213141516171819202122232425262728# SOAleistudy.com. 86400 IN SOA ns.leistudy.com. nsadmin.leistudy.com. ( 2018022801 ;序列号 2H ;刷新时间 10M ;重试时间 1W ;过期时间 1D ;否定答案的TTL值)# NSleistudy.com. IN NS ns1.leistudy.com.leistudy.com. IN NS ns2.leistudy.com.# MXleistudy.com. IN MX 10 mx1.leistudy.com. IN MX 20 mx2.leistudy.com.# Awww.leistudy.com. IN A 1.1.1.1www.leistudy.com. IN A 1.1.1.2mx1.leistudy.com. IN A 1.1.1.3mx2.leistudy.com. IN A 1.1.1.3# AAAAwww.leistudy.com. IN AAAA ::1# PTR4.3.2.1.in-addr.arpa. IN PTR www.leistudy.com 2.1 SOAname [TTL] IN RR_TYPE value name: 当前区域的名字；例如mageud.com.，或者2.3.4.in-addr.arpa.； value：有多部分组成 当前区域的区域名称（也可以使用主DNS服务器名称）； 当前区域管理员的邮箱地址；但地址中不能使用@符号，一般使用点号来替代 (主从服务协调属性的定义以及否定答案的TTL) 1234567magedu.com. 86400 IN SOA magedu.com. admin.magedu.com. ( 2017010801 ; serial 主从服务协调属性 2H ; refresh 10M ; retry 1W ; expire 1D ; negative answer ttl 否定答案的 TTL) 2.2 NSname [TTL] IN RR_TYPE value name: 当前区域的区域名称 value: 当前区域的某DNS服务器的名字，例如ns.magedu.com.； 注意： 一个区域可以有多个ns记录； 相邻的两条记录其name相同时，后面的可省略； 12magedu.com. 86400 IN NS ns1.magedu.com. 86400 IN NS ns2.magedu.com. 2.3 MXname [TTL] IN RR_TYPE value name: 当前区域的区域名称 value：当前区域某邮件交换器的主机名； 注意：MX记录可以有多个；但每个记录的value之前应该有一个数字表示其优先级； 123# @ 可表示当前区域的名称@ IN MX 10 mx1.magedu.com.@ IN MX 20 mx2.magedu.com. 2.4 Aname [TTL] IN RR_TYPE value name：某FQDN，例如www.magedu.com. value：某IPv4地址； 123www.magedu.com. IN A 1.1.1.1www.magedu.com. IN A 1.1.1.2bbs.magedu.com. IN A 1.1.1.1 2.5 AAAAname [TTL] IN RR_TYPE value name：FQDN value: IPv6 1www.magedu.com. IN AAAA ::1 2.6 PTRname [TTL] IN RR_TYPE value 作用: 反向解析的资源记录格式 name：IP地址，IP必需反过来写，而且必需加特定后缀；例如 1.2.3.4 的记录应该写为4.3.2.1.in-addr.arpa. value：FQND 14.3.2.1.in-addr.arpa. IN PTR www.magedu.com. 2.7 CNAMEname [TTL] IN RR_TYPE value name: FQDN格式的别名； value: FQDN格式的正式名字； 1web.magedu.com. IN CNAME www.magedu.com.]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[16.1 DNS域名服务原理]]></title>
    <url>%2F2018%2F03%2F07%2Flinux_mt%2F19-DNS%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90%E5%AE%9E%E6%88%98%2FDNS%E5%9F%9F%E5%90%8D%E6%9C%8D%E5%8A%A1%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[DNS域名服务原理 本章我们开始学习 Linux 上的第一个服务，也是互联网的基础服务 DNS。之所以存在 DNS 服务是因为相对于数字形式的 ip 地址，人们更容易记住字符串，因此就有了将字符串格式的域名转换为数字格式的 ip 的需求。在互联网诞生的早期，计算机尚且属于稀缺资源，域名与 ip 地址的对应关系，保存在本地的 hosts (/etc/hosts) 文件上。随着连入互联网的主机越来越多，每个主机都保存所有域名与ip 对应的的副本已经不现实，于是就有了 DNS 服务。本节我们就来讲解 DNS 服务，内容包括: DNS 服务的原理 DNS 域名解析的过程 DNS 区域数据库文件 使用 bind 配置 DNS 服务 DNS 虽然是互联网的基础服务，但是实际上很少人会买域名，配置 DNS 服务器的人很少，所以很多人对 DNS 服务并不熟悉。本节我们就来讲解 DNS 服务的基本原理。 1. DNS 概述1.1 DNS 相关概念DNS 全称为 Domain Name Service 属于应用层协议，工作于 udp/tcp 的 53 号端口。DNS 服务工作于 udp 53 号端口，tcp 的 53 端口用于实现主从 DNS 同步。 为了分散 DNS 查询的负载，同时方便域名的管理，DNS 被组织成一个倒置的树结构。如下图所示 根域为 .，其下是顶级域和国家域，每个顶级域由不同的机构进行域名管理。顶级域下是二级域，我们购买的域名不是单个域名而是整个二级域，购买后可根据需要配置子域。比如，我在.com.顶级域下购买了域 tao.com.，可根据需求配置一个域名 web.tao.com.,也可以配置 image.web.tao.com.，对于域名大范围在右边，小范围在左边。 1.2 DNS 服务上面展示的倒置树是 DNS 的结构示意图，在每个域上，都是有一个个 DNS 服务器。DNS 服务由 bind 程序提供。按照提供的服务类型，可将 DNS 服务器分为 负责解析至少一个域的主名称服务器和辅助名称服务器； 不负责哉解析的缓存名称服务器； 1.3 DNS 查询请求流程 12 章中我们讲解了如何配置 Linux 的网络属性，/etc/resolv.conf 配置文件内配置了我们的 DNS 服务器指向。当我们在浏览器内输入 www.baidu.com 时，将按照如下的顺序查询 百度的 ip 地址: 首先会访问本地的 hosts文件，如果有记录则直接返回结果 查询本地的DNS缓存DNS，有则直接返回 向 /etc/resolv.conf 配置的 DNS 服务器发起查询请求 如果域名是自己负责解析的域，DNS 服务器将直接查询数据库并返回结果； 如果不是自己负责解析域，并且服务器内未缓存，DNS 服务器将向发起迭代查询 如上图所式，配置文件指向的 DNS 服务器，将帮助我们按照 DNS 的层级结构从顶至下发起迭代查询，直至查询到结果返回给我们。 因此 DNS 的查询可分为: 递归查询：本机向配置的 DNS 服务器发起的即是递归查询，DNS 服务器返回给我们的是结果 迭代查询：DNS 服务向上层 DNS 服务器发起的则是迭代查询，需要根据返回结果继续迭代查询。 DNS 服务器返回给我们的结果有如下几种情况: 肯定答案：域名的解析结果 否定答案：不存在查询的键，因此，不存在与其查询键对应的值； 权威答案：由直接负责的DNS服务器返回的答案； 非权威答案：由非直接负责的DNS服务器的缓存返回，有可能缓存失效 1.4 DNS 反向解析DNS 除了将域名解析为 ip 外，还能将 ip 解析为主机名 名称 –&gt; IP：正向解析 IP –&gt; 名称：反向解析 但是需要注意的是，正向反向解析的的名称空间，不是同一个空间，即正向反向解析不是同一棵树，使用的是不同的解析库文件 1.5 DNS 中的区域与域域(domain)，FQDN（Full Qualified Domain Name）是一种逻辑概念，包括物理上的 由 FQDN --&gt; IP 的正向解析区域(zone) 由 IP --&gt; FQDN 的反向解析区域(zone) 2. 主从 DNS 服务器为了放置 DNS 单节点故障导致整个服务不可用，也为了平衡负载，DNS 服务器通常为主从模式 主DNS服务器：为维护所负责解析的域数据库的那台服务器；读写操作均可进行； 从DNS服务器：从主DNS服务器那里或其它的从DNS服务器那里“复制”一份解析库；但只能进行读操作； 2.1 主从同步方式DNS 服务器的主从复制有如下特性: 数据库有序列号(serial),即数据库的版本号；主服务器数据库内容发生变化时，其版本号递增 从服务器会按照设置的时间间隔从主服务器同步数据 refresh: 刷新时间间隔,从服务器每多久到主服务器检查序列号更新状况 retry: 重试时间间隔, 从服务器从主服务器请求同步解析库失败时，再次发起尝试请求的时间间隔； expire: 过期时长，从服务器始终联系不到主服务器时，多久之后放弃从主服务器同步数据；停止提供服务； 处理从服务器定时同步外，主服务器会在每次数据发生变更时，通知从服务器随时更新数据 数据传送(区域传送)分为如下两种，通常只会进行增量传送 全量传送：axfr, 传送整个数据库； 增量传送：ixfr, 仅传送变量的数据]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.4 私建 CA]]></title>
    <url>%2F2018%2F03%2F06%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E7%A7%81%E5%BB%BACA%2F</url>
    <content type="text"><![CDATA[私建 CA 很多时候我们为了测试目的，或者不便让用户去申请证书，我们就需要私建 CA，本节我们就来讲解如何私建 CA。 1. 私建 CACA创建的工具有两个，小范围内可直接使用 openssl 命令，如果要维护大量的CA，可以使用完全 CA 创建工具 openCA。 那么如何创建 CA？前面我们知道 PKI 公钥基础设施包括如下几个部分: 签证机构：CA 注册机构：RA 证书吊销列表：CRL 证书存取库： 所以私建 CA 首先要创建出上述的基础设施，然后才能签发证书。而证书的申请及签发大体上包括以下步骤: 申请方生成申请请求 RA 进行核验 CA 签署 证书获取 下面我们就分创建 CA，和签发一个证书两个步骤讲解私建 CA的整个过程。 1.1 创建公钥基础设施创建一个私有 CA非常简单，只要在确定配置为 CA 的服务上生成一个自签证书，并为CA提供所需要的目录及文件即可。CA 所需的目录定义在 CA 的配置文件中 /etc/pki/tls/openssl.cnf 12345678910111213141516171819202122232425# less /etc/pki/tls/openssl.conf####################################################################[ ca ]default_ca = CA_default # The default ca section####################################################################[ CA_default ]dir = /etc/pki/CA # CA 的工作目录certs = $dir/certs # 已经签发的证书目录crl_dir = $dir/crl # 已吊销证书的放置目录database = $dir/index.txt # 已经签发证书的索引#unique_subject = no # Set to &apos;no&apos; to allow creation of # several ctificates with same subject.new_certs_dir = $dir/newcerts # default place for new certs.certificate = $dir/cacert.pem # CA自签证书serial = $dir/serial # 当前序列号，表示新签发证书的编号crlnumber = $dir/crlnumber # 新吊销证书的编号 # must be commented out to leave a V1 CRLcrl = $dir/crl.pem # The current CRLprivate_key = $dir/private/cakey.pem # CA 私钥RANDFILE = $dir/private/.rand # private random number filedefault_days = 365 # 证书默认的有效时长default_crl_days= 30 # how long before next CRL 1.2 证书申请签发查看openssl req [options] outfile 作用: 生成证书签署请求 选项: -new：生成新证书签署请求； -x509: 生成自签格式证书，专用于创建私有CA时； -key：生成请求时用到的私钥文件,openssl 会自动提取出公钥放置在证书签署请求中； -out：生成的请求文件路径，自签证书将直接生成签署过的证书 -days：证书的有效时长，单位是day； openssl ca 作用: CA 签发证书 选项: -in &lt;file&gt;: 证书签署请求文件路径 -out &lt;file&gt;: 生成的新证书的保存路径 -days：证书的有效时长，单位是day； openssl x509 作用: 查看证书信息 选项: -in：指定输入文件，默认是标准输入。 -out：指定输出文件，默认是标准输出。 -passin：指定私钥密码的来源 -serial：显示序列号。 -subject：打印项目的DN -issuer：打印签发者的DN -email：打印email地址 -startdate：打印开始日期 -enddate：打印结束日期 -purpose：打印证书的用途 -dates：打印开始日期和结束日期 -public：输出公钥 -fingerprint：输出证书的指纹 -noout：没证书输出 -days: 设置证书的有效期时间，默认30天 -req：输入是一个证书请求，签名和输出 -CA：设置CA证书，必须是PEM格式的 -text：以文本格式输出证书 1.3 构建私有CA步骤12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758# 1. 生成所需要的文件和目录$ dir=/etc/pki/CA$ cd $dir$ touch &#123;serial,index.txt&#125;$ echo 01 $ serial$ mkdir -pv $dir&#123;certs,crl,newcerts&#125;# 2. CA 自签证书# 生成私钥$ (umask 077; openssl genrsa -out /etc/pki/CA/private/cakey.pem 4096)$ openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -out /etc/pki/CA/cacert.pem -days 3655 # new：生成新证书签署请求； # x509：生成自签格式证书，专用于创建私有CA时； # key：生成请求时用到的私钥文件； # out：证书的保存路径 # days：证书的有效时长，单位是day；# 3. 发证# 3.1 要用到证书的主机生成证书请求：# 3.2 把请求文件传输给 CA# 3.3 CA 验证证书合法性，签署证书，并将证书发还给请求者# 3.1 步骤：（以httpd为例）# 用到证书的主机生成私钥$ mkdir /etc/httpd/ssl$ cd /etc/httpd/ssl$ (umask 077; openssl genrsa -out /etc/httpd/ssl/httpd.key 2048)# 生成证书签署请求，(csr - certificate security request)$ openssl req -new -key /etc/httpd/ssl/httpd.key -out /etc/httpd/ssl/httpd.csr -days 365# 3.2 将请求通过可靠方式发送给CA主机；$ scp /etc/httpd/ssl/httpd.csr root@196.168.1.105:/tmp# 3.3 在CA主机上签署证书 (crt - certificate 的简写)$ openssl ca -in /tmp/httpd.csr -out /etc/pki/CA/certs/httpd.crt -days 365# 3.4 查看证书中的信息：$ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -text# 4. 吊销证书：# 4.1. 客户端获取要吊销的证书的serial：$ openssl x509 -in /etc/pki/CA/certs/httpd.crt -noout -serial -subject# 4.2 CA主机吊销证书# 先根据客户提交的serial和subject信息，对比其与本机数据库index.txt中存储的是否一致；# 吊销, 其中的SERIAL要换成证书真正的序列号；$ openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem# 4.3. 生成吊销证书的吊销编号（第一次吊销证书时执行）$ echo 01 $ /etc/pki/CA/crlnumber# 4.4 更新证书吊销列表$ openssl ca -gencrl -out thisca.crl# 4.5 查看crl文件：$ openssl crl -in /PATH/FROM/CRL_FILE.crl -noout -text]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.3 openssl 命令使用]]></title>
    <url>%2F2018%2F03%2F05%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2Fopenssl%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[openssl 命令使用 OpenSSL 分为三个组成 libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 openssl 命令行工具有多个子命令，大体上分为如下三类 标准命令(standard) 消息摘要命令（dgst子命令） 加密命令（enc子命令） 本节我们就来讲解常见命令的使用 1. openssl 使用概述12345678910111213141516171819202122232425262728293031323334353637383940openssl ?openssl:Error: '?' is an invalid command.Standard commands # 可使用的标准子命令 asn1parse ca ciphers cms crl crl2pkcs7 dgst dh dhparam dsa dsaparam ec ecparam enc engine errstr gendh gendsa genpkey genrsa nseq ocsp passwd pkcs12 pkcs7 pkcs8 pkey pkeyparam pkeyutl prime rand req rsa rsautl s_client s_server s_time sess_id smime speed spkac ts verify version x509 # 消息摘要子命令 dgst, 下面是可用的算法Message Digest commands (see the `dgst' command for more details)md2 md4 md5 rmd160 sha sha1 # 对称加密子命令 enc，下面是可用的算法Cipher commands (see the `enc' command for more details)aes-128-cbc aes-128-ecb aes-192-cbc aes-192-ecb aes-256-cbc aes-256-ecb base64 bf bf-cbc bf-cfb bf-ecb bf-ofb camellia-128-cbc camellia-128-ecb camellia-192-cbc camellia-192-ecb camellia-256-cbc camellia-256-ecb cast cast-cbc cast5-cbc cast5-cfb cast5-ecb cast5-ofb des des-cbc des-cfb des-ecb des-ede des-ede-cbc des-ede-cfb des-ede-ofb des-ede3 des-ede3-cbc des-ede3-cfb des-ede3-ofb des-ofb des3 desx idea idea-cbc idea-cfb idea-ecb idea-ofb rc2 rc2-40-cbc rc2-64-cbc rc2-cbc rc2-cfb rc2-ecb rc2-ofb rc4 rc4-40 rc5 rc5-cbc rc5-cfb rc5-ecb rc5-ofb seed seed-cbc seed-cfb seed-ecb seed-ofb zlib 2. 标准命令1.1 生成用户密码openssl password [OPTIONS] [password] 作用: 生成用户密码 参数: password 用户密码，可省略，默认会提示用户输入 选项: -crypt: standard Unix password algorithm (default) -1: MD5-based password algorithm -salt string: use provided salt -in file: read passwords from file -stdin: read passwords from stdin -reverse: switch table columns 123$ openssl passwd -1 -salt tabcPassword: # 根据提示输入用户密码$1$tabc$dMfThcS/0AhHbG277/5.Y. 1.2 生成随机数openssl rand OPTIONS num 参数: NUM 表示字节数 选项: -out file: write to file -base64: base64 encode output -hex: hex encode output 123456789$ openssl rand -base64 10CyrtOhCwGXySRQ==$ openssl rand -hex 1061fc2a72e000622746f4$ openssl passwd -1 -salt `openssl rand -hex 4`Password:$1$e3a21fb9$Zahip67zta7xJB2QiaVAm0 2. 加密命令2.1 对称加密openssl enc -ciphernam OPTIONS 作用: 使用对称加密算法加密文件 选项: -e: 加密 -d: 解密 -a/-base64: 使用 base64 编码和解码文件 -ciphernam: 指定使用的加密算法 -in &lt;file&gt;: 待加密的明文文件 -out &lt;file&gt;: 加密后的密文输出路径 -pass &lt;arg&gt;: 加密使用的密码 -md: 指定密钥生成的摘要算法，用户输入的口令不能直接作为文件加密的密钥，而是经过摘要算法做转换，此参数指定摘要算法，默认md5 -S: 在把用户密码转换成加密密钥的时候需要使用盐值，默认盐值随机生成 -salt: use a salt in the key derivation routines. This is the default 12345# -e 加密openssl enc -e -des3 -a -salt -in fstab -out fstab.ciphertext# -d 解密openssl enc -d -des3 -a -salt -out fstab -in fstab.ciphertext 2.2 单向加密openssl dgst OPTIONS file 作用: 使用单向加密算法，提取摘要信息 参数: file 指定提取摘要的文件 提取算法: -md4 -md5 -ripemd160 -sha -sha1 -sha224 -sha256 -sha384 -sha512 -whirlpool 选项: -c: to output the digest with separating colons -r: to output the digest in coreutils format -d: to output debug info -hex: output as hex dump -binary: output in binary form 12$ openssl dgst -md5 /PATH/TO/SOMEFILE$ md5sum /path/to/somefile 2.3 公钥加密openssl rsautl 作用: 使用RSA密钥进行加密、解密、签名和验证等运算 算法： 加解密: RSA，ELGamal 数字签名：RSA， DSA， ELGamal 密钥交换：DH 3. 生成密钥openssl genrsa OPTIONS numbits 作用: 生成私钥 参数: numbits 私钥的长度，只能是 1024 的证书倍 参数: -out &lt;file&gt;: 输出的文件路径 -passout arg: 指定密钥文件的加密口令，可从文件、环境变量、终端等输入 openssl rsa [options] &lt;infile &gt;outfile 作用: 管理生成的密钥，rsa 默认输出私钥，通过 -pubout 指定输出公钥 选项: -in arg:输入文件 -out arg:输出文件 -passin arg:指定输入文件的加密口令，可来自文件、终端、环境变量等 -passout arg:指定输出文件的加密口令，可来自文件、终端、环境变量等 -pubin:指定输入文件是公钥 -pubout:指定输出文件是公钥 -text:以明文形式输出各个参数值 -check:检查输入密钥的正确性和一致性 123456# 生成私钥# shell 中 () 内的命令会在同一个子 shell 中执行$ (umask 077; openssl genrsa -out /PATH/TO/PRIVATE_KEY_FILE NUM_BITS)# 提出公钥$ openssl rsa -in /PATH/FROM/PRIVATE_KEY_FILE -pubout -out outputfile 4. Linux系统上的随机数生成器Linux 中有如下几个随机数生成器 /dev/random：仅从熵池返回随机数；随机数用尽，阻塞； /dev/urandom：从熵池返回随机数；随机数用尽，会利用软件生成伪随机数，非阻塞；伪随机数不安全； 附注: 熵池中随机数的来源： 硬盘IO中断时间间隔； 键盘IO中断时间间隔；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.2 公钥基础设置与ssl会话]]></title>
    <url>%2F2018%2F03%2F04%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E5%85%AC%E9%92%A5%E5%9F%BA%E7%A1%80%E8%AE%BE%E7%BD%AE%E4%B8%8Essl%E4%BC%9A%E8%AF%9D%2F</url>
    <content type="text"><![CDATA[公钥基础设置与ssl会话 上一节我们学习了通信加密的基础知识，常见的加密解密算法，ssl/tls 协议。 还概括性的介绍了在已知公钥和基于公钥基础设施实现安全通信的过程。ssl/tls 正是用来规范如何通过公钥基础设施来进行安全通信的协议，本节我们就来详细讲解公钥基础设施，数字证书以及 ssl 会话建立的过程。 1. 公钥基础设施公钥基础设置，PKI(Public Key Infrastructure)，由以下部分: 签证机构：CA，实际签发数字证书的机构 注册机构：RA，接收证书申请的机构 证书吊销列表：CRL 证书存取库 证书申请方向注册机构发起证书申请请求，注册机构统一提交给签证机构，由签证机构对申请者进行尽责调查，在确认无误后向申请方签发证书。如果申请者私钥丢失等其他原因，可向签证机构申请吊销证书。 2. 数字证书X.509v3 定义了证书的结构以及认证协议标准，数字证书包含了以下内容: 版本号 序列号 签名算法ID: 提取数字证书特征码的单向加密算法 发行者名称 有效期限 主体名称 主体公钥 发行者的惟一标识 主体的惟一标识 扩展 发行者的签名: CA 私钥对数字证书的特征码加密后的结果 2. SSL会话ssl 会话创建需要三个步骤: 客户端向服务器端索要并验正证书； 双方协商生成“会话密钥”； 双方采用“会话密钥”进行加密通信； SSL Handshake Protocol(ssl 握手协议) 就是用来规范客户端与服务器端如何协商生成会话密钥。如下图所示，其分成了四个阶段 第一阶段：ClientHello客户端将向服务器端发送以下信息: 支持的协议版本，比如tls 1.2； 客户端生成一个随机数，稍后用户生成“会话密钥” 支持的加密算法，比如AES、3DES、RSA； 支持的压缩算法； 第二阶段：ServerHello服务器端将向客户端发送以下信息 确认使用的加密通信协议版本，比如tls 1.2； 服务器端生成一个随机数，稍后用于生成“会话密钥” 确认使用的加密方法； 服务器证书； 第三阶段-Client：客户端接收到服务器的证书后，验正服务器证书，在确认无误后取出其公钥；（发证机构、证书完整性、证书持有者、证书有效期、吊销列表）。发送以下信息给服务器端： 一个随机数； 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 客户端握手结束通知； 第四阶段-Server服务器端收到客户端发来的第三个随机数pre-master-key后，计算生成本次会话所有到的“会话密钥”；向客户端发送如下信息： 编码变更通知，表示随后的信息都将用双方商定的加密方法和密钥发送； 服务端握手结束通知；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[15.1 通信加密和解密技术入门]]></title>
    <url>%2F2018%2F03%2F03%2Flinux_mt%2F18-%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%2F%E9%80%9A%E4%BF%A1%E5%8A%A0%E5%AF%86%E5%92%8C%E8%A7%A3%E5%AF%86%E6%8A%80%E6%9C%AF%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[通信加密和解密技术入门 从本章开始，我们进入 Linux 学习的第二部分 Linux 网络服务与安全。第二部分会涉及到以下的内容 网络安全加密，Openssl，Openssh DNS 服务 web 服务，包括构建在 apache httpd 服务上的 LAMP，和构建在 nginx 上的 LNMP 文件服务，包括 nfs，samble，ftp 自动化安装相关的 dhcp，pxe 防火墙 iptables 系统管理相关的一些命令和服务包括 sudo，pam, nsswitch 本章我们将学习网络加密和解密技术，内容分成了三个部分: 基础知识，包括常见的加密算法，ssl 协议，以及安全通信中的基础设施 CA 如何利用我们的加密算法实现安全通信 加密工具 openssl工具的使用 很多互联网的基础协议诞生于互联网产生的初期，那时候能使用互联网的人很少，能实现主机之间的通信就已经很不容易，也就没有安全通信的需求，所以大多数的基础网络通信协议都是明文传输的。随着互联网的普及，安全通信的需求越来越迫切，ssl 协议孕育而生，它位于应用层和传输层之间，为所有的应用层协议提供可选的安全通信服务。安全通信需要各种加密技术，同时也出现了通信安全的基础设施 CA，本节就会介绍这部分的基础知识，内容包括 网络安全概述，包括安全的目标，面临的威胁，以及可能的防范手段 ssl 协议的作用和实现 加密算法和协议 公钥基础设施及安全通信的过程 1. 网络安全概述 安全的目标： 保密性：confidentiality 完整性：integrity 可用性：availability 攻击类型： 威胁保密性的攻击：窃听、通信量分析； 威胁完整性的攻击：更改、伪装、重放、否认 威胁可用性的攻击：拒绝服务（DoS） 解决方案： 技术（加密和解密）、服务（用于抵御攻击的服务，也即是为了上述安全目标而特地设计的安全服务） 加密和解密： 传统加密方法：替代加密方法、置换加密方法 现代加密方法：现代块加密方法 服务： 认证机制 访问控制机制 2. ssl 协议 通信协议栈分为 5 层，最上面是应用层，又称为资源子网，关注的是只关心数据是如何组织起来的，传输层及以下又称为通信子网关注的是如何传输数据。 ssl(Secure Sockets Layer) 协议相当于位于应用层与传输层之间的半层，它是可选的，可为所有的应用协议提供可选的安全通信服务。ssl 有众多实现，最著名的开源实现是 OpenSSL，任何想使用安全通信的服务，只要在进行网络传输时调用 OpenSSL 提供的服务即可。以 https 服务为例 http --&gt; ssl --&gt; https。 通过 OpenSSL 实现安全通信的过程其实是非常复杂的，http 与 https 其实是两个独立的服务，http的服务的默认端口是 80，https 则是 443。 2.1 ssl 版本SSL协议的诞生Netscape（网景通信公司）在1994年创建了SSL协议的原始规范，但是第一个SSL协议版本因为使用弱加密算法受到密码学界的质疑，所以从来没有公开发布过。Netscape在1995年2月修订了规范，并发布了一个大大改进的版本SSL 2.0协议，虽然SSL 2.0版本被认为是一个相当强大和健壮的协议，但仍存在一些易受攻击的漏洞。 SSL协议更名TLS协议在1996年，由Netscape和Paul Kocher共同设计的版本SSL 3.0协议发布。SSL(Secure sockets Layer) 3.0协议获得互联网广泛认可和支持，因特网工程任务组（IETF）接手负责该协议，并将其重命名为传输层安全 TLS(Transport Layer Security) 协议。TLS协议的第一个版本（RFC 2246）于1999年1月发布，实质上就是SSL 3.0协议的适度改进版。虽然TLS协议和SSL协议是同一个协议的迭代升级，但是其重命名后在名称上造成的混淆一直延续到今天，业内通常将二者统称为SSL/TLS协议。 当前正在使用的时 TLS 的 V1.0, V1.1, V1.2, V1.3。TLS 采用分层设计 最底层：基础算法原语的实现，aes, rsa, md5 向上一层：各种算法的实现； 再向上一层：组合算法实现的半成品； 用各种组件拼装而成的各种成品密码学协议软件； 2.2 ssl 开源实现Linux系统上 ssl 有两个开源实现:OpenSSL(ssl) 和 GPG(pgp)。GPG 是商业软件 pgp 的开源实现。更常用的是 OpenSSL，因此我们主要讲解 OpenSSL。OpenSSL 由三个部分组成: libencrypto库:加密算法库 libssl库:加密模块应用库，实现了ssl及tls openssl多用途命令行工具 3. 加密算法和协议加密算法分为以下几类，它们具有不同的特性，在安全通信中用于不同的安全目标。 对称加密: 数据加密 公钥加密: 数字签名和密钥交换 单向加密: 数据完整性认证 密钥交换: 完成密钥交换的特定协议 3.1 对称加密 定义: 加密和解密使用同一个密钥； 特性： 加密、解密使用同一个密钥； 将原始数据分割成为固定大小的块，逐个进行加密； 缺陷： 密钥过多； 密钥分发困难 算法 DES：Data Encryption Standard; 3DES：Triple DES; AES：Advanced Encryption Standard; (128bits, 192bits, 256bits, 384bits) Blowfish Twofish IDEA RC6 CAST5 3.2 公钥加密： 定义: 密钥分为公钥与私钥 公钥：从私钥中提取产生；可公开给所有人；pubkey 私钥：通过工具创建，使用者自己留存，必须保证其私密性；secret key； 特点：用公钥加密的数据，只能使用与之配对儿的私钥解密；反之亦然； 缺陷：加密时间长 用途： 数字签名：主要在于让接收方确认发送方的身份； 密钥交换：发送方用对方公钥加密一个对称密钥，并发送给对方； 数据加密 算法： RSA， DSA， ELGamal DSS: Digital Signature Standard DSA：Digital Signature Algorithm 3.3 单向加密 定义: 用于提出数据指纹；只能加密，不能解密； 特性：定长输出、雪崩效应； 功能：数据完整性校验； 算法： md5：Message Digest 5, 128bits sha1：Secure Hash Algorithm 1, 160bits sha224, sha256, sha384, sha512 3.4 密钥交换协议密钥交换协议 IKE（Internet Key Exchange）主要作用是如何在不安全的网络环境中实现密钥交换。 主要有以下算法 RSA，使用公钥加密进行密钥交换 DH算法(迪菲-赫尔曼算法) ECDH(椭圆曲线DH算法) ECDHE(临时椭圆曲线DH算法) DH 算法的密钥交换过程如下所示 1234567891011121314公钥加密DH（Deffie-Hellman）A：p, gB：p, gA: x --&gt; p^x%g ==&gt; B A: (p^y%g)^x=p^yx%gB: y --&gt; p^y%g ==&gt; A B: (p^x%g)^y=p^xy%g 4. 公钥基础设施与安全通信过程公钥基础设施主要作用是确保安全的获取通信双方的公钥，要完整了解公钥基础设施与安全通信过程我们得分成两步: 在已知通信双方公钥的情况下，我们如何安全通信 公钥基础设施如何确保我们安全拿到对方的公钥 4.1 已知公钥下安全通信过程A —&gt; B1234567891011A -----&gt; B ----&gt; 作用-----------------------------------------------------B公钥加密的 B 私钥解密 密钥交换对称加密密钥 获取对称密钥------------------------------------------------------对称加密的 ------&gt; 使用对称密钥 -----&gt; 数据保密性传输内容 解密传输内容---------------------------------------------------------A私钥加密的 --------&gt; 使用 A 公钥解密指纹 ---&gt; A 身份验证传输内容的指纹 重算传输内容指纹 对比指纹 ---&gt; 数据完整性 A: A 使用单向加密提取传输内容特征码，并使用自己的私钥加密特征码 A 使用对称密钥加密传输内容 A 使用 B 的公钥加密使用到的对称加密的密钥 B: B 使用自己的私钥解密获取对称加密的密钥 使用对称加密密钥解密整个文件内容 使用 A 的公钥解密获取邮件内容特征码 使用同样的加密算法提取接收内容的特征码，与解密的特征码对比验证数据完整性 4.2 基于CA获取公钥A —&gt; B 数字证书交换及验证 通信双方分别发送 hello 信息给对方，开启 ssl 会化，然后协商后续通信过程使用的加密算法等信息 双方分别获取对方的数字证书 通过发行者名称获取本地已经保存的CA的证书，获取CA公钥 验证CA: 使用 CA 公钥解密发行者签名，认证 CA，并获取数字证书特征码 验证数字证书完整性: 使用数字证书中签名算法ID表明的单向加密算法重新计算特征码，并与 3 中解密出来的特征码进行比对 对于主机数字证书，主体名称必须与访问的主机名称(域名) 必须一致，否则也可能不会通过认证 证书验证包括: 证书内容完整有效 证书名称与访问服务器是否一致 证书是否是信任的CA颁发的 证书是否在有效期内 证书是否在CA的吊销列表中 通信双方通过 CA 以安全方式获取私钥之后，就可以安全性的进行网络通信了。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.6 systemd及systemctl]]></title>
    <url>%2F2018%2F03%2F02%2Flinux_mt%2F16-selinux%2Fsystemd%E5%8F%8Asystemctl%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Centos7 的服务管理工具 本节我们学习 Centos7 的开机启动程序 Systemd，及其服务管理工具 systemctl。我们会与 Centos6 中的 upstart 的启动程序对比来讲解。大家也可以参考阮一峰老师的博客。本节内容如下: Systemd 概述 Systemctl 命令的使用 Systemd 配置文件格式 1. Sysmted 概述：MBR 架构的系统，开机启动过程是 POST --&gt; Boot Sequeue(BIOS) --&gt; Bootloader(MBR) --&gt; Kernel(ramdisk) --&gt; rootfs --&gt; /sbin/init，而 Systemd 正是 Centos7 的/sbin/init 程序 1.2 Systemd的新特性systemd 相比于 Centos5 的 SysV init，和 Centos 的 Upstart，具有如下特性: 新特性 系统引导时实现服务并行启动； 按需激活进程； 系统状态快照； 基于依赖关系定义服务控制逻辑； 关键特性： 基于socket的激活机制：socket与程序分离； 基于bus的激活机制； 基于device的激活机制； 基于Path的激活机制； 系统快照：保存各unit的当前状态信息于持久存储设备中； 向后兼容sysv init脚本；/etc/init.d/ 不兼容： systemctl的命令是固定不变的； 非由systemd启动的服务，systemctl无法与之通信； 1.2 服务配置Sysv init 和 Upstart 中，服务的管理单元是一个个具有特定格式的 shell 脚本，由 service 命令统一进行管理。而 Systemd 中服务的核心单元叫 Unit，unit 由其相关配置文件进行标识、识别和配置，配置文件中主要包含了系统服务、监听的socket、保存的快照以及其它与init相关的信息。systemd 按照功能将 unit 分为了如下几种类型。 unit的常见类型 类型 文件扩展名 作用 Service unit .service 用于定义系统服务 Target unit .target 用于模拟实现运行级别 Device unit .device 用于定义内核识别的设备 Mount unit .mount 定义文件系统挂载点 Socket unit .socket 用于标识进程间通信用到的socket文件 Snapshot unit .snapshot 管理系统快照 Swap unit .swap 用于标识swap设备 Automount unit .automount 文件系统自动点设备 Path unit .path 用于定义文件系统中的一文件或目录 systemd 的配置文件systemd 的配置文件位于以下三个目录中 /usr/lib/systemd/system: 实际配置文件的存存放位置 /run/systemd/system：不常用 /etc/systemd/system: 基本上都是软连接 对于那些支持 Systemd 的软件，安装的时候，会自动在/usr/lib/systemd/system目录添加一个配置文件。如果你想让该软件开机启动，就执行下面的命令（以httpd.service为例）。 12345[root@hp system]# ll /etc/systemd/system/default.targetlrwxrwxrwx. 1 root root 40 3月 5 17:37 /etc/systemd/system/default.target -&gt; /usr/lib/systemd/system/graphical.target[root@hp system]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 上面的命令相当于在 /etc/systemd/system 目录添加一个符号链接，指向 /usr/lib/systemd/system 里面的httpd.service文件。这是因为开机时，Systemd只执行 /etc/systemd/system 目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。 除了使用普通的文本查看命令外查看配置文件外，systemctl cat NAME.service 可通过服务名称直接查看配置文件 123456789101112131415161718192021222324[root@hp system]$ systemctl cat httpd# /usr/lib/systemd/system/httpd.service[Unit]Description=The Apache HTTP ServerAfter=network.target remote-fs.target nss-lookup.targetDocumentation=man:httpd(8)Documentation=man:apachectl(8)[Service]Type=notifyEnvironmentFile=/etc/sysconfig/httpdExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUNDExecReload=/usr/sbin/httpd $OPTIONS -k gracefulExecStop=/bin/kill -WINCH $&#123;MAINPID&#125;# We want systemd to give httpd some time to finish gracefully, but still want# it to kill httpd after TimeoutStopSec if something went wrong during the# graceful stop. Normally, Systemd sends SIGTERM signal right after the# ExecStop, which would kill httpd. We are sending useless SIGCONT here to give# httpd time to finish.KillSignal=SIGCONTPrivateTmp=true[Install]WantedBy=multi-user.target 2. systemctl 命令使用2.1 管理系统服务 (service unit)systemctl [OPTIONS...] COMMAND [NAME...] OPTIONS: -t, --type=: 指定查看的 unit 类型 -a, --all：查看所由服务 服务启动与关闭 作用 init systemctl 启动 service NAME start systemctl start NAME.service 停止 service NAME stop systemctl stop NAME.service 重启 service NAME restart systemctl restart NAME.service 状态 service NAME status systemctl status NAME.service 条件式重启 service NAME condrestart systemctl try-restart NAME.service 重载或重启服务 systemctl reload-or-restart NAME.servcie 重载或条件式重启服务 systemctl reload-or-try-restart NAME.service 12345678910111213141516171819[root@hp system]# systemctl status httpd● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-07 09:14:30 CST; 1s ago Docs: man:httpd(8) man:apachectl(8) Main PID: 6170 (httpd) Status: &quot;Processing requests...&quot; CGroup: /system.slice/httpd.service ├─6170 /usr/sbin/httpd -DFOREGROUND ├─6174 /usr/sbin/httpd -DFOREGROUND ├─6176 /usr/sbin/httpd -DFOREGROUND ├─6177 /usr/sbin/httpd -DFOREGROUND ├─6178 /usr/sbin/httpd -DFOREGROUND ├─6180 /usr/sbin/httpd -DFOREGROUND └─6181 /usr/sbin/httpd -DFOREGROUND8月 07 09:14:28 hp.tao systemd[1]: Starting The Apache HTTP Server...8月 07 09:14:30 hp.tao systemd[1]: Started The Apache HTTP Server. 输出: Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志 服务状态查看 作用 init systemctl 查看某服务当前激活与否的状态 systemctl is-active NAME.service 查看所有已激活的服务 systemctl list-units –type service 查看所有服务（已激活及未激活) systemctl list-units -t service –all 开机自启 作用 init systemctl 设置服务开机自启 chkconfig NAME on systemctl enable NAME.service 禁止服务开机自启 chkconfig NAME off systemctl disable NAME.service 查看某服务是否能开机自启 chkconfig –list NAME systemctl is-enabled NAME.service 查看所有服务的开机自启状态 chkconfig –list systemctl list-unit-files –type service 禁止某服务设定为开机自启 systemctl mask NAME.service 取消此禁止 systemctl unmask NAME.servcie 依赖关系 作用 init systemctl 查看服务的依赖关系 systemctl list-dependencies NAME.service 2.2 管理 target units 作用 init systemctl 运行级别 0 runlevel0.target, poweroff.target 运行级别 1 runlevel1.target, rescue.target 运行级别 2 runlevel2.tartet, multi-user.target 运行级别 3 runlevel3.tartet, multi-user.target 运行级别 4 runlevel4.tartet, multi-user.target 运行级别 5 runlevel5.target, graphical.target 运行级别 6 runlevel6.target, reboot.target 级别切换 init N systemctl isolate NAME.target 查看级别 runlevel systemctl list-units –type target 查看所有级别 systemctl list-units -t target -a 获取默认运行级别 /etc/inittab systemctl get-default 修改默认运行级别 /etc/inittab systemctl set-default NAME.target 切换至紧急救援模式 systemctl rescue 切换至emergency模式 systemctl emergency 2.3 其它常用快捷命令 关机： systemctl halt, systemctl poweroff 重启： systemctl reboot 挂起： systemctl suspend 快照： systemctl hibernate 快照并挂起： systemctl hybrid-sleep 3. service unit file 配置3.1 unit file 组成unit file 通常由如下 三个部分组成: [Unit]： 定义与Unit类型无关的通用选项； 用于提供 unit 的描述信息、unit 行为及依赖关系等； [Service]： 与特定类型相关的专用选项；此处为 Service 类型； [Install]： 定义由systemctl enable以及systemctl disable命令在实现服务启用或禁用时用到的一些选项； 12345678910111213141516171819# systemctl cat sshd# /usr/lib/systemd/system/sshd.service[Unit]Description=OpenSSH server daemonDocumentation=man:sshd(8) man:sshd_config(5)After=network.target sshd-keygen.serviceWants=sshd-keygen.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/sshdExecStart=/usr/sbin/sshd -D $OPTIONSExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target Unit段 Description：当前服务的简单描述 After：定义unit的启动次序；表示当前unit应该晚于哪些unit启动；其功能与Before相反； Before：定义sshd.service应该在哪些服务之前启动 Requies：依赖到的其它units；强依赖，被依赖的units无法激活或异常退出时，当前unit即无法激活； Wants：依赖到的其它units；弱依赖，被依赖的units无法激活时，不影响当 unit 的启动； Conflicts：定义units间的冲突关系； 附注： After和Before字段只涉及启动顺序，不涉及依赖关系 Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的 Service段 Type：用于定义影响ExecStart及相关参数的功能的unit进程启动类型； simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 EnvironmentFile：指定当前服务的环境参数文件 ExecStart：指明启动unit要运行命令或脚本；其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件 ExecReload：重启服务时执行的命令 ExecStop：停止服务时执行的命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 Restart：定义了服务退出后，Systemd 的重启方式 no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 on-abnormal：只有被信号终止和超时，才会重启 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启 附注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal KillMode:定义 Systemd 如何停止服务 control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。 RestartSec：表示 Systemd 重启服务之前，需要等待的秒数 对于 sshd 服务而言将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。 所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误 Install段 Alias： RequiredBy：被哪些units所依赖； WantedBy：表示该服务所在的 Target 3.2 修改配置文件后重启对于新创建的unit文件或修改了的unit文件，要通知systemd重载此配置文件 systemctl daemon-reload 4.Target 的配置文件12345678910111213141516[root@hp system]$ systemctl cat multi-user.target# /usr/lib/systemd/system/multi-user.target# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Multi-User SystemDocumentation=man:systemd.special(7)Requires=basic.targetConflicts=rescue.service rescue.targetAfter=basic.target rescue.service rescue.targetAllowIsolate=yes Target 配置文件里面没有启动命令 Requires：要求basic.target一起运行。 Conflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。 After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。 AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.5 SELinux简介]]></title>
    <url>%2F2018%2F03%2F01%2Flinux_mt%2F16-selinux%2FSELinux%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[SELinux简介 对于安全性很多人存在误解，觉得 Linux 比 windows 更加安全，其实不然。SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，用于增强 Linux 的安全性。SELinux 在实际生产环境中使用的很少，原因并不是 SELinux 不够好，而是想要做到精准的权限控制，需要明确知道并管理进程需要访问的资源，对这些信息的管理本身有很大负担。所以本节我们只介绍 SELinux 的简单原理和管理，并不会对其做深入介绍。具体内容包括: SELinux 的权限模型 SELinux 工作模型 SELinux 管理 1. SELinux 权限模型Linux传统权限模型下，进程能够访问的哪些资源，取决于进程的发启者能够访问的资源集合。这样存在一些弊端，资源所需访问的资源很少，但是能够访问的资源却很大，一旦进程被不怀好意的人控制，就会对 Linux 安全造成威胁。因此 SELinux 才用最小权限法则，进程只能访问那些它必需访问控制的资源，这样就可以提高 Linux 的安全性。两种权限模型的对比如下: Linux传统权限模型 权限模型: DAC (Discretionary Access Control) 自主访问控制 进程权限: 取决于进程发起者作为属主、属组、其它用户的权限集和 SELinux: 权限模型: MAC (Mandatory Access Control): 强制访问控制 TE (Type Enforcement)：最小权限法则 进程权限: 取决于SELinux 规则库 SELinux 有两种工作级别，不同工作级别下，受控级别的范围不同: strict： 每个进程都收到 selinux 的控制 targeted: 仅有限个进程受到 selinux 的控制，只监控容易被入侵的进程 之所以有 targeted 级别，主要还是受限于管理所有进程能够访问资源的成本太高 2. SELinux 工作模型进程的执行过程可以概括成 “进程对资源执行的操作” 即 subject operation object subject: 进程主体 object: 系统资源，主要是文件 operation: 进程对资源能够执行的操作 SELinux 的核心就是确定”进程能够对哪些资源执行什么操作”。为了将进程与资源关联起来，SELinux 为每个进程及文件提供了安全标签 安全标签: user:role:type:: user: SELinux 的 user role: 角色 type: 类型 进程的 type 称为域 domain,表示一个空间 资源的 type 称为类型，域能访问哪些资源类型取决于 SELinux 规则库 policy domian 包含的 type 即进程能够操作的资源范围，domian 与 type 的对应关系记录在 SELinux 的规则库中 除了对进程访问资源的控制外，SELinux 还对进程的功能作了限制，比如 httpd 进程而言，其有上传和下载等功能，相对于下载而言，上传功能的风险则高的多。因此默认情况下高风险功能在 SELinux 中是禁止的，想要启用必需显示开启。这部分控制又称为 SELinux 的布尔规则设置。 2.1 进程的安全标签如下第一段 LABEL 即为进程的域，由 5 段组成，后两段对于我们了解 SELinux 意义不大 123456[root@hp ~]# ps auxZLABEL USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDsystem_u:system_r:init_t:s0 root 1 0.7 0.1 194440 9048 ? Ss 21:28 0:02 /usr/lib/systemd/systemd --switched-root --system --deserializesystem_u:system_r:kernel_t:s0 root 2 0.0 0.0 0 0 ? S 21:28 0:00 [kthreadd]system_u:system_r:kernel_t:s0 root 3 0.0 0.0 0 0 ? S 21:28 0:00 [ksoftirqd/0]system_u:system_r:kernel_t:s0 root 4 0.0 0.0 0 0 ? S 21:28 0:00 [kworker/0:0] 2.2 文件的类型system_u:object_r:admin_home_t:s0 即为文件的类型 1234[root@hp ~]# ll -Z .-rw-------. root root system_u:object_r:admin_home_t:s0 anaconda-ks.cfgdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Desktopdrwxr-xr-x. root root unconfined_u:object_r:admin_home_t:s0 Documents 2.3 SELinux 规则库 policySELinux 的规则遵循“法无授权即禁止不可行”的原则，即如果进程受 SELinux 控制，如果规则库中没有显示定义规则则禁止访问。另外由于所由进程对资源的访问都会读取 SELinux 规则库，因此规则库以二进制格式进行存放，需要专用的命令才能修改。 SELinux 的规则库即按照我们之前所说的模型进行编写: subject operation object ==&gt; domain --&gt; policy --&gt; type subject: 主-进程 domain object: 宾-资源 type Files Directories Porcesses Special files or various types(块设备文件、字符设备、FIFO、socket) FileSystems Links File descriptors operation: 谓-操作 Create Read Write Lock Rename Link Unlink Append Excute I/O Control 2. SELinux 配置文件SELinux 的配置位于 /etc/sysconfig/selinux 1234567891011# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=permissive# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected.# mls - Multi Level Security protection.SELINUXTYPE=targeted 参数: SELINUXTYPE: SELinux 的工作级别 SELINUX: SELinux 启用状态 disabled: 禁用，关闭 SELinux enforcing: 启用，强制，一旦进程不符合 SELinux 的权限控制会禁止进程访问相关资源 permissive: 启用，警告，SELinux 不会禁止进程违规访问资源，仅记录日志 附注: SELinux 日志文件则位于: /var/log/audit/audit.log 需要特别说明的是由 disabled –&gt; enforcing|permissive 需要重启系统才会生效，因为系统要为所有受控的进程和文件打上安全标签 3. SELinux 相关命令3.1 SELinux 启用状态管理getenforcegetenforce 作用: 获取当前 SELinux 状态 12[root@hp ~]# getenforcePermissive 显示: disabled: 禁用 permissive: 警告，仅记录日志 enforcing: 强制 setenforcesetenforce value 作用: 启用SELinux value: 0: 设置为 permissive 1: 设置为 enforcing 效力: 当前有效，开机后无效 附注: 永久有效，需修改配置文件。 需要特别注意的是使用 setenfoce 命令的前提是 SELinux 状态不能为 disabled。如果 SELinux 为 disabled 只能修改配置文件然后重启。 12vim /etc/selinux/config # 或 /etc/sysconfig/selinuxSELINUX=&#123;disabled|enforcing|permissive&#125; 2.3 SELinux type 标签管理ls -Z /path/to/somefile 作用: 查看文件标签 ps auxZ 作用: 查看进程标签 chconchcon OPTIIONS file 作用: change context 修改文件安全标签 OPTIONS -t TYPE: 设置文件 type -R: 递归修改 --reference=file: 参考某文件的标签进行设置 12345678910[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa[root@hp tmp]# chcon -t admin_home_t aa[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:admin_home_t:s0 aa[root@hp tmp]# chcon aa --reference bb[root@hp tmp]# ll -Z aa-rw-r--r--. root root unconfined_u:object_r:user_tmp_t:s0 aa restoreconrestorecon -R file 作用: 还原默认标签 -R: 递归修改 2.4 SELinux的布尔规则设置getseboolgetsebool [-a] [boolean_name] 作用: 显示 SELinux 布尔型规则 参数: boolean_name 规则名称 选项: -a 显示所有布尔型规则 123456789101112[root@hp ~]# getsebool -a|grep httpdhttpd_anon_write --&gt; offhttpd_builtin_scripting --&gt; onhttpd_can_check_spam --&gt; offhttpd_can_connect_ftp --&gt; offhttpd_can_connect_ldap --&gt; offhttpd_can_connect_mythtv --&gt; offhttpd_can_connect_zabbix --&gt; offhttpd_can_network_connect --&gt; offhttpd_can_network_connect_cobbler --&gt; offhttpd_can_network_connect_db --&gt; offhttpd_can_network_memcache --&gt; off setseboolsetsebool [ -PNV ] boolean value | bool1=val1 bool2=val2 ... 作用: 设置布尔规则 VARIABLE: ={0|off|false}: 关闭功能 ={1|on|true}: 开启功能 选项: P: 将修改写入配置文件中，否则仅仅当前设置有效 123456[root@hp tmp]# getsebool httpd_use_nfshttpd_use_nfs --&gt; off[root@hp tmp]# setsebool httpd_use_nfs 1[root@hp tmp]# getsebool httpd_use_nfshttpd_use_nfs --&gt; on]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.4 通过 ks 自动安装系统]]></title>
    <url>%2F2018%2F02%2F28%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2F%E9%80%9A%E8%BF%87ks%E8%87%AA%E5%8A%A8%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[通过 ks 自动安装系统 1. 通过 ks 利用光盘的仓库安装操作系统1.1 配置 http 服务器 在 192.168.1.110 配置一个 http 服务器，让局域网内的所有机器都能访问到(http://192.168.1.110/anaconda-ks.cfg) 1.2 修改 kickstart 文件ksvalidator anaconda-ks.cfg: 检查 ks 语法错误 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&apos;cn&apos;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activatenetwork --hostname=www.tao.com# Root passwordrootpw --iscrypted $6$LZCrSYmUUKgH0NFI$T49uuvCjfCfl/7f87EZUHFBcqIRWjkhGeNuyHhGn/xUzv1o2sHefEH3AwHoMV7eVWY5rg2BarnuzlUkOCLgbL0# System servicesservices --disabled=&quot;chronyd&quot;# System timezonetimezone Asia/Shanghai --isUtc --nontpuser --name=tao --password=$6$wpzzJIpol5z5KHw0$bsn4zRMv1hkBwg2HV8dqeE895i4YdgJU.J6q222HSec/sUBBPZflcdipfn9Z3U96mzlS48gZ5vFBAOG/WjV561 --iscrypted --gecos=&quot;tao&quot;# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda# Partition clearing informationclearpart --initlabel --list=nvme0n1p11,nvme0n1p10,nvme0n1p8# Disk partitioning informationpart /boot/efi --fstype=&quot;efi&quot; --ondisk=nvme0n1 --size=1028 --fsoptions=&quot;umask=0077,shortname=winnt&quot;part pv.1133 --fstype=&quot;lvmpv&quot; --ondisk=nvme0n1 --size=153604part /boot --fstype=&quot;xfs&quot; --ondisk=nvme0n1 --size=1021volgroup cl --pesize=4096 pv.1133logvol /home --fstype=&quot;xfs&quot; --size=25600 --name=home --vgname=cllogvol /var --fstype=&quot;xfs&quot; --size=46080 --name=var --vgname=cllogvol swap --fstype=&quot;swap&quot; --size=2048 --name=swap --vgname=cllogvol / --fstype=&quot;xfs&quot; --size=25600 --name=root --vgname=cllogvol /usr --fstype=&quot;xfs&quot; --size=51200 --name=usr --vgname=cl%packages@^developer-workstation-environment@base@core@debugging@desktop-debugging@development@dial-up@directory-client@fonts@gnome-apps@gnome-desktop@guest-desktop-agents@input-methods@internet-applications@internet-browser@java-platform@multimedia@network-file-system-client@performance@perl-runtime@print-client@ruby-runtime@virtualization-client@virtualization-hypervisor@virtualization-tools@web-server@x11kexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 1.3 创建虚拟机并启动安装进入安装的 boot 界面输入1boot linux text ip=192.168.1.115 netmask=255.255.255.0 ks=http:/192.168.1.110/ks.cfg 2. 通过自制光盘自动安装操作系统2.1 创建 kickstart 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts=&apos;cn&apos;# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=enp0s3 --onboot=off --ipv6=auto --no-activatenetwork --hostname=virtual.tao# Root passwordrootpw --iscrypted $6$oSLEiL/Vx1k1thR7$5oER8NwNYgfdZcegPA6bBLyvMREZ5Pa6gEuikfDR.B09Mv7kWyJAaXAOoIbfBCZXDj91a5rBealE3S17i71.f1# System servicesservices --enabled=&quot;chronyd&quot;# System timezonetimezone Asia/Shanghai --isUtcuser --groups=wheel --name=tao --password=$6$U7NwGZhelPqRaCP5$3VO3wcfzClT/nGXqoQobVN7.jlIfSTHDgUApHjAcwDhxROWK5/s3zZE0zUIaIhZse1OES30roxS1yxEQyydUv. --iscrypted --gecos=&quot;tao&quot;# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=&quot; crashkernel=auto&quot; --location=mbr --boot-drive=sda# Partition clearing informationclearpart --none --initlabel# Disk partitioning informationpart pv.157 --fstype=&quot;lvmpv&quot; --ondisk=sda --size=31747part /boot --fstype=&quot;xfs&quot; --ondisk=sda --size=1024volgroup centos --pesize=4096 pv.157logvol / --fstype=&quot;xfs&quot; --size=10240 --name=root --vgname=centoslogvol /var --fstype=&quot;xfs&quot; --size=10240 --name=var --vgname=centoslogvol /home --fstype=&quot;xfs&quot; --size=10240 --name=home --vgname=centoslogvol swap --fstype=&quot;swap&quot; --size=1020 --name=swap --vgname=centos%packages@^gnome-desktop-environment@base@core@desktop-debugging@development@dial-up@directory-client@fonts@gnome-desktop@guest-agents@guest-desktop-agents@input-methods@internet-browser@java-platform@multimedia@network-file-system-client@networkmanager-submodules@print-client@x11chronykexec-tools%end%addon com_redhat_kdump --enable --reserve-mb=&apos;auto&apos;%end%anacondapwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notemptypwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyokpwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty%end 2.2 创建磁盘映像文件123456789101112131415161718cd /var/isomkdir cdrommount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/cp -ra cdrom/ mybootvim myboot/ks.cfg # 复制上述的 kickstart 文件# 添加安装菜单vim isolinux/isolinux.cfglabel ks menu label ^Install tao linux kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfg# 创建光盘镜像genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V "CentOS 7 x86_64" -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/# -V "CentOS 7 x86_64" 必需与 hd:LABEL=CentOS\x207\x20x86_64 保持一致 3. 通过自制光盘使用网络仓库安装操作系统3.1 制作镜像文件12345678910111213141516171819cd /var/isomount -o loop CentOS-7-x86_64-DVD-1708.iso cdrom/cp -ra cdrom/isolinux/ myiso/vim isolinux/isolinux.cfg # 添加开机菜单label ks menu label Ks Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfgcd myisocp /root/anaconda-ks.cfg ks.cfgvim ks.cfg # Use CDROM installation media 更改为 # cdrom url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/genisoimage -o Net.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V &quot;CentOS 7 x86_64&quot; -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myiso 3.2 修改 kickstart 文件ks 文件与上面的配置类似，但是需要使用 url 命令指定外部仓库的位置，将12345# Use CDROM installation media 更改为cdrom# 更改为url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/ 3.3 创建虚拟机并启动安装创建虚拟机后，选择配置的菜单，启动自动安装过程]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.3 Centos 安装程序 anaconda 配置]]></title>
    <url>%2F2018%2F02%2F27%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2Fanaconda%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Centos 安装程序 anaconda 配置 上一节我们讲解了 Centos 的安装启动过程，下面我们来说一下，anaconda 启动后会进行哪些操作，以及如何配置 anaconda。 1. anaconda的工作过程anaconda 在进行操作系统安装时会经由如下几个步骤: 安装前配置阶段，包括设置如下参数 安装过程使用的语言； 键盘类型 安装目标存储设备 Basic Storage：本地磁盘 Special Storage： iSCSI 设定主机名 配置网络接口 时区 管理员密码 设定分区方式及MBR的安装位置； 创建一个普通用户； 选定要安装的程序包； 安装阶段 在目标磁盘创建分区并执行格式化； 将选定的程序包安装至目标位置； 安装bootloader； 首次启动 iptables selinux core dump 2. anaconda的配置方式安装前配置阶段，有两种配置方式 交互式配置方式；利用 anaconda 提供的安装界面，逐项进行选择配置 通过读取配置文件中，事先定义好的配置项，自动完成配置；此文件即为kickstart文件；交互式配置安装完成后，在 root 目录下会生成此次安装的 kickstart 文件 /root/anaconda-ks.cfg kickstart 文件有特定的语法格式 可以直接手动编辑，或依据模板修改 也可以使用创建工具 system-config-kickstart，此命令会提供给我们一个交互界面，类似模拟 anaconda 的安装界面。我们可以打开 root 目录下生成的 kickstart 文件作为模板来生成我们的kickstart 文件。system-config-kickstart 安装与使用界面如所示 12345yum install system-config-kickstartsystem-config-kickstart# ksvalidator 命令可用于检查 ks 文件是否有语法错误ksvalidator /root/kickstart.cfg 3. kickstart 文件格式大体上，kickstart 文件由三个部分组成123456789101112131415161718# 1. 命令段#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical......# 2. 程序包段%packages # 开始标记@group_name # 要安装的包组package # 要安装的单个包-package # 不要安装的单个程序包%end # 结束标记# 3. 脚本段 命令段：指定各种安装前配置选项，如键盘类型等；有一些是必备命令，有一些则是可选命令 程序包段：指明要安装程序包，以及包组，也包括不安装的程序包； 脚本段： %pre：安装前脚本，运行环境：运行安装介质上的微型Linux系统环境； %post：安装后脚本，运行环境：安装完成的系统； 3.1 命令段kickstart 可用命令很多，想深入了解，可以参考官方文档：《Installation Guide》。下面是我安装 Centos7 之后生成的 ks 文件。我们只会介绍最常用的命令的。 123456789101112131415161718192021222324252627282930313233#version=DEVEL# System authorization informationauth --enableshadow --passalgo=sha512# Use CDROM installation mediacdrom# Use graphical installgraphical# Run the Setup Agent on first bootfirstboot --enableignoredisk --only-use=sda# Keyboard layoutskeyboard --vckeymap=cn --xlayouts='cn'# System languagelang zh_CN.UTF-8# Network informationnetwork --bootproto=dhcp --device=ens33 --onboot=off --ipv6=auto --no-activatenetwork --hostname=localhost.localdomain# Root passwordrootpw --iscrypted $6$ji4or39qLiMVBwAi$E9N78iOYlZw9zzD3g3CGgVvb7MSUgLbsjq9WiwIu6qSGV.y8Sbmx8WtvrWyAPnKkHhdxJKhUAZqXl2zrzjp3t0# System servicesservices --enabled="chronyd"# System timezonetimezone Asia/Shanghai --isUtcuser --groups=wheel --name=tao --password=$6$u/SLeiTrWJUgp.8E$fGCp/IAm01lyGVBkcYMTrutmAFDjdEblCorhX5Kv.cgCZvVpn8PB4LoQ/6.Qn1Tlvq0YqwhzivNqqCSeGpgc5/ --iscrypted --gecos="tao"# X Window System configuration informationxconfig --startxonboot# System bootloader configurationbootloader --append=" crashkernel=auto" --location=mbr --boot-drive=sdaautopart --type=lvm# Partition clearing informationclearpart --none --initlabel 必备命令 authconfig --enableshadow --passalgo=sha512:认证方式配置 bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb quiet&quot; 作用: 定义bootloader的安装位置及相关配置 --append: 添加到内核的参数 keyboard us: 设置键盘类型 lang zh_CN.UTF-8: 语言类型 part: 创建磁盘分区 clearpart --none --drives=sda：清空磁盘分区 part /boot --fstype=ext4 --size=500: 定义基本磁盘分区 part pv.008002 --size=51200: 创建逻辑卷的物理卷，008002 为物理卷的标识 volgroup myvg --pesize=4096 pv.008002: 创建逻辑卷组 logvol /home --fstype=ext4 --name=lv_home --vgname=myvg --size=5120: 创建逻辑卷 rootpw --iscrypted passwd: 管理员密码 timezone Asia/Shanghai: 时区 12# 生成加密密码的方式(root 密码)openssl passwd -1 -salt `openssl rand -hex 4` 可选命令 install|upgrade：安装或升级； text|graphical：安装界面类型，text为tui，默认为GUI network --onboot yes --device eth0 --bootproto dhcp --noipv6 作用: 配置网络接口 --onboot yes: ifcfg 中的 ON_BOOT 参数，其他参数类似 firewall: 防火墙设置 firewall --disabled: 关闭防火墙 firewall --service ssh: 启动防火墙，放行 ssh 服务 selinux --disabled: 关闭 selinux halt|poweroff|reboot：安装完成之后的行为； repo --name=&quot;CentOS&quot; --baseurl=cdrom:sr0 --cost=100 作用: 指明安装时使用的repository； url --url=http://172.16.0.1/cobbler/ks_mirror/CentOS-6.7-x86_64/ 作用: 指明安装时使用的repository，但为url格式； url --url=https://mirrors.aliyun.com/centos/7/os/x86_64/]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.2 Centos安装过程]]></title>
    <url>%2F2018%2F02%2F26%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2FCentos%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos安装过程 本节我们来讲解 Centos 系统的安装过程。 1. 安装程序：anaconda前面我们说过操作系统的层次，如下图所示，因为直接面向硬件编程是一件非常困难的是，所以才有了操作系统。如果有安装过 Centos 系统就会知道，安装过程有一个操作界面供我们进行选择安装，显然这是一个应用程序，那么这个应用程序是直接在硬件之上编写的么？我们说过在硬件之上编写应用程序是极其困难的，且不易移植，所以我们的安装程序也是构建在内核之上，只不过这个内核不是来自我们的计算机，而是我们的安装光盘或U盘上。Centos 的安装程序就是 annaconda。123456789--------------| 库调用接口 |---------------| 系统调用接口 |-------------------------------| 操 作 系 统 |-------------------------------| 底 层 硬 件 |------------------------------- 2. 安装光盘的结构12345678910111213141516mount -r /dev/cdrom /media/cdromcd /media/cdromtree -L 1.├── CentOS_BuildTag├── EFI├── EULA├── GPL├── images├── isolinux # 内核所在目录├── LiveOS├── Packages├── repodata├── RPM-GPG-KEY-CentOS-7├── RPM-GPG-KEY-CentOS-Testing-7└── TRANS.TBL 我们安装光盘的目录结构如上所示，isolinux 就是光盘上操作系统内核所在的目录，其余部分是程序包仓库。 操作系统安装时 首先加载操作系统内核； 光盘安装就是加载位于 isolinux 中的内核 除了光盘，内核还可以来自 U 盘，网络等其他引导设备 通过 PXE 可以实现通过网络自动安装操作系统，这个我们会在后面详述配置过程。 启动 anaconda，进而根据用户选择，安装操作系统 anacona及其安装用到的程序包等来自于程序包仓库，此仓库的位置可以为 本地光盘，光盘中 isolinx 之外的就是目录就是程序包仓库 本地硬盘 ftp server http server nfs server anaconda 提供的安装界面分为: tui：基于cureses的文本配置窗口 gui：图形界面 3. CentOS的安装过程启动流程当前我们就以光盘安装来讲解 Centos 的安装过程1234567891011121314cd /media/cdrom/isolinuxtree -L 1.├── boot.cat # MBR 中的 bootLoader├── boot.msg├── grub.conf├── initrd.img├── isolinux.bin # 提供安装界面├── isolinux.cfg # 配置文件，包含开机菜单├── memtest├── splash.png├── TRANS.TBL├── vesamenu.c32└── vmlinuz 加载并启动 BootLoader Stage1: 执行 isolinux/boot.cat，光盘的 MBR 包含的就是此文件 Stage2: 执行 isolinux/isolinux.bin 提供安装界面和开机启动菜单 BootLoader 引导和加载内核，并装载根文件系统 内核: isolinux/vmlinuz 根文件系统: isolinux/initrd.img 启动anaconda 默认界面是图形界面：512MB+内存空间； 若需要显式指定启动TUI接口： 向启动内核传递一个参数”text”即可； 如果想手动指定安装仓库，也可以通过向内核传递参数更改 3.1 isolinux.binisolinux.bin 其配置文件位于 isolinux/isolinux.cfg，配置文件中包含了开机启动菜单 1234567891011121314151617vim /media/cdrom/isolinux/isolinux.cfg....label linux # 菜单标识 menu label ^Install CentOS 7 # 菜单名称 kernel vmlinuz # 指定内核 # 内核参数，通过 boot 命令行添加的参数会添加在此行后 append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quietlabel rescue menu indent count 5 menu label ^Rescue a CentOS system text help If the system will not boot, this lets you access files and edit config files to try to get it booting again. endtext kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 rescue quiet 3.2 向内核传递参数安装启动时，我们可以通过向内核传递参数，来更改 anacoda 的启动方式，那么如何向内核参数传递参数呢？ 首先进入安装界面，这个安装界面就是 isolinux/isolinux.bin 提供的，上面的选项就是 isolinux/isolinux.cfg 配置文件的内容 然后按 ESC 即进入 boot 命令行界面，输入菜单标识 参数即可以向对应菜单的内核传递参数。传递的参数将附加在, isolinux.cfg 对应菜单的 append 行后面。例如通过 boot 界面控制 anaconda 的启动方式: linux text: 指定 anaconda 以tui 方式启动 linux method: 手动指定程序包源 说明: 此处 linux 表示 isolinux.cfg 中的一个菜单标识 也可以在特定的菜单名称上按 TAB 键，就可以编辑特定菜单的参数 3.3 boot 界面的安装引导选项boot 界面有如下选项可供使用: text：文本安装方式 method：手动指定使用的安装方法 与网络相关的引导选项： ip=IPADDR netmask=MASK gateway=GW dns=DNS_SERVER_IP ifname=NAME:MAC_ADDR – 指定上述设置应用在哪个网卡上 远程访问功能相关的引导选项： vnc vncpassword=&#39;PASSWORD&#39; 启动紧急救援模式： rescue 装载额外驱动： dd 指定 kickstart 文件的位置 ks= DVD drive: ks=cdrom:/PATH/TO/KICKSTART_FILE Hard Drive： ks=hd:/DEVICE/PATH/TO/KICKSTART_FILE HTTP Server： ks=http://HOST[:PORT]/PATH/TO/KICKSTART_FILE FTP Server: ks=ftp://HOST[:PORT]/PATH/TO/KICKSTART_FILE HTTPS Server: ks=https://HOST[:PORT]/PATH/TO/KICKSTART_FILE 安装选项文档: www.redhat.com/docs , 《installation guide》 4. 创建引导光盘我们可以创建自己的镜像文件，在镜像文件内创建好 kickstart 文件，并在菜单中配置好 ks 的位置，这样就可以直接进行安装。下面是配置过程1234567891011121314&gt; mkdir /tmp/myiso/isolinux&gt; cp /media/cdrom/isolinux/* /tmp/myiso/isolinux&gt; cp /root/kickstart.cfg /tmp/myiso/isoLinux# centos6&gt; mkisofs -R -J -T -v --no-emul-boot --boot-load-size 4 --boot-info-table -V &quot;CentOS 6 x86_64 boot&quot; -c isolinux/boot.cat -b isolinux/isolinux.bin -o /root/boot.iso myiso/# Centos7&gt; sudo genisoimage -o CentOS-7.iso -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -R -J -v -T -V &quot;CentOS 7 x86_64&quot; -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot myboot/## 配置 isolinux/isolinux.cfg 添加安装项，直接配置 ks 参数label ks menu label ^Install CentOS 7 kernel vmlinuz append initrd=initrd.img inst.stage2=hd:LABEL=CentOS\x207\x20x86_64 quiet ks=cdrom:/ks.cfg mkisofs使用 mkisofs 创建磁盘镜像文件时，有以下几个特别注意的点需要注意: -V 参数指定的标签必需与 isolinux/isolinux.cfg 中的 hd:LABEL=的值相同，否则开机启动时将找不到磁盘镜像文件 如果要在 efi 启动，需要添加如下参数： -eltorito-alt-boot -bimages/efiboot.img -no-emul-boot 不能在 Centos6 的系统上制作 Centos7 因为两者系统的 genisoimage 命令的版本不一样， 6 的系统制作出来的 iso 不能在 efi 环境启动； 详细可参考这边博客 https://www.linuxidc.com/Linux/2015-03/114509.htm]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[14.1 Linux内核模块功能定制]]></title>
    <url>%2F2018%2F02%2F25%2Flinux_mt%2F15-Linux%E5%86%85%E6%A0%B8%E5%AE%9A%E5%88%B6%E4%BB%A5%E5%8F%8A%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%8A%A8%E5%8C%96%E5%AE%89%E8%A3%85%E5%AE%9E%E6%88%98%2FLinux%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E5%8A%9F%E8%83%BD%E5%AE%9A%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Linux内核模块功能定制 上一章我们详细讲解了 Linux 启动流程，再此基础上，本章我们来讲解内核的编译和安装。本章内容如下: 编译内核以定制内核功能 Centos 操作系统的安装过程 Centos 安装程序 anaconda 配置 内核编译是一个大工程，需要对硬件，内核各个参数功能都有比较深入了解，才能编译出有特定功能需求的内核。本节主要是带大家了解内核的编译过程，能编译成功即可。本节内容如下: 编译内核的环境准备 根据当前操作系统的编译模板，编译内核 1. 编译内核在编译内核之前，我们需要了解目标主机的功能需求，并准备好开发环境，具体可包括如下几个方面: 准备好开发环境； 获取目标主机上硬件设备的相关信息； 获取到目标主机系统功能的相关信息，例如要启用的文件系统； 获取内核源代码包：http://www.kernel.org 1.1 准备开发环境开发环境主要是准备编译环境，Centos6-7 中安装如下两个包组即可: Development Tools: 中文下叫”开发工具” Server Platform Development: 中文下叫 “服务器平台开发” - Centos7 可能没有此包组 1.2 获取目标主机上硬件设备的相关信息Linux 中有如下命令，可以帮助我们获取硬件设备的相关信息包括: CPU： cat /proc/cpuinfo lscpu x86info -a PCI设备： lspci [-v|-vv] lsusb [-v|-vv]: 显示 usb 信息 lsblk: 显示块设备信息 了解全部硬件设备信息：hal-device(Centos6) 2. 内核编译过程：内核的编译与程序包的编译安装过程类似，遵循./configure ==&gt; make ==&gt; make install。接下来我们将利用现有操作系统的编译安装模板，来编译一个内核。 2.1 简单依据模板文件的制作过程：1234567891011121314151617181920212223#！/bin/bash# 1. 编译内核tar xf linux-3.10.67.tar.xz -C /usr/srccd /usr/srcln -sv linux-3.10.67 linuxcd linux# cp /boot/config-$(uname -r) .config # 复制当前系统的编译模板进行参考make menuconfig # 配置内核选项make [-j \#] # 编译内核，可使用-j指定编译线程数量make modules_install # 安装内核模块make install # 安装内核# make install 会自动完成以下步骤# 2. 安装 bzImage 为 /boot/vmlinuxz-VERSION-RELEASEll arch/x86/boot/bzImagell arch/x86_64/boot/bzImage# 3. 生成 initramfs 文件# 4. 编辑 grub 的配置文件# 5. 重启系统，选择使用新内核 2.2 screen命令：执行 make 命令时，如果是远程连接到服务器，可能因为网络问题而断开连接，此时 make 就会终止。为了避免因为断开连接导致编译过程前功尽弃，可以使用 screen 命令 screen 作用: 终端模拟器，允许在一个终端上打开多个屏幕 特性: screen 的模拟终端不会因为当前物理终端断开连接而丢失，即 screen 内运行的程序不会因为物理终端断开连接而终止 选项: 打开screen： screen 拆除screen： Ctrl+a, d 列出screen： screen -ls 连接至screen：screen -r SCREEN_ID 关闭screen: exit 2.3 编译过程的详细说明： 配置内核选项 支持“更新”模式进行配置：在已有的.config文件的基础之上进行“修改”配置； make config：基于命令行以遍历的方式去配置内核中可配置的每个选项； make menuconfig：基于cureses的文本配置窗口；需要额外安装 ncurses-devel 包 make gconfig：基于GTK开发环境的窗口界面； 包组“桌面平台开发” make xonfig：基于QT开发环境的窗口界面； 支持“全新配置”模式进行配置： make defconfig：基于内核为目标平台提供的“默认”配置为模板进行配置； make allnoconfig：所有选项均为“no”； 编译 多线程编译：make [-j #] 编译内核中的一部分代码： 只编译某子目录中的相关代码： cd /usr/src/linux make path/to/dir/ – 只能在内核源码目录内，基于相对路径编译 只编译一个特定的模块 cd /usr/src/linux make path/to/dir/file.ko 如何交叉编译： 目标平台与当前编译操作所在的平台不同； make ARCH=arch_name 要获取特定目标平台的使用帮助： make ARCH=arch_name help 如何在执行过编译操作的内核源码树上做重新编译： 事先清理操作： make clean：清理编译生成的绝大多数文件，但会保留config，及编译外部模块所需要的文件； make mrproper：清理编译生成的所有文件，包括配置生成的config文件及某些备份文件； make distclean：相当于mrproper，额外清理各种patches以及编辑器备份文件；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.6 Linux内核功能及模块应用]]></title>
    <url>%2F2018%2F02%2F24%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FLinux%E5%86%85%E6%A0%B8%E5%8A%9F%E8%83%BD%E5%8F%8A%E6%A8%A1%E5%9D%97%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Linux内核功能及模块应用 之前的章节中，我们讲解了 Linux 系统的启动流程，grub，以及 系统启动之后的 init 程序，最后我们来讲解 Linux 内核相关内容，包括 Linux 内核的组成，包括 内核，内核模块，ramdisk 内核模块的管理 ramdisk 文件的制作 内核参数的修改 1. Linux 内核设计体系1.1 内核的组成部分：Linux 是单内核设计，但引入了模块化机制，其组成包括如下几个部分 kernel：内核核心，一般为bzImage，通常位于/boot目录，名称为vmlinuz-VERSION-release； kernel object： 内核对象，即内核模块，一般放置于/lib/modules/VERSION-release/ 内核模块与内核核心版本一定要严格匹配； ramdisk：辅助性文件，并非必须，这取决于内核是否能直接驱动rootfs所在的设备。ramdisk 是一个简装版的根文件系统，可能包括 目标设备驱动，例如SCSI设备的驱动； 逻辑设备驱动，例如LVM设备的驱动； 文件系统，例如xfs文件系统； 1.2 内核信息获取uname命令：uname [OPTION]... 作用: print system information 选项： -a: 显示所有内核信息 -r：内核的release号 -n：主机名，节点名称 2. 模块信息获取和管理2.1 模块信息获取模块信息获取有 lsmod, moinfo 两个命令，它们的用法如下 lsmodlsmod： 作用: 显示内核已经装载的模块 来源: 显示的内容来自于 /proc/modules 文件 modinfomodinfo [-F field] [-k kernel] [modulename|filename...]： 作用: 查看单个模块的详细信息 选项: -F field： 仅显示指定字段的信息； -n：显示模块文件路径； -p：显示模块参数 12&gt; modinfo -F filename btrfs&gt; modinfo -n btrfs depmoddepmod 作用: 内核模块依赖关系文件及系统信息映射文件的生成工具； 2.2 模块管理模块装卸载有两组命令，一组是 modprobe 可以自动解决模块的依赖关系，另一组是 insmod,rmmod 不能自动解决模块的依赖关系，它们的用法如下 modprobemodprobe [ -C config-file] [-r] module_name [module params]： 作用: 装载和卸载模块，会自动解决模块之间的依赖关系 选项: 默认: 动态装载模块 modprobe module_name -r: 动态卸载 modprobe -r module_name -C: 指定模块装载时的配置文件，默认为 /etc/modprobe.conf /etc/modprobe.d/\*.conf insmodinsmod [filename] [module options...]： 作用: 模块的装载的另一命令，不会自动解决模块之间的依赖关系，不常用 filename：模块文件的文件路径； eg: insmod $(modinfo -n xfs) rmmodrmmod [module_name]： 作用: 模块卸载的另一命令 module_name: 模块名称，不需要模块的路径 3. ramdisk文件的制作：ramdisk 的制作有两个命令，Centos5 使用的 mkinitrd，Centos6-7 使用了 dracut，但是同时也提供了 mkinitrd, 其是基于 dracut 的脚本文件，它们的使用说明如下 mkinitrdmkinitrd [OPTION...] [&lt;initrd-image&gt;] &lt;kernel-version&gt; 作用: 为当前使用中的内核重新制作ramdisk文件： 选项: --with=&lt;module&gt;：除了默认的模块之外需要装载至initramfs中的模块； --preload=&lt;module&gt;：initramfs所提供的模块需要预先装载的模块； eg： mkinitrd /boot/initramfs-$(uname -r).img $(uname -r) dracut命令dracut [OPTION...] [&lt;image&gt; [&lt;kernel version&gt;]] 作用: low-level tool for generating an initramfs image eg： dracut /boot/initramfs-$(uname -r).img $(uname -r) 解开 ramdisk 文件12345&gt; mv initramfs-3.10.0-514.el7.x86_64.img initramfs-3.10.0-514.el7.x86_64.img.gz&gt; gzip -d initramfs-3.10.0-514.el7.x86_64.img.gz&gt; mkdir initrd&gt; cd initrd&gt; cpio -id &lt; ../initramfs-3.10.0-514.el7.x86_64.img 4. 系统参数查看和修改Linux 系统的所有参数通过 /proc，/sys 两个伪文件系统输出给用户查看和修改。 4.1 /proc 目录/proc 的作用如下: 作用: 内核把自己内核状态和统计信息，以及可配置参数通过 /proc 伪文件系统加以输出： /proc：内核状态和统计信息的输出接口； /proc/sys: 内核参数的配置接口 ； 内核参数分为 只读：信息输出；例如/proc/#/* 可写：可接受用户指定一个“新值”来实现对内核某功能或特性的配置；/proc/sys/ 4.1 /proc/sys 管理工具Linux 可修改的系统参数都放置在 /proc/sys 目录下，有三种修改方式 通过 sysctl 命令，这是专用修改内核参数的命令 由于 /proc 是伪文件系统，因此可以通过 cat，echo 等文件系统命令利用IO重定向进行修改，需要注意的是不能使用文本编辑器进行修改 上述两种方式只临时有效，要想永久有效，需要修改配置文件 1234# 修改示例&gt; ls /proc/sys/kernel/hostname -l&gt; sysctl -w kernal.hostname=&apos;localhost&apos;&gt; echo &quot;localhost&quot; &gt; /proc/sys/kernel/hostname sysctl命令sysctl [options] [variable[=value]] 作用: 专用于查看或设定/proc/sys目录下参数的值； 查看： sysctl -a: 查看所有参数 sysctl parameter: 查看特定参数 修改：sysctl -w parameter=value 附注：sysctl 的内核参数是相对于 /proc/sys 目录下文件的相对路径而言的，比如 /proc/sys/net/ipv4/ip_forward 相当于 net.ipv4.ip_forward 1234# /proc/sys/net/ipv4/ip_forward# parameter = net.ipv4.ip_forward&gt; sysctl -w net.ipv4.ip_forward=1&gt; echo 1 &gt; /proc/sys/net/ipv4/ip_forward 文件系统命令（cat, echo) 查看： cat /proc/sys/PATH/TO/SOME_KERNEL_FILE 设定： echo &quot;VALUE&quot; &gt; /proc/sys/PATH/TO/SOME_KERNEL_FILE 修改配置文件 默认配置文件: /etc/sysctl.conf /etc/sysctl.d/\*.conf 配置文件立即生效：sysctl -p [/PATH/TO/CONFIG_FILE] 4.2 常用内核参数： net.ipv4.ip_forward：路由核心转发功能； vm.drop_caches：设置值为 1，将回收buffer，cache 的缓存 kernel.hostname：主机名； net.ipv4.icmp_echo_ignore_all：忽略所有ping操作； 5. /sys目录：/sys 目录目前主要的作用是 输出内核识别出的各硬件设备的相关属性信息， 也有内核对硬件特性的可设置参数；对此些参数的修改，即可定制硬件设备工作特性； udev 命令系统上所有的设备文件，都是由 udev 命令生成，这个命令的特点如下: udev 通过读取 /sys 目录下的硬件设备信息按需为各硬件设备创建设备文件； udev是用户空间程序；专用工具：devadmin, hotplug； udev为设备创建设备文件时，会读取其事先定义好的规则文件，一般在/etc/udev/rules.d/目录下，以及/usr/lib/udev/rules.d/目录下； 1234567891011# 1. 修改 vmware 网卡的名称&gt; vim /usr/lib/udev/rules.d/70-persistent-net.rules# 修改特定 mac 地址网卡的名称# 2. 如果网卡有特定的配置信息，需要为网卡重新生成对应名称的配置文件&gt; cd /etc/sysconfig/net-work-script# 卸载网卡并重新装载网卡，让配置生效&gt; modprobe -r e1000&gt; modprobe e1000]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.5 grub2 系统配置与使用]]></title>
    <url>%2F2018%2F02%2F23%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2Fgrub2%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[grub2 系统配置与使用 上一节我们介绍了 grub 第一版的配置和使用，接下来我们学习 grub2。内容介绍同上一节相同，如下: grub2 概述 认识 grub2 的菜单 grub2 的启动流程 grub2 命令行的使用 grub2 的配置文件 安装 grub2 开机过程中常见问题解决 1. grub2 概述grub2 支持 efi，比 grub 更加复杂，本人对此并不是很懂。关于 grub2 的详细描述可以参考这篇博文Grub 2：拯救你的 bootloader 1.1 认识 grub2 菜单正常开机启动后，我们就会看到一个类似上图的grub2 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。 1.2 设备表示grub2 设备的表示方式与 grub 并不相同 grub2 中设备从 0 开始编号，而分区则是从 1 开始编号 MBR 和 GPT 两种分区格式表示并不相同 (hd0,1)： 一般的默认语法，由 grub2 自动判断分区格式 (hd0,msdos1)： 磁盘分区为传统的 MBR 模式 (hd0,gpt1)：磁盘分区为 GPT 模式 2. grub2 命令行的使用下面是在 grub2 命令行中直接启动操作系统的示例，可以看到 grub2 更加接近我们 bash。 1234567891011grub&gt; ls # 查看当前的磁盘分区设备(hd0), (hd0, msdos1), (hd0, msdos2)grub&gt; set root=(hd0, msdos1) # 设置根设备grub&gt; ls / # 查看当前设备内的文件grub&gt; linux /vmlinux-VERSION-releaser ro root=/dev/mapper/centos-root # 设置内核和跟目录grub&gt; initrd /initramfs-VErSION-releaser # 设置 initramdiskgrub&gt; insmod gizo # 装载必要的驱动模块grub&gt; insmod xfsgrub&gt; insmod part_msdosgrub&gt; boot # 启动开机流程 3. grub2 的配置文件grub2 的配置分成了核心配置和辅助配置两个部分 核心配置文件/boot/grub2/grub.cfg，是 grub2 在开机启动过程中读取的配置文件 辅助配置文件是 grub2-mkconfig 会读取的配置文件，此命令用于生成核心配置文件。辅助配置文件包括 /etc/default/grub文件 与 /etc/grub.d/目录两个部分。 因此 grub2 参数可分成两个步骤: 修改 /etc/default/grub 与 /etc/grub.d/ 内的相关辅助配置文件 使用 grub2-mkconfig -o /boot/grub2/grub.cfg 生成新的 grub.cfg 核心配置文件 通过 grub.cfg 的结构与注释，可以直接看出 辅助配置文件的作用结果。首先我们来看 grub.cfg 的文件结构。 3.1 grub2 配置文件grub.cfg 主要包括两个部分 第一部分是环境配置段，大多是环境设置与默认值设置，对应于 /etc/default/grub 第二部分是菜单选项，/etc/grub.d/内每个配置文件生成的菜单选项，都包含在对应文件的注释中。 12345678910111213141516171819202122232425# 1. 最开始的部份，大多是环境设置与默认值设置set timeout=5set default=&quot;2&quot;### BEGIN /etc/grub.d/10_linux #### 2. /etc/grub.d/10_linux 生成的菜单项menuentry &apos;CentOS Linux (4.9.86-30.el7.x86_64) 7 (Core)&apos; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-4.9.86-30.el7.x86_64-advanced-0afffff8-52f1-4af0-90e5-958f57489518&apos; &#123; load_video set gfxpayload=keep insmod gzio insmod part_gpt insmod xfs if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d else search --no-floppy --fs-uuid --set=root 748911a9-cbdb-4f17-acb8-8f44661ec67d fi linuxefi /vmlinuz-4.9.86-30.el7.x86_64 root=/dev/mapper/cl-root ro crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet initrdefi /initramfs-4.9.86-30.el7.x86_64.img&#125;### END /etc/grub.d/10_linux ###### BEGIN /etc/grub.d/30_os-prober ###### END /etc/grub.d/30_os-prober ### 3.2 grub2 辅助配置文件下面我们来看各个辅助配置文件的组成 /etc/default/grub主要环境配置文件，常见的配置选项如下 12345678910111213141516171819202122232425262728293031GRUB_TIMEOUT=5# 作用: 指定默认倒数读秒的秒数，0 表示直接开机，-1 表示必需用户选择GRUB_TIMEOUT_STYLE# 作用：是否隐藏菜单项目# 选项：menu -- 默认，显示菜单# countdown -- 显示剩余秒数，不显示菜单# hidden -- 什么都不显示GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;#GRUB_DEFAULT=2# 作用： 指定要用哪一个菜单 （menuentry） 来作为默认开机项目# 可选值：包括“ saved, 数字, title 名,ID 名”等等# ID 名值的是 menuentry 后使用 --id 为选项指定的 ID# 默认值：就是以第一个开机菜单来作为默认项目GRUB_DISABLE_SUBMENU=true# 作用：是否要隐藏次菜单，通常是藏起来的好！GRUB_TERMINAL_OUTPUT=&quot;console&quot;# 作用：指定输出的画面应该使用哪一个终端机来显示# 可选值：console, serial, gfxterm, vga_text# 默认值：console 文字终端机GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rd.lvm.lv=cl/usr rhgb quiet&quot;# 作用：为 menuentry 内 linux16 指定的内核追加额外的参数GRUB_DISABLE_RECOVERY=&quot;true&quot;# 作用：取消救援菜单的制作 /etc/grub.d/分段配置，每个文件实现一个特殊功能，grub2-mkconfig 会分析并执行 /etc/grub.d/* 内的文件，来创建 grub.cfg 00_header: 创建初始的显示项目，包括需要载入的模块分析、屏幕终端机的格式、倒数秒数、菜单是否需要隐藏等等，大部分在 /etc/default/grub 里面所设置的变量，大概都会在这个脚本当中被利用来重建 grub.cfg 10_linux: 根据分析 /boot 下面的文件，尝试找到正确的 linux 核心与读取这个核心需要的文件系统模块与参数,将所有在 /boot 下面的核心文件创建为一个独立的菜单选项 30_os-prober: 查看系统其他分区是否存在操作系统，如果存在制作成一个独立的菜单选项，可通过 /etc/default/grub 内的选项 GRUB_DISABLE_OS_PROBER=true 来取消此文件的执行 40_custom: 如果还有其他想要自己手动加上去的菜单项目，或者是其他的需求，那么建议在这里补充 3.3 grub2 中的帐号机制grub2 内将用户分为了两类，超级管理帐号(superusers) 和普通用户(users) 特性 superusers user 作用 设置系统管理员与相关参数还有密码等 设置一般帐号的相关参数与密码，可设置多个用户 权限 将可在 grub2 内具有所有修改的权限 使用这个密码的用户可以选择要进入某些菜单项目 附注 一旦设置了这个 superusers 的参数，则所有的指令修改将会被变成受限制的 菜单项目也要搭配相对的帐号才行 附注 只有系统管理员能够修改参数 一般用户只能选择可用的开机菜单，不能修改菜单 设置 grub 帐号的步骤以设置一个超级管理员帐号 vbird,和一个普通帐号 dmtsai 为例，相关操作如下123456789101112131415161718192021222324252627282930# 1. 先取得 vbird 与 dmtsai 的密码。&gt; grub2-mkpasswd-pbkdf2Enter password: # 输入 vibird 密码Reenter password: # 再一次输入密码PBKDF2 hash of your password is XXXXXXXXXXXXXXXXXXXXX# 2. 将密码与帐号写入到 01_users 文件内# 附注：在 /etc/grub.d/* 下面的文件是“执行脚本”,只能通过 cat 或 echo 来将帐密数据显示出来&gt; vim /etc/grub.d/01_userscat &lt;&lt; eofset superusers=&quot;vbird&quot;password_pbkdf2 vbird XXXXXXXXXXXXXXXXXXXXXpassword_pbkdf2 dmtsai XXXXXXXXXXXXXXXXXXXXXeof# 3. 给 01_users 给予执行权限&gt; chmod a+x /etc/grub.d/01_users# 4. 修改 menuentry，配置用户# --unrestricted：默认不受限制# --users &quot;帐号名称&quot;：限定特定账户使用# 无 --users 无 --unrestricted：一定要系统管理员”才能够进入与修改&gt; vim /etc/grup.d/40_custommenuentry MyLinux --users dmtsai &#123; load_video insmod gzio linux16 ...... .........&#125; 4. 安装 grub2grub2-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 12345678&gt; mkdir /mnt/boot&gt; mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区&gt; grub2-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中&gt; grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 5. 开机过程中常见问题解决5.1 忘记开机密码新版的 systemd 的管理机制中，需要 root 的密码才能以救援模式登陆 Linux，所以无法通过救援模式重新设置 root 密码。我们需要借助 rd.break 核心参数 进入开机画面，按下 e 来进入编辑模式，在 linux16 参数上添加 rd.break 参数 改完之后按下 [crtl]+x 开始开机 开机完成后屏幕会出现如下的类似画面,此时处于 RAM Disk 的环境，正真的根应该被挂载在 /sysroot 12345678910111213141516171819&gt; mount # 检查一下挂载点！一定会发现 /sysroot 才是对的/dev/mapper/centos-root on /sysroot&gt; mount -o remount,rw /sysroot # 挂载成可读写&gt; chroot /sysroot # 实际切换了根目录的所在！取回你的环境了&gt; echo &quot;your_root_new_pw&quot; | passwd --stdin root # 修改root密码&gt; touch /.autorelabel # 如果SELinux=Enforcing，必需，详细说明见下&gt; exit&gt; reboot# touch /.autorelabel 等同操作# 1. 在 rd.break 模式下，修改完 root 密码后，将SELinux 该为 Permissive&gt; vim /etc/selinux/configSELINUX=permissive# 2. 重新开机后，重至 /etc SELinux 安全文本&gt; restorecon -Rv /etc&gt; vim /etc/selinux/configSELINUX=Enforcing&gt; setenforce 1 SELinux 的说明: 在 rd.break 的 RAM Disk 环境下，系统是没有 SELinux 的,更改密码会修改 /etc/shadow， 所以的 shadow 的SELinux 安全本文的特性将会被取消，SELinux 为 Enforcing 的模式下，如果你没有让系统于开机时自动的回复 SELinux 的安全本文，你的系统将产生“无法登陆”的问题。加上 /.autorelabel 就是要让系统在开机的时候自动的使用默认的 SELinux type 重新写入 SELinux 安全本文到每个文件去 5.2 因文件系统错误而无法开机文件系统错误常见原因有两个: 通常就是 /etc/fstab的设置问题，尤其是使用者在实作 Quota/LVM/RAID 时，最容易写错参数， 又没有经过 mount -a 来测试挂载，就立刻直接重新开机 曾经不正常关机后，也可能导致文件系统不一致情况， 也有可能会出现相同的问题 开机启动时，在检查文件系统时会有提示信息，类似下图所示。通常只要输入 root 密码进入救援模式，然后重新挂载根目录即可。 上图属于第二种错误状况。图中的第二行处，fsck 告知其实是 /dev/md0 出错。系统会自动利用 fsck.ext3 去检测 /dev/md0，等到系统发现错误，并且出现“clear [Y/N]”时，输入“ y ”即可。但是需要注意的是 partition 上面的 filesystem 有过多的数据损毁时，即使 fsck/xfs_repair 完成后，可能因为伤到系统盘，导致某些关键系统文件数据的损毁，那么依旧是无法进入 Linux 此时，最好就是将系统当中的重要数据复制出来，然后重新安装，并且检验一下，是否实体硬盘有损伤的现象才好 5.3 进入紧急模式systemd.unit=emergency.target 5.4 通过光盘进入救援模式如果 grub 已经损坏，并已重启，将无法进入 grub，也就无法正常开机，此时需要借助光盘进入救援模式 进入 BIOS 调整开机启动次序 插入光盘或装机U盘，开机启动，进入如下画面 选择”Troubleshooting”, 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 12&gt; chroot /mnt/sysimage/&gt; grub-install /dev/sda]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.4 grub配置与使用]]></title>
    <url>%2F2018%2F02%2F22%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2Fgrub%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[grub配置与使用 本节我们我们将学习主流的 BootLoader 程序 grub。这部分内容与开机启动项设置，忘记 root 密码，操作系统修复相关。grub 有两个版本，使用方式几乎完全不一样，本节首先介绍第一个版本，下一节介绍第二个版本。本节内容如下: grub 概述 认识 grub 的菜单 grub 的启动流程 grub 命令行的使用 grub 的配置文件 安装 grub 开机过程中常见问题解决 1. grub 概述grub: 是 GRand Unified Bootloader 的简称，目前包括如下两个版本。 grub 0.x: grub legacy，简称 grub grub 1.x: grub2 1.1 认识 grub 菜单正常开机启动后，我们就会看到一个类似上图的grub 开机启动菜单界面。 使用上下键，可以选择开机启动项 按下 e 键就可以编辑光标所在项的启动选项 按下 c 键就可以进入 grub 的命令行 默认情况下，如果不做任何选择，五秒之后系统在默认的开机启动项上开机启动，如果进行了上述任何一个操作则必须按下确认键才能启动操作系统。上图是我虚拟机上 grub2 的界面。grub 界面类似，操作完全相同。 1.2 启动步骤grub 启动包括三个步骤: stage1: BIOS 读取并加载 mbr 中的 BootLoader stage1_5: 位于 mbr 之后的扇区，作用是让 stage1 中的 bootloader 能识别 stage2 所在的分区上的文件系统 stage2：位于/boot/grub/，stage2及内核等通常放置于一个基本磁盘分区，因为 stage1_5 能识别的文件系统有限，其实现的功用如下： 提供菜单、并提供交互式接口 加载用户选择的内核或操作系统 允许传递参数给内核 可隐藏此菜单 为菜单提供了保护机制 为编辑菜单进行认证 为启用内核或操作系统进行认证 在学习 grub 使用时，我们首先需要了解 grub 是如何识别设备的。grub 中使用 (hd#,#) 表示磁盘设备及分区(hd#,#) hd#: 表示磁盘编号，用数字表示，从0开始编号 #: 表示分区编号，用数字表示; 从0开始编号 例如 (hd0,0) 表示第一块磁盘的第一个分区。 我们知道 grub 的作用就是在没有根文件系统的前提下直接加载内核，因此 grub 的根设备与操作根设备文件系统不是同一个概念。grub 的根设备指的是包含stage2 以及内核文件所在的设备，内核文件的位置也是相对于 grub 根设备的文件系统而言的。 如果 /boot 独立分区，那么 grub 的根设备就是 /boot 所在分区，内核文件直接位于根之下，所以其路径为 /vmlinuz-VERSION 如果 /boot 是 / 下的目录，那么 grub 的根设备就是 / 所在分区，内核文件的路径为 /vmlinuz-VERSION所以 grub 的根对内核文件的路径有着直接影响。 2. grub的命令行接口下面是在 grub 命令行中直接启动操作系统的示例，grub 命令行有很多可用命令，列示如下:12345# 手动在grub命令行接口启动系统grub&gt; root (hd#,#)grub&gt; kernel /vmlinuz-VERSION-RELEASE ro root=/dev/DEVICE selinux=0 init=/bin/bashgrub&gt; initrd /initramfs-VERSION-RELEASE.imggrub&gt; boot help: 获取帮助列表 help COMMAND: command 详细帮助信息 root (hd#,#): 设置根设备 find (hd#,#)/PATH/TO/SOMEFILE：查找特定磁盘分区上的文件，如果使用了 root 指定了根设备可以省略 (hd#,#)，下同 kernel /PATH/TO/KERNEL_FILE: 设定本次启动时用到的内核文件；额外还可以添加许多内核支持使用的cmdline参数 initrd /PATH/TO/INITRAMFS_FILE: 设定为选定的内核提供额外文件的ramdisk boot: 引导启动选定的内核 3. 配置文件：grub 的配置文件在 /boot/grub/grub.conf, /etc/grub.conf 是其软连接。一个最简单的配置文件如下，注释中描述了每一项的含义。grub 中实现了菜单编译和选中特定菜单的两级认证功能。可以使用明文密码，但是建议使用 md5 加密后字串。grub 为我们提供了一个快捷命令 grub-md5-crypt 用于生成密码的 md5 1234567891011# grub 示例配置文件default=0 # 设定默认启动的菜单项，编号从0开始timeout=5 # 指定菜单项等待选项选择的时长splashimage=(hd0,0)/PATH/TO/XPM_PIC_FILE： # 指明菜单背景图片文件路径hiddenmenu # 隐藏菜单，不想隐藏，无须此项即可password --md5 MD5_STRING # 设置菜单编辑密码，--md5 后跟 md5 加密后的密码字符串title My Linux # 定义菜单项“标题”, 可出现多次； root (hd#,#) # grub查找stage2及kernel文件所在设备分区，为grub的“根”; kernel /PATH/TO/VMLINUZ_FILE [PARAMETERS] # 启动的内核 initrd /PATH/TO/INITRAMFS_FILE # 内核匹配的ramfs文件； password --md5 MD5_STRING #启动选定的内核或操作系统时进行认证； 12345# 使用 grub-md5-crypt 生成 md5 密码串&gt; grub-md5-cryptPassword: # 输入两次密码Password:MD5_STRING 4. 安装 grubgrub 正常情况下，不”瞎搞”，不会损坏，毕竟不会有谁没事去覆盖掉磁盘的 MBR，但是不怕一万就怕万一。安装双系统时，如果后安装的 Window，window 的 BootLoader 是没法引导 Linux，但是 grub 能引导 Window，此时我们就需要重新安装 Linux。 安装 grub 有两种方法，如下 方法一 命令行grub-install --root-directory=ROOT /dev/DISK ROOT 为 boot 目录所在的父目录 12345678&gt; mkdir /mnt/boot&gt; mount /dev/sdb1 /mnt/boot # /dev/sdb1 为 /boot 目录所在的分区&gt; grub-install --root-directory=/mnt /dev/sdb # /boot 的父目录是 /mnt # grub stage1 此时会安装到 sdb 的 MBR 中&gt; grub-install --root-directory=/mnt /dev/sdb1 # grub stage1 此时会安装到 sdb 第一个分区的 boot sector 中 方法二 grub 命令行123# 前提: 设备上必须存在 grup 目录，里面的文件必须齐全grub&gt; root (hd#,#)grub&gt; setup (hd#) 5. 常见开机问题的解决5.1 进入单用户模式： 编辑grub菜单(选定要编辑的title，而后使用e命令); 在选定的 kernel 后附加 1, s, S或single都可以； 在kernel所在行，键入“b”命令； 5.2 grub 已经损坏，并已重启这种情况下已经无法进入 grub，因此需要使用光盘或装机 U 盘进入救援模式 进入 BIOS 调整开机启动次序 开机启动，进入如下画面 选择”Troubleshooting”, 然后选择 “Rescue a CentOS Linux system” 救援模式会将找到的根挂载至 /mnt/sysimage/，然后执行以下命令 12&gt; chroot /mnt/sysimage/&gt; grub-install /dev/sda]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.3 Centos7 Systemd 启动流程]]></title>
    <url>%2F2018%2F02%2F21%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS7-Systemd%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos7 Systemd 启动流程 本节我们学习 Centos7 的开机启动程序 Systemd，及其服务管理工具 systemctl。我们会与 Centos6 中的 upstart 的启动程序对比来讲解。大家也可以参考阮一峰老师的博客。本节内容如下: Systemd 概述 Systemctl 命令的使用 Systemd 配置文件格式 1. Sysmted 概述：MBR 架构的系统，开机启动过程是 POST --&gt; Boot Sequeue(BIOS) --&gt; Bootloader(MBR) --&gt; Kernel(ramdisk) --&gt; rootfs --&gt; /sbin/init，而 Systemd 正是 Centos7 的/sbin/init 程序 1.2 Systemd的新特性systemd 相比于 Centos5 的 SysV init，和 Centos 的 Upstart，具有如下特性: 新特性 系统引导时实现服务并行启动； 按需激活进程； 系统状态快照； 基于依赖关系定义服务控制逻辑； 关键特性： 基于socket的激活机制：socket与程序分离； 基于bus的激活机制； 基于device的激活机制； 基于Path的激活机制； 系统快照：保存各unit的当前状态信息于持久存储设备中； 向后兼容sysv init脚本；/etc/init.d/ 不兼容： systemctl的命令是固定不变的； 非由systemd启动的服务，systemctl无法与之通信； 1.2 服务配置Sysv init 和 Upstart 中，服务的管理单元是一个个具有特定格式的 shell 脚本，由 service 命令统一进行管理。而 Systemd 中服务的核心单元叫 Unit，unit 由其相关配置文件进行标识、识别和配置，配置文件中主要包含了系统服务、监听的socket、保存的快照以及其它与init相关的信息。systemd 按照功能将 unit 分为了如下几种类型。 unit的常见类型 类型 文件扩展名 作用 Service unit .service 用于定义系统服务 Target unit .target 用于模拟实现运行级别 Device unit .device 用于定义内核识别的设备 Mount unit .mount 定义文件系统挂载点 Socket unit .socket 用于标识进程间通信用到的socket文件 Snapshot unit .snapshot 管理系统快照 Swap unit .swap 用于标识swap设备 Automount unit .automount 文件系统自动点设备 Path unit .path 用于定义文件系统中的一文件或目录 systemd 的配置文件systemd 的配置文件位于以下三个目录中 /usr/lib/systemd/system: 实际配置文件的存存放位置 /run/systemd/system：不常用 /etc/systemd/system: 基本上都是软连接 对于那些支持 Systemd 的软件，安装的时候，会自动在/usr/lib/systemd/system目录添加一个配置文件。如果你想让该软件开机启动，就执行下面的命令（以httpd.service为例）。 12345[root@hp system]# ll /etc/systemd/system/default.targetlrwxrwxrwx. 1 root root 40 3月 5 17:37 /etc/systemd/system/default.target -&gt; /usr/lib/systemd/system/graphical.target[root@hp system]# systemctl enable httpdCreated symlink from /etc/systemd/system/multi-user.target.wants/httpd.service to /usr/lib/systemd/system/httpd.service. 上面的命令相当于在 /etc/systemd/system 目录添加一个符号链接，指向 /usr/lib/systemd/system 里面的httpd.service文件。这是因为开机时，Systemd只执行 /etc/systemd/system 目录里面的配置文件。这也意味着，如果把修改后的配置文件放在该目录，就可以达到覆盖原始配置的效果。 除了使用普通的文本查看命令外查看配置文件外，systemctl cat NAME.service 可通过服务名称直接查看配置文件 123456789101112131415161718192021222324[root@hp system]$ systemctl cat httpd# /usr/lib/systemd/system/httpd.service[Unit]Description=The Apache HTTP ServerAfter=network.target remote-fs.target nss-lookup.targetDocumentation=man:httpd(8)Documentation=man:apachectl(8)[Service]Type=notifyEnvironmentFile=/etc/sysconfig/httpdExecStart=/usr/sbin/httpd $OPTIONS -DFOREGROUNDExecReload=/usr/sbin/httpd $OPTIONS -k gracefulExecStop=/bin/kill -WINCH $&#123;MAINPID&#125;# We want systemd to give httpd some time to finish gracefully, but still want# it to kill httpd after TimeoutStopSec if something went wrong during the# graceful stop. Normally, Systemd sends SIGTERM signal right after the# ExecStop, which would kill httpd. We are sending useless SIGCONT here to give# httpd time to finish.KillSignal=SIGCONTPrivateTmp=true[Install]WantedBy=multi-user.target 2. systemctl 命令使用2.1 管理系统服务 (service unit)systemctl [OPTIONS...] COMMAND [NAME...] OPTIONS: -t, --type=: 指定查看的 unit 类型 -a, --all：查看所由服务 服务启动与关闭 作用 init systemctl 启动 service NAME start systemctl start NAME.service 停止 service NAME stop systemctl stop NAME.service 重启 service NAME restart systemctl restart NAME.service 状态 service NAME status systemctl status NAME.service 条件式重启 service NAME condrestart systemctl try-restart NAME.service 重载或重启服务 systemctl reload-or-restart NAME.servcie 重载或条件式重启服务 systemctl reload-or-try-restart NAME.service 12345678910111213141516171819[root@hp system]# systemctl status httpd● httpd.service - The Apache HTTP Server Loaded: loaded (/usr/lib/systemd/system/httpd.service; enabled; vendor preset: disabled) Active: active (running) since 二 2018-08-07 09:14:30 CST; 1s ago Docs: man:httpd(8) man:apachectl(8) Main PID: 6170 (httpd) Status: &quot;Processing requests...&quot; CGroup: /system.slice/httpd.service ├─6170 /usr/sbin/httpd -DFOREGROUND ├─6174 /usr/sbin/httpd -DFOREGROUND ├─6176 /usr/sbin/httpd -DFOREGROUND ├─6177 /usr/sbin/httpd -DFOREGROUND ├─6178 /usr/sbin/httpd -DFOREGROUND ├─6180 /usr/sbin/httpd -DFOREGROUND └─6181 /usr/sbin/httpd -DFOREGROUND8月 07 09:14:28 hp.tao systemd[1]: Starting The Apache HTTP Server...8月 07 09:14:30 hp.tao systemd[1]: Started The Apache HTTP Server. 输出: Loaded行：配置文件的位置，是否设为开机启动 Active行：表示正在运行 Main PID行：主进程ID Status行：由应用本身（这里是 httpd ）提供的软件当前状态 CGroup块：应用的所有子进程 日志块：应用的日志 服务状态查看 作用 init systemctl 查看某服务当前激活与否的状态 systemctl is-active NAME.service 查看所有已激活的服务 systemctl list-units –type service 查看所有服务（已激活及未激活) systemctl list-units -t service –all 开机自启 作用 init systemctl 设置服务开机自启 chkconfig NAME on systemctl enable NAME.service 禁止服务开机自启 chkconfig NAME off systemctl disable NAME.service 查看某服务是否能开机自启 chkconfig –list NAME systemctl is-enabled NAME.service 查看所有服务的开机自启状态 chkconfig –list systemctl list-unit-files –type service 禁止某服务设定为开机自启 systemctl mask NAME.service 取消此禁止 systemctl unmask NAME.servcie 依赖关系 作用 init systemctl 查看服务的依赖关系 systemctl list-dependencies NAME.service 2.2 管理 target units 作用 init systemctl 运行级别 0 runlevel0.target, poweroff.target 运行级别 1 runlevel1.target, rescue.target 运行级别 2 runlevel2.tartet, multi-user.target 运行级别 3 runlevel3.tartet, multi-user.target 运行级别 4 runlevel4.tartet, multi-user.target 运行级别 5 runlevel5.target, graphical.target 运行级别 6 runlevel6.target, reboot.target 级别切换 init N systemctl isolate NAME.target 查看级别 runlevel systemctl list-units –type target 查看所有级别 systemctl list-units -t target -a 获取默认运行级别 /etc/inittab systemctl get-default 修改默认运行级别 /etc/inittab systemctl set-default NAME.target 切换至紧急救援模式 systemctl rescue 切换至emergency模式 systemctl emergency 2.3 其它常用快捷命令 关机： systemctl halt, systemctl poweroff 重启： systemctl reboot 挂起： systemctl suspend 快照： systemctl hibernate 快照并挂起： systemctl hybrid-sleep 3. service unit file 配置3.1 unit file 组成unit file 通常由如下 三个部分组成: [Unit]： 定义与Unit类型无关的通用选项； 用于提供 unit 的描述信息、unit 行为及依赖关系等； [Service]： 与特定类型相关的专用选项；此处为 Service 类型； [Install]： 定义由systemctl enable以及systemctl disable命令在实现服务启用或禁用时用到的一些选项； 12345678910111213141516171819# systemctl cat sshd# /usr/lib/systemd/system/sshd.service[Unit]Description=OpenSSH server daemonDocumentation=man:sshd(8) man:sshd_config(5)After=network.target sshd-keygen.serviceWants=sshd-keygen.service[Service]Type=notifyEnvironmentFile=/etc/sysconfig/sshdExecStart=/usr/sbin/sshd -D $OPTIONSExecReload=/bin/kill -HUP $MAINPIDKillMode=processRestart=on-failureRestartSec=42s[Install]WantedBy=multi-user.target Unit段 Description：当前服务的简单描述 After：定义unit的启动次序；表示当前unit应该晚于哪些unit启动；其功能与Before相反； Before：定义sshd.service应该在哪些服务之前启动 Requies：依赖到的其它units；强依赖，被依赖的units无法激活或异常退出时，当前unit即无法激活； Wants：依赖到的其它units；弱依赖，被依赖的units无法激活时，不影响当 unit 的启动； Conflicts：定义units间的冲突关系； 附注： After和Before字段只涉及启动顺序，不涉及依赖关系 Wants字段与Requires字段只涉及依赖关系，与启动顺序无关，默认情况下是同时启动的 Service段 Type：用于定义影响ExecStart及相关参数的功能的unit进程启动类型； simple（默认值）：ExecStart字段启动的进程为主进程 forking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程 oneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务 dbus：类似于simple，但会等待 D-Bus 信号后启动 notify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务 idle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合 EnvironmentFile：指定当前服务的环境参数文件 ExecStart：指明启动unit要运行命令或脚本；其中的变量$OPTIONS就来自EnvironmentFile字段指定的环境参数文件 ExecReload：重启服务时执行的命令 ExecStop：停止服务时执行的命令 ExecStartPre：启动服务之前执行的命令 ExecStartPost：启动服务之后执行的命令 ExecStopPost：停止服务之后执行的命令 Restart：定义了服务退出后，Systemd 的重启方式 no（默认值）：退出后不会重启 on-success：只有正常退出时（退出状态码为0），才会重启 on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启 on-abnormal：只有被信号终止和超时，才会重启 on-abort：只有在收到没有捕捉到的信号终止时，才会重启 on-watchdog：超时退出，才会重启 always：不管是什么退出原因，总是重启 附注: 对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal KillMode:定义 Systemd 如何停止服务 control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉 process：只杀主进程 mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号 none：没有进程会被杀掉，只是执行服务的 stop 命令。 RestartSec：表示 Systemd 重启服务之前，需要等待的秒数 对于 sshd 服务而言将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。Restart设为on-failure，表示任何意外的失败，就将重启sshd。如果 sshd 正常停止（比如执行systemctl stop命令），它就不会重启。 所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/sshd（注意等号后面的那个连词号），就表示即使/etc/sysconfig/sshd文件不存在，也不会抛出错误 Install段 Alias： RequiredBy：被哪些units所依赖； WantedBy：表示该服务所在的 Target 3.2 修改配置文件后重启对于新创建的unit文件或修改了的unit文件，要通知systemd重载此配置文件 systemctl daemon-reload 4.Target 的配置文件12345678910111213141516[root@hp system]$ systemctl cat multi-user.target# /usr/lib/systemd/system/multi-user.target# This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Multi-User SystemDocumentation=man:systemd.special(7)Requires=basic.targetConflicts=rescue.service rescue.targetAfter=basic.target rescue.service rescue.targetAllowIsolate=yes Target 配置文件里面没有启动命令 Requires：要求basic.target一起运行。 Conflicts：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。 After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。 AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.2 Centos5 init 启动流程]]></title>
    <url>%2F2018%2F02%2F20%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS5-init%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Centos5 init 启动流程 在上一节我们详细讲解了开机启动流程中内核级部分，接下来我们讲学习内核加载并完成根文件系统之后 init 程序的启动过程。因为内容过多，而且不同Centos 版本并不相同，因此我们将分成两个节，本节将讲解一下内容: CentOS5 SysV init 的启动流程 /etc/inittab 的格式和内容 Centos5 的服务启动方式 chkconfig 设置服务开机启动 /sbin/init 程序执行的操作 CentOS6 Upstart 的启动流程 1.1 CentOS 5： SysV init1.1 运行级别 运行级别：为了系统的运行或维护等目的而设定的机制； 0-6：7个级别； 0: 关机, shutdown 1: 单用户模式(single user)，root用户，无须认证；维护模式； 2: 多用户模式(multi user)，会启动网络功能，但不会启动NFS；维护模式； 3: 多用户模式(mutli user)，完全功能模式；文本界面； 4: 预留级别：目前无特别使用目的，但习惯以同3级别功能使用； 5: 多用户模式(multi user)， 完全功能模式，图形界面； 6: 重启，reboot 默认级别：3, 5 级别切换：init level 级别查看： who -r runlevel 1.2 配置文件：/etc/inittab/etc/inittab 作用: 每行定义一种 action 以及与之对应的 process 格式: id:runlevels:action:process id：一个任务的标识符； runlevels：在哪些级别启动此任务，格式如下: n: 单个数字例如 2，表示仅在第二级别 nnn: 多个数字例如 234，表示在第二三四级别 也可以为空，表示所有级别； action：在什么条件下启动此任务； process：任务； action： wait：等待切换至此任务所在的级别时执行一次； respawn：一旦此任务终止，就自动重新启动之； initdefault：设定默认运行级别；此时，process省略； sysinit：设定系统初始化方式，此处一般为指定/etc/rc.d/rc.sysinit脚本； 12345678910111213id:3:initdefault: -- 设置系统默认启动级别si::sysinit:/etc/rc.d/rc.sysinit -- 系统初始化脚本l0:0:wait:/etc/rc.d/rc 0 -- rc 脚本框架，启动对应级别下的服务l1:1:wait:/etc/rc.d/rc 1…………l6:6:wait:/etc/rc.d/rc 6tty1:2345:respawn:/usr/sbin/mingetty tty1 --- 虚拟终端启动... ...tty6:2345:respawn:/usr/sbin/mingetty tty6 # mingetty会调用login程序；# 打开虚拟终端的程序除了mingetty之外，还有诸如getty等； rc 脚本框架：1234567for srv in /etc/rc.d/rc#.d/K*; do $srv stopdonefor srv in /etc/rc.d/rc#.d/S*; do $srv startdone rc脚本：接受一个运行级别数字为参数； rc 3: 意味着去启动或关闭/etc/rc.d/rc3.d/目录下的服务脚本所控制服务； K*：要停止的服务；K##*，优先级，数字越小，越是优先关闭；依赖的服务先关闭，而后关闭被依赖的； S*：要启动的服务；S##*，优先级，数字越小，越是优先启动；被依赖的服务先启动，而依赖的服务后启动； rc#.d/ 目录下所有文件都是链接文件，连接到 /etc/rc.d/init.d/ 12&gt; ls /etc/rd.d/init.d rc rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d rc.local rc.sysinit 1.2 服务启动/etc/init.d/* (/etc/rc.d/init.d/*)脚本执行方式： /etc/init.d/SRV_SCRIPT {start|stop|restart|status} service SRV_SCRIPT {start|stop|restart|status} 1.3 配置服务开机启动chkconfig命令： 作用: 管控/etc/init.d/每个服务脚本在各级别下的启动或关闭状态； 添加：chkconfig --add name 作用: 将 name 脚本添加到service 命令的控制中，并按照脚本中 chkconfig 的配置在对应级别下设置开机启动，其他级别下设置开机关闭 启动/关闭指定级别服务： chkconfig [--level LEVELS] name on|off|reset --level LEVELS：指定要控制的级别；默认为2345； 查看：chkconfig --list [name] 删除：chkconfig --del name 作用: 将服务从 service 管理的范围内删除，并从各个级别的开机启动中删除 注意：正常级别下，最后启动的一个服务S99local 没有链接至/etc/init.d下的某脚本，而是链接至了/etc/rc.d/rc.local （/etc/rc.local）脚本；因此，不便或不需写为服务脚本的程序期望能开机自动运行时，直接放置于此脚本文件中即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445&gt; vim /etc/init.d/testsrv#!/bin/bash# testsrv serviec testing script## chkconfig: 234 50 60# description: testing service# 注解: 必须要有 chkconfig:# chkconfig: LLL NN NN -- 被添加到的级别，启动优先级，关闭优先级# chkconfig: - 50 60 -- 表示没有级别$prog=$(basename $0)if [ $# -lt 1 ]; then echo &quot;Usage: $&#123;prog&#125; &#123;start|stop|status|restart&#125;&quot; exit 1fiif [ &quot;$1&quot; == &quot;start&quot; ]; then echo &quot;start $prog success&quot;elif [ &quot;$1&quot; == &quot;stop&quot; ]; then echo &quot;stop $prog success&quot;elif [ &quot;$1&quot; == &quot;status&quot; ]; then if pidof $prog &amp;&gt; /dev/null; then echo &quot;$prog is running&quot; else echo &quot;$prog is stopped&quot; fielif [ &quot;$1&quot; == &quot;restart&quot; ]; then echo &quot;restart $prog success&quot;else echo &quot;Usage: $&#123;prog&#125; &#123;start|stop|status|restart&#125;&quot; exit 2fi&gt; chkconfig --add testsrv&gt; ls /etc/rc.d/rc3.d/ |grep testsrv&gt; chkconfig --list testsrv&gt; chkconfig --level 23 testsrv off&gt; chkconfig --del testsrv 1.5 总结（用户空间的启动流程）：/sbin/init (/etc/inittab) 设置默认运行级别 运行系统初始化脚本(/etc/rc.d/rc.sysinit)，完成系统初始化 设置主机名 设置欢迎信息 激活udev和selinux 挂载/etc/fstab文件中定义的所有文件系统 检测根文件系统，并以读写方式重新挂载根文件系统 设置系统时钟； 根据/etc/sysctl.conf文件来设置内核参数 激活lvm及软raid设备 激活swap设备 加载额外设备的驱动程序 清理操作 关闭对应级别下需要停止的服务，启动对应级别下需要开启的服务 设置登录终端 [–&gt; 启动图形终端] 2. CentOS 6：Centos 6 中init程序为 upstart，但依然为/sbin/init 配置文件包括如下: /etc/init/*.conf /etc/inittab（仅用于定义默认运行级别） 注意：*.conf为upstart风格的配置文件，需遵循其配置语法； rcS.conf rc.conf start-ttys.conf CentOS 6启动流程： POST –&gt; Boot Sequence(BIOS) –&gt; Boot Loader (MBR) –&gt; Kernel(ramdisk) –&gt; rootfs –&gt; switchroot –&gt; /sbin/init –&gt;(/etc/inittab, /etc/init/*.conf) –&gt; 设定默认运行级别 –&gt; 系统初始化脚本 –&gt; 关闭或启动对应级别下的服务 –&gt; 启动终端]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[13.1 CentOS系统启动流程介绍]]></title>
    <url>%2F2018%2F02%2F19%2Flinux_mt%2F14-Linux%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E7%AE%A1%E7%90%86%2FCentOS%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[CentOS系统启动流程介绍 本章我们将学习 Linux 启动流程和内核模块管理相关的内容。通过本章我们将学习如下内容: Linux 系统的组成及特点 CentOS 系统的启动流程 开机启动成 grub 的配置和使用 内核功能与内核模块的加载与使用 在学习本章内容之前，需要对之前学习的操作系统知识做一个简单梳理总结，目的是了解 Linux 系统在启动时面临了哪些问题，怎么去解决这些问题。这样我们才能知道为什么启动流程是”这样”。 123456789--------------| 库调用接口 |---------------| 系统调用接口 |-------------------------------| 操 作 系 统 |-------------------------------| 底 层 硬 件 |------------------------------- 在一个已经开机的计算机上，操作系统位于底层硬件之上，通过加载硬件的驱动程序从而能够管理各种硬件设备。操作系统通过系统调用，将管理底层硬件的接口暴露给各应用程序。应用程序在需要时发起系统调用即可完成对底层硬件的驱动。系统调用接口比较简陋，不便于程序员进行编程，因此在系统调用基础上有各种库，方便程序员进行编程。 操作系统=内核+根文件系统，Linux 中一切皆文件，Linux 的所有设备都表现为根文件系统上的某个文件。因此内核必需首先要加载底层磁盘设备的驱动程序，然后加载该磁盘设备上特定的文件系统，最后挂载根文件系统。 但是在系统启动之前，操作系统和各种驱动程序都是存放在硬盘上的。这样就会出现以下问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 因此开机启动，必需要解决上述两个问题。 本节，我们开始学习 Centos 系统的启动流程，本章开篇我们了解到，开机过程中存在两个问题: 为加载内核需要读取磁盘中的内核源码，而读取磁盘文件需要先挂载根文件系统，此时操作系统还没有更不可能挂在根文件系统了 挂载根文件系统时，首先需要加载磁盘和文件系统的驱动程序。而文件系统还没有挂载，根本没法读取到位于根文件系统中的驱动程序 本节核心就是讲解如何解决上述两个问题，并在此基础上介绍 Linux 系统的启动。本节将包括以下内容: Linux 系统特性，包括Linux 系统的功能及设计思路 Linux 开机启动流程，包括: Linux 系统组成，Linux 为开机启动准备的额外文件 Linux 系统详细启动过程 1. Linux 系统特性Linux 主要由内核+根文件系统组成，一个运行中的Linux，可以看作是运行在内核之上，由内核负责完成底层硬件管理，从而将硬件接口抽象为系统接口以后，让根文件系统工作为文件系统的一个底层虚拟机。运行中的OS可以分为内核空间和用户空间两个部分，应用程序运行在用户空间，通常表现为一个进程或线程；而内核空间主要运行内核代码，执行特权操作，通过系统调用向用户空间输出接口。用户空间通过发起系统调用执行特权操作。 Linux 需要实现的功能包括: 进程管理，进程创建，调度，销毁 内存管理，将内存抽象为虚拟的线性地址格式，为每个进程提供一份，就好像每个进程单独运行在操作系统之上一样 IPC 机制: 消息队列 semerphor 信号量 share memory 共享内存 网络协议栈 文件系统 驱动程序 《Linux 设备驱动》 安全功能 内核设计有两种流派 单内核设计：把所有功能集成于同一个程序，典型代表为 Linux 微内核设计：每种功能使用一个单独的子系统实现，典型代表为 Windows, Solaris Linux 虽然为单内核设计但是充分吸收了微内核的特点，支持模块化(.ko (kernel object))，支持模块运行时动态装载或卸载。 1. Linux 系统启动流程1.1 Linux 系统的组成首先我们来解决开机启动的第二个问题。内核加载根文件系统需要加载驱动程序，而驱动程序就在根之上。因此我们不能依赖根文件系统上的驱动程序，内核必须自带驱动程序。 一种方法是将设备的驱动程序编译进内核，对于个人用户自编译的系统没有有问题，因为只需要将其特定的驱动程序编译进内核即可，然后对于操作系统发行商而然，它面对的是各种用户的不同驱动设备，如果都将这些驱动程序编译进内核，内核将庞大无比，而每个用户又只会用到其中一个。 另一种方法是借助于中间临时根文件系统，中间临时根文件系统包含了加载根文件系统所在设备的驱动程序，而中间根文件系统放置在一个基于内存的磁盘设备中，内核无须加载其他驱动程序即可访问该设备。内核启动后，先访问基本设备挂载中间的临时根文件系统，并从中装载设备驱动程序，在真正的根文件系统准备完成之后，从临时根切换到真正的根。 用于系统初始化的基于内存的磁盘设备通常称为 ramdisk，内核在启动过程中需要将 ranmdisk 装载进内存 ，并将其识别为一个根文件系统。ramdisk 并不是发行商预先生成，而是在系统安装过程中针对当前设备临时生成了，因此其仅需包含当前设备的驱动程序即可。 因此从编译完成后的视角，Linux 系统由如下部分组成: 核心文件：/boot/vmlinuz-VERSION-release ramdisk： CentOS 5：/boot/initrd-VERSION-release.img # 基于 ram 的磁盘 CentOS 6,7：/boot/initramfs-VERSION-release.img # 基于 ram 的文件系统 模块文件： /lib/modules/VERSION-release 如果内核提供了多个版本，将会有多个内核目录 1234567891011121314151617181920212223242526272829303132333435363738394041424344&gt; uname -r # 内核版本4.9.86-30.el7.x86_64&gt; ls /boot/|grep vmvmlinuz-4.9.86-30.el7.x86_64&gt; ls /lib/modules/$(uname -r)/kernelarch crypto drivers fs lib mm net sound virt&gt; tree -L 2 /lib/modules/$(uname -r)/lib/modules/4.9.86-30.el7.x86_64├── build -&gt; ../../../usr/src/kernels/4.9.86-30.el7.x86_64├── extra├── kernel│ ├── arch│ ├── crypto│ ├── drivers│ ├── fs│ ├── lib│ ├── mm│ ├── net│ ├── sound│ └── virt├── modules.alias├── modules.alias.bin├── modules.block├── modules.builtin├── modules.builtin.bin├── modules.dep├── modules.dep.bin├── modules.devname├── modules.drm├── modules.modesetting├── modules.networking├── modules.order├── modules.softdep├── modules.symbols├── modules.symbols.bin├── source -&gt; build├── updates├── vdso│ ├── vdso32.so│ └── vdso64.so└── weak-updates 1.2 MBR 与 BootSector接下来我们来解决第一个问题，在没有根文件系统的前提下将内核加载进内存。可引导设备的第一个分区叫MBR，MBR 中包含了开机引导程序 BootLoader。开机启动时会先加载 MBR内的BootLoader，由BootLoader 将内核加载到内存。有人可能会问，开机时是如何读取到MBR的，BootLoader又是如何读取到内核文件的。BIOS 通过硬件的 INT 13 中断功能来读取 MBR，也就是说，只要 BIOS 能够侦测的到你的磁盘 （不论磁盘是 SATA 还是 SAS ），那他就有办法通过 INT 13 这条信道来读取该磁盘的第一个扇区内的 MBR 软件，这样 boot loader 也就能够被执行。boot loader 能够识别操作系统的文件格式，也就能加载核心文件。其他分区的第一个扇区叫做 boot sector，也可以安装BootLoader，这样可以实现多系统安装。 有了上述阐述，我们就可以开始讲解开机启动流程了。 1.2 Centos 系统的启动流程(MBR 架构)启动流程: POST: 加电自检。 x86 架构的计算机被设计成，只要通电就会去执行，主板上有个 ROM 芯片内的BOIS程序 通过 BIOS 程序去载入 CMOS 的信息，并且借由 CMOS 内的设置值取得主机的各项硬件参数及设置，例如硬盘的大小与类型 在获取硬件信息后，BIOS 会进行开机自我测试 (Power-on Self Test, POST) ，然后开始执行硬件侦测的初始化，并设置 PnP 设 备，之后再定义出可开机的设备顺序，接下来就会开始进行开机设备的数据读取 Boot Sequence:开机启动次序 家电自检完成后，计算机就会按次序查找各引导设备，第一个有引导程序的设备即为本次启动用到的设备。 引导程序称为 BootLoader，又称引导加载器。 如果是通过U盘安装操作系统，就需要进入 BIOS 设置系统的开机启动次序 bootloader：引导加载器，程序，位于MBR中； 功能： 提供一个菜单，允许用户选择要启动的系统或不同的内核版本； 把用户选定的内核装载到RAM中的特定空间中，解压、展开，而后把系统控制权移交给内核 Windows：ntloader Linux： LILO：LIinux LOader GRUB：Grand Uniform Bootloader GRUB 0.X：Grub Legacy GRUB 1.X：Grub2 MBR/GRUB: MBR：Master Boot Record，512bytes： 446bytes：bootloader 64bytes：fat, 磁盘分区表 2bytes：55AA GRUB：两阶段加载 bootloader：1st stage Partition：filesystem driver, 1.5 stage Partition：/boot/grub, 2nd stage Kernel: 自身初始化： 探测可识别到的所有硬件设备； 加载硬件驱动程序；（有可能会借助于ramdisk加载驱动） 以只读方式挂载根文件系统； 运行用户空间的第一个应用程序：/sbin/init 执行 init 程序： CentOS 5：SysV init 配置文件：/etc/inittab CentOS 6：Upstart init 的升级版，可以并行启动 配置文件: /etc/inittab: 为向前兼容，基本没哟使用 /etc/init/\*.conf CentOS 7：Systemd 配置文件： /usr/lib/systemd/system/ /etc/systemd/system/ ramdisk： Linux内核的特性之一：使用缓冲和缓存来加速对磁盘上的文件访问； 升级: ramdisk –&gt; ramfs 生成工具: CentOS 5: initrd – mkinitrd CentOS 6,7: initramfs – dracut, mkinitrd 1.3 总结:系统初始化流程（内核级别） POST自检， 按照BootSequence(BIOS)查找能开机启动的设备 在设备的 MBR上加载 BootLoader，BootLoader 去磁盘分区上读取内核。 Kernel可能会借助于 ramdisk 加载真正根文件系统所在设备的驱动程序 内核装载 rootfs（readonly，并执行开机启动程序 /sbin/init 需要说明的是无论是下述的 ramdisk 还是 BootLoader 都是在安装操作系统时针对当前硬件生成的。所以 BootLoader 是能够识别当前主机的硬盘设备的。但是需要注意的是BootLoader 是需要和磁盘分区打交道的，而BootLoader 本身一般是无法驱动那些软设备，逻辑设备(LVM),也无法驱动RAID这些复杂的逻辑结构，因此内核只能放在基本的磁盘分区上。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.5 作业管理]]></title>
    <url>%2F2018%2F02%2F18%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[作业管理 所谓作业管理就是我们如何在同一终端下执行多个任务。Linux 中作业分为 前台作业(foregroud)：通过终端启动，且启动后会一直占据终端； 后台作业(backgroud)：可以通过终端启动，但启动后即转入后台运行（释放终端）； 如果我们想在同一终端执行多个任务，就必须将当前的前台作业切换为后台作业 1. 将作业运行于后台如何将作业运行于后台呢: 运行中的作业，使用 快捷键 Ctrl+z，作业被送往后台后，会转为停止状态； 尚未启动的作业 使用 COMMAND &amp;，命令后跟 &amp;，进程自动以后台作业运行 需要注意的是，上述作业虽然被送往后台，但其依然与终端相关；如果希望把送往后台的作业剥离与终端的关系使用 nohup 命令，即 nohup COMMAND &amp; 2. 作业控制命令 fg [[%]JOB_NUM]：把指定的作业调回前台； bg [[%]JOB_NUM]：让送往后台的作业在后台继续运行； kill %JOB_NUM：终止指定的作业； jobs：查看所有的作业]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.4 系统状态查看]]></title>
    <url>%2F2018%2F02%2F17%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E7%B3%BB%E7%BB%9F%E7%8A%B6%E6%80%81%E6%9F%A5%E7%9C%8B%2F</url>
    <content type="text"><![CDATA[系统状态查看 系统状态查看命令，可以查看系统包括磁盘，CPU，内存，缓存，进程，网络等等几乎所有的状态信息。本节我们主要介绍 vmstat,pmap, dstat 三个命令的使用。 1. vmstat命令：vmstat [options] [delay [count]] 作用: 查看虚拟内存使用状况 选项： -s：显示内存统计数据；类似于 cat /proc/meminfo 1234tao@hp:~$ vmstatprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 0 484884 1292 3710880 0 0 179 83 455 865 14 4 82 1 0 输出: procs： r：等待运行的进程的个数；CPU上等待运行的任务的队列长度； b：处于不可中断睡眠态的进程个数；被阻塞的任务队列的长度； memory： swpd：交换内存使用总量； free：空闲的物理内存总量； buffer：用于buffer的内存总量； cache：用于cache的内存总量； swap si：数据进入swap中的数据速率（kb/s） so：数据离开swap的速率(kb/s) io bi：从块设备读入数据到系统的速度（kb/s） bo：保存数据至块设备的速率（kb/s） system in：interrupts，中断速率，即每秒发生的中断次数； cs：context switch, 上下文切换的速率，即每秒发生的进程切换次数； cpu us：user space，用户空间占用 cpu 比例 sy：system，内核空间占用 cpu 比例 id：idle，cpu 空闲比例 wa：wait，等待 I/O 完成，消耗的 cpu 时间比例 st: stolen，被虚拟化技术偷走的 cpu 时间比例 2. pmap命令：pmap [options] pid [...] 作用: 显示进程虚拟内存到物理内存的映射关系表 -x：显示详细格式的信息； 另一种查看方式：cat /proc/PID/maps 3. dstat命令：dstat [-afv] [options..] [delay [count]] 作用: 统计系统资源的使用情况 常用选项： -c， --cpu：显示cpu相关信息； -C 1,3,...,total: 显示指定的cpu相关信息； -d, --disk：显示磁盘的相关信息 -D sda,sdb,...,tobal: 显示指定磁盘的相关信息 -g：显示page相关的速率数据； -m：Memory的相关统计数据 -n：显示network 相关统计数据； -p：显示process的相关统计数据； -r：显示io请求的相关的统计数据； -s：显示swapped的相关统计数据； --tcp --udp --raw --socket --ipc --top-cpu：显示最占用CPU的进程； --top-io：最占用io的进程； --top-mem：最占用内存的进程； --top-lantency：延迟最大的进程； 1234567tao@hp:~$ dstatYou did not select any stats, using -cdngy by default.----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--usr sys idl wai hiq siq| read writ| recv send| in out | int csw 14 3 82 1 1 0|1355k 633k| 0 0 | 0 0 |1788 3408 26 1 73 0 1 0| 0 4096B| 471B 224B| 0 0 |1916 1627 26 0 73 1 0 0| 0 188k| 92B 0 | 0 0 |1950 1744]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.3 进程管理的实时动态命令]]></title>
    <url>%2F2018%2F02%2F16%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E5%AE%9E%E6%97%B6%E5%8A%A8%E6%80%81%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[进程管理实时动态命令 下面介绍的 top, htop，glances 都是能实时查看系统状态的动态命令，有众多快捷键可以控制屏幕显示的内容。htop 是 top 命令的升级版，glance 则是另一款 htop 它们实现的功能类似。 1. topuptime 作用: 显示系统时间、运行时长及平均负载； 过去1分钟、5分钟和15分钟的平均负载； 等待运行的进程队列的长度； 注释: 显示内容即 top 命令的首部信息 top options 作用: display Linux processe 选项: -d #: 指定刷新时间间隔，默认为3秒； -b: 以批次方式显示； -n #: 显示多少批次，与 -b 一起使用； 快捷键: 排序: P: 以占据CPU百分比排序； M: 以占据内存百分比排序； T: 累积占用CPU时间排序； 首部信息: uptime信息: l 命令 tasks及cpu信息: t 命令 CPU分别显示使用数字 1 内存信息: m命令 退出命令: q 修改刷新时间间隔: s 终止指定的进程: k 帮助: h 显示COMMAND 详细信息: c 12345678910#快捷键: l# top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40#快捷键: t# Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie#快捷键: 1# %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st#快捷键: m# KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cache KiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 4812 tao 20 0 2876852 431600 139652 S 9.5 5.3 49:00.29 atom 2150 root 20 0 447256 122816 71820 S 4.6 1.5 13:42.31 X 4384 tao 20 0 4824324 1.066g 39644 S 3.6 13.8 49:54.58 java top - 18:10:50 up 9:21, 6 users, load average: 0.73, 0.55, 0.40 作用: Top 任务队列信息(系统运行状态及平均负载)，与uptime命令结果相同 字段: 系统当前时间 系统运行时间，未重启的时间 当前登录用户数 系统负载，即任务队列的平均长度，3个数值分别统计最近1，5，15分钟的系统平均负载 单核CPU情况下，0.00 表示没有任何负荷，1.00表示刚好满负荷，超过1侧表示超负荷，理想值是0.7； 多核CPU负载：CPU核数 * 理想值0.7 = 理想负荷，例如：4核CPU负载不超过2.8何表示没有出现高负载 Tasks: 333 total, 1 running, 332 sleeping, 0 stopped, 0 zombie 作用: Tasks 进程相关信息 字段: 进程总数，例如：Tasks: 231 total, 表示总共运行231个进程 正在运行的进程数，例如：1 running, 睡眠的进程数，例如：230 sleeping, 停止的进程数，例如：0 stopped, 僵尸进程数，例如：0 zombie %Cpu(s): 5.6 us, 2.3 sy, 0.0 ni, 90.8 id, 0.1 wa, 0.8 hi, 0.4 si, 0.0 st 作用: CPU 相关信息 字段: us: 用户空间占用CPU百分比，例如：Cpu(s): 12.7%us, sy: 内核空间占用CPU百分比，例如：8.4%sy, ni: 用户进程空间内改变过优先级的进程占用CPU百分比，例如：0.0%ni, id: 空闲CPU百分比，例如：77.1%id, wa: 等待输入输出的CPU时间百分比，例如：0.0%wa, hi: CPU服务于硬件中断所耗费的时间总额，例如：0.0%hi, si: CPU服务软中断所耗费的时间总额，例如：1.8%si, st: Steal time 虚拟机被hypervisor偷去的CPU时间（如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的） KiB Mem : 8115092 total, 501932 free, 5477676 used, 2135484 buff/cacheKiB Swap: 2097148 total, 2093124 free, 4024 used. 1486672 avail Mem 作用: 内存 相关信息 字段: 物理内存总量，例如：Mem: 12196436k total, 使用的物理内存总量，例如：12056552k used, 空闲内存总量，例如：Mem: 139884k free, 用作内核缓存的内存量，例如：64564k buffers 字段值含义 PID = (Process Id): 进程Id； USER = (User Name): 进程所有者的用户名； PR = (Priority): 优先级 NI = (Nice value): nice值。负值表示高优先级，正值表示低优先级 VIRT = (Virtual Image (kb)): 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES = (Resident size (kb)): 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR = (Shared Mem size (kb)): 共享内存大小，单位kb S = (Process Status): 进程状态。D=不可中断的睡眠状态,R=运行,S=睡眠,T=跟踪/停止,Z=僵尸进程 %CPU = (CPU usage): 上次更新到现在的CPU时间占用百分比 %MEM = (Memory usage (RES)): 进程使用的物理内存百分比 TIME+ = (CPU Time, hundredths): 进程使用的CPU时间总计，单位1/100秒 PPID = (Parent Process Pid): 父进程Id RUSER = (Real user name): UID = (User Id): 进程所有者的用户id GROUP = (Group Name): 进程所有者的组名 TTY = (Controlling Tty): 启动进程的终端名。不是从终端启动的进程则显示为 ? P = (Last used cpu (SMP)): 最后使用的CPU，仅在多CPU环境下有意义 SWAP = (Swapped size (kb)): 进程使用的虚拟内存中，被换出的大小，单位kb TIME = (CPU Time): 进程使用的CPU时间总计，单位秒 CODE = (Code size (kb)): 可执行代码占用的物理内存大小，单位kb DATA = (Data+Stack size (kb)): 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb nFLT = (Page Fault count): 页面错误次数 nDRT = (Dirty Pages count): 最后一次写入到现在，被修改过的页面数 WCHAN = (Sleeping in Function): 若该进程在睡眠，则显示睡眠中的系统函数名 Flags = (Task Flags &lt;sched.h&gt;): 任务标志，参考 sched.h COMMAND = (Command name/line): 命令名/命令行 2. htophtop options 选项: -d #: 指定延迟时间间隔； -u UserName: 仅显示指定用户的进程； -s COLUME: 以指定字段进行排序； 子命令: l: 显示选定的进程打开的文件列表； s: 跟踪选定的进程的系统调用； t: 以层级关系显示各进程状态； a: 将选定的进程绑定至某指定的CPU核心； 3. glances命令：glances options 作用: 动态的系统状态监控工具，使用类似 top 常用选项： -b：以Byte为单位显示网上数据速率； -d：关闭磁盘I/O模块； -m：关闭mount模块； -n：关闭network模块； -t #：刷新时间间隔； -1：每个cpu的相关数据单独显示； -o {HTML|CSV}：输出格式； -f /PATH/TO/SOMEDIR：设定输出文件的位置； C/S模式下运行glances命令： 服务模式：glances -s -B IPADDR IPADDR：本机的某地址，用于监听； 客户端模式： glances -c IPADDR IPADDR：是远程服务器的地址； 附注: C/S 模式下无论是密码还是内容都是明文传输的，容易被截获，glances 不适合 C/S 模式使用]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.2 进程管理命令]]></title>
    <url>%2F2018%2F02%2F15%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2F%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[进程管理命令 Linux系统上有众多进程查看及管理工具，不完全列示如下: 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall 进程优先级调整: nice, renice 这些命令在我们以后的运维过程中都能用到，希望大家能熟练掌握。 1. 进程查看1.1 pstreepstree options 作用: 以树状图的方式展现进程之间的派生关系 选项: -p: 显示程序 pid； -u: 显示用户名称； -n: 用 pid 排序,预设是以程序名称来排序； -a: 显示每个程序的完整指令，包含路径，参数或是常驻服务的标示； -c: 不使用精简标示法； -G: 使用VT100终端机的列绘图字符； -h: 列出树状图时，特别标明现在执行的程序； -H&lt;pid&gt;: 此参数的效果和指定”-h”参数类似，但特别标明指定的程序； -l: 采用长列格式显示树状图； -U: 使用UTF-8列绘图字符； -V: 显示版本信息 1.2 psps 命令简介在前面的 4.1 Linux目录机构 我们提到过，Linux 有两个伪文件系统 /proc,/sys /proc/: 是基于内存的虚拟文件系统，保存了内核及进程的相关信息； /proc 内的内核参数分为两类: 状态变量: 其用于输出内核中统计信息或状态信息，仅用于查看 可设置其值从而调整内核运行特性的参数,位于 /proc/sys/，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； /sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径 其主要作用在于为管理Linux设备提供一种统一模型的的接口； Linux 进程的各种状态信息保存在 /proc 中以进程 PID 号命名的文件中。ps 命令即是通过读取 /proc/PID 目录内的文件，显示进程的相关信息。ps 命令选项有三种风格: UNIX 风格的参数，必需使用 - BSD 风格的参数, 不能使用 - GNU 风格的长选项, 使用--开头 ps 使用ps [options]: 作用: report a snapshot of the current processes. BSD 选项: a: 所有与终端相关的进程； x: 所有与终端无关的进程； u: 以用户为中心组织进程状态信息显示； U&lt;uname&gt;: 显示特定用户进程 -o/o field1, field2,...: 可以加 - 也可以不加 用于自定义要显示的字段列表，字段列表以逗号分隔； 常用的field: pid, ni, pri, psr, pcpu, stat, comm, tty, ppid, rtprio UNIX 选项: -e: 显示所有进程 -f: 显示完整格式的进程信息 -F: 显示完整格式的进程信息，与 -f 显示的字段略不同 -H: 以层级结构显示进程的相关信息； -U&lt;uid&gt;: 显示特定用户进程 -u&lt;uid&gt;: 显示特定用户进程 常用组合之一: ps aux ps -ef ps -eFH ps -eo, ps axo ps aux1234567891011tao@hp:~$ ps aux |head -10USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.1 194436 9136 ? Ss 08:49 0:03 /usr/lib/systemd/systemd --switched-root --system --deserialize 21root 2 0.0 0.0 0 0 ? S 08:49 0:00 [kthreadd]root 3 0.0 0.0 0 0 ? S 08:49 0:00 [ksoftirqd/0]root 5 0.0 0.0 0 0 ? S&lt; 08:49 0:00 [kworker/0:0H]root 7 0.0 0.0 0 0 ? S 08:49 0:03 [rcu_sched]root 8 0.0 0.0 0 0 ? S 08:49 0:00 [rcu_bh]root 9 0.0 0.0 0 0 ? S 08:49 0:01 [rcuos/0]root 10 0.0 0.0 0 0 ? S 08:49 0:00 [rcuob/0]root 11 0.0 0.0 0 0 ? S 08:49 0:00 [migration/0] %CPU: CPU 占用百分比 %MEM: 内存占用百分比 VSZ: 虚拟内存集； RSS: Resident Size，常驻内存集； TTY: 进程所属终端 STAT: 进程状态 R: running，运行中 S: interruptable sleeping，可中断睡眠 D: uninterruptable sleeping，不可中断睡眠 T: Stopped，停止状态 Z: zombie，僵尸进程 +: 前台进程 l: 多线程进程 N: 低优先级进程 &lt;: 高优先级进程 s: session leader，管理着多个其他进程的进程 START: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -ef12345678tao@hp:~$ ps -ef|head -10UID PID PPID C STIME TTY TIME CMDroot 1 0 0 08:49 ? 00:00:04 /usr/lib/systemd/systemd --switched-root --system --deserialize 21root 2 0 0 08:49 ? 00:00:00 [kthreadd]root 3 2 0 08:49 ? 00:00:00 [ksoftirqd/0]root 5 2 0 08:49 ? 00:00:00 [kworker/0:0H]root 7 2 0 08:49 ? 00:00:03 [rcu_sched]root 8 2 0 08:49 ? 00:00:00 [rcu_bh] PPID: 父进程的 pid C: cpu utilization, CPU 占用率 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eFH1234567tao@hp:~$ ps -eFH|head -10UID PID PPID C SZ RSS PSR STIME TTY TIME CMDroot 2 0 0 0 0 2 08:49 ? 00:00:00 [kthreadd]root 3 2 0 0 0 0 08:49 ? 00:00:00 [ksoftirqd/0]root 5 2 0 0 0 0 08:49 ? 00:00:00 [kworker/0:0H]root 7 2 0 0 0 3 08:49 ? 00:00:03 [rcu_sched]root 8 2 0 0 0 0 08:49 ? 00:00:00 [rcu_bh] C: cpu utilization, CPU 占用率 SZ: VSZ 虚拟内存集； RSS: Resident Size，常驻内存集； PSR: 进程运行于哪颗CPU之上 STIME: 开始运行时间 TIME: 进程累积实际使用CPU时间片之和 ps -eo|axo1234567891011tao@hp:~$ ps -eo user,uid,nice,priority,psr,pcpu,stat,rtprio,cmd,tty,ppidUSER UID NI PRI PSR %CPU STAT RTPRIO CMD TT PPIDroot 0 0 20 0 0.0 Ss - /usr/lib/systemd/systemd -- ? 0root 0 0 20 2 0.0 S - [kthreadd] ? 0root 0 0 20 0 0.0 S - [ksoftirqd/0] ? 2root 0 -20 0 0 0.0 S&lt; - [kworker/0:0H] ? 2root 0 0 20 0 0.0 S - [rcu_sched] ? 2root 0 0 20 0 0.0 S - [rcu_bh] ? 2root 0 0 20 2 0.0 S - [rcuos/0] ? 2root 0 0 20 0 0.0 S - [rcuob/0] ? 2root 0 - -100 0 0.0 S 99 [migration/0] ? 2 ps -eo user, uid, nice, priority, psr, pcpu, stat, rtprio, cmd, tty, ppid ni/nice: nice值 priority: priority, 优先级 psr: PSR 进程运行于哪颗CPU之上 pcpu: %CPU cpu 占用百分比 stat: STAT 进程状态 rtprio: real time priority，实时优先级 1.3 pgreppgrep [options] pattern 作用: 通过进程名或其他属性查找进程 参数: pattern 匹配进程名的模式 选项 -l: 显示进程名； -a: 显示完整格式的进程名； -u uid: effective user，有效用户 -U uid: real user，实际用户 -t TERMINAL: 与指定的终端相关的进程； -P pid: 显示此进程的子进程； -o：仅显示找到的最小（起始）进程号； -n：仅显示找到的最大（结束）进程号； 12345678tao@hp:~$ pgrep -la htt*13163 /usr/sbin/httpd -DFOREGROUND13169 /usr/sbin/httpd -DFOREGROUND13172 /usr/sbin/httpd -DFOREGROUND13173 /usr/sbin/httpd -DFOREGROUND13177 /usr/sbin/httpd -DFOREGROUND13178 /usr/sbin/httpd -DFOREGROUND13180 /usr/sbin/httpd -DFOREGROUND 1.4 pidof命令:pidof [options] program [program..] 作用: 根据进程名，取其进程 pid 参数: program 进程名称 选项: -s：仅返回一个进程号； 12tao@hp:~$ pidof httpd13180 13178 13177 13173 13172 13169 13163 2. 进程管理kill 类命令可以向进程发送信号，以实现对进程管理。Linux 中每个信号的标识方法有三种: 信号的数字标识； 信号的完整名称； 信号的简写名称； 12345# HUP = SIGHUP = 1tao@hp:monitor$ kill -l 1HUPtao@hp:monitor$ kill -l SIGHUP1 2.1 kill查看信号类型kill -l [signal] 作用: 查看信号类型 参数: signal 待查看的信号类型，可选，默认显示所有信号 常用信号: 12345678910111213141516171819tao@hp:monitor$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAXtao@hp:monitor$ kill -l 1HUPtao@hp:monitor$ kill -l SIGHUP1 发送信号管理进程kill [-s signal|-SIGNAL] pid... 作用: 用于向进程发送信号，以实现对进程的管理 选项: -s signal|-SIGNAL: 指明要发送的信号 -p：指定kill 命令只打印相关进程的进程号，而不发送任何信号； -u：指定用户 常用信号: 1） SIGHUP: 无须关闭进程而让其重读配置文件； 2）SIGINT: 终止正在运行的进程，相当于Ctrl+c 9）SIGKILL: 杀死运行中的进程； 15）SIGTERM: 终止运行中的进程； 18）SIGCONT: 启动暂停的进程 19）SIGSTOP: 暂停进程 1234kill -9 1999kill -s 9 1999kill -SIGKILL 1999kill -KILL 1999 2.2 killallkillall [-SIGNAL] program 作用: 使用进程的名称来杀死进程，使用此指令可以杀死一组同名进程 参数: program 进程名称 选项: -e：对长名称进行精确匹配； -l：忽略大小写的不同； -p：杀死进程所属的进程组； -i：交互式杀死进程，杀死进程前需要进行确认； -l：打印所有已知信号列表； -q：如果没有进程被杀死。则不输出任何信息； -r：使用正规表达式匹配要杀死的进程名称； -s signal|-SIGNAL：指定发送的信号 -u：杀死指定用户的进程。 2.3 pkillpkill [options] pattern 作用: 通过进程名或其他属性向进程发送信号，用法与 pgrep 类似 选项: -u uid: effective user，向指定的有效用户发送信号 -U uid: real user，向指定的实际用户发送信号 -t TERMINAL: 向指定的终端相关的进程发送信号； -P pid: 向此进程的子进程发送信号 -g：指定进程组； -o：仅向找到的最小（起始）进程号发送信号； -n：仅向找到的最大（结束）进程号发送信号； 3. 进程优先级调整Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级，Nice值用于调整静态优先级。 需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。进程启动时，nice值默认为0，优先级是120，可通过nice值调整的优先级范围是 100-139，nice值分别对应于-20, 19 诸多命令都可以查看进程的优先级与 nice 值，比如 ps axo pid, ni, priority, comm nicenice [OPTION] [COMMAND [ARGU]...] 作用: 以指定的nice值启动并运行命令 参数: COMMAND： 要执行的命令，如果没给 COMMAND, 显示当前进程的优先级 ARGU: 传递给 COMMAND 的参数 选项： -n NICE: 指定优先级，默认为 5 注意：仅管理员可调低nice值； renicerenice [-n] NICE PID... 作用: 更改已经运行用户的优先级 参数: NICE: 新 nice 值 PID: 进程PID 4. 未涉及到的命令：sar, tsar, iostat, iftop, nethog, …]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[12.1 Linux进程原理]]></title>
    <url>%2F2018%2F02%2F14%2Flinux_mt%2F13-%E8%BF%9B%E7%A8%8B%E5%8F%8A%E4%BD%9C%E4%B8%9A%E7%AE%A1%E7%90%86%2FLinux%E8%BF%9B%E7%A8%8B%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux进程原理 本章我们来学习 Linux 中的进程管理，这是运维的基本内容，我们需要借此查看 Linux 服务的负载，分析和删除系统上的异常进程等等。首先我们会简单介绍操作系统原理中有关进程，虚拟内存相关的基础知识，这是原理部分；如果对进程一无所知对很多命令的输出结果我们很难明白其含义。然后我们会介绍 Linux 上常用的进程查看和管理工具，这些都是我们分析和管理系统的重要工具，最后我们会说一说 Linux 中的作业管理。本章内容总结如下: 操作系统的基本原理之进程 常用的进程查看和管理工具 进程查看命令: pstree, ps, pidof, pgrep 进程管理命令: kill, pkill, killall，nice, renice 实时动态命令的使用，top, glances, htop 系统状态查看,vmstat, pmap, dstat 作业管理 有关 Linux 的实现有两本书推荐大家观阅读 Linux内核设计与实现: 入门级 深入理解Linux内核: 进阶级 当然没那么容易说清楚进程是什么。无论是什么程序员，操作系统，编译原理永远都是谜一样的话题，但是人总是要慢慢进步的，随着我们不断成长，对其的认识也会慢慢深入。好吧，我们开始吧。 现代操作系统都是多任务系统，目前常用的服务器也就 64 个核心，通常要运行的任务一定比操作系统的核心多，那么就存在几个问题。一是我们应该如何给不同任务分配运行时间？二是多个任务如何共享使用我们的存储设备，特别是内存？这就涉及到进程和虚拟内存的概念了。 1. 进程和内存的抽象进程 进程是操作系统对一个独立的运行程序的抽象，是操作系统调度的基本单元(操作系统调度的基本单元应该是线程，但是通常一个进程只有一个线程，可以先这么理解)。每个进程都有一个叫作 task structure 的结构，其包含了该进程能正常运行的所有上下文。什么是程序运行的上下文呢？那我们要从计算机的存储系统说起。 我们都知道我们的计算机有硬盘，内存，缓存。为什么回有这么多存储设备呢？主要是因为不同的存储介质工作频率不相同，工作频率高的造价高。如果我存储介质跟不上 CPU 的频率就会造成 CPU 性能的浪费。因此基于最近被访问的数据很有可能在接下来再次被访问这样一个原理，计算机的存储系统被构建成了如下的层次结构 典型的 CPU 里面有寄存器，它的工作频率几乎和CPU 一致，但是容量很小，仅仅保存了当前指令的操作数和下一次要执行的指令。当发生进程切换时，寄存器就会被新进程的数据所覆盖。所以这些寄存器中的数据都应该被保存起来，以便下此进程再次执行时就好像从没有中断过一样能继续执行。包括 CPU 中寄存器的值，程序打开的文件描述符等等在内的维持程序能正常执行的所有数据就是进程的上下文。 虚拟内存 操作系统的任务是变化的，但是运行中的内存是不变。那么应该如何分配每个进程占用的空间，占用的内存位置，以避免它们相互影响呢？ 操作系统将内存抽象为虚拟内存，所有进程启动时，所见的内存空间均为虚拟内存，进程可以假设为当前系统上只有内核和自己。虚拟内存对于所用程序都是统一的，因此程序无需考虑实际内存的分配问题，直接向虚拟内存空间申请和释放内存即可。虚拟内存和物理内存被划分为一个个页框，当进程需要内存时，其向虚拟内存空间申请内存，然后由操作系统将空闲的物理页框与进程申请到的虚拟页框建立关联关系。进程访问数据时必需将虚拟地址转换实际的内存地址才能访问到数据。计算机上有一个专门的单元 MMU 用于完成虚拟地址的转换。上图 task_structure 中的 mm_struct 保存就是虚拟页框与物理页框的映射关系。 2. 运行中进程 进程的内存空间结构如上图左边所示，包括代码段，数据段，堆栈等。创建进程时，父进程调用 fork() 系统调用创建子进程，此时子进程共享父进程的所有环境，然后子进程调用 exec() 系统调用将自己的代码装载入代码段；最后父子进程各自运行。Linux 使用写时复制，当子进程需要修改父进程的内存空间时，它首先将当前内存中的内容复制到新的空闲空间中，然后在修改。因此父子进程不会相互影响。 进程都是有父进程创建和销毁。Centos 中的第一个进程叫 init ，它是所有进程父进程。Centos567 的 init 程序并不相同。我们会在后面的系统开机启动中详细讲解。 运行中的进程存在优先级的概念，优先级用于控制进程的执行次序Linux 中进程优先级别为0-139： 1-99：实时优先级； 100-139：静态优先级； 数字越小，优先级越高，Nice值(-20,19) 用于调整静态优先级。需要注意的是，优先级越靠近 99，优先级越高。可以通过调整 Nice 值调整程序优先级。普通用户只能调高优先级(即降低程序优先级)，不能调高优先级。root 可以调高或调低。 进程之间可能需要通信，进程间通信叫作 IPC，IPC 有如下方式。 IPC: Inter Process Communication 同一主机上： signal: 信号 shm: shared memory: 共享内存 semerphor: 信号量 不同主机上： rpc: remote procecure call 远程系统调用 socket: 套接子 进程最终必需由父进程收回，如果父进程意外终止而没有收回进程，进程就会成为孤儿进程，在进程执行完成后将称为僵尸进程。 3. 用户空间与内核空间 为了避免用户空间的程序破坏内核，Linux 将操作系统的指令分成了4个不同级别，这些级别的指令被分别放在操作系统抽象的环上。最内存的内核和系统调用属于特权指令，被称为内核空间，外层的指令属于普通指令，被称为用户空间。 当进程需要调用特权指令时，进程需要发出软中断，陷入内核，由内核执行所需的特权执行，并将执行结果交给用户进程。进程获取到结果后继续运行。进程等待系统调用结果而不能执行时，我们称进程处于不可中断睡眠状态。运行中的进程有如下几种状态 运行态：running，正在被CPU 执行 就绪态：ready，程序准备完成，等待内核调度执行 睡眠态： 可中断：interruptable，进程的执行时间耗尽而被换出CPU 不可中断：uninterruptable 停止态：暂停于内存中，但不会被调度，除非手动启动之；stopped 僵死态：zombie 最后Linux 中进程可以分为两类 守护进程: 在系统引导过程中启动的进程，跟终端无关的进程； 前台进程：跟终端相关，通过终端启动的进程，也可把在前台启动的进程送往后台，以守护模式运行；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.7 网络客户端工具]]></title>
    <url>%2F2018%2F02%2F13%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[网络客户端工具 在本章的最后一节，我们来说一说一些常用的网络客户端工具，包括 ping 命令 ftp 客户端工具 wget 下载工具 1. ping1.1 pingping [OPTION] destination 作用: send ICMP ECHO_REQUEST to network hosts 参数: destination 目标主机 选项: -c #：发送的ping包个数； -w #：ping命令超时时长； -W #：一次ping操作中，等待对方响应的超时时长； -s #：指明ping包报文大小； 1.2 hpinghping options 作用: send (almost) arbitrary TCP/IP packets to network hosts 选项: --fast --faster --flood -i uX 1.3 traceroutetraceroute ip/FQDN 作用: 跟踪从源主机到目标主机之间经过的网关； 2. ftp 客户端2.1 lftplftp [-p port] [-u user[,pass]] server_ip 作用: ftp 客户端命令的升级版 子命令: get, mget put, mput rm, mrm help ls 2.2 lftpgetlftpget [-c] [-d] [-v] URL [URL...] 作用: 借助 lftp 下载文件 选项: -c：继续此前的下载； 1234&gt; ftp server_ip# 无密码登录&gt; Name: anonymous&gt; Password: 直接回车 3. wget命令：wget [option]... [URL]... 作用: The non-interactive network downloader. 选项: -b：在后台执行下载操作； -q：静默模式，不显示下载进度； -O file：下载的文件的保存位置； -c：续传； --limit-rate=amount：以指定的速率传输文件；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.6 网络属性配置之 nmcli 系列命令]]></title>
    <url>%2F2018%2F02%2F12%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2FCentos7-nm%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 nmcli 系列命令 本节我们来介绍 Linux 网络属性配置的第三组系列命令 nm。nm(network management) 是 Centos7 新增的命令，使用方式类似 ip 命令，将网络属性分成了多个 OBJECT，每个 OBJECT 都有众多子命令用于对其进行管理配置。nm 主要包含两个工具: nmcli: nm 的命令行工具 nmtui: nm 的图形客户端 1. nmclinmcli [ OPTIONS ] OBJECT { COMMAND | help } OBJECT: device: 显示和管理网络接口，类似 ip link connection: 启动，停止，管理网络连接，类似 ip addr 1.1 nmcli devicenmcli device COMMAND COMMAND:{status | show | connect | disconnect | delete | wifi | wimax } 1.2 nmcli connectionnmcli connection COMMAND COMMAND: { show | up | down | add | edit | modify | delete | reload | load } nmcli connection modifynmcli connection modify IFACE [+|-]&lt;setting&gt;.&lt;property&gt; &lt;value&gt; 作用: 如何修改IP地址等属性： 效力: 直接修改 ifcfg-IFACE 文件，修改完成不会生效，需要重启 参数: IFACE: 接口标识 setting.property: 网络属性值 ipv4.address ipv4.gateway ipv4.dns1 ipv4.method manual: 手动配置 dhcp 1234567localectl list-localeslocalectl set-locale LANG=en_US.utf8nmcli g status # 显示网络接口状态nmcli device show ens33nmcli connection modify ens33 ipv4.address 192.168.1.101# 重启以生效修改nmcli con down ens33; nmcli connection up ens33 2. nmtuinmcli 命令的图形化工具]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.5 网络配置文件]]></title>
    <url>%2F2018%2F02%2F11%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[网络配置文件 本节我们来学习如何通过修改配置文件来更改网络属。RHEL系的网络配置文件主要包括两个部分: IP/NETMASK/GW/DNS等属性的配置文件，位于 /etc/sysconfig/network-scripts/ifcfg-IFACE 路由的相关配置文件，位于 /etc/sysconfig/network-scripts/route-IFACE 更改配置后需要重启网络服务以重载配置文件才能让配置的网络属性生效，因此我们会简单的说一说网络服务的管理。Linxu 的服务管理我们会在后面的章节详细介绍。本章将包括以下内容: 配置文件的修改 ifcfg-IFACE 配置参数 route-IFACE 配置参数 Centos 网络服务的管理 给网络接口配置多个地址 网卡名称修改 1. 网络配置的修改所有的配置文件都是文本文件，可通过vim 直接修改，Centos 也提供了专用的修改命令 CentOS 6：system-config-network-tui，setup CentOS 7: nmtui 2. ifcfg-IFACEifcfg-IFACE 常用配置参数 DEVICE：此配置文件对应的设备的名称； HWADDR：设备的MAC地址； UUID：此设备的惟一标识； ONBOOT：在系统引导过程中，是否激活此接口； BOOTPROTO：激活此接口时使用什么协议来配置接口属性，常用的有dhcp、bootp、static、none； TYPE：接口类型，常见的有Ethernet, Bridge； IPADDR： IP地址； NETMASK：子网掩码；CentOS 7支持使用PREFIX以长度方式指明子网掩码； GATEWAY：默认网关； DNS1：第一DNS服务器指向； DNS2：备用DNS服务器指向； DOMAIN：DNS搜索域； IPV6INIT：是否初始化IPv6； IPV4_FAILURE_FATAL: 如果 IPV4 不可用是否关闭此网络接口 USERCTL：是否允许普通用户控制此设备； NM_CONTROLLED：是否使用NetworkManager服务来控制接口；Centos6 上建议为 no PEERDNS：如果BOOTPROTO的值为“dhcp”，是否允许dhcp server分配的dns服务器指向覆盖本地手动指定的DNS服务器指向；默认为允许 1234567891011121314151617181920212223# ifcfg-IFACE 配置示例ESSID="CLOUD3_5G"NAME=CLOUD3_5GHWADDR=00:28:F8:35:06:ECUUID=816cdc8b-e62f-4bdb-9ca8-be2545a5a7e6ONBOOT=yesBOOTPROTO=dhcpMODE=ManagedKEY_MGMT=WPA-PSKTYPE=WirelessDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_ADDR_GEN_MODE=stable-privacySECURITYMODE=openMAC_ADDRESS_RANDOMIZATION=defaultPEERDNS=yesPEERROUTES=yes 3. route-IFACEroute-FACE 支持两种配置方式，但不可混用 方式一: 每行一个路由条目12TARGET via GW192.168.1.101 via 172.168.2.1 方式一: 每三行一个路由条目1234567ADDRESS#=TARGETNETMASK#=MASKGATEWAY#=NEXTHOPADDRESS0=192.168.4.0NETMASK0=255.255.255.0GATEWAY0=172.16.1.1 4. 网络服务管理Centos6 上网络管理的服务有两个 network，NetworkManager，但 NetworkManger 仍处于实验阶段，功能还不完善，比如创建集群或桥接接口 NetworkManger 都不支持。建议在 Centos6 中关闭 NetworkManager 只使用 network；即 将 ifcfg-IFACE 配置文件中的 NM_CONTROL 设置为 No 把 NetworkManager 服务禁止掉 Centos7 中 NetworkManager 已经很完善，并且已经是网络管理的默认服务 12345678910111213141516systemctl status network● network.service - LSB: Bring up/down networking Loaded: loaded (/etc/rc.d/init.d/network; bad; vendor preset: disabled) Active: active (exited) since 三 2018-08-01 10:21:35 CST; 6min ago Docs: man:systemd-sysv-generator(8) Process: 12814 ExecStop=/etc/rc.d/init.d/network stop (code=exited, status=0/SUCCESS) Process: 13126 ExecStart=/etc/rc.d/init.d/network start (code=exited, status=0/SUCCESS)systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-08-01 08:45:21 CST; 1h 43min ago Docs: man:NetworkManager(8) Main PID: 1199 (NetworkManager) CGroup: /system.slice/NetworkManager.service ├─1199 /usr/sbin/NetworkManager --no-daemon 4.1 管理网络服务Centos 6，7服务的启动和管理完全并相同，我们会在后面操作系统的启动流程以及服务管理详细讲解，现在大家只要知道可以使用以下这些命令即可: Centos6: service SERVICE {start|stop|restart|status} /etc/rc.d/init.d/network {start|stop|restart|status} CentOS 7： systemctl {start|stop|restart|status} SERVICE[.service] 网络配置文件修改之后，如果要生效，需要重启网络服务 CentOS 6：service network restart CentOS 7：systemctl restart NetworkManager.service 5. 给网卡配置多个地址给网卡配置多个地址有多种方式: ip addr add ip dev IFACE label label_name ifconfig IFACE_LABEL IPADDR/NETMASK IFACE_LABEL: 地址别名，eth0:0, eth0:1, … eg: ifconfig ens33:1 192.168.1.117/24 up 为别名添加配置文件； cp ifcfg-eth0 ifcfg-eth0:0，然后修改 ifcfg-eth0:0 1234&gt; vim /etc/sysconfig/network-script/ifcfg-eth0:0DEVICE=eth0:0 # DEVICE 修改为地址别名BOOTPROTO=None # 网上别名不支持动态获取地址；只能使用 static, none删除 HWADDR，UUID 6. 网络接口名称修改udev 程序是 Linux 识别各种设备的辅助程序，因此通过修改其配置文件可以修改网络接口的名称。123456# Centos6 修改过程vim /etc/udev/rules.d/70-persistent-ipoib.rules # 更改网络接口名称modprobe -r e1000 # 卸载网卡驱动modprobe e1000 # 装载网卡驱动，会重新读取 70-persistent-ipoib.rules 配置文件# Centos7 由于网卡命名规则变化，所以 Centos6 的规则不适用]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.4 网络属性配置之 ip 系列命令]]></title>
    <url>%2F2018%2F02%2F10%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2Fip%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 ip 系列命令 本节我们来介绍 Linux 网络属性配置的第二组系列命令 ip 命令。ip 命令是 Linux 的”新贵”，相比于 ifcfg 它们更加的高效。ip 系列包括如下几个命令 ip 命令: 有众多子命令，拥有配置网络地址，网络接口属性，路由等多种功 能 ss 命令: netstat 命令的优化版，用于查看网络连接状态 1. ipip [ OPTIONS ] OBJECT { COMMAND | help } 作用: show / manipulate routing, devices, policy routing and tunnels. OBJECT: 作用对象 link: 网络接口属性 addr: 网络地址 route: 路由 netns: 网络命名空间 COMMAND: 每个作用对象上的可用子命令 help: 是一个通用子命令，用于显示特定作用对象的可用命令 注意： OBJECT可简写，各OBJECT的子命令也可简写； 通过上面的展示可以看出，ip 将网络地址，路由，网络接口等划分成了一个个独立的对象，每个独立的对象拥有特定的子命令来对其进行管理和配置。 1.1 ip linkip link： network device configuration，是用来配置网络设备的子命令，可用于管理网络接口的各种属性。其常用子命令如下 ip link setip link set [dev] NAME options 作用: 更改网络接口属性 [dev] NAME:指明要管理的设备，dev关键字可省略 参数： up|down：，up 表示启用，down 表示关闭； multicast on|off：启用或禁用多播功能； name NAME：重命名接口 mtu NUMBER：设置MTU的大小，以太网默认为1500； netns PID：ns为namespace，用于将接口移动到指定的网络名称空间 123456789ip link set eth1 downip link set multicast onip link show# 改名ip link set eno1 downip link set name eno8888ip link set eno8888 up ip link show|listip link show|list options 作用: 显示网络接口属性 参数: [dev] NAME：指明要显示的接口，dev关键字可省略； up: 仅仅显示启用状态的接口设备 ip link helpip link help 作用: 显示 ip link 简要使用帮助 1.2 ip netnsip netns：manage network namespaces. 用于管理网络命名空间。网络命名空间在虚拟化中具有重要作用，我们会在虚拟化重新介绍 ip netns 的使用，此处仅作了解即可 ip netns COMMAND: ip netns list：列出所有的netns ip netns add NAME：创建指定的netns ip netns del NAME：删除指定的netns ip netns exec NAME IP_COMMAND 作用: 在指定的netns中运行命令 NAME: 表示指定的命名空间 IP_COMMAND: 任何可使用的 ip 命令 1234567891011ip netns helpip netns add mynetip link set eno1 netns mynet # 将 eno1 添加到 mynet 名称空间中ip link showip netns exec mynet ip link show # 显示 mynet 中的网络设备ip netns del mynetip link show 1.3 ip addressip address:protocol address management. 用于管理网络地址，作用类似于 ifconfig 命令 ip addr addip addr add IP dev IFACE IFADDR 作用: 为网络接口添加 IP 地址 参数: IP: ip/netmask dev IFACE: 指定网络接口 IFADDR: 为地址的添加的额外属性 label NAME：为额外添加的地址指明接口别名； broadcast ADDRESS：广播地址；会根据IP和NETMASK自动计算得到，一般无需指明 scope SCOPE_VALUE：指明网络接口的作用域了解即可 global：全局可用； link：接口可用； host：仅本机可用； 12345ifconfig eth1 0# 一个网卡可添加多个地址ip addr add 192.168.1.101/24 dev eth1ip addr add 192.168.100.100/24 dev eth1 label eth1:0 # 指定接口别名 ip addr deleteip addr add IP dev IFACE 作用: 删除网络接口的 IP 地址，delete 可简写成 del 参数: IP: 指明要删除的 ip/netmask dev IFACE: 指定网络接口 1ip addr del 192.168.1.101/24 dev eth1 ip addr showip addr show|list options 作用: 显示网络接口地址详细信息 选项: [dev] IFACE: 显示特定接口的地址，默认显示所有接口 label PATTERN: 显示指定模式别名的接口 ip addr fluship addr flush dev IFACE options 作用: 清空网络设备的IP地址，不支持简写 选项: label PATTERN: 删除指定模式别名的接口 12ip addr flush dev eth1ip addr show eth1 1.4 ip routeip route routing table management，路由表管理 ip route addip route {add|change|replace} TARGET via GW options 作用: add,change,replace 使用方式类似 add: 添加路由条目，可根据路由信息自动判断是主机路由还是网络路由 change: 更改路由 replace: 更改或添加路由 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK via GW: 网关或路由的下一跳 选项: dev IFACE: 指明从哪个网络接口发送报文 src SOURCE_IP: dev 指明的网卡存在多个地址时，指定出口IP 12345ip addr add 10.0.0.100/8 dev eth1ip addr add 10.0.20.100/8 dev eth1ip route add 192.168.0.0/24 via 10.0.0.1 dev eth1 src 10.0.20.100ip route add default via 192.168.1.1` ip route deleteip route delete TARGET [via GW] 作用: 删除路由条目 参数: TARGET: 主机路由即 IP，网络路由即 NETWORK/MASK [via GW]: 如果 TARGET 能唯一指明路由条目则无需指明网管 eg: ip route del 192.168.1.0/24 ip route showip route show options 作用: 查看路由条目 选项: TARGET: 显示特定路由条目 [dev] IFACE: 查看特定网卡的路由条目 via PREFIX: 查看特定网关的路由条目 ip route fluship route flush options 作用: 清空路由条目 选项: prefix/mask: 删除特定前缀的路由条目 [dev] IFACE: 查看网卡的路由条目 via PREFIX: 删除特定网关的路由 12ip route flush 10/8 # 删除前缀为 10，掩码为 8 位的条目ip route flush 192/8 # 指定的 192/8 无法删除 192/24 的路由条目 ip route getip route get TARGET [via GW] 作用: 获取一条特定的路由信息 1ip route get 192.168.0.0/24 2. ss命令：ss [options] [ FILTER ] 作用：类似于 netstat，用于查看网络连接状态 类 netstat 选项： -t：TCP协议的相关连接 -u：UDP相关的连接 -w：raw socket相关的连接 -x：unix socket 相关 -l：监听状态的连接 -a：所有状态的连接 -n：数字格式 -p：相关的程序及其PID -e：扩展格式信息 特有选项: -m：内存用量 -o：计时器信息 FILTER: ss 用于筛选的表达式 格式: [ state TCP-STATE ] [ EXPRESSION ] TCP-STATE： LISTEN：监听 ESTABLISEHD：建立的连接 FIN_WAIT_1： FIN_WAIT_2： SYN_SENT： SYN_RECV： CLOSED： EXPRESSION： dport = 目标端口号 sport = 源端口号 eg：&#39;( dport = :22 or sport = :22 )&#39; - 每个部分都必须有空格隔开 12ss -tan &apos;( dport = :22 or sport = :22 )&apos;ss -tan state ESTABLISHED]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.3 网络属性配置之 ifcfg 系列命令]]></title>
    <url>%2F2018%2F02%2F09%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2Fifcfg%E7%B3%BB%E5%88%97%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[网络属性配置之 ifcfg 系列命令 本节我们来介绍 Linux 网络属性配置的第一组系列命令 ifcfg。ifcfg 系列是 Linux 中很古老的命令，几乎存在于所有的Linux 发行版中。ifcfg 系列包括如下几个命令: ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 ifup/ifdown: 启动/关闭接口 1. ifconfigifconfig 的配置会立即送往内核中的TCP/IP协议栈，并生效 查看接口状态 ifconfig：默认显示活跃状态的接口 ifconfig IFACE [up|down]：后跟网络接口名，显示特定接口，up 表示激活接口，down 表示关闭接口 ifconfig -a：显示所有接口，包括inactive状态的接口； 设置接口地址ifconfig IFACE {address [netmask NETMASK]} options ifconfig IFACE IP/MASK ifconfig IFACE IP netmask NETMASK options： up： 激活接口。如果给接口声明了地址，等于隐含声明了这个选项 down: 关闭此接口 [-]promisc: 启用混杂模式，减号表示禁用 add addr/prefixlen：添加 IPV6 地址 del addr/prefixlen：删除 IPV6 地址 12ifconfig eth0 192.168.100.6/24 upifconfig eth0 192.168.100.6 netmask 255.255.255.0 2 route路由表中的路由条目有三种类型，范围越小优先级越高: 主机路由：目标地址为单个IP； 网络路由：目标地址为IP网络； 默认路由：目标为任意网络，0.0.0.0/0.0.0.0 路由查看route -n -n: 以数字形式显示主机名，默认会反解主机名 添加路由route add [-net|-host] target [netmask Nm] [gw GW] [[dev] If] -net: 指定网络路由 -host: 指定主机路由 netmask: 指定掩码, 默认为 255.255.255.255 gw: 指定路由的下一跳 dev: 指定发送数据包的网卡 1234567891011示例：route add -host 192.168.100.6 gw 192.168.0.1 dev eth0route add -net 10.0.0.0/8 gw 192.168.10.1 dev eth1route add -net 10.0.0.0 netmask 255.0.0.0 gw 192.168.10.1 dev eth1route add -net 0.0.0.0/0.0.0.0 gw 192.168.10.1 route add default gw 192.168.10.1 -- 添加默认路由route add -net 0.0.0.0 netmask 0.0.0.0 gw 192.168.10.1 -- 添加默认路由``` #### 删除路由`route del [-net|-host] target [gw Gw] [netmask Nm] [[dev] If]` 示例：route del -host 192.168.100.6 gw 192.168.0.1route del -net 10.0.0.0/8 gw 192.168.10.1route del default``` 3. netstatnetstat can print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 显示路由表netstat -rn -r：显示内核路由表 -n：以数字形式显示主机名，默认会反解主机名 显示网络连接netstat [options] 选项: -t, --tcp：显示TCP协议的相关连接，及其链接状态； -u, --udp：显示UDP相关的连接 -U, --udplite：显示udplite 相关的链接 -S, --sctp：显示 sctp 相关的链接 -w, --raw：显示raw socket相关的连接,指不经过传输层，由应用层直接通过 ip 进行的链接 -l, --listening：显示处于监听状态的连接 -a, --all：显示所有状态 -n, --numeric：以数字格式显示IP和Port； -e, --extend：以扩展格式显示 -p, --program：显示相关的进程及PID； 显示接口的统计数据netstat {--interfaces|-I|-i} [options] 选项: -I, --interfaces&lt;iface&gt;: 指定显示的接口 eg: netstat -Ietho -i: 显示所有活跃接口 -a, --all: 与 -i 同时使用显示所有接口，包括未激活的 -e, --extend: 以扩展格式进行显示 4. ifup/ifdownifup|ifdown iface 作用: 启用或关闭接口 注意: 这两个命令是通过配置文件/etc/sysconfig/network-scripts/ifcfg-IFACE来识别接口并完成配置的；如果设备没有对应的配置文件，则无法通过这两个命令启动或关闭]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.2 网络接口命名与配置指南]]></title>
    <url>%2F2018%2F02%2F08%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E7%BD%91%E7%BB%9C%E6%8E%A5%E5%8F%A3%E5%91%BD%E5%90%8D%E4%B8%8E%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[网络接口命名与配置指南 上一节我们讲解了网络的基础知识，很推荐大家读一读计算机网络-自顶向下方法。本节我们会介绍 Linux 中网络接口(网卡)的命名方式，以及概括性的说一说 Linux 中进行网络配置的方式；在接下来的章节中，我们会详细讲解每个命令的使用。本节内容如下: 网络配置方式 Linxu 网络接口的命名方式 1. 网络配置方式将一台 Linux 主机接入到网络中，需要为其配置如下几个参数 IP/NETMASK：本地通信 路由（网关）：跨网络通信 DNS服务器地址：基于主机名的通信 这些参数的配置可以通过命令直接修改内核中的网络参数，也可以修改配置文件然后让内核重载配置文件或下次重新启动生效；也可以依赖本地局域网中配置的 DHCP 服务，为局域网中的其他主机动态配置。DHCP(Dynamic Host Configure Procotol) 服务的配置我们会在后面的章节中介绍。Linux 中配置网络属性的命令和相关配置文件如下 1.1 网络属性管理网络属性配置的配置文件不同的发行版有所不同，RedHat及相关发行版的配置文件位于 /etc/sysconfig/network-scripts/ifcfg-NETCARD_NAME，其中 NETCARD_NAME 为特定网络接口的名称。网络属性管理有众多命令家族，概述如下: ifcfg家族： ifconfig：配置IP，NETMASK route：路由查看与管理 netstat：网络状态及统计数据查看 iproute2家族： ip OBJECT：ip 命令下有众多子命令 addr：管理和查看地址和掩码； link：网络接口属性管理 route：路由查看与管理 ss：网络状态及统计数据查看 CentOS 7特有的 nm(Network Manager)家族 nmcli：nm 命令行工具 nmtui：text window 工具 Centos6 特有的: system-config-network-tui setup, setup 拥有专属的配置文件 system-config-netword-tui 1.2 DNS服务DNS 服务配置DNS 服务只能通过修改其配置文件 /etc/resolv.conf 进行配置。Linux 主机最多可指定三个 DNS 服务器 1234# vim /etc/resolv.confnameserver 10.143.22.116 # 主DNS服务器地址nameserver 10.143.22.118 # 备用DNS服务器地址nameserver 10.143.22.116 # 第三备份DNS服务器地址 DNS 服务测试测试 DNS 服务是否正常，可以使用 host, nslookup, dig 三个命令 正解: FQDN(域名)到 IP dig -t A FQDN host -t A FQND 反解: IP 到 FQDN dig -x IP host -t PTR IP DNS 是互联网的基础服务，我们会花一整章节，来详细介绍 DNS 服务。 1.3 本地主机名配置主机名有三种配置方式 hostname, hostnamectl 和修改配置文件 hostname 查看：hostname 配置：hostname HOSTNAME 效力：只对当前系统有效，重启后无效； hostnamectlCentos7 新增的特有命令 hostnamectl status：显示当前主机名信息； hostnamectl set-hostname：设定主机名，永久有效； 效力: 通过 hostnamectl 修改的主机名立即生效，且永久有效 修改配置文件 主机名的配置文件位于 /etc/sysconfig/network 效力：此方法的设置不会立即生效； 但以后会一直有效； 12# vim /etc/sysconfig/networkHOSTNAME=&quot;hostname&quot; 3. 网络接口命名方式网络接口(网卡)的命名在Linux 中有特定设置过程。默认情况下，Centos6 采用传统的命名机制，Centos7 采用可预测命名方案，支持多种不同的命名机制，这种命名机制需要 biosdevname 程序的参与 3.1 命名机制 Centos6 传统命名： 以太网：ethX, [0,oo)，例如eth0, eth1, … PPP网络：pppX, [0,...], 例如，ppp0, ppp1, … CentOS7 可预测命名方案：支持多种不同的命名机制 如果Firmware(固件)或BIOS为主板上集成的设备提供的索引信息可用，则根据此索引进行命名，如eno1, eno2, … 如果Firmware或BIOS为PCI-E扩展槽所提供的索引信息可用，且可预测，则根据此索引进行命名，如ens1, ens2, … 如果硬件接口的物理位置信息可用(硬件接口的拓扑结构)，则根据此信息命名，如enp2s0, … 如果用户显式定义根据MAC地址命名，例如enx122161ab2e10, … 上述均不可用，则仍使用传统方式命名； 3.2 名称组成格式Centos7 中 eno1，ens1，enp2s0 命名组成如下所示: 前缀 en：ethernet 以太网接口 wl：wlan 无线局域网设备 ww：wwan 无线广域网设备 后缀 o&lt;index&gt;: 集成设备的设备索引号；(onbus) s&lt;slot&gt;: 扩展槽的索引号； x: 基于MAC地址的命名； p&lt;bus&gt;s&lt;slot&gt;: 基于总线及槽的拓扑结构进行命名； bus: PCI 总线编号 slot: 总线上的扩展槽编号 3.3 网卡设备的命名过程Centos7 网卡命名经过了以下过程: udev 辅助工具程序 /lib/udev/rename_device 会根据 /usr/lib/udev/rules.d/60-net.rules 中的指示去查询 /etc/sysconfig/network-script/ifcfg-IFACE 配置文件，根据HWADDR 读取设备名称 biosdevname 根据 /user/lib/udev/rules.d/71-boosdevname.rules 通过检查网络接口设备，根据 /usr/lib/udev/rules.d/75-net-description 中 ID_NET_NAME_ONBOARD 和 ID_NET_NAME_SLOT,ID_NET_NAME_PATH 命名 Centos7 也可以设置网络接口回归传统方式的命名方式: vim /etc/default/grub 配置文件，添加 GRUB_CMDLINE_LINUX=&quot;net.ifnames=0 rhgb quiet&quot; 为 grub2 生成配置文件 grub2-mkconfig -o /etc/grub2.cfg 重启系统]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[11.1 计算机网络基础知识]]></title>
    <url>%2F2018%2F02%2F07%2Flinux_mt%2F12-%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8F%8ALinux%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[程序包编译安装 本章我们开始学习 Linux 网络配置相关知识。计算机网络包含了众多协议和基础设施，大学里一般都有专门的课程来讲解。本章主要还是对网络配置相关命令讲解，对于计算机网络的基础知识，在一章里肯定没法说清道明。不过有几本书推荐给大家，可以作为深入学习的参考资料。计算机网络-自顶向下方法 五星推荐，对计算机网络的整体架构，基础设施，大多数协议都作了详细概述，通俗易懂。TCP/IP详解 这一系列分成了三卷，对 TCP/IP 协议栈原理作了深入讲解。自己还没读过，大神都是力荐。本章将包含以下内容: 网络基础知识 Linux 网络配置的相关命令 ifcfg 系列命令 ip 系列命令 Centos7 特有的 nmcli 命令 网络配置的配置文件 网络客户端工具 本节先来简单说一说网络相关的基础知识。由于网络知识庞大繁杂，此篇文章将会持续更新，希望能以通俗易懂的方式让大家对网络有个基础的认识。 计算机网络协议是一个网络协议栈，目的是将计算机主机之间通信这一复杂问题划分为多个层次，每个层次通过协议进行规范，向上层输出标准 api。一来通过分层降低解决问题的难度，二来特定层次可以有不同的实现，可以变动改进，只要遵守即定的协议，就不会影响到起他层次的使用，提供了最大程度的灵活性。我们学习网络知识，就是要学习计算机网络的层次，每个层次面对的问题，怎么解决问题，涉及到的协议和基础设施；最后对整个网络有个整体性的认识。本节将按照这样的顺序，对计算机网络做一个简述，包括: 计算机网络的分层 计算机网络协议栈 1. 计算机网络的分层我们的数据都是以二进制的格式存放在磁盘上的，至于它是文本，还是视频取决于二进制数据的组织形式。因此我们在通过网络传输数据时，数据仍是以二进制的形式进行传输，只是不同的传输介质表示二进制的方式不同。比如以太网使用高电压表示 1，低电压表示 0。最终数据传输完成后仍然需要按照特定的组织方式还原数据。 因此从宏观上来看，计算机网络被分成两个层次，通信子网和资源子网。通信子网关注的是如何传输数据，资源子网则只关心数据是如何组织起来的。资源子网不必关心通信子网是如何实现的，只调用其提供的标准接口。因此整个过程有点类似于现实世界中寄快递，快递公司帮我们运输物品，我们不必关心快递公司是如何运输，但是我们必需确保我们物品没有损坏，也可以按需选择不同的快递公司。通过这样的分层我们将一个复杂问题分隔成一个个独立的子问题。 资源子网通常由各个应用程序提供，比如我们常用的 httpd，位于操作系统的用户空间中，通信子网由操作系统内核实现，通过套接子 socket，向用户空间的应用程序提供标准接口。 12345 --------------------用户空间 &lt;--- | | ---&gt; 资源子网 |-------------------|内核空间 &lt;--- | | ---&gt; 通信子网 |-------------------| 2. 计算机网络协议栈 计算机网络协议栈目前有两个标准: TCP/IP 协议栈，这是当前事实上的使用标准，在实际生产环境中逐步演化而来，缺点是每个网络层次之间的接口定义并不是非常明确 OSI 协议栈，这是 ISO 组织对 TCP/IP 作出改进之后的版本，各个网络层次之间界限明确，但是各个层次之间功能有所重复，并没有TCP/IP效率高。正因为其定义规范且明确，这是一个我们更容易学习的版本 上图就是两个协议栈的对比示意图，每个层次的作用概述如下: 通信子网: 物理层: 定义传输介质及介质之间的传输协议，比如电压等(网卡标准定义) 数据链路层: 定义局域网内主机之间的通信，比如传输速度等 网络层: 定义网络与网络之间的通信 传输层: 定义进程与进程之间的通信 资源子网: 应用层: 会话层 表示层 应用层 2.1 物理层设备：网桥或交换机寻址：MAC 地址 Media Access Control 48bits，前 24bits 由 ICANN 分配 2.2 网络层设备：路由器寻址：IP 地址 Internet protocol, 由网络号+主机号组成 IPv4：32bits 8bits.8bits.8bits.8bit 2.3 传输层寻址：IP 地址 + 端口端口号:16bits 1-1023：固定分配，而且只有管理员有权限启用； 1024-4W：半固定， 4W+：临时 2.4 数据的传输过程 MAC：本地通信；范围：本地局域网； IP：界定通信主机，源和目标；范围：互联网； Port：界定进程；范围：主机 ； 3. IP地址分类IP 地址用于标识网络及网络中的主机，按照用于表示网络的字节数将 IP 地址分为 ABCDE 五大类: A类： 第一段为网络号，后三段为主机号 网络号：0 000 0000 - 0 111 1111：1-127 网络数量：126，127 每个网络中的主机数量：2^24-2 默认子网掩码：255.0.0.0，/8 私网地址：10.0.0.0/8 B类： 前两段为网络号，后两段为主机号 网络号：10 00 0000 - 10 11 1111：128-191 网络数：2^14 每个网络中的主机数量：2^16-2 默认子网掩码：255.255.0.0，/16 私网地址：172.16.0.0/16-172.31.0.0/16 C类： 前三段为网络号，最后一段为主机号 网络号：110 0 0000 - 110 1 1111：192-223 网络数：2^21 每个网络中的主机数量：2^8-2 默认子网掩码：255.255.255.0, /24 私网地址: 192.168.0.0/24-192.168.255.0/24 D类：组播 网络号: 1110 0000 - 1110 1111：224-239 E类：科研 网络号: 1111 0000 - 1111 1111: 240-255]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.4 程序包编译安装]]></title>
    <url>%2F2018%2F02%2F06%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2F%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[程序包编译安装 前面我们讲解了使用 rpm，yum 安装程序包的方法，相比于编译安装，它们更加便捷，但是由于 rpm 包是编译好的二进制程序，我们就无法根据自己的需求去定制程序特性和功能。所有如果想定制程序，则必需编译安装，在编译时启用需要的特性。本节我们首先会说一说编译安装的过程，然后再来介绍如何在 Linux 中实现编译安装 C/++ 程序。本节内容概括如下: 程序的编译安装过程 如何获取源代码 编译安装C源代码 1. 程序的编译安装过程 如上图所示，C 程序的编译要经过 源代码 --&gt; 预处理 --&gt; 编译(gcc) --&gt; 汇编 --&gt; 链接 四步 预处理: 处理注释，宏替换，头文件 编译: 将预处理之后的源代码编译成汇编代码 汇编: 将汇编代码编译成二进制机器代码 链接: 如果程序用到了其他 C 库的代码，则需要将这部分代码动态链接至二进制机器代码中 上述就是一个简单 C 程序编译过程的概述，如果想了解更多细节，可查阅其他资料。 我们知道现在的大型软件工程都不太可能由一个人完成，同时为了程序的可维护性和扩展性，通常都会将代码放置在多个文件中，文件中的代码之间，很可能存在跨文件依赖关系。因此在编译 C 过程中，必需按照特定的顺序编译才能编译成功。为了辅助程序的编译，因此出现了很多项目管理工具。make,cmake 则时 C 和 C++ 中最常见的项目管理工具。 make 工具的配置文件 makefile 记录了程序编译的详细过程，make 工具根据 makefile 的配置可以自动完成程序的编译安装。通常在程序包中有两个辅助生成 makefile 的文件 – configure 和 Makefile.ini。Makefile.ini 是 makefile 的模板，configure 是一个脚本文件，有众多选项，能根据用户提供的参数，依据 Makefile.ini 模板动态生成 makefile 文件。因此用户可以借助于 configure 提供的选项定制 makefile 文件，从而定制程序包的编译安装。autoconf 工具可以辅助生成configure脚本，而 automake 则用于辅助生成 Makefile.in 顺便说一下，rpm 包中有一种类似 testapp-VERSION-release.src.rpm 的以 src.rpm 结尾的 rpm 源码包，其内部的代码是未编译的，需要使用rpmbuild命令制作成二进制格式的rpm包，而后才能安装，在 rpmbuild 过程中，用户就可以自定义程序的特性和功能。 1.2 C代码编译安装三步骤根据上述的编译过程阐述， C 代码编译安装大体需要如下三个步骤: ： 通过选项传递参数，指定启用特性、安装路径等；执行时会参考用户的指定以及Makefile.in文件生成makefile； 检查依赖到的外部环境； make：根据makefile文件，构建应用程序； make install: 脚本，将构建的应用程序放置到配置的目录中 附注: 安装前建议查看INSTALL，README 1.3 configure 可用选项./configure [options] 的众多选项可以分为如下几类 –help: 获取其支持使用的选项 安装路径设定： --prefix=/PATH/TO/SOMEWHERE: 指定默认安装位置；默认为/usr/local/ `–sysconfdir=``/PATH/TO/SOMEWHERE：配置文件安装位置； System types: 指定目标平台系统结构 Optional Features: 可选特性 --disable-FEATURE: 关闭特性 --enable-FEATURE[=ARG]: 启用特性 Optional Packages: 可选包 --with-PACKAGE[=ARG] --without-PACKAGE 2. 开源程序源代码的获取常见的源代码有如下几个获取途径 官方自建站点： apache.org (ASF) mariadb.org 代码托管： SourceForge Github.com code.google.com 3. 编译安装C源代码完整的编译安装过程还包括安装前的环境准备以及安装后的配置操作，C源代码完整的安装过程如下 提供开发工具及开发环境，通常包含在开发工具的包组中 开发工具包括：make, gcc等 开发环境包括：开发库，头文件, glibc(C 标准库) 开发工具安装: CentOS6: yum groupinstall &quot;Development Tools&quot; &quot;Server Platform Development&quot; Centos7: yum groupinstall &quot;Development Tools&quot; 执行 configure脚本，指定安装位置、指定启用的特性 执行 make make install 安装后的配置： 导出二进制程序目录至PATH环境变量中； 编辑文件/etc/profile.d/NAME.sh，export PATH=/PATH/TO/BIN:$PATH 导出库文件路径： 编辑/etc/ld.so.conf.d/NAME.conf ，添加新的库文件所在目录至此文件中； 让系统重新生成库文件缓存：ldconfig [-v] 导出头文件 基于链接的方式实现：ln -sv /path/include /usr/include/dir 导出帮助手册 编辑/etc/man.config文件，添加一个MANPATH]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.3 yum命令使用]]></title>
    <url>%2F2018%2F02%2F05%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2Fyum%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[yum命令使用 yum 是 rpm 的前端工具，在 rpm 基础上能自动解决程序包的依赖问题，管理程序更加的方便。本节我们就来介绍 yum 的使用，包括以下内容: yum 的架构示意图 yum 仓库指向定义 yum 命令的使用 yum 仓库管理 1. yum 概述 上图是 yum 架构的示意图，yum 是 C/S 架构的服务。yum 的 Serve 端就是一个文件服务器，称为 yum 仓库或 yum 源。yum 仓库包含了众多 rpm 包以及包相关的元数据文件。元数据放置在 repodata 目录，其中包含了包之间的依赖关系。 客户端在请求安装某 rpm 包时，首先会下载元数据到本地并缓存，然后分析包之间的依赖关系，分析完成后向 yum 仓库请求下载该 rpm 包及其缺失的依赖包并安装。 通常 rpm 包安装之后就会被删除，但元数据可以重复使用，因此 yum 客户端会在本地缓存yum 仓库的元数据。但缓存有可能失效，因此为及时发现 yum 仓库的变化，yum 仓库会生成元数据的特征码(单向加密算法提取的指纹信息)。yum 客户端在每次请求时首先下载特征码与本地缓存的特征码进行比对，如果不相同说明 yum 仓库发生变动，则重新下载元数据。 yum 的服务器端和客户端具有如下特征 yum Server yum 服务器端就是一个文件服务器，支持 ftp://，http://，nfs://，file:// 四种协议， file:// 表示本地文件系统 yum 仓库存储了众多rpm包，以及包的相关的元数据文件，元数据放置于 repodata 中 yum 客户端 yum 客户端即我们通常使用的 yum 命令 yum 的配置文件 /etc/yum.conf /etc/yum.repo.d/*.conf 用于配置 yum 源的指向 yum 仓库中包含 repodata 目录的路径，就是 yum 源应该指向的路径 接下来，我们就来逐一讲解 yum 的配置文件，yum 命令的使用以及如何创建 yum 仓库 1.1 yum 的配置文件yum 的核心配置文件包括两个部分: /etc/yum.conf：为所有仓库提供公共配置 /etc/yum.repos.d/*.repo：为仓库的指向提供配置 可以使用 whatis/man yum.conf 获取配置文件的帮助信息，yum 仓库配置的常用选项如下所示 12345678910[repositoryID] # yum 源的唯一标识 IDname=Some name for this repository # yum 源的名称baseurl=url://path/to/repository/ # yum 源的地址，可多个 urlenabled=&#123;1|0&#125; # 是否启用，默认为 1 启用gpgcheck=&#123;1|0&#125; # 包来对源合法性进行检验gpgkey=URL # 秘钥文件位置enablegroups=&#123;1|0&#125; # 是否在此仓库上支持组failovermethod=&#123;roundrobin|priority&#125; # baseurl 指向多个时，失败后如何选择下一个连接 # 默认为：roundrobin，意为随机挑选；priority 表示从上至下顺序选取cost=1000 # yum 源的开销，指定仓库优先级，开销越大，优先级越低 1.2 配置文件中的可用变量yum 源的配置文件中有一些可用变量，可以方便根据当前平台特性，选择特定的 yum 源。常用变量包括 变量名称 作用 $releasever 当前OS的发行版的主版本号，即 centos-release 这个 rpm 包的 Version值 通过 rpm -qi centos-release 可查看 $arch 平台，比如 i386，x86, x86_64，通过 arch 命令可查看当前值 $basearch 基础平台，平台分类中的大类，比如 i386，i568，x86都属于 i386 $YUM0-$YUM9 用户可自定义使用的变量 1234567891011# 阿里云 yum 配置示例[base]name=CentOS-$releasever - Base - mirrors.aliyun.comfailovermethod=prioritybaseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/ http://mirrors.aliyuncs.com/centos/$releasever/os/$basearch/#mirrorlist=http://mirrorlist.centos.org/?release=$releasever&amp;arch=$basearch&amp;repo=osgpgcheck=1gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7# 附注: 我的Linux 上 baseurl=http://mirrors.aliyun.com/centos/7/os/x86_64/ 2. yum 命令yum 命令有众多子命令，大体上可以分为两个部分 用于安装，卸载，查看，搜索程序包和程序包组 yum 缓存，事务，历史等管理子命令 yum [options] [command] [package ...] 通用选项: --nogpgcheck：禁止进行gpg check； -y: 自动回答为“yes”； -q：静默模式； --disablerepo=repoidglob：临时禁用此处指定的repo； --enablerepo=repoidglob：临时启用此处指定的repo； --noplugins：禁用所有插件 子命令： 程序包管理子命令 install reinstall update update-to downgrade check-update upgrade upgrade-to remove|erase deplist list info search provides | whatprovides 程序包组管理子命令 groupinstall groupupdate grouplist groupremove groupinfo yum 管理子命令 clean makecache repolist version history help 2.1 程序包管理子命令安装 yum install package1 [...]: 安装程序包 yum reinstall package1 [...]: 重新安装程序包 升级 yum update [package1] [...]: 升级程序包 yum downgrade package1 [...]: 降级安装程序包 yum check-update: 检查可用升级 卸载yum remove | erase package1 [package2] [...] 作用: 卸载程序包 附注: 依赖被卸载的包的包也会被卸载 查询 yum search string1 [...]: 查找程序包，会以指定的关键字搜索程序包名及summary信息； yum info [package1]: 查看特定程序包相关信息 yum deplist package1 [...]: 查看指定包所依赖的特性(capabilities) yum provides | whatprovides feature1 [...] 作用: 查看指定的特性(可以是某文件)是由哪个程序包所提供 yum list [all | glob_exp1] [glob_exp2] [...]yum list {available|installed|updates} [glob_exp1] [...] 作用: 查找程序包，支持通配符，只会匹配程序包名称 选项: all: 列出所有包 available: 列出所有可用的包 installed: 列出所有已经安装的包 updates: 列出所有可更新的包 eg: yum list php* 搜索所有以 php 开头的包 2.2 程序包组管理的相关命令 yum groupinstall group1 [group2] [...]: 安装 yum groupupdate group1 [group2] [...]: 升级 yum groupremove group1 [group2] [...]: 卸载 yum grouplist [hidden] [groupwildcard] [...]: 查看所有可用包组 yum groupinfo group1 [...]: 查看特定包组相关信息 2.3 yum 管理命令缓存yum clean [packages | metadata | expire-cache | rpmdb | plugins | all] 作用: 清理本地缓存 选项: 通过参数，可只清除特定内容 yum makecache 作用: 构建缓存 事务历史yum history [PARAM] 作用: 查看yum事务历史 参数: [info|list|packages-list|packages-info|summary|redo|undo|rollback|new|sync|stats] 显示仓库列表yum repolist [all|enabled|disabled] 作用: 显示仓库列表 参数: all: 显示所有仓库 enabled: 显示启用的仓库 disabled: 显示禁用的仓库 3. yum 仓库管理3.1 使用光盘当作本地yum仓库使用光盘当作本地yum仓库的操作步骤如下: 挂载光盘至某目录，例如/media/cdrom mount -r -t iso9660 /dev/cdrom /media/cdrom 创建配置文件 12345[CentOS7]name=baseurl=file:////media/cdromgpgcheck=enabled= 3.2 创建 yum 仓库createrepo [options] &lt;directory&gt; 作用: 创建 yum 仓库所需的 repodata 目录 选项: -u --baseurl &lt;url&gt;：指定Base URL的地址 -o --outputdir &lt;url&gt;: 指定元数据的输出位置 -x --excludes &lt;packages&gt;: 指定在形成元数据时需要排除的包 -q --quiet: 安静模式执行操作，不输出任何信息。 -g --groupfile &lt;groupfile&gt; 作用: 指定本地软件仓库的组划分，范例如下： 注意：组文件需要和rpm包放置于同一路径下 eg: createrepo -g comps.xml /path/to/rpms -v --verbose: 输出详细信息 -c --cachedir &lt;path&gt; 作用: 指定一个目录，用作存放软件仓库中软件包的校验和信息。 附注: 当createrepo在未发生明显改变的相同仓库文件上持续多次运行时，指定cachedir会明显提高其性能。 -d --database: 该选项指定使用SQLite来存储生成的元数据，默认项。 3.3 yum 的使用奇巧 当我们安装一个不在 yum 仓库的本地 rpm 包时，可使用 yum install local_rpm.rpm 安装，如果次包依赖到 yum 仓库中的其他 rpm 包将自动解决依赖关系。 当我们安装一堆不再 yum 仓库的 rpm 包，且这些 rpm 包本身也存在依赖关系时，可将这些 rpm 包制作成一个本地yum 仓库，这样就可以使用 yum 自动解决所有的依赖关系。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.2 软件包管理rpm命令使用]]></title>
    <url>%2F2018%2F02%2F04%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2Frpm%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[软件包管理rpm命令使用 本节我们主要来讲解 rpm 命令的使用。rpm 可实现程序的安装、卸载和升级。但相比于程序的管理，rpm 的查询命令能帮助我们快速找到文件或二进制程序所属的程序包，及程序包的配置文件等信息，反而更加重要。由于程序之间存在依赖关系，而 rpm 不能自动帮我们解决程序的依赖问题，因此在程序的管理更加常用的命令是 rpm 的前端管理工具 yum。yum 能自动帮我们解决程序的依赖问题，我们会在下个章节介绍 yum 的使用。 1. CentOS rpmrpm 提供了应用程序的安装、升级、卸载、查询、校验和数据库维护，其使用方式如下。我们会分段讲解各个命令的使用 rpm [OPTIONS] [PACKAGE_FILE] 子命令选项: 安装：-i, --install 升级：-U, --update, -F, --freshen 卸载：-e, --erase 查询：-q, --query 校验：-V, --verify 数据库维护：--builddb, --initdb 通用选项: -v：verbose，详细信息 -vv：更详细的输出 1.1 安装rpm {-i|--install} [install-options] PACKAGE_FILE ... [install-options]： -h：hash marks输出进度条；每个#表示2%的进度； --test：测试安装，检查并报告依赖关系及冲突消息等； --nodeps：忽略依赖关系；不建议； --replacepkgs：重新安装 --nosignature：不检查包签名信息，不检查来源合法性； --nodigest：不检查包完整性信息； --noscripts: 不执行程序包脚本片段，包括以下四种类型的脚本 注意：rpm可以自带脚本，包括四类： preinstall：安装过程开始之前运行的脚本，%pre ， --nopre 可禁止执行此类脚本 postinstall：安装过程完成之后运行的脚本，%post , --nopost 可禁止执行此类脚本 preuninstall：卸载过程真正开始执行之前运行的脚本，%preun, --nopreun 可禁止执行此类脚本 postuninstall：卸载过程完成之后运行的脚本，%postun , --nopostun 可禁止执行此类脚本 1.2 升级：rpm {-U|--upgrade} [install-options] PACKAGE_FILE ...rpm {-F|--freshen} [install-options] PACKAGE_FILE ...rpm -Uvh PACKAGE_FILE ...rpm -Fvh PACKAGE_FILE ... -U：升级或安装； -F：升级，不存在旧版程序，不执行任何操作 --oldpackage：降级； --force：强制升级； [install-options]: 所有安装时可用选项，升级亦可用 注意： 不要对内核做升级操作；Linux支持多内核版本并存，因此，直接安装新版本内核； 如果某原程序包的配置文件安装后曾被修改过，升级时，新版本的程序提供的同一个配置文件不会覆盖原有版本的配置文件，而是把新版本的配置文件重命名(FILENAME.rpmnew)后提供； 1.3 卸载：rpm {-e|--erase} [--allmatches] [--nodeps] [--noscripts] [--test] PACKAGE_NAME ... --allmatches：卸载所有匹配指定名称的程序包的各版本； --nodeps：忽略依赖关系 --test：测试卸载，dry run模式 1.4 查询：rpm {-q|--query} [select-options] [query-options] [select-options]: 通过什么查询程序包 PACKAGE_NAME：查询指定的程序包是否已经安装，及其版本； -a, --all：查询所有已经安装过的包； -f FILE：查询指定的文件由哪个程序包安装生成； -g, --group &lt;group&gt;: -p, --package PACKAGE_FILE：用于实现对未安装的程序包执行查询操作； --whatprovides CAPABILITY：查询指定的CAPABILITY由哪个程序包提供； --whatrequires CAPABILITY：查询指定的CAPABILITY被哪个包所依赖； [query-options]: 查询包的哪些信息 --changelog：查询rpm包的changlog； -l, --list：程序安装生成的所有文件列表； -i, --info：程序包相关的信息，版本号、大小、所属的包组，等； -c, --configfiles：查询指定的程序包提供的配置文件； -d, --docfiles：查询指定的程序包提供的文档； --provides：列出指定的程序包提供的所有的CAPABILITY； -R, --requires：查询指定的程序包的依赖关系； --scripts：查看程序包自带的脚本片断； 用法： 查询已安装包: -qi PACKAGE, -qf FILE, -qc PACKAGE, -ql PACKAGE, -qd PACKAGE 查询未安装包: -qpi PACKAGE_FILE, -qpl PACKAGE_FILE, -qpc PACKAGE_FILE, … 1.5 校验：rpm {-V|--verify} [select-options] [verify-options] [select-options]: 同 query [verify-options] 1234567891011121314&gt; vim /usr/share/zsh/5.0.2/functions/tcp_open # 修改了 zsh 包的部分文件&gt; rpm -V zshS.5....T. /usr/share/zsh/5.0.2/functions/tcp_open# 检验结果: - S file Size differs- M Mode differs (includes permissions and file type)- 5 digest (formerly MD5 sum) differs- D Device major/minor number mismatch- L readLink(2) path mismatch- U User ownership differs- G Group ownership differs- T mTime differs- P caPabilities differ 2. 包来源合法性验正和完整性验正网络数据的合法性和完整性验证需要使用到加密技术，在后续的 web 服务章节我们会详细讲解加密算法在数据合法性和完整性上的应用，此处我们简单介绍一下。 加密算法分为对称加密，单向加密和非对称加密三类。 对称加密指的是加密和解密使用的是同一种密钥 单向加密，只要源数据发生微弱变化，加密结果会发生巨大变化，它通常用于提取指纹信息，被用作完整性验证 非对称加密，有公钥和私钥两部分组成，使用私钥加密的数据只能使用公钥解密，反之亦然。如果某人用其私钥加密了某个数据，我们用其私钥能够解密就可以说明数据来自他。 因此在包来源合法性和完整性验证过程中，包的制作者首先使用单向加密获取包的指纹信息，并将其用自己的私钥加密制作成数据签名。由于其公钥所有人都可以获取，包下载者下载包后，使用其公钥解密数字签名，如果能够解密说明包的确来自包制作者。然后在使用同样的单向加密算法，对包进行加密，将加密结果与数字签名内的指纹信息进行比对，如果相同说明包是完整的。 使用 rpm 验证包来源合法性和完整性包括如下两个步骤: 获取并导入信任的包制作者的公钥： rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-7 对于CentOS发行版来说公钥位于 /etc/pki/rpm-gpg 目录内 验正： 安装此组织签名的程序时，会自动执行验正； 手动验正：rpm -K PACKAGE_FILE 3. rpm 数据库重建rpm 数据库记录了所有包的基本信息，所属文件，及其所属文件的存放路径等信息。rpm 查询操作都是基于此数据库进行的。rpm 管理器数据库在/var/lib/rpm/ 下。如果数据库出现损坏，可使用 rpm 命令进行修复，修复命令如下 rpm {--initdb|--rebuilddb} [--dbpath DIRECTORY] [--root DIRECTORY] --initdb：初始化数据库，当前无任何数据库可实始化创建一个新的；当前存在数据库时不执行任何操作； --rebuilddb：重新构建，通过读取当前系统上所有已经安装过的程序包进行重新创建；无论当前是否存在，都会重新创建数据库 获取帮助： CentOS 6：man rpm CentOS 7：man rpmdb]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10.1 Linux程序包管理介绍]]></title>
    <url>%2F2018%2F02%2F03%2Flinux_mt%2F11-%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%AE%A1%E7%90%86%2FLinux%E7%A8%8B%E5%BA%8F%E5%8C%85%E7%AE%A1%E7%90%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Linux程序包管理介绍 本节是 Linux 包管里器的一些背景知识，目的是让大家对为什么会存在包管里器，包管理器本身有个大体上的了解。在这之后我们会详细介绍 Centos 的包管理器 rpm 的使用。本节主要包含以下内容: 为什么会有包管里器 包管理器简介 包管理器的种类 包的命令格式 包依赖关系的解决 包的可能来源 1. 为什么会有包管里器大型程序的构建是一件非常复杂的使用，为了方便的程序的管理，我们不可能将几千甚至几万行的代码放在同一个文件中；如果有 C 程序的使用经验就会知道，在编译 C 的过程，如果程序文件存在依赖关闭，则必须按照依赖顺序进行编译，否则无法编译成功。因此出现了 make,cmake 这样的工具用于帮助实现程序的编译。于此同时编译需要特殊环境和工具，编译环境的准备也不是一件容易的事，因此为方便终端用户在 Linux 上安装使用程序出现了包管理器。 所谓包管理器就是预先将程序编译好；然后将其打包成程序包。程序包的安装过程，就是将编译好的目标程序(我们称之为目标二进制格式) 的二进制程序、库文件、配置文件、帮助文件放置到特定目录中即可，rpm 的数据库会记录每个程序的每个文件及其存放位置，因此通过我们也可以通过 程序包管理器轻松实现对程序的升级，卸载和查询。 二进制的 C 程序是与平台相关的，因此只能安装与自身平台架构相同的程序包。需要注意的是程序的特定功能是在程序编译时就确定的，因此为满足不同人对程序功能的定制需求，程序包通常会按照功能进行分包；即通用的功能放在主包中，其他额外的功能放在分包中。 2. 程序包管理器2.1 程序包管里器的种类不同的主流 Linux 发行版为自家开发了特有的包管里器，目前比较流行的有如下几个，Centos主要使用 rpm，我们的介绍也以 rpm 为主 debian：dpt(dpkg), 后缀名为 .deb redhat：rpm(redhat package manager/rpm is package manager),后缀名为 .rpm S.u.S.E：rpm, “.rpm” Gentoo：ports ArchLinux：dnf 2.1 包命名格式程序包的命名方式遵循特定的规则，包含了很多信息，通过包名我们大体上就可以判断其是否符合我们需要。rpm 的包名由源代码的名称衍生而来。 源代码名称: name-VERSION.tar.gz VERSION：major.minor.release eg: redis-3.0.2.targz rpm 包名称: name-VERSION-ARCH.rpm eg: redis-3.0.2-1.centos7.x64.rpm VERSION：major.minor.release 源代码包的版本号，此处为 3.0.2 ARCH:release.os.arch rpm包的发行号，此处为 1.centos7.x64 release: rpm 包制作的版本号 os: 操作系统平台 arch: archetecture 硬件架构包括i386, x64(amd64), ppc, noarch 等 由于 rpm 存在拆包的可能，支包的命名方式是在主包的基础上添加了支包的功能说明 主包：name-VERSION-ARCH.rpm 支包：name-function-VERSION-ARCH.rpm，function 可以是 devel, utils, libs, … 2.2 依赖关系：包管理不能自动解决程序的依赖关系，因此每个程序包都有与之对应的前端工具，能自动解决安装卸载过程中的依赖关系 yum：rhel系列系统上rpm包管理器的前端工具； apt-get (apt-cache)：deb包管理器的前端工具； zypper：suse的rpm管理器前端工具； dnf：Fedora 22+系统上rpm包管理器的前端工具； lddldd /path/binary_file 作用: 查看二进制文件依赖的库文件 ldconfigldconfig 作用: 管理和查看本机的挂载库文件 -p: 显示本机已经缓存的所有可用库文件及文件路径映射关系 配置文件: /etc/ld.so.conf, /etc/ld.so.conf.d/*.conf 缓存文件: /etc/ld.so.cache 2.3 程序包的组成程序包由如下几个部分组成: 程序包的组成清单（每个程序包都单独 实现）； 文件清单 安装或卸载时运行的脚本 数据库（公共） 程序包的名称和版本； 依赖关系； 功能说明； 安装生成的各文件的文件路径及校验码信息； 等等等 /var/lib/rpm/ 2.4 获取程序包的途径我们的程序包基本都是从网络上下载获取，因此应该尽量从正规途径下载程序包，防止被植入后门。包下载之后应该尽量对其来源合法性，程序包完整性进行检查，确认没有问题后在使用。可靠的包获取途径如下所示: 系统发行版的光盘或官方的文件服务器（或镜像站点） http://mirrors.aliyun.com, http://mirrors.sohu.com, http://mirrors.163.com 项目的官方站点 第三方组织： EPEL 搜索引擎 http://pkgs.org http://rpmfind.net http://rpm.pbone.net 自动动手，丰衣足食]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.2 任务计划和周期性任务]]></title>
    <url>%2F2018%2F02%2F02%2Flinux_mt%2F10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2FLinux%E4%BB%BB%E5%8A%A1%E8%AE%A1%E5%88%92%E5%92%8C%E5%91%A8%E6%9C%9F%E6%80%A7%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[任务计划和周期性任务 Linux 中定时执行的任务有任务计划和周期性任务两种，所谓任务计划即只在未来的某时间点执行一次某任务，周期性任务则是按照特定的时间规律定期执行某任务。本节我们就来讲解Linux 中这两种任务的实现方式。因为计划任务和周期任务的执行结果会通过邮件发送给用户，因此我们首先来简单说一下邮件服务。本节内容如下所示: 本地邮件服务和使用 mailx 收发邮件 任务计划：at 和 batch 周期性任务计划：cron 1. 本地邮件服务 上图是一个QQ邮箱用户编写一封邮件，发送给一个163邮箱用户，后者接收邮件并阅读的过程。其中 smtp协议: 属于TCP/IP 上的应用层协议，完成跨网络传输邮件，是邮件服务器之间的传输协议 pop3/imap4: 是客户端与邮件服务器之间的传输协议，定义了用户向服务商查询、分组、移动、编辑等方面的操作规范 POP3是比较老的协议，而IMAP稍微新一点 mailxmailx [-s &#39;SUBJECT&#39;] username[@hostname] 作用: Mail User Agent, 用户收发邮件的工具程序； 收邮件: 不带参数使用 mailx 会进入命令行交互客户端，可用于接收邮件 发邮件: -s &#39;SUBJECT&#39;: 指定邮件的主题 username[@hostname]: 指定收件人，本地传送无需域名 附注: 默认进入交互式输入环境，填写邮件正文，也可通过输入重定向或管道指定 123456789101112131415&gt; mail # 不带参数可进入 mail 的交互模式，可查收邮件Heirloom Mail version 12.5 7/5/10. Type ? for help.&quot;/var/spool/mail/tao&quot;: 3 messages 3 new&gt;N 1 root Tue Jul 24 09:59 17/583 N 2 root Tue Jul 24 10:00 18/553 &quot;hellp&quot; N 3 root Tue Jul 24 10:00 18/556 &quot;hellp&quot;&amp; 1 # &amp; 后输入邮件编号，即可查看邮件内容&gt; mail -s &quot;welcome&quot; taothis is jerry , welcome # 交互式输入邮件内容. # 空行后接 . 或使用 ctrl+d 表示结束输入&gt; ls /var/log | mail -s &quot;subject&quot; tao # 通过管道输入邮件正文&gt; mail -s &quot;subject&quot; tao &lt; /etc/fstab # 通过输入重定向输入邮件内容 2. 任务计划2.1 at命令at [OPTION]... TIME 作用: 在 time 指定的时间运行特定命令，默认会进入交互式命令行，用于输入要执行的命令 选项: -l: 查看作业队列，相当于atq -f /PATH/FROM/SOMEFILE: 从指定文件中读取作业任务，而不用再交互式输入； -d at_id: 删除指定的作业，相当于atrm，后跟任务的 id 号，通过 atq 即可查看； -c: 查看指定作业的具体内容； -q QUEUE: 指明队列, at的作业有队列，用单个字母表示，默认都使用a队列； TIME: HH:MM [YYYY-mm-dd]: 指定具体的时间 noon, midnight, teatime, tomorrow: 使用特定的时间标识 now+num[minutes, hours, days, OR weeks]: 使用相对时间 12345678&gt; at now+2minat&gt; echo &quot;abc&quot;at&gt; &lt;EOT&gt; # 按 ctrl+d 表示结束输入job 3 at Tue Jul 24 19:06:00 2018&gt; atq2 Tue Jul 24 19:06:00 2018 a tao3 Tue Jul 24 19:06:00 2018 a tao 2.2 batch命令：batch 会让系统自行选择在系统资源较空闲的时间去执行指定的任务 3. 周期性任务计划：cron3.1 cron 简介123456789$ rpm -ql cronie/etc/cron.d/etc/cron.d/0hourly/etc/cron.deny/etc/pam.d/crond # 守护进程/etc/sysconfig/crond/usr/bin/crontab # 辅助工具/usr/lib/systemd/system/crond.service/usr/sbin/crond 周期性任务计划由 cronie 程序包提供，包括了 crond 守护进程及相关辅助工具。在定义周期性任务之前，首先需要确保crond守护进程(daemon)处于运行状态。centos7 和 centos6 检查服务运行状态的命令如下:123456789101112# centos7 使用 systemctl 查看服务运行状态&gt; systemctl status crond.service● crond.service - Command Scheduler Loaded: loaded (/usr/lib/systemd/system/crond.service; enabled; vendor preset: enabled) Active: active (running) since 三 2018-07-25 08:59:13 CST; 47min ago Main PID: 1897 (crond) CGroup: /system.slice/crond.service └─1897 /usr/sbin/crond -n# centos6&gt; service crond statuscrond is running. 向crond提交作业的方式不同于at，它需要使用专用的配置文件，此文件有固定格式，不建议使用文本编辑器直接编辑此文件；要使用crontab命令。cron任务分为两类： 系统cron任务，主要用于实现系统自身的维护；需要手动编辑 /etc/crontab 文件进行任务配置 用户cron任务，可通过 crontab 命令，进行配置 3.2 系统cron的配置系统 cron 的配置文件位于 /etc/crontab，其内容如下。1234567891011121314SHELL=/bin/bash # 定义执行命令的 默认 shellPATH=/sbin:/bin:/usr/sbin:/usr/bin # 不同于用户登录后获得的环境，因此，建议命令使用绝对路径，或者自定义PATH环境变量；MAILTO=root # 执行结果邮件发送给MAILTO指定的用户# For details see man 4 crontabs# Example of job definition:# .---------------- minute (0 - 59)# | .------------- hour (0 - 23)# | | .---------- day of month (1 - 31)# | | | .------- month (1 - 12) OR jan,feb,mar,apr ...# | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat# | | | | |# * * * * * user-name command to be executed 周期性任务定义: 每一行定义一个周期性任务，共7个字段； * * * * * user-name command to be executed * * * * * : 定义周期性时间 user-name : 运行任务的用户身份 command to be executed：要执行的任务 需要特别注意的，cron 周期性任务的执行环境跟用户登陆后的系统环境并不一样，cron 执行时默认的 PATH 为 /sbin:/bin:/usr/sbin:/usr/bin，因此，建议命令使用绝对路径，或者在脚本中自定义PATH环境变量； 3.3 用户cron的配置用户的 cron 配置文件位于 /var/spool/cron/USERNAME 与用户名同名的文件，其配置文件与系统 cron 配置文件类似，唯一的区别是在定义周期性任务时无需指明 user-name，默认是用户自己。建议使用 crontab 命令进行周期性任务的定义，因为其能自动检查语法错误，防止出错。 3.4 cron 中的时间表示法* * * * * 周期性时间有如下定义方式: 特定值: 给定时间点有效取值范围内的值，day of week和day of month一般不同时使用； *: 给定时间点上有效取值范围内的所有值；表“每..” #,#,#:逗号分隔的离散值 #-#: 短线连接开头和结束的连续取值： */#:在指定时间点上，定义步长,表示每隔多少的意思 注意： 指定的时间点不能被步长整除时，其意义将不复存在； 最小时间单位为“分钟”，想完成“秒”级任务，得需要额外借助于其它机制； 123456789# cron 时间定义示例3 * * * * # 每小时执行一次；每小时的第3分钟；3 4 * * 5 # 每周执行一次；每周5的4点3分；5 6 7 * * # 每月执行一次；每月的7号的6点5分；7 8 9 10 * # 每年执行一次；每年的10月9号8点7分；9 8 * * 3,7 # 每周三和周日；0 8,20 * * 3,70 9-18 * * 1-5*/5 * * * * # 每5分钟执行一次某任务； 3.5 crontab命令crontab [-u user] [-l | -r | -e] [-i] 作用: 编辑用户 cron 配置文件 选项 -e：编辑任务； -l：列出所有任务； -r：移除所有任务；即删除/var/spool/cron/USERNAME文件； -i：在使用-r选项移除所有任务时提示用户确认； -u user：root用户可为指定用户管理cron任务； 通知：命令运行结果将以以邮件通知给当前用户；想拒收邮件可通过如下方式实现 COMMAND &gt; /dev/null: 命令正常运行不通知用户，运行出错则通知用户 COMMAND &amp;&gt; /dev/null: 无论命令是否正常运行均不通知用户 转义：定义COMMAND时，如果命令需要用到%，需要对其转义；但放置于单引号中的%不用转义亦可； 注意: 某任务在指定的时间因关机未能执行，下次开机不会自动执行 如果期望某时间因故未能按时执行，下次开机后无论是否到了相应时间点都要执行一次，可使用anacron实现 练习1231、每12小时备份一次/etc目录至/backups目录中，保存文件 名称格式为“etc-yyyy-mm-dd-hh.tar.xz”2、每周2、4、7备份/var/log/secure文件至/logs目录中，文件名格式为“secure-yyyymmdd”；3、每两小时取出当前系统/proc/meminfo文件中以S或M开头的行信息追加至/tmp/meminfo.txt文件中；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[9.1 压缩打包工具]]></title>
    <url>%2F2018%2F02%2F01%2Flinux_mt%2F10-%E5%8E%8B%E7%BC%A9%E5%B7%A5%E5%85%B7-%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%2F%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%89%93%E5%8C%85%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[压缩打包工具 所谓压缩就是使用精心设计的压缩算法减少文本的容量大小，这对音频与视频无效，因为它们本身就是已压缩的。Linux 有众多的压缩和打包工具，本节我们将介绍如下命令的使用： gzip/gunzip bzip2/bunzip2 xz/unxz zip/unzip 通用的打包压缩工具 tar, cpio Linux 的打包工具 1.1 gzip/gunzip/zcatgzip [OPTION]... FILE... -d：解压缩，相当于gunzip； -#：指定压缩比，默认是6；数字越大压缩比越大（1-9）； -c：将压缩结果输出至标准输出，默认 gzip 会删除源文件，只保留压缩后的文件 gzip -c FILE &gt; /PATH/TO/SOMEFILE.gz zcat GZIP_FILE 作用: 不用解压缩，直接查看压缩文件的内容 1.2 bzip2/bunzip2/bzcatbzip2 [OPTION]... FILE... -d：解压缩，相当于 bunzip2 -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：keep，保留原文件； 1.3 xz/unxz/xzcatxz [OPTION]... FILE... -d：解压缩，相当于 unxz -#：指定压缩比；默认是6；数字越大压缩比越大（1-9）； -k：保留原文件； 2. 归档打包工具1.1 tartar [OPTION]... FILE... 选项: 可以带- 可以不带 f: 指定要生成或解包的目标文件 c: 创建归档 x: 展开归档 t: 查看归档文件的文件列表 z: 使用 gzip 压缩 j: 使用 bzip2 压缩 J: 使用 xz 压缩 C: 展开归档时，将文件展开到指定目录 用法: 创建归档 -c -f /PATH/TO/SOMEFILE.tar FILE... -cf /PATH/TO/SOMEFILE.tar FILE... 查看归档文件的文件列表 -tf /PATH/TO/SOMEFILE.tar 归档压缩 -zcf /PATH/TO/SOMEFILE.tar.gz FILE... -jcf /PATH/TO/SOMEFILE.tar.bz2 FILE... -Jcf /PATH/TO/SOMEFILE.tar.xz FILE... 展开归档: -xf /PATH/FROM/SOMEFILE.tar -xf /PATH/FROM/SOMEFILE.tar -C /PATH/TO/SOMEDIR - 解压至指定目录 附注: 无须额外指定，tar 会自动根据文件名后缀使用响应的命令进行解压缩 1.2 zip：zip/unzip 作用: 归档和压缩 后缀: .zip 12&gt; zip pam.d.zip pam.d/* # 必须指定打包压缩包含的文件&gt; unzip pam.d.zip 1.3 cpio]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.5 btrfs文件系统管理与应用]]></title>
    <url>%2F2018%2F01%2F31%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2Fbtrfs%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[btrfs文件系统管理与应用 1. btrfs文件系统：1.1 简介 简介: Btrfs (B-tree, Butter FS, Better FS), GPL, Oracle, 2007, CoW; 核心特性： 多物理卷支持：btrfs可由多个底层物理卷组成；支持RAID，以联机“添加”、“移除”，“修改”； 写时复制更新机制(CoW)：复制、更新及替换指针，而非“就地”更新； 数据及元数据校验码：checksum 子卷：sub_volume 快照：支持快照的快照； 透明压缩： 1.2 文件系统创建：mkfs.btrfs -L ‘LABEL’ -d : raid0, raid1, raid5, raid6, raid10, single -m : raid0, raid1, raid5, raid6, raid10, single, dup -O -O list-all: 列出支持的所有feature； 属性查看： btrfs filesystem show 挂载文件系统： mount -t btrfs /dev/sdb MOUNT_POINT 透明压缩机制： mount -o compress={lzo|zlib} DEVICE MOUNT_POINT 子命令：filesystem, device, balance, subvolume]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.4 Linux中实现LVM逻辑卷与快照]]></title>
    <url>%2F2018%2F01%2F30%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2FLVM%E9%80%BB%E8%BE%91%E5%8D%B7%E4%B8%8E%E5%BF%AB%E7%85%A7%2F</url>
    <content type="text"><![CDATA[Linux中实现LVM逻辑卷与快照 LVM(Logical Volumn Manager) 逻辑卷，是将一个或多个底层块设备组织一个逻辑的工具。逻辑卷可以在使用过程中动态扩大和收缩，而不影响已经存在的文件。Centos7 默认安装下，会自动将磁盘组织成逻辑卷。本节我们就来介绍如何使用逻辑卷，将包含如下内容 LVM 简介 LVM 的创建和管理 1. LVM 的简介我们知道普通分区一旦确定之后便不能更改大小，想扩大或缩减分区，只能删除分区然后重新创建，但这势必会影响到分区上已经存在的文件。LVM 则是在物理设备(分区)的基础上添加了一层逻辑层，以达到可以动态更改容量的目的。对于那些实现无法确定磁盘使用量的情况，LVM 提供了很大的便利。但是额外的逻辑层使得 LVM 在数据恢复上变的更加困难。因此觉得LVM好的和感觉差的差不多对半开。 LVM 物理结构LVM 的物理结构如下图所示 每个物理设备首先被组织成 PV(Physical Volume) 多个 PV 合并组成 VG(Volume Group) 逻辑卷组，统一进行管理，VG 可以动态增加和删除 PV 以扩大或收缩容量 PE(Physical Extent) 是 VG 容量分配的基本单元 LV(Logical Volume) 包含特定数量的 PE，构成逻辑上的分区，可动态调整包含的PE 数，以达到动态调整分区容量的目的；包含在 LV 中的PE 称为 LE LVM 创建过程因此逻辑卷的创建，首先需要将物理设备创建为 PV，将多个 PV 创建为 VG，然后在 VG 的基础上创建 LV，LV 即是可以用来创建文件系统并挂载使用的逻辑分区。整个过程即 pv --&gt; vg --&gt; lv。LVM 由内核模块 dm, device mapper(设备映射组件)提供。下面是 pv,vg,lv 一众命令的概览。 作用 PV VG LV 创建 pvcreate vgcreate lvcreate 显示 pvdisplay vgdisplay lvdisplay 简要显示 pvs vgs lvs 删除 pvremove vgremove lvremove 降低容量 vgreduce lvreduce 添加容量 vgextend lvextend 搜索 pvscan vgscan lvscan LV 的设备文件一个逻辑卷 LV 的设备有三个，其中两个是便于访问的软连接 /dev/dm-#: LV 实际上的设备文件 /dev/VG_NAME/LV_NAME: 指向 dm-# 的软连接 /dev/mapper/VG_NAME-LV_NAME: 指向 dm-# 的软连接 2. LVM 管理下面我们开始学习pv，vg，lv 一众命令 2.1 PV 管理pvs|pvdisplays [pv_device] 作用: 显示系统上所有 pv 的基本信息 pv_device: pv 所在设备的设备文件名，显示特定 PV 信息；可选，默认显示所有 PV pvcreate /dev/DEVICE 作用: 创建 PV pvremove pv_device 作用: 删除 PV pv_device: pv 所在设备的设备文件名 2.2 VG 管理vgs|vgdisplays [vg_name] 作用: 显示系统上所有 vg 的基本信息 vg_name: 卷组名，可选，默认显示所有卷组 vgcreate [-s #] vg_name pv_device.... 作用: 创建卷组 -s: 指定PE 大小，默认4M，可用单位 kKmMgGtTpPeE vg_name: 卷组名 pv_device: pv 所在设备，可多个 vgextend vg_name pv_device.... 作用: 向 vg 添加 pv vgreduce vg_name pv_device.... 作用: 从 vg 删除 pv vgremove vg_name 作用: 删除整个卷组 2.3 LV 管理lv 的扩大或缩减不仅要调整 lv 自身大小，还需要调整 lv 上的文件系统大小。 lv 创建和删除lvs|lvdisplays [lv_device] 作用: 显示系统上所有 lv 的基本信息 lv_device: 逻辑卷lv 的设备文件；可选，默认显示所有 lv lvcreate -L #[mMgGtT] -n lv_name vg_name: 作用: 在特定卷组内创建 lv -L: 指定 lv 的大小 -n: 指定 lv 的名称 lvremove /dev/VG_NAME/LV_NAME 作用: 删除 lv 附注: 删除前需先卸载文件系统 扩展逻辑卷：扩展逻辑卷，首先需要调整逻辑卷大小，然后需要调整文件系统大小，相关命令如下 lvextend -L [+]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 扩展逻辑卷容量 -L: 指定逻辑卷大小，+ 表示增加多少，没有+直接指定变更后的总大小 eg: lvextend -L 4G /dev/myvg/mylv lvextend -L +2G /dev/myvg/mylv resize2fs /dev/myvg/mylv [size] 作用: 调整文件系统大小 size: 指定调整后大小，默认使用所有分区空间，单位有mMgGtT 缩减逻辑卷缩减逻辑卷很危险，必需离线操作，大体上需要经过如下步骤: 先确定缩减后的目标大小；并确保对应的目标逻辑卷大小中有足够的空间可容纳原有所有数据； 卸载文件系统: umount /dev/VG_NAME/LV_NAME 文件系统强制检测: e2fsck -f 缩减文件系统大小: resize2fs DEVICE # 缩减逻辑卷大小: lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 重新挂载文件系统: mount lvreduce -L [-]#[mMgGtT] /dev/VG_NAME/LV_NAME 作用: 缩减逻辑卷容量 -L: 指定逻辑卷大小，- 表示减少多少，没有-直接指定变更后的总大小 创建快照卷：lvcreate -L #[mMgGtT] -p r -s -n 快照卷 原卷 作用: 创建 lv 的快照卷 -L #[mMgGtT]: 指定快照卷大小 -n: 指定快照卷名称 -s: 指明创建快照卷 -p r: 设置只读 注意：快照卷是对某逻辑卷进行的，因此必须跟目标逻辑卷在同一个卷组中；无须指明卷组； 练习12345678910111213141516171819202122232425练习1：创建一个至少有两个PV组成的大小为20G的名为testvg的VG；要求PE大小为16MB, 而后在卷组中创建大小为5G的逻辑卷testlv；挂载至/users目录；&gt; pvcreate /dev/sdb&gt; pvcreate /dev/sdc&gt; vgcreate -s 16M testvg /dev/sdb /dev/sdc&gt; lvcreate -L 5G -n testlv testvg&gt; mkfs -t ext4 /dev/testvg/testlv&gt; mount /dev/testvg/testlv /users练习2： 新建用户archlinux，要求其家目录为/users/archlinux，而后su切换至archlinux用户，复制/etc/pam.d目录至自己的家目录；&gt; useradd archlinux -d /users/archlinux&gt; echo &quot;aaaa&quot;|password archlinux --stdin&gt; cp -r /etc/pam /users/archlinux练习3：扩展testlv至7G，要求archlinux用户的文件不能丢失；&gt; lvextend -L +20M /dev/testvg/testlv&gt; resize2fs /dev/testvg/testlv练习4：收缩testlv至3G，要求archlinux用户的文件不能丢失；&gt; umount /user&gt; fsck -t ext4 -f /dev/testvg/testlv&gt; resize2fs /dev/testvg/testlv 30M&gt; lvreduce -L 30M /dev/testvg/testlv&gt; mount /dev/testvg/testlv /user/archlinux练习5：对testlv创建快照，并尝试基于快照备份数据，验正快照的功能；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.3 Linux RAID]]></title>
    <url>%2F2018%2F01%2F29%2Flinux_mt%2F09-RAID%E5%92%8CLVM%E5%BA%94%E7%94%A8%2FLinux_RAID%2F</url>
    <content type="text"><![CDATA[Linux RAID 本章，我们来了解一些更复杂的磁盘使用方式，算是前一章的进阶。本章将包含以下内容: RAID 磁盘阵列 LVM 逻辑卷 btrfs 文件系统 RAID 全称叫廉价冗余磁盘阵列（Redundant Array of Inexpensive Disks)，后因磁盘不再廉价， RAID 咨询委员会将其改名为独立磁盘冗余阵列(Redundant Array of Independent Disks)。其设计初衷是为了将多个容量较小、相对廉价的磁盘进行有机组合，从而以较低的成本获得与昂贵大容量磁盘相当的容量、性能、可靠性。RAID 主要利用数据条带、镜像和数据校验技术来获取高性能、可靠性、容错能力和扩展性。根据运用或组合运用这三种技术的策略和架构，可以把 RAID 分为不同的等级，以满足不同数据应用的需求。本节我们学习的核心就是来了解 RAID 各个等级，包括如下内容 RAID 概述 RAID 各等级的组织结构和特性 软件RAID的实现 1. RAID 概述从实现角度看， RAID 主要分为软 RAID、硬 RAID 以及软硬混合 RAID 三种。软 RAID 所有功能均有操作系统和 CPU 来完成。，没有独立的 RAID 控制 / 处理芯片和 I/O 处理芯片，效率自然最低。硬 RAID 配备了专门的 RAID 控制 / 处理芯片和 I/O 处理芯片以及阵列缓冲，不占用 CPU 资源，但成本很高。生长环境中则主要以硬 RAID为主。 RAID 中主要有三个关键概念和技术：镜像（ Mirroring ）、数据条带（ Data Stripping ）和数据校验（ Data parity ）。 镜像，将数据复制到多个磁盘，一方面可以提高可靠性，另一方面可并发从两个或多个副本读取数据来提高读性能。显而易见，镜像的写性能要稍低， 确保数据正确地写到多个磁盘需要更多的时间消耗。 数据条带，将数据分片保存在多个不同的磁盘，多个数据分片共同组成一个完整数据副本，这与镜像的多个副本是不同的，它通常用于性能考虑。数据条带具有更高的并发粒度，当访问数据时，可以同时对位于不同磁盘上数据进行读写操作， 从而获得非常可观的 I/O 性能提升 。 数据校验，利用冗余数据进行数据错误检测和修复，冗余数据通常采用海明码、异或操作等算法来计算获得。利用校验功能，可以很大程度上提高磁盘阵列的可靠性、鲁棒性和容错能力。不过，数据校验需要从多处读取数据并进行计算和对比，会影响系统性能。 不同等级的 RAID 采用一个或多个以上的三种技术，来获得不同的数据可靠性、可用性和 I/O 性能。至于设计何种 RAID （甚至新的等级或类型）或采用何种模式的 RAID ，需要在深入理解系统需求的前提下进行合理选择，综合评估可靠性、性能和成本来进行折中的选择。 2. RAID 等级在实际应用领域中使用最多的 RAID 等级是 RAID0 、 RAID1 、 RAID4 、 RAID5 、RAID10 、JBOD。接下来将逐一介绍这几个 RAID 等级 2.1 RAID0RAID0 又称条带，将数据分片保存在多个不同的磁盘，以获取读写性能的提升。其组织结构如下图所示，我们以竖向排列的磁盘表示条带。 2.2 RAID1RAID0 又称镜像，多个磁盘保存了数据的相同副本，通过冗余提供高的容错能力。其组织结构如下图所示，我们以横向排列的磁盘表示镜像，以与条带显示区分，介绍 RAID10 时更容易理解。 2.3 RAID10RAID10 指的是，先将磁盘两两分组组成 RAID1,然后将 RAID1 组织成RAID0。其组织结构如下图所示，数据先分片，在冗余保存。 2.4 RAID4RAID4 指的是有一块专门作为校验的磁盘，剩余磁盘组织成 RAID0，由校验盘提供冗余容错能力。其组织结构如下图所示，Ap,Bp等 表示校验数据块。 2.5 RAID5RAID4 有个明显的问题是，专门的校验盘负载过重。所以RAID5 将校验功能分散到了所有磁盘上。其组织结构如下图所示，校验数据块 Ap,Bp等分散在各个磁盘中。 2.6 RAID6RAID6 与 RAID5 类似，只不过有两个校验盘，能允许两块盘出现故障 2.7 JBOD JBOD 是将多个物理磁盘串联起来，提供一个巨大的逻辑磁盘，一个存满了就存下一个。它只是简单提供一种扩展存储空间的机制，不提升存储性能，也没有提供冗余容错能力。其组织结构如下图所示。 2.8 各个 RAID 等级性能比较 级别 读性能 写性能 容错性 最少磁盘数 可用空间 RAID-0 提升 提升 降低 &gt;=2 N*min(S1,S2,..) RAID-1 提升 略有下降 有 &gt;=2 1*min(S1,S2..) RAID-4/5 提升 提升 允许坏1块磁盘 &gt;=3 (N-1)*min(S1,S2,…) RAID-6 提升 提升 允许坏2块磁盘 &gt;=4 (N-2)*min(S1,S2,…) RAID-10 提升 提升 &gt;=4 每组镜像最多只能坏一块 N*min(S1,S2,…)/2 JBOD 不变 不变 降低 &gt;=2 sum(S1,S2,…) 3. 软件RAID的实现CentOS 上软RAID的实现由 md(multi devices)模块，及其提供 mdadm 命令组成 md 模块: multidisks, 一个内核模块，用于支持将任何块设备组织成RAID mdadm 命令: 操作 md 模块的模式化工具 mdadmmdadm [mode] raiddevice [options] component-devices mode: 管理模式 -A: 装配模式，重新识别此前实现的RAID -C：创建模式，创建RAID -F：监控模式 管理模式：-f, -r, -a raiddevice: RAID设备的设备文件,通常为/dev/md#，#表示一个数字 component-devices:成员设备 支持的RAID级别: JBOD, RAID0, RAID1, RAID4, RAID5, RAID10 options: C: 创建模式中专用选项 -n #: 用于创建RAID设备的磁盘个数； -l #: 级别 -a {yes|no}: 自动为创建的RAID生成设备文件; -c Chunk_Size: 指明块大小 -x #: 指明空闲盘的个数 管理模式 mdadm /dev/md# -f /dev/some_device：将/dev/md#中的/dev/some_device手动设置为损坏 mdadm /dev/md# -r /dev/some_device：将/dev/md#中的损坏状态的/dev/some_device移除 mdadm /dev/md# -a /dev/new_device: 新增设备 装配模式 停止软件RAID：mdadm -S /dev/md# 重新启用RAID： mdadm -A /dev/md# /dev/DEVICE... mdadm的配置文件/etc/mdadm.conf RAID 设备查看 cat /proc/mdstat: 当前系统上所有已启用的软件RAID设备及其相关信息 mdadm -D /dev/md#：显示指定的软RAID的详细信息 12345# 创建一个10G空间的RAID0&gt; mdadm -C /dev/md0 -a yes -n 2 -l 0 /dev/sdb&#123;1,2&#125;# 创建大小为10G空间的RAID5 -- 3*5G，6*2G (n-1)*2G&gt; mdadm -C /dev/md1 -a yes -n 3 -l 5 /dev/sda&#123;3,5&#125; /dev/sdb3 练习1234567891011121314151617181920212223242526# centos7 GPT 分区格式练习1：创建一个可用空间为10G的RAID1设备，要求其chunk大小为128k，文件系统为ext4，有一个空闲盘，开机可自动挂载至/backup目录；&gt; fdisk /dev/nvme0n1 # 创建3个大小为 50M 的类型为 13 磁盘分区&gt; mdadm -C /dev/md0 -n 2 -l 1 -c 128K -x 1 /dev/nvme0n1p&#123;12,13,14&#125;&gt; mdadm -D /dev/md0&gt; mke2fs -t ext4 /dev/md0&gt; blkid /dev/md0/dev/md0: UUID=&quot;8d46d667-d3e2-4f5e-b918-4e6d9a576445&quot; TYPE=&quot;ext4&quot;&gt; vim /etc/fstabUUID=&quot;8d46d667-d3e2-4f5e-b918-4e6d9a576445&quot; /backup ext4 defaults,acl 0 0&gt; mount -a# 拆除 RAID&gt; umount /dev/md0&gt; mdadm -S /dev/md0练习2：创建一个可用空间为10G的RAID10设备，要求其chunk大小为256k，文件系统为ext4，开机可自动挂载至/mydata目录；&gt; fdisk /dev/nvme0n1 # 创建4个大小为 50M 的类型为 13 磁盘分区&gt; mdadm -C /dev/md0 -n 4 -l 10 -c 256K /dev/nvme0n1p&#123;12,13,14,15&#125;&gt; mkfs -t ext4 /dev/md0&gt; blkid /dev/md0/dev/md0: UUID=&quot;779bf9e4-846c-443d-970e-6a9b12a235c8&quot; TYPE=&quot;ext4&quot;&gt; vim /etc/fstabUUID=&quot;779bf9e4-846c-443d-970e-6a9b12a235c8&quot; /mydata ext4 defaults 0 0&gt; mount -a]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.2 磁盘与文件系统的管理命令]]></title>
    <url>%2F2018%2F01%2F28%2Flinux_mt%2F08-Linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[磁盘使用与文件系统管理介绍 本节，我们来学习磁盘和文件系统管理的相关命令，我们将按照从磁盘到创建一个可用的文件系统的顺序，逐步讲解相关命令的使用，内容如下: 磁盘分区 重载内核分区表 文件系统管理 挂在文件系统 其他相关命令 1. 磁盘进行分区磁盘分区管理主要有 fdisk，parted，sfdisk 三个命令。掌握一个即可，我们主要来学习 fdisk。fdisk 提供了一个交互式接口来管理分区，它有许多子命令，分别用于不同的管理功能；所有的操作均在内存中完成，不会直接同步到磁盘，直到使用w命令保存至磁盘上。fdisk 命令的使用方式如下 查看磁盘的分区信息：fdisk -l [device...] 作用: 列出指定磁盘设备上的分区情况，默认列出所有磁盘设备的分区情况 参数: device 设备文件名 cat /proc/partitions 作用: 查看内核分区信息 管理分区fdisk device 作用: 管理分区，进入 fdisk 交互式管理界面 12345678910111213141516171819202122232425# fdisk 使用示例&gt; fdisk /dev/nvme0n1WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.欢迎使用 fdisk (util-linux 2.23.2)。更改将停留在内存中，直到您决定将更改写入磁盘。使用写入命令前请三思。命令(输入 m 获取帮助)：m命令操作 d 删除已有分区 g create a new empty GPT partition table G create an IRIX (SGI) partition table l 列出所有的分区类型 m 查看帮助信息 n 创建新分区 o create a new empty DOS partition table p 显示现有分区信息 q 不保存并退出 s create a new empty Sun disklabel t 修改分区类型 v verify the partition table w 保存并退出 x extra functionality (experts only) 2. 重载内存分区表在已经分区并且已经挂载其中某个分区的磁盘设备上创建的新分区，内核可能在创建完成后无法直接识别；需要通知内核强制重读磁盘分区表。可用命令有如下三个: partprobepartprobe [device] 作用: inform the OS of partition table changes 附注: CentOS 5 仅能使用此命令 partxpartx [-a|-u] device 作用: tell the Linux kernel about the presence and numbering of on-disk partitions 选项: -a: 向内核添加所有分区表 -u: 向内核更新分区表 -l: 列出分区表 -s, --show: 显示分区表详细信息 -n, --nr M:N: 与 -s一起使用，限制显示的行 -o, --output list: 与 -s一起使用，限制显示的列 kpartxkpartx -af device 作用: Create device maps from partition tables 3. 文件系统管理3.1 文件系统创建Windows无法识别Linux的文件系统； 因此，存储设备需要两种系统之间交叉使用时，应该使用windows和Linux同时支持的文件系统：fat32(vfat)。mkfs.vfat device mkfsmkfs -t fs_type device 作用: 通用的文件系统创建命令，内部会调用特定文件系统的创建命令 选项: -t 指定要创建的文件系统 eg: mkfs -t ext4 /dev/sda1 == mkfs.ext4 /dev/sda1 12&gt; mkfsmkfs mkfs.btrfs mkfs.cramfs mkfs.ext2 mkfs.ext3 mkfs.ext4 mkfs.fat mkfs.minix mkfs.msdos mkfs.vfat mkfs.xfs mke2fsmke2fs [OPTIONS] device 作用: ext系列文件系统专用创建工具 选项: -t {ext2|ext3|ext4}： 指明要创建的文件系统类型 mkfs.ext4 = mkfs -t ext4 = mke2fs -t ext4 -b {1024|2048|4096}：指明文件系统的块大小； -L LABEL：指明卷标； -j： 创建有日志功能的文件系统ext3； mke2fs -j = mke2fs -t ext3 = mkfs - t ext3 = mkfs.ext3 -i #：bytes-per-inode，指明inode与字节的比率；即每多少字节创建一个Indode; -N #：直接指明要给此文件系统创建的inode的数量； -m #：指定预留的空间，百分比； -O [^]FEATURE：以指定的特性创建目标文件系统； mkswapmkswap [OPTIONS] device 作用: 创建swap文件系统 选项: -L LABEL：指明卷标 -f：强制创建 附注: Linux上的交换分区必须使用独立的swap文件系统； 且文件系统的System ID必须为82； swapon [OPTION] [DEVICE] 作用: 启用交换分区 选项: -a 启用定义在/etc/fstab文件中的所有swap设备； -p #: 指定此交换设备的优先级 swapoff DEVICE 作用: 禁用交换分区 3.2 文件系统查看和修改e2label 作用: 查看与设定 ext 系列文件系统的卷标 查看: e2label device 设定: e2label device LABEL dumpe2fsdumpe2fs [-h] device 作用: 显示 ext 系列文件系统的属性信息 选项: -h 仅显示超级块信息 tune2fstune2fs [OPTIONS] device 作用: 查看或修改ext系列文件系统的某些属性 注意：块大小创建后不可修改； 选项: -l：查看超级块的内容； -j：启动日志功能，即将 ext2 转换为 ext3； -L LABEL：修改卷标； -m #：调整预留空间百分比，后跟数字标直接表示百分之几； -O [^]FEATHER：开启或关闭某种特性； -o [^]mount_options：开启或关闭某种默认挂载选项 tune2fs -0 acl /dev/sda1: 开启访问控制列表功能 tune2fs -0 ^acl /dev/sda1: 关闭访问控制列表功能 blkidblkid 作用: 显示块设备属性，主要是显示文件系统类型 blkid device: 查看特定设备所有分区文件系统的类型和属性 blkid -L LABEL：根据LABEL定位设备 blkid -U UUID：根据UUID定位设备 3.3 文件系统检查因进程意外中止或系统崩溃等原因导致定稿操作非正常终止时，可能会造成文件损坏；此时，应该检测并修复文件系统。建议离线进行，不能让其他用户在正在修复的文件系统中读写文件。Linux 上的文件系统检测工具 fsck 同 mkfs 一样是一个通用的文件系统修复工具 fsckfsck -t fs_type device 作用: check and repair a Linux file system 选项: -t fstype: 指明文件系统类型； -a：无须交互而自动修复所有错误； -r：交互式修复 eg: fsck -t ext4 = fsck.ext4 e2fscke2fsck [OPTIONS] device 作用: ext系列文件系统的专用工具 选项: -y: 对所有问题自动回答为yes; -f：即使文件系统处于clean状态，也要强制进行检测 4. 文件系统挂载根文件系统这外的其它文件系统要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”；此目录即为“挂载点”。Linux 中用于挂载和卸载的命令是 mount,umount 挂载点，即用于作为另一个文件系统的访问入口,应该具有如下特性: 事先存在； 应该使用未被或不会被其它进程使用到的目录； 挂载点下原有的文件将会被隐藏； 4.1 文件系统挂载mount [option]... [-t fstype] [-o option] 设备 挂载点 作用: 将设备挂载至特定目录 设备: 设备文件: /dev/sda 卷标: -L 卷标 UUID: -U UUID 常用的挂载选项： -r: readonly, 只读挂载 -w: read and write， 读写挂载 -t fstype：指明要挂载的设备上的文件系统的类型；多数情况下可省略，此时mount会通过blkid来判断要挂载的设备的文件系统类型； -L LABEL：以卷标方式指定设备， mount -L MYDATA 挂载点 -U UUID: 以UUID的方式指定设备，mount -U uuid 挂载点 -a: 自动挂载所有(/etc/fstab文件中定义的)支持自动挂载的设备 -n: 默认情况下，设备挂载或卸载的操作会同步更新至/etc/mtab文件中；-n用于禁止此特性； -B --bind: 绑定到目录到另一个目录上 -o option: 挂载文件系统的选项 async：异步I/O，数据写操作先于内存完成，而后再根据某种策略同步至持久设备中 sync: 同步I/O， atime/noatime: 文件和目录被访问时是否更新最近一次的访问时间戳 auto/noauto：设备是否支持mount的-a选项自动挂载 diratime/nodiratime: 目录被访问时是否更新最近一次的访问时间戳 dev/nodev: 是否支持在此设备上使用设备； user/nouser: 是否允许普通用户挂载此文件设备 exec/noexec: 是否允许执行此设备上的二进制程序文件 suid/nosuid: 是否支持在此设备的文件上使用suid ro: 只读 rw: 读写 remount: 重新挂载，通常用于不卸载的情况下重新指定挂载选项 acl: 启用此文件系统的 acl 功能，默认不支持； defaults: 默认选项 rw, suid, dev, exec, auto, nouser, and async eg: mount -o acl DEVICE MOUNT_POINT: 挂载后启动 acl 选型 tune2fs -o acl DEVICE 为设备设定默认挂载选项，启动 acl mount -o remount,ro /dev/sda: 以只读方式重新挂载 4.2 查看已挂载的设备查看已挂载的设备可使用如下三个命令 mount cat /etc/mtab cat /proc/mounts 4.3 特殊设备挂载挂载文件mount --bind 源目录 目标目录: 作用: 可以实现将目录绑定至另一个目录上，作为其临时访问入口； 挂载光盘mount -r /dev/cdrom mount_point 光盘设备文件： IDE 接口的光盘: /dev/hdc SATA接口的光盘: /dev/sr0 符号链接文件： /dev/cdrom /dev/cdrw: rw 表示是可写光盘 /dev/dvd /dev/dvdrw: rw 表示可写 dvd 挂载本地的回环设备mount -o loop /PATH/TO/SOME_LOOP_FILE MOUNT_POINT 4.4 文件系统卸载umount device|dir 作用: 卸载设备 参数: 设备文件或挂载点 注意：正在被进程访问到的挂载点无法被卸载，要想查看设备被哪个或哪些进程所战用，可以使用如下命令 lsof MOUNT_POINT: 查看占用设备的进程 fuser -v MOUNT_POINT: 查看占用设备的用户 fuser -km MOUNT_POINT: 终止所有正在访问某挂载点的进程 4.5 自动挂载/etc/fstab文件可用于配置除根文件系统以外的其它文件系统在开机时自动挂载。每行定义一个要挂载的文件系统及相关属性，每行有 6 个字段，从左往右各个字段的含义如下。使用 mount -a 可自动挂载定义在此文件中的所支持自动挂载的设备。需要额外注意的是swap 分区的挂载点永远是 swap, 且自动使用 swapon 挂载 挂载的设备： 设备文件 LABEL=”” UUID=”” 伪文件系统名称: proc, sysfs, devtmpfs, configfs 挂载点： 文件系统类型 挂载选项： 挂载选项可以有多个，彼此间使用逗号分隔； 转储频率：作用不大，大多数是 0 0：从不转储 1: 每天转储 2: 每隔一天 自检次序： 0：不自检，额外创建的文件系统都无须自动自检 1：首先自检，通常只有根文件系统需要首先自检 2：次级自检，不同的设备可以使用同一个自检次序 3 …. 5. 其他相关命令其他命令主要包括如下几个命令: 手动创建设备文件的 mknod 命令 查看磁盘使用量的 df 命令 查看文件夹大小的 du 命令 mknodmknod [OPTION]... NAME TYPE [MAJOR MINOR] 作用: 可用于手动创建字符或块设备文件 选项: -m MODE：创建后的设备文件的访问权限 dfdf [OPTION]... [FILE]... 作用: 查看已挂载设备的磁盘使用量 选项: -l：仅显示本地挂载设备的相关信息； -h：human-readable，以易读的方式显示磁盘使用量 -i：显示inode的使用状态而非blocks -P, --portability: 使用POSIX格式输出，不会出现换行 dudu [OPTION]... [FILE]... 作用: 查看文件夹的大小 选项: -s: sumary，只显示文件夹的总大小 -h: human-readable 以人类易读方式显示容量大小 1234567练习：1、创建一个10G的分区，并格式化为ext4文件系统； (1) block大小为2048；预留空间为2%，卷标为MYDATA； (2) 挂载至/mydata目录，要求挂载时禁止程序自动运行，且不更新文件的访问时间戳； (3) 可开机自动挂载；2、创建一个大小为1G的swap分区，并启动之；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[8.1 磁盘使用与文件系统管理介绍]]></title>
    <url>%2F2018%2F01%2F27%2Flinux_mt%2F08-Linux%E7%A3%81%E7%9B%98%E5%8F%8A%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2F%E7%A3%81%E7%9B%98%E4%B8%8E%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[磁盘使用与文件系统管理介绍 本章我们开始学习 Linux 磁盘和文件系统管理，这部分内容与操作系统原理，文件系统，磁盘硬件密切相关，内容多而且难。但是对Linux 运维而言，我们需要了解的仅仅是其中的基本概念以及如何使用命令管理分区和文件系统。因此将本章分为两个部分: 磁盘和文件系统的相关原理 磁盘和文件系统管理命令 第一部分讲解原理，属于概括性的数理总结，由于本人理解的有限，所以更加深入的内容还需要同学自己去谷歌相关的文档；第二部分是命令使用，将按照分区创建，文件系统创建管理的顺序，详细讲解管理磁盘和文件系统的所有常用命令。 磁盘是计算的五大基本组件之一，主要提供持久化存储功能。Linux 为管理磁盘，便于程序员扩展系统和用户读写磁盘数据，将磁盘管理划分成了多个层次。如同网络协议栈一样，各层级之间通过协议和接口进行规范，这样就能便于管理和扩展。这是编程领域常用的技术手段，如果两个层次无法衔接，就添加一个中间层。Linux 的磁盘管理大体分成了以下几个层次 123456789--------------------------------| 虚拟文件系统 | ---&gt; 提供了读写文件的统一接口-------------------------------| 特定的文件系统 | ---&gt; 抽象了对不同设备驱动程序的调用接口-------------------------------- ---&gt; 磁盘设备文件，提供了管理磁盘的统一接口| 磁盘设备的驱动程序 | ---&gt; 将对磁盘适配器的机器指令转换为系统调用-------------------------------- |磁盘 | 磁盘适配器| --------------------------------- 本节我们将围绕此结构，逐层讲解各层，内容如下: 抽象层次的理解 磁盘的组成和磁盘分区 文件系统的组成 1. 抽象层次的理解磁盘通常包括两个部分，一是存储数据的磁盘，另一个是与磁盘相对应的磁盘适配器，适配器相当于磁盘的控制单元，可以接收指令，并控制磁盘的寻道和读写。适配器的指令是与硬件相关的简单机器指令，与生产磁盘的硬件厂商密切相关。 所以为管理磁盘，包括其他硬件设备，都需要生产厂商提供与操作系统相适应的驱动程序。需要强调的是硬件的驱动程序是硬件厂商提供的，而不是内核开发者提供，因为硬件设备千千万万，只有厂商才最清楚他们生产的硬件设备是什么样。因此磁盘管理从发送与磁盘相关的机器指令变成了调用了相应驱动程序的系统调用。 我们知道越底层的东西越丑陋，也就越难用，想想如果你想创建一个文件，竟然需要写一个程序去调用系统调用，该多么费劲。文件系统的作用就是帮助我们管理磁盘，我们只需要调用文件系统的一条命令，就可以读写文件，而不用管数据到写到了磁盘何处。 此处还有一个问题，Linux 上的文件系统有很多，他们调用 api 可能都不一样，想想如果换一个文件系统，创建文件的函数就变了，大概编写 touch 命令的程序员就疯了，他要为所有文件系统都写一段代码。因此Linux 为统一管理所有的文件系统，创建了虚拟文件系统 vfs。可以将 vfs 理解为一个统一的框架，比如创建文件的命令就叫做 writer，此时不管什么文件系统，都要将其创建文件的调用向 vfs 注册。这样当我们调用 writer 时，vfs 就知道特定的文件系统创建文件的函数是什么，进而由 vfs 调用该函数创建文件。 因此，程序员只要调用 vfs 提供的标准接口就可以在所有的文件系统上读写文件了。了解了整个层次结构，接下来我们就来了解各个层次结构的细节。 1. 磁盘分区的作用就是将一个完成的磁盘，划分成逻辑上独立的管理单元。由于磁盘特殊的寻址特点，因此分区与磁盘的硬件结构密切相关。所以我们先来了解磁盘的硬件结构，然后再来看磁盘是如何分区的。 1.1 磁盘的类型磁盘按照生产工艺可以分为机械硬盘，固态硬盘，按照接口类型可以分为 IDE(ata)：并口，133MB/s SCSI：并口，Ultrascsi320, 320MB/S, UltraSCSI640, 640MB/S SATA：串口，6gbps SAS：串口，6gbps USB：串口，480MB/s 并口指的是同一线缆可以接多块设备；串口则是同一线缆只可以接一个设备。对于电脑的硬件架构，大家可以找不用的台式机拆开看看，这样就会有更加具体的理解。由于机械硬盘更容易理解，我们首先来看机械式硬盘的硬件结构 1.2 机械式硬盘的硬件结构 1.3 磁盘的分区结构 上面几幅图是机械硬盘结构和分区的示意图，如果不能理解可以参阅此博客 https://blog.csdn.net/u012758088/article/details/76668465 Centos5-6 中分区是以柱面为单位进行划分，而 Centos7 中分区划分的基本单位则是扇区 1.4 磁盘设备文件设备文件的主次设备号Linux 中一切接文件，所有设备都组成了设备文件,放置在 /dev 目录下，用于关联至设备的驱动程序，是设备的访问入口，能利用 Linux 中的统一接口进行管理。设备有主，次设备号 major：主设备号，区分设备类型；用于标明设备所需要的驱动程序； minor：次设备号，区分同种类型下的不同的设备；是特定设备的访问入口； 设备文件命令规则设备文件有统一的命名规则，由ICANN 规定，具体的规则如下；由于设备被检测到的顺序是可能发生变化的，设备的设备文件可能发生变化，因此除了设备文件名，Linux 还提供了其他引用设备的方式，包括卷标，UUID。 centos5 IDE: /dev/hd# SCSI,SATA,SAS,USB: /dev/sd[a-z]# [a-z]: 表示不同设备,为不同设备被检测到的次序 #: 表示不同设备上的不同分区 centos&gt;=6: 统一使用 /dev/sd[a-z]# 123&gt; /dev/nvme0n1p2 # 设备文件# 259, 2 即为设备的主次设备号brw-rw----. 1 root disk 259, 2 7月 17 09:16 /dev/nvme0n1p2 1.4 磁盘分区格式分区格式顾名思义就是如何在磁盘上表示分区。分区格式除了会影响分区的划分，还会影响操作系统的开机启动方式。早期的分区格式是 MBR，这种分区格式有分区数量和磁盘大小有限制，对于超出范围的磁盘容量无法识别。GPT 是最新的磁盘分区技术，比 MBR 更复杂，但是已经没有了 MBR 的种种限制 MBR MBR 是 Master Boot Record 的简称。如图，MBR 是磁盘的的第一个扇区，它包括如下三个部分 446bytes：包含了 bootloader 开机启动程序，用于引导启动操作系统 64bytes：分区表，每16bytes标识一个分区，一共只能有4个分区，其中又一个可作为扩展分区，用于创建其他逻辑分区； 主分区和扩展分区的标识：1-4 逻辑分区：5+ 2bytes：MBR区域的有效性标识；55AA为有效； GPTGPT 暂时我也不是很清楚，大家可以参考此片博文 https://blog.csdn.net/diaoxuesong/article/details/9406015。过段时间会补充此部分，请稍等。 2. 文件系统内核级文件系统由内核提供文件系统驱动和用户空间的文件系统管理工具组成。因为 ext4 文件系统相对容易理解，此处我们 ext4 文件系统为列，讲解文件系统的基本原理 2.1 ext4 组成部分 block inode inode表 inode bitmap, block bitmap 块组 superblock 块组描述符表(GDT) 2.2 文件查找过程2.3 链接文件链接文件值访问同一个文件不同路径，有硬链接和软链接之分 硬链接 硬链接：指向同一个inode的多个文件路径； 特性： 目录不支持硬链接； 硬链接不能跨文件系统； 创建硬链接会增加inode引用计数； 创建： ln src link_file 符号链接 符号链接：指向一个文件路径的另一个文件路径； 特性： 符号链接与文件是两人个各自独立的文件，各有自己的inode；对原文件创建符号链接不会增加引用计数； 支持对目录创建符号链接，可以跨文件系统； 删除符号链接文件不影响原文件；但删除原文件，符号指定的路径即不存在，此时会变成无效链接； 符号链接文件的大小是其指定的文件的路径字符串的字节数； 创建：ln -s src link_file lnln [-s] source dest: 作用: 创建链接文件 选项: -s 创建软链接，默认创建硬链接 2.4 文件管理操作 文件被删除： inode被标记为空闲，此inode指向的磁盘块被标记为空闲； 如果inode被引用了多次，且此次删除未使得其引用计数降低为的话，这意味着文件被删除仅删除了一个访问路径； 文件复制： 创建一个新文件，并原文件中数据在新文件指向的磁盘块中再写一次的过程； 文件移动： 在同一个分区移到：移动文件仅是改变了文件访问路径； 跨分区移到：在新分区创建文件，把数据复制过去，删除原分区数据； 2.5 文件系统挂载2.6 日志文件系统2.7 vfs 虚拟文件系统]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.6 awk使用与实战]]></title>
    <url>%2F2018%2F01%2F24%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fawk%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[sed命令应用与实战 Linxu 上有文本处理三剑客grep,sed,awk。本节我们来学习最后一个命令 awk 的使用。 awk 算得上是一门编程语言，这个编程语言内有包括变量，条件判断，循环，命令等诸多语言特性。我们将按照类似 bash 脚本的方式，从变量开始逐一讲解 awk 的使用。内容概述如下: awk 命令简介 awk 变量与数组的使用 awk 程序执行逻辑，包括顺序执行，条件判断和循环 awk 内置函数 有关 awk 的使用推荐大家阅读 《sed和awk》 《Linux Shell与脚本编程指南》 1. awk 简介Centos 中的 awk 是 GNU awk即 gawk。awk 是指向 gawk 命令的软连接 12345tao@hp:~$ which awk/usr/bin/awktao@hp:~$ ll /usr/bin/awklrwxrwxrwx. 1 root root 4 5月 8 09:34 /usr/bin/awk -$ gawk 1.1 awk 处理逻辑 如上图，awk 将文件处理分成三个阶段。第一阶段由 BEGIN 标识，第三阶段由 END标志，分别位于文件处理前和文件处理之后。 文本处理位于第二阶段，awk 每次读取文件中的一行，按照内部 FS 变量标识的分割符，将行分割成多个字段。字段按照位置分别保存在 $1,$2,$3…. 等变量中，供 awk 编程使用，$0 表示整行。awk 中的字段变量如下所示 12345-----------------------------------| $0 | # 整行------------------------------------| $1 | $2 | $3 | .......| # $n 表示分隔后的第 n 个字段------------------------------------ 作为一个编程语言，awk 有一些基本的语法特性，如果你有其他编程语言的使用经验，记住这些语法特性基本上很快就能写出 awk 程序。我们以如下例子来说明这些基本特性 awk -F: &#39;/^r/{if ($3$10) {i=1;printf &quot;|%-15s |%-15s|\n&quot;,$1,$7} }&#39; /etc/passwd 使用 {} 分割代码块 控制语句的条件判断放置在 ()内 代码块内的多条语句使用;分割，按顺序从左往右执行 使用 &quot;&quot; 表示字符串 使用/pattern/ 表示使用正则表达式 如果你不懂上面说的什么意思，没有关系，我们接下来会详细介绍 awk 的语法。 1.2 awk 命令使用gawk [options] &#39;program&#39; FILE ... 作用: 文件格式化工具 选项: -F：指明输入时用到的字段分隔符； -v var=value: 自定义变量； 参数: FILE: 待处理的文本文件，可多个 program: awk 编程脚本，必须使用单引号括起 格式: &#39;PATTERN{ACTION STATEMENTS}&#39; PATTERN：过滤出要处理的行 {ACTION STATEMENTS}: 编程语句表达式 12345tao@hp:~$ awk -F: &apos;&#123;print $1&#125;&apos; /etc/passwdrootbindaemonadm 1.3 PATTERNPATTERN 用于过滤出要处理的行，有如下几种过滤方式 empty： 作用: 空模式，匹配每一行 /regular expression/ 作用: 仅处理能够被此处的模式匹配到的行； relational expression: 作用: 关系表达式；结果为“真”才会被处理;非0值，非空均为真； /pat1/,/pat2/： 作用: 从 pat1 匹配首行到 pat2 匹配的首行之间的行 注意: 不支持类似 sed 直接给出数字的格式 startline,endline,只能通过关系表达式实现 BEGIN/END模式 BEGIN{}: 仅在开始处理文件中的文本之前执行一次； END{}：仅在文本处理完成之后执行一次； pattern 使用示例下面是一些使用 PATTERN 的示例，可以先跳过。 1234567891011121314151617181920212223242526272829# 1. empty# 显示eth0网卡配置文件的配置信息，只显示=号后的内容；$ gawk -F= '&#123;print $2&#125;' /etc/sysconfig/network-scripts/ifcfg-eth0# 2. /regular expression/# 显示默认shell为nologin的用户；$ gawk -F: '$7~/nologin$/&#123;print $1&#125;' /etc/passwd# 显示/etc/sysctl.conf文件定义的内核参数的参数名；$ awk -F= '/^[^#]/&#123;print $1&#125;' /etc/sysctl.conf# 显示eth0网卡的ip地址；$ ifconfig eth0 | awk -F: '/inet addr/&#123;print $2&#125;' | awk '&#123;print $1&#125;'# 3. relational expression# 显示gid小于500的组；$ gawk -F: '$3&lt;500&#123;print $1&#125;' /etc/group# 4. line ranges$ awk -F: '(NR$=2&amp;&amp;NR&lt;=10)&#123;print $1&#125;' /etc/passwd$ awk -F: '/^r/,/^h/&#123;print $1&#125;' /etc/passwd# 5. BEGIN/ENDawk -F: 'BEGIN&#123;printf "%-15s|%-15s\n","user","bash"&#125;&#123;printf "%-15s|%-15s\n",$1,$7&#125;END&#123;print "---------------------------\n"&#125;' /etc/passwd# 6. 指定复杂分隔符$ ifconfig eth0 | awk 'BEGIN&#123;FS="[ :]+"&#125;/inet addr/&#123;print $4&#125;' 2. awk 编程语法2.1 变量变量特性awk 中变量具有如下特性: 区分大小的 变量直接引用，无需使用 $, $1 整体表示一个变量，存储了第一个字段的值 自定义变量可以通过 -v var=value 选项指定，也可以在program中直接定义 1234awk -v FS=: '&#123;print $1&#125;' /etc/passwd # 等同于awk -F: '&#123;print $1&#125;' /etc/passwd# -F 就是指定 FS 变量的值 内置变量awk 有众多内置变量，常见的如下所示: FS：input field seperator，默认为空白字符； OFS：output field seperator，默认为空白字符； RS：input record seperator，输入时的换行符； ORS：output record seperator，输出时的换行符；- NF：number of field，字段数量 {print NF}: 打印当前行列数 {print $NF}: 打印当前行最后一个字段的值 NR：number of record, 行数；如果 awk 后跟多个文件，这个 NR 将是所有行的累计值 FNR：各文件分别计数；行数； FILENAME：当前文件名； ARGC：命令行参数的个数； ARGV：数组，保存的是命令行所给定的各参数； 2.2 输出awk 的输出有 print,printf 两个命令 printprint item1, item2, ... 作用: 输出后跟的内容 特性: 逗号分隔符； 输出的各item可以字符串，也可以是数值；当前记录的字段、变量或awk的表达式； 如省略item，相当于print $0; printfprintf FORMAT, item1, item2, ... 作用: 格式化输出,与 C 语言的 printf 函数的使用方式完全相同，bash中也有同名命令 说明: printf 不会自动换行，需要显式给出换行控制符，\n 参数: FORMAT: 格式化字符串，表示以特定格式显示数据；包括格式符和修饰符两个部分 item1..: 被格式化的数据，FORMAT中需要分别为后面的每个item指定一个格式化符号； 格式符： %c: 显示字符的ASCII码； %d, %i: 显示十进制整数； %e, %E: 科学计数法数值显示； %f: 显示为浮点数； %g, %G：以科学计数法或浮点形式显示数值； %s：显示字符串； %u：无符号整数； %%: 显示%自身； 修饰符： #[.#]：第一个数字控制显示的宽度；第二个数字表示小数点后的精度 -: 左对齐 +：显示数值的符号 12345678$ printf "%-5.2f\n" 3.23.20$ awk 'BEGIN&#123;printf "%-5.3f\n", 32.44456&#125;'32.445$ printf "%+20.2f\n" 3.2 +3.20 2.3 操作符awk 支持几乎所有的常规操作符 算术操作符： x+y, x-y, x*y, x/y, x^y, x%y -x +x: 转换为数值； 字符串操作符：没有符号的操作符，字符串连 赋值操作符： =, +=, -=, \*=, /=, %=, ^= ++, -- 比较操作符: $, $=, &lt;, &lt;=, !=, == 模式匹配符：后接正则表达 ~：是否匹配 !~：是否不匹配 逻辑操作符： &amp;&amp; || ! 条件表达式：selector?if-true-expression:if-false-expression 123456789# 1. 算术运算$ awk 'BEGIN&#123;i=1;i++;print i^3&#125;'8# 5. 模式匹配符awk -F: '&#123;if($1 ~ /^r/)&#123;print $1&#125;&#125;' /etc/passwd# 7. 条件表达式awk -F: '&#123;$3$=1000?usertype="Common User":usertype="Sysadmin or SysUser";printf "%15s:%-s\n",$1,usertype&#125;' /etc/passwd 2.4 控制语句过程式编程语言的代码执行顺序有顺序执行，条件判断和循环。awk 中常见的控制语句语法如下所示: if(condition) {statments} if(condition) {statments} else {statements} while(conditon) {statments} do {statements} while(condition) for(expr1;expr2;expr3) {statements} break continue next 代码块使用 {}，控制语句中的条件放置在 ()内，而 代码块内顺序执行的代码使用 ; 分隔。 if-elseif(condition) statement [else statement] 1234567$ awk -F: '&#123;if($3$=1000) &#123;printf "Common user: %s\n",$1&#125; else &#123;printf "root or Sysuser: %s\n",$1&#125;&#125;' /etc/passwd$ awk -F: '&#123;if($NF=="/bin/bash") print $1&#125;' /etc/passwd$ awk '&#123;if(NF$5) print $0&#125;' /etc/fstab$ df -h | awk -F[%] '/^\/dev/&#123;print $1&#125;' | awk '&#123;if($NF$=20) print $1&#125;' while循环while(condition) statement 使用场景：对一行内的多个字段逐一类似处理时使用；对数组中的各元素逐一处理时使用； 123$ awk '/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;print $i,length($i); i++&#125;&#125;' /etc/grub2.cfg$ awk '/^[[:space:]]*linux16/&#123;i=1;while(i&lt;=NF) &#123;if(length($i)$=7) &#123;print $i,length($i)&#125;; i++&#125;&#125;' /etc/grub2.cfg do-while循环do statement while(condition) 意义：至少执行一次循环体 for循环 for(expr1;expr2;expr3) statement: 普通 for 循环 for(var in array) {for-body：遍历数组的特殊语法格式 1$ awk &apos;/^[[:space:]]+linuxefi/&#123;for(i=1;i&lt;NF;i++)&#123;if(length($i)$5)&#123;print $i,length($i)&#125;&#125;&#125;&apos; /boot/grub2/grub.cfg switch语句switch(expression) {case VALUE1 or /REGEXP/: statement; case VALUE2 or /REGEXP2/: statement; ...; default: statement} nextawk 内自动按行进行遍历，awk 内的循环主要用来遍历每行内的所有字段，next 是 awk 特有的，用来提前结束 awk 内对本行的处理而直接进入下一行； 1$ awk -F: '&#123;if($3%2!=0) next; print $1,$3&#125;' /etc/passwd 2.5 关联数组array[index-expression] index-expression: 可使用任意字符串；字符串要使用双引号； 如果某数组元素事先不存在，在引用时，awk会自动创建此元素，并将其值初始化为“空串”，如果用于数值运算，默认为 0； 若要判断数组中是否存在某元素，要使用 index in array 格式进行； 若要遍历数组中的每个元素，要使用for循环，注意 for 循环迭代的是下标不是值； for(var in array) {for-body} 1234567891011$ awk 'BEGIN&#123;weekdays["mon"]="Monday";weekdays["tue"]="Tuesday";for(i in weekdays) &#123;print weekdays[i]&#125;&#125;'$ ss -tan|awk '&#123;stat[$1]+=1;&#125;END&#123;for(i in stat)&#123;print i,stat[i]&#125;&#125;'$ awk '&#123;ip[$1]++&#125;END&#123;for(i in ip) &#123;print i,ip[i]&#125;&#125;' /var/log/httpd/access_log# 练习1：统计/etc/fstab文件中每个文件系统类型出现的次数；$ awk '/^UUID/&#123;fs[$3]++&#125;END&#123;for(i in fs) &#123;print i,fs[i]&#125;&#125;' /etc/fstab# 练习2：统计指定文件中每个单词出现的次数；$ awk '&#123;for(i=1;i&lt;=NF;i++)&#123;count[$i]++&#125;&#125;END&#123;for(i in count) &#123;print i,count[i]&#125;&#125;' /etc/fstab 2.6 函数函数调用使用 function_name(argu1, argu2, ...) 内置函数 数值处理： rand()：返回0和1之间一个随机数； 字符串处理： length([s])：返回指定字符串的长度； sub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其第一次出现替换为s所表示的内容； gsub(r,s,[t])：以r表示的模式来查找t所表示的字符中的匹配的内容，并将其所有出现均替换为s所表示的内容； split(s,a[,r])：以r为分隔符切割字符s，并将切割后的结果保存至a所表示的数组中； 1$ netstat -tan | awk &apos;/^tcp\&gt;/&#123;split($5,ip,&quot;:&quot;);count[ip[1]]++&#125;END&#123;for (i in count) &#123;print i,count[i]&#125;&#125;&apos;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.5 sed命令应用与实战]]></title>
    <url>%2F2018%2F01%2F23%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fsed%E5%91%BD%E4%BB%A4%E5%BA%94%E7%94%A8%E4%B8%8E%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[sed命令应用与实战 Linux 中有文本处理三剑客 grep, egrep, fgrep：文本过滤器 sed：Stream EDitor，流编辑器，行 awk：文本格式化工具，报告生成器 前面我们已经介绍了grep 命令的使用，本节我们来讲解 sed 。sed 是基于行的文本处理工具，其处理文件使用的命令与 vim 命令行很相似由，地址定界+编辑命令组成，地址定界用于铆定要处理的行，编辑命令指定编辑操作。相比于 vim，sed 无需将整个文本加载至内存，因此 sed 更适用于文件太大而不便使用 vim 打开的情景。本节我们会详细介绍 sed 命令的使用，内容如下: sed 工作原理 sed 命令的使用 1. sed 工作原理 如图是 sed 命令工作流程的示意图。sed 有两个专用的内存空间，一个叫模式空间(Pattern Space)，用于暂存地址定界匹配到的行，这些行会被接下来的 Edit 编辑命令编辑；另一个是保持空间(Hold Space)，我的理解是这就是一个临时的交换空间，可以辅助模式空间完成多行处理。我们会在后面详细介绍如何使用保持空间完成一些高级操作。 整个处理过程是。文件按行被读取，如果不能被地址定界所匹配，默认直接输出到标准输出(1)，被匹配的行进入模式空间，被 Edit 编辑命令处理，然后输出到标准所输出(2)。如果指定了原处修改源文件的 -i 选项，原本输出到标准输出的数据流将被重定向到原文件。编辑命令中有个 p 命令，其作用是将匹配到的行复制一遍再一次输出到标准输出(3) 上述过程中，我们描述了(1)(2)(3) 三种输出到标准输出的情况，sed 的 -n 选项可以禁止(1)(2)输出到标准输出。 2 sed 使用sed [OPTION]… ‘script’ [input-file] … 说明: sed 命令由选项和处理文件的 script 脚本组成 options： -n：不输出模式空间中的内容至屏幕，具体控制见原理部分 -f /PATH： 指定包含 script 的文件，逐行执行内部的编辑命令 -r, --regexp-extended：支持使用扩展正则表达式； -i, --in-place：直接编辑原文件 ； -e script：多点编辑,可使用多次，指定多个编辑脚本，文件将按行被每个命令处理； script： 格式: 地址定界+命令，多个命令使用 “;” 隔开 地址定界 位置表示 作用 空地址 对全文进行处理 # 数字，指定行 #,# 指定行范围，从哪一行开始，哪一行结束 #,+# 从哪一行开始，往下几行；例如：3,+7 $ 最后一行，要使用 ‘’ 引用 script，否则 $ 会解释为引用变量值 1,$ 第一行到最后一行 /pattern/ 被此模式所匹配到的每一行 /pat1/,/pat2/ 第一次由pat1匹配到的行，至第一次由pat2匹配到的行之间的所有行 #，/pat1/ # 指定的行到/pat1/匹配到的第一行之间的行 a～b 步进,从 a 行开始，每隔 b 取一行 1~2 所有奇数行 2~2 所有偶数行 编辑命令： d：删除模式空间中的内容 p：额外显示模式空间中的内容； a \text：在匹配行后面追加文本“text”，支持使用\n实现多行追加； i \text：在匹配行前面插入文本“text”，支持使用\n实现多行插入； c \text：把匹配到的行替换为此处指定的文本“text”； w /PATH：保存模式空间匹配到的行至指定的文件中； r /PATH：读取指定文件的内容至当前文件被模式匹配到的行后面；文件合并； eg: sed &#39;6r /home/tao/log.csv&#39; /etc/fstab =：为模式匹配到的行打印行号； !：条件取反；位于编辑命令之前，表示地址定界之前的行 格式: 地址定界!编辑命令； eg: sed &#39;/^UUID/!d&#39; /etc/fstab s///：查找替换，其分隔符可自行指定，常用的有s@@@, s###等； 替换标记： g：全局替换； w /PATH/TO/SOMEFILE：将替换成功的结果保存至指定文件中； p：显示替换成功的行； eg: sed &#39;/^UUID/s/UUID/uuid/g&#39; /etc/fstab sed &#39;s@r..t@&amp;er@&#39; /etc/passwd – &amp; 后项引用前面匹配到的内容 sed &#39;s@r..t@&amp;er@p&#39; /etc/passwd – 仅仅打印被替换的行 结合保持空间的高级编辑命令 命令 作用 h 把模式空间中的内容覆盖至保持空间中 H 把模式空间中的内容追加至保持空间中 g 把保持空间中的内容覆盖至模式空间中 G 把保持空间中的内容追加至模式空间中 x 把模式空间中的内容与保持空间中的内容互换 n 覆盖读取匹配到的行的下一行至模式空间中 N 追加读取匹配到的行的下一行至模式空间中 d 删除模式空间中的行 D 删除多行模式空间中的所有行 sed 多点编辑的执行逻辑1234567891011# 输出第二行内容&gt; sed -n -r &apos;6p&apos; fstab&gt; # Accessible filesystems, by reference, are maintained under &apos;/dev/disk&apos;# 对第六行执行替换，但是 -n 禁止了输出&gt; sed -r -n -e &apos;6s/Access/aaaa/&apos; fstab&gt;# 第六行被第一个 script 执行了替换，替换后的内容被第二个 script 输出&gt; sed -r -n -e &apos;6s/Access/aaaa/&apos; -e &apos;6p&apos; fstab&gt; # aaaaible filesystems, by reference, are maintained under &apos;/dev/disk&apos; 3. 示例：普通用法示例123456789# 删除/boot/grub/grub2.cfg文件中所有以空白字符开头的行的行首的所有空白字符；&gt; sed &apos;s@^[[:space:]]\+@@&apos; /etc/grub2.cfg# 删除/etc/fstab文件中所有以#开头的行的行首的#号及#后面的所有空白字符；&gt; sed &apos;s@^#[[:space:]]*@@&apos; /etc/fstab# 输出一个绝对路径给sed命令，取出其目录，其行为类似于dirname；&gt; echo &quot;/var/log/messages/&quot; | sed &apos;s@[^/]\+/\?$@@&apos;&gt; echo &quot;/var/log/messages&quot; | sed -r &apos;s@[^/]+/?$@@&apos; 使用保持空间的高级示例12345678sed -n &apos;n;p&apos; FILE：显示偶数行；sed &apos;1!G;h;$!d&apos; FILE：逆序显示文件的内容；sed ’$!d&apos; FILE：取出最后一行；sed &apos;$!N;$!D&apos; FILE：取出文件后两行；sed &apos;/^$/d;G&apos; FILE：删除原有的所有空白行，而后为所有的非空白行后添加一个空白行；sed &apos;n;d&apos; FILE：显示奇数行；sed &apos;G&apos; FILE：在原有的每行后方添加一个空白行；sed -n &apos;1!G;h;$p&apos;: 逆序显示文件的内容；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.4 文本处理命令]]></title>
    <url>%2F2018%2F01%2F22%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2F%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[文本处理命令 1. 文本处理工具trtr [OPTION]... SET1 [SET2] 作用: 将输入中 SET1中的每个字符替换SET2中的每个字符，字符是顺序替换 如果SET1的字符长度大于SET2，那么将SET1中多出来的字符用SET2中的最后一个字符替换 参数: -t: 将SET2中的每个字符替换SET1中的每个字符，字符字符顺序1对1替换，无论SET1还是SET2哪个长，只替换对应的字符，多出的不替换。 -c: 取反操作，取数据流中SET1中指定字符的补集。 -d: 删除SET1中指定的字符，这里没有SET2 -s: 将SET1中指定的连续的连续重复的字符用单个字符替代，可以使用-s ‘\n’删除空行。 字符编码集: [:alpha:]：字母，可以用来替代’a-zA-Z’ [:lower:]：小写字母,可以用来替代’a-z’ [:upper:]：大写字母,可以用来替代’A-Z’ [:digit:]：数字,可以用来替代’0-9’ [:alnum:]：字母和数字,可以用来替代’a-zA-Z0-9’ [:space:]：空白字符 [:punct:]：标点符号 [:xdigit:]：十六进制字符 [:cntrl:]：控制（非打印）字符 [:print:]：可打印字符 [:graph:]：图形字符 wcwc [-clw] [FILE...] 作用: 用于计算字数，可以计算文件的Byte数、字数、或是列数 若不指定文件名称、或是所给予的文件名为”-“，则wc指令会从标准输入设备读取数据 参数: -c, --bytes, --chars; 只显示Bytes数。 -l, --lines: 只显示行数。 -w, --words: 只显示单词数 cutcut [-df] [file] 作用: 从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出 参数： -d ：自定义分隔符，默认为制表符。 -f ：与-d一起使用，指定显示的区域，表示方式如下: n：指定的单个字段 n-m：连续的多个字段 n,m：离散的多个字段 -c ：以字符为单位进行分割 eg: cut -d: -f1,3-5,7 /etc/passwd sortsort [-frtknu] [file] 作用: 针对文本文件的内容，以行为单位来排序 参数: -t: 指定分隔符 -k POS1[,POS2]: 用于排序比较的字段 -f: 排序时，忽略大小写 -r: 逆序排序 -n: 基于数值大小而非字符进行排序 -u: 排序并去重 -b: 忽略每行前面开始出的空格字符 -c: 检查文件是否已经按照顺序排序。 -d: 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。 -m: 将几个排序好的文件进行合并 -o: 将排序后的结果存入指定的文件 uniquniq [-cdufsw][输入文件][输出文件] 作用: 检查文本文件中重复出现的行列 只有连续且一致的行才算重复行 参数: -c,--count: 显示每行的重复次数 -d, --repeated: 仅显示重复过的的行 -u, --unique: 仅显示未曾重复过的行 diff 和 patchdiff [OPTION]... FILES 作用: 按行比较文件 选项: -u: 使用unfied机制，即显示要修改的行的上下文，默认为3行； 补丁: diff /PATH/TO/OLDFILE /PATH/TO/NEWFILE &gt; /PATH/TO/PATCH_FILE patch -i /PATH/TO/PATCH_FILE /PATH/TO/OLDFILEpatch /PATH/TO/OLDFILE &lt; /PATH/TO/PATCH_FILE 作用: 向文件打补丁 patch -R /PATH/TO/PATCH_FILE /PATH/TO/OLDFILE 作用: 撤消补丁]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.3 grep命令与正则表达式]]></title>
    <url>%2F2018%2F01%2F21%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fgrep%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[grep命令与正则表达式 Linux 中有文本处理三剑客grep,sed,awk，它们都会用到正则表达式。bash 中正则表达式分为基础正则表达式和扩展的正则表达式。本节我们来学习 grep 命令与基本的正则表达式。 1. grepgrep 存在一组相关命令 grep: 支持基本的正则表达式 == grep -G egrep: 支持扩展的正则表达式 == grep -E fgrep: 不支持正则表达式，匹配速度快 == grep -F，无须转义 grep [-acinvAB] pattern filename -o：仅显示匹配到字符串本身 -a：将 binary 文件已 text 文件的方式查找数据 -c：计算找到”查找字符串” 的次数 -i：忽略大小写 -n：输出行号 -v：反向匹配 -q：静默模式，不输出匹配的文本，通过 echo $? 获取是否匹配成功 -A：after，后接数字，列出匹配行及之后 n 行 -B：before，后接数字，列出匹配行及之前 n 行 -C：context，上下文，列出匹配前后各 n 行 --color=auto：将找到的关键词高亮显示 2. 基础正则表达式基础正则表达式大致上可以分为四类: 字符匹配 匹配次数 位置锚定 分组及引用 需要额外说明的是下面的\转义符是必须的，因为这些元字符在 bash 中有特殊含义，需要转义。 字符匹配 元字符 作用 . 匹配任意单个字符 [] 匹配指定范围内的任意单个字符 [^] 匹配指定范围外的任意单个字符 [[:digit:]] 数字 [[:lower:]] 小写字母 [[:upper:]] 大写字母 [[:alpha:]] 字母 [[:alnum:]] 数字+字母 [[:punct:]] 特殊符号 [[:space:]] 空白字符 匹配次数用在要指定其出现的次数的字符的后面，用于限制其前面字符出现的次数；默认工作于贪婪模式； 元字符 作用 * 匹配其前面的字符任意次；0,1,多次 .* 匹配任意长度的任意字 \? 匹配其前面的字符0次或1次；即其前面的字符是可有可无的 \+ 匹配其前面的字符1次或多次；即其面的字符要出现至少1次 \{m\} 匹配其前面的字符m次 \{m,n\} 匹配其前面的字符至少m次，至多n次 \{0,n\} 至多n次 \{m,\} 至少m次 位置锚定匹配单词或句子的首部或尾部 元字符 作用 ^ 行首锚定；用于模式的最左侧 $ 行尾锚定；用于模式的最右侧 ^PATTERN$ 用于PATTERN来匹配整行 ^$ 匹配空白行 ^[[:space:]]*$ 空行或包含空白字符的行 \&lt; 或 \b 词首锚定，用于单词模式的左侧 \&gt; 或 \b 词尾锚定，用于单词模式的右侧 \&lt;PATTERN\&gt; 匹配完整单词 分组及引用\(\): 将一个或多个字符捆绑在一起，当作一个整体进行处理 分组括号中的模式匹配到的内容会被正则表达式引擎自动记录于内部的变量中，比如： \1：表示模式从左侧起，第一个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \2：表示模式从左侧起，第二个左括号以及与之匹配的右括号之间的模式所匹配到的字符 \n：其他一次类推，这种引用前面的分组括号中的模式所匹配到的字符叫做后向引用 12345678910111213141516171819202122练习：# 显示/etc/passwd文件中不以/bin/bash结尾的行；&gt; grep -v &quot;/bin/bash$&quot; /etc/passwd# 找出/etc/passwd文件中的两位数或三位数；&gt; grep &quot;\&lt;[0-9]\&#123;2,3\&#125;\&gt;&quot; /etc/passwd# 找出/etc/rc.d/rc.sysinit或/etc/grub2.cfg文件中，以至少一个空白字符开头，且后面非空白字符的行；&gt; grep &quot;^[[:space:]]\+[^[:space:]]&quot; /etc/grub2.cfg# 找出&quot;netstat -tan&quot;命令的结果中以&apos;LISTEN&apos;后跟0、1或多个空白字符结尾的行；&gt; netstat -tan | grep &quot;LISTEN[[:space:]]*$&quot;&gt; vim a.txtHe loves his lover.He likes his lover.She likes her liker.She loves her liker.&gt; grep &quot;\(l..e\).*\1&quot; a.txtHe loves his lover.She likes her liker. 3. 扩展正则表达式扩展正则表达式与基本正则表达式主要有两点区别 不需要额外的转义符\,词首词尾锚定仍为 \&lt;,\&gt;, \b 支持 | 表示或 a|b：a或者b； C|cat：C或cat (c|C)at：cat或Cat 123456789101112131415161718192021222324# 练习：# 1. 找出/proc/meminfo文件中，所有以大写或小写S开头的行；至少有三种实现方式；&gt; grep -i &quot;^s&quot; /proc/meminfo&gt; grep &quot;^[sS]&quot; /proc/meminfo&gt; grep -E &quot;^(s|S)&quot; /proc/meminfo# 2. 显示肖前系统上root、centos或user1用户的相关信息；&gt; grep -E &quot;^(root|centos|user1)\&gt;&quot; /etc/passwd# 3. 找出/etc/rc.d/init.d/functions文件中某单词后面跟一个小括号的行；&gt; grep -E -o &quot;[_[:alnum:]]+\(\)&quot; /etc/rc.d/init.d/functions# 4. 使用echo命令输出一绝对路径，使用egrep取出基名；&gt; echo /etc/sysconfig/ | grep -E -o &quot;[^/]+/?$&quot;# 5. 进一步：取出其路径名；类似于对其执行dirname命令的结果；# 6. 找出ifconfig命令结果中的1-255之间的数值；&gt; ifconfig | grep -E -o &quot;\&lt;([1-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\&gt;&quot;# 7. 课外作业：找出ifconfig命令结果中的IP地址；# 8. 添加用户bash, testbash, basher以及nologin(其shell为/sbin/nologin)；找出/etc/passwd文件中用户名同shell名的行；&gt; grep -E &quot;^([^:]+\&gt;).*\1$&quot; /etc/passwd]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.2 文件查找工具]]></title>
    <url>%2F2018%2F01%2F20%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2F%E6%96%87%E4%BB%B6%E6%9F%A5%E6%89%BE%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[文件查找工具 本节我们学习文件查找工具，主要是两个命令的使用 locate，find。 1. locatelocate [OPTION]... PATTERN... 作用: 依赖于事先构建好的索引库；查找指定模式匹配的文件 规则: 默认使用 pattern 进行全路径模糊匹配 参数: PATTERN: 匹配规则，可多个 选项: -a：所有 pattern 的匹配规则必须同时满足 -b：只匹配路径中的基名，默认匹配整个路径； -c：统计出共有多少个符合条件的文件 -r：使用基本正则表达式进行匹配 特性： 查找速度快； 模糊查找； 非实时查找； updatedb: 作用: 构建 locate 所需的数据库(耗费资源) 附注: 索引构建过程需要遍历整个根文件系统，极消耗资源； 2. findfind [OPTION]... [查找起始路径] [查找条件] [处理动作] 查找起始路径：指定具体搜索目标起始路径；默认为当前目录； 查找条件：指定的查找标准，可以根据文件名、大小、类型、从属关系、权限等等标准进行；默认为找出指定路径下的所有文件； 处理动作：对符合查找条件的文件做出的操作，例如删除等操作；默认为输出至标准输出； 查找条件find 的查找条件可以通过选型或测试进行指定，较为常用的是测试，有如下几种测试条件 文件名: -name &quot;pattern&quot;: 支持使用通配符，仅仅匹配文件名称，必须是完全匹配文件名而不是部分匹配 -iname &quot;pattern&quot;: 忽略名称大小，必须是完整匹配文件名 -regex pattern: 使用正则表达式，必须完整匹配整个文件路径，不仅仅是文件名称 根据属主，属组 -user username: 查找属主为指定用户的文件 -group groupname: 查找属组为指定组的文件 -uid userid: 查找属主为指定 uid 的文件 -gid groupid: 查找属组为指定 gid 的文件 -nouser: 查找没有属主的文件 -nogroup: 查找没有属组的文件 eg: find /tmp -user root -ls 根据文件类型查找 -type TYPE: 查找指定类型的文件 f: 普通文件 d: 目录文件 l：符号链接文件 b：块设备 文件 c：字符设备文件 p：管道文件 s：套接字文件 组合条件 -a : and -o : or -not|！ : not eg： find /tmp \( -nouser -o -nogroup \) -ls find /tmp -nouser -ls -o -nogoroup -ls find /tmp \( -not -user root -a -not -name &quot;fstab&quot; \) -ls 附注: 处理动作仅限于位置相关的查找 文件大小 -size [+|-]#UNIT: UNIT: 查找单位，k，M，G eg: find /var -size +3k -exec ls -h {} \ 3k: 表示范围为 (2k, 3k] -3k: 表示范围为 [0, 2k] +3k: 表示范围为 (3k, ∞) 根据时间戳 以天为单位 -atime [+|-]# -mtime [+|-]# -ctime [+|-]# eg: find /var -atime 3 -ls 3: 表示[3, 4) +3 表示[4, ∞) -3 表示[0, 3） 以分钟为单位 -amin [+|-]# -mmin [+|-]# -cmin [+|-]# 根据权限查找 -perm [/|-]MODE eg: find /var -perm 640 -ls 640: 精确查找，0表示不考虑 /640: 任何一类用户(u,g,o)的权限中的任何一位(r,w,x)符合条件即满足，9位权限之间存在“或”关系； -640: 每一类用户(u,g,o)的权限中的每一位(r,w,x)同时符合条件即满足，9位权限之间存在“与”关系； 处理动作 -print: 默认动作，显示至屏幕 -ls: 类似对查找的文件执行 ls -l 命令 -delete: 删除查到到的文件 -fls /path: 查找到的所有文件的长格式信息保存至指定文件中 -ok COMMAND {} \; 对查找到的每个文件执行由 COMMAND指定的命令 对每个文件执行命令之前，都会交互式确认 {}：表示find 传递的文件名本身 \;:固定格式符 exec COMMAND {} \;:作用同 ok,但不会交互式确认 eg: find /tmp -nouser -exec chown root {} \; find /tmp -cmin -5 -exec mv {} {}.new \; {}：表示find 传递的文件名本身 需要注意的是 find 传递查找到的文件路径至后面的命令时，是先查找出所有符合条件的文件路径，并一次性传递给后面的命令；但是有些命令不能接受过长的参数，此时命令执行会失败；使用 find | xargs COMMAND 可规避此问题。xargs 命令可将参数一次一个传递给 COMMAND。 3. 练习123456789101112131415161718192021222324# 查找/var/目录属主为root且属组为mail的所有文件；&gt; find /var -user root -a -group mail# 查找/usr目录下不属于root、bin或hadoop的所用文件；&gt; find /usr -not -user root -a -not -user bin -a -not -user hadoop&gt; find /usr -not \(-user root -o -user bin -o -user hadoop\)# 查找/etc/目录下最近一周内其内容修改过的，且不属于root且不属于hadoop的文件；&gt; find /etc -mtime -7 -a -not \(-user root -o -user hadoop\)# 查找当前系统上没有属主或属组，且最近1个月内曾被访问过的文件；&gt; find / \(-nouser -o -nogroup\) -a -atime -30# 查找/etc/目录下大于1M且类型为普通文件的所有文件；&gt; find /etc -size +1M -type f# 查找/etc/目录所有用户都没有写权限的文件；&gt; find /etc/ -not -perm /222# 查找/etc/目录下至少有一类用户没有写权限；&gt; find /etc/ -not -perm -222# 查找/etc/init.d/目录下，所有用户都有执行权限且其它用户有写权限的文件；&gt; find /etc/init.d/ -perm -113]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7.1 vim使用]]></title>
    <url>%2F2018%2F01%2F19%2Flinux_mt%2F07-%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%2Fvim%E6%B7%B1%E5%85%A5%E8%AE%B2%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[vim使用 本章我们将学习与文本操作相关内容，包括: 文本处理相关命令 文本查找相关命令 正则表达式 vim 编辑器 vim(vi) 是 Linux 下最常用的文本编辑器，拥有众多快捷键和命令，学习曲线很陡峭。下面两幅图是 vim 快捷键的便捷记忆图。本节内容如下: 认识 vim 的三种模式 编辑模式又称命令模式 输入模式 末行模式 vim 编辑模式的常用命令 vim 末行模式的使用 vim 高级用法 vim 配置 1. 认识 vim 的三种模式1.1 vim 三种模式的转换默认使用 vim 打开文件后会进入编辑模式，编辑模式下不能使用退格和键盘直接修改文本内容，但是可以使用特定命令实现编辑功能。输入模式即我们通常可以使用键盘直接文本的模式，而末行模式，则是我们可以在 vim 的最后一行输入 vim 特有的命令实现编辑功能。三种模式使用特定命令可以实现转换。 编辑模式 –&gt; 输入模式 命令 作用 i insert, 在光标所在处输入 a append，在光标在处后方输入 o 在光标所在处的下方打开一个新行 I 在光标所在行的行首输入 A 在光标所在行的行尾输入 O 在光标所在处的上方打开一个新行 其他的模式转换 编辑模式 –&gt; 末行模式: : 输入模式 –&gt; 编辑模式: ESC 末行模式 –&gt; 编辑模式: ESC 末行模式与输入模式不能直接转换 1.2 使用 vin 打开和关闭文件使用 vim 打开文件vim [OPTION] .... FILE ..... +#：打开文件后，光标定位到 # 行，不加行号默认定位到最后一行 +/PATTERN: 打开文件后，光标处于 pattern 匹配到的第一行 vim 中保存文件 ZZ: 在编辑模式下直接保存并退出； :q: 退出 :w： 保存 :q!: 强制退出，不保存此前的编辑操作 :wq: 保存并退出； :x: 保存并退出； :w /PATH/TO/SOMEFILE 2. vim 编辑模式的常用命令vim 编辑模式下的常用命令大体可以分为分为光标跳转，编辑命令，其他命令三类。大多数命令都可以使用类似 nCOMMAND 的方式，即在命令前加上数字，表示重复执行该命令 n 次。对于能这样使用的命令，下面将直接标注为 nCOMMANDA。 Linux 有个vim自带的练习教程叫 vimtutor 2.1 光标跳转所谓光标跳转即让光标从当前位置迅速跳转到特定位置，包括字符跳转，单词跳转，行首行尾跳转，行间跳转，句间跳转，段落跳转。 字符间跳转nCOMMAND 跳转由 n 指定的个数的字符； 命令 作用 h 左，支持 nCOMMAND j 下，支持 nCOMMAND k 上，支持 nCOMMAND l 右，支持 nCOMMAND 单词间跳转 命令 作用 w 下一个单词的词首，支持nCOMMAND e 当前或后一个单词的词尾，支持nCOMMAND b 当前或前一个单词的词首，支持nCOMMAND 行首行尾跳转 命令 作用 ^ 跳转至行首的第一个非空白字符 0 跳转至行首 $ 跳转至行尾 行间跳转 命令 作用 nG 跳转至由 n 指定的行 1G, gg 跳转到第一行 G 跳转到最后一行 句间跳转： ): 跳转到句尾 (: 跳转到句首 段间跳转 }: 跳转到段尾 {: 跳转到段首 2.2 编辑命令编辑命令指删除特定字词句，这部分命令可结合跳转命令实现批量修改。 字符编辑： 命令 作用 x 删除光标所在处的字符 nx 删除光标所在处起始的 n 个字符 xp 交换光标所在处的字符与其后面的字符的位置 rCHAR replace,使用 CHAR 字符替换光标所在处的字符 删除命令d delete 删除命令，可结合光标跳转字符，实现范围删除，支持 nCOMMANDA 命令 作用 d$ 删除光标到行尾 d^ 删除光标到非空白首部 dw 删除光标到下个词词首 ndw 删除光标到下 n 个词词首 de 删除光标到当前词词尾 db 删除光标到当前词词首 dd 删除光标所在处的行 ndd 删除光标所处的行起始的共 n 行 粘贴命令：p (put, paste) 粘贴命令 命令 作用 p 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的下方；否则，则粘贴至当前光标所在处的后方 P 缓冲区中的内容如果为整行，则粘贴在当前光标所在行的上方；否则，则粘贴至当前光标所在处的前方 复制命令y yank 复制命令，工作行为相似于d命令； 命令 作用 y$ 复制光标到行尾 y^ 复制光标到非空白首部 yw 复制光标到下个词词首 nyw 复制除光标到下 n 个词词首 ye 复制光标到当前词词尾 yb 复制光标到当前词词首 yy 复制光标所在处的行 nyy 复制除光标所处的行起始的共 n 行 改变命令c change 改变命令，功能同 d 命令，操作完成后会从编辑模式切换到输入模式 命令 作用 c$ 删除光标到行尾 c^ 删除光标到非空白首部 cw 删除光标到下个词词首 ncw 删除光标到下 n 个词词首 ce 删除光标到当前词词尾 cb 删除光标到当前词词首 cc 删除光标所在处的行 ncc 删除光标所处的行起始的共 n 行 2.3 其它编辑操作其他编辑操作如下 可视化模式可视化模式，可让用户在编辑模式下，非整行扩行选定文本片段 v,箭头: 按住 v 后，使用箭头按字符选定文本； V,箭头: 按住 V 后，使用箭头按行选定文本； 附注: 结合编辑命令 d, c, y，实现选定区域的删除复制 撤销和重复执行 命令 作用 u undo 撤销此前的操作 #u 撤销此前的#个操作 Ctrl+r recover 撤销此前的撤销 . 重复执行前一个编辑操作 3. vim 末行模式的使用vim末行模式，是 vim 内建的命令行接口，通过地址定界和之前介绍的编辑命令，可实现批量操作。所谓地址定界即选择出特定范围的行。除此之外 vim 还能实现保存，查找，替换等诸多功能。 3.1 地址定界地址定界的格式是 :start_pos[,end_pos]，位置的表示可以是数字也可以是正则表达式，具有多种表达方式 位置表示 作用 # 数字，表示特定的第#行，例如5即第5行 #,# 指定行范围，左侧为起始行，右侧为结束行 #,+# ：指定行范围，左侧为超始行绝对编号，右侧为相对左侧行号的偏移量；例如：3,+7 . 表示当前行 $ 最后一行 .,$-1 当前行到倒数第二行 1,$ 第一行到最后一行，即全文 % 全文，等同于 1,$ /pattern/ 从光标所在处起始向文件尾部第一次被模式所匹配到的行, 例如/first/,$ /pat1/,/pat2/ 从光标所在处起始，第一次由pat1匹配到的行开始，至第一次由pat2匹配到的行结束之间的所有行 地址定界可同编辑命令 d,y,c一同使用，实现编辑操作。例如 :1,20d 删除 1 到 20 行。 3.2 保存和加载末行模式中保存和加载其他文件的常用命令如下 命令 作用 :q 退出 :w 保存 :q! 强制退出，不保存此前的编辑操 :wq 保存并退出 :x 保存并退出 :w /PATH/TO/SOMEFILE 将文本保存至指定的文件中，可通过地址定界选定保存的文本范围 :r /PATH/FROM/SOMEFILE 将指定的文件中的文本读取并插入至指定位置 3.3 查找通过 / 或 ？ 命令，可在 vim 中实现查找 /PATTERN：从当前光标所在处向文件尾部查找能够被当前模式匹配到的所有字符串； ?PATTERN：从当前光标所在处向文件首部查找能够被当前模式匹配到的所有字符串； 查找后，可使用 n，N 查找下一个 n：查找下一个，表示与命令方向相同的下一个； N：查找上一个，表示与命令方向相反的上一个； 3.4 查找并替换末行模式中通过 s 命令可实现替换功能，s 命令的使用格式如下::地址定界s/要查找的内容/替换为的内容/修饰符 要查找的内容：可使用基本正则表达式； 替换为的内容：不能使用下则表达式，但可以引用； 修饰符： i：忽略大小写； g：全局替换，意味着一行中如果匹配到多次，则均替换； 分隔符/:可把替换为其它非常用字符@ 或 #： s@@@ s### 引用: 如果”要查找的内容”部分在模式中使用了分组符号可在”替换为的内容”中使用后向引用； 直接引用查找模式匹配到的全部文本，要使用&amp;符号； 示例: %s@\&lt;t\([[:alpha:]]\+\)\&gt;@T\1@g: 将以小写 t 开头的字母替换为大写 T开头 %s@\&lt;t[[:alpha:]]\+\&gt;@&amp;er@g: 在所哟单词后面加上 er 123456789101112131415练习：# 1. 复制/etc/grub2.cfg文件至/tmp目录中，用查找替换命令删除/tmp/grub2.cfg文件中以空白字符开头的行的行首的空白字符；&gt; %s@^[[:space:]]\+@@&gt; %s/^[[:space:]]\+//# 2. 复制/etc/rc.d/init.d/functions文件至/tmp目录中，用查找替换命令为/tmp/functions文件的每个以空白字符开头的行的行首加上#；&gt; %s@^[[:space:]]\+[^[:space:]]@#&amp;@g&gt; %s/^([[:space:]]\+)/#&amp;/g# 3. 为/tmp/grub2.cfg文件的前三行的行首加上#号；&gt; 1,3s/.*/#&amp;/g# 4. 将/etc/yum.repos.d/CentOS-Base.repo文件中所有的enabled=0替换为enabled=1，所有gpgcheck=0替换为gpgcheck=1；&gt; %s/\(enabled\|gpgcheck\)=0/\1=1/g&gt; %s@\(enabled\|gpgcheck\)=0@\1=1@g 4. vim 高级用法多文件模式vim /tmp/{file1，file2} :next: 切换至下一文件 :prev: 切换至上一个文件 :last: 切换至最后一个文件 :first: 切换至第一个文件 :wall：保存所有 :qall：退出所有 :wqall: 保存并退出所有 窗口分割vim -o FILE1 FILE2.... 水平分割vim -O FILE1 FILE2.... 垂直分割 Ctrl + w 松开后，加箭头: 切换窗口 Ctrl + w, s: 水平分割当前文件 Ctrl + w, v: 垂直分割当前文件 5. vim 配置vim 的配置可在末行模式下设定，此时仅对当前vim进程有效；要想永久有效可编辑配置文件 全局配置：/etc/vimrc 用户个人配置：～/.vimrc vim 中常见的配置选项 作用 配置 行号 显示：set number, 简写为set nu 取消显示：set nomber, set nonu 括号匹配高亮 匹配：set showmatch, set sm取消：set nosm 自动缩进 启用：set ai禁用：set noai 高亮搜索 启用：set hlsearch禁用：set nohlsearch 语法高亮 启用：syntax on禁用：syntax off 忽略字符大小写 启用：set ic禁用：set noic]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.9 脚本示例与练习]]></title>
    <url>%2F2018%2F01%2F18%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E8%84%9A%E6%9C%AC%E7%A4%BA%E4%BE%8B%E4%B8%8E%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[脚本示例与练习 本节是一些常用的脚本示例，可供我们学习参考 1. 条件判断练习更改主机名将当前主机名称保存至hostName变量中；主机名如果为空，或者为localhost.localdomain，则将其设置为www.magedu.com；12&gt; hostName=$(hostname)&gt; [ -z &quot;$hostName&quot; -o &quot;$hostName&quot; == &quot;localhost.localdomain&quot; -o &quot;$hostName&quot; == &quot;localhost&quot; ] &amp;&amp; hostname www.magedu.com 比较求大者通过命令行参数给定两个数字，输出其中较大的数值；1234567891011121314#!/bin/bash#if [ $# -lt 2 ]; then echo "Two integers." exit 2fideclare -i max=$1if [ $1 -lt $2 ]; then max=$2fiecho "Max number: $max." 2. 命令行参数判断用户ID 奇偶通过命令行参数给定一个用户名，判断其ID号是偶数还是奇数； 比较文件行数通过命令行参数给定两个文本文件名，如果某文件不存在，则结束脚本执行；都存在时返回每个文件的行数，并说明其中行数较多的文件； 3. for 循环练习添加用户12345678910111213#!/bin/bash#for username in user21 user22 user23; do if id $username &amp;&gt; /dev/null; then echo "$username exists." else useradd $username if [ $? eq 0 ]; then echo "$username" | passwd --stdin "$username" &amp;&gt; /dev/null echo "Add $username finished" fi fidone 求和123456789#!/bin/bash# 示例：求100以内所有正整数之和；declare -i sum=0for i in &#123;1..100&#125;; do echo "\$sum is $sum, \$i is $i" sum=$[$sum+$i]doneecho $sum 判断文件类型12345678910111213141516171819#!/bin/bash# 示例：判断/var/log目录下的每一个文件的内容类型for filename in /var/log/*; do if [ -f $filename ]; then echo "Common file." elif [ -d $filename ]; then echo "Directory." elif [ -L $filename ]; then echo "Symbolic link." elif [ -b $filename ]; then echo "block special file." elif [ -c $filename ]; then echo "character special file." elif [ -S $filename ]; then echo "Socket file." else echo "Unkown." fi done 12345678#!/bin/bash# 打印成法口诀表for i in &#123;1..9&#125;; do for j in $(seq 1 $i); do echo -e -n "$&#123;i&#125;X$&#123;j&#125;=$[$i*$j]\t" done echodone 4. 类 C 风格for 循环求和1234567891011121314151617181920212223# 示例：求100以内所有正整数之和#!/bin/bash#declare -i sum=0for ((i=1;i&lt;=100;i++)); do let sum+=$idoneecho "Sum: $sum."``` ### 打印九九乘法表```bash# 示例：打印九九乘法表#!/bin/bash#for ((j=1;j&lt;=9;j++)); do for ((i=1;i&lt;=j;i++)); do echo -e -n "$&#123;i&#125;X$&#123;j&#125;=$[$&#123;i&#125;*$&#123;j&#125;]\t" done echodone 5. 显示一个菜单给用户要求12345678# 显示一个如下的菜单给用户# cpu) display cpu information# mem) display memory information# disk) display disks information# quit) quit# 要求：(1) 提示用户给出自己的选择；# (2) 正确的选择则给出相应的信息；否则，则提示重新选择正确的选项； bash 脚本123456789101112131415161718192021222324252627#!/bin/bash#cat &lt;&lt; EOFcpu) display cpu informationmem) display memory infomationdisk) display disks informationquit) quit===============================EOFread -p "Enter your option: " optionwhile [ "$option" != "cpu" -a "$option" != "mem" -a "$option" != "disk" -a "$option" != "quit" ]; do echo "cpu, mem, disk, quit" read -p "Enter your option again: " optiondoneif [ "$option" == "cpu" ]; then lscpuelif [ "$option" == "mem" ]; then free -melif [ "$option" == "disk" ]; then fdisk -l /dev/[hs]d[a-z]else echo "quit" exit 0fi 6. 服务框架脚本要求12345# 示例：写一个服务框架脚本；# $lockfile, 值/var/lock/subsys/SCRIPT_NAME# (1) 此脚本可接受start, stop, restart, status四个参数之一；# (2) 如果参数非此四者，则提示使用帮助后退出；# (3) start，则创建lockfile，并显示启动；stop，则删除lockfile，并显示停止；restart，则先删除此文件再创建此文件，而后显示重启完成；status，如果lockfile存在，则显示running，否则，则显示为stopped. bash 脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/bash## chkconfig: - 50 50# description: test service script#prog=$(basename $0)lockfile=/var/lock/subsys/$progcase $1 instart) if [ -f $lockfile ]; then echo "$prog is running yet." else touch $lockfile [ $? -eq 0 ] &amp;&amp; echo "start $prog finshed." fi ;;stop) if [ -f $lockfile ]; then rm -f $lockfile [ $? -eq 0 ] &amp;&amp; echo "stop $prog finished." else echo "$prog is not running." fi ;;restart) if [ -f $lockfile ]; then rm -f $lockfile touch $lockfile echo "restart $prog finished." else touch -f $lockfile echo "start $prog finished." fi ;;status) if [ -f $lockfile ]; then echo "$prog is running" else echo "$prog is stopped." fi ;;*) echo "Usage: $prog &#123;start|stop|restart|status&#125;" exit 1esac]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.8 bash 配置文件]]></title>
    <url>%2F2018%2F01%2F17%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fbash%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[bash 配置文件 bash 的配置文件也是 shell 脚本，用于定义环境变量，别名或运行一些特殊用途的脚本。比如一些特殊用途的别名，我们不想每次登陆 shell 后都重新设置，可以定义在配置文件中；又比如想将一些特定目录添加到 PATH 环境变量中等等。要理解 bash 的配置文件，我们首先需要明白 bash 的两种登陆类型，它们会分别读取不同的配置文件，所以本节的内容如下: bash 中的登陆类型 bash 配置文件类型 配置文件的生效过程 1. bash 中的登陆类型bash 中配置文件大致分为交互式登录和非交互式登录 两种类型。每种类型发生的情景对应如下: 交互式登录shell进程： 直接通过某终端输入账号和密码后登录打开的shell进程； 使用su命令：su - USERNAME, 或 su -l USERNAME 执行的登录切换； 非交互式登录shell进程： su USERNAME执行的登录切换； 图形界面下打开的终端； 运行脚本 2. bash的配置文件类型针对两种登陆类型，配置文件也分成了两类： profile类：为交互式登录的shell进程提供配置 bashrc类：为非交互式登录的shell进程提供配置 2.1 profile类配置文件profile: 作用: 用于定义环境变量； 运行命令或脚本； 位置: 全局配置：对所有用户都生效； /etc/profile /etc/profile.d/*.sh 用户个人：仅对当前用户有效； ~/.bash_profile 注意：仅管理员可修改全局配置文件； 2.2 bashrc类配置文件bashrc: 作用: 定义本地变量； 定义命令别名； 位置: 全局配置：/etc/bashrc 用户个人：~/.bashrc 注意：仅管理员可修改全局配置文件； 3. 配置文件的生效过程 交互式登录: /etc/profile --&gt; /etc/profile.d/* --&gt; ~/.bash_profile --&gt; ~/.bashrc --&gt; /etc/bashrc 非交互式登录: ~/.bashrc --&gt; /etc/bashrc --&gt; /etc/profile.d/* 需要注意的配置文件和命令行定义的配置具有不同的生效时间: 对于命令行，例如变量和别名作用域为当前shell进程的生命周期； 对于配置文件，虽然可以永久有效，但是只对随后新启动的shell进程才有效，对当前shell 无效；因此让配置文件定义的特性立即生效需要额外操作，有两种方法可供选择 通过命令行重复定义一次； 让shell进程重读配置文件； source /PATH/FROM/CONF_FILE . /PATH/FROM/CONF_FILE]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.7 程序交互与信号捕捉]]></title>
    <url>%2F2018%2F01%2F16%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E7%A8%8B%E5%BA%8F%E4%BA%A4%E4%BA%92%E5%92%8C%E9%80%80%E5%87%BA%E7%8A%B6%E6%80%81%2F</url>
    <content type="text"><![CDATA[程序交互，退出状态与信号捕捉 本节我们开始学习 bash shell 编程的第七部分，包含以下内容: 如何在程序执行过程中与用户交互 bash 编程调试 设置脚本执行的状态返回值 如何在 bash 中使用 ASCII 颜色 dialog 实现窗口化编程 信号捕捉 1. 用户交互bash 中与用户交互主要通过 read 命令完成，read 可以输出一段文字提示用户输入指定内容，并将用户输入保存在特定变量中，read 的使用方式如下 read [OPTIONS] [变量名 ...] 作用:从标准输入读取一行并将其分为不同的域 选项: -p 提示符: 用户提示符 -t 超时: 设置等待用户输入的超时时长，单位秒 -a 数组 -d 分隔符 -i 缓冲区文字 -n 读取字符数 -N 读取字符数 -u 文件描述符 1234567891011&gt; read -p &quot;enter a disk filename&quot; -t 5 name&gt; [ -z &quot;$name&quot; ] &amp;&amp; name=&quot;value&quot;&gt; read a bjerry mark cd&gt; echo $ajerry&gt; echo $b # 值个数多于变量个数时，所有多余的变量默认保存在最后一个变量中mark cd 2. bash 调试bash 命令有两个参数可以帮助我们调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 3. 脚本的状态返回值之前我们说过，程序执行有状态返回值，保存在 $? 变量中。shell 脚本的状态返回值有如下特点: 默认是脚本中执行的最后一条件命令的状态返回值 使用 exit [n] 可自定义退出状态码，n 位于 0-255 之间，0 表示执行成功无异常，默认为 0 exit 类似 python 中的return，程序遇到 exit 即终止 4. 在bash中使用ACSII颜色\033[31m hello \033[0m 格式: \033[31m 表示颜色控制开始符，\033[0m 表示颜色控制结束符，中间为要显示的文本 颜色控制: ##m(31m) - 左侧`#`： - 3：表示前景色 - 4：表示背景色 - 右侧 `#`: 表示颜色种类, 范围是 1, 2, 3, 4, 5, 6, 7 格式控制: #m(5m) 加粗、闪烁等功能； 组合: 多种控制符，可组合使用，彼此间用分号隔开； 12345678tao@hp:shell$ echo -e "\033[31m htto \033[0m" httotao@hp:shell$ echo -e "\033[41;32m htto \033[0m" httotao@hp:shell$ echo -e "\033[42;35;4m htto \033[0m"htto 5. dialog 实现窗口化编程123yum install dialog -ydialog --msgbox hello 17 30 本节我们来学习 bash shell 编程的第九部分如何在 shell 中捕捉信号。shell 中捕捉信号主要是使用 shell 内置的 trap 命令。shell 中的信号捕捉有以下几点需要特别注意。 15) SIGTERM 和 9) SIGKILL 信号是不可捕捉的，以防止不能终止进程。 bash 中的命令会以子进程运行，因此信号可能会被子进程捕获，执行脚本的进程因此可能无法捕获到信号。但是如果 trap 在子命令之前优先执行，信号则会优先被执行脚本的进程捕获。 程序执行过程中可能会产生很多临时文件或其他数据，正常结束时，这些临时文件都会被清理；但是如果程序执行过程中被 Ctrl-C 终止可能这些临时数据将无法被清除；因此可能需要捕捉 2) SIGINT 信号以清除执行程序时产生的临时文件。 6. 信号捕捉traptrap -l: 作用: 等同于 kill -l 列出所有信号 trap &#39;COMMAND&#39; SIGNALS 作用: 指定在接收到信号后将要采取的动作，常见的用途是在脚本程序被中断时完成清理工作 常可以进行捕捉的信号： 1) SIGHUP 2) SIGINT 12# 表示当shell收到HUP INT PIPE QUIT TERM这几个命令时，当前执行的程序会读取参数“exit 1”，并将它作为命令执行。trap "exit 1" HUP INT PIPE QUIT TERM 示例1234567891011121314151617181920212223#!/bin/bash#declare -a hosttmpfilestrap 'mytrap' INTmytrap() &#123; echo "Quit" rm -f $&#123;hosttmpfiles[@]&#125; exit 1&#125;for i in &#123;1..50&#125;; do tmpfile=$(mktemp /tmp/ping.XXXXXX) if ping -W 1 -c 1 172.16.$i.1 &amp;&gt; /dev/null; then echo "172.16.$i.1 is up" | tee $tmpfile else echo "172.16.$i.1 is down" | tee $tmpfile fi hosttmpfiles[$&#123;#hosttmpfiles[*]&#125;]=$tmpfiledonerm -f $&#123;hosttmpfiles[@]&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.6 函数和参数传递]]></title>
    <url>%2F2018%2F01%2F15%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%87%BD%E6%95%B0%E5%92%8C%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%2F</url>
    <content type="text"><![CDATA[函数和参数传递 本节我们来学习 bash shell 编程的第六部分参数传递与函数，包括以下内容: 如何向脚本传递参数 bash 函数 局部作用域 1. 参数传递1.1 位置参数所谓位置参数是 bash 中，脚本或函数接收参数的形式，除了位置参数，脚本中还内置了一些特殊参数，用于保存特定的值。参数的对应关系如下所示 myscript.sh argu1 argu2.... 位置参数: $1: 表示第一个位置参数 argu1 $2: 表示第二个位置参数 argu2 ${10}:表示第 10 个位置参数 argu10 ${11}:表示第 11 个位置参数 argu10,其他以此类推 特殊变量： $0：脚本文件路径本身； $#：脚本参数的个数； $*：由空格分隔的所有参数的字符串 “$1 $2 $n” $@：所有参数组成的列表 “$1”，”$2”，”$3”，”$n” 1.2 参数轮替shift [n] 作用：造成参数变量的号码偏移，即整体参数的右移 n：数字，默认为1，代表拿掉最前面几个参数的意思 2. 函数2.1 bash 函数特性函数是主要作用是实现代码重用，其在每次被调用时创建，返回时终止。bash 中的函数与 bash 脚本的使用方式基本是类似的。 函数的返回值函数的返回值也包括执行结果返回值和状态返回值 函数的执行结果返回值为代码的输出包括 函数中的打印语句：echo, print 函数中调用的系统命令执行后返回的结果 执行状态返回值： 默认是函数体中最后一次执行的命令状态结果 使用 return [0-255] 自定函数执行状态的返回值，不能使用 exit, exit 会直接退出脚本 函数参数函数也通过位置接收传递进来的参数，并且表示方法与脚本完全相同。因此函数内的 $n 参数并不是脚本中的 $n 参数。向函数传递参数时，在函数名后跟空白分隔参数列表即可，testfunc arg1 arg2 arg3 ... 函数作用域bash 函数默认与脚本共享同一作用域，函数内可以直接访问和修改脚本内变量的值。要想创建局部变量必需使用 local VARIABLE=VALUE。因此 bash 中的变量有三种: 局部变量：作用域是函数内；在函数结束时被自动销毁,因此不会影响脚本内同名变量的值 本地变量：作用域是当前shell脚本程序文件，在运行脚本的shell进程结束时被销毁 环境变量：作用域是当前进程及其子进程 因为函数内能直接修改脚本内变量的值，所以函数最好都使用局部变量，以免函数调用非预期的更改脚本内变量的值，引入难以调试的 bug。 2.2 定义语法：123456789# 方式一function F_NAME &#123; # 函数名后必需要有空格 函数体&#125;# 方式二F_NAME() &#123; # ()后必需要有空格 函数体&#125; 3. 函数使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 练习：写一个脚本，完成如下功能(使用函数)：# 1、提示用户输入一个可执行命令；# 2、获取这个命令所依赖的所有库文件(使用ldd命令)；# 3、复制命令至/mnt/sysroot/对应的目录中# 解释：假设，如果复制的是cat命令，其可执行程序的路径是/bin/cat，那么就要将/bin/cat复制到/mnt/sysroot/bin/目录中，如果复制的是useradd命令，而useradd的可执行文件路径为/usr/sbin/useradd，那么就要将其复制到/mnt/sysroot/usr/sbin/目录中；# 4、复制各库文件至/mnt/sysroot/对应的目录中；#!/bin/bash#target=/mnt/sysroot/[ -d $target ] || mkdir $targetpreCommand() &#123; if which $1 &amp;&gt; /dev/null; then commandPath=`which --skip-alias $1` return 0 else echo &quot;No such command.&quot; return 1 fi&#125;commandCopy() &#123; commandDir=`dirname $1` [ -d $&#123;target&#125;$&#123;commandDir&#125; ] || mkdir -p $&#123;target&#125;$&#123;commandDir&#125; [ -f $&#123;target&#125;$&#123;commandPath&#125; ] || cp $1 $&#123;target&#125;$&#123;commandDir&#125;&#125;libCopy() &#123; for lib in `ldd $1 | egrep -o &quot;/[^[:space:]]+&quot;`; do libDir=`dirname $lib` [ -d $&#123;target&#125;$&#123;libDir&#125; ] || mkdir -p $&#123;target&#125;$&#123;libDir&#125; [ -f $&#123;target&#125;$&#123;lib&#125; ] || cp $lib $&#123;target&#125;$&#123;libDir&#125; done&#125;read -p &quot;Plz enter a command: &quot; commanduntil [ &quot;$command&quot; == &apos;quit&apos; ]; do if preCommand $command &amp;&gt; /dev/null; then commandCopy $commandPath libCopy $commandPath fi read -p &quot;Plz enter a command: &quot; commanddone]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.5 字符串处理]]></title>
    <url>%2F2018%2F01%2F14%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[字符串处理 本节我们来学习 bash shell 编程的第五部分字符串处理，内容包括: 字符串的切片，基于位置取子穿 基于模式取子串 查找和替换 大小写转换 变量赋值操作 bash 中获取变量的值可以使用 ${VARIABLE},字符串操作就是在此基础上的扩展。 1. 字符串操作1.1 字符串切片：${string:offset:length} 作用: 正向切片，offset 表示偏移量，lenght 表示截取的字符个数 注意: bash 中字符串和数组一样，下标从 0 开始 ${string: -length} 作用: 反向切片，取尾部的指定个数的字符，- 前必须要有空格 1234567tao@hp:shell$ a=01234tao@hp:shell$ echo $&#123;a:1:2&#125;12tao@hp:shell$ echo $&#123;a: -2&#125;34 1.2 基于模式取子串需要特别注意的是，查找的关键字 word 只支持通配符 语法 作用 ${variable#*word} 自左而右，删除字符开始至第一次出现word ${variable##*word} 自左而右，删除字符开始至最后一次出现word ${variable%word*} 自右而左，删除第一次出现word至字串尾部 ${variable%%world*} 自右而左，删除最后一次出现word至字串尾部 12345678910111213141516171819tao@hp:~$ file='/var/log/messages'tao@hp:~$ echo $&#123;file#*/&#125;var/log/messagestao@hp:~$ echo $&#123;file##*/&#125;messagestao@hp:~$ echo $&#123;file%/*&#125;/var/logtao@hp:~$ echo $&#123;file%%/*&#125;tao@hp:~$ phonenumber='010-110-8'tao@hp:~$ echo $&#123;phonenumber%%-*&#125;010tao@hp:~$ echo $&#123;phonenumber%-*&#125;010-110tao@hp:~$ echo $&#123;phonenumber##*-&#125;8 1.3 查找替换：需要注意的是，pattern 只能使用通配符，省略 /SUBSTI 时表示查找删除 语法 作用 ${var/PATTERN/SUBSTI} 查找，第一次被 PATTERN 匹配到的字符串，替换为SUBSTI ${var//PATTERN/SUBSTI} 查找，所有被PATTERN 匹配到的字符串，替换为SUBSTI ${var/#PATTERN/SUBSTI} 查找，行首被PATTERN 匹配到的字符串，替换为SUBSTI ${var/%PATTERN/SUBSTI} 查找，行尾被PATTERN 匹配到的字符串，替换为SUBSTI 1.4 大小写转换： ${variable^^}: 小–&gt;大 ${variable,,}: 大–&gt;小 2. 变量赋值操作 变量设定方式 param 没有设定 param 为空 param 为非空字符串 var=${param-word} var=word var= var=$param var=${param:-word} var=word var=word var=$param var=${param+word} var= var=word var=word var=${param:+word} var= var= var=word var=${param=word} var=word param=word var= param= var=$param param 不变 var=${param:=word} var=word param=word var=word param=word var=$param param 不变 var=${param?word} word 输出到stderr var= var=$param var=${param:?word} word 输出到stderr word 输出到stderr var=$param 12# 为脚本使用配置文件，并确保某变量有可用值的方式variable=$&#123;variable:-default vaule&#125;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.4 数组与算数运算]]></title>
    <url>%2F2018%2F01%2F13%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组与算数运算 本节我们来学习 bash shell 编程的第四部分内容数组与算数运算。 1. 数组数组和字典是编程中非常常用的数据结构，但是 bash 对它们支持都比较有限。原因我们在本章第一节就说过，bash 本质上并不能算一种语言，因此也很少被拿来做复杂的编程。它更适合利用 Linux 中已有的命令完成特定功能。所以 bash 对复杂数据结构的支持很有限。bash 4.0 之后才开始支持字典，默认也只支持一维数组。下面我们将通过数组的声明，赋值和引用来讲解数组的使用。 bash 中字典又称为关联数组，使用方式与数组基本一致，只是将数字索引改为，字符串索引即可 1.1 数组声明数组和字典的声明: 数组声明: declare -a 字典声明: declare -A， bash 4.0及以上才支持，必需显示声明 1.2 数组的赋值bash 中的数组有多种赋值方式，常用的如下所示 赋值方式 语法 一次只赋值一个元素 a[0]=$RANDOM 一次赋值全部元素 a=(red blue yellow green) 只赋值特定元素 a=([0]=green [3]=red [2]=blue [6]=yellow) 用户输入 read -a ARRAY 12345678910# 数组赋值支持通配符logs=(/var/log/*.log)# 字典赋值declare -A worldworld[us]="america"echo "$&#123;world['us']&#125;"# 向非稀疏数组追加元素ARRAY[$&#123;#ARRAY[*]&#125;]=value 1.3 数组的访问变量引用可以使用 ${VARIABLE},而数组的访问就是在此基础上添加上要访问的索引。需要特别注意的是数组引用 {}不可省略，否则[index] 会被当作普通字符对待 用索引访问: ${ARRAY[index]} ${ARRAY}: 没有下标时，默认引用索引为 0 的元素 访问整个数组： ${ARRAY[@]}: 每个参数是一个独立的串 ${ARRAY[*]}: 所有参数是一个串 数组切片: ${ARRAY[@]:offset:number}: 取出偏移两之后特定数量的元素 ${ARRAY[@]:offset}：取出偏移量后的所有元素 ${ARRAY[@]}: 取出所有元素 说明: offset是偏移的元素个数,number 是取出的元素的个数 1234567891011# 获取数组的长度: echo $&#123;#ARRAY[*]&#125;`echo $&#123;#ARRAY[@]&#125;`# 获取数组第 0 个元素的字符串长度echo $&#123;#ARRAY&#125;tao@hp$ world[0]=ustao@hp$ echo $&#123;#world[*]&#125; # 数组长度1tao@hp$ echo $&#123;#world&#125; # 数组 0 元素的字符长度2 1.4 从数组中删除元素：unset ARRAY[index] 2. 数组使用示例示例 1定义一个数组，数组中的元素是/var/log目录下所有以.log结尾的文件；统计其下标为偶数的文件中的行数之和； 1234567891011121314#!/bin/bash#declare -a filesfiles=(/var/log/*.log)declare -i lines=0for i in $(seq 0 $[$&#123;#files[*]&#125;-1]); do if [ $[$i%2] -eq 0 ]; then let lines+=$(wc -l $&#123;files[$i]&#125; | cut -d' ' -f1) fidoneecho "Lines: $lines." 示例 2生成10个随机数，升序排序 12345678910111213141516171819202122#!/bin/bash#for((i=0;i&lt;10;i++))do rnd[$i]=$RANDOMdoneecho -e "total=$&#123;#rnd[@]&#125;\n$&#123;rnd[@]&#125;\nBegin to sort"for((i=9;i&gt;=1;i--))do for((j=0;j&lt;i;j++)) do if [ $&#123;rnd[$j]&#125; -gt $&#123;rnd[$[$j+1]]&#125; ] ;then swapValue=$&#123;rnd[$j]&#125; rnd[$j]=$&#123;rnd[$[$j+1]]&#125; rnd[$[$j+1]]=$swapValue fi donedoneecho $&#123;rnd[@]&#125; 2. 算术运算bash 是弱类型编程语言，所有变量的默认类型是字符串。因此算术运算必需借助特定的命令来实现。同时 bash 中默认也不支持浮点数，当然也几乎用不到 常见的算术运算符包括 +，-，*，/, **, %，bash中实现算术运算有如下几种方式: let var=3+4: let 不会打印输出，只能使用变量进行保存 let count+=2: let 支持增量赋值 +=，-=，*=, /=, %= let count++: let 支持自增运算 var=$[$var+1] var=$(($var+1)) var=$(expr 3 \* 4): 运算符和操作数之间必须使用空格分割，* 需要转义 $RANDOM: bash 内置的随机数生成器，表示 1-32767 的随机数 echo $[$RANDOM%60] 注意：乘法符号在有些场景中需要使用转义符； 1234567脚本练习：# 计算/etc/passwd文件中的第10个用户和第20个用户的id号之和；id1=$(head -10 /etc/passwd | tail -1 | cut -d: -f3)id2=$(head -20 /etc/passwd | tail -1 | cut -d: -f3)# 计算/etc/rc.d/init.d/functions和/etc/inittab文件的空白行数之和；grep &quot;^[[:space:]]*$&quot; /etc/rc.d/init.d/functions | wc -l]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.3 循环]]></title>
    <url>%2F2018%2F01%2F12%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2F%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[循环 本节我们来学习 bash shell 编程的第三部分循环，包括以下内容: for 循环 while 循环 until 循环 循环体内的控制语句 continue, break 1. for 循环for 循环通过遍历列表的方式执行循环，列表生成有如下几种方式 1.1 列表生成方式 直接给出:user1 user2 user3 整数列表 {start..end}: 使用内置关键字{} 生成整数列表 $(seq [start [incremtal]] last): 使用 seq 命令生成整数列表 返回列表的命令，例如 ls 命令 glob 通配符，例如 for file in /var/*; do; done 变量引用，例如 $*, $@ 1.2 for 循环语法for 循环的语法，及其使用示例如下所示123for VARAIBLE in LIST; do 循环体done 123456789101112131415#!/bin/bash#declare -i uphosts=0declare -i downhosts=0for i in &#123;1..17&#125;; do if ping -W 1 -c 1 172.16.$i.1 &amp;&gt; /dev/null; then echo "172.16.$i.1 is up." let uphosts+=1 else echo "172.16.$i.1 is down." let downhosts+=1 fidoneecho "Up hosts: $uphosts, Down hosts: $downhosts." 1.3 类 C 风格for 循环for 循环除通常的列表遍历外，还有一种类 C 风格使用方法，其语法如下 控制变量初始化：仅在循环代码开始运行时执行一次； 控制变量的修正语句：每轮循环结束会先进行控制变量修正运算，而后再做条件判断； 123for ((控制变量初始化;条件判断表达式;控制变量的修正语句)); do 循环体done 12345678910# 示例：求100以内所有正整数之和#!/bin/bash#declare -i sum=0for ((i=1;i&lt;=100;i++)); do let sum+=$idoneecho "Sum: $sum." 2. while 循环2.1 while 条件循环while 循环只要条件满足，就会一直执行123while CONDITION1; do 循环体done 12345678910111213#!/bin/bash#declare -i i=1declare uphosts=0declare downhosts=0net="172.169.250"while [ $i -le 20 ]; do if ping -c 1 -w $net.$i &amp;&gt;/dev/null; then echo "$net.$i is up" let uphosts++ fidone 2.2 while 文件遍历while循环还有一种特殊用法，可用于文件遍历。如下所示 while 将依次读取/PATH/FROM/SOMEFILE 文件中的每一行，且将其赋值给VARIABLE变量123while read VARIABLE; do 循环体；done &lt; /PATH/FROM/SOMEFILE 123456789101112# 示例：找出ID号为偶数的用户，显示其用户名、ID及默认shell；#!/bin/bash#while read line; do userid=$(echo $line | cut -d: -f3) username=$(echo $line | cut -d: -f1) usershell=$(echo $line | cut -d: -f7) if [ $[$userid%2] -eq 0 ]; then echo "$username, $userid, $usershell." fidone &lt; /etc/passwd 2.3 创建死循环while true 可以创建死循环， sleep 命令可以让进程休眠一段时间 sleep NUMBER[SUFFIX]: 作用: 让程序在 sleep 处休眠 NUMBER 秒 SUFFIX: 默认为 s, 指暂停的秒数, m 指分钟, h 指小时, d 代表天数 1234567891011#!/bin/bash# 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出；while true; do if who | grep "^logstash\&gt;" &amp;&gt; /dev/null; then break fi sleep 3doneecho "$(date +"%F %T") logstash logged on" &gt;&gt; /tmp/users.log 3. until 循环until 循环只要条件满足，就会退出循环 123until CONDITION; do 循环体done 1234567#!/bin/bash# 练习：每隔3秒钟到系统上获取已经登录用户的用户的信息；其中，如果logstash用户登录了系统，则记录于日志中，并退出；until who | grep "^logstash\&gt;" &amp;&gt; /dev/null; do sleep 3doneecho "$(date +"%F %T") logstash logged on" &gt;&gt; /tmp/users.log 4. 循环控制语句4.1 continuecontinue 可提前结束本轮循环，直接进入下一轮循环判断； 12345678910111213141516171819202122232425262728293031323334# 示例：求100以内所有偶数之和； #!/bin/bash#declare -i evensum=0declare -i i=0while [ $i -le 100 ]; do let i++ if [ $[$i%2] -eq 1 ]; then continue fi let evensum+=$idoneecho "Even sum: $evensum"``` ### 3.2 breakbreak 可提前跳出整个循环。在下面的示例中 `while true` 将创建死循环，达到满足的条件时，break 将跳出循环。```bash# 示例：求100以内所奇数之和#!/bin/bash#declare -i oddsum=0declare -i i=1while true; do let oddsum+=$i let i+=2 if [ $i -gt 100 ]; then break fidone]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.2 if 和条件判断]]></title>
    <url>%2F2018%2F01%2F11%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fif%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[if 和条件判断 本节我们来学习 bash shell 编程的第二部分条件判断，包括以下内容: 条件测试的实现 测试表达式 数值测试 字符串测试 文件测试 组合测试 条件判断语句 if 和 case 1. 条件测试的实现bash 中测试的实现有两种方式，一是执行命令，并利用命令状态返回值来判断；二是所谓的测试表达式。但是所谓的测试表达式本质上仍然是由特定的测试命令执行，并通过命令状态返回值来判断测试是否满足。条件表达式我的理解只不过是为某些通用的测试目的提供便利。 因此测试是否满足，需要在执行测试命令后，使用 echo $? 查看测试结果。后面讲解的 if 语句则会自动判断命令执行状态，做出判断无需通过 $?。 bash 中的条件测试有如下三种使用方式，EXPRESSION 表示测试表达式 test EXPRESSION: bash 命令 [ EXPRESSION ]: [] 是 test 的同义词，使用方式与 test 完全一样 因为是命令，所有 bash 中的元字符如&gt; &lt; () 在表达式中使用时需要转义 命令的操作数不能为空，所以表达式中如果引用变量，需要使用 “$var”，否在当 var 不存在或为空时，会因为缺少操作数报语法错误 EXPRESSION两端必须有空白字符，否则为语法错误 [[ EXPRESSION ]] bash 内置关键字，[[]] 是 [] 的改进，大多数情况下可等同使用 因为不是命令，所以 bash 的元字符在表达式中使用无需转义 非命令，所以操作数为空时也能自动识别，但是在引用变量时，为防止变量包含空格，仍然建议使用 “$var” EXPRESSION两必须有空白字符，否则为语法错误 需要特别注意的是 bash 是通过 空格分隔运算符和操作数的，因此无论上述哪种形式，运算符和操作数之间必需要有空格。除了字符转义外，[] 和 [[]] 在支持的测试表达式范围上也略有不同，二者的区别可以参考此篇文章 http://mywiki.wooledge.org/BashFAQ/031 。一个实现 a 和 b 两个字符比较的示例如下。 1234&gt; test a \&gt; b&gt; [ a \&gt; b ]&gt; [[ a &gt; b ]]&gt; echo $? 2. 测试表达式2.1 数值测试 -eq：是否等于； [ $num1 -eq $num2 ] -ne：是否不等于； -gt：是否大于； -ge：是否大于等于； -lt：是否小于； -le：是否小于等于； 2.2 字符串测试 ==：是否等于； &gt;：是否大于； &lt;：是否小于； !=：是否不等于； =~：左侧字符串是否能够被右侧的PATTERN所匹配； -z &quot;STRING&quot;：判断指定的字串是否为空；空则为真，不空则假； -n &quot;STRING&quot;：判断指定的字符串是否不空；不空则真，空则为假； 注意: 字符串比较的操作数，都应该使用引号括住 [ -z &quot;$name&quot; ] [ &quot;$name&quot; = &quot;$myname&quot; ] 2.3 文件测试 文件存在测试 -a FILE: 等同于 -e FILE -e FILE: 存在则为真；否则则为假； -s FILE: 存在并且为非空文件则为值，否则为假； 存在及文件类型测试 -f FILE: 存在并且为 普通文件，则为真；否则为假； -d FILE: 存在并且为 目录文件，则为真；否则为假； -L/-h FILE: 存在并且为 符号链接文件，则为真；否则为假； -b: 是否存在并且为 块设备文件，则为真；否则为假； -c: 是否存在并且为 字符设备文件，则为真；否则为假； -S: 是否存在且为 套接字文件，则为真；否则为假； -p: 是否存在且为 命名管道文件，则为真；否则为假； 文件权限测试 -r FILE:在并且对当前用户可读； -w FILE:存在并且对当前用户可写； -x FILE:存在并且对当前用户可执行； -g sgid:存在并且 拥有sgid权限； -u suid:存在并且 拥有suid权限； -k sticky:存在并且 拥有sticky权限； 丛属关系测试 -t fd：文件是否打开且与某终端有关 -O FILE 当前用户是否为文件的属主 -G FILE 当前用户是否为文件的属组 更改及新旧对比测试 -N FILE: 文件自从上一次读操作后是否被修改过； file1 -nt file2: file1的mtime新于file2则为真，否则为假； file1 -ot file2: file1的mtime旧于file2则为真，否则为假； file1 -ef file2: 两文件是否是指向同一设备的 inode 的硬链接 2.4 组合测试条件bash 中表示逻辑运算有两种方式，一是使用命令的逻辑运算符，连接两个命令；另一个是表达式的逻辑符号，连接两个表达式。不过 [] 与 [[]]的使用方式有所不同 逻辑与： [ condition1 -a condition2 ] [[ condition1 &amp;&amp; condition2 ]] command1 &amp;&amp; command2 逻辑或： [ condition1 -o condition2 ] [[ condition1 || condition2 ]] command1 || command2 逻辑非： [ ! condition ] [[ ! condition ]] ! command eg： [ -O FILE ] &amp;&amp; [ -r FILE ] 或 [ -O FILE -a -r FILE ] 3. 条件判断语句3.1 if 语句语法if 语句会自动通过判断条件测试命令的执行状态来判断测试条件是否满足1234567891011121314151617if condition; then passelse passfiif conditionthen passelse passfi# 将 if 写在一行，命令行中常用if condition; then command1;command2; else command3; fiif [[ a &gt; b ]]; then echo "aaaa"; else echo "bbbb"; fi 示例通过参数传递一个用户名给脚本，此用户不存时，则添加之； 1234567891011121314#!/bin/bash#if [ $# -lt 1 ]; then echo "At least one username." exit 2fiif grep "^$1\&gt;" /etc/passwd &amp;&gt; /dev/null; then echo "User $1 exists."else useradd $1 echo $1 | passwd --stdin $1 &amp;&gt; /dev/null echo "Add user $1 finished."fi 3.2 case 语句语法123456789101112case $VARAIBLE in PAT1) 分支1 ;;PAT2) 分支2 ;;...*) 默认分支 ;;esac case PAT 支持glob风格的通配符： *：任意长度的任意字符； ?：任意单个字符； []：范围内任意单个字符； a|b：a或b]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6.1 shell 脚本简介]]></title>
    <url>%2F2018%2F01%2F10%2Flinux_mt%2F06-shell%E8%84%9A%E6%9C%AC%E7%BC%96%E7%A8%8B%2Fbash%E5%8F%98%E9%87%8F%E4%B8%8E%E9%80%BB%E8%BE%91%E8%BF%90%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[shell 脚本简介 本章我们将开始学习 bash shell 编程。bash shell 是一门编程语言，内容庞大，按照课程的设计应该循序渐进逐步深入。但是为便于以后复查参考，会将所有 bash shell 相关的知识放在此章节中。本章我们将学习以下内容: 变量与逻辑运算 循环与条件判断 函数和位置参数 程序的学习不言而喻是为了提高运维的效率，如果我们是管理几台主机不会shell 编程可能无所谓，但是当我们管理的主机达到几百甚至几千台时，如果没有自动化运维工具和编程的基础的化，可能就只能睡在公司了。Python 和 bash shell 都是自动化运维非常常用的脚本语言，希望大家多多学习。有两本书推荐给大家 《Linux命令行和shell编程宝典》 《abs-guide》 《高级bash编程指南》 1. 程序的分类shell 脚本是一个比较特殊的编程语言，组成脚本的基本内容并不是通常意义上的函数或库而是 Linux 上的所有命令，所以即便只是将一条条 bash 命令堆砌在一起也可以称为 shell 脚本。因此可以将 shell 脚本看作只是在 bash 命令上添加了编程语言的特性而以。本节我们将对 shell 脚本做一个简单概述，让大家对编程能有个概括性的了解。 按照不同的分类标准，程序可以做不同的分类。根据运行方式，程序可以分为: 编译运行：源代码 –&gt; 由编译器编译成可执行的二进制文件，然后运行； 解释运行：源代码 –&gt; 运行时启动解释器，由解释器边解释边运行； 程序=指令+数据，按照程序是以指令为中心组织的，还是按照数据为中心组织，将程序分为: 过程式编程语言：以指令为中心来组织代码，数据是服务于代码； 面向对象的编程语言：以数据为中心来组织代码，围绕数据来组织指令； 我们的 shell脚本则属于过程式，解释运行的，利用系统上的命令及编程组件进行编程的编程语言。即脚本的基本组件是系统上的所有命令以及用户自定的函数，通过顺序，判断和循环来组织命令按照特定的逻辑运行即可。 2. 如何学习编程网络上有个很有争议性的人物叫王垠，写过一篇文章叫《如何掌握所有的程序语言》。其核心的观念是学习程序语言重要的是学习语言特性而且是重要的语言特性，而不是语言本身。什么是语言特性，我从中摘录了他列举的示例 变量定义 算术运算 for 循环语句，while 循环语句 函数定义，函数调用 递归 静态类型系统 类型推导 lambda 函数 面向对象 垃圾回收 指针算术 goto 语句 按照他所说重要的语言特性就像是计算机的基本组件，而程序语言则是在选择不同的语言特性的基础上组装起来的计算机。作为初学者，可能很难深刻理解他表述的含义，但是他列举的语言特性，却可以给我们学习程序语言提供一个很好的思路。我们也将按照类似的顺序学习 sell 脚本编程。本节我们来讲解 shell 中的变量，以及如何创建一个简单的 shell 脚本并运行。 1. 变量1.1 变量的语言特性在静态的编译语言和动态的脚本语言中，变量的概念并不完全相同。暂时大家可以理解为，变量是命名的内存空间，有类型之分。变量的类型有非常重要的作用，用于确定变量内容的 存储格式、数据范围和能参与的运算 等等。 与变量有关的语言特性包括 变量在使用前是否需要声明 强类型变量还是弱类型变量 强类型变量: 变量类型一旦确定不能改变，也不能将不同类型的变量相互运算 弱类型变量: 变量类型转换没有限制，不同类型之间的运算可能发生隐式转换 变量的作用域，这通常与变量的第一次出现的位置或声明方式有关。 变量引用，及如何获取变量的值。shell 比较特殊，需要特定的方式才能引用到变量的值 变量的命名规则，这在所有编程语言中大体是相同的。 变量名只能包含数字、字母和下划线，而且不能以数字开头 不能够使用程序的保留字 变量名最好能见名知义，并遵循某种命名法则，比如驼峰或者下划线； 1.2 shell 变量的语言特性shell 中的变量则具有以下语言特性 变量无需声明，可直接使用 弱类型变量,无特殊声明默认把所有变量统统视作字符型； 变量引用：${var_name}, $var_name 有只读变量，只读变量无法重新赋值，无法撤销；存活时间为当前shell进程的生命周期，随shell进程终止而终止 变量赋值时，”=” 两边不能有空格，否则最左侧的变量名将被当作命令被解释并执行 1234&gt; ls=1&gt; ls = 1ls: 无法访问=: 没有那个文件或目录ls: 无法访问1: 没有那个文件或目录 1.3 shell 变量的作用域bash 中变量有三种不同的作用域: 本地变量：作用域仅为当前shell进程；除非特殊声明，所有变量均为本地变量 环境变量：作用域为当前shell进程及其子进程；需要特殊声明 局部变量：作用域仅为某代码片断(函数上下文)； 1.4 查看与销毁shell 中变量的查看和销毁有如下几个命令: 查看环境变量 export declare -x printenv, env 查看所有变量：set 撤销变量：unset name 1.5 变量声明bash 中变量声明的命令有 declare, export, readonly，它们都是 bash 的内置命令，用法如下 export [name[=value] 不带参数显示所有变量及其内容 带参数用于声明环境变量 readonly [-aAf] [name[=value] ...] 不带参数显示所有只读变量 带参数用于声明只读变量 declare/typeset [-aixr] [variable=[value]]: 默认：显示所有的变量及其内容，类似于 set -x：与export 一样，将后面的变量转换成环境变量 +x：将 - 变成 + 可以进行取消操作 -a：声明数组类型 array -i：声明整数类型 interger -r：将变量设置成只读类型 -p：后接变量，单独列出变量的类型 1234567891011121314# 声明环境变量export name=valuename=valueexport namedeclare -x name=valuename=valuedeclare -x name# 声明只读变量，声明和赋值可同时进行declare -r name[=value]readonly name[=value] 1.5 shell 中的特殊变量shell 还有一些特殊变量，有特殊公用，列示如下: 位置参数变量: 保存了传递给 shell 脚本的参数； shell内置的有特殊功用的环境变量，通常为全大写字符，用于定义bash的工作环境，比如 PATH: 命令查找路经 HISTFILE, HISTSIZE, HISTFILESIZE, HISTCONTROL: 命令历史的控制参数 SHELL, HOME, UID: 当前用户的 shell类型，家目录以及UID 号 PWD, OLDPWD: 当前以及之前的工作目录 特殊变量： $?: 上一条命令的执行状态 2. 如何写shell脚本2.1 hello world 的 shell 脚本脚本文件的第一行顶格，给出解释器路径，用于指明解释执行当前脚本的解释器程序文件。常见的解释器包括 #!/bin/bash: bash shell 的解释器 #!/usr/bin/python: python 的解释器 #!/usr/bin/perl: perl 的解释器 一个 hello world 的shell 脚本如下:123#!/bin/bashecho &quot;hello world&quot; 2.2 运行脚本bash 中运行脚本有两种方式： 赋予执行权限，并直接运行此程序文件； 直接运行解释器，将脚本以命令行参数传递给解释器程序； 123456# 方法一: 赋予可执行权限，直接运行&gt; chmod +x /PATH/TO/SCRIPT_FILE&gt; /PATH/TO/SCRIPT_FILE# 方法二: 调用 bash 运行&gt; bash /PATH/TO/SCRIPT_FILE 2.3 bash 调试 bash -n script.sh – 检查脚本语法错误 bash -x script.sh – 单步执行，显示代码执行的详细过程 3. 练习1234练习1：写一个脚本，实现如下功能；(1) 显示/etc目录下所有以大写p或小写p开头的文件或目录本身；(2) 显示/var目录下的所有文件或目录本身，并将显示结果中的小写字母转换为大写后显示；(3) 创建临时文件/tmp/myfile.XXXX;]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.4 Linux特殊权限及facl扩展]]></title>
    <url>%2F2018%2F01%2F09%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2FLinux%E7%89%B9%E6%AE%8A%E6%9D%83%E9%99%90%E5%8F%8Afacl%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[Linux特殊权限及facl扩展 Linux 默认的访问控制模型是通过将用户划分为三类，每类用户都可设置读写执行权限实现的。但是某些特殊情况下，此模型可能不太适用，因为其控制的粒度不够。所谓特殊权限及facl 扩展就是用来扩展Linux 的访问控制模型的。本节内容包括: 安全上下文，即程序的访问控制执行环节 SUID SGID STICKY facl 1. 安全上下文：所谓安全上下文即怎么决定一个用户是否某一文件具有什么权限: 进程以某用户的身份运行； 进程是发起此进程用户的代理，因此以此用户的身份和权限完成所有操作； 权限匹配模型： 判断进程的属主，是否为被访问的文件属主；如果是，则应用属主的权限；否则进入第2步； 判断进程的属主，是否属于被访问的文件属组；如果是，则应用属组的权限；否则进入第3步； 应用other的权限； 2. SUID默认情况下，用户发起的进程，进程的属主是其发起者；因此，其以发起者的身份在运行。存在 SUID时，用户运行某程序时，如果此程序拥有SUID权限，那么程序运行为进程时，进程的属主不是发起者，而程序文件自己的属主； SUID 特性 进程发起者对程序文件具有可执行权限 进程的属主为程序文件的属主，而非程序发起者 SUID 权限展示在属主的执行权限位上 rws——:小写 s 表示属主原有 x 权限 rwS——:大写 S 表示属主原没有 x 权限 SUID 权限管理 chmod u+s FILE.....: 添加 SUID 权限 chmod u-s FILE.....: 删除 SUID 权限 2. SGID：默认情况下，新创建文件的数组为用户的有效用户组。当文件目录的属组有写权限，且有SGID权限时，那么所有属于此目录的属组，且以属组身份在此目录中新建文件或目录时，新文件的属组不是用户的基本组，而是此目录的属组； SGID 特性 默认情况下，用户创建文件时，其属组为此用户的基本组 一旦目录具有 SGID 权限，则对此目录具有写权限的用户，在此目录中创建的文件所属的组为目录的属组 SGID 权限展示在属组的执行权限位 —rws—: 小写 s 表示属组有 x 权限 —rwS—: 大写 S 表示属组没有 x 权限 SGID 权限管理 chmod g+s DIR.....: 添加 SGID 权限 chmod g-s DIR.....: 删除 SGID 权限 3. Sticky对于属组或全局可写的目录，组内的所有用户或系统上的所有用户对在此目录中都能创建新文件或删除所有的已有文件；如果为此类目录设置Sticky权限，则每个用户能创建新文件，且只能删除自己的文件； Sticky 特性 对于一个多人可写目录，如果此目录设置了 Sticky 权限，则每个用户仅能删除自己的文件 Sticky 权限展示在其它用户的执行权限位 ——rwt: other 拥有 x 权限 ——rwT: other 没有 x 权限 系统上的/tmp和/var/tmp目录默认均有sticky权限； Sticky 权限管理 chmod o+t DIR....: 添加 Sticky 权限 chmod o-t DIR....: 删除 Sticky 权限 基于八进制方式赋权时，可于默认的三位八进制数字左侧再加一位八进制数字 chmod 1777 4. faclfacl - file access control lists 指的是文件的额外赋权机制，在原来的u,g,o之外，另一层让普通用户能控制赋权给另外的用户或组的赋权机制。facl 包含两个命令，getfacl 用于查看文件访问控制列表，setfacl 用户设置文件访问控制列表 getfacl命令getfacl FILE... &gt; getfacl README.md # file: README.md # owner: tao # group: 197121 &lt;unknown&gt; user::rw- # 属主 user:centos:rw- # facl 赋权给 centos 的权限 group::r-- # 属组 other:r-- # 其他 setfacl命令： 赋权: 赋权给用户：setfacl -m u:USERNAME:MODE FILE... 赋权给组 ：setfacl -m g:GROUPNAME:MODE FILE... 撤权： 撤销用户赋权: setfacl -x u:USERNAME FILE... 撤销组赋权: setfacl -x g:GROUPNAME FILE...]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.3 用户权限管理]]></title>
    <url>%2F2018%2F01%2F08%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[Linux 用户与组管理命令 本节我们将学习用户权限以及权限管理。包括以下内容： Linux 的权限模型 Linux 权限管理 Linux 属主属组管理 umask 文件权限的遮罩码设置 1. Linux权限模型Linux 权限模型包括: Linux 按照属主，属组，其他三类用户，分别设置了r(读)，w(写)，x(执行) 三个权限 进程对文件的访问权限，取决于进程的发起者 权限的匹配按照属主，属组，其他的顺序，如果进程的发起者是文件的属主，则进程对此文件具有属主权限 123456&gt; ls /etc/passwd# rwxrwxrwx # 左三位：定义user(owner)的权限 # 中三位：定义group的权限； # 右三位：定义other的权限 1.1 文件与目录权限的含义 权限 文件 目录 r 可获取文件的数据 可使用ls命令获取其下的所有文件列表 w 可修改文件的数据 可修改此目录下的文件列表；即创建或删除文件 x 可将此文件运行为进程 可cd至此目录中，且可使用ls -l来获取所有文件的详细属性信息 1.2 权限的数字标识rwx 权限分别对应数字 421。这种以 2 的幂次递增的表示方式可以使得，任一一个总数都可以唯一表示一种权限类型。比如 5 表示 r-x 2.权限管理命令chmod 命令中用户可以使用如下代号表示 u：属主 g：属组 o：其它 a: 所有 chmod [OPTION]... MODE[,MODE]... FILE... 赋权表示法，直接操作一类用户的所有权限位rwx； 123456&gt; chmod ug=rwx /etc/fstab&gt; chmod ug=rwx,o= /etc/fstab&gt; chmod go= /etc/fstab# 数字权限设置，每个用户的权限不能省略&gt; chmod 666 /etc/fstab chmod [OPTION]... OCTAL-MODE FILE... 授权表示法：直接操作一类用户的一个权限位r,w,x； u+, u- g+, g- o+, o- a+, a- 12345&gt; chmod ug+x /etc/fstab&gt; chmod u-w /etc/fstab&gt; chmod +x /etc/fstab == chmod a+x /etc/fstab&gt; chmod +w /etc/fstab == /chmod u+w /etc/fstab # w 权限比较特殊&gt; chmod u+x,g+w /etc/fstab chmod [OPTION]... --reference=RFILE FILE... 引用表示法: 引用其他文件的权限为目标设置权限 --reference: 参考的文件 1chmod --reference=/var/log/message /etc/fstab chmod 的可用选项如下: 选项: -R, --recursive: 递归修改 注意：用户仅能修改属主为自己的那些文件的权限； installinstall 作用: copy files and set attributes 用法: 单源复制： install [OPTION]... [-T] SOURCE DEST 多源复制： install [OPTION]... SOURCE... DIRECTORY install [OPTION]... -t DIRECTORY SOURCE... 创建目录： install [OPTION]... -d DIRECTORY... 常用选项： -m, --mode=MODE：设定目标文件权限，默认为755； -o, --owner=OWNER：设定目标文件属主； -g, --group=GROUP：设定目标文件属组； mktempmktemp [OPTION]... [TEMPLATE] 作用: create a temporary file or directory 常用选项： -d：创建临时目录 注意：mktemp会将创建的临时文件名直接返回，因此，可直接通过命令引用保存起来； 1&gt; mktemp /tmp/mytext.XXXXXX # 有几个 X 就有几个随机字符 3. 从属关系管理命令chown命令：chown [OPTION]... [OWNER][:[GROUP]] FILE...chown [OPTION]... --reference=RFILE FILE... 作用: 修改文件的属主属组 选项： -R：递归修改 注意：仅管理员可修改文件的属主和属组； 12345&gt; chown -R tao:tao /etc/fstab # 同时更改属主属组&gt; chown -R tao.tao /etc/fstab # 同时更改属主属组&gt; chown -R tao /etc/fstab # 仅更改属主&gt; chown -R :tao /etc/fstab # 仅更改属组，.与: 均可&gt; chown -R --reference=/var/log/message /etc/fstab chgrpchgrp [OPTION]... GROUP FILE...chgrp [OPTION]... --reference=RFILE FILE... 4. umaskumask [MASK] 作用: 查看或设置文件的权限反向掩码，遮罩码； 默认查看当前 umask 后跟 MASK 设置 umask 效果: 文件默认权限 = 666-umask 目录默认权限 = 777-umask 注意： 文件用666去减，表示文件默认不能拥有执行权限；如果减得的结果中有执行权限，需要将其加1； 此类设定仅对当前shell进程有效； 123umask: 023666-023=644777-023=754 练习123456# 新建系统组mariadb, 新建系统用户mariadb, 属于mariadb组，要求其没有家目录，且shell为/sbin/nologin；尝试root切换至用户，查看其命令提示符；# 新建GID为5000的组mageedu，新建用户gentoo，要求其家目录为/users/gentoo，密码同用户名；# 新建用户fedora，其家目录为/users/fedora，密码同用户名；# 新建用户www, 其家目录为/users/www；删除www用户，但保留其家目录；# 为用户gentoo和fedora新增附加组mageedu;# 复制目录/var/log至/tmp/目录，修改/tmp/log及其内部的所有文件的属组为mageedu，并让属组对目录本身拥有写权限；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.2 用户与组管理命令]]></title>
    <url>%2F2018%2F01%2F07%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 用户与组管理命令 本节我们将详细讲解用户与组管理的相关命令，包括以下内容: 用户的管理 用户组的管理 1. 用户组管理groupaddgroupadd [选项] group_name 作用: 创建新组 选项: -g GID：指定GID；默认是上一个组的GID+1； -r: 创建系统组； groupmodgroupmod [选项] GROUP 作用: 修改组属性 参数: GROUP 指定要修改的组的组名 选项: -g GID：修改GID； -n new_name：修改组名； groupdelgroupdel [选项] GROUP 作用: 删除组 gpasswd命令：gpasswd [选项] group 组密码文件：/etc/gshadow 作用: 设置组密码或向组添加或删除用户 选项: -a USERNAME：向组中添加用户 -d USERNAME：从组中移除用户 2. 用户管理Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells useradduseradd -D： 作用: 显示创建用户的默认配置； useradd -D 选项: 作用: 修改创建用户选项的默认值； 修改的结果保存于/etc/default/useradd文件中； 选项: s: 设置默认 shell useradd [选项] 登录名 作用: 创建新用户 选项: -u, --uid UID：指定UID； -g, --gid GROUP：指定基本组ID，此组得事先存在； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：指明用户所属的附加组，多个组之间用逗号分隔； -c, --comment COMMENT：指明注释信息； -d, --home HOME_DIR：以指定的路径为用户的家目录；通过复制/etc/skel此目录并重命名实现；指定的家目录路径如果事先存在，则不会为用户复制环境配置文件； -M: 不为用户创建主目录 -s, --shell SHELL：指定用户的默认shell，可用的所有shell列表存储在/etc/shells文件中； -r, --system：创建系统用户； 注意：创建用户时的诸多默认设定配置文件为/etc/login.defs usermod命令usermod [选项] 登录名 作用: 修改用户属性 选项: -u, --uid UID：修改用户的ID为此处指定的新UID； -g, --gid GROUP：修改用户所属的基本组； -G, --groups GROUP1[,GROUP2,...[,GROUPN]]]：修改用户所属的附加组；原来的附加组会被覆盖； -a, --append：与-G一同使用，用于为用户追加新的附加组； -c, --comment COMMENT：修改注释信息； -d, --home HOME_DIR：修改用户的家目录；用户原有的文件不会被转移至新位置； -m, --move-home：只能与-d选项一同使用，用于将原来的家目录移动为新的家目录； -l, --login NEW_LOGIN：修改用户名； -s, --shell SHELL：修改用户的默认shell； -L, --lock：锁定用户密码；即在用户原来的密码字符串之前添加一个”!”； -U, --unlock：解锁用户的密码； userdel命令userdel [选项] 登录 作用：删除用户 选项: -r：删除用户时一并删除其家目录； passwdpasswd [-k] [-l] [-u [-f]] [-d] [-e] [-n mindays] [-x maxdays] [-w warndays] [-i inactivedays] [-S] [--stdin] [username] 作用: passwd：修改用户自己的密码； passwd USERNAME：修改指定用户的密码，但仅root有此权限； 选项: -l, -u：锁定和解锁用户； -d：清除用户密码串； -e DATE: expire 过期期限，日期； -i DAYS：inactive 非活动期限； -n DAYS：minimum 密码的最短使用期限； -x DAYS：maximum 密码的最长使用期限； -w DAYS：warning 警告期限； --stdin：echo &quot;PASSWORD&quot; | passwd --stdin USERNAME newgrp命令newgrp [-] [group] 作用: 临时切换指定的组为基本组； 选项: -: 会模拟用户重新登录以实现重新初始化其工作环境； 附注: 如果用户不属于切换的目标组，则需要输入目标组组密码 chagechage [选项] 登录名 作用: 更改用户密码过期信息 选项: -d, --lastday DAYS: 修改最近一次更改时间 -E, --exporedate DATE: 过期期限 -W: -m: -M: idid [OPTION]... [USER] 作用: 显示用户的真和有效ID; 选项: -u: 仅显示有效的UID； -g: 仅显示用户的基本组ID; -G: 仅显示用户所属的所有组的ID； -n: 显示名字而非ID； eg: id docker 12345练习1：创建用户gentoo，UID为4001，基本组为gentoo，附加组为distro(GID为5000)和peguin(GID为5001)；练习2：创建用户fedora，其注释信息为&quot;Fedora Core&quot;，默认shell为/bin/tcsh；练习3：修改gentoo用户的家目录为/var/tmp/gentoo；要求其原有文件仍能被用户访问；练习4：为gentoo新增附加组netadmin； 3. 用户切换susu 用法: su -l USERNAME|su - USERNAME: 登录式切换, 会通过读取目标用户的配置文件来重新初始化 su USERNAME: 非登录式切换：不会读取目标用户的配置文件进行初始化 注意：管理员可无密码切换至其它任何用户； 选项: -c &quot;COMMAND&quot;：仅以指定用户的身份运行此处指定的命令；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5.1 系统用户与组]]></title>
    <url>%2F2018%2F01%2F06%2Flinux_mt%2F05-Linux%E7%94%A8%E6%88%B7%E7%BB%84%E7%AE%A1%E7%90%86%E5%8F%8A%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F%E7%B3%BB%E7%BB%9F%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Linux 中的用户与用户组 本章我们将学习 Linux 中的用户，用户组及权限。这些都是Linux 运维的基础知识，并不难。通过四节我们将学习以下内容: Linux 中的用户及用户组 Linux 权限及权限的管理 用户及用户组的管理命令 对于 Linux 的用户及用户组，主要是学习 /etc/passwd, /etc/shadow, /etc/group 三个文件，它们保存着 Linux 用户、用户组及密码。用户管理相关命令的核心，也只是操作这几个文件而已。 有关用户包括三个方面的内容，简称 3A 用户认证 - Authentication: 用户登录时需要输入用户名和密码 用户授权 - Authorization: Linux 上文件有属主和属组，并为属组属组以及其他第三方定义了权限 授权审计 - Audition: 登录和认证会记录到日志文件中，以便于日后审计 本节我们将围绕第一方面，讲述如下内容: Linux 用户与组的基本概念，包括用户的分类，与ID标识 Linxu 用户的认证 1. Linux 用户基础计算机容易识别的是数字，因此用户和组在Linux 都标识为 16 位二进制数字，称为 UserID(UID)，GroupID,(GID)，范围是0-65535Linux 与用户相关的配置文件如下: /etc/passwd: 保存用户及属性信息 /etc/group: 组及其属性信息 /etc/shadow: 用户密码及相关属性 /etc/gshaow: 组密码及相关属性 /etc/login.defs: 用户创建和设置规则的配置 /etc/skel: 用户家目录的默认包含的文件 /etc/default/useradd: 用户创建的默认值配置 /etc/shells: 系统包含的所有shells 1.1 用户基础Linux 中的用户具有如下特征 用户标识: UserID(UID) 用户分类与 ID 范围: 管理员: 0 普通用户：1-65535 系统用户: 1-499(CentOS6), 1-999(CentOS7) 作用: 为了能够让那后台进程或服务类进程以非管理员的身份运行，通常需要为此创建多个普通用户；这类用户从不用登录系统； 登录用户: 500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/passwd: 名称解析库，保存了用户名，UID等基础信息 /etc/shadow: 保存了用户的密码 1.2 Linux 用户组Linux 用户组 组标识：GroupID, GID 组分类与 ID 范围: 管理员组：0 通用户组：1-65635 系统用户组：1-499(CentOS6), 1-999(CentOS7) 登录用户组：500-60000(CentOS6), 1000-60000(CentOS7) 配置文件: /etc/group: 保存了组名，组ID，组员等基本信息 /etc/gshadow: 保存了组的密码 组的其他分类: 从单个用户出发，分为： 用户的基本组 用户的附加组 按照名称: 私有组：组名同用户名，且只包含一个用户； 公共组：组内包含了多个用户； 1.3 密码的使用策略： 使用随机密码； 最短长度不要低于8位； 应该使用大写字母、小写字母、数字和标点符号四类字符中至少三类； 定期更换； 加密算法： 对称加密：加密和解密使用同一个密码； 非对称加密：加密和解密使用的一对儿密钥； 公钥：public key 私钥: private key 单向加密：只能加密，不能解密；提取数据特征码； 定长输出 雪崩效应 单向加密算法及对应命令: md5: message digest, 128bits – md5sum sha：secure hash algorithm, 160bits – shasum sha224 – sha224sum sha256 – sha256sum sha384 – sha284sum sha512 – sha512sum 2. 用户相关文件解析2.1 /etc/passwd 用户信息库name:password:UID:GID:GECOS:directory:shell name: 用户名 password：可以是加密的密码，也可是占位符x； UID： GID：用户所属的主组的ID号； GECOS：注释信息 directory：用户的家目录； shell：用户的默认shell，登录时默认shell程序； 2.2 /etc/shadow：用户密码用户名:加密的密码:最近一次修改密码的时间:最短使用期限:最长使用期限:警告期段:非活动期限:过期期限:保留字段 加密的密码: 使用 $ 符分割为 3 段分别表示: 数字，表示使用的加密算法 salt，表示加密过程中添加的随机数 加密之后的密码文本 2.3 /etc/group：组的信息库group_name:password:GID:user_list user_list：该组的用户成员；以此组为附加组的用户的用户列表；]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.3 文件管理命令]]></title>
    <url>%2F2018%2F01%2F05%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[bash常见特性 本节我们将学习与文件目录管理相关的命令，包括 目录管理类命令 文件查看类命令 文件管理工具 1. 目录管理类的命令：mkdirmkdir [OPTION]... DIRECTORY... 作用: 创建目录 选项: -p: 父目录不存在时，自动按需创建父目录； -v: verbose，显示详细过程； -m: MODE：直接给定权限； rmdirrmdir [OPTION]... DIRECTORY... 作用: 删除空目录 选项: -p：删除某目录后，如果其父目录为空，则一并删除之； -v: 显示过程； tree：tree [options] [directory] 作用: 以层级方式展开显示目录 选项: -L level：指定要显示的层级； 2. 文件查看类命令：cat：cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac：tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； moremore FILE 作用: 分屏查看文件内容，没有 less 常用，了解即可 特点：翻屏至文件尾部后自动退出； lessless FILE 作用: 分屏查看文件内容, man 手册页即是调用 less 命令显示的结果 可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit) headhead [options] FILE 作用: 查看文件的前n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 tailtail [options] FILE 作用: 查看文件的后n行； 选项: -n #: 指定查看多少行 -#: 同上，# 表示数字 -f: 查看文件尾部内容结束后不退出，跟随显示新增的行； statstat FILE... 作用: display file or file system status12345678910&gt; stat SUMMARY.md 文件：&quot;SUMMARY.md&quot; 大小：16876 块：40 IO 块：4096 普通文件设备：fd03h/64771d Inode：603785 硬链接：1权限：(0664/-rw-rw-r--) Uid：( 1000/ tao) Gid：( 1000/ tao)环境：unconfined_u:object_r:user_home_t:s0最近访问：2018-07-06 09:04:02.197198385 +0800 # access time最近更改：2018-07-06 09:04:02.185198436 +0800 # modify time 最近修改文件内容的时间最近改动：2018-07-06 09:04:02.185198436 +0800 # change time 最近文件元数据发生更改的时间创建时间：- touch：touch [OPTION]... FILE... 作用: 更改文件的时间戳 选项: -c: 指定的文件路径不存在时不予创建； -a: 仅修改access time； -m: 仅修改modify time； -t: STAMP 格式为 [[CC]YY]MMDDhhmm[.ss] 3. 文件管理工具copy命令式使用: 单源复制：cp [OPTION]... [-T] SOURCE DEST 如果DEST不存在：则事先创建此文件，并复制源文件的数据流至DEST中； 如果DEST存在： 如果DEST是非目录文件：则覆盖目标文件； 如果DEST是目录文件：则先在DEST目录下创建一个与源文件同名的文件，并复制其数据流； 多源复制： cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 如果DEST不存在：错误； 如果DEST存在： 如果DEST是非目录文件：错误； 如果DEST是目录文件：分别复制每个文件至目标目录中，并保持原名； 常用选项： -i：交互式复制，即覆盖之前提醒用户确认； -f：强制覆盖目标文件； -r, -R：递归复制目录； -d：== --no-dereference --preserve=links复制符号链接文件本身，而非其指向的源文件； -a, -- archive：相当于-dR --preserve=all，用于实现归档； --preserv=:保留源文件哪些属性，可用值如下 mode：权限 ownership：属主和属组 timestamps: 时间戳 context：安全标签 xattr：扩展属性 links：符号链接 all：上述所有属性 mvmv [OPTION]... [-T] SOURCE DESTmv [OPTION]... SOURCE... DIRECTORYmv [OPTION]... -t DIRECTORY SOURCE.. 使用: 同 cp 作用: 移动文件或目录 选项： -i：交互式； -f：force rmrm [OPTION]... FILE... 作用: 删除文件或目录 选项： -i：interactive，交互 -f：force，强制删除 -r: recursive，递归删除 删除目录：rm -rf /PATH/TO/DIR 危险操作：rm -rf /* 注意：所有不用的文件建议不要直接删除，而是移动至某个专用目录；（模拟回收站） trtr [OPTION]... SET1 [SET2] 作用: 把输入的数据当中的字符，凡是在SET1定义范围内出现的，通过对位转换为SET2出现的字符 用法1：tr SET1 SET2 &lt; /PATH/FROM/SOMEFILE – 用 SET2 替换 SET1 用法2：tr -d SET1 &lt; /PATH/FROM/SOMEFILE – 删除 SET 1中出现的字符 注意：不修改原文件 1234567# 把/etc/passwd文件的前6行的信息转换为大写字符后输出；&gt; head -n 6 /etc/passwd | tr &apos;a-z&apos; &apos;A-Z&apos;&gt; tr [a-z] [A-Z]how are youHOW ARE YOU]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.2 bash常见特性]]></title>
    <url>%2F2018%2F01%2F04%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2Fbash%E5%B8%B8%E8%A7%81%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[bash常见特性 bash 作为外壳程序的一种，为我们提供了与操作系统内核交互的接口。bash 本身具有丰富的特性，为我们执行和管理应用提供了便利。本节我们将学习 bash 的如下特性 命令历史 命令与路径补全 命令行展开 获取命令的执行状态和执行结果 引用与快捷键 通配符 IO重定向及管道 命令 hash 多命令执行 1. bash 命令历史命令历史指的是 shell 进程会其会话中保存此前用户提交执行过的命令；于此同时 bash 提供了快捷方式，以便我们能快速执行历史命令 1.1 命令历史控制相关的环境变量 HISTSIZE：shell进程可保留的命令历史的条数； HISTFILE: 持久保存命令历史的文件，默认为 ~/.bash_history HISTFILESIZE: 命令历史文件的大小； HISTCONTROL: 控制命令历史记录的方式，可选值如下 ignoredups：忽略重复的命令； ignorespace：忽略以空白字符开头的命令； ignoreboth：以上两者同时生效； 1.2 命令用法：history [-c] [-d 偏移量] [n]history -anrw [文件名]history -ps 参数 [参数...] -c: 清空命令历史； -d offset：删除指定命令历史 -r: 从文件读取命令历史至历史列表中； -w：把历史列表中的命令追加至历史文件中； history n：显示最近的 n 条命令； 1.3 快捷方式常见的历史命令的快捷方式如下 调用命令历史列表中的命令： !#：再一次执行历史列表中的第#条命令； !!：再一次执行上一条命令； !STRING：再一次执行命令历史列表中最近一个以STRING开头的命令； 调用上一条命令的最后一个参数： 快捷键：ESC, . - 表示先按 ESC，在按 . 字符串：!$ 2. 命令补全：所谓命令补全，就是在bash 中按下 tab 键之后，bash 会自动查找以当前输入字符开头的命令。如果给定的打头字符串如果能惟一标识某命令程序文件，则直接补全；不能惟一标识某命令程序文件，再击tab键一次，会给出列表。命令查找机制 如下： 优先查找内部命令； 根据PATH环境变量中设定的目录，自左而右逐个搜索目录下的文件名； 路径补全 与命令补全功能类似，只是路径补全只会在给定的起始路径下，逐一匹配起始路径下的每个文件。道理很简单，如果匹配到别处的文件名，在起始目录也还是查找不到，所以补全也没什么用。 命令和路径补全是 bash 中非常好用的功能，没事多敲击几次 tab 就好。 3. 命令行展开Linux 中有如下特殊字符，用于扩展命令的输入方式: ~: 自动展开为用户的家目录，或指定的用户的家目录； {}: 可承载一个以逗号分隔的路径列表，并能够将其展开为多个路径； 123456&gt; /tmp/&#123;a,b&#125; # 相当于&gt; /tmp/a /tmp/b&gt; mkdir -pv /tmp/x/&#123;y1/&#123;a,b&#125;,y2&#125;&gt; mkdir -v &#123;a,b&#125;_&#123;c,d&#125;&gt; mkdir -pv /tmp/mysysroot/&#123;bin,sbin,etc/sysconfig/network-scripts,usr/&#123;bin,sbin,local/&#123;bin,sbin,etc,lib&#125;,lib,lib64&#125;,var/&#123;cache,log,run&#125;&#125; 4. 获取命令的执行状态和执行结果命令的执行状态: 表示命令执行成功还是失败 命令执行完成之后，其状态返回值保存于bash的 $? 特殊变量中； 命令返回值: 表示命令的返回结果，或者是命令的输出内容 bash 中可以通过如下方式引用命令的执行结果，这在 bash 编程中非常有用 $(COMMAND) COMMAND 5. 引用与快捷键5.1 Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name 5.2 快捷键 Ctrl+a：跳转至命令行行首 Ctrl+e：跳转至命令行行尾 Ctrl+u：删除行首至光标所在处之间的所有字符； Ctrl+k：删除光标所在处至行尾的所有字符； Ctrl+l：清屏，相当于clear 6. globbing - 文件名通配通配符指的是 bash 中的特殊字符，称为元字符，元字符不表示字符本身而是表示一定范围内的或符合匹配条件的一类字符。通过元字符达到模糊匹配的作用。需要注意的是通配符跟正则表达式是完全不同的东西，不同软件，程序中的通配符也不会完全相同。需要特别注意的是bash 中的通配机制 匹配的是整体文件名，而非部分 bash 中的元字符如下 *：匹配任意长度的任意字符 ?：匹配任意单个字符 []：匹配指定范围内的任意单个字符，有如下几种特殊格式： `[a-z], [A-Z]: 不会区分文件名大小写，二者表示范围相同 [0-9], [a-z0-9]`: [[:upper:]]：所有大写字母 [[:lower:]]：所有小写字母 [[:alpha:]]：所有字母 [[:digit:]]：所有数字 [[:alnum:]]：所有的字母和数字 [[:space:]]：所有空白字符 [[:punct:]]：所有标点符号 [^]：匹配指定范围外的任意单个字符 [^[:upper:]] [^0-9] [^[:alnum:]] 123456789101112131415161718# 练习# 显示/var目录下所有以l开头，以一个小写字母结尾，且中间出现一位任意字符的文件或目录；&gt; ls -d /var/l?[[:lower:]]# 显示/etc目录下，以任意一位数字开头，且以非数字结尾的文件或目录；&gt; ls -d /etc/[0-9]*[^0-9]# 显示/etc目录下，以非字母开头，后面跟一个字母及其它任意长度任意字符的文件或目录；&gt; ls -d /etc/[^a-z][a-z]*# 复制/etc目录下，所有以m开头，以非数字结尾的文件或目录至/tmp/magedu.com目录；&gt; cp -r /etc/m*[^0-9] /tmp/magedu.com/# 复制/usr/share/man目录下，所有以man开头，后跟一个数字结尾的文件或目录至/tmp/man/目录下；&gt; cp -r /usr/share/man/man[0-9] /tmp/man/# 复制/etc目录下，所有以.conf结尾，且以m,n,r,p开头的文件或目录至/tmp/conf.d/目录下；&gt; cp -r /etc/[mnrp]*.conf /tmp/conf.d/ 7. IO重定向及管道7.1 IO重定向：IO 我的理解就是文本流，所谓 IO 重定向就是将原本输入输出一个地方的文件流重新导向另一个地方。与输入输出相关的概念如下 可用于输入的设备包括：文件、键盘设备、文件系统上的常规文件、网卡等； 可用于输出的设备包括：文件、显示器、文件系统上的常规文件、网卡等； 默认情况下，bash 为程序提供了三种标准数据流： 输入的数据流；&lt;– 标准输入(stdin)，键盘； 输出的数据流：–&gt; 标准输出(stdout)，显示器； 错误输出流： –&gt; 标准错误输出(stderr)，显示器； IO 重定可分为覆盖重定向和追加重定向，所谓覆盖就是如果重定向的目标是文件，会先清空文件中的内容，而追加只是在文件的结尾继续写入。IO重定向的实现如下: 输入重定向： &lt; &lt;&lt;: 表示创建文档，使用方式见下 cat命令 输出重定向 &gt;: 覆盖重定向 == 1&gt; &gt;&gt;: 追加重定向 == 1&gt;&gt; 错误输出重定向： 2&gt;: 覆盖重定向 2&gt;&gt;: 追加重定向 合并正常输出流和错误输出流： &amp;&gt; &amp;&gt;&gt; 123456# 合并正常输出流和错误输出流COMMAND &gt; /path/to/somefile 2&gt;&amp;1 # 方法一COMMAND &amp;&gt; /path/to/somefile # 方法二COMMAND &gt;&gt; /path/to/somefile 2&gt;&amp;1 # 方法一COMMAND &amp;&gt;&gt; /path/to/somefile # 方法二 需要注意的是上述中 1,2 指代的是标准输入输出对应的文件描述符(fd, file descriptor)。文件描述符是操作系统的一个抽象概念，表示打开的文件。大家可以理解为 Linux中一切皆文件，如果要操作文件必须将文件关联到某个文件描述符。bash 在开启时，会自动做如下关联 标准输入：0 标准输出：1 错误输出：2 Linux 中有一个特殊设备/dev/null，它会丢弃接收到的所有输入，又称数据黑洞。通常在 shell 编程中，我们只需要知道命令的执行状态，而无需命令的执行结果时，可以将输出重定向至此设备 1&gt; head -1 /etc/passwd &amp;&gt; /dev/null # 判断 /etc/passwd 是否有内容 7.2 管道管道是 Linux 提供的一种进程间交互(IPC)的一种方法。大家不必过于纠结它是个什么东西，只要知道的是，它可以把一个程序的输入变成另一个程序的输入，就像一根管道一样连接着程序与程序。管道的使用方式类似 COMMAND | COMMAND | COMMAND....,使用 | 链接多个命令即可。1234# 管道与 IO重定向定义&gt; cat /etc/issue | tr &apos;a-z&apos; &apos;A-Z&apos; &gt; /tmp/issue&gt; who | head -2 | tr &apos;a-z&apos; &apos;A-Z&apos; | tr -d &apos;0-9&apos; &gt; /tmp/who.txt 7.3 bash 中对IO重定向的控制set 作用: 设置或撤销，shell 选项或位置参数的值 set -C 作用: 禁止覆盖输出重定向至已存在的文件； 附注: 此时可使用强制覆盖输出：&gt;| set +C 作用: 关闭上述特性 7.4 重定向相关命令catcat &gt; /PATH/TO/SOMEFILE &lt;&lt; EOF12345678910# EOF 表示文档创建的结束符# 通过屏幕的输入将保存至 /PATH/TO/SOMEFILE&gt; cat &gt; /PATH/TO/SOMEFILE &lt;&lt; EOFhow are youyes it is meEOF&gt; cat /PATH/TO/SOMEFILEhow are youyes it is me tee命令：tee [OPTION]... [FILE] 作用: 把标准输入的数据复制到每一个文件FILE,同时送往标准输出, 参数: FILE: 可以有多个 选项: -a: 追加到给出的文件, 而不是覆盖 eg：COMMAND | tee /PATH/TO/SOMEFILE 8.命令 hash所谓命令 hash 是指 bash 会缓存此前命令的查找结果。哈希是一种数据结构，通常也称为字典存储着键值对，能通过键快速的查找到对应的值。bash 内置的 hash 命令能显示和管理 bash 命令的缓存结果。 hash [options] [COMMAND] 用法:- `hash`：列出所有的缓存结果 - `hash -d COMMAND`：删除 COMMAND 命令的缓存 - `hash -r`：清空所有缓存 9. 多命令执行bash 中可以同时执行多条命令，命令之间可以没有关系顺序执行，也可以逻辑关系。可以理解为写在命令行的单行脚本。 COMMAND1; COMMAND2;....: 多条命令互不影响，顺序执行 COMMAND1 &amp;&amp; COMMAND2: &amp;&amp; 表示逻辑与，只有在第一条命令执行成功时，才会执行第二条命令 COMMAND1 || COMMAND2: || 表示逻辑或，只有在第一条命令执行失败时，才会执行第二条命令 1id $username || useradd $username 这里可以将 COMMAND1，COMMAND2 想象成一个逻辑判断表达式，&amp;&amp; 表示逻辑与，如果 COMMAND1 为False，整个表达式一定为 False，因此也就没有必要执行 COMMAND2，从样如果COMMAND1 为真，在逻辑或下，整个表达式肯定为真，也没有必要执行第二个表达式。这就是逻辑运算中短路逻辑。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4.1 Linux目录结构]]></title>
    <url>%2F2018%2F01%2F03%2Flinux_mt%2F04-Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%92%8C%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2FLinux%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Linux 目录结构 接下来，我们将学习 Linux 下的目录结构和Linux Bash 的基础特性。通过三节内容，我们将学习以下内容: Linux 文件系统及文件的组织结构 Linux 常见的文件类型 Bash 常见特性和快捷键使用 常用基础命令与命令历史 基础的文件管理命令与系统变量 文件系统同样是很复杂的东西，具体原理后面会介绍。当前，只要知道文件系统是操作系统对磁盘的抽象，为用户提供了管理磁盘文件的接口。开机启动时，内核加载完毕之后，内核就会挂载用户在开机启动配置文件中设置的根文件系统。Linux 上的文件系统必需挂载到根文件系统上才能被使用。开机启动流程，文件系统会在之后详细介绍。当前我们需要重点了解的是，Linux 上目录和文件的组织结构。 如同在 Windows 上创建目录和文件上一样，我们可以在Linux 上随意的创建和删除文件。但是就像我们很难在别人的Windows 系统上查找文件一样，如果各Linux 发行厂商随意的组织 Linux 的文件，当我们更换一个 Linux 发行版时，我们可能就很难找到配置文件，应用程序；程序开发者也很难统一配置程序的安装目录。所以 Linux 标准委员会为避免这种情况发生，指定了一个标准，叫 FHS(filesystem hierarchy standard)。 FHS 主要对 /, /usr, /var 的使用进行了规范，我们将按照这三个层次进行介绍。在本文的结尾，我们将对Linxu 上的文件系统类型作详细介绍。 1. FHS 简介1.1 官方文档简介This standard enables: Software to predict the location of installed files and directories, and Users to predict the location of installed files and directories. We do this by: Specifying guiding principles for each area of the filesystem, Specifying the minimum files and directories required, Enumerating exceptions to the principles, and Enumerating specific cases where there has been historical conflict. The FHS document is used by: Independent software suppliers to create applications which are FHS compliant, and work with distributionswhich are FHS complaint, OS creators to provide systems which are FHS compliant, and Users to understand and maintain the FHS compliance of a system.The FHS document has a limited scope: Local placement of local files is a local issue, so FHS does not attempt to usurp system administrators. FHS addresses issues where file placements need to be coordinated between multiple parties such as localsites, distributions, applications, documentation, etc. 1.2 FHS 标准内容概述/, /usr, /var 必需包含的目录，及目录作用如下: / bin/: 所有用户可用的基本命令程序文件 sbin/: 供系统管理使用的工具程序 boot/: 引导加载器必须用到的各静态文件，包括 kernal, initramfs(initrd), grub 等 dev/: 存储特殊文件或设备文件，设备包括如下两种类型 字符设备，又称线性设备 块设备，又称随机设备 etc/: 系统程序的配置文件，只能为静态 home/: 普通用户家目录的集中位置 root/: 管理员家目录 lib: 为系统启动或根文件系统上的应用程序(/bin, /sbin等)提供共享库，以及为内核提供内核模块 libc.so.*： 动态链接的 C库 ld*: 运行时链接器或加载器 modules/: 用于存储内核模块的目录 lib64: 同lib，64 位系统特有的存放 64 位共享库的目录 media/: 便携式设备挂载点 mnt/: 其他文件系统的临时挂载点 opt/: 附加应用程序的安装位置，可选路径 srv/: 当前主机为服务提供的数据 tmp: 为哪些会产生临时文件的程序提供的用于存储临时文件的目录 usr/: shareable, read-only data，独立的层级目录，存放全局共享的只读数据路径 bin/: sbin/: 非管理或维护系统运行所必须的，额外添加的管理命令 lib: lib64: includ/: C 程序头文件 share/: 命令手册页和自带文档等框架特有的文件的存储位置 X11R6: X-Window 程序的安装位置 src: 程序源码文件的存储位置 local/: Local hierarchy 独立的层级目录，让系统管理员安装本地应用程序，也通常用于安装第三方程序- 应用程序多版本共存时，新版程序通常安装于此目录 - 层级结构与 /usr 类似 var/: var Hierarchy, 独立的层级目录，用于存储常发生变化的数据的目录 cache/: Application cache data lib/: Variable state information local/: Variable data for /usr/local lock/: Lock files log: Log files and directories opt/: Variable data for /opt run/: Data relevant to running processes spool/: Application spool data tmp/: Temporary files preserved between system reboots proc/: 基于内存的虚拟文件系统，用于为内核及进程存储其相关信息； 它们多为内核参数，例如net.ipv4.ip_forward, 虚拟为net/ipv4/ip_forward, 存储于/proc/sys/, 因此其完整路径为/proc/sys/net/ipv4/ip_forward； sys/: 用于挂载sysfs虚拟文件系统 提供了一种比proc更为理想的访问内核数据的途径； 其主要作用在于为管理Linux设备提供一种统一模型的的接口； 参考: https://www.ibm.com/developerworks/cn/linux/l-cn-sysfs/ 2. / 根目录3. /usr 目录4. /var 目录5. Linux 系统上的文件类型5.1 常见文件类型：1234&gt; lldrwxrwxr-x. 2 tao tao 158 2月 25 18:32 ankidrwxrwxr-x. 3 tao tao 43 2月 24 18:36 codingdrwxrwxr-x. 4 tao tao 53 1月 30 14:11 linux ls -l 命令显示结果第一列的首子母即表示文件类型，Linux 中的文件类型如下 -：常规文件；即f； d: directory，目录文件(路径映射) b: block device，块设备文件，支持以“block”为单位进行随机访问 c：character device，字符设备文件，支持以“character”为单位进行线性访问 l：symbolic link，符号链接文件 p: pipe，命名管道 s: socket，套接字文件 5.2 设备文件的设备号1234&gt; ll /dev# 10, 58 表示设备的设备号crw-------. 1 root root 10, 58 6月 19 21:35 network_latencycrw-------. 1 root root 10, 57 6月 19 21:35 network_throughput 设备文件还有设备号，其作用如下: major number：主设备号，用于标识设备类型，进而确定要加载的驱动程序; 8位二进制：0-255 minor number：次设备号，用于标识同一类型中的不同的设备; 8位二进制：0-255]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.2 Linux 命令帮助]]></title>
    <url>%2F2018%2F01%2F02%2Flinux_mt%2F03-Linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F</url>
    <content type="text"><![CDATA[Linux 中获取命令帮助 通过之前的学习我们了解到 Linux 命令分为两类，一类是 shell 内置的内嵌命令，另一类是外部命令。这两种命令获取帮助的并不相同，对于内部命令使用 help command 即可。而对于外部命令有很多方式，其中最重要也是最便捷的就是使用 man 帮助手册。本节我们将学习如何获取外部命令的使用帮助，以及了解 man 手册的使用方式。 1. 获取命令的使用帮助内部命令：help COMMAND外部命令： COMMAND --help: 命令自带简要格式的使用帮助 man COMMAND: 使用手册：manual info COMMAND: 获取命令的在线文档； 很多应用程序会自带帮助文档：/usr/share/doc/APP-VERSION，包括不限于 README：程序的相关的信息； INSTALL: 安装帮助； CHANGES：版本迭代时的改动信息； 主流发行版官方文档: eg：http://www.redhat.com/doc 程序官方的文档：官方站点上的”Document” 搜索引擎 123# google 搜索引擎的使用技巧keyword filetype:pdfkeyword site:domain.tld 2. man 帮助手册的使用简述2.1 man 手册页组成关于man的简介如下列表所示: man手册的原始文档位于 /usr/share/man中， 使用手册为压缩格式的文件，有章节之分,包括 ls /usr/share/man man1：用户命令； man2：系统调用； man3：C库调用； man4：设备文件及特殊文件； man5：文件格式；（配置文件格式） man6：游戏使用帮助； man7：杂项； man8：管理工具及守护进行； 当我们 man COMMAND 进入man手册后，其由如下几个部分组成。界面示例如下 SECTION：组成部分 NAME：功能性说明 SYNOPSIS：语法格式 DESCRIPTION：描述 OPTIONS：选项 EXAMPLES：使用示例 AUTHOR: 作者 BUGS: 报告程序bug的方式 SEE ALSO: 参考 SYNOPSIS: 命令使用 []：可选内容； &lt;&gt;：必须提供的内容； a|b|c：多选一； ...：同类内容可出现多个； 123456789101112131415161718&gt; man ifconfigIFCONFIG(8) Linux System Administrator&apos;s Manual IFCONFIG(8)NAME ifconfig - configure a network interfaceSYNOPSIS ifconfig [-v] [-a] [-s] [interface] ifconfig [-v] interface [aftype] options | address ...NOTE This program is obsolete! For replacement check ip addr and ip link. For statistics use ip -s link.DESCRIPTION Ifconfig is used to configure the kernel-resident network interfaces. It is used at boot time to set up interfaces as necessary. After that, it is usually only needed when debugging or when system tuning is needed.............. 1.2 man 命令使用man [CHAPTER] COMMAND 作用: 在特定章节中搜索命令的帮助手册, CHAPTER 参数可选 注意： 并非每个COMMAND在所有章节下都有手册； 可通过 whatis COMMAND 查看哪些章节中存在COMMAND 的帮助手册 whatis的执行过程是查询数据库进行的，必要时可通过 makewhatis 手动更新数据库 1.2 man 手册查看操作进入man手册页之后，其界面环境就是调用 less 命令的执行结果，可用的操作如下 翻屏： 空格键：向文件尾翻一屏； b: 向文件首部翻一屏； Ctrl+d：向文件尾部翻半屏； Ctrl+u：向文件首部翻半屏； 回车键：向文件尾部翻一行； k: 向文件首部翻一行； G：跳转至最后一行； #G: 跳转至指定行； 1G：跳转至文件首部； 文本搜索： /keyword：从文件首部向文件尾部依次查找；不区分字符大小写； ?keyword：从文件尾部向文件首部依次查找； n: 与查找命令方向相同； N: 与查找命令方向相反； 退出：q(quit)]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3.1 Linux 命令基础]]></title>
    <url>%2F2018%2F01%2F01%2Flinux_mt%2F03-Linux%E7%B3%BB%E7%BB%9F%E7%BB%84%E6%88%90%E5%92%8C%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E5%B8%AE%E5%8A%A9%2F%E5%B8%B8%E7%94%A8%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[Linux 基础命令 在安装完 Centos 之后，我们开始正式学习 Linux。在深入学习 Linux 之前，我们需要学习一些最基本命令的使用。我们将分成两节来学习下面内容: Linux 中的命令类型 Linux 命令的标准使用格式 Linux 常见基础命令的使用 如何使用 Linux 帮助文档 Linux 各个部分大多都有标准进行规范，以降低在不同发行版之间的迁移难度，命令也不例外。本节我们首先将学习命令的语法通用格式，然后了解 Linu 中命令的分类；最后介绍 Linux 常用的基础命令。 1. 命令的语法通用格式：COMMAND OPTIONS ARGUMENTS COMMAND: 命令名，发起一命令，请求内核将某个二进制程序运行为一个进程； 命令本身是一个可执行的程序文件：二进制格式的文件，有可能会调用共享库文件； 多数系统程序文件都存放在：/bin, /sbin, /usr/bin, /usr/sbin，/usr/local/bin, /usr/local/sbin 普通命令：/bin, /usr/bin, /usr/local/bin 管理命令：/sbin, /usr/sbin, /usr/local/sbin 共享库：/lib, /lib64, /usr/lib, /usr/lib64, /usr/local/lib, /usr/local/lib64 32bits的库：/lib, /usr/lib, /usr/local/lib 64bits的库：/lib64, /usr/lib64, /usr/local/lib64 注意：并非所有的命令都有一个在某目录与之对应的可执行程序文件 命令必须遵循特定格式规范：exe, msi, ELF(Linux) 查看命令类型: file /bin/ls OPTIONS： 作用: 命令选项，指定命令的运行特性； 类型: 选项有两种表现形式： 短选项：-C, 例如-l, -d 注意：有些命令的选项没有-； 如果同一命令同时使用多个短选项，多数可合并：-l -d = -ld 长选项：–word, 例如–help, –human-readable 注意：长选项不能合并； 注意：有些选项可以带参数，此称为选项参数； ARGUMENTS： 命令的作用对象；命令对什么生效； 注意：不同的命令的参数；有些命令可同时带多个参数，多个之间以空白字符分隔； 例如：ls -ld /var /etc 2. Linxu 的命令类型 命令分为两类： 内置命令(builtin): 由shell程序的自带的命令： 外部命令: 独立的可执行程序文件，文件名即命令名： 查看命令类型：type COMMAND 内部命令显示为 builtin 外部命令显示为命令文件路径； 注意：命令可以有别名；别名可以与原名相同，此时原名被隐藏；此时如果要运行原命令，则使用\COMMAND； 3. Linxu 的常用命令3.1 文件与目录查看命令pwd: 作用: 显示工作目录 cd：cd [/PATH/TO/SOMEDIR] 作用: change directory 改变当前工作目录 选项: cd: 切换回家目录；注意： cd ~：切换回自己的家目录，bash中, ~表示家目录； cd ~USERNAME：切换至指定用户的家目录； cd -：在上一次所在目录与当前目录之间来回切换； 附注: 相关的环境变量 $PWD：当前工作目录 $OLDPWD：上一次的工作目录 lsls [OPTION] [FILE] 作用: list, 列出指定目录下的内容 选项: -a: 显示所有文件，包括隐藏文件； -A: 显示除.和..之外的所有文件； -l: –long, 长格式列表，即显示文件的详细属性信息； -h: –human-readable：对文件大小单位换算；换算后结果可能会非精确值； -d: 查看目录自身而非其内部的文件列表； -r: reverse, 逆序显示； -R: recursive，递归显示； cat：cat [OPTION] [FILE] 作用: concatenate, 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； tac：tac [OPTION] [FILE] 作用: 文件文本查看工具； 选项: -n：给显示的文本行编号； -E: 显示行结束符$； filefile [FILE] 作用: 查看文件内容类型； echoecho [SHORT-OPTION] [STRING] 作用: 回显 选项: -n: 不进行换行； -e：让转义符生效； Linxu 中引号的效力 STRING可以使用引号，单引号和双引号均可用； 单引号：强引用，变量引用不执行替换； 双引号：弱引用，变量引用会被替换； 附注: 变量引用可使用 ${name} 和 $name 3.2 关机与重启命令shutdownshutdown [OPTIONS] [TIME] [WALL] 作用: 关机或重启命令 OPTIONS: -h: halt -r: reboot -c: cancel TIME： now: 立刻马上 hh:mm: 指定几时几秒 +m: m 分钟后 +0 3.3 日期相关的命令：Linux 系统启动时从硬件读取日期和时间信息；读取完成以后，就不再与硬件相关联；此时系统时钟与硬件时钟是相互独立的 datedate [OPTION] [+FORMAT] 作用: 显示系统时钟日期时间： 选项: -d String|-d @timestamp: 显示指定的时间字符串或时间戳表示的时间 -s, --set=STRING: 设置系统时间 FORMAT：格式符 %F:= %Y-%m-%d %T:直接显示时间 (24 小时制) %Y:完整年份 (0000-9999) %m:月份 (01-12) %d:日 (01-31) %H:小时(00-23) %M:分钟(00-59) %S:秒(00-60) %s:从1970年1月1号(unix元年)0点0分0秒到命令执行那一刻经过的秒数； 123456789101112131415# 按特定格式显示时间&gt; date +%s1531134611&gt; date -d @1531134611 +%F2018-07-09&gt; date -d &quot;2017-10-13 23:00:00&quot; +%F2017-10-13&gt; date# 设置系统时间&gt; date -s &quot;2018-10-13 23:10:12&quot;&gt; date -s &quot;2018/10/13 23:10:12&quot; hwclock / clockhwclock [function] [option] 作用:显示或设定硬件时钟 选项: -s: –hctosys,以硬件为准，把系统调整为与硬件时间相同； -w: –systohc：以系统为准，把硬件时间调整为与系统时钟相同； cal：cal [[month] year] 作用: 显示日历 3.4 命令别名与查找alias [alias-name[=string] 作用: 查看或定义命令别名： 常用: alias: 获取所有可用别名的定义： alias NAME=&#39;COMMAND&#39;： 定义别名： 注意：仅对当前shell进程有效 unalias NAME: 撤销别名： whichwhich [options] programname 作用: shows the full path of (shell) commands 选项: --skip-alias：忽略别名 whereis命令：whereis [options] name 作用: locate the binary, source, and manual page files for a command 选项: -b: 仅搜索二进制程序路径； -m：仅搜索使用手册文件路径； 3.5 登录用户查看whowho [OPTION] 作用: show who is logged on 选项: -b: 系统此次启动的时间； -r: 显示系统运行级别； ww [user] 作用: Show who is logged on and what they are doing. 增强版的 who ttytty 作用: 显示当前终端]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>马哥 Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 单元测试]]></title>
    <url>%2F2017%2F09%2F22%2Funittest%2Funittest_01%2F</url>
    <content type="text"><![CDATA[至关重要的单元测试 1. 单元测试Python 中有多个单元测试框架，最常用的应该是 unittest。本文的目的就是想系统介绍一下 unittest 的使用。 除了各种单元测试框架，Python 中还有不少可以用来辅助单元测试的模块，我看到的最有用但是却很少人使用的是 wrapt。wrapt 模块提供的功能可以部分替代unittest.mock ，简化单元测试的复杂度。这是我们将介绍的第二部分内容。 本文思路和部分内容借鉴自雨痕老师的Python3 学习笔记，这应该是既流畅的Python 之后我第二推荐的书，很适合有 Python经验的同学作为 Python 学习的补充。 下面我们就正式开始我们的内容。 2. Unittest2.1 Unittest 框架 从上面的 Unittest 框架，我们大体上就能看出使用 Unittest 进行单元测试的整个流程: 构建测试用例(Suit) 通过加载器选择我们想要测试的测试用例(Loader) 执行器执行测试返回结果(Runner) 下面是与框架对应的相关组件: TestLoader: 加载器，查找测试方法 Suit: 测试构建组件 TestCase: 测试用例，实现一个到多个测试方法，测试的基础单元 FunctionTestCase: 继承自 TestCase 专门为函数准备的通用测试类型 TestSuite: 测试套件，组合多个用例或套件 TestRunner: 执行器，执行测试，返回测试结果 TestResult: 测试结果 我们目的是学习各个组件的常见使用，并了解各个组件之间调用的”钩子”，以帮助我们构建更好的单元测试。 2.2 调用钩子TestCase要想明白 unittest 各个组件之间的调用钩子，我们得从 unittest.TestCase 说起: unittest 中所有的测试用例都必须继承自 TestCase 通过实例化 TestCase 创建一个测试过程，其 run 方法是启动测试的钩子函数 run 方法只会执行在实例化 TestCase 通过 methodName 参数传入的方法(默认为runTest) 因此要想测试 TestCase 内多个测试方法，需要为每个测试方法创建一个 TestCase 实例 123class TestCase(object): def __init__(self, methodName='runTest'): pass TestSuite为了批量管理多个测试过程，unittest 提供了 TestSuite 测试套件。其内部的 _tests 属性和 addTests 方法用来收集和添加 TestCase 的实例(也包括TestSuite实例本身)；当其 run 被调用时，会依次调用 _tests 内收集的测试实例的 run 方法，启动每一个测试过程。 1234567891011121314151617class BaseTestSuite(object): """A simple test suite that doesn't provide class or module shared fixtures. """ def __init__(self, tests=()): self._tests = [] self.addTests(tests) def addTests(self, tests): if isinstance(tests, basestring): raise TypeError("tests must be an iterable of tests, not a string") for test in tests: self.addTest(test)class TestSuite(BaseTestSuite): def run(self, result, debug=False): pass TestLoaderTestLoader 是 unittest 用来查找测试方法，批量创建测试用例实例的组件。其提供了多种发现机制，可递归扫描目录，查找符合匹配条件的测试模块；或指定具体的模块，用例类型甚至是某个测试方法。其完整的发现流程是: discover 方法会递归目录，查找文件名与传入模式匹配的所有模块， 用 loadTestsFromModule 在模块内获取所有的测试用例类型 用 loadTestsFromTestCase 为发现的测试用例的全部测试方法创建实例 最终，上面的所有的实例组合成测试套件交给执行器 loadTestsFromTestCase 调用 getTestCaseNames 查找类型中包含特定前缀的测试方法，没有找到时返回 runTest。这个特定前缀由 TestLoader的testMethodPrefix类属性限定。 loadTestsFromModule 按照加载协议约定，先调用 load_tests 函数返回自定义测试套件。仅在模块内没有 load_tests 函数时，返回模块内的所有用例类型。 unittest 内置了默认的加载器实例 defaultTestLoader 可直接使用。 123456789101112131415161718192021222324252627282930313233343536class TestLoader(object): """ This class is responsible for loading tests according to various criteria and returning them wrapped in a TestSuite """ testMethodPrefix = 'test' sortTestMethodsUsing = cmp suiteClass = suite.TestSuite _top_level_dir = None def loadTestsFromTestCase(self, testCaseClass): """Return a suite of all tests cases contained in testCaseClass""" pass def loadTestsFromModule(self, module, use_load_tests=True): """Return a suite of all tests cases contained in the given module""" pass def loadTestsFromName(self, name, module=None): pass def loadTestsFromNames(self, names, module=None): """Return a suite of all tests cases found using the given sequence of string specifiers. See 'loadTestsFromName()'. """ pass def getTestCaseNames(self, testCaseClass): """Return a sorted sequence of method names found within testCaseClass """ pass def discover(self, start_dir, pattern='test*.py', top_level_dir=None): pass defaultTestLoader = TestLoader() TestRunnerTestRunner执行器用于启动测试过程并返回测试结果。其实例的run方法接受测试用例或套件作为参数，并调用它们的 run 方法，执行测试并返回测试结果。TestRunner 是默认的执行器类，其默认输出到 sys.stderr，可使用 stream 参数将结果保存到文件中。 1234567891011121314class TextTestRunner(object): """A test runner class that displays results in textual form. It prints out the names of tests as they are run, errors as they occur, and a summary of the results at the end of the test run. """ resultclass = TextTestResult def __init__(self, stream=sys.stderr, descriptions=True, verbosity=1, failfast=False, buffer=False, resultclass=None): pass def run(self, test): pass 下面是 unittest 简单使用示例，现在你应该能明白整个测试的过程了。 12345678910111213141516171819202122from unittest import TestCaseclass DemoTest(TestCase): def test_1(self): self.assertTrue(True) def test_2(self): self.assertFalse(False)# 1. 直接启动测试用例# 加载器loader = unittest.defaultTestLoader# 测试用例suite = DemoTest('test_2')# 实例化执行器，调用 run 方法，传入测试用例，启动测试过程unittest.TextTestRunner(verbosity=2).run(suite) # unittest 默认的执行器# 2. 通过加载器启动测试用例# 加载器返回的测试套件suite = loader.loadTestsFromTestCase(DemoTest)unittest.TextTestRunner(verbosity=2).run(suite) 2.3 命令行unittest 还提供了命令行，通常我们只需要编写测试用例，通过 Python -m unittest 可直接启动测试过程； TestLoader 提供的测试方法发现机制可通过命令参数直接使用。下面是命令行的使用示例: 12345678# 启动方式二: 使用命令执行测试cd /home/tao/project/algo/unittest_demopython -m unittest demaopython -m unittest demao.DemoTestpython -m unittest demao.DemoTest.test_1cd ..python -m unittest discover unittest_demo/ "de*.py" 2.4 TestCase 使用为了方便测试，TestCase 还提供了很多钩子函数和断言方法，下面是一个简单的说明: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import unittestclass TestCase(object): def setUp(self): # 每个测试方法执行前后，调用 setUp/tearDown pass def tearDown(self): # pass @classmethod def setUpClass(cls): # 无论多少个实例，setUpClass/tearDownClass 仅执行一次 pass @classmethod def tearDownClass(cls): # pass def assertFalse(self, expr, msg=None): # 如果 expr 不为 False 测试失败 pass def assertTrue(self, expr, msg=None): # 如果 expr 不为 True 测试失败 pass def assertRaises(self, excClass, callableObj=None, *args, **kwargs): pass def assertEqual(self, first, second, msg=None): # 如果 first != second 测试失败 passclass DemoTest(TestCase): @unittest.expectedFailure # 期望测试失败 def test_1(self): self.assertTrue(False) @unittest.skip('reason....') # 忽略该测试，还有几个制定版本 def test_2(self): self.assertFalse(True) def test_3(self): # 测试是否抛出指定异常 with self.assertRaises(Exception): raise Exception() 3. wraptunittest 框架中真正复杂的是 unittest.mock。如果测试目标依赖其他对象或模块，我们可能就需要模拟(mock)替代它。但是 mock 模块使用起来很复杂，不直观，所以这篇文章我不打算讲解 mock。我们来看看如何使用 wrapt 来替代 mock来简化我们的测试。 wrapt 是Python 装饰器的工业级实现。由于 Python 装饰器和单元测试中的模拟行为非常相似，因此 wrapt 在实现一个通用装饰器的同时附加了辅助单元测试的接口。wrapt 使用便利，但是实现却相当复杂。以至于 Wrapt 模块的作者 Graham Dumpleton 先生写了 14 篇博客详细讲述 wrapt 的实现，下面是Graham Dumpleton 先生的博文 和 Wrapt 模块的文档: GrahamDumpleton wrapt blog wrapt 1.10.11 documentation 在此我们只举例说明如何使用，有关 wrapt 的实现后续会翻译Graham Dumpleton先生写的 14 篇博文，其中会详细介绍(译文:使用 wrapt 辅助测试)。 3.1 使用 wrapt 辅助单元测试wrapt 中有两个辅助单元测试的核心接口: transient_function_wrapper: 用于创建一个作用范围受限的模拟行为，像下面这样我们可以轻松实现在 cover_urlopen 内对 urllib2.urlopen 函数的模拟，而 cover_urlopen 外 urllib2.urlopen不受影响 wrapt.ObjectProxy: 代理对象，可以非常直观的实现对类的模拟 transient_function_wrapper1234567891011121314# 模拟函数import urllib2from wrapt import transient_function_wrapper@transient_function_wrapper('urllib2', 'urlopen')def urllib_request_wrap(wrapped, instance, arg, kwarg): return b'覆盖 urllib2.urlopen 函数返回值'# 对 urllib2.urlopen 函数的模拟，只会发生在 urllib_request_wrap 装饰的函数中@urllib_request_wrapdef cover_urlopen(): print urllib2.urlopen(url='http://www.baidu.com/')cover_urlopen() ObjectProxy1234567891011121314151617181920212223242526272829303132333435363738394041# 模拟类from wrapt import ObjectProxyclass Production(object): def __init__(self): self.value = 1 def run(self): print '%s running' % self.__class__.__name__class ProductionProxy(ObjectProxy): def __init__(self, wrapped): super(ProductionProxy, self).__init__(wrapped) self._self_value = 10 # 模拟类属性 @property def value(self): return self._self_value @value.deleter def value(self): del self._self_value # 通过方法覆盖，模拟类方法 def run(self): print 'proxy running'p = Production()print p.valuep_proxy = ProductionProxy(p)print p_proxy.valuep.run()p_proxy.run()print p.valueprint p_proxy.valuedel p_proxy.valueprint p_proxy.value]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor tornado 部署]]></title>
    <url>%2F2017%2F09%2F21%2Fdeploy%2Fsupervisor_tornado%2F</url>
    <content type="text"><![CDATA[通过 supervisor 创建监听套接字的文件描述符，为多个 tornado 进程共享 1. tornado 启动12345678910111213from tornado.netutil import set_close_execdef main(): app = AnalyticApiApplication() http_serve = httpserver.HTTPServer(app) # http_serve.listen(options.port) # supervisor 创建的监听套接字文件描述符，通过 0 号传递给 tornado的所有进程 sock = socket.fromfd(0, family=socket.AF_INET, type=socket.SOCK_STREAM) set_close_exec(sock.fileno()) sock.setblocking(0) # 设置套接字为非阻塞调用 http_serve.add_socket(sock) ioloop.IOLoop.instance().start() 2. supervisor 配置12345678command=/home/tao/.local/bin/pipenv run python app.py --connect=local-dev --debug=1socket=tcp://localhost:8888directory=/home/tao/projects/analytics_apiuser=taonumprocs=4process_name=%(program_name)s_%(process_num)02dstdout_logfile =/var/log/tornado_pyapi_stdout_%(process_num)02d.log stderr_logfile =/var/log/tornado_pyapi_stderr_%(process_num)02d.log 3. tornado.bind_socket12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788def bind_sockets(port, address=None, family=socket.AF_UNSPEC, backlog=_DEFAULT_BACKLOG, flags=None, reuse_port=False): """Creates listening sockets bound to the given port and address. Returns a list of socket objects (multiple sockets are returned if the given address maps to multiple IP addresses, which is most common for mixed IPv4 and IPv6 use). Address may be either an IP address or hostname. If it's a hostname, the server will listen on all IP addresses associated with the name. Address may be an empty string or None to listen on all available interfaces. Family may be set to either `socket.AF_INET` or `socket.AF_INET6` to restrict to IPv4 or IPv6 addresses, otherwise both will be used if available. The ``backlog`` argument has the same meaning as for `socket.listen() &lt;socket.socket.listen&gt;`. ``flags`` is a bitmask of AI_* flags to `~socket.getaddrinfo`, like ``socket.AI_PASSIVE | socket.AI_NUMERICHOST``. ``reuse_port`` option sets ``SO_REUSEPORT`` option for every socket in the list. If your platform doesn't support this option ValueError will be raised. """ if reuse_port and not hasattr(socket, "SO_REUSEPORT"): raise ValueError("the platform doesn't support SO_REUSEPORT") sockets = [] if address == "": address = None if not socket.has_ipv6 and family == socket.AF_UNSPEC: # Python can be compiled with --disable-ipv6, which causes # operations on AF_INET6 sockets to fail, but does not # automatically exclude those results from getaddrinfo # results. # http://bugs.python.org/issue16208 family = socket.AF_INET if flags is None: flags = socket.AI_PASSIVE bound_port = None for res in set(socket.getaddrinfo(address, port, family, socket.SOCK_STREAM, 0, flags)): af, socktype, proto, canonname, sockaddr = res if (sys.platform == 'darwin' and address == 'localhost' and af == socket.AF_INET6 and sockaddr[3] != 0): # Mac OS X includes a link-local address fe80::1%lo0 in the # getaddrinfo results for 'localhost'. However, the firewall # doesn't understand that this is a local address and will # prompt for access (often repeatedly, due to an apparent # bug in its ability to remember granting access to an # application). Skip these addresses. continue try: sock = socket.socket(af, socktype, proto) except socket.error as e: if errno_from_exception(e) == errno.EAFNOSUPPORT: continue raise set_close_exec(sock.fileno()) if os.name != 'nt': sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) if reuse_port: sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1) if af == socket.AF_INET6: # On linux, ipv6 sockets accept ipv4 too by default, # but this makes it impossible to bind to both # 0.0.0.0 in ipv4 and :: in ipv6. On other systems, # separate sockets *must* be used to listen for both ipv4 # and ipv6. For consistency, always disable ipv4 on our # ipv6 sockets and use a separate ipv4 socket when needed. # # Python 2.x on windows doesn't have IPPROTO_IPV6. if hasattr(socket, "IPPROTO_IPV6"): sock.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1) # automatic port allocation with port=None # should bind on the same port on IPv4 and IPv6 host, requested_port = sockaddr[:2] if requested_port == 0 and bound_port is not None: sockaddr = tuple([host, bound_port] + list(sockaddr[2:])) sock.setblocking(0) sock.bind(sockaddr) bound_port = sock.getsockname()[1] sock.listen(backlog) sockets.append(sock) return sockets]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualenv]]></title>
    <url>%2F2017%2F09%2F04%2Fdeploy%2Fvirtualenv%2F</url>
    <content type="text"><![CDATA[virtualenv 基本使用 1. 环境创建virtualenv dirname – 创建虚拟环境source dirname/bin/activate – 启用虚拟环境 virtualenv 可用选项 作用 –distribute dirname 创建新的虚拟环境，并安装 pip –no-site-packages 使系统环境的包对虚拟环境不可见 2.virtualenvwrapper作用：virtualenv 管理工具，方便的创建/激活/管理/销毁虚拟环境 命令 作用 mkvirtualenv virname 新建虚拟环境 workon virname 激活 deactivate 关闭 rmvirtualenv virname 删除]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo github blog]]></title>
    <url>%2F2017%2F09%2F03%2Fhexo%2Fhexo-github%2F</url>
    <content type="text"><![CDATA[使用 githup pages 和 hexo搭建 blog，本文不是完整教程，只是整个流程概览和常用命令备忘 1. github blog 搭建 安装node.js node -v 安装 hexo npm install hexo-cli -g 注册 github 帐号 新建xxx.github.io仓库，xxx 为帐号名称 初始化 hexo blog 123hexo init blogcd blognpm install 配置 hexo github 安装 hexo-deployer-gitnpm install hexo-deployer-git --save 在网站的_config.yml中配置deploy 123deploy:type: git repo: &lt;repository url&gt; branch: [branch] 提交git 12hexo d -ghexo d 2. hexo 常用命令 命令 作用 hexo init dir_name 创建博客目录 hexo clean …. hexo g(generate) 生成静态文件 hexo s(server) 启动本地web服务，用于博客的预览 hexo d(deploy) 部署播客到远端 hexo d -g 生成部署 hexo s -g 生成预览 hexo new “name” 新建文章 hexo new page “name” 新建页面 Quick StartHexo HomedocumentationtroubleshootingHexo GitHub. Create a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
